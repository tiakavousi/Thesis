id,pr_number,user,created_at,body,distilbert_sentiment_label,distilbert_confidence
113856314,2929,onurkaraman,2017-04-28T05:53:31Z,can we contain the `javaconverters._` import to be within the specific method needing the conversion as is being done elsewhere in kafkacontroller? importing at the file-level can lead to a lot of surprises when reading the code.,0,0.9203874468803406
113856373,2929,onurkaraman,2017-04-28T05:54:07Z,remove. this import already exists.,0,0.982914924621582
113856447,2929,onurkaraman,2017-04-28T05:55:07Z,"every other data structure in the controller uses the old topicandpartition. for consistency, can we use topicandpartition instead of topicpartition?",0,0.9880125522613525
113856721,2929,onurkaraman,2017-04-28T05:57:39Z,can just be: [code block],0,0.9879911541938782
113856779,2929,onurkaraman,2017-04-28T05:58:18Z,can just be: [code block],0,0.9879911541938782
113857148,2929,onurkaraman,2017-04-28T06:02:27Z,can we make this naming consistent with topicdeletionstopreplicaresult? we can either change the other class name or maybe change your new class to something like leaderandisrresult or leaderandisrresponseresult?,0,0.988820493221283
113973577,2929,lindong28,2017-04-28T16:51:48Z,i think it may be better to rename `topicdeletionstopreplicaresult` to `topicdeletionstopreplicaresponsereceived`. but i don't have a strong opinion on this. i can also rename `leaderandisrresponsereceived` to `leaderandisrresponseresult`. do you have a strong preference between the two?,0,0.9079784750938416
113973608,2929,lindong28,2017-04-28T16:51:59Z,sure. fixed now.,0,0.9448716044425964
113973627,2929,lindong28,2017-04-28T16:52:07Z,sure. fixed now.,0,0.9448716044425964
113975537,2929,lindong28,2017-04-28T17:02:05Z,i was thinking that we may want to use the java version for new code so that we can gradually migrate to the java version. i have change the code to use topicandpartition.,0,0.9788542985916138
113975948,2929,lindong28,2017-04-28T17:04:27Z,fixed now.,0,0.9813029170036316
113975960,2929,lindong28,2017-04-28T17:04:32Z,fixed now.,0,0.9813029170036316
113984161,2929,onurkaraman,2017-04-28T17:47:26Z,i'd prefer renaming `topicdeletionstopreplicaresult` to `topicdeletionstopreplicaresponsereceived`.,0,0.9825233221054077
114925916,2929,ijuma,2017-05-05T03:03:47Z,this rule doesn't apply to `javaconverters` since you need explicit `asscala` and `asjava` calls anyway. that rule was for `javaconversions` which did things automatically and has been deprecated.,0,0.9875023365020752
114925955,2929,ijuma,2017-05-05T03:04:37Z,"yeah, we definitely want to migrate all the code to the java class. it probably makes sense to do the whole class in one go though.",0,0.9741050601005554
119011953,2929,becketqin,2017-05-30T04:52:54Z,why should we rename the class?,0,0.9319552183151245
119012138,2929,becketqin,2017-05-30T04:55:35Z,this was a public api so it seems worth keeping and maybe mark it as deprecated.,0,0.9826098680496216
119012234,2929,becketqin,2017-05-30T04:56:56Z,maybe add some java doc to describe the exception a little?,0,0.9859206080436707
119012458,2929,becketqin,2017-05-30T05:00:15Z,can we add java doc for metadata request v3?,0,0.9897357225418091
119012849,2929,becketqin,2017-05-30T05:06:29Z,java doc is missing.,0,0.9466239213943481
119012994,2929,becketqin,2017-05-30T05:07:39Z,nit: name is a little different from the way zk_version was named.,0,0.9829038977622986
119013074,2929,becketqin,2017-05-30T05:08:58Z,can just fall through.,0,0.9661300778388977
120798287,2929,lindong28,2017-06-08T04:35:36Z,thanks for the information .,1,0.6671109795570374
120800388,2929,lindong28,2017-06-08T05:03:46Z,this patch adds the scala class `leaderandisrpartitionstate` and `metadatapartitionstate`. `metadatapartitioninfo` makes it more explicit that this is a java class that corresponds to `metadatapartitionstate`.,0,0.9872583746910095
120800491,2929,lindong28,2017-06-08T05:05:06Z,then i wouldn't bother to rename this class if it is public api.,0,0.9862144589424133
120800642,2929,lindong28,2017-06-08T05:06:43Z,sure. i added this comment: `miscellaneous disk-related ioexception occurred when handling a request`.,0,0.9878053665161133
120800786,2929,lindong28,2017-06-08T05:09:03Z,sure. added this comment: [code block],0,0.9828786849975586
120800846,2929,lindong28,2017-06-08T05:10:00Z,good catch. thanks. i replaced it with `is_new` both here and in the protocol.java.,1,0.9880225658416748
120800894,2929,lindong28,2017-06-08T05:10:51Z,i forgot this is java not scala. good point. fixed now.,1,0.9637980461120605
121294118,2929,becketqin,2017-06-11T23:12:45Z,"the comment seems a little convoluted. i think it can just be ""whether the replica should have existed on the broker or not.""",-1,0.6295660138130188
121294281,2929,becketqin,2017-06-11T23:20:33Z,"do we need to create `leader_and_isr_request_live_leader_v1`? it seems that we do not have a consistent convention on when to create a new internal field version. my preference is that we always bump up request/response version if either request or response version is bumped, because the version would be used for compatibility check. but for internal fields, we do not have to bump up version if there is no change.",0,0.9727426767349243
121294385,2929,becketqin,2017-06-11T23:26:10Z,"yes, this is a public api. renaming it requires a kip.",0,0.9878939986228943
121294648,2929,becketqin,2017-06-11T23:40:16Z,"if the default value of isnew is false, for brokers which are running ibp version lower than 0.11.1, replicas may not be created if a broker has a disk failure? in leaderandisrrequest earlier than v5, it actually means `create the replica if it does not exist`. in this case, i think it might make sense to keep the same behavior on the broker when storage failure is detected. i.e. let the entire broker halt if ibp is lower than 0.11.0.",0,0.9842821955680847
121294669,2929,becketqin,2017-06-11T23:40:52Z,"btw, can you also bump up `apiversions` as well?",0,0.9901583790779114
121294748,2929,becketqin,2017-06-11T23:44:31Z,good cleanup.,1,0.9240002036094666
121294952,2929,becketqin,2017-06-11T23:47:17Z,is this renaming necessary?,0,0.9825352430343628
121295031,2929,becketqin,2017-06-11T23:52:10Z,the hierarchy here is a little strange. it might be clearer to create a new `abstractpartitionstate` class and let the partitionstate in leaderandisrrequest and updatemetadatarequest inherit from it.,0,0.7863008379936218
121295155,2929,becketqin,2017-06-11T23:56:56Z,see comments about the `partitionstate` hierarchy.,0,0.9853726029396057
121295230,2929,becketqin,2017-06-12T00:00:23Z,no need to do this if the struct does not contain the offline_replicas field. a big if statement seems simpler.,0,0.981334924697876
121295331,2929,becketqin,2017-06-12T00:05:39Z,is this change intended? can the parent directories on different disk have the same name?,0,0.9874510765075684
121295556,2929,becketqin,2017-06-12T00:16:13Z,it is weird to pass in both controller and a member of the controller. the eventmanager field is already private to controller package so it is accessible from here.,-1,0.9838848114013672
121295627,2929,becketqin,2017-06-12T00:18:48Z,could be replaced by [code block].,0,0.9870820045471191
121296146,2929,becketqin,2017-06-12T00:39:50Z,no need to have the brackets around `brokerid`,0,0.9874217510223389
121296370,2929,becketqin,2017-06-12T00:48:03Z,some of the logics in this class are the same as in `onbrokerfailure()` probably worth trying to abstract them out to a shared method to handle offline replicas.,0,0.9875417351722717
121296397,2929,becketqin,2017-06-12T00:49:05Z,no need to have eventmanager passed in.,0,0.9824390411376953
121296413,2929,becketqin,2017-06-12T00:49:40Z,empty java doc.,0,0.9617131352424622
121296662,2929,becketqin,2017-06-12T00:59:18Z,ditto above.,0,0.9270309805870056
121296804,2929,becketqin,2017-06-12T01:04:53Z,ditto above.,0,0.9270309805870056
121297063,2929,becketqin,2017-06-12T01:13:10Z,is a mutable map enough here?,0,0.9866581559181213
121297514,2929,becketqin,2017-06-12T01:22:21Z,why arraybuffer?,0,0.974557638168335
121297615,2929,becketqin,2017-06-12T01:25:06Z,would a mutable map work here?,0,0.9869821667671204
121297859,2929,becketqin,2017-06-12T01:31:27Z,"there should not be duplicates in the `livelogdirs`, right? so we can just remove the dir for `livelogdirs`.",0,0.989332914352417
121298466,2929,becketqin,2017-06-12T01:44:00Z,i did not see the logic to handle io failures in log segments loading. am i missing something?,0,0.514391303062439
121299795,2929,becketqin,2017-06-12T02:00:53Z,we should probably exit if broker id load or checkpoint fail.,0,0.9826403260231018
121305112,2929,becketqin,2017-06-12T03:19:54Z,"it seems that sometimes we are catching both ioexception and kafkastorageexception, sometimes we only catch kafkastorageexception. it might be better to only catch ioexception at the the direct thrown and convert them to kafkastorageexception. so in the caller methods we only need to catch kafkastorageexception.",0,0.9805161952972412
121305435,2929,becketqin,2017-06-12T03:25:16Z,this exception should probably extend from retriableexception instead of apiexception. a disk failure should not cause the client to throw exception to the users. the clients should just retry after the leadership moves to another healthy replica.,0,0.9810025691986084
121313873,2929,lindong28,2017-06-12T05:50:36Z,sure. i have updated the comment as you suggested.,0,0.9701073169708252
121313909,2929,lindong28,2017-06-12T05:50:58Z,sure. i updated the patch to removed `leader_and_isr_request_live_leader_v1`.,0,0.9720259308815002
121314572,2929,lindong28,2017-06-12T05:58:35Z,"regarding the first comment, it seems safer to disable replica creation if any replica offline. i think it is probably more backward compatible to do so -- currently leaderandisrrequest will fail to create replica if any disk is offline. regarding the second comment, good point. i should have updated the controller code to specify the version for leaderandisrrequest and updatemetadatarequest based on the configured `interbrokerprotocolversion`. i have updated the patch to do this and added `kafka_0_11_1_iv0` in `apiversion`. thanks!",1,0.6616809368133545
121314687,2929,lindong28,2017-06-12T06:00:02Z,`metadataresponsepartitionstate` will be more consistent and clearer than `partitionmetadata` in describing the usage of this class. it is not necessary to change the class. i replaced the todo with a comment that says `this is used to describe metadataresponsepartitionstate`.,0,0.9863496422767639
121314881,2929,lindong28,2017-06-12T06:02:16Z,"sure. i think we can do that refactor. since this is not an important refactor, can we do this refactor later or even in separate patch to reduce the chance of conflicts with other commits? for now i replaced the todo with a comment that says `this is used to describe leaderandisrpartitioninfo`.",0,0.9750995635986328
121314992,2929,lindong28,2017-06-12T06:03:26Z,i think the current class name updatemetadatarequestpartitionstate is good enough. i have removed this todo.,0,0.8600457906723022
121315115,2929,lindong28,2017-06-12T06:04:43Z,"the current code is simpler than having an extra `if` statement. i am wondering what is the benefit of the extra `if` statement. it seems to have negligible impact on performance, right?",0,0.8245978951454163
121315417,2929,lindong28,2017-06-12T06:08:39Z,"yes, it is intended. i think `dir.getparent` is exactly the same as `dir.getparentfile.getabsolutepath` according to their java doc. `dir.getparent` is a bit shorter. i think parent directories on different disk must have the different name since they are specified as a list of strings using `log.dirs` config. they must be different so that kafka can distinguish between them.",0,0.9792678356170654
121315565,2929,lindong28,2017-06-12T06:10:44Z,good point. previously i think my ide tells me it can not be accessed as `controller.eventmanager`. i have updated it to use `controller.eventmanager`.,1,0.9453604817390442
121315578,2929,lindong28,2017-06-12T06:10:53Z,good point. fixed now.,1,0.9691434502601624
121315647,2929,lindong28,2017-06-12T06:11:47Z,great point. i have moved the overlapping logic to a new method named `onreplicabecomeoffline(newofflinereplicas: set[partitionandreplica])`.,1,0.978613555431366
121315661,2929,lindong28,2017-06-12T06:11:56Z,sure. fixed now.,0,0.9448716044425964
121316067,2929,lindong28,2017-06-12T06:15:48Z,this comment seems ok since it is similar to the comment of `brokerchangelistener` and `isrchangenotificationlistener` etc. i can improve it. is there any example listener class's comment you want me to follow?,0,0.9737136363983154
121316335,2929,lindong28,2017-06-12T06:18:22Z,"i agree. but all existing listener class (e.g. partitionreassignmentlistener) takes this as the second argument. it seems better to keep the same code style for `logdireventnotificationlistener`, or we can update all of them to remove the second argument `eventmanager`. which solution do you prefer?",0,0.9754870533943176
121316376,2929,lindong28,2017-06-12T06:18:37Z,it is removed now. thanks.,1,0.8851737976074219
121316420,2929,lindong28,2017-06-12T06:18:44Z,it is removed now. thanks.,1,0.8851737976074219
121316852,2929,lindong28,2017-06-12T06:22:20Z,"i think it can be changed to a mutable map since a volatile var map can usually be replaced by a mutable map and vise versa. does kafka code has a preference between the two? i have chosen to use volatile var here because the code may be simpler. for example, i can simply do `checkpoints = checkpoints.filterkeys(_.getabsolutepath != dir)` in `logcleanermanager.handlelogdirfailure(dir: string)`.",0,0.9870408177375793
121317056,2929,lindong28,2017-06-12T06:24:16Z,"i think it can be changed to a mutable map since a volatile var map can usually be replaced by a mutable map and vise versa. does kafka code has a preference between the two? i have chosen to use volatile var here because the code may be simpler. for example, i can simply do `recoverypointcheckpoints = recoverypointcheckpoints.filterkeys(file => file.getabsolutepath != dir)` in `logmanager.handlelogdirfailure(dir: string)`.",0,0.9857707023620605
121319054,2929,lindong28,2017-06-12T06:43:47Z,"previously i think it is ok not to handle failure in `loadlogs()` because the subsequent requests (e.g. fetchrequest, producerrequest, leaderandisrrequest) can trigger `handlelogdirfailure(...)`. handling log directory failure in `loadlogs()` could allow broker to fail faster if all log directories are offline at the cost of slightly more code. anyway, i have updated the code to handle io failure in log segments loading.",0,0.9816433787345886
121319440,2929,lindong28,2017-06-12T06:47:22Z,we need to pass `logmanager.livelogdirs` to `logcleanermanager` by reference and be able to propagate the change in `logmanager.livelogdirs` to `logcleanermanager`. therefore we need to change its type to arraybuffer so that it is mutable. does this make sense?,0,0.9876420497894287
121319883,2929,lindong28,2017-06-12T06:51:16Z,note that `livelogdirs` has type `arraybuffer[file]` and `dir` has type `string`. it seems that `arraybuffer` only allows remove by position in the array. it does not have a method to remove element by value.,0,0.987657904624939
121320013,2929,lindong28,2017-06-12T06:52:20Z,"can you explain why we should let broker exit if broker id load fail? my concern is that this will cause broker to exit if any log directory goes offline, which defeats the purpose of this kip.",0,0.8668573498725891
121320570,2929,lindong28,2017-06-12T06:57:39Z,"it is possible to catch ioexception at the the direct thrown and convert them to kafkastorageexception. but the code change required for those try/catch/indentation is probably much more than the code needed for the extra exception in the catch. also, it is probably easier to verify that we catch both ioexception and kafkastrageexception in the request handling code than making sure we have a try/catch around every code that touches io. does this make sense?",0,0.9804077744483948
121320850,2929,lindong28,2017-06-12T07:00:26Z,i think it is probably better to keep `kafkastorageexception` as `apiexception` similar to the definition of`replicanotavailableexception`. the client code should not see `kafkastorageexception` if any replica is offline due to disk failure. instead the client should see e.g. `leadernotavailableexception` which is `retriableexception`. `kafkastorageexception` will only be received by controller. does this make sense?,0,0.9848489165306091
121347432,2929,ijuma,2017-06-12T09:32:10Z,"since it's an inner class of `metadataresponse`, there is no need to also add `metadataresponse` as a prefix to the inner class name.",0,0.9883140325546265
121349573,2929,ijuma,2017-06-12T09:41:19Z,"the intent is for `kafkacontroller.eventmanager` to be visible for testing (there's a comment next to the field). maybe we need to change the tests to access it reflectively since it's understandable that people may miss the comment. the reasoning is that by passing the `kafkacontroller` everywhere, it makes it harder to understand and limit the responsibility of each class. it would be nicer if we passed more granular instances . for example, this class needs `eventmanager`, `config`, `topicdeletionmanager` and `controllerchannelmanager`. if we passed those instead, we get a picture of what the class needs immediately instead of having to read every line of code.",0,0.964432954788208
121349800,2929,ijuma,2017-06-12T09:42:24Z,i explained in another similar comment why `eventmanager` is passed explicitly.,0,0.9864717125892639
121350268,2929,ijuma,2017-06-12T09:44:36Z,"the semantics are not the same if you simply replace a volatile map with a mutable one in the face of concurrency (i haven't looked at the code, but the volatile implies that multiple threads are in play here).",0,0.9719456434249878
121351052,2929,ijuma,2017-06-12T09:48:27Z,you can remove it by value by using `def -= (x: a): this.type`.,0,0.9871520400047302
121467556,2929,lindong28,2017-06-12T16:56:01Z,"it may be useful to rename this class such that, instead of doing `new metadataresponse.partitionmetadata(...)` in the code, we can do `import org.apache.kafka.common.requests.metadataresponse.partitionmetadata` and `new partitionmetadata(...)` e.g. in `metadatacache.java`. the latter is more concise. anyway, i have replaced this todo with just a comment.",0,0.9845251441001892
121468083,2929,lindong28,2017-06-12T16:58:09Z,"thanks for the explanation. do you prefer to include `eventmanager` explicitly in the constructor of `controllerbrokerrequestbatch`, or is it ok to reference `eventmanager` via `kafkacontroller`?",1,0.8270967602729797
121468423,2929,lindong28,2017-06-12T16:59:26Z,thanks. i think i will keep the existing approach of including `controllereventmanager` in the constructor of those listeners since it is needed in the test. we can refactor them in a separate patch if it is necessary.,1,0.9463179707527161
121469351,2929,lindong28,2017-06-12T17:03:14Z,yeah i understand the meaning of volatile. can you explain a bit more specifically the case in which one can not be replaced by the other? thank you.,1,0.8829430341720581
121483933,2929,lindong28,2017-06-12T18:02:17Z,you are right. i have updated the patch to use `livelogdirs -= new file(dir)`.,0,0.8668272495269775
121559449,2929,ijuma,2017-06-13T00:33:56Z,"if one uses a volatile var, it's possible to update multiple entries in the map without exposing the intermediate states. with mutable maps, that's typically not possible without some form of external locking. on the other hand, one can lose updates by using a volatile var. generally, it's clearer to use a concurrentmap if that is the intent.",0,0.9861029386520386
121560258,2929,lindong28,2017-06-13T00:41:47Z,"thanks for the explanation . i have two follow-up questions. suppose we don't use a thread-safe map and choose to use an external lock to protect a non-thread safe map, then are these two approaches equivalent? and in this specific case, do you recommend me to replace the ` var map` with a `concurrentmap`?",1,0.7636498212814331
121563032,2929,ijuma,2017-06-13T01:08:16Z,"if you have an external lock during updates in both cases (like in this example), then the volatile version has the advantage that you don't need a lock on reads. the disadvantage is that there is potentially more copying. in this particular case, you are using `filterkeys` which is just a view on the underlying map. that doesn't seem like a good idea. aside from that, i have to look at the changes more closely to have a worthwhile opinion on what should be done here.",0,0.8898893594741821
121759231,2929,becketqin,2017-06-13T18:27:55Z,doing that later is fine.,0,0.9532003402709961
121762930,2929,becketqin,2017-06-13T18:42:07Z,"i am not sure about why it is safer to disable replica creation on a broker with failed directory. does that mean a broker will not get assigned any new replica as long as it has one disk failed? does that require controller awareness? but the controller does not know about that if it runs old ibp, right?",0,0.7581458687782288
121763195,2929,becketqin,2017-06-13T18:43:15Z,we should probably just remove the ` controller` if there is no java doc for it.,0,0.9871085286140442
121765991,2929,becketqin,2017-06-13T18:53:54Z,"this code is only called at startup time. it is to protect against data messed up from different brokers. since the broker hasn't started yet, it is probably ok for the broker to shutdown. users can remove the log dir from the path and restart the broker in this case.",0,0.9870755076408386
121779680,2929,lindong28,2017-06-13T19:51:54Z,"note that this only matters when there is disk failure. let me try to explain it based in the following different scenarios: 1) all brokers are running old code. the choice of the default value doesn't matter in this case because the code in this patch won't be used. 2) brokers are rolling upgraded to use the new code but the ibp is still old. here is the concern with setting default value to true. suppose the broker is running new code and partition p1 is in an offline log directories of this broker. if controller is running old code and sends leaderandisrrequest asking this broker to be leader of p1, the broker will re-create partition p1 on a good log directory. the follower will truncate the log for p1 and the data will be lost. and kip-112 currently doesn't handle it the case that the offline disk is repaired and used again with p1 still in it. on the other hand, with default value set to false, broker will refuses to become leader for p1, controller will not handle re-elect leader for p1 because it is running old code. during this period partition will become unavailable because the producer/consumer will send request to this broker and receive notleadderforpartitionexception. however, this will only happen for a short period of time and the problem will be solved once the controller is moved to a broker which is running new code. thus in this case, it is safer to set default value to false. 3) all brokers are running new code but some brokers are still using old ibp. suppose controller sends leaderandisrrequest for a new partition p1 to a broker with offline log directory, the broker will refuse to create log for p1 and return error in leaderandisrresponse. since the controller is running new code, it will handle the error properly by re-electing leader for this partition. in the rare scenario that all brokers elected to be replicas for this partition have offline disk, the partition will be offline. but the chance of this happening is low and this will be addresses once the ibp is fully upgraded. 4) all brokers are running new code with the new ibp. in this case the leaderandisrrequest will explicitly specify the isnew field and the default value doesn't matter. does this make sense?",0,0.9746404886245728
121779812,2929,lindong28,2017-06-13T19:52:31Z,thanks ! i will also think about it more.,1,0.9721797108650208
121780457,2929,lindong28,2017-06-13T19:55:32Z,i think the purpose of kip-112 is to make sure that broker be able to serve replicas on the good log directory even if there is bad log directory. we can not achieve this goal and the availability will be reduced if broker can not startup due to disk failure. can you explain a bit more why it is a concern if broker id load fails in one log directory? does this cause data corruption?,0,0.9479399919509888
121784846,2929,lindong28,2017-06-13T20:15:35Z,yeah you are right. i have removed it from the patch.,0,0.9546270966529846
122559063,2929,lindong28,2017-06-17T02:39:55Z,"discussed with offline. we decide to assume isnew = false if ibp is old. there are two options here when ibp is old. one is to be behavior of the current patch, i.e. broker will not shutdown if there is offline replica, and if there is new replica is assign to a broker will offline log directory, its creation will fail and the replica will be offline even if it can be created on a good replica. the other solution is to simply let broker shutdown if there is offline log directory. this allows new partition/topic to be assigned to only live broker and they won't be offline immediately after creation. we choose the first solution because it can keep the replicas on good log directories online at the cost of having all new replicas on that broker offline. it is likely that the number of new replicas assigned to that broker will be much less than the number of replicas on the good log directories of that broker. also, if user does prefer the second solution, he/she can manually shutdown that broker so that new replica will be online. i have updated the notes in `upgrade.html` to explain this.",0,0.9729597568511963
122559075,2929,lindong28,2017-06-17T02:40:54Z,"discussed offline. i have updated the patch so that if there is ioexception when reading brokerid from metadata file, the corresponding log dir will be marked failure but the broker will not shutdown. on the other hand, after broker registers itself in the zookeeper, it will only try to checkpoint brokerid in the metadata files in the live log directory (i.e. `logmanager.livelogdirs`). most likely there won't be ioexception when writing to metadata files here. if there is, then broker will shutdown entirely.",0,0.9852691292762756
123092424,2929,becketqin,2017-06-20T20:53:29Z,"hmm, if that is the case, should the storage exception be converted to leadernotavailableexception when it is thrown for requests such as produce/fetch/listoffsets? also, in that case, does that mean the broker needs to hold on the response until the controller moves leadership? otherwise broker is essentially giving up leadership by itself without get the confirmation from the controller. another thing is that we need to make sure the error code returned matches what is reflected in the metadata response. i am not sure what is the best exception to return to the user in this case, but in general i would rather not reuse exceptions for different scenarios.",0,0.9288724660873413
123122372,2929,lindong28,2017-06-20T23:32:52Z,sure. i have made kafkastorageexception a retriable exception.,0,0.9748251438140869
123122415,2929,lindong28,2017-06-20T23:33:18Z,i have fixed the issue by using the `if` statement as suggested.,0,0.9862646460533142
123651559,2929,becketqin,2017-06-23T00:30:24Z,we should also add a 0.11.1 version pointing to kafka_0_11_1_iv0,0,0.9852124452590942
123659570,2929,lindong28,2017-06-23T02:08:06Z,sure. i have updated the patch to address this issue. and the patch has been rebased onto the latest trunk.,0,0.9433257579803467
123817916,2929,becketqin,2017-06-23T18:38:02Z,do we need to create this field version?,0,0.984775722026825
123832032,2929,becketqin,2017-06-23T19:54:25Z,"for these two cases, the broker needs to read data from internal topics asynchronously. it seems that in both case the broker will only log an error without notify the controller that they cannot serve as leaders for those two partitions.",0,0.9812960028648376
123836327,2929,becketqin,2017-06-23T20:20:01Z,looked a bit more. it seems that we are not handling the disk exceptions thrown from filerecords.readinto(). that method is also used by logcleaner. could you check?,0,0.9830817580223083
123840858,2929,becketqin,2017-06-23T20:45:37Z,the `truncateto` method can throw storage exceptions. if that storage exception happens in the `replicafetcherthread` it seems we are not handling that.,0,0.9537165760993958
123869098,2929,lindong28,2017-06-24T03:09:49Z,sorry. removed now.,-1,0.9863060712814331
123869183,2929,lindong28,2017-06-24T03:15:45Z,thanks for catching this. i have added `try/catch` for `truncateto`.,1,0.821895956993103
123871120,2929,lindong28,2017-06-24T05:32:43Z,sure. i have updated the code to handle ioexception here.,0,0.9652764797210693
123884003,2929,becketqin,2017-06-24T19:40:12Z,this looks a little verbose. maybe it could just be `updatemetadatarequest.partitionstate`,0,0.9200577139854431
123884171,2929,becketqin,2017-06-24T19:49:55Z,"should this class be in updatemetadatarequest? this patch introduces/modifies some classes containing similar fields, can we clean them up? we had some discussion on that before and i though a follow up patch is also fine. could you create another ticket to track this? more specifically, if there are common fields, an abstract partition state class would probably help. if there are additional partition state in different requests, those partitionsstate class should ideally extends from the abstract class and sit together with the corresponding requests.",0,0.9707580804824829
123884367,2929,becketqin,2017-06-24T20:01:18Z,"we are already checking the `isreplicalocal(replicaid)` above, can this logic be merged into that if statement?",0,0.9875870943069458
124189370,2929,becketqin,2017-06-27T06:45:27Z,"typo, filel -> file",0,0.9859902858734131
124197932,2929,becketqin,2017-06-27T07:34:37Z,i have the same question here. is it just to make sure we do not *lose* the log that failed to be removed?,0,0.9455115795135498
124200168,2929,becketqin,2017-06-27T07:47:39Z,is this the same as`logmanager.livelogdirs`?,0,0.9881340861320496
124413939,2929,becketqin,2017-06-27T22:35:56Z,"it seems that calling `replicamanager.handlelogdirfailure()` may cause deadlock here. say the broker is handling an leaderandisrrequest, it will first grab the `replicamanager.replicastatechangelock` and then grab the `abstractfetcherthread.partitionmaplock`. however, when handling disk failure in `replicafetcherthread.processpartitiondata()`, the locking order is reversed. one way to solve this is to add an abstract error handling method in abstractfetcherthread and invoke that out of the `partitionmaplock`.",0,0.9800252914428711
124416864,2929,becketqin,2017-06-27T22:55:08Z,logdirutils?,0,0.9883008003234863
124417294,2929,becketqin,2017-06-27T22:58:13Z,"it seems that in the existing code the broker will halt if `logmanager.cleanuplogs()` sees a disk exception here. but with the patch, it will just silently fail.",0,0.9317718744277954
124418494,2929,becketqin,2017-06-27T23:07:19Z,is this block needed?,0,0.986839771270752
124429369,2929,lindong28,2017-06-28T00:32:18Z,sure. it is renamed now.,0,0.9642786383628845
124429977,2929,lindong28,2017-06-28T00:38:11Z,"sure. i can clean them up. in the interest of reducing conflicts with other patches, i refactor the code and clean it up in a follow up patch. i will create the ticket after this patch is committed.",0,0.9471184015274048
124430275,2929,lindong28,2017-06-28T00:41:32Z,the `isreplicalocal(replicaid)` used above is only called if `replicaid` is not in `assignedreplicamap`. i couldn't find a good way to merge them. do you have a good way to do it?,0,0.9287232160568237
124430429,2929,lindong28,2017-06-28T00:43:07Z,thanks. fixed now.,1,0.8842014074325562
124430768,2929,lindong28,2017-06-28T00:46:48Z,not exactly the same because `config.logdirs` is a list of string whereas `logmanager.livelogdirs` is a list of file. i have updated the code to avoid the `if` statement.,0,0.9762193560600281
124438217,2929,lindong28,2017-06-28T02:07:35Z,great catch! it is fixed now.,1,0.9929521679878235
124439381,2929,lindong28,2017-06-28T02:19:21Z,good point. it is renamed now.,1,0.9724843502044678
124444527,2929,lindong28,2017-06-28T03:16:48Z,"thanks for catching this. this becomes a problem due to the use of `leaderepochcache` in kip-101. i have updated the patch to halt the system if `filenotfoundexception` is observed. while it is possible catch the ioexception thrown from this place and handle it, it will require a couple of try/catch/handle distributed across the code. and non-trivial change is needed to avoid deadlock because `replicafetcherthread.handleoffsetoutofrange()` may also trigger this code. i think the simplest approach is to just keep the existing code, i.e. halt the system if `filenotfoundexception` is thrown from here. i don't think it will affect the availability of jbod deployment because according to mayursh's comment, this `filenotfoundexception` is thrown if the broker is configured with raid. we can re-investigate this problem if this is also an issue when broker uses jbod.",1,0.8424404859542847
124445278,2929,lindong28,2017-06-28T03:25:41Z,yeah this is no longer needed in this test after a recent comment on jun 5. i will go through the core code after rebase but typically skip the test code if they pass. thanks for catching this! it is removed now.,1,0.9829882979393005
124479048,2929,becketqin,2017-06-28T08:19:26Z,"you are right, never mind.",0,0.7577484250068665
124685896,2929,junrao,2017-06-29T00:03:27Z,perhaps add a comment that summarizes what's changed in v1 of leaderandisr request?,0,0.9866190552711487
124686504,2929,junrao,2017-06-29T00:08:37Z,perhaps add a comment that summarizes what's changed in v4?,0,0.9822670817375183
124695356,2929,junrao,2017-06-29T01:37:04Z,could we avoid wrapping kafkastorageexception if e is already of kafkastorageexception?,0,0.9774678945541382
124696536,2929,junrao,2017-06-29T01:51:10Z,"state change log is for logging actions to requests from the controller. since this method could be called from serving non-controller request, perhaps it's better to just log it in the server.log.",0,0.9893488883972168
124711510,2929,lindong28,2017-06-29T04:49:26Z,i will replace `deleterecursively(...)` with `org.apache.kafka.common.utils.utils.delete(...)` in the next commit.,0,0.9863873720169067
124931997,2929,junrao,2017-06-29T23:01:39Z,"could we do filter { case (tp, log) .. } and map ( case (tp, log) ...} so that it's a bit clearer what's being referenced?",0,0.9877233505249023
124932600,2929,junrao,2017-06-29T23:06:13Z,is this worth logging?,0,0.9796247482299805
124932609,2929,junrao,2017-06-29T23:06:21Z,is this worth logging?,0,0.9796247482299805
124934166,2929,junrao,2017-06-29T23:18:20Z,we probably want to limit the places with direct zkutils access. perhaps it's better to send zk notification in replicamanger.handlelogdirfailure()?,0,0.9890415072441101
124935126,2929,junrao,2017-06-29T23:25:38Z,does this need to be synchronized inside logcreationordeletionlock since livelogdirs could be changed concurrently? offlinelogdirs could be called from a different thread for metric reporting.,0,0.9886564016342163
124935421,2929,junrao,2017-06-29T23:28:00Z,will it be worth adding a per logdir metric so that we can find out which individual log dir is online/offline?,0,0.9856045842170715
124936765,2929,junrao,2017-06-29T23:37:56Z,"perhaps it's better to only capture ioexception here? for other exceptions, it's probably better to just fail the broker as before.",0,0.9757047295570374
124940850,2929,junrao,2017-06-30T00:13:52Z,"there are a few places like logmanager.truncateto() where we call logmanager.handlelogdirfailure() directly. it seems that they should all call replicamanager.handlelogdirfailure() instead since it does things like taking the partition off allpartitions and removing the partition from replicafetchermanager, which need to be done on an offline logdir.",0,0.9871085286140442
124947219,2929,junrao,2017-06-30T01:21:12Z,"so, here, we are not communicating the truncation error back to the replica fetcher thread. ideally, if the truncation fails, we shouldn't let the replica fetcher proceed with the subsequent fetching.",0,0.9765505194664001
124948445,2929,junrao,2017-06-30T01:30:13Z,is .toseq needed?,0,0.9876662492752075
124948786,2929,junrao,2017-06-30T01:33:58Z,"for consistency, it seems that we need to handle ioexception in truncatefullyandstartat() and call handlelogdirfailure() too?",0,0.9875596165657043
125063695,2929,junrao,2017-06-30T15:15:48Z,"we requeue the logs that failed deletion mostly because of ioexception. so, i am not sure if we need to requeue removedlog now.",0,0.9419206976890564
125064418,2929,junrao,2017-06-30T15:18:51Z,could we add a comment to explain what isnew means?,0,0.9808071255683899
125069246,2929,junrao,2017-06-30T15:40:50Z,"in line 709, we convert an ioexception to kafkastorageexception in log.append. i am wondering if this is needed since the caller of append handles both ioexception and kafkastorageexception. also, in replicamanager, sometimes we catch kafkastorageexception and some other times we catch both ioexception and kafkastorageexception. it would useful to make that consistent. for example, we can make the convention that ioexception will be throw from java library and kafkastorageexception will be throw in the kafka code (but not wrapping ioexceptions from java). then the caller will catch both ioexception and kafkastorageexception",0,0.9457164406776428
125073587,2929,junrao,2017-06-30T16:00:19Z,"hmm, not sure why we need the additional check here. if replicaid is not in assignedreplicamap, it probably shouldn't lead to a kafkastorageexception.",0,0.9566777944564819
125087026,2929,junrao,2017-06-30T17:13:36Z,we probably need to do the following optimization in delete() here? coreutils.swallow(forceunmap(mmap)),0,0.9875820875167847
125088146,2929,junrao,2017-06-30T17:19:41Z,unused import,0,0.9649426341056824
125094553,2929,junrao,2017-06-30T17:51:33Z,could we adjust the comment of the return value accordingly?,0,0.9872095584869385
125097858,2929,junrao,2017-06-30T18:05:59Z,partitionstate seems unused?,0,0.9783534407615662
125101226,2929,junrao,2017-06-30T18:21:56Z,"hmm, doloadgroupsandoffsets() just runs in a scheduler. should we call replicamanager.handlelogdirfailure() on ioexception too? if so, we probably want to do the same in txnmanager.",0,0.9871858954429626
125109233,2929,junrao,2017-06-30T19:02:30Z,"in controller failover, would it be worth to clean up all leftover sequence nodes in logdireventpath? those nodes won't be useful since the new controller will send a leaderandisrrequest to every broker on failover.",0,0.9879989624023438
125112249,2929,junrao,2017-06-30T19:19:03Z,"if a disk fail in the code path outside of the log cleaner, we should remove that dir from checkpoints too. is that logic added already?",0,0.9869698286056519
125120383,2929,lindong28,2017-06-30T20:05:00Z,thanks for catching this. i have updated the patch to say `leader_and_isr_request_v1 added a per-partition is_new field. this field specifies whether the replica should have existed on the broker or not`.,1,0.970066249370575
125120952,2929,lindong28,2017-06-30T20:08:44Z,"sure. i added the following comment for `update_metadata_request_partition_state_v4`, `update_metadata_request_v4` and `metadata_response_v5`. `... added a per-partition offline_replicas field. this field specifies the list of replicas that are offline`",0,0.9730265736579895
125121473,2929,lindong28,2017-06-30T20:12:07Z,sure. i fixed it with the follow code: [code block],0,0.9823552966117859
125121745,2929,lindong28,2017-06-30T20:13:47Z,previously i thought this is used for making partition state change. they are the same because previously all state change are triggered by controller request. i have changed the code to log it in the server.log.,0,0.9884657859802246
125123322,2929,lindong28,2017-06-30T20:23:17Z,"when `logcleaner` encounters ioexception when cleaning up the log, we want to mark the corresponding log directory as offline and inform controller of the log directory failure via zookeeper. note that this ioexception is not triggered by an external request and thus will not go through `replicamanager`. since we probably don't want to reference replicamanager via logmanager, `logmanager.handlelogdirfailure()` seems to be the only reasonable place to have this log of wrting to log directory notification znode. i couldn't find a better way to address this problem. do you have a better solution?",0,0.8792200088500977
125130310,2929,lindong28,2017-06-30T21:06:04Z,"another reason to put the logic of zookeeper notification in logmanger is that, currently logmanager is managing which logs are online or offline and thus is the source of truth of offline log directories. ideally we would like to put the logic of notification in the same place so that the notification is sent if and only if the offline log directories change.",0,0.9777916073799133
125136812,2929,lindong28,2017-06-30T21:52:18Z,"previously i think the chance of exception due to this race condition is so small (because disk failure should be rare) that we don't want to degrade performance by getting lock every time we read `livelogdirs`. for example, metrics reporting will access `abstractfetchermanager.fetcherthreadmap` and it seems fine so far. but strictly speaking, you are right that this can cause race condition and it is better to prevent this completely from any unknown consequence. so i made the following changes to address the problem: 1) use `_livelogdirs: arrayblockingqueue[file]` to record offline log directories. we don't have to worry about blocking operation because we will only remove log directory from it. i think this may be a little better than using `logcreationordeletionlock synchronized {}` every time we access `_livelogdirs` (e.g. `checkpointlogrecoveryoffsets()`, `checkpointlogstartoffsets` and metrics reporting) so that these access won't block `logmanager.createlog()` or `logmanager.asyncdelete()` 2) add `def livelogdirs: array[file] = _livelogdirs.asscala.toarray` so that we don't have to change test code to work with `arrayblockingqueue[file]`. 3) update various checkpoint() methods (e.g. `checkpointlogstartoffsetsindir(dir: file)`) so that they can handle the case that the directory in the input parameter gets removed from the checkpoint map right after the method begins.",0,0.9144428968429565
125137370,2929,junrao,2017-06-30T21:56:44Z,"we could probably pass in a onlogdirfailure callback to the logcleaner. an ioexception could be triggered in different places. however, independent of where it's triggered, we always want to react with the same process, which includes (marking the partition/replica as offline, remove partition from replicafetcher, notify the controller, etc). replicamanager seems to be the best place to consolidate that process.",0,0.986677885055542
125138864,2929,lindong28,2017-06-30T22:07:56Z,"previously i don't think it is needed because if user wants to know which specific log directories are offline in addition to the offline log directory count, it probably means they want to fix the problem and they will login the machine anyway. in this case they can find the offline log directory name in the log. and user probably wants to fix the problem because the log itself gets deleted from the cluster because they need to see the exception trace to debug the problem. yes, it can make debug easier to have this metric. i have updated the patch with the following code: [code block]",0,0.9557485580444336
125139125,2929,lindong28,2017-06-30T22:10:15Z,sure. good point. i have updated the code to only catch `ioexception`.,1,0.9625350832939148
125142699,2929,lindong28,2017-06-30T22:44:00Z,"are you suggesting that `logmanager.handlelogdirfailure()` should invoke `replicamanager.handlelogdirfailure()` and `replicamanager` should be put in the constructor of the `logmanager`? this can be done. but i am worried that this creates circular dependency between `logmanager` and `replicamanager` and can make future development harder. in addition to the worry with this java class dependency, i also find hard to organize the methods. for example, say the broker receives a `producerequest`, triggers `replicamanager.appendtolocallog()`, which in turn calls `partition.appendrecordstoleader()` and fails with `ioexception`. note that we haven't touched `logmanger` in this path and thus `logmanger.handlelogdirfailure()` won't be called. now that the replicamanager catches an ioexception, ideally it should have its own method `handlelogdirfailure()` to deal with it, e.g. remove the corresponding topcpartition from `replicamanager.allpartitions` and `logmanager.logs`. then it become pretty straightforward to have `replicamanager.handlelogdirfailure()` to call `logmanager.handlelogdirfailure()`. but then it seems weird for `logmanager.handlelogdirfailure()` to invoke `replicamanager.handlelogdirfailure()` even though we can use some trick to make it work. do you have a solution to this circular invocation? currently if the ioexception is triggered by user's request, both `replicamanager.handlelogdirfailure` and `logmanager.handlelogdirfailure()` will be called so this is ok. if ioexception is triggered by e.g. `logcleaner`, only `logmanager.handlelogdirfailure()` will be triggered and some partition will still stay in `replicamanager.allpartitions`. as of now i don't find this to be a problem. because the next time any producerequest or fetchrequest tries to access a partition on that offline log directory, replicamanager will handle the log directory failure. also, i have updated the code so that `replicamanager.checkpointhighwatermarks()` will trigger `replicamanager.handlelogdirfailure()` if any partition in `allpartitions` is on an offline log directory. thus the period of inconsistency will be limited. does this address your concern?",-1,0.9439060091972351
125142923,2929,lindong28,2017-06-30T22:46:16Z,yeah i have concern with having `logmanager` call `replicamanager.handlelogdirfailure()`. we can continue the discussion in the other comment.,0,0.8576093316078186
125144710,2929,lindong28,2017-06-30T23:06:01Z,"yeah this can be improved. i removed this if statement and replaced this log with `info(s""stopping serving logs in dir $dir"")`.",0,0.9773122072219849
125144734,2929,lindong28,2017-06-30T23:06:16Z,no. i have removed this log.,0,0.9798023104667664
125144776,2929,junrao,2017-06-30T23:06:51Z,": my suggestion is that nobody should directly call logmanager.handlelogdirfailure() except for replicamanager.handlelogdirfailure(). the latter knows how to bring all parts to a consistent state with respect to ioexception, no matter where it's introduced. so, if a method hits an ioexception through replicamanager, we will just the ioexception bubble up to replicamanager and call replicamanager.handlelogdirfailure() there. if the ioexception is isolated logcleaner, we can somehow pass replicamanager.handlelogdirfailure() to logcleaner and let logcleaner call it. this way, any time a disk error is detected, it will be handled consistently no matter in which component the error is detected, which seems easier to reason about.",0,0.9659551978111267
125145180,2929,lindong28,2017-06-30T23:12:21Z,"sure. i have replaced this line with `val offlinetopicpartitions = logs.filter { case (tp, log) => log.dir.getparent == dir}.map { case (tp, log) => tp}`",0,0.9822529554367065
125145259,2929,lindong28,2017-06-30T23:13:35Z,hmm.. i couldn't remember why this is added in the first place.. removed now.,0,0.6364273428916931
125148715,2929,lindong28,2017-07-01T00:05:01Z,i see. do you think it is ok to have a method `logmanger.setlogfailurecallback()` that will be called in `kafkaserver.startup()` after the `replicamanager` is constructed? if yes then i will do it. we can not get not pass this callback to the constructor of `logmanager` because `logmanager` is instantiated before the `replicamanager`.,0,0.9857089519500732
125149426,2929,lindong28,2017-07-01T00:19:47Z,sure. i added the following java doc: [code block],0,0.983314037322998
125149731,2929,lindong28,2017-07-01T00:27:04Z,ok. i have updated the code to remove this re-enqueue logic.,0,0.9843676686286926
125152135,2929,lindong28,2017-07-01T01:57:02Z,"we need this check to address the issue we have been discussing in the other threads, i.e. the partition may have been removed in `logmanager` but not in `replicamanager`. in this case, replicaid will be in the assignedreplicamap even though the replica is offline. this additional check will make sure that `getorcreatereplica()` will throw kafkastorageexception in this case. more specifically, here is the currently workflow if logcleaner encounters ioexception: - `logmanager.handlelogdirfailure()` will remove this log dir and partitions and inform controller via zookeeper. - controller sends leaderandisrrequest for all partitions on this broker - `partition.getorcreatereplica()` for partitions on the offline log directory will throw kafkastorageexception, which in turn triggers `replicamanager.handlelogdirfailure()` so that those partitions can be removed from `replicamanager` as well.",0,0.9849346876144409
125152284,2929,lindong28,2017-07-01T02:07:26Z,yeah i would like to invoke `replicamanager.handlelogdirfailure()` whenever there is ioexception. but this is not done yet because `logmanager` is not able to reference `replicamanager` since it is instantiated before the `replicamanager`. we can address this problem by doing `logmanager.setonlogdirfailurecallback()` after the replicamanage is instantiated. i find this to be a big ugly though. what do you think?,-1,0.9447824358940125
125152579,2929,lindong28,2017-07-01T02:25:56Z,"btw, here is the current workflow if `logmanger.handlelogdirfailure()` is called by `logcleaner`. - `logmanager.handlelogdirfailure()` will remove this log dir and partitions and inform controller via zookeeper. - controller sends leaderandisrrequest for all partitions on this broker - `partition.getorcreatereplica()` for partitions on the offline log directory will throw kafkastorageexception, which in turn triggers `replicamanager.handlelogdirfailure()` so that those partitions can be removed from `replicamanager` and the `replicafetchermanager`.",0,0.9835403561592102
125152647,2929,lindong28,2017-07-01T02:29:54Z,sure. i have updated the patch to catch ioexception here. previously i had a long discussion with and we think it is ok to handle ioexception that currently doesn't trigger `halt()` in a followup patch. the reasons are recorded in this pull request. that is why i didn't catch ioexception here.,0,0.9788022041320801
125153306,2929,lindong28,2017-07-01T03:12:25Z,"the line in 709 is there before this patch. that is no longer needed after kip-112. i kept it there to avoid changing the indention of that code block so that the code diff and the code review can be a bit simpler. i will remove that conversion after most all comments have been addressed. besides the motivation of avoid changing code indentation, the current patch only convert ioexception to kafkastorageexception if the method needs to handle that ioexception before throwing that again. i assume that we don't want to have try/catch around all java library to convert ioexception to kafkastorageexception for code simplicity. as a result our kafka method may potentially throw both ioexception and kafkastorageexception and that is why some code needs to catch both. regarding the consistency, are you suggesting that the code that currently catches only the `kafkastorageexception` should be updated to catch both `ioexception` and `kafkastorageexception` and treat them as `kafkastoragexception`?",0,0.9606518745422363
125153341,2929,lindong28,2017-07-01T03:15:02Z,good point. i didn't realize we had this method. i have updated the code as suggested.,1,0.8956188559532166
125153345,2929,lindong28,2017-07-01T03:15:33Z,thanks. fixed now.,1,0.8842014074325562
125153388,2929,lindong28,2017-07-01T03:18:58Z,ah i should have done this. thanks for noticing this. i have updated the patch with the following comment: [code block],1,0.9657706022262573
125153403,2929,lindong28,2017-07-01T03:20:24Z,my bad.. removed now.,-1,0.9875002503395081
125153742,2929,lindong28,2017-07-01T03:43:25Z,good catch! i missed the fact that this method is run in a scheduler. sure. i have updated the patch to call relicamanager.handlelogdirfailure() in `doloadgroupsandoffsets()` when there is `ioexception`. i also reverted the change that was made to update the `responsemap` when there is `ioexception`. becket had similar comment and asked me to do the same in `transactionstatemanager`. i didn't do that because i am not sure i know `transactionstatemanager` good enough to handle ioexception in the best way. this is an existing problem with `transactionstatemanager` and probably other modules in kafka as well because they don't explicitly handle the scenario when the disk write operation fails. can we focus on the ioexception that currently causes `halt()` and leave the handling of ioexeption that are currently ignored (e.g. in `transactionstatemanager`) in follow up patch?,1,0.9839161038398743
125153969,2929,lindong28,2017-07-01T03:57:57Z,"no, that logic is not added. there are two reason i didn't do that. one reason is to avoid circular invocation. currently `logcleaner.handlelogdirfailure()` and `logcleanermanager.handlelogdirfailure()` will invoke `logmanager.handlelogdirfailure()`. it seems a bit ugly if we let `logmanager.handlelogdirfailure()` invoke `logcleanermanager.handlelogdirfailure()`. ideally the invoke between methods is a directed acyclic graph. the other reason is that it is not necessary to explicitly remove dir from `logcleanermanager.checkpoints` as long as `logmanager.handlelogdirfailure()` has already removed all partitions on the offline dir from `logmanager.logs`. note that all read or write operation on `logcleanermanager.checkpoints` is triggered by the partition in that log directory, which in turn comes from `logmanager.logs`. thus if all partitions on a dir is removed from `logmanager.logs`, it is guaranteed that this `dir` will no longer be used as key to access `logcleanermanager.checkpoints`. does this address the problem?",0,0.6633557677268982
125154247,2929,lindong28,2017-07-01T04:22:13Z,good point. i have added the following methods in `logdirutils` and invoked this at the beginning of `oncontrollerfailover()`. [code block],1,0.9683729410171509
125369462,2929,lindong28,2017-07-04T00:07:26Z,i realized that there is one way to do this without using `logmanger.setlogfailurecallback ()`. we can provide `kafkaserver` to the constructor of `logmanager`. then `logmanager.handlelogdirfailure()` can call `kafkaserver.replicamanager.handlelogdirfailure()`. the disadvantage is that this exposes a log of things to `logmanger`. does this sound reasonable?,0,0.9653251767158508
125761540,2929,junrao,2017-07-05T21:25:42Z,it may not be efficient to do the exists check in every iteration of topicpartition since the exists check requires a scan of allpartitions. perhaps we could figure out the topics to be removed by first getting the uniqe topics from newofflinepartitions and then do the exists check on allpartitions?,0,0.9755427241325378
125762622,2929,junrao,2017-07-05T21:31:15Z,perhaps it's better to rename createlog to getorcreatelog?,0,0.9853712320327759
125773929,2929,junrao,2017-07-05T22:34:28Z,"hmm, currently, the java producer from 0.11.0.0 will treat this new exception as an unknown exception and won't retry. since we may add new error code that may be retriable in the future, perhaps we should make unknownserverexception a retriable error? if so, we probably want to do that in a separate patch and patch the 0.11.0 and probably the 0.10.2 branch as well.",0,0.984531581401825
125796722,2929,junrao,2017-07-06T01:52:09Z,": good point on the circular dependency on constructing those objects. another approach that i am thinking is to have a diskfailurechannel which contains an in-memory queue. diskfailurechannel can be passed into all components such as logmananger, logcleaner, replicamanager, etc where io errors can be generated. if an io error happens in a component, it just enqueues the disk name into the diskfailurechannel. we can have a separate thread (maybe in replicamanager) that reads from diskfailurechannel and acts on it (e.g., remove partitions in replicamanager, remove logs in logmanager, remove partitions from replica fetcher), etc. this way, all disk errors will be handled consistently. the only thing is that disk errors will be handled asynchronously. however, i am not sure if disk errors need to be processed synchronously.",1,0.9362514615058899
125804911,2929,lindong28,2017-07-06T03:30:34Z,"thanks for the suggestion! one concern with having this queue for disk failure events is that, in the event a log directory fails, every attempt to access any replica in that log directory will generate a disk failure event for the same log directory. a lot of events may be instantiated and put into this queue which wastes cpu and memory. i am also concerned that we can not bound the number of events generated for a single disk failure since we don't know when the os will schedule that thread to read event from this queue. maybe we don't need this `diskfailurechannel`. we can just schedule a thread in `replicamanager` to read from `logmanager.offlinelogdirs` and call `replicamanager.handlelogdirs(dir)` when there is new offline log dir. i understand that the goal of this alternative approach is to make sure that the state in `replicamanager` (e.g. `replicamanager.allpartitions`) is consistent with the state in `logmanager` (e.g. `logmanager.logs`). and i agree that we can achieve this goal by having an extra thread in `replicamanager`. but i am not sure that the benefit of this alternative approach is worth the extra thread. note that the disadvantages of the alternative approach is: 1) it requires an extra thread in `replicamanager` which makes kafka's java class a bit more complicated; and 2) the log failure event will be processed asynchronously which potentially delays the controller notification and leader election. and we can not bound the delay. can you help me understand why it is necessary to keep state in `replicamanager` and `logmanager` consistent all the time? the current approach in the patch guarantees eventual consistency, i.e. the `replicamanager.handlelogdirfailure()` will be called after controller notification is sent and the broker receives `leaderandisrrequest` from controller. it seems that nothing will go wrong during the period of inconsistency -- if anything goes wrong then we will have the same issue with the alternative approach. and the alternative approach makes state consistent by delaying the execution of `logmanager.handlelogdirfailure()`. i will implement the alternative approach using an extra thread if the consistency is more important than the extra complexity and the potential delay in log failure handling.",1,0.8797560930252075
125806173,2929,lindong28,2017-07-06T03:47:24Z,good point. i replaced this with the following code: [code block],1,0.9829362630844116
125806333,2929,lindong28,2017-07-06T03:49:38Z,sure. i have renamed this method as `getorcreatelog()`,0,0.9646236896514893
125807634,2929,lindong28,2017-07-06T04:07:01Z,now i understand the question. i am not sure we should make `unknownserverexception` a retriable error because i am a bit concerned with having unnecessary retry if we do that. i think we can keep the current practice by making an error retriable only if we know it should be retriable. is there any reason that we should make `unknownserverexception` retriable? i understand that `kafkastorageexception` was previously non-retriable because it is send to client as `unknownserverexception`. but i couldn't find anything wrong with making it retriable now. it also doesn't break any contract between client and server because client is now receiving a new error (i.e. kafkastorageerror) from client's perspective. is there any concern with this approach?,-1,0.6434950232505798
126026144,2929,junrao,2017-07-06T21:54:51Z,"the issue that i am thinking is the following. the 0.11.0 client jar doesn't have the error code for kafkastorageexception. if the 011.1 server sends a kafkastorageexception to the 0.11.0 client, the client will treat it as an unknownserverexception and won't retry. however, ideally, we want the 0.11.0 client to retry in this case.",0,0.9310770034790039
126036453,2929,junrao,2017-07-06T22:55:31Z,": my thoughts are the following. (1) when reacting to a disk failure, it would be useful to handle this in order, e.g., removing the partition from replicamanager, followed by removing the log from logmanager. if you only remove the log from logmanager w/o removing the partition from replicamanager, then a request may hit an unexpected exception when trying to access the log, which is not ideal. (2) the notification to zk could take a long time if zk is not performing. doing the zk notification in a background thread reduces the potential latency impact to the client request. (3) we may implement a more sophisticated disk failure detection module (e.g., proactively verifying crcs in the log) in the future. having a diskfailurechannel allows us to integrate such a module easier (such a module only needs to interact directly with diskfailurechannel, instead of replicamanager). i agree that adding a separate disk failure handling thread adds a bit complexity, but probably not too much. to avoid building up the queue, perhaps diskfailurechannel can just maintain a disk dir set instead of a queue.",0,0.8959550857543945
126036708,2929,lindong28,2017-07-06T22:57:26Z,"i see. this makes sense. one concern with making `unknownserverexception` a retriable exception is that client may retry unnecessarily. maybe we can reduce unnecessary retries by distinguishing between `unknownserverexception` and `unknownexception`. an exception is an `unknownexception` if the error code is not found defined, .e.g. 0.11.0 client receives the error code for `kafkastorageexception`. thus the client wouldn't have to retry if server sends the error code of the existing server unknown exception. and the client will only retry unnecessarily if its client's version is (temporarily) lower than server's version. does this sound ok? i can submit a separate patch for 0.11.0 and 0.10.2 branch.",0,0.98101407289505
126038803,2929,ijuma,2017-07-06T23:11:22Z,"the downside of any of the suggested approaches is that it won't help already released versions. another option would be to use an existing retriableexception when dealing with older clients. this would require bumping the relevant protocol versions though. going forward, it may make sense to define a `retriableunknownexception` that the broker can use to force older clients to retry.",0,0.9175612926483154
126090944,2929,lindong28,2017-07-07T08:08:48Z,"i agree with your points. thanks so much for the detailed explanation. i have updated the patch to include `logdirfailurechannel` and an extra thread in `replicamanager`. the `logmanager.handlelogdirfailure()` will only be called by `replicamanager.handlelogdirfailure()`, which in turn will only be called by that thread. and the offline log dir name will be put into `logdirfailurechannel` if there is new offline dir. the new thread will block waiting for new offline log dir. i have also updated the patch to revert changes such as the zkutils in the logmanager constructor. i have reviewed the changes and the entire patches myself before uploading it. i think all comments have been addressed. can you take another look at the patch? thanks much for your time!",1,0.9699103236198425
126091184,2929,lindong28,2017-07-07T08:10:28Z,i have updated the patch so that `logmanager.handlelogdirfailure()` will be called only by `replicamanager.handlelogdirfailure()`,0,0.9878588318824768
126091442,2929,lindong28,2017-07-07T08:12:13Z,i have updated the patch so that the partitions will be removed from the replica fetcher if truncation fails.,0,0.9874629974365234
126092808,2929,lindong28,2017-07-07T08:20:06Z,thanks for the suggestion. yes we can also name that new exception as `retriableunknownexception`. and `errors.forcode(code)` will return `retriableunknownexception` if the code is larger than maximum code of the defined error on the client side. my previous idea is to name the new exception as either `unknownexception` which will be retriable. the advantage is that the error will be more explicit about that it is -- a code that is not found in the client's library. the advantage of your solution is that we can re-use the new exception for any retriable exception. does this sound good to you?,1,0.9258471727371216
126236649,2929,junrao,2017-07-07T20:19:46Z,"hmm, if we bump up the protocol, wouldn't we have the same problem on the old client using the old protocol? i.e, if the broker hits a kafkastorageexception serving a request from the old client, we have to convert kafkastorageexception to sth that the old client can recognize.",0,0.9832445383071899
126243848,2929,lindong28,2017-07-07T20:57:01Z,"i guess i didn't understand ismael's suggestion w.r.t. the protocol version.. in my opinion, the long term approach is to have a new retriable exception, named as either `unknownexception` or `retriableunknownexception` such that an known error code will be translated to this exception on the client side. one short term solution we can do in this patch is to transform kafkastorageexception to the error code of notleaderforpartitionexception in produceresponse and fetchresopnse. this is hacky. but it should address this problem without causing any additional concern since producer/consumer shouldn't really care whether this is kafkastorageexception as long as it is retriable. what do you think of this short term solution?",-1,0.9724490642547607
126252343,2929,ijuma,2017-07-07T21:48:02Z,"yes, my suggestion was to bump the protocol so that we reuse an existing retriable exception for the old version and `kafkastorageexception` for the new version. and `retriableunknownexception` would be a way to avoid this hack in the future, but it doesn't help now.",0,0.7532904744148254
126256742,2929,lindong28,2017-07-07T22:18:36Z,"thanks much. this makes sense. i have updated the patch to include `unknownretriableexception`, bumped up the version of producerequest and fetchrequest, and converted kafkastorageexception to the error code of notleaderforpartitionexception for existing versions of produceresponse and fetchresponse.",1,0.9817891716957092
126448908,2929,junrao,2017-07-10T15:06:52Z,"hmm, this thread is interruptible. could we just make takenextlogfailureevent() block infinitely?",0,0.9864458441734314
126462482,2929,junrao,2017-07-10T15:51:34Z,"this is going to affect how the replicafetchthread works. before this patch, if the replicafetchthread hits an ioexception during truncate, the affected replica will remain in the truncating state and the truncation will be retried. with the patch, since the ioexception is not propagated back to replicafetchthread, the replicafetchthread just assumes that the truncation has succeeded and moves onto the next stage. we want to preserve the original behavior.",0,0.9791657328605652
127005161,2929,lindong28,2017-07-12T16:30:58Z,this line can be removed. it probably becomes redundant after a rebase.,0,0.9739325642585754
127013042,2929,lindong28,2017-07-12T17:04:42Z,change java doc to the following ``` get the next offline log dir from logdirfailureevent queue. block waiting for up to the specified amount of time if there is no new offline log dir. ``,0,0.9860556125640869
127014976,2929,lindong28,2017-07-12T17:13:00Z,this can be removed now since we have `logdirfailurechannel`.,0,0.9890608787536621
127038150,2929,lindong28,2017-07-12T18:41:58Z,"never mind. this is still needed. if there is offline log dir, `getorcreatepartition()` will create the partition object before `getorcreatereplica()` fails with exception. in this case we need this code to remove the partition which doesn't have a valid local replica.",0,0.9611747860908508
127068479,2929,junrao,2017-07-12T20:51:59Z,could we adjust the above comment to reflect initialofflinedirs?,0,0.9885326623916626
127068824,2929,junrao,2017-07-12T20:53:23Z,this probably should be named islogdirectoroffline?,0,0.9895890951156616
127072655,2929,junrao,2017-07-12T21:09:18Z,_livelogdirs could change after the size check in line 77. should we tighten this up?,0,0.9883538484573364
127074402,2929,junrao,2017-07-12T21:17:20Z,should we swallow ioexception from the destroy() call?,0,0.9802395701408386
127075492,2929,junrao,2017-07-12T21:21:59Z,while load => while loading? ditto in line 292.,0,0.9405996203422546
127077430,2929,junrao,2017-07-12T21:30:38Z,should we call logdirfailurechannel.maybeaddlogfailureevent() on initialofflinedirs? we call logdirfailurechannel.maybeaddlogfailureevent() on log dirs that fail during loading.,0,0.9894006848335266
127078294,2929,junrao,2017-07-12T21:34:25Z,could we log the failed dir too?,0,0.9854669570922852
127078328,2929,junrao,2017-07-12T21:34:34Z,could we log the failed dir too?,0,0.9854669570922852
127084663,2929,junrao,2017-07-12T22:05:32Z,could we log the failed disk dir too?,0,0.9865627884864807
127084683,2929,junrao,2017-07-12T22:05:39Z,could we log the failed disk dir too?,0,0.9865627884864807
127236631,2929,junrao,2017-07-13T14:42:27Z,"should we add ""either""?",0,0.9796105623245239
127238635,2929,junrao,2017-07-13T14:49:02Z,"hmm, it doesn't seems that partition.deleterecordsonleader() can throw kafkastorageexception. it can throw ioexception though.",0,0.9772591590881348
127242028,2929,junrao,2017-07-13T15:00:27Z,perhaps it's simpler to just handle kafkastorageexception here instead of in line 579.,0,0.9825661182403564
127242867,2929,junrao,2017-07-13T15:03:26Z,perhaps it's simpler to just handle kafkastorageexception/ioexception here instead of in line 765?,0,0.9855048060417175
127247023,2929,junrao,2017-07-13T15:17:18Z,"hmm, shouldn't we pass in the isnew flag to the getorcreatereplica() call in line 182 too?",0,0.9765350818634033
127262313,2929,junrao,2017-07-13T16:15:26Z,"once a partition is removed from allpartitions, future produce/fetch request will get an unknowntopicpartitionexception, ideally, it seems that they should get a kafkastorageexception for consistency?",0,0.9882558584213257
127267996,2929,junrao,2017-07-13T16:37:56Z,could we adjust the message a bit so that unknown_retriable can be distinguished from unknown? it would also be useful to add a comment on how it should be used differently from unknown.,0,0.9888446927070618
127268535,2929,junrao,2017-07-13T16:40:18Z,"hmm, i thought the plan is for uncaught exceptions still be unknown (i.e., not retriable), but if the server throws a new exception that's retriable, the server will send unknown_retriable to old clients.",0,0.9840407371520996
127270473,2929,junrao,2017-07-13T16:49:09Z,could we add some comment that describe the flow of how disk failure is handled here?,0,0.9871009588241577
127276896,2929,lindong28,2017-07-13T17:16:22Z,"i think it is probably not necessary to call this on initialofflinedirs. the purpose of calling `maybeaddlogfailureevent()` is to cleanup state (e.g. logmanager.logs) and notifying controller. for initialofflinedirs, the no state will be created for replicas in these offline log directories. and the broker hasn't registered itself in the zookeeper yet and thus controller will query this broker for state of all replicas afterwards -- thus no need to notify controller either. on the other hand, if any log directory fails during loading, it is possible that states have been created for some logs that directory but not others. in this case we need to call `maybeaddlogfailureevent()` to clean up the state.",0,0.9807253479957581
127280905,2929,lindong28,2017-07-13T17:32:33Z,"i think it is probably ok to keep the current code. it is true that a log failure may happen right after the check in line 77. in this case the the caller may try to access that log directory that just became offline. however, there is no way to prevent this from happening since it is always possible for a log directory to become offline immediately before (or while) the caller tries to access it. thus caller code always needs to handle the possibility that log directory was removed from the state (e.g. `logmanager.recoverypointcheckpoints`). currently the only regular callers of `livelogdirs()` are those checkpoint routines. the code has handled with e.g. `this.recoverypointcheckpoints.get(dir).foreach(...)` to avoid nullpointerexception. does this make sense?",0,0.9815285205841064
127281494,2929,lindong28,2017-07-13T17:35:08Z,"initially i think it may be more concise to re-use the existing metric name with the additional tag. sure, i will replace this with `islogdirectoroffline`.",0,0.9853171706199646
127282168,2929,lindong28,2017-07-13T17:37:54Z,sorry. it is bad that i forgot to update comment. i have updated it to `create and check validity of the given directories that are not in the given offline directories...` i will go over the patch and see if there are other comments that i should update.,-1,0.9901788234710693
127282599,2929,lindong28,2017-07-13T17:39:43Z,good point. i have updated the code as suggested.,1,0.9575342535972595
127283147,2929,lindong28,2017-07-13T17:41:39Z,thanks. i have fixed the typo now.,1,0.908117949962616
127284560,2929,lindong28,2017-07-13T17:47:02Z,sure. i have also updated the corresponding comments in all checkpoint*() methods.,0,0.9775453805923462
127284651,2929,lindong28,2017-07-13T17:47:25Z,sure. fixed now.,0,0.9448716044425964
127284798,2929,lindong28,2017-07-13T17:48:01Z,sure. fixed now.,0,0.9448716044425964
127286069,2929,lindong28,2017-07-13T17:53:00Z,sure. fixed now.,0,0.9448716044425964
127289016,2929,lindong28,2017-07-13T18:04:32Z,i think this is ok. `isnew` flag is only matters for local replica. and the local replica of the leader broker must be in the insync replicas set and it will be created properly in line 173. maybe i can add a comment here. or do you like me to refactor the code a bit to call this method with the isnew flag?,0,0.9678675532341003
127291275,2929,lindong28,2017-07-13T18:14:03Z,yes that is the plan and it is actually implemented here. note that `errors.forexception(throwable t)` will return `errors.unknown` if the given exception is not listed in `errors.java`. and `errors.forcode(short code)` will return `errors.unknown_retriable` is the error code is out of the range of existing error codes listed in `errors.java`. our server code is not expected to call `errors.forcode(short code)` with a not-listed error code. the client may call `errors.forcode(short code)` with a not-listed error code if the client library version is smaller than the server library version and the server library has a new error code. in this case we want `errors.forcode(short code)` to return a retriable exception so that producer can re-send the message after metadata update. does this make sense?,0,0.9826847910881042
127294705,2929,lindong28,2017-07-13T18:27:30Z,sorry for the typo. it is removed now.,-1,0.9868552088737488
127300635,2929,lindong28,2017-07-13T18:50:23Z,yes you are right. previously i made a mistake that made me think that `arrayblockingqueue.take()` doesn't unblock after interruption. i have updated this to block infinitely.,0,0.9628081917762756
127301936,2929,lindong28,2017-07-13T18:55:37Z,good catch! you are right. i have updated the code to call `maybeaddlogfailureevent` and return kafkastorageexception if it is ioexception. i also updated the code not to catch kafkastorageexception.,1,0.9928126931190491
127305273,2929,lindong28,2017-07-13T19:08:56Z,sure. i have updated the patch as suggested.,0,0.9691935777664185
127307745,2929,lindong28,2017-07-13T19:20:02Z,sure. i have updated the code as suggested.,0,0.9742094874382019
127361245,2929,lindong28,2017-07-14T00:11:31Z,removed now.,0,0.9490092396736145
127361297,2929,lindong28,2017-07-14T00:12:02Z,fixed now.,0,0.9813029170036316
127376539,2929,lindong28,2017-07-14T03:02:30Z,"sure. i have renamed the variable `unknown` to `unknown_server_error` to distinguish it from `unknown_retriable`. i think it is reasonable because the corresponding exception is `unknownserverexception`. if we want to further differentiate the two, we also rename `unknown_retriable` to be `unknown_client_retriable` and rename `unknownretriableexception` to `unknownclientretriableexception`. what do you think? and i added the following comment for `unknown_retriable`. does that look ok? [code block]",0,0.9340898394584656
127377150,2929,lindong28,2017-07-14T03:10:28Z,sure i added the following comment. does this look ok? [code block],0,0.9828752279281616
127380697,2929,lindong28,2017-07-14T03:56:50Z,"good point. i have updated both the `logmanager.truncateto()` and `logmanager.truncatefullyandstartat()` so that these two method will call `maybeaddlogfailureevent()` and throw a kafkastorageexception if ioexception is caught. this preserves the previous behavior. based on your previous comments, i get that it is a bit ugly in when and where we should catch ioexception or kafkastorageexception. it is also not nice to have code that needs to decide whether we should throw the original kafkastoragexception or encapsulate the original ioexception into a kafkastorageexception. after thinking through this issue, i made the following changes to make the logic cleaner - `logdirfailurechannel` is now passed to the constructor of `log` and `logsegment` so that they can enqueue offline log dir when there is ioexception. - the patch guarantees if `maybeaddlogfailureevent()` is called before a new kafkastorageexception object is instantiated (except for very few scenarios where we know it is not needed). thus we do not need to call `maybeaddlogfailureevent()` when kafkastorageexception is caught. - we only need to call `maybeaddlogfailureevent()` when ioexception is caught. when ioexception is caught, we can either log the error and swallow the exception, or we can throw a new instance of kafkastorageexception so that the outside code can catch it and generate the proper error in the response.",1,0.6845084428787231
127380827,2929,lindong28,2017-07-14T03:58:34Z,actually i find it better to name the new error as unknownerrorcode. i will use it in the updated patch. i also moved the comment to `unknownerrorcodeexception.java`. do you think this name is better?,0,0.9839600920677185
127381549,2929,lindong28,2017-07-14T04:06:25Z,i still keep the code to catch `kafkastorageexception` since it may be useful if the underlying code re-throws kafkastorageexception in the future. it is a safe choice. but we no longer needs to call `maybeaddlogfailureevent` when kafkastorageexception is caught for the reasons explained in the other comment.,0,0.9377779960632324
127410791,2929,lindong28,2017-07-14T08:36:25Z,initially i thought it is ok and simpler to just return `unknowntopicpartitionexception` since the client only cares whether it needs to retry or not. but you are right that it is better and consistent to always return kafkastorageexception if client attempts to access a replica that is on an offline log directory. i have updated the patch with considerable change to achieve this consistency.,0,0.9182182550430298
127411380,2929,lindong28,2017-07-14T08:40:01Z,i added this comment to line 182: `we don't need to specify isnew flag since the local replica would have been created already`,0,0.9758930802345276
127600194,2929,lindong28,2017-07-16T06:53:27Z,"after more thought, i think it simpler to just specify the isnew flag so that future developer doesn't need to think about it. i have updated the patch to do so.",0,0.9782686829566956
127772691,2929,junrao,2017-07-17T17:37:25Z,"for code like this, perhaps it's useful to add a comment since it's easy to forget about the original reason over time.",0,0.9656476378440857
127794464,2929,junrao,2017-07-17T18:58:46Z,"hmm, now i am wondering if adding unknown_error_code is really a good idea. by adding this, the broker has to consider 3 different types of clients when adding a new retriable error: (1) clients that don't understand unknown_error_code; (2) clients that understand unknown_error_code, but don't understand the new specific error code (e.g., kafka_storage_error); (3) clients that understand the new specific error code. the broker has to send different error codes for those three different cases (1) send an existing retriable error (2) send unknown_error_code; (3) send the specific error code. we have to do this for each type of request that can receive the new error code. an alternative is the following. we don't introduce unknown_error_code. if the broker introduces a new retriable error, we bump up the request protocol. the broker (a) sends an existing retriable error for clients that don't understand the new specific error code; (b) sends the new specific error code otherwise. this seems simpler.",0,0.7604748606681824
127807824,2929,junrao,2017-07-17T19:53:39Z,"if would be useful to double check which requests other than produce/fetch can receive and care about kafka_storage_error. it seems that offsetcommit, offsetforleaderepoch, listoffsets and deleterecords could receive this. not sure if they all care about it though. a few new requests for eos could probably also hit this, which can be addressed in s a separate patch.",0,0.9790557026863098
127811509,2929,junrao,2017-07-17T20:09:05Z,islogdirectoroffline => islogdirectoryoffline,0,0.9805113673210144
127814413,2929,junrao,2017-07-17T20:21:06Z,islogdirectoroffline => islogdirectoryoffline,0,0.9805113673210144
127827127,2929,junrao,2017-07-17T21:12:09Z,the comment seems outdated now.,-1,0.5682222247123718
127837300,2929,junrao,2017-07-17T21:59:10Z,"hmm, not sure what the convention is now in handling ioexception at the log/logmanager level. we could (1) turn all ioexception in log to kafkastorageexception and call logdirfailurechannel.maybeaddlogfailureevent(). then, in replicamanager, we don't need to deal with ioexception. (2) let the ioexception for log to bubble to replicamanager and call logdirfailurechannel.maybeaddlogfailureevent() in replicamanager. it seems that the patch does a mix of both (1) and (2). in logmanager.getorcreatelog(), it seems it's possible for an ioexception to be thrown. in log, we are turning all ioexceptions to kafkastorageexception. it seems that it's better to pick either (1) or (2) and do it consistently in all places?",0,0.9568531513214111
127838104,2929,junrao,2017-07-17T22:03:17Z,"hmm, could we get ioexception here? i thought now the convention is to catch all ioexception in the log level and convert it to kafkastorageexception?",0,0.9853442311286926
127842977,2929,junrao,2017-07-17T22:32:36Z,perhaps it's better to use eq (reference equality).,0,0.9813344478607178
127845994,2929,junrao,2017-07-17T22:49:50Z,this seems to break the convention of not calling maybeaddlogfailureevent on kafkastorageexception?,0,0.9028472900390625
127846644,2929,junrao,2017-07-17T22:53:47Z,"hmm, the callers of getlogendoffset() don't seem to expect an exception.",0,0.9083588123321533
127849554,2929,junrao,2017-07-17T23:13:16Z,we don't need to mention producerequest here since it's not an inter broker request.,0,0.9866266846656799
127850607,2929,junrao,2017-07-17T23:20:51Z,should we do this on any ioexception?,0,0.9862229228019714
127858289,2929,junrao,2017-07-18T00:21:57Z,"the comment seems inaccurate. we are sending all replicas, not just live replicas in the leaderandisrrequest.",-1,0.5179159045219421
127864124,2929,junrao,2017-07-18T01:19:49Z,it would be useful to replace leaderandisrpartitionstate and metadatapartitionstate with partitionstate and updatemetadatarequest.partitionstate. this can be done in a followup cleaning patch.,0,0.9861475825309753
127864321,2929,junrao,2017-07-18T01:22:09Z,unused import timeunit,0,0.9832204580307007
127864547,2929,junrao,2017-07-18T01:24:18Z,"unused imports seq, set.",0,0.9851974844932556
127864941,2929,junrao,2017-07-18T01:28:24Z,it seems that we should check if the notification is of logdirfailureevent in logdireventnotification.process()?,0,0.9898355603218079
127865003,2929,junrao,2017-07-18T01:29:10Z,unused import,0,0.9649426341056824
127865578,2929,junrao,2017-07-18T01:34:27Z,using a null replicamanager to represent an offline partition seems a bit hacky. could we just add a new offline flag in the constructor?,-1,0.959392786026001
127865966,2929,junrao,2017-07-18T01:38:40Z,could we add a comment that leader_and_isr_response_v1 can receive the new kafkastorage error code?,0,0.9873805046081543
127866463,2929,junrao,2017-07-18T01:44:15Z,check whether is offline log directory => check whether there is offline log directory ?,0,0.9870759844779968
127867135,2929,junrao,2017-07-18T01:52:02Z,"hmm, a couple of thoughts on this. if the broker is still on an old inter-broker protocol, the controller won't be able to handle the failed disk dir event. so, the broker will be up with offline replicas, but new leaders can't be elected. perhaps it's better to just failed the broker in the old way if the inter-broker protocol is old? related to this, i am wondering if it's useful to add a config to turn off this new feature. this way, if there is a bug, the user has the option to switch to the old behavior.",0,0.8454403281211853
127867830,2929,junrao,2017-07-18T01:59:15Z,"in the following line in line 65, shouldn't we set the desired version to 4 if magic is on v2? super(apikeys.produce, (short) (magic == recordbatch.magic_value_v2 ? 3 : 2));",0,0.985481858253479
127885491,2929,lindong28,2017-07-18T05:32:18Z,"thanks much for the quick review! i think the current approach is probably simpler. the broker only needs to know 2 types of the clients instead of three, i.e. one that knows unknownerrorcodeexception and one that doesn't. if the request of the client suggests that the client knows unknownerrorcodeexception, then the broker will simply send the origin error code. the client library will convert the error to unknownerrorcodeexception if the error code is not recognized. otherwise, the broker should convert the new error code to an existing error code before sending the response. note that we need at most one `if/else` in each response to check whether the client knows unknownerrorcodeexception given the request version. on the other hand, the alternative approach requires kafka to potentially have multiple `if/else` in each response to check whether the clients know each newly-added error code. the number of check will increase overtime as we add more and more new error code. thus the current approach seems simpler. what do you think?",1,0.9779128432273865
127885621,2929,lindong28,2017-07-18T05:33:53Z,ah.. fixed now.,0,0.9628986120223999
127885629,2929,lindong28,2017-07-18T05:34:00Z,fixed now.,0,0.9813029170036316
127886423,2929,lindong28,2017-07-18T05:41:53Z,sure. i added this comment: [code block],0,0.9816249012947083
127889378,2929,lindong28,2017-07-18T06:11:39Z,"yeah had similar comment as well but i find that the patch in its current form is simpler. this is because not all exceptions bubble to the replicamanager. for example, both replicafetchthread and logclean may attempt to truncate the log which doesn't go through replicamanager. and we may have more ioexeption from new methods in the future. thus (2) alone wouldn't work. alternatively we can do (1) only, e.g. find all operations that may cause ioexception, catch/call logdirfailurechannel.maybeaddlogfailureevent() and re-throw a kafkastorageexception. my concern with this approach is that we will need to identify all possible calls that may throw ioexception and make sure that ioexception does not bubble up to replicamanager because otherwise we will return unknownserverexception in the response. this is doable but it requires carefully review of the code which may be error-prone both now and in the future development. on the other hand, if we can catch ioexception in the replicamanager where we generate the error code for various response, we can ensure that if any request handling incurs ioexception, we will trigger `maybeaddlogfailureevent` and return the proper error code. thus the current mixed approach seems simpler and more reliable than the approach (1). does this explanation sound reasonable? while i understand that consistency is a good feature, is there specific benefits of doing (1) only?",0,0.9648915529251099
127890064,2929,lindong28,2017-07-18T06:17:58Z,good point. i fixed all of them.,1,0.9640233516693115
127890791,2929,lindong28,2017-07-18T06:24:33Z,"no.. currently i didn't catch/try ioexception for methods like log.append(), logsegment.append() or offsetindex.append(). i feel that kafka' code will be cleaner and more reliable if we can catch ioexception in the methods which handle request and generate response. the only reason not all ioexception are caught in replicamanager or kafkaapi is that we have checkpoint file operation, replicafetcherthread or logcleaner which does io operation without requiring external request.",0,0.8688575625419617
127891075,2929,lindong28,2017-07-18T06:27:02Z,i see. i replaced the comment with this: `mark partition as offline in the cache if the local replica creation has failed due to offline log directory`,0,0.9872653484344482
127891341,2929,lindong28,2017-07-18T06:29:21Z,this is just for code simplicity of not having to duplicate the code of logging error and populating the response map. do you want me to separate them?,0,0.9856770038604736
127892176,2929,lindong28,2017-07-18T06:36:30Z,i think the behavior of throwing the exception is the same as returning none for `groupmetadatamanager`. i am not sure very what is the right behavior for `transactionstatemanager` if the corresponding partition is in offline log directory. previously i think it is reasonable to throw kafkastorageexception if the partition is offline. but i am not strong on this. i have changed it to return none instead.,-1,0.8586651682853699
127892430,2929,lindong28,2017-07-18T06:38:32Z,"thanks. i see. i have removed producerequest, fetchrequest and metadatarequest from this comment.",1,0.9712344408035278
127894263,2929,lindong28,2017-07-18T06:51:19Z,"i have thought about catching ioexception here. after reading [a link] i am still not sure why we previously didn't halt the kafka on any ioexception here. there are also some ioexception that are explicitly thrown in this class that do not trigger halt. i couldn't find a reason not to catch ioexception either. i choose to be conservative by preserving the behavior by not doing this on all ioexception just in case we have a reason not to do so. would you like me to do this on any ioexception? alternatively, maybe we can discuss the handling of these specific ioexception in a followup patch?",-1,0.5529541969299316
127894415,2929,lindong28,2017-07-18T06:52:19Z,good point. you are right. i removed the `live` here.,1,0.9418905377388
127894505,2929,lindong28,2017-07-18T06:52:58Z,thanks!! i will do it in a followup patch.,1,0.9888635873794556
127894624,2929,lindong28,2017-07-18T06:53:46Z,ah it somehow escaped from my reviews.. removed now.,0,0.9324252009391785
127894717,2929,lindong28,2017-07-18T06:54:26Z,my bad.. removed now.,-1,0.9875002503395081
127896162,2929,lindong28,2017-07-18T07:05:01Z,initially i think it is ok not to check it since there is only one type. it is similar to how we currently have a version field in the reassignment json file provided to `kafka-reassign-partitions.sh` but we currently don't check that version either. but it is also reasonable to check it. i have updated the code to throw illegalargumentexception is the event type value is not 1.,0,0.9754973649978638
127896355,2929,lindong28,2017-07-18T07:06:23Z,not sure why i missed these.. removed now.,-1,0.8508586883544922
127897210,2929,lindong28,2017-07-18T07:12:18Z,"initially i wanted to avoid adding complexity to the constructor. sure, i have added isoffline flag to the constructor.",0,0.9787742495536804
127897438,2929,lindong28,2017-07-18T07:13:34Z,sure. i added this: `leaderandisrresponse v1 may receive kafka_storage_error in the response`,0,0.9840811491012573
127897524,2929,lindong28,2017-07-18T07:14:08Z,thanks for catching this. fixed now.,1,0.8820233345031738
127898698,2929,lindong28,2017-07-18T07:21:48Z,"as long as the controller and the broker is running new code, the controller will be able to handle the failed disk dir event even if the inter-broker protocol is still old. more specifically, if there is log directory failure, the broker will write a sequential znode in zookeeper, the controller will send leaderandisrrequest, broker will specify error in the response, and the controller will trigger leader election. none of these steps require new inter-broker protocol. does this make sense? i am not sure we should add a config just to take care of the potential bug. ideally we don't want to add a config just for short-term use. the typical way of handling bug is to either hotfix the code or rollback to the last stable version. any kip or big code change may potentially have bug and it seems a big weird to add a config to handle the bug. adding this config is easy since all we need is to tell logdirfailurehandler to halt the broker when there is log directory failure. do you think it is necessary?",0,0.9360975623130798
127899953,2929,lindong28,2017-07-18T07:28:56Z,"no. this is the only improvement in my mind that i haven't made in this patch. i mentioned this in a comment after my last commit yesterday. as of this patch, producer will still send producerequest with version 3 if the message magic value is 2. this is because the newly-added produce version 4 is incompatible with 0.11 broker. as of now our producer determines the request version based on the minimum magic value in the data instead of using the apiversionsrequest to negotiate the this with the broker. this wasn't a problem in the latest kafka but this is causing problem for patches like kip-112 which wants to bump up producrequest version without bumping up the magic value. i don't think this is a critical problem for kip-112 since notleaderforpartitionexception in the response is a reasonable workaround. can i fix this issue in a followup patch later?",0,0.6558451056480408
127902927,2929,lindong28,2017-07-18T07:44:43Z,sure. i will go over all existing request and see if they need to handle kafkastorageexception specifically.,0,0.9733061194419861
127912013,2929,lindong28,2017-07-18T08:28:42Z,"another way i look at this is that, regardless of what the underlying code does, the outside code, i.e. those methods that determines the response, should catch all exception and determine the error in the response properly. this is similar to why we currently catch `throwable`. it is just that, instead of catching ioexception (as part of the throwable) and return unknownserverexception, it seems more reasonable to call `maybeaddlogdirfailure()` and return kafkastorageexception on ioexception.",0,0.9805593490600586
128041151,2929,junrao,2017-07-18T17:26:57Z,": ok, what you said about the approach in the patch makes sense. i was just wondering if we can achieve the same w/o introducing unknownerrorcode. the alternative that i suggested also just needs 1 if/else check. basically, you bump up the client request protocol, if the client is on the old protocol, the broker sends an existing retriable error code. otherwise, the broker sends the new specific error code. so, the logic is about the same as your patch, but we don't need to introduce unknown_error_code. this seems a bit simpler since we don't have to explain to the client developers the subtle difference btw unknown_error_code and unknown.",0,0.9041129946708679
128042260,2929,junrao,2017-07-18T17:30:51Z,": we don't necessarily have to go purely with (1) or (2). however, it would be useful to have a convention that we can follow in the future. could you summarize that convention? i seems that you are saying that all ioexception for client facing requests (but not inter broker requests) will be turned to kafkastorageexception in the log level?",0,0.9683360457420349
128042285,2929,junrao,2017-07-18T17:30:58Z,"hmm, we do convert ioexception to kafkastroageexception in log.append(), right?",0,0.9873712062835693
128042324,2929,junrao,2017-07-18T17:31:05Z,"fetchrequest is used by inter broker replication. so, we need to include it.",0,0.989191472530365
128042447,2929,junrao,2017-07-18T17:31:35Z,"in the future, we may need to add new event type. then, when upgrading a broker, the controller may see a new event type that it doesn't understand yet. so, it would be useful for the logic in the controller to be resilient to that.",0,0.9705302119255066
128042652,2929,junrao,2017-07-18T17:32:21Z,"is that true? in controllerchannlemanager, if the inter broker protocol is before 0.11.1, the controller will send v0 of leaderandisrrequest and the response won't have kafkastorageerror, which means that the controller won't be able to move failed replicas to offline?",0,0.9881239533424377
128044355,2929,lindong28,2017-07-18T17:38:37Z,"for offsetcommitrequest, i have updated the patch so that server will send `errors.not_coordinator` in the response if there is kafka_storage_error. this is similar to how broker currently converts not_leader_for_partition to not_coordinator when handling offsetcommitrequest. no change on the client side is needed. for offsetforleaderepoch, the server will send kafka_storage_error and the replica fetcher thread will retry if there is error -- it doesn't care which error it is. thus no change is needed. for listoffsets, the server will send kafka_storage_error and the client will convert this error to stalemetadataexception which extends invalidmetadataexception. thus no change is needed.",0,0.9511978626251221
128045320,2929,lindong28,2017-07-18T17:42:24Z,oops.. i added it back.,-1,0.9726998209953308
128048615,2929,lindong28,2017-07-18T17:54:31Z,"hmm.. not sure if i fully understand the alternative approach. let say we introduced two new retriable errors a and b for produceresponse in the future. a is added in version 5 and b is added in version 6. if we have unknown_error_code, then the response handling logic would look like this: [code block] on the other hand, if we don't have unknown_error_code, then the response handling logic would look like this, which increases over time as we have more and more new errors. [code block] thus it seems that unknown_error_code can make things a bit easier. does this make sense?",0,0.6140012145042419
128049363,2929,lindong28,2017-07-18T17:57:19Z,"right, this makes sense.",0,0.9588476419448853
128050930,2929,lindong28,2017-07-18T18:03:02Z,"i still think it is true.. in this case, controller will send leaderandisrrequest v0 which doesn't explicitly specify the isnew flag. the broker will assume isnew = false when it attempts to create the local replica. and if there is log directory fail, then broker either dies (if it is running the old code) or the broker will specify kafkastorageexception in the response (if it is running the new code). then the controller can move failed replicas offline. this works because leaderandisrresponse v0 already allows broker to specify per-partition error code. does this make sense?",0,0.9762582182884216
128057016,2929,lindong28,2017-07-18T18:26:44Z,my bad... i missed this. i have removed this ioexception handling here.,-1,0.988020122051239
128064844,2929,junrao,2017-07-18T18:58:50Z,got it. this is assuming that the new error code is a retriable error. how would the logic compare if the new error code is not retriable?,0,0.9812658429145813
128067682,2929,junrao,2017-07-18T19:08:02Z,"got it. i forgot that we don't convert the error code in leaderandisrresponse. then the issue is mostly when you have a mix of brokers with old and new code. if the controller happens to be on the broker with the old code, it wouldn't react to disk failure events until the controller is upgraded. in a larger cluster, rolling upgrade could take some time and leaving the offline replicas unprocessed for long is probably not ideal. if we only apply the new logic when the inter.broker protocol is 0.11.1, then the above issue can be addressed since at that point, we expect every broker to be on the new code. a minor related issue is that the offlinereplicas won't be propagated properly until the controller's inter broker protocol is on 0.11.1. this will affect the metadata response. not sure if we can avoid this completely. it would be useful to at least document this.",0,0.9379473328590393
128076192,2929,lindong28,2017-07-18T19:45:28Z,"if the new error is not retriable, then the client will convert the unknown error code to unknownserverexception which is non-retriable. i think it is a reasonable solution before the client library is upgraded.",0,0.9839835166931152
128076999,2929,lindong28,2017-07-18T19:48:56Z,both are good points. i will update the logdirfailurehandler so that it will halt the broker if the inter broker protocol is before 0.11.1.,1,0.9368199110031128
128078560,2929,lindong28,2017-07-18T19:55:33Z,"my previous convention is that: 1) ioexception should maybeaddlogdirfailureevent. 2) ioexception should either be logged or be re-thrown as kafkastorageexception. 3) kafkastorageexception should not trigger maybeaddlogdirfailureevent. previously i feel it is simpler to catch ioexception in the replicamanager similar to how we handle most other exceptions that happen during request processing. and i intend to avoid adding big try/catch because it typically makes code review harder. now i agree with you that it is a good idea to keep it consistent and try to catch ioexception before the replicamanager. i have updated the patch so that the replicamanger no longer needs to catch ioexception at all. ioexception is now caught in e.g. log, logmanager and checkpointfile. these ioexception will trigger maybeaddlogdirfailureevent() and be re-thrown as kafkstorageexception. i think this address the issue here.",0,0.8922940492630005
128079255,2929,lindong28,2017-07-18T19:58:32Z,i have updated the code so that replicamanager no longer needs to catch ioexception at all including here.,0,0.9867282509803772
128082294,2929,lindong28,2017-07-18T20:12:18Z,"i don't know why we don't halt the server on ioexception when reading or writing the checkpoint file. anyway, i have updated the patch to catch ioexception when reading/writing the checkpoint file, call maybeaddlogdirfailureevent(), and re-throw a kafkastorageexception. thus this issue is also addressed.",0,0.9655423760414124
128097699,2929,lindong28,2017-07-18T21:14:51Z,"ah, i probably misunderstood your previous question. if the new error code is non-retriable and client library already knows unknownerrorcodeexception, then the client library will treat the new error as a retraible error. it means that client may retry unnecessarily instead of failing fast. i think this is ok and better than having client failing immediately when it should retry.",0,0.8359299302101135
128097968,2929,junrao,2017-07-18T21:15:58Z,"hmm, if a new error is not retriable, the server code will probably look like the following. [code block] so, you don't really save code if the new error is not retriable. another thing that bothers me a bit is that the logic for handling a retriable error is a bit different from that for handing a non-retriable error. in the alternative approach, at least any new error code is handled in the same way.",-1,0.7102999091148376
128106111,2929,lindong28,2017-07-18T21:53:32Z,"my use-case for unknownerrorcodeexception is based on the assumption that it is always ok for client to retry. the client should always have a reasonable timeout setting if it retries. thus if the original error is non-retriable, the client will block unnecessarily up to that timeout which is not that bad. also, for requests that don't want to retry on unknown error code, we can always update its response handling logic to skip retry if error == unknownerrorcodeexception. does this sound reasonable? if not, then i think we will have to add specific if/else for potentially a few requests for every new error in the future. i can remove the unknownerrorcodeexception if you prefer not to make the decision in this patch.",0,0.9586430788040161
128109393,2929,junrao,2017-07-18T22:10:42Z,the issue with retrying on any unknown error is that an app (e.g. mirrormaker) could set the retry to infinite and then it won't be aware of the error. adding a new if/else statement for every new error code is not necessary bad as long as the process is clear. adding unknownerrorcodeexception seems more complicated to me at this moment. perhaps we could remove it and reconsider it later if there is a need.,-1,0.5147109627723694
128110294,2929,junrao,2017-07-18T22:14:52Z,"thanks. discussed this a bit with jason. it seems that we probably need to extend the current desired version logic to support the possibility of having multiple versions on the same magic (perhaps having a desired version range). so, we can do this in a followup jira. if you ping jason on that jira, he can help you with some suggestions.",1,0.8593738079071045
128133249,2929,lindong28,2017-07-19T01:13:44Z,"sure! after this pull request is closed, i will create tickets for all the todos mentioned in the discussion of this pull request. i will ping you and json for review later.",1,0.747158408164978
128133400,2929,lindong28,2017-07-19T01:15:19Z,sure. i have removed the unknownerrorcodeexception in the latest patch.,0,0.9845138192176819
128367026,2929,junrao,2017-07-19T21:05:50Z,"islogdirectoryoffline => logdirectoryoffline ? the latter seems more consistent with underreplicated in partition. if we change the name, make sure that we change it consistently in the place where the metric is removed as well.",0,0.9881667494773865
128371038,2929,junrao,2017-07-19T21:22:57Z,should we catch ioexception in fetchoffsetsbytimestamp() in line 1041 too?,0,0.9898239970207214
128376413,2929,junrao,2017-07-19T21:47:24Z,since all accesses to logsegment are through log/logcleaner/logmanager/logcleanermanager. perhaps we can just catch ioexceptions in those places instead of here?,0,0.988884449005127
128390730,2929,junrao,2017-07-19T23:09:30Z,cleanup => clean up,0,0.9769148826599121
128396923,2929,junrao,2017-07-19T23:55:28Z,use exit.halt() to be consistent with what's in replicamanager?,0,0.981597900390625
128397663,2929,junrao,2017-07-20T00:01:48Z,do we still need to call maybeaddlogfailureevent() on kafkastorageexception?,0,0.9876450896263123
128397699,2929,junrao,2017-07-20T00:02:13Z,do we still need to call maybeaddlogfailureevent() on kafkastorageexception?,0,0.9876450896263123
128399202,2929,junrao,2017-07-20T00:14:21Z,could we add some comment at the beginning of the class on the process of adding a new server side exception going forward?,0,0.9871025681495667
128400026,2929,junrao,2017-07-20T00:21:10Z,ioexception is unused now.,0,0.9699864983558655
128401597,2929,junrao,2017-07-20T00:35:49Z,unused import,0,0.9649426341056824
128404639,2929,junrao,2017-07-20T01:01:30Z,poll(0) => poll(10) to prevent busy loop?,0,0.9842584133148193
128404788,2929,junrao,2017-07-20T01:02:40Z,poll(0) => poll(10) to prevent busy loop?,0,0.9842584133148193
128542365,2929,junrao,2017-07-20T15:06:26Z,the comment seems inaccurate now.,-1,0.8209484219551086
128542947,2929,junrao,2017-07-20T15:08:22Z,could we just set the file to be unreadable and unwritable?,0,0.9062389135360718
128543296,2929,junrao,2017-07-20T15:09:22Z,should we assert the consumer sees at least 2 messages?,0,0.9848671555519104
128544125,2929,junrao,2017-07-20T15:12:14Z,"perhaps it's also useful to assert that logdireventnotificationpath is empty eventually. it may also be useful to verify the replica state for that replica in the controller is in offline state,",0,0.987865149974823
128548154,2929,junrao,2017-07-20T15:25:34Z,perhaps it's better to use kafkaconfig.logdirsprop,0,0.986275315284729
128550482,2929,junrao,2017-07-20T15:33:47Z,"to make this more robust, perhaps we need to disable the periodic metadata fresh in the producer?",0,0.9844205975532532
128551469,2929,junrao,2017-07-20T15:37:33Z,is sudo really needed?,0,0.9858812093734741
128552122,2929,junrao,2017-07-20T15:39:46Z,"this is for isr, not leader replica.",0,0.9862357974052429
128552194,2929,junrao,2017-07-20T15:40:00Z,leader => isr,0,0.9785259962081909
128559280,2929,junrao,2017-07-20T16:04:02Z,"""leader node"" doesn't cover the case when broker_type is follower.",0,0.9839009642601013
128559453,2929,junrao,2017-07-20T16:04:45Z,is sudo needed?,0,0.9867337942123413
128560468,2929,junrao,2017-07-20T16:08:41Z,is the test from line 161 to 174 necessary? it doesn't seem to be directly related to offline disks.,0,0.9826634526252747
128560625,2929,junrao,2017-07-20T16:09:19Z,topic2 actually has min.isr of 1.,0,0.9885421991348267
128561993,2929,junrao,2017-07-20T16:14:33Z,why is time-based log rolling needed here?,0,0.9641432166099548
128582900,2929,lindong28,2017-07-20T17:38:37Z,yeah.. i also prefer `logdirectoryoffline`. i changed it to `islogdirectoryoffline` because i didn't have a good reason not to use `islogdirectoryoffline` when asked previously. i have updated the patch to use `logdirectoryoffline`.,0,0.8892132043838501
128583248,2929,lindong28,2017-07-20T17:40:11Z,good catch. it is fixed now.,1,0.9838176965713501
128632191,2929,lindong28,2017-07-20T21:12:23Z,"you are right. i missed this.. i should have gone over all methods in log.scala. i just went over all the methods in log.java and made sure the following rule is satisfied for any method in this class: 1) if the method is used during log load phase, which should only happen before the broker registers itself in the zookeeper, this method doesn't have to convert ioexception to kafkastorageexception. 2) otherwise, if the method in incurs i/o operation and may be called by other classes after broker has registered itself (excluding shutdown()), this method should catch ioexception, add it to log dir failure channel, and re-throw kafkastorageexception 3) otherwise, the method either doesn't throw ioexception, or it is only called by internal methods in log that belong to one of the two above categories, we don't need to catch ioexception in this method. i still keep an unnecessary conversion from ioexception to kafkastorageexception in `log.roll()`. it is unnecessary because it is currently only called by methods in log.scala that will catch ioexception. i still keep it there since it is a public method and may be used in the future. it is a bit tedious to go over all method and make sure ioexception is caught `iff` it is needed. so i choose to lean towards over-catch it in log.scala. i can remove it if needed. i also added the comment `we don't convert ioexception to kafkastorageexception in this method because this method may be called before all logs are loaded` to some methods in log.scala so that future develop can be aware of this.",0,0.5354536771774292
128634615,2929,lindong28,2017-07-20T21:24:12Z,good point. i have updated the code to the following with an extra comment. i think we don't have to catch ioexception for logging purpose here because the ioexception should specify the file name and be caught and logged by the caller. [code block],1,0.9619194269180298
128634780,2929,lindong28,2017-07-20T21:25:03Z,thanks for catching this. it is fixed now.,1,0.8939259052276611
128634986,2929,lindong28,2017-07-20T21:26:03Z,clearly i didn't review the patch careful enough.. sorry. it is fixed.,-1,0.9880594611167908
128635061,2929,lindong28,2017-07-20T21:26:24Z,i should have noticed this.. it is fixed now.,0,0.9184694290161133
128639223,2929,lindong28,2017-07-20T21:48:19Z,good point. i added the following comment: [code block] i also added the following comment in `kafkastorageexception.java`: [code block],1,0.9829357862472534
128639576,2929,lindong28,2017-07-20T21:50:21Z,ah.. i just realized that i can not rely on intellij to show the unused import in gray color. it is fixed now.,0,0.9649757742881775
128639643,2929,lindong28,2017-07-20T21:50:52Z,it is fixed now... i need to be more careful.,0,0.49111491441726685
128640385,2929,lindong28,2017-07-20T21:54:56Z,i missed this. it is fixed now.,-1,0.9130837321281433
128644708,2929,lindong28,2017-07-20T22:20:45Z,"i just tested it by setting the file to be unwritable. the testproduceafterlogdirfailure() with pass. however, `kafkaservertestharness.teardown()` will fail with `java.nio.file.accessdeniedexception` because it is not able to delete the log directory. it is possible to swallow the exception so that the test will pass. but that the temporary log directory will not be removed after the test and will accumulate over time on the test server. according to the information provided below, it seems that the log directory can only be removed with sudo access if it is set to be unwritable. thus it seems simpler to just use the current approach by replacing the log directory with a file. [code block]",0,0.9646815061569214
128644975,2929,lindong28,2017-07-20T22:22:24Z,i think it is not necessary to use poll(10). `waituntiltrue()` will sleep for 100 ms before trying to poll() again.,0,0.9859409928321838
128646300,2929,lindong28,2017-07-20T22:31:01Z,"are you suggesting to set `retry.backoff.ms` to long_max when we create the producer? i am not sure we should do that because we need metadata to be refresh after producer sees kafkastorageexceptoin in the produceresponse, so that we can verify that producer can produce message after leadership is moved by controller. actually i intentionally set the `retry.backoff.ms` to 100 ms so that the producer can refresh the metadata almost immediately after it sees kafkastorageexception in the response. `metadata.max.age.ms` is 5 minutes by default which should be longer than the time needed for this test. thus it seems that the test is already robust since producer should not automatically refresh metadata unless it sees exception in the produceresposne. does it sound reasonable?",0,0.9361351728439331
128652090,2929,lindong28,2017-07-20T23:11:14Z,i don't think we should.. the first message sent by the first produce has already been consumed by the first call of `poll()`. this is the second call of `poll()` and it is possible to consume only one message.,0,0.9707604646682739
128652222,2929,lindong28,2017-07-20T23:12:32Z,it is probably not necessary because `waituntiltrue()` will sleep for 100 ms before trying to poll() again.,0,0.9793446660041809
128654104,2929,lindong28,2017-07-20T23:26:38Z,good point. i have updated the test to assert both requirements.,1,0.9662632942199707
128654285,2929,lindong28,2017-07-20T23:28:06Z,good point. i have updated the patch to use `kafkaconfig.logdirsprop`.,1,0.9700741767883301
128654830,2929,lindong28,2017-07-20T23:32:08Z,my bad. i have fixed this.,-1,0.9865919947624207
128654940,2929,lindong28,2017-07-20T23:33:03Z,thanks. it is fixed now.,1,0.8963304758071899
128655255,2929,lindong28,2017-07-20T23:36:10Z,"is this because after the broker has opened the file handler for a log segment, it can continue read/write to the log segment even after the log directory is removed or marked as unreadable. i set the log rolling to 3 sec so that the broker will need to create new log segment every 3 seconds. then the server will be able to discover log directory failure when it attempts to create file for a new log segment.",0,0.9874699115753174
128655516,2929,lindong28,2017-07-20T23:38:25Z,"thanks. i added a line that says ""and another topic with partitions=3, replication-factor=3, and min.insync.replicas=1""",1,0.9342740178108215
128655798,2929,lindong28,2017-07-20T23:40:34Z,my bad.. i have updated it to say `broker %d should be in isr set`,-1,0.9890907406806946
128656024,2929,lindong28,2017-07-20T23:42:30Z,i think it may be useful. this is needed to verify that the broker can still server replicas on the good disks even if it has bad disks.,0,0.9523335099220276
128659071,2929,junrao,2017-07-21T00:08:19Z,i was referring to metadata.max.age.ms. we can leave it as it is since metadata.max.age.ms is 5 minutes by default.,0,0.9858413934707642
128659130,2929,junrao,2017-07-21T00:08:49Z,could we add a comment for that?,0,0.985282301902771
128661501,2929,lindong28,2017-07-21T00:32:22Z,"in particular, i made the following code changes: 1) catch ioexception in log.fetchoffsetsbytimestamp() 2) catch ioexception in log.deletesegments() 3) catch ioexception in log.flush() 4) catch ioexception in log.delete() 5) catch ioexception in log.truncateto() 6) catch ioexception in log.truncatefullyandstartat() 7) catch ioexception in log.asyncdeletesegment() 8) removed ioexception catch code in logmanager.truncateto() 9) removed ioexception catch code in logmanager.truncatefullyandstartat() 10) removed ioexception catch code in logmanager.deletelogs() 11) removed ioexception catch code in logsegment.changefilesuffixes() 12) removed ioexception catch code in logsegment.delete()",0,0.9773259162902832
128676856,2929,lindong28,2017-07-21T03:21:13Z,yes.. i think it is needed. below is the error if this command is executed without sudo. [code block] i also tried to execute the command with and without sudo by logging into the vagrant node. here is what i found: [code block],0,0.9823333621025085
128677507,2929,lindong28,2017-07-21T03:29:19Z,ah... i realized that i can work without `sudo`. the `chmod a-rw /mnt/kafka-data-logs-1/ -r` can actually change the permission of this log directory. but it still returned error probably because this command attempts to read information of this log directory after it takes effect. i am able to avoid sudo by replacing the command with `chmod a-w /mnt/kafka-data-logs-2/ -r`.,0,0.9261465072631836
128678929,2929,lindong28,2017-07-21T03:48:41Z,sure. i added the following comment: [code block],0,0.983934223651886
128679135,2929,lindong28,2017-07-21T03:51:24Z,yes. the sudo is needed in order to delete an unwritable log directory.,0,0.9873623847961426
128679816,2929,lindong28,2017-07-21T04:01:28Z,never mind.. i originally used `offlinelogdirectorycount` instead of the `logdirectoryoffline`. thanks for the suggestion!,1,0.9825313687324524
128680876,2929,lindong28,2017-07-21T04:16:46Z,i updated the code to use `kafkaconfig.logdirsprop` only if the dir count > 1. this is because some tests such as offsetcommittest.scala assumes that there is only one log directory and the will fetch the log directory based on `log.dir`. it seems simpler to keep these tests and only update the `testutils.createbrokerconfig()` to fill in the property based on the directory number. [code block],0,0.9813786745071411
128804228,2929,junrao,2017-07-21T16:26:51Z,"could we just use the existing def replicasinstate(topic: string, state: replicastate)?",0,0.9889172315597534
128805708,2929,junrao,2017-07-21T16:34:35Z,"this method is actually called in places after log loading. but in all other places, ioexceptions are handled by the callers. perhaps we can adjust the comment a bit.",0,0.988778829574585
128806377,2929,junrao,2017-07-21T16:37:50Z,"ditto as the above since it can be called after loading. also, we should change ?",0,0.9790998101234436
128806610,2929,junrao,2017-07-21T16:39:12Z,ditto as the above since it can be called after loading.,0,0.9849694967269897
128807592,2929,junrao,2017-07-21T16:44:48Z,it seems that logdirfailurechannel can be removed now.,0,0.9891782999038696
128818124,2929,lindong28,2017-07-21T17:36:06Z,i missed this. thanks for catching this. it is fixed now.,1,0.9659655690193176
128818202,2929,lindong28,2017-07-21T17:36:29Z,sure. i have removed this method.,0,0.9765081405639648
128818227,2929,lindong28,2017-07-21T17:36:36Z,it is fixed now.,0,0.9826627969741821
128818243,2929,lindong28,2017-07-21T17:36:41Z,sure. it is fixed now.,0,0.9471368193626404
128818272,2929,lindong28,2017-07-21T17:36:46Z,it is fixed now.,0,0.9826627969741821
128828324,2929,becketqin,2017-07-21T18:19:52Z,we also added producerequest v4.,0,0.9862990975379944
128828858,2929,lindong28,2017-07-21T18:22:05Z,remove logdirfailurechannel from cleaner.,0,0.9753410816192627
128833298,2929,becketqin,2017-07-21T18:40:41Z,"not sure if this is in kip-113, but we should probably also consider assigning the partitions based on the actual logdir size instead/in addition to the number of partitions. we can have a follow up patch for this.",0,0.9884589314460754
128850166,2929,becketqin,2017-07-21T20:04:24Z,nit: onreplicabecomeoffline -> onreplicasbecomeoffline,0,0.9832247495651245
128850247,2929,becketqin,2017-07-21T20:04:43Z,effected -> affected,0,0.9764100313186646
128851186,2929,lindong28,2017-07-21T20:10:01Z,i will add code to catch and handle ioexception in `locklogdirs()`,0,0.9890340566635132
128887429,2929,becketqin,2017-07-22T02:49:22Z,there are a lot of similar try/catch logic in this class. maybe we can group them into a lambda like we did for inlock.,0,0.9782789349555969
128889008,2929,becketqin,2017-07-22T04:30:34Z,"in groupcoordinator and txncoordinator, we load the state using filerecords.readinto() and if ioexception occurs, currently we log it and let it go. i am not sure if this has been discussed before, but should we notify controller to reelect leader in this case? it does not have to be in this patch. we can do it separately. let's see what say.",0,0.9814870357513428
128889452,2929,becketqin,2017-07-22T04:50:50Z,can we add a comment explaining the logic here? i was confused first time see this logic.,0,0.6396346688270569
128889819,2929,lindong28,2017-07-22T05:17:13Z,i am not sure whether we should add comment regarding the producerequest. said earlier that we only need to add comments regarding requested used between brokers. i guess we can do this in the other followup patch if needed.,0,0.9151332378387451
128889832,2929,lindong28,2017-07-22T05:18:33Z,yeah i think it is useful. it is probably better to do it in kip-113 so that we can finish this kip sooner :),1,0.9826252460479736
128889837,2929,lindong28,2017-07-22T05:18:53Z,thanks! fixed now.,1,0.9553532004356384
128889858,2929,lindong28,2017-07-22T05:19:33Z,sure. fixed now.,0,0.9448716044425964
128889862,2929,lindong28,2017-07-22T05:19:48Z,good point. it is fixed now.,1,0.9754536747932434
128889977,2929,lindong28,2017-07-22T05:27:59Z,"i think both groupcoordinator and txncoordinator will access log directory via methods in log, e.g. `log.read` in `groupmetadatamanager.loadgroupsandoffsets()`. thus ioexception will be caught and trigger `maybeaddlogfailureevent()`. i think this handling of ioexception is good enough for `groupcoordinator`. if this handling of ioexception is not good enough for `txncoordinator`, it is probably an existing problem and needs feedback from the developers who are more knowledgeable in transaction related logic. yeah let's do it in a followup patch if any fix is need for `txncoordinator`.",0,0.9641367793083191
128889980,2929,lindong28,2017-07-22T05:28:20Z,fixed now.,0,0.9813029170036316
128890112,2929,lindong28,2017-07-22T05:36:58Z,sure. i have updated the comment to clarify this better.,0,0.9446524381637573
128903577,2929,becketqin,2017-07-22T19:37:47Z,would it be better to put this method into coreutils?,0,0.9845059514045715
128903738,2929,lindong28,2017-07-22T19:45:05Z,i have thought about this. we can do it if we add another 1-2 parameters to this method. this is because both the object `logdirfailurechannel` and `dir` in the body of `maybehandleioexception` belong to `log`. thus the `maybehandleioexception()` in its current form can not be static. it seems to me that the code is simpler by putting it only in log. we can move it to coreutils with the extra parameter if you think that is better.,0,0.9691183567047119
452397898,9001,kowshik,2020-07-09T18:05:44Z,add doc,0,0.9847440123558044
452397966,9001,kowshik,2020-07-09T18:05:50Z,add doc,0,0.9847440123558044
452398154,9001,kowshik,2020-07-09T18:06:14Z,add doc,0,0.9847440123558044
452398464,9001,kowshik,2020-07-09T18:06:49Z,remove word 'should',0,0.966428816318512
452399744,9001,kowshik,2020-07-09T18:09:17Z,add doc to entire class,0,0.9871420860290527
452400240,9001,kowshik,2020-07-09T18:10:10Z,add doc to entire class,0,0.9871420860290527
452400376,9001,kowshik,2020-07-09T18:10:27Z,attributes can be final,0,0.9863112568855286
452401987,9001,kowshik,2020-07-09T18:13:20Z,1. add test code in `kafkaadminclienttest` 2. final variable names,0,0.9877404570579529
452402127,9001,kowshik,2020-07-09T18:13:36Z,add test code in `kafkaadminclienttest`,0,0.9884390234947205
452403561,9001,kowshik,2020-07-09T18:16:13Z,1 line gap before `cal`,0,0.9833148717880249
452406393,9001,kowshik,2020-07-09T18:21:18Z,eliminate and use invalid_request,0,0.9784972667694092
452406721,9001,kowshik,2020-07-09T18:21:49Z,eliminate and use invalid_request,0,0.9784972667694092
452407219,9001,kowshik,2020-07-09T18:22:42Z,"space between "","" and ""key""",0,0.9868975877761841
452407255,9001,kowshik,2020-07-09T18:22:46Z,final,0,0.9030922651290894
452407329,9001,kowshik,2020-07-09T18:22:56Z,final,0,0.9030922651290894
452408614,9001,kowshik,2020-07-09T18:25:15Z,make variables final throught class add doc,0,0.9875427484512329
452410015,9001,kowshik,2020-07-09T18:27:45Z,fix apikeys,0,0.989072859287262
452410620,9001,kowshik,2020-07-09T18:28:54Z,eliminate timeout?,0,0.9799001812934875
452413347,9001,kowshik,2020-07-09T18:34:02Z,add doc and explain various cases,0,0.9838988184928894
452413777,9001,kowshik,2020-07-09T18:34:54Z,call the variable as `nodecontents` ?,0,0.9881773591041565
452418487,9001,kowshik,2020-07-09T18:44:00Z,perhaps add info about newfeatures and incompatiblebrokers.,0,0.9838528633117676
452418679,9001,kowshik,2020-07-09T18:44:24Z,can improve by splitting into few lines,0,0.9820911288261414
452426595,9001,kowshik,2020-07-09T18:59:05Z,check braces (),0,0.9866676330566406
452428079,9001,kowshik,2020-07-09T19:01:44Z,s/supported/supportedfeatures same for other one,0,0.9868603348731995
452428293,9001,kowshik,2020-07-09T19:02:07Z,"say ""if there are any feature incompatibilities found.""",0,0.9841234087944031
452428858,9001,kowshik,2020-07-09T19:03:22Z,add unit test add doc,0,0.984289824962616
452432658,9001,kowshik,2020-07-09T19:10:56Z,shouldn't the code be waiting here?,0,0.9799382090568542
452435772,9001,kowshik,2020-07-09T19:16:57Z,add doc,0,0.9847440123558044
452435913,9001,kowshik,2020-07-09T19:17:15Z,remove these 2 lines,0,0.9781961441040039
452436233,9001,kowshik,2020-07-09T19:17:41Z,revert the file eventually,0,0.9661405682563782
453842949,9001,abbccdda,2020-07-13T18:21:40Z,nit: get a ` { updatefinalizedfeaturesresult}` as well,0,0.9887006878852844
456123467,9001,abbccdda,2020-07-16T22:57:10Z,s/`as input a set of finalizedfeatureupdate`/`in a set of feature updates`,0,0.9871349930763245
456124708,9001,abbccdda,2020-07-16T23:00:50Z,"for the entire sentence, i assume you want to say something like [code block]",0,0.9792309999465942
456125212,9001,abbccdda,2020-07-16T23:02:31Z,"looking at `updatefinalizedfeaturesresult`, we don't have a per feature based error code returned. if this is the case, how could we know which feature is missing?",0,0.9852697253227234
456126450,9001,abbccdda,2020-07-16T23:06:05Z,"we should suggest in what circumstances a user may require sending the request directly to the controller, to me if there is a case where user wants stronger consistency.",0,0.984674334526062
456150664,9001,abbccdda,2020-07-17T00:25:56Z,we should consider using optional for `finalizedfeaturesepoch` to indicate absence.,0,0.9882870316505432
456151287,9001,abbccdda,2020-07-17T00:27:57Z,"nit: one parameter each line, with the first parameter on the same line as constructor name.",0,0.9891110062599182
456151476,9001,abbccdda,2020-07-17T00:28:41Z,nit: seems not necessary,0,0.8962063789367676
456151635,9001,abbccdda,2020-07-17T00:29:16Z,`false otherwise` doesn't provide too much useful info.,0,0.6488075256347656
456603010,9001,abbccdda,2020-07-17T18:20:41Z,nit: we could just `return new updatefinalizedfeaturesrequestdata().setfinalizedfeatureupdates(items)`,0,0.9886665344238281
456849186,9001,abbccdda,2020-07-19T02:19:21Z,missing header,0,0.8798423409461975
456855815,9001,abbccdda,2020-07-19T04:00:54Z,nit: put first parameter on this line.,0,0.9880579710006714
456855941,9001,abbccdda,2020-07-19T04:02:52Z,"the definition seems not aligned with the kip which states `updatefeatures`, do you think it's necessary to mention `finalized` in all the function signatures?",0,0.9882531762123108
456857080,9001,abbccdda,2020-07-19T04:19:26Z,"it looks weird to complete `callvialeastloadednode` in a controller response handler. i'm inclined to increase a bit on the code duplication, based on `if (options.sendrequesttocontroller())` to have two separate request traces like: [code block] and try to complete the same future.",-1,0.985190212726593
456857730,9001,abbccdda,2020-07-19T04:29:50Z,"would be good to redundantly copy over the expected error codes from `admin.java` definition, similar to other response class such as `offsetcommitresponse`",0,0.9788490533828735
456858439,9001,abbccdda,2020-07-19T04:39:21Z,seems not necessary to have this helper as it doesn't reduce the code length.,0,0.9283280372619629
456858741,9001,abbccdda,2020-07-19T04:42:42Z,space,0,0.968176543712616
456859001,9001,abbccdda,2020-07-19T04:45:45Z,"this is a bit unique, since we should commonly rely on the error code to propagate information instead of a message which has unbounded size. could you explain why we couldn't simply re-invent a new error code if existing ones are not sufficient?",0,0.9034448862075806
456859342,9001,abbccdda,2020-07-19T04:50:52Z,"we don't need to include the same error information twice, as the client side will recognize anyway.",0,0.9856311082839966
456859761,9001,abbccdda,2020-07-19T04:56:54Z,access should be private,0,0.9820906519889832
456859864,9001,abbccdda,2020-07-19T04:58:05Z,nit: the comment seems unnecessary on l3011,0,0.9403390884399414
456859960,9001,abbccdda,2020-07-19T04:58:51Z,"commonly in scala we try to avoid using return, consider using `if-else` instead.",0,0.9818203449249268
456860187,9001,abbccdda,2020-07-19T05:01:31Z,`setting the allowdowngrade flag to true in the request`,0,0.9865325689315796
456862645,9001,abbccdda,2020-07-19T05:31:43Z,`apikeys.update_finalized_features api`,0,0.9858400821685791
456862745,9001,abbccdda,2020-07-19T05:33:11Z,we only need to mark testing only comment on the functions,0,0.9862231612205505
456863153,9001,abbccdda,2020-07-19T05:38:15Z,nit: mark the parameter as `logincompatibilities = true)`,0,0.974777102470398
456863287,9001,abbccdda,2020-07-19T05:39:58Z,redundant {},0,0.9722983241081238
456863554,9001,abbccdda,2020-07-19T05:42:50Z,redundant {},0,0.9722983241081238
456863914,9001,abbccdda,2020-07-19T05:48:12Z,do we need this precision of exact wait time? could we just track the function start time and compare with current system time for expiration?,0,0.9871951937675476
456931477,9001,abbccdda,2020-07-19T17:03:30Z,"`for a new kafka cluster (i.e. it is deployed first time), we would like to start the cluster with all the possible supported features finalized immediately.` i think this comment is hard to understand if reader has zero context on the feature versioning. it would be good to include a short explanation on what does a `supported feature` mean, and what it means to be `finalized`. `the new cluster will almost never be started with an old ibp config that’s less than kafka_2_7_iv0.` this sentence is positioned awkwardly. i would suggest we just propose `as a new cluster starting with ibp setting equal to or greater than kafka_2_7_iv0`",0,0.7600720524787903
456931559,9001,abbccdda,2020-07-19T17:04:23Z,"`then here is how we it` could be removed: `assuming this is the case, then the controller...`",0,0.968542218208313
456932817,9001,abbccdda,2020-07-19T17:17:40Z,"maybe a newbie question here: since the `supportedfeatures` could be mutated, why couldn't we just assume its min level marks the `defaultfeatureminversionlevels`? trying to understand the necessity for secondary bookkeeping. might be good to also put reasonings in the meta comment as well to clear confusion.",0,0.9521321654319763
456934831,9001,abbccdda,2020-07-19T17:38:27Z,"if this is broker required feature set, i feel we could name it something like `brokerrequiredversionrange`. `updated` sounds a bit blur for reader, as it couldn't infer the subject.",0,0.8940129280090332
456935073,9001,abbccdda,2020-07-19T17:40:37Z,what about the case where `existingversionrange.min() > updatedversionrange.max()` is true? for example: [code block] are we enabling version 3 as well?,0,0.989280641078949
457072387,9001,abbccdda,2020-07-20T05:46:02Z,"is it ok for us to always do `updatefeatureznode`, since this call is idempotent?",0,0.987894594669342
457075484,9001,abbccdda,2020-07-20T05:52:11Z,could the receiving broker analyze the request and decide to shut down itself? what's the gain we have by avoiding sending update metadata to incompatible brokers?,0,0.974090039730072
457076040,9001,abbccdda,2020-07-20T05:53:19Z,replace with `nonempty`,0,0.9733775854110718
457076787,9001,abbccdda,2020-07-20T05:54:49Z,"could we avoid blocking controller processing here, by putting the callback into a delayed queue or sth?",0,0.9840672016143799
457077246,9001,abbccdda,2020-07-20T05:55:46Z,`incompatiblefeatures`?,0,0.9778943061828613
457077954,9001,abbccdda,2020-07-20T05:57:18Z,"nit: i have seen that we use both `map{` and `map {`, could we try using only one format consistently within the current file?",0,0.987834095954895
457802220,9001,kowshik,2020-07-21T02:40:49Z,done. updated the doc now.,0,0.9799467921257019
457806176,9001,kowshik,2020-07-21T02:56:06Z,done.,0,0.9759407639503479
457806399,9001,kowshik,2020-07-21T02:57:00Z,done.,0,0.9759407639503479
457806541,9001,kowshik,2020-07-21T02:57:43Z,"to your point, this information is available in the error message returned in the response. the feature updates are atomically applied to zk by the controller i.e it is all or none. we don't have a use case (yet) where we have to programmatically learn which feature updates are incorrect. instead an error message with details seems sufficient to us. please let me know how you feel about it, and if you feel that we are better off in returning per-feature-update error code. this was discussed in the [a link], search for the word ""transaction"".",0,0.9668521881103516
457808548,9001,kowshik,2020-07-21T03:06:14Z,done.,0,0.9759407639503479
457809543,9001,kowshik,2020-07-21T03:10:05Z,done.,0,0.9759407639503479
457812340,9001,kowshik,2020-07-21T03:19:53Z,done. good point.,1,0.9535248279571533
457812690,9001,kowshik,2020-07-21T03:21:00Z,done.,0,0.9759407639503479
457812867,9001,kowshik,2020-07-21T03:21:44Z,done. removed.,0,0.9766796827316284
457813021,9001,kowshik,2020-07-21T03:22:17Z,done. removed.,0,0.9766796827316284
457813152,9001,kowshik,2020-07-21T03:22:53Z,done. good point.,1,0.9535248279571533
457815251,9001,kowshik,2020-07-21T03:32:07Z,done. good point.,1,0.9535248279571533
457821195,9001,kowshik,2020-07-21T03:56:30Z,it calls into couple other helper functions. let us keep it.,0,0.9782619476318359
457821791,9001,kowshik,2020-07-21T03:58:56Z,done.,0,0.9759407639503479
457821925,9001,kowshik,2020-07-21T03:59:25Z,done.,0,0.9759407639503479
457823139,9001,kowshik,2020-07-21T04:04:34Z,"the purpose of the error message is to sometimes describe with finer details on what is the error (such as which feature update is incorrect). to your point, it seems there are existing response types that do allow for an error message, examples are: `createtopicsresponse`, `createpartitionsresponse`, `deleteaclsresponse` etc. there is ongoing related discussion under another pr review comment and we can continue the discussion there: [a link] .",0,0.9793941378593445
457872699,9001,kowshik,2020-07-21T06:46:14Z,done. updated the doc.,0,0.9799586534500122
457873376,9001,kowshik,2020-07-21T06:47:55Z,done.,0,0.9759407639503479
457876122,9001,kowshik,2020-07-21T06:54:17Z,"done. this case is also handled now. to your point, the case where `updated.max < existing.min` can never happen unless brokers get downgraded (after finalizing features at higher levels), and especially if the downgrade was done improperly (without applying feature tooling commands). it's a rare case. but even in that case, the broker will start crashing because of incompatibility in supported feature version max level, so the problem is found before it reaches this point.",0,0.957321286201477
457879567,9001,kowshik,2020-07-21T07:02:03Z,not sure i understood. we will only update the `featureznode` if the status is not disabled currently (see the implementation below). what am i missing?,0,0.9536095857620239
457880383,9001,kowshik,2020-07-21T07:03:54Z,this handles the race condition described in the kip-584 [a link]. please refer to the kip for details. i have also added doc to this method.,0,0.9868451356887817
457883779,9001,kowshik,2020-07-21T07:11:03Z,done.,0,0.9759407639503479
457884903,9001,kowshik,2020-07-21T07:13:24Z,"i feel that there isn't a pressing reason to optimize this api path currently, and make it async. the api is not going to be frequently used, and an infrequent write to a zk node with low write contention feels like a relatively inexpensive case that we could block the controller on. please let me know how you feel.",0,0.8772455453872681
457885415,9001,kowshik,2020-07-21T07:14:28Z,done.,0,0.9759407639503479
457885467,9001,kowshik,2020-07-21T07:14:38Z,done. made the comment better. pls take a look.,0,0.9565535187721252
457890046,9001,kowshik,2020-07-21T07:23:55Z,"it is already explained in the class level doc. this is also explained in the kip-584 [a link]. this is needed because `defaultfeatureminversionlevels` is mainly for feature version deprecation. when we deprecate feature version levels, we first bump the `defaultfeatureminversionlevels` in a broker release (after making an announcement to community). this will automatically mean clients have to stop using the finalized min version levels that have been deprecated (because upon startup the controller will write the `defaultfeatureminversionlevels` to zk from within `kafkacontroller#setupfeatureversioning` method). once the write to zk happens, clients that are using the finalized features are forced to stop using the deprecated version levels. then, finally in the future when we remove the code for the deprecated version levels, that is when we will bump the min version for the supported feature in the broker. thereby we will completely drop support for a feature version altogether.",0,0.9852632284164429
457891034,9001,kowshik,2020-07-21T07:25:44Z,done.,0,0.9759407639503479
457892024,9001,kowshik,2020-07-21T07:27:45Z,done. calling it `incompatiblefeaturesinfo` now.,0,0.9883692264556885
457892374,9001,kowshik,2020-07-21T07:28:29Z,done.,0,0.9759407639503479
457892622,9001,kowshik,2020-07-21T07:28:55Z,done.,0,0.9759407639503479
457892858,9001,kowshik,2020-07-21T07:29:25Z,done.,0,0.9759407639503479
457897331,9001,kowshik,2020-07-21T07:37:49Z,"done. made it the way you suggested, pls take a look. overall either way looked fine to me but the one you suggested is a bit simpler.",0,0.8391427397727966
457903477,9001,kowshik,2020-07-21T07:48:51Z,done.,0,0.9759407639503479
457903582,9001,kowshik,2020-07-21T07:49:04Z,done.,0,0.9759407639503479
457904782,9001,kowshik,2020-07-21T07:51:11Z,done. removed.,0,0.9766796827316284
457905010,9001,kowshik,2020-07-21T07:51:34Z,done.,0,0.9759407639503479
457939241,9001,kowshik,2020-07-21T08:50:07Z,done.,0,0.9759407639503479
457981705,9001,kowshik,2020-07-21T10:01:43Z,done. i'm calling it `brokerdefaultversionrange` now.,0,0.9860767126083374
457985348,9001,kowshik,2020-07-21T10:08:39Z,"done. removed the word ""finalized""in the context of this api.",0,0.9881560802459717
457986837,9001,kowshik,2020-07-21T10:11:25Z,done.,0,0.9759407639503479
458503099,9001,abbccdda,2020-07-22T02:52:48Z,nit: do `{ describefeaturesresult}`,0,0.9826905131340027
458985306,9001,abbccdda,2020-07-22T18:06:59Z,nit: new line,0,0.96523118019104
458985676,9001,abbccdda,2020-07-22T18:07:40Z,could be simplified as `sendtocontroller`,0,0.9886748790740967
458986288,9001,abbccdda,2020-07-22T18:08:46Z,"why do we need this override, which seems to be exactly the same with super class?",0,0.9735118746757507
458987227,9001,abbccdda,2020-07-22T18:10:24Z,s/featurename/feature,0,0.9845879077911377
459002813,9001,abbccdda,2020-07-22T18:37:41Z,"the two `call` structs only have two differences: 1. used different node provider 2. one would handle not controller, one not so i would suggest a bit refactoring to reduce the code redundancy, by providing a helper as: [code block]",0,0.9846810102462769
459003818,9001,abbccdda,2020-07-22T18:39:25Z,"same here, why do we need this extension?",0,0.9828171730041504
459004097,9001,abbccdda,2020-07-22T18:39:54Z,"as discussed offline, we need to extend the result as per feature.",0,0.987784206867218
459004701,9001,abbccdda,2020-07-22T18:40:56Z,couldn't we just use `isincompatiblewith`?,0,0.9856799840927124
459005027,9001,abbccdda,2020-07-22T18:41:29Z,why do we jump from code 88 to 91?,0,0.95805424451828
459006265,9001,abbccdda,2020-07-22T18:43:34Z,"make sense, after looking further i realized that we also did some data format conversion.",0,0.9808889031410217
459008772,9001,abbccdda,2020-07-22T18:47:48Z,do we also need to check `allowautodowngrade` here?,0,0.9874542951583862
459009582,9001,abbccdda,2020-07-22T18:49:09Z,we could consider either making `data` to be private or remove this unnecessary accessor. i would prefer making it private.,0,0.9742770195007324
459009753,9001,abbccdda,2020-07-22T18:49:24Z,same here for consistency.,0,0.9829378724098206
459010149,9001,abbccdda,2020-07-22T18:50:03Z,"spaces look weird, let's try to remove all `two space` cases in this file.",-1,0.9818214774131775
459014883,9001,abbccdda,2020-07-22T18:58:04Z,"my pt is that since we know the outcome (feature versioning will be disabled), we don't need to do one more lookup but just try to push the update. anyway, i think this is a nit.",0,0.9416759014129639
459183702,9001,abbccdda,2020-07-23T02:26:11Z,parameters could be on the same line to be consistent with l80,0,0.9880245327949524
459185058,9001,abbccdda,2020-07-23T02:32:59Z,"`testupdatefeatures` should be suffice, as we sometimes are not passing in a real error.",0,0.9876468181610107
459185171,9001,abbccdda,2020-07-23T02:33:32Z,nit: prefer using `error == errors.none`,0,0.9428587555885315
459186000,9001,abbccdda,2020-07-23T02:37:26Z,`collections.emptylist()` should be suffice.,0,0.9877209067344666
459186249,9001,abbccdda,2020-07-23T02:38:39Z,we should have a matcher checking whether the sent request is pointing at the correct controller id.,0,0.9879597425460815
459186371,9001,abbccdda,2020-07-23T02:39:08Z,"make it a variable, as `int controllerid = 1`",0,0.9880129098892212
459186681,9001,abbccdda,2020-07-23T02:40:44Z,`defaultfeaturemetadata` should be suffice. ak repo normally tries to avoid using `get` as func prefix.,0,0.9865650534629822
459186760,9001,abbccdda,2020-07-23T02:41:09Z,nit: could use `utils.mkmap` to simplify here.,0,0.9890936613082886
459188638,9001,abbccdda,2020-07-23T02:50:16Z,nit: `zkclient.getdataandversion(featureznode.path)._2` should be suffice,0,0.9844011664390564
459188844,9001,abbccdda,2020-07-23T02:51:18Z,s/znode/znode,0,0.9858546853065491
459188931,9001,abbccdda,2020-07-23T02:51:41Z,s/ is is / is,0,0.9508129358291626
459189057,9001,abbccdda,2020-07-23T02:52:09Z,remove `in zk`,0,0.9848894476890564
459189198,9001,abbccdda,2020-07-23T02:52:55Z,nit: s/it's/its,0,0.8958252668380737
459189220,9001,abbccdda,2020-07-23T02:53:03Z,nit: s/it's/its,0,0.8958252668380737
459189352,9001,abbccdda,2020-07-23T02:53:49Z,remove `one and`,0,0.9835929870605469
459189517,9001,abbccdda,2020-07-23T02:54:36Z,remove `and their version levels` or restructure as `the information about finalized features' version levels`,0,0.9853863716125488
459189854,9001,abbccdda,2020-07-23T02:55:55Z,"could we just remove ` the feature versioning system (kip-584) is enabled, and`? it does not provide any useful information.",0,0.9601235389709473
459189970,9001,abbccdda,2020-07-23T02:56:23Z,s/this status/the enabled status,0,0.9850207567214966
459190247,9001,abbccdda,2020-07-23T02:57:49Z,we don't need to capitalize `broker` here,0,0.9851139783859253
459190329,9001,abbccdda,2020-07-23T02:58:15Z,same here,0,0.982987642288208
459190412,9001,abbccdda,2020-07-23T02:58:44Z,"s/`the reason to do this is that...`/`this process ensures we do not enable all the possible features immediately after an upgrade, which could be harmful to the application.`",0,0.9212480187416077
459190870,9001,abbccdda,2020-07-23T03:01:03Z,remove `then`,0,0.9823200106620789
459191665,9001,abbccdda,2020-07-23T03:05:05Z,{} could be removed.,0,0.983451247215271
459192115,9001,abbccdda,2020-07-23T03:07:16Z,nit: would be easier to read if we always compare `existingversionrange` towards `brokerdefaultversionrange` instead of flipping in this statement.,0,0.9867873191833496
459192901,9001,abbccdda,2020-07-23T03:11:05Z,i think we need to override `equals` here.,0,0.9774745106697083
459192976,9001,abbccdda,2020-07-23T03:11:26Z,cache,0,0.9860571622848511
459193453,9001,abbccdda,2020-07-23T03:13:22Z,`no updatemetadatarequest will be sent to broker...`,0,0.9827979207038879
459193711,9001,abbccdda,2020-07-23T03:14:45Z,does `features` guarantee to be non-null?,0,0.983834981918335
459193767,9001,abbccdda,2020-07-23T03:15:02Z,format,0,0.9792689681053162
459194593,9001,abbccdda,2020-07-23T03:19:03Z,"yea, i'm a bit worried about such a blocking call here as we don't have a precedence for relying on zk connect timeout (18 seconds), besides the result doesn't matter to the controller (since client will do the retry). cc to see if they have a different opinion on this.",-1,0.8684123754501343
459195272,9001,abbccdda,2020-07-23T03:22:08Z,what `clients` are we referring to here?,0,0.9799768924713135
459195338,9001,abbccdda,2020-07-23T03:22:35Z,`the class is immutable in production`,0,0.9813616871833801
459528132,9001,abbccdda,2020-07-23T15:16:34Z,is it necessary to quote `incompatible`?,0,0.9607800245285034
459538486,9001,abbccdda,2020-07-23T15:30:57Z,could you explain a bit why we no longer use singletons for feature cache?,0,0.9869957566261292
459554866,9001,abbccdda,2020-07-23T15:54:51Z,we could explicitly mention this is `either or` result.,0,0.9879493713378906
459556307,9001,abbccdda,2020-07-23T15:56:45Z,could be initialized closer to l3005,0,0.9866484999656677
459562747,9001,abbccdda,2020-07-23T16:06:37Z,could we assert the expected version here?,0,0.9878985285758972
459563255,9001,abbccdda,2020-07-23T16:07:24Z,nit: new line,0,0.96523118019104
459564526,9001,abbccdda,2020-07-23T16:09:36Z,...`withinvalidsmallvalue`,0,0.9812559485435486
459564664,9001,abbccdda,2020-07-23T16:09:48Z,...`withinvalidlargevalue`,0,0.9807979464530945
459565850,9001,abbccdda,2020-07-23T16:11:41Z,what's the purpose of this second test?,0,0.9744534492492676
459566826,9001,abbccdda,2020-07-23T16:13:14Z,nit: replace with `noncontrollerservers.head`,0,0.9866784811019897
459569818,9001,abbccdda,2020-07-23T16:17:56Z,this case seems not to be tested yet.,0,0.9305769801139832
459570396,9001,abbccdda,2020-07-23T16:18:54Z,format,0,0.9792689681053162
459653525,9001,abbccdda,2020-07-23T18:41:59Z,format,0,0.9792689681053162
459655758,9001,abbccdda,2020-07-23T18:45:44Z,we could refactor out a helper in `updatefeaturesrequest` to create `featureupdatekey`,0,0.987000048160553
459658554,9001,abbccdda,2020-07-23T18:50:45Z,"could we add some unit tests in `kafkaapistest.scala`, once the refactoring is finished?",0,0.9892436265945435
460365110,9001,kowshik,2020-07-25T04:51:52Z,done.,0,0.9759407639503479
460365185,9001,kowshik,2020-07-25T04:52:57Z,done.,0,0.9759407639503479
460365229,9001,kowshik,2020-07-25T04:53:47Z,done.,0,0.9759407639503479
460365305,9001,kowshik,2020-07-25T04:54:32Z,done. removed now. didn't realize it was present in super class too.,0,0.9285017848014832
460365462,9001,kowshik,2020-07-25T04:56:23Z,done. actually `feature` is removed from this class now.,0,0.9886329770088196
460369033,9001,kowshik,2020-07-25T05:44:35Z,done. good point.,1,0.9535248279571533
460369103,9001,kowshik,2020-07-25T05:45:25Z,done. removed now.,0,0.9800757169723511
460369423,9001,kowshik,2020-07-25T05:49:31Z,done. removed this method now.,0,0.9863094091415405
460369509,9001,kowshik,2020-07-25T05:50:19Z,done. not intentional. changed to 89 now.,0,0.8911613821983337
460369545,9001,kowshik,2020-07-25T05:50:51Z,done.,0,0.9759407639503479
460370082,9001,kowshik,2020-07-25T05:57:51Z,done. made the attribute private.,0,0.9868179559707642
460370089,9001,kowshik,2020-07-25T05:58:03Z,done. made the attribute private.,0,0.9868179559707642
460370162,9001,kowshik,2020-07-25T05:59:09Z,done.,0,0.9759407639503479
460371001,9001,kowshik,2020-07-25T06:10:14Z,done.,0,0.9759407639503479
460371104,9001,kowshik,2020-07-25T06:11:43Z,done.,0,0.9759407639503479
460371146,9001,kowshik,2020-07-25T06:12:24Z,done.,0,0.9759407639503479
460371283,9001,kowshik,2020-07-25T06:14:31Z,done.,0,0.9759407639503479
460371443,9001,kowshik,2020-07-25T06:16:22Z,done.,0,0.9759407639503479
460371572,9001,kowshik,2020-07-25T06:18:05Z,done.,0,0.9759407639503479
460373122,9001,kowshik,2020-07-25T06:38:13Z,"i have improved the matcher now, but how do i check the correct controller id?",0,0.9848055243492126
460373211,9001,kowshik,2020-07-25T06:39:17Z,`newversion` is more readable than `_2`.,0,0.9876402020454407
460373254,9001,kowshik,2020-07-25T06:39:52Z,done.,0,0.9759407639503479
460373296,9001,kowshik,2020-07-25T06:40:15Z,done.,0,0.9759407639503479
460373384,9001,kowshik,2020-07-25T06:41:31Z,done.,0,0.9759407639503479
460373389,9001,kowshik,2020-07-25T06:41:37Z,done.,0,0.9759407639503479
460373454,9001,kowshik,2020-07-25T06:42:14Z,done.,0,0.9759407639503479
460373463,9001,kowshik,2020-07-25T06:42:21Z,done.,0,0.9759407639503479
460373549,9001,kowshik,2020-07-25T06:43:36Z,done.,0,0.9759407639503479
460373561,9001,kowshik,2020-07-25T06:43:52Z,done.,0,0.9759407639503479
460373590,9001,kowshik,2020-07-25T06:44:08Z,done.,0,0.9759407639503479
460373616,9001,kowshik,2020-07-25T06:44:20Z,done.,0,0.9759407639503479
460373708,9001,kowshik,2020-07-25T06:45:15Z,done.,0,0.9759407639503479
460373729,9001,kowshik,2020-07-25T06:45:37Z,done.,0,0.9759407639503479
460373746,9001,kowshik,2020-07-25T06:45:51Z,done.,0,0.9759407639503479
460373809,9001,kowshik,2020-07-25T06:46:45Z,done.,0,0.9759407639503479
460374117,9001,kowshik,2020-07-25T06:50:59Z,"`featureznode` is a `case class`, and therefore the `equals` method is auto generated. let me know if i'm missing something. here is the doc: [a link]",0,0.986512303352356
460374136,9001,kowshik,2020-07-25T06:51:22Z,done.,0,0.9759407639503479
460374558,9001,kowshik,2020-07-25T06:57:15Z,"we can not just push the update, because, we have to decide if the node needs to be created or existing node should be updated. that is why we read the node first to understand if it exists or not, then we update the existing node only if the status does not match (this avoids a zk write in the most common cases).",0,0.9819968342781067
460374653,9001,kowshik,2020-07-25T06:58:43Z,done.,0,0.9759407639503479
460375004,9001,kowshik,2020-07-25T07:03:27Z,"yes, `broker.features` is just empty when there are no features set or none decoded from the `brokeridznode`.",0,0.9890080690383911
460375038,9001,kowshik,2020-07-25T07:04:01Z,done.,0,0.9759407639503479
460375251,9001,kowshik,2020-07-25T07:06:15Z,done. i was referring to external clients of kafka. have updated the doc now.,0,0.9834935665130615
460375270,9001,kowshik,2020-07-25T07:06:32Z,done.,0,0.9759407639503479
460375378,9001,kowshik,2020-07-25T07:08:11Z,done. removed quotes.,0,0.9812588095664978
460375750,9001,kowshik,2020-07-25T07:13:11Z,"it became painful to write tests using singletons. particularly in `kafka.server.updatefeaturestest` we would like to simulate presence of multiple brokers and a controller within the same test process. then we would like to set incompatible features for some brokers, and compatible features for some others. using a singleton for feature cache made it impossible to set up such an environment for testing. that is why we no longer use a singleton, instead we instantiate the class once in `kafkaserver` and we use the object wherever needed.",-1,0.9405033588409424
460375901,9001,kowshik,2020-07-25T07:15:07Z,done.,0,0.9759407639503479
460375935,9001,kowshik,2020-07-25T07:15:25Z,done.,0,0.9759407639503479
460376009,9001,kowshik,2020-07-25T07:16:37Z,done.,0,0.9759407639503479
460376035,9001,kowshik,2020-07-25T07:16:42Z,done.,0,0.9759407639503479
460376322,9001,kowshik,2020-07-25T07:20:35Z,"it is explained in the test doc above, and, i have also added comments now. the purpose is to check that the zk watch on the featureznode was re-established by the broker, after the first update triggers a zk notification that populates the cache. the best way to check it is to update the node again and see if the notification is received by the broker again.",0,0.9858940839767456
460376477,9001,kowshik,2020-07-25T07:22:27Z,done.,0,0.9759407639503479
460376521,9001,kowshik,2020-07-25T07:22:56Z,done.,0,0.9759407639503479
460376578,9001,kowshik,2020-07-25T07:23:54Z,done.,0,0.9759407639503479
461412713,9001,kowshik,2020-07-28T08:35:14Z,done.,0,0.9759407639503479
461413382,9001,kowshik,2020-07-28T08:36:21Z,done.,0,0.9759407639503479
461413992,9001,kowshik,2020-07-28T08:37:29Z,done.,0,0.9759407639503479
461416641,9001,kowshik,2020-07-28T08:42:00Z,done.,0,0.9759407639503479
461417458,9001,kowshik,2020-07-28T08:43:22Z,"sure, we can hear what others say.",0,0.9702076315879822
461418384,9001,kowshik,2020-07-28T08:44:51Z,will take a look.,0,0.9784966707229614
461418530,9001,kowshik,2020-07-28T08:45:03Z,this method has changed greatly and it has been moved to `kafkacontroller.scala`.,0,0.9790394902229309
461418681,9001,kowshik,2020-07-28T08:45:17Z,this method has changed greatly and it has been moved to `kafkacontroller.scala`.,0,0.9790394902229309
461421563,9001,kowshik,2020-07-28T08:49:51Z,"hmm, there seem to be very few call sites and therefore seems ok to inline it. let me know!",0,0.7195157408714294
461424717,9001,kowshik,2020-07-28T08:54:59Z,added a test now in `updatefeaturestest.scala`. look for `testsuccessfulfeatureupgradeandwithnoexistingfinalizedfeatures`.,0,0.9877854585647583
461771992,9001,abbccdda,2020-07-28T18:03:35Z,nit: s/name/names,0,0.9812692403793335
462453975,9001,abbccdda,2020-07-29T17:08:15Z,"note in the post-kip-500 world, this feature could still work, but the request must be redirected to the controller inherently on the broker side, instead of sending it directly. so in the comment, we may try to phrase it to convey the principal is that `the request must be handled by the controller` instead of `the admin client must send this request to the controller`.",0,0.9871982932090759
462456942,9001,abbccdda,2020-07-29T17:13:03Z,should this a per feature error or a top level error?,0,0.9710789322853088
462458761,9001,abbccdda,2020-07-29T17:15:56Z,"for top level exception such as cluster authorization exception, we could just define a top level error code instead of check-marking every feature with the redundant error code. i know we have been a bit inconsistent in such a case, but personally feel having layered error codes could make the response handling clear of whether it is per feature issue, or a high level issue.",0,0.9381456971168518
462458948,9001,abbccdda,2020-07-29T17:16:15Z,space,0,0.968176543712616
462459015,9001,abbccdda,2020-07-29T17:16:21Z,same here,0,0.982987642288208
462459152,9001,abbccdda,2020-07-29T17:16:34Z,same here,0,0.982987642288208
462462109,9001,abbccdda,2020-07-29T17:21:30Z,`can be issued only to the controller.`/ `must be processed by the controller`,0,0.9847803115844727
462462268,9001,abbccdda,2020-07-29T17:21:47Z,`could be processed by any random broker`,0,0.9842566847801208
462462801,9001,abbccdda,2020-07-29T17:22:41Z,same here,0,0.982987642288208
462463977,9001,abbccdda,2020-07-29T17:24:33Z,"try to put first parameter on the same line as the constructor, and align the rest parameters.",0,0.9845088124275208
462465188,9001,abbccdda,2020-07-29T17:26:28Z,"this won't work well with string format, consider doing `orelse`",0,0.9765883684158325
462465387,9001,abbccdda,2020-07-29T17:26:50Z,new line,0,0.9631602764129639
462471038,9001,abbccdda,2020-07-29T17:36:28Z,"i suggest we build a static method in the `updatefeaturesrequest` class to avoid exposing the sub modules of feature data, such like: [code block]",0,0.9873912930488586
462472940,9001,abbccdda,2020-07-29T17:39:43Z,does this overlap with `completeunrealizedfutures` check? we could just keep one to reduce the checking complexity.,0,0.988095760345459
462475689,9001,abbccdda,2020-07-29T17:44:02Z,"you are right, it seems not necessary.",0,0.9512504935264587
462477303,9001,abbccdda,2020-07-29T17:46:32Z,"do we need to make this a public error? it seems only be used internally, so could be made private if we don't have intention to let user catch.",0,0.9696210622787476
462480826,9001,abbccdda,2020-07-29T17:52:16Z,comment here since no better place: createapiversionsresponse on l198 could be made private,0,0.977423369884491
462483315,9001,abbccdda,2020-07-29T17:56:31Z,nit: could be replaced with lambda,0,0.9876583218574524
462485886,9001,abbccdda,2020-07-29T18:00:41Z,should we also mention that this flag would fail the request when we are not actually doing a downgrade?,0,0.9624898433685303
462488078,9001,abbccdda,2020-07-29T18:04:41Z,"i'm actually wondering whether this is too strict in the perspective of a user. if they accidentally set a feature version larger than the cache, what they only care about is to be able to change the version to it. so it's a matter of whether we think this is a user error, or this could happen when user gets stale feature information from a broker while the downgrade already succeed eventually. if we want to keep this check, it makes sense to update the meta comments around `allowdowngrade` to inform user that the request could fail when the target version is actually higher than the current finalized feature.",0,0.5511385202407837
462489375,9001,abbccdda,2020-07-29T18:07:00Z,could be moved to the `updatefeaturesresponse`,0,0.9882539510726929
462492285,9001,abbccdda,2020-07-29T18:11:58Z,could we make `updates` as a pass-in parameter to avoid calling `maketestfeatureupdates` twice?,0,0.9883261322975159
462492825,9001,abbccdda,2020-07-29T18:12:58Z,nit: could use lambda,0,0.9878624677658081
462496091,9001,abbccdda,2020-07-29T18:18:17Z,"do we need to call `featurecache.waituntilepochorthrow(newnode, config.zkconnectiontimeoutms)` here to ensure the update is successful?",0,0.9902070164680481
462498961,9001,abbccdda,2020-07-29T18:23:15Z,"i see, still wondering if we could just check whether `newfeatures` is equal to `existingfeatureznode.features`",0,0.9870252013206482
462500314,9001,abbccdda,2020-07-29T18:25:31Z,"are we good to proceed in this case? when there is no overlapping between broker default features and remote finalized features, is the current controller still eligible?",0,0.9871628880500793
462501301,9001,abbccdda,2020-07-29T18:27:19Z,"i see, what would happen to a currently live broker if it couldn't get any metadata update for a while, will it shut down itself?",0,0.9801867604255676
462502780,9001,abbccdda,2020-07-29T18:29:57Z,"i see, still i'm a bit worried future changes could break this assumption. not a bad idea to check `features != null`?",-1,0.9657833576202393
462504467,9001,abbccdda,2020-07-29T18:32:45Z,state the error explicitly here.,0,0.9794918298721313
462627189,9001,abbccdda,2020-07-29T22:30:26Z,"yea, i mean you could use `val newversion = zkclient.getdataandversion(featureznode.path)._2`, but it's up to you.",0,0.9459255933761597
462649895,9001,abbccdda,2020-07-29T23:38:21Z,is this case covered by the case on l1931? could we merge both?,0,0.9875594973564148
462650343,9001,abbccdda,2020-07-29T23:39:44Z,we should be consistent and remove `()` from `maxversionlevel`,0,0.9871007204055786
462651241,9001,abbccdda,2020-07-29T23:42:50Z,nit: new line,0,0.96523118019104
462658154,9001,abbccdda,2020-07-30T00:05:36Z,"could you clarify the reasoning here? if structs are not the same, are we going to do a partial update?",0,0.9853004813194275
462714278,9001,abbccdda,2020-07-30T03:34:34Z,could we get a static method instead of initiating a new `finalizedversionrange` for a comparison every time?,0,0.9877949953079224
462715368,9001,abbccdda,2020-07-30T03:39:07Z,why don't we just use `system.currenttimemillis()` to avoid conversion between nano time?,0,0.9867379665374756
462715603,9001,abbccdda,2020-07-30T03:39:57Z,seems not covered yet,0,0.9506966471672058
462716040,9001,abbccdda,2020-07-30T03:41:34Z,could be moved to `updatefeaturesresponse` as a utility.,0,0.9877743124961853
462716875,9001,abbccdda,2020-07-30T03:44:56Z,"some methods in the `brokerfeatures` are not covered by this suite, such as `defaultminversionlevel`, `getdefaultfinalizedfeatures` and `hasincompatiblefeatures`, you could use code coverage tool to figure out any missing part.",0,0.9891352653503418
462717083,9001,abbccdda,2020-07-30T03:45:45Z,indentation is not right.,-1,0.7878678441047668
462718258,9001,abbccdda,2020-07-30T03:50:44Z,the meta comment for `finalizedfeaturecache` should be updated as it is now being accessed for both read and write,0,0.9884945750236511
462719027,9001,abbccdda,2020-07-30T03:54:08Z,nit: this could be extracted as a common struct.,0,0.988384485244751
462719977,9001,abbccdda,2020-07-30T03:57:50Z,"could we only pass in `featurecache` to reduce the class coupling here? as we already have `brokerfeatures` as a private parameter, it shouldn't be too hard to set a helper to get supported features.",0,0.986789882183075
463880076,9001,kowshik,2020-07-31T23:01:47Z,"sorry, i do not understand why should describefeatures (in post kip-500) be handled only by controller?",-1,0.9851342439651489
463912157,9001,kowshik,2020-08-01T02:54:07Z,it does not overlap. this checks for unexpected responses for features that we never intended to update. `completeunrealizedfutures` is for futures that we never got a response for from the server -- we need to complete such futures exceptionally.,0,0.983796238899231
463912498,9001,kowshik,2020-08-01T02:57:46Z,this exception corresponds to `errors.feature_update_failed`. the caller of `adminclient#updatefeatures` can receive this exception whenever a feature update can not be written to zk (due to a zk issue). so this has to be a public error.,0,0.9540240168571472
463915406,9001,kowshik,2020-08-01T03:23:44Z,"updated the doc. let's keep the check, if it happens then it's a user error. especially because this can not happen if the user is using the tooling that we are going to provide in ak.",0,0.9435127973556519
463915409,9001,kowshik,2020-08-01T03:23:50Z,done.,0,0.9759407639503479
463915553,9001,kowshik,2020-08-01T03:25:20Z,"no, that is not required. please refer to the documentation above under `note` for this method where i have explained why.",0,0.9864245057106018
463916219,9001,kowshik,2020-08-01T03:34:23Z,isn't that what i'm using currently?,0,0.8710413575172424
463916470,9001,kowshik,2020-08-01T03:37:35Z,like how? i don't understand. isn't that what i'm doing currently?,-1,0.9105425477027893
463916610,9001,kowshik,2020-08-01T03:39:49Z,"if the broker has feature incompatibilities, then it should die as soon as it has received the zk update (it would die from within `finalizedfeaturechangelistener`).",0,0.9797300100326538
463916688,9001,kowshik,2020-08-01T03:40:25Z,done now.,0,0.9806601405143738
463934710,9001,kowshik,2020-08-01T07:31:07Z,"we should keep the existing check as it is. the reason is that if the existing node is `(disabled, {})` then here we would like to change it to `(enabled, features)`. therefore, we have to check the features as well as the `featureznodestatus`.",0,0.9874477982521057
463934948,9001,kowshik,2020-08-01T07:34:46Z,i do not understand the concern. which code path can possibly introduce `null` features attribute in `broker` object? it is impossible....,-1,0.924575924873352
463935718,9001,kowshik,2020-08-01T07:44:14Z,"a value < 1 is indicative of a deletion request (a kind of downgrade request). it is for convenience of generating a special error message, that we handle the case here explicitly: `...less than 1 for feature...`.",0,0.8630508184432983
463936048,9001,kowshik,2020-08-01T07:48:44Z,done.,0,0.9759407639503479
463936098,9001,kowshik,2020-08-01T07:49:28Z,existing approach is equally readable too. i'd rather leave it this way.,0,0.9698548316955566
463936412,9001,kowshik,2020-08-01T07:54:05Z,"since the app depends on monotonically increasing elapsed time values, `system.nanotime()` is preferred. `system.currenttimemillis()` can change due to daylight saving time, users changing the time settings, leap seconds, and internet time sync etc.",0,0.9853460788726807
463937032,9001,kowshik,2020-08-01T08:02:25Z,"the `finalizedfeaturecache.getsupportedfeatures` api is not the right fit for the cache's public interface (it is quite unrelated to the other public apis of the cache). i'd rather not pollute the public api there, just for the sake of convenience.",0,0.9258575439453125
463937184,9001,kowshik,2020-08-01T08:04:35Z,just 2 occurrences (one in this test and other in the next test). i'd leave it the way it is as the test is readable with values inlined in the test body.,0,0.9875900745391846
465565925,9001,kowshik,2020-08-05T08:36:36Z,"actually this is an error case now. have updated the code with the fix, and with good documentation.",0,0.6568926572799683
465570359,9001,kowshik,2020-08-05T08:44:21Z,"this does not seem to be required, since it is already achieved via `updatefeaturestest`. infact there we test using admin client, which is even better as it tests e2e client to server functionality. what do we gain by adding the additional tests in `kafkaapistest` ?",0,0.9881775975227356
465572011,9001,kowshik,2020-08-05T08:47:06Z,"i don't see that we consistently use a top level error code across other kafka apis, so i will leave it as it is. it feels ok for this api to not use it, as it does not make a significant difference.",-1,0.5339643955230713
465572056,9001,kowshik,2020-08-05T08:47:12Z,answered below.,0,0.9819700717926025
467279790,9001,junrao,2020-08-07T21:29:27Z,the kip wiki has allowdowngrade at the topic level. could we update that?,0,0.9895555377006531
467282147,9001,junrao,2020-08-07T21:32:28Z,the kip wiki doesn't include this field.,0,0.9609025120735168
467309169,9001,junrao,2020-08-07T22:15:43Z,"when we roll the cluster to bump up ibp, it seems that it's possible for status to be enabled and then disabled repeatedly? this can be a bit weird.",-1,0.9786124229431152
467315417,9001,junrao,2020-08-07T22:40:05Z,"when we roll the cluster to bump up ibp, it seems that it's possible for the min of finalized version to flip repeatedly? this can be a bit weird. also, it seems that we should set min version based on the largest min version across all brokers?",-1,0.974989652633667
467319530,9001,junrao,2020-08-07T22:57:09Z,"hmm, do we need to do this? if there is an incompatible feature, the broker will realize that and can just shut itself down.",0,0.9662699699401855
467326580,9001,junrao,2020-08-07T23:29:11Z,"if update.maxversionlevel < defaultminversionlevel, we throw an illegalstateexception. should we catch it and convert it to an error code?",0,0.9276517033576965
467330197,9001,junrao,2020-08-07T23:48:02Z,"since we are doing the compatibility check for every broker, do we need to special case here just for the broker feature on the controller?",0,0.9889154434204102
467333895,9001,junrao,2020-08-08T00:08:33Z,"if the broker discovers that it's incompatible, should it just shut itself down?",0,0.9253557324409485
467341811,9001,junrao,2020-08-08T01:04:11Z,could you explain how the default min version is different from the min in supportedfeatures?,0,0.9888667464256287
468000768,9001,junrao,2020-08-10T15:42:18Z,"the return type is different from the kip. which one is correct? since this is a public interface, in general, we don't want to expose anything other than truly necessary. this pr seems to expose a lot more public methods to the user. finalizedversionrange is in org.apache.kafka.common.feature. currently, all public interfaces are specified under javadoc in build.gradle. so, we need to either include that package in javadoc or move it to a public package.",0,0.9801023602485657
468000872,9001,junrao,2020-08-10T15:42:28Z,the return type is different from the kip. which one is correct?,0,0.9851511120796204
468002060,9001,junrao,2020-08-10T15:44:20Z,the kip also exposes host() and port(). are they still needed?,0,0.9897286891937256
468005420,9001,junrao,2020-08-10T15:49:30Z,"the kip doesn't have describefeaturesoptions. if we are changing the kip, could we summarize the list of the things that are changed?",0,0.9881497621536255
468008294,9001,junrao,2020-08-10T15:53:53Z,"again, this method has a different signature from the kip.",0,0.9841430187225342
468009874,9001,junrao,2020-08-10T15:56:13Z,the kip doesn't have this method.,0,0.928123414516449
468020800,9001,junrao,2020-08-10T16:14:00Z,handlenotcontrollererror() already throws an exception. should other errors like cluster_authorization_failed be treated in the same way?,0,0.9759235978126526
468084269,9001,kowshik,2020-08-10T18:04:56Z,i'm missing something. which lines on the kip-584 were you referring to? i didn't find any mention of the flag being at the topic level.,0,0.5099011063575745
468085443,9001,kowshik,2020-08-10T18:07:00Z,"yes, we changed to have an error code per feature update. i'll update the kip-584 write up.",0,0.9888606667518616
468089357,9001,kowshik,2020-08-10T18:14:32Z,"to be sure we are on same page, is this because of a controller failover during an ibp bump? it seems to me that this can happen mainly when ibp is being bumped from a value less than kafka_2_7_iv0 to a value greater than or equal to kafka_2_7_iv0 (assuming subsequent ibp bumps will be from kafka_2_7_iv0 to a higher value, so the node status will remain enabled). in general, i'm not sure how to avoid this node status flip until ibp bump has been completed cluster-wide.",0,0.830559253692627
468097360,9001,kowshik,2020-08-10T18:29:32Z,"true, this is possible. good point. to be sure i understood, are you referring broadly to any future ibp bump? or specifically are you referring to the ibp bump from a value less than kafka_2_7_iv0 to a value greater than or equal to kafka_2_7_iv0? (since kafka_2_7_iv0 is the ibp where the feature versioning system gets activated) to answer your question, i'm not sure how to avoid the flip. it is to be noted that min version level changes are used only for feature version deprecation. due to the flipping values, it merely means some version levels would go a few times from deprecated -> available -> deprecated -> available...., until the ibp bump has been completed cluster-wide. i can't (yet) think of a case where the flip is dangerous, since: 1. we have this check: [a link] and 2. as best practice, we can recommend to not change a) minversion of supportedfeature as well as b) default minversionlevel within the same release. the reason being that we typically first deprecate a feature version level before we remove the code to drop support for it i.e. (b) usually has to happen before (a).",1,0.8872872591018677
468101982,9001,kowshik,2020-08-10T18:38:18Z,"good question. yes, the broker will shut itself down. but still there is a possible race condition that needs to be handled to prevent an incompatible broker from causing damage to cluster. the race condition is described in the kip-584 [a link]. please let me know your thoughts.",0,0.5263286828994751
468103224,9001,kowshik,2020-08-10T18:40:39Z,"yes, excellent point. i'll fix this.",1,0.9721935391426086
468109791,9001,kowshik,2020-08-10T18:52:51Z,"it's required because `defaultminversionlevel` does not exist for a feature that's not in the supported list. however, i'll change the code to make the check more obvious to the reader (currently it's not).",0,0.9888922572135925
468111300,9001,kowshik,2020-08-10T18:55:30Z,"good question. the existing behavior is that it shuts itself down, as triggered by this loc. the reason to do it is that an incompatible broker can potentially do harmful things to a cluster (because max version level upgrades are used for breaking changes): [a link]",0,0.6128402948379517
468111785,9001,kowshik,2020-08-10T18:56:28Z,"sure, i'll update the pr documenting it.",0,0.9809813499450684
471627837,9001,junrao,2020-08-17T17:13:02Z,ok. there are a couple of places that this pr is inconsistent with the kip. 1. the kip has 2 levels of arrays: []featureupdatekey and []featurekey. this pr only has one array. 2. the kip has a timeoutms field and this pr doesn't.,0,0.9790844917297363
471806378,9001,junrao,2020-08-17T22:20:32Z,"my understanding of the race condition is that the controller finalizes a feature while there is a pending broker registration in the controller event queue. when the controller starts to process the new broker registration, it will realize that its supported feature is not compatible. here, it's seems that we will still process this new broker registration and only avoid sending updatatemetadatarequest to it. i am not sure if this helps since we already acted on this incompatible broker registration and some damage may already be done. the same updatatemetadatarequest will still be sent to other brokers and its metadata will be available to the clients. an alternative way is to just skip the handling of new broker registration if it's detected as incompatible.",0,0.8938714265823364
494170995,9001,kowshik,2020-09-24T09:28:25Z,done. i have added a top-level error code now.,0,0.9858750700950623
494171030,9001,kowshik,2020-09-24T09:28:29Z,done.,0,0.9759407639503479
494171814,9001,kowshik,2020-09-24T09:29:49Z,"done. fixed the kip and the code, so that they align with each other now.",0,0.9805090427398682
494173396,9001,kowshik,2020-09-24T09:32:21Z,"done. i've updated the kip-584 write up, please refer to [a link] in the kip.",0,0.9838324189186096
494174446,9001,kowshik,2020-09-24T09:34:09Z,done. i've fixed this now to align with the kip.,0,0.9721607565879822
494179911,9001,kowshik,2020-09-24T09:42:55Z,done. i've updated the kip to use `optional ` as well.,0,0.9858205318450928
494180021,9001,kowshik,2020-09-24T09:43:06Z,done. i've removed those methods from the kip.,0,0.9862464666366577
494180167,9001,kowshik,2020-09-24T09:43:22Z,done. i've updated the kip to mention `describefeaturesoptions`.,0,0.9860570430755615
494180305,9001,kowshik,2020-09-24T09:43:36Z,"done. i've updated the kip to align with whats used here, so both are the same now.",0,0.9842032194137573
494180601,9001,kowshik,2020-09-24T09:44:03Z,done. the kip has been updated to have this method now.,0,0.9815621972084045
494183456,9001,kowshik,2020-09-24T09:48:37Z,"done. fixed the code to not throw exception again when handling not_controller error. i'm not sure how could we treat it the same way. in the case of the not_controller error, the admin client code would retry the request once again when the exception is raised. but when cluster authorization fails, would a retry help?",0,0.9333879947662354
494519631,9001,kowshik,2020-09-24T18:20:37Z,done. i've changed the code such that we skip the broker registration if it's detected as incompatible.,0,0.9875433444976807
494542156,9001,kowshik,2020-09-24T18:54:14Z,done. this is fixed now.,0,0.9721373319625854
494569726,9001,kowshik,2020-09-24T19:46:20Z,done.,0,0.9759407639503479
494653251,9001,kowshik,2020-09-24T22:52:14Z,done.,0,0.9759407639503479
496093216,9001,junrao,2020-09-28T16:48:55Z,"space before ""name"".",0,0.9844217300415039
496099482,9001,junrao,2020-09-28T16:59:02Z,this is not included in the kip. should we update the kip?,0,0.9846110939979553
496104584,9001,junrao,2020-09-28T17:05:46Z,"since this is public facing, could we include the description in the kip?",0,0.9893873929977417
496118993,9001,junrao,2020-09-28T17:31:27Z,"since the user is not expected to instantiate this, should we make the constructor non-public?",0,0.9858492612838745
496120406,9001,junrao,2020-09-28T17:34:03Z,"since the user is not expected to instantiate this, should we make the constructor non-public?",0,0.9858492612838745
496122127,9001,junrao,2020-09-28T17:37:09Z,"this seems identical to supportedversionrange. should we just have one, sth like versionrange?",0,0.9852267503738403
496124713,9001,junrao,2020-09-28T17:41:52Z,are we adding the timeout option based on the kip discussion?,0,0.9857307076454163
496131186,9001,junrao,2020-09-28T17:52:57Z,"""at a those "" typo?",0,0.9842860102653503
496211011,9001,junrao,2020-09-28T20:24:46Z,"i guess after the first step, deprecated finalized versions are no longer advertised to the client, but they can still be used by existing connections?",0,0.9875795245170593
496213232,9001,junrao,2020-09-28T20:29:04Z,perhaps isfeatureversioningsupported is a better name?,0,0.9871517419815063
496227488,9001,junrao,2020-09-28T20:56:44Z,is it useful to expose firstactiveversion to the client?,0,0.9883818030357361
496253083,9001,junrao,2020-09-28T21:47:00Z,"could you define the default finalized features? also, default minimum version seems outdated now.",0,0.9574698805809021
496268711,9001,junrao,2020-09-28T22:22:21Z,perhaps it's better for the following code to use match instead if/else.,0,0.9829624891281128
496271143,9001,junrao,2020-09-28T22:29:17Z,setupfeatureversioning => maybesetupfeatureversioning ?,0,0.9867867231369019
496305291,9001,junrao,2020-09-29T00:20:56Z,map() is supposed to be used with no side effect. perhaps we could use match here.,0,0.9882707595825195
496306005,9001,junrao,2020-09-29T00:23:48Z,"do we need to return the stacktrace to the caller? since this is unexpected, perhaps we can log a warn?",0,0.9821346998214722
496306586,9001,junrao,2020-09-29T00:26:06Z,indentation,0,0.982236921787262
496309833,9001,junrao,2020-09-29T00:38:35Z,featurecache => finalizedfeaturecache ?,0,0.9863532781600952
496311550,9001,junrao,2020-09-29T00:45:23Z,"i think the convention is that if there is a top level error, the second level will just be empty since there is not need to process them individually.",0,0.9851941466331482
496312688,9001,junrao,2020-09-29T00:50:09Z,-1 => -1l?,0,0.9853734970092773
496315493,9001,junrao,2020-09-29T01:00:56Z,this package is not part of the javadoc and thus is not part of the public interface.,0,0.9867842793464661
496317328,9001,junrao,2020-09-29T01:08:23Z,"since we are including the timeout in the updatefeature request, perhaps we could just use that timeout here.",0,0.9879383444786072
496318368,9001,junrao,2020-09-29T01:12:25Z,featurecache => finalizedfeaturecache?,0,0.9863532781600952
496319189,9001,junrao,2020-09-29T01:15:24Z,"should we just verify the range [first_active_version, max]?",0,0.9893636703491211
496321312,9001,abbccdda,2020-09-29T01:23:04Z,"yea, you are right, i think this comment belongs to updatefeatures",0,0.7237896919250488
496506413,9001,kowshik,2020-09-29T08:09:57Z,done.,0,0.9759407639503479
496509097,9001,kowshik,2020-09-29T08:12:24Z,done. updated the kip. please refer to [a link] section.,0,0.9804573655128479
496509282,9001,kowshik,2020-09-29T08:12:34Z,done. updated the kip. please refer to [a link] section.,0,0.9804573655128479
496511604,9001,kowshik,2020-09-29T08:14:42Z,"it is instantiated from `kafka.server.updatefeaturestest`, so have to keep the c'tor public.",0,0.9847947955131531
496511864,9001,kowshik,2020-09-29T08:14:55Z,"it is instantiated from `kafka.server.updatefeaturestest`, so have to keep the c'tor public.",0,0.9847947955131531
496523315,9001,kowshik,2020-09-29T08:25:21Z,"i considered this, however if we plan to expose `firstactiveversion` to the client, then, it is better to have 2 separate classes like we do now. this is because `firstactiveversion` will become an attribute only in `supportedversionrange` class.",0,0.9864792227745056
496523894,9001,kowshik,2020-09-29T08:25:52Z,"yes, it is already added. the base class: `abstractoptions` contains a `timeoutms` attribute and the value is set in the `updatefeaturesrequest`.",0,0.9892134070396423
496524072,9001,kowshik,2020-09-29T08:26:03Z,done.,0,0.9759407639503479
496524793,9001,kowshik,2020-09-29T08:26:44Z,"yes, correct. i have updated the doc mentioning the same.",0,0.9826020002365112
496524910,9001,kowshik,2020-09-29T08:26:50Z,done.,0,0.9759407639503479
496525949,9001,kowshik,2020-09-29T08:27:48Z,"this is a really good point. yes, i feel it is useful to expose it to the client via `apiversionsresponse`. i can change the kip suitably and then update the pr.",1,0.9558137059211731
496526254,9001,kowshik,2020-09-29T08:28:04Z,"done. i reworded a bit and i'm now no longer using ""default finalized features"" and ""default minimum version"" in the wordings.",0,0.982700765132904
496527539,9001,kowshik,2020-09-29T08:29:14Z,done.,0,0.9759407639503479
496528169,9001,kowshik,2020-09-29T08:29:47Z,done.,0,0.9759407639503479
496528445,9001,kowshik,2020-09-29T08:30:00Z,done.,0,0.9759407639503479
496530810,9001,kowshik,2020-09-29T08:32:23Z,done. good point. i'm now logging just a warning and i've removed the stacktrace from the return value.,1,0.9339599609375
496531037,9001,kowshik,2020-09-29T08:32:31Z,done.,0,0.9759407639503479
496534914,9001,kowshik,2020-09-29T08:36:03Z,done.,0,0.9759407639503479
496535534,9001,kowshik,2020-09-29T08:36:37Z,done. great point.,1,0.982120931148529
496535646,9001,kowshik,2020-09-29T08:36:42Z,done.,0,0.9759407639503479
496538616,9001,kowshik,2020-09-29T08:39:26Z,done. i have now moved it to the package: `org.apache.kafka.clients.admin`.,0,0.9793739318847656
496543685,9001,kowshik,2020-09-29T08:44:03Z,"i agree. but note that in this method, we do not process an `updatefeaturesrequest`. this method is only called during controller election to setup feature versioning. so, i have incorporated your suggestion at the point where we process the request, look for `def processfeatureupdateswithactivecontroller` in this file where now i set the zk write timeout to be `min(timeoutms, config.zkconnectiontimeoutms)`.",0,0.9709997773170471
496544239,9001,kowshik,2020-09-29T08:44:33Z,done.,0,0.9759407639503479
496550557,9001,kowshik,2020-09-29T08:54:04Z,"we need to keep the existing validation. here is a case where `minversionlevel < firstactiveversion` is true, but still there are no incompatibilities: [code block] for example, the above can happen during step 1 of feature verison level deprecation. imagine the following: * a supported feature exists with `supportedversionrange={minversion=1, firstactiveversion=4, maxversion=7}` * the above feature is finalized at `{minversionlevel=2, maxversionlevel=6}` in zk already. then imagine a new kafka release is deployed that raises `firstactiveversion` for the supported feature from 1 -> 4 (in order to deprecate versions: 1,2,3). in such a case, during kafka server startup (where we check for feature incompatibilities), we would run into the comparison cited above between the new `supportedversionrange` and existing `finalizedversionrange`. but it is not considered to be a case of incompatibility.",0,0.9826244711875916
496901588,9001,abbccdda,2020-09-29T17:06:45Z,"do we want to have a different name from `org.apache.kafka.common.feature.finalizedversionrange`, such as `finalizedversionlevels`? same case for `supportedversionrange`, personally i feel the same class name makes the navigation harder.",0,0.8598118424415588
496916316,9001,abbccdda,2020-09-29T17:30:34Z,"i think we could just make the `firstactiveversion = minversion` by default, to avoid the requirement for configuring firstactiveversion",0,0.9866233468055725
496917029,9001,abbccdda,2020-09-29T17:31:41Z,similar here to make `firstactiveversion = minversion` as default.,0,0.9883255958557129
496917907,9001,abbccdda,2020-09-29T17:33:09Z,"so we are saving the zk epoch in a long, which was supposed to be an int field?",0,0.9830397963523865
497255894,9001,kowshik,2020-09-30T05:46:08Z,"yes, but can i do it in a follow-up pr? the reason is if i were to refactor it now, this pr will bloat up.",0,0.9209638833999634
497256162,9001,kowshik,2020-09-30T05:47:01Z,done. i've provided an overloaded c'tor now in `org.apache.kafka.common.feature.supportedversionrange` that only takes `minversion` and `maxversion` as parameters.,0,0.9829862713813782
497256475,9001,kowshik,2020-09-30T05:48:03Z,"as mentioned in above response to a different comment, i've provided an overloaded c'tor now in `org.apache.kafka.common.feature.supportedversionrange` that only takes `minversion` and `maxversion` as parameters.",0,0.9879273772239685
497257420,9001,kowshik,2020-09-30T05:51:12Z,we would like to avoid overflow issues once zk is gone in the future. this change is being done based on colin's suggestion in the kip-584 voting thread: - [a link] is colin's comment - [a link] is my response,0,0.9643738865852356
497399425,9001,kowshik,2020-09-30T10:17:16Z,done. the `firstactiveversion` is now part of `apiversionsresponse`. i added it in the recent commit: a7f4860f5f8bb87cfb01452e208ff8f4e45bcd8b.,0,0.9887612462043762
497793784,9001,junrao,2020-09-30T20:53:28Z,"hmm, why do we need to take the min? if the zk data is propagated quickly, waituntilepochorthrow() will just return early.",0,0.9873966574668884
497813798,9001,junrao,2020-09-30T21:34:06Z,"i was looking at existing classes fro the return value. for example, createaclsresult deliberately makes the constructor non-public.",0,0.9834016561508179
497848498,9001,junrao,2020-09-30T23:05:04Z,it's useful to return an error message too.,0,0.9826700687408447
497850391,9001,junrao,2020-09-30T23:11:02Z,could we use collections.emptymap()?,0,0.9890859127044678
497856858,9001,junrao,2020-09-30T23:32:11Z,"this can throw an exception due to feature mismatch. currently, this forces the controller to move but keeps the broker alive. should we force the broker to exit in this case?",0,0.9750906229019165
498072158,9001,kowshik,2020-10-01T08:29:43Z,"done. good point, removed the min now.",1,0.8885101079940796
498092489,9001,kowshik,2020-10-01T09:03:09Z,done. good catch. also i've modified `org.apache.kafka.clients.admin.{supported|finalized}versionrange` classes to make constructors non-public.,1,0.976164698600769
498093400,9001,kowshik,2020-10-01T09:04:48Z,would the default error message suffice?: `unable to update finalized features due to an unexpected server error.`,0,0.6921021938323975
498094043,9001,kowshik,2020-10-01T09:05:53Z,done.,0,0.9759407639503479
498113308,9001,kowshik,2020-10-01T09:38:02Z,"done. good point. it looks appropriate to me that we exit the broker in this case. i've captured the exception and added a call to `exit.exit(1)`, is there a better way to do it?",1,0.7040413618087769
498420758,9001,junrao,2020-10-01T17:55:31Z,"thinking about this a bit more. it seems that the intention of firstactiveversion is to avoid deploying a wrong version of the broker that causes the deprecation of a finalized feature version unexpectedly. however, the same mistake can happen with firstactiveversion since the deprecation of a finalized feature version is based on firstactiveversion. so, i am not sure if firstactiveversion addresses a real problem. in general, we tend to deprecate a version very slowly in ak. so, if the mistake is to deploy a new release that actually deprecates a supported version. old clients are likely all gone. so, moving finalized min version to supported min version may not cause a big problem. we can just document that people should make sure old versions are no longer used before deploying new releases. if the mistake is to deploy an old version of the broker whose maxsupportedversion is < maxfinalizedversion, we will fail the broker. so, this mistake can be prevented.",0,0.5954090356826782
498495464,9001,kowshik,2020-10-01T20:27:42Z,": i'd like to discuss an example that cites a problem i'm concerned about. let's say we have some feature `f` whose: * supported version range is: `[minversion=1, maxversion=6]` * existing finalized version range in the cluster is: `[minversionlevel=1, maxversionlevel=6]` now, let us say a point in time arrives when we need to deprecate the feature version `1`. let us say we bump up supported `minversion` to `2` in a subsequent major kafka release. before this new release is deployed, let us assume the cluster operator knows 100% that old clients that were using the feature at version `1` are gone, so this is not a problem. **problem:** still, if we deploy this new release, the broker will consider the following as a feature version incompatibility. * supported version range is: `[minversion=2, maxversion=6]` * existing finalized version range in the cluster is: `[minversionlevel=1, maxversionlevel=6]` upon startup of a broker thats using the new release binary, the above combination will crash the broker since supported `minversion=2` is greater than `minversionlevel=1`. basically the versioning system thinks that there is now a broker that does not support `minversionlevel=1`, which does not adhere to the rules of the system. we currently do feature version incompatibility checks during kafkaserver startup sequence, [a link]. here is my thought: this is where `firstactiveversion` becomes useful. by bumping it up during a release (instead of the supported feature's `minversion`), we are able to get past this situation. when `firstactiveversion`is advanced in the code, and the cluster is deployed, the controller (and all brokers) know that the advancement acts a request to the controller to act upon the feature deprecation (by writing the advanced value to the `featureznode`). so, in this case we would release the broker with the supported feature version range: `[minversion=1, firstactiveversion=2, maxversion=6]`, and the broker release wouldn't fail (because the intent is clearly expressed to the versioning system). what are your thoughts on the above? is there a different way to solve it better that i'm missing, without compromising the versioning checks enforced by the system?",0,0.805246114730835
498512579,9001,junrao,2020-10-01T21:04:51Z,": i was thinking what if we relax the current check by just making sure that maxversion of finalized is within the supported range. basically in your example, if supported minversion goes to 2, it's still allowed since it's less than maxversion of finalized. however, if supported minversion goes to 7, this fails the broker since it's more than maxversion of finalized. your concern for the relaxed check seems to be around deploying a wrong version of the broker by mistake. i am not sure if that's a big concern. if the wrong broker affects maxversion of finalized, the broker won't start. if the wrong broker affects minversion of finalized, if we deprecated slowly, it won't impact the existing clients.",0,0.5461778044700623
498574911,9001,kowshik,2020-10-02T00:38:05Z,"does the below feel right to you? the key thing seems to be that you feel it is rare to deprecate feature versions in ak. i agree with the same. so, i propose we just do not have to solve the deprecation problem in this pr, until we find a clear route that the ak community agrees with. in this pr i propose to revert the `firstactiveversion` change, leaving the rest of the things the way they are. in the future, we can develop a concrete solution for version deprecation i.e. the part on how to advance `minversion` of supported feature, may be (or may not be) using `firstactiveversion` or other ways (it is up for discussion, maybe in a separate kip). i have made this proposed change in the most recent commit: 4218f95904989028a469930d0c266362bf173ece. regarding your thought: there is a consequence to relaxing the current check: the controller can not effectively finalize `minversionlevel` for the feature, because, with a relaxed check we do not know whether all brokers in the cluster support a particular `minversion` when the controller finalizes the `minversionlevel` at a particular value. it seems useful to keep the concept of `minversionlevel` like the way it is now (i.e. it is the lowest version guaranteed to be supported by any broker in the cluster for a feature). and as i said above, in the future, we can decide on ways to mutate it safely (maybe through `firstactiveversion` or other means).",0,0.9277644753456116
498959506,9001,junrao,2020-10-02T17:39:15Z,"this this case, existingfeatureznode.features is expected to be empty? could we log a warn if this is not the case and always set finalized to empty?",0,0.9904041290283203
498960633,9001,junrao,2020-10-02T17:41:40Z,should we call updatefeatureznode() so that we can get the logging?,0,0.9892908930778503
498980025,9001,junrao,2020-10-02T18:19:31Z,"this test may not be enough. the issue is that when a controller fails over, it's possible that new brokers have joined the cluster during the failover. so, if existingfeatureznode is enabled, it may not be reflecting the state in those newly joined brokers. so, it seems that we need to do the validation for every broker during controller failover in that case.",0,0.9320901036262512
499034372,9001,junrao,2020-10-02T20:25:16Z,"""we do not know whether all brokers in the cluster support a particular minversion when the controller finalizes the minversionlevel at a particular value."" the controller knows the minsupportedversion for all brokers, right? what if we do the following? when finalizing a feature, the controllers uses the highest minsupportedversion across all brokers as finalizedminversion, as long as it's <= finalizedmaxversion. on broker restart, we also advance finalizedminversion if the new broker's minsupportedversion has advanced (assuming still <= finalizedmaxversion).",0,0.9851471781730652
499036138,9001,junrao,2020-10-02T20:29:54Z,could we make the constructor non-public?,0,0.9881855249404907
499036605,9001,junrao,2020-10-02T20:31:03Z,could we make the constructor non-public?,0,0.9881855249404907
499102118,9001,kowshik,2020-10-03T01:14:01Z,done.,0,0.9759407639503479
499102130,9001,kowshik,2020-10-03T01:14:05Z,done.,0,0.9759407639503479
499102146,9001,kowshik,2020-10-03T01:14:17Z,done.,0,0.9759407639503479
499102163,9001,kowshik,2020-10-03T01:14:24Z,done.,0,0.9759407639503479
499102176,9001,kowshik,2020-10-03T01:14:36Z,done. excellent catch.,1,0.9845113754272461
499102266,9001,kowshik,2020-10-03T01:15:32Z,"awesome. this is a very good point. the approach you proposed is very elegant, and we should shoot for it, when we’re giving the benefit of the doubt on deprecation to the broker binary version. i’ll update the kip with details and share with community for feedback. as soon as that is done, i'll follow up in separate pr implementing this logic.",1,0.9915390610694885
499739889,9001,junrao,2020-10-05T16:54:25Z,it's a bit weird that featureznode.status is defined as featureznodestatus.value. it seems that it should be defined as just featureznodestatus?,-1,0.9856958985328674
499740489,9001,junrao,2020-10-05T16:55:28Z,should we log the non-empty features too?,0,0.9869385957717896
499753420,9001,junrao,2020-10-05T17:18:52Z,should we revert the changes here?,0,0.9655971527099609
499761963,9001,junrao,2020-10-05T17:34:20Z,"this is probably not enough since it only waits for the controller path to be created in zk, which happens before the processing of the finalized features.",0,0.972615659236908
499775367,9001,junrao,2020-10-05T17:59:22Z,could we add feature to the javadoc above?,0,0.989028811454773
499776675,9001,junrao,2020-10-05T18:01:47Z,should we use a version > 0?,0,0.9860627055168152
499776894,9001,junrao,2020-10-05T18:02:14Z,typo thats,0,0.9779922366142273
499810462,9001,kowshik,2020-10-05T19:05:24Z,"done. i have improved it now introducing a type definition called `featureznodestatus` that points to `value`. iiuc you were referring to this loc, correct? [a link] here the enum: `featureznodestatus` is defined and used in the same file. i thought i'd add an `import` to fix it like the below, but it was a little unusual to add an `import` statement right above the class definition: [code block] with my recent change, in the future it should be possible to `import featureznodestatus._` within other files when referring to the enum value.",0,0.8178914785385132
499811265,9001,kowshik,2020-10-05T19:06:45Z,done.,0,0.9759407639503479
499811752,9001,kowshik,2020-10-05T19:07:42Z,done. nice catch!,1,0.9904513359069824
499812076,9001,kowshik,2020-10-05T19:08:21Z,done.,0,0.9759407639503479
499816373,9001,kowshik,2020-10-05T19:16:34Z,done. good point.,1,0.9535248279571533
499816619,9001,kowshik,2020-10-05T19:17:03Z,done.,0,0.9759407639503479
499847021,9001,kowshik,2020-10-05T20:16:35Z,done. please take a look at the fix. i've added logic to wait for processing on a dummy event just after waiting for controller election. i'm hoping this will make sure the controller failover logic is completed before the test proceeds further to make assertions.,0,0.9058220386505127
501418496,9001,chia7712,2020-10-08T02:53:08Z,"the error message says it can't be null but there is no null check. for another, this check can happen early (when creating [code block])",0,0.9836867451667786
501432770,9001,chia7712,2020-10-08T03:51:37Z,"should we add an empty-parameter variety for [code block]? that is similar to other methods, like [code block] and [code block].",0,0.9884861707687378
501489060,9001,chia7712,2020-10-08T06:58:43Z,the top-level error message is not propagated.,0,0.9462569952011108
501575432,9001,kowshik,2020-10-08T09:26:06Z,done. addressed in #9393.,0,0.9797093868255615
501575489,9001,kowshik,2020-10-08T09:26:11Z,done. addressed in #9393.,0,0.9797093868255615
501575519,9001,kowshik,2020-10-08T09:26:13Z,done. addressed in #9393.,0,0.9797093868255615
102111062,2476,becketqin,2017-02-21T00:13:51Z,the variable names seem a little misleading. are all partitions without leader information unauthorized?,0,0.5265405774116516
102111239,2476,becketqin,2017-02-21T00:16:05Z,should we use the exception returned by the broker in this case?,0,0.9851277470588684
102113712,2476,becketqin,2017-02-21T00:48:53Z,"when `client.poll(future, remaining)` returns true, the future may either contains a value (succeeded) or an error (failed). if the future has an error, calling `future.value()` will throw exception. it seems better if we can return the full results to the users even if some of the requests failed so the users will be able to know which partitions has failed to purge.",0,0.9854466915130615
102114179,2476,becketqin,2017-02-21T00:55:27Z,"it seems a single `consumernetworkclient.poll(0)` cannot guarantee all the requests are sent out. also, the interface might be a little weird that after `purgedatabefore()` is returned the users have to keep calling future.client.poll() otherwise the futures will not be completed. i am wondering how would user use the asynchronous purge in this case? at very least we should document this clearly.",-1,0.651828408241272
102114578,2476,becketqin,2017-02-21T01:00:08Z,this could just be a string concatenation.,0,0.9863307476043701
102116849,2476,becketqin,2017-02-21T01:29:45Z,this seems a little over optimizing. any reason we care about invoking time.milliseconds here more than in line 441 and everywhere else?,-1,0.6105510592460632
102117137,2476,becketqin,2017-02-21T01:33:37Z,should we log the partition information and which replica is unavailable here?,0,0.986771285533905
102117519,2476,becketqin,2017-02-21T01:38:43Z,should this be in write lock?,0,0.9891330599784851
102118327,2476,becketqin,2017-02-21T01:47:26Z,is this comment accurate?,0,0.9796374440193176
102118888,2476,becketqin,2017-02-21T01:54:33Z,nit: could be `mapvalues`.,0,0.9884772300720215
102119889,2476,becketqin,2017-02-21T02:06:32Z,"methods with three tuples as return value may be a little hard to follow, may be we can create a case class. at very least we should document each field of the return value.",0,0.9838972091674805
102121248,2476,becketqin,2017-02-21T02:22:07Z,do we want to distinguish between no_log_start_offset v.s. log_start_offset = 0? is it clearer to define the no_log_start_offset as -1?,0,0.9873560667037964
102146034,2476,lindong28,2017-02-21T07:37:14Z,agree. i have updated the names.,0,0.9772619009017944
102146077,2476,lindong28,2017-02-21T07:37:42Z,good point. i have updated code to use error from metadatarequest.,1,0.9785760045051575
102146450,2476,lindong28,2017-02-21T07:40:56Z,great point. i have updated the adminclient to create its own thread to do `client.poll(retrybackoffms)`. i find it necessary for adminclient to have its own thread in order to support both syn and async operation. i have also added `testlogstartoffsetafterasyncpurge()` to validate the asyn purge operation.,1,0.9504460096359253
102147486,2476,lindong28,2017-02-21T07:49:25Z,"this should not be a problem for `purgedatabefore()`, because those `futures` provided to the `compositefuture` has been constructed in such a way that they never raises exception. those future will call `future.complete(result)` in case of `onfailure`, where result indicates has the error information. i agree it would be make `compositefuture` more useful if this class handles the logic of converting error to result and return the full results to user as you suggested. but i don't have a good way to do it now because `compositefuture` doesn't know the type of the return value -- it currently use template `t`.",0,0.9032838940620422
102147741,2476,lindong28,2017-02-21T07:51:19Z,is there any negative impact to use stringbuilder as compared to string concatenation? using stringbuilder here allows us to have the same code style as `tostring()` of other requests such as `producerequest` and `leaderandisrrequest`.,0,0.9733366966247559
102147786,2476,lindong28,2017-02-21T07:51:46Z,good point. i have updated the log message as you suggested.,1,0.9386059045791626
102147860,2476,lindong28,2017-02-21T07:52:34Z,i think it is not bad to remove one unnecessary call to `time.milliseconds`. i removed it since you don't like it.,-1,0.9026557207107544
102148192,2476,lindong28,2017-02-21T07:55:22Z,i validated that we can not use `mapvalues()` here. this is because `mapvalues()` returns a map view which maps every key of this map to `f(this(key))`. the resulting map wraps the original map without copying any elements. as a result `status.ackspending = true` in the constructor of `delayedpurge` becomes no-op.,0,0.9878832697868347
102148242,2476,lindong28,2017-02-21T07:55:47Z,good point. i have updated the code to make it more readable.,1,0.9701927900314331
102148307,2476,lindong28,2017-02-21T07:56:18Z,"i think we should use readlock since this method doesn't update leader or isr of the partition, right?",0,0.9869317412376404
102148443,2476,lindong28,2017-02-21T07:57:24Z,it was not accurate. i have updated the comment to replace `all replicas of this broker` to `in-sync replicas of this broker`,0,0.7887640595436096
102148589,2476,lindong28,2017-02-21T07:58:36Z,i don't think it is necessary to distinguish between no_log_start_offset v.s. log_start_offset = 0. is there any use-case for no_log_start_offset?,0,0.9825831651687622
102260819,2476,becketqin,2017-02-21T17:01:27Z,"not much difference, just for readability (see below) we can keep them the same as other requests. [a link]",0,0.9848323464393616
102263429,2476,becketqin,2017-02-21T17:12:12Z,"yes, you are right. read lock here is fine.",0,0.8902125358581543
102265149,2476,becketqin,2017-02-21T17:19:34Z,"in general, we want to identify the state of the system as clear as possible. the follower should not take any action if the log_start_offset on the broker is no_log_start_offset. but if the follower sees the leader returning the starting offset = 0 while the actual starting offset on the leader is not, this introduces confusion.",0,0.934887170791626
102267118,2476,becketqin,2017-02-21T17:27:24Z,the kip stated that the consumer will put value -1l as the log_begin_offset.,0,0.9880362749099731
102267688,2476,becketqin,2017-02-21T17:29:46Z,"nit: in consumer we use the term ""earliest"" instead of ""smallest"", maybe we can make the term consistent.",0,0.9860410094261169
102269297,2476,becketqin,2017-02-21T17:37:30Z,maybe we should always use the latest version here?,0,0.9849003553390503
102269853,2476,becketqin,2017-02-21T17:39:51Z,latest version?,0,0.9786958694458008
102289505,2476,lindong28,2017-02-21T19:04:23Z,agree. i have updated the code to test all versions of fetchresponse.,0,0.9761562943458557
102289533,2476,lindong28,2017-02-21T19:04:33Z,sure. updated to use latest version here.,0,0.9467377662658691
102289562,2476,lindong28,2017-02-21T19:04:42Z,sure. made the change.,0,0.9654320478439331
102289627,2476,lindong28,2017-02-21T19:04:58Z,nice catch. updated to use -1l here.,1,0.9767023324966431
103133485,2476,becketqin,2017-02-27T03:54:41Z,"the comment is a little confusing here. how about ""the offset before which the messages will be deleted.""",-1,0.6657032370567322
103134243,2476,becketqin,2017-02-27T04:09:47Z,sleeping here seems not ideal and may miss subsequent action invoked by the users. we probably want to have a long poll() and just wake up the networkthread when needed.,0,0.5969557166099548
103134387,2476,becketqin,2017-02-27T04:12:42Z,"since we have separate thread now, retry could be done without involving users, right?",0,0.9861072301864624
103136031,2476,becketqin,2017-02-27T04:45:50Z,nit: can we just call it timebeforelocalpurge?,0,0.9861207604408264
103136983,2476,becketqin,2017-02-27T05:02:36Z,"if we want to make this optimization, we should do it in line 330 as well.",0,0.9852578043937683
103138261,2476,becketqin,2017-02-27T05:26:55Z,the earliest offset allowed...,0,0.9861998558044434
103138990,2476,becketqin,2017-02-27T05:38:11Z,"the statement here is a little misleading. logstartoffset is not used to ""decide"" the log retention. the log retention is still based on time/size limit. the logstartoffset will be updated by retention. a manual update of logstartoffset may trigger the log deletion.",0,0.9729951024055481
103139730,2476,becketqin,2017-02-27T05:49:15Z,"hmm, why would truncation change the startlogoffset? shouldn't truncation always be above the startlogoffset?",0,0.9630688428878784
103140001,2476,becketqin,2017-02-27T05:53:11Z,"the update of logstartoffset should probably be synchronized and ensure no rewind will happen, otherwise a fetch request may see an incorrect logstartoffset.",0,0.9823299050331116
103140524,2476,becketqin,2017-02-27T06:00:58Z,"it seems we should be careful about when to delete the log segments. in the current code, when the leader deleted an old log segment. the low watermark will not increase immediately because the followers has not updated the logstartoffset yet. however, at this point if user tries to fetch from lw, they will receive an offset out of range exception, which is not expected. one solution would be letting the segment deletion to be based on the low watermark instead of logstartoffset. so we need to delay the log deletion until low watermark is updated. similarly the valid range of fetch request should be based on lw instead of logstartoffset. nit: there is an existing typo in line 729, which missed a ""t"" in ""deleteretentionmsbreachedsegments()"".",0,0.9804500341415405
103140662,2476,becketqin,2017-02-27T06:02:53Z,"should it be an error to truncate beyond the logstartoffset? logstartoffset should not decrease, right?",0,0.9785674214363098
103140993,2476,becketqin,2017-02-27T06:07:48Z,"it seems that we should also checkpoint low watermarks, right?",0,0.9820597171783447
103272179,2476,lindong28,2017-02-27T18:07:47Z,"when there is no pending requests, `consumernetworkclient.poll(...)` blocks for up to `retrybackoffms`. it means the thread does poll() in kind of busy looping manner if we don't sleep here. also, the thread holds the lock on `consumernetworkclient` while blocked on `selector.poll()` which means the user will be blocked waiting for lock in order to enqueue requests.",0,0.980830192565918
103273306,2476,lindong28,2017-02-27T18:13:28Z,"yes we can, if we ask user to specify retries num and retry back off. current implementation assumes retries = 1. this seems like an optimization which may be added later?",0,0.9880901575088501
103273330,2476,lindong28,2017-02-27T18:13:35Z,sure. fixed now.,0,0.9448716044425964
103273660,2476,lindong28,2017-02-27T18:15:11Z,"do you mean `debug(""produce to local log in %d ms"".format(time.milliseconds - stime))`? i thought this `time.milliseconds` will only be evaluated if debug level logging is enabled, no?",0,0.9883769154548645
103274743,2476,lindong28,2017-02-27T18:20:09Z,sure. fixed now.,0,0.9448716044425964
103275187,2476,lindong28,2017-02-27T18:22:19Z,fixed.,0,0.9810503125190735
103276622,2476,lindong28,2017-02-27T18:28:41Z,"i include this scenario because i couldn't provide that log truncation will always be above the logstartoffset. for example, we have had bug such that log may be truncated below high watermark in case of double failure.",0,0.9827535152435303
103276835,2476,lindong28,2017-02-27T18:29:37Z,sure. i changed it to `log deletion`.,0,0.9863634705543518
103288992,2476,lindong28,2017-02-27T19:23:42Z,good point. i just added `lock` around this.,1,0.9239251017570496
103293344,2476,lindong28,2017-02-27T19:42:11Z,"sure, the typo is fixed. in the current implementation, if user seeks to earliest offset, he/she will seek to the `logstartoffset` of the leader regardless of what is the low watermark. user will not seek to lw since lw is not even exposed to the user. is there any concern with this approach?",0,0.9846871495246887
103295145,2476,becketqin,2017-02-27T19:49:35Z,"if poll() itself is not a busy looping internally, we will not have a busy loop (even though it look like so). however, in the current case, if retry back off is set to 0, we do have a busy poll(). holding a lock and blocking on selector.poll() is strange, maybe we should reconsider that. even if that is true, we can still have a queue outside of the consumernetworkclient and wake up the sender thread to poll from that queue.",0,0.7473127245903015
103295641,2476,lindong28,2017-02-27T19:51:32Z,if everything is implemented correctly then log start offset should not decrease. but in reality we have seen unlean leader election during double failure where the logendoffset is truncated beyond high watermark. it seems safer to preserve the existing behavior of `truncateto()` and allow logstartoffset to be reduced if such truncation does happen instead of throwing exception. note that such truncation will only happen as part of unclean leader election initiated by the brokers themselves.,0,0.9802199006080627
103295886,2476,lindong28,2017-02-27T19:52:40Z,"no, we intentionally only checkpoint logstartoffset. is there any reason to checkpoint lowwatermark?",0,0.9757600426673889
103307226,2476,becketqin,2017-02-27T20:43:41Z,it will call `time.milliseconds` because it is an argument passed to the `debug()`.,0,0.9874901175498962
103307455,2476,becketqin,2017-02-27T20:44:49Z,"if it is not an expected behavior, we should throw some exception instead of allowing the lw to decrease, right?",0,0.976520836353302
103310427,2476,ijuma,2017-02-27T20:58:41Z,"i'm a bit confused about the discussion here, so i'll just explain how it works. :) whatever one passes as a parameter to `debug` is only evaluated if debug logging is enabled. at runtime, a `function0` is passed and the body of that function is the block of code passed as the parameter to `debug`. does that make sense?",1,0.9576717615127563
103362427,2476,becketqin,2017-02-28T02:16:09Z,"thanks for the clarification . you are right, i realized that after taking a closer look.",1,0.9331782460212708
103580604,2476,lindong28,2017-02-28T23:49:38Z,"discussed offline. given that existing apis such as `adminclient.listgroupoffsets(..)` and `kafkaconsumer.retrieveoffsetsbytimes(..)` would not retry and just expose the exception to user, it should be ok for `adminclient.purgedatabefore(...)` to do the same thing. if we think it is useful to retry for user, we probably want to discuss the new configs and do it in java adminclient as part of kip-117.",0,0.9841646552085876
103580824,2476,lindong28,2017-02-28T23:51:17Z,"discussed offline. given that `log.truncateto(...)` has explicitly consider the case that the targetoffset is smaller than base offset of the first log segment, it would be safer and simpler for us to assume that `log.truncateto(...)` can truncate to an offset smaller than logstartoffset.",0,0.9865338802337646
103580946,2476,lindong28,2017-02-28T23:52:03Z,"discussed offline. given that log.truncateto(...) has explicitly consider the case that the targetoffset is smaller than base offset of the first log segment, it would be safer and simpler for us to assume that log.truncateto(...) can truncate to an offset smaller than logstartoffset.",0,0.9855776429176331
103595573,2476,lindong28,2017-03-01T01:49:32Z,"i have updated the adminclient to remove the sleep operation. and the patch guarantees that if user thread attempts to send any request, it will get the lock on consumernetworkclient and enqueue the requests once the currehnt `client.poll(..)` exits. the user thread may still wait up to `maxretrybackoffms` in order to send the requests as of current implementation. this is because `consumernetworkclient.poll(...)` does not guarantee that it will unblock and send the request if there is available request to be send by `consumernetworkclient.send(...)`. the problem exists even if we have a queue outside of consumernetworkclient and use only one thread to call `consumernetworkclient.poll(...)` and `consumernetworkclient.send(...)`. having user thread wake up consumer may help reduce the chance of unnecessary block but doesn't prevent this from happening. ideally we want to be able to fix consumernetworkclient so that user's request should get sent immediately if there is no other inflight requests. but it turns out to be a non-trivial fix. the problem is that `consumernetworkclient.poll(...)` will hold the lock of `consumernetworkclient` while it is blocked on `nioselector.select(ms)`. if user calls `nioselector.wakeup()`, it may be lost if the sender thread is right before the `nioselector.select(ms)` while `nioselector.wakeup()` is called. if user attempt to get the lock of `consumernetworkclient` before calling `nioselector.wakeup()`, then it will block as well while trying to get the lock. we need to find a way for the `poll(...)` to release lock while it is waiting on `nioselector.select(ms)`. but i don't have an easy way to fix it.",0,0.9777416586875916
103671647,2476,ijuma,2017-03-01T12:21:50Z,"i didn't see this mentioned in the kip. this is a user facing cli tool, so we should mention it there.",0,0.9879010915756226
103671752,2476,ijuma,2017-03-01T12:22:42Z,"we can only do this once there's agreement that the next release is 0.11.0. luckily, i started that discussion recently and people seem to be in favour. :)",1,0.9551263451576233
103671959,2476,ijuma,2017-03-01T12:23:50Z,"since 0.10.0, we do the `iv0` thing (e.g. `kafka_0_11_0_iv0`). the version string should be changed accordingly.",0,0.9887202382087708
103672175,2476,ijuma,2017-03-01T12:25:02Z,an empty synchronized block doesn't do anything. is this still in progress?,0,0.9289977550506592
103681117,2476,ijuma,2017-03-01T13:21:02Z,"just so that we are on the same page. until this method is available in the java adminclient, there is no public api for it (i.e. the scala `adminclient` is an internal class), right? so, the tool is the only way to do it if one doesn't want to deal with breakage later.",0,0.9841670393943787
103748555,2476,lindong28,2017-03-01T18:00:15Z,i included it as a way for myself and probably reviewers to test the patch. i was not sure if it needs to be included in the patch. let me propose it in the mailing thread and specify it in the kip. i am ok to remove it if others don't think it is necessary.,0,0.9561960101127625
103748701,2476,lindong28,2017-03-01T18:00:59Z,great. thanks for confirmation :),1,0.9926552772521973
103749257,2476,lindong28,2017-03-01T18:03:45Z,i see. i changed this to `kafka_0_11_0_iv0`.,0,0.9667204022407532
103750145,2476,lindong28,2017-03-01T18:08:14Z,"it is actually needed as a way for user thread to get the lock to enqueue requests once sender thread has finished its current `client.poll(...)`. even though it is empty, this synchronzed block is still useful because some other thread may have the lock here. this trick will no longer be needed after kafka-4820 is committed.",0,0.9875779747962952
103751509,2476,lindong28,2017-03-01T18:14:51Z,have we explicitly stated in the code or documentation that this class is internal and should not be used by users? becket is not aware of this as well. it seems that user can already construct scala adminclient directly and that is how i expect this api to be used.,0,0.9515290856361389
103792810,2476,ijuma,2017-03-01T21:25:42Z,"since this is going away, i won't comment further. :)",1,0.9779621362686157
103793255,2476,ijuma,2017-03-01T21:27:59Z,i see. sounds good to ask in the mailing list thread if people think it's useful.,1,0.9265326261520386
103793302,2476,ijuma,2017-03-01T21:28:15Z,"if we keep this class, we need to update the comment.",0,0.9861689805984497
103794835,2476,ijuma,2017-03-01T21:35:34Z,"by the way, i think the code as it is now is a bit dangerous. imagine that there are some changes and this field starts being used in info logging. it's not unlikely that a bug will be introduced. is this optimisation really worth doing?",-1,0.5420988202095032
103795078,2476,ijuma,2017-03-01T21:36:36Z,what is the reason for this change?,0,0.9308848977088928
103795243,2476,ijuma,2017-03-01T21:37:29Z,what is the reason for this change?,0,0.9308848977088928
103796063,2476,ijuma,2017-03-01T21:41:20Z,"the vast majority of kafka code is not public api. the somewhat unintuitive way that public api is defined at the moment is by what has javadoc published: [a link] apart from that, the old producers and consumers are also public api (until we remove them). the admin package is definitely internal and that's why there was no kip for the scala adminclient when it was added in 0.9.0.0 (or any of the changes since).",0,0.9640734195709229
104300596,2476,lindong28,2017-03-05T00:07:59Z,ok. the optimization is removed now.,0,0.9855076670646667
104300644,2476,lindong28,2017-03-05T00:09:59Z,discussed offline. the issue is resolved after we change the definition of lowwatermark to be the minimum logstartoffset of all live replicas.,0,0.9863389730453491
104300648,2476,lindong28,2017-03-05T00:10:22Z,discussed offline. we don't need to checkpoint lowwatermark.,0,0.9721898436546326
104300660,2476,lindong28,2017-03-05T00:11:23Z,i have updated the kip to include this script and email the mailing thread about this addition. there is no objection so far. i assume we can include this script in the patch.,0,0.9764198064804077
104300670,2476,lindong28,2017-03-05T00:12:10Z,the `synchronized` has been removed in the patch after rebasing the patch onto the trunk. kafka-4820 has been committed to the trunk.,0,0.9884379506111145
104300696,2476,lindong28,2017-03-05T00:14:58Z,i see. i think the method is available in two ways. user can use the script without having to deal with breakage later. and user can also uses our internal api and will need to deal with breakage later. linkedin kafka team will use the second solution and is ok to deal with breakage later.,0,0.869102954864502
104300714,2476,lindong28,2017-03-05T00:16:25Z,"thanks. i have updated the comment to ""a command for purging data of given partitions to the specified offset.""",1,0.9404352307319641
104300777,2476,lindong28,2017-03-05T00:19:27Z,it is a side effect of making change and reverting change in the process of implementing this patch. i have changed it to the original order.,0,0.790318489074707
104301004,2476,lindong28,2017-03-05T00:38:27Z,i thought `setup()` and `teardown()` will be executed once for every test method (e.g. testconsumeafterpurge) but the initialization of `consumers` in `trait integrationtestharness` will be executed only once per test class (e.g. adminclienttest). i am wrong. i have reverted this change.,-1,0.9642851948738098
104834321,2476,junrao,2017-03-08T02:56:13Z,we probably want to add a comment that this is only used in the fetch requests from the followers.,0,0.9874128103256226
104834398,2476,junrao,2017-03-08T02:57:11Z,could we adjust the comment above accordingly?,0,0.9867245554924011
104834503,2476,junrao,2017-03-08T02:58:43Z,do we need to override this method to public?,0,0.9766321778297424
104834563,2476,junrao,2017-03-08T02:59:22Z,unused import,0,0.9649426341056824
104834590,2476,junrao,2017-03-08T02:59:42Z,"hmm, not sure about this. in general networkclient is not thread safe.",-1,0.7204150557518005
104834673,2476,junrao,2017-03-08T03:00:18Z,it's kind of weird to use a consumernetworkclient to implement purgedatabefore() since this api has nothing to do with consumer.,-1,0.9860894680023193
104834719,2476,junrao,2017-03-08T03:01:01Z,unused import,0,0.9649426341056824
104834774,2476,junrao,2017-03-08T03:01:42Z,%s => %d for oldlowwatermark and newlowwatermark,0,0.9707231521606445
104834848,2476,junrao,2017-03-08T03:02:37Z,"hmm, should we take max here?",0,0.9775320291519165
104834900,2476,junrao,2017-03-08T03:03:15Z,"to be consistent with the logic in recovery, should we initialize this to baseoffset?",0,0.9875996112823486
104834928,2476,junrao,2017-03-08T03:03:39Z,could we add the new param to javadoc above and adjust the comment accordingly?,0,0.9882999658584595
104834990,2476,junrao,2017-03-08T03:04:21Z,d% => %d,0,0.9286184310913086
104835046,2476,junrao,2017-03-08T03:05:03Z,unused import,0,0.9649426341056824
104835080,2476,junrao,2017-03-08T03:05:32Z,hasenough => lowwatermarkreached ?,0,0.9843555092811584
104835108,2476,junrao,2017-03-08T03:06:03Z,could we just reuse logflushoffsetcheckpointintervalmsprop instead of introducing a new config?,0,0.9881171584129333
104835196,2476,junrao,2017-03-08T03:07:03Z,should the comment be changed to all live replicas?,0,0.9849928617477417
104835279,2476,junrao,2017-03-08T03:08:04Z,"do we want to poll with 0 since it can burn cpu unnecessarily? also, instead of duplicating the code for waiting the consumer to be ready, could we factor it out to a private method and reuse?",0,0.9575298428535461
104835345,2476,junrao,2017-03-08T03:08:58Z,is there a need to test async? it seems the sync test is enough?,0,0.9864761233329773
104835380,2476,junrao,2017-03-08T03:09:23Z,"instead of the sleeping for a fixed amount of time, it would be better to do the checking in a waituntiltrue() method.",0,0.9855673313140869
104840525,2476,lindong28,2017-03-08T04:11:36Z,good point. maybe we should specify this in the explanation of the field instead of in the comment? i added following to the field's doc: the field is only used when request is sent by follower. for simplicity i didn't specify that the field will be set to -1 if the request is sent by consumer.,1,0.648045539855957
104840843,2476,lindong28,2017-03-08T04:16:38Z,ah i should have updated the comment here. it is updated now.,0,0.9732121825218201
104841044,2476,lindong28,2017-03-08T04:19:13Z,my bad. i have changed it back to protected.,-1,0.9853869676589966
104841196,2476,lindong28,2017-03-08T04:21:38Z,thanks. fixed now.,1,0.8842014074325562
104841282,2476,lindong28,2017-03-08T04:22:59Z,yeah `networkclient` is not thread-safe. but `consumernetworkclient` explicitly stated in its java doc that it is thread-safe.,0,0.9781650900840759
104841527,2476,lindong28,2017-03-08T04:26:14Z,"i agree this name is a bit weird. maybe we should either rename this class, or implement another `xxxnetworkclient` class to be used for sending requests by java adminclient in the future. as of now i don't have a simple solution for this. i think we can keep it as is and think more thoroughly in the java adminclient. what do you think?",-1,0.971921980381012
104841631,2476,lindong28,2017-03-08T04:27:50Z,"sorry, i thought checkstyle will catch all unused import but i am wrong. it seems that checkstyle only does this check for java files. will check it manually in the future.",-1,0.9831125140190125
104841846,2476,lindong28,2017-03-08T04:30:57Z,thanks. fixed in both messages.,1,0.8991368412971497
104842139,2476,lindong28,2017-03-08T04:35:40Z,"if we truncate log using `truncatefullyandstartat` to an offset that is higher than the `logstartoffset`, i think we should keep the logstartoffset not changed instead of increasing it, right? it seems similar to the existing logic of updating `recoverypoint`, where we use `math.min`. another argument is that it is safer to assume a small logstartoffset.",0,0.9804609417915344
104842737,2476,lindong28,2017-03-08T04:43:59Z,"i think we still need to set this to -1 initially so that we can call `nextoffsetfromlog()` the first time we access `nextoffset()`. the longer answer: we can set initialize this to `baseoffset` in recovery because we will read all entries in `recovery()`. in the scenario that we do not call `recover()`, we need to initialize `nextoffset` to the `nextoffset` of the latest entry in the log segment file. to trigger this, we need to initialize `nextoffset` to -1 and call `nextoffsetfromlog()` the first time we access `nextoffset()`.",0,0.9821589589118958
104847614,2476,lindong28,2017-03-08T05:38:08Z,good point. it is updated now.,1,0.9704434275627136
104847763,2476,lindong28,2017-03-08T05:39:01Z,my bad. thanks for catching this! fixed now.,-1,0.9777461290359497
104847789,2476,lindong28,2017-03-08T05:39:14Z,fixed now.,0,0.9813029170036316
104848112,2476,lindong28,2017-03-08T05:40:57Z,sure. replaced `hasenough` with `lowwatermarkreached`.,0,0.9882286787033081
104849219,2476,lindong28,2017-03-08T05:49:11Z,"i am not sure. it seems safer to have a separate config. the current default value of `logflushoffsetcheckpointintervalms` is 60 seconds. but we probably want logflushstartoffsetcheckpointintervalms to be set to a lower value because if a broker fails after user purge data but before the logstartoffset is checkpointed, the offset may not be preserved. having separate configs allows user to tradeoff between disk write overhead and logstartoffset persistence. also, it is probably cheaper to checkpoint logstartoffset than checkpointing recoveroffset. we only need to checkpoint logstartoffset for a partition if its logstartoffset > baseoffset, which only happens when user has explicitly requested data purge. thus the actually amount of data written to the log-start-offset-checkpoint file is probably much less than the data written to recovery-point-offset-checkpoint. this means that we can set logflushstartoffsetcheckpointintervalms to a lower value without worrying too much about its overhead.",0,0.960026204586029
104849362,2476,lindong28,2017-03-08T05:50:56Z,thanks! updated now.,1,0.9498429298400879
104849612,2476,lindong28,2017-03-08T05:53:58Z,it seems that we don't have to worry about cpu burn because `testutils.waituntiltrue()` will wait for 100l between calls to `poll(0)`. sure. i updated the patch to move this wait logic into a separate method.,0,0.962180495262146
104851102,2476,lindong28,2017-03-08T06:09:38Z,it is no longer needed after we add a dedicated thread in adminclient to do `poll()`. removed now.,0,0.9857123494148254
104851560,2476,lindong28,2017-03-08T06:15:06Z,this test with offline brokers is needed when we define lw to min offset of all replicas. but it is not needed anymore after we change it to beh min offset of all live replicas. i simply removed this part.,0,0.9875065088272095
105036939,2476,lindong28,2017-03-08T22:11:18Z,thought about this more. i think we should just set `logstartoffset` to `newoffset`. the reason is that `truncatefullyandstartat(...)` is supposed to create a new log. thus `logstartoffset` should be the same as `baseoffset` of the first segment.,0,0.9805629253387451
105060654,2476,junrao,2017-03-09T00:29:07Z,"ok, we can leave it as it is.",0,0.9848410487174988
105060659,2476,junrao,2017-03-09T00:29:10Z,"yes, that makes sense.",0,0.9645439386367798
105060668,2476,junrao,2017-03-09T00:29:15Z,"yes, that works. it's just that if we initialize to baseoffset (which is what nextoffsetfromlog() will return on an empty segment), _nextoffset is always initialized properly and we probably can get rid of the if test in nextoffset().",0,0.9842931628227234
105067509,2476,lindong28,2017-03-09T01:20:50Z,"i am not sure we can get rid of the if test in `nextoffset()`. suppose we initialize `_nextoffset` to `baseoffset` and the segment is not empty, when should we call `nextoffsetfromlog()` in order to set `_nextoffset` to the correct value? currently we need the if test in `nextoffset()` to call `nextoffsetfromlog()` on the first invocation of `nextoffset()`. did i miss something?",0,0.8771193623542786
105333239,2476,junrao,2017-03-10T05:30:29Z,could this be private?,0,0.9868327379226685
105333267,2476,junrao,2017-03-10T05:30:54Z,thanks for the explanation. then this is fine.,1,0.5661296844482422
105567622,2476,lindong28,2017-03-12T20:11:43Z,yeah it should be private. i will change it.,0,0.970183253288269
106523663,2476,becketqin,2017-03-16T20:31:18Z,should this be `leader_not_available` instead?,0,0.9842409491539001
106525699,2476,becketqin,2017-03-16T20:40:21Z,"do we want to wait until the networkthread to exit before closing the `consumernetworkclient`? otherwise there will be some exception thrown and logged, which seems no ideal.",0,0.9325199127197266
106527195,2476,becketqin,2017-03-16T20:47:31Z,can we use a macro instead?,0,0.9877802133560181
106549682,2476,becketqin,2017-03-16T22:47:38Z,the terminology lso is also used by kip-98 as last stable offset. just a note so that we do not introduce confustion.,0,0.9889717698097229
106550281,2476,becketqin,2017-03-16T22:51:38Z,what is lbo?,0,0.9851040244102478
106550413,2476,becketqin,2017-03-16T22:52:31Z,hw -> lw,0,0.9300791621208191
106550867,2476,becketqin,2017-03-16T22:55:53Z,would it be safer to set the initial value to -1l if it is only kept on the leader?,0,0.9847097992897034
106551121,2476,becketqin,2017-03-16T22:57:58Z,nit: we usually do not use the `_*` pattern in apache kafka.,0,0.9842490553855896
106551960,2476,becketqin,2017-03-16T23:03:44Z,attempt => attempting,0,0.9799585938453674
106560377,2476,becketqin,2017-03-17T00:09:41Z,shouldn't this be -1l?,0,0.9597005248069763
106568532,2476,becketqin,2017-03-17T01:29:44Z,we can probably make those methods protected.,0,0.9868348240852356
106569363,2476,becketqin,2017-03-17T01:40:25Z,this number seems a little too large for deleterecordsrequest.,0,0.8885687589645386
106571166,2476,becketqin,2017-03-17T02:03:40Z,this could be [code block],0,0.9882047176361084
106586044,2476,lindong28,2017-03-17T05:24:34Z,thanks. good catch. fixed now.,1,0.9841452240943909
106587187,2476,lindong28,2017-03-17T05:40:53Z,"are you suggesting to wait for networkthread to exit before or after calling `client.close()`? if we call `client.close()` first, we can not prevent error from being logged because `selector.close()` will log error. if we wait for networkthread to exit first, then close() may become a blocking call which seems unnecessary. i agree with you that we do not want to throw exception here. but i am not sure why we should not log any error here. for example, `selector.close()` may log error if there is `ioexception`. i have updated the code to catch exception. does this address the problem?",0,0.9125113487243652
106587383,2476,lindong28,2017-03-17T05:43:42Z,sure. fixed now.,0,0.9448716044425964
106587470,2476,lindong28,2017-03-17T05:45:01Z,sure. replaced `lso` with `logstartoffset`.,0,0.9882524609565735
106587521,2476,lindong28,2017-03-17T05:45:44Z,good catch. thanks. it means logbeginoffset. replaced it with logstartoffset.,1,0.9884534478187561
106587539,2476,lindong28,2017-03-17T05:46:07Z,thanks. fixed now.,1,0.8842014074325562
106587752,2476,lindong28,2017-03-17T05:49:36Z,"i used `_*` here because we have methods `lastcaughtuptimems`, `logstartoffset` and `lowwatermark`. what would you suggest to name these variables?",0,0.9881271719932556
106587831,2476,lindong28,2017-03-17T05:50:30Z,sure. changed it to -1l.,0,0.9748820066452026
106587893,2476,lindong28,2017-03-17T05:51:13Z,fixed now.,0,0.9813029170036316
106587916,2476,lindong28,2017-03-17T05:51:32Z,good catch. fixed now.,1,0.9816462397575378
106588046,2476,lindong28,2017-03-17T05:53:18Z,good point. i changed it to 1.,1,0.9146216511726379
106588193,2476,lindong28,2017-03-17T05:55:28Z,cool. fixed now.,1,0.9801456332206726
106767687,2476,becketqin,2017-03-18T00:47:23Z,"it seems that if any exception is thrown from the network thread, the futures that have been returned will not be completed forever. ideally we will want to have those futures get an exception so that users do not wait on that indefinitely.",0,0.9732649922370911
106770832,2476,lindong28,2017-03-18T02:29:49Z,thanks for your review! i have fixed it in the last commit.,1,0.9828287959098816
106821825,2476,junrao,2017-03-19T23:00:48Z,should we update upgrade.html?,0,0.9870424270629883
106821828,2476,junrao,2017-03-19T23:00:59Z,should we rename offset to sth like fetchoffset so that it's clear how it's different from logstartoffset?,0,0.9862913489341736
106821831,2476,junrao,2017-03-19T23:01:08Z,should we follow the convention by nesting partitions inside topics?,0,0.9850487112998962
106821839,2476,junrao,2017-03-19T23:01:25Z,"so, we are not calling maybeincrementleaderlw() when the old segments are deleted? this means that lw may not be accurate when there is only 1 replica?",0,0.949444591999054
106821844,2476,junrao,2017-03-19T23:01:34Z,"hmm, it seems that we should be using the logstartoffset from the follower, not from the leader?",0,0.9801185131072998
106821857,2476,junrao,2017-03-19T23:01:55Z,"if we modify the log, we should probably coordinate this with the log cleaner. in logmanager.truncateto(), we first abort the ongoing cleaning, then truncate and finally resume the cleaning. we probably should do the same here.",0,0.9868107438087463
106821867,2476,junrao,2017-03-19T23:02:15Z,should we adjust the comment above accordingly?,0,0.9830576777458191
106821871,2476,junrao,2017-03-19T23:02:27Z,"hmm, the change doesn't seem right. the first value should be startoffset and the second value should be logstartoffset?",0,0.9118920564651489
106821879,2476,junrao,2017-03-19T23:02:53Z,"is this comment still correct? i thought we check the delete offset is smaller than hw, which is less than log end offset?",0,0.9883973002433777
106821907,2476,junrao,2017-03-19T23:03:49Z,"is it important to track this metric, especially at partition level, given deleterecords is a rare operation?",0,0.9765331149101257
106821909,2476,junrao,2017-03-19T23:04:03Z,"hmm, could timestampoffset.offset be < localreplica.logstartoffset? it seems that the result returned from fetchoffsetfortimestamp() guarantees that timestampoffset.offset >= localreplica.logstartoffset?",0,0.9887129068374634
106821916,2476,junrao,2017-03-19T23:04:13Z,this is not a produce response.,0,0.8885250091552734
106821917,2476,junrao,2017-03-19T23:04:19Z,do we need this to be 10000? could we make it 60000?,0,0.98499596118927
106821918,2476,junrao,2017-03-19T23:04:23Z,log begin offset => log start offset?,0,0.9876995086669922
106821926,2476,junrao,2017-03-19T23:04:40Z,"it seems that logstartoffset is only needed in replicafetcherthread. instead of adding it in partitionfetchstate, perhaps it's simpler to just add it here by calling getlogstartoffset()?",0,0.9866595268249512
106821934,2476,junrao,2017-03-19T23:04:54Z,"if we do this, perhaps there is no need to pass in metadatacache through methods like becomeleaderorfollower() and maybeupdatemetadatacache()?",0,0.9869723916053772
106837370,2476,lindong28,2017-03-20T05:48:26Z,i am not sure we have that convention. this is the same pattern used by `reassignpartitionscommand`. i can change it if you think the other pattern is better.,0,0.921237587928772
106837391,2476,lindong28,2017-03-20T05:49:00Z,i didn't change it in order to reduce the amount of code change and conflicts with other patches. i will change it as you suggested.,0,0.9853439927101135
106838059,2476,lindong28,2017-03-20T06:03:20Z,"it seems ok because when there is no follower, lw is only used in the `purgeresponse` to tell user whether purge has finished. in this case the `purgerequest` would have triggered `maybeincrementleaderlw`.",0,0.9882093667984009
106838930,2476,lindong28,2017-03-20T06:20:34Z,good point. i have updated code so that `deletelogstartoffsetbreachedsegments` is called periodically by `logmanager` for non-compact topics and by `logcleaner` compact topics. `deleterecordsrequest` only needs to update `logstartoffset` of the `replica`.,1,0.9379317164421082
106839374,2476,lindong28,2017-03-20T06:27:55Z,sure. i updated the comment to say `return error on attempt to read beyond the log end offset or read below log start offset`. is this ok?,0,0.9855623245239258
106840055,2476,lindong28,2017-03-20T06:40:15Z,you are right. it is wrong after we add that check. i have removed this comment.,0,0.9368065595626831
106840295,2476,lindong28,2017-03-20T06:44:02Z,it is not important. i added it because we have similar per-partition metrics in `delayedproduce`. i realized that we don't per-partition metrics in `delayedfetch`. it is removed now.,0,0.9473802447319031
106840866,2476,lindong28,2017-03-20T06:52:31Z,good point. it is removed now.,1,0.9586325287818909
106840929,2476,lindong28,2017-03-20T06:53:38Z,my bad. i have corrected this comment now.,-1,0.9879717230796814
106841258,2476,lindong28,2017-03-20T06:59:03Z,"i like this to be smaller to reduce the chance that a logstartoffset updated by deleterecordsrequest is lost. this is useful e.g. if there is only one replica and the broker may crash. anyway, i will change it to 60 sec.",1,0.5921877026557922
106841300,2476,lindong28,2017-03-20T06:59:37Z,sure. fixed now.,0,0.9448716044425964
106843753,2476,lindong28,2017-03-20T07:28:19Z,oops... good point! thanks! i fixed the bug by passing `followerlogstartoffset` to `updatelogreadresult` via `logreadresult`.,1,0.9913359880447388
106843969,2476,lindong28,2017-03-20T07:30:10Z,i think the original error message is probably wrong. why the range of log segments depend on an offset provided by the user?,0,0.9107196927070618
106844614,2476,lindong28,2017-03-20T07:37:08Z,`logstartoffset` is also needed in `replicamanager.readfromlocallog`. it seems reasonable to include it in the `fetchrequest.partitiondata` since `fetchrequest.partitiondata` is supposed to contain the same fields of `protocol.fetch_request_partition_v1`. does this make sense?,0,0.9880239367485046
106844878,2476,lindong28,2017-03-20T07:40:41Z,"sure. i have updated the code to remove `metadatacache` from parameters of methods `becomeleaderorfollower`, `maybeupdatemetadatacache` and `makefollowers`.",0,0.9832342863082886
106845566,2476,lindong28,2017-03-20T07:50:07Z,hmm.. i wasn't aware i need to change upgrade.html. i will do it tomorrow.,0,0.8321681022644043
106956008,2476,lindong28,2017-03-20T16:58:20Z,"sorry, i missed the first `%d` in the message. i have corrected this now.",-1,0.9882616400718689
107039812,2476,junrao,2017-03-20T23:13:42Z,"ok, we can leave this as it is since the /admin/reassign_partitions path in zk already follows the same pattern.",0,0.9890224933624268
107039880,2476,junrao,2017-03-20T23:14:13Z,"if lw is only used for deleterecordresponse, do we need to store and maintain it in replica? could we just compute it on the fly when serving deleterecordrequests?",0,0.9884849190711975
107039905,2476,junrao,2017-03-20T23:14:24Z,"so, deleterecordsrequest can't be applied on a compacted topic? should we return an error code in the response in that case?",0,0.97944176197052
107039943,2476,junrao,2017-03-20T23:14:38Z,i meant is there a need to include logstartoffset in partitionfetchstate in abstractfetcherthread.scala? it seems that only replicafetcherthread needs it.,0,0.9884724020957947
107049639,2476,lindong28,2017-03-21T00:29:02Z,ah i see your point now. you are right that we don't have to include it in `abstractfetcherthread`. i have removed it from `partitionfetchstate` in `abstractfetcherthread` and the code change in `consumerfetcherthread` and `abstractfetcherthread` is much smaller now. thanks!,1,0.9766015410423279
107052078,2476,lindong28,2017-03-21T00:51:33Z,"yes we can compute it on the fly when we need it in e.g. in `delayeddeleterecords`. is there reason to do it on the fly instead of maintaining it in the `replica`? is it because you think the patch would be simpler if we compute it on the fly? i think both solution has the same performance. but maintaining it in replica in the same way as `hw` may make lw easier to reason about and extend in the future. for example, the code is easier to extend if we want to use `lw` in the future as a way to determine the minimum offset available for consumption (currently the minimum offset available for consumption varies between replicas because different replicas may have different logstartoffset).",0,0.9758744239807129
107052828,2476,lindong28,2017-03-21T00:58:38Z,"btw, the reason `maybeincrementleaderlw()` is not called when the old segments are deleted is that the concept of `lw` and partition is at a higher level than `logmanager`, `logcleaner` and `log`. ideally those classes such as `logmanager` do not contain reference to the higher level class such as `partition`.",0,0.9865684509277344
107058922,2476,lindong28,2017-03-21T02:04:36Z,i have updated `upgrade.html` to change latest version from 0.10.3.0 to 0.11.0 and specify change in the fetchrequet and fetchresponse.,0,0.9888350367546082
107195440,2476,junrao,2017-03-21T15:56:32Z,"my concern is that if we store it, but don't make it accurate, then someone may start using it in the future without realizing that it's only accurate at deleterecordrequest time. so, it's better to either store it and make it accurate, or not store it and always compute it accurately when needed.",0,0.8475305438041687
107281864,2476,lindong28,2017-03-21T21:35:35Z,"i see. i just updated the patch to store `lowwatermark` in `partition` instead of `replica` and always call `maybeincrementleaderlw()` when we retrieve `lowwatermark`. i still maintain lowwatermark as state so that we only need to call `trycompletedelayedrequests` if lowwatermark has increased. other than that, the `lowwatermark` is essentially computed on the fly developer access it through `partition.updateandgetlowwatermarkiflocal()`. i added a comment that says: `lowwatermark should always be accessed through updateandgetlowwatermarkiflocal() because we may not update lowwatermark when log segment is deleted`.",0,0.9734757542610168
107512572,2476,lindong28,2017-03-22T19:42:46Z,i will add back this javascript template in the next commit. guozhang just told me that we are expected to have a local webserver in order to read this upgrade.html.,0,0.9803698062896729
107589219,2476,junrao,2017-03-23T05:10:16Z,"it still seems that it's a bit weird to maintain lowwatermarkiflocal just to see if the value has changed. another way to do that is in partition.updatereplicalogreadresult(), we compute lw before and after calling replica.updatelogreadresult. then, we will know if lw has changed. we can further optimize it by only computing the lw if the deleterecordpurgatory is not empty.",-1,0.9546656608581543
107589225,2476,junrao,2017-03-23T05:10:22Z,we are resetting log-start-offset to the base offset of first segment?,0,0.9871131777763367
107589236,2476,junrao,2017-03-23T05:10:29Z,"this logic seems a bit dangerous. there is no synchronization between nextoffset() and the updating of nextoffset in append(). so they can step on each other. since the deleting record logic never deletes the active segment, it seems that we could just use the base offset of the next segment as the next offset of the current segment. then we don't need to maintain nextoffset per segment?",-1,0.8330759406089783
107589241,2476,junrao,2017-03-23T05:10:34Z,"i had a comment on this earlier. if deleterecords() can't be applied on a compacted topic, should we send some error code in the response?",0,0.9794710278511047
107748044,2476,lindong28,2017-03-23T18:26:29Z,that is a good idea. i have updated the patch to avoid maintaining lowwatermark as state of partition and compute it only on the fly. and `updatereplicalogreadresult` would only compute lw if deleterecordpurgatory is not empty.,0,0.5181251168251038
107750331,2476,lindong28,2017-03-23T18:35:39Z,"this is kind of similar to what we do with recoverypoints if its checkpoint file is unreadable. for example, if recoverypoints checkpoint file is unreadable but `.kafka_cleanshutdown` file exists, we will reset recoverypoint to `activesegment.nextoffset` after warning `resetting the recovery checkpoint to 0`. here we assume the log-start-offset in the checkpoint file is 0 if checkpoint file is not readable. on a second thought, i agree it is confusing because we will always set `logstartoffset` to at least base offset of the first second if its checkpoint file is unreadable. i will remove this statement.",0,0.9204109311103821
107752878,2476,lindong28,2017-03-23T18:45:42Z,"my apology, i missed your comment here. `deleterecordsrrequest` can actually be applied on a compacted topic. `deleterecordsrrequest` will increase the logstartoffset. when `logcleaner` calls `log.deleteoldsegments()`, those log segments which breach the logstartoffset will be deleted.",-1,0.6884500980377197
107753068,2476,lindong28,2017-03-23T18:46:29Z,"sorry, i missed your comment there previously. my bad. deleterecordsrrequest can actually be applied on a compacted topic. deleterecordsrrequest will increase the logstartoffset. when logcleaner calls log.deleteoldsegments(), those log segments which breach the logstartoffset will be deleted. thus we don't need to send error code in response.",-1,0.9867458939552307
107779887,2476,junrao,2017-03-23T20:48:59Z,"hmm, in logcleaner, we have the following code. only logs configured as compacted and deleted are deletable and will call deleteoldsegments(). [code block]",0,0.9863583445549011
107785265,2476,lindong28,2017-03-23T21:12:04Z,"after kip-71 is committed, log compaction and deletion can co-exist. strictly speaking deleterecordsrequest can be applied on a compacted topic: if a topic is compacted and deletable, its log segment can be deleted by logcleaner; if a topic is non-compacted and deletable, its log segment can be deleted by the `logmanager.cleanuplogs()` which runs periodically. are you suggesting that deleterecordsresponse should provide error immediately if the topic is not deletable? this is certainly a good point. i missed this part previously. i will update the patch to do it. thanks!",0,0.979897677898407
107806053,2476,lindong28,2017-03-23T23:16:43Z,"i get your concern. i am not sure we could just use the base offset of the next segment, because `nextoffset()` is a method that exists prior to this kip and is actually used by `log` to initialized `nextoffsetmetadata` (i.e. `nextoffsetmetadata = new logoffsetmetadata(activesegment.nextoffset(), activesegment.baseoffset, activesegment.size.toint)`). thus we actually need `nextoffset` of the active log segment. i have updated the patch so that `nextoffset()` is a read-only operation and only returns the cached next offset. and i make sure that for non-empty segment that is read from disk, we will always call `updatenextoffsetfromlog()` before the first call to its `nextoffset()`. i think it should resolve the problem.",0,0.5640411376953125
107819630,2476,junrao,2017-03-24T01:24:55Z,"before this patch, we have nextoffset(), which computes the next offset by scanning the last portion of the log. this could be expensive, but is only used during the initial log loading. i was suggesting that we could just keep the logic as it is. in deletelogstartoffsetbreachedsegments(), we always use the baseoffset of the next segment to check if a segment should be deleted. if a segment doesn't have the next segment, we know it's the active segment and won't be deleted. this way, we never need to call nextoffset() in deletelogstartoffsetbreachedsegments().",0,0.9746715426445007
107820483,2476,lindong28,2017-03-24T01:35:40Z,"thanks for the quick comment . yes it is possible to do that, i.e. we keep the previous expensive implementation of `nextoffset()` which scans the last portion of the log, and implement `deletelogstartoffsetbreachedsegments()` in such a way that the deletion of a segment depends on the baseoffset of the next segment. i am just not very sure about advantage of that approach as compared to the approach in the current patch. in comparison, that approach keeps nextoffset() expensive, and requires more complex implementation of `deletelogstartoffsetbreachedsegments()` because it can no longer re-use `deleteoldsegments(predicate)` to delete partition. the benefit of the approach is that we don't need to maintain `nextoffset` as state in `logsegment`. i am ok with the suggested approach. let me do that then.",1,0.6166778802871704
107825145,2476,lindong28,2017-03-24T02:34:51Z,"after thinking about this more, i agree that it is safer to keep less state in the class unless `nextoffset()` is called frequently. thus i agree the suggested approach is simpler. thanks .",1,0.9598862528800964
108008403,2476,junrao,2017-03-24T22:07:24Z,we could use mapvalues() here?,0,0.9876008033752441
108008598,2476,junrao,2017-03-24T22:09:03Z,"thinking a bit more. it seems that a delayeddeleterecord could be added right after the if check. in the next updatereplicalogreadresult() call, lw may not advance any more. then the response will be delayed. perhaps, if (replicamanager.delayeddeleterecordspurgatory.delayed() > 0) , we could just always call trycompletedelayedrequests()?",0,0.9817185401916504
108008646,2476,junrao,2017-03-24T22:09:26Z,this is not very accurate. lw will increase with deleterecordsrequest or log deletion?,0,0.6956371665000916
108008660,2476,junrao,2017-03-24T22:09:33Z,should we initialize this to an unknownoffset?,0,0.9834268093109131
108009638,2476,lindong28,2017-03-24T22:18:10Z,"no we can not use `mapvalues()`. this is because `mapvalues()` returns a view and any write operation on that view will be ignored later, e.g. `status.ackspending = true` in `delayeddeleterecords`.",0,0.9882122874259949
108010888,2476,lindong28,2017-03-24T22:23:08Z,"yes i think it is correct. for example, if there is only one replica, deleterecordsrequest or log retention will immediately increase lw.",0,0.987008273601532
108011703,2476,lindong28,2017-03-24T22:28:46Z,there is no existing variable named unknownoffset. there is `logoffsetmetadata.unknownsegbaseoffset` but i am not sure we should use unknownsegbaseoffset for logstartoffset. so i created `log.unknownlogstartoffset = -1l`. does address the problem?,0,0.9844879508018494
108012358,2476,lindong28,2017-03-24T22:34:33Z,"if there is only one live replica for this partition, then lw will increase immediately to the specified offset and the response can be sent to the client. otherwise, say there is at least one live follower for this partition, lw will not increase now. lw will increase in the next updatereplicalogreadresult() call, and the response can be sent back then. does this work?",0,0.9877375364303589
108092052,2476,junrao,2017-03-27T05:16:52Z,"to follow the convention in fetch_response, should this be named fetch_request_partition_v5?",0,0.9895162582397461
108092057,2476,junrao,2017-03-27T05:17:01Z,could you include the changes from kip-98 too?,0,0.9881091713905334
108266895,2476,junrao,2017-03-27T20:08:06Z,"we don't read the logstartoffset from the checkpoint in this case, which is a bit inconsistent with how we load the log when the broker starts up. this seems ok for now since in the rare case when a follower loses the whole log (but still has the logstartoffset checkpoint), it can discover the logstartoffset from the leader quickly. not sure if we want to add a comment on this.",0,0.9675379395484924
108287834,2476,lindong28,2017-03-27T21:44:53Z,"i am not sure i understand the problem of inconsistency here. i think this `createlog()` will only be called when the replica doesn't exist on the broker, which means the broker should not have logstartoffset for this replica, right? are you considering the scenario that the replica is deleted (either through stopreplicarequet or manually deleted via `rm -rf`) but the logstartoffset is still there? in that case i think we should actually ignore the outdated logstartoffset in the checkpoint file and read the value from leader. because logstartoffset can be considered as logically deleted if log file is deleted. does this make sense?",0,0.8842291831970215
108288220,2476,lindong28,2017-03-27T21:46:54Z,"i think it may be better for owners of kip-98 to add this in the upgrade note (e.g. in kafka-4816) because they know much more about the change in kip-98 than i do.. anyway, i can go over the kip-98 doc and add things that i think necessary.",0,0.9708938002586365
108291575,2476,ijuma,2017-03-27T22:02:38Z,", feel free to leave out the kip-98 change for now. i am about to file a jira for updating the upgrade notes for kip-98. this is not the only one.",0,0.9251506924629211
108301862,2476,lindong28,2017-03-27T23:07:34Z,thanks . then i won't include this in the patch.,0,0.8247570991516113
108301889,2476,lindong28,2017-03-27T23:07:45Z,sure. i will change it to be fetch_request_partition_v5.,0,0.9770540595054626
108305808,2476,lindong28,2017-03-27T23:38:42Z,"as of now, the base offset of the first segment of a compacted topic can be always 0. thus it seems ok to have its logstartoffset as 0. we can consider logstartoffset as the lower bound of the offset of the first message in the partition, but not necessarily the strict lower bound. i couldn't find any use-case that would be broken due to this definition.",0,0.9786010980606079
108326834,2476,becketqin,2017-03-28T03:17:00Z,"can we be more clear on this field. in the `fetchresponse` we have log_start_offset which have almost the same comment. maybe here we can say ""the smallest available offset across all live replicas.""",0,0.9877589344978333
108326881,2476,becketqin,2017-03-28T03:17:44Z,for the given topic => for the given partition.,0,0.9853413701057434
108329771,2476,junrao,2017-03-28T03:54:50Z,"i don't think it breaks anything. so, we can leave this as it is.",0,0.9590752124786377
108333754,2476,becketqin,2017-03-28T04:49:22Z,"there seems a very rare case that may result in message loss. assuming there is only one replica, consider the following sequence: 1. user deletes a topic, we are not deleting the log starting offset from the checkpoint file. 2. if the topic is created again with the same name and the partitions happen to be on the same broker. 3. user produced some messages and before the log starting offset is checkpointed, the broker went down. 4. now when the broker restarts, the old checkpointed log starting offset may be applied to the newly created topic, which may cause the messages that have been produced into the log to be unavailable to the users. this is a very rare corner case, though.",0,0.9766904711723328
108335119,2476,lindong28,2017-03-28T05:07:41Z,sure. updated now.,0,0.9492981433868408
108335175,2476,lindong28,2017-03-28T05:08:03Z,good catch. fixed now.,1,0.9816462397575378
108335392,2476,lindong28,2017-03-28T05:10:53Z,good point. i fixed the problem by always do `checkpointlogstartoffsetsindir(removedlog.dir.getparentfile)` when a partition is deleted. the overhead will probably be smaller than checkpointing the cleaner offset which we already do everytime we delete a partition.,1,0.9045849442481995
103840661,2614,junrao,2017-03-02T02:42:05Z,"we may add new compression codec in the future. using the bits from 15 downwards makes adding new compression codec a bit easier in the future. also, unused should be 5-15.",0,0.9845672845840454
103840673,2614,junrao,2017-03-02T02:42:15Z,"in the comment above the class and in the kip wiki, lastoffsetdelta is after attributes.",0,0.9872451424598694
103840681,2614,junrao,2017-03-02T02:42:21Z,the comment is no longer valid?,0,0.9210970997810364
103840693,2614,junrao,2017-03-02T02:42:29Z,"hmm, should we be passing in delta timestamp?",0,0.9846183657646179
103840712,2614,junrao,2017-03-02T02:42:36Z,the comment seems outdated. attributes are no longer used to indicate the presence of key and value.,0,0.7133570313453674
103840724,2614,junrao,2017-03-02T02:42:43Z,"could we spell out how this is calculated? also, does it include the length field?",0,0.9879669547080994
103840746,2614,junrao,2017-03-02T02:42:57Z,"if key is null, should we return -1, which is the current convention?. ditto for valuesize().",0,0.8195236325263977
103840757,2614,junrao,2017-03-02T02:43:04Z,"we compute crc from timestamp, instead of attributes.",0,0.9878586530685425
103840767,2614,junrao,2017-03-02T02:43:09Z,timestamp => timestampdelta? ditto in sizeinbytes() and sizeofbodyinbytes().,0,0.9840767979621887
103840780,2614,junrao,2017-03-02T02:43:15Z,probably non-idempotent/non-transactional to make it clear?,0,0.9823051691055298
103840821,2614,junrao,2017-03-02T02:43:40Z,"for up-converted message, timestamp will be -1. but shouldn't timestamptype be the timestamptype of the topic?",0,0.9878667593002319
103840897,2614,junrao,2017-03-02T02:44:17Z,"the comment above suggests that lastoffset() is the same as nextoffset(), which seems inaccurate.",0,0.9631421566009521
103840910,2614,junrao,2017-03-02T02:44:25Z,shouldn't we return -1 if there is no key? ditto for valuesize().,0,0.5022719502449036
103840930,2614,junrao,2017-03-02T02:44:37Z,should that be hasvalue() to be consistent with haskey()?,0,0.9855656027793884
103840934,2614,junrao,2017-03-02T02:44:42Z,should this be fixed?,0,0.9830572009086609
103840949,2614,junrao,2017-03-02T02:44:51Z,should we return 0 or logentry.no_sequence?,0,0.986920952796936
103840960,2614,junrao,2017-03-02T02:45:00Z,probably mention the magic in the error message.,0,0.9775691628456116
103840968,2614,junrao,2017-03-02T02:45:05Z,bytebufferlogentry => bytebufferoldlogentry ?,0,0.9879996180534363
103840980,2614,junrao,2017-03-02T02:45:10Z,integer => long? ditto in a few other places.,0,0.9663631319999695
103840998,2614,junrao,2017-03-02T02:45:19Z,it's a bit weird to assign lastoffset to firstoffset with old magic. perhaps adding a comment to explain why?,-1,0.9830379486083984
104274159,2614,ijuma,2017-03-04T01:44:08Z,"i think we should introduce a `byteutils` class and move all the relevant methods there. maybe we could do that in its own pr, which could be merged quickly independently of the message format changes?",0,0.9867138266563416
104276385,2614,hachikuji,2017-03-04T02:40:23Z,works for me.,0,0.959456741809845
104345921,2614,junrao,2017-03-06T05:29:26Z,1 => logentry.magic_value_v1? ditto in line 84 below.,0,0.7143728733062744
104345937,2614,junrao,2017-03-06T05:29:39Z,"so, the old consumer won't work on the eos message format? if so, should we pin the fetchrequest version in consumerfetcherthread to an older version?",0,0.9890307784080505
104345956,2614,junrao,2017-03-06T05:30:02Z,"since maxmessagesize now applies to record set, it would be useful to change the description in kafkaconfig and describe that change in the upgrade section of the documentation.",0,0.988757312297821
104345961,2614,junrao,2017-03-06T05:30:07Z,entry probably should now be named logrecord?,0,0.9887655973434448
104345969,2614,junrao,2017-03-06T05:30:18Z,"in validatemessagesandassignoffsets(), should we further validate that there is only 1 log entry in records in eos format?",0,0.9894429445266724
104345976,2614,junrao,2017-03-06T05:30:26Z,does this need to be fixed? could we reuse abstractrecords.estimatesizeinbytes() for estimating the size for all magic?,0,0.9886305332183838
104495063,2614,junrao,2017-03-06T19:07:12Z,"hmm, this adds some complexity and i am not sure about the benefit. first, when sending the first few batches of the data in the producer or when the leaders are not on all brokers, we don't have a connection to all brokers. so the minusedmagic may not be very accurate. could we just rely on the down conversion logic on the broker side and make it clearer in the documentation that eos feature should be turned on only when the whole cluster has been upgraded?",0,0.5367146134376526
104495083,2614,junrao,2017-03-06T19:07:17Z,does this array need to be nullable?,0,0.9815736413002014
104495161,2614,junrao,2017-03-06T19:07:35Z,"could you add some comment on what needs to be done if we change the version of the key in the future? for example, do we have to explicitly delete keys on the old version since it won't be compacted out by the new version of the key?",0,0.9884054660797119
104495190,2614,junrao,2017-03-06T19:07:44Z,should we support the write method here?,0,0.988287627696991
104495211,2614,junrao,2017-03-06T19:07:49Z,the reference bytebufferloginputstream.bytebufferlogentry in the comment above is no longer valid.,0,0.9371567368507385
104495248,2614,junrao,2017-03-06T19:07:55Z,should we include laststableoffset?,0,0.988837480545044
104495273,2614,junrao,2017-03-06T19:08:01Z,the error message seems to be the opposite.,0,0.9085138440132141
104495288,2614,junrao,2017-03-06T19:08:05Z,is the todo still valid?,0,0.9850035905838013
104495343,2614,junrao,2017-03-06T19:08:20Z,should timestamptype be hardcoded to createtime or should it use the topic level config? ditto for line 256 below.,0,0.9501200318336487
104495356,2614,junrao,2017-03-06T19:08:25Z,is 1024 guaranteed to be always large enough?,0,0.9838864207267761
104495396,2614,junrao,2017-03-06T19:08:38Z,"should we print out additional information related to eos format (e.g. pid, epoch, sequence) etc? should we support printing out the control message?",0,0.9894207715988159
104495429,2614,junrao,2017-03-06T19:08:44Z,"now that we have increased the param limit in checkstyle, do we still need this?",0,0.9876042604446411
105383915,2614,ijuma,2017-03-10T12:01:24Z,we should add a note that this is an internal class since the package doesn't make that obvious.,0,0.9841895699501038
105384533,2614,ijuma,2017-03-10T12:06:49Z,"nit: `maxusablemagic = math.min(usablemagic, maxusablemagic)`?",0,0.9857894778251648
105385120,2614,ijuma,2017-03-10T12:11:24Z,"i think this `switch` should be a separate method as it's the interesting logic that may need to be updated when we add more produce versions. maybe it should live in `producerequest`? and we should have a test that breaks when we add a new produce version to the protocol (if we don't already) so that we don't forget to update it (since the client would still work fine, it could go unnoticed).",0,0.9715956449508667
105386294,2614,ijuma,2017-03-10T12:20:42Z,"hmm, would it be better to have a `nodeapiversions.usableversion` that takes a `desiredversion` as well? we could the collapse these two branches and there would be no need to call `ensureusable`.",0,0.9864107966423035
105386464,2614,ijuma,2017-03-10T12:21:54Z,"it's an existing issue, but realised that this comment is out of date.",0,0.9163798689842224
105387601,2614,ijuma,2017-03-10T12:30:43Z,"can we just simply call `get` on the map? also, maybe we should return `null` if there's no element (like `map.get`).",0,0.9881145358085632
105388069,2614,ijuma,2017-03-10T12:34:39Z,maybe we could move the logic that creates the appropriate `usableversion` into a static factory method (or constructor) in `usableversion`.,0,0.98833829164505
105390691,2614,ijuma,2017-03-10T12:54:19Z,"i found the term `default` a bit confusing here. this is `usableversion`, right? i guess you were trying to avoid repeating it since the class name is `usableversion`. could we just call it `value`?",-1,0.6567749381065369
105390911,2614,ijuma,2017-03-10T12:55:59Z,"i think the field name should just be `apiversion`, no?",0,0.9862960577011108
105391297,2614,ijuma,2017-03-10T12:58:39Z,"this should be ""0.11.0-iv0"" and the rest should be updated accordingly.",0,0.9852647185325623
105392682,2614,ijuma,2017-03-10T13:08:27Z,"`create_time` is correct, see [a link]",0,0.9878174662590027
105394318,2614,ijuma,2017-03-10T13:19:26Z,"it makes sense to leave space for the compression type, but i'd hope we won't need more than 3 bits for it.",0,0.9771724343299866
105394549,2614,ijuma,2017-03-10T13:20:53Z,"would `basicrecord` or `simplerecord` be a better name? i think the key feature is that it just captures the essence of what a record is: timestamp, key, value (and potentially headers in the future?).",0,0.9884786009788513
105497417,2614,hachikuji,2017-03-10T21:55:38Z,"my guess is we'll have another message format bump before we run out of room for compression codecs, but i don't mind adding another bit if you think it's useful.",0,0.9601944088935852
105498031,2614,hachikuji,2017-03-10T21:58:44Z,"oh, i may have misunderstood. are you suggesting moving the transactional flag and timestamp type to the end of the second byte?",0,0.7166035771369934
105515378,2614,hachikuji,2017-03-11T00:20:03Z,"i do this validation inside `producerequest`. if there is more than one entry, we will raise `invalidrecordexception` before the request reaches `logvalidator`.",0,0.9895402789115906
105516191,2614,hachikuji,2017-03-11T00:29:01Z,"yes, i think we can.",0,0.9509237408638
105516431,2614,hachikuji,2017-03-11T00:31:41Z,"if fetching in `read_uncommitted`, we do not compute the aborted transaction list. i thought `null` would be a good way to communicate this instead of an empty array, which would be ambiguous (are there no aborted transactions or did we just not compute them?).",0,0.9857062101364136
105516776,2614,hachikuji,2017-03-11T00:35:28Z,"discussed offline, but for posterity, down-conversion on the broker only helps when the broker supports the new produce request version. however, the client also needs to support older versions of the produce request, which must use older versions of the message format. the difficulty is that there is a delay between the time that the producer starts building the batch and the time that we send the request, and we may have chosen the message format based on out-dated metadata. in the worst case, we optimistically chose to use the new message format, but found that the broker didn't support it, so we need to down-convert on the client before sending.",0,0.9452829360961914
105698631,2614,hachikuji,2017-03-13T16:02:00Z,"yeah, let's do this for now. we can add support in a follow-up if desired.",0,0.9743709564208984
105722433,2614,hachikuji,2017-03-13T17:33:41Z,i guess the todo should really go to the other constructor.,0,0.9860332608222961
105724542,2614,hachikuji,2017-03-13T17:42:04Z,we'd need to increase a bit more to capture this one too. increasing to 12 dropped two others.,0,0.9816139936447144
105732368,2614,hachikuji,2017-03-13T18:11:01Z,i assume you are asking whether we can support this method directly using the `filechannel`? i have implemented this in the latest commit.,0,0.9876925349235535
105733027,2614,hachikuji,2017-03-13T18:13:44Z,"yeah, that's fair. let me see if we can move it to `producerequest`.",0,0.9376757740974426
105746262,2614,hachikuji,2017-03-13T19:09:50Z,"yes, that sounds good.",1,0.7929078340530396
105767662,2614,junrao,2017-03-13T20:48:30Z,"since we already have 3 bits for compression, so leaving this as it is will be fine.",0,0.9738658666610718
105767710,2614,junrao,2017-03-13T20:48:40Z,"i was trying to say it seems that we (should) never do writes through fileloginputstream? if so, perhaps the implementation can just throw unsupportedexception?",0,0.9595494866371155
105770550,2614,hachikuji,2017-03-13T21:01:32Z,i guess the name is a little misleading. we're really reading here into the provided buffer. maybe the name should be `readinto`?,0,0.8455178737640381
105985925,2614,junrao,2017-03-14T18:09:16Z,"since we are including the exact key/value length, perhaps we should exclude the max key/value length in max_record_overhead?",0,0.9875923991203308
105985975,2614,junrao,2017-03-14T18:09:30Z,"perhaps name this to producerepoch to distinguish it from the partitionleaderepoch? if so, probably rename the variables in the class as well.",0,0.988465428352356
105985994,2614,junrao,2017-03-14T18:09:37Z,should we pass in timestampdelta instead of timestamp?,0,0.9874581694602966
105987708,2614,hachikuji,2017-03-14T18:16:04Z,`simplerecord` works for me. i may have actually had this in the code at one time or another.,0,0.9869383573532104
106071613,2614,junrao,2017-03-15T02:02:41Z,it's a bit weird to call this maxusablemagic when we take the min. perhaps this and the method should be minusablemagic?,-1,0.9836874008178711
106071657,2614,junrao,2017-03-15T02:03:05Z,"hmm, the method doesn't do exactly what the comment says. if desiredversion is not usable, it doesn't seem to fall back to latest usable version. is the comment incorrect?",0,0.9151779413223267
106071664,2614,junrao,2017-03-15T02:03:10Z,maybe useful to include the min/max version in the error message?,0,0.9871614575386047
106071700,2614,junrao,2017-03-15T02:03:30Z,"this can be a bit tricky. it seems that maxusablemagic could change btw when size is computed in line 190 and in line 205. if the estimated size is not correct, we may not be able to append the record to the newly allocated recordsbuilder, which will cause the assertion in line 209 to fail.",0,0.5534969568252563
106071703,2614,junrao,2017-03-15T02:03:34Z,annotate this with ?,0,0.9861491918563843
106071718,2614,junrao,2017-03-15T02:03:46Z,legacyrecordbatch => abstractlegacyrecordbatch ?,0,0.9847152233123779
106071726,2614,junrao,2017-03-15T02:03:52Z,perhaps it's clearer to name this legacyrecord()?,0,0.9856016039848328
106071817,2614,junrao,2017-03-15T02:04:48Z,"the comment in loginputstream says it only does shallow iteration. however, here we are doing deep iteration. so, perhaps the comment needs to be changed?",0,0.9837064743041992
106071826,2614,junrao,2017-03-15T02:04:52Z,log logentries => logentries,0,0.9866915941238403
106071834,2614,junrao,2017-03-15T02:04:56Z,due => due,0,0.9570590257644653
106071846,2614,junrao,2017-03-15T02:05:04Z,epoch => producerepoch here and in the comment?,0,0.9830988049507141
106071855,2614,junrao,2017-03-15T02:05:09Z,could we call this producerepoch to distinguish it from partitionleaderepoch?,0,0.9889995455741882
106071869,2614,junrao,2017-03-15T02:05:18Z,"hmm, is remaining() correct? it seems that limit() is right.",0,0.9750492572784424
106071874,2614,junrao,2017-03-15T02:05:25Z,"hmm, the last message has offset 3. so, shouldn't position be 4?",0,0.9836587309837341
106071891,2614,junrao,2017-03-15T02:05:39Z,"could we print out whether this is a control record? and if so, perhaps print out more details about the control record?",0,0.9871528744697571
106071917,2614,junrao,2017-03-15T02:05:54Z,could we print out leaderepoch as well. also epoch => producerepoch?,0,0.985639214515686
106083563,2614,junrao,2017-03-15T04:21:17Z,"with this, it's possible to have no records added to the builder. does the builder support that at close() time?",0,0.9885243773460388
106086048,2614,junrao,2017-03-15T04:58:44Z,it seems that the validation has been done in line 203?,0,0.9865351319313049
106086067,2614,junrao,2017-03-15T04:58:56Z,"hmm, why do we need to do this check? the batch could be on magic 2? ditto on the ensurenotcontrolrecord() check below.",0,0.950711727142334
106239779,2614,hachikuji,2017-03-15T18:00:26Z,"i agree it reads a little weird, but i'm not sure `minusablemagic` is accurate. the minimum usable magic would always be 0, but we are actually trying to get the maximum magic value that is supported across all brokers, which means taking the minimum of the max versions supported by all.",-1,0.5850009918212891
106243896,2614,hachikuji,2017-03-15T18:15:53Z,i'll clarify the comment. what i was trying to say is that `loginputstream` only handles one level of iteration (it itself does not descend into compressed payloads).,0,0.987964391708374
106247667,2614,hachikuji,2017-03-15T18:30:11Z,"the `toarray` we're delegating to begins from `buffer.position()`, so `remaining()` seems correct. i'll add a test case to figure it out.",0,0.9882859587669373
106249688,2614,hachikuji,2017-03-15T18:37:57Z,"yes, we basically set the built records to `memoryrecords.empty` and reset the position in the underlying buffer.",0,0.9883982539176941
106251349,2614,hachikuji,2017-03-15T18:44:06Z,this was intended to be temporary until we have the transactional portion of kip-98. i didn't want to get too far into that validation in this patch if possible. does that seem reasonable?,0,0.9500243067741394
106257259,2614,hachikuji,2017-03-15T19:08:53Z,good catch. it seems we need to use the same value throughout this logic. we always have the code to handle conversion later if we need it.,1,0.9743900895118713
106258412,2614,hachikuji,2017-03-15T19:13:49Z,"should have known not to try to slip something by jun! fixing this is actually a bit tricky since we need to retain the control record long enough to update the consumer's position. this requires a bit of refactoring in `fetcher`, which i had intended to do in a follow-up. i'll see if there's an easier workaround for now.",-1,0.5726844072341919
106321514,2614,junrao,2017-03-16T01:23:48Z,"it seems that we should either use (1) 0 and buffer.limit() or (2) buffer.position() and buffer.remaining(), but not mixing the two? for (2), typically the buffer is in the write mode. in the read mode, (1) is probably what we want?",0,0.987686812877655
106322699,2614,ijuma,2017-03-16T01:35:51Z,seems like `offset` is ignored in the `else` case.,0,0.980303943157196
106322962,2614,ijuma,2017-03-16T01:38:41Z,"the reason why `0` is being passed is that `position` is called in the overloaded `toarray` method. so, this is actually doing `2` although it's not too clear.",0,0.9853489995002747
106324045,2614,junrao,2017-03-16T01:50:08Z,"could we also print out baseoffset. basetimestamp, partitionleaderepoch, basesequence?",0,0.9899699091911316
106342774,2614,hachikuji,2017-03-16T05:43:08Z,good catch,1,0.9703027606010437
106454133,2614,ijuma,2017-03-16T15:45:48Z,"shouldn't we document the behaviour in 0.11.0 first? we can add a note about the previous behaviour at the end, but if someone sees these docs, they should be interested in 0.11.0.",0,0.9870327711105347
106455746,2614,ijuma,2017-03-16T15:51:39Z,nit: would `struct.hasfield(transactional_id_key_name)` be a little better?,0,0.9876869320869446
106455926,2614,ijuma,2017-03-16T15:52:15Z,nit: would `struct.hasfield(transactional_id_key_name)` be a little better?,0,0.9876869320869446
106460700,2614,ijuma,2017-03-16T16:09:43Z,"could we call `usableversion.ensureusable(version)` here? also, maybe we can improve the exception message from that method to be as good as this one (i.e. include the supported versions).",0,0.982748806476593
106461149,2614,ijuma,2017-03-16T16:11:24Z,"can we mention the requested `apikey` in the exception? also, it would be good to document that the method throws an exception instead of just returning `null` if no `apiversion` can be found.",0,0.9885461926460266
106478107,2614,junrao,2017-03-16T17:17:01Z,perhaps save this in a constant and reuse?,0,0.9813014268875122
106478136,2614,junrao,2017-03-16T17:17:07Z,"hmm, is headers nullable? if so, should we use -1 to represent null for consistency?",0,0.9873421788215637
106478167,2614,junrao,2017-03-16T17:17:14Z,this should now be named writedefaultrecordheader()? there are a bunch of places like that.,0,0.9775181412696838
106478340,2614,junrao,2017-03-16T17:17:53Z,this should be appendlegacyrecord()? there are a few other places referencing oldlogrecord.,0,0.9888222217559814
106525941,2614,ijuma,2017-03-16T20:41:31Z,nit: `batch`.,0,0.9886237382888794
106528086,2614,ijuma,2017-03-16T20:51:27Z,"have we settled on using `magic` instead of `messageformatversion`? we may need to clean-up some scala code later. personally, i think `messageformatversion` is less `magic` (see what i did there). ;)",0,0.8581690788269043
106535449,2614,ijuma,2017-03-16T21:25:42Z,should some of this github response be included in the code comments?,0,0.9878631830215454
106536471,2614,ijuma,2017-03-16T21:30:15Z,"to avoid this cast, we can add an overrides for `downconvert` in `filerecords` and `memoryrecords` that make the type more specific (where we know it cannot fail).",0,0.9877232313156128
106537132,2614,ijuma,2017-03-16T21:33:25Z,i think that makes sense for what it's worth.,0,0.9270614385604858
106541553,2614,ijuma,2017-03-16T21:56:35Z,"we don't have to do this now, but i wonder if `recordbatch` could simply be an abstract class and we could remove this one. or we could wait until we move to java 8, keep the interface and use default methods.",0,0.9727257490158081
106542021,2614,ijuma,2017-03-16T21:59:19Z,you don't need to say `beginning in 0.11.0` since that's the case for everything in this list.,0,0.9872204065322876
106542403,2614,ijuma,2017-03-16T22:01:33Z,is it worth saying something about `batch.size`? it seems that is what ensures that the batch will be of an appropriate size.,0,0.983156144618988
106543613,2614,ijuma,2017-03-16T22:09:03Z,can we simplify this in a similar way as we simplified `networkclient`?,0,0.9863288998603821
106546543,2614,ijuma,2017-03-16T22:26:41Z,typo: `unusuable`,0,0.9783251881599426
106546942,2614,ijuma,2017-03-16T22:29:16Z,is this just an optimisation or it's a correctness issue?,0,0.96485835313797
106570149,2614,junrao,2017-03-17T01:50:37Z,"entry => batch ? also, the comment above still references entry.",0,0.9880483746528625
106570158,2614,junrao,2017-03-17T01:50:45Z,logentries => recordbatch? there are a few other places like that in this file.,0,0.9883332848548889
106570162,2614,junrao,2017-03-17T01:50:51Z,convertlogentry => convertrecordbatch?,0,0.9876441359519958
106570181,2614,junrao,2017-03-17T01:51:05Z,we can only do this if headervalue.hasarray() is true? ditto for the crc computation in computechecksum() and in readfrom(). we can probably write a util for that.,0,0.9866083860397339
106570196,2614,junrao,2017-03-17T01:51:22Z,should we assert headerkey is not null?,0,0.9857614040374756
106570214,2614,junrao,2017-03-17T01:51:26Z,log_entry_overhead => record_batch_overhead ?,0,0.9877575635910034
106570219,2614,junrao,2017-03-17T01:51:31Z,"instead of ""magic v2"", referencing magic()?",0,0.9824429750442505
106570227,2614,junrao,2017-03-17T01:51:35Z,logentry => recordbatch ?,0,0.9870381355285645
106570233,2614,junrao,2017-03-17T01:51:40Z,1 => named constant?,0,0.984933078289032
106570245,2614,junrao,2017-03-17T01:51:46Z,could you add a bit more explanation on why the crc is useless?,0,0.9786444902420044
106570254,2614,junrao,2017-03-17T01:51:50Z,buildeosrecord => builddefaultrecord?,0,0.9853164553642273
106570260,2614,junrao,2017-03-17T01:51:55Z,onelogentry => onerecordbatch ?,0,0.9866676330566406
106570281,2614,junrao,2017-03-17T01:52:09Z,"in validatemessagesandassignoffsets(), when validating the defaultrecordbatch, should we also validate the the message count matches the actual number of messages in the array and the header count matches the actual number of headers?",0,0.9889304041862488
106570283,2614,junrao,2017-03-17T01:52:15Z,"instead of 0, referencing the constant?",0,0.9850147366523743
106581113,2614,junrao,2017-03-17T04:15:14Z,"ok, perhaps add a todo comment for now?",0,0.985893726348877
106581349,2614,junrao,2017-03-17T04:18:30Z,could we include an error message to indicate that this is unexpected? or could we throw an illegalstateexception instead?,0,0.9388015866279602
106892521,2614,ijuma,2017-03-20T12:53:15Z,the implementation of this method in `legacyrecord` is: [code block] i think you need something similar here.,0,0.9884372353553772
106895148,2614,ijuma,2017-03-20T13:05:52Z,nit: shouldn't we represent this as `records => [record]` instead of having `recordscount` as a separate line?,0,0.9827352166175842
106896027,2614,ijuma,2017-03-20T13:10:21Z,"in the documentation above, we use `length` while here we use `size`. it would be good to be consistent.",0,0.9510754346847534
106896581,2614,ijuma,2017-03-20T13:13:16Z,is it ever possible that we use `defaultrecordbatch` with `magic == 0`?,0,0.9880446791648865
106898316,2614,ijuma,2017-03-20T13:21:36Z,is this uint32 or int32? the code does both. :),1,0.9745231866836548
106899598,2614,ijuma,2017-03-20T13:28:02Z,we should have a private method for reading the last offset delta. we are using `readunsignedint` in `lastoffset` and `getint` here.,0,0.9893553853034973
106900105,2614,ijuma,2017-03-20T13:30:31Z,"this should be uint32, i believe.",0,0.9711155891418457
106913341,2614,ijuma,2017-03-20T14:26:05Z,"hmm, shouldn't we have more tests here? looking at the tests for the legacy records, some ideas: 1. tests like `simplerecordtest.*isvalid*`, but for `defaultrecordbatch`. 2. `legacyrecordtest.testchecksum` would be useful to have as well. 3. `simplerecord.buildeosrecord` should be renamed and moved here. 4. some tests involving compression? or is the idea that `memoryrecordstest` and `memoryrecordsbuildertest` cover those? it may be worth adding some javadoc to the test classes to give an idea of the what they're intended to test.",0,0.9804964661598206
106913783,2614,ijuma,2017-03-20T14:27:34Z,nit: logrecord -> record.,0,0.9846675992012024
106914828,2614,ijuma,2017-03-20T14:31:11Z,"i think we should rename this class `legacysimplerecordtest` (or something like that) and move the tests that are not for `legacyrecord` elsewhere. also, if there are tests that would make sense for `defaultrecord`, we should port them.",0,0.9882325530052185
106915417,2614,ijuma,2017-03-20T14:33:09Z,should this be in `memoryrecordsbuildertest` (or `memoryrecordstest`)?,0,0.9890856146812439
106915947,2614,ijuma,2017-03-20T14:35:04Z,we should add a comment here.,0,0.9823926687240601
106916671,2614,ijuma,2017-03-20T14:37:33Z,nit: i would say exactly-once as not everyone is familiar with the eos terminology.,0,0.9722955226898193
106917876,2614,ijuma,2017-03-20T14:41:50Z,nit: would `struct.hasfield(transactional_id_key_name)` be a little better?,0,0.9876869320869446
106919175,2614,ijuma,2017-03-20T14:46:02Z,i think we should call the `validaterecords` method for all versions.,0,0.9888131022453308
106919335,2614,ijuma,2017-03-20T14:46:32Z,"if we do this check, should we not do it for other versions `magic_value_v1` too?",0,0.9864587187767029
106919624,2614,ijuma,2017-03-20T14:47:25Z,"instead of saying ""version 3 and above"", should we just say ""version $version""?",0,0.985071063041687
106919757,2614,ijuma,2017-03-20T14:47:55Z,"i think we should call the `validaterecords` method for all versions. also, why do we only do it on `tostruct` instead of the constructor?",0,0.9883615374565125
106920410,2614,ijuma,2017-03-20T14:50:06Z,why was this moved to a separate line?,0,0.9384435415267944
106922600,2614,ijuma,2017-03-20T14:57:51Z,"maybe replace `unexpected` by `unknown`? given the versioning, it is expected that new versions will be introduced eventually.",0,0.9867985844612122
106929150,2614,ijuma,2017-03-20T15:20:29Z,"if you use `standardcharsets.utf_8`, you don't need the try/catch.",0,0.9870902895927429
106929931,2614,ijuma,2017-03-20T15:22:48Z,is there a reason why we don't just call `crc32.crc32` here? was it while doing some experiments with other implementations?,0,0.9718971848487854
106933605,2614,ijuma,2017-03-20T15:36:00Z,"it's a bit odd that `legacyrecord` is referenced here. if this is the same for legacy and default, we should move it to a shared class. otherwise, it seems this logic should not live here any more.",-1,0.7686233520507812
106934435,2614,ijuma,2017-03-20T15:38:55Z,shouldn't this pass the headers as well?,0,0.9800833463668823
106934918,2614,ijuma,2017-03-20T15:40:29Z,i wonder if some of these constructors that are only used by tests should be static factory methods to avoid accidental usage from non-test code.,0,0.816718578338623
106935553,2614,ijuma,2017-03-20T15:42:47Z,"the formatting of this method doesn't seem to follow our java convention (yes, i know, intellij) since the `return` is in the same line as the `if`. using `&&` is a concise alternative.",0,0.9875467419624329
106967419,2614,hachikuji,2017-03-20T17:40:23Z,"an optimization i guess. we could construct a new `memoryrecords` with the stored buffer, but i didn't see a good reason to.",0,0.7941375970840454
106967704,2614,hachikuji,2017-03-20T17:41:30Z,"lol, looks like my mind got stuck somewhere between typing ""unusual"" and ""unusable"".",1,0.9071054458618164
107003151,2614,hachikuji,2017-03-20T20:09:52Z,i could go either way... i ended up favoring `magic` mainly because it gives more concise variable and method names.,0,0.955293595790863
107003332,2614,hachikuji,2017-03-20T20:10:39Z,i debated on this... i'm inclined to leave it for later since this is internal.,-1,0.7334692478179932
107022774,2614,ijuma,2017-03-20T21:34:16Z,"note that this is only true before kip-74. after kip-74, this should never happen.",0,0.9701821208000183
107026003,2614,ijuma,2017-03-20T21:50:52Z,shouldn't we use the buffer position here?,0,0.9822410941123962
107041677,2614,hachikuji,2017-03-20T23:27:01Z,good point,1,0.9578153491020203
107043636,2614,hachikuji,2017-03-20T23:42:06Z,hmm... we should check with magnus which case it was that he was accidentally using. was it the old produce request version with the new format?,0,0.9599367380142212
107044557,2614,hachikuji,2017-03-20T23:48:56Z,that's fair,0,0.9521241784095764
107044757,2614,ijuma,2017-03-20T23:50:19Z,is it right that `0` is used if there is none for this and `producerid`? the constants at the top of the file seem to indicate that it's `-1`?,0,0.985680103302002
107044853,2614,ijuma,2017-03-20T23:51:03Z,we should probably replace `message set` with `record batch` in the comments.,0,0.9885064363479614
107045184,2614,ijuma,2017-03-20T23:53:34Z,`log overhead` -> `batch overhead`?,0,0.9889233112335205
107045235,2614,ijuma,2017-03-20T23:53:59Z,`log entry` -> `record batch`,0,0.9847739934921265
107045406,2614,ijuma,2017-03-20T23:55:21Z,"wouldn't this be better as a top level interface? i think an inner interface would make sense if we called it `mutable` only. as it is, the name stands well on its own and it makes usage a bit less verbose.",0,0.9492610096931458
107047035,2614,ijuma,2017-03-21T00:08:17Z,the `shallow` should be removed. maybe we need to do a search and replace for that string.,0,0.9829437136650085
107048855,2614,ijuma,2017-03-21T00:22:43Z,that's a good point. maybe we should just add a comment saying that we don't validate older versions because some clients rely on that.,1,0.6138048768043518
107057682,2614,hachikuji,2017-03-21T01:50:20Z,i think we can remove these utilities. i didn't know about the methods already in `crc32` until i started updating that class.,0,0.9881309270858765
107057717,2614,hachikuji,2017-03-21T01:50:50Z,agreed,0,0.9622963666915894
107057751,2614,hachikuji,2017-03-21T01:51:12Z,you are my hero,1,0.9474642872810364
107059245,2614,hachikuji,2017-03-21T02:08:33Z,"after thinking about this, it might be better to move the attribute logic into the record classes. we'll duplicate a little code, but it seems better to keep the usage of record attributes encapsulated.",0,0.9854481816291809
107146211,2614,ijuma,2017-03-21T12:57:36Z,nit: formatting (same as other case).,0,0.987714409828186
107146442,2614,ijuma,2017-03-21T12:59:00Z,"nit, if you are importing everything in `record`, then there's no reason to specify `recordbatch` on its own, right?",0,0.9827501773834229
107146675,2614,ijuma,2017-03-21T13:00:13Z,why are we not defaulting to `current` any more? same for the other method.,0,0.9792636036872864
107146794,2614,ijuma,2017-03-21T13:00:54Z,do we need to have a method like this for message format 1?,0,0.9858915209770203
107147049,2614,ijuma,2017-03-21T13:02:08Z,nit: `logentry` -> `record`?,0,0.9893766641616821
107147536,2614,ijuma,2017-03-21T13:04:22Z,why don't we use `logentries` here and in other similar methods?,0,0.9789832830429077
107147613,2614,ijuma,2017-03-21T13:04:43Z,shall we call this `records`?,0,0.9875743985176086
107148607,2614,ijuma,2017-03-21T13:09:43Z,"unfortunately, there are a few magic values in these tests. how did you arrive at the correct values for the array fill and `segmentbytesprop`?",-1,0.51629638671875
107148969,2614,ijuma,2017-03-21T13:11:14Z,"as you know, we have had a lot of issues with the cleaner in the past. and we don't have any system tests with compacted topics. do you feel like we have enough coverage for all message format versions?",0,0.7939037084579468
107149933,2614,ijuma,2017-03-21T13:15:44Z,it would be a bit clearer if we did: [code block],0,0.9802917242050171
107152276,2614,ijuma,2017-03-21T13:26:31Z,nit: entry -> record.,0,0.9720624089241028
107153794,2614,ijuma,2017-03-21T13:32:43Z,nice catch.,1,0.9548078775405884
107156070,2614,ijuma,2017-03-21T13:41:08Z,"if i understand correctly, you have two `flush` calls to ensure that we produce two batches, right? a few suggestions: 1. add a comment 2. rename the tests to make it clear that they're about record batches now, not records. 3. maybe we should do a `get` on the future in case it fails (in that case, we can probably remove the `flush()`).",0,0.9819674491882324
107157124,2614,ijuma,2017-03-21T13:45:19Z,"one more thing, we should consider changing the default to use the new format's overhead. at the moment it is: `val messagemaxbytes = 1000000 + messageset.logoverhead`.",0,0.9869731068611145
107157639,2614,ijuma,2017-03-21T13:47:20Z,"to avoid similar brittleness, would it be better to say something like `maxmessagesize - record_batch_overhead - 24` (the latter being the key size)?",0,0.9855572581291199
107159115,2614,ijuma,2017-03-21T13:52:44Z,should we be returning the current version in these stub returns?,0,0.9873310923576355
107160387,2614,ijuma,2017-03-21T13:57:21Z,"answering your question, this index is for the lz4 checksum value as the comment above says. maybe we should mention in the comment that it's not our message crc.",0,0.9872774481773376
107161317,2614,ijuma,2017-03-21T14:00:52Z,why do we need the `flush`? we are waiting until the future completes already?,0,0.9786224961280823
107161936,2614,ijuma,2017-03-21T14:03:08Z,`logentries` -> `records`.,0,0.9874290823936462
107162213,2614,ijuma,2017-03-21T14:04:15Z,is it intentional that we want to wait for a send to complete before doing the next send? is it related to how many batches we create?,0,0.9641485214233398
107162877,2614,ijuma,2017-03-21T14:06:35Z,how we get `12`? maybe worth adding a comment?,0,0.9846038222312927
107163216,2614,ijuma,2017-03-21T14:07:51Z,"hmm, can we not use a constant for the offset as we had before?",0,0.980006217956543
107166963,2614,ijuma,2017-03-21T14:21:01Z,maybe we should have a shared constant for the magic offset since it's the same for all formats?,0,0.9851855635643005
107168486,2614,ijuma,2017-03-21T14:26:07Z,maybe we want to update this comment?,0,0.9819368720054626
107168520,2614,ijuma,2017-03-21T14:26:17Z,entry -> batch,0,0.9827650189399719
107168876,2614,ijuma,2017-03-21T14:27:23Z,i was wondering about the fact that `baseoffset` is not the same as `firstoffset` for compacted topics. do we care in cases like this?,0,0.8913754820823669
107169714,2614,ijuma,2017-03-21T14:30:03Z,seems like we need to update the scaladoc of this method. why are we now using `maxtimestamp` instead of the first timestamp?,0,0.9804902672767639
107170322,2614,ijuma,2017-03-21T14:32:15Z,logentry -> recordbatch,0,0.9874841570854187
107171955,2614,ijuma,2017-03-21T14:37:59Z,could some of this logic be moved to `fetchrequest` like we did for the `producerequest`? we could then also write a unit test to verify the behaviour (if we haven't already).,0,0.9889984726905823
107173311,2614,ijuma,2017-03-21T14:42:54Z,`logentryiteratormap` -> `recordbatchesiteratormap`,0,0.9840509295463562
107173784,2614,ijuma,2017-03-21T14:44:22Z,do we need to mention `recordbatch` explicitly here?,0,0.9857073426246643
107174475,2614,ijuma,2017-03-21T14:46:40Z,"should we change the message to mention batch size instead of message size? also, we may consider using `recordbatchtoolargeexception` (which already exists) although maybe later in case it may break things.",0,0.9884651899337769
107175231,2614,ijuma,2017-03-21T14:49:08Z,"nit: it may make sense to keep all the logic in one place. `shouldretainmessage` is only called from this method, so is there any reason not to just add the first check there as well?",0,0.9871041178703308
107177315,2614,ijuma,2017-03-21T14:55:27Z,"we stated in `recordbatch` that `baseoffset` remains the same after compaction. it would be good to specify the behaviour of other header fields like `lastoffset` and `maxtimestamp`. furthermore, we should make sure to test the specified behaviour for these cases (i.e. compaction removes the first/last item in the batch, compaction removed the item with the max timestamp). do we have these tests already?",0,0.9864755272865295
107180500,2614,ijuma,2017-03-21T15:05:51Z,nit: `s` is not needed and the line below.,0,0.9872989058494568
107181957,2614,ijuma,2017-03-21T15:10:49Z,haha,1,0.8607993721961975
107183186,2614,ijuma,2017-03-21T15:15:06Z,`maybebatch` or we can just remove the val altogether.,0,0.9861868619918823
107183305,2614,ijuma,2017-03-21T15:15:30Z,logentry -> recordbatch,0,0.9874841570854187
107183565,2614,ijuma,2017-03-21T15:16:32Z,shallowlogentry -> recordbatch,0,0.9859106540679932
107183893,2614,ijuma,2017-03-21T15:17:43Z,entries -> batches,0,0.9849558472633362
107183937,2614,ijuma,2017-03-21T15:17:54Z,we can remove the comment.,0,0.9867160320281982
107184438,2614,ijuma,2017-03-21T15:19:43Z,"i don't understand this comment. what about compaction? also, we handle compressed and uncompressed the same now, so maybe there's no point in mentioning `uncompressed`?",0,0.6649964451789856
107185244,2614,ijuma,2017-03-21T15:22:29Z,nit: space after `=`.,0,0.9866776466369629
107186719,2614,ijuma,2017-03-21T15:27:00Z,"it's a bit odd that we use all lowercase for the existing fields and camel-case for the new ones. would it make sense to use just one style (camel-case seems better, but not sure about compatibility guarantees)?",-1,0.6083731651306152
107187022,2614,ijuma,2017-03-21T15:28:05Z,"seems like we have no junit tests for `dumplogsegments` although the system tests do exercise it. i filed [a link] so that we can address this, but worth keeping in mind that manual verification is needed in the meantime.",0,0.9781503081321716
107193728,2614,ijuma,2017-03-21T15:50:46Z,"i removed this, the other `convert` method, `convertsize` and the tests that called these methods and the code compiled. seems like they are unused and can be removed. we must make sure that the conversion cases are still tested before removing the tests that call these methods.",0,0.9824036359786987
107198136,2614,ijuma,2017-03-21T16:05:51Z,would it be clearer if we called this `outerrecord` or something?,0,0.9873886108398438
107200862,2614,ijuma,2017-03-21T16:16:00Z,we don't need to wrap `iterator`. the following makes it compile: [code block] what do you think?,0,0.9881293773651123
107226762,2614,hachikuji,2017-03-21T17:47:22Z,guess that's the danger of using the optimize imports shortcut.,0,0.7945347428321838
107264435,2614,hachikuji,2017-03-21T20:20:55Z,you are right. it seems unnecessary and the test works without it.,0,0.9584718346595764
107268478,2614,hachikuji,2017-03-21T20:37:34Z,"right. a lot of the testing around the max message size is obviously sensitive to how the messages are batched. if possible, i'd like to save refactoring of these test cases for a follow-up.",0,0.9767845273017883
107268800,2614,hachikuji,2017-03-21T20:38:59Z,i think we can use `recordbatch.max_record_overhead`,0,0.9868391156196594
107269975,2614,ijuma,2017-03-21T20:43:55Z,sounds good.,1,0.9202015399932861
107270196,2614,hachikuji,2017-03-21T20:44:52Z,i'm not sure we need a dependence on the offset here. maybe we can just flips some arbitrary bits in the payload?,0,0.944420576095581
107272979,2614,ijuma,2017-03-21T20:56:40Z,"ah, i understand what you did now. maybe add a comment?",0,0.9536080956459045
107279979,2614,hachikuji,2017-03-21T21:27:11Z,"i think the invariant we are trying to maintain is that the offsets added to the index are strictly increasing, so using the base offset in place of the first offset seems sufficient and avoids the decompression needed to find the actual first offset.",0,0.9788067936897278
107281528,2614,hachikuji,2017-03-21T21:34:02Z,"the behavior is not actually different. recall that this is ""shallow"" iteration in the old code. the timestamp we are accessing is actually the max timestamp when the record is viewed as a batch. in the uncompressed case, the ""batch"" has just a single record so the timestamp is the same as its max timestamp. in the compressed case, the timestamp is the max timestamp of all records in the batch. we preserve the old behavior and adopt the old compressed behavior for the new message format. i can update the comment to clarify this.",0,0.9836835265159607
107283016,2614,hachikuji,2017-03-21T21:40:57Z,"it is possible, but i am not sure conversion is something we want to hide too deeply. maybe we can consider this for a follow-up?",-1,0.5935549736022949
107286163,2614,hachikuji,2017-03-21T21:56:43Z,"this is a good point. the current usage of `recordbatchtoolargeexception` is to indicate when a batch exceeds the log segment size, but this only really made sense for the old format without compression. it might be worthwhile considering in a follow-up whether we have need to reuse this error for other purposes. for now, i'll update the message.",1,0.8569012880325317
107290844,2614,hachikuji,2017-03-21T22:22:17Z,"see memoryrecordstest.filterto. the test is kind of a bear, but it covers a large number of cases. i'll update the doc for `lastoffset` and `maxtimestamp`.",0,0.9776860475540161
107292917,2614,hachikuji,2017-03-21T22:34:27Z,"yeah... debated on this. all lower-case is hard to read (e.g. ""partitionleaderepoch""), but i wasn't sure about compatibility.",-1,0.5234307050704956
107294949,2614,ijuma,2017-03-21T22:46:13Z,"ok, maybe we can consider using camel-case for the existing fields in a follow-up.",0,0.9851652383804321
107295245,2614,ijuma,2017-03-21T22:48:12Z,"follow-up is fine. generally, i think it's a good pattern to keep the logic in `kafkaapis` simple since it makes it harder to test.",0,0.753474235534668
107296984,2614,hachikuji,2017-03-21T22:58:41Z,"yeah, that's a good idea.",1,0.9549052715301514
107297922,2614,hachikuji,2017-03-21T23:04:56Z,good call. seems better.,1,0.9638674855232239
107298677,2614,hachikuji,2017-03-21T23:09:57Z,"yes, i agree. there are probably ways we can do it so that we keep so visibility into the fact that the down-conversion is happening behind the scenes (maybe just comments).",0,0.9683674573898315
107316444,2614,ijuma,2017-03-22T01:37:53Z,"i was going to suggest removing this, but was unsure. happy that you did it anyway. :)",1,0.9932791590690613
107318058,2614,ijuma,2017-03-22T01:55:28Z,"my bad, you're right. thanks for updating the comment.",-1,0.9839506149291992
107327673,2614,ijuma,2017-03-22T03:43:37Z,"copied and pasted from the method comment, so we can delete it, i think.",0,0.9887035489082336
107328065,2614,ijuma,2017-03-22T03:48:46Z,was this never required? it seems like we don't do it any more.,-1,0.572393000125885
107334914,2614,junrao,2017-03-22T05:25:37Z,move this to previous line?,0,0.9871882200241089
107334929,2614,junrao,2017-03-22T05:25:48Z,logentries => recordbatch?,0,0.9874475598335266
107334933,2614,junrao,2017-03-22T05:25:51Z,the the => the,0,0.9738255143165588
107398114,2614,ijuma,2017-03-22T12:14:51Z,do you know why we had 2 builders?,0,0.9829220771789551
107412161,2614,ijuma,2017-03-22T13:29:38Z,did we decide on this one?,0,0.9743435382843018
107415960,2614,ijuma,2017-03-22T13:45:00Z,nice that we avoid the overhead of the streams here.,0,0.7823446989059448
107425811,2614,ijuma,2017-03-22T14:22:21Z,"yes, i agree that it's worth adding a brief comment explaining until we fix the issue.",0,0.9344691634178162
107441751,2614,ijuma,2017-03-22T15:15:15Z,"is it ok that we don't check the magic here, but we do for the append that takes a legacy record?",0,0.9815883636474609
107494215,2614,hachikuji,2017-03-22T18:23:25Z,looks like i forgot this one. i'll fix.,0,0.9346386194229126
107498549,2614,hachikuji,2017-03-22T18:39:56Z,"yeah, that's a good question. i'm not sure there's a good reason for the check in the `legacyrecord` case. i think initially we were doing something like copying the bytes directly, so it may have made more sense before.",0,0.886376678943634
107499252,2614,hachikuji,2017-03-22T18:42:53Z,"oh, i guess we still do the memory copy in this case. the question is whether we should?",0,0.9771516919136047
107510450,2614,hachikuji,2017-03-22T19:32:49Z,i think we were verifying the auto-incrementing behavior. i will verify that we have both cases covered.,0,0.9854620695114136
107539054,2614,ijuma,2017-03-22T21:34:50Z,this method is only used by `bytebuffermessageset` (i.e. scala clients) so it seems ok to favour consistency over optimisation in this case.,0,0.9855378270149231
107768943,2614,ijuma,2017-03-23T19:58:09Z,why doesn't assertequals work here?,0,0.9349704384803772
107769018,2614,ijuma,2017-03-23T19:58:34Z,would it be worth adding some timestamp assertions as well?,0,0.986583411693573
107773329,2614,ijuma,2017-03-23T20:19:57Z,"`non-compressed` should be removed, right?",0,0.9871311783790588
107773377,2614,ijuma,2017-03-23T20:20:11Z,`verifyconvertedbatches`,0,0.9827300310134888
107774031,2614,hachikuji,2017-03-23T20:23:08Z,"we only convert messages when necessary. so if we down-convert a batch to version 1, and we have messages which are magic 0, we won't up-convert them to 1.",0,0.9816741943359375
107774243,2614,hachikuji,2017-03-23T20:24:03Z,ack. may as well.,0,0.9814640879631042
107839904,2614,junrao,2017-03-24T06:02:41Z,"actually, if crc only covers from attributes to the end, do we really need to switch partitionleaderepoch and crc?",0,0.9866906404495239
107886287,2614,ijuma,2017-03-24T11:52:21Z,"it's true that the change is not strictly needed. the reasoning for the switch is that this way the crc includes everything that follows it (same as for v0 and v1 formats). in v0 and v1, the offset and length are before the crc and are not included in the computation. in v2, the offset, length, partitionleaderepoch and magic are before the crc and not included in the computation. given that, do you think the benefit is worth the switch?",0,0.9802462458610535
107915842,2614,junrao,2017-03-24T14:33:18Z,"earlier, jason's proposal is to put crc to the very end after records and covers everything from magic. if we do that, the switch is not ideal, but makes sense. if crc is still at the front, then it seems leaving crc in its current location causes less confusion.",0,0.9450200796127319
107921226,2614,ijuma,2017-03-24T14:55:05Z,"if we leave the crc in the same position as in v0 and v1, would you still change the computation to be from attributes to the end? a couple of alternatives (each with pros/cons): 1. include magic in the crc computation, but not partitionleaderepoch (con: we'd have to call `checksum.update` twice instead of once). 2. compute the crc from magic to the end (as it was before), but with partitionleaderepoch always assumed to be -1. this makes the computation simple on the producer side, but it's a bit tricky after the partitionleaderepoch has been set. this is a bit similar to how tcp includes the checksum field in the checksum computation, but assumes it to be always 0 (to avoid the chicken and egg problem).",0,0.9785364270210266
107945087,2614,hachikuji,2017-03-24T16:30:20Z,"i think we can swap the crc and leader epoch fields in the current version, but keep the scope of the crc unchanged. in other words: [code block] it's a little odd that we change the scope of the crc in this format, but perhaps it's less odd than changing the location of the field entirely.",0,0.9652462005615234
107954369,2614,hachikuji,2017-03-24T17:13:11Z,"this is a tough one. it's nice being consistent with the old format to some extent, but clients would still need to look at the magic byte first to figure out how to validate the crc, so maybe the consistency win is marginal. the main advantage of the format in the current patch is that it's clear at a glance what is covered by the crc, so it seems easier to explain.",0,0.6166144609451294
107982462,2614,ijuma,2017-03-24T19:27:43Z,discussed offline and jun said he was ok with leaving as is.,0,0.9721445441246033
108027606,2614,lindong28,2017-03-25T04:13:03Z,bug: we should use `partitionresponseheader` instead of `partitionresponse` to get the response. i guess this is not discovered by any test because the current patch always has `last_stable_offset = -1l`?,0,0.9293215274810791
108040126,2614,ijuma,2017-03-25T16:48:09Z,thanks for catching this . this field won't be used until the transactional code lands. i submitted a pr with tests: [a link],1,0.9545122981071472
139199834,3874,ijuma,2017-09-15T16:59:14Z,i assume this is not intentional :),-1,0.42577582597732544
139200069,3874,lindong28,2017-09-15T17:00:26Z,i made this to skip findbug and speedup test execution while i am still debugging my test :),1,0.9549449682235718
139200184,3874,lindong28,2017-09-15T17:00:59Z,the code is almost ready. i will let you know once it is done today.,0,0.8952367305755615
139200865,3874,tombentley,2017-09-15T17:04:32Z,"`renameddir` was instantiated in the line above, it can't possibly `== dir`. i think you mean `.equals()`",0,0.9832034111022949
139204236,3874,tombentley,2017-09-15T17:20:39Z,but if replication factor == 1 we've lost the log? from the description you give it sounds like we lose track of the state of the renaming because the only information to go on are the names of the files in the directory. could this be solved by having a transaction log file for the deletion in the same directory?,0,0.9815110564231873
139204483,3874,ijuma,2017-09-15T17:21:46Z,`==` in scala is _not_ reference equality.,0,0.9709572792053223
139206306,3874,tombentley,2017-09-15T17:29:35Z,why is this necessary? a comment to explain why would be useful.,0,0.9750750660896301
139206895,3874,tombentley,2017-09-15T17:32:07Z,doh! thank you.,1,0.9712028503417969
139276166,3874,lindong28,2017-09-16T02:26:05Z,thanks for the comment. the patch you saw was fully ready for review. the patch has been updated now with better code.,1,0.9229698181152344
139276169,3874,lindong28,2017-09-16T02:26:25Z,i will comment on this later.,0,0.9752540588378906
139527305,3874,junrao,2017-09-18T20:11:53Z,perhaps we can just get rid of the return value since it always returns errors.none?,0,0.9817103743553162
139529322,3874,junrao,2017-09-18T20:20:37Z,"i thought if destinationdir is any, we will also cancel any existing disk movement?",0,0.989652693271637
139531084,3874,junrao,2017-09-18T20:27:42Z,there is one otherwise in 1) and another in 2). it's very not clear which is matched to which if.,0,0.7092683911323547
139532975,3874,junrao,2017-09-18T20:35:32Z,it seems that 1) and 2) are in reverse order of the code below.,0,0.9825559854507446
139534077,3874,junrao,2017-09-18T20:40:13Z,should logmanager.updatepreferredlogdir() only remember the preferred log dir if the log doesn't exist?,0,0.9882420897483826
139534824,3874,junrao,2017-09-18T20:43:15Z,should we handle the case when destinationdir is any?,0,0.9891806244850159
139536481,3874,junrao,2017-09-18T20:49:55Z,we use ( for .filter and { for .map. we probably want to be consistent.,0,0.9817551374435425
139539863,3874,junrao,2017-09-18T21:03:29Z,"probably simpler to say ""if the replica is not created or is offline"".",0,0.9847346544265747
139554816,3874,junrao,2017-09-18T22:16:43Z,it seems that we can just combine the logging here and that in line 1398?,0,0.9887668490409851
139555164,3874,junrao,2017-09-18T22:18:40Z,"could we add a comment to explain futurelogs a bit? also, for consistency, should we rename logs to sth like primarylogs or currentlogs?",0,0.9891981482505798
139555761,3874,junrao,2017-09-18T22:22:13Z,we probably want to do foreach{ topicpartition => ...} to be consistent?,0,0.9868860244750977
139557211,3874,junrao,2017-09-18T22:31:11Z,perhaps offlinedirs could be a set?,0,0.9881513118743896
139558508,3874,junrao,2017-09-18T22:39:37Z,should we add isfuture to the param list in the comment above?,0,0.9877113699913025
139558693,3874,junrao,2017-09-18T22:40:43Z,"hmm, it seems that every time we truncate a log, we want to truncate the future log to the same offset? ditto for truncatefullyandstartat().",-1,0.703757107257843
139559651,3874,junrao,2017-09-18T22:46:53Z,should we add the missing param topicpartition and isfuture in the comment above?,0,0.9852747917175293
139560220,3874,junrao,2017-09-18T22:50:27Z,new params missing in the comment above.,0,0.9606798887252808
139562965,3874,junrao,2017-09-18T23:08:38Z,it seems that this should be an illegalstateexception since this is not expected?,0,0.9236359000205994
139563311,3874,junrao,2017-09-18T23:10:55Z,"if we check the preferredlogdir when it's added, it seems this should also be an illegalstateexception.",0,0.9799466729164124
139566414,3874,junrao,2017-09-18T23:33:03Z,typo direcotory,0,0.9873455166816711
139566677,3874,junrao,2017-09-18T23:35:00Z,"we probably want to use consistent naming in comments and variables(e.g., primary/secondary or current/future or sth else.)",0,0.9858583807945251
139567451,3874,junrao,2017-09-18T23:40:32Z,"could we move in the following sequence to avoid this corner case issue? 1. rename futurelog to log.completed. 2. rename currentlog to log.deleted. 3. rename log.completed to log. this way, if we fail at any step, we will have either log.completed or log to recover from. we probably also don't need the logic to rename back in the failure case. we just need some extra logic in loadlogs().",0,0.9830295443534851
139572154,3874,junrao,2017-09-19T00:16:49Z,should we include futurelogs in logsbytopicpartition too?,0,0.9879619479179382
139572695,3874,junrao,2017-09-19T00:22:02Z,could we use named variables instead of _._1 and _._2?,0,0.9879077076911926
139576864,3874,junrao,2017-09-19T01:03:50Z,"this doesn't seem to be a complete sentence. are we missing ""when"" before ""the future""?",0,0.8494191765785217
139578305,3874,junrao,2017-09-19T01:19:00Z,"the kip says using zero-copy to move data btw disks, but this is not. we probably can file a separate followup jira to revisit whether such an optimization is worth doing.",0,0.9874694347381592
139579858,3874,junrao,2017-09-19T01:35:23Z,"hmm, this doesn't look right. it seems that we want to use the future replica's latest epoch to build the leaderepochrequest.",0,0.7431398034095764
139582141,3874,junrao,2017-09-19T01:58:07Z,we probably want to use current/future replica instead of leader/follower.,0,0.9835147857666016
139812138,3874,junrao,2017-09-19T20:42:26Z,replicafetchermanager probably needs to be changed accordingly?,0,0.985099732875824
139834520,3874,junrao,2017-09-19T22:28:37Z,"after we do the swap, there is no checkpoint file for log cleaner. this means that we need to clean the compacted topic from the beginning, which is not ideal. one option is to copy the checkpoint to the destination log dir at the beginning of the data movement.",0,0.9842742085456848
139835264,3874,junrao,2017-09-19T22:33:34Z,"hmm, do we need this? it seems that any replica being moved across disks should be subject to throttling. the reason that we have this for inter-broker replication throttling is to avoid throttling replicas already in sync.",0,0.9858163595199585
139835968,3874,junrao,2017-09-19T22:37:48Z,typo betwee,0,0.9870964288711548
139836442,3874,junrao,2017-09-19T22:40:29Z,"we have another quota for log cleaning, which is also intra broker. to avoid confusion, would it be better to name this sth like ""replication.across.dirs.throttled.rate""?",0,0.9874184131622314
139836798,3874,junrao,2017-09-19T22:42:41Z,"hmm, this wasn't in the kip. do we need this at the topic level?",0,0.9820677042007446
139843596,3874,junrao,2017-09-19T23:32:07Z,"to make it clear, would it be better to rename assignedreplicas to replicasassignedtofuturedir?",0,0.9886386394500732
139844894,3874,junrao,2017-09-19T23:42:00Z,does log need to be var?,0,0.9874881505966187
139846597,3874,junrao,2017-09-19T23:55:45Z,"hmm, why do we need to remove newofflinepartitions from replicaalterdirmanager?",0,0.9823585152626038
139849668,3874,junrao,2017-09-20T00:19:58Z,"hmm, the issue with this approach is that if one thread has no partition left and another thread has multiple partitions, we can't let the former to pick up the load from the latter. an alternative is to put all partitions in a queue and let alterreplicathreads pick up one partition at a time from the queue. this will improve the thread utilization.",0,0.9783867597579956
139851404,3874,lindong28,2017-09-20T00:32:57Z,sure. i will update the patch to get rid of the return value in this method.,0,0.9720572233200073
139852351,3874,lindong28,2017-09-20T00:41:27Z,"ah i forgot this. i just checked the kip-113 wiki and it does say that broker will cancel existing movement if ""any"" is specified as the destination log directory. i am wondering if we should to make the cancellation operation more explicit by saying, if ""cancel"" is specified as the destination log directory, the existing movement of this replica should be canceled. the issue with the existing design in the wiki is that user can not distinguish between ""don't care"" and ""cancel existing movement"". what do you think?",-1,0.6845951080322266
139852501,3874,lindong28,2017-09-20T00:42:38Z,yeah it is more readable to reorder the comment. i will change it as suggested. thanks.,1,0.9335994124412537
139854278,3874,junrao,2017-09-20T00:59:03Z,"yes, explicitly modeling cancellation will be better. perhaps we can change alter_replica_dir_request to sth like the following. alterreplicadirrequest => [movedpartitions] [cancelledpartitions] movedpartitions => logdir [topic [partitions]] cancelledpartitions => [topic [partitions]] with that, i am not sure we still need to support any in logdir anymore.",0,0.9821227788925171
139854818,3874,lindong28,2017-09-20T01:04:35Z,"i have considered the suggested approach. i think the current approach may be simpler. - if we only remember the preferred log dir when the log doesn't exist, then in order to create the future log in the destination directory, the destination log directory needs to be passed to both `partition.getorcreatereplica(...)` and `logmanager.getorcreatelog()`, thus adding one more parameter to each method. - in addition, the suggested approach means that there will be two different ways that destination log directory is passed to logmanager, i.e. `logmanager.getorcreatelog(...)` and `logmanager.updatepreferredlogdir(...)`. this makes the logic a bit more complicated than the current patch. on the other hand, i think we only need to do `logmanager.updatepreferredlogdir()` if neither the current log nor the future log is in the user-specified log directory. i will update the patch to do it. what do you think?",0,0.9600350856781006
139855447,3874,lindong28,2017-09-20T01:11:06Z,my bad.. i have updated the comment as shown below: [code block],-1,0.9899505376815796
139855723,3874,lindong28,2017-09-20T01:14:06Z,"in the current patch, `any` will be read and filtered by `reassignpartitionscommand` such that broker will not see or handle `any` as the destination log directory. this may change if we want to allow user to cancel ongoing movement. i will reply to the other command after thinking through this.",0,0.9879204034805298
139855851,3874,lindong28,2017-09-20T01:14:55Z,sure. i have updated the patch to use `}` consistently.,0,0.9637580513954163
139855941,3874,lindong28,2017-09-20T01:15:47Z,good point. i have updated the comment as suggested.,1,0.9414119124412537
139856155,3874,lindong28,2017-09-20T01:17:43Z,i think `replicaalterdirmanager` will only be able to fetch data from source log of a partition if the source log of the partition is on an offline log directory. thus newofflinepartitions should be removed from replicaalterdirmanager. does this make sense?,0,0.9882135391235352
139856530,3874,junrao,2017-09-20T01:21:52Z,"yes, that makes sense.",0,0.9645439386367798
139856926,3874,lindong28,2017-09-20T01:26:19Z,sure. i have updated the patch to combine these two statements and the statement in line 1401 into this: [code block],0,0.9737913608551025
139856929,3874,junrao,2017-09-20T01:26:21Z,got it. make sense. thanks.,1,0.9564512372016907
139858472,3874,lindong28,2017-09-20T01:42:28Z,sure. i have fixed this as suggested. i will pass over the entire patch later to see if this needs to be fixed in anywhere else.,0,0.9633620381355286
139858629,3874,lindong28,2017-09-20T01:44:04Z,sure. i have updated the patch to use set.,0,0.967136800289154
139859230,3874,lindong28,2017-09-20T01:50:05Z,you are right. i have updated the patch to document `isfuture` for all methods in logmanager as appropriate.,0,0.8414782285690308
139859392,3874,lindong28,2017-09-20T01:51:53Z,sure. i have updated the patch to document parameters of this method.,0,0.9601491689682007
139859579,3874,lindong28,2017-09-20T01:53:57Z,sure. i have updated the patch to document all parameters of this method.,0,0.9589171409606934
139859792,3874,lindong28,2017-09-20T01:56:03Z,sure. i have updated the patch to use illegalstateexception here.,0,0.9829692244529724
139859805,3874,lindong28,2017-09-20T01:56:11Z,good point. i have updated the patch to use illegalstateexception here.,1,0.9223800897598267
139868382,3874,lindong28,2017-09-20T03:30:21Z,"good point regarding the cleaner checkpoint. i am wondering if it may be better to simply pause log cleaner for all those partitions that are being moved to other log directories. this approach may have two advantages over the suggested approach of saving copying the checkpoint file at the beginning of the data movement: - the broker performance is better than the suggested approach. with the suggested approach, broker needs to clean the data after the checkpoint twice. it is better to only do log cleaning after the partition has been moved to the destination log directory. - the implementation is simpler than the suggested approach. with the suggested approach, the offset for the same partition will be recorded twice in two log directories. and we will need to have more logic in logcleanermanager.allcleanercheckpoints() to differentiate between checkpoint of primary log and the checkpoint of the future log. and we probably need to take more care to keep the checkpoints across log directories consistent if e.g. log renames during swap phase failed. the only concern may be that the size of the compacted partition in the source log directory may be larger than if it is compacted. it is only a concern if replica movement takes a long time. and if this is the case, we probably already have problem with the size of the future log in the destination log directory anyway. what do you think?",1,0.6718453168869019
139870056,3874,lindong28,2017-09-20T03:51:41Z,"`any` is only used in the json file that is provided to the `reassignpartitionscommand`. this is necessary in the case that user only wants to specify log directory for one out of three replicas for a given partition. in that case the `log_dirs` field in the json file will be something like `[""any"", ""/path/to/logdir"", ""any""]`. also note that `reassignpartitionscommand` will filter out the `any` before it constructs alterreplicadirrequest. thus `any` will not be specified as log directory in alterreplicadirrequest and broker does not need to understand this constant. after more thinking, i think we probably don't need to provide a constant for user to cancel ongoing reassignment. there are two use-case for cancelling replica movement. one use-case is that user wants the replica to stay in the current log directory and he/she already knows the absolute path of the current log directory. in this case user can simply reassign partition again using the current log directory as the destination log directory. replicamanager will stop replica movement as appropriate. the other use-case is that user wants to save broker io by stop moving replica. in this case it is probably better to use quota to throttle replica movement. and user can also use either `kafka-log-dirs.sh` or `adminclient.describereplicalogdir` to read the current log directory (and lag) of the partitions that are being moved, and reassign replica again with the current log directory as the destination log directory. thus it seems that we don't need to support explicit cancellation. also, given that we are on a tight schedule to put this patch in 1.0 release, it may be better to try to reduce big changes to the patch unless it is necessary for the jbod feature.",0,0.987744152545929
139875419,3874,lindong28,2017-09-20T04:56:06Z,thanks. i have updated the patch to fix it.,1,0.9240832924842834
139875907,3874,lindong28,2017-09-20T05:03:18Z,good point. i have updated the patch to consistently use current/future in the comment everywhere in this patch. i verified this by searching for primary in the diff.,1,0.9640346169471741
139876330,3874,lindong28,2017-09-20T05:08:49Z,this method is only used in test. we can not naively include futurelogs in logsbytopicpartition because it returns a map with topicpartition as key. i have updated the patch to remove this method and replaced its use in test with logmanger.getlog().,0,0.9876977801322937
139876533,3874,lindong28,2017-09-20T05:11:11Z,sure. it is fixed now.,0,0.9471368193626404
139878127,3874,lindong28,2017-09-20T05:29:13Z,my bad. it is fixed now.,-1,0.9876018166542053
139878292,3874,lindong28,2017-09-20T05:31:07Z,yes. we should consider zero-copy. we probably don't have time to investigate it in this patch due to the 1.0 release deadline.,0,0.9781911373138428
139878466,3874,lindong28,2017-09-20T05:32:42Z,"ah, my bad.. it is fixed now.",-1,0.9893993139266968
139879142,3874,lindong28,2017-09-20T05:39:57Z,i maybe wrong here because i have not read through the kip wiki of this epoch. the idea here is that replicaalterdirthread will always copy&past the epoch from the current replica to the future replica of this partition. thus it is safe to simply read the epoch and epoch offset from the current replica's cache. did i miss something here?,0,0.7038489580154419
139879604,3874,lindong28,2017-09-20T05:44:50Z,"yeah i have thought about this problem. the thing is that it requires change in the abstractfetchermanager to address this issue, or we need to create a new manager class for replicaalterdirthread. the code will be more complicated with either solution. currently the replica is assigned to threads using abstractfetchermanager.getfetcherid(...). suppose the hash function is good, it should roughly evenly balance the partition across the available replicaalterdirthread. maybe we can have a follow up jira to optimize this if the load imbalance across threads turn out to be an issue. does this sound ok?",0,0.9383251667022705
139879668,3874,lindong28,2017-09-20T05:45:30Z,my bad. thanks for catching this. it is fixed now.,-1,0.9847331643104553
139879987,3874,lindong28,2017-09-20T05:48:45Z,ah.. it is fixed now.,0,0.9581027030944824
139880505,3874,lindong28,2017-09-20T05:54:47Z,is `log.cleaner.io.max.bytes.per.second` the config for throttling log cleaning? i am not sure it is easy to be confused with `intra.broker.replication.throttled.rate`. the former uses `log.cleaner` in the name thus we know it is for log cleaner. the latter uses `replication` in the name and therefore we know it is for replication within the broker. did i miss something here?,0,0.9547176957130432
139881125,3874,lindong28,2017-09-20T06:00:27Z,yeah it wasn't in the kip.. it seems useful and reasonable to include in this patch. i can document this sensor in the kip-113 wiki. i think it may be useful to have it as topic level for debug purpose. but i am not strong on this. i have updated the patch to only record it for `alltopicsstats`.,-1,0.9037216305732727
139881570,3874,lindong28,2017-09-20T06:05:15Z,sure. i have renamed variables in this method and in reassignpartitions() as appropriate.,0,0.9806193113327026
139882608,3874,lindong28,2017-09-20T06:14:48Z,it needs to be var because `partition.maybedeleteandswapfuturereplica()` needs to do `replica.log = futurereplica.log`. alternative we can replace the current replica with the future replica in partition.allreplicasmap. but that means we need to copy states such as lastfetchtimems from the current replica to the future replica. and it takes extra care to maintain this when we add new state in the replica in the future. thus i choose the current approach because it is simpler.,0,0.9743477702140808
139883108,3874,lindong28,2017-09-20T06:18:41Z,"i have replied to the other comment. i think we probably don't need to change alterreplicadirrequest or reassignpartitionscommand. replicamanager will not need to handle the case when destinationdir is any because alterreplicadirrequest is not expected to specify ""any"" as log directory.",0,0.9889195561408997
139884242,3874,lindong28,2017-09-20T06:28:16Z,sure. i added the following comment and renamed `logs` to `currentlogs`. [code block],0,0.9824726581573486
139885668,3874,lindong28,2017-09-20T06:40:07Z,"my gut feel is that the logic is harder to be correct if we add more suffix and more rename steps. for example, the following sequence of events may happen with the suggested approach: - futurelog is successfully renamed to log.completed. - currentlog can not be renamed due to log directory failure. - log.completed is renamed to log. if we do not rename it to log now, then when the broker starts with currentlog still offfline, broker will forget about currentlog and will need to rename log.completed to log - now broker restarts again with currentlog online. broker sees two copies of log for the same partition. it will be hard for broker to decide which one to use if the log has been truncated when currentlog is still offline. i think the current approach has simpler with less suffix. it will cause the replica to be deleted in very rare scenario. and even then the broker should be able to recover from this as long as rf > 1. if rf = 1, kafka can not ensure no data loss anyway due to disk failure.",-1,0.8773036599159241
139891303,3874,lindong28,2017-09-20T07:15:24Z,"currently the the future replica will only be written by the replicaalterdirthread. and the current log will only be written by replicafetcherthread and kafkarequesthandler. the replicaalterdirthread is responsible for fetch data from current log to the future log in the same way that replicafetcherthread fetches data from leader to follower. the advantage of this design is that 1) the design is simpler because replicaalterdirthread uses essentially the same logic as replicafetcherthread; and 2) most new logic for intra-broker replication is handled by replicaalterdirthread and replicafetcherthread won't need to worry about the future log. in order to address this problem cleanly while still keep the pattern described above, i have updated the patch so that logmanager.truncateto() will always be called from partition.truncateto(). and the same for truncatefullyandstartat(). in partition.truncateto() will grab the read lock `partition.leaderisrupdatelock` before truncating the log. with the use of partition.leaderisrupdatelock, the current patch ensures that when `partition.maybedeleteandswapfuturereplica()` calls `logmanager.deleteandswapfuturelog`, it is guaranteed that `replica.logendoffset == futurereplica.logendoffset` and no thread can truncate or write the log because all write operation will need to grab `leaderisrupdatelock`. therefore, if the replicafetcherthread truncates the log to an offset smaller than the log end offset of the future log, it is guaranteed that replicaalterdirthread() will receives offsetoutofrangeexception and truncate the future log as well. does this make sense?",0,0.9633349180221558
139891823,3874,lindong28,2017-09-20T07:18:43Z,"just to double check, are you suggesting that we don't need `intrabrokerreplicationthrottledreplicasprop` and should assume that `intrabrokerreplicationthrottledrateprop` is applies to all replicas? i think it makes sense. i will update the patch after confirmation.",0,0.9862240552902222
140006970,3874,ijuma,2017-09-20T15:34:42Z,"seems like we made a bit of a mistake with the existing throttling configs in that they don't specify the unit. the log cleaner setting gets that right. also, it seems like `replication` should be reserved for data transfer between two replicas. are there two replicas here or is this just a case of copying data from one log dir to another?",0,0.9474161267280579
140017132,3874,junrao,2017-09-20T16:08:15Z,"yes, that's not a bad idea. we could pause log cleaning during disk movement and copy the cleaning point after the movement completes.",0,0.9597048163414001
140017691,3874,junrao,2017-09-20T16:10:29Z,"yes, we could make it simple for now that the only way to cancel is to specify the source log dir in alterreplicadirrequest.",0,0.9896087050437927
140021307,3874,junrao,2017-09-20T16:24:44Z,"after a power failure, it's possible for the future replica to have more data than the current replica after recovery. new data could then be appended to the current replica before the future replica resumes replicating. you could have data like the following. current replica: offset: 0 1 2 epoch: 1 1 2 value : v1 v2 v4 future replica: offset: 0 1 2 epoch: 1 1 1 value : v1 v2 v3 to reconcile the replicas, you want to use future replica's latest epoch (i.e. 1) to find the offset of the last offset in that epoch in the current replica so that the future replica can get rid of v3 and copy v4 over.",0,0.9736407995223999
140023208,3874,junrao,2017-09-20T16:32:18Z,"i was thinking that longer term, it may be better to have a single quota that covers all i/os within a broker (including log cleaner, moving data across disks, etc). in that case, a config name with ""intra.broker"" may be more appropriate. however, if we use that name for moving data across disks, it may make future naming a bit harder.",0,0.9633421301841736
140023952,3874,junrao,2017-09-20T16:35:04Z,"if we enable replication quota, the quota metric already tracks the byte rate across all moving partitions. so this seems redundant?",0,0.9728707075119019
140029825,3874,junrao,2017-09-20T16:58:12Z,"hmm, does it guarantee that? after the current replica truncates the data, new data could have been written to the current replica. when the future replica fetches from the current replica again, it may have seen the new data and therefore won't receive offsetoutofrangeexception. this will potentially lead to inconsistent data between the future and the current replica.",0,0.9764474034309387
140030015,3874,junrao,2017-09-20T16:58:55Z,"yes, that's my suggestion.",0,0.9783179759979248
140030170,3874,lindong28,2017-09-20T16:59:40Z,good point. i didn't consider the scenario that the future log may be ahead of the current log. i will updated the patch to use the latest epo of the future replica here.,1,0.8192066550254822
140031247,3874,lindong28,2017-09-20T17:04:23Z,thanks. i have updated the patch as suggested.,1,0.8496058583259583
140032664,3874,lindong28,2017-09-20T17:10:02Z,you are right. we no longer need this metric now that we will apply quota to all topic partitions. i have removed this metric from the patch.,0,0.8853052258491516
140034012,3874,junrao,2017-09-20T17:15:18Z,"yes, we can probably optimize this in the future if needed.",0,0.9842376112937927
140038010,3874,junrao,2017-09-20T17:30:37Z,": in general, i agree the simpler the better. however, changing suffix in the future potentially will be even more complicated in order to support upgrade. so, it's worth thinking a bit more to see if we can get things right in the first place. for the approach that i described above. i was thinking that if any step fails, you stop and skip the rest of the steps. you only clean this up during log recovery on startup. for the scenario that you described, the sequencing will be the following. a) futurelog is successfully renamed to log.completed. b) currentlog can not be renamed due to log directory failure. c) currentlog will be marked offline and disk movement is stopped. d) broker is restarted and the log dir for currentlog is still offline. disk movement is still stopped and log.completed is untouched. e) broker is restarted and the log dir for currentlog is online. continue with step 2) and 3) above during log recovery. this is a bit more complicated than your approach, but seems safer and matches how we do swapping in log cleaner.",0,0.7479155659675598
140038900,3874,lindong28,2017-09-20T17:33:45Z,"it is two replicas here instead of simply copying data from one log dir to another because we are maintaining states such as epoch and high watermark in the future replica. i think it is a good idea to have a single config to throttle all i/os within a broker. given that this probably needs to deprecate the existing `log.cleaner.io.max.bytes.per.second` config, maybe we should do it in a separate kip and find a good name for it? regarding this patch, i think `intra.broker.replication.throttled.rate` is ok because this name says ""replication"" which means fetching data from one replica to another. i am also good with `across.dirs.replication.throttled.rate` (which is more consistent with `leader.replication.throttled.rate`). do you prefer me to change the name to `across.dirs.replication.throttled.rate`?",0,0.6802597045898438
140062197,3874,junrao,2017-09-20T18:59:37Z,how about log.dirs.balancing.io.max.bytes.per.second ?,0,0.9880818128585815
140063395,3874,junrao,2017-09-20T19:04:27Z,typo ofr,0,0.981293261051178
140065045,3874,lindong28,2017-09-20T19:11:26Z,sure. i have updated the patch to rename this config and related variables as suggested.,0,0.9692153334617615
140086569,3874,junrao,2017-09-20T20:40:06Z,"should we remove the future replica too? otherwise, we may pick up the wrong futurereplica.logendoffset if logdir is changed again.",0,0.9674065709114075
140088276,3874,junrao,2017-09-20T20:47:14Z,"hmm, the logic seems to be the reverse of the comment.",0,0.9531131386756897
140090819,3874,junrao,2017-09-20T20:57:47Z,should we check if destinationdir is offline too and return an error if so?,0,0.9842866063117981
140097808,3874,junrao,2017-09-20T21:27:55Z,we should be using futurereplica's hw instead of currentreplica.,0,0.9857015609741211
140107358,3874,junrao,2017-09-20T22:17:02Z,"hmm, if the replica is a future one, it seems that we don't read the hw from the checkpoint. this may impact the initial offset for replication in the future replica.",0,0.9689440727233887
140109134,3874,lindong28,2017-09-20T22:28:01Z,"great point.. i have been thinking about the right solution since your comment. i have addressed the problem with the following changes to the patch: - add methods truncateto() and truncatefullyandstartat() in partition.scala. both methods need to grab readlock of leaderisrupdatelock before truncating the log. - add method appendrecordstofuturereplica() in partition.scala. this method needs to grab inwritelock of leaderisrupdatelock first. if leo of the current replica >= leo of the future replica, this method will append data to the future log. otherwise, this method will throw offsetoutofrangeexception. this method ensures that, if the current replica is truncated after replicaalterdirthread fetches from the current replica but before replicaalterdirthread try to append data to the future replica, the data will not be appended. - abstractfetcherthread.processfetchrequest() will catch offsetoutofrangeexception thrown from processpartitiondata(). when this exception is caught, the future replica will be truncated with handleoffsetoutofrange and marked for truncation. and the future replica will be truncated again based on the epoch when replicaalterdirthread calls maybetruncate() next time. does this solution sound ok? i am not sure very sure whether we need to both do handleoffsetoutofrange() and mark the log for truncation. maybe we need only one of them?",1,0.9720667004585266
140110357,3874,junrao,2017-09-20T22:35:50Z,are we really removing the partition from the source checkpoint file as the comment says?,0,0.9816515445709229
140111701,3874,lindong28,2017-09-20T22:44:47Z,my solution has a flaw. let me think about how to fix it..,-1,0.8783036470413208
140112065,3874,junrao,2017-09-20T22:47:32Z,should we remove future replicas for newofflinepartitions too?,0,0.9873281121253967
140115757,3874,junrao,2017-09-20T23:13:41Z,"hmm, i am not sure that we should do line 1080-1090 on every leaderandisr request especially the controller could re-send the same leaderandisr request. it seems that it's enough to just do this on the very first leaderandisr request (i.e., inside ""if (!hwthreadinitialized) {"").",0,0.8287096619606018
140122257,3874,lindong28,2017-09-21T00:03:31Z,"after more thinking, i made the following change to address the issue. - add method appendrecordstofuturereplica() in partition.scala. this method needs to grab inwritelock of leaderisrupdatelock to prevent race condition with log truncation on the current replica. after appending records to the future replica, this method will do the following. [code block] here is why this could address the issue. in order for the issue in this thread to happen, the following events need to happen: 1) replicaalterdirthread fetches some messages from the current replica 2) the current replica is truncated such that some data that was fetched above will be deleted from the current replica 3) new data is appended to the current replica after log truncation 4) replicaalterdirthread now appends the fetched data to the future replica. this causes inconsistency because it appends some data that was just truncated on the current replica. with the change made above, in step 4) the replicaalterdirthread will notice that the latest epoch of the current replica is larger than the latest epoch of the future replica while the offset of the first message with that epoch in the current replica is smaller than the offset of the last message in the fetched records. then the replicaalterdirthread can truncate the future replica to solve the problem. does this make sense?",0,0.9644390344619751
140122398,3874,lindong28,2017-09-21T00:04:44Z,thanks. it is fixed now.,1,0.8963304758071899
140122619,3874,lindong28,2017-09-21T00:06:29Z,thanks for catching this. it is fixed now.,1,0.8939259052276611
140122997,3874,junrao,2017-09-21T00:09:50Z,"i was thinking that one way to do this is that if the current replica truncates, we just remove the partition from the replicaalterdirthread and add it back again. this will force the initialization with proper truncation if needed.",0,0.9823909401893616
140123008,3874,lindong28,2017-09-21T00:09:58Z,thanks. you are right. i have updated the patch to fix this bug.,1,0.9568411111831665
140123222,3874,lindong28,2017-09-21T00:12:05Z,"i think alterreplicadir() already checks whether the destinationdir is offline at the beginning. if it is offline, it will return kafkastorageexception as error.",0,0.9876751899719238
140128580,3874,lindong28,2017-09-21T00:58:12Z,"my concern with doing it only on the first leaderandisrrequest is that this imposes two restrictions that it actually enforced now but may not be true in the future. one restriction is that controller needs to send all partitions in the first leaderandisrrequest to a broker. it is true as of now. but from design perspective broker should also be able to setup partition state properly if the partition is specified in the subsequent leaderandisrrequest. another restriction is that broker always need to shutdown after receiving stopreplicarequest with delete = false. otherwise, when broker receives leaderandisrrequest to be leader/follower for a partition, state of this partition may not be setup properly. this is also true for now. but it is just not very nice because ideally we should be able to send stopreplicarequest and leaderandisrrequest to stop/start a partition in a broker. i have updated the patch to address the problem by only doing line 1080 - 1090 for partitions that are online and not already created before the broker receives this leaderandisrrequest.",0,0.9378788471221924
140128968,3874,lindong28,2017-09-21T01:02:10Z,"newofflinepartitions will be removed from replicamanager.allpartitions. i think we probably don't need to remove the replica from partition.allreplicasmap if the partition object itself is going to be removed and garbage collected, right?",0,0.9849088788032532
140129564,3874,lindong28,2017-09-21T01:08:09Z,previously i think it is more accurate to just use the hw of the current replica. i have updated the patch to use hw of the future replica.,0,0.9823132157325745
140130152,3874,lindong28,2017-09-21T01:13:58Z,"yes i think so. it is same way as how logcleaner.updatecheckpoints() is used to remove partition from cleaner offset checkpoint file. logmanager.asyncdelete() will delete the log from logmanager.futurelogs before it calls `cleaner.updatecheckpoints`. the caller of altercheckpointdir(), in this case logmanager.deleteandswapfuturelog(), needs to update logmanager.currentlogs before it calls logmanager.deleteandswapfuturelog(). then `updatecheckpoints(sourcelogdir, none)` will remove the partition from source log directory and updatecheckpoints(destlogdir, option(topicpartition, offset)) will add the partition to the destination log directory.",0,0.985587477684021
140130593,3874,lindong28,2017-09-21T01:18:53Z,"i think we actually read hw from the checkpoint if the replica is a future one. when the future replica is newly created, it is ok that we don't have hw for the future replica because the log for this future replica is empty. then `replicamanager.checkpointhighwatermarks()` will checkpoint hw for the future replica in the destination log directory. when broker restarts and load the log, partition.getorcreatereplica() will read the hw checkpoint in the destination log directory for future replica as well. does this make sense?",0,0.9873144030570984
140131155,3874,lindong28,2017-09-21T01:24:40Z,"it seems that all other issues have been addressed. i need to think more about this issue more. let me first fix the test, cleanup the patch and upload it.",0,0.9494981169700623
140131332,3874,junrao,2017-09-21T01:26:46Z,thanks for the explanation. makes sense.,1,0.8184157013893127
140131769,3874,junrao,2017-09-21T01:31:31Z,"ok, sounds good.",1,0.787392258644104
140131983,3874,junrao,2017-09-21T01:34:06Z,thanks. make sense. missed that isreplicalocal() covers future replica too.,1,0.9342584013938904
140163072,3874,lindong28,2017-09-21T07:04:14Z,"i think the suggested approach will work. i am just wondering if the following approach would be simpler: in logmanager.deleteandswapfuturelog(): 1. rename futurelog to be the current log 2. rename currentlog to be deleted. and here is how we handle log directory failure: 1) futurelog is successfully renamed to be the current log 2) currentlog can not be renamed due to log directory failure 3) the log in the source log directory will be marked offline. the log in the destination log directory will serve as the current log and this partition is still online. 4) broker is restarted and the source log directory is still offline. nothing needs to be done. the partition is online. 5) broker is restarted and the source log directory is online. but the destination log directory is online. in this case the log in the source log directory will be truncated based on the leader epoch and will be try to catch up with the leader. 6) broker is restarted and both source and destination log directory is offline. logmanager.loadlogs() will choose the one with the larger latestepoch as the current log. if these two replicas has the same leader epoch, then the one with the larger nextoffset will be chosen as the current log. the other log will be marked for deletion. the advantage of this solution is that we don't need to new suffix, and we don't need to have the logic of renaming a log directory back-and-forth. this solution takes advantage of the leaderepoch to resolve conflicts. do you think this would be a good solution?",0,0.9542591571807861
140326737,3874,junrao,2017-09-21T18:40:08Z,": what you suggested is simpler. my concerns are the following: (1) it can't truly protect the case when the same partition shows up in more than one log dir (say by human mistakes). (2) the approach of using leaderepoch only works when the message format has been upgraded. however, users may not upgrade the message format immediately after upgrading the code. picking the replica based on just the offset is less reliable.",0,0.8904162645339966
140330274,3874,lindong28,2017-09-21T18:54:37Z,"regarding (1), if the same partition appears on multiple log directories due to human either, i think log manager can still choose the one with the highest epoch (or nextoffset if epoch is the same) to address the problem. is my understanding right? regarding (2), i am wondering if it is reasonable to support intra-broker replica movement only if message format has been increased to support leader epoch. i personally think it is a good tradeoff to keep the kafka implementation simpler in the long term. it seems reasonable for a new feature to rely on a message format that has come before it. btw, in my solution to another issue you raised, i.e. inconsistency between the current and the future replica, i also used this trick of leader epoch to address the problem. the solution to that problem will probably be less clean if we can not reply on leader epoch. i will need to think more about how to address these two problems if we want to allow user to move replica within broker with older message format.",0,0.86129230260849
140330487,3874,lindong28,2017-09-21T18:55:28Z,also note that kip-112 is only enabled if inter-broker-protocol is 1.0 or higher. i am wondering if the similar logic can be applied to determine whether kip-113 is fully supported.,0,0.9834409952163696
140347295,3874,junrao,2017-09-21T20:13:39Z,": for (1), if there is human error, the 2 replicas could correspond to the same topic created at different times. so, their leader epoch may not be directly comparable. it just feels safer if we have a more direct way to detect errors like this. for (2), note that inter-broker-protocol is separate from the message format. even when the message format is set, leader epoch only applies to newly produced messages.",0,0.9705867171287537
140361789,3874,junrao,2017-09-21T21:18:44Z,"hmm, i am not sure if we should lock the writes to the current replica while writing to the future replica. what you said earlier makes sense: we want the writes to the current and the future replica to be independent. another concern is that we are duplicating the logic for epoch checking in replicaalterdirsthread here. i was thinking that another way to do this is in partition.truncateto(), if the truncation is on a current replica, we simply remove it and add it back to the replicaalterdirmanager if it's there. the newly added partition will go through the initialization phase to do the truncation that's needed. this way, the writes to current and the future replica can still be independent.",0,0.875009298324585
140364258,3874,junrao,2017-09-21T21:30:09Z,could we replace replicamgr.getpartition(topicpartition).get with partition?,0,0.9891083240509033
140365688,3874,junrao,2017-09-21T21:36:34Z,it's not very clear what's being deleted from the name. would it be better to name this replacecurrentwithfuturelog?,0,0.936634361743927
140366268,3874,junrao,2017-09-21T21:39:25Z,it seems that we need to call replicaalterdirmanager.shutdownidlefetcherthreads() after a partition is removed?,0,0.9860605001449585
140369569,3874,junrao,2017-09-21T21:55:51Z,"there are various error loggings like that in line 220 with text ""error to broker .."". those lines are now shared between the replicafetcherthread and the replicaalterdirthread. so, we probably want to make the logging clearer.",0,0.9863770604133606
140370782,3874,junrao,2017-09-21T22:02:02Z,the reference to leader is not accurate here.,-1,0.6696550250053406
140371771,3874,junrao,2017-09-21T22:07:07Z,"hmm, shouldn't we get the startoffset from the future replica?",0,0.975620448589325
140375054,3874,junrao,2017-09-21T22:29:05Z,should we make this volatile now that it's updatable?,0,0.9657252430915833
140377631,3874,junrao,2017-09-21T22:47:03Z,we probably want to have a separate window size and window samples config for the intrabroker quota?,0,0.9868224859237671
140377671,3874,junrao,2017-09-21T22:47:19Z,intrabroker => logdirsbalancing?,0,0.9878448843955994
140379049,3874,junrao,2017-09-21T22:57:49Z,"to be consistent with the new throttling name, perhaps name this num.log.dirs.balancing.threads? if so, we want to change variable names, comments, and documentations accordingly.",0,0.9886416792869568
140379353,3874,junrao,2017-09-21T23:00:10Z,this is now unused.,0,0.9563758969306946
140380696,3874,junrao,2017-09-21T23:09:43Z,"hmm, leaderepochcache is maintained when records are appended to the log. so, not sure if we need to call initializeleaderepochcache() when renaming.",0,0.986200213432312
140380952,3874,junrao,2017-09-21T23:11:40Z,"if the dir name doesn't change, could we skip the steps below?",0,0.9861178994178772
140383875,3874,junrao,2017-09-21T23:34:10Z,could we add topicpartition too?,0,0.9872949719429016
140385799,3874,junrao,2017-09-21T23:51:11Z,we probably want to rename intra-broker-throttle to log-dirs-balancing-throttle?,0,0.9856607913970947
140385990,3874,junrao,2017-09-21T23:53:02Z,should we make it volatile?,0,0.9714395403862
140387569,3874,junrao,2017-09-22T00:07:08Z,unused import,0,0.9649426341056824
140389918,3874,junrao,2017-09-22T00:26:11Z,is the comment still valid?,0,0.9826034903526306
140389959,3874,junrao,2017-09-22T00:26:37Z,should we do the assert in a waituntil loop?,0,0.9868943691253662
140390517,3874,junrao,2017-09-22T00:32:46Z,"the replica on broker 100 is just changing the log dir. waitforreassignmenttocomplete() only checks for the completion of cross broker replica movement, but not of cross log dirs movement. perhaps we should do this in a waituntil() loop?",0,0.9887412190437317
140595813,3874,lindong28,2017-09-22T21:01:15Z,"regarding (2), i am thinking that it may be reasonable to say we only support inter-broker replica movement only if message format is supports epoch. this is similar to saying that we only support time-based query if message format supports time index, and we only kafkaheader if the message format support kafka header. this may be worth doing if it can keep the kafka implementation simpler in the long term. also regarding (2), my understanding is that we can use leader epoch to choose the newer log directory in this case after message format has been upgraded to support leader epoch, even if there is still old messages in the log that doesn't have leader epoch. this is because the trick here only look at the epoch of the latest message for each log directory. if this is not true then my approach would not work. regarding (1), i realized the following shortcomings of the suggested approach while trying to implement it. let me compare the suggested approach with my approach in more detail below. to clarify, my approach is the following: 1) rename futurelog to be the current log 2) rename currentlog to be deleted. the approach you suggested is the following: 1) rename futurelog to log.completed. 2) rename currentlog to log.deleted. 3) rename log.completed to log. pros of the suggested approach: - it allows user to move replica between log directories of the same broker before user has upgraded to the message format that support leader epoch. (a short term benefit) - it matches how we do swapping in log cleaner (i am not very sure the benefit of following the existing swapping logic in log cleaner in this case though. can you explain a bit more?) - it can help us detect human error if the user mistakenly copied a directory with old data to a broker which already has directory for this partition on another log directory. cons of the suggested approach: - if we fail at the step 2 (rename currentlog to log.deleted), we will mark the partition offline even if we can use the partition in the destination log directory. this reduces availability of the partition. - if we fail at step 3 (rename log.completed to log), we will still delete the replica in the source log directory because it has been successfully renamed for deletion. this reduces the persistence of the partition. - extra logic is needed to keep completable logs in a separate map in logmanager so that we can include its size in the describelogdirsresponse. we also need extra metric tag for log whose directory has be renamed to log.completed. this adds complexity to kafka implementation in the long term. - it doesn't protect against more complicated errors, e.g. if user deletes new log directory before copying the old log directory, or if user deletes specific segment for the partition. overall i think the ability to detect some human error is nice to have. but human error detection is generally hard to do and we don't have a good definition for the scope of human error that can be detected. i am not sure if this is worth the cost in availability and code complexity. actually, if we do want to detect this specific human error, we can also modify the my approach to have broker refuse to start if the same partition appears in more than one directory. this will generate false positive only if source log directory fails exactly at the time the destination partition has caught up with the source partition, which should be pretty. since user knows the log directory that was offline, he/she can manually delete the partition in the source log directory correctly and restart the broker. the reply is a bit long. thanks for taking time to read and discuss this issue.",0,0.8952093720436096
140636915,3874,junrao,2017-09-23T16:22:58Z,": i like the modified version of your approach. basically fail the broker if we detect duplicated logs during restart. this makes the logic simpler. with this, we probably don't need to have the constraint on message format.",1,0.7717142701148987
140643683,3874,lindong28,2017-09-23T23:16:22Z,"ah, i didn't realize you have replied to this thread. yeah i have considered this option. my concern with this approach is that truncation usually happens at the partition level or log level, but the management of replicaalterdirmanager and replicafetchermanager ideally should happen at the replicamanager level, which is higher than the level of partition and log. usually the level of caller should be higher than the level of caller to avoid deadlock and to make the code logic simpler to maintain and develop in the long term. in this specific case, if we add/remove partition from replicaalterdirmanager, a replicafetcherthread may need to get the following lock if truncation happens: abstractfetcherthread.partitionmaplock, partition.leaderisrupdatelock, replicamanager.replicastatechangelock, replicaalterdirmanager.maplock and replicaalterdirthread.maplock. this may cause deadlock if another kafkarequesthandler attempts to get the replicamanager.replicastatechangelock and then partition.leaderisrupdatelock. do you think the approach i suggested previously would work? do you have concern with having this approach depend on the leader epoch and thus the message format?",0,0.9588455557823181
140645077,3874,lindong28,2017-09-24T01:25:35Z,"yeah i have considered this option. my concern with this approach is that truncation usually happens at the partition level or log level, but the management of replicaalterdirmanager and replicafetchermanager ideally should happen at the replicamanager level, which is higher than the level of partition and log. usually the level of caller should be higher than the level of caller to avoid deadlock and to make the code logic simpler to maintain and develop in the long term. in this specific case, if we add/remove partition from replicaalterdirmanager, a replicafetcherthread may need to get the following lock if truncation happens: abstractfetcherthread.partitionmaplock, partition.leaderisrupdatelock, replicamanager.replicastatechangelock, replicaalterdirmanager.maplock and replicaalterdirthread.maplock. this may cause deadlock if another kafkarequesthandler attempts to get the replicamanager.replicastatechangelock and then partition.leaderisrupdatelock. regarding your concern with ""lock the writes to the current replica while writing to the future replica"", i think it probably won't hurt performance much. it will reduce the maximum throughput of writing to the current replica by at most half. but i assume that for most replica, the average throughput should be much less than 50% of the maximum throughput that a broker can write to a partition. furthermore, even if the throughput of this partition is very close to the maximum throughput, we actually want to reduce the throughput that a broker can write to the current replica before the future replica catches up. does this make sense? do you think the approach i suggested previously using leader epoch would work? do you have concern with having this approach depend on the leader epoch and thus the message format?",0,0.9507623910903931
140645086,3874,lindong28,2017-09-24T01:26:15Z,"regarding your concern with ""lock the writes to the current replica while writing to the future replica"", i think it probably won't hurt performance much. it will reduce the maximum throughput of writing to the current replica by at most half. but i assume that for most replica, the average throughput should be much less than 50% of the maximum throughput that a broker can write to a partition. furthermore, even if the throughput of this partition is very close to the maximum throughput, we actually want to reduce the throughput that a broker can write to the current replica before the future replica catches up. does this make sense? we can continue discussion under the new batch of comment you provided. thanks!",0,0.9462985992431641
140645139,3874,lindong28,2017-09-24T01:30:45Z,"my bad. previously i was very tight on the time and spent on most of the time on addressing the comments and have not spent enough time on reviewing the patch myself. now that i have time, i will review the patch myself twice and let you know once it is ready.",-1,0.9884965419769287
140645147,3874,lindong28,2017-09-24T01:31:10Z,the issue is fixed as suggested.,0,0.9827855229377747
140645440,3874,lindong28,2017-09-24T02:02:10Z,"i understand that ideally we want to shutdown idle threads. my concern with this approach is that it will let replicaalterdirthread depend on replicaalterdirmanager which introduce circular dependency and make it easier to have deadlock in the future. the only drawback of the current approach is that, there may be idle replicaalterdirthread until the broker receives the next leaderandisrrequest. during this period this replicaalterdirthread will call dowork() once every 1 second by default, which doesn't seem like a problem. thus i think the little performance overhead is better than complicating the kafka implementation. what do you think?",0,0.897652268409729
140645451,3874,lindong28,2017-09-24T02:03:35Z,my bad. it is fixed now.,-1,0.9876018166542053
140645510,3874,lindong28,2017-09-24T02:06:24Z,previously i thought it is always more accurate to simply read the logstartoffset (and similarly hw) from the current replica. i forgot to go over the patch and correct this after your previous comment regarding the use of hw. i will go over the patch twice to make sure all these are corrected. it is fixed as suggested.,0,0.9829703569412231
140648350,3874,lindong28,2017-09-24T06:20:07Z,it is fixed now. i should be able to fix missing parameters like this in the next update.,0,0.9847673773765564
140651820,3874,lindong28,2017-09-24T09:39:56Z,good point. i have updated the name as suggested. thanks!,1,0.9873611927032471
140653814,3874,lindong28,2017-09-24T11:24:16Z,"i am not sure i understand the problem here. it seems that current error logging in abstractfetcherthread is technically correct. for example, the `error to broker` in line 220 is correct because `sourcebroker.id` still refers to the broker from which the data is fetched, for both replicafetcherthread and replicaalterdirthread. furthermore, the log4j error logging already identifies the class (either replicafetcherthread or replicaalterdirthread) for those log statements in the abstractfetcherthread, thus there is probably no need to identify in the logging message whether it is for replicafetcherthread or replicaalterdirthread. does this make sense?",0,0.948676347732544
140653857,3874,lindong28,2017-09-24T11:25:59Z,good point! i have updated the patch to make it volatile.,1,0.9850451350212097
140653887,3874,lindong28,2017-09-24T11:27:44Z,it is fixed now. i will review the patch myself twice and try to catch all these things.,0,0.9511198401451111
140654025,3874,lindong28,2017-09-24T11:34:18Z,"i don't have a good reason for adding a separate window size and window samples. i think the main difference between interbroker and logdirsbalancing quota is the throttle rate which can already be configured differently for these two quotas. is there any scenario where user may want to use different window size and window samples for interbroker and logdirsbalancing quota? if not, maybe we can do it when we need it in the future?",0,0.8189619779586792
140654292,3874,lindong28,2017-09-24T11:48:32Z,"replicaalterdir describes the action of these threads and classes, whereas logdirsbalancing identifies the purpose of this action of moving replica. i think replicaalterdir* is more useful and explicit for kafka developer to understand the what these replicaalterdirthread is doing. on the other hand, logdirsbalancing is probably more useful for user to understand the purpose of this new quota. if we were to unify the name, i think it is better to use replace logdirsbalancing with replicaalterdir. the reason is that it is a bit weird and vague to have method like adminclient.logdirsbalancing(map ). and both developer and user probably needs to translate logdirsbalancing to replicaalterdir in order to understand what the new thread, thread manager and request is doing. what do you think?",0,0.9707274436950684
140654314,3874,lindong28,2017-09-24T11:49:27Z,sorry.. it is fixed now.,-1,0.9881338477134705
140654337,3874,lindong28,2017-09-24T11:50:30Z,good point. i have updated the patch as suggested.,1,0.9499228596687317
140654392,3874,lindong28,2017-09-24T11:53:26Z,"i think we need to call initializeleaderepochcache() because the leaderepochcheckpointfile.checkpoint.file is determined and fixed in initializeleaderepochcache(). thus if we don't call initializeleaderepochcache() after the log directory is renamed, leaderepochcheckpointfile.write() will still try to write to a file in the old log directory which no longer exists.",0,0.9876119494438171
140654406,3874,lindong28,2017-09-24T11:54:17Z,"yes, you are right. i will rename these.",0,0.9004783630371094
140654424,3874,lindong28,2017-09-24T11:54:59Z,ah.. fixed now.,0,0.9628986120223999
140654487,3874,lindong28,2017-09-24T11:57:27Z,thanks. i have updated the comment to the following. i will review the patch end-to-end twice to try to make comments and the code consistent after the previous changes. `// when we execute an assignment that moves an existing replica to another log directory on the same broker`,1,0.9371788501739502
140654577,3874,lindong28,2017-09-24T12:02:24Z,you are right. it is fixed now.,0,0.7697994709014893
140654729,3874,lindong28,2017-09-24T12:10:00Z,you are right. strictly speaking we should use waituntil() here. i have updated the patch accordingly.,0,0.9371464848518372
140683628,3874,junrao,2017-09-25T03:34:28Z,": your suggested approach probably works in the common case. my concerns are the following. (1) log truncation is a relatively rare event. your approach tries to solve the problem by requiring writes to future log to hold on to the lock to the current log on every write. so, we add overhead in the common path to solve a rare event. intuitively, to solve a rare event, we also want to add overhead in the rare path. (2) your approach won't be able to distinguish leader epoch inconsistency due to log truncation or bugs in kafka. in the latter case, we probably want to error out instead of continuing. (3) the dealing with leader epoch is tricky to reason about and is already done during replica initialization in the replicaalterdirthread. if possible, it would be useful to limit the places that we deal with leader epoch directly. (4) in theory, even if a topic has the new message format, a truncation may bring the log to the point where there is only old message. (5) intuitively, the disk balancing feature seems independent of message format. so, it feels a bit weird to require that. as for the concerns that you mentioned on the suggested approach. i am not sure we need to hold partition.leaderisrupdatelock. that lock is only needed when the replica set changes. truncating an existing future replica doesn't change replica set though. we do want to make sure that the reinitialization in the future replica is synchronized properly with potential concurrent alterlogdir requests, as you pointed out. so, the following is a slightly modified approach. after the replicafetchthread truncates the log, it will do the following: (1) call a new method in replicaalterdirthread.addpartitionswithtruncation that takes a partition and a truncating offset. this method won't directly do truncation in the future replica. it simply sets the partition state to be truncating if the partition is still present in the partition map. when replicaalterdirthread sees this new state, it ignores any pending fetch response and truncates the future log to the truncating offset, and then resumes fetching. addpartitionswithtruncation() needs to hold partitionmaplock. however, since only replicafetchthread.truncation can call replicaalterdirthread.addpartitionswithtruncation, but not vice versa. there is no cycle to form a deadlock. this approach seems to address all the above concerns: (1) no additional overhead in the write path, which is common, (2), (3) no additional logic for dealing with leader epoch, (4) and (5) doesn't require new message format. neither approach deals with the case when a truncation only happens on the current replica, but not the future replica, and the broker dies. this can still lead to the case when the future replica's log can be ahead of the current replica. if the message format doesn't have the leader epoch, this may not be dealt with cleanly during future replica initialization. we could potentially just truncate the future replica to the log end offset of the current replica in that case during recovery.",0,0.907477855682373
140683654,3874,junrao,2017-09-25T03:34:53Z,could we just add a scheduler thread that calls replicaalterdirmanager.shutdownidlefetcherthreads() periodically?,0,0.9895080327987671
140683674,3874,junrao,2017-09-25T03:35:14Z,"my point is that for replicaalterdirthread, the logging ""to broker"" doesn't convey much info since it always moves data within the same broker. when there is an error, it's more useful to know the source log dir from which the future replica is copying.",0,0.9734343886375427
140683704,3874,junrao,2017-09-25T03:35:49Z,"the window size and window samples impact how much load can be put during initialization. during initialization, we give a full window worth of quota. so, the larger the window, the more bytes can be put in initially. since interbroker quota may be configured based on network capacity whereas logdirsbalancing quota is mostly based on disk capacity, having separate window sizes between the two quotas allows the admin to control the initial load separately.",0,0.9845547080039978
140683719,3874,junrao,2017-09-25T03:36:06Z,"hmm, it seems that both the num.threads config and the disk movement quota will be set by the admin. so, it seems it makes sense to make them consistent. naming them both after replica alter dir will be fine too.",0,0.9669634103775024
140683728,3874,junrao,2017-09-25T03:36:14Z,"ah, makes sense. could you add a comment about this?",0,0.974407970905304
140683945,3874,junrao,2017-09-25T03:39:55Z,"a related concern here is that we are paying the sort overhead on every fetch request. if there are lots of partitions, this could add non-trivial overhead. the queue approach where the replicaalterdirthread takes one partition at a time from the queue obviates the need for that. it's fine to optimize this in a followup patch though.",0,0.9713359475135803
140922489,3874,lindong28,2017-09-25T23:09:34Z,"i think your points 1-5 makes sense. my concern with the modified approach is that it requires replicafetcherthread to depend on the replicaalterdirthread in order to call fetching. addpartitionswithtruncation(). it seems a bit clumsy. i have another way of doing that by passing the truncation signal from replicafetcherthread to replicaalterdirthread via the affected partition. here is my modified approach: 1) partition.truncateto() and partition.truncatefullyandstartat() will grab write lock of leaderisrupdatelock. and partition.appendrecordstofuturereplica() will grab read lock of leaderisrupdatelock. thus we still ensure that the truncation of the current replica and the append operation of the future replica will be executed in order. 2) when the current replica of a partition is truncated, it will set partition.futurereplicaneedtruncation to true. 3) partition.appendrecordstofuturereplica() will first check whether partition.futurereplicaneedtruncation is true. if the flag is true, the method will set the flag to false and throw offsetoutofrangeexception. 4) if abstractfetcherthread.processfetchrequest() catches an ooor exception from processpartitiondata(), it will update partitionstate for this partition to set truncatinglog to true. then the future replica will be truncated based on the leader epoch later. this approach also seems to address all the above concerns: (1) no additional overhead in the write path, which is common, (2), (3) no additional logic for dealing with leader epoch, (4) and (5) doesn't require new message format. in comparison to the previous modified approach, the class dependency graph will be simpler and more intuitive. what do you think?",0,0.5705205798149109
140923612,3874,lindong28,2017-09-25T23:17:24Z,great! i will implement this version in the updated patch.,1,0.9926633834838867
140928340,3874,lindong28,2017-09-25T23:53:27Z,thanks for catching this. i have updated it patch to fix it.,1,0.9329089522361755
140928991,3874,lindong28,2017-09-25T23:57:55Z,good point. i have updated the patch to call replicaalterdirmanager.shutdownidlefetcherthreads() every 2.5 seconds.,1,0.9350230693817139
140931539,3874,lindong28,2017-09-26T00:19:55Z,"i see. currently abstractfetcherthread can not get the log directory for partition in general because consumerfetcherthread, which also extends abstractfetcherthread, does not have log directory for partition. i think the existing implementation probably already provides log directory of the partition in the error log when this information is needed. the idea is that we need to know the log directory of the partition in the error log only if this is a log directory failure. but if this is the case, the original exception should have specified the log directory of the partition. does this sound reasonable?",0,0.9790331721305847
140931968,3874,lindong28,2017-09-26T00:23:48Z,i see. the default size of the full window is 11 seconds. i think the replica movement typically lasts much longer than 11 seconds and in general it is not a big deal to have a slow start. i am not sure it is worth two additional configs to optimize the initial performance of intra-broker replica movement. i don't have a strong opinion on this. do you prefer me to add two configs for this new quota?,-1,0.594734787940979
140932270,3874,lindong28,2017-09-26T00:26:57Z,sure. i added this comment: `re-initialize leader epoch cache so that leaderepochcheckpointfile.checkpoint can correctly reference the checkpoint file in renamed log directory`,0,0.9814189672470093
140936761,3874,lindong28,2017-09-26T01:07:01Z,sure. i have updated the patch to use replica alter dir consistently.,0,0.9659101366996765
140938334,3874,lindong28,2017-09-26T01:22:16Z,"good point. i have updated the patch with the following code. the new implementation should require only one pass of the partitionmap with o(n) time complexity, which is same as the time complexity of replicafetcherthread.buildfetchrequest().",1,0.9588236212730408
140938438,3874,lindong28,2017-09-26T01:23:13Z,here is the code. the idea is that we only need the maximum partition in the filtered partitionmap. [code block],0,0.9866331815719604
140941543,3874,junrao,2017-09-26T01:55:06Z,": the modified approach sounds good overall. a few more questions on this. (a) do we need the leaderisrupdatelock in step 1? if we truncate the current replica first and then insert the truncation point in the future replica, eventually the future replica will be able to truncate to the right offset, right? (b) for step 2 and 3, we can set the truncation state through partition. but we could also just directly set the state in replicaalterdirthread, which seems simpler since it avoids a level of indirection. (c) not sure why we need to turn the truncation state to ooor exception. the handling of ooor may truncate to a different offset than the truncation offset. it seems it's clearer if we handle the truncation state directly.",0,0.546113908290863
140942158,3874,junrao,2017-09-26T02:01:26Z,"yes, i'd prefer to add two new configs for the new quota since we already have separate window configs for the client and the replication quota.",0,0.9856588244438171
140952243,3874,lindong28,2017-09-26T03:54:06Z,sure. i will update the patch to add these two new configs.,0,0.958267092704773
140993990,3874,lindong28,2017-09-26T08:53:21Z,"good point regarding (a). indeed, truncateto() and truncatefullyandstartat() can simply use the readlock instead of the writelock. readlock is needed to avoid race condition with maybereplacecurrentwithfuturereplica(). regarding (b), can you explain a bit more how replicafetcherthread can set state in replicaalterdirthread after log truncation? are you suggesting that replicafetcherthread constructor should take `replicaalterdirmanger.fetcherthreadmap` as input. then when log truncation happens for partition, it derives the corresponding replicaalterdirthread from `replicaalterdirmanger.fetcherthreadmap` by hashing the topic and partition, before calling `replicaalterthread. addpartitionswithtruncation ()`? it seems a bit weird to put `replicaalterdirmanger.fetcherthreadmap` in the constructor of each replicafetcherthread. what do you think? regarding (c), i agree we don't need to throw ooor if we can directly set the truncation state. i am just not sure how we can directly set the truncation state due the concern with (b) described above. also, in my suggested approach, the handling of this ooor will not reset offset using handleoffsetoutofrange. instead it will set partitionstate.truncatinglog to true so that the partition will be truncated based on the leader epoch later. i am going to update the patch soon so that you can see it.",1,0.6463766098022461
141366056,3874,junrao,2017-09-27T14:44:59Z,": i was thinking of adding a truncatepartition(map[topicpartition, long]) method in abstractfetcherthread and abstractfetchermanager. the latter will call the former. the method takes a truncation offset for each partition in the map. replicafetcherthread will have access to replicaalterdirmanager to call truncatepartition() when the current log is truncated. currently, abstractfetcherthread maintains partitionfetchstate for each partition, if the state is truncatinglog, it will issue leaderepochrequest, followed by log truncation. we can probably introduce a separate leaderepochstate. during initialization, a partition will go through leaderepoch state (where leader epoch request is issued) and then truncatinglog state (where log will be truncated). when truncatepartition() is called, abstractfetcherthread just sets the partition state to truncatinglog state. when abstractfetcherthread sees a partition in that state, it will just truncate the log to the specified truncating offset and then transition to the fetch state. for (a), i am not sure we even need a read lock on leaderisrupdatelock. in the case when a partition is already removed when abstractfetcherthread.truncatepartition() is called, we can simply ignore that partition.",0,0.9703485369682312
141389315,3874,lindong28,2017-09-27T15:57:01Z,"regarding (b), it seems that leaderepochstate is not used in the suggested approach? i think the suggested approach would work. my only concern with this approach is that his approach will have replicafetcherthread depend on replicaalterdirthread, which is a bit unintuitive. on the other hand, my current approach is more complicated because it requires a new flag in parition, ooor exception from partition.truncateto(...), and handling of this ooor exception thrown from processpartitiondata(). i will implement the suggested approach if you think it is ok to have replicafetcherthread depend on replicaalterdirthread. can you confirm this? regarding (a), i think readlock is needed by truncateto() and truncatefullyandstartat() to avoid race condition with maybereplacecurrentwithfuturereplica(). for example, if truncateto() does not grab the read lock, it is possible that maybereplacecurrentwithfuturereplica() finds the leo of the future replica equals leo of the current replica, truncateto() truncates the current replica, and then maybereplacecurrentwithfuturereplica() replaces the current replica with the future replica, and the future replica has data that should have been truncated. does this make sense?",0,0.8735946416854858
141399349,3874,junrao,2017-09-27T16:33:14Z,": in comparison, the approach that lets replicafetcherthread reference replicaalterdirmanager seems a bit better. your explanation on the locking requirement makes sense. we are abusing the intent of leaderisrupdatelock now. so, we probably want to add some comments on that.",0,0.6983227729797363
141768963,3874,lindong28,2017-09-29T00:49:23Z,thanks for all the comments! i have updated the patch as suggested.,1,0.9804425835609436
142055101,3874,tedyu,2017-10-02T03:57:10Z,should we check whether getreplica(request.futurelocalreplicaid).get.log is none (in case we get read lock immediately after write lock is released) ? see code at line 197 above.,0,0.9896789789199829
142070001,3874,lindong28,2017-10-02T07:34:43Z,maybereplacecurrentwithfuturereplica() will not cause nosuchelementexception here because there the thread that calls maybereplacecurrentwithfuturereplica() for a given partition is guaranteed to be the same replicaalterdirthread that appends record to the future replica of this partition.,0,0.9859436750411987
142263275,3874,junrao,2017-10-02T21:41:00Z,unused import offsetoutofrangeexception.,0,0.9783450365066528
142266788,3874,junrao,2017-10-02T21:58:47Z,"hmm, not sure why we need to check partitionstates.contains() here since we already have the check in line 179.",0,0.9762322902679443
142267378,3874,junrao,2017-10-02T22:01:30Z,indentation,0,0.982236921787262
142278626,3874,junrao,2017-10-02T23:08:27Z,"hmm, i am not sure that we should always let a partition go through the leader epoch logic when a partition is marked for truncation. there are two cases here. (1) if a partition is not in the fetching mode, we should let the replica go through the leader epoch logic and truncate based on the epoch response. after that, we will truncate again based on the marked truncation offset. (2) if a partition is in the fetching mode, we should just do the truncation based on the marked truncation offset w/o going through the leader epoch logic. we probably want to add some comments to document this. also, given this new method, the existing includelogtruncation flag can be a bit confusing. perhaps it's clearer to rename it to isrecovering?",0,0.9241631627082825
142283836,3874,junrao,2017-10-02T23:46:58Z,"the name appendtofollower is now a bit mis-leading since it can be used to append records for future replicas, which is not really a follower. perhaps it's better to rename the methods here and those in log as appendwithoffsetassignment() and appendwithoutoffsetassignment().",0,0.920026957988739
142294260,3874,ijuma,2017-10-03T01:17:04Z,"we can use this in `logfuturedirname` and `logdeletedirname`. we can maybe add a `suffix` parameter and have `""""` as the default.",0,0.988783061504364
142294466,3874,ijuma,2017-10-03T01:19:17Z,it seems like `if/else` could be about appending the third tag instead of duplicating all the logic.,0,0.9789611101150513
142294684,3874,lindong28,2017-10-03T01:21:36Z,"previously i had a method called `appendrecordstofuturereplica`. i merged it with `appendrecordstofollower` to reduce the number of methods. since this is misleading, i think it may be better to add method `appendrecordstofuturereplica`, which is more intuitive and more consistent with the name `appendrecordstoleader`. what do you think?",0,0.9703877568244934
142294773,3874,ijuma,2017-10-03T01:22:21Z,"we typically use dash-separated names for kafka metrics. should it be `is-future` then? also, i wonder if this name will be clear to people. i'll think a bit more, don't have any concrete suggestions, right now.",0,0.8272875547409058
142294900,3874,lindong28,2017-10-03T01:23:46Z,"the reason is that replicadiralterthread may have removed topicpartition from the partitionstates in `processpartitiondata()` if the future replica has caught up with the current replica. in this case if we call `partitionstates.updateandmovetoend()`, this partition will be added back to the `partitionstates` by mistake.",0,0.9865759611129761
142294964,3874,lindong28,2017-10-03T01:24:06Z,my bad.. it is fixed now.,-1,0.9886175990104675
142295005,3874,lindong28,2017-10-03T01:24:24Z,thanks much for the detailed review. it is fixed now.,1,0.9503870010375977
142295483,3874,ijuma,2017-10-03T01:28:49Z,"does this not need to be `volatile`? also, now that it's a `var`, we may want to make it private and only provide a public accessor.",0,0.9873487949371338
142295625,3874,ijuma,2017-10-03T01:30:23Z,we should probably use `utils.atomicmovewithfallback`.,0,0.9883090257644653
142295728,3874,ijuma,2017-10-03T01:31:36Z,"seems like we should extract a method that just takes the suffix and generates the `uniqueid`, etc.",0,0.9871827363967896
142421245,3874,lindong28,2017-10-03T14:37:39Z,"one reason to let a partition go through leader epoch is that, if the leader replica is truncated to offset 10, append data up to offset 20, and truncated again to offset 15, first truncation offset 10 will be overwritten by the second truncation offset 20. in reality the window for this happening is probably small and we expect the truncation to happen almost immediately on the future replica after the leader is truncated. but ideally we would probably want to stay on the safe side and use leader epoch to make sure this does not cause any problem. another reason to apply leader epoch is to mimic what we are currently doing with the follower replica. currently whenever leader replica is truncated, it is guaranteed that there is leadership transfer, and the replica will be removed from the replicafetchermanager and added back in the follower. thus the follower will always apply leader epoch if leader is truncated. so it seems to make sense to always truncate the future replica using leader epoch whenever the current replica is truncated. does this make sense? also, is there any correct or performance concern if we always use leader epoch to truncate the future replica?",0,0.9476549029350281
142422846,3874,lindong28,2017-10-03T14:42:59Z,"good point. you are right, it should be volatile. i have updated the patch to make it private and added a public accessor for it.",1,0.9226284623146057
142423254,3874,lindong28,2017-10-03T14:44:26Z,yeah it should be is-future. i have updated the patch as suggested. thanks!,1,0.9742612838745117
142424683,3874,lindong28,2017-10-03T14:49:18Z,sure. i updated the patch with the following code: [code block],0,0.9840091466903687
142427674,3874,lindong28,2017-10-03T14:59:18Z,"i have considered this api. `utils.atomicmovewithfallback` calls `files.move`. and according to the java doc of `files.move`, this method will fail if the target file exists, which is the case here when we replace the current replica with the future replica.",0,0.9871058464050293
142429205,3874,lindong28,2017-10-03T15:04:25Z,"sure. i have updated the patch to add a private method `logdirname(topicpartition: topicpartition, suffix: string)`. i still keep the method `logfuturedirname` and `logdeletedirname` because it seems easy to use by the caller. i can remove these two methods if you prefer.",0,0.9467210173606873
142429272,3874,ijuma,2017-10-03T15:04:36Z,"`files.move` does not fail if the target file already exists given the right `copyoptions`, which `atomicmovewithfallback` uses.",0,0.985490083694458
142429768,3874,ijuma,2017-10-03T15:06:22Z,"in particular, `atomic_move` should work on linux. and on windows, we fallback to `replace_existing`.",0,0.987277090549469
142430102,3874,ijuma,2017-10-03T15:07:34Z,"although, this is a directory, so not sure. maybe we should write a test to verify. either way, if `atomic_move` doesn't work, we should use `files.move` with `replace_existing`, which should work, i believe.",0,0.9699186086654663
142431419,3874,lindong28,2017-10-03T15:12:09Z,sure. i have updated the patch to use this method in the newly-added private method.,0,0.9757059216499329
142432032,3874,lindong28,2017-10-03T15:14:15Z,i made a mistake previously. the `renamedir` will rename a directory but the destination direction does not exist. thanks for the explanation. i will try and test this approach.,1,0.796943724155426
142433208,3874,ijuma,2017-10-03T15:18:11Z,sounds good. the main advantage of the `files` apis when compared to the legacy ones is that they provide error messages when things go wrong. that can be quite helpful.,1,0.9500986337661743
142482694,3874,lindong28,2017-10-03T18:24:12Z,i have updated the patch as suggested.,0,0.9844681620597839
142558743,3874,junrao,2017-10-04T00:34:06Z,good point. could you add a comment for that?,1,0.9181548357009888
142559035,3874,junrao,2017-10-04T00:37:14Z,: very good point on double truncation. one way to get around this is to maintain the smallest truncation offset if the partition is marked for truncation multiple times. my concern of depending on leader epoch is that it won't apply if the message format is old.,1,0.9848349094390869
142704994,3874,lindong28,2017-10-04T15:27:09Z,sure. actually the comment is already in the patch.,0,0.9808127284049988
142707839,3874,lindong28,2017-10-04T15:37:00Z,"good point. i have update the patch to use the smallest truncation offset. even if we use the smallest truncation offset, i think it is still safer to use leader epoch to truncate the future replica if leader epoch is available. this is because truncation offset is only recorded in the memory which may be lost if broker restarts. does this make sense?",1,0.8710400462150574
142721548,3874,lindong28,2017-10-04T16:24:54Z,i have rebased patch onto trunk. i will go through this patch end-to-end after we agree on how to truncate the future replica.,0,0.9830577969551086
142831425,3874,junrao,2017-10-05T01:26:53Z,": thinking a bit more. we can use leader epoch to handle truncation since if the leader epoch doesn't exist, we fall back to hw and the truncation point should always be no lower than that. so, this should be safe.",0,0.8200500011444092
142933529,3874,lindong28,2017-10-05T13:17:04Z,"great. thanks for taking time to think through this. since it is safe to use leader epoch and there is not performance concern with doing it, to simplify the implementation, i am going to update the patch to use only leader epoch or high watermark to truncate the future replica without recording the truncation offset. does this sound ok?",1,0.987855851650238
143042586,3874,junrao,2017-10-05T20:04:43Z,extra empty line,0,0.9765298366546631
143044343,3874,junrao,2017-10-05T20:12:27Z,"in the common case, partitionandoffsets will have less entries than partitionstates. so, it will be more efficient to iterate partitionstates and do lookups in partitionandoffsets.",0,0.9864770174026489
143052139,3874,junrao,2017-10-05T20:45:12Z,"since this method is only called only by replicaalterdirmanager, perhaps it should be defined there?",0,0.9851658940315247
143060422,3874,junrao,2017-10-05T21:21:00Z,"in this case, the current replica won't have an leader epoch info after truncation. to deal with this better, it seems that it's better for a follower replica or a future replica to fall back to the initialized offset in the partitionstate in abstractfetcherthread, instead of hw, when leader epoch can't be found. we can initialize the offset in partitionstate to the truncation point in this case. in other cases, we can pass in hw to initialize the offset in partitionstate.",0,0.9860939979553223
143061641,3874,junrao,2017-10-05T21:27:09Z,"it maybe possible that the log end offset in the partition is less than leaderendoffset. in that case, we really want to start fetching from the log end offset instead of leaderendoffset. so, it seems it's safer for truncateto() to return the current log end offset after truncation and use that as the starting offset for fetching. ditto in replicaalterlogdirsthread.",0,0.9767678380012512
143065376,3874,junrao,2017-10-05T21:45:46Z,do we need the lock here? it seems that we just need to make sure the current replica is not being updated when maybedeleteandswapfuturereplica() is called.,0,0.9823710918426514
143067860,3874,junrao,2017-10-05T21:59:13Z,getreplicaorexception can throw an exception. we don't want to kill the replicaalterlogdirsthread because of this. it seems that we need to return resultwithpartitions?,0,0.9675795435905457
143068459,3874,junrao,2017-10-05T22:02:31Z,it seems lastpartitionopt is better than maxpartitionopt?,0,0.9823998212814331
143071316,3874,junrao,2017-10-05T22:19:12Z,alterlogdirs => alterreplicalogdirs ?,0,0.9859874844551086
143071753,3874,junrao,2017-10-05T22:21:21Z,"numalterlogdirsreplicationquotasamples => numalterreplicalogdirsquotasamples ? ditto for alterlogdirsreplicationquotawindowsizeseconds. in general, it would be useful to make the naming consistent.",0,0.9866264462471008
143072002,3874,junrao,2017-10-05T22:22:44Z,num.replica.alter.log.dirs.threads => num.alter.replica.log.dirs.threads ?,0,0.9876810312271118
143072168,3874,junrao,2017-10-05T22:23:44Z,alter.log.dirs.replication.quota.window.num => alter.replica.log.dirs.quota.window.num? ditto for alter.log.dirs.replication.quota.window.size.seconds.,0,0.9351110458374023
143073815,3874,junrao,2017-10-05T22:33:36Z,shutdownidlereplicaalterlogdirsthread => shutdownidlealterreplicalogdirsthread ?,0,0.9806838631629944
143073900,3874,junrao,2017-10-05T22:33:58Z,replicaalterlogdirsmanager => alterreplicalogdirsmanager?,0,0.9855174422264099
143074047,3874,junrao,2017-10-05T22:34:43Z,"shutdown-idle-replica-alter-log-dirs-thread => shutdown-idle-alter-replica-log-dirs-thread? also, 2500l could probably just be 10000l since the idle threads don't have to be closed that quickly.",0,0.9883304834365845
143079118,3874,junrao,2017-10-05T23:09:46Z,"it seems that we if the source dir is offline, we want to avoid adding the partition to replicaalterlogdirsmanager?",0,0.9807792901992798
143084972,3874,junrao,2017-10-05T23:57:02Z,"since we are calling sourcelog.close() later, could we just call it here instead calling sourcelog.closehandlers()?",0,0.9881957769393921
143091621,3874,lindong28,2017-10-06T01:01:45Z,thanks. it is removed now.,1,0.7611958980560303
143091979,3874,lindong28,2017-10-06T01:05:13Z,"sorry, i missed the exception here. instead of returning resultwithpartitions, how about we keep it consistent with replicafetcherthread.fetchepochsfromleader(), which returns `tp -> new epochendoffset(errors.forexception(t), undefined_epoch_offset)` in the resulting map if the current replica for this topic partition is offline?",-1,0.9808025360107422
143092370,3874,lindong28,2017-10-06T01:09:14Z,it is called maxpartitionopt because this is the toipcpartition with largest topic (in alphabetical order) or the largest partition (if topic string is the same). this topic partition is not selected based on its order in partitionstates. `lastpartitionopt` seems to suggest it is the last partition that is put into the partitionstates. that is why i used `maxpartitionopt`. do you still prefer `lastpartitionopt`?,0,0.985834538936615
143092809,3874,lindong28,2017-10-06T01:13:48Z,"i intentionally used alterlogdirs to reduce the length of the variable name and related config key name in other places. i think ""replica"" can be removed from the name because its type is `replicationquotamanager`, which already includes the word ""replication"". i will change it to `altereplicalogdirs` if you prefer. what do you think?",0,0.9838101863861084
143092968,3874,lindong28,2017-10-06T01:15:23Z,"i just think that ""numalterreplicalogdirsquotasamples"" is a bit verbose by having both ""replica"" and ""replication"". thus i removed ""replica"" from the name. i will change it to ""numalterreplicalogdirsquotasamples"" if you prefer.",0,0.9776221513748169
143093247,3874,lindong28,2017-10-06T01:18:38Z,"though the request is named ""alterreplicalogdirsrequest"", the thread is `replicaalterlogdirsthread`, which is more consistent with `replicafetcherthread`. because this config is used to determine the thread number, it seems more intuitive to name it `num.replica.alter.log.dirs.threads`. what do you think?",0,0.9857560992240906
143093359,3874,lindong28,2017-10-06T01:19:51Z,"i just think that ""alter.log.dirs.replication.quota.window.num"" is more consistent with the existing config ""replication.quota.window.num"". what do you think?",0,0.9879364371299744
143093452,3874,lindong28,2017-10-06T01:20:49Z,i think it is because the thread class is named `replicaalterlogdirsthread`. i can change it if you still prefer `shutdownidlealterreplicalogdirsthread`.,0,0.9873839616775513
143093676,3874,lindong28,2017-10-06T01:23:06Z,do you prefer to rename the manager class from `replicaalterlogdirsmanager` to `alterreplicalogdirsmanager`? previously i think `replicaalterlogdirsmanager` is more consistent with the existing class `replicafetcherthreadmanager`. same for the `replicaalterlogdirsthread`.,0,0.9882843494415283
143174644,3874,lindong28,2017-10-06T12:11:34Z,"the reason this is defined in abstractfetchermanager is that, this method currently uses `fetcherthreadmap`, `maplock` and `getfetcherid`, which are currently private in abstractfetchermanager. i thought it is better to keep them private and only uses these variables in `abstractfetchermanager`. another reason is that we already have methods such as `abstractfetcherthread.fetchepochsfromleader()`, which are defined in `abstractfetcherthread` but only used in `replicafetcherthread`. i am not strong on this. do you prefer to change variables above to protected and move `markpartitionsfortruncation` to `replicaalterdirmanager`?",0,0.9769604206085205
143176721,3874,lindong28,2017-10-06T12:24:02Z,"i am not sure i fully understand your suggestion. i checked the current implementation of replicafetcherthread.handleoffsetoutofrange(). if log end offset in the partition is less than leaderendoffset, the current implementation will start fectching from `math.max(leaderstartoffset, replica.logendoffset.messageoffset)`. so it already does what you suggested, right?",0,0.9605041146278381
143178096,3874,lindong28,2017-10-06T12:32:43Z,"good point. it is not needed. in addition to the reason you mentioned, another reason is that appendrecordstofuturereplica() will be called by the same replicaalterlogdirsthread that calls maybedeleteandswapfuturereplica() for this partition. i will update the patch to remove this lock. thanks!",1,0.9843329191207886
143178280,3874,lindong28,2017-10-06T12:33:55Z,"it is named `shutdown-idle-replica-alter-log-dirs-thread` because the thread class is replicaalterlogdirsthread. do you think we should change the name of the thread class and thread manger class? sure, i will update the patch to use 10000l as interval.",0,0.9882367253303528
143178857,3874,lindong28,2017-10-06T12:36:56Z,"yeah i think the current implementation already avoids adding the partition to replicaalterlogdirsmanager if the source dir is offline. if the source dir is offline, the `val replica = getreplicaorexception(topicpartition)` at line 604 will throw kafkastorageexception and this method will not call `replicaalterlogdirsmanager.addfetcherforpartitions` for this partition.",0,0.9848300218582153
143179842,3874,lindong28,2017-10-06T12:42:37Z,"i think we need to call sourcelog.closehandlers() instead of sourcelog.close(). if we call sourcelog.close() and if source log directory is offline, this method will throw kafkastorageexception without closing handler for this sourcelog. later when logmanager.handlelogdirfailure() is called for this source log directory, the handles of this sourcelog will not be closed because sourcelog has already been removed from `currentlogs`. on the other hand, if we sourcelog.closehandlers() and if the source log directory is offline, the handler of sourcelog will be closed before sourcelog.renamedir() throws kafkastorageexception. all handlers in the source log directory will be properly closed in this case. does this make sense?",0,0.9834563136100769
143179997,3874,lindong28,2017-10-06T12:43:33Z,good point. this makes sense. let me think more about how to handle this case properly.,1,0.9480807185173035
143258114,3874,junrao,2017-10-06T17:59:55Z,"the case that i am worried about is the following. suppose the follower replica has logendoffset of 5 and truncateto(10) is called. after that, we will be fetching from offset 10, which could be in the offset range of the leader. this means that we will be missing messages from offset 5 to 10 in the follower. fetching from offset 5 in this case will be safer.",0,0.8481519818305969
143258987,3874,junrao,2017-10-06T18:03:26Z,"yes, that covers the common case. the case that i was concerned about is when the source replica is taken offline after getreplicaorexception() but before getpartition(topicpartition).get.getorcreatereplica(request.futurelocalreplicaid). in this case, are we creating a future replica on an offline partition?",0,0.9771202802658081
143320042,3874,lindong28,2017-10-07T02:11:34Z,"replicamanager.handlelogdirfailure() is the only method that will take a replica offline. this method is synchronized with replicamanager.alterreplicalogdirs() using replicastatechangelock. thus if the handelogdirfailure() is executed after alterreplicalogdirs(), the future replica will be created first, and then both the current replica and the future replica will be taken offline. if the handelogdirfailure() is executed before alterreplicalogdirs(), the future replica will not be created on the offline partition. so the current implementation seems correct, right?",0,0.9837400317192078
143320196,3874,lindong28,2017-10-07T02:18:44Z,"in replicafetcherthread.handleoffsetoutofrange(), we will first check whether `leaderendoffset < replica.logendoffset.messageoffset`. the code block which you mentioned here is only executed if `leaderendoffset < replica.logendoffset.messageoffset`. in the case ""the follower replica has logendoffset of 5 and truncateto(10) is called"", i assume you are saying that `replica.logendoffset.messageoffset` is 5 and `leaderendoffset` is 10, then the code block here won't be executed. instead, the code block in the `else` branch will truncate the follower replica to offset `math.max(leaderstartoffset, replica.logendoffset.messageoffset)`, which will be offset 5 if the leaderstartoffset is smaller than the follower's leo. later replicafetcherthread will actually fetch starting from offset 5, which seems correct. did i miss something here?",0,0.9821760058403015
143355895,3874,lindong28,2017-10-08T14:15:27Z,"sorry for late reply on this issue. now i think about this more, i think the current patch handles this case well. i understand that if truncatefullyandstartat() is called for the current replica, the current patch will truncate the future replica to high watermark which does not have any effect. but truncatefullyandstartat() will also be called for the future replica later. if truncatefullyandstartat() is called for the current replica, then we know that futurereplica's logendoffset < ""currentreplica's logendoffset before truncation"" < ""currentreplica's logstartoffset after truncation"". this means that replicaalterdirthread will see offsetoutofrangeexception for futurereplica and call handleoffsetoutofrange for future replica. later truncatefullyandstartat() will be called for the future replica as well, which makes the result correct. do you think this make sense? if not, can you explain a bit more what will go wrong?",-1,0.9879758954048157
143356250,3874,lindong28,2017-10-08T14:29:43Z,this lock is removed.,0,0.9803357124328613
143356393,3874,lindong28,2017-10-08T14:36:43Z,"i have updated the patch to return `tp -> new epochendoffset(errors.forexception(t), undefined_epoch_offset)` if the replica is offline. hw will be used to truncate the future replica before the future replica is removed from replicaalterdirthread later.",0,0.9892165660858154
143356469,3874,lindong28,2017-10-08T14:40:19Z,thanks. i realized that the signature of this method could be simplified to `markpartitionsfortruncation(topicpartition: topicpartition)`. i have updated the patch to do the following to optimize the performance of this method. [code block],1,0.9742715954780579
143529807,3874,junrao,2017-10-09T17:22:58Z,": yes, it doesn't seem that this can happen here. so we can leave this as it is.",0,0.8747226595878601
143530433,3874,junrao,2017-10-09T17:25:52Z,": good point that we can rely on truncatefullyandstartat() being called on the future replica later since its offset will be out of range too. in that case, it seems that replicamgr.replicaalterlogdirsmanager.markpartitionsfortruncation() is a no op. do we need to call it here? however, the same issue may happen on truncateto(). consider the following case. the current replica needs to call partition.truncateto(leaderendoffset) since its logendoffset is > leaderendoffset, which can happen when an unclean leader election is triggered. we then call replicamgr.replicaalterlogdirsmanager.markpartitionsfortruncation(). if there is no leader epoch info (e.g., message format is still old), the future replica will default to truncating to its hw, which could be > the leaderendoffset of the current replica. by the time the future replica fetches again, more data could have been accumulated in the current replica and the future replica's offset could still be in range. however, some of the data in the future replica now are different from the current replica. in this case, it's better if the future replica defaults to the leaderendoffset of the current replica during truncation.",1,0.855521559715271
143530570,3874,junrao,2017-10-09T17:26:26Z,"hmm, do we need to truncate based on hw for those partitions that are already marked as offline? it seems that it's simpler to just let handlepartitionswitherrors() deals with them before they are removed from replicaalterdirthread.",0,0.9841136932373047
143545091,3874,lindong28,2017-10-09T18:31:56Z,"yeah you are right, markpartitionsfortruncation() is not needed if currentreplica. truncatefullyandstartat() is called. i will remove the markpartitionsfortruncation() here. regarding the second issue, i agree that the inconsistency between the current and the future replica can happen if the remaining message's format is old. but it seems to me that the same inconsistency can happen between follower and leader as well if the message format is old. thus the inconsistency between the future and the current replica does not increase the problem we already have. and in the long term, all messages will have the new format and this won't be an issue. thus i am not sure the reduced change of inconsistency is worth additional code complexity. but i will update the patch as suggested if you think this is worth doing. what do you think?",0,0.9057667851448059
143546055,3874,lindong28,2017-10-09T18:36:29Z,"strictly speaking, we don't have to truncate the future replica is the current replica is offline. but it is probably more intuitive to return `epochendoffset(errors.forexception(t), undefined_epoch_offset)` here because the purpose of this method is `fetchepochsfromleader()`. the caller of this method, in this case abstractfetcherthread.maybetruncate(), should decide which to handlepartitionswitherror or truncate the replica. does this make sense?",0,0.9834344387054443
143592973,3874,junrao,2017-10-09T22:36:40Z,"ok, this is fine then.",0,0.9651951789855957
143592989,3874,junrao,2017-10-09T22:36:48Z,": i agree that the same issue may happen between the leader and the follower, which we can improve separately in the future. we probably don't want to introduce new issues here between the current and the future replica. i am not sure if my suggestion will add more complexity though. we already store the initial offset in abstractfetcherthread.partitionstates, but ignore it in maybetruncate(). it seems that it's more natural to fall back to this initial offset instead of hw. then, we just need to set the initial offset in markpartitionsfortruncation().",0,0.9331677556037903
143783274,3874,lindong28,2017-10-10T16:33:23Z,"the reason i think they are the same problem (not new issue) is that, the future replica is conceptually very similar to the follower replica. replicaalterlogdirsthread works in a very similar way as the replicafetcherthread. they currently share the same problem regarding the inconsistency. and if we have a solution for the follower replica, the solution should be applicable to the future replica as well. i personally think the future replica is just another follower replica on the same broker as leader. let's say we think the inconsistency in the future replica is a new problem and we want to fix it. i think re-using the offset in `abstractfetcherthread.partitionstates` for truncation will make the code a bit more complicated for the following reasons: - if we allow markpartitionsfortruncation() to change the offset in `partitionstates`, then replicafetcherthread (and replicaalterlogdirsthread) will need to handle this properly in processpartitiondata(). currently only one thread will update the offset in `partitionstates` and `fetchoffset` should always equals `replica.logendoffset.messageoffset` in `processpartitiondata()`. - as of now, the offset in `partitionstates` is always the leo of the follower (and future) replica. thus it is no-op if we truncate the follower replica to this offset in maybetruncate(). re-using this offset to store the truncation offset may make the code harder to maintain. it may be better to store the truncationoffsets in a separate map and use it in maybetruncate(...) as shown in [a link] thanks for all the discussion. given my explanation above, can you let me know which solution you prefer? besides, do you want me to change the name of configs and classes as you raised in the other comments?",0,0.8483228087425232
143793959,3874,junrao,2017-10-10T17:14:38Z,": a couple of things. first, when markpartitionsfortruncation(), the replica is now transitioning to a maybe truncating state (not ready for fetching). if there is a pending fetch response, we should just ignore it. i have a separate pr ([a link] that tries to tighten this up. second, once we have that. the implementation that i was thinking is the following. markpartitionsfortruncation() just marks the partition as maybe truncating and puts the initial offset in partitionstates. from that point on, the replica won't be used for fetching data until it transitions to the ready for fetch state. during the handling of maybetruncate() logic, we will try to decide the truncation point based on leader epoch if possible. otherwise, we will just fall back to the initial offset. so, implementation wise, i am not sure we really need a separate truncationoffsets map. so, my thinking is that such a change seems relatively small and safer than the current approach. as for the naming, i don't want have a strong preference. it's up to you to pick sth consistent.",0,0.9586646556854248
143807179,3874,lindong28,2017-10-10T18:03:08Z,this solution makes sense. i have updated the patch as suggested. it seems that all comments have been addressed. i will rebase the patch onto trunk and review it myself tomorrow. thanks!,1,0.9793988466262817
143874421,3874,junrao,2017-10-10T22:55:11Z,if we tighten the check in abstractfetcherthread like in [a link] we can still throw an exception here since it shouldn't be possible. that seems a more general fix since it covers the replicafetcherthread too.,0,0.9849879145622253
143876603,3874,junrao,2017-10-10T23:08:56Z,we probably want to throw an illegalstateexception if includelogtruncation is false since markpartitionsfortruncation() is not meant to be called in that case.,0,0.9640143513679504
143882150,3874,junrao,2017-10-10T23:52:27Z,partitionstoalterlogdirwithlogendoffset =>futurereplicasandinitialoffset ?,0,0.9844632148742676
143898257,3874,lindong28,2017-10-11T02:20:26Z,"good point. i have updated the patch as suggested, i.e. still throw exception here and check `isreadyforfetch` in `processfetchrequest()`. i can rebase the patch after your patch is committed.",1,0.9514011740684509
143899061,3874,lindong28,2017-10-11T02:28:59Z,thanks for catching this. i have updated the patch as suggested.,1,0.8874655961990356
143900496,3874,lindong28,2017-10-11T02:43:07Z,"actually, since that state is not possible, i have updated the patch to replace runtimeexception with illegalstateexception.",0,0.9693295359611511
143900528,3874,lindong28,2017-10-11T02:43:31Z,sure. i have updated the patch to check for this illegal state.,0,0.9137452244758606
144160448,3874,junrao,2017-10-11T23:14:38Z,"how about we change the comment to the following? ""it's possible that a partition is removed and re-added or truncated when there is a pending fetch request. in this case, we only want to process the fetch response if the partition state is ready for fetch and the current offset is the same as the offset requested.""",0,0.9863990545272827
144160911,3874,junrao,2017-10-11T23:17:52Z,"we should throw the exception, right?",0,0.9820321798324585
144162641,3874,junrao,2017-10-11T23:30:32Z,"how about changing the comment slightly to the following? ""the read lock is needed to prevent the follower replica from being updated while replicaalterdirthread is executing maybedeleteandswapfuturereplica() to replace follower replica with the future replica.""",0,0.986724853515625
144162836,3874,junrao,2017-10-11T23:32:12Z,"how about changing the comment slightly to the following? ""the read lock is needed to prevent the follower replica from being truncated while replicaalterdirthread is executing maybedeleteandswapfuturereplica() to replace follower replica with the future replica.""",0,0.9863438606262207
144162863,3874,junrao,2017-10-11T23:32:26Z,"how about changing the comment slightly to the following? ""the read lock is needed to prevent the follower replica from being truncated while replicaalterdirthread is executing maybedeleteandswapfuturereplica() to replace follower replica with the future replica.""",0,0.9863438606262207
144168236,3874,lindong28,2017-10-12T00:15:17Z,sure. i have updated the comment as suggested.,0,0.9745836853981018
144168256,3874,lindong28,2017-10-12T00:15:22Z,sure. i have updated the comment as suggested.,0,0.9745836853981018
144168262,3874,lindong28,2017-10-12T00:15:26Z,sure. i have updated the comment as suggested.,0,0.9745836853981018
144168272,3874,lindong28,2017-10-12T00:15:29Z,sure. i have updated the comment as suggested.,0,0.9745836853981018
144168299,3874,lindong28,2017-10-12T00:15:46Z,ah... my bad. thanks much for catching this.,-1,0.9878078103065491
144629332,3874,junrao,2017-10-13T18:40:47Z,"earlier, you had assertequals(nummessages, consumerrecords.size), which seems useful. is there a reason to remove this?",0,0.9875121712684631
144632221,3874,junrao,2017-10-13T18:54:22Z,"hmm, do we need the read lock here? replica/log can only be changed by leaderandisrrequest, stopreplicarequest, and alterreplicalogdirs, all of which are already protected under replicastatechangelock.",0,0.9892228841781616
144632346,3874,junrao,2017-10-13T18:54:57Z,"it seems that this case should never happen. so, should we throw illegalstateexception?",0,0.8706880211830139
144632596,3874,junrao,2017-10-13T18:56:03Z,should performed => should be performed,0,0.9830392599105835
144665825,3874,junrao,2017-10-13T22:01:56Z,"hmm, it seems that sourcelog.close() can only throw kafkastorageexception because closehandlers() has already been called due to offline log dir. so, not sure why closehandlers() needs to be called again.",0,0.9555596709251404
144666248,3874,junrao,2017-10-13T22:05:13Z,is this comment correct? it seems that logsegment.close() does a superset of logsegment.closehandlers().,0,0.9869819283485413
144680990,3874,lindong28,2017-10-14T00:49:04Z,"thanks for the review. i think we need readlock here is that the log directory of the current replica is not changed by replicaaltherlogdirsthread when the kafkarequesthandler thread is checking whether it needs to create future replica (when it handles alterreplicalogdirsrequest). if we don't use read lock here, the following scenario can happen: 1) broker receives alterreplicalogdirsrequest 2) kafkarequesthandler calls maybecreatefuturereplica(). it finds that the log directory of the current replica is different from the user-specified destination log directory. so it creates future replica and will later try to add this partition replicaalterlogdirsmanager 3) replicaaltherlogdirsthread calls maybereplacecurrentwithfuturereplica(), updated the log directory of the current replica, removed the future replica from allreplicasmap, and removed this partition from replicaalterlogdirsmanager. 4) kafkarequesthandler will now add this partition to replicaalterlogdirsmanager. 5) now we have an inconsistent state where replicaalterlogdirsmanager has this partition but this partition does not have future replica. the replicaalterlogdirsthread will see replicanotavailableexception and fail. does this make sense?",1,0.9173403978347778
144681216,3874,lindong28,2017-10-14T00:54:15Z,"on a double thought, i realized that this could actually happen if the broker receives the same alterreplicalogdirsrequest multiple times, which could happen because reassignpartitionscommand will re-send alterreplicalogdirsrequest. does this make sense?",0,0.978262186050415
144681244,3874,lindong28,2017-10-14T00:54:59Z,thanks. i will update the patch to fix it.,1,0.8824042081832886
144681370,3874,lindong28,2017-10-14T00:57:22Z,i think it is correct. i verified that close() does not set abstractindex.mmap to null. note that close() can not set mmap to null so that abstractindex.delete() can be executed by the scheduler thread.,0,0.9869751930236816
144681629,3874,lindong28,2017-10-14T01:03:50Z,"i think log.close() also does disk io operation, e.g. when it calls producerstatemanager.takesnapshot() or filerecords.flush(). therefore it could throw kafkastorageexception() if the ioexception occurs. i realized that we need maybehandleioexception() for log.close() to catch e.g. ioexception from producerstatemanager.takesnapshot(). i have updated the patch to do this.",0,0.9705399870872498
144681763,3874,lindong28,2017-10-14T01:06:46Z,"the reason is that testutils.consumetopicrecords() will throw exception if the consumerecords.size() is not exactly the nummessages(). do you prefer me to add back assertequals(nummessages, consumerrecords.size) so that this check is more explicit in the test?",0,0.9854179620742798
144913957,3874,junrao,2017-10-16T17:30:53Z,thanks for the explanation. this is fine then.,1,0.6284116506576538
144913975,3874,junrao,2017-10-16T17:30:58Z,"thanks, sound goods.",1,0.7403169274330139
144913998,3874,junrao,2017-10-16T17:31:04Z,"ok. then ""file handlers"" can be a bit confusing since we do close the channel associated with the log segment. how about changing the comment to the following? ""the memory mapped buffer for index files of this log will be left open until the log is deleted""",0,0.8889718055725098
144914073,3874,junrao,2017-10-16T17:31:23Z,"hmm, this is the case that the future replica exists, but not in the specified log dir. resending the same alterreplicalogdirsrequest won't lead to this case, right?",0,0.9831083416938782
144914169,3874,junrao,2017-10-16T17:31:52Z,"i guess the scenario that you are describing is that there is already an ongoing replica movement across disks at step 2. however, in that case, it seems that we will remove the partition from replicaalterlogdirsmanager and the future replica in line 591 and 592. after that point, replicaalterlogdirsthread can't call maybereplacecurrentwithfuturereplica() any more because the additional partition state check that we added in abstractfetcherthread, right?",0,0.982887864112854
144995830,3874,lindong28,2017-10-16T23:30:42Z,"not sure i explained my thought clearly. i think here the case is that the future replica already exists in the specified log dir. more specifically, when the broker receives the same alterreplicalogdirsrequest again, it calls replicamanager.alterreplicalogdirs(). alterreplicalogdirs() should only add this partition to replicaalterlogdirsmanager if this future replica has not already been created. so alterreplicalogdirs() calls maybecreatefuturereplica(), and maybecreatefuturereplica() should return true iff the future replica is newly created. because it is possible that future replica already exists, we should not throw illegalstateexception. does this sound ok?",0,0.9784769415855408
144995860,3874,lindong28,2017-10-16T23:30:59Z,sure. i have updated the comment and related method names as suggested.,0,0.9686047434806824
144996257,3874,lindong28,2017-10-16T23:34:00Z,"the scenario is that there is already an ongoing replica movement for this same partition to the same destination log directory, which can happen if broker receives the same alterreplicalogdirsrequest again. because the requested destination log directory of the alterreplicalogdirsrequest is same as the destination log directory of the ongoing movement, we will not remove the partition from replicaalterlogdirsmanager. does this make sense?",0,0.9808456897735596
144999197,3874,lindong28,2017-10-16T23:56:36Z,"actually, in the scenario that there is already an ongoing replica movement to a different destination log directory, the following may happen: - replicaaltherlogdirsthread calls maybereplacecurrentwithfuturereplica(), updated the log directory of the current replica and removed the future replica from allreplicasmap() - kafkarequesthandler calls alterreplicalogdirs(). because future replica has been removed, it will not remove this partition from replicaalterlogdirsmanager. then it will create the future replica for this partition and add fetcher for this partition. - then replicaaltherlogdirsthread will remove fetcher for this partition. this leads to an inconsistent state where we have future replica for this partition but this partition is not in replicaalterlogdirsmanager. the main issue is that, we do not have a lock that makes it an atomic operation to 1) add/remove partition from replicaalterlogdirsmanager and 2) add/remove future replica for the partition. protect maybecreatefuturereplica() with `leaderisrupdatelock` could reduce the chance of this race condition.",0,0.983702540397644
145007121,3874,junrao,2017-10-17T01:06:10Z,": thanks for the info. makes sense. perhaps we should throw an illegalstateexception if future replica exists, but is on a log dir different from the input?",1,0.9644528031349182
145007148,3874,junrao,2017-10-17T01:06:34Z,": in the scenario that there is already an ongoing replica movement to a different destination log directory, i am not sure what you described can happen. maybereplacecurrentwithfuturereplica() is called inside processpartitiondata() and is protected by the abstractfetcherthread.partitionmaplock. so, while this is ongoing, no new partitions can be added to the fetcher. the other scenario that there is already an ongoing replica movement for this same partition to the same destination log directory does make sense. so, we can keep the readlock there.",0,0.947189450263977
145007951,3874,lindong28,2017-10-17T01:14:41Z,sure. i have updated the code to throw illegalstateexception if the current log dir of the future replica is different from the requested log dir. thanks!,1,0.9768397212028503
145008087,3874,lindong28,2017-10-17T01:16:16Z,thanks much for the discussion!,1,0.9803637862205505
1400867677,3874,Hongten,2023-11-21T16:32:47Z,"i have a question about the previous var. if the log dir name doesn't end with ""-future"", the `currentlogs` will put the topic partition as key and log as value, and return log. the simple logic like the below: [code block] if the `previous` is not null, then there is an `illegalstateexception` to be thrown. right?",0,0.9784948825836182
59305175,1215,becketqin,2016-04-12T00:37:28Z,"i have a question regarding the code here. on line 199 of this patch (line 192 of the original code), we check if the index file exists or not. however, right before this, we have already created the log segment which will create the index file if it does not exist. so it seems the test here will never be false?",0,0.9697490930557251
59380790,1215,ijuma,2016-04-12T14:02:16Z,was it intentional to remove the volatile annotation from this var?,0,0.9807959794998169
59381324,1215,ijuma,2016-04-12T14:05:03Z,"also, do we actually need to mutate the vars above in the subclasses? if not, they should remain `private[this]` as they were before. we have accessor methods (without the underscore).",0,0.9887714982032776
59381969,1215,ijuma,2016-04-12T14:08:30Z,"a tuple of 3 elements is not great for readability, i think it's time to introduce a case class for the method result.",-1,0.7190247178077698
59382177,1215,ijuma,2016-04-12T14:09:43Z,unintentional indent.,-1,0.7058167457580566
59425499,1215,becketqin,2016-04-12T18:13:02Z,i was actually wondering why we need these variables? they are just a derived value based on `mmap.limit` and `mmap.position`. shouldn't we just define them as methods?,0,0.9671348929405212
59429145,1215,ijuma,2016-04-12T18:33:05Z,"it's a good question. i assumed they were there for performance reasons, but i haven't checked.",1,0.8531134128570557
59433036,1215,becketqin,2016-04-12T18:54:25Z,thought about this again. having the variables makes sense because we do not lock the mmap on read. that means the read can happen when the writing of an index entry is half-done. i'll keep the variables.,0,0.976783275604248
60862080,1215,junrao,2016-04-25T04:38:00Z,typo abastract,0,0.9865879416465759
60862083,1215,junrao,2016-04-25T04:38:04Z,key/value combination => key or value,0,0.9870302081108093
60862084,1215,junrao,2016-04-25T04:38:10Z,should we assert that exactly one of targetkey and targetkey is not empty?,0,0.9846559762954712
60862100,1215,junrao,2016-04-25T04:38:40Z,"when searching for offset, the passed in value is the absolute offset whereas the offsets in the index are relative. so, we use to translate the absolute offset to the relative one in indexslotfor(). that logic seems to be lost in the new code.",0,0.9841790795326233
60862105,1215,junrao,2016-04-25T04:38:48Z,the description starting from line 155 seems redundant. the description in line 150 and 151 explains this method pretty well.,0,0.9539146423339844
60862107,1215,junrao,2016-04-25T04:38:53Z,it seems it's more natural to return none in this case.,0,0.9632287621498108
60862130,1215,junrao,2016-04-25T04:39:07Z,passing in handleandmaybestop seems a bit more complicated than necessary. i am wondering if we can just reuse the iterator() code to be able to iterate messageandoffset from an arbitrary position. the caller can decide what to do.,0,0.6895937919616699
60862136,1215,junrao,2016-04-25T04:39:22Z,typo: mappying and timestamp,0,0.9865135550498962
60862140,1215,junrao,2016-04-25T04:39:26Z,unused imports.,0,0.9382352828979492
60862143,1215,junrao,2016-04-25T04:39:33Z,the comment on line 172 is now outdated. perhaps we can just say all index files.,0,0.9753065705299377
60862149,1215,junrao,2016-04-25T04:39:45Z,that's a good point. it seems that we should check the existence of the index file before creating logsegment.,1,0.8231912851333618
60862151,1215,junrao,2016-04-25T04:39:56Z,"the warning log in line 205 always refers to indexfile, which is not necessarily correct now.",0,0.9877117276191711
60862158,1215,junrao,2016-04-25T04:40:12Z,"hmm, it seems that we should insert the offset in segment i that has the largest timestamp. not sure why we want to insert the offset in the next segment.",0,0.9073725342750549
60862171,1215,junrao,2016-04-25T04:40:34Z,"hmm, does the seg.largesttimestamp always correspond to logendoffset?",0,0.9876941442489624
60862192,1215,junrao,2016-04-25T04:41:35Z,"the current getoffsetbefore() api is a bit awkward to use since it's tightly coupled with how we use the last modified time in each log segment. for example, it doesn't seem to make sense to return a sequence of offsets now that we have message level timestamp. so, it's probably simpler and better to leave the current implementation of getoffsetbefore() as it is. in log, logsegment, and timeindex, we expose a simple api that takes a timestamp and returns a single offset whose timestamp is >= than the input. in the future, we can design a new request that exposes this capability to the client.",0,0.7835138440132141
60862196,1215,junrao,2016-04-25T04:41:44Z,"hmm, i think we want to show both the actual size and the max size, not the ratio.",0,0.9714640974998474
60862197,1215,junrao,2016-04-25T04:41:50Z,could we just call entry.getvalue once?,0,0.9888495802879333
60862201,1215,junrao,2016-04-25T04:41:58Z,"hmm, is this right? the offset associated with the largest timestamp may not be the last offset in the time index.",0,0.984038233757019
60862203,1215,junrao,2016-04-25T04:42:02Z,is lastoffset ever used?,0,0.9863366484642029
60862208,1215,junrao,2016-04-25T04:42:09Z,should we compute maxtimestampsofar before appending to the timeindex?,0,0.9885593056678772
60862210,1215,junrao,2016-04-25T04:42:13Z,typo retrun,0,0.9855475425720215
60862213,1215,junrao,2016-04-25T04:42:21Z,not sure why we need max here since we should always be able to find a timestamp >= lasttimeindexentry.timestamp.,0,0.944265604019165
60862216,1215,junrao,2016-04-25T04:42:32Z,"not sure why we need ""the timestamp is the max timestamp before that offset.""",0,0.9791058897972107
60862218,1215,junrao,2016-04-25T04:42:34Z,typo timestmaps,0,0.9865829348564148
60862221,1215,junrao,2016-04-25T04:42:38Z,larger than => larger than or equal to,0,0.9658371806144714
60862225,1215,junrao,2016-04-25T04:42:45Z,store => stored,0,0.9849846363067627
60862228,1215,junrao,2016-04-25T04:42:46Z,typo monitonically,0,0.9756882786750793
60862233,1215,junrao,2016-04-25T04:43:05Z,is it worth maintaining _lasttimestamp and _lastoffset since they can be obtained from lastentry?,0,0.987080991268158
60862237,1215,junrao,2016-04-25T04:43:17Z,"if there is no return value, the convention is not to use =. so, it will be def maybeappend() { }",0,0.9867540001869202
60862243,1215,junrao,2016-04-25T04:43:25Z,"do you mean ""timestamp can't be"" instead ""timestamp can be""?",0,0.9834920763969421
60862249,1215,junrao,2016-04-25T04:43:33Z,"timestampoffset(timestamp, offset) != lastentry seems a more expensive check. could we just check timestamp and _lasttimestamp?",0,0.903675377368927
60862253,1215,junrao,2016-04-25T04:43:41Z,this check seems useless since _entries is calculated from mmap.position.,0,0.8318577408790588
60862264,1215,junrao,2016-04-25T04:44:04Z,"hmm, not sure why this logic here is different from that in offsetindex.truncateto. if we find an index entry that matches offset exactly, it seem that we should delete that slot from the time index too.",0,0.9624571204185486
60862266,1215,junrao,2016-04-25T04:44:11Z,"the error message is only for timestamp, but the failure could be due to offset.",0,0.9818520545959473
60862269,1215,junrao,2016-04-25T04:44:15Z,should 35% be 33%?,0,0.9772090911865234
60862271,1215,junrao,2016-04-25T04:44:16Z,the each => each,0,0.9804607033729553
60923190,1215,junrao,2016-04-25T14:36:11Z,"we should insert the offset corresponding to maxtimestampsofar, right?",0,0.9888833165168762
60952050,1215,becketqin,2016-04-25T17:22:10Z,this logic has been moved to `parseindexentry()` in offsetindex and timeindex. this is to make `indexslotfor()` entry format agnostic.,0,0.9880901575088501
60956589,1215,becketqin,2016-04-25T17:50:02Z,good point. i think we can use the iterator for timestamp search. we probably still need to keep a separate scan function for offset search because the iterator does not give the position. but this will be only used by offset search so there is no function argument passed in.,1,0.8945871591567993
60967454,1215,becketqin,2016-04-25T18:52:36Z,"if we check the existence of the index files before creating log segment, would it be a little difficult to distinguish between 1) the upgrade case and 2) time index file is really missing? in (1), we want to just create an empty time index without rebuilding the time index. in (2), we want to rebuild the entire time index. i am wondering in which case will we miss a index? is it only when the index is deleted manually?",0,0.9052485823631287
60968317,1215,becketqin,2016-04-25T18:57:47Z,"hmm, if we return none, what timestamp and offset response should we return to the user? we cannot simply use the log end offset or hw because it is possible the log end offset or hw has grown after the search. so it seems we should tell the caller that up until which offset we have searched?",0,0.9851683378219604
60974231,1215,becketqin,2016-04-25T19:35:42Z,"the way we index the timestamp changed a little since the original proposal. the original proposal was that a timestamp entry `(t, offset)` means the message with timestamp `t` is at `offset`. now it means that before `offset`, the largest timestmap we have seen is `t`. so the offset does not point to the message with the largest timestamp any more. the benefit of the current way is that it is a little easier to build and maintain. so in this case, we are treating the entire log segment as a big message set and assuming the last modification time is the largest timestamp in this segment. so that means before the base offset of the next segment, the largest timestamp we see in this segment is the last modification time of the segment. that is why the last time index entry in each inactive segment always points to the base offset of the next segment.",0,0.9652157425880432
60974567,1215,becketqin,2016-04-25T19:37:52Z,there is no real logic change here. i just changed the printing code format to a shorter pattern.,0,0.974172830581665
60981807,1215,becketqin,2016-04-25T20:23:08Z,please see the previous reply. the offsets is no longer the offset of the message with maxtimestampsofar now.,0,0.9873822331428528
60982883,1215,becketqin,2016-04-25T20:29:09Z,"if the starting position is the position from the last time index entry, it is not guaranteed that we can find a timestamp >= lasttimeindexentry.timestamp.",0,0.9862197637557983
60995200,1215,becketqin,2016-04-25T21:45:14Z,"i was trying to say that when the log segment tries to append a time index entry, it is not guaranteed the timestamp of that entry is strictly larger than the timestamp of previous entries. but the offset has to be strictly larger. we probably should also check the timestamp as well.",0,0.9823099970817566
60996355,1215,becketqin,2016-04-25T21:53:24Z,"this check is to avoid throwing exception in cases when we insert the last entry to the time index when the log segment is closed or rolled. in those cases, we may see attempt to insert a duplicate a time index entry whose offset is the same as the previous one. we can probably split it into two if statement.",0,0.9877024292945862
60996692,1215,becketqin,2016-04-25T21:55:58Z,actually the last check won't even be evaluated unless the previous two statement are true. not sure if performance is a concern here.,0,0.8914825916290283
60996885,1215,becketqin,2016-04-25T21:57:13Z,"_entries is a variable loaded from mmap.position when then index is created, but after that it is maintained separately. the original offset index has the check so i just left it unchanged.",0,0.9887885451316833
61005130,1215,becketqin,2016-04-25T23:04:06Z,"this is also related the to semantic meaning of the time index. because the offset in the index entry is the ""next"" offset. so if the truncated to index is the same offset in the index entry, we should keep the entry because the max timestamp corresponding to that time index entry are not truncated.",0,0.9856400489807129
61006403,1215,becketqin,2016-04-25T23:16:09Z,"if we compute the maxtimestampsofar before appending to the timeindex, we will require the lastoffset of the messages. if we do it in this way we only need the firstoffset.",0,0.9865798354148865
61188911,1215,Ishiihara,2016-04-27T00:49:44Z,the parentheses may not be needed here as this function does not have side effect. correct me if i am wrong.,0,0.9058624505996704
61188922,1215,Ishiihara,2016-04-27T00:49:50Z,maybe add another log after the file is successfully deleted.,0,0.9830644726753235
61188929,1215,Ishiihara,2016-04-27T00:49:56Z,are we always rounding up or rounding down? it would be nice to reflect that in the function name.,0,0.9765834808349609
61188934,1215,Ishiihara,2016-04-27T00:50:01Z,assume all entries are valid and set the position to the last entry,0,0.9840551018714905
61188942,1215,Ishiihara,2016-04-27T00:50:05Z,how about using a different error message? e.g. entry size exceeds max index size.,0,0.9653580188751221
61189019,1215,Ishiihara,2016-04-27T00:51:03Z,may be remove forcefully?,0,0.9770238995552063
61189107,1215,Ishiihara,2016-04-27T00:52:21Z,how bout log in the error level?,0,0.9810619950294495
61326011,1215,Ishiihara,2016-04-27T20:03:02Z,the comments of the return value are inconsistent. largest_timestamp_checked_before_target_timestamp and largest_timestamp_checked.,0,0.9382156729698181
61326015,1215,Ishiihara,2016-04-27T20:03:04Z,this equivalent as -> this is equivalent to,0,0.9798832535743713
61674500,1215,becketqin,2016-04-30T20:20:34Z,"it seems this message is warning about a wrong maxindexsize argument, but not because there are too many entries. so the error message seems right. but we can probably add the current index size in the log.",0,0.9721111059188843
61674869,1215,becketqin,2016-04-30T20:48:16Z,"this is a pre-existing comments. i am not sure if it is really a ""forceful"" free. so i just leave it as is.",0,0.680149257183075
61674895,1215,becketqin,2016-04-30T20:50:28Z,"not sure if it is needed. if something wrong happened, an exception should be thrown and we will see that in the log. otherwise it is removed successfully. so no exception = success?",0,0.9685540795326233
61676699,1215,Ishiihara,2016-04-30T23:10:43Z,it seems a bit nicer if we use string interpolation.,0,0.9318832755088806
61676701,1215,Ishiihara,2016-04-30T23:10:47Z,"again not a big deal, but we can use pattern matching to be more scala-like. [code block]",0,0.9750216007232666
61676704,1215,Ishiihara,2016-04-30T23:10:54Z,nit: comment is not aligned with code below.,0,0.9550530314445496
61676705,1215,Ishiihara,2016-04-30T23:10:57Z,"not a bit deal, but we need to import `ioexception` to make the ide happy.",0,0.9675391316413879
61684116,1215,ijuma,2016-05-01T09:09:56Z,it is true that pattern matching is a more scala-like. the suggested code is missing a case entry if the first case doesn't match though.,0,0.9859084486961365
64971303,1215,junrao,2016-05-27T21:53:50Z,unused import ioexception,0,0.9798943400382996
64971332,1215,junrao,2016-05-27T21:54:10Z,"this interface is a bit awkward. since we expect either key or value to be set, another option is to have sth like the following. protected def indexslotfor(idx: bytebuffer, target: k, boolean istargetforkey):",-1,0.6659021973609924
64971340,1215,junrao,2016-05-27T21:54:17Z,the comment on return value is duplicated as the one in line 170.,0,0.9869781732559204
64971410,1215,junrao,2016-05-27T21:54:58Z,could we just return the base offset in this case?,0,0.9879008531570435
64971431,1215,junrao,2016-05-27T21:55:10Z,typo timestmap,0,0.9868515133857727
64971444,1215,junrao,2016-05-27T21:55:19Z,perhaps it's better to do the try/catch for each index file so that we know which one is corrupted?,0,0.9818555116653442
64971523,1215,junrao,2016-05-27T21:56:00Z,"hmm, for those segments w/o time index because they were created in 0.9, we will update the index with the last modified time. however, it seems that we didn't change maxtimestampsofar in the log segment after that since logsegmentsseq(i).loadlargesttimestamp() is called before updating the index?",0,0.9858978986740112
64971535,1215,junrao,2016-05-27T21:56:11Z,"hmm, it seems that if assignoffsets is false, we won't set maxtimestampinmessageset properly? perhaps we should initialize maxtimestampinmessageset in analyzeandvalidatemessageset()?",0,0.9802496433258057
64971545,1215,junrao,2016-05-27T21:56:15Z,returnoffsets is unused,0,0.9829145073890686
64971577,1215,junrao,2016-05-27T21:56:30Z,does the timestamp in the last message necessarily have the largest timestamp?,0,0.9840261936187744
64971583,1215,junrao,2016-05-27T21:56:33Z,no need for unit.,0,0.9747672080993652
64971598,1215,junrao,2016-05-27T21:56:37Z,no need to have unit =. there are a few other places like that.,0,0.9783329367637634
64971603,1215,junrao,2016-05-27T21:56:39Z,typo retrun,0,0.9855475425720215
64971625,1215,junrao,2016-05-27T21:56:50Z,"hmm, in this case, should we return lastoffset + 1 in the segment and perhaps with a max timestamp?",0,0.9851480722427368
64971644,1215,junrao,2016-05-27T21:56:58Z,"intuitively, if there is no message, should largesttimestamp be maxlong?",0,0.9867445826530457
64971662,1215,junrao,2016-05-27T21:57:06Z,perhaps we should move this comment to before line 125?,0,0.9852426052093506
64971685,1215,junrao,2016-05-27T21:57:18Z,"since there is no close() method in timeindex, we probably want to clarify that the logic of adding the last timestamp index entry is in logsegment.onbecomingactivesegment().",0,0.9761507511138916
64971723,1215,junrao,2016-05-27T21:57:40Z,typo validatd,0,0.9880726337432861
64971763,1215,junrao,2016-05-27T21:58:00Z,it seems that maxtimestamp won't be set properly if messagetimestamptype is log_append_time?,0,0.9829713702201843
64971776,1215,junrao,2016-05-27T21:58:05Z,could we update the comment with respect to the return type?,0,0.9873663187026978
64971791,1215,junrao,2016-05-27T21:58:11Z,it would be useful to add a comment explaining the return type before the method.,0,0.987338662147522
64971800,1215,junrao,2016-05-27T21:58:16Z,log timestamp => offset,0,0.9873659610748291
64971805,1215,junrao,2016-05-27T21:58:19Z,"hmm, not sure what this is for.",-1,0.7800498604774475
64972732,1215,Ishiihara,2016-05-27T22:10:04Z,the ioexception is used in scaladoc.,0,0.9889172315597534
64998112,1215,becketqin,2016-05-29T06:05:53Z,"hmm, but the key and value type might be different, so only defining the target to be the type of key seems not enough. maybe it is less awkward if have sth like: `protected def indexslotfor(idx: bytebuffer, target: indexentry[k, v], searchbyentity: indexsearchentity):` the indexsearchentity is an enumeration that is either searchbykey or searchbyvalue.",0,0.9606406092643738
64998229,1215,becketqin,2016-05-29T06:20:56Z,"actually never mind. since we only search by key, so having key is probably good enough.",1,0.7856903076171875
64998294,1215,becketqin,2016-05-29T06:29:16Z,we do search by value when truncating the time index... so maybe we still need to pass in the index entry.,0,0.9850577712059021
64998628,1215,becketqin,2016-05-29T07:16:57Z,"if there is no message after the starting point, it means we have reached the log end. ideally we should return the offset that we started to search with, but we only have position in this method. so we return none here to let the caller know that we have reached the log end and the caller will return the offset corresponding to the physical starting position.",0,0.9850100874900818
64999284,1215,becketqin,2016-05-29T08:12:38Z,i added that according to the scala coding style guide. maybe we can do a refactoring separately if we want to. [a link],0,0.9833443760871887
64999465,1215,ijuma,2016-05-29T08:27:13Z,"yeah, kafka currently deviates from that convention. i prefer the scala coding style guide way, but there isn't a strong reason either way (one way is a little more consistent, but is more verbose). so, it probably makes sense to stick with kafka's way for now as it would create a lot of diffs to change.",0,0.6906679272651672
65019054,1215,becketqin,2016-05-30T02:53:53Z,"if `log.searchfortimestamp()` returns none, that means there is no message at or after the position we started to search with. it could happen when: 1. the log segment is empty 2. the log segment is truncated after we got the position from the offset index. for case (1) maybe we should just return (notimestamp, baseoffset). for case (2) maybe we should propagate the none to the caller so the caller can retry the search. this does not completely solve the problem that we may return an offset to the user that is later truncated, but would avoid it as much as possible. does that sound reasonable?",0,0.9797388315200806
65019819,1215,becketqin,2016-05-30T03:10:57Z,"previously we don't have a concept of largest timestamp for a log segment. implicitly the largest timestamp is the last modification time. so all the logic around timestamp is built based on last modification time. with kip-33 supposedly most of the previous logic that are depending on `lastmodified()` should now be using largest timestamp. maxtimestampsofar is only updated when it sees actual timestamp in a message (except for old inactive log segments where maxtimestampsofar is always the same as last modification time and does not change). i am thinking to leave `lastmodified()` as it is but replace the external usage of `lastmodified()` with `largesttimestamp()`. `largesttimestamp()` prefers to use the maxtimestampsofar if it exists, but falls back to lastmodified if no message has a timestamp, such that the external logic would be the same for all segments no matter whether they contains timestamp or not. i may have missed some usages of `lastmodified()` in the current patch. i will fix that in the coming patch.",0,0.9875323176383972
65023366,1215,becketqin,2016-05-30T04:55:32Z,"this is printing out the mismatches. the first timestamp is the timestamp in the index, and the second timestamp is the mismatch timestamp in the log. so the printed string seems correct?",0,0.9859988689422607
65023563,1215,becketqin,2016-05-30T05:01:36Z,"i was trying to list the offsets of the mismatch timestamp index entry. but the format seems wrong, i am thinking of something like the following: when timestamp does not match. `timestamp: 1000 (log timestamp: 2000) offset: 100` when timestamp and offset both do not match `timestamp: 1000 (log timestamp: 2000) offset: 100 (log offset: 200)`",0,0.8622400760650635
65999852,1215,junrao,2016-06-07T02:00:58Z,would it be better to name this searchtype?,0,0.9861115217208862
65999868,1215,junrao,2016-06-07T02:01:09Z,"hmm, this may not be reliable. could we just compare this to (long) int.max?",0,0.9674179553985596
65999871,1215,junrao,2016-06-07T02:01:13Z,unused import,0,0.9649426341056824
65999886,1215,junrao,2016-06-07T02:01:27Z,"to be consistent with the code, maxtimestamp should be before timestamp. also, timestamp is too generic and it's not clear what it really means. how about rename it to logappendtime?",0,0.9347048997879028
65999931,1215,junrao,2016-06-07T02:02:11Z,"hmm, this means that when upgrading, we are forced to scan all existing log segments since they won't have the timeindex. could we just create an empty timeindex file in this case? see my other comment in logsegment on whether it's useful to always have a non-empty timeindex.",0,0.9830008745193481
65999965,1215,junrao,2016-06-07T02:02:42Z,"hmm, we should be checking timeindex.entries instead of maxentries, right?",0,0.98455411195755
65999990,1215,junrao,2016-06-07T02:03:12Z,"hmm, is the while loop necessary? it seems that if foundoffset is none, we can just return baseoffset of next segment or nextoffset if the search is on the active segment. also, if we have an empty log, do we loop forever?",0,0.9847090244293213
66000164,1215,junrao,2016-06-07T02:05:21Z,"in the proposal of kip-33, we changed the behavior of log rolling to be that if the largesttimestamp in the segment hasn't changed for the log rolling time, we will roll another log segment. thinking about this a bit more, i am wondering if it's better to preserve the current log rolling logic based on the log segment create time. the current behavior provides a nice property that a log segment is guaranteed to be rolled within certain amount of time. this is useful since there are use cases where people may have some sensitive data that has to be deleted or cleaned after certain amount of time. the new behavior will make this harder to enforce since the active segment is never deleted or cleaned and there is no time bound on when the new segment can be rolled. the log deletion policy can still be based on the timestamp in the message.",0,0.9154525995254517
66000207,1215,junrao,2016-06-07T02:06:06Z,extra space before *,0,0.9762660264968872
66000218,1215,junrao,2016-06-07T02:06:19Z,extra space before *,0,0.9762660264968872
66000237,1215,junrao,2016-06-07T02:06:33Z,should we append nextoffset or baseoffset here?,0,0.9879013299942017
66000245,1215,junrao,2016-06-07T02:06:39Z,extra space before *,0,0.9762660264968872
66000271,1215,junrao,2016-06-07T02:06:58Z,"hmm, if none of the message has timestamp, should we include the offset of the first message in the segment?",0,0.9828512668609619
66000275,1215,junrao,2016-06-07T02:07:04Z,we should document when we return none.,0,0.9856771230697632
66000282,1215,junrao,2016-06-07T02:07:08Z,foundtimestampoffsetopt is unused.,0,0.9778019785881042
66000320,1215,junrao,2016-06-07T02:07:44Z,"currently, we have the logic to force adding an index entry (with last modified timestamp) if none of the message has timestamp. i am wondering why this is necessary. it seems that we can just leave the timeindex empty in that case and largesttimestamp() can still return lastmodified? that may make the log recovery logic a bit simpler.",0,0.9569898247718811
66000326,1215,junrao,2016-06-07T02:07:49Z,unused import,0,0.9649426341056824
66000354,1215,junrao,2016-06-07T02:08:10Z,"the comment here says insert a time index entry with the last modified time and the base offset. however, in logsegment.onbecomeinactivesegment(), we insert the next offset, not the base offset. it seems that inserting the base offset makes sense.",0,0.9861774444580078
66000366,1215,junrao,2016-06-07T02:08:23Z,is the comment accurate? maybeappend() may see the same timestamp as long as no new messages have a larger timestamp.,0,0.987922728061676
66000386,1215,junrao,2016-06-07T02:08:43Z,"the comment is not accurate. we don't return a number of entries. also, we are trying to find an entry with timestamp >= than targettimestamp",0,0.5217496156692505
66000434,1215,junrao,2016-06-07T02:09:22Z,"we will need to explain the output better. perhaps when we print ""mismatches in :"" , we can say these are cases where the timestamp in the wrapper message doesn't match the inner. also, it would also be useful to capture errors in which the timestamps are not increasing in the index.",0,0.9825240969657898
66187001,1215,becketqin,2016-06-08T03:13:26Z,"the assumption here is that `this.start + position` is a positive integer, and `size` is also a positive integer. when you say not reliable, do you mean `this.start + position` can also overflow?",0,0.9839657545089722
66188197,1215,becketqin,2016-06-08T03:34:23Z,"the current code actually creates the time index file in line 195 when it instantiate the logsegment. so the else branch seems never be called. i asked that question earlier and you suggested that we can check the index existence before we instantiate the logsegment. but the problem of that is we are not able to distinguish between 1) upgrade case and 2) the time index is missing. we want to create an empty index in case 1) and want to rebuild the time index in case 2). i thought case 2) only occurs when the time index is manually deleted, which is rare. therefore i left the code as it is, i.e. always create an empty time index when it is missing. this is essentially assuming that when a time index is missing it is the upgrade case.",0,0.918771505355835
66188736,1215,becketqin,2016-06-08T03:46:00Z,"this is to make sure the time index file is not resized to zero so it can hold at least one time index entry. but putting the check here is a little confusing, i will move it into ensurenonemptytimeindex().",0,0.9683937430381775
66296450,1215,becketqin,2016-06-08T17:06:48Z,"i am not sure if we have the same guarantee even if we still let the log rolling based on the log segment create time. there are a few issues, 1. when the timestamp type is createtime, the messages in the segment may have older timestamp than the create time of the log segment. so the log rolling may still be delayed from the application perspective. 2. in some linux system, the create time of a file is not available. so based on segment file create time may not always work. i am thinking that maybe we can just let the log rolling based on the timestamp of the first time index entry. we can always insert an index entry when the first message is appended to the log segment. this provides similar guarantee of the previous log rolling and does not have the above two issues. what do you think?",0,0.8189316987991333
66299695,1215,becketqin,2016-06-08T17:25:05Z,"the main idea behind this while loop is to make sure we give user a good offset to our best effort. `targetseg.findoffsetbytimestamp()` only returns none when log truncation occurred after we find the physical position by looking up the offset index. in that case, the may be no message after the physical position because it could have been truncated. we cannot return the nextoffset in that case because it is possible that some new messages have been appended after `targetseg.findoffsetbytimestamp()` returns. we haven't checked the timestamp of those messages, so returning nextoffset in this case might result in skipping messages with larger timestamp. that said, this case should be very rare because truncation usually only occurs on the followers, so they should not server offset request. however, if we have a fast leadership fail over and failback, it could still happen. when the log segment is empty, baseoffset is returned by `targetseg.findoffsetbytimestamp()`.",0,0.9552122354507446
66301258,1215,becketqin,2016-06-08T17:32:07Z,"i was thinking the semantic meaning of this is that the timestamp of the last message in the segment is lastmodified. but you are right that during a search by timestamp, we would want to start from the base offset.",0,0.9656620621681213
66302572,1215,becketqin,2016-06-08T17:39:05Z,i think we do return the offset of the first message if none of the messages has timestmap.,0,0.9887004494667053
66318868,1215,junrao,2016-06-08T19:04:05Z,"right, could this.start + position overflow to a negative value and then + size bring it to positive again?",0,0.9826647639274597
66319046,1215,junrao,2016-06-08T19:05:03Z,"interesting. then, in the code, perhaps we should just get rid of the check of the existence of the offset and the time index files since they are guaranteed to be present after logsegment is created? i agree the case that people manually delete the index files is rare.",0,0.9468211531639099
66319077,1215,junrao,2016-06-08T19:05:14Z,"ok, perhaps we can add this in the javadoc.",0,0.9865288734436035
66319260,1215,junrao,2016-06-08T19:06:23Z,"ok, perhaps we can add some comments to make it clear why we need to do the loop. a related question is what happens when there is no offset whose timestamp is >= than the target timestamp? should we return the log end offset or sth like -1? if it's the former, the user may not know the fact that there is no offset with a larger or equal timestamp.",0,0.9845696091651917
66319334,1215,junrao,2016-06-08T19:06:48Z,"yes, what you suggested sounds like a good idea. i would just modify that slightly to do the time-based rolling based on the timestamp of the first message in the segment. we probably want to update the kip wiki and bring this up in the mailing list to see if people have any concern about the change.",0,0.628168523311615
66376458,1215,becketqin,2016-06-09T03:05:27Z,"theoretically it is possible. but if it is a log segment it seems not possible because the `this.start` would be 0, so it is essentially `position + size`. i don't know if we ever call `read()` on a sliced filemessageset.",0,0.9797776341438293
66377571,1215,becketqin,2016-06-09T03:22:58Z,"thought about this a little more, it seems that it would be better to append the nextoffset - 1. the offset is essentially used in two cases: 1) search by timestamp 2) log truncation. for case 1, the previous behavior was that if the target timestamp is greater than the lastmodified, we will simply start from the next segment. this behavior will be changed if we append the baseoffset here. i.e. user needs to start consume from the beginning of this segment instead of the beginning of next segment. for case 2, if an inactive log is truncated and becomes the active log segment again, we will want to truncate the time index entry as well, if we append the nextoffset -1 here, the time index will also be truncated. but if we append baseoffset here, the time index entry won't be truncated.",0,0.9793491363525391
66479759,1215,becketqin,2016-06-09T16:58:29Z,"the patch currently returns log end offset if there is no offset whose timestamp is greater than the target timestamp. i am wondering in which case user would want to know there is no timestamp greater or equals to the target timestamp? currently, user can always start consuming from the returned offset and it is guaranteed that no message with larger timestamp will be missed. if we return -1, what user would do in that case? they can not seek to the end because after we return -1, some messages with larger timestamp could have been appended so consuming from log end offset will miss those messages.",0,0.974583089351654
66480437,1215,becketqin,2016-06-09T17:02:43Z,"yes based on the timestamp of the first message sounds good. more precisely the time based log rolling will be based on the first message that has a timestamp if there is at least one such message. if there is no message that has a timestamp, the time based log rolling will be based on the create time, which is the same as previous behavior.",0,0.742787778377533
66536970,1215,junrao,2016-06-09T23:00:02Z,"yes, that sounds reasonable.",0,0.9625957608222961
66540277,1215,junrao,2016-06-09T23:33:48Z,"i looked at the commit history on this class a bit more. it seems that the existing logic is because of a bug introduced in kafka-2012. we should check the existence of the offset index file before instantiating a logsegment, not after. then, if the offset index is missing, we will rebuild the index. so, perhaps we can fix the logic here as the following. (1) if offset index is missing, rebuild both indexes. (2) if only the timeindex is missing, create an empty timeindex file (i.e., assuming that it's an old segment from pre-v10).",0,0.9694739580154419
66561253,1215,becketqin,2016-06-10T04:45:37Z,"that is a good point. i think it should work. there is a slight difference. the current patch essentially takes a snapshot of the timestamp when last message is appended to the log segment. so even if user touched the segments later and changed the modification time, it does not affect the log retention. if we change the behavior to only use lastmodified of the file, it could change if user touch the file later. i remember our sre used to do touch the file for some reasons, but i am not sure if this is an important difference.",1,0.5329306721687317
66561646,1215,becketqin,2016-06-10T04:54:58Z,i see. that sounds reasonable to me.,0,0.9583730697631836
66696679,1215,junrao,2016-06-11T00:21:04Z,"yes, after the producer upgrades to 0.10, all new messages will have a timestamp and the time-based retention will be more accurate. for the old messages, the current behavior is to use the current last modified time for retention. we don't really have to improve it if that makes the new code simpler.",0,0.9799456596374512
67100177,1215,junrao,2016-06-15T05:05:33Z,"this iterator actually copies the key and value from the file channel to the buffer. for searching timestamp, we could do a special iteration that just copies the header part (like how we do in search by offset). we need to think through whether it's worth specializing.",0,0.9855851531028748
67100215,1215,junrao,2016-06-15T05:06:14Z,"hmm, is that true? the segment could have messages with and w/o timestamp. stopping early may prevent us from finding the offset with the timestamp that we want.",0,0.9840609431266785
67100246,1215,junrao,2016-06-15T05:06:25Z,"in this case, should we really maxtimestampchecked since it is not really associated with lastoffsetchecked + 1?",0,0.9870648384094238
67100351,1215,junrao,2016-06-15T05:06:48Z,"do we need to duplicate the code for index and timeindex? since both indexes are of abstractindex, perhaps we can just iterate two abstractindex in a loop and do the sanitycheck and recover in the loop (we may need to add a absolutepath() method in abstractindex).",0,0.9889997839927673
67100430,1215,junrao,2016-06-15T05:07:17Z,it's a bit awkward to have to create logsegment here and in line 196. we can avoid that by just doing sth like the following val indexexist = indexfile.exists() segment = new logsegment(...) if (indexexist) else,-1,0.5837215185165405
67100453,1215,junrao,2016-06-15T05:07:40Z,"for segments where no message has timestamp, should we really use last modified time?",0,0.9884782433509827
67100460,1215,junrao,2016-06-15T05:07:43Z,typo timestaamp,0,0.9870818853378296
67100462,1215,junrao,2016-06-15T05:07:47Z,an => a,0,0.9705461263656616
67100482,1215,junrao,2016-06-15T05:08:04Z,"it seems that we can retain the tombstone using the message timestamp, instead of segment time. we can file a separate jira to track that.",0,0.9889726042747498
67100485,1215,junrao,2016-06-15T05:08:09Z,no need for extra space before startms,0,0.9821946024894714
67100491,1215,junrao,2016-06-15T05:08:13Z,maxtimestampsofarbeforeappend is never used.,0,0.9779869914054871
67100692,1215,junrao,2016-06-15T05:10:25Z,"do we have to append the timestamp for the first message to the index? if so, we are not doing that consistently in recover(). for log rolling, it seems that we can just track the timestamp of the first message (if notimestamp, just use the create time) during startup or append w/o needing the index entry.",0,0.9872855544090271
67100718,1215,junrao,2016-06-15T05:10:48Z,"if we update offsetofmaxtimestamp, don't we need to update offsetofmaxtimestamp accordingly?",0,0.9884939789772034
67100724,1215,junrao,2016-06-15T05:10:55Z,could we improve the text to make it clearer how the index is corrupted?,0,0.9834575653076172
67100745,1215,junrao,2016-06-15T05:11:19Z,"there is inconsistency in the caller of maybeappend(). some of them does [code block] and some others don't do the check. it would be better if we can do this consistently. it seems if maybeappend() just ignores negative timestamp, the caller doesn't have to do the check anymore.",0,0.9534907937049866
67100751,1215,junrao,2016-06-15T05:11:26Z,this comment is a bit weird in that it tries to explain things that we don't do. is it useful?,-1,0.9751782417297363
67100757,1215,junrao,2016-06-15T05:11:31Z,could we improve the text to make it clearer how the index is corrupted?,0,0.9834575653076172
67100764,1215,junrao,2016-06-15T05:11:34Z,on => one,0,0.979824423789978
67100776,1215,junrao,2016-06-15T05:11:44Z,"hmm, not sure why we need to have the while loop here. aren't we just loop the same wrappermessageopt over and over?",0,0.9234687089920044
67100784,1215,junrao,2016-06-15T05:11:51Z,this should probably go to stderr as those mismatches.,0,0.9479157328605652
67398599,1215,becketqin,2016-06-16T18:26:01Z,"hmm, i actually did that in my first patch. `searchforoffset()` and `searchfortimestamp` were sharing a `scanandhandlemessages()` function that does a special iteration by only looking at the headers. you suggested maybe we can just use the iterator in the comments and i thought it was a good suggestion because of the following reasons: 1. search by timestamp is a very infrequent call. 2. unlike searching by offset, searching by timestamp do need to look into the payload if the message is a compressed message. so copy the value into the buffer seems reasonable. 3. because we have the index, the number of bytes we read from the disk should be relatively small assuming the timestamps are not abnormal. so it seems not worth duplicating the code of the iterator here?",0,0.9218253493309021
67426111,1215,becketqin,2016-06-16T21:20:15Z,"yes, stopping early means we may not find the exact offset with a timestamp that we want. but it will not miss that message. in reality, a log segment may have messages w/ and w/o timestamp because some of the producers have been upgraded and others have not. what concerns me of not stopping when see old message is that if we don't have any message w/ a timestamp (or the timestamp we wanted locates close to the end of the log segment), we may end up with scanning the entire log segment. that will pollute the memory and impact the performance. since we are not appending a time index entry to the time index for the first message with a timestamp in a segment. can we do the following? 1. in `timeindex.lookup()`, when slotfor() returns -1 in the timeindex, we can just return the offset of the first entry instead of baseoffset (the offset will be baseoffset if the first message has a timestamp). this will essentially skip all the earlier messages w/o a timestamp in the log segment. if the time index is empty, we still return baseoffset. 2. in `searchfortimestamp()` we keep searching when we see message w/o a timestamp until we find the timestamp. the only risk is that if two indexed offset in the time index are far away, we may still be scanning the entire log. for example, if message 0 has a timestamp 100, message 100000 has timestamp 200. when people are searching for timestamp 150, we will scan the message from 0 to 100000. but this should be rare.",-1,0.6917526125907898
67427456,1215,becketqin,2016-06-16T21:28:46Z,"currently this method returns the `maxtimestampchecked` and the `nextoffsettoread`, so it is not the exact timestamp to offset mapping. do you think it would be better to return a tuple `(timestamp, offset)` instead of a `timestampoffset`?",0,0.9886748194694519
67445751,1215,becketqin,2016-06-17T00:17:41Z,it seems reasonable to use the last modification time as the biggest timestamp of the segment. do you have any specific concern?,0,0.9823471307754517
67449438,1215,junrao,2016-06-17T01:12:15Z,"ok, sounds good. we can leave this as it is. sorry for going back/forth on this.",-1,0.9879372715950012
67449469,1215,junrao,2016-06-17T01:12:49Z,"1. slotfor returns -1 only when the timeindex is empty. in the case, the largest timestamp of the segment is notimestamp. so, this segment shouldn't need to be search since notimestamp is smaller than any target timestamp, right 2. yes, not sure how common the case you described can happen. given that search by timestamp is infrequent, perhaps scanning more is ok?",0,0.9755780100822449
67449480,1215,junrao,2016-06-17T01:12:56Z,it doesn't seem timestamp is used by the caller. could we just return option[long]?,0,0.9889891743659973
67449925,1215,becketqin,2016-06-17T01:19:39Z,"if a log segment has messages w/ and w/o timestamp, the first message in a log segment may not always have the timestamp. so it seems we still need to store the timestamp of the first message that w/ a timestamp somewhere, right? or do you mean we only look at the timestamp of the first message to determine whether to use the message timestamp or segment create time?",0,0.9783923625946045
67454855,1215,becketqin,2016-06-17T02:48:30Z,i am not sure how to make the text clearer. it seems we have already specifically stated the problem?,-1,0.7696184515953064
67455183,1215,becketqin,2016-06-17T02:55:00Z,i added this because offset index will throw exception if we attempt to insert an offset index entry whose offset equals to the previous offset. i am trying to avoid confusing future contributors here by adding these comments.,0,0.9247124195098877
67455678,1215,becketqin,2016-06-17T03:04:39Z,"the wrappermessageopt will be updated in line 206. we need to do this because if user is producing uncompressed messages, a ""batch"" would actually be multiple messages. the first message in the batch may not always have the the largest timestamp. so we need to scan a little. we should be able to find the indexed timestamp before the next indexed offset in the time index or the log end, whichever comes first.",0,0.9863108396530151
67554576,1215,becketqin,2016-06-17T18:25:35Z,"1. slotfor also returns -1 if the timestamp is smaller than the first indexed timestamp. so the case i described is something like the following: say we have 1 gb log segment, the first message w/ a timestamp is offset 1234567 at position 900mb. and the timestamp is 1000. so the first time index entry will be (1000, 1234567) in this case. now if user come and search for timestamp 100, `indexslotfor` will return -1, and currently we will return baseoffset if `indexslotfor` returns -1. so we will scan the log from base offset and page 900 mb into memory. if we return the offset in the first time index entry. we don't need to scan the previous 900 mb in that segment. because we know that there is no timestamp before the offset of the first indexed offset in the time index, there is no need to scan that. in another scenario, if the time index is empty, that means there is no timestamp in the segment. but in that case `logsegment.largesttimestamp()` will return the last modification time. so `log.fetchoffsetsbytimestamp()` will not skip the segment but treat it the same way as the segments that have timestamps. this essentially means at log level, we people search for we do not distinguish between the largesttimestamp from the message timestamp or the largesttimestamp from last modification time. they provides a unified experience to the users. are you suggesting that we always ignore the old messages completely in the new way of searching for timestamp. i am worried about the transition period regarding that approach. for example, say some user is now using the timestamp search at segment granularity. if they want to consume all the data after 8:00 am, they can start to consume the data after the segment whose last modification time is before 8:00 am. there may be duplicates but it works. now the users upgraded to new consumer which search for timestamp based on message timestamp, suddenly we skip all the old segments and they always get log end offsets. that was also why i am not sure if we should skip the old messages or we should just stop on seeing old messages. 1. i agree the case i described would be rare, so scanning until we find timestamp should be fine.",0,0.9787710309028625
67583237,1215,junrao,2016-06-17T22:21:08Z,"thanks for the explanation. 1. yes, i agree that it's better to use last modified time for segments with no timestamp. so, if all messages have notimestamp, the semantic is that the search will return the offset of the first message in the segment whose last modified time is >= the target timestamp. 2. if a segment has messages with and w/o timestamp, to find the message matching the precise timestamp may require us scan most the segment, but is probably ok since it's rare. it would be useful to document the semantics in the comment above log.fetchoffsetsbytimestamp() on those corner cases.",1,0.9429495334625244
67583244,1215,junrao,2016-06-17T22:21:13Z,"ok, this is fine then.",0,0.9651951789855957
67583312,1215,junrao,2016-06-17T22:21:47Z,"yes, i was thinking of just looking at the timestamp of the first message. if it doesn't have timestamp, we use create time. this is probably simpler than having to force an index entry on first message with timestamp. for those segments with a mix of valid timestamp and notimestamp, we can decide whether the rolling will be based on the old or the new behavior. either is fine, but we probably want to pick one that's easier to implement.",0,0.9721122980117798
67583331,1215,junrao,2016-06-17T22:21:59Z,"corrupt index found, index file (%s) has non-zero size and the last offset is %d is not larger than the base offset is %d",0,0.9720900058746338
67583348,1215,junrao,2016-06-17T22:22:18Z,"got it. then, is it enough to read only maxmessagesize from the log? it seems that we may need to scan to the end of the log to find the message that we are looking for.",0,0.988241970539093
67591522,1215,becketqin,2016-06-18T00:40:28Z,"yes, you are right. we do need to read till the end of the log.",0,0.9772223830223083
67594888,1215,becketqin,2016-06-18T03:53:16Z,"just want to make sure i understand the behavior we want here. it seems that sometimes we want to skip the messages w/o timestamps, and sometimes we don't skip. for example, if we have two log segments: segment 0: baseoffset=0, no message has timestamp, last offset 99, last modified=1000. segment 1: baseoffset=100, the first message with a timestamp is at offset 105, and the timestamp is 2000. the second message with a timestamp is at offset 150, and the timestamp is 3000. now if we search for timestamp 1500, it looks that we should return offset 100, i.e. we should not ignore messages 100 - 104 that do not have timestamps, even though the timestamp we wanted is at offset 105. on the other hand if we search for timestamp 2500, it seems that we will skip the messages 106 - 149 because they don't have timestamps. it seems a little weird that we treat the messages w/o timestamps differently depending on where the messages are. do you think that is the behavior we want or it would be better if we have a consistent behavior regarding messages w/o timestamps? previously i am taking the approach that we always don't skip the messages w/o timestamps. but that does mean we may not able to return the exact message with the timestamp we wanted. what do you think?",0,0.977104127407074
67604184,1215,junrao,2016-06-18T17:46:39Z,"hmm, i was thinking that if you search for timestamp 1500, we will return offset 105 since that's the first message whose timestamp is >= 1500. similarly, if you search for timestamp 2500, we will return offset 150. in the case where a segment has no timestamp (we know that from largesttimestamp), we can optimize by not scanning the whole segment and just return the offset of the first message in the segment. otherwise, we will just scan the segment as much as needed.",0,0.9817968606948853
67605816,1215,becketqin,2016-06-18T19:57:05Z,"if we return 105 when search for 1500, would that cause problem for the transitional period? previously user will consume from 100, which may be the messages they actually wanted. once they switch to new timestamp search, the user will not see message 100 - 104 any more. in our example there are only 5 messages, but in real world there could be more. it looks there is a trade-off we need to make between backward compatibility and accuracy of search. i am not sure how critical the backward compatibility here is. personally i feel that when there are mixture of messages with and w/o timestamps, backward compatibility seems more important. because the accuracy will increase when more and more messages contains timestamp. and we will have the full accuracy once the users have fully rolled out the new message format.",-1,0.7424888610839844
67625139,1215,junrao,2016-06-19T22:34:37Z,"to me, it seems that we just need to preserve compatibility when things are comparable. for example, if a segment has no message with timestamp, it makes sense to use the old behavior, i.e., treating all messages in the segment as if they have the last modified time. if a segment has messages with and w/o timestamp, it's not directly comparable with the old behavior. it seems to me that simply finding the first message with a timestamp >= than the target is easy to understand. stopping at the first message with notimestamp seems harder to explain since it depends on where those messages are and what the indexing interval is. in any case, we probably need a separate kip to expose the timestamp search in an api. we can discuss more and finalize the decision then.",0,0.8594657778739929
67625332,1215,becketqin,2016-06-19T22:51:54Z,"i see. i will create another kip then. the concern i have is that from user's perspective, they don't really care or know which segment the messages go into. they only want to make sure that all the messages produced after a certain timestamp **t** will be consumed. previously the offsets we return to the user are based on last modification time at segment level. it seems that now when we have old messages without timestamps, we should still keep the previous behavior.",0,0.7814845442771912
67796773,1215,junrao,2016-06-21T01:49:35Z,the previous indentation seems correct?,0,0.9843816161155701
67796777,1215,junrao,2016-06-21T01:49:41Z,do we need loadedsegment at all? it seems that loadedsegment is always segment.,0,0.9873005747795105
67796798,1215,junrao,2016-06-21T01:49:54Z,"could we get rid of indexortimeindex and change warn to log ""found corrupted index due to e.getmessage() ...""? the message in the exception tells us the file name, which should be good enough.",0,0.9883906841278076
67796809,1215,junrao,2016-06-21T01:50:01Z,the comment is not accurate. the rolling is now based on the timestamp of the first message.,0,0.6824943423271179
67796815,1215,junrao,2016-06-21T01:50:05Z,do we need the extra new line?,0,0.9852129220962524
67796820,1215,junrao,2016-06-21T01:50:09Z,do we need the extra space before startms?,0,0.9855203032493591
67796828,1215,junrao,2016-06-21T01:50:16Z,the comment seems in the wrong location.,-1,0.8109606504440308
67796839,1215,junrao,2016-06-21T01:50:24Z,unused val maxtimestampsofarbeforeappend,0,0.98544842004776
67796844,1215,junrao,2016-06-21T01:50:28Z,this comment seems in the wrong location now.,-1,0.8736464381217957
67796889,1215,junrao,2016-06-21T01:50:59Z,"this forces us to read one message from every log segment during clean startup, which may incur additional i/os. another way is to calculate rollingbasetimestamp lazily when timewaitedforroll() is first called and then remember it. this will avoid the potential extra i/os.",0,0.9839772582054138
67796907,1215,junrao,2016-06-21T01:51:14Z,"if we update maxtimestampsofar, don't we need to update offsetofmaxtimestamp accordingly? otherwise, the next time we add an entry to the time index, the offset may not match maxtimestampsofar.",0,0.987476646900177
67796913,1215,junrao,2016-06-21T01:51:20Z,"to be more precise, we are not adding the last, but the largest time index entry.",0,0.9812978506088257
67796920,1215,junrao,2016-06-21T01:51:23Z,the comment seems inaccurate.,-1,0.8324682116508484
67796925,1215,junrao,2016-06-21T01:51:29Z,the comment is no longer accurate now that we only return offset.,0,0.8159186244010925
67796958,1215,junrao,2016-06-21T01:51:46Z,"more precisely, the comment should be ""get the index entry with a timestamp less than or equal to the target timestamp"".",0,0.9852303862571716
67796971,1215,junrao,2016-06-21T01:51:55Z,could we use file.getabsolutepath instead file.getname here to make it consistent?,0,0.9888407588005066
67796980,1215,junrao,2016-06-21T01:52:01Z,that means the we => that means we,0,0.9788764715194702
67796995,1215,junrao,2016-06-21T01:52:12Z,"is the comment still accurate? we don't insert the last modification time of the file to the time index, right?",0,0.9859678745269775
67797002,1215,junrao,2016-06-21T01:52:19Z,we want to find the time index entry whose timestamp is less than or equal to the given timestamp.,0,0.9843593239784241
67797008,1215,junrao,2016-06-21T01:52:24Z,could we use file.getabsolutepath instead file.getname here to make it consistent?,0,0.9888407588005066
67797017,1215,junrao,2016-06-21T01:52:33Z,that may require a large heap for the tool. could we read messages in chunks up to maxmessagesize?,0,0.9884740710258484
67797065,1215,junrao,2016-06-21T01:53:06Z,"it seems that we just need to print timestamp and offset in the index. not sure why we need to print s""(log timestamp: $maxtimestamp)"" and s""(log offset: ${partialfilemessageset.head.offset})"".",0,0.9737453460693359
67797070,1215,junrao,2016-06-21T01:53:09Z,typo indexs,0,0.9850113987922668
67797073,1215,junrao,2016-06-21T01:53:11Z,typo indexs,0,0.9850113987922668
67968372,1215,junrao,2016-06-21T23:03:13Z,"hmm, is that right? the rolling check happens before the append. so, the first message in the segment is ""set"", which has notimestamp. then, we will be using the creation time of the segment. so, it seems that in the case, we should roll another segment after calling append() in line 94.",0,0.9843358993530273
67968389,1215,junrao,2016-06-21T23:03:19Z,"hmm, do we need the if test since the baseoffset is 0?",0,0.984121561050415
67968395,1215,junrao,2016-06-21T23:03:22Z,the comment is no longer accurate.,-1,0.8001436591148376
67968397,1215,junrao,2016-06-21T23:03:25Z,unused val msgperseg,0,0.9854341745376587
67968464,1215,junrao,2016-06-21T23:04:08Z,"hmm, shouldn't we populate messages of format 0.9.0 here since we want to set message format to 0.9.0 later?",0,0.9518628120422363
67968484,1215,junrao,2016-06-21T23:04:20Z,"to trigger the rebuild of the index, don't we need to set recoverypoint to 0?",0,0.9872216582298279
67968492,1215,junrao,2016-06-21T23:04:24Z,unused import,0,0.9649426341056824
67968503,1215,junrao,2016-06-21T23:04:31Z,"hmm, why will the append hit the exception here? the timestamp seems larger than the ones in the index.",0,0.9795079827308655
67968517,1215,junrao,2016-06-21T23:04:37Z,"hmm, not sure why we will hit the exception since the offset to be appended is larger than the ones in the index.",0,0.8467775583267212
67968523,1215,junrao,2016-06-21T23:04:41Z,this is no longer accurate.,-1,0.7843107581138611
67968533,1215,junrao,2016-06-21T23:04:48Z,"is ""might"" accurate? it seems it should be ""will"".",0,0.9826276898384094
67968542,1215,junrao,2016-06-21T23:04:52Z,offset index => offset index entry,0,0.9850467443466187
67968550,1215,junrao,2016-06-21T23:04:55Z,this is no longer true.,0,0.577864408493042
68103620,1215,becketqin,2016-06-22T18:02:49Z,"not sure i fully understand this. it seems we need to read the first message from the file anyway, whether at the startup time or when the first message is appended after startup. if the first message received after startup and the first message in the segment resides in the same disk block, we only page in once. otherwise we still need to page in two blocks. so it seems the disk i/os are the same? do you mean we can save the disk i/o if there is no message appended to a partition after startup?",0,0.9627969264984131
68108307,1215,becketqin,2016-06-22T18:28:10Z,"hmm, i think filemessageset.read() only set a start position and end position. it does not really read anything into the heap, right? this is just allow the iterator to iterate until the end of the segment. it seems not creating any additional memory pressure.",0,0.9705755710601807
68109192,1215,becketqin,2016-06-22T18:32:30Z,"i was thinking this easier for user to find out what when wrong. when i run this command, i found it is a little ugly that we have to switch between the dumped errors and the printed index entries.",-1,0.8184456825256348
68109601,1215,becketqin,2016-06-22T18:34:34Z,"ah... sorry for the confusion, i changed the assertion expected value but forgot to change the assertion message.",-1,0.9889468550682068
68111083,1215,becketqin,2016-06-22T18:42:13Z,"logically the first message appended to a log segment does not cause the insertion of index entries, so searching for the timestamp of the first message should give base offset. but in our case the base offset happened to be the same as the offset of our first message.",0,0.9868675470352173
68111692,1215,becketqin,2016-06-22T18:45:29Z,it does not really matter whether we append message in 0.9.0 or 0.10.0 format because the log segment will do down conversion when the message is appended if the format is 0.10.0,0,0.9834616184234619
68112128,1215,becketqin,2016-06-22T18:47:50Z,"in our case, we will have corrupted log index, so no matter what recovery point it is, the index will be deleted and rebuilt.",0,0.9769207835197449
68112512,1215,becketqin,2016-06-22T18:49:59Z,this is because the time index entry is already full. we only allow maxentries - 1 entries to be appended if skip full check is set to false (which is the default value).,0,0.9877491593360901
68113246,1215,becketqin,2016-06-22T18:54:01Z,"our base offset is 45l, max entries = 30l. the offset of the last time index entry is (30 - 1) \* 10 + 45 = 335. we are appending an entry with offset (30 - 2) \* 10 = 280. so it is smaller.",0,0.9841406345367432
68166110,1215,junrao,2016-06-23T02:06:26Z,"mayberoll() is only called on the active segment. so, if we get first message on demand when mayberoll() is called, we can avoid reading the first message on all old segments.",0,0.9753418564796448
68166173,1215,junrao,2016-06-23T02:07:29Z,"good point. so, this is not an issue then.",1,0.6311852931976318
68166576,1215,junrao,2016-06-23T02:14:25Z,"but the log is not configured with 0.9.0 message format when the append happens, right?",0,0.9883339405059814
68167173,1215,junrao,2016-06-23T02:24:51Z,"got it. sorry, i thought the first field is the offset.",-1,0.9887795448303223
68244074,1215,becketqin,2016-06-23T14:26:12Z,got it. thanks for the explanation. that makes sense.,1,0.9308920502662659
68244889,1215,becketqin,2016-06-23T14:30:19Z,"ah, you are right. sorry i was reading the lines below this, which is recovering the log.",-1,0.9877356886863708
68306815,1215,ijuma,2016-06-23T20:16:47Z,doing this means that `comparekey` and `comparevalue` will cause boxing to take place. two ways to fix this: - use `` although it's a bit hard to know when the optimisation is not applied - use `long` everywhere when doing the comparisons,0,0.9772449135780334
68307091,1215,ijuma,2016-06-23T20:18:40Z,`java.util.long.compare`?,0,0.9869728684425354
68307419,1215,ijuma,2016-06-23T20:20:40Z,how can we say it is fully compatible and then say that there are `potential breaking changes`?,0,0.9844492077827454
68307613,1215,ijuma,2016-06-23T20:21:50Z,"for the two above, it would probably be useful to say what the previous behaviour was as well.",0,0.9779238104820251
68308726,1215,ijuma,2016-06-23T20:28:32Z,`asinstanceof` and `anyval` are generally avoided in scala as there is usually a cleaner and safer way to do things. maybe `indexslotfor` should take a function that does the comparison?,0,0.9856539368629456
68313140,1215,ijuma,2016-06-23T20:54:35Z,"this is a bit odd, why not the standard `int mid = (low + high) >>> 1`?",-1,0.6253122091293335
68313919,1215,ijuma,2016-06-23T20:58:58Z,"a micro-optimisation is to leave this as the last `else` as we return once it succeeds. statistically, we are more likely to hit the other branches more times.",0,0.958505392074585
70016160,1215,junrao,2016-07-08T01:51:20Z,timebased => time-based,0,0.9849308729171753
70016179,1215,junrao,2016-07-08T01:51:40Z,"on the leader, during append, we actually use the first offset in the messageset when adding the time index entry. to be consistent, we probably should do it here as well.",0,0.9871231317520142
70016194,1215,junrao,2016-07-08T01:51:52Z,"we need to set skipfullcheck to true when calling maybeappend here, right?",0,0.9847457408905029
70016202,1215,junrao,2016-07-08T01:51:57Z,would it be better to rename this to loadlargesttimestamp()?,0,0.9873201847076416
70016219,1215,junrao,2016-07-08T01:52:15Z,it's kind of verbose to have to do the assignment here and in line 256. perhaps we can move these two lines after line 241. then we can get rid of the two else clauses.,0,0.979613184928894
70016230,1215,junrao,2016-07-08T01:52:24Z,"we need to set skipfullcheck to true when calling maybeappend, right?",0,0.9838272333145142
70016242,1215,junrao,2016-07-08T01:52:35Z,the error message is a bit hard to understand. could we improve that?,-1,0.7767936587333679
70145743,1215,junrao,2016-07-08T21:45:34Z,"ran into an issue while testing dumplogsegments (details can be found in the jira since pr comment doesn't support attachment). it seems that if the producer sends a batch of non-compressed messages, in logsegment.append(), we always pass in the offset of the first message, but the offset of the largest message may not be the first. this seems to be what's failing the check in the tool. not sure if this is the behavior that we want. if yes, we will need to document this properly, i.e., the index may point to an offset before the message that has the corresponding timestamp. but then, we have to think through other implications such as how this affects truncation.",0,0.8775653839111328
70380300,1215,becketqin,2016-07-12T05:48:19Z,"i meant it was compatible api wise, however there are potential breaking changes in resource footprint. i agree we should be clearer on this. i'll update the doc.",0,0.9447020292282104
70680191,1215,junrao,2016-07-13T18:19:59Z,could we add offsetofmaxtimestamp?,0,0.9897108674049377
70680203,1215,junrao,2016-07-13T18:20:03Z,could we rename this to validateandoffsetassignresult?,0,0.9890270233154297
70680256,1215,junrao,2016-07-13T18:20:19Z,"we changed the logic to only use the wrapper message offset in time index in append(). so, perhaps we should do the same during recovery? also, it would be good to avoid calling entry.firstoffset twice since decompression is needed each time.",0,0.9837570786476135
70680297,1215,junrao,2016-07-13T18:20:33Z,"in line 460, do we still need the test messageformatversion > message.magicvalue_v0? it seems it's already covered by line 458.",0,0.989666223526001
70680342,1215,junrao,2016-07-13T18:20:43Z,"hmm, in this case, if the targetcodec is nocompression, we should return the offset of the first message, right?",0,0.9813433289527893
70680368,1215,junrao,2016-07-13T18:20:52Z,"for the code btw 484 and 491, if messagetimestamptype and timestamp != maxtimestamp, don't we need to change the timestamp in the wrapper message?",0,0.9876562356948853
70680433,1215,junrao,2016-07-13T18:21:11Z,"typo firxst also, the next line of the comment seems to talk about the same thing.",0,0.985352098941803
70680461,1215,junrao,2016-07-13T18:21:20Z,"when i ran the following command, i got an exception. bin/kafka-run-class.sh kafka.tools.dumplogsegments --files 00000000000000113931.timeindex dumping /users/junrao/downloads/00000000000000113931.timeindex exception in thread ""main"" java.lang.illegalargumentexception: invalid max index size: -1 at kafka.log.abstractindex. (abstractindex.scala:54) at kafka.log.offsetindex. (offsetindex.scala:51) at kafka.tools.dumplogsegments$.kafka$tools$dumplogsegments$$dumptimeindex(dumplogsegments.scala:185) at kafka.tools.dumplogsegments$$anonfun$main$1.apply(dumplogsegments.scala:101) at kafka.tools.dumplogsegments$$anonfun$main$1.apply(dumplogsegments.scala:91) at scala.collection.indexedseqoptimized$class.foreach(indexedseqoptimized.scala:33) at scala.collection.mutable.arrayops$ofref.foreach(arrayops.scala:108) at kafka.tools.dumplogsegments$.main(dumplogsegments.scala:91) at kafka.tools.dumplogsegments.main(dumplogsegments.scala)",0,0.9722256660461426
70684786,1215,junrao,2016-07-13T18:44:25Z,"since we changed the logic, so for compressed messages, we need the offset of the wrapper message for the timeindex. also, could we save the last messageandoffset to avoid calling retainedmessages.last (since it requires iteration)?",0,0.9891383051872253
70926518,1215,becketqin,2016-07-15T06:19:26Z,i was not able to reproduce this issue. it seems that the exception would only happen if the time index file does not exist.,0,0.6941744089126587
72359859,1215,junrao,2016-07-26T23:57:16Z,is removing the above code correct? it doesn't seem there is code to compute the largest timestamp lazily.,0,0.9728444218635559
72360736,1215,becketqin,2016-07-27T00:06:07Z,the maxtimestampsofar and offsetofmaxtimestamp are loaded when the log segment is constructed. so it seems that we don't need to load it again.,0,0.9866634607315063
72363721,1215,junrao,2016-07-27T00:39:52Z,got it. then the changes look good.,1,0.6339618563652039
75409338,1215,junrao,2016-08-18T23:50:45Z,typo timestmp,0,0.9871015548706055
75409364,1215,junrao,2016-08-18T23:51:01Z,could we just set appendinfo.maxtimestamp here and get rid of maxtimestampinmessageset?,0,0.9890439510345459
75409371,1215,junrao,2016-08-18T23:51:04Z,rollingbasetimestamp => rollingbasedtimestamp ?,0,0.987413763999939
75409380,1215,junrao,2016-08-18T23:51:14Z,perhaps it would be safer for the callers to use named params since the first three params are of the same type.,0,0.9843607544898987
75409406,1215,junrao,2016-08-18T23:51:27Z,perhaps we should add largesttimestamp and offsetoflargesttimestamp to the trace logging too?,0,0.9889608025550842
75409414,1215,junrao,2016-08-18T23:51:31Z,typo messsage,0,0.9866942167282104
75409417,1215,junrao,2016-08-18T23:51:34Z,shouldn't we used created instead of 0 here?,0,0.9778217673301697
75409433,1215,junrao,2016-08-18T23:51:47Z,"we probably shouldn't eat the exception here. if there is an error when appending to the time index, we should probably just halt the jvm so that we can run recover on restart.",0,0.9801995754241943
75409443,1215,junrao,2016-08-18T23:51:54Z,that means the we => that means we,0,0.9788764715194702
75409460,1215,junrao,2016-08-18T23:52:06Z,"is the following comment still accurate? we don't insert the last modification time of the file to the time index, right?",0,0.9863640666007996
75409490,1215,junrao,2016-08-18T23:52:23Z,the name wrappermessagetimestamp seems inaccurate since the message set is not always compressed?,0,0.9324102401733398
75409524,1215,junrao,2016-08-18T23:52:45Z,"in both this line and line 472, it seems that we should be using offsetofmaxtimestamp instead of the offset of the last message since validatedmessages may not be compressed when adding to the log. also, could we make wrappermessagetimestamp a non-option field since all possible values are some.",0,0.9881656169891357
75409563,1215,junrao,2016-08-18T23:52:59Z,"it seems that the ordering of the 2nd and the 3rd params is reversed? to avoid this, perhaps it will be clearer to use named parameters since timestamp and offset are of the same type.",0,0.9856152534484863
75410546,1215,junrao,2016-08-19T00:04:46Z,could we not print this if there is no error?,0,0.9752325415611267
75422544,1215,becketqin,2016-08-19T03:14:55Z,"i am thinking that if there is no message in the segment, the log segment would not have been waiting for rolling, so returning 0 seems reasonable. the return value here does not matter much because we check the segment size in log.mayberoll(). but it is probably better to return (now - created) since we have a trace level logging in log.mayberoll().",0,0.9771604537963867
75424163,1215,becketqin,2016-08-19T03:45:08Z,"hmm, if the message is not compressed, the offset should be the exact offset of the message that has the largest timestamp. when using create_time (line 472), that message would be offsetofmaxtimestamp. but when using log_append_time, it seems the offset should be the offset of the first message in the message set because all the messages in the validatedmessages will have the same timestamp. (on line 474, offsetcounter has not been incremented yet. so offsetcounter.value is still the offset of first message). i thought about making wrappermessagetimestamp non-option, but we actually will pass in none in the constructor in line 272.",0,0.9791688323020935
75424189,1215,becketqin,2016-08-19T03:45:45Z,good catch! i'll add a unit test for this. can't believe it is not caught in the unit tests.,1,0.9916630983352661
75425328,1215,junrao,2016-08-19T04:06:50Z,thanks for the explanation. that makes sense. the current logic is correct then.,1,0.7717952132225037
75517403,1215,junrao,2016-08-19T17:08:21Z,the comment is no longer valid. we can probably just remove it.,0,0.9122812151908875
75517610,1215,junrao,2016-08-19T17:09:30Z,"it seems that timeindex.maybeappend() won't throw ioexception. so, swallowing the exception here is actually fine.",0,0.9803357124328613
210999572,5527,Kaiserchen,2018-08-17T18:41:38Z,serialized wrapper?,0,0.9879470467567444
211006524,5527,Kaiserchen,2018-08-17T19:08:05Z,"can skip the second length, its known anyway.",0,0.9850484728813171
211006693,5527,Kaiserchen,2018-08-17T19:08:55Z,treating the whole thing as buffer?,0,0.9636738300323486
211008763,5527,Kaiserchen,2018-08-17T19:17:47Z,i think the step here an optimizer _could potentially_ exploit is the repartitioning. so one could try to only factor out the repartitioning,0,0.9846414923667908
211009275,5527,Kaiserchen,2018-08-17T19:20:07Z,probably need to wrap into delegatingpeekingkeyvalueiterator,0,0.9855167269706726
211347575,5527,bellemare,2018-08-20T17:38:36Z,"true, i could just do it as the remainder. thanks",1,0.9573004841804504
211347916,5527,bellemare,2018-08-20T17:39:41Z,"i'll have to look more into the optimizer. tbh i built this originally in 1.0 and just did a functional port, not necessarily a best practices one. thanks",1,0.9760273694992065
211390368,5527,bellemare,2018-08-20T20:05:51Z,"i don't understand your question, can you elaborate?",-1,0.6623926162719727
211396540,5527,bellemare,2018-08-20T20:27:36Z,will do.,0,0.9548023343086243
211399371,5527,bellemare,2018-08-20T20:37:52Z,"i notice that in 2.x that i may be able to rework this to allow for enabled cache using a `prefixscan` function similar to `threadcache.range`. i will have to look into this a bit more, though i don't think it will affect performance much since i anticipate rocksdb prefixscan to take the longest overall.",0,0.975823700428009
211510890,5527,Kaiserchen,2018-08-21T07:57:50Z,"might be, its one of the places i got stuck once. from experience i can tell that its working sufficiently well w/o cache. i think rocks does a pretty good job in not seeking around to randomly on the disk",1,0.6064413189888
211511167,5527,Kaiserchen,2018-08-21T07:58:50Z,i would not recommend to spend to much energy. at the moment i really don't expect the optimizer to be able to exploit any of this. probably also not in the future. was just a though popping into my head,-1,0.6734971404075623
211511539,5527,Kaiserchen,2018-08-21T08:00:21Z,i think the whole section could look nicer if you would start with bytebuffer.allocate(totallength).asintbuffer(keylength).asbytebuffer.put(key).put(key)... something,0,0.8993171453475952
214673257,5527,Kaiserchen,2018-09-03T12:23:37Z,would need to forward `null` here?,0,0.9802518486976624
214674662,5527,Kaiserchen,2018-09-03T12:29:31Z,would remove this class and avoid protected final here. doesn't seem like a convincing java programming style.,-1,0.790561318397522
214715526,5527,bellemare,2018-09-03T15:01:58Z,"i'll leave it out for now. if someone else thinks otherwise, they can speak up or it can be done in a subsequent pr.",0,0.9786262512207031
214744117,5527,bellemare,2018-09-03T18:30:42Z,"yes, cleaner to do so. the value is not relevant. i have fixed that and added a clarification comment (i can remove all comments if required before final submission).",0,0.9652001857757568
214744281,5527,bellemare,2018-09-03T18:32:41Z,"i will change this - but i do appreciate any advice on how i should changee that. i'll post my updated code and we can determine if it's any better, or if there is a more specific approach i should follow.",1,0.9464206695556641
275888898,5527,adaniline-traderev,2019-04-16T16:34:03Z,"why is the topic passed as null? it causes issues with genericrecord avro serializer, since it tries to register schemas under ""null-value"" subject, and the schema registry responds with ""version not compatible"" error",0,0.9639286994934082
275899695,5527,bellemare,2019-04-16T17:00:50Z,"the issue is actually with the confluent implementation of the serde, as they incorrectly attempt to register when null topics are passed in. read [a link] for more details. that being said, it has been extremely quiet in that git repo, i am not sure how much effort confluent puts into supporting work on that product.",-1,0.816631019115448
275904020,5527,adaniline-traderev,2019-04-16T17:11:42Z,"if this does not gets fixed either way, this pr will be unusable for most of the practical use cases. what is the downside of passing the topic name to the serializer? i tried it, and it seemed to work as expected. is there a workaround if confluentinc/schema-registry#1061 is not fixed?",0,0.9255892634391785
275908240,5527,bellemare,2019-04-16T17:22:45Z,"i think the main issue would be the large amount of internal topic schemas registered to the schema registry. this, combined with any breaking changes to the schema (due to normal business requirement changes) would make it such that you are now needing to manually delete schema registry entries made to internal topics. this is a workflow that i do not believe was ever intended to be done with the confluent serde. as it stands right now, there are allegedly other functionalities that require null serialization (""there are several places in streams where we need to serialize a value for purposes other than sending it to a topic (ktablesuppressprocessor comes to mind), and using `null` for the topic is the convention we have.""). these too will not work with the confluent serde. if they do not fix it, then the next best thing to do would be wrap it in your own implementation and intercept null-topic values to avoid registration. i do not see why it wouldn't be fixed since the current behaviour of registering ""null-topic"" is fundamentally useless. anyways, with all that being said, for this particular line i can certainly pass in the topic since it's fairly well-defined. if you wish to have your internal topics registered to the schema registry, no big deal. for other parts, such as [a link] there is no solution using the current confluent serde.",0,0.7532543540000916
275924688,5527,adaniline-traderev,2019-04-16T18:02:56Z,"confluent serde needs a schema id, and looks like it is not stored in genericdata.record instance - it may not be trivial to fix confluentinc/schema-registry#1061...",0,0.9857122302055359
275926845,5527,bellemare,2019-04-16T18:08:30Z,"that is a fair point. : it may not be as easy to get the hash value as we thought if we rely on the value serde, namely because of the interactions with the schema registry to serialize the data. though this is technically a confluent issue, it may be sufficient to put a blocker on this pr since, as adaniline demonstrates, many users of this use the confluent serde. any thoughts on a way forward are welcome.",1,0.5175617933273315
275978323,5527,vvcephei,2019-04-16T20:28:13Z,"hmm. this does seem like an impediment. the serializer interface doesn't specifically state whether the topic is nullable or non-nullable. what it does say is ` topic topic associated with data`. getting fully into armchair lawyer mode, it seems like this statement implies non-nullability, since `null` is not a valid topic name. if it could be null, it should say something like ""the topic associated with the data, or null if there is none."" also, backing up to a higher level, the serializer interface is specifically for serializing data for use with kafka topics. so, it's probably not appropriate to use it for general serialization. if we want to do that, maybe we should add a new interface that doesn't imply we're sending data to a topic. then again, this is in support of an optimization. perhaps we should just drop the optimization for now and go back to storing only the foreign key reference for the correctness check. for bonus points, we could design a message and storage format that leaves the door open for future optimizations like this, without an awkward upgrade procedure. wdyt, ?",0,0.7120104432106018
276022142,5527,guozhangwang,2019-04-16T22:48:53Z,"on the high-level, i think this should be fixed at confluent sr, rather than letting an ak feature blocked on it -- i.e. users should still be able to pass in not-null topic names while non-schema required typed data will not be registered. reading on the source code of avro-serializer, i think the root cause is that today we treat all primitive typed data as a simple avro-schema as well when serializing, hence still registering it. details are here: [a link] and [a link] we could, instead, fix sr to let it just use primitive serdes directly for primitive types. in this way users can still provide topic names.",0,0.9709072709083557
276026299,5527,pgwhalen,2019-04-16T23:08:22Z,"fwiw , as a user of the sr/serdes, i would consider ""fix sr to let it just use primitive serdes directly for primitive type"" to be a regression. registering primitive schemas with the schema registry is a feature, because it allows other applications (support tooling, etc.) to understand the data in a topic without any context whatsoever.",0,0.9861034154891968
276236590,5527,bellemare,2019-04-17T13:20:57Z,"i think to answer the question of if confluent needs to change their sr and serde, or if we need to take a different approach requires us to address john's first paragraph: ""the serializer interface doesn't specifically state whether the topic is nullable or non-nullable."" if the topic must be non-nullable, then the current approach with the hash code wont work, since the output topic is unknown by the ktablerepartitionerprocessorsupplier.java. if the topic must be nullable (and still provide a serialized output), then the confluent serde/sr needs to change to support this. this isn't clear from the contract and so it probably does need to be resolved. lastly, i do agree with pgwhalen on the usage of primitive schemas in support tooling. we use this functionality all the time with schema registry lookups, as opposed to having our team guess as to what it may have been serialized in. one last thought - for the confluent serde, if the topic is null and the type is a primitive, we can avoid registration and do as outlined. if the type is not a primitive, it can throw an exception (as it effectively does now, upon trying to register to topic-null). this does seem a bit hacky and perhaps a bit complicated, but it may work.",0,0.9804620742797852
276244207,5527,adaniline-traderev,2019-04-17T13:36:43Z,"can the solution be to have a separate interface to calculate data hash (hashsupplier, etc), and have confluent avro serializer implement it? looks like it is a separate concern from kafka data serialization this way ktablerepartitionerprocessorsupplier could do something like [code block]",0,0.9817734360694885
276324353,5527,guozhangwang,2019-04-17T16:17:04Z,"i see. that's a valid point. after a second thought i feel that instead of all / never (i.e. always register a simple avro schema, v.s. never register for primitive types) we should give users options to choose from the two. -traderev that should also work, in fact, we can just let streams to use a special serde other than whatever registered serde for this repartition topic's value, instead of asking the registered serde to provide a hashserde function: note that, the current serde precedence is, from high to low: 1) user overridden value at the dsl. 2) streams library hard-coded value internally (think: longserde for `count`). 3) default registered serde value. but i'm a bit concerned about adding more special handling of serdes at the streams side, i.e. add more scenarios of case 2) above: today streams try to reason about the resulted stream key/value type out of an operator in a best effort and try to use the serde correspondingly event if user does not specify any overrides. the goal is to try to be as adherent to case 1) as possible. although we do have special hard-coded serdes as case 2), e.g. in `count` operator, we hard-coded the serde as longserde unless user overrides it, we still want to keep such cases as small as possible, since having streams to special-handle, e.g. a `ktablerepartitionerprocessor` opens the door for more complexity, as this handling logic would be scattered across the classes and error-prone: note that besides the sink node, at the source node of the downstream sub-topology, streams then should also remember to use a special serde instead of the registered one to deserialize it as well. that being said, if people feels it is worth to add this complexity in streams for good reasons, i can be convinced as well ---------------- philosophically, i'd still argue that, the ak code should not yield to a single vendor's dependency when considering its logic (disclaimer: i'm currently employed at confluent). we should consider what's the best approach for ak streams here, and then if it affects the eco-system dependency we should fix it on the other side.",0,0.9583964943885803
276332348,5527,bellemare,2019-04-17T16:36:42Z,"i don't disagree with your stand on ak first. i do, however, agree with john that the contract is not quite clear on if topic should always be non-null or if topic can be nullable. this is pivotal for determining the way forward. i believe that a precedent has been set by the suppress functionality ( [a link] ), and if we wish to be consistent we should make clear that serializers need to handle null topics (though that handling could simply be throwing an exception.. as is effectively the case with the confluent serde / sr ).",0,0.8412762880325317
276340194,5527,guozhangwang,2019-04-17T16:56:51Z,"for this aspect, my personal take is streams should pass in the topic name whenever it knows -- for the example you brought up, currently it's because the operator does not know the topic name i believe, for which we could refactor internal code to fix it (would like to chime in here whether that is really doable) -- and not relying on any assumptions of the serdes itself, whether the topic is nullable or not.",0,0.9777519106864929
276340707,5527,vvcephei,2019-04-17T16:58:10Z,"hah! well, now i'm really in the middle of it ;) it's worth noting that there's plenty of precedent on both sides of the issue. i don't think the suppress implementation constitutes a contract. it could just as easily be argued that l95 there is a bug. actually, i still feel the way i did toward the beginning of the thread, that it makes more sense to say it's non-nullable (given the javadoc and the origin/ownership of the interface in `kafka-clients`). i'm happy to fix that bug in suppress, since we actually do send the serialized result there to a changelog topic, we should just provide the cl topic name to the serializer. this case is more of a bind because i'm not aware of anywhere else in streams where we legitimately serialize something we have no intention of sending to any topic.",1,0.9909115433692932
276375010,5527,mjsax,2019-04-17T18:24:46Z,"i think for suppress() it's a bug -- and it seems to break sr integration: on restore the schema needs to be fetches from the sr if avro is used, but with `null` topic on serialization the schema would never have be registered correctly and restore would fail with schema not found error. for passing in `null` in general, i think it should be allowed, but i also think it's not really necessary. we can pass in the repartition topic name here, too. with regard to the concern about writing something different into the topic compared to a registered schema: we do this already for windowed changelog topics (note that only the user-data-key is serialized as avro for this case, and we add one or two additional longs and maybe a unique counter before writing into the changelog). if we believe this is an issue, we can fix it, but i would not block this pr for it. it's orthogonal and if we think we need to fix it, we need to fix it for all topics. however, it was not an issue in practice so far, thus, my personal take it, that we should move forward with this pr and pass in the repartition topic name.",0,0.6825551986694336
276391436,5527,bellemare,2019-04-17T19:07:18Z,"i can certainly pass in the repartition topic name for the serializer without any issue for both the serializer and deserializer here. [a link] at that point, it's up to the confluent serde users to complain about their sr being populated with internal topic schemas (an issue we have run into at my company), though it's not a deal breaker. that being said, i am not aware of how to obtain the destination topic in [a link] this processor creates the hash code for the current event from the value serde (ie: confluent's), but has no knowledge of the downstream repartition topic, and thus cannot provide a topic. it is my understanding that this would require information not available to the processor, and so will not work as currently structured. this is the real issue that hasn't been adequately addressed yet, aside from the suggestion from john to drop the hash code optimization. this would skip the whole issue, though it may be sub-optimal in terms of developer experience.",0,0.9044566750526428
276433024,5527,adaniline-traderev,2019-04-17T21:04:07Z,here is another instance where a serializer is called with null topic. i was just wondering if it is possible to pass [code block] as topic name - seemed to worked in my testing scenario...,0,0.9565330147743225
276456917,5527,vvcephei,2019-04-17T22:24:43Z,"at the risk of being annoying, the processor _could_ just make up a topic name to use. this would also fix your problem. right now, i think we have three viable solutions (in order of my preference): 1. generate a topic name for the processor to pass to the serializer 2. pass null to the serializer, forcing confluent's sr and any other serializer/sr to handle nulls gracefully. 3. drop the optimization option 2 is a little unfriendly to confluent sr (and other serializer) implementations, but pragmatically, we _are_ upstream, so we have this leverage we can apply to force them to change.",0,0.7788439989089966
276716731,5527,vvcephei,2019-04-18T15:30:20Z,"further in support of making up a topic name to give the serializer, this is what we're currently doing with state stores, when change-logging is disabled. we unconditionally generate the topic name to pass, given only the appid and storename: [code block] when change-logging is disabled for a store, there is no such topic; i.e., it's a made-up topic name. it's not immediately clear how this is different from something like: `applicationid + ""-"" + processorname + ""-recordhash""`",0,0.9798494577407837
276720367,5527,vvcephei,2019-04-18T15:38:47Z,(tangential: i've just submitted [a link] to fix the suppression serde handling. please feel free to review it!),0,0.7065815329551697
277324985,5527,bellemare,2019-04-22T15:24:41Z,"john, i do indeed like that option of `applicationid + ""-"" + processorname + ""-recordhash""` because of the existing precedence with the made-up changelog topic. i believe a decision like this would further align us with the statement ""topic should always be non-null in serialize/deserialize"". so it comes down to 3 options: 1) punt any question on the serde topic nullability by removing the optimization. 2) require that serde topic parameter be nullable by setting topic to null as i have already done in this pr. 3) require that serde topic parameter be non-nullable by creating a fake topic name. in order of preference, i believe 3 is most reasonable, followed by 1. i think 2 is actually fairly reasonable, but least likely to provide a productive way forward because of the existing ambiguous contract. nullability would require that the loosest form of string be used. if no one else objects, i'll go about using a `applicationid + ""-"" + processorname + ""-recordhash""` and post an update shortly.",1,0.8125602006912231
277394421,5527,bellemare,2019-04-22T18:55:23Z,"small change. wasn't able to figure out a clean way to get processorname, but since it's a dummy anyways, i went with context().topic() instead of processorname",0,0.9725622534751892
278785940,5527,guozhangwang,2019-04-26T01:44:10Z,"back to the sr / avro-serde issue we discussed above: after thinking about that a bit more, i'm wondering if we should just fix it by hard coding a serde for the hash value. since our current serde precedence is: 1) user specified serde at the dsl control object. 2) streams hard-coded serde on some special operator (e.g. at `count` operator we hard-code longserde). 3) globally registered serde via config. for the hashvalue, we can treat it as case 2) above and hard-code a serde internally that override the registered serde. and for this foreign key join operation we would not expose control objects for serde overrides case 1), hence this way we should be safe. wdyt?",0,0.9705803990364075
278872345,5527,mjsax,2019-04-26T09:25:08Z,"from my understanding, the design was to first serializer the data, and afterwards compute a hashvalue based on the `byte[]` array. however, for the first step, we don't know the type and thus cannot hard code a serializer. is my understanding incorrect?",0,0.9236448407173157
278953143,5527,bellemare,2019-04-26T13:41:49Z,"this is my understanding as well, which is why i do not see another way forward at the moment.",0,0.8749276995658875
279118475,5527,guozhangwang,2019-04-26T22:14:28Z,"ah okay, i think i was the culprit for the misunderstanding here: i was thinking that we will 1) compute the hash code first, and then 2) serialize that hash code, and hence the issue is that sr also register for a primitive type which i thought should be addressed at streams. now i realize that we are 1) serializing first, and then 2) compute the hash value based on the bytes. this actually makes much more sense since we cannot guarantee all typed objects have a consistent implementation of the `hashcode` interface. in this way though, the bottom line is that we are calling the serializer for getting the bytes, but we are not actually sending the bytes over the wire. and there are serializers like confluent avroserde out there which tries to remember which topics are serialized with which schema, which will then break since streams are not actually using the serialized bytes actually. given that scenario (hopefully i got it right this time :p), i think although it is indeed fixable on confluent avroserde to not register schema given `null` topic name, it is still only one serde and we cannot tell there are no other serdes in the wild that relies on the passed in topic name parameters to bookkeep some mappings, and therefore i think we still need to consider this issue at the streams layer. on this regard my preference is that, at the moment, we just pass in the actual topic name than using a consistent dummy topic name, and my reasoning is that repartition topics are really internal ones specific to the streams app itself, and not supposed to be exposed outside the app (though for changelog topics there may be some exceptions like other apps / consumers may want to read that topic directly, for repartition topics like this one i do feel that they should be really `transient` and not be leveraged by any external clients), and hence protecting such mis-usages sounds like an overkill to me. in the long run, we should consider adding extra apis in the general serde interface which does not take extra parameters (for this purpose i think neither `topic` name or `iskey` boolean should be included) but just object -> bytes and vice versa, to leave no space for any serdes have semantical business logic around those fields. at that time we can then be on the safer side by choose the new apis.",0,0.7589587569236755
279160285,5527,bellemare,2019-04-27T16:22:52Z,"- sounds very reasonable to me. my question is, do i now simply use `context().topic()`? i believe that is correct, since it'll be the topic that we're sourcing the data from, but i just want to verify.",0,0.8826727271080017
279167678,5527,mjsax,2019-04-27T20:37:59Z,"i discussed this with some other people, and somebody mentioned, that for the value we serialize, this value is actually also store in rocksdb (input `ktable`). we also know, that the corresponding `byte[]` are written into the store changelog topic. hence, instead of using the repartition topic, using the changelog topic should be a better option, as it does not leak anything into sr (or whatever other serdes might do with the topic name). even if there is not changelog topic for the input ktable (we do some optimizations and sometimes don't create one (eg, the store might actual be a logical view and is not materialized). but even for this case, using the changelog topic name seems to be save.",0,0.9537152051925659
279514920,5527,bellemare,2019-04-29T19:58:05Z,"`context().topic()` gives the repartition topic name in the serializer, which is what i want. in the processor sections, where i use null, `context().topic()` gives me the input-topic name for the ktable... which is also fine, since the serializer will check against the input topic schema, which must be valid by definition of the data being within the topic... so i suspect this issue can be laid to rest, in line with adaniline-traderev's suggestion. this removes any requirement for the upstream serializer to have to do special work for null values.",0,0.8828791975975037
279749459,5527,bellemare,2019-04-30T13:20:15Z,"after a long discussion, yes, this is what i think is currently the best option. thanks for the suggestion in the first place!",1,0.9766432046890259
280145412,5527,guozhangwang,2019-05-01T17:26:43Z,"i'm not sure i can fully follow the suggestion of using changelog topic v.s. the repartition topic here: are you suggesting to do it universally or just for this case? if it is the latter case, i felt it a bit awkward due to inconsistency with other source `ktable` cases where we will just follow the `sourcenode / recorddeserializer` path to deserialize using the source topic; it if it the first case, that also has some drawbacks since with today's topology generation not all source `ktable`s will need to be materialized to a store and hence not necessary having a changelog topic. i still feel that using the source topic name (and i.e. in this case, the repartition topic) admittedly exposed to sr but is philosophically the right thing to do, and we should consider fixing it on serde apis in the future. wdyt",0,0.5406618714332581
280147603,5527,vvcephei,2019-05-01T17:33:38Z,might as well just remove it. i think murmur3 is fine.,0,0.875917375087738
280147762,5527,vvcephei,2019-05-01T17:34:10Z,wouldn't hurt to have some tests for this. maybe copy those from hive as well.,0,0.970716655254364
280158927,5527,vvcephei,2019-05-01T18:07:46Z,"recommend making this final as well, and just moving the null initialization to the fk constructor.",0,0.9808573722839355
280159330,5527,vvcephei,2019-05-01T18:08:52Z,[code block] we try to avoid unnecessary qualifiers. also applies elsewhere. i won't call them out further at this time.,0,0.9777172803878784
280187466,5527,mjsax,2019-05-01T19:34:29Z,"i was just talking about the foreign-key case (not sure why you thought it might be anything else?). my understanding is the following: the contract is that we should pass a topic name into the serializer of which we want to write the data into. this contract breaks if we pass in the repartition topic name, because we write something different into the repartition topic. you are right that the changelog topic might not exist, however, my personal take is, that registering for a non-existing topic, is a smaller violation of the contract that passing in the ""wrong"" repartition topic name. note, that the changelog topic name is conceptually the ""right"" topic name. however, this case would not happen very often anyway (compare examples below). your comment trigger one more thought: the optimization framework could actually check for different cases, and if there is an upstream topic (either changelog or source topic that has the same schema), we could actually use this name. some examples (does not cover all cases): [code block] for this case we need to materialize the base table (that is also the join-table), and the schema is registered on `table-topic` already, so we can pass in `table-topic` to avoid leaking anything. [code block] for this case we materialize the derived table from the filter() and we get a proper `filter-changelog-topic` and we can pass this one. [code block] for this case, the agg result ktable is materialized and we can pass the `agg-changelog-topic` as name. [code block] for this case, the agg result ktable is materialized and we can pass the `agg-changelog-topic` as name, because the filter() does not change the schema. thus, even if the join-input ktable is not materialized, we can avoid to leak anything by ""borrowing"" the upstream changelog topic name of the filter input ktable. [code block] for this case, we need to materialize the result of `mapvalues()` and get a proper changelog topic for the join-input table. [code block] this might be a weird case, for which the base table is materialized, while the input join-table would not be materialized, and also the type changes via mapvalues(). hence, the `table-topic` schema is not the same as the join schema and we also don't have a changelog topic for the join-input ktable. we still use the changelog-topic name of the non-existent changelog topic (of the mapvalues() result ktable). as you can see, we can cover a large scope of cases for which we don't leak anything and can always use a topic name that contains data corresponding to the schema. does this explain my thoughts?",0,0.7568451166152954
280187571,5527,vvcephei,2019-05-01T19:34:49Z,"[code block] in general, we try to retrict visibility to the minimum required. i won't call these out further at this time.",0,0.9712331891059875
280188086,5527,vvcephei,2019-05-01T19:36:37Z,"might be a good idea to throw an exception here, to make sure we don't modify the code later and falsify this assumption.",0,0.9749250411987305
280188308,5527,vvcephei,2019-05-01T19:37:30Z,"also, i'm not sure about the fact that configure is called outside of this chain, but close is part of this chain... seems like an ambiguous ownership situation.",-1,0.7004813551902771
280189461,5527,vvcephei,2019-05-01T19:41:36Z,[code block] i personally prefer this any time you're specifically referencing the size of an int or long.,0,0.9715511798858643
280189627,5527,vvcephei,2019-05-01T19:42:09Z,unused,0,0.9405757188796997
280190516,5527,vvcephei,2019-05-01T19:44:58Z,"take this with a grain of salt if you don't like it, but you could save a fair bit of code if you just implement all the `serde`, `serializer`, and `deserializer` interfaces in this one class. (the `serializer()` and `deserializer()` getters can just return `this` in that case). personally, i kind of like this because it puts the serialization and deserialization logic right next to each other, which seems easier to maintain their symmetry.",0,0.5197755098342896
280191410,5527,vvcephei,2019-05-01T19:47:53Z,not sure what this means...,-1,0.9697427153587341
280192430,5527,vvcephei,2019-05-01T19:51:02Z,"my immediate reaction is that it's a little surprising that `byprimarykey := false` means ""use _only_ the foreign key"". boolean flags like this generally contribute to code complexity/obscurity. what do you think about just making separate partitioners for the primary and foreign keys?",-1,0.800725519657135
280193830,5527,vvcephei,2019-05-01T19:55:29Z,it's a little surprising that the store's name is the same as the topic name,0,0.8999390602111816
280194501,5527,vvcephei,2019-05-01T19:57:36Z,"generally, we forbid null keys in ktable apis for this reason. feel free to just drop the record, log a message, and increment the right metric (look around for other null-key checks in the ktable processors).",0,0.9568780064582825
280195544,5527,vvcephei,2019-05-01T20:00:35Z,"just dropping this in before i forget, following kip-307, we need to provide a mechanism to name these operators and internal states.",0,0.9841699600219727
280258689,5527,guozhangwang,2019-05-02T00:07:58Z,"i understand your reasoning now, but still i felt streams should not fix it trying to piggy-back on another topic that happens to be of the same schema that this serde is used for; or rather, i'd prefer to use a non-exist dummy topic than an existing topic if we do not like repartition topics (again, i agree that repartition topic is not ideal, since we are, in fact, not sending the bytes serialized in that way to the topic).",0,0.8411355018615723
281378147,5527,vvcephei,2019-05-06T21:53:40Z,"this reads a little funny to me. can we just say that it's a many:1 join with the other table, and the foreignkeyextractor selects the key in the other table to join with?",-1,0.9764809608459473
281378332,5527,vvcephei,2019-05-06T21:54:17Z,missing ``,0,0.9386642575263977
281378589,5527,vvcephei,2019-05-06T21:55:13Z,feels like this deserves a comment.,0,0.6978794932365417
283745078,5527,bellemare,2019-05-14T11:12:12Z,done.,0,0.9759407639503479
283746677,5527,bellemare,2019-05-14T11:17:24Z,roger that. will review code + apply.,0,0.9402375817298889
283748861,5527,bellemare,2019-05-14T11:24:01Z,done.,0,0.9759407639503479
283756936,5527,bellemare,2019-05-14T11:49:18Z,"done. i copied the tests over. they depend on guava so i added that as a test dependency for the kafka common package. it's also apache-2.0 license so i don't think there's a problem with this, but if there is please let me know.",0,0.9662488102912903
283758235,5527,bellemare,2019-05-14T11:52:54Z,"i'm not sure i follow on this point. is it that the serdes may be closed multiple times, once by my combinedkey(ser/de)erializer and also outside of it?",0,0.91255122423172
283758342,5527,bellemare,2019-05-14T11:53:12Z,"haha yes, programming 101. fixed. :)",1,0.9904194474220276
283759023,5527,bellemare,2019-05-14T11:55:15Z,thanks - removed.,0,0.8792708516120911
283759466,5527,bellemare,2019-05-14T11:56:34Z,deprecated comment. should have been removed. fixed.,0,0.9619207382202148
283760279,5527,bellemare,2019-05-14T11:59:01Z,"good point. i think you are correct and that it will be clearer. the irony here is that i never use it with byprimarykey=true... i think i abandoned that part of the code and forgot to clean it up. so, no more boolean, and i will clean up the name.",1,0.5907220840454102
283766444,5527,bellemare,2019-05-14T12:16:09Z,"i think this makes sense. i did spend time tabbing back and forth while writing it, so having them together sounds like a better idea to me. done.",1,0.7306175827980042
283769402,5527,bellemare,2019-05-14T12:24:13Z,done.,0,0.9759407639503479
283779807,5527,bellemare,2019-05-14T12:49:23Z,bit of a typo there. it should be the state store name. this state store is materializing the combinedkey and so should not be associated with any particular topic name. i will clear this up.,0,0.9817888140678406
283816226,5527,bellemare,2019-05-14T14:06:20Z,done. let me know if it's still unclear.,0,0.9838719367980957
283816527,5527,bellemare,2019-05-14T14:06:58Z,done.,0,0.9759407639503479
283830915,5527,bellemare,2019-05-14T14:34:01Z,done.,0,0.9759407639503479
283833355,5527,bellemare,2019-05-14T14:38:09Z,the wiki says it's currently under discussion - has it already been accepted? just curious as to if this work needs to be done for 2.3 if it's not going to be a part of it.,0,0.9789928793907166
284348335,5527,vvcephei,2019-05-15T16:39:07Z,"i think this is fine, but of course i'm not a lawyer. :)",1,0.9881147146224976
284349058,5527,vvcephei,2019-05-15T16:40:44Z,"i haven't reviewed the most recent state, so this might not be relevant anymore, but i just meant that this class is *not* responsible for calling configure, but it *is* responsible for calling close. ideally, the same class should be responsible for both.",0,0.9566279053688049
284349463,5527,vvcephei,2019-05-15T16:41:40Z,"heh, i wouldn't say it's so basic. we use literals all over the code base for this; i've just recently started promoting the use of the constant field instead.",0,0.779042661190033
284350221,5527,vvcephei,2019-05-15T16:43:25Z,"woah, it looks like the contributor forgot to update the kip. it was accepted. i'll update the wiki.",0,0.9762002825737
284853800,5527,bellemare,2019-05-16T19:02:00Z,"i put this in its own interface for now because it's not immediately clear where it should live. it needs to be part of statestore, given how all of the various wrapper classes, like the metered, caching and logging ones work. however, i do not want it to be in the readonlykeyvaluestore as it shouldn't be exposed to the outside world.",0,0.888469398021698
284854252,5527,bellemare,2019-05-16T19:03:19Z,one of the effects of prefixscan needing to be attached to statestore,0,0.9835905432701111
284854473,5527,bellemare,2019-05-16T19:03:57Z,"i'm not really sure how the timestamped statestores work, nor if i even need to support this (since my intention is to only use the non-timestamped versions).",0,0.5644907355308533
284854893,5527,bellemare,2019-05-16T19:05:12Z,"this is a weird one. i end up with a stack overflow error as the above function calls just go back and forth. it seems like it's getting some weird scope problem. this works around it, but i am not sure if i stumbled on an existing bug or if it's something i introduced. i'm just not really sure how what i did could have caused this.",-1,0.9838010668754578
284855494,5527,bellemare,2019-05-16T19:06:52Z,all the above will be cleaned up.,0,0.9811093807220459
284856271,5527,bellemare,2019-05-16T19:09:16Z,"i'm required to supply a materialized store with a name, otherwise the internals of ktableimpl cannot get the name for the state store, and therefore the subscriptionresolverjoinprocessorsupplier cannot access it (fails with npe). this is related to the aforementioned changes to the ktableimpl constructor dropping the `isqueryable` boolean.",0,0.9852244853973389
284857540,5527,bellemare,2019-05-16T19:13:03Z,"am i going to need to handle all of these statestore types? i suspect i'll need to handle both `timestampedkeyvaluestore` and regular `keyvaluestore`, but given that `context.getstatestore` can return any of them, i don't know if i should expect to handle the remainder.",0,0.9678782820701599
287059994,5527,bellemare,2019-05-23T17:44:50Z,"hi guozhang - i noticed that in this pull ( [a link] ) you made it such that the non-queryable store name is no longer obtainable in ktableimpl. i need access to the materializedinternal.storename, but cannot get it anymore (that i know of). do you have any suggestions of what i should do to get it? my only other options appear to be rewriting the ktableimpl constructors back to what they were before, but since you made this change i would like your input. basically, i am now being given materializerinternal.queryablestorename, but i need materializerinternal.storename for when the user does not specify the materialized store (which is frequently). please advise - thanks",0,0.7672431468963623
289081888,5527,guozhangwang,2019-05-30T17:06:36Z,"sorry i've just seen this now. the main motivation of that pr is to avoid materializing state stores unnecessarily and the queryable-name refacotring is sort of a by-product. i was thinking that the parent store names (user-specified or internal) can be accessed from `ktablevaluegettersupplier#storenames`, would that be a possible work-around for you?",-1,0.9862657189369202
289094679,5527,bellemare,2019-05-30T17:38:45Z,"edit: i may have something. i am leaving this here for now to show where i am stuck, but i will update it if i figure out how to properly use your suggestion... - thanks for the reply. basically `ktablea.dojoinonforeignkey(....) ` needs to be able to access `ktablea's` own internal state store to compare the hash values for the workflow we established in kip-213. when `ktablea` is not materialized (internally or by user-specified queryable-name), then i do not think we can query the parents directly since they are by definition different data stores. i do not see how they can slot in as a replacement for the following section (originalsource is what used to be the always-populated statestore, user-specified or internally materialized, represented by queryablestorename) [a link] based on my understanding, it appears i need to have tablea materialized, otherwise i am not sure how to proceed with this ticket. this is basically where i am stuck. i admit i don't know enough about this part of kafka streams to speak with certainty on this.",1,0.469860702753067
289108628,5527,guozhangwang,2019-05-30T18:13:10Z,"i see. i think the protocol should be that when a join operator requires to access its parents (the joining ktables, for example in this case) it will quire from its parent's `valuegetter`, which would chase up until it finds some processor with associated state stores, or it would go all the way up and require the source ktable to be materialized (see `ktableimpl#valuegettersupplier` --- actually you can find the related materials i got from kafka summit this year, [a link] around slide 56 :) so back to your example, even if the source ktable is materialized without a name, calling a join later should cause its `ktablesource#materialize()` be triggered, where its internal `storename` which is always not-null since it would be auto-generated as `nameprovider.newstorename(generatedstoreprefix)` if not specified, would be assigned to its exposable `queryablename`. and then this name can be accessed by its descent processors in the topology if necessary. hope this would help for you to figure it out.",1,0.904100775718689
289109055,5527,guozhangwang,2019-05-30T18:14:22Z,"note the logic `should cause its ktablesource#materialize() be triggered` may need to be added by you, i.e. the `subscriptionresolverjoinprocessorsupplier` should require to get its parent's valuegetter, which eventually would trigger this function.",0,0.9884886145591736
289121346,5527,bellemare,2019-05-30T18:45:39Z,"i think i solved it with your original recommendation, though by getting the valuegettersupplier as you recommended and not the storenames directly. your follow up message is exactly what i did, so i am glad to have that confirmation. it's passing my tests now and appears to work with and without user-specified queryablestorenames, so i believe this did the trick! thanks for your help! :thumbs_up: now i just need to work on the remaining highlighted issues.",1,0.9908550977706909
289122840,5527,bellemare,2019-05-30T18:49:23Z,overcome by events. no longer relevant :thumbs_up:,0,0.5505493879318237
289124387,5527,guozhangwang,2019-05-30T18:53:10Z,great!,1,0.9904076457023621
296021873,5527,vvcephei,2019-06-20T21:31:11Z,this should get reverted before merging. also with the other commented-out stuff below.,0,0.9865131974220276
296022446,5527,vvcephei,2019-06-20T21:33:08Z,unused,0,0.9405757188796997
296022680,5527,vvcephei,2019-06-20T21:34:01Z,"please attribute the source, along with noting the commit hash, as you did for the main code.",0,0.9883893728256226
296023510,5527,vvcephei,2019-06-20T21:36:54Z,"i've always felt that this was a weird use of the `valuemapper` class, elsewhere. what do you think about using `java.util.function.function ` instead?(just now having this thought)",-1,0.9732102155685425
296023880,5527,vvcephei,2019-06-20T21:38:09Z,"thanks! you can ""resolve"" this comment to clean up the pr.",1,0.9717873930931091
296025422,5527,vvcephei,2019-06-20T21:43:18Z,"documentation nit. since this is such a complicated operation, i think we might want some more verbose comments here. something like:",0,0.9498574137687683
296025600,5527,vvcephei,2019-06-20T21:43:54Z,"as mentioned in the ktablerepartitionerprocessorsupplier, i'm wondering if we can do without this partitioner by using combinedkey only in the prefix-scan store, and not over the wire?.",0,0.9849397540092468
296026278,5527,vvcephei,2019-06-20T21:46:07Z,"""thisstatestorename"" is a little esoteric :) can we try to make this more self-documenting? i'm assuming that you're copying this convention over from the other join, where we say ""this"" and ""other"", but there's a lot going on here. maybe you can establish a different convention, like ""primary key table"" and ""foreign key table"", or ""left side"" and ""right side"", etc..",1,0.9801908135414124
296026592,5527,vvcephei,2019-06-20T21:47:06Z,"as i understand it, the value getter interface is mainly to support looking up values in another ktable. it's fine (and more direct) for you to just wire the same state store in to both processors. then, you won't need a ""prefix value getter"" interface anymore.",0,0.9768890738487244
296026762,5527,vvcephei,2019-06-20T21:47:34Z,"this doesn't seem quite right... i expected to see a *this* joiner handling updates from this table, and and *other* joiner handling updates from the other table (the subscriptionresolverjoinprocessorsupplier), followed by a merge node, but it looks like we're doing something else here?",0,0.7614673376083374
296026938,5527,vvcephei,2019-06-20T21:47:58Z,"didn't totally follow this todo... the pk-side ktable needs to be copartitioned with the input to the ""subcriptionresolverjoinprocessor"" the fk-side ktable needs to be copartitioned with the output of the ""ktablerepartitionerprocessorsupplier"" in both cases, there's one pre-determined topic and one repartition topic we control, so the co-partitioning should be trivial, unless i'm missing something...",0,0.8637822270393372
296027875,5527,vvcephei,2019-06-20T21:50:58Z,"can we assume both keys are not null (i.e., can we add a condition to skip any null-key updates in both processors so that we can rely everywhere on the fact that keys can never be null? other stateful operators already do something similar (see aggregations, for example), and there are metrics and logs for it. edit: i later figured out that this is part of the prefix-search magic.",0,0.9806542992591858
296028126,5527,vvcephei,2019-06-20T21:51:55Z,"not sure i follow what this case means edit: i later figured out that is a ""magic"" case for creating search prefixes...",0,0.6184287071228027
296028311,5527,vvcephei,2019-06-20T21:52:35Z,"can we name the type parameters pk and fk here and elsewhere, just so we don't have to remember which is which?",0,0.9868428111076355
296028562,5527,vvcephei,2019-06-20T21:53:35Z,"regarding `&& foreignvalueandtime.value() != null`, is this because we're only doing an inner join?",0,0.9704975485801697
296028691,5527,vvcephei,2019-06-20T21:54:08Z,there's a protocol for handling cases like this. check out the aggregate processors.,0,0.9852404594421387
296028773,5527,vvcephei,2019-06-20T21:54:26Z,"not sure if identity is sufficient here, since these objects come from deserializers (i.e., this condition may _never_ be true) also not sure if we can rely on `equals` to be any better than identity. i'm wondering, rather than checking inside this processor, we should ask the upstream table to suppress such no-ops, similar to how we request `sendoldvalues`. then, the upstream processor can perform this check on the serialized form of the data and save a bunch of work downstream (aka, right here).",0,0.9675909280776978
296028913,5527,vvcephei,2019-06-20T21:55:02Z,"oooh... for reference, i just spent 30 minutes trying to figure out how the prefix scan is correct, only to realize that you have created a special ""search key"" that just happens to produce a prefix of the ""stored key"" when used in conjunction with your combinedkeyserde. this seems like a _very_ mysterious implicit coupling relationship among 4 different classes. there's got to be a better way...",-1,0.6241554617881775
296028980,5527,vvcephei,2019-06-20T21:55:17Z,we'd better close this iterator.,0,0.9756811261177063
296029149,5527,vvcephei,2019-06-20T21:55:53Z,"maybe a nit, this sentinel is constant and small, so caching it in a static field is probably valuable.",0,0.936048686504364
296029321,5527,vvcephei,2019-06-20T21:56:30Z,"can the key actually be an empty array? if so, it's not a safe sentinel value for null. the hashed value of an empty array is `[-7122613646888064702, -8341524471658347240]`. it seems like we could do better by actually using an empty array as the sentinel-hash representing a null value. then, we don't have to send any bytes over the wire to represent null, or store any bytes for that matter.",0,0.9846804738044739
296029499,5527,vvcephei,2019-06-20T21:57:20Z,"alternatively, does this mean there's no need to notify the other side at all, and we can just proceed to recompute the join result? might break semantics, though...",0,0.5930308699607849
296029644,5527,vvcephei,2019-06-20T21:57:52Z,"if we move the primary key into the value and just forward to the foreign key, we can drop the extra partitioner and also extra serde from the wire protocol",0,0.987862229347229
296030000,5527,vvcephei,2019-06-20T21:59:09Z,"this hash _must_ match the one we produce in ktablerepartitionerprocessorsupplier. if we _ever_ produce a different hash for the same value, we will _lose data_. in light of this, it seems like both locations really need to reference the same logic somewhere, either in a static method somewhere, or passed in as a ""hash function"" over the values. as an illustration of the legitimacy of the concern, you're using a different topic here than in the other location, which could result in a different serial form of the same data.",0,0.9247817993164062
296030317,5527,vvcephei,2019-06-20T22:00:19Z,"maybe a nit... maybe move this byte to the front and make it a bit field, so that we have a straightforward path to pack more boolean flags into the value in the future.",0,0.9816495776176453
296031064,5527,vvcephei,2019-06-20T22:03:10Z,"adding this new interface to keyvaluestore may have some serious implications for implementers. are we sure we have to? at least, we need to add a default implementation.",0,0.8107689023017883
296031167,5527,vvcephei,2019-06-20T22:03:33Z,"note this isn't a byte[], but a k. not actually sure if this api makes sense. for example, what would this api mean if my key type is uuid or mycustomrecord? in other words, only some key types even have prefixes.",0,0.981776773929596
296033792,5527,vvcephei,2019-06-20T22:13:07Z,"sorry, feeling a bit dense... is this right? it seems like it would cut off some results that should be at the end of the range. in particular, it seems like it cuts off keys like `[prefix]ff01`, since that key is strictly greater than `[prefix]ff`. you might want to take a look at the function that rocksdb uses to compute the range-end for range queries.",-1,0.9886166453361511
296034425,5527,vvcephei,2019-06-20T22:15:38Z,"just a thought, does rocks return in sorted order? if so, we can probably do better by comparing backwards from the end of the prefix. then again, that might screw up cache locality, not sure...",0,0.7323569655418396
296034482,5527,vvcephei,2019-06-20T22:15:50Z,probably should be illegalstateexception,0,0.9568338394165039
296034728,5527,vvcephei,2019-06-20T22:16:47Z,"huh, neat... as i read it, the serial format for our combinedkeys is [fk length][fk bytes][pk bytes] this means that all the records with same-length foreign keys are sorted together, a prefix scan won't suffer any ambiguity between fk and prefixes of the pk. this seems to avoid a problem we face in the session window store. putting it in terms of this key if we have two records with r1.fk=aa r1.pk=b and r2.fk=a and r2.pk=ab, they are both serialized as aab, and in particular, a prefix scan would get pseudomatches that are out of the range and have to handle it by decomposing the serial form and then double-checking the prefix. but since you prefix by the size of the fk, there's no ambiguity, even if the fks are variably sized! but it is worth noting that this depends on the exact serialization format.",1,0.6723944544792175
296034895,5527,vvcephei,2019-06-20T22:17:23Z,"this is due to the subclassing. if you instead wrap and delegate, this won't be a problem.",0,0.9843429327011108
296857031,5527,bellemare,2019-06-24T18:29:39Z,"yep, this is the intended design. it definitely is sensitive to how the serialization is handled, but i think that it's okay as it currently stands.",0,0.9484919309616089
296858048,5527,bellemare,2019-06-24T18:31:57Z,"yep. i'm taking a look at this now and i don't know what i was thinking. i have tested some of the submap logic and it indeed seems that i am cutting off some values. thank you for catching this, ugh. range is a bit different because it specifies the entire key, whereas with prefix we're only concerned with the first n bytes of the key. i will think on this some more. i am wondering if it's best to just wrap the entire thing in an iterator that compares the prefix on each ""next()"" call, and only returns those that meet the full prefix, much like i already have established in the rocksdbdualcfprefixiterator.",1,0.4873254597187042
296898877,5527,bellemare,2019-06-24T20:22:38Z,"okay, so i believe that i have figured out what i was doing wrong... i needed to do: `map.submap(fromkey, true, tokey, false);` and set tokey to be fromkey + 1 as a byte array. i am currently testing it and it seems to be working, but i want to test further in case i am misunderstanding the submap results.",0,0.6103206872940063
296908737,5527,vvcephei,2019-06-24T20:48:08Z,"yeah, that last thing sounds like what i had in mind. the rocksdb function i had in mind is one that basically computes `+1` for an array of bytes (i.e., iterate backwards from the end to find the first byte that isn't already `0xff` and add `1` to it).",0,0.9714710712432861
298135494,5527,bellemare,2019-06-27T11:45:43Z,:thumbs_up:,0,0.8380307555198669
298136127,5527,bellemare,2019-06-27T11:47:36Z,cleaned.,0,0.9716952443122864
298137597,5527,bellemare,2019-06-27T11:52:05Z,"done. hash included, along with link to file in github.",0,0.9878347516059875
298138716,5527,bellemare,2019-06-27T11:55:17Z,"to me it felt natural as i wanted to apply a mapping function to a value and obtain a result. semantically they feel the same though, so i don't really care one way or another. if you think it's more appropriate to go with `java.util.function.function ` i will make the change.",0,0.5081366300582886
298143733,5527,bellemare,2019-06-27T12:10:41Z,"according to their wiki ( [a link] ) it does provide a sorted iterator. the range function operates on this principle too, which confirms this to be the case in the code. we have to validate the entire prefix for each event either way, forwards or backwards. as soon as we run into an event which does not have the full prefix, we terminate and hasnext() will from then on return false. i don't think there's anything in terms of efficiency to be done here, but let me know if i misunderstood.",0,0.9739103317260742
298143789,5527,bellemare,2019-06-27T12:10:51Z,yup. thanks!,1,0.9833652377128601
298198372,5527,bellemare,2019-06-27T14:11:53Z,will be adding this in shortly.,0,0.9816992282867432
298669556,5527,bellemare,2019-06-28T16:45:02Z,i'll do my best to clarify the entire operation in the next commit.,0,0.9701001048088074
298670452,5527,bellemare,2019-06-28T16:47:50Z,"i'm fine with using the ""primary key table"" and ""foreign key table"" lingo, but given that this was stripped out of the function name somewhere previously in the review, i wasn't sure it was ""allowed"". to be frank, _i_ find it confusing to talk about this as if it's _not_ a `foreignkeyinnerjoin` and `foreignkeyleftjoin`, but instead some sort of special-case normal `join` and `leftjoin`. i'm just going to go ahead and call it what i want internally, and then we can all bicker about the bike-shed name afterwards. :)",0,0.8833407163619995
298799471,5527,bellemare,2019-06-29T13:20:55Z,"it just means the fk is the same - the hash may have changed. we need to update the hash in the subscription state store on the rhs, otherwise valid updates coming from the rhs table will join on a stale hash, and be discarded during the resolver phase (oldhash != currenthash).",0,0.9869242310523987
298799689,5527,bellemare,2019-06-29T13:30:26Z,"yep, you're correct. i believe this is an artifact left over from the initial design, when i used to send (combinedkey , v) as the event, and it was either put the fk in the key or in the value. i'll adjust the code accordingly.",0,0.9304147362709045
298801769,5527,bellemare,2019-06-29T14:52:45Z,"okay, while i took it out from over-the-wire, but we still need the serde for the `prefixscanstorebuilder`, since combinedkeys are stored to the changelog topic. the end result is that the only thing that is removed is the custom partitioner, which i like as i we no longer rely on a copied + pasted + slightly-edited partitioner.",0,0.9554091691970825
298802096,5527,bellemare,2019-06-29T15:03:53Z,"while it could go into a static method, it will always need a topic name unique between all topologies because of the weak interface definition of `serialization`. it is ambiguous as to whether topic can be null in `serialize(topic,data)`. from experience, the confluent avro serde _will_ register once with a null topic, but then will forever give already-registered exceptions for all remaining registrations. this means that we will forever need some unique dummy topic per foreignkeyjoin schema, and it will need to live in some common place. i can create a dummy topic name in the `ktableimpl.doforeignkeyjoin()` and pass in the necessary common reference to both `subscriptionresolverjoinprocessorsupplier` and `ktablerepartitionerprocessorsupplier`. this will ensure that `serialize(topic,data)` is consistent, since the topic will not rely on the topology (outside of uniqueness).",0,0.9638437628746033
298802436,5527,bellemare,2019-06-29T15:16:43Z,"changed to instructions, no longer relevant",0,0.9049115777015686
298802801,5527,bellemare,2019-06-29T15:31:05Z,"i am not sure we have to add this to all keyvaluestores. i had previously tried to limit it to the rocksdb instance only, but previously-given feedback suggested that it should support both caching and logging for performance related reasons. what we have now is due partially to a snowballing of inclusion of caching, logging and rocksdb store, and partially due to my thinking that ""if range can work in all tables, why not prefixscan since it's basically the same operation?"" the prefixscankeyvaluestore needs to support both get() (for lhs->rhs lookup) and prefixscan() (rhs->lhs lookup), and get() is tied to readonlykeyvaluestore. i also didn't want to expose prefixscan to the outside world via readonlykeyvaluestore. if you (or anyone else) feels strongly about removing it, please direct me on how you would see best to limit it to rocksdb + caching + logging. i am not confident in messing with the existing structure too much, so guidance / direction on it would be preferred than leaving it strictly up to me. :thumbs_up:",0,0.936691403388977
298803316,5527,bellemare,2019-06-29T15:49:33Z,"the key can be anything. the issue is that murmur3 cannot hash a null to a unique sentinel that wouldn't also be available by hashing another value. so any value we choose will not work. that being said, i could do something like (you mentioned using a bit in another comment): hash is null: `{1-bit nullhash = true}{remaining-serialized-data}`. hash is notnull: `{1-bit nullhash = false}{2-bytes hash}{remaining-serialized-data}`. the only thing i am rusty on is how the bit is handled in over-the-wire communication. would it not simply end up being stored as a full byte anyways? in this case, we're adding a full byte to each message just to indicate if the hash is actually null, and this is in both directions. however, for correctness sake i believe we should do this as i don't think there is any safe sentinel we can use. if we want to save space, we have two more options. 1) fold this in with the version byte, and only give version 7-bits. {1-bit-nullhash}{7-bit-version} 2) can also switch to hash64 (50% chance of collision in ~4 billion events) instead of hash128 (50% chance of collision in ~1.844674407e19). for the sake of moving this along, i will just include a single-bit of isnullhash and take it from the version byte. this should satisfy our needs.",0,0.8962978720664978
298808164,5527,bellemare,2019-06-29T18:48:06Z,"i folded all this in, the 7-bit version and the 1-bit and the 1 bit ""isnull"". i'll resolve this one now and if it's no good for whatever reason then just open another.",0,0.9772222638130188
298808919,5527,bellemare,2019-06-29T19:20:22Z,overcome by events.,0,0.8657494783401489
298809600,5527,bellemare,2019-06-29T19:50:15Z,removed in latest version.,0,0.866395890712738
298809661,5527,bellemare,2019-06-29T19:52:20Z,"all joins are being executed in the subscriptionresolverjoinprocessorsupplier. everything comes in from the subscriptionresponsewrapper topic, so there is no this/other.",0,0.9869409203529358
298809878,5527,bellemare,2019-06-29T20:03:23Z,"sorry, my comment was not very clear. currently what you described does work for a single `lefttable.joinonforeignkey(righttable, ...)`. however, i was concerned how it would work when we start chaining them together. i currently have a (somewhat complexly written) integration test (`ktablektableforeignkeyinnerjoinmultiintegrationtest`) where i do: [code block] and then: `table_1.joinonforeignkey(table_2, ... ).joinonforeignkey(table_3, ...)` the test does not pass (times-out after 60s of waiting) when `table_1_size != table_3_size` , using the co-partitioning as you suggested above. i'm not familiar enough with what's going on under the hood to explain it, nor have i spent much time digging deeper, but it seems that the partition distribution for chained `joinonforeignkey` needs some attention.",-1,0.9797705411911011
298810060,5527,bellemare,2019-06-29T20:12:27Z,it would make it inconsistent with the types in ktableimpl. i standardized them across all the code in this pr because once learned it's consistent everywhere you look. i am hesitant to change them because the next comment will be someone asking to make them consistent with ktableimpl...,-1,0.5779728889465332
298864664,5527,bellemare,2019-07-01T02:18:54Z,"i will remove this. i am not sure how to go about asking the processor to not send no-ops, but unless it's built in i'd like to limit the scope. this pr is big enough that i don't want to add more than necessary.",0,0.8853590488433838
298865371,5527,bellemare,2019-07-01T02:26:44Z,"i will add more comments to make it clearer. the coupling is indeed tight because it's based strictly on the byte ordering of the key. i couldn't think of a better way, so if you think this is a deal-breaker please let me know and we'll throw it back on the mailing list.",0,0.8993262648582458
298866241,5527,bellemare,2019-07-01T02:35:21Z,"corrected the comments - this is probably also related to your question about where should the prefixscan even go. the only real requirements are rocksdb, logging and caching stores. since they're so intertwined, it's hard for me to give you a good answer on if this should be here or not. if we have to ask, probably not, but tbh i'm really looking for guidance on this since i'm a bit over my head on where it should go. i have asked for feedback on this previously, but so far you're the only one to take not.",0,0.6907160878181458
299600884,5527,bellemare,2019-07-02T17:34:00Z,"can't handle multiple input partition counts if we chain foreignkeyjoins together. i did a few hours of investigation into this and it appears it's related to a combination of: a) multiple topicgroups ( [a link] ) b) creating sinks (for both the subscription and subscriptionresponse topics) c) how sinks are handled with copartitioning and a per-topic-group way: => the result is that sink topics are assigned the maximum number of partitions in the topicgroup (as all sink topics are treated - [a link] ""if this topic is one of the sink topics of this topology, use the maximum of all its source topic partitions as the number of partitions"" the result is that we end up with the wrong (ie: a maximum) number of partitions for some but not all of the internal repartition topics. for instance, if i have the following: `left.joinonforeignkey(rightonetable, named.as(""join1""), ...).joinonforeignkey(righttwotable, named.as(""join2""), ...)` [code block] i would expect to have the following topics with partitions: [code block] instead, due to the aforementioned dynamics, i get: [code block] as a result, i will not be supporting variable partition counts in this pr, but will put it off until after this one is comitted and roll it in its own pr. the scope on this pr is large enough.",0,0.9620112180709839
299612961,5527,bellemare,2019-07-02T18:01:42Z,"true - the unfortunate part is that wiring it in and getting it via `processorcontextimpl.getstatestore(..)` ( [a link] ) is that it does not match any of the store types, and so cannot be accessed that way. i can modify that further, but this is all due to the same original question - where in the interface definitions should `prefixscankeyvaluestore.prefixscan()` live?",-1,0.9490238428115845
307344539,5527,vvcephei,2019-07-25T15:01:25Z,"hey , i think your feeling is reasonable, but to me it actually supports using a function more than using a valuemapper. what i mean is, you just want to run a _function_ on the value and obtain a result. the valuemapper implies you're mapping the value to a new value to produce a new ktable with the result value. in other words, it only makes sense in a `mapvalues()` operation. the valuemapper interface was introduced for the `mapvalues()` operator, and we abused (along with others of our functional interfaces) by using it other places where we just want a unary function (because java had no stdlib functions at that point). now that java has function, we can clean this mess up. right now, though, i'm just proposing not to create more mess that we have to clean up later. if people disagree with using function (for some reason), then we should make a new semantically correct interface instead of using valuemapper.",0,0.9092820882797241
307349571,5527,vvcephei,2019-07-25T15:10:40Z,"ok, just for the record, i think we have to fix this before merging... i'll see if i can figure it out.",0,0.9519596099853516
307394163,5527,bellemare,2019-07-25T16:39:15Z,i had researched it more extensively a few weeks ago but just realized now i forgot to post the findings. they were pending publishing in my own review...,0,0.7341098189353943
307394639,5527,bellemare,2019-07-25T16:40:15Z,i've just posted the findings. i am concerned about scope creep if we tinker with the copartitioner. as it stands right now i think the size of this pr is intimidating enough.,-1,0.8985550403594971
307397528,5527,bellemare,2019-07-25T16:47:19Z,function it is. your perspective on the misuse of valuemapper makes sense.,0,0.9523300528526306
311715968,5527,abbccdda,2019-08-07T19:05:58Z,nit: newline,0,0.9799820184707642
318776174,5527,cpettitt-confluent,2019-08-28T20:26:53Z,"it might be better to throw if there is overflow. otherwise the return prefixed key does not follow the protocol in combinedkeyschema. i don't think it would happen in practice, but if we're going to address it one way or the other i would probably lean toward explicitly failing on overflow. otherwise we should at least doc that this widens the array of bytes in the case of overflow.",0,0.9834557175636292
318778418,5527,cpettitt-confluent,2019-08-28T20:32:27Z,"as this is public documentation, it would be nice to explain what named is used for.",0,0.9707342982292175
318778654,5527,cpettitt-confluent,2019-08-28T20:33:05Z,as this is public documentation it would be nice to have documentation on it. it looks like it would be the same as the previous sans named.,0,0.7736588716506958
318778736,5527,cpettitt-confluent,2019-08-28T20:33:18Z,same comment as above.,0,0.9851358532905579
318802475,5527,cpettitt-confluent,2019-08-28T21:32:47Z,do we need to be careful here about getting dos'd by an extreme length either due to malice or accident? do we have a key limit anywhere else that we could use to assert that `foreignkeylength` is within acceptable limit?,0,0.9248940944671631
318803831,5527,cpettitt-confluent,2019-08-28T21:36:44Z,"it seems given this that we can at least assert that foreignkeylength is less than or equal to 2147483643 bytes. though a better bound, if there is one, would be nice.",0,0.7619805335998535
318813557,5527,cpettitt-confluent,2019-08-28T22:07:33Z,should this be sent only when the old and new key do not match?,0,0.9775640368461609
318814883,5527,cpettitt-confluent,2019-08-28T22:12:16Z,looks like dead code that can be removed?,0,0.9646313786506653
318816694,5527,cpettitt-confluent,2019-08-28T22:19:04Z,`value.getforeignvalue() == null && (!leftjoin || currentvaluewithtimestamp == null)` ?,0,0.9841358661651611
318817354,5527,cpettitt-confluent,2019-08-28T22:21:28Z,minor: order of visibility keywords in field declarations are reversed here vs. other places in the code.,0,0.9852380156517029
318819397,5527,cpettitt-confluent,2019-08-28T22:30:04Z,"maybe worth an assert here that version fits in 7-bits? not that we're going to hit it any time soon, but if we set the 8th bit then given the semantics below we are considered to have a null hash.",0,0.984802782535553
318820465,5527,cpettitt-confluent,2019-08-28T22:34:09Z,same comment re. version as above.,0,0.9873425960540771
318821811,5527,cpettitt-confluent,2019-08-28T22:39:37Z,`cache.isempty()` seems sufficient? curious why you needed to change this.,0,0.9848820567131042
318822498,5527,cpettitt-confluent,2019-08-28T22:42:21Z,curious: is there any functional change by moving this code?,0,0.9645414352416992
318822822,5527,cpettitt-confluent,2019-08-28T22:43:38Z,i think we can revert this for cleanliness.,0,0.9715941548347473
318822997,5527,cpettitt-confluent,2019-08-28T22:44:19Z,"given the size of this commit, it seems worth reverting non functional changes like this.",0,0.9694696068763733
318823102,5527,cpettitt-confluent,2019-08-28T22:44:43Z,same as last few comments :),1,0.9429103136062622
318823246,5527,cpettitt-confluent,2019-08-28T22:45:17Z,same as above.,0,0.9746477603912354
318824005,5527,cpettitt-confluent,2019-08-28T22:48:25Z,minor: you could get away with keeping this mutable if you initialize it here and do `addall` with `topicstocopartitiongroup.get` below. just check `copartitiongroup.isempty` to determine if you can break.,0,0.9861191511154175
318824758,5527,cpettitt-confluent,2019-08-28T22:51:26Z,is it? :d,1,0.9745290875434875
319131058,5527,bellemare,2019-08-29T15:23:00Z,"my understanding is that if the foreign key is too large it couldn't have been written as a message to kafka (exceeds maximum batch/message size). accordingly, the maximum size of the foreignkey is limited to the maximum allowable batch/message size. is this incorrect?",0,0.9677779078483582
319136512,5527,bellemare,2019-08-29T15:33:33Z,"i believe we chose this because with a regular join we propagate the same output value for each event sent in. if there are n events with the same old and new state, we output n joined events, even if they are the same. if we do not send when oldkey == newkey, then we swallow + hide the event.",0,0.975406289100647
319136649,5527,bellemare,2019-08-29T15:33:50Z,yep. i'll go through and try to clean it up. lots of stuff changed and got reverted unsuccessfully.,0,0.9331761598587036
319137563,5527,bellemare,2019-08-29T15:35:36Z,"haha, good eye. i didn't notice the repeated logic at the end... sigh... thanks.",1,0.9861051440238953
319138304,5527,bellemare,2019-08-29T15:37:01Z,:thumbs_up:,0,0.8380307555198669
319139534,5527,bellemare,2019-08-29T15:39:27Z,i can put some validation in the serializer since it's the one that's forcing a byte into 7-bits.,0,0.9885618686676025
319142830,5527,bellemare,2019-08-29T15:45:25Z,same solution - will validate in serialization since it's the serializer that is limiting it to 7 bits.,0,0.9871269464492798
319144549,5527,bellemare,2019-08-29T15:48:52Z,"this is an artifact of a broken trunk that i needed to fix to get this to compile a few weeks back. currently in trunk it seems to be fixed ( [a link] ) , so i'll resolve this when i make a new pr rebasing this off of the murmur3hash pr that needs to be resolved prior....",0,0.8741732239723206
319150616,5527,cpettitt-confluent,2019-08-29T16:02:01Z,"my bad! i thought this was coming from a topic, but this is just for the prefix matching in the store. this can be closed out.",-1,0.9909851551055908
319153538,5527,cpettitt-confluent,2019-08-29T16:08:32Z,":thumbs_up:makes sense. my understanding is that sending an output even for each input is best effort, e.g. the output event is not emitted if the hash changes more quickly than the updates get through the rhs.",0,0.8927269577980042
319153674,5527,cpettitt-confluent,2019-08-29T16:08:49Z,:thumbs_up:,0,0.8380307555198669
319172463,5527,bellemare,2019-08-29T16:53:53Z,"there was at one point - i believe i was using the storebuilder to build the store, then i had to connect it afterwards. it would throw an exception if i tried to connect a store that was not built yet. the work that john r did to fix up the topology seems to have remedied it, so i'll revert the order back to the original order.",0,0.9685336947441101
319174179,5527,bellemare,2019-08-29T16:58:03Z,"yes, i will do so. this was an artifact of my ide organizing the imports i believe.",0,0.9723768830299377
319195586,5527,bellemare,2019-08-29T17:50:08Z,deftly overcome by events! will remove the whole thing.,0,0.5561472177505493
319198127,5527,bellemare,2019-08-29T17:56:13Z,"i'll leave that up to to comment on, as he is the one who made these changes... . actually, now i'm not sure why this change is in here, i think this was supposed to be in its own pr? john?",0,0.7964277863502502
319261222,5527,bellemare,2019-08-29T20:38:03Z,"i see what you're saying, but i am not sure it's proper to put the exception in the bytes.increment as it's doing what it says it should do (ie: increment the byte array by 1). john and i noticed this before, but since combinedkeyschema always starts with a positive integer, wrap-around won't affect us in either case. as john noticed 22 days ago: [code block] we're implicitly protected as long as the maximum of positive integers are always 0x7fff ffff.",0,0.9787792563438416
319263781,5527,bellemare,2019-08-29T20:45:03Z,:thumbs_up:,0,0.8380307555198669
319275297,5527,cpettitt-confluent,2019-08-29T21:16:08Z,good point. that seems to support an assertion / exception vs. adding behavior we don't expect to run though? if we overflow clearly there is a logic error somewhere in the callee and it would be better to find out directly vs. as a side effect of behavior we don't expect to exercise?,1,0.7378589510917664
320388724,5527,bellemare,2019-09-03T17:24:51Z,"yep, fair enough. i'll make it such that it'll throw an error if it would result in a wrap around. the caller will have to allocate additional room if they want it to roll over.",0,0.9788342714309692
320395570,5527,bellemare,2019-09-03T17:40:50Z,indexarrayoutofbounds? or do you have something else in mind? i can't seem to find a reasonable choice from the list...,0,0.7848135232925415
320401139,5527,cpettitt-confluent,2019-09-03T17:53:34Z,"i don't have a strong opinion. i suppose `illegalargumentexception(""overflow"")` would be fine. that seems most appropriate, especially if we document that increment only works for inputs up to max int - 1.",0,0.6943060755729675
320401556,5527,cpettitt-confluent,2019-09-03T17:54:35Z,"btw, this is not a blocker to me. i think if we get the one change we discussed above (exception on overflow) that things are looking pretty good from my perspective. i'll do a pass on the tests too.",0,0.8123127222061157
321287361,5527,bbejeck,2019-09-05T14:09:51Z,nit: `prefix_scan_processor` and `join_on_foreign_key_name` names are unused.,0,0.9883220791816711
321398773,5527,vvcephei,2019-09-05T17:49:17Z,"thanks, -confluent . i think we're better off favoring immutability unless there's a significant readability or performance advantage to mutable state.",1,0.8704115748405457
321400745,5527,vvcephei,2019-09-05T17:53:29Z,"using `size()` was actually identified as a performance regression. trunk is now using `isempty()`: [a link] regardless, this line should not appear in your diff at all. i'd just smash it with whatever is in trunk.",0,0.9873007535934448
322342024,5527,bbejeck,2019-09-09T16:40:07Z,"although this class is in an `internals` package, some brief javadoc would be helpful. the overall flow is complex, and a short description will help grok the functionality and where the class fits in the flow of things. same thing for all other classes in `internals.foreignkeyjoin` so i won't repeat the comment.",0,0.9849194288253784
322368963,5527,bbejeck,2019-09-09T17:42:07Z,this is unrelated to this pr but i'm wondering the `processorgraphnode` _always_ used as the node name we could simplify this class. but let's just leave it as is for now.,0,0.980542778968811
322376681,5527,bbejeck,2019-09-09T17:59:31Z,"nit: the test doesn't cover `prefixbytes` method. i'm not a proponent of 100% test coverage always, but imho that method is a main factor in the ""other->this"" join so it should have coverage in this case.",0,0.977331817150116
322855625,5527,bellemare,2019-09-10T16:55:24Z,"according to the commits i made, this should be removed by now... not sure why it's still showing up in the review...",-1,0.9329252243041992
322918610,5527,bbejeck,2019-09-10T19:20:26Z,"i think it _may_ be possible to implement the integration tests using the `topologytestdriver`, the benefit of which would be that we could get coverage reports and the tests run faster without the embedded broker. the test cases look complete to me, but without coverage reports, we could be missing something.",0,0.9805397987365723
322919371,5527,bbejeck,2019-09-10T19:22:00Z,leftover debugging?,0,0.981268584728241
323413934,5527,bellemare,2019-09-11T19:15:44Z,"i'm not familiar enough with this myself. if it's problematic i would be willing to address it in another pr, as i'm experiencing some fatigue on this one.",-1,0.9486873149871826
323413988,5527,bellemare,2019-09-11T19:15:53Z,very much so. thanks!,1,0.9763228893280029
323985652,5527,mjsax,2019-09-12T23:12:49Z,"seems we need to update `streamsresetter` to delete those topics, too?",0,0.9879597425460815
323985742,5527,mjsax,2019-09-12T23:13:15Z,as above.,0,0.978552520275116
325438742,5527,vvcephei,2019-09-18T00:27:57Z,"yes, we do. good catch!",1,0.9909937977790833
326269999,5527,bbejeck,2019-09-19T16:30:05Z,"nit: enabling optimizations is a two-step process. in addition to setting the `optimize` flag in the configs, we also need pass in the configs to the overloaded `streambuilder#build(properties)` method here.",0,0.987686812877655
326272813,5527,bellemare,2019-09-19T16:36:36Z,"whoops! that's not a nit, that's just a miss on my part. thanks!",1,0.9412404894828796
426783396,8680,abbccdda,2020-05-18T17:25:17Z,nit: we could use { versionrangetype} to reference to the classes.,0,0.988835871219635
426783652,8680,abbccdda,2020-05-18T17:25:44Z,could be simplified as new features<>,0,0.9855855107307434
426783720,8680,abbccdda,2020-05-18T17:25:51Z,same here,0,0.982987642288208
426805425,8680,abbccdda,2020-05-18T18:06:33Z,nit: extra line,0,0.970479428768158
426806321,8680,abbccdda,2020-05-18T18:08:17Z,is this function only used in unit test?,0,0.9849122762680054
426806671,8680,abbccdda,2020-05-18T18:09:02Z,we should ensure `features` is not null,0,0.9866983890533447
426807646,8680,abbccdda,2020-05-18T18:10:58Z,"nit: just a personal preference, but getting one less internal reference to a public function `all` makes the code usage check easier, like `features.get(feature)`.",0,0.9848034381866455
426808456,8680,abbccdda,2020-05-18T18:12:36Z,"also if we could potentially have a not-found feature, we should either fail with illegal state, or make the return type `optional `",0,0.9825947880744934
426808879,8680,abbccdda,2020-05-18T18:13:21Z,maybe rephrase as `a map with the underlying features serialized`,0,0.9872774481773376
426809504,8680,abbccdda,2020-05-18T18:14:35Z,s/deserializes/deserialize,0,0.986003041267395
426810909,8680,abbccdda,2020-05-18T18:17:09Z,we should check `null` for other.,0,0.9842405319213867
426829453,8680,abbccdda,2020-05-18T18:53:37Z,nit: might make sense to build meta comment for parameters: [code block],0,0.9866160154342651
426836963,8680,abbccdda,2020-05-18T19:07:57Z,s/ !featuresandepoch.isempty / featuresandepoch.isdefined,0,0.9840195178985596
426838064,8680,abbccdda,2020-05-18T19:10:06Z,this is because the write path has not been implemented?,0,0.971737802028656
426865773,8680,abbccdda,2020-05-18T20:07:15Z,nit: add a line,0,0.9863990545272827
426873359,8680,abbccdda,2020-05-18T20:23:39Z,i think we need to bump the schema version to 4? same with `apiversionsrequest.json`,0,0.988218367099762
426875434,8680,abbccdda,2020-05-18T20:28:01Z,"looks like we have some gaps for unit testing `apiversionsresponse`. could we add unit tests for this class, since the logic `createapiversionsresponse` becomes non-trivial now?",0,0.9864240288734436
426875879,8680,abbccdda,2020-05-18T20:28:59Z,s/allapi/getallfeatures,0,0.98770672082901
426876134,8680,abbccdda,2020-05-18T20:29:35Z,we need the apache license title,0,0.9857630729675293
426876793,8680,abbccdda,2020-05-18T20:30:54Z,we could use `org.apache.kafka.common.utils.utils#mkmap` here,0,0.9846580028533936
426876852,8680,abbccdda,2020-05-18T20:31:01Z,same here,0,0.982987642288208
426877891,8680,abbccdda,2020-05-18T20:33:12Z,nit: new line,0,0.96523118019104
426884892,8680,abbccdda,2020-05-18T20:47:45Z,"in terms of naming, do you think `finalizedversionrange` is more explicit? also when i look closer at the class hierarchy, i feel the sharing point between finalized version range and supported version range should be extracted to avoid weird inheritance. what i'm proposing is to have `versionrange` as a super class with two subclasses: `supportedversionrange` and `finalizedversionrange`, and make `minkeylabel` and `maxkeylabel` abstract functions, wdyt?",0,0.9622623920440674
426890390,8680,abbccdda,2020-05-18T21:00:09Z,"note this function is public, which suggests there could be external dependency that we need to take care of. the safer approach is to keep this static function and create a separate one with augmented parameters. cc for validation.",0,0.9857600331306458
426931875,8680,abbccdda,2020-05-18T22:44:55Z,i think we could delay the addition for these helpers until we actually need them.,0,0.9821412563323975
426933479,8680,abbccdda,2020-05-18T22:49:35Z,"i gave it more thought, and wonder whether we could just call this function `features` to be more consistent with our convention for getters.",0,0.6980010271072388
426933776,8680,abbccdda,2020-05-18T22:50:20Z,need to check null,0,0.9680777788162231
426934551,8680,abbccdda,2020-05-18T22:52:20Z,is there a difference between `objects.equals` and `this.minkeylabel.equals(that.minkeylabel)`?,0,0.9870170950889587
426935082,8680,abbccdda,2020-05-18T22:53:54Z,"nit: testminmax, and we could reuse the same `new versionrange(1, 2)` by only creating it once.",0,0.9886093139648438
426936469,8680,abbccdda,2020-05-18T22:57:45Z,does l17-23 really necessary for testing?,0,0.9843263030052185
426936751,8680,abbccdda,2020-05-18T22:58:34Z,could we add a reference to the class?,0,0.9883211255073547
426937532,8680,abbccdda,2020-05-18T23:00:50Z,it seems that we don't have the handling logic for this featurecacheupdateexception. do we think this is fatal?,-1,0.5800349116325378
426937944,8680,abbccdda,2020-05-18T23:02:01Z,is this function being used?,0,0.9863311052322388
426940597,8680,abbccdda,2020-05-18T23:10:12Z,do you expect these helper functions actually to be used in production logic with subsequent prs?,0,0.9876170754432678
426940830,8680,abbccdda,2020-05-18T23:10:56Z,i don't think we need a nested if-else: [code block],0,0.9789549112319946
426942377,8680,abbccdda,2020-05-18T23:16:03Z,could we make feature extraction as a helper function?,0,0.988621175289154
426942842,8680,abbccdda,2020-05-18T23:17:26Z,could we make this parameter configurable?,0,0.9883058071136475
426976264,8680,abbccdda,2020-05-19T01:19:38Z,what would happen if we are dealing with a v4 json map containing features?,0,0.9765926003456116
426976396,8680,abbccdda,2020-05-19T01:20:02Z,nit: this test could move closer to testfromjsonv4withnorack,0,0.9831424355506897
426976932,8680,abbccdda,2020-05-19T01:22:05Z,should we test `isdefined` before calling `get`?,0,0.988108217716217
426977978,8680,abbccdda,2020-05-19T01:26:17Z,s/existingstr/oldfeatureandepoch,0,0.9861438274383545
426978090,8680,abbccdda,2020-05-19T01:26:43Z,this val seems redundant.,0,0.8054039478302002
426978267,8680,abbccdda,2020-05-19T01:27:25Z,nit: this errormsg val seems redundant.,0,0.8692284226417542
426979984,8680,abbccdda,2020-05-19T01:34:31Z,"this is only used on l53, maybe we could just use supportedfeatures instead",0,0.9874014258384705
426980855,8680,abbccdda,2020-05-19T01:37:40Z,"this comment is a bit vague to me, what are you referring by `incompatibilities`?",-1,0.7018138766288757
426990007,8680,abbccdda,2020-05-19T02:12:55Z,nit: maybe rename to `incompatiblewith` and flip the boolean,0,0.9869375824928284
426990716,8680,abbccdda,2020-05-19T02:15:41Z,"might worth getting a ticket to define the handling strategy for such exception, and in general how `updateorthrow` will be used.",0,0.9820941090583801
426997108,8680,abbccdda,2020-05-19T02:39:40Z,does this event actually happen? will we hit illegal state exception in `updatelatestorthrow`?,0,0.9777762293815613
427022316,8680,kowshik,2020-05-19T04:25:04Z,done.,0,0.9759407639503479
427023280,8680,kowshik,2020-05-19T04:29:23Z,"do you feel strongly about this? the reasons why i ask the question is: 1. caller is unlikely to pass `null`. 2. i looked over a number of other existing classes in kafka, and there aren't any null checks for most constructor parameters. it will help me if you could share couple examples from existing code where the `null` check convention is followed in kafka.",0,0.8112897872924805
427023377,8680,kowshik,2020-05-19T04:29:55Z,done. good point!,1,0.9843669533729553
427023394,8680,kowshik,2020-05-19T04:30:00Z,done.,0,0.9759407639503479
427023705,8680,kowshik,2020-05-19T04:31:11Z,"done. yes, i've changed it to default visibility now.",0,0.9777632355690002
427023770,8680,kowshik,2020-05-19T04:31:31Z,done. removed it.,0,0.982100784778595
427024341,8680,kowshik,2020-05-19T04:34:02Z,done. good point!,1,0.9843669533729553
427024379,8680,kowshik,2020-05-19T04:34:12Z,done. good point!,1,0.9843669533729553
427025378,8680,kowshik,2020-05-19T04:38:08Z,"the underlying data structure is a `map`. it would be simpler if this method just returns `null` if the feature doesn't exist. for example, that is how java's `map.get` works, here is the javadoc: [a link] also, i've documented this method now (doc was previously absent).",0,0.9873586297035217
427025539,8680,kowshik,2020-05-19T04:38:51Z,done.,0,0.9759407639503479
427025597,8680,kowshik,2020-05-19T04:39:05Z,done.,0,0.9759407639503479
427025866,8680,kowshik,2020-05-19T04:40:04Z,done. good point! added test as well.,1,0.9817201495170593
427027670,8680,kowshik,2020-05-19T04:47:29Z,it provides slightly better convenience: `object.equals` will also take care of the `null` checks for you. also it turned out it was overkill to use `objects.equals` for primitive type checks for `minvalue` and `maxvalue`. so i've simplified the code to use `==` those attributes. good point!,1,0.9806455969810486
427027909,8680,kowshik,2020-05-19T04:48:28Z,done.,0,0.9759407639503479
427033616,8680,kowshik,2020-05-19T05:10:37Z,done. also added a test. good catch!,1,0.9916063547134399
427034499,8680,kowshik,2020-05-19T05:13:51Z,done. good point!,1,0.9843669533729553
427034758,8680,kowshik,2020-05-19T05:14:57Z,"are you sure? all newly added fields are tagged (i.e. optional). going by [a link] in kip-482, it is not required to change the schema version whenever tagged fields are introduced.",0,0.9889671206474304
427035290,8680,kowshik,2020-05-19T05:16:58Z,done.,0,0.9759407639503479
427035380,8680,kowshik,2020-05-19T05:17:19Z,done.,0,0.9759407639503479
427042310,8680,kowshik,2020-05-19T05:42:26Z,done.,0,0.9759407639503479
427042434,8680,kowshik,2020-05-19T05:42:49Z,done.,0,0.9759407639503479
427043245,8680,kowshik,2020-05-19T05:45:33Z,"done. some of it is not required. good point, i have removed the unnecessary testing now. we still need to check if exception is thrown in these 4 basic tests: min < 1, max < 1, min & max < 1 and max > min.",0,0.7906752824783325
427043710,8680,kowshik,2020-05-19T05:47:05Z,done.,0,0.9759407639503479
427044348,8680,kowshik,2020-05-19T05:49:07Z,"no, this constructor overload was simply created to avoid a churn of test code at number of places adding the additional `supportedfeatures` parameter. how do you feel about keeping it?",0,0.969786524772644
427045136,8680,kowshik,2020-05-19T05:51:37Z,done. good point!,1,0.9843669533729553
427045338,8680,kowshik,2020-05-19T05:52:15Z,done. it was unused and i have eliminated it now.,0,0.9801806807518005
427045754,8680,kowshik,2020-05-19T05:53:30Z,done.,0,0.9759407639503479
427045906,8680,kowshik,2020-05-19T05:54:00Z,done.,0,0.9759407639503479
427046004,8680,kowshik,2020-05-19T05:54:19Z,done.,0,0.9759407639503479
427046331,8680,kowshik,2020-05-19T05:55:17Z,it is used intentionally to split the log message into 2 lines (for ~100-char readability limit per line). otherwise the string will be huge and all in the same line.,0,0.9824147820472717
427046353,8680,kowshik,2020-05-19T05:55:21Z,it is used intentionally to split the log message into 2 lines (for ~100-char readability limit per line). otherwise the string will be huge and all in the same line.,0,0.9824147820472717
427047251,8680,kowshik,2020-05-19T05:58:04Z,"i have added comments now to the code. the idea i had was that this event may happen, rarely (ex: operational error). in such a case, we do not want to kill the brokers, so we just log a warning and treat the case as if the node is absent, and populate the cache with empty features. so, this case is actually handled inside `featurecacheupdater.updatelatestorthrow()`. the call to read zk node will return `zkversion.unknownversion` whenever the node does not exist in zk, and i've explicitly handled this returned version.",0,0.9769968390464783
427047400,8680,kowshik,2020-05-19T05:58:32Z,done.,0,0.9759407639503479
427048695,8680,kowshik,2020-05-19T06:02:19Z,good point. i have improved the doc now. let me know how you feel about it.,1,0.9663602709770203
427049093,8680,kowshik,2020-05-19T06:03:24Z,done.,0,0.9759407639503479
427049831,8680,kowshik,2020-05-19T06:05:39Z,done.,0,0.9759407639503479
427050030,8680,kowshik,2020-05-19T06:06:13Z,"yes, this will get used in the future. for example the write path will use it.",0,0.9888836741447449
427050597,8680,kowshik,2020-05-19T06:07:55Z,done. good point!,1,0.9843669533729553
427057916,8680,kowshik,2020-05-19T06:27:29Z,done.,0,0.9759407639503479
427060765,8680,kowshik,2020-05-19T06:34:31Z,"the tests have been already added. pls check out the tests added in `apiversionsresponsetest.java`, particularly: `shouldreturnfeaturekeyswhenmagiciscurrentvalueandthrottlemsisdefaultthrottle`. let me know if this test does not look sufficient.",0,0.9879684448242188
427063053,8680,kowshik,2020-05-19T06:39:32Z,done.,0,0.9759407639503479
427063724,8680,kowshik,2020-05-19T06:40:58Z,done.,0,0.9759407639503479
427064271,8680,kowshik,2020-05-19T06:42:10Z,"in my understanding, this is an impossible case. because, we always write features into the json only in v5 or above. that is why, there is no test for it. let me know how you feel about it.",0,0.8752339482307434
427064923,8680,kowshik,2020-05-19T06:43:33Z,done.,0,0.9759407639503479
427827018,8680,kowshik,2020-05-20T08:21:37Z,"as we discussed offline today, this exception is already handled in `changenotificationprocessorthread.dowork()` method defined in `finalizedfeaturechangelistener.scala`. basically, the zk change notification processor thread exits the broker with a fatal error (non-zero exit code) when this exception (or any exception) is caught while trying to update `finalizedfeaturecache`.",0,0.9878163933753967
427884165,8680,kowshik,2020-05-20T09:51:49Z,done.,0,0.9759407639503479
427885025,8680,kowshik,2020-05-20T09:53:14Z,"done. good point! - i have now created 3 classes as you proposed. `baseversionrange` is the base class, and, `supportedversionrange` & `finalizedversionrange` are it's child classes. - the key labels couldn't be made into abstract functions since these constants are needed within `deserialize()` which is a static method defined in the child classes.",1,0.9829463958740234
428080079,8680,abbccdda,2020-05-20T14:55:57Z,"yea, the reasoning is that we have `get` call blindly look up inside `features` which in this case null is not valid. and i don't feel passing `null` makes sense for the caller, correct?",0,0.8842677474021912
428367400,8680,abbccdda,2020-05-20T23:39:32Z,`deserialize()`? i think the second sentence is redundant.,0,0.9623371362686157
428370254,8680,abbccdda,2020-05-20T23:48:46Z,do we want to get a unit test class for `baseversionrange`?,0,0.9882964491844177
428370905,8680,abbccdda,2020-05-20T23:51:04Z,should be `supportedversionrange`,0,0.9870896935462952
428371260,8680,abbccdda,2020-05-20T23:52:20Z,"just for the sake of argument, i feel we could remove this method and just test: [code block] for incompatibility.",0,0.9685783386230469
428392754,8680,abbccdda,2020-05-21T01:13:18Z,nit: supportedversionrange,0,0.9889355301856995
428392936,8680,abbccdda,2020-05-21T01:14:10Z,why this is a `note`? could we just comment like: [code block],0,0.9831435084342957
428402864,8680,abbccdda,2020-05-21T01:54:32Z,"maybe i'm a bit too obsessive about code duplication, but after i made an attempt i thought we could actually have the internal deserialization logic shared between `deserializefinalizedfeatures` and `deserializesupportedfeatures` by making a template [code block]",-1,0.792543888092041
428403904,8680,abbccdda,2020-05-21T01:58:35Z,missing header,0,0.8798423409461975
428404068,8680,abbccdda,2020-05-21T01:59:14Z,seems we didn't trigger style check on this new class.,0,0.8678827285766602
428404491,8680,abbccdda,2020-05-21T02:00:52Z,what's the difference between this test class and its super class test case? same question for `supportedversionrangetest`,0,0.9874234795570374
428418517,8680,abbccdda,2020-05-21T02:58:16Z,could we move this logic as part of inner else? like: [code block] it makes the if-else logic more tight.,0,0.9458858966827393
428419538,8680,abbccdda,2020-05-21T03:02:18Z,"i think we don't need to talk about future work inside the comment, just making it clear that the read path for serving apiversionsrequest is the only reader as of now.",0,0.982455849647522
428420141,8680,abbccdda,2020-05-21T03:04:59Z,nit: provide,0,0.9842872619628906
428421713,8680,abbccdda,2020-05-21T03:11:58Z,do we need the comment to be on info level?,0,0.9864034652709961
428422280,8680,abbccdda,2020-05-21T03:14:25Z,nit: don't feel strong about having this parameter,-1,0.9635251760482788
428422483,8680,abbccdda,2020-05-21T03:15:18Z,feel neutral about this helper function,-1,0.6083081364631653
428422966,8680,abbccdda,2020-05-21T03:17:24Z,"i don't think this is scala accepted comment style to add `-`, do you see a warning?",0,0.9566881656646729
428424395,8680,abbccdda,2020-05-21T03:23:53Z,`feature cache update gets interrupted`,0,0.9778327345848083
428426189,8680,abbccdda,2020-05-21T03:31:57Z,"does the version field existence guarantee there is a valid feature data node or not? in fact, `getdataandversion` returns an optional data. i checked the getdataandversion caller `produceridmanager`, there is a handling for empty data which i feel we should have as well. additionally, i think since we haven't implemented the write path yet, could we get a ticket to write down a short description on how the write path shall look like, by defining the different cases like: [code block] if that makes sense, so that we could keep track of the design decisions we made in the read path pr when implementing the write path.",0,0.957322895526886
428426448,8680,abbccdda,2020-05-21T03:33:03Z,"could we summary the possible thrown error code in the comment as well? for example, does a json deserialization error should be treated as fatal?",0,0.984560489654541
428429013,8680,abbccdda,2020-05-21T03:44:51Z,"is it possible to have no enqueued updater, and cause this function block the thread indefinitely?",0,0.9804213643074036
428429615,8680,abbccdda,2020-05-21T03:47:38Z,"for an educational question, does the zkclient have a separate thread to do the node change monitoring?",0,0.9874395728111267
428430093,8680,abbccdda,2020-05-21T03:49:45Z,does the order matter here? i was wondering if there is any concurrent issue if we unregister before the queue and thread get cleaned up.,0,0.9787017107009888
428430356,8680,abbccdda,2020-05-21T03:50:57Z,we could just comment `for testing only`,0,0.9885317087173462
428430553,8680,abbccdda,2020-05-21T03:51:55Z,`wait time for the first feature cache update upon initialization`,0,0.9851399064064026
428430779,8680,abbccdda,2020-05-21T03:52:57Z,"i think the comment is not necessary, since we have already commented on `kafka_2_6_iv1`",0,0.9845949411392212
428431584,8680,abbccdda,2020-05-21T03:56:16Z,nit: returns a reference to the latest features supported by the broker.,0,0.98811274766922
428432424,8680,abbccdda,2020-05-21T04:00:05Z,this logging is duplicate,0,0.9853870868682861
428432727,8680,abbccdda,2020-05-21T04:01:36Z,"i'm slightly inclined to return a set of features instead of just strings, and make the string conversion as a helper. but i leave this up to you to decide, and we could always adapt the function to make it more useful in other scenarios as needed.",0,0.9327775239944458
428432904,8680,abbccdda,2020-05-21T04:02:25Z,"if that's the case, i feel we could remove the testing only comment.",0,0.984635591506958
428433279,8680,abbccdda,2020-05-21T04:04:10Z,"aha, the order is wrong for `kafka_0_10_0_iv1` and `kafka_2_6_iv1`",0,0.790238618850708
428433517,8680,abbccdda,2020-05-21T04:05:31Z,"i think even if this is an operational error, the cluster is at risk of violating the feature semantics previously enabled, which is different from an unknown feature version from the beginning. i feel we should just exit in fatal error for this case, but would open for discussion.",0,0.9653056859970093
428434151,8680,abbccdda,2020-05-21T04:08:21Z,s/asjavamap/featuresasjavamap,0,0.987453043460846
428434945,8680,abbccdda,2020-05-21T04:11:27Z,could we log statusint here as well? also i feel the exception should be thrown from `featureznodestatus.withnameopt`,0,0.9879825115203857
428435694,8680,abbccdda,2020-05-21T04:15:15Z,is there a more dedicated exception code for deserialization error? i feel the kafkaexception is a bit too general compared with illegalargument,-1,0.9257262349128723
428436046,8680,abbccdda,2020-05-21T04:16:59Z,could we name it v0 for simplicity?,0,0.9868754148483276
428436573,8680,abbccdda,2020-05-21T04:19:58Z,"i feel we might worth creating a separate thread discussing whether we could get some benefit of the automated protocol generation framework here, as i think this could be easily represented as json if we define it in the common package like other rpc data. the difficulty right now is mostly on the serialization and deserialization for feature itself, but these could have workarounds if we want to do so.",0,0.9118720293045044
428437318,8680,abbccdda,2020-05-21T04:23:22Z,"i'm a bit surprised, do we want to support feature znode deletion in long term?",-1,0.8729768991470337
428437571,8680,abbccdda,2020-05-21T04:24:39Z,could we extract some common initialization logic for the tests to reduce duplication?,0,0.9874951243400574
428437659,8680,abbccdda,2020-05-21T04:24:58Z,nit: space,0,0.9737508893013
428438063,8680,abbccdda,2020-05-21T04:27:00Z,"if we are not validating the features by extracting them, i think we do not need to pass in a non-empty feature list?",0,0.9789454340934753
428573407,8680,kowshik,2020-05-21T10:32:12Z,"it is thoroughly tested in it's child class test suite: `supportedversionrangetest`. personally i feel it is good enough this way, because, anyway to test this class we need to inherit into a sub-class (since constructor is `protected`). and by testing via `supportedversionrangetest`, we achieve exactly the same. i have now added top-level documentation in the test suite of `supportedversionrangetest`, explaining the above.",1,0.6430376172065735
428576410,8680,kowshik,2020-05-21T10:39:55Z,done. i'm raising an exception now if it is `null`. i see your point. will be good to learn what is the convention in kafka for constructor param null checks.,1,0.5709229111671448
428577156,8680,kowshik,2020-05-21T10:41:42Z,done.,0,0.9759407639503479
428578424,8680,kowshik,2020-05-21T10:44:59Z,done.,0,0.9759407639503479
428578472,8680,kowshik,2020-05-21T10:45:04Z,done. good point!,1,0.9843669533729553
428578829,8680,kowshik,2020-05-21T10:45:53Z,done.,0,0.9759407639503479
428579070,8680,kowshik,2020-05-21T10:46:29Z,done. good point!,1,0.9843669533729553
428579884,8680,kowshik,2020-05-21T10:48:19Z,done.,0,0.9759407639503479
428580337,8680,kowshik,2020-05-21T10:49:28Z,done.,0,0.9759407639503479
428581013,8680,kowshik,2020-05-21T10:51:04Z,done. good point!,1,0.9843669533729553
428581253,8680,kowshik,2020-05-21T10:51:45Z,done.,0,0.9759407639503479
429069672,8680,kowshik,2020-05-22T06:41:44Z,done.,0,0.9759407639503479
429071500,8680,kowshik,2020-05-22T06:47:02Z,"done. i have simplified this test suite eliminating the redundant tests, and only keeping the ones specific to `finalizedversionrange`. also i have added documentation to both test suites explaining their purpose.",0,0.9714770317077637
429074215,8680,kowshik,2020-05-22T06:55:11Z,done. changed to `illegalargumentexception`. good point!,1,0.9752022624015808
429076303,8680,kowshik,2020-05-22T07:01:08Z,"done. for the other point, i don't feel strongly for it. i feel it is ok to have an api that doesn't throw and just lets the caller decide (based on the context) if an empty returned value is incorrect.",-1,0.9212005734443665
429076742,8680,kowshik,2020-05-22T07:02:23Z,no. but we want to test the behavior about what happens during a deletion (ex: operational error).,0,0.9839991927146912
429077064,8680,kowshik,2020-05-22T07:03:13Z,done.,0,0.9759407639503479
429077469,8680,kowshik,2020-05-22T07:04:23Z,done.,0,0.9759407639503479
429078661,8680,kowshik,2020-05-22T07:07:36Z,"as far as i can see, no zk node class defined in this file is defined in such a way. every class in this file encodes/decodes json by itself, and manages its own attributes. should we break the norm?",0,0.983668863773346
429086184,8680,kowshik,2020-05-22T07:27:10Z,done.,0,0.9759407639503479
429087972,8680,kowshik,2020-05-22T07:31:25Z,"see l848 below where it is validated. the call to `zkclient. getallbrokersincluster` decodes each `brokeridznode` content from json to `brokerinfo` object. then, we check whether the call returns exactly the same `brokerinfo` objects defined here, and, along the way features are checked too.",0,0.9883578419685364
429089245,8680,kowshik,2020-05-22T07:34:40Z,done.,0,0.9759407639503479
429089574,8680,kowshik,2020-05-22T07:35:30Z,done. good catch!,1,0.9906185269355774
429089817,8680,kowshik,2020-05-22T07:36:05Z,done.,0,0.9759407639503479
429090026,8680,kowshik,2020-05-22T07:36:42Z,done.,0,0.9759407639503479
429093727,8680,kowshik,2020-05-22T07:45:18Z,done. good point!,1,0.9843669533729553
429096612,8680,kowshik,2020-05-22T07:51:42Z,done. removed extra logging in the caller of this method (see `finalizedfeaturecache`).,0,0.9894988536834717
429101010,8680,kowshik,2020-05-22T08:01:36Z,"done. yes, i feel json deserialization should be treated as fatal. it should never happen, and, can indicate corruption.",-1,0.5454077124595642
429107026,8680,kowshik,2020-05-22T08:14:57Z,done. removed.,0,0.9766796827316284
429107347,8680,kowshik,2020-05-22T08:15:43Z,"done. but it's actually ""change notification queue interrupted"".",0,0.9887136816978455
429109170,8680,kowshik,2020-05-22T08:19:43Z,"the function blocks indefinitely - yes. but this shouldn't cause a problem or lead to deadlock/limbo situation. even if this thread is waiting for an item to become available in the queue, the waiting thread can always get interrupted by the `finalizedfeaturechangelistener.close()` call which calls `shutdownablethread.shutdown()`. note that the `shutdownablethread.shutdown()` method interrupts the thread, which should unblock any waiting `queue.take()` operation and makes it raise an `interruptedexception`: [a link] [a link]",0,0.981956958770752
429110087,8680,kowshik,2020-05-22T08:21:36Z,done. removed.,0,0.9766796827316284
429111103,8680,kowshik,2020-05-22T08:23:51Z,"i didn't understand the question. are you saying the logging severity should be lower or higher? this is a rare case anyway as the feature node doesn't get created often, so, `info` logging seems fine to me.",0,0.9537309408187866
429113491,8680,kowshik,2020-05-22T08:28:40Z,"you bring up a good point. my main concern is availability. if we exit the broker here, then, whenever the feature zk node gets deleted (accidentally), it could crash all brokers in the fleet all at once leading to an availability problem. with regards to violating feature semantics, good point. i'm in 2 minds here, and perhaps we can also hear 's thoughts on this topic.",1,0.9668263792991638
429117278,8680,kowshik,2020-05-22T08:36:30Z,yes. here is the documentation explaining the same: [a link],0,0.9834575653076172
429117918,8680,kowshik,2020-05-22T08:37:53Z,done. removed.,0,0.9766796827316284
429120585,8680,kowshik,2020-05-22T08:43:40Z,the order probably doesn't matter in this case. but logically i decided to follow the below order since i could reason about it better: 1. stop the inflow of new events 2. clear pending events 3. stop the processing of all events,0,0.9419392943382263
429120739,8680,kowshik,2020-05-22T08:44:04Z,done.,0,0.9759407639503479
429123988,8680,kowshik,2020-05-22T08:50:49Z,"i have added documentation here in this method describing all the cases. the empty data case should never happen and can indicate a corruption. the reason is that we always return non-empty data in `featureznode.encode`, so the zk node content should never empty. yes, i can add some more info to kafka-10028 or in the write path pr summary.",0,0.9859740138053894
429126751,8680,kowshik,2020-05-22T08:56:54Z,done.,0,0.9759407639503479
429126867,8680,kowshik,2020-05-22T08:57:07Z,done.,0,0.9759407639503479
429128812,8680,kowshik,2020-05-22T09:01:12Z,done.,0,0.9759407639503479
429474760,8680,abbccdda,2020-05-22T22:08:39Z,we could have multiple here,0,0.9836416244506836
429476928,8680,abbccdda,2020-05-22T22:19:31Z,"i didn't look thoroughly enough, but the only illegalargumentexception i found is [code block] which should never happen as we always use `matchanyversion` in `retryrequestsuntilconnected`. are we trying to catch some other exceptions here?",0,0.9707126021385193
429480603,8680,abbccdda,2020-05-22T22:38:14Z,"my feeling is that this could be on debug level, but no strong perference.",0,0.911088228225708
429494635,8680,abbccdda,2020-05-23T00:13:07Z,nit: minkeylabel,0,0.9866273999214172
429495765,8680,abbccdda,2020-05-23T00:22:36Z,"i see, makes sense.",0,0.9670170545578003
429496037,8680,abbccdda,2020-05-23T00:24:54Z,nit: we could test `emptysupportedfeatures.features().isempty()`,0,0.9878525733947754
429497749,8680,abbccdda,2020-05-23T00:40:54Z,nit: could you elaborate why this helper function and `finalizedfeaturesandepoch` struct is useful in this context? just for easier message printing?,0,0.9874566197395325
429498395,8680,abbccdda,2020-05-23T00:48:10Z,so here we will directly throw nosuchelementexception if `maybefeatureznodebytes` is empty? do we want to check this case and throw a customized exception instead?,0,0.9883297681808472
429498408,8680,abbccdda,2020-05-23T00:48:17Z,nit: space,0,0.9737508893013
429499008,8680,abbccdda,2020-05-23T00:54:28Z,"this leads to a more general question: is there a way to cleanup all the zk feature path? reading from the kip, i don't see we have any admin api to do so, which makes me wonder how could this case happen in reality. in terms of severity, i think crushing the entire cluster seems to be an overkill as well, maybe we should have some blocking mechanism in place for any feature extraction call here, until we see `handlecreation` gets triggered again?",0,0.8211215138435364
429509179,8680,abbccdda,2020-05-23T03:18:11Z,"nit: one liner: `this.features = objects.requirenonnull(features, ""provided features can not be null."");`",0,0.9804613590240479
429509941,8680,abbccdda,2020-05-23T03:30:12Z,nit: remove `only`,0,0.9823074340820312
429510099,8680,abbccdda,2020-05-23T03:32:02Z,"this comment should be frequent and the `featurezknodepath` is staying constant, could we just make it for debugging level?",0,0.9899353384971619
429510224,8680,abbccdda,2020-05-23T03:34:25Z,"i don't think this note is necessary, maybe just merge with the first line as: [code block]",0,0.9779921174049377
429510520,8680,abbccdda,2020-05-23T03:39:24Z,"do you think we should add this config as part of the kip since it is public? i think it would just be a minor update, but let's wait and see others thoughts on this.",0,0.9773461818695068
429510746,8680,abbccdda,2020-05-23T03:43:32Z,remove semi-colon,0,0.9820758104324341
429511091,8680,abbccdda,2020-05-23T03:50:12Z,s/it's/its,0,0.9128116965293884
429511146,8680,abbccdda,2020-05-23T03:51:19Z,`a kafka cluster exists already and the ibp config is less than kafka_2_6_iv1` to `an existing kafka cluster with ibp config less than kafka_2_6_iv1`,0,0.9827582240104675
429511236,8680,abbccdda,2020-05-23T03:52:57Z,"i think the norm exists because we don't have automated framework by then, and doing hand-written json serialization and deserialization is a bit wasting. cc as this is a major direction discussion.",-1,0.7816515564918518
429589291,8680,kowshik,2020-05-24T00:51:52Z,done.,0,0.9759407639503479
429589607,8680,kowshik,2020-05-24T01:00:30Z,done. also added doc.,0,0.9802409410476685
429590012,8680,kowshik,2020-05-24T01:12:17Z,done.,0,0.9759407639503479
429590179,8680,kowshik,2020-05-24T01:16:53Z,"actually i've eliminated the helper method now, and, there is only 1 method: `updateorthrow(...)`.",0,0.9880421161651611
429590200,8680,kowshik,2020-05-24T01:17:20Z,done.,0,0.9759407639503479
429590218,8680,kowshik,2020-05-24T01:17:45Z,done.,0,0.9759407639503479
429590248,8680,kowshik,2020-05-24T01:18:15Z,done.,0,0.9759407639503479
429590426,8680,kowshik,2020-05-24T01:23:07Z,"fixed now. good point. actually the code was incorrect. i meant to wrap `featureznode.decode` call with the `try-catch`, since, it throws `illegalargumentexception`. i have fixed the code now to do the same.",1,0.9062734842300415
429590504,8680,kowshik,2020-05-24T01:25:20Z,done.,0,0.9759407639503479
429590532,8680,kowshik,2020-05-24T01:25:46Z,done.,0,0.9759407639503479
429590593,8680,kowshik,2020-05-24T01:27:36Z,"sounds good. yeah, it is minor and feels like an implementation detail to me. but we can wait to see what others say.",1,0.9657937288284302
429590614,8680,kowshik,2020-05-24T01:27:57Z,done.,0,0.9759407639503479
429590626,8680,kowshik,2020-05-24T01:28:30Z,done.,0,0.9759407639503479
429590656,8680,kowshik,2020-05-24T01:29:04Z,done.,0,0.9759407639503479
429591914,8680,kowshik,2020-05-24T01:59:16Z,done.,0,0.9759407639503479
429593151,8680,kowshik,2020-05-24T02:26:04Z,"the deletion of znode is a rare case, it should never happen in reality unless it is zk corruption, or rarely an operational error that deletes some zk nodes. it's not easy to prevent damage in such a case. from a correctness standpoint, imagine what would happen if the feature znode gets deleted, and, afterwards a broker restarts. it will start with empty cache, so the damage is done. therefore, it seems that even if we add a special logic here, we can not prevent damage if the source of truth is lost. two things to note here: 1. the client should anyway ignore older stale epoch responses, if it had seen newer epochs that are greater. in that spirit, the client can be also made to treat the absence of finalized features in an `apiversionsresponse` just like a stale epoch case, if, it had seen at least one valid `apiversionsresponse` earlier (i.e. at least one response with some valid epoch). 2. deletion of individual finalized feature is actually supported in [a link], but not deletion of the entire znode. search for the word 'deletion' in the kip write-up. if needed, this deletion functionality could be extended to provide the ability to delete all features too.",0,0.9479859471321106
430737606,8680,abbccdda,2020-05-26T22:15:42Z,"thanks, i don't think we need to be super paranoid with this rare scenario, but we should also be indicating this error state to the client suggesting that some manual fix is necessary. my proposed idea above is to add such an error state to the feature cache to refuse any further updates until we have: 1. a node creation event 2. restart of the broker (once the issue gets fixed), so this blocking behavior shall be ephemeral and recoverable from broker perspective. we don't have to implement this logic in the current pr, as we don't have a write path yet, just get a jira to track it sounds fine. make sense to cc and as well.",0,0.46004682779312134
432781217,8680,junrao,2020-05-29T23:29:07Z,"this won't make 2.6.0 release. so, perhaps we should use kafka_2_7 or whatever the next release is?",0,0.9860826134681702
432782068,8680,junrao,2020-05-29T23:33:18Z,"i missed this in the kip, but it seems that long is overkilling for version. the version in request is short and the version in zk data is int. so, perhaps this should just be short?",0,0.9119742512702942
432782926,8680,junrao,2020-05-29T23:37:35Z,"minvalue > 1, maxvalue > 1 => minvalue >= 1, maxvalue >= 1",0,0.9818257093429565
432783145,8680,junrao,2020-05-29T23:38:43Z,should we include the label too?,0,0.9874211549758911
432783472,8680,junrao,2020-05-29T23:40:25Z,serialize typically means generating binary data. perhaps this is better called tomap()?,0,0.9810644388198853
433327328,8680,junrao,2020-06-01T15:53:29Z,missing license header,0,0.7844788432121277
433337829,8680,junrao,2020-06-01T16:10:17Z,empty => isempty ?,0,0.9813900589942932
433347401,8680,junrao,2020-06-01T16:27:29Z,"could we use map {case(feature, versionlevel, _) => ...} to avoid unnamed references like _1?",0,0.9887216091156006
433359805,8680,junrao,2020-06-01T16:50:36Z,the kip doesn't seems to include this field. could we add it to the kip wiki?,0,0.9888160228729248
433366871,8680,junrao,2020-06-01T17:03:47Z,"interruptedexception can be thrown if the thread is shut down explicitly. in this case, we probably don't want to throw runtimeexception to the caller.",0,0.9804866909980774
433373309,8680,junrao,2020-06-01T17:16:17Z,"hmm, could we just use config.zkconnectiontimeoutms for this, instead of introducing a new config?",0,0.9874019026756287
433375459,8680,junrao,2020-06-01T17:20:23Z,"hmm, is waitonceforcacheupdatems <=0 supported? in that case, it seems that we still need to read the /features path in zk?",0,0.9884601831436157
433382257,8680,junrao,2020-06-01T17:32:58Z,"if this thread is being closed, the interruptedexception is expected and we don't need to log this.",0,0.9859521389007568
433384475,8680,junrao,2020-06-01T17:37:12Z,"hmm, this just kills the thread, but not the broker as the comment says. also, not sure about killing the broker. we probably should just log an error and continue since this is not necessarily fatal.",0,0.8353177309036255
433395727,8680,junrao,2020-06-01T17:58:03Z,"hmm, the epoch returned from zk is int32. does finalizedfeaturesepoch need to be int64?",0,0.9884777665138245
433399575,8680,junrao,2020-06-01T18:05:16Z,"hmm, why is finalizedfeaturesepoch an optional but latestsupportedfeatures is not?",0,0.960203230381012
433400012,8680,junrao,2020-06-01T18:06:06Z,should we add public methods for accessing those fields?,0,0.9849243760108948
433402784,8680,junrao,2020-06-01T18:11:26Z,it doesn't seem we store security protocol map in the broker registration.,0,0.9815499782562256
433403260,8680,junrao,2020-06-01T18:12:25Z,should we include the new field in tostring()?,0,0.9865998029708862
433409944,8680,junrao,2020-06-01T18:25:22Z,the existing comments seem incorrect since we don't store listener_security_protocol_map in zk.,0,0.9147488474845886
434343065,8680,kowshik,2020-06-03T06:47:41Z,done. made it kafka_2_7_iv0.,0,0.9040095210075378
434344257,8680,kowshik,2020-06-03T06:50:32Z,done. i have made it `int16` now. great point.,1,0.985680341720581
434345400,8680,kowshik,2020-06-03T06:53:05Z,done.,0,0.9759407639503479
434346281,8680,kowshik,2020-06-03T06:55:08Z,done.,0,0.9759407639503479
434417020,8680,kowshik,2020-06-03T09:01:38Z,done.,0,0.9759407639503479
434428173,8680,kowshik,2020-06-03T09:20:02Z,"it's because non-existing supported features _can_ be represented by an empty map (i.e. broker does not advertise any features). but on the other hand, non-existing finalized features can not be represented by empty map alone, as we need a suitable epoch value that indicates the absence of finalized features. to address this case, i saw 2 ways: 1) provide a negative epoch value indicating absence of finalized features, or 2) represent using an empty `optional` for both finalized features and epoch. i chose the latter approach. please, let me know if you have concerns.",0,0.9676589965820312
434431330,8680,kowshik,2020-06-03T09:25:27Z,"i had added such apis previously. but wanted these removed, as they are not currently unused. please refer to this comment: [a link] please, let me know, and i can add them back if you prefer.",0,0.9786930084228516
434431880,8680,kowshik,2020-06-03T09:26:20Z,done. changed to `int32` now. great point!,1,0.9900012016296387
434434381,8680,kowshik,2020-06-03T09:30:30Z,done.,0,0.9759407639503479
434434804,8680,kowshik,2020-06-03T09:31:10Z,done. nice catch!,1,0.9904513359069824
434435193,8680,kowshik,2020-06-03T09:31:48Z,done.,0,0.9759407639503479
434435824,8680,kowshik,2020-06-03T09:32:53Z,done.,0,0.9759407639503479
434438288,8680,kowshik,2020-06-03T09:36:50Z,done. removed the catch clause and exception wrapping.,0,0.9879343509674072
434441200,8680,kowshik,2020-06-03T09:41:16Z,done.,0,0.9759407639503479
434443007,8680,kowshik,2020-06-03T09:44:10Z,"it kills the broker because `shutdownablethread` catches `fatalexiterror` and triggers exit sequence: [a link] i have updated the comment to use the word ""eventually"". regarding logging fatal and continuing -- the exception caught here almost always indicates a feature incompatibility, and, that means the broker can cause damage if it sticks around. that is why i felt it is better to kill the broker in such a rare incompatibility case. please, let me know your thoughts.",0,0.9067569375038147
434444716,8680,kowshik,2020-06-03T09:46:55Z,done. i have changed the code disallowing values <= 0.,0,0.9874057173728943
434444848,8680,kowshik,2020-06-03T09:47:11Z,done. great point!,1,0.9908314347267151
434445428,8680,kowshik,2020-06-03T09:48:14Z,done.,0,0.9759407639503479
434448455,8680,kowshik,2020-06-03T09:53:30Z,done. removed. great catch!,1,0.9916354417800903
434450195,8680,kowshik,2020-06-03T09:56:30Z,sure. i will be happy to follow up on this. trying to understand the process -- should i update the kip and send an email as fyi to `dev.apache.org` ?,1,0.9627038836479187
435543865,8680,junrao,2020-06-04T20:56:15Z,"to handle zk session expiration, we need to register a statechangehandler. that way, we can read the /features path from zk when the new session is established since the feature could have changed btw the old and the new zk sessions. see object zkstatechangehandler as an example.",0,0.9874710440635681
435558683,8680,junrao,2020-06-04T21:20:35Z,could we pass in `optional ` instead of two separate optional?,0,0.9879713654518127
435560941,8680,junrao,2020-06-04T21:23:29Z,"if finalizedfeaturesepoch is not present, we probably want to set the field to sth like -1 instead of leaving it as the default value of 0.",0,0.9878900647163391
435562341,8680,junrao,2020-06-04T21:26:15Z,the comment can be a bit misleading since features is not optional.,0,0.5780580043792725
435567942,8680,junrao,2020-06-04T21:39:10Z,it's probably better to close this before zkclient since the close call unregister from zkclient.,0,0.9858245849609375
435595571,8680,junrao,2020-06-04T22:53:02Z,the name of the method probably should include failure?,0,0.9736871719360352
435595915,8680,junrao,2020-06-04T22:54:00Z,missing license header,0,0.7844788432121277
435596401,8680,junrao,2020-06-04T22:55:36Z,"could we just assertequals(featureznode, decoded)?",0,0.989440381526947
435597745,8680,junrao,2020-06-04T22:59:39Z,`version > currentversion` means that we can't downgrade the broker. we will need to relax this check.,0,0.9842941164970398
435598956,8680,junrao,2020-06-04T23:03:22Z,missing license header,0,0.7844788432121277
435601124,8680,junrao,2020-06-04T23:10:31Z,missing license header,0,0.7844788432121277
435604964,8680,junrao,2020-06-04T23:23:22Z,"hmm, if the feature is disabled, it seems that updatedfinalizedfeatures shouldn't be reflected in the cache, right?",0,0.9799177050590515
435606223,8680,junrao,2020-06-04T23:27:47Z,do we want to throw an exception here?,0,0.9712256193161011
435607391,8680,junrao,2020-06-04T23:31:54Z,missing license header,0,0.7844788432121277
436493426,8680,kowshik,2020-06-08T07:04:45Z,done.,0,0.9759407639503479
436493633,8680,kowshik,2020-06-08T07:05:14Z,done.,0,0.9759407639503479
436494049,8680,kowshik,2020-06-08T07:06:16Z,done.,0,0.9759407639503479
436495007,8680,kowshik,2020-06-08T07:08:46Z,done. great point!,1,0.9908314347267151
436495405,8680,kowshik,2020-06-08T07:09:48Z,done.,0,0.9759407639503479
436495661,8680,kowshik,2020-06-08T07:10:28Z,done.,0,0.9759407639503479
436496035,8680,kowshik,2020-06-08T07:11:21Z,done.,0,0.9759407639503479
436496254,8680,kowshik,2020-06-08T07:11:54Z,done.,0,0.9759407639503479
436515190,8680,kowshik,2020-06-08T07:53:52Z,done. i have modified the code such that `featurecacheupdater.updatelatestorthrow` will now clear the cache whenever it sees that the feature zk node is disabled. great point!,1,0.9910097122192383
436524414,8680,kowshik,2020-06-08T08:11:36Z,done. changed it to use a latch that gets notified when the exit procedure is called. great point!,1,0.9901894927024841
436527003,8680,kowshik,2020-06-08T08:16:56Z,done.,0,0.9759407639503479
436532143,8680,kowshik,2020-06-08T08:26:36Z,done.,0,0.9759407639503479
436543251,8680,kowshik,2020-06-08T08:47:05Z,done.,0,0.9759407639503479
436544409,8680,kowshik,2020-06-08T08:49:14Z,"done. i'm no longer passing 2 optionals, since, we decided (below) that epoch can be set as -1 whenever it is absent.",0,0.9824991226196289
436607402,8680,kowshik,2020-06-08T10:44:45Z,this config has been eliminated now.,0,0.9818891286849976
437045081,8680,junrao,2020-06-08T22:54:43Z,"this is not really ""change-notification"". so, the name can just be featureznode.path.",0,0.9872683882713318
437049072,8680,junrao,2020-06-08T23:06:49Z,2.6.x => 2.7.x,0,0.9828604459762573
437049227,8680,junrao,2020-06-08T23:07:19Z,2.6.x => 2.7.x,0,0.9828604459762573
437123822,8680,kowshik,2020-06-09T03:56:53Z,done.,0,0.9759407639503479
437123965,8680,kowshik,2020-06-09T03:57:29Z,done.,0,0.9759407639503479
437124061,8680,kowshik,2020-06-09T03:57:53Z,done.,0,0.9759407639503479
437140900,8680,abbccdda,2020-06-09T05:10:27Z,nit: we could use utils.mkmap here,0,0.9865577816963196
437141678,8680,abbccdda,2020-06-09T05:13:44Z,"we don't need to check `other == null` here, the next condition check covers it.",0,0.9861255288124084
437143331,8680,abbccdda,2020-06-09T05:19:56Z,"nit: should all the parameters be final here, not just minmagic?",0,0.985939621925354
437145250,8680,abbccdda,2020-06-09T05:26:56Z,"i overlooked this case, let's maintain this static constructor without renaming it, since it is public.",0,0.9881770014762878
437146576,8680,abbccdda,2020-06-09T05:31:25Z,"nit: instead of using comments, better to build this into the test name, for example: `testinvalidsuppportedfeatureswithmissingmaxversion`",0,0.9875169396400452
437153379,8680,abbccdda,2020-06-09T05:53:27Z,nit: {} not necessary,0,0.9725229144096375
437580565,8680,abbccdda,2020-06-09T16:57:16Z,nit: use `introduced` to align with previous comment?,0,0.9869360327720642
437582007,8680,abbccdda,2020-06-09T16:59:26Z,it's -> its,0,0.9520468711853027
437582948,8680,abbccdda,2020-06-09T17:00:59Z,could be simplified as `the latest known finalizedfeaturesandepoch or empty if not defined in the cache`,0,0.9885950684547424
437584758,8680,abbccdda,2020-06-09T17:04:11Z,"i think we could remove `if the cache update is not successful, then, a suitable exception is raised...` which is pretty obvious.",0,0.9772633910179138
437586235,8680,abbccdda,2020-06-09T17:06:41Z,"sorry it's been a while since my last review, but have we discussed the recovery path when we hit a data corruption exception for the cluster? is there a way to turn off the feature versioning completely to unblock, or we have a mechanism to wipe out zk data?",-1,0.984850287437439
437592050,8680,abbccdda,2020-06-09T17:16:33Z,"being a bit paranoid here, would it be possible to have out-of-order updates from zk, such that the version number is not monotonically increasing? i'm thinking even we could throw in finalizedfeaturecache, do we really want to kill the broker, or we should just log a warning and proceed.",-1,0.8843792676925659
437598721,8680,abbccdda,2020-06-09T17:27:52Z,"i think i'm no longer insisting on this point, as we could make this as a follow-up work. filed jira here: [a link]",0,0.9769017100334167
437604015,8680,abbccdda,2020-06-09T17:36:59Z,nit: space,0,0.9737508893013
437605413,8680,abbccdda,2020-06-09T17:39:17Z,v4 doesn't have feature right? what's the purpose of this test?,0,0.9793446660041809
437606748,8680,abbccdda,2020-06-09T17:41:34Z,add the space back,0,0.9857876300811768
437607867,8680,abbccdda,2020-06-09T17:43:22Z,nit: we could add a minor test to verify a negative `waitonceforcacheupdatems` will throw,0,0.9880933165550232
437851289,8680,kowshik,2020-06-10T04:20:38Z,done.,0,0.9759407639503479
437851622,8680,kowshik,2020-06-10T04:21:57Z,done. good point.,1,0.9535248279571533
437855643,8680,kowshik,2020-06-10T04:38:46Z,done.,0,0.9759407639503479
437855789,8680,kowshik,2020-06-10T04:39:31Z,done.,0,0.9759407639503479
437856190,8680,kowshik,2020-06-10T04:41:11Z,done.,0,0.9759407639503479
437856298,8680,kowshik,2020-06-10T04:41:37Z,done.,0,0.9759407639503479
437856385,8680,kowshik,2020-06-10T04:41:59Z,done.,0,0.9759407639503479
437856510,8680,kowshik,2020-06-10T04:42:29Z,done.,0,0.9759407639503479
437857795,8680,kowshik,2020-06-10T04:47:48Z,done.,0,0.9759407639503479
437858130,8680,kowshik,2020-06-10T04:49:06Z,it's a 2-line block.,0,0.9846545457839966
437874395,8680,kowshik,2020-06-10T05:50:01Z,"1. re: out-of-order updates from zk: i don't understand. when a watch fires from zk, we react by issuing a zk read operation to obtain the latest value of the zk node (see l75). it is impossible that we get a stale read from zk after watch fires on the client side. 2. re: broker death: the exception thrown here almost always indicates a feature incompatibility, and, that means the broker can cause damage if it sticks around (because feature bumps are breaking changes and you can not allow an incompatible broker to stick around in the cluster). that is why i felt it is better to kill the broker in such a rare incompatibility case. note that after the controller has finalized features, there should be no brokers in the cluster with incompatibilites, so death here makes sense. note: i have also explained point #2 in this comment: [a link]",0,0.7967449426651001
437875708,8680,kowshik,2020-06-10T05:54:19Z,thanks. good idea to leave a jira. i have linked it to kafka-9755.,1,0.9835593104362488
437875864,8680,kowshik,2020-06-10T05:54:45Z,done.,0,0.9759407639503479
437876419,8680,kowshik,2020-06-10T05:56:21Z,it checks backwards compatibility i.e. it checks whether the deserialization code (v5-based) can correctly deserialize v4 such that features are assigned empty value by default..,0,0.9864234328269958
437877179,8680,kowshik,2020-06-10T05:58:47Z,done.,0,0.9759407639503479
437877390,8680,kowshik,2020-06-10T05:59:31Z,done.,0,0.9759407639503479
437883374,8680,kowshik,2020-06-10T06:17:37Z,it's very rare especially when controller is the only entity writing to the zk node. i have now modified the code to handle this case and clear the cache. perhaps that's better than crashing the broker in such a case. remediation will need human intervention in fixing the zk node. we can provide tooling if required.,0,0.9219990372657776
1333345949,14406,philipnee,2023-09-21T16:40:02Z,is the extra line intentional?,0,0.9551354646682739
1333349057,14406,philipnee,2023-09-21T16:42:59Z,kafkaexception?,0,0.9851616621017456
1333353029,14406,philipnee,2023-09-21T16:46:45Z,it is handled in the error event handler - which means the user should get the exception upon invoking poll. i wonder if we could just log info or at a different level. or even no logging.,0,0.9116212129592896
1333353596,14406,philipnee,2023-09-21T16:47:22Z,extra line :grinning_face_with_sweat:,-1,0.4560655653476715
1333355626,14406,philipnee,2023-09-21T16:49:19Z,ditto : as the error is log here - we might not need the extra logging,0,0.9501920342445374
1333393941,14406,junrao,2023-09-21T17:28:22Z,"just to understand this. if the consumer gets a fenced_leader_epoch, a metadata update is triggered. once the new metadata is received, the validatepositionsapplicationevent will trigger the offsetforleaderepoch request to validate the fetch position. until the new metadata is received, the consumer will just continuously fetch from the old leader and receiving the same fenced_leader_epoch error?",0,0.9870727062225342
1333594757,14406,junrao,2023-09-21T20:54:51Z,"i guess the purpose of this code is when there is no pending records, we block until some new records are fetched. however, i am wondering if it achieves the purpose. when processing a fetchevent, applicationprocessor just calls requestmanagers.fetchrequestmanager.drain(). if there is nothing to drain, an empty queue is returned immediately. this will unblock fetchevent to return immediately without waiting for the poll time?",0,0.972019612789154
1333599432,14406,lianetm,2023-09-21T21:00:26Z,is this an old comment i guess?,0,0.9425312280654907
1333605133,14406,lianetm,2023-09-21T21:07:38Z,i find this name combination closer+assertopen kind of confusing. i even think it would it be easier to follow if we just had the explicit check `if(isclose()) throw` here,0,0.6604534983634949
1333613388,14406,lianetm,2023-09-21T21:17:24Z,do we expect to have nulls here even if these come from the blockingqueue that does not accept nulls?,0,0.9784877896308899
1333616692,14406,philipnee,2023-09-21T21:21:51Z,have you ran into a scenario that the module is null?,0,0.9563078284263611
1333617066,14406,lianetm,2023-09-21T21:22:23Z,"need ""to"" throw",0,0.9566650986671448
1333620613,14406,lianetm,2023-09-21T21:27:18Z,debug level better? (same for all other log lines in this func),0,0.9872484803199768
1333698259,14406,junrao,2023-09-21T23:36:53Z,is this request guaranteed to be sent when the consumer is closed? do we need this guarantee?,0,0.986161470413208
1333708126,14406,junrao,2023-09-21T23:55:37Z,is the rebalance callback called here?,0,0.9834797382354736
1333739561,14406,philipnee,2023-09-22T00:36:53Z,"current log is at trace level: `log.trace(""closing the kafka consumer"");`",0,0.9845126271247864
1333760307,14406,junrao,2023-09-22T01:07:10Z,"this logic is a bit weird. applicationeventprocessor handles fetchevent by draining all completefetches from fetchbuffer, but here we are just adding them back to fetchbuffer again.",-1,0.9830697774887085
1334577989,14406,junrao,2023-09-22T16:08:24Z,could we describe what this class does? it's a bit weird the `backgroundeventprocessor.process` is called from `prototypeasyncconsumer` in the foreground.,-1,0.8759756088256836
1334591301,14406,junrao,2023-09-22T16:20:46Z,this causes an exception to be thrown in the application thread. it seems that we should avoid doing that for at least the retriable exceptions? ditto below.,0,0.8833661079406738
1334595965,14406,junrao,2023-09-22T16:25:38Z,it seems that timer.currenttimems() doesn't change btw poll start and poll end because of the way that timer is constructed?,0,0.9845374822616577
1334596869,14406,junrao,2023-09-22T16:26:33Z,is that todo still needed since we implemented `poll` now?,0,0.9866886734962463
1334617225,14406,junrao,2023-09-22T16:47:30Z,should we wait for the time here like what we did in `refreshcommittedoffsetsifneeded`?,0,0.9787216782569885
1334630287,14406,junrao,2023-09-22T17:01:40Z,"this is an existing issue, but i don't quite understand this comment. in other places, we just use `time` directly assuming it's never null.",0,0.8662779927253723
1334636045,14406,junrao,2023-09-22T17:08:20Z,do we need this since closetimer is already bounded by requesttimeoutms?,0,0.9886839985847473
1334639334,14406,junrao,2023-09-22T17:11:53Z,we are not really passing in closetimer below.,0,0.6868529915809631
1334651469,14406,junrao,2023-09-22T17:25:40Z,could we remove `this` for better consistency?,0,0.9871867895126343
1334655265,14406,junrao,2023-09-22T17:29:54Z,"we haven't implemented the group subscription logic in prototypeasyncconsumer, right? ditto for the pattern subscribe below.",0,0.9128379225730896
1334668882,14406,junrao,2023-09-22T17:45:36Z,"`fetchposition` is updated in the background thread, right? so, it could change anytime during the `poll` call in the consumer. do we need the info on `fetchposition` to be accurately reflected here?",0,0.9894853234291077
1334677351,14406,junrao,2023-09-22T17:55:10Z,the comment is a bit confusing. the code doesn't seem to do anything related to offsets and rebalance.,-1,0.946169912815094
1334678608,14406,junrao,2023-09-22T17:56:44Z,no partitions are provided to this method.,0,0.9764603972434998
1334719457,14406,junrao,2023-09-22T18:48:26Z,"this is an existing issue, but i am not sure why the comment mentions `fetchrecords`.",0,0.8837353587150574
1334720342,14406,junrao,2023-09-22T18:49:38Z,could we update the javadoc?,0,0.9887999296188354
1334733479,14406,junrao,2023-09-22T19:06:57Z,there is still a mention of `deserializers` above.,0,0.9862187504768372
1334734342,14406,junrao,2023-09-22T19:08:09Z,extra new line,0,0.9643937349319458
1334738863,14406,junrao,2023-09-22T19:14:25Z,it seems that none of the request managers implements `close`. does this need to be `closeable`?,0,0.9823732376098633
1334740555,14406,junrao,2023-09-22T19:16:49Z,`requestmanagers` doesn't take .,0,0.9645819067955017
1334821243,14406,junrao,2023-09-22T21:13:33Z,the noid part is a bit confusing. assignfromusersingletopic?,-1,0.820957601070404
1334829050,14406,junrao,2023-09-22T21:27:55Z,"`client.updatemetadata `eventually calls `metadata.updatewithcurrentrequestversion`. so, not sure why we are updating cluster metadata twice with different values.",0,0.9414561986923218
1334857621,14406,junrao,2023-09-22T22:25:49Z,could we be consistent with the use of `this`?,0,0.9875450730323792
1334860526,14406,junrao,2023-09-22T22:31:22Z,consumerclient => networkclientdelegate?,0,0.9848281741142273
1334869446,14406,kirktrue,2023-09-22T22:52:25Z,"yes, just to set off the child `subpackage` element more cleanly. but i can remove it if you'd like.",0,0.9761728644371033
1334870059,14406,kirktrue,2023-09-22T22:54:15Z,"are you saying that the incoming error (`t`) is already logged before the callback is invoked? if so, then yeah, it makes sense to remove it here.",0,0.984601616859436
1334870549,14406,kirktrue,2023-09-22T22:55:37Z,"sorry, can you elaborate? where is the error logged other than this?",-1,0.9862695336341858
1334870694,14406,kirktrue,2023-09-22T22:56:06Z,yep. i'll remove it.,0,0.9849766492843628
1334870735,14406,kirktrue,2023-09-22T22:56:12Z,will remove.,0,0.9759372472763062
1334870782,14406,kirktrue,2023-09-22T22:56:20Z,ok. i'll change it. thanks.,1,0.9281012415885925
1334871262,14406,kirktrue,2023-09-22T22:57:46Z,"hmm... i can see your point. the naming is definitely confusing :grinning_squinting_face: it used to be named `maybethrowillegalstateexception()`, so it could be worse.",-1,0.9402124881744385
1334871627,14406,kirktrue,2023-09-22T22:59:03Z,i found the occasional `null` event in the past. the collections didn't prevent it. maybe it's an extra level of paranoia that has outlived its purpose?,-1,0.5834552049636841
1334872019,14406,kirktrue,2023-09-22T23:00:22Z,do you mean if `networkclientdelegate` is still `null`? yes. that can happen if the object is constructed and then used without calling `initializeresources` beforehand. perhaps a comment or a restructuring of the code could be made.,0,0.9888652563095093
1334872655,14406,kirktrue,2023-09-22T23:02:24Z,"i need ""to"" proofread my comments more thoroughly :grinning_face_with_smiling_eyes:",1,0.6185104250907898
1334873271,14406,kirktrue,2023-09-22T23:04:12Z,"i'll change the log line at the start of the method from `info` to `trace` and leave the log line at the end of the method as `debug`. in so doing, both will match the levels in `kafkaconsumer.close()`.",0,0.9891140460968018
1334876767,14406,kirktrue,2023-09-22T23:16:05Z,"not yet, no. i'll remove the comment because we haven't implemented the callback mechanism here. it's in a draft pr #14357. we do have the _general_ mechanism for how we'll end up calling them, which is via the `backgroundeventprocessor`. i did notice a difference between `kafkaconsumer` and `prototypeasyncconsumer`—the former is potentially invoking the rebalance callback on each iteration of the loop inside `poll()` whereas the latter implementation is only calling it once at the top of `poll()`. i'll change ours to work in a similar fashion.",0,0.9791914820671082
1334878210,14406,kirktrue,2023-09-22T23:21:07Z,"yes, this is ugly and ripe for reworking. there are two buffers to store `completedfetch`es: one for the background thread and one for the application thread. this way the background thread can write to _its_ buffer and the application thread can read from _its_ buffer without them stepping on each other's toes.",-1,0.9802165627479553
1334878765,14406,kirktrue,2023-09-22T23:23:21Z,"yeah, that is a bit weird. it's the same with `applicationeventprocessor.process()` being called from the background thread. each thread ""processes"" the events it received from the other thread.",-1,0.9844173192977905
1334878800,14406,kirktrue,2023-09-22T23:23:31Z,"but yes, i'll definitely add some comments here.",0,0.976375162601471
1334879279,14406,kirktrue,2023-09-22T23:25:15Z,my understanding was that the failure is only propagated to this callback once the retries have been exhausted. am i misunderstanding?,0,0.6235880255699158
1334881403,14406,kirktrue,2023-09-22T23:32:36Z,"the `timer` is created inside `poll()` is passed into the other methods. the only one that updates it directly is `pollforfetches` which updates it only in the `finally` block at the end: [code block] i double-checked our implementation against `kafkaconsumer` and they seem to match in that regard. `kafkaconsumer` passes the `timer` into the methods related to the consumer coordinator, but since we don't have that functionality just yet, we don't.",0,0.9838274717330933
1334881860,14406,kirktrue,2023-09-22T23:34:21Z,good question. do we need to update our `poll` implementation to include the wakeup mechanism?,1,0.9465405941009521
1334882482,14406,kirktrue,2023-09-22T23:37:13Z,do you remember why we opted for a non-blocking event here?,0,0.9849512577056885
1334882689,14406,kirktrue,2023-09-22T23:38:10Z,`offsetfetcher.resetpositionsifneeded()` is used in the `kafkaconsumer` and it appears to send off the reset positions request asynchronously :thinking_face:,0,0.9833694100379944
1334884022,14406,kirktrue,2023-09-22T23:43:15Z,"`createtimerforrequest` appears to only be called from `close()`. some of the constructors' contents are wrapped in a `try-catch` block that attempts to close the consumer on initialization failure. so if the constructor fails before we initialize the `time` instance variable, it would be `null` when we attempt to `close()` up any resources. i'm assuming based on that comment that only `close()` has that concern about using `time`.",0,0.9799731969833374
1334885217,14406,kirktrue,2023-09-22T23:48:32Z,true. there doesn't appear to be any blocking calls made from the `fetchbuffer.close()` path. i'll dig around some more.,0,0.9844748973846436
1334885226,14406,kirktrue,2023-09-22T23:48:34Z,true. we don't have to account for time it takes for the coordinator to close because we don't have a coordinator :grinning_face_with_smiling_eyes:. i'll remove that.,0,0.5952195525169373
1334885719,14406,kirktrue,2023-09-22T23:50:42Z,"the inclusion of `this` here is, in fact, to be more consistent... with the code in `kafkaconsumer.subscribe()`. at one point we took as much of the code from `kafkaconsumer` as we could, warts and all. i'll remove this `this`, though.",0,0.9869922399520874
1334885895,14406,kirktrue,2023-09-22T23:51:38Z,"there are several other places in the `prototypeasyncconsumer` that we do things sub-optimally, just to match `kafkaconsumer`.",0,0.9857585430145264
1334886142,14406,kirktrue,2023-09-22T23:52:47Z,i'll dig in on this a little deeper.,0,0.9567291736602783
1334886595,14406,kirktrue,2023-09-22T23:54:45Z,this is another case of grabbing the code verbatim from `kafkaconsumer`. does the code comment make sense to you?,0,0.9699706435203552
1334886820,14406,kirktrue,2023-09-22T23:55:41Z,good catch. old comments :frowning_face_with_open_mouth:,1,0.9850665330886841
1334888478,14406,kirktrue,2023-09-23T00:03:26Z,"i think i wrote the initial comment :grimacing_face: i was trying to explain that `drain()`-ing a `completedfetch` is like `close()`-ing it, in that we free its resources. but it's _unlike_ `close()` because we can technically still call `fetchrecords()` on it without throwing some sort of `illegalstateexception` or anything. is this better? or should i just scrap the whole comment altogether?",-1,0.8989289402961731
1334892999,14406,kirktrue,2023-09-23T00:28:08Z,will do.,0,0.9548023343086243
1334893011,14406,kirktrue,2023-09-23T00:28:13Z,will exorcise them.,0,0.9682278633117676
1334893046,14406,kirktrue,2023-09-23T00:28:28Z,i'll remove it.,0,0.9813470840454102
1334893631,14406,kirktrue,2023-09-23T00:32:19Z,"the `fetchrequestmanager` does by virtue of extending from `abstractfetch`. the sole reason for that it is so that it can prepare to send requests to the brokers to close their fetch sessions. it's kind of kludgey the way it's done, so i'll take another look to see if it can be done more cleanly.",0,0.9153263568878174
1334894116,14406,kirktrue,2023-09-23T00:35:10Z,thanks for the catch!,1,0.9525227546691895
1334896241,14406,kirktrue,2023-09-23T00:49:26Z,removed the extra line.,0,0.9814997911453247
1335942472,14406,lianetm,2023-09-25T14:07:00Z,"my understanding is that in that case it won't continuously fetch from the old leader because of the partition subscription state, which will transition to `awaiting_validation` (not a valid state for fetching). the moment a new metadata is discovered, [a link], so the [a link] will not fetch from them. to complete the validation picture, once the `offsetforleaderepoch` response is received, the subscription state will transition to `fetching` again and fetch requests should resume for that partition. my thoughts but please correct me if i'm missing something from the fetching story.",0,0.9281270503997803
1336253362,14406,junrao,2023-09-25T18:31:51Z,: thanks for the reply. that's my understanding too. my question was what happens before the new metadata is received. will the consumer continuously fetch from the older leader?,1,0.9602147340774536
1336273549,14406,junrao,2023-09-25T18:52:21Z,should this comment be moved to above the `client.prepareresponse` below?,0,0.9889028668403625
1337443244,14406,kirktrue,2023-09-26T15:54:24Z,i reverted the change to the comment. i don't remember changing it :man_shrugging:,-1,0.9137159585952759
1337444033,14406,kirktrue,2023-09-26T15:55:02Z,i've updated this so that the `close()` method is a lot cleaner.,0,0.9659463167190552
1337444456,14406,kirktrue,2023-09-26T15:55:21Z,removed the unnecessary timer.,0,0.9754947423934937
1337444877,14406,kirktrue,2023-09-26T15:55:43Z,"`createtimerforrequest()` is no longer used, so marking this as resolved.",0,0.9873427152633667
1337660657,14406,kirktrue,2023-09-26T19:02:44Z,i've changed the mechanism to handle the responses from fetch such that we should now properly block until results are available.,0,0.9859163165092468
1337661714,14406,kirktrue,2023-09-26T19:03:54Z,"this has been reworked as part of a recent change. not only are there are still two `fetchbuffer`s, but i've _added_ a blocking queue between them since the `fetchbuffer` should not be updated on the `future` callback, since that is updated on another thread and `fetchbuffer` is not thread safe.",0,0.972615659236908
1337662384,14406,kirktrue,2023-09-26T19:04:41Z,"it is currently being worked on for the kip-848 work, so its development is running in parallel.",0,0.9858749508857727
1337849711,14406,kirktrue,2023-09-26T22:39:41Z,it looks like the other call sites that add error events to the handler also log them :man_shrugging:,-1,0.8475825190544128
1337881130,14406,kirktrue,2023-09-26T23:43:17Z,"in the refactored version, the logging is not as verbose.",0,0.9766970872879028
1337881557,14406,kirktrue,2023-09-26T23:44:08Z,"this code has been refactored, but it still has the check, just to be paranoid.",-1,0.810684084892273
1337882369,14406,kirktrue,2023-09-26T23:45:52Z,added a brief comment to explain this case.,0,0.9810769557952881
1338972414,14406,philipnee,2023-09-27T17:35:33Z,"i am actually not sure if we need this as networkclientdelegate is already doing the connection checking. if the node is unavailable for reconnection, then it would fail the unsentrequest and presumably trigger a retry. the original code does the connection checking because the request is sent right after its creation; however, there's a time gap between the creation and the actual network io. i think it is harmless to leave it here but it would be great if we could clean them up later.",0,0.8702946901321411
1338973379,14406,philipnee,2023-09-27T17:36:21Z,"per previous comment - if we actually clean up the code, we should only care if there's a fetchtarget or not.",0,0.97444087266922
1339157715,14406,philipnee,2023-09-27T20:13:48Z,we are logging debug for the request manager but info here. just want to make sure we are consistent with the logging level.,0,0.9834511280059814
1339158103,14406,philipnee,2023-09-27T20:14:09Z,thanks for removing the boolean.,0,0.5338746309280396
1339158811,14406,philipnee,2023-09-27T20:14:54Z,my only fear is that this could spam the trace log,-1,0.8209211826324463
1340402407,14406,philipnee,2023-09-28T16:26:40Z,should we use ( ) instead of { } ?,0,0.9836474061012268
1340690791,14406,philipnee,2023-09-28T21:36:39Z,"since we also need to send offsetcommit upon closing, maybe it is best to poll the networkclientdelegate upon closing.",0,0.9847831130027771
1342913561,14406,junrao,2023-10-02T16:29:31Z,could we describe what `poll` does?,0,0.9839613437652588
1342950743,14406,junrao,2023-10-02T17:11:23Z,the above comment that this class is only used from a single thread seems incorrect. the background thread adds fetched data into `completedfetches` and `prototypeasyncconsumer` drains `completedfetches` through `fetchcollector.collectfetch(fetchbuffer)`. there is actually very subtle synchronization between the two threads. could we document the correct way of using this class and how we achieve synchronization so that future developers don't break it?,0,0.9693371653556824
1342984775,14406,junrao,2023-10-02T17:50:15Z,"hmm, with this logic, there is a short window between `completedfetch` in `fetchresults` and `completedfetch` be added to back to `fetchbuffer`. during this window, `backgroundthread` could make a `poll` call, see no buffered data in `fetchbuffer` and fetch the same offset again? then the consumer could see duplicated data because of this.",0,0.9873695969581604
1343046752,14406,junrao,2023-10-02T18:58:21Z,"earlier, we have ""do not have a valid position and are not awaiting reset"". the reset there and the reset here mean different things. the former refers to resetting the offset based on offsetforleaderepoch and the latter refers to resetting the offset to either the earliest or latest. it would be useful to make this clear.",0,0.9856416583061218
1343059742,14406,junrao,2023-10-02T19:11:22Z,"it still seems weird that we only use the timer for `refreshcommittedoffsetsifneeded`, but not for other cases where we don't have valid fetch positions. for example, if all partitions are in await_validation state, it seems that prototypeasyncconsumer.poll() will just go in a busy loop, which is not efficient.",-1,0.8753909468650818
1343061015,14406,junrao,2023-10-02T19:12:57Z,"if `initializingpartitions` is empty, do we still send the offsetfetch request? i didn't see the logic for short-circuiting.",0,0.9806914329528809
1343147889,14406,junrao,2023-10-02T20:46:12Z,is `this` needed?,0,0.9839640259742737
1343150605,14406,junrao,2023-10-02T20:49:09Z,"to be consistent with other places, it seems that we want to combine this with the previous line. ditto below.",0,0.9304237961769104
1343163505,14406,junrao,2023-10-02T21:04:40Z,where is the callback handler?,0,0.9881908893585205
1343232059,14406,junrao,2023-10-02T22:44:17Z,"at this stage, we are just propagating connection level errors like disconnectexception, which is retriable. so, it seems that we shouldn't throw this error back to the application. ditto in `pollonclose`.",0,0.8532793521881104
1343246844,14406,junrao,2023-10-02T23:12:14Z,"if the background thread dies, should we throw an exception to the user thread on the next `poll` call?",0,0.9784602522850037
1343251934,14406,junrao,2023-10-02T23:21:55Z,"instead of using `currenttimems`, we need to use `timer.currenttimems` to pick up the latest time, right?",0,0.9876948595046997
1343259817,14406,junrao,2023-10-02T23:40:32Z,is this comment addressed?,0,0.9840131998062134
1343265294,14406,junrao,2023-10-02T23:52:58Z,fetchposition is updated in the user thread.,0,0.9880885481834412
1343266219,14406,junrao,2023-10-02T23:54:58Z,was this comment addressed?,0,0.9810266494750977
1344756235,14406,kirktrue,2023-10-03T21:21:19Z,"it is now run as part of the `consumer.close()` process, yes.",0,0.9866625666618347
1344758105,14406,kirktrue,2023-10-03T21:22:10Z,"no, not yet. do we want to add something for wakeup here, or should i remove the comment? thanks.",1,0.6720070838928223
1344762836,14406,kirktrue,2023-10-03T21:26:43Z,can you look at the new `defaultbackgroundthread.runatclose()` method i added? do we need to update the `commitrequestmanager` to implement the `pollonclose()` api i added?,0,0.9896572232246399
1344780023,14406,kirktrue,2023-10-03T21:47:18Z,updated to overload the `assignfromuser` method name with a single `topicpartition`. then that single partition is used to return the topic name to reduce the number of times `noid` appears in that code.,0,0.9889463782310486
1344786987,14406,kirktrue,2023-10-03T21:54:37Z,"good question. as a test, i made this change locally: [code block] i ran the tests and they all passed, so i don't know why it was written like that :man_shrugging: this code in `fetchrequestmanagertest` is copied from `fetchertest`; as much as we could was left verbatim.",1,0.9312654137611389
1344795530,14406,kirktrue,2023-10-03T22:03:44Z,done.,0,0.9759407639503479
1344799794,14406,kirktrue,2023-10-03T22:08:14Z,done.,0,0.9759407639503479
1344801112,14406,kirktrue,2023-10-03T22:09:55Z,fixed in both original `fetchertest` and the copied `fetchrequestmanagertest`.,0,0.9892895817756653
1344822614,14406,kirktrue,2023-10-03T22:34:18Z,i added documentation to the `requestmanager` interface with pointers to it from the methods in `fetchrequestmanager`.,0,0.9892592430114746
1344897098,14406,kirktrue,2023-10-04T00:05:17Z,"yes, the process is a bit convoluted... to perform the process of moving the fetched records from the background thread to the application thread and then on to the user, `prototypeasyncconsumer` has these three instance variables: 1. `fetchresults` 2. `fetchbuffer` 3. `fetchcollector` all three of those objects are created in the application thread when the `prototypeasyncconsumer` is created. `fetchbuffer` and `fetchcollector` are only ever referenced by the application thread; `fetchresults`, however, is used by **both** threads. `fetchresults` is referenced in the background thread when it is used in the `fetchevent` callback in the `sendfetches()` method: [code block] since the `whencomplete()` method is executed when the background thread ""completes"" the `future`, `fetchresults` is thus modified on the background thread. the rest of the process should occur on the application thread. during calls to `poll()` on the application thread, data from `fetchresults` is moved to `fetchbuffer` in `pollforfetches()`: [code block] the data in `fetchbuffer` is later extracted in `fetchcollector` during the `poll()` process, but this again is on the application thread. this roundabout way of getting the data is specifically done so that we don't write to the `fetchbuffer` inadvertently from the background thread. hence these javadoc comment for `fetchresults`: [code block] this is a rough idea of what happens on the background thread: then later in the application thread during `poll()`: let me know if that makes sense or if there is still a gap that i'm not seeing. i can write the above up (with any changes you'd like) in code comments.",0,0.9720531702041626
1344899034,14406,kirktrue,2023-10-04T00:09:08Z,i've removed the qualifiers where they're not needed.,0,0.9833447337150574
1344900260,14406,kirktrue,2023-10-04T00:11:31Z,fixed.,0,0.9810503125190735
1344900777,14406,kirktrue,2023-10-04T00:12:12Z,fixed.,0,0.9810503125190735
1346179200,14406,junrao,2023-10-04T16:45:53Z,": thanks for the explanation. two followup questions. 1. the background thread has the following path` fetchrequestmanager.poll -> handlefetchresponse -> fetchbuffer.add(completedfetch)`. so, it seems that the background thread also writes the fetched data to `fetchbuffer`. 2. this is related to my other [a link]. the background thread has the following path `fetchrequestmanager.poll -> abstractfetch.preparefetchrequests -> abstractfetch.fetchablepartitions -> reads fetchbuffer.bufferedpartitions()`. since fetchbuffer is written by the application thread, how do we coordinate the synchronization btw the two threads?",1,0.9631026983261108
1346234546,14406,kirktrue,2023-10-04T17:33:01Z,you're right. thanks for catching that! changed.,1,0.9805208444595337
1346270372,14406,kirktrue,2023-10-04T18:05:36Z,yes. i added a check that it's not closed at the top of `runonce()`.,0,0.9888632297515869
1346278813,14406,kirktrue,2023-10-04T18:13:15Z,this was an outdated comment. fixed.,0,0.7393844723701477
1346451911,14406,junrao,2023-10-04T20:54:01Z,background network thread => network thread ?,0,0.9865765571594238
1346463369,14406,junrao,2023-10-04T21:05:03Z,"this will cause a logging of error during normal shutting down of the consumer, right? it would be useful to avoid that.",0,0.9727380871772766
1346493970,14406,philipnee,2023-10-04T21:35:27Z,thanks - i think we will need to do that. i created kafka-15548 to handle the closing task.,1,0.9446213841438293
1346504058,14406,kirktrue,2023-10-04T21:47:38Z,i removed the error propagation (and logging).,0,0.9874675869941711
1346508562,14406,kirktrue,2023-10-04T21:51:54Z,any reason we don't check if `initializingpartitions` is non-empty before creating the `offsetfetchapplicationevent`?,0,0.9863936305046082
1346517075,14406,kirktrue,2023-10-04T21:59:23Z,"regardless of the return value of `updatefetchpositions()`, `poll()` will still go on to call `pollforfetches()` which will block for data availability or timeout expiration.",0,0.9877691864967346
1346545044,14406,kirktrue,2023-10-04T22:32:56Z,"for point #1, the background thread has a _separate_ fetch buffer. it doesn't write to the same object. the application thread `fetchbuffer` is created in `prototypeasyncconsumer` and the background thread `fetchbuffer` is created in `abstractfetch`. for point #2, i think your [a link] is correct. i'm not yet sure how to maintain those two fetch buffers separately without running into that race condition.",0,0.9698569774627686
1346546088,14406,kirktrue,2023-10-04T22:34:22Z,"yes, i can see that now. given that there are two separate `fetchbuffer`s and the way they're populated, i think the window is actually a bit bigger. i need to noodle on this for a bit.",0,0.8687595725059509
1346562666,14406,junrao,2023-10-04T22:58:01Z,`fetcher` is a `testablefetchrequestmanager`. could we just do `poll` instead of `fetcher.poll`?,0,0.9891987442970276
1346567694,14406,junrao,2023-10-04T23:06:49Z,"where is the callback? also,` networkclient#send` happens in the caller, not here, right?",0,0.986174464225769
1346572630,14406,junrao,2023-10-04T23:15:53Z,it's very confusing that the above two `handlefetchresponse` refer to different methods. could we name them differently?,-1,0.8363932967185974
1346604856,14406,kirktrue,2023-10-05T00:00:01Z,"yes, it would, but what do you expect when you're logging at `trace`? :face_with_tongue:",0,0.9584778547286987
1346606768,14406,kirktrue,2023-10-05T00:02:48Z,changed to debug,0,0.986354649066925
1346607807,14406,kirktrue,2023-10-05T00:04:39Z,i've removed the logging and error forwarding as it is handled in the `networkclientdelegate` layer.,0,0.9884849786758423
1346612374,14406,kirktrue,2023-10-05T00:11:20Z,"at the beginning of the `kafkaconsumer.poll()` loop, it does this: [code block] do we support _disabling_ wake-ups? i don't see the analogue to `maybetriggerwakeup()`, `disablewakeups()`, etc. in `wakeuptrigger`. can we emulate what `kafkaconsumer` is doing in the `poll()` loop with our current implementation? if not, i'd prefer to a) remove the comment, and b) file a new jira. thoughts?",0,0.9692762494087219
1346613925,14406,kirktrue,2023-10-05T00:12:42Z,i'll review with .,0,0.9815034866333008
1346615044,14406,kirktrue,2023-10-05T00:14:29Z,`abstractfetch` is used by both the current `fetcher` as well as the `fetchrequestmanager`. i'd have to refactor the code to rid ourselves of it. what do you think about filing a new jira to track a follow-up change for this?,0,0.985012412071228
1346616102,14406,kirktrue,2023-10-05T00:16:29Z,"i'd like to file a separate jira for this, only because it's been this way for a while. i need more time to understand it before changing it, and would love to get the integration tests and perhaps even system tests online before changing it. thoughts?",0,0.7283611297607422
1346616646,14406,kirktrue,2023-10-05T00:17:22Z,i think i need to circle back with to get her input on this as she's much closer to it than i am.,0,0.7609726190567017
1347629215,14406,junrao,2023-10-05T15:39:53Z,"yes, it's fine to have a separate jira to clean this up.",0,0.9640841484069824
1347692761,14406,junrao,2023-10-05T16:28:21Z,"this logic looks correct in the test. however, in the actual code, there could be unconsumed data in `prototypeasyncconsumer.fetchresults `and `prototypeasyncconsumer.fetchbuffer`. how do we prevent those data from being returned to the user? same question when partition is paused.",0,0.9876448512077332
1347727982,14406,junrao,2023-10-05T16:57:13Z,"hmm, should the code be commented out? it doesn't match the comment above.",0,0.9347453117370605
1347742323,14406,junrao,2023-10-05T17:10:13Z,"i don't quite understand these 3 lines. why are we polling the fetcher again since typically this doesn't happen after pollonclose is called on the fetcher? also, for the test as it is, it seems that the first request is the one with the final epoch, not the second?",0,0.9381760954856873
1347748114,14406,junrao,2023-10-05T17:15:36Z,does this test subsume `testinflightfetchonpendingpartitions`?,0,0.9875713586807251
1347751320,14406,junrao,2023-10-05T17:18:29Z,should the comment be moved to just above `client.prepareresponse` below?,0,0.9883905649185181
1347752851,14406,lianetm,2023-10-05T17:19:55Z,"agree , i will update the comments to better explain. the bottom line is that positions may be reset in 2 different ways: - using the committed offsets (retrieved with `offsetfetch` sent to the group coordinator). this if committed offsets are in use. - using the partition offsets (retrieved with `listoffset` sent to the partition leader + reset strategy) the `offsetforleaderepoch` request is the one used to validate positions, basically retrieving epoch and end offsets from a leader, to validate the the current position held on the consumer side. makes sense? i will update the comments for each step.",0,0.9737548828125
1347759469,14406,junrao,2023-10-05T17:26:00Z,should the comment be moved to just above client.prepareresponse below? ditto in a few other places.,0,0.971325159072876
1347768459,14406,junrao,2023-10-05T17:34:57Z,is the upgrade on the server or the client side?,0,0.9859778881072998
1347777973,14406,lianetm,2023-10-05T17:43:31Z,i updated the comments in this other pr that i had just opened [a link],0,0.9823577404022217
1347791680,14406,junrao,2023-10-05T17:56:33Z,it would be useful to clarify that `fetchedrecords()` is called deep inside `fetcher.collectfetch()`. ditto in a few other places mentioning `fetchedrecords()`.,0,0.9854936003684998
1347799078,14406,kirktrue,2023-10-05T18:03:41Z,i'm planning to remove the comments and create a new jira to track this change. cc,0,0.97575843334198
1347806531,14406,junrao,2023-10-05T18:11:27Z,be consistent with usage of `this`.,0,0.9856554269790649
1347811905,14406,junrao,2023-10-05T18:17:09Z,where is the resizing?,0,0.9835980534553528
1347832688,14406,junrao,2023-10-05T18:40:09Z,its been => it has been,0,0.9639214277267456
1347834317,14406,junrao,2023-10-05T18:41:55Z,this seems unnecessary given the `assertemptyfetch` below?,0,0.9552420377731323
1347865054,14406,kirktrue,2023-10-05T19:14:43Z,todo: fix the comment in the code and explain about the applicationeventprocessor.,0,0.9874180555343628
1347874026,14406,kirktrue,2023-10-05T19:25:07Z,todo: find case where we _might_ be sending rpcs with empty sets.,0,0.9877689480781555
1347874693,14406,kirktrue,2023-10-05T19:25:55Z,todo: to create a separate ticket to review/fix.,0,0.9823494553565979
1347883272,14406,junrao,2023-10-05T19:35:43Z,could we write this as parameterized test to avoid duplicating the code in the next few tests?,0,0.9869338274002075
1347884952,14406,junrao,2023-10-05T19:37:30Z,should we assert there is no pending request after this?,0,0.9811913371086121
1347885711,14406,lianetm,2023-10-05T19:38:19Z,"i know for sure we skip empty lists and don't send requests for all the partition offsets related events (on the `offsetsrequestmanager` on [a link], [a link] and [a link]. that being said, here is about fetching the committed offsets, and i don't see a clear early return but maybe i'm missing how it happens so let's wait for to give it a closer look.",0,0.9757450222969055
1347894828,14406,junrao,2023-10-05T19:45:34Z,it would be useful to add a comment why offset is not reset yet on `offset_out_of_range`. this is because the error handling happens when new records are polled.,0,0.9891412258148193
1347906316,14406,junrao,2023-10-05T19:57:07Z,could this be replaced with `fetchrecordsinto`?,0,0.9890350699424744
1347908197,14406,junrao,2023-10-05T19:58:49Z,is this redundant given the test in 1811?,0,0.9745409488677979
1347910980,14406,junrao,2023-10-05T20:01:53Z,"hmm, why don't we return records from other partitions since maxrecords is maxint?",0,0.9808068871498108
1347913781,14406,junrao,2023-10-05T20:05:21Z,why don't we return records from tp1 since maxrecords is 2?,0,0.9740691781044006
1347914377,14406,junrao,2023-10-05T20:06:06Z,affect => effect,0,0.9828698039054871
1347923838,14406,junrao,2023-10-05T20:17:28Z,what's the purpose of this code? the receive is delayed and thus there is no throttledelayms received in the client.,0,0.9826853275299072
1347931744,14406,junrao,2023-10-05T20:26:15Z,why is `recordsfetchleadmin` different from `partitionlead` given there is only 1 assigned partition?,0,0.9767746329307556
1347936262,14406,junrao,2023-10-05T20:31:04Z,"`expectedbytes` is calculated as total, instead of avg. is this correct?",0,0.9874072074890137
1347938331,14406,junrao,2023-10-05T20:33:31Z,"the name is a bit mis-leading. we get a full response, but skipped an offset before the fetch position.",0,0.8357873558998108
1347960253,14406,junrao,2023-10-05T20:54:36Z,the expected and actual are reversed.,0,0.9819236397743225
1348009426,14406,kirktrue,2023-10-05T21:36:47Z,i filed kafka-15555 as a separate follow-up task to handle the wakeup mechanics.,0,0.9866204261779785
1348009622,14406,kirktrue,2023-10-05T21:37:03Z,i will remove the temporary comment in a bit.,0,0.9831138849258423
1348011353,14406,kirktrue,2023-10-05T21:39:43Z,removed.,0,0.9311882257461548
1348019537,14406,junrao,2023-10-05T21:45:42Z,capitalize in?,0,0.98371821641922
1348029408,14406,kirktrue,2023-10-05T21:58:16Z,"i have filed kafka-15556 (_remove networkclientdelegate methods isunavailable, maybethrowauthfailure, and tryconnect_) to address this issue since it's affecting other `requestmanager` implementations.",0,0.9837248921394348
1348029671,14406,kirktrue,2023-10-05T21:58:45Z,true. we'll handle that in kafka-15556.,0,0.9578835964202881
1348047927,14406,kirktrue,2023-10-05T22:14:19Z,i filed kafka-15557 (_fix duplicate metadata update in fetcher tests_) to address this issue.,0,0.9881870150566101
1348055761,14406,kirktrue,2023-10-05T22:21:17Z,created kafka-15558 (_determine if timer should be used elsewhere in prototypeasyncconsumer.updatefetchpositions()_) to address separately as the given implementation is the same as the current implementation. perhaps fixes in both `consumer` implementations is warranted?,0,0.9900346398353577
1348062340,14406,junrao,2023-10-05T22:22:48Z,node => note?,0,0.9851008057594299
1348062596,14406,kirktrue,2023-10-05T22:22:55Z,filed kafka-15551 (_evaluate conditions for short circuiting consumer api calls_) to implement this consistently.,0,0.9882664084434509
1348083698,14406,kirktrue,2023-10-05T23:00:07Z,"yes, it appears that it will continue to attempt to fetch from the old leader. when a fetch response is received from the broker and we notice that it has an error, we call `fetchcollector.handleinitializeerrors()` to deal with the different error conditions. when it notices that the error is `fenced_leader_epoch`, it will execute these two statements (from the `fetchutils.requestmetadataupdate()` method): [code block] that's all it does. the logic doesn't update the `fetchstate` for that partition. it doesn't clear out the leader epoch. nothing. the next time the user calls the `consumer.poll()` method, the `fetcher`/`fetchrequestmanager` will determine for which partitions we should issue `fetch` rpcs. the first step is to call the `subscriptionstate.fetchablepartitions()` method which checks each partition: [code block] because we didn't change anything in the underlying state of the partition in `subscriptionstate` previously, when the `topicpartitionstate.isfetchable()` method is invoked, it returns `true`. thus it is included in the list for which to fetch, and we will likely hit the same error.",0,0.9861598610877991
1348084921,14406,kirktrue,2023-10-05T23:02:32Z,the error message in `errors` for `fenced_leader_exception` states that this error is caused when...,0,0.947756290435791
1348087535,14406,kirktrue,2023-10-05T23:07:55Z,"naively it seems like we want to clear/reset the partition's `metadata.leaderandepoch` value in the metadata cache locally. then in the fetch logic, that would allow us to skip that partition when we check for the presence of a leader: [code block]",0,0.9078564643859863
1348088801,14406,junrao,2023-10-05T23:10:38Z,should this comment be moved to just above `client.prepareresponse` below?,0,0.9882027506828308
1348091800,14406,junrao,2023-10-05T23:16:50Z,not sure what we are testing here. which handler is this referring to?,0,0.5957670211791992
1348107483,14406,junrao,2023-10-05T23:44:11Z,"hmm, the consumernetworkthread shouldn't die because of a topicauthorizationexception, right? ditto below.",0,0.873288094997406
1348110728,14406,junrao,2023-10-05T23:51:45Z,which call is returning long.max_value?,0,0.9875962734222412
1348111165,14406,junrao,2023-10-05T23:52:48Z,does this test cover `testfindcoordinator`?,0,0.9888600707054138
1348903678,14406,junrao,2023-10-06T15:51:45Z,be consistent with the use of `this`. ditto below.,0,0.9790081977844238
1348915254,14406,junrao,2023-10-06T16:02:18Z,should we fix `this.records` above too?,0,0.9877002239227295
1348955876,14406,junrao,2023-10-06T16:31:47Z,this will run the network i/o in the application thread and break the model that all network i/os should be done in the background thread? will this be safe since now there could be two threads driving a shared networkclient?,0,0.9875388145446777
1348962486,14406,junrao,2023-10-06T16:38:11Z,called from by => called by,0,0.9834344983100891
1349023459,14406,junrao,2023-10-06T17:13:46Z,the auto offset commit seems to happen asynchronously? do we guarantee that the new owner of the unsubscribed partitions could pick up the latest committed offset?,0,0.9852851033210754
1349173413,14406,junrao,2023-10-06T18:18:01Z,"there is a subtle difference between transitioning to reset from initializing and transitioning to reset from `offsetoutofrangeexception` during fetch. in the latter, the application thread will call `fetchcollector.handleinitializeerrors()`. if there is no default offset reset policy, an `offsetoutofrangeexception` will be thrown to the application thread during `poll`, which is what we want. however, for the former, if there is no default offset reset policy, we simply ignore that partition through `offsetfetcherutils.getoffsetresettimestamp`. it seems in that case, the partition will be forever in the reset state and the application thread won't get the `offsetoutofrangeexception`.",0,0.9849557280540466
1349184330,14406,junrao,2023-10-06T18:28:19Z,"thanks, kirk. does the old consumer have the same behavior too? should we file a followup jira to improve this?",1,0.9492547512054443
1349221937,14406,philipnee,2023-10-06T19:11:48Z,"hi jun - i think we mostly use ""background thread"" in lieu of network thread, so maybe just use background thread?",0,0.8740948438644409
1349342751,14406,kirktrue,2023-10-06T21:44:50Z,"i will triple check, and if so, i will add a jira.",0,0.9845628142356873
1349343412,14406,kirktrue,2023-10-06T21:46:03Z,"i just pushed a proposed fix for this, which is basically to make the `fetchbuffer` thread safe. now there is only one fetch buffer for the consumer and is accessed by both threads.",0,0.9870679974555969
1349343753,14406,kirktrue,2023-10-06T21:46:49Z,you didn't see that i got fed up and changed the name of `defaultbackgroundthread` to `consumernetworkthread` :grinning_squinting_face:,-1,0.9218049049377441
1349361459,14406,junrao,2023-10-06T22:15:08Z,"1. this is an existing issue. but the way we handle paused partitions in `collectfetch` seems problematic. the application thread first calls `fetchbuffer.setnextinlinefetch(null)` and then calls `fetchbuffer.addall(pausedcompletedfetches)`. this could leave a brief window where the paused partition is not included in either `nextinlinefetch` or `completedfetches`. if the background thread kicks in in that window, it could have fetched another chunk for that partition and added the response back to fetchbuffer. this would violate the assumption there is no more than one pending `completedfetch` per partition in fetchbuffer and could cause records returned not in offset order or duplicates to be returned. 2. the second existing issue is on the `fetchbuffer.setnextinlinefetch` call in `collectfetch`. the issue is that after all records are drained from `nextinlinefetch`. we only call `setnextinlinefetch` when there is a new `completedfetch`. however, until the drained `completedfetch` is removed from `nextinlinefetch`, the background thread can't fetch the next chunk. so, it seems that we will just be stuck here.",0,0.9530750513076782
1350689034,14406,junrao,2023-10-09T18:46:55Z,should we just remove this method?,0,0.9785851240158081
1350697908,14406,junrao,2023-10-09T18:54:59Z,the only useful part of this call is to wake up the consumernetworkthread so that it could prefetch the next data chunk. perhaps we could make that an explicit call like `applicationeventhandler.wakeup`?,0,0.9866318106651306
1350700366,14406,junrao,2023-10-09T18:57:04Z,this call seems unnecessary.,0,0.518352746963501
1350703155,14406,junrao,2023-10-09T18:59:36Z,the comment seems obsolete since we are not fetching data below.,0,0.8428936004638672
1350707142,14406,junrao,2023-10-09T19:03:50Z,"`notemptycondition.await` returns false if the waiting time detectably elapsed before return from the method. this seems to be case to break out of the while loop. so, it seems that the `if` test should be reversed.",0,0.9850780963897705
1350773132,14406,junrao,2023-10-09T20:44:37Z,"currently, `fetchbuffer.setnextinlinefetch` and `fetchbuffer.poll` are separate operations and we expect the caller to call them in the right order to avoid a partition missing in fetchbuffer in the transition phase. it still leaves us with the situation that a partition could be in both completedfetches and nextinlinefetch at a particular time. it's not a problem for now, but it may be in the future. could we make them an atomic operation? if not, could we add a comment to document the correct usage of the api and the impact on partition being duplicated in completedfetches and nextinlinefetch?",0,0.9741135239601135
1351006437,14406,kirktrue,2023-10-09T23:58:22Z,removed.,0,0.9311882257461548
1351006470,14406,kirktrue,2023-10-09T23:58:29Z,done.,0,0.9759407639503479
1351011656,14406,kirktrue,2023-10-10T00:04:22Z,i removed the latter phrases to reduce confusion.,0,0.9813889861106873
1351011802,14406,kirktrue,2023-10-10T00:04:32Z,agreed. i've updated the names.,0,0.9807432889938354
1351042141,14406,kirktrue,2023-10-10T00:15:32Z,you're right. i've changed the core logic and updated that test (and another one that is essentially the same thing).,0,0.9485466480255127
1351054656,14406,kirktrue,2023-10-10T00:19:07Z,"yeah, i don't see it either. i'm not exactly sure what this testing is exercising. , do you remember?",-1,0.5216246247291565
1351063405,14406,kirktrue,2023-10-10T00:24:28Z,yes. i've removed `testfindcoordinator()` as it's now superfluous.,0,0.9865502119064331
1351064502,14406,kirktrue,2023-10-10T00:26:59Z,"these are constructors, so even though it's not _strictly_ needed, i've been following the standard java convention.",0,0.9841135144233704
1352874538,14406,kirktrue,2023-10-10T16:28:35Z,removed check to avoid.,0,0.9777241349220276
1352874719,14406,kirktrue,2023-10-10T16:28:44Z,done.,0,0.9759407639503479
1352876631,14406,kirktrue,2023-10-10T16:30:05Z,i've refactored the code to run it in the background thread again.,0,0.9865168333053589
1352879009,14406,kirktrue,2023-10-10T16:31:35Z,fixed.,0,0.9810503125190735
1357182316,14406,junrao,2023-10-12T17:43:47Z,not sure if this is a useful test since offsetsrequestmanager.resetpositionsifneeded() seems to never directly throw an exception?,0,0.9762203693389893
1357194942,14406,junrao,2023-10-12T17:55:19Z,"this needs to wait for the cleanup to be done until the timeout, right?",0,0.9716695547103882
1358651225,14406,kirktrue,2023-10-13T18:16:51Z,i removed the commented out code and explained why we need to use `runatclose()` instead of closing the fetcher directly.,0,0.9881888628005981
1358658187,14406,kirktrue,2023-10-13T18:19:15Z,"you are correct, sir. i removed those lines. thanks for the catch!",1,0.9819549918174744
1358665833,14406,kirktrue,2023-10-13T18:22:24Z,"the ordering and way they go about testing it is different. as this is an issue from the original `fetchertest`, i'll open a ticket to resolve separately. thanks!",1,0.9416133165359497
1358682245,14406,kirktrue,2023-10-13T18:33:16Z,"it looks like both. the test starts off mimicking a client that doesn't support topic ids. the test sets up the local subscriptions and metadata with a topic that has no id. then the test ""upgrades"" the client to a version that _does_ support topic ids. this is to validate that the fetch session (on the broker) should remove the topic without the id in favor of the topic with the id. and then the test ""downgrades"" the client again to ensure the opposite case. i haven't looked at the underlying code in any depth, however.",0,0.9664561152458191
1358693714,14406,kirktrue,2023-10-13T18:43:42Z,"`fetchedrecords()` calls `fetcher.collectfetch()`, so it's the other way around. i updated the call sites and changed `fetchedrecords()` to just `fetchrecords()` so that it's hopefully a little more clear.",0,0.985503613948822
1358701620,14406,kirktrue,2023-10-13T18:53:30Z,"i had removed most unnecessary uses of `this` in a previous round of updates, but left these because they were necessary. there are three tests that create a locally-scoped variable named `records` that masks the instance-scoped variable of the same name, hence the use of `this` to distinguish them. i've updated the tests to change the name of the local variable to `testrecords` so it's a) more clear that they're separate from `records`, and b) removes the use of `this`.",0,0.9828884601593018
1358712167,14406,kirktrue,2023-10-13T19:07:09Z,"the `testunauthorizedtopic()` test method was added to `fetchertest` almost eight years ago. here's what the test looked like when it was initially committed: [code block] the comment makes a little more sense when taken in its historical context. but it makes a little more sense still when you look at the test method that used to appear directly above `testunauthorizedtopic()`: [code block] my take is that the author copied the `testfetchrecordtoolarge()` to use as a starting point for the new `testunauthorizedtopic()` method. separately, although `testfetchrecordtoolarge()` is no longer around, we still test the 'record too large' case in `testfetchrequestwhenrecordtoolarge()`. i'm inclined to remove the comment because it's pretty clear that the intent of `testunauthorizedtopic()` is to validate that a `topicauthorizationexception` is thrown if the fetch response includes the `topic_authorization_failed` error. what do you think?",0,0.9730764627456665
1358713529,14406,kirktrue,2023-10-13T19:09:06Z,changed,0,0.9773849844932556
1358717315,14406,kirktrue,2023-10-13T19:14:04Z,correct. i've removed the unnecessary `fetchrecords()` call from `testpartialfetchwithpausedpartitions()` in both fetcher tests.,0,0.9875578880310059
1358758478,14406,kirktrue,2023-10-13T19:40:51Z,done.,0,0.9759407639503479
1358761112,14406,kirktrue,2023-10-13T19:43:39Z,done.,0,0.9759407639503479
1358764452,14406,kirktrue,2023-10-13T19:48:25Z,done.,0,0.9759407639503479
1358791361,14406,kirktrue,2023-10-13T20:21:36Z,"done. here's what i added: [code block] i'll admit, i don't know that i totally understand what i wrote or if it's correct :)",1,0.8081192970275879
1358832549,14406,junrao,2023-10-13T20:48:48Z,should the comment be moved to just above `consumernetworkthread.runatclose` below?,0,0.9878288507461548
1358914146,14406,kirktrue,2023-10-13T22:24:45Z,"i may be misunderstanding your comment, but the code to denote partitions as being revoked (via `subscriptionstate.markpendingrevocation()` will be handled in kafka-15539.",0,0.9701262712478638
1358914547,14406,kirktrue,2023-10-13T22:25:46Z,done.,0,0.9759407639503479
1358914571,14406,kirktrue,2023-10-13T22:25:51Z,done.,0,0.9759407639503479
1358918492,14406,kirktrue,2023-10-13T22:36:04Z,yes. done.,0,0.9706167578697205
1358949767,14406,kirktrue,2023-10-13T23:05:23Z,"i looked into this a bit, and it has to do with the records that are used for the different partitions, their counts, offsets, etc. i think it should be investigated and cleaned up for clarity and reassurance. i will open a new jira ticket since this is part of the existing `fetchertest` suite.",0,0.9657551050186157
1358952151,14406,kirktrue,2023-10-13T23:14:09Z,filed kafka-15606 to track.,0,0.9858712553977966
1358952187,14406,kirktrue,2023-10-13T23:14:15Z,added this to kafka-15606.,0,0.9860637784004211
1358953070,14406,kirktrue,2023-10-13T23:17:34Z,added a link to this question to kafka-15606.,0,0.985663115978241
1358953131,14406,kirktrue,2023-10-13T23:17:49Z,fixed,0,0.975196123123169
1358953536,14406,kirktrue,2023-10-13T23:19:06Z,i'll file a bug to investigate this question. thanks!,1,0.9747294187545776
1358953612,14406,kirktrue,2023-10-13T23:19:25Z,i'll file a bug to investigate this question. thanks!,1,0.9747294187545776
1358953637,14406,kirktrue,2023-10-13T23:19:31Z,i'll file a bug to investigate this question. thanks!,1,0.9747294187545776
1358954499,14406,kirktrue,2023-10-13T23:22:49Z,maybe `testfetchresponsemetricswithskippedoffset()`?,0,0.9871320724487305
1358955393,14406,kirktrue,2023-10-13T23:25:43Z,renamed and reversed.,0,0.9808120727539062
1358956176,14406,kirktrue,2023-10-13T23:28:19Z,changed `testreturnabortedtransactionsinuncommittedmode()` to `testreturnabortedtransactionsinuncommittedmode()`,0,0.9856942296028137
1358956462,14406,kirktrue,2023-10-13T23:29:46Z,fixed.,0,0.9810503125190735
1358956804,14406,kirktrue,2023-10-13T23:31:02Z,fixed,0,0.975196123123169
1358957417,14406,kirktrue,2023-10-13T23:32:34Z,i believe it is referring to the `runnable` that is passed into `setwakeuphook()`.,0,0.9829362630844116
1358990414,14406,kirktrue,2023-10-14T00:22:58Z,done.,0,0.9759407639503479
1358990445,14406,kirktrue,2023-10-14T00:23:03Z,done.,0,0.9759407639503479
1358990537,14406,kirktrue,2023-10-14T00:23:29Z,done. replaced with direct call to `applicationeventhandler.wakeup()`.,0,0.9882163405418396
1358990617,14406,kirktrue,2023-10-14T00:23:57Z,"we are not fetching, but we are waiting, so i reworded the comment. lmk if it still needs tweaking. thanks.",1,0.9211799502372742
1358990797,14406,kirktrue,2023-10-14T00:24:33Z,thanks for catching that. i fixed this but it's pretty clear now that i need unit tests to validate correctness.,1,0.9600780606269836
1360933149,14406,junrao,2023-10-16T16:27:06Z,"i made the comment when the code had a `fetchbuffer` in both `prototypeasyncconsumer` and `abstractfetch` since we need to apply the same check on `subscriptions.isfetchable` to both places. now, we only have a single fetchbuffer in `abstractfetch`. this is no longer an issue.",0,0.985309898853302
1360942134,14406,junrao,2023-10-16T16:34:07Z,unsentrequest => lastunsentrequest ?,0,0.984061062335968
1360995022,14406,junrao,2023-10-16T17:04:12Z,got it. this is referring to server side upgrade with topicid support.,0,0.9516242742538452
1360998263,14406,junrao,2023-10-16T17:07:32Z,fetchedrecords() => fetchrecords() ?,0,0.9879354238510132
1361004569,14406,junrao,2023-10-16T17:13:29Z,: thanks for the explanation. it makes sense to me to remove the comment here.,1,0.9011099338531494
1361103184,14406,junrao,2023-10-16T18:17:15Z,"thanks for updating the comment, kirk. the comment seems correct. it would be useful to further add that because the fetch position in the request is different from the one in fetch state, the fetched data, including the `offset_out_of_range` error is ignored in `fetchcollector.handleinitializeerrors` because of the following code. ` if (position == null || fetchoffset != position.offset) { ` it's a bit weird that the above check is only done for the `offset_out_of_range` error, instead of any error. it might be useful to file a jira to revisit this logic.",1,0.7418861389160156
1361109166,14406,junrao,2023-10-16T18:23:52Z,"yes, the proposed new name sounds good to me.",1,0.8127817511558533
1361131214,14406,junrao,2023-10-16T18:38:47Z,thanks for the reply. i still don't quite understand the test. why do we duplicate the following code both inside and outside of setwakeuphook? [code block] mockclient is only woken up through `networkclientdelegate.disconnectasync`.,1,0.8344206213951111
1361156117,14406,junrao,2023-10-16T19:05:33Z,the way the code is written. we will wake up `applicationeventhandler` whether fetch is empty or not. perhaps it's simpler to just always call `applicationeventhandler.wakeup()` after each `fetchcollector.collectfetch(fetchbuffer)` call?,0,0.9874901175498962
1361329379,14406,kirktrue,2023-10-16T22:36:19Z,i have filed kafka-15615 to resolve.,0,0.977837860584259
1361329900,14406,kirktrue,2023-10-16T22:37:18Z,"this is one of the more serious and subtle issues, so i want to know you're ok with the new approach before i resolve this conversation in the pr. thanks!",1,0.9770722389221191
1361332784,14406,kirktrue,2023-10-16T22:42:39Z,filed kafka-15617,0,0.9816529154777527
1361345756,14406,kirktrue,2023-10-16T23:07:23Z,"references were changed to either `fetchrequests` or `collectfetch` as appropriate. some minor refactoring was also introduced to use `assertthrows` instead, where possible.",0,0.9867432117462158
1361346244,14406,kirktrue,2023-10-16T23:08:26Z,removed.,0,0.9311882257461548
1361346884,14406,kirktrue,2023-10-16T23:09:43Z,changed.,0,0.9753402471542358
1361353808,14406,junrao,2023-10-16T23:23:31Z,": yes, the fix lgtm.",0,0.9826938509941101
1361355764,14406,kirktrue,2023-10-16T23:27:28Z,great :grinning_face_with_smiling_eyes: thanks!,1,0.9891288876533508
1361357104,14406,junrao,2023-10-16T23:29:55Z,the comment is a bit mis-leading since the fetcher doesn't block. it throws an exception.,0,0.9074305295944214
1361357218,14406,kirktrue,2023-10-16T23:30:05Z,can you chime in on this question? thanks!,1,0.9363298416137695
1361357318,14406,kirktrue,2023-10-16T23:30:16Z,can you chime in on this question? thanks!,1,0.9363298416137695
1361357471,14406,kirktrue,2023-10-16T23:30:32Z,can you chime in on this question? thanks!,1,0.9363298416137695
1361358097,14406,kirktrue,2023-10-16T23:31:42Z,"i am not fond of this code as written, and have made at least two attempts to change it. it's a bit messy but i will take another pass to clean it up. ideally most—if not all—of the logic would live in `fetchbuffer`.",-1,0.949540376663208
1361358254,14406,kirktrue,2023-10-16T23:32:03Z,"ok, i'll look at this again.",0,0.9767524600028992
1364694361,14406,kirktrue,2023-10-18T23:39:42Z,filed kafka-15634.,0,0.9824408888816833
1364696003,14406,kirktrue,2023-10-18T23:42:49Z,filed kafka-15635.,0,0.9826410412788391
1364698472,14406,kirktrue,2023-10-18T23:47:24Z,filed kafka-15636.,0,0.9830238223075867
1364699488,14406,kirktrue,2023-10-18T23:49:29Z,filed kafka-15637.,0,0.9822414517402649
1364700996,14406,kirktrue,2023-10-18T23:52:47Z,filed kafka-15638.,0,0.9823363423347473
1364704339,14406,kirktrue,2023-10-18T23:59:55Z,filed kafka-15639.,0,0.9824756383895874
1364706025,14406,kirktrue,2023-10-19T00:02:24Z,i removed the comment since there's a more explanatory comment below already.,0,0.9825466275215149
1364707771,14406,kirktrue,2023-10-19T00:04:26Z,done.,0,0.9759407639503479
1364712500,14406,kirktrue,2023-10-19T00:08:48Z,i've filed kafka-15640 to look into this in more detail.,0,0.9775227904319763
1364715414,14406,kirktrue,2023-10-19T00:13:45Z,i've added this to kafka-15640 for a dedicate effort to clean up the modifications to this data to make them atomic operations.,0,0.9871483445167542
1364758468,14406,kirktrue,2023-10-19T01:15:42Z,"i tried to update the comment, but ended up confused on how to explain it. because this looks like an existing issue that needs more investigation, i filed kafka-15641 to follow up.",0,0.8424894213676453
1366182334,14406,kirktrue,2023-10-19T21:59:35Z,both `kafkaconsumer` and `prototypeasyncconsumer` commit offsets asynchronously. i've filed kafka-15651 to review.,0,0.988200306892395
1366237460,14406,kirktrue,2023-10-19T23:37:40Z,"the issue is with how `offsetsrequestmanager.resetpositionsifneeded()` handles the call to `offsetfetcherutils.getoffsetresettimestamp()`. since `getoffsetresettimestamp()` may throw an exception, `offsetsrequestmanager` should catch it and forward it to the application thread. but instead, `offsetsrequestmanager` allows the error to bubble up to the `applicationeventprocessor`, which will then bubble it up to `consumernetworkthread`, which handles it by logging the error and exiting its `run()` method. in fact, this appears to be the intended behavior since `offsetsrequestmanagertest.testresetpositionsthrowspreviousexception()` explicitly tests that `offsetsrequestmanager.resetpositionsifneeded()` will throw the error directly at the caller. what needs to change is for `offsetsrequestmanager.resetpositionsifneeded()` to catch the exception and enqueue an `errorbackgroundevent` on the background event queue. in this way, the error will be processed on the application thread as part of `poll()`.",0,0.9852741956710815
1366237944,14406,kirktrue,2023-10-19T23:38:52Z,i don't see any existing unit tests which track the specific case that mentioned. i'm currently looking at the integration tests to see if those cover this case.,0,0.9789495468139648
1366262621,14406,kirktrue,2023-10-20T00:00:34Z,"yes. i've made the change that on `close()`, the application thread will wait for the network thread to finish its cleanup, up to the given timeout.",0,0.9881752729415894
1366266506,14406,kirktrue,2023-10-20T00:06:58Z,"unfortunately, there are no unit tests or integration tests which catch the offset reset case. i'll file a jira to have one concocted.",0,0.9317625761032104
1366267515,14406,kirktrue,2023-10-20T00:09:25Z,i've made the following changes: 1. now `offsetsrequestmanager` correctly enqueues errors from `getoffsetresettimestamp()` onto the background event queue for use by the application thread 2. renamed `offsetfetchertest`'s `testrestoffsetsauthorizationfailure()` to `testresetoffsetsauthorizationfailure()` 3. renamed `offsetsrequestmanagertest`'s `testresetpositionsthrowspreviousexception()` to `testresetoffsetsauthorizationfailure()` and updated its logic to ensure the expected error is present in the queue for the application thread to check in `poll()`,0,0.9740497469902039
1367260539,14406,junrao,2023-10-20T16:53:42Z,could we just redirect the implement to the constructor above?,0,0.9882662892341614
1367369975,14406,junrao,2023-10-20T18:27:18Z,would it be clearer to rename refreshcommittedoffsetsifneeded to initwithcommittedoffsetsifneeded?,0,0.9884017109870911
1367383773,14406,junrao,2023-10-20T18:44:13Z,"in `offsetfetcherutils.getoffsetresettimestamp()`, if there is no offset reset policy, currently we just ignore it. it seems that we should throw an exception in that case?",0,0.9839040040969849
1367498133,14406,kirktrue,2023-10-20T21:30:10Z,filed kafka-15652 to ensure that we have tests that catch this case.,0,0.980591356754303
1367508455,14406,kirktrue,2023-10-20T21:49:59Z,fixed.,0,0.9810503125190735
1367508628,14406,kirktrue,2023-10-20T21:50:19Z,done.,0,0.9759407639503479
1367510616,14406,kirktrue,2023-10-20T21:53:31Z,done.,0,0.9759407639503479
1367515674,14406,junrao,2023-10-20T22:03:20Z,"this doesn't seem quite right. it's possible for a fetchrequest to return no data. in that case, if we don't wake up the the network thread, it may not be able to send the next fetch request for a long time.",0,0.8174782395362854
1367516322,14406,junrao,2023-10-20T22:04:01Z,`wakeup` => `wakeupnetworkthread` ?,0,0.9881691932678223
1367517181,14406,kirktrue,2023-10-20T22:05:48Z,"there is a default offset reset strategy which is configured via `consumerconfig`, passed to the `kafkaconsumer`, and then to the `subscriptionstate`, right? why wouldn't we fall back to that if there's no overridden offset reset strategy for a particular partition?",0,0.9835079908370972
1367529409,14406,junrao,2023-10-20T22:33:26Z,"[a link] has 3 options: `latest`, `earliest`, `none`. it's possible for a user to choose `none`, which means ""throw exception to the consumer if no previous offset is found for the consumer's group"". but in that case, `offsetfetcherutils.getoffsetresettimestamp` just ignores that partition and won't reset it forever. we need to throw an exception so that the user knows. it's a bit of weird configuration since it means a consumer can't really consume for the very first time with this option. however, i tested it out with the existing consumer and it does throw an exception. [code block]",-1,0.870637059211731
1367535648,14406,kirktrue,2023-10-20T22:51:18Z,"i changed the `return null` to `throw new nooffsetforpartitionexception(partition)`. i re-ran the tests and nothing failed, so there seems to be another gap in the tests.",0,0.9706960916519165
1367536108,14406,kirktrue,2023-10-20T22:52:38Z,"the enqueuing of other events will also call `wakeupnetworkthread`, so it shouldn't be a problem. but i went ahead and changed it as requested.",0,0.9869824647903442
1367536128,14406,kirktrue,2023-10-20T22:52:43Z,done,0,0.9764507412910461
1367537583,14406,junrao,2023-10-20T22:56:48Z,could we just return empty here instead of calling collectfetch() again since the caller is in a loop and can call this method to collect fetch again?,0,0.987983226776123
1367545811,14406,junrao,2023-10-20T23:12:39Z,would it be clearer to rename `refreshcommittedoffsetsifneeded` to `initwithcommittedoffsetsifneeded`?,0,0.9876300692558289
1367556045,14406,kirktrue,2023-10-20T23:25:15Z,"the `refreshcommittedoffsetsifneeded()` name is derived from existing code in `kafkaconsumer` that calls out to `consumercoordinator.refreshcommittedoffsetsifneeded()`. if we change the method name in `prototypeasyncconsumer`, should we change `consumercoordinator`'s corresponding method name too?",0,0.9895998239517212
1367557772,14406,junrao,2023-10-20T23:32:12Z,"yes, in both cases, the method sets offsets for partitions in initializing state.",0,0.9882446527481079
1367559124,14406,kirktrue,2023-10-20T23:37:47Z,"yes, we could update `pollforfetches()` to simply return `fetch.empty()` at the end. however, there's code that intentionally blocks (for a little bit) waiting for fetch data to arrive in the buffer: [code block] also, each loop through `poll()` executes `updateassignmentmetadataifneeded()` before checking the fetch buffer for any data. that method does a lot of work (network i/o) that we'd ideally skip if we already have the data. perhaps we could update `awaitnotempty()` with a return flag so that the tail end of `pollforfetches()` can look something like this: [code block]",0,0.9302671551704407
1367562895,14406,junrao,2023-10-20T23:52:41Z,"thanks for the explanation, kirk. we can just leave the code as it is then.",1,0.925487220287323
1367565477,14406,kirktrue,2023-10-21T00:03:02Z,updated and a bit of cleanup.,0,0.9825928211212158
1370389793,14406,lianetm,2023-10-24T15:20:23Z,"i had missed a detail here. we're only implementing this with the default timeout, but not the overloaded one below, that has the timeout provided by the user. is there a reason or is it just that we missed the latter one? (same for the `listtopics`)",0,0.9456311464309692
1370452938,14406,lianetm,2023-10-24T15:58:23Z,(i guess it will be all part of the integration with the metadata calls right?),0,0.9864205121994019
1370486899,14406,kirktrue,2023-10-24T16:21:12Z,good call out. i don't know that the necessary topic plumbing code was written at that time. would you mind filing a bug to resolve?,1,0.8971825242042542
751663483,11390,ccding,2021-11-17T21:48:45Z,why do we remove `false` from the third parameter? the default is `true`,0,0.9844563603401184
751670345,11390,ccding,2021-11-17T21:59:29Z,why do we remove the keyword `override` here?,0,0.9715737700462341
751673278,11390,ccding,2021-11-17T22:04:21Z,is this change intentional?,0,0.9554193019866943
754749020,11390,satishd,2021-11-23T01:26:46Z,"good catch, fixed it.",1,0.9653019309043884
754749244,11390,satishd,2021-11-23T01:27:35Z,"intellij auto formatted, fixed it.",0,0.9861533641815186
755410314,11390,junrao,2021-11-23T18:38:36Z,is this change needed?,0,0.9830894470214844
755430690,11390,junrao,2021-11-23T19:08:52Z,"hmm, why do we want to eat the ioexception? ditto below.",0,0.7708157896995544
755446235,11390,junrao,2021-11-23T19:32:40Z,"does the parent cl have a super set of classpathes than the child? if so, is urls1 a subset of urls2?",0,0.9850851893424988
755523984,11390,junrao,2021-11-23T21:42:25Z,i the local log => in the local log,0,0.9849286675453186
755548648,11390,junrao,2021-11-23T22:22:25Z,listoffset returns the leaderepoch for the localstartoffset. could we just use that leaderepoch? it will simplify the code below.,0,0.9890599250793457
760490750,11390,junrao,2021-12-01T19:04:46Z,could we add remotelogmanager to the javadoc too?,0,0.9891595244407654
760491245,11390,junrao,2021-12-01T19:05:34Z,does this need to be volatile?,0,0.9769291281700134
760630665,11390,junrao,2021-12-01T22:49:37Z,indentation,0,0.982236921787262
760661057,11390,junrao,2021-12-01T23:54:44Z,could this case just be handled below for earliest_local_timestamp?,0,0.9888456463813782
760671044,11390,junrao,2021-12-02T00:20:02Z,could this be private?,0,0.9868327379226685
761506462,11390,junrao,2021-12-02T22:15:31Z,"we need to find the first segment matching the timestamp from the remote segments, then the local segments.",0,0.9862713813781738
761524592,11390,junrao,2021-12-02T22:50:20Z,fetchremoteindex() can take time. could we call this asynchronously so that we don't block the request handler thread?,0,0.9889442920684814
762123788,11390,junrao,2021-12-03T17:33:27Z,this may not matter for now. but it's probably better to use config.maxindexsize as the max index size.,0,0.9862398505210876
762126153,11390,junrao,2021-12-03T17:37:24Z,should >= be > ?,0,0.9840457439422607
762129356,11390,junrao,2021-12-03T17:42:27Z,could we add a description for this class?,0,0.9871527552604675
762138449,11390,junrao,2021-12-03T17:57:18Z,should we close inputstream when done?,0,0.9873522520065308
762171200,11390,junrao,2021-12-03T18:53:08Z,should we use a shutdownablethread?,0,0.9851598739624023
762176132,11390,junrao,2021-12-03T19:01:36Z,"the abort marker for offsets within the fetch range could be in subsequent log segments. so, we need to collect aborted transactions beyond the segment that the fetch offset resides.",0,0.9878074526786804
762183906,11390,junrao,2021-12-03T19:15:33Z,could we just call loadclass() once as in createremotestoragemanager()?,0,0.9893556237220764
762188249,11390,junrao,2021-12-03T19:23:09Z,could we add topicids to javadoc?,0,0.9885542988777161
762189948,11390,junrao,2021-12-03T19:26:06Z,could we reuse the method unifiedlog.remotelogenabled()?,0,0.989018976688385
762191856,11390,junrao,2021-12-03T19:29:25Z,should we just add remote_log_metadata_topic_name to topic.internal_topics?,0,0.9864375591278076
762193670,11390,junrao,2021-12-03T19:32:32Z,could we just get rid of filteredleaderpartitions as we have for followertopicpartitions?,0,0.985590934753418
762195818,11390,junrao,2021-12-03T19:36:31Z,"hmm, it seems that we only want to remove topicid when all partitions in the topic are removed?",0,0.973921537399292
762200473,11390,junrao,2021-12-03T19:44:52Z,does this need to be a concurrent map since there is no synchronization on access?,0,0.9806013107299805
762202911,11390,junrao,2021-12-03T19:49:17Z,"similar here, since fetch from remove storage can block, it would be better to do this asynchronously so that it doesn't block a request handler thread.",0,0.9862298965454102
762206303,11390,junrao,2021-12-03T19:55:19Z,should we also close all opened files in entries?,0,0.9874112010002136
762325936,11390,junrao,2021-12-03T22:36:03Z,"to use array(), we have to first check hasarray(). it's probably simpler to do buffer.put(logheaderbuffer).",0,0.9861867427825928
762355278,11390,junrao,2021-12-04T00:22:04Z,the code doesn't seem to check topicid.,0,0.9688301086425781
762355609,11390,junrao,2021-12-04T00:23:48Z,which request?,0,0.9793199896812439
762357821,11390,junrao,2021-12-04T00:34:25Z,"when receiving offset_moved_to_tiered_storage, we know the follower's offset is below leader's local start offset. it seems that we could directly ask for leader's local start offset instead of calling fetchlatestoffsetfromleader().",0,0.9889966249465942
762359179,11390,junrao,2021-12-04T00:41:01Z,it's less verbose to do [code block],0,0.9378782510757446
762362355,11390,junrao,2021-12-04T00:58:51Z,reloadsegments => reloadsnapshots ?,0,0.9868929982185364
762362423,11390,junrao,2021-12-04T00:59:17Z,is this needed since the caller calls this already?,0,0.9863511919975281
762364294,11390,junrao,2021-12-04T01:11:13Z,where is the logic to rebuild remotelogmetadatasnapshotfile?,0,0.9864047765731812
762366976,11390,junrao,2021-12-04T01:29:24Z,loading from remote storage could be expensive. it would be useful to do this asynchronously so that the replication thread can make faster progress on other partitions.,0,0.9582054018974304
762367379,11390,junrao,2021-12-04T01:32:13Z,do we want to include the change in fetchrequest too?,0,0.989086389541626
762367939,11390,junrao,2021-12-04T01:36:36Z,"it's not really ""by local timestamp"". it's localstartoffset.",0,0.9762638807296753
767417471,11390,satishd,2021-12-13T05:14:43Z,this is added to exclude any generated files by the tiered storage test runs.,0,0.9877973198890686
767425395,11390,satishd,2021-12-13T05:41:05Z,"it checks if the given resource exists within this class loader first, it delegates to the parent classloader if it is not found in this class loader.",0,0.9876123070716858
767426396,11390,satishd,2021-12-13T05:44:05Z,it is a `val` for now and it is not needed to be declared as volatile and the compiler does not allow too. this will be updated in the upcoming changes to `var` and then it can be declared as volatile.,0,0.9883825182914734
767427042,11390,satishd,2021-12-13T05:45:48Z,updated with shutdownablethread.,0,0.9845046997070312
767427379,11390,satishd,2021-12-13T05:46:46Z,this is an unused method. remotelogmanager handles going through subsequent segments and collect all aborted transactions. these changes will be added in the next pr. i will remove this unused method for now.,0,0.9875768423080444
767427546,11390,satishd,2021-12-13T05:47:16Z,"actually, that can still be improved. updated with the changes to avoid creating `classloaderawareremotestoragemanager` unnecessarily and calls going through classloader switching.",0,0.974800169467926
767427717,11390,satishd,2021-12-13T05:47:50Z,i plan to do that later. it requires the metadata topic configs to be built and auto topic creation manager needs to handle this topic creation etc.,0,0.9823606014251709
767428241,11390,satishd,2021-12-13T05:49:29Z,good point. changed it to use topicpartition instead of topic as we need to maintain a different data structure for all the partitions and need to synchronize between them. having concurrentmap of topicpartion with topicid is simpler to manage here.,1,0.9560291767120361
767428501,11390,satishd,2021-12-13T05:50:15Z,i will address in a followup pr.,0,0.9865137934684753
767428782,11390,satishd,2021-12-13T05:51:13Z,this cleansup all the earlier loaded snapshots. it loads the newly created snapshot.,0,0.9868495464324951
767430230,11390,satishd,2021-12-13T05:55:41Z,"`rlsmetadata = rlm.fetchremotelogsegmentmetadata(partition, epoch.get, leaderlocallogstartoffset)` returns empty and this method throws an error back to the caller here. it retries again until the required `rlsmetadata` is available. `remotelogmetadatasnapshotfile` is loaded when assigning of partitions are done as part of `topicbasedremotelogmetadatamanager.assignpartitions()`.",0,0.9866443276405334
767430483,11390,satishd,2021-12-13T05:56:24Z,i will address this in a followup pr.,0,0.9856172204017639
767434452,11390,satishd,2021-12-13T06:08:20Z,used `option.foreach` here. can you be more specific here?,0,0.9876421689987183
767435783,11390,satishd,2021-12-13T06:11:55Z,i will address this in a followup pr.,0,0.9856172204017639
767698400,11390,satishd,2021-12-13T12:08:40Z,updated the javadoc.,0,0.9852677583694458
768141997,11390,junrao,2021-12-13T21:38:33Z,should we remove this?,0,0.9739704728126526
772110652,11390,junrao,2021-12-20T06:38:21Z,was this comment addressed?,0,0.9810266494750977
772110800,11390,junrao,2021-12-20T06:38:43Z,the return value is not very intuitive. i'd expect a true return value to indicate that the request is handled successfully.,0,0.7602817416191101
772110895,11390,junrao,2021-12-20T06:38:56Z,could we add a comment on what this method does?,0,0.9854825735092163
772110978,11390,junrao,2021-12-20T06:39:11Z,"in the else case, should we truncate all local log?",0,0.9890425801277161
772111057,11390,junrao,2021-12-20T06:39:21Z,change from ` replicamgr.remotelogmanager.foreach(rlm => { } ) ` to ` replicamgr.remotelogmanager.foreach{rlm => } ` ditto in a few other places.,0,0.9855871200561523
772111223,11390,junrao,2021-12-20T06:39:45Z,"hmm, the remote data could end at leaderlocallogstartoffset - 1. in that case, we won't find a corresponding rlsmetadata.",0,0.9877741932868958
772111916,11390,junrao,2021-12-20T06:41:23Z,"this is kind of awkward and inefficient. could we add a better api to avoid the trial and error approach? for example, we could have an api that waits for the remote log segment metadata up to offset leaderlocallogstartoffset - 1 becoming available with leader epoch less than or equal to currentleaderepoch.",-1,0.9481866359710693
772111987,11390,junrao,2021-12-20T06:41:35Z,it's awkward to stream into a temp file only to load it back in memory.,-1,0.6821082830429077
773121075,11390,satishd,2021-12-21T13:08:06Z,"updated the comment, we do not really need to have a check here. let me know if i am missing anything here.",0,0.9742977619171143
773121400,11390,satishd,2021-12-21T13:08:36Z,addressed it in the latest commit.,0,0.9826589822769165
773121903,11390,satishd,2021-12-21T13:09:20Z,this is inline with `handleoutofrangeerror` contract. i am fine with the suggested change but it is good to have similar semantics to `handleoutofrangeerror` method too for uniformity.,0,0.920296847820282
773122505,11390,satishd,2021-12-21T13:10:13Z,good point. i updated it to address this scenario too in the latest commit.,1,0.9662412405014038
773123927,11390,satishd,2021-12-21T13:12:13Z,changed it to use the leader epoch of leader's local-log-start-offset and find the respective earlier epoch for (leader's local-log-start-offset -1) from the leader.,0,0.987975001335144
773143045,11390,satishd,2021-12-21T13:39:14Z,filed [a link] to add the suggested improvement.,0,0.9841126799583435
773499214,11390,wyuka,2021-12-21T23:16:35Z,shouldn't this method be called `setremotelogmanager(...)`?,0,0.9806849956512451
778990618,11390,ccding,2022-01-05T17:08:02Z,`local-log-start-timestamp` instead of `local-log-start-offset` in the comment?,0,0.9884783625602722
779060541,11390,junrao,2022-01-05T18:52:06Z,"when we hit offsetoutofrangeexception, it's possible that remote storage is enabled. in that case, we also need to rebuild the remote log metadata.",0,0.9889918565750122
779089066,11390,ccding,2022-01-05T19:40:31Z,is it possible to make `topic.isinternal(topicpartition.topic())` to return true if `topicbasedremotelogmetadatamanagerconfig.remote_log_metadata_topic_name.eq(topicpartition.topic()))`? then we can get rid of the `topicbasedremotelogmetadatamanagerconfig.remote_log_metadata_topic_name.eq(topicpartition.topic()))` check,0,0.9779472947120667
779142706,11390,ccding,2022-01-05T21:17:24Z,do we need to log if there are any exceptions? or throw the exception out?,0,0.9840519428253174
779158936,11390,ccding,2022-01-05T21:47:49Z,is there any reason for not using the existing suffixes? [a link],0,0.9823071360588074
779162870,11390,ccding,2022-01-05T21:55:20Z,should the error message be `cleaned up`?,0,0.9826541543006897
779166585,11390,ccding,2022-01-05T22:02:35Z,why do we use `coreutils.tryall` in one case and use `array().foreach( try catch )` in the other case?,0,0.9879095554351807
779169864,11390,ccding,2022-01-05T22:09:02Z,"we can use `val dirname = ""remote-log-index-cache""` here",0,0.9875356554985046
779171925,11390,ccding,2022-01-05T22:13:11Z,what is the trade-off between using a daemon thread and using kafka scheduler?,0,0.9785968065261841
779175283,11390,ccding,2022-01-05T22:20:08Z,[code block] i think we don't need to flush the parent dir. it doesn't matter if the cache file is not renamed during an unclean shutdown.,0,0.9826610684394836
779177001,11390,junrao,2022-01-05T22:23:44Z,space after if.,0,0.9810567498207092
779177082,11390,ccding,2022-01-05T22:23:57Z,do we need to log/handle exception caused by fetchandcreateindex,0,0.9896695017814636
779191474,11390,junrao,2022-01-05T22:55:27Z,"topicbasedremotelogmetadatamanager independently updates the metadata state from the tier topic. when we make the `rlm.fetchremotelogsegmentmetadata` call, how does it make sure that it has caught up enough records from the tier topic including the segment covering the requested offset?",0,0.9889587163925171
779191948,11390,ccding,2022-01-05T22:56:38Z,"wanted to double check you mean `log.remotelogenabled()` or `!log.remotelogenabled()` here, because it is `filternot`",0,0.9829018115997314
779192232,11390,ccding,2022-01-05T22:57:20Z,"`log.remotelogenabled()` already checks internal and equals remote_log_metadata_topic_name, do we need to check again here?",0,0.9846732020378113
779196455,11390,junrao,2022-01-05T23:07:36Z,"endoffset is exclusive. so, we could just use leaderlogstartoffset.",0,0.9864912033081055
779199654,11390,junrao,2022-01-05T23:15:45Z,should we use foreach instead of map?,0,0.9864417314529419
779200299,11390,junrao,2022-01-05T23:17:30Z,should we flush the leader epoch file at the end?,0,0.9868266582489014
779213401,11390,junrao,2022-01-05T23:55:08Z,should we write the producer snapshot to a temp file first and then rename?,0,0.9874727725982666
779216639,11390,junrao,2022-01-06T00:05:34Z,"it possible that the endoffset in rlsmetadata is larger than leaderlocallogstartoffset. if we fetch the local log from leaderlocallogstartoffset, duplicated tnx could be added to producerstatemanager. it's better to start fetching from rlsmetadata.endoffset + 1.",0,0.9810900092124939
779223560,11390,junrao,2022-01-06T00:26:56Z,this is the top level error. unknown_topic_id and inconsistent_topic_id are partition level errors and don't need to be handled here.,0,0.9824749827384949
779233183,11390,junrao,2022-01-06T00:57:41Z,why does this method need to be protected instead of private? ditto for fetchoffsetandbuildremotelogauxstate.,0,0.9813832640647888
784750507,11390,satishd,2022-01-14T10:57:46Z,we have not yet made `topicbasedremotelogmetadatamanagerconfig.remote_log_metadata_topic_name` as internal topic. i plan to make this change once it is created as an internal topic.,0,0.9827318787574768
784751134,11390,satishd,2022-01-14T10:58:44Z,we do not want to log here. it should be handled by the invoker.,0,0.95787113904953
784753702,11390,satishd,2022-01-14T11:02:40Z,there is no specific reason other than having a shorter suffix. i do not have a strong opinion on that. i am fine with eitherways.,-1,0.6559311747550964
784764008,11390,satishd,2022-01-14T11:18:34Z,"in the earlier case, we want the exception to be thrown with the exception as mentioned in `coreutils.tryall`. but in this case, we want to catch each invocation and ignore it instead of collecting like coreutils.tryall.",0,0.9865630865097046
784768268,11390,satishd,2022-01-14T11:25:20Z,"no, we want to throw it back so that invoker can handle it.",0,0.9819071888923645
784770314,11390,satishd,2022-01-14T11:28:57Z,nice catch!!,1,0.9914939403533936
784772939,11390,satishd,2022-01-14T11:33:21Z,"good point, i am making a simpler check here to use `filter`. [code block]",1,0.8462312817573547
784793287,11390,satishd,2022-01-14T12:08:32Z,we do not need to flush it as`cache.assign` already flushes the entry.,0,0.9886733889579773
784793923,11390,satishd,2022-01-14T12:09:39Z,"sure, it is good to do that. addressed it in the latest commit.",1,0.9505448937416077
784801502,11390,satishd,2022-01-14T12:22:42Z,"if it does not catchup then it returns `optional.empty`, and that we throw a remotestorageexception. as the caller receives remotestorageexception, it will be retried again.",0,0.9822435975074768
785875887,11390,satishd,2022-01-17T11:19:35Z,"in that case, i prefer to use '>' instead of '>=' like below. this is more clear and easy to read. i have also added a comment to talk about a case in leader epoch gap. [code block]",0,0.9698142409324646
786517360,11390,satishd,2022-01-18T08:36:13Z,"i refactored `assign` whether to flush or not with default as true for backward compatibility. in this case, i assign all the entries without flush, and flush to the file at the end.",0,0.9892528653144836
786518882,11390,satishd,2022-01-18T08:38:15Z,"we encounter `offsetoutofrangeexception` only when the offsets are beyond the range of [logstartoffset, logendoffset]. why do we need to build remote log metadata in that case? i may be missing something here.",0,0.9880686402320862
786736586,11390,satishd,2022-01-18T13:01:15Z,good point! made the respective changes in the latest commit.,1,0.9803080558776855
788215466,11390,junrao,2022-01-19T22:58:55Z,space after if,0,0.9781984090805054
788253183,11390,junrao,2022-01-20T00:23:47Z,"if we hit offsetoutofrangeexception, we call fetchearliestoffsetfromleader() inside fetchoffsetandapplyfun(), which fetches the localstartoffset. we then truncate the whole log and start fetching from localstartoffset. if the leader has data in remote storage, the follower won't have the remote log metadata for consumer fetch and won't have the same state (e.g. producer state) as the leader.",0,0.9879952073097229
788269196,11390,junrao,2022-01-20T01:02:58Z,fetchearlierepochendoffset(3) => fetchearlierepochendoffset(2) ?,0,0.9855172038078308
788270782,11390,junrao,2022-01-20T01:07:16Z,"it's possible for the local data to overlap a bit with what's in the remote storage. so, leaderlocallogstartoffset - 1 is not necessarily the highest offset in remote storage. could we name highestoffsetinremotefromleader more properly?",0,0.9887999296188354
788279027,11390,junrao,2022-01-20T01:29:23Z,we need to return nextoffset to the caller so that fetchoffsetandapplyfun() could set the next fetch offset to this.,0,0.9886323809623718
789307564,11390,wyuka,2022-01-21T02:46:58Z,we can use [code block] instead,0,0.9886216521263123
789308168,11390,wyuka,2022-01-21T02:48:04Z,we can use [code block] instead,0,0.9886216521263123
791322611,11390,satishd,2022-01-25T03:10:39Z,"sure, as we discussed offline, i added the approach to keep offsetoutofrange like earlier, which is to fetch the log-start-offset and it may get a response of offsetmovedtotieredstorage if it tries to fetch from log-start-offset and it is moved to tiered storage.",0,0.9879953265190125
791957579,11390,yyang48,2022-01-25T17:28:55Z,"just curious, why we need to read this value from the buffer and discard it immediately?",0,0.9580687880516052
791968984,11390,yyang48,2022-01-25T17:42:00Z,"i'm not sure whether this buffer is big enough or not? from the line 58: the size of the buffer is the record content size + 12. however, from the line 34, the logheaderbuffer is: 17. in the line 59, if we put the entire logheaderbuffer to this buffer, in the worse case, we need 5 bytes more space in the capacity. is this correct?",0,0.9805909991264343
796465473,11390,satishd,2022-02-01T10:40:54Z,good point. it is not really needed. looks like it was added earlier to log offset but the log was removed.,1,0.9319716691970825
796479255,11390,satishd,2022-02-01T10:58:08Z,"no, we do not really need more space here. i updated with more comments in the code on how it works. this is aligned with the existing code in other places like `filechannelrecordbatch`. payload : log_overhead + 4 + 1 (magic:byte) + reocrd-content log_overhead = 8(offset:long) + 4(size:int) = 12 `size` = 4 + 1(magic) + record-content-size. `logheaderbuffer` is read until magic. that is why the complete buffer-size is 12(log_overhead) + size. we do not count ""4 + 1(magic)"" here as it is already taken into account with size_read_from_header",0,0.9689391255378723
804020896,11390,junrao,2022-02-10T19:07:26Z,should we complete the javadoc? ditto for fetchearliestoffsetfromleader().,0,0.5574195384979248
804023336,11390,junrao,2022-02-10T19:10:45Z,could we add the javadoc for this one?,0,0.9879046082496643
804025075,11390,junrao,2022-02-10T19:13:07Z,"is ""related to offsets out of rage"" true? also, since we explained this error, do we need the error code?",0,0.9493553042411804
804026471,11390,junrao,2022-02-10T19:15:03Z,"is ""handle the offset out of range error"" true?",0,0.9863446950912476
804030400,11390,junrao,2022-02-10T19:20:34Z,"could we make it clear that the reason that we don't need to backoff and retry is because we move the partition to a failed state? also, could we put true in a separate line? ditto for handleoutofrangeerror().",0,0.8462004661560059
804042686,11390,junrao,2022-02-10T19:37:27Z,"the above long comment doesn't quite fit into remote storage. we could make it more general that covers both cases. if that's too complicated, perhaps have a separate method just for handling remote storage.",0,0.9730298519134521
804145767,11390,junrao,2022-02-10T21:59:14Z,could we change earliestorlatest to sth more generic now that it can have 3 values?,0,0.987631618976593
804149120,11390,junrao,2022-02-10T22:00:51Z,there is no leader epoch before 0.10. so the leader epoch can just be -1.,0,0.986528754234314
804186063,11390,junrao,2022-02-10T22:32:48Z,"this call writes another snapshot, which is unnecessary. perhaps we could just do producerstatemanager.truncateandreload()?",0,0.9852395057678223
804191359,11390,junrao,2022-02-10T22:38:43Z,"if we get here, it means the leader has started tiering the data but the follower hasn't received the remotestorageenable config yet. it seems that we should backoff and retry the same offset instead of just fetching from leaderlocallogstartoffset?",0,0.988352358341217
804196978,11390,junrao,2022-02-10T22:45:04Z,this is not just an offset index.,0,0.9785529375076294
804200819,11390,junrao,2022-02-10T22:49:26Z,why is this called cleanableindex? it's bit confusing given log cleaner. maybe sth like baseindex?,-1,0.6120241284370422
804201757,11390,junrao,2022-02-10T22:50:32Z,time stamp => timestamp,0,0.9832715392112732
804203296,11390,junrao,2022-02-10T22:52:28Z,space after if,0,0.9781984090805054
804223128,11390,junrao,2022-02-10T23:14:55Z,"hmm, it's kind of weird to set the class loader on each call. is this needed? do other remote storage classes just use the classloader for rlm and rlmm?",-1,0.984504222869873
804234045,11390,junrao,2022-02-10T23:27:08Z,the original configs in config may contain implementation specific properties. how do we pass those to rlmm and rlm through remotelogmanager?,0,0.9888700246810913
804239401,11390,junrao,2022-02-10T23:33:20Z,it seems that we never add to topicpartitionids?,0,0.978762686252594
804245130,11390,junrao,2022-02-10T23:43:38Z,"in the local case, if all the messages in the remote storage have larger timestamps, it seems that we return the timestamp of the first message.",0,0.9871642589569092
804245833,11390,junrao,2022-02-10T23:45:16Z,could we call maybeepoch.get() once in the loop?,0,0.9877369403839111
804250739,11390,junrao,2022-02-10T23:56:46Z,previousepoch?,0,0.9841921329498291
804250861,11390,junrao,2022-02-10T23:57:03Z,nextepoch?,0,0.9858139157295227
804250995,11390,junrao,2022-02-10T23:57:19Z,epochentry?,0,0.9836751818656921
804251574,11390,junrao,2022-02-10T23:58:41Z,should previousepoch be initialize to none?,0,0.984454333782196
804252215,11390,junrao,2022-02-11T00:00:12Z,this seems unused?,0,0.9358466863632202
804252997,11390,junrao,2022-02-11T00:02:09Z,it's not really local timestamp.,0,0.9267411828041077
804265970,11390,junrao,2022-02-11T00:35:38Z,"should we load up existing files to entries during init()? otherwise, it's not clear when they will be cleaned up.",0,0.9758843183517456
804266325,11390,junrao,2022-02-11T00:36:47Z,should we close the indexes too?,0,0.9855108261108398
804266637,11390,junrao,2022-02-11T00:37:38Z,this is never read?,0,0.9120692014694214
804267665,11390,junrao,2022-02-11T00:40:18Z,is this safe? the entry could be cleaned immediately after this check.,0,0.9846633672714233
804268708,11390,junrao,2022-02-11T00:43:07Z,rewind() is typically used after the buffer is written. should we use clear()?,0,0.9892566800117493
804270391,11390,junrao,2022-02-11T00:47:41Z,was this comment addressed?,0,0.9810266494750977
804274827,11390,junrao,2022-02-11T01:00:19Z,"this is not supported yet, right? should we throw an exception?",0,0.9778792262077332
804275488,11390,junrao,2022-02-11T01:02:03Z,should we just throw unsupportedexception?,0,0.9526726007461548
804277844,11390,junrao,2022-02-11T01:09:06Z,no need to pass in reloadfromcleanshutdown since it's always false?,0,0.9787847399711609
804280439,11390,junrao,2022-02-11T01:16:55Z,this seems an indirect way to check message version. should we just check that explicitly?,0,0.9832180738449097
804281396,11390,junrao,2022-02-11T01:19:46Z,"hmm, locallogstartoffset could change after the call the remotelogmanager.",0,0.9882851839065552
804843541,11390,junrao,2022-02-11T17:03:42Z,"for other broker side plugins (e.g. authorizer), we never needed a special class loader. why do we need this for the remote storage plugin?",0,0.9864647388458252
812537683,11390,satishd,2022-02-23T03:44:29Z,"this is to avoid library conflicts directly or indirectly with the existing libraries in the system classpath. this classloader loads the libraries in the given paths. whenever a class needs to be loaded, it delegates to the system classloader only when it is not found in the configured paths. rsm or rlmm providers can have all the required libraries in given directories and add them as classpath for rsm or rlmm. this provides isolation with the libraries in the system classpath.",0,0.986016571521759
813156759,11390,junrao,2022-02-23T17:48:17Z,"yes, i understand the intent. however, there are quite a few pluggable components on the broker side right now. sorting out the classpath dependencies among all of them seems quite complicated. another way to solve the issue is through shading. a potential conflicting library could be renamed to a different package.",0,0.9231340885162354
814028646,11390,satishd,2022-02-24T16:00:43Z,updated the statement and the error code is removed.,0,0.9787471890449524
814031095,11390,satishd,2022-02-24T16:03:07Z,"sure, i also updated the method to return true if it was able to handle it.",0,0.9871605634689331
814036592,11390,satishd,2022-02-24T16:09:03Z,`responsepartition.leaderepoch` returns -1 with <= kafka_0_10_1_iv2 version. no need to explicitly set it as -1.,0,0.9847789406776428
814039902,11390,satishd,2022-02-24T16:12:30Z,`remotelogmanagerconfig#remotestoragemanagerprops()` and `remotelogmanagerconfig#remotelogmetadatamanagerprops()` return respective properties which are used while configuring rsm and rlmm in `remotelogmanager#configurersm()` and `remotelogmanager#configurerlmm()`.,0,0.9862610697746277
814041397,11390,satishd,2022-02-24T16:13:59Z,this code missed while merging other changes. addressed with the latest commit.,0,0.9803555011749268
814045120,11390,satishd,2022-02-24T16:17:57Z,changed it to `version 8 enables listing offsets by local log start offset.`,0,0.9864764213562012
814046367,11390,satishd,2022-02-24T16:19:15Z,we do not need to explicitly close them as they are already closed inside `deleteifexists()` method.,0,0.9843757748603821
814050149,11390,satishd,2022-02-24T16:23:14Z,"this is used in dowork(), updated with the latest commit.",0,0.9887464642524719
814127632,11390,satishd,2022-02-24T17:53:23Z,good catch!! i will address it.,1,0.993389368057251
814640948,11390,kowshik,2022-02-25T10:10:57Z,"this class is slim in functionality, and i don't feel there is any real benefit for introducing this. also for the future, it is not clear to me what operations can be included in this class, and which ones can't be. i feel that the earlier design without this base class was simpler. are we planning to add new functionality in the future into this class?",-1,0.7121567130088806
814642656,11390,kowshik,2022-02-25T10:13:11Z,"lets rename `x` to something more readable, ex: `index`.",0,0.9882241487503052
814658812,11390,kowshik,2022-02-25T10:35:11Z,s/related to offset moved to tiered storage/offset_moved_to_tiered_storage can we also log the topicpartition?,0,0.9895819425582886
814660162,11390,kowshik,2022-02-25T10:37:09Z,"this method `fetchoffsetandapplytruncateandbuild` is currently doing a number of things, which is clear from the method name. it will be hard to cover all test cases in unit test. so, it is better if its simplified.",0,0.9846363067626953
814668927,11390,kowshik,2022-02-25T10:50:08Z,"here to build the remote log aux state we only need the leader local log start offset, right? in such a case, i think it gets complicated if we try to repurpose `fetchoffsetandapplytruncateandbuild` here. can we just introduce a separate method that would just attempt to get the leader's local log start offset, and pass it into `buildremotelogauxstate`?",0,0.9776509404182434
814678429,11390,kowshik,2022-02-25T11:04:36Z,"this method is doing a lot of things, and it is worthwhile thinking about how to simplify it. in its current form, it is going to be hard to test it.",0,0.7562339305877686
814981129,11390,junrao,2022-02-25T18:00:33Z,"i was referring to ""the timestamp will be message.notimestamp"". it should be the timestamp of the first message.",0,0.9801869988441467
818028561,11390,junrao,2022-03-02T19:29:10Z,"the purpose of a special class loader is to address potential class conflicts. if the same class exists btw the plugin and kafka, by switching the class loader, it seems that we don't know deterministically which version of the class will be loaded, which can be confusing.",0,0.9324577450752258
898097965,11390,divijvaidya,2022-06-15T15:02:56Z,the comment does not match the functionality for the function here. this implementation only performs delete.,0,0.9498464465141296
981140295,11390,divijvaidya,2022-09-27T11:51:53Z,nit i would suggest to move `testutils.resource` to `utils` and use that to mimic java's try-with-resource in scala.,0,0.9894037246704102
981150239,11390,divijvaidya,2022-09-27T12:02:42Z,"this could be refactored into a method in leaderepochcache, perhaps with signature `assign(seq(epochentry))`",0,0.9891130924224854
981152254,11390,divijvaidya,2022-09-27T12:04:55Z,"do we want to clear the existing cache first using `cache.clearandflush()`? asking because (and correct me if i am wrong) in the case of uncleanleaderelection, this follower may have log lineage belonging to previous leader. the new leader may have a different log lineage which doesn't contain epochs present in old lineage. those epochs absent missing in new lineage need to be removed from the cache.",0,0.9778429865837097
983849860,11390,divijvaidya,2022-09-29T17:39:05Z,this offset is the `last-tiered-offset + 1` and not the `local-log-start-offset`. please correct me if i am wrong but this is inconsistent with what is described in the kip-405 where we say:,0,0.961871325969696
985706396,11390,satishd,2022-10-03T12:06:00Z,this offset is not `last-tiered-offset + 1` but `previousoffsettoleaderlocallogstartoffset` which is `leaderlocallogstartoffset - 1`. this is aligned with what we mentioned in kip-405. you can take a look at the usage of `mayberlsm` which is [code block],0,0.9868823885917664
1025959204,11390,showuon,2022-11-18T03:46:54Z,nit: add a space before `new rcordheader`,0,0.9887162446975708
1026063322,11390,showuon,2022-11-18T06:18:22Z,nit: remotestoragesystemenable -> remotestoragesystemenable[d],0,0.96703040599823
1026064974,11390,showuon,2022-11-18T06:22:09Z,nit: remote logging -> remote log,0,0.9869009852409363
1026065351,11390,showuon,2022-11-18T06:22:57Z,should we also check `__cluster_metadata` topic? it isn't checked in `isinternal`,0,0.9888970255851746
1026079869,11390,showuon,2022-11-18T06:48:22Z,nit: remotestoragesystemenable -> remotestoragesystemenable[d],0,0.96703040599823
1026086446,11390,showuon,2022-11-18T07:01:21Z,"there will be background thread to delete them later, right? i don't think this is necessary.",0,0.9555023908615112
1026087680,11390,showuon,2022-11-18T07:03:42Z,where's the implementation?,0,0.9849568009376526
1026095589,11390,showuon,2022-11-18T07:18:10Z,"this `computifabsent` method might do 3 `fetchandcreateindex` for all 3 indexes, which will take many time, inside the lock. could we fetch them before we lock the `entries`?",0,0.9889523386955261
1026097879,11390,showuon,2022-11-18T07:21:53Z,forgot to add javadoc for 3 parameters,0,0.7711050510406494
1026112608,11390,showuon,2022-11-18T07:44:38Z,"the implementation of `lookuptimestamp` above is also returning the `the timestamp of the first message.`. so, only javadoc needs to be updated",0,0.9883634448051453
1026121749,11390,showuon,2022-11-18T07:57:35Z,nit: additional comma at the end,0,0.9874797463417053
1026133917,11390,showuon,2022-11-18T08:14:42Z,updated partition fetch state,0,0.9881270527839661
1026146723,11390,showuon,2022-11-18T08:28:16Z,agree. there must be something wrong here. error log is also necessary.,0,0.9734463691711426
1026150319,11390,showuon,2022-11-18T08:32:22Z,nit: the indent is not quite right here,0,0.8672190308570862
1026173480,11390,showuon,2022-11-18T08:57:36Z,nit: give a change -> chance?,0,0.9652916193008423
1026175979,11390,showuon,2022-11-18T09:00:20Z,ditto,0,0.8428916931152344
1026242726,11390,showuon,2022-11-18T10:02:31Z,"i think it should `mock the segment of offset 0-4 moved to remote store.`, right?",0,0.9848706126213074
1026243503,11390,showuon,2022-11-18T10:03:18Z,ditto,0,0.8428916931152344
1032869910,11390,satishd,2022-11-27T05:35:05Z,we were doing that earlier but you suggested to do normal truncation until local-log-start-offset as mentioned [a link].,0,0.9890069961547852
1032869957,11390,satishd,2022-11-27T05:36:00Z,this is addressed with the latest changes.,0,0.98341965675354
1032870167,11390,satishd,2022-11-27T05:38:00Z,we can keep it simple for now as you suggested. removed baseindex for now but we may add it later if needed.,0,0.9844439029693604
1032870377,11390,satishd,2022-11-27T05:39:57Z,adding space fails with style-check.,0,0.8376154899597168
1032870521,11390,satishd,2022-11-27T05:41:05Z,this is the existing convention used in other properties like unclean.leader.election.enable etc,0,0.9790500998497009
1032870562,11390,satishd,2022-11-27T05:41:34Z,this is the existing convention used in other properties like unclean.leader.election.enable etc,0,0.9790500998497009
1032870593,11390,satishd,2022-11-27T05:42:27Z,these are not loaded as entries marked for deletion. it is good to delete them any pending deletions when a broker is started.,0,0.9647720456123352
1032870604,11390,satishd,2022-11-27T05:42:41Z,it is addressed with the latest set of commits.,0,0.984159529209137
1032871126,11390,satishd,2022-11-27T05:49:04Z,changed the text to make it more clear.,0,0.97690749168396
1032871130,11390,satishd,2022-11-27T05:49:09Z,changed the text to make it more clear.,0,0.97690749168396
1032944075,11390,satishd,2022-11-27T14:45:54Z,leaderepochcache is already cleaned up by the earlier `truncatefullyandstartat` call.,0,0.9874976873397827
1032945780,11390,satishd,2022-11-27T14:57:26Z,i will address in the next commit.,0,0.9871234893798828
1033092123,11390,showuon,2022-11-28T03:31:34Z,any reason why we don't want to `extends closeable` here?,0,0.980156660079956
1033093221,11390,showuon,2022-11-28T03:34:54Z,"i saw we already updated the `_locallogstartoffset` in `maybeincrementlogstartoffset` method. if you know there are some other places we also need to update it, maybe you can make it much clear in the comment.",0,0.9870748519897461
1033097357,11390,showuon,2022-11-28T03:45:59Z,fair enough,0,0.9163533449172974
1033136878,11390,showuon,2022-11-28T05:22:04Z,should we lock it?,0,0.9793753027915955
1033141283,11390,showuon,2022-11-28T05:32:56Z,"thanks for the update, but i think we still lock for the period of loading 3 index files. how about this: [code block] wdyt?",0,0.6538283228874207
1033492033,11390,satishd,2022-11-28T12:38:45Z,"added closeable as part of this pr, and we do not really need it with the latest changes..",0,0.9603776931762695
1033493533,11390,satishd,2022-11-28T12:40:19Z,locking is not really needed here as `init` method is invoked only when remoteindexcache instance is getting initialized.,0,0.9879080653190613
1033515905,11390,satishd,2022-11-28T13:02:53Z,"this creates race between writers and readers of these files which may fail readers with io errors. for ex: the race can occur in 3 ways 1. multiple writers writing those indexes concurrently 2. one of them will update the entry with the existing file but that file could have been over written in step-1 3. when readers start reading, those file might have been overwritten in step-1.",0,0.9585667252540588
1033516642,11390,satishd,2022-11-28T13:03:35Z,"please ignore the stale comment, removed with the latest commit.",0,0.9590120911598206
1034340498,11390,satishd,2022-11-29T06:20:02Z,"[a link] covers to get indexes or data in async manner for critical paths, we can cover as part of that jira. wdyt?",0,0.9892590641975403
1034345625,11390,showuon,2022-11-29T06:29:16Z,sounds good to me! i'll resolve this comment.,1,0.9898708462715149
1034345639,11390,satishd,2022-11-29T06:29:18Z,good point. this is clarified in later comments.,1,0.9551962614059448
1041219212,11390,satishd,2022-12-06T16:50:10Z,"it does not really create another snapshot as it has the below check in producerstatemanager#takesnapshot. also, it is good to use `log.loadproducerstate` as any extra logic that may be added does not need to be added separately here. [code block]",0,0.938373863697052
1041821188,11390,showuon,2022-12-07T06:52:56Z,nit: javadoc doesn't include all params,0,0.986626923084259
1041842874,11390,showuon,2022-12-07T07:22:48Z,"nit: i know we don't test them, but could we add some comments here? thanks.",1,0.9000043272972107
1042140948,11390,divijvaidya,2022-12-07T12:24:53Z,"consider the following scenario: 1. leader is archiving to tiered storage and has a follower. 2. follower has caught up to offset x (exclusive). 3. while follower is offline, leader moves x to tiered storage and expires data locally till y, such that, leaderlocallogstartoffset > x and y = leaderlocallogstartoffset. meanwhile, x has been expired from tiered storage as well. hence, x < globallogstartoffset as well. now, there could be a scenario where globallogstartoffset > leaderlocallogstartoffset because segments has been expired from remote but not from local. 3. follower comes online and tries to fetch x from leader, leader throws moved to tiered storage exception. 4. follower moves to buildaux state and tries to fetch the metadata. the metadata may not exist since the segment has been deleted in remote storage and we will get an error. this could be addressed at replica manager where it could detect if the remote segments have been deleted and accordingly throw an out of bound instead of move to tiered storage exception, but we should also add a defensive handling check here. in the above scenario, we should directly move to truncation instead of build aux state. the defensive check could be `&& leaderlocallogstartoffset > leaderlogstartoffset` over here. also, please add a test for this scenario.",0,0.9777007699012756
1043330520,11390,satishd,2022-12-08T13:04:03Z,this is addressed with the latest commit.,0,0.9861325025558472
1043330573,11390,satishd,2022-12-08T13:04:07Z,this is addressed with the latest commit.,0,0.9861325025558472
1043981337,11390,junrao,2022-12-09T01:39:11Z,the comment is a bit confusing since 4 bytes + magic doesn't add up to log_overhead.,-1,0.8847090005874634
1043981867,11390,junrao,2022-12-09T01:40:03Z,same question here. it seems that it's better to make it clear that abstractindex is closable?,0,0.9822642207145691
1043982291,11390,junrao,2022-12-09T01:41:10Z,does this need to be volatile?,0,0.9769291281700134
1043982526,11390,junrao,2022-12-09T01:41:43Z,should we reset hwm too?,0,0.9870849251747131
1043982906,11390,junrao,2022-12-09T01:42:42Z,should this be in the storage module like classloaderawareremotelogmetadatamanager?,0,0.9896713495254517
1043983132,11390,junrao,2022-12-09T01:43:19Z,i guess we will add the logic to delete the remote data later?,0,0.9865824580192566
1043983263,11390,junrao,2022-12-09T01:43:42Z,target offset => start offset?,0,0.9875282645225525
1043983592,11390,junrao,2022-12-09T01:44:31Z,"do we need to make ""all the messages in the remote storage have larger timestamps"" a special case here? it seems the last option covers that case already.",0,0.9874709248542786
1043983792,11390,junrao,2022-12-09T01:45:04Z,could we just assign to maybeepoch directly and get rid of startingoffsetepoch?,0,0.9857792854309082
1043984064,11390,junrao,2022-12-09T01:45:35Z,"if no message has timestamp, we will fall to here. this doesn't seem to implement what the comment says.",0,0.8163310289382935
1043984353,11390,junrao,2022-12-09T01:46:29Z,"it would be useful to make logging a complete sentence, so sth like debug(s""received error ${errors.offset_moved_to_tiered_storage} at "" + s""fetch offset: ${currentfetchstate.fetchoffset} for "" + s""topic-partition: $topicpartition"")",0,0.9665505290031433
1043984841,11390,junrao,2022-12-09T01:47:46Z,haven't => hasn't,0,0.8669362664222717
1043985073,11390,junrao,2022-12-09T01:48:20Z,"we already stopped processing requests at this point, right?",0,0.9714084267616272
1043985230,11390,junrao,2022-12-09T01:48:41Z,this seems unused?,0,0.9358466863632202
1043985494,11390,junrao,2022-12-09T01:49:22Z,could this be private?,0,0.9868327379226685
1043985686,11390,junrao,2022-12-09T01:49:51Z,should fetchearlierepochendoffset(2) be fetchearlierepochendoffset(90)?,0,0.9866967797279358
1043985886,11390,junrao,2022-12-09T01:50:14Z,"could we use complete sentence? e.g. s""active producers with size of ${log.producerstatemanager.activeproducers.size}, "" s""logstartoffset is $leaderlogstartoffset and logendoffset is $nextoffset"")",0,0.9841794371604919
1043986046,11390,junrao,2022-12-09T01:50:34Z,"yes, thinking about this more. i am not sure that truncating all local logs is the right thing to do. if we do that, the replica's log may not give a complete view of the data. we could get into this situation when (1) the topic level remote storage flag propagation is delayed; (2) incorrect configuration by the user (e.g. remotestoragesystemenable not enabled on all brokers). in both cases, it seems a better strategy is to error out and keep retrying. in the case (1), the issue will be resolved automatically when the topic level flag is propagated to this broker. in the case (2), this issue will be resolve after the user fixes the configuration.",0,0.9080049991607666
1043987311,11390,junrao,2022-12-09T01:51:30Z,it seems no non-test caller sets flushtofile to false?,0,0.9809869527816772
1043989048,11390,junrao,2022-12-09T01:52:25Z,truncateonfetch is always true?,0,0.9897819757461548
1043989337,11390,junrao,2022-12-09T01:52:47Z,add newline after,0,0.9870232343673706
1043989757,11390,junrao,2022-12-09T01:53:22Z,could this be private?,0,0.9868327379226685
1043990559,11390,junrao,2022-12-09T01:54:23Z,could we add a description of the class?,0,0.9875926375389099
1044740416,11390,junrao,2022-12-09T18:47:37Z,could we use case statement to avoid using unnamed references?,0,0.9876148700714111
1044741168,11390,junrao,2022-12-09T18:48:41Z,"hmm, i am not sure that i understand the test. the snapshot corresponding to offset 5 should still be there, right? where did we delete it?",0,0.6430114507675171
1044757469,11390,junrao,2022-12-09T19:11:36Z,why are we calling the same thing a second time?,0,0.8548524975776672
1044758640,11390,junrao,2022-12-09T19:13:28Z,why are we calling the same thing a second time? ditto in two other places below.,-1,0.6262083649635315
1044791351,11390,junrao,2022-12-09T19:42:37Z,"hmm, the log segment only has 1 record with timestamp and startoffset. why do we return timestamp + 1 here?",0,0.983269453048706
1044796318,11390,junrao,2022-12-09T19:48:50Z,add a new line above,0,0.9859955906867981
1044806867,11390,junrao,2022-12-09T20:05:41Z,_locallogstartoffset could change after we find out the epoch. perhaps we could save it as a local val and use it in the return value.,0,0.9883092641830444
1046991743,11390,satishd,2022-12-13T10:58:07Z,comment does not say that magic+4 bytes adds upto log_overhead. updated the comment to make it more clear about the “size” used in the below code. `int buffersize = log_overhead + size;`,0,0.986836314201355
1047001228,11390,satishd,2022-12-13T11:04:58Z,i will address it in a followup pr. filed [a link],0,0.9845749139785767
1047001890,11390,satishd,2022-12-13T11:05:34Z,right. added the respective delete part for now which is about removing the partitions. more on that will be added respectively when we add handling partition deletes with respect to remote storage also.,0,0.9883307218551636
1047002015,11390,satishd,2022-12-13T11:05:45Z,done,0,0.9764507412910461
1047002223,11390,satishd,2022-12-13T11:05:58Z,done,0,0.9764507412910461
1047003879,11390,satishd,2022-12-13T11:07:40Z,"that case is taken care in `lookuptimestamp`. let me know if i am missing anything here. `val timestampoffset = lookuptimestamp(rlsmetadata, timestamp, startingoffset)`",0,0.985318660736084
1047004756,11390,satishd,2022-12-13T11:08:10Z,done,0,0.9764507412910461
1047005713,11390,satishd,2022-12-13T11:08:41Z,updated it with the right text.,0,0.9768163561820984
1047007959,11390,satishd,2022-12-13T11:09:51Z,nice catch! this is moved to `metadataversion`.,1,0.9893007874488831
1047008633,11390,satishd,2022-12-13T11:10:15Z,"no, fetchearlierepochendoffset(2) is right. argument here is the leader epoch.",0,0.9809532761573792
1047008950,11390,satishd,2022-12-13T11:10:25Z,done,0,0.9764507412910461
1047009169,11390,satishd,2022-12-13T11:10:31Z,done,0,0.9764507412910461
1047014746,11390,satishd,2022-12-13T11:14:32Z,right.,0,0.9566289782524109
1047015681,11390,satishd,2022-12-13T11:15:31Z,`truncateonfetch` is the existing code. it is not added by this pr.,0,0.9885039925575256
1047016127,11390,satishd,2022-12-13T11:15:58Z,done,0,0.9764507412910461
1047017673,11390,satishd,2022-12-13T11:17:33Z,this is overridden by `listoffsetsrequestwithremotestoretest`,0,0.9857040047645569
1047018234,11390,satishd,2022-12-13T11:17:46Z,done,0,0.9764507412910461
1047018559,11390,satishd,2022-12-13T11:17:55Z,done,0,0.9764507412910461
1047019754,11390,satishd,2022-12-13T11:18:35Z,updated with javadoc to explain the testcases with the latest commits.,0,0.9869695901870728
1047020063,11390,satishd,2022-12-13T11:18:44Z,updated with javadoc to explain the testcases with the latest commits.,0,0.9869695901870728
1047020508,11390,satishd,2022-12-13T11:18:57Z,done,0,0.9764507412910461
1047020836,11390,satishd,2022-12-13T11:19:07Z,done,0,0.9764507412910461
1047024290,11390,satishd,2022-12-13T11:21:03Z,+1 on this approach. this is aligned with our initial proposal in this pr also. latest commit is updated with this change.,0,0.7734186053276062
1047369687,11390,satishd,2022-12-13T16:07:36Z,added more documentation about the test for better clarity with the latest commit. statemanager.reloadsnapshots() deletes the existing snapshots.,0,0.9875796437263489
1049205016,11390,satishd,2022-12-15T04:33:13Z,"as discussed offline, the current follower fetch retries when it receives an error while building aurxiliary state. it will eventually gets the auxiliary data from remote storage for the available leader-log-start-offset.",0,0.9877060055732727
1049392445,11390,showuon,2022-12-15T09:20:23Z,maybe we should have an assertion before and between the 1st and 2nd call to `getindexentry`? like this: [code block],0,0.9826929569244385
1049393028,11390,showuon,2022-12-15T09:20:56Z,typo: sis -> is,0,0.9755045175552368
1049396894,11390,showuon,2022-12-15T09:23:45Z,i saw there are many places have this assertion. i've created a jira to address it: [a link] . you can ignore it for this pr. thanks.,1,0.9606136679649353
1049993923,11390,junrao,2022-12-15T18:15:54Z,"this is still not very precise since size includes other fields like crc, attributes, etc. so, we could probably just omit it and say the total size of a batch is log_overhead + the size of the rest of the content.",0,0.9769432544708252
1050008020,11390,junrao,2022-12-15T18:31:58Z,it's better to use locallog.logendoffsetmetadata since it has the log metadata in addition to the offset.,0,0.9881987571716309
1050013671,11390,junrao,2022-12-15T18:39:10Z,"it seems that the ""no message in the remote storage has the given timestamp"" case is covered in the otherwise clause too?",0,0.9833604097366333
1050017122,11390,junrao,2022-12-15T18:43:27Z,it seems that both offsetforleaderepochrequestversion and listoffsetrequestversion are moved to metadataversion and can be removed here?,0,0.9899307489395142
1050029710,11390,junrao,2022-12-15T18:57:17Z,"then, could we just remove this param?",0,0.985885739326477
1050033092,11390,junrao,2022-12-15T19:01:07Z,inmemory => in memory,0,0.9847376942634583
1050035787,11390,junrao,2022-12-15T19:04:29Z,could we add a similar comment as in line 125?,0,0.9875922799110413
1050039191,11390,junrao,2022-12-15T19:09:04Z,change to curlocallogstartoffset = locallogstartoffset ?,0,0.9880746006965637
1050045012,11390,junrao,2022-12-15T19:16:40Z,should we add a test that explicitly tests the producer state after handling offset_moved_to_tiered_storage error? this can be done in a separate pr.,0,0.990010678768158
1050536097,11390,satishd,2022-12-16T09:28:23Z,updated with what you suggested to make it more clear.,0,0.9823042154312134
1050536434,11390,satishd,2022-12-16T09:28:47Z,done,0,0.9764507412910461
1050536942,11390,satishd,2022-12-16T09:29:21Z,done,0,0.9764507412910461
1050537018,11390,satishd,2022-12-16T09:29:26Z,done,0,0.9764507412910461
1050537960,11390,satishd,2022-12-16T09:30:25Z,"as you suggested earlier, i created a [a link] for that and mentioned it in my earlier [a link].",0,0.9875918626785278
1051118349,11390,junrao,2022-12-16T20:06:38Z,logendoffset still uses offset. we want to use logendoffsetmetadata.,0,0.9898647665977478
1051439769,11390,ijuma,2022-12-17T18:26:58Z,+1,0,0.696722686290741
263150141,6363,kkonstantine,2019-03-06T21:47:30Z,please skip this file and review: [a link] instead. thanks!,1,0.9665442705154419
263150256,6363,kkonstantine,2019-03-06T21:47:51Z,please skip this file and review: [a link] instead. thanks!,1,0.9665442705154419
263151738,6363,kkonstantine,2019-03-06T21:52:09Z,please skip this file and review: [a link] instead. thanks!,1,0.9665442705154419
263151859,6363,kkonstantine,2019-03-06T21:52:30Z,please skip this file and review: [a link] instead. thanks!,1,0.9665442705154419
263151902,6363,kkonstantine,2019-03-06T21:52:37Z,please skip this file and review: [a link] instead. thanks!,1,0.9665442705154419
263151960,6363,kkonstantine,2019-03-06T21:52:46Z,please skip this file and review: [a link] instead. thanks!,1,0.9665442705154419
263152009,6363,kkonstantine,2019-03-06T21:52:55Z,please skip this file and review: [a link] instead. thanks!,1,0.9665442705154419
263152049,6363,kkonstantine,2019-03-06T21:53:03Z,please skip this file and review: [a link] instead. thanks!,1,0.9665442705154419
263152103,6363,kkonstantine,2019-03-06T21:53:11Z,please skip this file and review: [a link] instead. thanks!,1,0.9665442705154419
263152397,6363,kkonstantine,2019-03-06T21:54:01Z,please skip this file and review: [a link] instead. thanks!,1,0.9665442705154419
263152448,6363,kkonstantine,2019-03-06T21:54:08Z,please skip this file and review: [a link] instead. thanks!,1,0.9665442705154419
263152502,6363,kkonstantine,2019-03-06T21:54:17Z,please skip this file and review: [a link] instead. thanks!,1,0.9665442705154419
263242755,6363,kkonstantine,2019-03-07T05:31:22Z,"this file changes can be omitted, although it'd be nice to consider whether we want to enable a few log messages in connect integration tests. this is something that manually needs to be enabled when someone debugs a failure at an integration test.",0,0.9867629408836365
268807968,6363,rhauch,2019-03-25T19:10:32Z,missing the `` for most of the parameters.,0,0.8213625550270081
268809353,6363,rhauch,2019-03-25T19:14:31Z,"nit: might this be null, or will it only be empty?",0,0.9751996397972107
268809411,6363,rhauch,2019-03-25T19:14:38Z,"nit: might this be null, or will it only be empty?",0,0.9751996397972107
268845523,6363,rhauch,2019-03-25T20:51:45Z,nit: should the header be in a ` ` section so it's easier to read given it uses constant-width formatting?,0,0.9884753227233887
268846278,6363,rhauch,2019-03-25T20:53:50Z,"the [a link] that `compatible` is the default. also, why is the protocol string for eager ""`default`""?",0,0.9848777055740356
268847672,6363,rhauch,2019-03-25T20:57:16Z,"why not define a new field in the enum and assign via a constructor, rather than define an abstract method and override in the definitions? see [a link] for an example.",0,0.9836408495903015
268847927,6363,rhauch,2019-03-25T20:57:50Z,the [a link] mentions that `compatible` is the default.,0,0.9868630170822144
268848356,6363,rhauch,2019-03-25T20:58:40Z,nit: maybe use `timeunit.seconds.tomillis(300)` for the value? that seems to be more in line with how we're doing time-related constants now.,0,0.9853897094726562
268848881,6363,rhauch,2019-03-25T21:00:06Z,can this be final? can it also be private? (i don't see it's used anywhere else in the code.),0,0.983970582485199
268849865,6363,rhauch,2019-03-25T21:02:40Z,"doesn't each process only have a single distributedworker instance? if so, then would `connect_client_id_sequence.getandincrement()` ever return something other than 1?",0,0.9872598648071289
268868053,6363,rhauch,2019-03-25T21:53:33Z,"did you consider having a single log message that output all of these in one message? would that make it easier to follow what is being decided, especially if there are lots of interjected messages from currently-running connectors and tasks?",0,0.9843782782554626
268869092,6363,rhauch,2019-03-25T21:56:44Z,add javadoc,0,0.9856758117675781
268882992,6363,rhauch,2019-03-25T22:43:19Z,is this method used anymore?,0,0.9816853404045105
268911175,6363,rhauch,2019-03-26T01:06:41Z,"the logic of these methods is not trivial, and while connectassignortest has unit tests that exercise some of these methods, what do you think about writing unit tests for these. they really don't use state, so they would seem straightforward to test and it would help any future work by preventing regressions.",0,0.9761499166488647
268911374,6363,rhauch,2019-03-26T01:08:03Z,this combination of javadoc and line comments is unusual. is there a reason this isn't in the javadoc?,0,0.777540922164917
268912546,6363,rhauch,2019-03-26T01:16:43Z,nit: seems odd to have statics after member fields.,-1,0.8779442310333252
268913739,6363,rhauch,2019-03-26T01:24:46Z,how about a validator to ensure that worker configs are valid before the distributedworker starts instantiating its components and throwing illegalargumentexceptions?,0,0.9757316708564758
268913846,6363,rhauch,2019-03-26T01:25:27Z,"what happens if name is not lowercase? there's no validator for this, so it's possible to get an exception at a strange point.",0,0.945593535900116
268914485,6363,rhauch,2019-03-26T01:29:39Z,i don't think this is used anywhere except for tests. is that intentional?,0,0.7104446887969971
268914753,6363,rhauch,2019-03-26T01:31:27Z,"i think these fields will never be null based upon how it is currently used, but there are no asserts or checks to ensure there are no npes here. is this intentional?",0,0.9663328528404236
268915078,6363,rhauch,2019-03-26T01:33:33Z,"it took me a while to find this class. would it make more sense if there were named `incrementalcooperativeassignortest` instead, since that's all that's being tested?",0,0.9804701209068298
268916477,6363,rhauch,2019-03-26T01:43:03Z,do you think it's easier to understand the test to simply do: [code block],0,0.9788662791252136
268916806,6363,rhauch,2019-03-26T01:45:25Z,"is this all that we can assert here? it doesn't really seem to validate much of the logic by just checking the sizes, does it?",0,0.9338391423225403
271858376,6363,kkonstantine,2019-04-03T17:46:44Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9866598844528198
271858438,6363,kkonstantine,2019-04-03T17:46:52Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9866598844528198
271858506,6363,kkonstantine,2019-04-03T17:47:02Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9866598844528198
271858588,6363,kkonstantine,2019-04-03T17:47:16Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9866598844528198
271858640,6363,kkonstantine,2019-04-03T17:47:23Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9866598844528198
271858676,6363,kkonstantine,2019-04-03T17:47:29Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9866598844528198
271858830,6363,kkonstantine,2019-04-03T17:47:41Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9866598844528198
271858905,6363,kkonstantine,2019-04-03T17:47:54Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9866598844528198
271908729,6363,rayokota,2019-04-03T20:01:15Z,"wouldn't it be better to return an empty map? then it would be consistent with the code in the rest of the method body that also returns an empty map if both are `null`. and it would also be consistent with `asmap` that never returns `null` as well as a few other methods in this class that return `collections.emptylist` instead of `null`, and also remove a bunch of `null` checks.",0,0.9882579445838928
271909677,6363,rayokota,2019-04-03T20:03:53Z,"if `taskassignments` never returns `null`, you can simplify these checks.",0,0.9866769313812256
271910018,6363,rayokota,2019-04-03T20:04:51Z,"if `taskassignments` never receives `null`, you can simplify this so that it also never returns `null`.",0,0.9818059802055359
271910748,6363,rayokota,2019-04-03T20:06:58Z,`asmap()` never returns `null`; that's why it would be nice if `asrevokedmap` also never returns `null`.,0,0.9876639246940613
271911651,6363,rayokota,2019-04-03T20:09:34Z,yay!,1,0.9896801114082336
271911745,6363,rayokota,2019-04-03T20:09:53Z,yay!,1,0.9896801114082336
271912716,6363,rayokota,2019-04-03T20:12:39Z,wouldn't it be better to have something like `public static connectprotocolcompatibility default = eager;`,0,0.9636619687080383
271913903,6363,rayokota,2019-04-03T20:16:03Z,"why can't this just be `name().tolowercase(locale.root)`. otherwise if `protocol()` is allowed to differ from `name()`, then how do i go from a `protocol()` to the enum (since there is only a way to go from `name()` to enum).",0,0.9849666357040405
271916281,6363,rayokota,2019-04-03T20:22:40Z,should we check that `update` is `null`? it's confusing if `running` is allowed to be `null` but `update` is assumed not to be.,0,0.7802614569664001
271917878,6363,rayokota,2019-04-03T20:27:21Z,nit: can be replaced with `computeifabsent`,0,0.9888007640838623
271918316,6363,rayokota,2019-04-03T20:28:35Z,nit: can be replaced with `computeifabsent`,0,0.9888007640838623
271918654,6363,rayokota,2019-04-03T20:29:29Z,nit: can be replaced with `getordefault`,0,0.9883942604064941
271918689,6363,rayokota,2019-04-03T20:29:35Z,nit: can be replaced with `getordefault`,0,0.9883942604064941
271919947,6363,rayokota,2019-04-03T20:33:02Z,do we need an `assert` that the `memberconfigs` is never empty? otherwise `return maxoffset` will throw npe.,0,0.9868927597999573
271920454,6363,rayokota,2019-04-03T20:34:20Z,"nit: this can be simplified to `maxoffset = math.max(maxoffset, memberrootoffset)` if we initialize `maxoffset` with `long maxoffset = long.min_value`.",0,0.987874448299408
271923960,6363,rayokota,2019-04-03T20:43:37Z,"there is an `equals` call here, but i don't see `equals` and `hashcode` methods for `connectassignment`. if you are assuming reference equality, perhaps use `==`?",0,0.9881807565689087
271927037,6363,rayokota,2019-04-03T20:51:08Z,"why not return `connectassignment.empty()`? i found 2 callers to this method: `incrementalcooperativeconnectprotocol.derserializemetadata` sends the result to the `extendedworkerstate` constructor, which replaces null with `connectassignment.empty()`. the other caller, `workercoordinator.onjoincomplete()`, tries to call `version()` and would get an npe.",0,0.9864882826805115
271928754,6363,rayokota,2019-04-03T20:55:39Z,nit: could add `throws schemaexception` to the method declaration if you want,0,0.9898264408111572
271930819,6363,rayokota,2019-04-03T21:01:10Z,do we need an `assert` that `allmembermetadata` is not empty? otherwise an npe would result here i think,0,0.987569272518158
271933574,6363,rayokota,2019-04-03T21:08:51Z,should this return an empty `bytebuffer`? i think one of the callers will get a npe otherwise.,0,0.9890177249908447
271933845,6363,rayokota,2019-04-03T21:09:40Z,nit: `.stream().foreachordered()` can be replaced with `.foreach()`,0,0.9866600036621094
271934088,6363,rayokota,2019-04-03T21:10:24Z,nit: `.stream().foreachordered()` can be replaced with `.foreach()`,0,0.9866600036621094
271934289,6363,rayokota,2019-04-03T21:10:57Z,nit: `.stream().foreachordered()` can be replaced with `.foreach()`,0,0.9866600036621094
271979425,6363,kkonstantine,2019-04-04T00:16:31Z,"unfortunately this value has to stay as is, called `default`, otherwise we won't be able to have live rolling upgrades. in all the versions up to now, the `workercoordinator` sets the name of the embedded protocol in the joingrouprequest (aka metadata request) as `default`. small price to pay i think, because it's internal info. we can deprecate the term `default` eventually",0,0.9221838712692261
271979799,6363,kkonstantine,2019-04-04T00:18:57Z,in the `reverse` map we put both values lowercase and uppercase (values are matching the enum name which is upper case). they can be used either way then. i don't think i was the first to introduce this. but i have found useful that we don't strictly accept only uppercase values. i don't see much downside to it.,0,0.9223182201385498
271980517,6363,kkonstantine,2019-04-04T00:23:32Z,"i find the two ways equivalent, with minor pros and cons in edge cases.",0,0.9755725860595703
271980846,6363,kkonstantine,2019-04-04T00:25:39Z,correct. i didn't get to the removal of `cooperative` as well as the switch of default yet. will update in a bigger commit without other cleanup comments.,0,0.9798722863197327
271982564,6363,kkonstantine,2019-04-04T00:36:45Z,"the sets are many. i'd still like to take a final look on what is printed before we merge. but seems not printing as soon as possible, might hide issues, even during integration tests. but i see your point. let's get back to that.",0,0.8601861000061035
272760693,6363,kkonstantine,2019-04-05T22:24:34Z,i believe they are there now.,0,0.8996621966362
272761166,6363,kkonstantine,2019-04-05T22:27:38Z,let me know if that's what you had in mind.,0,0.9786770343780518
274026037,6363,mumrah,2019-04-10T15:36:25Z,"`objects#requirenonnull` can be used during assignment as well, e.g. [code block]",0,0.9877533316612244
274068757,6363,mumrah,2019-04-10T17:13:39Z,"minor: since there are so few values to consider, maybe prefer a brute force approach? e.g., `values().stream().findfirst(mode -> mode.name().equalsignorecase(querymode)`",0,0.9796932935714722
275537294,6363,kkonstantine,2019-04-15T20:44:49Z,"this file contains the old code in `workercoordinator` _as-is_. i would prefer not to introduce changes at all, no matter how small the changes. in a pr that big, it's simply a matter of discipline not to try to change multiple execution paths at once. this and the optimizations below are small. additionally, this code is not expected to run if the new rebalancing policy is chosen. i'm happy to return to this code, that is know encapsulated in a separate and well defined class for a similar clean once the the code has been released.",1,0.9561262130737305
275537397,6363,kkonstantine,2019-04-15T20:45:07Z,same as above.,0,0.9746477603912354
275537442,6363,kkonstantine,2019-04-15T20:45:16Z,same as above,0,0.9772257208824158
275537487,6363,kkonstantine,2019-04-15T20:45:21Z,same as above,0,0.9772257208824158
275537527,6363,kkonstantine,2019-04-15T20:45:30Z,same as above,0,0.9772257208824158
275537593,6363,kkonstantine,2019-04-15T20:45:41Z,same as above,0,0.9772257208824158
275538726,6363,kkonstantine,2019-04-15T20:48:59Z,"it's not a checked exception. we don't add unchecked exception to the signature. only in javadoc. this method is `private`, so i'm adding the javadoc mention on the `public` methods that check version.",0,0.9880309700965881
275549911,6363,kkonstantine,2019-04-15T21:22:22Z,fixed. with a note to improve logging and log messages in this class.,0,0.9822313189506531
275560677,6363,kkonstantine,2019-04-15T21:57:44Z,"the distinction i want to reflect here is that, task assignments have always been a required field of the connect protocol (v0 and therefore v1) and this can not change in a backwards compatible way. to the contrary, the revoked assignments correspond to a new field, which is also `nullable` which here means also optional. deprecating such a field if we need to might be easier in the future (although not completely transparent since we don't selectively unpack fields in the protocol schema). that's why `asmap` does not return `null` while `asrevokemap` might return `null`. i'll comment below too.",0,0.9776802659034729
275562433,6363,kkonstantine,2019-04-15T22:04:33Z,see previous comment.,0,0.980539083480835
275563850,6363,kkonstantine,2019-04-15T22:10:28Z,"this is different. this takes you from on-the-wire representation to the in-memory representation. also, it's meant to be used both for assignments and revocations. of course, for this protocol it doesn't make sense to keep `null` in the in-memory representation of `connectassignment`. see another take on compatibility between v0 and v1 in `connectprotocolcompatibilitytest`",0,0.977940559387207
275563890,6363,kkonstantine,2019-04-15T22:10:39Z,see comment above,0,0.981052577495575
275567590,6363,kkonstantine,2019-04-15T22:25:40Z,"enums in java are more expressive. we don't have to restrict ourselves to what `name()` represents. here we have a good example, where the protocol has to stay as `default` for backwards compatibility but we don't have to call the enum literal `default`. giving the literal a more accurate name, while keeping compatibility is one of the reasons enums in java are more powerful than elsewhere.",0,0.9253101348876953
275567702,6363,kkonstantine,2019-04-15T22:26:14Z,let's revisit when we reduce the enum values to reflect the voted version of the kip,0,0.9869667887687683
275571648,6363,kkonstantine,2019-04-15T22:43:44Z,this is not meant to be a general method. i removed the `null` check because assignment collections should not be `null`. if we see fit later on we could factor out this logic to a more general diff method in `connectassignment` itself.,0,0.9867060780525208
275575635,6363,kkonstantine,2019-04-15T23:02:18Z,"with api generator has become a bit harder to argue about, but both current and new code depend on members this list (`allmembermetadata`) not being `null`. any gaps of api generator with `final` member fields and when arrays are allowed to be set to `null` instead of an empty array should not be addressed as part of this pr imo. i think it's safe to depend on the previous assumption, that `allmembermetadata` can not be `null`.",0,0.9604947566986084
275576977,6363,kkonstantine,2019-04-15T23:08:48Z,but if we were to introduce these methods on `connectassignment` this code would still work right? while reference equality would be harder to track in this case.,0,0.9847058653831482
275585786,6363,kkonstantine,2019-04-15T23:55:41Z,"currently this doesn't seem possible because we never send a `connectassignment.empty()` intentionally unless this is called in a metadata request. we might send an assignment that is practically empty on an error, but in this case equality here is not true. however, i'll tighten the checks and will increase coverage. we might end up diverging, depending on who's using this call. however, again for metadata we need `null` because this goes to a nullable field.",0,0.9579541087150574
275586823,6363,kkonstantine,2019-04-16T00:01:33Z,"see explanation above. this ties back to what we send over the wire. a `connectassignment.empty` assignment is never sent over the wire (you'll always have the leader and the leader url fields for instance, even if you receive an empty assignment).",0,0.9870741367340088
275587099,6363,kkonstantine,2019-04-16T00:03:19Z,"see answer in the other comment about `asmap`. the two methods are not symmetric to this respect, because one field is required and the other one is optional.",0,0.985221803188324
275587135,6363,kkonstantine,2019-04-16T00:03:30Z,fixed,0,0.975196123123169
275587191,6363,kkonstantine,2019-04-16T00:03:50Z,"as mentioned above, these fields in `v1` protocol are `nullable`. therefore, instead of going back and forth from empty list to `null` and vice versa, i prefer to have `taskassignments` handle `null` and potentially return `null`, because `null` is what needs to be used when these optional fields are empty.",0,0.9858649969100952
275588182,6363,kkonstantine,2019-04-16T00:09:40Z,"changed, although with the need to convert `long` to `int` it's less brief than ideal. though still safer, i agree.",0,0.9320497512817383
275588691,6363,kkonstantine,2019-04-16T00:12:39Z,fixed. i must have had plans for parameterizing it in unit tests that i didn't follow after all.,0,0.9795688986778259
275588918,6363,kkonstantine,2019-04-16T00:13:49Z,this is older code which i chose not to change here. one place where you can see the counter making a difference is in integration tests with multiple workers at the moment.,0,0.982465386390686
275589318,6363,kkonstantine,2019-04-16T00:16:11Z,i'm keeping the old comment from `connectprotocol`. not sure it belongs to the javadoc. wdyt?,0,0.9295587539672852
275589829,6363,kkonstantine,2019-04-16T00:19:14Z,"in general, i'm not sure our checkstyle is very opinionated w.r.t to this order. changed to bring empty first.",-1,0.7511924505233765
275590343,6363,kkonstantine,2019-04-16T00:22:13Z,"this class has some overlap with other classes such as `connectorsandtasks` and even `leaderstate`. i agree and i would also like to consolidate, but maybe when we are near the end of the pr review.",0,0.9743925929069519
275590597,6363,kkonstantine,2019-04-16T00:23:38Z,i'll add a requirement in the constructor rather than here.,0,0.9872645139694214
275592326,6363,kkonstantine,2019-04-16T00:34:24Z,fixed,0,0.975196123123169
275592693,6363,kkonstantine,2019-04-16T00:36:30Z,"also, to comment, java allows us to not have strict binding to enum names. i'm inclined to use this functionality here.",0,0.9510603547096252
275593431,6363,kkonstantine,2019-04-16T00:41:13Z,javadoc fixed with reference to `null`,0,0.9888973832130432
275593446,6363,kkonstantine,2019-04-16T00:41:19Z,javadoc fixed with reference to `null`,0,0.9888973832130432
275893903,6363,mumrah,2019-04-16T16:46:38Z,does connect use the `time` utility class? my understanding is that it makes instrumenting time-based logic easier in the test code.,0,0.9789549112319946
275900247,6363,mumrah,2019-04-16T17:02:14Z,"i was wondering about the thread safety of this assignment, but i see that calls to this method are protected by upstream synchronization in abstractcoordinator. maybe we should include a note about thread safety in the class javadoc?",0,0.9828638434410095
275903378,6363,mumrah,2019-04-16T17:10:05Z,"maybe consider exposing only what is needed from workercoordinator rather than depending on the whole class here? instead, you could pass in a clusterconfigstate supplier and a leaderstate consumer. this would also make unit testing this method more straightforward. just a thought.",0,0.9674870371818542
275904303,6363,mumrah,2019-04-16T17:12:29Z,"how is error handling done for this method? it mutates its own state (previousassignment) as well as the workercoordinator. if we fail half way through the assignment procedure, how do we ensure a valid overall state?",0,0.9833053946495056
275905898,6363,mumrah,2019-04-16T17:16:39Z,why the explicit check for log level here?,0,0.9604006409645081
275908713,6363,mumrah,2019-04-16T17:23:57Z,"nit: a method reference can be used here e.g., `foreach(workerload::assign)`",0,0.9874402284622192
275912009,6363,mumrah,2019-04-16T17:32:06Z,why iterator here instead of stream?,0,0.9729849100112915
275944942,6363,kkonstantine,2019-04-16T18:54:49Z,"we seem to follow this pattern in other enums elsewhere too, so i'm more inclined to keep it the same here too. i agree with your point. but also the footprint of a hashmap here is not an issue too i'd say. thus this is more stylistic than anything else i believe. wdyt?",0,0.9175021052360535
275945434,6363,kkonstantine,2019-04-16T18:56:08Z,"yes, i'm a big proponent of mocking time and `time` util specifically. i missed its use here. will add!",-1,0.8289984464645386
275946661,6363,kkonstantine,2019-04-16T18:59:28Z,good point. in general we don't assume multi-threading for the code that is run by the herder and this has simplified things. i'll add a mention,1,0.7602394223213196
275953129,6363,kkonstantine,2019-04-16T19:18:02Z,to avoid the `foreach` loop if the log level is not at least debug (the methods called on `wl` don't compute anything indeed),0,0.9755719900131226
275955774,6363,kkonstantine,2019-04-16T19:25:52Z,"the `numtorevoke` that is used to exit the `for` loops (potentially early) is not effectively final. i could work around it, but i'm not sure the result would be more readable.",0,0.908491313457489
275956315,6363,kkonstantine,2019-04-16T19:27:18Z,til. thanks!,1,0.948625922203064
276076567,6363,kkonstantine,2019-04-17T04:39:04Z,added guard in the constructor,0,0.9880040884017944
276076869,6363,kkonstantine,2019-04-17T04:41:28Z,done,0,0.9764507412910461
276079316,6363,kkonstantine,2019-04-17T04:58:31Z,done,0,0.9764507412910461
276861923,6363,rayokota,2019-04-18T23:04:07Z,perhaps either 1) add `equals` and `hashcode` to `connectassignment` or 2) add a comment here stating that the `equals` method is relying on reference equality since `equals` is not overridden in `connectassignment`. wdyt?,0,0.9897079467773438
277123841,6363,kkonstantine,2019-04-20T04:49:03Z,"sure! added a comment for now, and i'll revisit method implementation if we need it for general comparisons between assignments (i don't see a reason yet).",0,0.8270883560180664
277124243,6363,kkonstantine,2019-04-20T05:14:41Z,done,0,0.9764507412910461
277799701,6363,kkonstantine,2019-04-23T17:54:02Z,"the changes to the enum that reflect the latest kip version have been pushed. again, using ""default"" is required in order to be backwards compatible and support older workers.",0,0.9828311204910278
277800822,6363,kkonstantine,2019-04-23T17:56:56Z,"again, i'd prefer to support both: `eager` and `eager` as well as `compatible` and `compatible`. are we ok with that?",0,0.9845802783966064
277933842,6363,ewencp,2019-04-24T02:14:52Z,"why this particular setup with a new class? the naming seems like it's going to be confusing since there's no obvious differentiation in naming. its been awhile since i looked at the code, but i think the general pattern expected (from both `consumerprotocol` and `connectprotocol` when we generalized) is that we'd maintain the different version schemas alongside each other, much as we do for lower level message types (e.g. check what `metadatarequest` code looks like). this means we have mostly reuse and just a bit of delta for various parsing/serialization since lots of the code overlaps. at a minimum, i'd suggest renaming this class to something clearly tied to the updated code, whether similar to the `incrementalcooperativeconnectprotocol` class or some variant that is perhaps more general that would apply even with further extensions.",0,0.9369279146194458
277934191,6363,ewencp,2019-04-24T02:17:07Z,"currently with only 1 version we just do validation inline, but given this is common state between this class and the base class, why not make it a field and any necessary accessors on the base class? seems like ideally this class would only add new fields that are truly unique to it (and lack of stored state in one case vs the other seems weird).",0,0.8293660283088684
277938290,6363,ewencp,2019-04-24T02:45:57Z,"at some length of fields, `stringbuilder` probably makes sense. not sure how frequently we're logging this, which i assume is main use case here",0,0.9679188132286072
277939161,6363,ewencp,2019-04-24T02:52:28Z,"why do we need distinct here but not on the subsequent task list? why would there be dups here but not there? i think its fine to include this if we want to be defensive, but seems like it should be used in both cases if that's the goal.",0,0.9266107678413391
277945505,6363,ewencp,2019-04-24T03:40:16Z,these methods could validate the `key` is in the expected set to be more defensive against coding errors,0,0.9772388935089111
277945625,6363,ewencp,2019-04-24T03:41:08Z,nit: you're doing a redundant lookup here after already assigning to `connectors` to do the `null` check,0,0.9841141700744629
277946373,6363,ewencp,2019-04-24T03:47:35Z,"why are we documenting v1 subscription here? it's also identical to v0, but even if it weren't, this code deals with v0, right?",0,0.9860550761222839
277946470,6363,ewencp,2019-04-24T03:48:27Z,"i guess this kind of explains my above question re: v1 docs here since this doesn't include everything for v0, but again, why re-document this here?",0,0.9769819378852844
277947459,6363,ewencp,2019-04-24T03:56:30Z,"if anything, it seems even better to just generalize to case insensitivity (which i am not a fan of in many cases, but in the context of enum configs should be harmless unless we make some pretty bad decisions). tbh, i'm not sure why elsewhere we're optimizing the string -> enum lookup unless it is in a hot path, which it doesn't seem like it should be here",-1,0.6110885739326477
277947904,6363,ewencp,2019-04-24T04:00:14Z,"not sure if this was intended to apply to both connect protocol and scheduled rebalance max delay, but validator on the delay would make sense as well -- at a minimum to ensure non-negative",0,0.9817091226577759
277948672,6363,ewencp,2019-04-24T04:06:36Z,"hmm, so this is a potentially interesting change. client.id can be used for some things like quotas. since this is for workers, i'm not sure we're actually changing behavior in any interesting way here, but we should consider what the possible fallout in behavior could be by changing the default client.id behavior here.",0,0.9483622908592224
277950243,6363,ewencp,2019-04-24T04:18:49Z,"we use normal logging elsewhere in this file, i assume this is stray debugging code?",0,0.9840100407600403
278276834,6363,ewencp,2019-04-24T19:11:50Z,what's the reason for removing this? if anything i would think we should have more logging around these operations rather than less.,0,0.9662512540817261
278278502,6363,ewencp,2019-04-24T19:16:38Z,"it seems like most of the other logic around the protocol versions is cleanly factored into the protocol classes. could we refactor this logic as well, e.g. to get this from `assignment`?",0,0.9865784049034119
278371438,6363,ewencp,2019-04-25T01:29:36Z,"why are we clearing these here? i would think the key thing in this class would just be to force the rejoin when tasks are revoked and it doesn't look like we use this anywhere else in this class that this would cause a problem. is there some sharing with code elsewhere that relies on this? (and if so, could we just hand this class a copy instead?)",0,0.9378215074539185
278372255,6363,ewencp,2019-04-25T01:36:27Z,"this might be worth a comment as well, or actually even restructuring a bit. it seems confusing that the `runningassignment` after starting all the connectors and tasks would be `empty()`. i *suspect* this is being done because on the subsequent round, this forces the `assignmentdifference` to be the full set of connectors/tasks in `assignment`. but it might be more intuitive to reset `runningassignment` to `empty()` in the `onrevoked` (where they actually stop running, and given that it's just based on the parameters, it might be more implicit based on what was passed in than based on the protocol version). i *think* that also handles my above comment because the check for protocol version is no longer necessary -- it should just work out.",0,0.8404350280761719
278374311,6363,ewencp,2019-04-25T01:54:11Z,"seems like copy paste? and a bunch of the utilities would be. aside from the diff to make protected, did you consider having this inherit from eager and override the key functionality but reuse the rest (which perhaps is better structured as utilities elsewhere, but your inclination to not change the existing implementation too much seems reasonable to me at least for awhile for maintenance reasons, although even there that code hasn't changed in a long time)?",0,0.9760823845863342
278732876,6363,kkonstantine,2019-04-25T21:09:29Z,"added a validation and a validator class that can allow anyone to write a validator in place. i think this is useful and will help with easy addition of validations, that currently are missing from several places. i believe this part belongs to a separate pr with a jira ticket that informs for the addition of what i called `lambdavalidator`. but before i create this i'd like to get some feedback here. wdyt ?",0,0.7240728735923767
278733160,6363,kkonstantine,2019-04-25T21:10:18Z,"given that i've added several integration tests that bring up several workers, i think it makes sense to leave this here.",0,0.9600839614868164
278741717,6363,kkonstantine,2019-04-25T21:36:44Z,"i'm using an assignment via `leaderset` to the coordinator itself though. i'm inclined to say that encapsulation makes sense for now. i feel it doesn't pose a big trade-off. i'd suggest leaving it for now, since it's an easy future refactoring.",0,0.8933582305908203
278751495,6363,kkonstantine,2019-04-25T22:12:31Z,that's a good question. we might need to reset this under certain errors. i'll get back to that.,1,0.6076523065567017
278752888,6363,ewencp,2019-04-25T22:18:41Z,this is getting a bit confusing -- this seems the same as `currentworkerassignment`. what mutates that causes this to be different?,-1,0.9308156371116638
278755759,6363,kkonstantine,2019-04-25T22:31:50Z,added a note at the class level for both `eagerassignor` and `incrementalcooperativeassignor`. we could potentially add a more detailed note such as the one in `abstractcoordinator` on locking.,0,0.9885419607162476
278758021,6363,ewencp,2019-04-25T22:42:40Z,normally `time` would be injected for testing?,0,0.9884155988693237
278765522,6363,kkonstantine,2019-04-25T23:21:58Z,i like to keep the programmatic way of defining test cases. but you are right in that the workers here won't scale significantlly. changed.,0,0.6216228008270264
278766008,6363,kkonstantine,2019-04-25T23:24:35Z,the goal of this test is to validate balanced assignment. thus asserting the size is deterministic and probably sufficient. if we agree on the scheduling algorithms additional unit tests will be added (possibly here) and in `workercoordinatorincrementaltest`,0,0.9831907153129578
278772408,6363,ewencp,2019-04-26T00:01:36Z,it feels like we're getting inconsistent with the naming. `connectassignment` and `connectprotocol.assignment` vs `incrementalcooperativeconnectprotocol.extendedworkerstate` vs `connectprotocol.workerstate`.,-1,0.5386924147605896
278785956,6363,ewencp,2019-04-26T01:44:19Z,"i realize we can get the value via `protocolcompatibility.protocol()` here, but might be clearer to just be explicit anyway. definitely in this case it feels like it makes it harder to parse what's going on here (to me at least)",0,0.925745964050293
278786168,6363,ewencp,2019-04-26T01:46:02Z,what about `cooperative` here?,0,0.9847046136856079
278786302,6363,ewencp,2019-04-26T01:47:04Z,"seems we are missing `cooperative` case here? seems like if we don't handle it here, that setting won't work and having that mode doesn't serve much purpose (even if we encourage people to just leave it in `compatible` given expected low overhead generally)",0,0.8632623553276062
278787756,6363,ewencp,2019-04-26T01:59:34Z,"would any of this be better handled by dynamic dispatch rather than switch statements (for further extensibility)? not a huge deal, but given (at least in this case) it seems like we could dispatch to one of the `[x]connectprotocol` classes, i'm wondering if it avoids switch case hell and keeps the logic for each closer to related protocols and outside of otherwise more general logic. (this admittedly could have been done initially but not nearly as valuable with just one case...)",0,0.9322633147239685
278788073,6363,ewencp,2019-04-26T02:02:07Z,"i'm still working through updated code and all the classes, but this feels a bit messy. admittedly we just dumped the `connectprotocol` here initially when we only had one type. but now it seems confusing when i use the new protocol directly vs having to switch on compatibility, etc. not sure i have a concrete suggestion yet, but i worry about the more general classes here ending up with both explicit (compat mode) and implicit (this case where we always use `incrementalcooperativeconnectprotocol`) decisions about how to handle logic of different versions. i'll think more about how we can refactor...",-1,0.9579641819000244
278788840,6363,ewencp,2019-04-26T02:08:42Z,"we should move this log *above* any actions taken, even if for some reason we only want it in this conditional instead of immediately after the deserialization. since something in onrevoked code could log, ordering of events would be confusing with this where it currently is.",0,0.9631126523017883
278789848,6363,ewencp,2019-04-26T02:17:05Z,"this approach seems interesting -- we previously had this class handle this as immutable (the entire snapshot was left unchanged or entirely replaced). do we actually need to mutate like we do here? a few lines down we do [code block] so main value here seems to be for the log statement a couple lines below. the other value in mutating things in this block seems to be for `newassignment`. but it's taking anything *left* in the old assignment and adding it to `newassignment`. but i thought in the kip we still reiterate to the member all assigned resources, so adding the old leftover ones seems redundant. shouldn't the `newassignment` already contain exactly what we want to update `assignmentsnapshot` with before we attempt any of these mutations?",0,0.8731776475906372
278790323,6363,ewencp,2019-04-26T02:21:21Z,this is another location where i wonder if we just maintain one assignor and update *it* when we see protocol version change rather than maintaining `currentconnectprotocol` and switching on it could refactor some of this logic to be more general,0,0.9521074295043945
278791412,6363,ewencp,2019-04-26T02:30:58Z,didn't notice earlier in review that we're making previously internal state mutable. seems to be used primarily by the assignors for identical logic. can we keep this internal state by pushing that logic into this class? i.e. some sort of `tryupdatesnapshot(maxoffset)`?,0,0.9883068203926086
278791963,6363,ewencp,2019-04-26T02:35:24Z,"i haven't worked through all of them, but i think at least `leaderstate()` and `currentprotocolversion()` can be private. with ^^ suggested update, i think some of the `config[x]snapshot()` methods could be as well. we should try to be conservative about what internal state we're exposing. `configstate` and `leaderstate` in particular worry me more since making that mutable by other classes makes this code a lot harder to reason about.",-1,0.9195473194122314
278792696,6363,ewencp,2019-04-26T02:41:45Z,"nit: i found this terminology a bit weird. do we (or something else) use `embed` like this normally? if not using a builder pattern but wanting a static method instead of public constructor to build it (which, tbh, seems like a fine solution to me...), i would expect `build(..., ...)` or similar.",-1,0.9770897626876831
278795951,6363,ewencp,2019-04-26T03:07:44Z,appears to be unused?,0,0.9733182787895203
278796064,6363,ewencp,2019-04-26T03:08:38Z,sigh... one day this class will either disappear or become more than a mostly useless pass-through that is mostly here just for the constructor and fields...,-1,0.9094645380973816
278796757,6363,ewencp,2019-04-26T03:14:29Z,"might want to extend this comment to explain updated conditions, i.e. that in original mode all connectors and tasks are revoked, but in newer modes it may be a partial list. this is internal, so not critical, but if you're updating some of the other todo javadocs, this would be another nice improvement",1,0.5652771592140198
278798597,6363,ewencp,2019-04-26T03:28:13Z,"nit: just naming, but there's only one `clusterconfigstate` in this test... extra number not necessary",0,0.9854867458343506
278805479,6363,ewencp,2019-04-26T04:29:09Z,same question about `cooperative` enum option as before,0,0.9865661263465881
278806121,6363,ewencp,2019-04-26T04:34:43Z,"we should enable this for sure, at least at some level. they get stored in truncated logs if successful, and (as of recently) we store full logs for debugging purposes if the test fails. tbh, still not sure how we ended up in a log-free state by default -- it just results in having to turn this on manually, and if test failures are not reproducible locally and only in jenkins, this is a huge pain. in fact, i'd happily merge this as a separate pr even before this pr :) aside from performance or excessive logging, for tests there isn't much downside in ratcheting up the log level",-1,0.8175748586654663
278806552,6363,ewencp,2019-04-26T04:38:52Z,"i think nm on this, pretty sure it was moved from other code. just hard to see without loading the full hidden diffs in github review",0,0.9696601033210754
278806717,6363,ewencp,2019-04-26T04:40:29Z,"primary question here is what coverage looks like. `distributedherder.java` now has paths that consider both protocol versions, but looks like these tests are only using `v0` paths. is that ok? based on herder changes, i think loc coverage may not have changed too much, but critical differences might not be well tested now?",0,0.9800066351890564
278807647,6363,ewencp,2019-04-26T04:49:36Z,are we missing other parameterizations? only have one here... `cooperative`?,0,0.9823770523071289
278807823,6363,ewencp,2019-04-26T04:51:38Z,logger or remove?,0,0.986503005027771
278809207,6363,ewencp,2019-04-26T05:04:48Z,this is never a good sign in a test like this. what does this accomplish?,-1,0.937328577041626
278810850,6363,ewencp,2019-04-26T05:18:23Z,"might want to highlight the `balanced` pieces below here, that's ultimately the critical bit beyond just running what we expect (which tbh, makes the most important part of these tests hard to find)",0,0.9726290106773376
278812987,6363,ewencp,2019-04-26T05:36:38Z,"just be wary that this entire loop capturing state is a bit dangerous. of course you don't expect it to happen, but it's possible there is a rebalance (unintentionally due to timeouts) and you get some inconsistent set of results wrt connector state/location. at a bare minimum, tons of repeated tests locally and many repeated tests on jenkins would be warranted here to avoid any potential flakiness, especially given ak jenkins' penchant for unexpected timing issues.",-1,0.8136478662490845
278816564,6363,ewencp,2019-04-26T06:00:17Z,this is the kind of assertion that could become flaky given incremental population of `connectors`.,0,0.9698165059089661
279022852,6363,kkonstantine,2019-04-26T16:40:18Z,"you are right, this used to be bad, but for a few java versions now, the compiler is able to substitute [a link] to `stringbuilder` on the bytecode. for this class, what i get from: `javap -c connectassignment.class | less` is: [code block] based on that i avoid `+` in loops but in constant expression as this one i keep using `+` for readability. i'm inclined to leave it here, since i'd expect this transformation will be common among java compilers but i can also hardcode `stringbuilder`. wdyt?",-1,0.6727880239486694
279027503,6363,kkonstantine,2019-04-26T16:54:39Z,"chose to be on the safe side and map to what we've been doing already in `connectprotocol#asmap`: [a link] and [a link] if we feel confident to diverge on the new protocol (slightly here), i'm happy to do that.",1,0.9577862620353699
279086507,6363,kkonstantine,2019-04-26T20:04:33Z,"since we use `assert` in a few places already, i'll use `assert` here too. let me know if you had something else in mind.",0,0.987117350101471
279086549,6363,kkonstantine,2019-04-26T20:04:40Z,done here and below,0,0.9833357334136963
279087129,6363,kkonstantine,2019-04-26T20:06:37Z,typo since this was added after v1 javadocs. however the descriptions are correct. nothing should be v1 in this class.,0,0.9852897524833679
279087208,6363,kkonstantine,2019-04-26T20:06:56Z,same typo as above. format is correct,0,0.9842306971549988
279088293,6363,kkonstantine,2019-04-26T20:11:01Z,"if i understand correctly, you are suggesting something similar to what suggested. keep case insensitivity but remove the map. i'll apply this change.",0,0.979212760925293
279088613,6363,kkonstantine,2019-04-26T20:12:09Z,comments are not in chronological order :) i hope you find inline validations useful and we can keep this. should i submit another pr with some unit tests?,1,0.9907222986221313
279089415,6363,kkonstantine,2019-04-26T20:14:45Z,"indeed, this code is not an addition. it's moved from `workergroupmember` _as-is_ to your point, here, every time i reload i search for ""load diff"" and i load the hidden files. thankfully only 5 or 6 so far :)",1,0.8916910886764526
279100216,6363,kkonstantine,2019-04-26T20:52:48Z,got a second comment on that. changed to runtime check.,0,0.9816458225250244
279135611,6363,kkonstantine,2019-04-27T00:28:05Z,"it was moved inside `onjoinprepare`. that's because now `onrevoked` might also be called in `onjoincomplete`. but this wouldn't mean that a ""rebalance started"".",0,0.9816954135894775
279136107,6363,kkonstantine,2019-04-27T00:36:22Z,"i did inject it elsewhere, especially after 's comment. but this was somehow missed even though i thought i grepped. fixed",0,0.9421615600585938
279136319,6363,kkonstantine,2019-04-27T00:39:55Z,"you are bringing up a good point. i considered `connectassignment` more involed and worthy of factoring out to its own class, but not `workerstate`. we haven't decided what we'll do yet, but i'm more inclined to suggest `connectassignment` and `connectworkerstate` as separate classes. wdyt?",1,0.8183620572090149
279136441,6363,kkonstantine,2019-04-27T00:41:59Z,`cooperative` was removed as per the latest comments on the kip (the point was brought up by ). there's was a missed javadoc reference which i've just removed. only `eager` and `compatible` atm.,0,0.9883461594581604
279136636,6363,kkonstantine,2019-04-27T00:45:28Z,i agree,0,0.934429407119751
279136696,6363,kkonstantine,2019-04-27T00:46:30Z,"maybe you started reviewing when it hadn't been removed. as mentioned in a comment above, `cooperative` has been removed to reflect the kip.",0,0.988248348236084
279136963,6363,kkonstantine,2019-04-27T00:51:25Z,i thought i had a use of it :) removed now.,1,0.8936334848403931
279137024,6363,kkonstantine,2019-04-27T00:52:32Z,:) if i understand correctly this is not actionable immediately,1,0.9643937349319458
279586499,6363,kkonstantine,2019-04-30T00:33:51Z,make sense. updated!,1,0.573356032371521
279587083,6363,kkonstantine,2019-04-30T00:38:25Z,i'm also hugely in favor of tests that don't depend on `sleep`. probably this was left here since earlier stages of manual debugging with these tests. removed from all tests. if needed the assertions will be improved.,0,0.8591759204864502
279587559,6363,kkonstantine,2019-04-30T00:41:53Z,"indeed. i'm saving this comment of yours for better verification of flakiness. given that reviews are in progress still, i haven't run integration tests in repeated mode, but i'll definitely do so before merging and will tighten the assertions if needed.",0,0.7778526544570923
279587997,6363,kkonstantine,2019-04-30T00:45:04Z,maybe you are referring to the assertion for imbalanced assignment? because the assignment being unique should be a strong deterministic requirement. but i agree with a holistic review of the assertions here.,0,0.9689024090766907
279588163,6363,kkonstantine,2019-04-30T00:46:18Z,fixed!,0,0.698331356048584
279588578,6363,kkonstantine,2019-04-30T00:49:31Z,"indeed, the unit testing gaps currently are found here here and in `workercoordinatorincrementaltest`. these will be filled asap. but wanted to first get a round of reviews on the protocol, because these tests will pin the checks on the proposed functionality tbh (as opposed to integration tests for example). definitely a known gap atm.",0,0.9774412512779236
279588748,6363,kkonstantine,2019-04-30T00:50:41Z,"so, `cooperative` was removed, but i left the parameterization just in case we go back and for between `eager` and `compatible` still here (or the original `workercoordinatortest`). i might as well remove it if not.",0,0.9883784651756287
279588838,6363,kkonstantine,2019-04-30T00:51:20Z,debugging leftover probably.,0,0.9809510707855225
279589061,6363,kkonstantine,2019-04-30T00:53:14Z,"as mentioned above, `cooperative` was removed. left, in case some common tests are covered by both (although the assertions might be affected - hence the 1 failure i've left hanging around still so we don't have the impression that we are done with those unit tests).",0,0.9860135912895203
279589343,6363,kkonstantine,2019-04-30T00:55:29Z,"removed, thanks!",1,0.8416443467140198
279590175,6363,kkonstantine,2019-04-30T01:02:09Z,"totally agree too. this is indeed weird given that the two commits that refer to this file, don't show evidence of when this change happened. i'll submit another pr that can backported. thanks!",1,0.9749064445495605
280291175,6363,rhauch,2019-05-02T05:20:11Z,"okay, that makes sense. but it might be nice to denote that requirement with a short comment.",0,0.962530255317688
280291571,6363,rhauch,2019-05-02T05:24:51Z,i agree with (on a [a link] that a validator on the scheduled rebalance max delay is probably pretty beneficial to ensure non-negative values.,0,0.9672063589096069
280292191,6363,rhauch,2019-05-02T05:30:53Z,+1,0,0.696722686290741
280292897,6363,rhauch,2019-05-02T05:36:54Z,"wouldn't it be helpful here to have more debug or trace logs in this method? i worry that without them, it's going to be hard to track what this logic is doing. it may makes sense to refactor a bit to have a single return preceded by a log message, rather than having multiple log messages for each of the returns.",-1,0.6978618502616882
280292977,6363,rhauch,2019-05-02T05:37:44Z,same comment hear about adding more debug/trace logging for most of the branches.,0,0.9870424270629883
280294446,6363,rhauch,2019-05-02T05:51:26Z,"and given ewen's [a link], if `completeworkerassignment` is not different than `currentworkerassignment`, then will `connectorassignments` be any different than before, and `taskassignments` be any different than before?",0,0.9880383014678955
280294974,6363,rhauch,2019-05-02T05:56:18Z,"it'd be really great to have unit tests for many of these methods. the `performtaskassignment(...)` method is already pretty lengthy, and there are just a few unit tests whereas there seem to be lots of permutations and branches. not only would they help with confidence, but they'd help with regression testing if/when we have to get back into this code.",1,0.8428462743759155
280295034,6363,rhauch,2019-05-02T05:56:45Z,ping,0,0.9714881777763367
280295298,6363,rhauch,2019-05-02T05:58:58Z,"right, but everything in the for loop starting on line 335 (except for the return on line 347) is dealing with debug logging, right? if so, then line 336 could be moved into this debug-only block.",0,0.9888505339622498
280295967,6363,rhauch,2019-05-02T06:04:40Z,isn't it possible that some of these are 0 due to integer division truncating? seems like all 4 of these lines could be replaced with something like: [code block],0,0.9814769625663757
280296761,6363,rhauch,2019-05-02T06:10:52Z,"+1. the value of logging in this whole class is not really going to be knowing the final end state, but being able to track the logic in this class to figure out why the end state doesn't match an expected state on some user's connect cluster, and hopefully being able to learn enough to understand what paths are taken so that we can reproduce the case. the other approach is to log all of the initial state up front and all of the new state at the end, such that with that information we could reproduce any logged scenario with a unit test that we can then debug to trace the logic.",0,0.9299296736717224
280296881,6363,rhauch,2019-05-02T06:11:51Z,ping,0,0.9714881777763367
280297070,6363,rhauch,2019-05-02T06:13:38Z,i think it'd be useful to have just one style of javadoc.,0,0.9633324146270752
280297285,6363,rhauch,2019-05-02T06:15:29Z,+1 on the separate classes.,0,0.9437334537506104
280297897,6363,rhauch,2019-05-02T06:20:00Z,"right, and that would be easier to unit test, too.",0,0.9664639830589294
283517005,6363,kkonstantine,2019-05-13T20:15:26Z,"as mentioned this was an insightful observation. returning to this after i added several tests on the assignor code. we have the following two cases: 1) the assignment is computed by the assignor, it contains only revocations and it fails to be delivered. in the next round of rebalancing this failure to change the state of revoked tasks is detected by the assignor, and instead of skipping revocation according to its policy that mandates that there's no consecutive revocations, it re-applies revocation of tasks. this should happen until the assignment containing the revoked tasks succeeds. 2) the assignment is computed by the assignor, it contains only assignments and it fails to be delivered. distinguishing this case from the case that active assignments are detected as lost, would result in a more complicated logic of the assignor's state machine. instead of doing that, the current code, selects to interpret the failed assignment as referring to lost tasks and therefore it enters the deferred rebalancing period, with the specified delay. i believe this keeps things simpler. in a sense whether a worker goes down, or an assignment fails to be delivered, are both considered failures that takes us to the deferred rebalancing logic. the current unit tests currently confirm this behavior. wdyt ?",0,0.6754148006439209
283518084,6363,kkonstantine,2019-05-13T20:18:05Z,"my rule of thumb is that i include in a if statement only the debug statements that would result in eager (and potential wasteful) computation of print arguments. the rest of the debug logging is kept outside the if branch, which will allow us to remove the if branch altogether if the line that requires it is removed. otherwise, we risk keeping redundant `if`s around.",0,0.9475896954536438
283528795,6363,kkonstantine,2019-05-13T20:44:26Z,"this test class, now called `incrementalcooperativeassignortest` has been significantly extended to include a big set of tests for the new assignor. resolving this comment and will follow up on other test additions.",0,0.9877254366874695
283529644,6363,kkonstantine,2019-05-13T20:46:37Z,changed to an explicit call to `compatible.protocol()`. resolving this comment. thanks,1,0.9478648900985718
283530355,6363,mumrah,2019-05-13T20:48:19Z,i think that sounds reasonable. thanks for the follow-up !,1,0.9617038369178772
283530780,6363,kkonstantine,2019-05-13T20:49:28Z,`sleep` statements have been removed.,0,0.9826715588569641
283553403,6363,kkonstantine,2019-05-13T21:54:32Z,fixed,0,0.975196123123169
283555350,6363,kkonstantine,2019-05-13T22:00:53Z,removed,0,0.9654131531715393
283557138,6363,kkonstantine,2019-05-13T22:07:18Z,i see your point. when i initially imported this comment _as-is_ i considered it non-javadoc comment and then i added javadoc. upgraded as javadoc now.,0,0.951259970664978
283557471,6363,kkonstantine,2019-05-13T22:08:34Z,fixed. `stream` is used now instead of a static map.,0,0.9883149862289429
283558392,6363,kkonstantine,2019-05-13T22:11:56Z,"given the generated bytecode, i'll keep the current form of `tostring` if you don't mind. resolving here, but feel free to comment if you feel otherwise.",0,0.950114905834198
283562360,6363,kkonstantine,2019-05-13T22:27:52Z,"added `between(0, integer.max_value)`",0,0.9868157505989075
284026277,6363,rhauch,2019-05-14T22:34:22Z,"i see what ewen is suggesting - it definitely could be confusing. concretely, at a minimum, rename `connectassignment` -> `incrementalcooperativeassignment` to tie it more closely with the `incrementalcooperativeconnectprotocol`. (even if we think it *might* be useful in a future protocol, we can refactor if/when that happens.) the design in this pr doesn't follow the `consumerprotocol` and `consumerassignor` model too closely. there, the assignor methods dealt with `subscription` and `assignment` types, and so those were defined in the `consumerassigner` class. the `consumerprotocol` just serialized those types. in the current design, the `connectassignor` doesn't deal with the `assignment` and `workerstate` types, and so defining those types in the `connectassignor` class doesn't make much sense. instead, the different `connectassignor` subclasses use their respective protocol in their implementation of `performassignment(...)`. given this difference, i suggest that we simply rename all of the classes that go with the incremental cooperative protocol / assignor to begin with `incrementalcooperative`.",0,0.9519156217575073
284026633,6363,rhauch,2019-05-14T22:35:33Z,+1,0,0.696722686290741
284035771,6363,rhauch,2019-05-14T23:15:43Z,"when a user has this in their logs, what do they do? maybe add a bit more detail to this log message that lets them know what action they could/should perform, if any. when would the member configs be empty?",0,0.9844616055488586
284037825,6363,rhauch,2019-05-14T23:25:06Z,thoughts on this now that you've been running this a while in tests and in soak?,0,0.948677122592926
284066405,6363,rhauch,2019-05-15T02:25:31Z,"is there _any_ chance we might have `totalworkersnum` might be 0, resulting in termination of the worker?",0,0.9791545271873474
284067290,6363,rhauch,2019-05-15T02:31:49Z,"`connectorsandtasks.embed(new arraylist<>(), new arraylist<>())` is called 5 places in non-test code. wdyt about adding a `connectorsandtasks.create()` method to reduce the code a bit?",0,0.989467442035675
284067493,6363,rhauch,2019-05-15T02:33:14Z,"if you believe debug logging is sufficient at this point to be able to track behavior based only on logs, then go ahead and resolve this conversation. if not, maybe consider adding more in key places.",0,0.9792769551277161
284067892,6363,kkonstantine,2019-05-15T02:35:47Z,"actually, the current form, that prints each assignment set separately has been working out nicely in the logs even with lots of connectors. what i think is key, is to use `assignments: ` suffix (or similar) in the end. this way you can grep/collect these lines all together focusing on the logger of this class as well (either via log4j or again by grepping). the fact that these assignments (every set) are printed in a separate line makes the lineage of the assignment process easy to follow. i'll review their final message but again, i'm inclined to retain a common substring and have each one in their own line. rebalancing is happening in certain moments, so there's no significant issue with verbosity here.",0,0.7365683913230896
284068513,6363,rhauch,2019-05-15T02:39:42Z,these methods will sort `completeworkerassignment` -- is that worth a comment above these two lines?,0,0.988827109336853
284068845,6363,rhauch,2019-05-15T02:42:03Z,i guess i'm a bit surprised that this method modifies `workerassignments`. maybe mention in the `` description here and in `assignconnectors(...)`?,0,0.56000816822052
284069392,6363,rhauch,2019-05-15T02:45:59Z,"these assign methods are pretty boilerplate, with i think just 2 lines in each that is distinct (the log line and the worker.assign call). did you consider pulling into a method and supplying a bi-function that takes the connectortaskid and the worker?",0,0.8792617321014404
284069861,6363,kkonstantine,2019-05-15T02:49:38Z,it's mutated by: [code block] i see your point and we might be able to consolidate. but i feel that this is higher risk low value optimization at this point. i'm more inclined to leave a comment for a future refactoring.,-1,0.6522276997566223
284070224,6363,rhauch,2019-05-15T02:52:11Z,"one thing that would be nice to have: what are the characteristics of the parameters and returned map? for example, is it possible that the returned map contain null `bytebuffer` reference, and if so what does that mean?",0,0.9800384640693665
284070727,6363,rhauch,2019-05-15T02:55:39Z,"but at least on the first line of this method, wouldn't it make sense to use an `connectassignment.isempty()` method here, rather than relying upon instance equality? same behavior, but that would seem less brittle.",0,0.9739495515823364
284071019,6363,rhauch,2019-05-15T02:57:18Z,"i added a comment regarding this regarding the `connectassignor.performassignment(...)` method's javadoc. iiuc, it's possible that the returned `map ` can contain a null byte buffer reference. is null allowed / handled everywhere this method (and others) are used?",0,0.9892110824584961
284071662,6363,rhauch,2019-05-15T03:01:55Z,though wouldn't it be helpful to have the names of the classes related to the incremental protocol all start with `incrementalcooperative`? this is related to my earlier comment (previous review).,0,0.9878336191177368
284072023,6363,rhauch,2019-05-15T03:04:32Z,+1,0,0.696722686290741
284072326,6363,kkonstantine,2019-05-15T03:06:58Z,these are now specifically tested in `incrementalcooperativeassignortest` alone and as part of the tests cases for `performtaskassignment`. also tested in `workercoordinatorincrementaltest`,0,0.9864872097969055
284072920,6363,rhauch,2019-05-15T03:10:59Z,"we're starting 4 connectors, so should we check that all 4 are running?",0,0.9877419471740723
284072977,6363,rhauch,2019-05-15T03:11:28Z,"we're starting 4 connectors, so should we check that all 4 are running?",0,0.9877419471740723
284073066,6363,rhauch,2019-05-15T03:12:15Z,", can you provide an update?",0,0.9865173101425171
284073384,6363,rhauch,2019-05-15T03:14:30Z,can you provide an update?,0,0.9878739714622498
284074000,6363,rhauch,2019-05-15T03:18:48Z,what is the status of these tests that are commented out?,0,0.9802636504173279
284365134,6363,kkonstantine,2019-05-15T17:22:13Z,"indeed, when a `joingroupresponse` is received with no errors (`errors.none` in errors field) the response will have at least the leader itself as a member. removed this warning because it's a no-op.",0,0.9857990741729736
284366320,6363,kkonstantine,2019-05-15T17:25:18Z,"true. i'd like as part of this pr to apply minimal or no changes to v0 (now eager) protocol. also, as opposed to `connectprotocol` the overlap between the two assignor implementations is quite small, so i think subclassing is not worth it here. i suggest we consider a refactoring (including any helper methods in utils classes) in a subsequent iteration/cleanup.",0,0.9290508031845093
284366792,6363,kkonstantine,2019-05-15T17:26:35Z,good point. moved to builder pattern,1,0.9756514430046082
284367865,6363,kkonstantine,2019-05-15T17:29:02Z,we need the aggregated result of the assignment and creating a new list that we return as a result doesn't worth it i think. i'll update the javadoc to make it more clear. the signature of the method without a return type should also be a hint.,0,0.9786807894706726
284370260,6363,kkonstantine,2019-05-15T17:34:35Z,i see your point. but given that currently we provide only reference equality i wouldn't like to hide this fact within an `isempty` method that would implement this reference equality check. i wouldn't like this to be confused with an assignment that it just has no assigned or revoked resources at the moment.,0,0.5763053894042969
284374327,6363,kkonstantine,2019-05-15T17:45:05Z,fixed and improved all the logs in this method,0,0.9840657114982605
284375015,6363,kkonstantine,2019-05-15T17:46:44Z,fixed by introducing builders for both inner classes here.,0,0.9873490333557129
284375778,6363,kkonstantine,2019-05-15T17:48:22Z,"this remains the case. but for reasons of symmetry with `connectorsandtasks` which is similar i'm inclined to retain this for now, if that's ok.",0,0.9794082045555115
284381964,6363,kkonstantine,2019-05-15T18:02:28Z,i'll add a temp edit to `jenkins.sh` and will run the connect tests (unit and integration) in repeat today. locally i have not noticed flakiness after several runs.,0,0.9835911393165588
284388778,6363,kkonstantine,2019-05-15T18:19:34Z,leftovers of an early import of tests. removed.,0,0.9796367287635803
284539491,6363,kkonstantine,2019-05-16T05:00:16Z,"as discussed briefly offline, the new classes are now both separate public classes and are called `extendedassignment` and `extendedworkerstate`. one of the primary intentions is to leave the current protocol version (v0) with minimal changes. a subsequent refactoring in one of the next version could consolidate the two classes (maybe with a better name).",0,0.9869166612625122
284539787,6363,kkonstantine,2019-05-16T05:02:43Z,"dynamic dispatch is not very easy or elegant here, because the protocol classes are effectively static classes (have only static methods) and we can't hold on to a reference on their instance and use inheritance effectively. i've moved the creation of `joingrouprequestprotocolcollection` in the protocols though, and now the `switch` block (which i also dislike compared to dynamic dispatch) is small.",0,0.8590034246444702
284541423,6363,kkonstantine,2019-05-16T05:14:14Z,the above pr is merged. i removed this temp commit. thanks for reviewing!,1,0.9829997420310974
284542971,6363,kkonstantine,2019-05-16T05:25:34Z,"as mentioned in another thread, the classes are now named `extendedassignment` and `extendedworkerstate` respectively",0,0.9867566823959351
284544064,6363,kkonstantine,2019-05-16T05:32:48Z,i have now added tests related to the new rebalancing protocol in this class too. (also the worker coordinator tests as well).,0,0.9850282669067383
284834540,6363,kkonstantine,2019-05-16T18:13:23Z,added: ` // we have at least one worker assignment (the leader itself) so totalworkersnum can't be 0`,0,0.9672867059707642
284834759,6363,kkonstantine,2019-05-16T18:13:54Z,same reason why we removed a warning about empty `memberconfigs` above,0,0.9870797991752625
284835203,6363,kkonstantine,2019-05-16T18:15:00Z,this block now reads: [code block] we shouldn't mind these averages being 0. this means there's not much to revoke.,0,0.9695613384246826
284843672,6363,kkonstantine,2019-05-16T18:36:05Z,added,0,0.9735139608383179
284845286,6363,kkonstantine,2019-05-16T18:39:52Z,this sorting should not matter in any decision. it does it to apply weighted round-robin internally. but the order in the list of assignments does not matter.,0,0.9608009457588196
284845721,6363,kkonstantine,2019-05-16T18:40:50Z,"i've added and improved debug logs. if during additional testing we consider that some info logs are warranted, we could return here.",0,0.9816027283668518
284846327,6363,kkonstantine,2019-05-16T18:42:15Z,add clarification.,0,0.9860469698905945
284846980,6363,kkonstantine,2019-05-16T18:43:45Z,i'll create a ticket for future refactoring to address this.,0,0.9836086630821228
284847996,6363,kkonstantine,2019-05-16T18:46:11Z,made `leaderstate` private. but `currentprotocolversion` is used by `workergroupmember`,0,0.9854344129562378
284849064,6363,kkonstantine,2019-05-16T18:48:59Z,`null` value for the `bytebuffer` value of this map is not allowed. every member should have an assignment even if it's empty.,0,0.9791116714477539
284849278,6363,kkonstantine,2019-05-16T18:49:35Z,at this point i will clear this if needed in a subsequent cleanup/refactoring after more testing is applied.,0,0.98478102684021
284849517,6363,kkonstantine,2019-05-16T18:50:12Z,this is also candidate for subsequent refactoring. will create a jira ticket.,0,0.9863907098770142
284849946,6363,kkonstantine,2019-05-16T18:51:18Z,"i'll leave the old method unchanged, but we can also consider enhancement during the refactoring described in other comments that will follow-up.",0,0.9881224036216736
284850119,6363,kkonstantine,2019-05-16T18:51:48Z,"also, leaving as-is since it's the old code. but will revisit",0,0.9866238832473755
284850476,6363,kkonstantine,2019-05-16T18:52:51Z,at this point i will avoid the risk of optimizations and will include this in the ticket that will revisit tuning of the new rebalancing code. thanks!,1,0.9777308702468872
284853764,6363,kkonstantine,2019-05-16T19:01:54Z,i'm disabling the assertion at the moment because it results in flaky runs on jenkins. will return to it in a separate pr. thanks!,1,0.9267557263374329
284876254,6363,ryannedolan,2019-05-16T20:06:57Z,"instead of biconsumer here, and relying on exceptions to pass validation errors back to the caller, maybe this should be `(k, v) -> error`?",0,0.9858545660972595
284879355,6363,ryannedolan,2019-05-16T20:15:45Z,"would be nice to roll up this re-throw into ensurevalid(), i.e. catch the exception and format a general error message there.",0,0.970223069190979
284879788,6363,ryannedolan,2019-05-16T20:16:54Z,it's strange to rely on runtimeexceptions for validation like this. maybe narrow to configexceptions at least.,-1,0.8169716000556946
284882011,6363,kkonstantine,2019-05-16T20:22:55Z,i think the current pattern works. i'll resolve this comment.,0,0.9778844714164734
284882177,6363,ryannedolan,2019-05-16T20:23:22Z,:party_popper:,0,0.974899411201477
284882599,6363,kkonstantine,2019-05-16T20:24:25Z,good points. let's revisit in a follow up cleanup/refactoring since this is not critical atm.,1,0.9701400399208069
284883108,6363,kkonstantine,2019-05-16T20:25:43Z,"again here the difficulty is part due to protocol classes being effectively static. since it's not critical for the initial version of the new rebalancing, let's revisit in a follow-up.",0,0.9753550291061401
284883316,6363,kkonstantine,2019-05-16T20:26:08Z,see comment above about protocol classes being effectively static.,0,0.9844728112220764
284884565,6363,kkonstantine,2019-05-16T20:29:30Z,made `protected` and added several tests in `incrementalcooperativeassignortest`,0,0.9875646233558655
284886129,6363,ryannedolan,2019-05-16T20:33:54Z,i think this is a lot of gymnastics to avoid writing a couple `if`s and `for`s.,0,0.8016186952590942
284886324,6363,kkonstantine,2019-05-16T20:34:28Z,"since this doesn't influence the actual schemas of the protocols, i'd also suggest to punt to the next refactoring/cleanup of the protocol classes.",0,0.9863096475601196
284919786,6363,kkonstantine,2019-05-16T22:20:49Z,the current form maps exactly to `ensurevalid` in the validator interface. this addition here is minor. i'd suggest discussion any improvements on config defs in a separate pr/jira issue.,0,0.9892584681510925
284920523,6363,kkonstantine,2019-05-16T22:24:05Z,"again, this is added for convenience. it's not implementing the validation as other validators do in this class. what developers chooses to throw here, is their own responsibility, as when they implement the `validator` interface.",0,0.9816505312919617
284920787,6363,kkonstantine,2019-05-16T22:25:25Z,"not a bad idea. but at the moment, i'd suggest taking improvements on this code in a separate pr",0,0.7339235544204712
284921328,6363,kkonstantine,2019-05-16T22:27:32Z,this is a two line lambda still and straightforward. still not in any critical path of this pr.,0,0.9734660387039185
284921479,6363,kkonstantine,2019-05-16T22:28:18Z,i've kept uniqueness requirement but have removed assertion around balancing atm.,0,0.986828088760376
284952509,6363,kkonstantine,2019-05-17T01:34:30Z,10 successful consecutive runs of all the connect tests (including integration tests). [a link],0,0.9628801345825195
284952789,6363,kkonstantine,2019-05-17T01:36:30Z,here just confirming that they've started to go to the next phase (which is to remove a worker). not an assertion of the connectors per se. but i agree we could tighten it in a subsequent iteration.,0,0.9818909764289856
220729441,5582,rajinisivaram,2018-09-26T21:27:38Z,i remember i had `supportsclientreauth` and `supportsserverreauth` in my commit. it may be worth checking if we can have a single `supportsreauth` method and have the caller track mode.,0,0.987572431564331
220729477,5582,rajinisivaram,2018-09-26T21:27:44Z,confusing to have `supportsclientreauth` and `clientsupportsreauthentication`. perhaps `supportsreauth` instead of `supportsclientreauth` and `remotesupportsreauth` instead of `clientsupportsreauthentication` (or something along those lines)?,-1,0.7450628876686096
220730428,5582,rajinisivaram,2018-09-26T21:31:36Z,"can't all this be done in the authenticator? we can move it to some shared class later if we need it in two places, but for now we just need this in `saslclientauthenticator`?",0,0.989474356174469
220732429,5582,rajinisivaram,2018-09-26T21:39:59Z,i thought we weren't supporting re-authentication or connection termination for ssl. why do we need time?,0,0.9431571960449219
220732576,5582,rajinisivaram,2018-09-26T21:40:38Z,"as before with ssl, can we avoid tracking time unless it is actually used?",0,0.9860833287239075
220735918,5582,rajinisivaram,2018-09-26T21:54:37Z,we have to avoid invoking an extra `time.milliseconds()` for every request. actual time should get propagated from the caller.,0,0.9820826053619385
220736421,5582,rajinisivaram,2018-09-26T21:56:25Z,"`kafkachannel` is a network-layer class, not a security-related class, so this should perhaps say `authenticationsession` or something like that to make it more obvious.",0,0.9866936802864075
220736573,5582,rajinisivaram,2018-09-26T21:57:12Z,why do we need this?,0,0.9493659734725952
220740223,5582,rajinisivaram,2018-09-26T22:14:17Z,"seeing it here, the metric name doesn't look right. `v0` refers to saslauthenticaterequest version. perhaps `sasl-authentication` with tag `version=0` or something similar to our request metrics which has apikey and version would be better?",0,0.9768908619880676
220740427,5582,rajinisivaram,2018-09-26T22:15:20Z,why are we tracking time here?,0,0.9568188786506653
220741020,5582,rajinisivaram,2018-09-26T22:18:09Z,should this be `session_lifetime_ms`?,0,0.9885295033454895
220741102,5582,rajinisivaram,2018-09-26T22:18:29Z,as before `sessionlifetimems`?,0,0.9883044958114624
220742581,5582,rajinisivaram,2018-09-26T22:25:48Z,"do we need to track `interestedinwritingimmediatelyafterreauthentication`? aren't we starting reauthentication during write, so this would always be true?",0,0.9888518452644348
220745052,5582,rajinisivaram,2018-09-26T22:38:53Z,the comment is now incomplete. don't we still throttle in some cases?,0,0.9427860975265503
220745279,5582,rajinisivaram,2018-09-26T22:40:03Z,this code looks totally out of place here.,-1,0.9133605360984802
220786458,5582,rondagostino,2018-09-27T03:49:07Z,":thumbs_up: i eliminated these two methods by adding `long clientsessionreauthenticationtimems()` and `long serversessionexpirationtimenanos()`. these new methods only ever return non-null on the client and server, respectively. `clientsessionreauthenticationtimems()` now contains the 85%-95% calculation that was in `kafkachannel` and you asked if it could be moved into the authenticator.",0,0.9326875805854797
220786477,5582,rondagostino,2018-09-27T03:49:21Z,:thumbs_up: i've renamed this to be `boolean connectedclientsupportsreauthentication()` which is clear and no longer is close to any other method names since i eliminated the other two that were close as described above.,0,0.963551938533783
220786498,5582,rondagostino,2018-09-27T03:49:30Z,:thumbs_up: i moved this into `saslclientauthenticator` -- the percentage calculation is now factored into the return value of `clientsessionreauthenticationtimems()`,0,0.9141388535499573
220786511,5582,rondagostino,2018-09-27T03:49:40Z,":thumbs_up: we don't need time. i added it in order to support the `long sessionbegintimems()` method i had added to `authenticator`, but now that the percentage calculation is moved into `saslclientauthenticator` we don't need the `sessionbegintimems()` method on `authenticator` anymore. this file is now untouched.",0,0.9213952422142029
220786528,5582,rondagostino,2018-09-27T03:49:47Z,":thumbs_up: agreed, same as above: i added it in order to support the `long sessionbegintimems()` method i had added to `authenticator`, but now that the percentage calculation is moved into `saslclientauthenticator` we don't need the `sessionbegintimems()` method on `authenticator` anymore. this file is now untouched.",0,0.9693463444709778
220786549,5582,rondagostino,2018-09-27T03:49:59Z,:thumbs_up: i moved the server-side-kill check from `kafkaapis` to `kafkarequesthandler` and now i pass in the nanos time that was already calculated.,0,0.9702813029289246
220786564,5582,rondagostino,2018-09-27T03:50:08Z,:thumbs_up: it is now `boolean serverauthenticationsessionexpired(long nanos)`,0,0.9206621050834656
220786574,5582,rondagostino,2018-09-27T03:50:12Z,":thumbs_up: we don't need this. i added it in order to support the `long sessionbegintimems()` method i had added to `authenticator`, but now that the percentage calculation is moved into `saslclientauthenticator` we don't need the `sessionbegintimems()` method on `authenticator` anymore. this file is now untouched.",0,0.9125840067863464
220786590,5582,rondagostino,2018-09-27T03:50:19Z,":thumbs_up: we don't need this. i added it in order to support the `long sessionbegintimems()` method i had added to `authenticator`, but now that the percentage calculation is moved into `saslclientauthenticator` we don't need the `sessionbegintimems()` method on `authenticator` anymore. this file is now untouched.",0,0.9125840067863464
220786604,5582,rondagostino,2018-09-27T03:50:30Z,":thumbs_up: yes, it is always true -- i removed it.",0,0.9675465226173401
220786622,5582,rondagostino,2018-09-27T03:50:40Z,":thumbs_up: i moved it to `kafkarequesthandler` which also has the side-effect of making a nanosecond time value available for the comparison, which means we can eliminate the call to `time.milliseconds()` on every request that you had flagged as problematic.",0,0.9723253846168518
220789008,5582,rondagostino,2018-09-27T04:13:55Z,"i realized today that we also have to count the connections from older clients that do not send sasl_authenticate. so it might be good to not refer to ""version"" at all. maybe it is best to not refer to ""sasl"" either? how about `successful-authentication-no-reauth` as the metric name? then maybe we don't need a special tag? if we still do need a tag then maybe `reauthsupport=false` to avoid referring to ""version""?",0,0.9714415669441223
220789699,5582,rondagostino,2018-09-27T04:21:00Z,"not sure. i changed the names of the methods on `authenticator` so that we now have `serversessionexpirationtimenanos()` and `clientsessionreauthenticationtimems()`. this value is communicating the expiration time, and then the `saslclientauthenticator` applies the 85%-95% factor to get a re-authentication time. based on this, it probably shouldn't have ""reauth"" in the name since that implies the factor has been applied -- which it has not at this point. so i think yes, it should be session_lifetime_ms. do you agree? if so i will change -- just confirm or suggest otherwise.",0,0.9776713848114014
220791745,5582,rondagostino,2018-09-27T04:41:24Z,:thumbs_up: i adjusted the javadoc. let me know if it is now more accurate.,0,0.9462454915046692
220917846,5582,rondagostino,2018-09-27T13:15:36Z,"oops, the file is not untouched -- just the sections related to ssl and plaintext are untouched.",0,0.5638810396194458
220917981,5582,rondagostino,2018-09-27T13:15:59Z,"again, oops, the file is not untouched -- just the sections related to ssl and plaintext are untouched.",-1,0.6631345152854919
220919003,5582,rondagostino,2018-09-27T13:19:09Z,"oops, the file is not untouched because it still needs to send in a `supplier ` rather than `authenticator` when it creates a `kafkachannel` -- but the reference to `time` is now gone.",0,0.8840543627738953
220919332,5582,rondagostino,2018-09-27T13:20:07Z,"again, oops, the file is not untouched because it still needs to send in a `supplier ` rather than `authenticator` when it creates a `kafkachannel` -- but the reference to `time` is now gone.",0,0.7615897059440613
221238033,5582,rondagostino,2018-09-28T12:37:26Z,:thumbs_up: changing to session_lifetime_ms,0,0.8478710651397705
221238079,5582,rondagostino,2018-09-28T12:37:35Z,:thumbs_up: changing to sessionlifetimems,0,0.957499623298645
221241246,5582,rondagostino,2018-09-28T12:49:59Z,changing to `successful-authentication-no-reauth-total` without extra tags.,0,0.9868332743644714
221574183,5582,rajinisivaram,2018-10-01T11:23:19Z,using a combination of nanos and millis in the reauthentication logic is very error-prone.,-1,0.620525598526001
221575447,5582,rajinisivaram,2018-10-01T11:28:04Z,propagate time since we have tests that use mocktime.,0,0.9866431951522827
221576245,5582,rajinisivaram,2018-10-01T11:31:42Z,this is either a local client connection (on a client or inter-broker connection) or a remote client connection (on a broker).,0,0.9859074354171753
221576504,5582,rajinisivaram,2018-10-01T11:32:58Z,can we move this below the `final` fields?,0,0.9881780743598938
221580005,5582,rajinisivaram,2018-10-01T11:47:25Z,should this be under the `channel.successfulauthentications() == 1`? presumably a client can use v0 authenticate request and still reauthenticate.,0,0.9902010560035706
221580843,5582,rajinisivaram,2018-10-01T11:50:51Z,`responsesreceivedduringreauthentication.foreach`? also null check looks unnecessary since we guarantee it is never null?,0,0.9822652339935303
221581167,5582,rajinisivaram,2018-10-01T11:52:23Z,could just be part of the previous `if` statement?,0,0.9876790642738342
221581375,5582,rajinisivaram,2018-10-01T11:53:24Z,add `-ms` to the metric names?,0,0.9889950156211853
221581926,5582,rajinisivaram,2018-10-01T11:55:42Z,typo: `lifetime`,0,0.9742555022239685
221582659,5582,rajinisivaram,2018-10-01T11:58:42Z,need to either change the name of this constant or where it is defined. negotiated configs dont come from jaas.,0,0.9500148296356201
221583408,5582,rajinisivaram,2018-10-01T12:02:03Z,also set state to `send_handshake_request`,0,0.9887160658836365
221583541,5582,rajinisivaram,2018-10-01T12:02:42Z,this check is not needed if we set initial state during reauthentication to `send_handshake_request`,0,0.9885318279266357
221583677,5582,rajinisivaram,2018-10-01T12:03:17Z,"same as before, we dont need this if initial state is set for reauthentication,",0,0.9836193919181824
221584414,5582,rajinisivaram,2018-10-01T12:06:25Z,"this should only be done for re-authentication. otherwise it will end up with tight poll loop after authentication if there is nothing to be sent. in general, we need to make sure that we don't change any behaviour for the initial authentication.",0,0.9745274186134338
221585462,5582,rajinisivaram,2018-10-01T12:10:56Z,"on the broker-side, i think we need a minimum re-authentication interval as well to restrict the rate at which clients re-authenticate. this is particularly important since we dont apply any quotas for authentication. without imposing a re-authentication rate limit, a client that enters a re-authentication loop (due to a bug or intentionally) would effectively stop the broker from doing anything useful.",0,0.9721664786338806
221587034,5582,rajinisivaram,2018-10-01T12:16:57Z,we have an exception that is going to result in the connection being closed. seems unnecessary to re-authenticate before closing connection.,0,0.7827776670455933
221587359,5582,rajinisivaram,2018-10-01T12:18:29Z,initiaize in the constructor similar to other fields?,0,0.9865286350250244
221588748,5582,rajinisivaram,2018-10-01T12:23:34Z,"can't we set buffers to a good state from `reauthenticate()` so that this method doesn't have to do anything special for re-authentication? we have received a handshake request, we just need to continue just as with authentication?",0,0.9874001145362854
221589195,5582,rajinisivaram,2018-10-01T12:25:18Z,nit: can we reduce the length of the method name?,0,0.9882217049598694
221591025,5582,rajinisivaram,2018-10-01T12:32:01Z,"in each of the tests, we could check metrics (expired-and-killed in some tests and re-authenticated where expected)",0,0.9867689609527588
221592475,5582,rajinisivaram,2018-10-01T12:37:22Z,this results in errors logged in the broker with stack trace. i don't think we want that.,0,0.8570140600204468
221824499,5582,rondagostino,2018-10-02T04:47:12Z,":thumbs_up: changed so that both use nanos. we need to use nanoseconds on the server side to avoid a call to time.milliseconds() on each request as per previous review comments, so i changed the client side to use nanos as well.",0,0.9589350819587708
221824522,5582,rondagostino,2018-10-02T04:47:24Z,"this class uses the time variable in multiple places already, so i simply replicated the same solution. if we wish to fix all of them then perhaps it can be resolved via a separate ticket as opposed to this kip?",0,0.9862114191055298
221824530,5582,rondagostino,2018-10-02T04:47:31Z,:thumbs_up: definitely; fixed.,1,0.6157863140106201
221824536,5582,rondagostino,2018-10-02T04:47:36Z,:thumbs_up: moved,0,0.9553942680358887
221824549,5582,rondagostino,2018-10-02T04:47:46Z,"we do not record latency for authentication, which is the case where `channel.successfulauthentications() == 1 ` -- the value `channel.reauthenticationlatencyms()` will be null in that case.",0,0.9878805875778198
221824558,5582,rondagostino,2018-10-02T04:47:54Z,"converted to `.foreach`, but we do have to check for null since that is the default (javadoc says null is possible, which it is)",0,0.9886423945426941
221824568,5582,rondagostino,2018-10-02T04:48:00Z,:thumbs_up: fixed,0,0.9233655333518982
221824578,5582,rondagostino,2018-10-02T04:48:06Z,"`request-latency-avg` and `request-latency-max` don't have it (neither do `commit-latency`, `poll-latency`, and `process-latency` metrics). assume this means it should remain as-is.",0,0.986729621887207
221824588,5582,rondagostino,2018-10-02T04:48:11Z,:thumbs_up: fixed,0,0.9233655333518982
221824625,5582,rondagostino,2018-10-02T04:48:16Z,:thumbs_up: created `org.apache.kafka.common.security.authenticator.saslutils` to hold this constant.,0,0.9490718841552734
221824632,5582,rondagostino,2018-10-02T04:48:23Z,:thumbs_up: i created a `process_apiversions_response` state where we process the response we got -- either from the server in the auth case or from the previous authenticator in the re-auth case. this will be the initial state when re-authenticating. i think this makes it clear what is going on.,0,0.8917810320854187
221824639,5582,rondagostino,2018-10-02T04:48:29Z,:thumbs_up: removed,0,0.9636431336402893
221824664,5582,rondagostino,2018-10-02T04:48:45Z,":thumbs_up: agreed, no longer needed -- the initial state for client-side re-authentication is now `process_apiversions_response`.",0,0.9825050234794617
221824673,5582,rondagostino,2018-10-02T04:48:51Z,":thumbs_up: fixed. i think maybe the original code had kept track of whether we we needed to immediately write something or not, and perhaps it was handled there? can't remember, but regardless, it is fixed now -- we remove write interest as before when we are not in a ""re-authentication"" scenario.",0,0.9786729216575623
221824682,5582,rondagostino,2018-10-02T04:48:59Z,":thumbs_up: i defined a 1-second requirement that applies to the second and subsequent re-authentications. so the first re-authentication can happen immediately after authentication if desired, but the second re-authentication must then happen at least 1 second later (and so on), otherwise the sasl handshake is passed through without beginning the re-authentication process (and that would mean the connection is closed, which also results in the client experience the newly-implemented ddos delay). there are two reasons i set it for the second re-auth. one is is because `saslauthenticatortest` would end up running longer if we had to set the interval that much longer. the other is that we don't have a time value that we can use to set the start time until `kafkachannel.maybebeginserverreauthentication()` is invoked. i think this is reasonable -- is it okay with you?",0,0.9169068336486816
221824691,5582,rondagostino,2018-10-02T04:49:06Z,"actually, my understanding of this is that we received something that had been sent prior to the re-authentication process beginning -- it doesn't match what we were expecting back, so we didn't send it, so it must have come from before -- so we have to save it so it can be processed later. does that make sense? if so, then i think this code is correct.",0,0.9723415970802307
221824708,5582,rondagostino,2018-10-02T04:49:11Z,:thumbs_up: fixed,0,0.9233655333518982
221824720,5582,rondagostino,2018-10-02T04:49:20Z,":thumbs_up: good point. i split out the `processpayload()` method to address a cyclomatic complexity issue, and i did not see the simplification at that time. done.",1,0.9676145911216736
221824731,5582,rondagostino,2018-10-02T04:49:24Z,:thumbs_up: fixed,0,0.9233655333518982
221824759,5582,rondagostino,2018-10-02T04:49:41Z,:thumbs_up: removed,0,0.9636431336402893
221824978,5582,rondagostino,2018-10-02T04:52:09Z,"was unable to get this working, and it is almost 1am here at this point. will look again asap.",0,0.9240003228187561
221852361,5582,rondagostino,2018-10-02T07:50:04Z,"actually, i just got it working.",0,0.9763346910476685
221980284,5582,mk6i,2018-10-02T14:43:37Z,"i am confused by what this part of this sentence, can you elaborate? [code block]",-1,0.6998481154441833
221988637,5582,rondagostino,2018-10-02T15:02:55Z,here's the quote from the kip related to this: does that clarify it?,0,0.9820558428764343
222097603,5582,rajinisivaram,2018-10-02T20:20:08Z,`listener.name.sasl_ssl.oauthbearer.connection.max.expired.ms`?,0,0.9871050119400024
222103261,5582,rajinisivaram,2018-10-02T20:38:38Z,do you mean in a different class? because `channelbuilders` didn't have `time` before this pr.,0,0.928381085395813
222104230,5582,rajinisivaram,2018-10-02T20:41:42Z,"nit: we initialize all other instance variables in the constructor, can we do the same here? i dont think we need the initialzations, especially nulls.",0,0.9820846915245056
222105405,5582,rajinisivaram,2018-10-02T20:45:20Z,"don't think we close the connection on processing saslhandshakerequest, we simply fail the request. do we want to close the connection for this case?",0,0.9157140254974365
222106188,5582,rajinisivaram,2018-10-02T20:48:04Z,`!ready()` here is an `illegalstateexception` since we never expect to here with with an not-ready channel?,0,0.9519832730293274
222106589,5582,rajinisivaram,2018-10-02T20:49:10Z,"since this is used only as the minimum reauthentication interval, can give it a name that indicates its usage?",0,0.9857307076454163
222108202,5582,rajinisivaram,2018-10-02T20:54:05Z,we could use the same name `reauthenticationlatencyms` for the method in authenticator as well? or use `reauthenticationelapsedtimems` in both cases?,0,0.9892376661300659
222111763,5582,rajinisivaram,2018-10-02T21:05:26Z,do we really need this method - test could just create one using hard-coded params?,0,0.9852970242500305
222115747,5582,rajinisivaram,2018-10-02T21:18:41Z,"now that we dont support java 7, we can use lambdas for these conditions (and the ones below).",0,0.9875341653823853
222116790,5582,rajinisivaram,2018-10-02T21:22:30Z,is this used?,0,0.9859181642532349
222117341,5582,rajinisivaram,2018-10-02T21:24:36Z,nit: `else if`?,0,0.9725788235664368
222118885,5582,rajinisivaram,2018-10-02T21:30:08Z,these two method use names that are not consistent with the config name.,0,0.9599717855453491
222119990,5582,rajinisivaram,2018-10-02T21:34:35Z,"so many tests with these two calls, couldn't we just have additional parameters to `verifyauthenticationmetrics` that optionally verify reauthentication and no-reauth metrics?",0,0.9849714636802673
222121974,5582,rajinisivaram,2018-10-02T21:42:18Z,"as before, can we move initializations to the constructor and remove unnecessary null iniitializations?",0,0.9876667261123657
222122932,5582,rajinisivaram,2018-10-02T21:46:03Z,"yes, this code is fine.",0,0.9419129490852356
222123268,5582,rajinisivaram,2018-10-02T21:47:24Z,"same as before, null initializations unnecessary.",0,0.8985830545425415
222124202,5582,rajinisivaram,2018-10-02T21:51:04Z,can we create an inner class to store the re-authentication state? there are just too many of these relevant only for re-authentication.,0,0.9781864285469055
222125964,5582,rajinisivaram,2018-10-02T21:58:50Z,"why is this code here? `reauthenticate()` has the sasl request, so it can do this check specific to reauthentication.",0,0.9887123107910156
222127047,5582,rajinisivaram,2018-10-02T22:03:34Z,we should be able to set up the state and call `authenticate` without separating out the methods.,0,0.9862257242202759
222144498,5582,harshach,2018-10-02T23:40:10Z,"is it going to be used for sasl only if so can you make it ""sasl.connection.max.reauth.ms""",0,0.9732319116592407
222161863,5582,rondagostino,2018-10-03T01:51:29Z,i think `listener.name.sasl_ssl.oauthbearer.connections.max.reauth.ms`?,0,0.9860281944274902
222164887,5582,rondagostino,2018-10-03T02:18:47Z,"oops, sorry, you are correct. fixed.",-1,0.9886437654495239
222358775,5582,rondagostino,2018-10-03T15:33:28Z,:thumbs_up:,0,0.8380307555198669
222359402,5582,rondagostino,2018-10-03T15:35:11Z,"ah, you are correct, we fail the request in kafkaapis and the connection is nor closed. doc adjusted accordingly here.",0,0.982941210269928
222360598,5582,rondagostino,2018-10-03T15:38:22Z,:thumbs_up: `min_reauth_interval_one_second_nanos`,0,0.9528133869171143
222361705,5582,rondagostino,2018-10-03T15:41:08Z,:thumbs_up: renamed `authenticator` method to match this one: `reauthenticationlatencyms`,0,0.973013699054718
222390337,5582,rondagostino,2018-10-03T17:04:46Z,:thumbs_up: we now throw `illegalstateexception` if that occurs,0,0.9510015845298767
222452923,5582,rondagostino,2018-10-03T20:18:01Z,:thumbs_up: removed it.,0,0.9799395799636841
222476244,5582,rondagostino,2018-10-03T21:37:07Z,:thumbs_up: added `` annotation to `testcondition` and implemented lambdas here. did not adjust any other uses of `testcondition` anywhere else unrelated to this pr.,0,0.9739234447479248
222477179,5582,rondagostino,2018-10-03T21:41:11Z,:thumbs_up: removed. this file is no longer affected by this pr.,0,0.9783092141151428
222477623,5582,rondagostino,2018-10-03T21:42:51Z,:thumbs_up: done,0,0.7853332757949829
222478232,5582,rondagostino,2018-10-03T21:45:26Z,:thumbs_up: fixed,0,0.9233655333518982
222478999,5582,rondagostino,2018-10-03T21:48:38Z,i believe there was a desire to keep our options open in this regard and not mention sasl explicitly -- thoughts?,0,0.889379620552063
222479519,5582,rondagostino,2018-10-03T21:50:49Z,:thumbs_up: done,0,0.7853332757949829
222480744,5582,rondagostino,2018-10-03T21:55:41Z,just want to confirm that this is acceptable.,0,0.9710763692855835
222486198,5582,rondagostino,2018-10-03T22:19:53Z,":thumbs_up: done. also shortened the max session reauth ms value from 500 ms to 100 ms, which shaved 20 seconds off of the test runtime (85 seconds dropped to 65 seconds locally). i'm interested to see if this exposes any errors when run on the build farm.",0,0.9359912276268005
222500340,5582,rondagostino,2018-10-03T23:39:47Z,:thumbs_up: fixed,0,0.9233655333518982
222501837,5582,rondagostino,2018-10-03T23:49:12Z,"the `reauthenticate()` method has the `networkreceive` instance. we don't parse that and extract the `saslhandshakerequest` that it contains until later in the flow, at this point in the code. is it okay to keep the changed mechanism check here, as-is?",0,0.9890895485877991
222509254,5582,rondagostino,2018-10-04T00:39:49Z,:thumbs_up: created a `private static class reauthinfo` that has three public final fields: eliminated the `private boolean reauthenticating;` field with `private reauthinfo reauthinfo;`,0,0.9537107348442078
222901371,5582,rondagostino,2018-10-05T06:19:47Z,:thumbs_up: i added a new `reauth_process_handshake` state and that is where re-authentication starts.,0,0.9740319848060608
223997295,5582,rajinisivaram,2018-10-10T09:16:02Z,"yes, since this config is used by the broker to force reauthentication using connection termination as well, there is no reason why we can't apply it for ssl as well in future. so it makes sense to keep it neutral.",0,0.9812343716621399
224002046,5582,rajinisivaram,2018-10-10T09:29:31Z,dont think we need the `mutestate` check on the server-side since we are processing a received packet when we invoke this.,0,0.9551629424095154
224005987,5582,rajinisivaram,2018-10-10T09:39:25Z,is there a reason why this is passing in `time.milliseconds` while the others don't? there is some scope to use a common time value in all of these records to avoid multiple calls to `time.milliseconds()`.,0,0.9844398498535156
224007360,5582,rajinisivaram,2018-10-10T09:42:49Z,could this just use `currenttimenanos`?,0,0.9884359836578369
224008571,5582,rajinisivaram,2018-10-10T09:46:24Z,"move this to the end of the class? we tend to have enum definitions at the start, but typically other inner classes at the end.",0,0.9861586689949036
224009396,5582,rajinisivaram,2018-10-10T09:48:26Z,just return `pendingauthenticatedreceives` and remove the check for `null` in selector?,0,0.9885985851287842
224009880,5582,rajinisivaram,2018-10-10T09:49:51Z,update comment since reauth starts in the state above?,0,0.9886320233345032
224010118,5582,rajinisivaram,2018-10-10T09:50:36Z,include `reauth` in the state name?,0,0.9859485626220703
224010735,5582,rajinisivaram,2018-10-10T09:52:28Z,"isn't this the same as `initial`? from this state onwards, we could use common states? perhaps you have them separate to make it easy to fall through rather than loop back to the start of `authenticate()` when handshake response is received. if it is hard to keep a common state, it is fine to leave as-is.",0,0.9829996228218079
224012583,5582,rajinisivaram,2018-10-10T09:58:35Z,"couldn't we move all four of these (or some of these) into `reauthinfo`? we could create `reauthinfo` early on and populate reauthentication metadata into it. if we really need to separate out fields related to next reauth from the fields related to current reauth, perhaps we could have a separate class with these fields.",0,0.9879593849182129
224014312,5582,rajinisivaram,2018-10-10T10:04:18Z,move `math.min` to `saslauthenticateversion()` to avoid duplication?,0,0.9872653484344482
224017228,5582,rajinisivaram,2018-10-10T10:14:56Z,"this comment is odd because that is not quite what we would do. if we can't fall through, we would put `authenticate` in a loop to process the next state.",-1,0.6390479803085327
224017388,5582,rajinisivaram,2018-10-10T10:15:26Z,"if we need to keep `initial` and `reauth_initial`, we should have. a method to use common code for this state.",0,0.9874710440635681
224018091,5582,rajinisivaram,2018-10-10T10:17:43Z,"do we need this check at all? if it isn't, it is a bug in the implementation and we would see a classcastexception with the class names.",0,0.9875680208206177
224018434,5582,rajinisivaram,2018-10-10T10:18:55Z,"if we always stored `apiversionsresponsefromoriginalauthentication` in `reauthinfo`, we can avoid this check.",0,0.9814426302909851
224021054,5582,rajinisivaram,2018-10-10T10:28:24Z,"looks like we are getting `time.milliseconds()` just for logging. log entries contain date and time anyway, so we could just log the intervals we actually use instead of computing new ones just for logging.",0,0.9799480438232422
224021468,5582,rajinisivaram,2018-10-10T10:30:00Z,nit: unnecessary `long.valueof`,0,0.96541827917099
224023926,5582,rajinisivaram,2018-10-10T10:39:22Z,move this class to the end to be consistent with other classes?,0,0.986640989780426
224024097,5582,rajinisivaram,2018-10-10T10:39:54Z,can we move these three fields into `reauthinfo`?,0,0.9890900254249573
224024425,5582,rajinisivaram,2018-10-10T10:41:11Z,"add checkstyle suppression instead for this file, rather than split the method with a checkstyle comment.",0,0.9855151176452637
224025199,5582,rajinisivaram,2018-10-10T10:44:19Z,"nit: this is not a `utils` class, more like `configs`?",0,0.9857664108276367
224026269,5582,rajinisivaram,2018-10-10T10:48:29Z,"nit: too many boolean params, making it hard to know what this is doing.",-1,0.8827404379844666
224027337,5582,rajinisivaram,2018-10-10T10:52:17Z,why do we need this boolean?,0,0.9709468483924866
224028035,5582,rajinisivaram,2018-10-10T10:55:07Z,i can't tell from the method name what the function returned is.,0,0.9722779393196106
224028525,5582,rajinisivaram,2018-10-10T10:56:47Z,why?,0,0.6633803844451904
224029495,5582,rajinisivaram,2018-10-10T10:59:26Z,why is this in `testutils`?,0,0.9667688608169556
224031032,5582,rajinisivaram,2018-10-10T11:05:24Z,"we are doing at least two `time.nanoseconds` calls per channel, can we get the value at the start and use it in the three usages here.",0,0.987078070640564
224031497,5582,rajinisivaram,2018-10-10T11:07:25Z,"not sure this matches the actual implementation,",-1,0.7336099147796631
224033627,5582,rajinisivaram,2018-10-10T11:16:04Z,"i think parameterization was useful at the start, but not sure we want to commit that. there are several tests where this parameter is not used at all, causing the same tests to be run twice. it feels like we should add some extra reauthentication tests and perhaps update some existing tests to also verify reauthentication. i think a new test which waits for multiple reauthentications while sending and receiving data continuously is sufficient (run with sasl_plaintext and sasl_ssl). it could run with a mechanism where reauthentication latency is higher and the test could run in a loop until latency > 0 to avoid timing errors in the test. all existing tests can stay as-is and use the existing `server.verifyauthenticationmetrics()` that just checks that there are no reauthentications. a new version of that with reauthentication count as arg could check for reauthentication metrics as well. what do you think?",0,0.944562554359436
224035834,5582,rajinisivaram,2018-10-10T11:24:51Z,do we need a boolean here? are there tests where it is guaranteed to be > 0?,0,0.9869654178619385
224041831,5582,rajinisivaram,2018-10-10T11:47:25Z,same as in saslclientauthenticator - unnecessary check since classcastexception gives all the information required in case there is a bug in the code.,0,0.9848625063896179
224042409,5582,rajinisivaram,2018-10-10T11:49:16Z,do we need this method?,0,0.9856400489807129
224042825,5582,rajinisivaram,2018-10-10T11:50:51Z,"why is this conditional, can't we always set it?",0,0.9366831183433533
224043656,5582,rajinisivaram,2018-10-10T11:53:15Z,need `ms` in the method name since it is returning millis.,0,0.9874991774559021
224044350,5582,rajinisivaram,2018-10-10T11:55:17Z,just `credentialexpirationms` is sufficient since this is not the server's credential?,0,0.9894362688064575
224045454,5582,rajinisivaram,2018-10-10T11:59:08Z,can we move this into `reauthinfo` (rename that class if required)?,0,0.9885928630828857
224045546,5582,rajinisivaram,2018-10-10T11:59:27Z,"same as above, move to `reauthinfo`?",0,0.9884446859359741
224045843,5582,rajinisivaram,2018-10-10T12:00:34Z,this can be in `reauthinfo` as well. and `reauthinfo` can have a method `authenticating()` or `reauthenticating()` to avoid all the checks for `null`. same for clientauthenticator as well.,0,0.9891610741615295
224162804,5582,rondagostino,2018-10-10T17:04:57Z,:thumbs_up: fixed,0,0.9233655333518982
224165591,5582,rondagostino,2018-10-10T17:13:46Z,:thumbs_up: now define `long readytimems = time.milliseconds()` at the top and use that time value for all metric `record()` calls.,0,0.9654229283332825
224189017,5582,rondagostino,2018-10-10T18:20:58Z,"i don't think we can use `currenttimenanos` because it represents the time when `poll()` was invoked, and that could be as far back in time as the timeout value (i.e. a large timeout value could in theory result in `java.nio.channels.selector.select()` blocking for quite a while). if we use a time to far in the past it increases the chance of the reauth decision yielding `false` when in fact it should yield `true` -- and in that case we could end up with our connection being killed. what we can do is reuse the `channelstarttimenanos` if it is available (i.e. `channelstarttimenanos != 0 ? channelstarttimenanos : time.nanoseconds()`) since it is a very recent value. furthermore, we can delay actually getting the time as long as possible -- and therefore maybe we don't need to calculate it at all -- by making `kafkachannel` accept a `supplier ` rather than a `long`. i've made both of these changes.",0,0.9420933127403259
224209301,5582,rondagostino,2018-10-10T19:21:42Z,:thumbs_up: moved.,0,0.97428959608078
224210770,5582,rondagostino,2018-10-10T19:26:35Z,:thumbs_up: return value is now always non-null.,0,0.9676437377929688
224211024,5582,rondagostino,2018-10-10T19:27:28Z,:thumbs_up: fixed,0,0.9233655333518982
224250048,5582,rondagostino,2018-10-10T21:35:37Z,:thumbs_up: now include `reauth_` prefix for all re-authentication states.,0,0.9833727478981018
224250994,5582,rondagostino,2018-10-10T21:39:12Z,"yeah, it is a fall-through issue. will keep code as-is given that the duplicated code is only two lines: [code block] however, in light of the comment below, i will refactor this out into a common method.",0,0.9862827658653259
224252644,5582,rondagostino,2018-10-10T21:45:34Z,:thumbs_up: created `private static class authinfoforreauth` to hold all of these in one place.,0,0.9770698547363281
224270430,5582,rondagostino,2018-10-10T23:11:04Z,":thumbs_up: done, we now send in the `apiversionsresponse` instance.",0,0.978402316570282
224271563,5582,rondagostino,2018-10-10T23:17:28Z,:thumbs_up: fixed the comment -- it now states that we won't add the loop to minimize changes.,0,0.9753983020782471
224271904,5582,rondagostino,2018-10-10T23:19:29Z,:thumbs_up: added method `sendinitialtokenandsetintermediatestate()`,0,0.9644832015037537
224272371,5582,rondagostino,2018-10-10T23:22:31Z,:thumbs_up: removed.,0,0.9716109037399292
224273014,5582,rondagostino,2018-10-10T23:26:45Z,`reauthinfo` will be null for the `saslclientauthenticator` instance associated with the initial authentication; that instance will have an instance of `authinfoforreauth` to hold the `apiversionsresponse` received from the broker. this check is therefore necessary under these conditions.,0,0.9883120656013489
224276026,5582,rondagostino,2018-10-10T23:46:27Z,:thumbs_up: done,0,0.7853332757949829
224276273,5582,rondagostino,2018-10-10T23:47:58Z,:thumbs_up: removed,0,0.9636431336402893
224436894,5582,rondagostino,2018-10-11T12:58:25Z,:thumbs_up: moved,0,0.9553942680358887
224439886,5582,rondagostino,2018-10-11T13:07:00Z,created `private static class authinfoforreauth`,0,0.9864945411682129
224442030,5582,rondagostino,2018-10-11T13:13:28Z,:thumbs_up: done,0,0.7853332757949829
224444370,5582,rondagostino,2018-10-11T13:19:45Z,"renamed it `saslinternalconfigs` (there is already a `org.apache.kafka.common.config.saslconfigs` class, and it is part of the public api, so it is not an appropriate place to put this internal constant).",0,0.9832435250282288
224506417,5582,rondagostino,2018-10-11T15:57:43Z,":thumbs_up: created `public enum metrictype` and the method `public void waitformetrics(string nameprefix, final double expectedvalue, set metrictypes)`. this method now looks like this: [code block]",0,0.9486061930656433
224508051,5582,rondagostino,2018-10-11T16:02:15Z,":thumbs_up: this is now removed, and the expected/actual values are now included as part of the assertion error message.",0,0.9811254739761353
224509330,5582,rondagostino,2018-10-11T16:05:44Z,":thumbs_up: true that it is not really reusable; `nioechoserver` needs that functionality, so now it's a `private static boolean` method on that class rather than a `public static boolean` method on `testutils`.",0,0.937432587146759
224514170,5582,rondagostino,2018-10-11T16:20:30Z,"the above change resulted in a disallowed import error, so i refactored out the following method and put it back into `testutils`. this is better than having the whole `maybebeginserverreauthentication()` method there. [code block]",0,0.9830753803253174
224523568,5582,rondagostino,2018-10-11T16:49:37Z,"good question! there was a comment above that method that stated: [code block] i didn't think about it much; i just read that comment and figured that since i'm making a change to `saslauthenticaterequest` and `saslauthenticateresponse` and they don't contain a `hashmap` i could -- and should -- test for equality and hashcode. but now that you ask, and i do spend the time to think about it, it seems that testing equality and hashcode doesn't provide the value i thought it would (and that the comment seemed to imply that it would except for the annoying tendency of a hashmap to screw up the results)! all we would be testing for is to make sure the result of serializing a request to a `struct` can be deserialized back to a request and then serialized again to an equivalent `struct`. in other words, it doesn't actually test that the serialization code (i.e. `saslauthenticateresponse.tostruct()`) is working perfectly -- the equality and hashcode tests will still succeed even if that code serializes a field incorrectly because the same field will be serialized incorrectly both times (for example). note that incorrect serialization would presumably be caught indirectly via failure of other unit or integration tests. what maybe has to change here is the original comment. should i adjusted it?",1,0.977601170539856
224526490,5582,rondagostino,2018-10-11T16:59:07Z,"ok, it's now just a single call to `time.nanoseconds()` under all circumstances except for when `sasl_handshake_request` is sent and either 1) re-authentication is not enabled; or 2) re-authentication is enabled but it occurred less than a second ago. in these two cases `time.nanoseconds()` will be invoked twice, but it probably doesn't matter since this is a rare occurrence and we are going to send an error back to the client if/when it happens.",0,0.9816120266914368
224600485,5582,rondagostino,2018-10-11T20:52:28Z,"fixed. there is now a processor-level metric `expired-connections-killed-count` that tracks the value on a per-(listener,processor) basis as well as an aggregated sum of these to provide a broker-wide metric. the aggregated sum metric is called `expiredconnectionskilledcount`. the `ops.html` doc is also updated to reflect this.",0,0.9875576496124268
224643320,5582,rondagostino,2018-10-12T00:36:27Z,:thumbs_up: removed,0,0.9636431336402893
224643550,5582,rondagostino,2018-10-12T00:38:09Z,no -- removed.,0,0.9514520168304443
224644898,5582,rondagostino,2018-10-12T00:49:37Z,:thumbs_up: changed.,0,0.9763535261154175
224645195,5582,rondagostino,2018-10-12T00:52:07Z,:thumbs_up: renamed,0,0.9349986910820007
224645547,5582,rondagostino,2018-10-12T00:54:51Z,:thumbs_up: moved,0,0.9553942680358887
224645875,5582,rondagostino,2018-10-12T00:57:22Z,:thumbs_up: moved,0,0.9553942680358887
224646884,5582,rondagostino,2018-10-12T01:06:23Z,:thumbs_up: i moved `authenticationorreauthenticationtext()` into `authinfoforreauth` and added a `private boolean reauthenticating()` method to `saslserverauthenticator`.,0,0.9818964004516602
224647371,5582,rondagostino,2018-10-12T01:11:20Z,did the same thing for `saslclientauthenticator`.,0,0.9864919781684875
224650731,5582,rondagostino,2018-10-12T01:42:13Z,"actually, after seeing some other review comments, i decided to do what you said: there is now a `reauthinfo` class only -- no additional `authinfoforreauth` class -- and we add the re-authentication data to it.",0,0.9857924580574036
224652056,5582,rondagostino,2018-10-12T01:53:43Z,now that i decided to get rid of the `authinfoforreauth` the code looks like this: [code block],0,0.9772908091545105
224652317,5582,rondagostino,2018-10-12T01:56:07Z,i decided to get rid of `authinfoforreauth` and keep everything in a single `reauthinfo` instance as you originally suggested.,0,0.9852619767189026
224888052,5582,rondagostino,2018-10-12T19:09:14Z,"the client sends multiple `sasl_authenticate` requests, and i was thinking the client is known to support the latest version if it sends at least one of them with the required version. i realize it is unlikely to send different versions each time, but technically if it sends the required version just once then we know it supports that version. so i was trying to take that (admittedly rare) possibility into account. another way to do it would be: [code block] i figured the way i did it was better than that since it avoids the write when the value is already true. i can always set it if you feel that is more appropriate -- just let me know, otherwise i'll leave it as-is.",0,0.8188832998275757
224890138,5582,rondagostino,2018-10-12T19:17:38Z,"sasl plain authenticates so quickly in the test case that the latency is 0, so if i check to make sure there is a non-zero latency in that case the test fails. i know you have a comment below about adjusting the unit tests to not be so wasteful. i may be able to get rid of this as i do that.",0,0.9563202857971191
224907777,5582,rondagostino,2018-10-12T20:34:55Z,"in the meantime, i added a comment describing the reasoning.",0,0.9849990010261536
225389120,5582,rondagostino,2018-10-16T03:52:30Z,"i eliminated this problem by always recording a latency of at least 1 ms when there is a non-zero latency to record. so now 100,000 nanoseconds of latency is recorded as 1 ms, for example.",0,0.9778205156326294
225389599,5582,rondagostino,2018-10-16T03:56:59Z,i just added a new `reauth_bad_mechanism` state on the `saslserverauthenticator` because a change in the mechanism wasn't being recorded as a failed re-authentication in the metrics. now it is being recorded correctly.,0,0.9751493334770203
225389740,5582,rondagostino,2018-10-16T03:58:28Z,resolved. i now record a latency of at least 1 ms when there is any non-zero latency.,0,0.9869852662086487
225389970,5582,rondagostino,2018-10-16T04:00:32Z,"latest commit attempts to resolve this. all mechanisms include at least 1 re-authentication test. there is a multiple mechanism re-authentication test; there are tests for changing the principal, changing the mechanism, and re-authenticating too fast; and there is a test that continually sends data over the connection until the number of re-authentications is 5.",0,0.9841361045837402
227157687,5582,rajinisivaram,2018-10-22T22:16:49Z,do we need these two fields `clientsessionreauthenticationtimenanos` and `serversessionexpirationtimenanos`? couldn't we just use `authenticator.clientsessionreauthenticationtimenanos()` and `authenticator.serversessionexpirationtimenanos()`?,0,0.9879739284515381
227158301,5582,rajinisivaram,2018-10-22T22:19:31Z,reword exception message since channel is not ready on receiving first handshake?,0,0.9806545376777649
227159398,5582,rajinisivaram,2018-10-22T22:24:42Z,can we move this into `authenticator`?,0,0.9889044165611267
227159491,5582,rajinisivaram,2018-10-22T22:25:04Z,can we move this into `authenticator`?,0,0.9889044165611267
227160254,5582,rajinisivaram,2018-10-22T22:28:35Z,"there are so many methods in kafkachannel that simply call a method in `authenticator`. i wonder if it would be better to add an `authenticator()` method and let callers directly use `authenticator`, reducing the amount of code in `kafkachannel`.",0,0.9470472931861877
227162913,5582,rajinisivaram,2018-10-22T22:40:48Z,not sure why this needs to be a suppiler of time rather than the value itself. the code would be more readable with just a value.,0,0.917953610420227
227164081,5582,rajinisivaram,2018-10-22T22:46:25Z,"this no longer reflects the sequence of states, so it will be good to add javadoc for `saslstate` showing the two sequences for initial auth and reauth. i would probably move the reauth states to the end so that initial flows through to complete.",0,0.9844812154769897
227164773,5582,rajinisivaram,2018-10-22T22:49:51Z,leave `setsaslstate(saslstate.intermediate)` here similar to other cases?,0,0.9853341579437256
227165780,5582,rajinisivaram,2018-10-22T22:54:21Z,"as with client `saslstate`, since states don't flow through, we should have comment for `saslstate` showing the two sequences for initial auth and reauth. again, i would move reauth to the end so that `initial_request` flows through to `complete`.",0,0.9887180328369141
227166408,5582,rajinisivaram,2018-10-22T22:57:10Z,not sure we need this state. we can set state to failed and throw the appropriate exception.,0,0.8712766766548157
227168000,5582,rajinisivaram,2018-10-22T23:04:47Z,"looking at just this code, it looks like we record this for auth and reauth, even though it actually happens only once as expected. it would be more readable to move this code under the `if (channel.successfulauthentications() == 1)`.",0,0.986444890499115
227168301,5582,rajinisivaram,2018-10-22T23:06:23Z,why can't we just throw `saslauthenticationexception` here?,0,0.9688023924827576
227168794,5582,rajinisivaram,2018-10-22T23:09:04Z,not used?,0,0.9662325978279114
227168816,5582,rajinisivaram,2018-10-22T23:09:12Z,not used?,0,0.9662325978279114
227169229,5582,rajinisivaram,2018-10-22T23:11:14Z,"not sure whether these methods add any value since you could just use `enumset.of` instead of `metrictype.setof`? and actually looking at `waitformetrics`, it would be even better to use varargs.",0,0.9840532541275024
227170791,5582,rajinisivaram,2018-10-22T23:19:42Z,we don't need a try-finally block when teardown does the cleanup.,0,0.9650937914848328
227170823,5582,rajinisivaram,2018-10-22T23:19:53Z,we don't need a try-finally block when teardown does the cleanup.,0,0.9650937914848328
227170844,5582,rajinisivaram,2018-10-22T23:20:00Z,we don't need a try-finally block when teardown does the cleanup.,0,0.9650937914848328
227170925,5582,rajinisivaram,2018-10-22T23:20:23Z,we don't need a try-finally block when teardown does the cleanup.,0,0.9650937914848328
227170945,5582,rajinisivaram,2018-10-22T23:20:30Z,we don't need a try-finally block when teardown does the cleanup. lots of these changes in this file are unnecessary (and the test is more readable without the try-finally.,0,0.9384775757789612
227393856,5582,rondagostino,2018-10-23T13:37:45Z,:thumbs_up: done,0,0.7853332757949829
227397762,5582,rondagostino,2018-10-23T13:46:33Z,"here's what i changed it to. not sure if this is what you were getting at. let me know if there is something else it should say. i also fixed the javadoc -- it was still referring to ""not muted"" when we got rid of that check based on a review comment. [code block]",0,0.9601843357086182
227401789,5582,rondagostino,2018-10-23T13:54:48Z,"i don't think so, no. for one, if we did, then `kafka.network.processor` would have to be able to get to the `authenticator` instance, and currently `kafkachannel` does not expose that publicly. the guts of this method also refers to state within `kafkachannel` as well (specifically, `lastreauthenticationstartnanos`), and while we could pass that in instead, fundamentally the `kafkachannel` instance also has to swap out its `authenticator` instances. so i think this method really has to belong in `kafkachannel`.",0,0.9425893425941467
227402058,5582,rondagostino,2018-10-23T13:55:19Z,"similar to above: i don't think so, no, for the same reasons.",0,0.8758783936500549
227408464,5582,rondagostino,2018-10-23T14:07:56Z,"not sure. my gut says the benefit would be minimal and the downside to exposing the `authenticator` (adding complexity to code that now simply asks the `kafkachannel` to do stuff) would outweigh any benefit, but regardless, if you decide it is something you would like to do maybe it can be addressed as a separate ticket?",0,0.8340892195701599
227409726,5582,rondagostino,2018-10-23T14:10:29Z,"there was a desire to not call `time.nanoseconds()` unnecessarily. we had a time value already, but it wasn't guaranteed to be current, so we have to get it again; making it a `supplier` meands we can delay getting it for as long as possible and avoid it completely if the logic is short-circuited first.",-1,0.6553170680999756
227414037,5582,rondagostino,2018-10-23T14:18:22Z,:thumbs_up: javadoc added/declarations re-ordered,0,0.9613475203514099
227418118,5582,rondagostino,2018-10-23T14:26:33Z,"lol. i changed this based on a previous review comment: `if we need to keep initial and reauth_initial, we should have. a method to use common code for this state.` . it didn't seem worthwhile to make a method with just `sendsaslclienttoken(new byte[0], true)` in it, so i put both that and `setsaslstate(saslstate.intermediate) ` in there and named it accordingly. i'm good whichever way you want to go -- just let me know if you decide it should be different than what it currently is (i.e. maybe put it back to the way it was?). will leave as-is otherwise.",1,0.9805278778076172
227421513,5582,rondagostino,2018-10-23T14:34:05Z,:thumbs_up: javadoc added/declarations re-ordered,0,0.9613475203514099
227426184,5582,rondagostino,2018-10-23T14:43:53Z,:thumbs_up: moved,0,0.9553942680358887
227450301,5582,rondagostino,2018-10-23T15:37:53Z,see comment below.,0,0.9795164465904236
227451106,5582,rondagostino,2018-10-23T15:39:43Z,"i added this state because without it the attempt to change the mechanism isn't recorded as a failed re-authentication in the metrics. if we simply throw the exception then it is caught either by `nioechoserver.maybebeginserverreauthentication()` (in the case of a unit test) or by `kafka.network.processor.processcompletedreceives()` (in real-world use). in the unit test case the exception is simply ignored, and eventually the channel is closed while we are waiting in vain for the metric to update. in real-world use the channel would end up being closed -- but again no metric update occurs because the server-side `selector` never sees the channel as being ""`!channel.ready()`"" -- it needs to see this in order to call `channel.prepare()`, catch the `authenticationexception`, and record the failed re-authentication in the metric. i realize it is a bit odd to have to create this extra state, and we can avoid it if we are willing to not record the attempt as a failed re-authentication in the metrics, but i figured we would want to to record it.",0,0.9792314767837524
227451806,5582,rondagostino,2018-10-23T15:41:21Z,:thumbs_up: removed,0,0.9636431336402893
227451895,5582,rondagostino,2018-10-23T15:41:36Z,:thumbs_up: removed,0,0.9636431336402893
227453157,5582,rondagostino,2018-10-23T15:44:39Z,":thumbs_up: agreed, eliminated all the methods and now invoke `enumset.of()` directly.",0,0.9830512404441833
227458546,5582,rondagostino,2018-10-23T15:57:23Z,"oops, didn't see that cleanup code. :thumbs_up: removed (everywhere)",-1,0.7772879600524902
227458722,5582,rondagostino,2018-10-23T15:57:48Z,:thumbs_up: removed,0,0.9636431336402893
227458807,5582,rondagostino,2018-10-23T15:57:59Z,:thumbs_up: removed,0,0.9636431336402893
227458896,5582,rondagostino,2018-10-23T15:58:11Z,:thumbs_up: removed,0,0.9636431336402893
227458997,5582,rondagostino,2018-10-23T15:58:27Z,:thumbs_up: removed (everywhere),0,0.9723963737487793
227798966,5582,rajinisivaram,2018-10-24T13:56:03Z,"yes, let's leave it as is for now.",0,0.9794274568557739
227799411,5582,rajinisivaram,2018-10-24T13:57:04Z,does it really need to be that uptodate? couldn't we just use the time that we have?,0,0.9522078037261963
227800879,5582,rajinisivaram,2018-10-24T14:00:27Z,"looking at the rest of the code, i think it will be good to set the state here like in the rest of the code. perhaps: [code block]",0,0.9606232643127441
227801592,5582,rajinisivaram,2018-10-24T14:02:09Z,"thanks for the explanation. yes, we do want to record it, so let's keep the state.",1,0.7011187672615051
228162494,5582,rondagostino,2018-10-25T13:01:00Z,done,0,0.9764507412910461
228247041,5582,rondagostino,2018-10-25T16:32:54Z,"actually, i just realized that `currenttimenanos` does not represent the time when `poll()` was invoked -- it actually represents the moment after the `select()` returns. so we can use that value if necessary.",0,0.9859759211540222
228248803,5582,rondagostino,2018-10-25T16:37:41Z,"yeah, we can. i mistakenly thought `currenttimenanos` represented the time when `poll()` was called, but it is actually the moment when the `select()` call returns, so it is relatively recent. so now i use the most recent value we have if there is one, otherwise we use `currenttimenanos`. i kept it as a `supplier<>` though -- for symmetry with `kafkachannel.maybebeginserverreauthentication()`. i can pass the long value in directly if you prefer, otherwise i think we're good here now.",0,0.935337483882904
423906760,8657,chia7712,2020-05-12T17:25:21Z,"it collects the ""key"" used to complete delayed requests. the completion is execute out of group lock.",0,0.9875710010528564
423907638,8657,chia7712,2020-05-12T17:26:53Z,this is the main change of this pr (address [a link],0,0.9860926270484924
423908084,8657,chia7712,2020-05-12T17:27:34Z,new check for this pr. make sure it does not hold group lock,0,0.976284921169281
423908468,8657,chia7712,2020-05-12T17:28:09Z,"this test case is for ""trylock"" so i just remove it.",0,0.9865909814834595
423913246,8657,chia7712,2020-05-12T17:35:42Z,"this is another case of deadlock. [code block] is in a **group lock** and it tries to complete other delayed joins which related to same **__consumer_offsets** partition. hence, this pr make it control the group lock manually in order to make sure it does not hold group lock when calling [code block]",0,0.9813210368156433
426943627,8657,hachikuji,2020-05-18T23:19:57Z,"currently we have a somewhat convoluted model where `replicamanager` creates delayed operations, but we depend on lower level components like `partition` to be aware of them and complete them. this breaks encapsulation. not something we should try to complete in this pr, but as an eventual goal, i think we can consider trying to factor delayed operations out of `partition` so that they can be managed by `replicamanager` exclusively. if you assume that is the end state, then we could drop `completedelayedrequests` and let `replicamanager` _always_ be responsible for checking delayed operations after appending to the log. other than `replicamanager`, the only caller of this method is `groupmetadatamanager` which uses it during offset expiration. i think the only reason we do this is because we didn't want to waste purgatory space. i don't think that's a good enough reason to go outside the normal flow. it would be simpler to follow the same path. potentially we could make the callback an `option` so that we still have a way to avoid polluting the purgatory.",0,0.9570151567459106
426944679,8657,hachikuji,2020-05-18T23:23:37Z,"hmm.. does the group purgatory suffer from the same deadlock potential? if we call `checkandcomplete` for a group ""foo,"" i don't think we would attempt completion for any other group.",0,0.9415539503097534
426960637,8657,hachikuji,2020-05-19T00:20:05Z,"for reference, here are links to two alternative approaches that i considered earlier this year: - async completion: [a link] - lock-safe offset cache: [a link] i think jun was not satisfied with the first approach because it called for another thread pool. its advantage though was a simpler and more intuitive api than what we have here. an idea which i never implemented was to let the request handlers also handle delayed operation completion so that we did not need another thread pool. basically rather than calling the callback in `delayedproduce` directly, we add a new operation to the request queues. obviously this has its own tradeoffs. the second commit tries to use lock-free data structures so that we do not need the lock when completing the callback. this was only a partial solution which handled offset commit appends, but not group metadata appends. i am not sure how to handle join group completion asynchronously, so i gave up on this idea. only posting in case it's useful to see how some of these alternatives might have looked. i'm ok with the approach here, but i do wish we could come up with a simpler api. one thought i had is whether we could make the need for external completion more explicit. for example, maybe `appendrecords` could return some kind of object which encapsulates purgatory completion. [code block] just a thought.",0,0.904280424118042
427095614,8657,chia7712,2020-05-19T07:45:43Z,thanks for reviews! we are on the same page :) (my previous comment [a link] this style lgtm :),1,0.9911198019981384
427102729,8657,chia7712,2020-05-19T07:57:45Z,"you are right. it requires lock for group ""foo"" only. but the potential deadlock i tried to avoid/describe is that the caller has held a lock of group_a and then it tried to complete delayed request for group_b. it is possible to cause deadlock as it requires the lock of group_b to completing delayed request for group_b. that way the comment says the caller should not hold any group lock.",0,0.9681997895240784
427114083,8657,chia7712,2020-05-19T08:16:25Z,pardon me. i fail to catch your point.,-1,0.9704355597496033
427430032,8657,hachikuji,2020-05-19T16:19:03Z,"the join/heartbeat purgatories are a little different from the produce purgatory. the key is based on the groupid, so when we complete an operation for group ""foo,"" we won't complete for group ""bar"" incidentally. at least that is my understanding. if you look at `delayedoperationpurgatory.checkandcomplete`, we only complete watchers for the passed key.",0,0.9831979870796204
427432140,8657,hachikuji,2020-05-19T16:22:06Z,"sorry, let me be clearer: 1. mainly i'm suggesting moving the delayed operation checking into `replicamanager` instead of `partition`. 2. we can change the call to `appendrecordstoleader` in `groupmetadatamanager` to go through `replicamanager` as well. 3. we could make the callback optional in `replicamanager.appendrecords` so that we do not have to add a callback (which appears to be the only reason we write directly to `partition` from `groupmetadatamanager`). anyway, just a suggestion. i thought it might let us keep the completion logic encapsulated in `replicamanager`.",-1,0.9843676686286926
427435780,8657,chia7712,2020-05-19T16:27:30Z,"you are totally right. my above comment is not clear. i added the comment to remind developers following code is dangerous. [code block] of course, the above code is nonexistent currently. i'm just worry that the deadlock is easy to produce in the future if we don't notice the lock issue.",-1,0.948555588722229
427723802,8657,chia7712,2020-05-20T03:40:48Z,"in fact, there is a example of deadlock in join purgatories. [code block] called by [code block] is possible to call [code block] to append records to __consumer_offsets-{**partitionfor(group.groupid)**}. if there are groups related to same partition, [code block] which is holding a group lock will require locks for other groups.",0,0.9871964454650879
428949769,8657,junrao,2020-05-21T22:28:41Z,"perhaps reword like the following? returning a map of successfully appended topic partitions and a flag indicting whether the hwm has been incremented. if the caller passes in completedelayedrequests as false, the caller is expected to complete delayed requests for those returned partitions.",0,0.9870725274085999
428950361,8657,junrao,2020-05-21T22:30:37Z,"could we do `localproduceresults.filter{ case (tp, logappendresult) => ... }` to avoid unnamed references?",0,0.989074170589447
428956078,8657,junrao,2020-05-21T22:48:37Z,could we add a comment for the return value?,0,0.9876392483711243
428958530,8657,junrao,2020-05-21T22:56:39Z,could we add a comment for the return value?,0,0.9876392483711243
428972538,8657,junrao,2020-05-21T23:47:16Z,"this is bit tricky to untangle. it seems the original code holds the group lock for both the `group.hasallmembersjoined` check and the call to forcecomplete(). so, we probably want to keep doing that. i am thinking that we could do the following. 1. change `groupcoordinator.oncompletejoin()` so that (1) it checks group.hasallmembersjoined inside the group lock and returns whether hasallmembersjoined is true. 2. in `delayedjoin.trycomplete() `, we do [code block] in oncomplete(), we do nothing.",0,0.851776123046875
430253921,8657,chia7712,2020-05-26T08:47:57Z,"could you take a look? i'd like to address comment but it produces a big change to this pr. hence, it would be better to have more reviews/suggestions before kicking off.",0,0.9282448291778564
430748553,8657,junrao,2020-05-26T22:47:10Z,"i was trying to check if it's safe to do this. the intention for this is probably to avoid the deadlock between the group lock and the lock in delayedoperation. none of the caller of joinpurgatory.checkandcomplete holds a group lock now. the only other caller that can first hold a group lock and then the lock in delayedoperation is joinpurgatory.trycompleteelsewatch(). however, that's not an issue since that's when the delayedjoin operation is first added. so, this changes seems ok.",0,0.9679816961288452
430750020,8657,junrao,2020-05-26T22:51:20Z,"""as the lock is not free"" : do you mean ""when the lock is free""?",0,0.946760356426239
430750723,8657,junrao,2020-05-26T22:53:22Z,a flag => a flag in replicamanager.appendrecords().,0,0.9877303242683411
430755656,8657,junrao,2020-05-26T23:08:08Z,could we add a comment to explain the return value?,0,0.9862340688705444
430756183,8657,junrao,2020-05-26T23:09:43Z,a map containing the topic partitions having new records and a flag indicating whether the hwm has been incremented.,0,0.9866238236427307
430757287,8657,junrao,2020-05-26T23:13:06Z,"i agree that it's simpler to let the caller in replicamanager to complete the delayed requests. this way, we don't need to pass completedelayedrequests in here.",0,0.9765123128890991
430761183,8657,junrao,2020-05-26T23:26:08Z,could we add a comment to explain the return value?,0,0.9862340688705444
431001869,8657,chia7712,2020-05-27T10:01:27Z,"it may produce deadlock if we hold the group lock for [code block]. [code block] is possible to append record to [code block] (see [a link] and hence it will try to complete other delayed joins which have groups belonging to same partition of [code block]. that is why i make [code block] control the group lock manually. for another, [code block] is used by [code block] only so it should be fine to change behavior of group lock in this case.",0,0.9817320704460144
431002494,8657,chia7712,2020-05-27T10:02:37Z,copy that.,0,0.9867016673088074
431003374,8657,chia7712,2020-05-27T10:04:13Z,"hmmm, i misunderstand your point. please ignore my first comment :)",-1,0.7930827140808105
431206147,8657,chia7712,2020-05-27T14:58:55Z,make sure [code block] does not cause deadlock,0,0.9853657484054565
431208549,8657,chia7712,2020-05-27T15:00:48Z,both methods are executed with lock,0,0.9876534342765808
431209368,8657,chia7712,2020-05-27T15:01:31Z,this is a workaround to deal with deadlock caused by taking multiples group locks,0,0.9862352013587952
431210497,8657,chia7712,2020-05-27T15:02:28Z,this enum type is more readable than [code block],0,0.9872757792472839
439543737,8657,junrao,2020-06-12T17:12:08Z,it's cleaner to not pass in completedelayedrequests here and let the caller (`replicamanager.appendrecords()`) check and complete purgatory instead.,0,0.9644542336463928
439549136,8657,junrao,2020-06-12T17:23:34Z,"could we use `map {case (tp, appendresult) => ...}` here to avoid using unamed references?",0,0.9887054562568665
439872747,8657,junrao,2020-06-14T22:15:38Z,"another way that doesn't require checking lock.isheldbycurrentthread is the following. but your approach seems simpler. override forcecomplete() to [code block] in oncomplete(), do nothing. in trycomplete(), do [code block] in onexpiration(), [code block]",0,0.982584536075592
439872846,8657,junrao,2020-06-14T22:16:58Z,expire -> oncomplete -> completedelayedrequests,0,0.9870977997779846
439873175,8657,junrao,2020-06-14T22:21:43Z,"delyaedoperation.lockopt defaults to none. so, we don't have to specify it explicitly.",0,0.9762017726898193
439873441,8657,junrao,2020-06-14T22:25:23Z,"""groupcoordinator#oncompletejoin() tries to complete delayed requests"" => since the completion of the delayed request for partitions returned from groupcoordinator#oncompletejoin() need to be done outside of the group lock.",0,0.9856742024421692
439875801,8657,junrao,2020-06-14T22:54:00Z,typo whihc,0,0.9855505228042603
439875892,8657,junrao,2020-06-14T22:55:07Z,the caller no longer passed in completedelayedrequests.,0,0.9630811214447021
439876215,8657,junrao,2020-06-14T22:59:03Z,all callers pass in completedelayedrequests as false. could we remove this param?,0,0.9838985800743103
439876392,8657,junrao,2020-06-14T23:01:18Z,there was => there were,0,0.9644721150398254
439876493,8657,junrao,2020-06-14T23:02:54Z,"replicamanager.appendrecords()., => replicamanager.appendrecords(),",0,0.987556517124176
439876557,8657,junrao,2020-06-14T23:04:08Z,may requires => may require,0,0.9805193543434143
439878341,8657,junrao,2020-06-14T23:27:03Z,"hmm, why do we need this logic now?",0,0.9558509588241577
439878736,8657,junrao,2020-06-14T23:31:46Z,"hmm, why do we need to mock this since replicamanager.getmagic() is only called through replicamanager.handlewritetxnmarkersrequest()?",0,0.9786544442176819
439878969,8657,junrao,2020-06-14T23:34:51Z,"hmm, this should only be called with leaderhwchange.leaderhwincremented, but the mock later returns leaderhwchange.none? ditto below.",0,0.8759826421737671
439914680,8657,chia7712,2020-06-15T03:35:28Z,testreplicamanager#appendrecords ([a link] always complete the delayedproduce immediately so the txn offset is append also. this pr tries to complete the delayedproduce after releasing the group lock so it is possible to cause following execution order. 1. txn prepare 1. txn completion (fail) 1. txn append (this is executed by delayedproduce),0,0.9883361458778381
439915438,8657,chia7712,2020-06-15T03:39:51Z,the caller of [code block] may hold the group lock so it could produce deadlock if [code block] tries to complete purgatory.,0,0.963562548160553
439920019,8657,chia7712,2020-06-15T04:03:59Z,[code block] ([a link] also call [code block]. there are delayed ops are completed by [code block] so we have to mock the [code block]. the mock is same to [a link],0,0.9842057228088379
439923720,8657,chia7712,2020-06-15T04:23:45Z,read [a link] again. it is a nice idea to refactor [code block] and [code block] to simplify the behavior of checking delayed operations. could i address the refactor in another pr to avoid bigger patch?,0,0.6588912606239319
440514740,8657,junrao,2020-06-16T00:14:56Z,"thanks. i am still not sure that i fully understand this. it seems that by not completing the delayedproduce within the group lock, we are hitting illegalstateexception. that seems a bug. do you know which code depends on that? it seems that we do hold a group lock when updating the txnoffset. [a link]",1,0.45462334156036377
440515043,8657,junrao,2020-06-16T00:15:55Z,"yes, we can refactor that in a separate pr. could you file a followup jira for that?",0,0.9883511662483215
440576071,8657,chia7712,2020-06-16T04:15:13Z,"the root cause (changed by this pr) is that the ""txn initialization"" and ""txn append"" are not executed within same lock. **the test story is shown below.** [code block] calls [code block] to add [code block] to [code block] (this is the link you attached). [code block] called by [code block] throws [code block] if [code block] is [code block] ([a link] **why it does not cause error before?** [code block] is updated by the callback [code block] ([a link] [code block] always create [code block] do handle the [code block] ([a link] the condition to complete the [code block] is [code block]. and the condition gets true when call both [code block] and [code block] since the former calls [code block] two times and another calls [code block] once. it means [code block] is always executed by [code block] and noted that [code block] is executed within a group lock ([a link] . in short, txn initialization ([a link] and txn append ([a link] are executed with same group lock. hence, the following execution order is impossible. 1. txn initialization 1. txn completion 1. txn append however, this pr disable to complete delayed requests within group lock held by caller. the [code block] which used to append txn needs to require group lock again.",0,0.9868643879890442
440585314,8657,chia7712,2020-06-16T04:53:54Z,nice caching. most methods don't need this flag. let me revert them :),1,0.9881950616836548
441175806,8657,junrao,2020-06-16T22:23:40Z,typo rebalacne,0,0.9853447079658508
441177055,8657,junrao,2020-06-16T22:27:14Z,the delayed requests may be completed as much as possible => the delayed requests may be completed inside the call with the expectation that no conflicting locks are held by the caller,0,0.9864691495895386
441177351,8657,junrao,2020-06-16T22:28:07Z,callers can complete the delayed requests manually => callers can complete the delayed requests after releasing any conflicting lock.,0,0.9871734380722046
441178418,8657,junrao,2020-06-16T22:31:00Z,"""if the caller no longer passed in completedelayedrequests"" the caller still passes this in, just as false.",0,0.9778451323509216
441180667,8657,junrao,2020-06-16T22:37:19Z,""" if the caller no longer passed in completedelayedrequests"" => there is no completedelayedrequests passed in.",0,0.9823725819587708
441182450,8657,junrao,2020-06-16T22:42:33Z,to to => to,0,0.9511693716049194
441186463,8657,junrao,2020-06-16T22:54:36Z,"thanks for the great explanation. i understand the issue now. essentially, this exposed a limitation of the existing test. the existing test happens to work because the producer callbacks are always completed in the same replicamanager.appendrecords() call under the group lock. however, this is not necessarily the general case. your fix works, but may hide other real problems. i was thinking that another way to fix this is to change the test a bit. for example, we expect completetxnoperation to happen after committxnoffsetsoperation. so, instead of letting them run in parallel, we can change the test to make sure that completetxnoperation only runs after committxnoffsetsoperation completes successfully. joingroupoperation and syncgroupoperation might need a similar consideration.",1,0.9699819684028625
441289689,8657,chia7712,2020-06-17T05:32:25Z,will roger that ! i didn't notice something interesting. could you share it with me?,1,0.8971973657608032
441846005,8657,junrao,2020-06-17T21:31:23Z,if there is no completedelayedrequests passed in => if completedelayedrequests is false,0,0.9824581742286682
441846819,8657,junrao,2020-06-17T21:33:16Z,if there is no completedelayedrequests passed in => if completedelayedrequests is false,0,0.9824581742286682
441859110,8657,junrao,2020-06-17T22:02:38Z,i think the intention for the test is probably to use the same producerid since it tests more on transactional conflicts.,0,0.9833477139472961
441859824,8657,junrao,2020-06-17T22:04:30Z,"hmm, why don't we need the lock here since committxnoffsetsoperation and completetxnoperation could still run in parallel?",0,0.985597550868988
441862013,8657,junrao,2020-06-17T22:10:14Z,"perhaps change the comment to sth like the following? ""setting to true to make completetxnoperation and committxnoffsetsoperation complete atomically since they don't typically overlap. otherwise completetxnoperation may see a pending offsetandmetadata without an appendedbatchoffset.""",0,0.9845606088638306
441938174,8657,chia7712,2020-06-18T02:48:30Z,"got it. however, the same producerid means the group completed by completetxnoperation is possible to be impacted by any committxnoffsetsoperation (since the partitions are same also). hence, the side-effect is that we need a single lock to control the happen-before of txn completion and commit so the test will get slower.",0,0.9818790555000305
441938393,8657,chia7712,2020-06-18T02:49:28Z,you are right,0,0.8903062343597412
442330606,8657,junrao,2020-06-18T15:53:30Z,"since creategroupmembers() is called in multiple tests, it seems we will be accumulating allgroupmembers across tests. that seems unexpected?",0,0.9313830137252808
442337184,8657,chia7712,2020-06-18T16:03:15Z,"junit, by default, creates a new instance for each test case so [code block] is always new one for each test case.",0,0.988723874092102
452634516,8657,ijuma,2020-07-10T05:48:24Z,it's weird to have a method that invokes a callback and returns a result. do we need both? we have a number of other methods that do something similar. it would be good to reconsider that as it's difficult to reason about usage in such cases.,-1,0.9829340577125549
452635111,8657,ijuma,2020-07-10T05:50:38Z,"the usual naming convention is to only capitalize the first letter, eg leaderhwchange.",0,0.979637086391449
452754165,8657,chia7712,2020-07-10T10:12:49Z,"thanks for your reviews. you are totally right and had given a great refactor idea ([a link] given that refactor will bring a lot of changes to this pr, i had filed a ticket to refactor related code (see [a link] in order to make this pr focus on bug fix.",1,0.9883663058280945
452755236,8657,chia7712,2020-07-10T10:15:19Z,will roger that!,0,0.6309890151023865
463043040,8657,ijuma,2020-07-30T14:35:33Z,"i notice that we are including the `$` here and in a few other places, we should not do that.",0,0.7866441607475281
463044371,8657,ijuma,2020-07-30T14:37:19Z,i raised the point before that it's a bit unusual and unintuitive to have both a callback and a return value. any thoughts on this?,-1,0.6220915913581848
463066191,8657,chia7712,2020-07-30T15:07:03Z,"the response was [a link] in short, we should have a way of fetching delayed request from partition instead of using return value to carry them.",0,0.9884660243988037
463066323,8657,chia7712,2020-07-30T15:07:14Z,will copy that!,0,0.9108926653862
463318346,8657,ijuma,2020-07-30T23:03:17Z,"thanks, i had missed that. will respond in that thread.",1,0.9264132380485535
464562972,8657,junrao,2020-08-03T17:39:30Z,"could we change the explanation to sth like the following? this method may trigger the completeness check for delayed requests in a few purgatories. occasionally, for serialization in the log, a caller may need to hold a lock while calling this method. to avoid deadlock, if the caller holds a conflicting lock while calling this method, the caller is expected to set completedelayedrequests to false to avoid checking the delayed operations during this call. the caller will then explicitly complete those delayed operations based on the return value, without holding the conflicting lock.",0,0.9857565760612488
464567219,8657,junrao,2020-08-03T17:45:18Z,group lock => conflicting lock,0,0.980645477771759
464567267,8657,junrao,2020-08-03T17:45:24Z,group lock => conflicting lock,0,0.980645477771759
464574837,8657,junrao,2020-08-03T18:00:13Z,"perhaps add ""but completes the delayed requests without holding the group lock"".",0,0.9882418513298035
464580388,8657,junrao,2020-08-03T18:11:18Z,a lot of group lock => multiple group locks,0,0.9714235067367554
464580891,8657,junrao,2020-08-03T18:12:15Z,"""this method may hold a lot of group lock"" : this is actually not true. unlike producer/fetch purgatory, which is keyed on partition, joinpurgatory is keyed on the group. so, when we complete a key, only a single group's lock will be held. the reason that we don't want the caller to hold a group lock is that delayedjoin itself uses a lock other than the group lock for delayedoperation.maybetrycomplete() and we want to avoid the deadlock between that lock and the group lock.",0,0.9535422921180725
464697840,8657,junrao,2020-08-03T22:36:59Z,this could be `completedelayedjoinrequests(groupstocomplete)` ?,0,0.9890334606170654
464715376,8657,junrao,2020-08-03T23:33:17Z,perhaps we could add a comment on what this method is intended to test?,0,0.9862339496612549
464791414,8657,chia7712,2020-08-04T04:25:52Z,thanks for explanation. i will revise the comment according to your comment.,1,0.8439199328422546
465179335,8657,junrao,2020-08-04T16:31:50Z,"hmm, it seems that we are now introducing a new potential deadlock. the conflicting paths are the following. path 1 hold group lock -> joinpurgatory.trycompleteelsewatch(delayedjoin) -> watchforoperation (now delayedjoin visible through other threads) -> operation.maybetrycomplete() -> hold delayedjoin.lock path 2 delayedjoin.maybetrycomplete -> hold hold delayedjoin.lock -> trycomplete() -> hold group lock",0,0.9722059369087219
465200508,8657,chia7712,2020-08-04T17:07:08Z,how about removing inner lock ([code block]) from [code block] ? it seems to me [code block] does not need the inner lock.,0,0.9744240641593933
465206257,8657,chia7712,2020-08-04T17:17:09Z,"another approach is that - we introduce an new method ""aftertrycomplete"" to [code block]. the new method is invoked by [code block] after lock is released. [code block] still pass group lock to [code block] and use ""aftertrycomplete"" to complete delayed requests",0,0.9865795969963074
465867406,8657,junrao,2020-08-05T16:53:02Z,": yes, that's a possibility. it adds some complexity to delayedoperation. another possibility is to have a special case to complete the delayed requests from groupmanager.storegroup() in groupcoordinator.oncompletejoin() in a separate thread.",0,0.9813693761825562
478599979,8657,junrao,2020-08-27T18:01:35Z,unneeded new line.,0,0.9218002557754517
478600507,8657,junrao,2020-08-27T18:02:36Z,we probably want to add a comment why this is needed.,0,0.9810568690299988
478603243,8657,junrao,2020-08-27T18:07:40Z,"hmm, why do we need to override this instead of using the one defined in delayedjoin?",0,0.9715463519096375
478603776,8657,junrao,2020-08-27T18:08:37Z,this probably should be included in the local time as before.,0,0.985338568687439
478604292,8657,junrao,2020-08-27T18:09:33Z,could we add the new param to the javadoc?,0,0.9884663820266724
479379705,8657,junrao,2020-08-28T15:31:08Z,this can just be private.,0,0.9863132238388062
479381963,8657,junrao,2020-08-28T15:34:58Z,kafkaapis.handle() => kafkaapis.handle() and the expiration thread for certain delayed operations (e.g. delayedjoin),0,0.9879576563835144
479382167,8657,junrao,2020-08-28T15:35:19Z,the above comment is outdated now.,0,0.8107630014419556
479382962,8657,junrao,2020-08-28T15:36:41Z,we probably should rename this to sth like safetrycomplete().,0,0.984749436378479
479383807,8657,junrao,2020-08-28T15:38:11Z,the default value is none.,0,0.9595777988433838
479389617,8657,junrao,2020-08-28T15:49:04Z,at the end of kafkaapis.handle() => at the end of kafkaapis.handle() and the expiration thread for certain delayed operations (e.g. delayedjoin),0,0.9872703552246094
479390056,8657,junrao,2020-08-28T15:49:47Z,in a queue => are stored in a queue,0,0.9855849146842957
479467548,8657,junrao,2020-08-28T18:24:30Z,the last sentence doesn't complete.,0,0.5613186955451965
479474904,8657,ijuma,2020-08-28T18:41:05Z,can we not use a `boolean` here? `false` until it's been incremented and then `true`. is there value in having the third state?,0,0.9873046278953552
479475681,8657,ijuma,2020-08-28T18:42:47Z,should we be guarding against exceptions here?,0,0.9810406565666199
479661386,8657,junrao,2020-08-29T15:40:22Z,a action => an action,0,0.9778941869735718
479669354,8657,junrao,2020-08-29T17:05:19Z,"even if we hit an exception in handlexxx(), it would still be useful to complete the actionqueue.",0,0.9892162084579468
479670056,8657,junrao,2020-08-29T17:13:30Z,"it seems that we have to distinguish 3 states here: (1) records not appended due to an error; (2) records appended successfully and hwm advanced; (3) records appended successfully and hwm not advanced. in case (1), no purgatory needs to be checked.",0,0.9819309711456299
479670351,8657,junrao,2020-08-29T17:16:24Z,is this used?,0,0.9859181642532349
479670727,8657,junrao,2020-08-29T17:20:46Z,perhaps we could add a note at the top of delayedoperation so that people are aware of the need to complete actions for new delayedoperations in the future.,0,0.9857879877090454
479677889,8657,chia7712,2020-08-29T18:40:53Z,completing delayed actions may cause exception. should exception be swallowed and log if we move the completion to the final block?,0,0.969645619392395
479678653,8657,chia7712,2020-08-29T18:50:10Z,you are right. i miss the exception in [code block]. let me revert this change,0,0.9225975275039673
479678761,8657,ijuma,2020-08-29T18:51:18Z,what's the reasoning for taking just 1 item ? could this cause the queue to grow over time?,0,0.9540798664093018
479678812,8657,ijuma,2020-08-29T18:52:04Z,another approach would be for this queue to be per request thread instead of per server. that would simplify concurrency handling.,0,0.9846602082252502
479679930,8657,chia7712,2020-08-29T19:05:13Z,"it is dangerous to complete delayed actions by [code block] as most methods of [code block] are executed with locking. we, now, depend on [code block] to complete the delayed action produced by someone who can't complete delayed action due to locking. for example, [code block] can produce an new action and the new action can't be completed by [code block] itself due to group locking.",0,0.6608086824417114
479680637,8657,chia7712,2020-08-29T19:13:19Z,the thread has to pass queue to method of replicmanager/groupcoordinator if queue is kept by thread. a lot of methods are included so that is a big patch. i prefer to keep small patch though it gets bigger now :(,-1,0.987798810005188
479682849,8657,junrao,2020-08-29T19:37:54Z,good question. it's based on the assumption that each kafkaapis.handle() call only calls replicamanager. appendrecords() once. not sure if this is always true in the future. perhaps a safer approach is to have action.trycompleteaction() get the current size of the queue and complete all those actions.,1,0.7659245133399963
479683036,8657,chia7712,2020-08-29T19:40:00Z,it should be fine to let handler complete actions as much as possible since the response is created before handling delayed actions.,0,0.9786062836647034
479683212,8657,junrao,2020-08-29T19:42:24Z,"yes, if actionqueue.trycompleteaction() throws an exception, we can just catch it and log a warning in finally since the response has been sent by then.",0,0.9888145327568054
479683544,8657,junrao,2020-08-29T19:45:56Z,"i was thinking to add a comment so that if someone adds a future delayed operation that calls replicamanager.appendrecords() in oncomplete() like delayedjoin, he/she is aware that this operation's onexpiration() needs to call actionqueue.trycompleteaction().",0,0.9840521812438965
479684163,8657,junrao,2020-08-29T19:53:51Z,"perhaps we can make this a bit clearer. sth like the following. leaderhwincremented has 3 possible values: (1) if records are not appended due to an error, the value will be none; (2) if records are appended successfully and hwm is advanced, the value is some(true); (3) if records are appended successfully and hwm is not advanced, the value is some(false).",0,0.9305127859115601
479684353,8657,junrao,2020-08-29T19:55:43Z,"note that the action queue is not only called by requests threads, but also by the expiration thread for certain delayed operations.",0,0.9877602458000183
479686292,8657,ijuma,2020-08-29T20:17:33Z,good point .,1,0.9406068921089172
479686398,8657,ijuma,2020-08-29T20:19:12Z,i suggest using a sealed trait with 3 case objects to make this clearer. using `option[boolean]` as a tristate value is generally best avoided.,0,0.9840722680091858
479686517,8657,chia7712,2020-08-29T20:20:30Z,will copy that,0,0.985030472278595
479689381,8657,chia7712,2020-08-29T20:55:45Z,please take a look at this method,0,0.9752480983734131
479689457,8657,ijuma,2020-08-29T20:56:53Z,"main thing to decide is what to do in case of exception, do we stop processing or do we continue?",0,0.969726026058197
479689653,8657,ijuma,2020-08-29T20:59:38Z,why are we using a blocking queue? it doesn't seem like we ever need the blocking functionality. am i missing something?,0,0.53296959400177
479689694,8657,chia7712,2020-08-29T20:59:55Z,i prefer to just catch it and log a warning as the response has been processed. wdyt?,0,0.9792530536651611
479689838,8657,chia7712,2020-08-29T21:01:42Z,you are right. how about using [code block] instead?,0,0.9599170684814453
479691180,8657,ijuma,2020-08-29T21:20:30Z,"yes, i think that's better. one thing i was wondering about is whether contention is going to be an issue for this `actionqueue`. multiple threads are adding items to it and then trying to consume from it. i haven't thought about all the details, but would a thread local work better? in that case, each thread would add and then drain. this works fine for the request threads, but i wasn't sure about the other case that pointed out.",0,0.9403170347213745
479692892,8657,chia7712,2020-08-29T21:44:06Z,handler (thread) can have local actionqueue and it is passed to each method to collect delayed actions. [code block] is specific case since the delayed actions are possible to be access by two thread (timeout thread and handler thread). a simple way to address thread local is that [code block] owns an actionqueue and the queue is passed to [code block] and then the queue is consumed by [code block]. both [code block] and [code block] are thread-safe so use a thread local queue is safe.,0,0.9837262034416199
479706182,8657,junrao,2020-08-30T00:59:37Z,"if we are unlucky, a single thread could be held up in this loop for a long time. perhaps we could let each thread only complete the number of actions that it sees when entering trycompleteactions().",0,0.8783423900604248
479706303,8657,junrao,2020-08-30T01:01:16Z,"perhaps we could do the try/catch of each action here instead of kafkaapis. this way, we are guaranteed that all pending actions are processed in time.",0,0.9816001057624817
479706407,8657,junrao,2020-08-30T01:02:56Z,"since we are draining more than 1 item now, this comment is no longer accurate.",-1,0.5936478972434998
479716882,8657,ijuma,2020-08-30T03:41:47Z,maybe we can go with a single `actionqueue` in this pr. we can submit a separate pr for reducing the contention by having one per thread.,0,0.9884173274040222
479737358,8657,chia7712,2020-08-30T08:05:15Z,"sure. i will file a pr to follow the pattern in #9229 in order to simplify code base, i will revert the action queue in ""per server"" :)",1,0.9524139761924744
479802860,8657,junrao,2020-08-30T18:47:31Z,need => needs,0,0.9798118472099304
479802912,8657,junrao,2020-08-30T18:48:05Z,is failed => failed,0,0.9037692546844482
479803168,8657,junrao,2020-08-30T18:50:50Z,probably increased is clearer than incremental.,0,0.983148455619812
479829275,8657,ijuma,2020-08-30T23:26:35Z,another nit: `leaderhwchange` adheres to the coding convention better.,0,0.9848180413246155
482743072,8657,chia7712,2020-09-03T06:50:50Z,"this change avoids deadlock in [code block]. if we update [code block] before [code block], the other threads can take the same key to complete delayed request. hence the deadlock happens due to following conditions. **thread_1** holds [code block] of transactionstatemanager to call [code block] and it requires lock of delayed request to call [code block]. **thread_2** holds lock of delayed request to call [code block] (updatecachecallback) and [code block] requires [code block] of transactionstatemanager.",0,0.9876670837402344
482753529,8657,chia7712,2020-09-03T07:06:44Z,"according to above case, there is a potential deadlock. [code block] [code block] is executed after updating [code block]. hence, it is possible that the lock of this request is held by **another thread**. the deadlock happens if this [code block] is holding the **lock** required by **another thread**. it seems to me the simple approach is to remove [code block]. that should be fine since we have called [code block] before.",0,0.9784377813339233
483276075,8657,junrao,2020-09-03T21:58:37Z,": 1. i think we still need `operation.safetrycomplete` in `delayedoperation.trycompleteelsewatch()`. the reason is that after the `operation.trycomplete()` call, but before we add the key to watch, the operation could have been completed by another thread. since that thread doesn't see the registered key, it won't complete the request. if we don't call `operation.safetrycomplete` after adding the key for watch, we could have missed the only chance for completing this operation. 2. i am not sure if there is a deadlock caused by transactionstatemanager. i don't see updatecachecallback hold any lock on statelock. the following locking sequence is possible through transactionstatemanager. thread 1 : hold readlock of statelock, call replicamanager.appendrecords, call trycompleteelsewatch, hold lock on delayedoperation thread 2: hold lock on delayedoperation, call delayedoperation.oncomplete, call removefromcachecallback(), hold readlock of statelock. however, since both threads hold readlock of statelock, there shouldn't be a conflict. do you see the test fail due to a deadlock?",0,0.8208709359169006
483552275,8657,chia7712,2020-09-04T11:15:46Z,the following read/write lock is from[code block] of [code block] 1. thread_1: holding readlock and waiting for lock of delayed op (transactionstatemanager#appendtransactiontolog) 2. thread_2: waiting for writelock ([code block]) [code block] 3. thread_3: holding lock of delayed op and waiting for readlock (another thread is trying to complete delayed op) **deadlock** 1. thread_1 is waiting for thread_3 1. thread_3 is waiting for thread_2 1. thread_2 is waiting for thread_1,0,0.9840546250343323
483832980,8657,junrao,2020-09-04T20:33:01Z,": thanks for the explanation. `statelock` is created as an unfair reentrantreadwritelock. so, in that case, will thread_3's attempt for getting the readlock blocked after thread_2? did the test actually failed because of this?",1,0.9466196298599243
483897245,8657,chia7712,2020-09-05T01:53:31Z,"to the best of my knowledge, writers have preference over readers in order to avoid starvation. that behavior is not public and we can get some evidence from source code. for example: [code block] at any rate, the non-fair mode does not guarantee above situation does not happen. hence, it would be better to avoid potential deadlock caused by [code block]. how about using [code block] in trycompleteelsewatch? it avoids conflicting locking and still check completion of delayed operations after adding watches?",0,0.9290040135383606
483966128,8657,junrao,2020-09-05T16:31:58Z,": thanks for the explanation. i agree that it's a potential problem. does using `trylock` in `trycompleteelsewatch()` lead us back to the previous issue that we could miss the opportunity to to complete an operation (fixed with kafka-6653)? another possibly is that we hold the lock in delayed operation while adding the operation to watch list and do the final `safetrycomplete()` check. this way, when the delayed operation is exposed to another thread, every thread, including the caller, always first acquires the lock in delayed operation. this should avoid all potential deadlocks between `trycompleteelsewatch()` and `checkandcomplete()`. what do you think?",1,0.9600323438644409
484039528,8657,chia7712,2020-09-06T08:22:57Z,nice idea. i have addressed this approach.,1,0.9736472964286804
484090245,8657,junrao,2020-09-06T16:38:01Z,requiring => requires,0,0.9746549129486084
484090563,8657,junrao,2020-09-06T16:41:37Z,it seems that we don't need the `if` here?,0,0.9734039306640625
484090694,8657,junrao,2020-09-06T16:43:11Z,we should return if `trycomplete()` returns true.,0,0.988031268119812
484091466,8657,junrao,2020-09-06T16:51:33Z,"this is an existing issue. i am not sure if calling `trycomplete()` without holding the operation's lock guarantees visibility to another thread. for example, thread 1 changes the state in the operation in `trycomplete()`. it then calls `trycomplete()` holding the operations's lock but doesn't change the state in the operation. thread 2 calls `trycomplete()` holding the operations's lock. is thread 2 guaranteed to see the changes made by thread 1 since the update was made without crossing the memory boundary by subsequent readers? if this is an issue, we could extend to lock to do the first `trycomplete()` check.",0,0.9684937000274658
484092252,8657,junrao,2020-09-06T16:59:20Z,"this approach is fine but leaks operation.lock beyond tests. another way to package this is to add a new method in delayedoperation like trycompleteandmaybewatch(). if that's not very clean, we can keep the current approach.",0,0.9825917482376099
484092496,8657,junrao,2020-09-06T17:02:00Z,do we still need this change to avoid deadlocks?,0,0.9789217710494995
484092945,8657,junrao,2020-09-06T17:06:29Z,"with this change, `delayedoperations.checkandcompletefetch()` is only used in tests. i am wondering if it can be removed. it's fine if we want to do this in a followup pr. unrelated to this pr, `delayedoperations.checkandcompleteproduce` and `delayedoperations.checkandcompletedeleterecords` seem unused. we can probably remove them in a separate pr.",0,0.960379421710968
484097161,8657,chia7712,2020-09-06T17:52:54Z,"pardon me, the latest commit does it. if the trycomplete return true, this method return true also. or you mean we can do return in the lambda function directly? if so, the reason i don’t address it is the impl of return in lambda is to throws and then catch exception.that is anti-pattern in scala and we should avoid it from our hot methods.",0,0.515735387802124
484097601,8657,chia7712,2020-09-06T17:57:55Z,there is an new test for this new behavior. in the delayedoperationtest.,0,0.9865378141403198
484097948,8657,chia7712,2020-09-06T18:01:29Z,"yep. if we add it to watch list too early, the concurrent issue happens as trycompleteelsewatch calls trycomplete without locking.",0,0.9869122505187988
484099709,8657,chia7712,2020-09-06T18:21:23Z,"it depends :) however, it should be fine to extend the lock to do it in this pr. will address it in next commit",1,0.961824893951416
484101535,8657,junrao,2020-09-06T18:40:54Z,"yes, you are right. i missed the bracket alignment.",0,0.6111863255500793
484101769,8657,junrao,2020-09-06T18:43:34Z,"yes, it's just that if all non-testing usage of delayedoperation.lock is within delayedoperation itself, it makes it a bit easier to trace down all usage of lock.",0,0.9852203130722046
484138649,8657,chia7712,2020-09-07T00:59:57Z,"this approach can not resolve all potential deadlock. for example: 1. thread_a gets lock of op 1. thread_a adds op to watch list 1. thread_a calls op#trycomplete (and it requires lock_b) 1. thread_b holds lock_b 1. thread_b sees op from watch list 1. thread_b needs lock of op hence, we are facing the following issues. 1. the last completion check can cause deadlock after the op is exposed to other threads (by watch list). 1. the last completion check can not be removed due to kafka-6653. how about using actionqueue to resolve it? we add completion check to actionqueue after adding op to watch list. all handlers are able to complete it even if they don't have same key.",0,0.9498100876808167
484163863,8657,chia7712,2020-09-07T03:20:48Z,"as the potential deadlock caused by holding lock in [code block], i don""t change the [code block] to [code block]. maybe we can deal with this issue when we meet such issue.",0,0.9787604212760925
484164627,8657,chia7712,2020-09-07T03:24:50Z,i will file a ticket after this pr is merged. this is small change. i will remove them in this pr,0,0.9698902368545532
484181930,8657,junrao,2020-09-07T04:52:58Z,": what you described is possible, but probably not an issue in practice. since trycomplete() always completes a delayed operation asynchronously, there is no reason for the caller of a delayed operation to hold any lock while calling trycomplete. therefore, in step 4 above, the first lock that thread_b (assuming it's well designed) can acquire should be the lock in delayed operation.",0,0.9840913414955139
484209068,8657,chia7712,2020-09-07T06:32:29Z,"you are right. however, not sure how to maintain that ""well designed"" code in the future as the deadlock is implicit. it seems to me avoiding multiples exclusive lockings can avoid the deadlock. i will keep current approach since the story i described may be overkill in practice.",0,0.9313769936561584
484519651,8657,junrao,2020-09-07T16:45:35Z,"since safetrycomplete() is no longer used in trycompleteelsewatch(), the above comment is not completely relevant. perhaps we could just explain what this method does ""thread-safe variant of trycomplete().""",0,0.9833779335021973
484521628,8657,junrao,2020-09-07T16:52:44Z,it requires lock_b => it tries to require lock_b,0,0.9864886403083801
484522816,8657,junrao,2020-09-07T16:57:32Z,"perhaps we could change this comment to sth like the following. to avoid the above scenario, we recommend delayedoperationpurgatory.checkandcomplete() be called without holding any lock. since delayedoperationpurgatory.checkandcomplete() completes delayed operations asynchronously, holding a lock to make the call is often unnecessary.",0,0.9853461980819702
484523257,8657,junrao,2020-09-07T16:59:24Z,there is a potential deadlock => there is a potential deadlock between the callers to trycompleteelsewatch() and checkandcomplete(),0,0.9858157634735107
484523534,8657,junrao,2020-09-07T17:00:21Z,thread_c holds lock of op => thread_c calls checkandcomplete () and holds lock of op,0,0.9879337549209595
484524545,8657,junrao,2020-09-07T17:04:35Z,is this change still necessary now that we always call trycomplete() with lock in trycompleteelsewatch?,0,0.9881409406661987
484543835,8657,chia7712,2020-09-07T18:44:50Z,will copy that,0,0.985030472278595
484605576,8657,junrao,2020-09-08T01:37:51Z,safetrycompleteandelse => safetrycompleteorelse ?,0,0.9854561686515808
484606811,8657,junrao,2020-09-08T01:43:41Z,"the above comment is a bit out of context now. perhaps we could change ""we do the check in the following way"" to ""we do the check in the following way through safetrycompleteandelse()"".",0,0.9690299034118652
484607882,8657,junrao,2020-09-08T01:48:33Z,do we still need to change the ordering now that we always call trycomplete() with lock in trycompleteelsewatch?,0,0.9879733324050903
484609072,8657,junrao,2020-09-08T01:53:44Z,checkandcomplete () => checkandcomplete(),0,0.9864612221717834
484610866,8657,junrao,2020-09-08T02:01:32Z,"perhaps change the above to the following? we hold the operation's lock while adding the operation to watch list and doing the trycomplete() check. this is to avoid a potential deadlock between the callers to trycompleteelsewatch() and checkandcomplete(). for example, the following deadlock can happen if the lock is only held for the final trycomplete() check.",0,0.9871615767478943
484622290,8657,chia7712,2020-09-08T02:52:05Z,i will revert this change,0,0.8238537907600403
484638938,8657,junrao,2020-09-08T04:08:51Z,"i think we still want to keep the rest of the paragraph starting from ""call trycomplete()."".",0,0.9874704480171204
484639236,8657,junrao,2020-09-08T04:10:06Z,"we hold => through safetrycompleteorelse(), we hold",0,0.9840098023414612
484640168,8657,junrao,2020-09-08T04:14:27Z,thread_b holds lock_b => thread_b holds lock_b and calls checkandcomplete(),0,0.9880465269088745
484640862,8657,junrao,2020-09-08T04:17:41Z,"noted that current approach can't prevent all deadlock. => note that even with the current approach, deadlocks could still be introduced.",0,0.9801018238067627
484644802,8657,junrao,2020-09-08T04:35:49Z,"instead of introducing a global var, could we add a new param when constructing committxnoffsetsoperation and completetxnoperation?",0,0.9891602396965027
484645849,8657,junrao,2020-09-08T04:40:17Z,thread_a gets lock of op => thread_a calls trycompleteelsewatch() and gets lock of op,0,0.9880800843238831
485026583,8657,junrao,2020-09-08T15:52:56Z,to call safetrycomplete => to call the final trycomplete(),0,0.9855894446372986
485026799,8657,junrao,2020-09-08T15:53:16Z,trycompleteelsewatch => trycompleteelsewatch(),0,0.9817373752593994
485034262,8657,junrao,2020-09-08T16:04:21Z,causes error => causes an error,0,0.9461119771003723
485034296,8657,junrao,2020-09-08T16:04:23Z,such error => such an error,0,0.9609677791595459
94801659,2264,ijuma,2017-01-05T16:36:06Z,it seems like this field is not used anywhere.,0,0.6274417638778687
95000465,2264,hachikuji,2017-01-06T19:05:19Z,i think we need to enforce a minimum version of 2 since older versions would expect an older version of the message format. this is also an easy way to detect that we're talking with a version of the broker older than 0.10. i'm wondering if it would make sense to raise an exception to the user immediately when we connect to such a broker instead of waiting until we send an incompatible request?,0,0.9702380299568176
95016586,2264,cmccabe,2017-01-06T20:43:03Z,"sure, we can enforce a minimum version of 2 here. brokers earlier than 0.10 will automatically disconnect our clients, since those brokers don't support apiversionsrequest, which is the first thing we send after kafka-3600.",0,0.9876701831817627
95197805,2264,ijuma,2017-01-09T17:01:03Z,"nit: in kafka, we don't use `get` prefix for accessors.",0,0.984060525894165
95198122,2264,ijuma,2017-01-09T17:02:33Z,"this is not needed, `stringbuilder` appends `null` for you.",0,0.9869497418403625
95204211,2264,ijuma,2017-01-09T17:35:24Z,nit: it may make sense to move the requestbuilder to the end as it's likely to be bigger and make it harder to read the other fields.,0,0.9819706678390503
95204352,2264,ijuma,2017-01-09T17:36:01Z,"we have a method `requestbuilder` that is the same as this, so we can remove this one.",0,0.9886736273765564
95215232,2264,cmccabe,2017-01-09T18:28:11Z,"ok, i'll remove that here (and elsewhere)",0,0.9863399267196655
95215682,2264,cmccabe,2017-01-09T18:30:19Z,k,0,0.9391535520553589
95239733,2264,cmccabe,2017-01-09T20:32:35Z,"this should be used any time that there is a version mismatch problem between the message we are trying to send and the message versions we can actually send to the desired broker. i fixed the fetcher to use this instead of doing its own thing to detect version problems. i also change the type of this to runtimeexception, so that the exact exception which the builder raised can be preserved here.",0,0.9889252781867981
95248631,2264,ijuma,2017-01-09T21:20:56Z,nit: should this be `newrequest` since it's a method in `kafkaclient`? or is it clearer how it is?,0,0.9873505234718323
95252239,2264,ijuma,2017-01-09T21:39:37Z,"nit: do we really need 3 lines for this? seems like we could do it in two. in kafka, we generally go for wider lines than the traditional 80 columns (100 to 120 is common).",0,0.9686972498893738
95252366,2264,ijuma,2017-01-09T21:40:22Z,can we expand on when this can happen?,0,0.9840319752693176
95261313,2264,hachikuji,2017-01-09T22:27:41Z,nit: this alignment is weird. are you using intellij defaults?,-1,0.9879605174064636
95262756,2264,hachikuji,2017-01-09T22:36:29Z,does it make sense to special case the apiversion request only instead of skipping the check for all internal requests?,0,0.9873524904251099
95263217,2264,hachikuji,2017-01-09T22:39:17Z,nit: we usually skip braces for one-line branches like this. a few more below.,0,0.9840424060821533
95264033,2264,hachikuji,2017-01-09T22:44:20Z,"would it make sense to push this check into `getusableversion`? i wouldn't consider a negative version ""usable.""",0,0.9851565361022949
95264436,2264,hachikuji,2017-01-09T22:46:54Z,is this equivalent to this? [code block],0,0.9869958758354187
95264759,2264,hachikuji,2017-01-09T22:48:56Z,nit: indentation,0,0.9879170060157776
95265028,2264,hachikuji,2017-01-09T22:50:32Z,nit: use string interpolation,0,0.988767683506012
95265544,2264,hachikuji,2017-01-09T22:53:41Z,"there's a bug in `processdisconnection` (not introduced in this patch) that we ought to fix here. the type of `node` here is a string, but `nodeapiversions` is keyed by integer. (the conversion between string and int all over this class always pains me.)",-1,0.9429661631584167
95265740,2264,ijuma,2017-01-09T22:54:41Z,"unfortunately, 0.9.0.1 has a bug where it won't disconnect when it receives an unknown request. it will keep the connection open until the connection reaper comes along. a subsequent request can cause an immediate disconnection though.",0,0.920872688293457
95265836,2264,hachikuji,2017-01-09T22:55:18Z,i think `nodeid` is a more accurate name.,0,0.9859927892684937
95265980,2264,ijuma,2017-01-09T22:56:13Z,"nit: is it right to say it's an `obsolete` broker? seems a bit too strong, obsolete means `no longer produced or used; out of date` whereas it could be a broker that is just 4 months old given our current time-based release schedule.",0,0.6567656993865967
95266228,2264,ijuma,2017-01-09T22:57:44Z,do we really need to do this? i'd prefer if we didn't expose a static mutable array outside this class.,0,0.9708153009414673
95266232,2264,hachikuji,2017-01-09T22:57:45Z,nit: seems like there's enough room on the previous line for this,0,0.9234417676925659
95266343,2264,ijuma,2017-01-09T22:58:27Z,nit: `version`?,0,0.9872397780418396
95266684,2264,hachikuji,2017-01-09T23:00:39Z,seems this was our last usage for the `now` parameter.,0,0.9797693490982056
95266777,2264,hachikuji,2017-01-09T23:01:13Z,nit: can this fit on the line above?,0,0.98792564868927
95267609,2264,ijuma,2017-01-09T23:06:14Z,"these 3 lines can simply be `val version = apiversion.getorelse(protoutils.latestversion(apikey,id))`.",0,0.9888167381286621
95267715,2264,hachikuji,2017-01-09T23:06:56Z,seems we can turn this into an assertion when it is not an apiversion request.,0,0.9874193072319031
95267760,2264,ijuma,2017-01-09T23:07:12Z,"nit: it should be `val version: short` (space after the colon, not before).",0,0.9880820512771606
95268226,2264,hachikuji,2017-01-09T23:10:16Z,`now` is never used.,0,0.9430341124534607
95268276,2264,ijuma,2017-01-09T23:10:37Z,"looks like the code for both `builder(...)` is the same, so maybe we can just do the `livebrokers` bit in the `if/else`.",0,0.9876438975334167
95268361,2264,ijuma,2017-01-09T23:11:14Z,"nit: the map creation is usually done like `map(securityprotocol.plaintext -> new endpoint(node.host, node.port))`.",0,0.9891336560249329
95268422,2264,hachikuji,2017-01-09T23:11:38Z,nit: you can leave out the type on the right-hand side.,0,0.9878036975860596
95268671,2264,ijuma,2017-01-09T23:13:10Z,nit: is there a reason why you didn't chain this one too?,0,0.8014102578163147
95268734,2264,ijuma,2017-01-09T23:13:39Z,seems like the `()` introduced here are not needed.,0,0.9811075925827026
95271011,2264,hachikuji,2017-01-09T23:28:58Z,`api` no longer used. indentation needs fixing also.,0,0.9787378907203674
95271585,2264,hachikuji,2017-01-09T23:32:24Z,there are a few javadoc references that need fixing as well.,0,0.9883941411972046
95274471,2264,hachikuji,2017-01-09T23:54:45Z,"i think it might be better to move this check into `consumernetworkclient.requestfuturecompletionhandler` to ensure that we don't forget any checks. also `onfailure` seems like a more appropriate callback for that case,",0,0.9777688980102539
95275129,2264,hachikuji,2017-01-10T00:00:05Z,"nit: string interpolation is preferred. another one below. also, not sure about the convention of including the function name. wouldn't the logger do that for us?",0,0.9705058336257935
95276737,2264,hachikuji,2017-01-10T00:13:40Z,"in this case, we're using the presence of the `offsets` field to indirectly determine that the version that was used was 0. i'm not sure we'll always have something so convenient, so i've been wondering if we need a way to determine the version that was used more directly. for example, we could have `clientresponse` or even `abstractresponse` include a field for the version.",0,0.97268146276474
95276915,2264,cmccabe,2017-01-10T00:15:26Z,"ok, i realigned it with the left paren",0,0.985451877117157
95276973,2264,cmccabe,2017-01-10T00:15:53Z,k,0,0.9391535520553589
95277223,2264,hachikuji,2017-01-10T00:18:28Z,why was this changed?,0,0.865017294883728
95277345,2264,cmccabe,2017-01-10T00:19:36Z,"hmm. i haven't thought about it that hard, but i think special casing will probably get messy here. it also duplicates work done elsewhere to check if the message is sendable.",0,0.9367809295654297
95277392,2264,hachikuji,2017-01-10T00:19:57Z,the `impl` suffix is a little unconventional. can we just use `getoffsetsbytimes`?,0,0.7607904076576233
95278127,2264,cmccabe,2017-01-10T00:26:26Z,k,0,0.9391535520553589
95278471,2264,cmccabe,2017-01-10T00:29:17Z,ok,0,0.9667208194732666
95278543,2264,cmccabe,2017-01-10T00:29:57Z,removed,0,0.9654131531715393
95278678,2264,hachikuji,2017-01-10T00:30:54Z,i think we need to pass this exception to the future instead of raising. would be good to have a test case if we don't already.,0,0.8757932782173157
95278757,2264,cmccabe,2017-01-10T00:31:41Z,"yeah, let's just do that.",0,0.9638662338256836
95278815,2264,cmccabe,2017-01-10T00:32:16Z,k,0,0.9391535520553589
95278891,2264,cmccabe,2017-01-10T00:33:00Z,yeah,0,0.9325205683708191
95279595,2264,hachikuji,2017-01-10T00:39:47Z,"we didn't have it before, but maybe we should add a null check here for more resilience in the future.",0,0.9711818099021912
95279607,2264,cmccabe,2017-01-10T00:39:56Z,"yeah, that is pretty nasty. i'll fix it. i wish there were some workaround for this, but it looks like java map still always supports put(object) to allow compatibility with the pre-generics days... we should start running findbugs to catch things like this",-1,0.9896117448806763
95279753,2264,hachikuji,2017-01-10T00:41:13Z,"i'm a little unclear on the pattern for which fields are included in the builder constructor and which are included through methods. i thought perhaps it would be the required arguments included in the constructor, but we didn't pass the timestamps to query in the `listoffsetrequest` above, which seems required.",0,0.9675009846687317
95280248,2264,cmccabe,2017-01-10T00:45:07Z,k,0,0.9391535520553589
95280508,2264,cmccabe,2017-01-10T00:47:36Z,k,0,0.9391535520553589
95280577,2264,cmccabe,2017-01-10T00:48:05Z,k,0,0.9391535520553589
95280644,2264,cmccabe,2017-01-10T00:48:41Z,yeah,0,0.9325205683708191
95281013,2264,cmccabe,2017-01-10T00:51:28Z,k,0,0.9391535520553589
95281567,2264,cmccabe,2017-01-10T00:56:07Z,i added a comment,0,0.9856575131416321
95282327,2264,hachikuji,2017-01-10T01:02:40Z,maybe `unsupportedbrokerexception`?,0,0.9757444858551025
95284742,2264,cmccabe,2017-01-10T01:26:27Z,"hmm, how would the 0.9.0.1 broker even know that it was getting another request? it doesn't know the size of the first request so it doesn't know where that request ends and a new one begins.",0,0.9656682014465332
95284792,2264,cmccabe,2017-01-10T01:26:58Z,k,0,0.9391535520553589
95284826,2264,hachikuji,2017-01-10T01:27:24Z,nit: would be nice to be consistent on the use of braces or parenthesis. i think we are trying to encourage the latter.,1,0.6694135069847107
95286297,2264,junrao,2017-01-10T01:43:04Z,"when the transport is ssl, the client can't send requests immediately after the socket is connected. we have to wait for the ssl handshake to complete. so, perhaps the selector needs to further return the transport.ready() state in kafkachannel to networkclient.",0,0.9880615472793579
95286337,2264,junrao,2017-01-10T01:43:30Z,"using the current version is ok for now since there is currently only one version of saslhandshakerequest. it would be useful to add a comment that when there are new versions of saslhandshakerequest, we need to select the version based on the result of apirequest accordingly.",0,0.9806441068649292
95290016,2264,hachikuji,2017-01-10T02:25:10Z,we seem to be missing the version mismatch check in `handleproduceresponse`.,0,0.9537776708602905
95303775,2264,cmccabe,2017-01-10T05:53:19Z,k,0,0.9391535520553589
95304065,2264,cmccabe,2017-01-10T05:57:04Z,"setversion is a method on the base class, abstractrequest#builder. so it returns an instance of abstractrequest#builder rather than an instance of the derived class fetchrequest#builder, which is awkward for scala's type inference.",0,0.978741466999054
95304445,2264,cmccabe,2017-01-10T06:01:54Z,k,0,0.9391535520553589
95304662,2264,cmccabe,2017-01-10T06:04:57Z,nice,1,0.8361793160438538
95304719,2264,cmccabe,2017-01-10T06:06:13Z,k,0,0.9391535520553589
95304766,2264,cmccabe,2017-01-10T06:06:44Z,k,0,0.9391535520553589
95304877,2264,cmccabe,2017-01-10T06:08:33Z,k,0,0.9391535520553589
95305418,2264,cmccabe,2017-01-10T06:16:03Z,"ok, we can hide it",0,0.9854688048362732
95305559,2264,cmccabe,2017-01-10T06:17:31Z,"obsolete may be a little strong, but it's clear what it means and what the user should do if they want access to the feature. we could also go with something like ""outdatedbrokerexception""?",0,0.967357873916626
95305659,2264,cmccabe,2017-01-10T06:18:44Z,"it sounds like we would be in the clear then, since we're sending an apiversionsrequest followed by a follow-on request?",0,0.9868467450141907
95305690,2264,cmccabe,2017-01-10T06:19:14Z,fixed,0,0.975196123123169
95305695,2264,cmccabe,2017-01-10T06:19:19Z,k,0,0.9391535520553589
95305967,2264,cmccabe,2017-01-10T06:22:42Z,k,0,0.9391535520553589
95305976,2264,cmccabe,2017-01-10T06:22:50Z,sounds good,1,0.9535238742828369
95305989,2264,cmccabe,2017-01-10T06:22:56Z,removed,0,0.9654131531715393
95306011,2264,cmccabe,2017-01-10T06:23:05Z,"yes, let's replace it with that",0,0.9836007952690125
95306022,2264,cmccabe,2017-01-10T06:23:14Z,fixed,0,0.975196123123169
95306030,2264,cmccabe,2017-01-10T06:23:21Z,k,0,0.9391535520553589
95306063,2264,cmccabe,2017-01-10T06:23:48Z,ugh. that's a nasty one. i fixed it in the patch. we should run findbugs...,-1,0.9918322563171387
95306070,2264,cmccabe,2017-01-10T06:23:54Z,k,0,0.9391535520553589
95306078,2264,cmccabe,2017-01-10T06:23:59Z,k,0,0.9391535520553589
95306086,2264,cmccabe,2017-01-10T06:24:06Z,yeah,0,0.9325205683708191
95306094,2264,cmccabe,2017-01-10T06:24:11Z,ok,0,0.9667208194732666
95306102,2264,cmccabe,2017-01-10T06:24:17Z,yeah,0,0.9325205683708191
95306242,2264,cmccabe,2017-01-10T06:26:07Z,"hmm. i think if it were just newrequest, i would wonder whether it was a new abstractrequest or a new clientrequest. what do you think?",0,0.9751827716827393
95306249,2264,cmccabe,2017-01-10T06:26:14Z,ok,0,0.9667208194732666
95306275,2264,cmccabe,2017-01-10T06:26:38Z,i added a comment,0,0.9856575131416321
95306664,2264,cmccabe,2017-01-10T06:32:08Z,k,0,0.9391535520553589
95307070,2264,cmccabe,2017-01-10T06:37:05Z,"hmm, i didn't see any code path where the return value could be null, or the value of the future itself, or the keys or values of the map. maybe an npe is ok in that case?",0,0.9821495413780212
95307372,2264,cmccabe,2017-01-10T06:40:56Z,"i wanted to avoid confusion with the public api of that name. how about ""retrieveoffsetsbytimes""?",0,0.9742478132247925
95307500,2264,cmccabe,2017-01-10T06:42:28Z,"good catch. i made some other edits to the for loop, but they're no longer necessary now. reverted",1,0.9787594079971313
95308523,2264,cmccabe,2017-01-10T06:54:58Z,"i think abstractresponse should have a version number in it, since the data it contains varies based on the version. sometimes the interpretation of the data varies based on version as well. it's a property of the response and it belongs in the response object. but hopefully we can hold off on that for now since this patch is kinda big as-is...",0,0.9055407643318176
95308701,2264,cmccabe,2017-01-10T06:57:14Z,"yeah, let's leave the function name out. will use string interpolation",0,0.9853142499923706
95309085,2264,cmccabe,2017-01-10T07:02:05Z,"you are right that the general pattern is that constructor arguments are required, other things are optional. ideally we would have listoffsetrequest#builder(map ) and listoffsetrequest#builder(map ), but we can't do that because of a java limitation... both constructors would have the same type once type erasure has been performed, which is not allowed.",0,0.9766764044761658
95309234,2264,cmccabe,2017-01-10T07:03:58Z,"braces seem a little more familiar to me because of json. but if parentheses are the way to go, i can change it. it's a big change though since all the builders have a tostring. are we sure we want the parens?",0,0.9440312385559082
95324930,2264,ijuma,2017-01-10T09:19:53Z,i was debating that myself before writing the comment. let's leave it as is then.,0,0.9375483393669128
95342279,2264,ijuma,2017-01-10T11:04:44Z,"oh, i see. the compiler is correct in not allowing that then. one way to fix that is to change the definition of `builder` to be: [code block] but this makes it more awkward to use the abstract builder directly due to the additional type parameter (in scala we could use type members instead). an alternative is to override `setbuilder` in each builder and use the more specific type there. it's a bit annoying, but builders are supposedly used more times than they are defined.",-1,0.7816768884658813
95342721,2264,ijuma,2017-01-10T11:07:32Z,"the broker assumes that all requests are consistent with regards to the common request header elements. if we set the minimum versions correctly, we should be in the clear, i think. it would be good to have a test for 0.9.0.1, but we can do that in a follow-up.",0,0.9800549745559692
95343648,2264,ijuma,2017-01-10T11:13:53Z,"i think i prefer `unsupportedbrokerversion`. but it's subjective and `obsolete`/`outdated` are more explicit with regards that you want a newer broker. another point: if we think of the protocol as something independent from kafka (i.e. there could be other implementations), which is something that jay thinks we should, then `unsupportedbrokerversion` also seems better.",0,0.9449657201766968
95344394,2264,ijuma,2017-01-10T11:19:23Z,"there are indeed a few ways to do this. we tend to follow the `foo(a=""a"",b=""b"")` model and this is what public classes like `producerrecord` and `consumerrecord` do. also, it's worth saying that, outside of loops, `stringbuilder` is no better than string concatenation with regards to performance. up to java 8, javac will do the stringbuilder thing itself. from java 9, invokedynamic will be used to allow the runtime to choose the best strategy ([a link] my suggestion is to clean this up in a subsequent pr. it can even be done after the feature freeze.",0,0.9671425819396973
95358669,2264,ijuma,2017-01-10T13:01:34Z,", there is a comment already a couple of lines above (i asked ashish to add it as part of kafka-3600): [code block] maybe we can move the comment so that it's closer to the request creation.",0,0.9854308366775513
95358836,2264,ijuma,2017-01-10T13:02:45Z,"it's a bit odd that we add a hardcoded prefix and suffix in a generic `join` method. typically, these would be parameters and the default case would be no prefix or suffix (consistent with `join` that takes a `collection`).",0,0.5206432342529297
95359080,2264,ijuma,2017-01-10T13:04:29Z,nit: space missing before `:`.,0,0.9662954807281494
95359283,2264,ijuma,2017-01-10T13:05:52Z,", have we tested with ssl enabled?",0,0.9870222210884094
95363623,2264,ijuma,2017-01-10T13:33:37Z,nit: `1: short` is a little better because it will fail to compile if the conversion is not possible where `toshort` will happily overflow. doesn't make a difference in these particular cases though.,0,0.9309674501419067
95368726,2264,ijuma,2017-01-10T14:04:14Z,nit: `0: java.lang.long` is a tiny bit shorter.,0,0.9843648672103882
95369472,2264,ijuma,2017-01-10T14:08:50Z,i think it would be worth adding an overload without the `callback` as it's optional and many callers don't need it.,0,0.9658687710762024
95370437,2264,ijuma,2017-01-10T14:14:21Z,this is unused.,0,0.9094939231872559
95373680,2264,ijuma,2017-01-10T14:31:44Z,i think is thinking of the case where `ret.get(partition)` returns `null`. not sure if we are enforcing that elsewhere though.,0,0.9704470038414001
95376734,2264,ijuma,2017-01-10T14:46:19Z,"typo, `r` missing.",0,0.966581404209137
95378574,2264,ijuma,2017-01-10T14:54:01Z,nit: i think this is harder to read by being split into 3 lines like this. looks like a staircase. ;) there's one other case like that.,1,0.974028468132019
95379773,2264,ijuma,2017-01-10T14:59:28Z,change `versionid` to `short` like you did in other places?,0,0.982835590839386
95394973,2264,ijuma,2017-01-10T16:01:54Z,it looks like we only need to support `2` and above: [a link],0,0.9847528338432312
95397340,2264,ijuma,2017-01-10T16:11:14Z,should we be validating that version is always `1`? version `0` would probably mean that something is wrong.,0,0.9234218597412109
95398519,2264,ijuma,2017-01-10T16:16:08Z,in other request classes we don't throw an exception in case the version is higher than expected. we should be consistent. i think this approach is good because it forces people to consider how to handle a new version when it's introduced.,0,0.7958542704582214
95399367,2264,ijuma,2017-01-10T16:19:57Z,i think we should set it to `-1` in this case to make it clear that it won't be used as we have the following: [code block],0,0.9861970543861389
95400451,2264,ijuma,2017-01-10T16:24:42Z,we have 3 `getversion` calls. one should be enough.,0,0.9846590757369995
95402987,2264,ijuma,2017-01-10T16:35:38Z,parenthesis are not needed here or the other branches since a single value is being returned now.,0,0.9855071306228638
95403350,2264,ijuma,2017-01-10T16:37:05Z,nit: should be `fetchdata()`.,0,0.9891624450683594
95403601,2264,ijuma,2017-01-10T16:38:06Z,nit: there should be a space before `:`.,0,0.9748154878616333
95403993,2264,ijuma,2017-01-10T16:39:51Z,"personally, i think `short` and `null` for no usable version is less error-prone (you'll get a npe if you accidentally try to use it instead of ending with a `-1` somewhere it should not be).",0,0.9744734168052673
95404122,2264,ijuma,2017-01-10T16:40:22Z,seems like this comment should be in the method documentation.,0,0.9851556420326233
95404878,2264,ijuma,2017-01-10T16:43:20Z,why not use `enummap `? it would be more readable imo.,0,0.9884073138237
95405837,2264,ijuma,2017-01-10T16:47:11Z,can this ever be less than 0?,0,0.971592903137207
95405971,2264,ijuma,2017-01-10T16:47:48Z,`math.min` and 4 lines become 1?,0,0.9844537377357483
95406464,2264,ijuma,2017-01-10T16:50:01Z,this `tostring` is quite long. :) it would be nice to break it down into smaller methods so that it's easier to understand.,1,0.9759244322776794
95407688,2264,ijuma,2017-01-10T16:55:15Z,"any reason we are using `linkedlist` instead of `arraylist`? we seem to be adding to the end, iterating and then clearing (after jason's suggestion), so `arraylist` seems like the better option.",0,0.9858593344688416
95409034,2264,ijuma,2017-01-10T17:01:28Z,"it would be good to include the most current version in this message as well. also, as jun said it may be a good to log at a higher level if we are downgrading a request. not sure what jun had in mind, but maybe `debug`?",0,0.9716466069221497
95410187,2264,ijuma,2017-01-10T17:06:45Z,we have the following code for failed metadata requests: [code block] should we be doing similarly for this case (since we now do `apiversionsrequest` before `metadatarequest`)?,0,0.9887363314628601
95410941,2264,ijuma,2017-01-10T17:10:14Z,`now` is no longer used,0,0.9593626856803894
95411451,2264,ijuma,2017-01-10T17:12:49Z,"we are now doing `apiversions` unconditionally. this means that 0.10.2 brokers won't be able to talk to 0.9.0.x brokers, right? we shouldn't do that.",0,0.9145961403846741
95418264,2264,cmccabe,2017-01-10T17:45:59Z,"hmm. just to clarify, you think that throwing the exception when we see an unexpected version is the right way to go? i can add that to the other requests if so.",0,0.9763873815536499
95418858,2264,cmccabe,2017-01-10T17:48:52Z,the other versions are used in unit tests. the server also can handle them to support older clients.,0,0.9882285594940186
95419171,2264,cmccabe,2017-01-10T17:50:25Z,"i wanted to do this, but it got messy. the problem is that there are a bunch of unit tests that are using reflection to call these methods-- and also some scala code. i think we should have a follow-on jira for converting the parse() methods to use 'short' for version.",0,0.5537502765655518
95419258,2264,cmccabe,2017-01-10T17:50:53Z,k,0,0.9391535520553589
95419528,2264,cmccabe,2017-01-10T17:52:23Z,that's a good point. what do you suggest? one approach is to (re)add a constructor parameter to networkclient that will allow the brokers to bypass sending apiversions.,1,0.7225252389907837
95438375,2264,cmccabe,2017-01-10T19:27:44Z,k,0,0.9391535520553589
95438824,2264,cmccabe,2017-01-10T19:29:50Z,i fixed it to be an exception instead,0,0.9803260564804077
95440180,2264,hachikuji,2017-01-10T19:36:18Z,i doubt it would add much to the size of this patch if you want to do it here. a follow-up would work as well. i'm anxious to have a good general approach in place so that we have clear patterns to follow going forward.,-1,0.7280793190002441
95442388,2264,cmccabe,2017-01-10T19:47:17Z,"from a user point of view, unsupportedbrokerversion is that it doesn't make it clear whether the broker version is too new or old. it also suggests that the whole broker is unsupported, whereas just this one api is unsupported. hmm. it seems like we could still have other implementations of the protocol even if we used outdatedbrokerexception / obsoletebrokerexception? i'm open to ideas on this. i would kind of like something that gives the user a clear hint that they need to upgrade...",0,0.7376887202262878
95443442,2264,cmccabe,2017-01-10T19:52:32Z,"ah, good point. let me add a check for that just to be safe. after all, this data is coming over the wire, so we should not unconditionally trust it.",0,0.5440999865531921
95445212,2264,hachikuji,2017-01-10T20:02:02Z,note there was a previous comment about using `arraylist` instead of `linkedlist`.,0,0.985372006893158
95449880,2264,cmccabe,2017-01-10T20:27:07Z,k,0,0.9391535520553589
95450837,2264,cmccabe,2017-01-10T20:32:37Z,"yeah, it would be good to have a clear pattern here. let's do it in a follow-on.",0,0.7628335356712341
95452015,2264,cmccabe,2017-01-10T20:39:34Z,"hmm. cansendrequest should be making sure that the ssl handshake is complete, right? call stack: [code block] kafkachannel#ready has: [code block]",0,0.9827683568000793
95452301,2264,cmccabe,2017-01-10T20:41:17Z,: i'll parameterize our ducktape tests for client compat with ssl,0,0.9784500002861023
95458316,2264,cmccabe,2017-01-10T21:13:47Z,renamed to utils#mkstring and made this optional with function overloads.,0,0.9877306818962097
95463538,2264,ijuma,2017-01-10T21:40:30Z,this should be `setversion(version)` i think.,0,0.9881987571716309
95465642,2264,hachikuji,2017-01-10T21:50:26Z,sounds reasonable to me.,0,0.963254988193512
95466268,2264,hachikuji,2017-01-10T21:53:37Z,nit: string interpolation,0,0.9878461956977844
95466619,2264,hachikuji,2017-01-10T21:55:35Z,probably more helpful to convert the error code to an instance of `errors` and use `message()`. even better would be to have `apiversionsresponse` use a field of type `errors` instead of a short.,0,0.9773744940757751
95468151,2264,hachikuji,2017-01-10T22:03:47Z,"nit: the `tostring()` is not needed, right?",0,0.9861878752708435
95468429,2264,hachikuji,2017-01-10T22:05:28Z,i was thinking about this a little more. i wonder if we could just change the key type to string to make it consistent with `nodesneedingapiversionsfetch`?,0,0.864471971988678
95469545,2264,hachikuji,2017-01-10T22:11:46Z,could we have this accept an `apikeys` instance instead of short? then we wouldn't need the check for a negative api key. also would be nice to document what exactly this method is returning. is it the largest version supported by both the client and server?,0,0.939747154712677
95471626,2264,hachikuji,2017-01-10T22:23:31Z,"typo: ""reponse""",0,0.9874686002731323
95471877,2264,hachikuji,2017-01-10T22:25:04Z,i think i had a comment before about moving this check into `consumernetworkclient.requestfuturecompletionhandler`.,0,0.9873557686805725
95472157,2264,hachikuji,2017-01-10T22:26:54Z,"to be clear, if the broker doesn't support this then we'll raise `obsoletebrokerexception`? i wonder if that handling is consistent with the behavior when the broker is up to date, but has an old message format version. it seems our handling of the `unsupported_for_message_format` is to add a null entry to the result. maybe we should do the same?",0,0.966203510761261
95472929,2264,hachikuji,2017-01-10T22:31:10Z,would we ever return a negative offset to the user?,0,0.9815077185630798
95473004,2264,hachikuji,2017-01-10T22:31:35Z,nit: move to previous line,0,0.9848797917366028
95473512,2264,hachikuji,2017-01-10T22:34:31Z,another suggestion: `incompatibleprotocolversion`?,0,0.9815389513969421
95475950,2264,hachikuji,2017-01-10T22:49:21Z,seems the only usage is internal to `networkclient`. maybe we could just use the variable directly?,0,0.9881299734115601
95477354,2264,ijuma,2017-01-10T22:57:56Z,"also, is `discoverpeerversions` the right name? seems like it should be `discoverbrokerversions` as `networkclient` is also used by clients.",0,0.9889764189720154
95477481,2264,cmccabe,2017-01-10T22:58:42Z,"ok, i added a constructor parameter and a unit test. thanks for catching this!",1,0.9800323843955994
95477659,2264,ijuma,2017-01-10T22:59:44Z,"are the comments inside the if/else adding anything over what the code does? to me, they seem to say exactly the same thing as the code.",0,0.9671474099159241
95479078,2264,cmccabe,2017-01-10T23:09:16Z,k,0,0.9391535520553589
95479437,2264,cmccabe,2017-01-10T23:11:52Z,"for some reason, there is no math.min(short, short), only math.min(int, int). i could use the int version with a typecast, but i thought the cast was ugly.",-1,0.9624911546707153
95479552,2264,cmccabe,2017-01-10T23:12:44Z,k,0,0.9391535520553589
95480087,2264,cmccabe,2017-01-10T23:16:37Z,k,0,0.9391535520553589
95480896,2264,cmccabe,2017-01-10T23:22:12Z,k,0,0.9391535520553589
95481038,2264,cmccabe,2017-01-10T23:23:07Z,ok. will leave it as toshort here since the typecast is kind of annoying visually (edit: it's an ascription) ;),-1,0.7416163086891174
95481685,2264,cmccabe,2017-01-10T23:28:03Z,"not really, can remove",0,0.96272873878479
95482457,2264,hachikuji,2017-01-10T23:33:37Z,seems this field could be final. might be worth a pass over the other request types to locate other fields that could be final.,0,0.9820826053619385
95482720,2264,hachikuji,2017-01-10T23:35:25Z,this seems unneeded.,0,0.6405730247497559
95483218,2264,hachikuji,2017-01-10T23:39:11Z,"it would be nice to be consistent about whether a field should be included in the constructor or whether it should have a setter. i don't know that we have any cases that call for mutating a field that was initialized in the constructor, so i would prefer to just leave off the setters in that case and make the field final.",0,0.9818114638328552
95483731,2264,cmccabe,2017-01-10T23:43:13Z,"oops, sorry, i meant to reply but i closed the browser window. arraylist seems like overkill here since we don't expect a lot of aborted sends to happen. also, the memory consumed by arraylist only grows and never shrinks (unless you call trimtosize), which seems like a bad choice here.",-1,0.9869621992111206
95483834,2264,cmccabe,2017-01-10T23:43:59Z,k,0,0.9391535520553589
95484012,2264,cmccabe,2017-01-10T23:45:13Z,ok,0,0.9667208194732666
95484274,2264,cmccabe,2017-01-10T23:47:15Z,"yeah, let's use errors to get the error enum. can refactor further later",0,0.9862087965011597
95484396,2264,cmccabe,2017-01-10T23:48:10Z,"true, it should be called implicitly",0,0.9858673214912415
95484656,2264,cmccabe,2017-01-10T23:49:56Z,good ideas. done,1,0.9755899310112
95484862,2264,cmccabe,2017-01-10T23:51:24Z,"i don't understand what you mean by ""the broker is up to date, but has an old message format version"".",0,0.9065030813217163
95484986,2264,cmccabe,2017-01-10T23:52:18Z,"right, i have been looking at that. thinking of doing it in a follow-on jira since i will need to take a deeper look at the rpc paths when doing that",0,0.96006840467453
95485081,2264,cmccabe,2017-01-10T23:53:03Z,k,0,0.9391535520553589
95485096,2264,cmccabe,2017-01-10T23:53:08Z,no,0,0.922592043876648
95485142,2264,cmccabe,2017-01-10T23:53:26Z,k,0,0.9391535520553589
95486629,2264,hachikuji,2017-01-11T00:05:59Z,"i'm thinking of the case where the broker doesn't support v1 of listoffsets. for this case, i think we currently raise `obsoletebrokerexception`. i am questioning whether it would be more consistent to return a null entry in this case in the result of `offsetsfortimes`. currently it is possible for the broker to support the new api version, but not the message format version which is needed to answer the query. in this case, we return a null entry.",0,0.954010009765625
95488513,2264,ijuma,2017-01-11T00:20:08Z,"well, the `arraylist` array would expand to 10 elements the first time an aborted send is added. and then, it will probably never grow beyond that. linkedlist in java is just not a very good collection in general. each node has 3 references and there is a node instance per item. a funny tweet by joshua bloch: "" does anyone actually use linkedlist? i wrote it, and i never use it."" [a link]",-1,0.8296871185302734
95489336,2264,ijuma,2017-01-11T00:26:51Z,i asked colin to add this point to the follow-up jira.,0,0.9844100475311279
95490172,2264,ijuma,2017-01-11T00:33:36Z,we should not have it in the javadoc then as this is a class that is exposed to users.,0,0.9775216579437256
95504733,2264,junrao,2017-01-11T03:03:06Z,"in the patch, it seems that once a channel is connected, but is not necessarily ready, networkclient can start issuing apirequest. this can fail if transport is ssl and transportlayer.ready() is false. it's also too late to only start issuing apirequest after channel is ready since the apirequest should be sent before sasl handshake (sasl handshake completes when authenticator.complete() is true). what the networkclient is supposed to do is only start issuing apirequest after transportlayer.ready() is true. it's just that currently, this state is no propagated by selector.",0,0.9712108969688416
95506134,2264,ijuma,2017-01-11T03:23:02Z,"i'm not sure what you mean when you say that the patch starts issuing apiversions request before transport layer is ready: [code block] isn't that ok (we call `selector.ischannelready(node)`)? the point about sasl. the outcome of the discussion in the pr for kafka-3600 was that we don't have to send the api versions request before the sasl request for now since there's only one version of the saslhandshake request. if we ever introduce an additional version, we can change the client at the same time. it seems like there's no downside to this since brokers will have to keep supporting the old sasl handshake request anyway. do you feel differently?",0,0.8931463956832886
95507893,2264,junrao,2017-01-11T03:50:34Z,": yes, i missed the selector.ischannelready(node) check. so, this is fine. about the sasl, that's reasonable. we can keep the changes in the pr as they are.",0,0.92469322681427
95579492,2264,ijuma,2017-01-11T13:41:57Z,"i submitted a pr that removes unused setters, makes fields final and tries to make things a bit more regular. makes it a bit simpler, but more could be done probably.",0,0.9759876728057861
95579966,2264,ijuma,2017-01-11T13:44:52Z,", this one seems important to resolve before merging.",0,0.9692989587783813
95582701,2264,ijuma,2017-01-11T14:01:03Z,i've done this in my pr.,0,0.9522556066513062
95582725,2264,ijuma,2017-01-11T14:01:11Z,removed in my pr.,0,0.9708687663078308
95582772,2264,ijuma,2017-01-11T14:01:25Z,fixed in my pr.,0,0.9746710658073425
95582876,2264,ijuma,2017-01-11T14:02:06Z,the server doesn't use the builder so i think that would be ok. but let's leave it for now.,0,0.9793988466262817
95582919,2264,ijuma,2017-01-11T14:02:21Z,"yes, but let's consider that in a separate pr.",0,0.9827379584312439
95583125,2264,ijuma,2017-01-11T14:03:35Z,changed in my pr.,0,0.9682944416999817
95583846,2264,ijuma,2017-01-11T14:07:42Z,i did this for a bunch of builders in my pr.,0,0.9442146420478821
95638931,2264,hachikuji,2017-01-11T18:21:36Z,can you address this comment please?,0,0.9848950505256653
95641786,2264,cmccabe,2017-01-11T18:35:12Z,done,0,0.9764507412910461
95641982,2264,cmccabe,2017-01-11T18:36:01Z,sounds good,1,0.9535238742828369
1290585581,14182,jeffkbkim,2023-08-10T19:23:36Z,i would include the priorities when considering uniform vs. sticky vs. rack-aware,0,0.9838973879814148
1290588764,14182,jeffkbkim,2023-08-10T19:27:03Z,"is ""expected"" in the name bring necessary?",0,0.9869624972343445
1290589362,14182,jeffkbkim,2023-08-10T19:27:44Z,"is this ""remaining number of partitions""?",0,0.981229305267334
1290591418,14182,jeffkbkim,2023-08-10T19:30:04Z,i don't think we need this comment,0,0.8236357569694519
1290591834,14182,jeffkbkim,2023-08-10T19:30:34Z,how's `previousowners`?,0,0.9845482707023621
1290610215,14182,jeffkbkim,2023-08-10T19:49:17Z,why is all of this under the constructor?,0,0.9508762955665588
1290610669,14182,jeffkbkim,2023-08-10T19:49:49Z,nit: can we match the argument ordering?,0,0.9876360297203064
1290611774,14182,jeffkbkim,2023-08-10T19:51:09Z,"`buildassignment()` makes more sense. also, this should be an abstract method under `uniformassignor`",0,0.9839538335800171
1290636312,14182,jeffkbkim,2023-08-10T20:17:29Z,i'm noticing a pattern where we are using class variables when they can just be method variables. we should aim to use the smallest scope for all variables.,0,0.9744575619697571
1290763071,14182,rreddy-22,2023-08-10T23:12:48Z,including balance >rack>stickiness,0,0.9250035285949707
1290763624,14182,rreddy-22,2023-08-10T23:13:54Z,"yeah because the extra partitions haven't been assigned yet, i'm just taking a count of how many are expected to get the extra partition",0,0.9729083180427551
1290764909,14182,rreddy-22,2023-08-10T23:16:54Z,"i think this name makes it clear that its a map, if we just used previousowners, its not clear whose previous owner right. we would then have to name it previouspartitionowners, which is kinda the same as partitiontopreviousowner?",0,0.9876218438148499
1290765488,14182,rreddy-22,2023-08-10T23:18:12Z,"any computations required to initialise the global attributes are done in this constructor, similar to the other existing assignors",0,0.9882159233093262
1290766391,14182,rreddy-22,2023-08-10T23:20:13Z,done,0,0.9764507412910461
1290813322,14182,jeffkbkim,2023-08-11T01:14:50Z,"`nummemberswithextrapartition` : number of members to get the extra partition, no? there is no expected vs. actual though, we always distribute that number",0,0.9834161996841431
1290813753,14182,jeffkbkim,2023-08-11T01:16:00Z,"it is implied by the type that the previous owners are keyed by topicidpartition. like how we are using `potentiallyunfilledmembers`, `unfilledmembers`, or `newassignment`",0,0.9873616695404053
1290880471,14182,rreddy-22,2023-08-11T04:25:37Z,"its typically called as assignor.build so i thought that makes it kinda clear that its building the assignment, and the return value also specifies the same",0,0.986289381980896
1290880628,14182,rreddy-22,2023-08-11T04:25:58Z,"changed a few of them, rest we discussed on call",0,0.978689968585968
1291715874,14182,jeffkbkim,2023-08-11T19:39:09Z,nit: `alltopicidpartitions` and newline each argument,0,0.9881828427314758
1291716306,14182,jeffkbkim,2023-08-11T19:39:46Z,nit: allsubscriptionsequal,0,0.9854645133018494
1291718703,14182,jeffkbkim,2023-08-11T19:43:22Z,"nit: ``` public groupassignment assign( assignmentspec assignmentspec, subscribedtopicdescriber subscribedtopicdescriber ) throws partitionassignorexception {",0,0.987149715423584
1291718960,14182,jeffkbkim,2023-08-11T19:43:43Z,nit: new line each argument,0,0.987506628036499
1291724906,14182,jeffkbkim,2023-08-11T19:52:45Z,this and `parttiionracks` can be initialized as empty collections. then we just handle the case where `!membersbyrack.isempty()`,0,0.9819799661636353
1291729367,14182,jeffkbkim,2023-08-11T19:59:06Z,can you explain why we need to create `membersbyrack` then transform it to `memberracks`? can't we just create `memberracks` from the start?,0,0.9874773025512695
1291731843,14182,rreddy-22,2023-08-11T20:02:51Z,yeah my point was that nummemberswithextrapartition sounds like the members already have the extra partition but its actually a number of how many members we expect to have an extra and this number keeps decreasing as we assign the partitions.,0,0.9433697462081909
1291732541,14182,rreddy-22,2023-08-11T20:03:44Z,okay i'll rename it,0,0.9690307974815369
1293887191,14182,jeffkbkim,2023-08-14T19:32:12Z,we can move this to l93 and remove the else block,0,0.9875363707542419
1293887893,14182,jeffkbkim,2023-08-14T19:33:01Z,"can we use `this.classvariable = ...` for all the class scoped variables in the constructor? also, don't we get a nosuchelementexception if the iterator is empty? (do we test this case) lastly, we can just use the first member's subscribed topic ids because we know all members are subscribed to the same topics right?",0,0.9854151010513306
1293888288,14182,jeffkbkim,2023-08-14T19:33:30Z,do we need this variable?,0,0.9877184629440308
1293889620,14182,jeffkbkim,2023-08-14T19:35:13Z,i think a debug log should suffice. logs will get flooded if a topic metadata changes,0,0.9871237277984619
1293893418,14182,jeffkbkim,2023-08-14T19:38:31Z,should we move this to the top of the method?,0,0.9828998446464539
1293898405,14182,jeffkbkim,2023-08-14T19:42:34Z,can we use `minquota = totalpartitionscount / numberofmembers;` and do we need to declare and initialize separately?,0,0.9878509640693665
1293910818,14182,jeffkbkim,2023-08-14T19:57:07Z,do we need this? we can iterate through a set,0,0.9871677756309509
1293913755,14182,jeffkbkim,2023-08-14T20:00:36Z,we can remove the parentheses,0,0.9871456623077393
1294009242,14182,jeffkbkim,2023-08-14T22:00:23Z,"this will iterate through the entire list. let's instead use a set to store subscriptions. also, if the subscription list does not contain the topic id, should we throw an illegal state exception? every topic id from the assigned partitions should exist in the subscription list right",0,0.9874479174613953
1294021888,14182,jeffkbkim,2023-08-14T22:19:36Z,"how's `retainedcurrentassignment`? in kafka, we don't use `get` in method names.",0,0.9838541150093079
1294034638,14182,jeffkbkim,2023-08-14T22:42:29Z,`k` --> `__`,0,0.977555513381958
1294037874,14182,jeffkbkim,2023-08-14T22:47:31Z,ditto,0,0.8428916931152344
1294047232,14182,jeffkbkim,2023-08-14T23:07:04Z,can we `continue` here instead of using `assigned` variable?,0,0.9877540469169617
1294051623,14182,jeffkbkim,2023-08-14T23:16:44Z,let's use streams api when possible [code block],0,0.9895842671394348
1294052212,14182,jeffkbkim,2023-08-14T23:18:06Z,"let's use streams api (foreach, intstream.foreach)",0,0.9887623190879822
1294054650,14182,jeffkbkim,2023-08-14T23:23:29Z,"this is implying we will be assigning an extra partition for this member right? how come we don't ""assign"" it here?",0,0.9134477376937866
1294062365,14182,jeffkbkim,2023-08-14T23:40:50Z,why can't we just create a new arraylist and add the ones where count > 0?,0,0.9716323018074036
1294064001,14182,jeffkbkim,2023-08-14T23:44:19Z,you can use getordefault,0,0.9858694076538086
1294068788,14182,jeffkbkim,2023-08-14T23:55:16Z,assignpartitiontomemberandupdateunfilledmembers it's hard to assume the side effects when looking at the existing name,0,0.9774065017700195
1294068919,14182,jeffkbkim,2023-08-14T23:55:35Z,i think we can use map#compute here right,0,0.9718732237815857
1294069200,14182,jeffkbkim,2023-08-14T23:56:10Z,we can break out of the for loop instead of using assigned here,0,0.9888929724693298
1294076876,14182,jeffkbkim,2023-08-15T00:14:57Z,why do we need to remove here,0,0.9680383801460266
1294086512,14182,jeffkbkim,2023-08-15T00:38:49Z,"what i don't like about this approach is that the reader needs to know 2 things: 1. unfilledmembers (member -> remaining partition count) only exists when the count is > 0. 2. assignpartitiontomember removes a member from unfilledmembers if the count is 0 after decrementing or else we don't know whether this for loop will end. also i have not seen a for loop where we add something to the original collection we are iterating through. i think `while (!queue.isempty())` should be more readable. also, if there is a bug somewhere and for some reason the sum of all unfilledmembers` partition counts is greater than sortedpartitions size then we could have an infinite loop since there will be a member that still needs partitions to be assigned. we should add this check somewhere",0,0.622032642364502
1294086912,14182,jeffkbkim,2023-08-15T00:39:55Z,do we need this?,0,0.983482837677002
1294086965,14182,jeffkbkim,2023-08-15T00:40:02Z,do we need this?,0,0.983482837677002
1294087718,14182,jeffkbkim,2023-08-15T00:42:11Z,ditto on using continue,0,0.9785218834877014
1294087923,14182,jeffkbkim,2023-08-15T00:42:45Z,how come we iterate on unfilledmembers instead of roundrobinmembers as in `rackawarerounrobinassignment`? this looks like a bug; can we add a test that breaks this,0,0.7296434044837952
1294088129,14182,jeffkbkim,2023-08-15T00:43:19Z,ditto on using a while loop,0,0.9539481401443481
1295197016,14182,rreddy-22,2023-08-15T22:21:32Z,changed to something else,0,0.9750863909721375
1295198962,14182,rreddy-22,2023-08-15T22:22:32Z,this shouldn't even happen at all so that's why its a warning. this case is handled by the target assignment builder,0,0.984329342842102
1296343128,14182,jeffkbkim,2023-08-16T19:31:45Z,"if a topic is deleted, how does the target assignment builder handle it?",0,0.9837008118629456
1300462035,14182,rreddy-22,2023-08-21T17:52:49Z,"collections.emptymap is immutable though right, ig a better option would be to initliaze them as new hashmaps",0,0.9855716228485107
1300620312,14182,rreddy-22,2023-08-21T20:36:34Z,"we check if rack aware assignment is possible i.e if partition racks and member racks exist and whether there's any intersection between the two sets, only then we assign the memberracks which is final.",0,0.9879164695739746
1300622597,14182,rreddy-22,2023-08-21T20:39:02Z,the code actually does just use the first members subscribed topic ids,0,0.9890111684799194
1300627015,14182,rreddy-22,2023-08-21T20:44:16Z,"that depends if the members map can be empty i guess which i think is checked before, it definitely can't be null",0,0.9831660985946655
1300631692,14182,rreddy-22,2023-08-21T20:50:14Z,"if a topic is deleted then it's basically the case where the topic doesn't exist in the topic metadata, it is just simply left off the subscription list before its sent to the assignor.",0,0.9849708676338196
1300633100,14182,rreddy-22,2023-08-21T20:52:07Z,we can't cause we might remove topics from the list just in case there's members subscribed to topics that don't exist in the topic metadata,0,0.9821640253067017
1300633833,14182,rreddy-22,2023-08-21T20:53:05Z,i wanted to keep them in just to segregate the replicaracks parts,0,0.9748324751853943
1300637770,14182,rreddy-22,2023-08-21T20:58:04Z,"not necessarily, since there could be partitions belonging to old subscriptions or topics that don't exist anymore and we don't need them anymore aka they're not valid anymore which is fine. mentioned in the javadoc",0,0.9837706089019775
1300779466,14182,rreddy-22,2023-08-22T00:25:27Z,"its not retained cause we didn't decide if we wanna keep it yet, that's decided in assignstickypartitions. this is just getting the valid assignment in terms of if the partitions are still part of the subscription topics and also if the racks don't match then we just store the prev owner info for the future",0,0.9836987257003784
1300780584,14182,rreddy-22,2023-08-22T00:27:40Z,i don't understand what's the change?,-1,0.5343576669692993
1303273451,14182,rreddy-22,2023-08-23T16:29:35Z,"so there's potentially unfilled members which includes members that have remaining number of partitions to receive as >=0, i.e there could be members that have met the quota but are eligible to receive an extra partition. what i'm doing in this step is increasing the remaining count if there's still a possibility that a member could receive an extra partition. if the remaining count is still > 0 after that we add it to the unfilled members list.",0,0.9792549014091492
1303299811,14182,rreddy-22,2023-08-23T16:54:38Z,"isn't it kinda expected that if i assign a partition to a member from the unfilled map and the remaining value is updated aka reduced by 1, and it's removed from the map if it isn't unfilled anymore.",0,0.969414234161377
1303309866,14182,rreddy-22,2023-08-23T17:04:30Z,"i still have to update the rr members after assigning the partition, i can't break within this if statement right.",0,0.9814953207969666
1305945556,14182,rreddy-22,2023-08-25T17:26:18Z,discussed offline that this isn't possible,0,0.9263821244239807
1305948679,14182,rreddy-22,2023-08-25T17:29:41Z,we can't use continue cause there's multiple other steps after that which need to be executed before we exit the loop,0,0.9838610887527466
1305956396,14182,rreddy-22,2023-08-25T17:37:07Z,"we are iterating over the roundrobin members, we're just using the size of all the unfilled members so that we do at least n number of iterations",0,0.9797877073287964
1305957286,14182,rreddy-22,2023-08-25T17:37:44Z,discussed offline that this isn't possible,0,0.9263821244239807
1305998324,14182,rreddy-22,2023-08-25T18:13:40Z,while loop instead of for loop?,0,0.9819869995117188
1308056437,14182,jeffkbkim,2023-08-28T23:42:28Z,can we keep rangeassignor changes in a separate pr?,0,0.9894277453422546
1308059442,14182,jeffkbkim,2023-08-28T23:49:03Z,what if the collections are out of order? can we add a test case for this,0,0.9875333309173584
1308060754,14182,jeffkbkim,2023-08-28T23:51:42Z,javadocs,0,0.9841963648796082
1308061244,14182,jeffkbkim,2023-08-28T23:52:48Z,"let's add javadocs for all of the methods below. also, can there be a case where any of the parameters are null? collections#disjoint can throw npe",0,0.9873679280281067
1308061768,14182,jeffkbkim,2023-08-28T23:54:00Z,nit: totopicidpartitions,0,0.984276533126831
1308061977,14182,jeffkbkim,2023-08-28T23:54:26Z,nit: topicidpartitions,0,0.9841459393501282
1308062300,14182,jeffkbkim,2023-08-28T23:55:04Z,change k to __,0,0.9792079329490662
1308062948,14182,jeffkbkim,2023-08-28T23:56:30Z,topics,0,0.9269449710845947
1308068063,14182,jeffkbkim,2023-08-29T00:08:19Z,how's [code block] this aligns with the parameters in userackawareassignment,0,0.9887356162071228
1308072483,14182,jeffkbkim,2023-08-29T00:18:02Z,"i think we can do the following here: when initializing membersbyrack in l152, also initialize memberracks. then only set memberracks to collections.emptymap if userackawareassignment is false. then we don't have to do this transformation",0,0.9871343970298767
1308073563,14182,jeffkbkim,2023-08-29T00:20:43Z,nit: memberrack,0,0.9835853576660156
1308074883,14182,jeffkbkim,2023-08-29T00:23:59Z,"can you help me understand which part is rack-aware manner? also, can we add a test case for this?",0,0.9848275184631348
1308075407,14182,jeffkbkim,2023-08-29T00:25:09Z,this looks to be an exact copy of clients/common. can we move that instead?,0,0.9896562099456787
1308077282,14182,jeffkbkim,2023-08-29T00:29:12Z,do we need this change in this pr?,0,0.9853750467300415
1308077407,14182,jeffkbkim,2023-08-29T00:29:30Z,what's this change for?,0,0.9742342829704285
1308077660,14182,jeffkbkim,2023-08-29T00:30:06Z,"nit: we can remove kafka also, can we move this to buildassignment() and direct the reader to the method to see the step by step?",0,0.9878894686698914
1308079903,14182,jeffkbkim,2023-08-29T00:35:27Z,"nit: track it ""as the partition's"" prior owner",0,0.9890418648719788
1308081089,14182,jeffkbkim,2023-08-29T00:38:29Z,i'm wondering whether to have a userackawarestrategy field in rackinfo instead so that we don't have to infer this information here.,0,0.9601680636405945
1308081761,14182,jeffkbkim,2023-08-29T00:39:56Z,"actually, i think we should throw an illegal state exception. since this is not expected to happen",0,0.9037262797355652
1308082801,14182,jeffkbkim,2023-08-29T00:42:39Z,why can't we do `final int minquota = totalpartitionscount / numberofmembers;`?,0,0.9814465045928955
1308083274,14182,jeffkbkim,2023-08-29T00:43:51Z,`assignmentspec.members().keyset().foreach(memberid -> ...`,0,0.9862223267555237
1308085281,14182,jeffkbkim,2023-08-29T00:48:43Z,nit: assignedstickypartitions,0,0.988376796245575
1308086816,14182,jeffkbkim,2023-08-29T00:52:39Z,should we add a debug log indicating that the topic no longer exists in the metadata?,0,0.9856955409049988
1308086969,14182,jeffkbkim,2023-08-29T00:53:04Z,we can move the parentheses around (partition),0,0.9884340167045593
1308087850,14182,jeffkbkim,2023-08-29T00:55:05Z,we don't need this since retainedpartitionscount will be 0 in l178,0,0.9874080419540405
1308088960,14182,jeffkbkim,2023-08-29T00:57:28Z,"""previous"" step might not even need this comment. perhaps ""assign the extra partition if possible"" or something along those lines",0,0.9865679740905762
1308089767,14182,jeffkbkim,2023-08-29T00:59:28Z,nit: assignedstickypartitions,0,0.988376796245575
1308090172,14182,jeffkbkim,2023-08-29T01:00:20Z,"personally, the word ""all"" does not add much value to variable names. how's `sortedtopics` also, what's the benefit of sorting the topics?",0,0.977229118347168
1308091012,14182,jeffkbkim,2023-08-29T01:02:22Z,nit: can remove parentheses around (topic),0,0.987220048904419
1308091211,14182,jeffkbkim,2023-08-29T01:02:52Z,we can inline partitioncount in l377,0,0.9881657361984253
1308093254,14182,jeffkbkim,2023-08-29T01:08:18Z,how's unassignedpartitionssizeequalsremainingassignments,0,0.9730467796325684
1308095670,14182,jeffkbkim,2023-08-29T01:13:56Z,"nit: ""sort"" and ""potential members""",0,0.9838058948516846
1308097288,14182,jeffkbkim,2023-08-29T01:17:54Z,is this a linked list?,0,0.9843035340309143
1308098707,14182,jeffkbkim,2023-08-29T01:19:55Z,`while(!roundrobinmembers.isempty() && !assigned)` is more readable since most for loops do not change the size,0,0.979174792766571
1308102973,14182,jeffkbkim,2023-08-29T01:28:55Z,ah right. that makes sense,0,0.923530638217926
1308137334,14182,rreddy-22,2023-08-29T02:48:14Z,"lets decide what to do here cause i've also asked david multiple times, i think he said a warning is enough let me double check",0,0.9719997644424438
1308140708,14182,rreddy-22,2023-08-29T02:55:31Z,i feel like a whole pr for minor changes which are kinda related to what i learn from doing the other assignors would be unnecessary especially cause even minor ones take time to go through the review process and stuff. they might just go undone,-1,0.8231147527694702
1308143447,14182,rreddy-22,2023-08-29T03:01:34Z,"that's kinda why i used list/set before but i changed it to collections on receiving comments on the interface. but that's a good point, i'll make sure the order doesn't matter",0,0.6896363496780396
1308150557,14182,rreddy-22,2023-08-29T03:18:54Z,"no they can't be null, they are all initialized in rackinfo",0,0.9882321953773499
1308150974,14182,rreddy-22,2023-08-29T03:19:52Z,"i named the method alltopicidpartitions to emphasize that its not a subset, so i feel like we can leave this as alltopicidpartitions as well",0,0.9631866216659546
1308151486,14182,rreddy-22,2023-08-29T03:21:17Z,renamed to alltopicids,0,0.9829692244529724
1308152462,14182,rreddy-22,2023-08-29T03:23:48Z,agreed but memberracks and partitionracks are more readable and concise i guess in my opinion so i would leave it like this,0,0.9580166339874268
1308155008,14182,rreddy-22,2023-08-29T03:30:00Z,its a final attribute that why can't assign it twice and i feel like what's the point of initializing it before hand if i'm doing it in an if else block later which guarantees initialization,0,0.9314943552017212
1308164291,14182,rreddy-22,2023-08-29T03:52:16Z,i don't think i understand the question,-1,0.58385169506073
1308165291,14182,rreddy-22,2023-08-29T03:54:34Z,"it's not haha i would've used that otherwise, this has partition as an integer whereas that has topicpartition (another class) as the attribute in addition to topic id",0,0.9420424103736877
1308165924,14182,rreddy-22,2023-08-29T03:55:52Z,yes because we decided how we want to handle the non existent topic case in this pr and hence this is just a side effect of that,0,0.9622258543968201
1308166084,14182,rreddy-22,2023-08-29T03:56:13Z,"this just keeps happening idky, ignore this file we have to force push it in the end",0,0.5696468949317932
1308167128,14182,rreddy-22,2023-08-29T03:58:46Z,"i feel like the code pattern has always been to explain what the assignor does at the top instead of at assign/build, and since this is basically the main function of the assignor, it shouldn't make a difference if its at the top explaining what the optimized uniform assignment builder does",0,0.5482022166252136
1308167658,14182,rreddy-22,2023-08-29T03:59:51Z,"since we mentioned partition's up front in the sentence it makes sense that from then onwards ""it"" always refers to the partition",0,0.9816662669181824
1308169146,14182,rreddy-22,2023-08-29T04:03:11Z,makes sense,0,0.9699445366859436
1308171085,14182,rreddy-22,2023-08-29T04:07:48Z,all is mentioned to emphasize that it's all of the members assigned sticky partitions,0,0.9852445721626282
1308172074,14182,rreddy-22,2023-08-29T04:10:08Z,it actually means that the topic is no longer subscribed to by the group but yes that also translates into not being in the topic metadata sometimes,0,0.9843146204948425
1308173102,14182,rreddy-22,2023-08-29T04:12:34Z,why will it be zero?,0,0.914858877658844
1308173397,14182,rreddy-22,2023-08-29T04:13:20Z,"i feel like its very hard to understand without this comment, just for the sake of anyone trying to understand why i used that index for the extra partition i would leave it in",-1,0.9750732779502869
1308174183,14182,rreddy-22,2023-08-29T04:15:04Z,replied before,0,0.981856644153595
1308174694,14182,rreddy-22,2023-08-29T04:16:12Z,"all means every single topic right, if it was just sorted topics, which/whose topics?",0,0.9815443754196167
1308177084,14182,rreddy-22,2023-08-29T04:21:48Z,it makes sure that all the unassigned partitions are present topic wise and then when we do a rr distribution while assigning these partitions they are distributed more evenly by topic as well,0,0.9819890260696411
1308179490,14182,rreddy-22,2023-08-29T04:26:47Z,total again emphasizes that i'm talking about all the unassigned partitions and all the remaining assignments right? and also since it returns a boolean value doesn't is make sense still,0,0.9708998799324036
1308181709,14182,rreddy-22,2023-08-29T04:31:34Z,"i don't want the loop to run until the roundrobinmembers list is empty though, this could cause an infinite loop. i just want it to go through every member at the very least and then if it doesn't find a member that is suitable then we just move on and the partition might get assigned later",0,0.9478970170021057
1309478048,14182,jeffkbkim,2023-08-30T00:36:34Z,you can't change what's stored in an empty map but you can change which map the variable points to. though it seems fine in this case since we are using streams api and need a final variable,0,0.9802754521369934
1309478864,14182,jeffkbkim,2023-08-30T00:38:35Z,space after `this.`,0,0.9836351871490479
1309479632,14182,jeffkbkim,2023-08-30T00:40:16Z,this can get npe if the members is empty right?,0,0.9867250919342041
1309481820,14182,jeffkbkim,2023-08-30T00:45:47Z,that seems like a big assumption; let's at least add something to the javadocs,0,0.9536561965942383
1309482536,14182,jeffkbkim,2023-08-30T00:47:07Z,can you remind me again why we need to do at least n number of iterations?,0,0.9861413240432739
1309482922,14182,jeffkbkim,2023-08-30T00:48:08Z,ok,0,0.9667208194732666
1309487439,14182,jeffkbkim,2023-08-30T00:57:49Z,"on i don't see which part is ""in a rack-aware manner"" in the code. can we test that the sorting happens as expected",0,0.9870736598968506
1309488516,14182,jeffkbkim,2023-08-30T01:00:25Z,"ah i see. i'm still leaning towards reusing that one, but will leave it up for david to decide",0,0.7092486619949341
1309488929,14182,jeffkbkim,2023-08-30T01:01:19Z,we should probably fix this..,0,0.9597726464271545
1309489359,14182,jeffkbkim,2023-08-30T01:02:29Z,we have the step by step details at `assign()` for the range assignor right,0,0.9879769682884216
1309492110,14182,jeffkbkim,2023-08-30T01:06:29Z,"i meant if currentassignmentsize is 0, then retainedpartitionscount will be 0 and hence we won't iterate anyways",0,0.9841205477714539
1309493644,14182,jeffkbkim,2023-08-30T01:08:40Z,"not sure why i left this comment, can disregard",-1,0.6796929836273193
1309498804,14182,jeffkbkim,2023-08-30T01:16:13Z,"that would make sense if we are using collections that form a subset of all topics somewhere in the code. otherwise it seems redundant i'm not sure i follow. even if the topics weren't sorted, we would still ensure unassigned partitions are present, no? what makes them distribute more evenly?",0,0.9582106471061707
1309500746,14182,jeffkbkim,2023-08-30T01:19:20Z,"""is __ equals __"" is not grammatically correct. if we want to, we can do `is __ equal to __` but i felt that was too long. do we ever have a case where we handle a subset of unassigned partitions? even the variable is called unassignedpartitions",0,0.8139851689338684
1309503692,14182,jeffkbkim,2023-08-30T01:23:50Z,the while loop will still iterate through all members at the very least right? since we poll one every iteration can you help me understand why the while loop can be infinite whereas the for loop cannot?,0,0.9785858392715454
1309504407,14182,jeffkbkim,2023-08-30T01:24:47Z,can we add a test case?,0,0.9880340695381165
1309505394,14182,jeffkbkim,2023-08-30T01:26:18Z,seems like you've changed this to a set. is the comment above still valid?,0,0.9846382737159729
1310726962,14182,jeffkbkim,2023-08-30T19:28:56Z,`if (unfilledmembers.containskey(memberid)`,0,0.9875462651252747
1310733452,14182,jeffkbkim,2023-08-30T19:35:51Z,"there are 2 cases i'm concerned about: 1. i == unfilledmembers.size() but roundrobinmembers is not empty. this means we still have members to distribute 2. roundrobinmembers.size() < unfilledmembers.size(): we'll get npe. these 2 cases may not happen in practice, but the code makes it seem they might. this makes it hard to read and reason about.",0,0.5745862722396851
1310797271,14182,jeffkbkim,2023-08-30T20:41:10Z,nit: (member -> ...,-1,0.9384385347366333
1310803310,14182,jeffkbkim,2023-08-30T20:47:16Z,"this looks like overkill and i don't think this works. for instance, if `totalassignmentsizesofallmembers.get(i)` keeps increasing by 1, we can have first member start off with 1 then the last member end with 100 if monotonically increasing. can we do a single iteration and track the maximum and minimum size? then we can do `asserttrue((max - min) <= 1)` right for ""partition assigned at most one member"", we can have a map and increment it. then after looping we just check whether the number of topic id partitions equals number of members and that each value is 1 i also wonder if we can add this check to uniformassignor, and run this at the end of `buildassignment()`. then the general assignor can also use this to see if it needs to do another iteration. we will need to add test cases for this",0,0.9214311838150024
1310837682,14182,jeffkbkim,2023-08-30T21:19:41Z,"to confirm my understanding: 1. we assign t1p1 and t2p1 to memberb since they have rack info 2. roundrobin the rest (unassignedpartitions, starting with t1p0) is this correct?",0,0.9863009452819824
1310840406,14182,jeffkbkim,2023-08-30T21:22:35Z,"should we also check rack awareness? (if both partition and member rack exists, check they match)",0,0.9888536930084229
1310843247,14182,jeffkbkim,2023-08-30T21:25:49Z,we should assert computed assignment here,0,0.9883368611335754
1310843639,14182,rreddy-22,2023-08-30T21:26:13Z,"cause we want to iterate through/visit every member at least once, n is the number of members.",0,0.985789954662323
1310845118,14182,jeffkbkim,2023-08-30T21:27:42Z,"i think ""n members m topics"" is understandable and simple. i've noticed other tests follow ""n members subscribed to m topics"". can we unify the format?",0,0.9403157830238342
1310846978,14182,rreddy-22,2023-08-30T21:29:45Z,"its just different formatting and every time i push any changes this file gets modified, i'll change it directly in the end",0,0.9627360701560974
1310868257,14182,jeffkbkim,2023-08-30T21:51:30Z,"is membera assigned t1p0 and t2p0 because there is a replica for t1p0 and t2p0 that have ""rack1""? (from mkmapofpartitionracks) i'm just wondering what the assignment would be if we actually did a successful first assignment where a was in rack1 and b was in rack2.",0,0.982550323009491
1310869571,14182,jeffkbkim,2023-08-30T21:53:06Z,"t1p0 and t2p0 technically have racks in ""rack1"" right? so they should be both assigned to member b but already met its quota?",0,0.986782431602478
1310880384,14182,jeffkbkim,2023-08-30T22:04:57Z,"no, we could have removed members from unfilledmembers in the if block above. and if we do so, we would also remove them from roundrobinmembers. since they start with the same members, they will end up with the same members",0,0.9852194786071777
1310892402,14182,rreddy-22,2023-08-30T22:20:42Z,"yeah that's true sorry idr when i changed it, i'll move it",-1,0.9887213110923767
1310897847,14182,rreddy-22,2023-08-30T22:28:40Z,but this is for when currentassignmentsize is non zero,0,0.983357310295105
1310903635,14182,rreddy-22,2023-08-30T22:36:50Z,"distribute evenly topic wise as well, as in if i distributed partitions in random order its possible that all the partitions from a single topic go to one member only, if i rr a list that goes topic wise i'm distributing each topics partitions evenly",0,0.9807943105697632
1310906983,14182,rreddy-22,2023-08-30T22:41:32Z,"got it, changed it",0,0.967470109462738
1310919719,14182,rreddy-22,2023-08-30T22:55:28Z,"because we keep adding members back to the round robin queue until the remaining partitions to be received by the member hits 0. therefore, the roundrobinmembers queue will never be empty unless all the partitions are assigned/ all the quotas are met.",0,0.9860367178916931
1310920650,14182,rreddy-22,2023-08-30T22:56:41Z,here we might assign all the partitions that have matching racks but there's gonna be other partitions that haven't been assigned yet and therefore the remaining number of partitions to be received by members may not have reached zero yet.,0,0.9853501319885254
1310923371,14182,rreddy-22,2023-08-30T23:00:26Z,can members be empty?,0,0.9842475652694702
1310930694,14182,rreddy-22,2023-08-30T23:11:59Z,the efficiency is the same right? this shows that remaining is greater than zero. i also feel like its safer just incase we have any members with negative or 0 value as remaining,0,0.8639054298400879
1310941152,14182,rreddy-22,2023-08-30T23:28:53Z,its 300 partitions and 50 members xd,0,0.9822754859924316
1310948792,14182,rreddy-22,2023-08-30T23:40:20Z,cools i'll double check,1,0.863230288028717
1310952891,14182,rreddy-22,2023-08-30T23:49:29Z,"yes that's correct, a is rack1 and p0 belongs to rack1",0,0.985715925693512
1310961579,14182,rreddy-22,2023-08-31T00:03:21Z,"i think i might have to redo this example, thanks for the catch!",1,0.9648646712303162
1312351774,14182,jeffkbkim,2023-08-31T22:33:16Z,"if there's no pattern, can we change the name to testvalidityandbalanceforlargesampleset?",0,0.9888370037078857
1312392393,14182,rreddy-22,2023-08-31T23:49:36Z,"the test is correct if we let go of the fact that the current assignment wasn't done by this assignor, but with whatever information the assignor got, the behavior was as expected",0,0.9834365844726562
1312392493,14182,rreddy-22,2023-08-31T23:49:50Z,changed the current assignment to what this assignor would've returned,0,0.9817440509796143
1312392605,14182,rreddy-22,2023-08-31T23:50:05Z,explained offline,0,0.9814528226852417
1312609650,14182,rreddy-22,2023-09-01T06:07:33Z,"well since we check the exact assignment for each member, when i was writing the exact partitions i made sure that the racks are matching so i feel like that is checked there already. to write a check again we would have to do quite some steps since its not guaranteed that every partition assigned to a member has a matching rack even if both partition and member racks exist",0,0.920209527015686
1312610747,14182,rreddy-22,2023-09-01T06:09:10Z,yes,0,0.9564858078956604
1312612036,14182,rreddy-22,2023-09-01T06:11:09Z,1) this part specifically was taken from the client assignor so we know it works. 2) this can't work for the general assignor cause the definition of balance will not remain the same. in general assignor the min and max could have a larger difference and it would still be the most balanced possible,0,0.9762641191482544
1312613499,14182,rreddy-22,2023-09-01T06:13:28Z,the total assignment size can't keep increasing by 1 ever xd total partitions divided by total members is how many they'll each have and at most some of them will get 1 extra partition,0,0.9822694659233093
1312619017,14182,rreddy-22,2023-09-01T06:22:01Z,"nummembersbypartition is a map that's part of the rack info which tracks how many members are in the same rack as the partition. the sum of those members is used to sort them right, that's the ""rack aware manner"". sorting happens as expected since i put in print statements to verify them but also without that the assignments wouldn't be as expected and we do a 1:1 check on every assignment in the test cases",0,0.9800652861595154
1312623868,14182,rreddy-22,2023-09-01T06:29:08Z,"1) it doesn't matter if round robin members is not empty, we're doing this by partition so it's very possible that after iterating through the list many members are yet to receive partitions. the only time round robin members will be empty/there's no more members that need partitions is for the last partition.",0,0.9739828109741211
1312624721,14182,rreddy-22,2023-09-01T06:30:23Z,"unless round robin members is empty how will we get a npe, we would keep polling and adding it back right even if its just one member",0,0.9824924468994141
1312625110,14182,rreddy-22,2023-09-01T06:30:53Z,anyways i changed it to round robin members size just like the rack aware round robin,0,0.9797981977462769
1312625675,14182,rreddy-22,2023-09-01T06:31:40Z,it is in the javadoc,0,0.986179530620575
1312625983,14182,rreddy-22,2023-09-01T06:32:03Z,"* if the member has met their allocation quota, the member is removed from the * tracking map of members with their remaining allocations. * otherwise, the count of remaining partitions that can be assigned to the member is updated.",0,0.985241711139679
1313213976,14182,jeffkbkim,2023-09-01T15:59:03Z,can we just use subscriptionset instead of subscriptionlist? it doesn't seem like we need a list to do any of the other operations.,0,0.9828769564628601
1313281824,14182,jeffkbkim,2023-09-01T16:50:11Z,"the `&& !assigned` part would prevent the infinite loop, no?",0,0.984774649143219
1313283639,14182,jeffkbkim,2023-09-01T16:52:33Z,"no, unless we have a bug. can we add a check in assign() and throw illegal argument exception if members is empty?",0,0.9755081534385681
1313292815,14182,jeffkbkim,2023-09-01T17:01:15Z,that makes sense,0,0.975830614566803
1313294383,14182,jeffkbkim,2023-09-01T17:02:37Z,"thanks, that makes sense",1,0.7075212001800537
1313393423,14182,jeffkbkim,2023-09-01T18:41:47Z,discussed offline. makes sense,0,0.9615837931632996
1313408646,14182,jeffkbkim,2023-09-01T19:02:23Z,this can be resolved,0,0.9842996597290039
1313434102,14182,jeffkbkim,2023-09-01T19:33:18Z,"that makes sense -- i forgot we're checking each member. still, i think it's possible to check the balancedness without a nested for loop. not sure if that affects the validity part",0,0.9389504790306091
1313436894,14182,jeffkbkim,2023-09-01T19:36:10Z,nit: `foreach(partition -> {`,0,0.9857928156852722
1313437179,14182,jeffkbkim,2023-09-01T19:36:28Z,nit: foreach(partition ->,0,0.9877294898033142
1313439928,14182,jeffkbkim,2023-09-01T19:39:17Z,nit: javadocs,0,0.9833605289459229
1313441197,14182,jeffkbkim,2023-09-01T19:40:29Z,can we put the arguments into new lines?,0,0.9867657423019409
1313442250,14182,jeffkbkim,2023-09-01T19:41:29Z,nit: [code block],0,0.9873168468475342
1313442609,14182,jeffkbkim,2023-09-01T19:41:50Z,nit: [code block],0,0.9873168468475342
1313443677,14182,jeffkbkim,2023-09-01T19:43:00Z,indentation looks off. [code block],0,0.9864495396614075
1313444165,14182,jeffkbkim,2023-09-01T19:43:30Z,nit: [code block],0,0.9873168468475342
1313444928,14182,jeffkbkim,2023-09-01T19:44:18Z,indentation looks off. [code block],0,0.9864495396614075
1313445794,14182,jeffkbkim,2023-09-01T19:45:13Z,let's split this [code block],0,0.9870951771736145
1313448367,14182,jeffkbkim,2023-09-01T19:47:52Z,"makes sense, let's leave it as is",0,0.9750921130180359
1315178473,14182,rreddy-22,2023-09-04T19:46:52Z,"as discussed on call, i added a check in the assign method instead",0,0.9883833527565002
1315178560,14182,rreddy-22,2023-09-04T19:47:07Z,done,0,0.9764507412910461
1315178781,14182,rreddy-22,2023-09-04T19:47:52Z,added check but i don't think we need to throw an illegal state exception,0,0.986372172832489
1315178928,14182,rreddy-22,2023-09-04T19:48:32Z,we could but since we're checking for validity anyways we can leave it,0,0.9855624437332153
1315500509,14182,dajac,2023-09-05T07:41:53Z,nit: `log` -> `log` as this is a constant.,0,0.9875970482826233
1315500739,14182,dajac,2023-09-05T07:42:04Z,nit: we can remove this empty line.,0,0.9862961769104004
1315501863,14182,dajac,2023-09-05T07:42:59Z,nit: `log` -> `log`.,0,0.9881788492202759
1315502677,14182,dajac,2023-09-05T07:43:41Z,could we please add javadoc to all the attributes? we have been doing this for all the new code in this module so we should continue.,0,0.9863651990890503
1315507070,14182,dajac,2023-09-05T07:47:13Z,nit: do we need to define `userackawarestrategy` as an attribute if we can get it from `rackinfo.userackstrategy`? we could perhaps have a method instead.,0,0.9891757369041443
1315508408,14182,dajac,2023-09-05T07:48:17Z,nit: there is an space between the `*`.,0,0.9844180345535278
1315509745,14182,dajac,2023-09-05T07:49:20Z,i suppose that we assume that we cannot get here if members is empty. is this correct?,0,0.978935718536377
1315511582,14182,dajac,2023-09-05T07:50:52Z,i think that we should directly throw the illegalstateexception. it is a bit weird to construct it to wrap it in another one right away.,-1,0.9826664924621582
1315512642,14182,dajac,2023-09-05T07:51:49Z,this comment is incorrect as the implementation fails if the topic does not exist.,0,0.6444056034088135
1315513303,14182,dajac,2023-09-05T07:52:22Z,could this be final as well?,0,0.9840961694717407
1315529530,14182,dajac,2023-09-05T08:04:38Z,nit: `log` -> `log`.,0,0.9881788492202759
1315531958,14182,dajac,2023-09-05T08:06:51Z,is using an hashset necessary here? we could perhaps use `firstsubscriptionset.containsall(memberspec.subscribedtopicids())`. would it work?,0,0.988654613494873
1315558356,14182,dajac,2023-09-05T08:28:24Z,"is there a reason to have this abstract class here? personally, i find it a bit weird as the concrete classes are not defined in this class. how about extracting it?",-1,0.9729807376861572
1315560818,14182,dajac,2023-09-05T08:30:26Z,nit: javadoc.,0,0.9863433837890625
1315804029,14182,dajac,2023-09-05T12:09:33Z,nit: could this method be static?,0,0.9878506064414978
1315804175,14182,dajac,2023-09-05T12:09:42Z,ditto.,0,0.859873354434967
1315805497,14182,dajac,2023-09-05T12:10:55Z,nit: do we really need to create the arraylist here?,0,0.9851013422012329
1315808858,14182,dajac,2023-09-05T12:14:13Z,we already have the very same class in the `metadata` module. i wonder if we should move that one to `server-common` module so that we could reuse it here. it could land in the `common` package over there. what do you think?,0,0.9406137466430664
1315811048,14182,dajac,2023-09-05T12:16:15Z,nit: could we keep the previous code and use `getordefault` instead of `get`? the code would be more concise...,0,0.9834401607513428
1315814176,14182,dajac,2023-09-05T12:19:10Z,nit: we should use `int` here.,0,0.9884670972824097
1315815939,14182,dajac,2023-09-05T12:20:48Z,nit: this code is duplicated. should we have an helper method for it?,0,0.9890626072883606
1315831564,14182,dajac,2023-09-05T12:34:20Z,nit: we can remove ` `.,0,0.9876640439033508
1315836673,14182,dajac,2023-09-05T12:38:40Z,shouldn't we keep what we had here?,0,0.8957526683807373
1315836903,14182,dajac,2023-09-05T12:38:52Z,nit: `log` -> `log`.,0,0.9881788492202759
1316096433,14182,rreddy-22,2023-09-05T15:50:54Z,yep i'll raise a different pr for range assignor changes,0,0.9836498498916626
1316390836,14182,rreddy-22,2023-09-05T20:47:41Z,"its not the exact same, that one has topicid mapped to topicpartition here its just the partition number",0,0.9746280312538147
1316396258,14182,rreddy-22,2023-09-05T20:54:00Z,removing this,0,0.9721949100494385
1316406386,14182,rreddy-22,2023-09-05T21:05:56Z,"ack will remove it but we can ignore this file for now since the implementation isn't in yet, just needed the initial template for now to get the conditional implementation of the specific assignment builder based on the subscriptions.",0,0.9893411993980408
1316408646,14182,rreddy-22,2023-09-05T21:08:55Z,yeah correct i added a check in the assign method so its not possible anymore,0,0.948869526386261
1316429235,14182,rreddy-22,2023-09-05T21:30:10Z,done,0,0.9764507412910461
1316439651,14182,rreddy-22,2023-09-05T21:40:09Z,"yep makes sense i removed it, i thought in the future if we wanted to have a flag in the assignor to switch it on or off",0,0.9803664088249207
1316456003,14182,rreddy-22,2023-09-05T21:55:51Z,i wanted to throw a partition assignor exception since the exception is related to the assignor? can we do that only? or do we have to do just an illegal state exception?,0,0.9564358592033386
1316792230,14182,rreddy-22,2023-09-06T06:24:50Z,which concrete classes? we made it abstract so that any builder that implements this class would need to implement buildassignment which is the main function called within assign,0,0.9873894453048706
1316793219,14182,rreddy-22,2023-09-06T06:26:04Z,i believe it's easier to understand since alltopicidpartitions is a method that returns this list which is used later on no?,0,0.9482116103172302
1316806195,14182,rreddy-22,2023-09-06T06:41:06Z,will do,0,0.9603245854377747
1316955014,14182,dajac,2023-09-06T08:52:10Z,generaluniformassignmentbuilder and optimizeduniformassignmentbuilder. how about extracting abstractassignmentbuilder from uniformassignor and calling it abstractuniformassignmentbuilder?,0,0.9867731928825378
1316956874,14182,dajac,2023-09-06T08:53:30Z,i was referring to `new arraylist<>(topicids)`. is creating a new arraylist from the set necessary? alltopicidpartitions could take a collection for instance to avoid it.,0,0.9840547442436218
1316961213,14182,dajac,2023-09-06T08:56:03Z,i was referring to [a link] it is really bad to have two classes with the same name but slightly different. i wonder if we can do something about it...,-1,0.9881232380867004
1317663852,14182,rreddy-22,2023-09-06T18:17:32Z,ohh got it yeah that makes sense,0,0.7193351984024048
1317669213,14182,rreddy-22,2023-09-06T18:23:27Z,"ohh my bad i got this question before so i instinctively replied, i realized i was thinking of the kafka common topicidpartition class but yeah this seems usable, would we need a new pr to move the file though?",-1,0.9882441759109497
1317676113,14182,rreddy-22,2023-09-06T18:30:53Z,"discussed offline, going to throw only partitionassignorexception",0,0.9881162643432617
1319775413,14182,dajac,2023-09-08T11:53:49Z,nit: we usually add an empty line before the javadoc for attributes.,0,0.9890301823616028
1319776220,14182,dajac,2023-09-08T11:54:38Z,nit: should we log at debug level here?,0,0.9882723689079285
1319779160,14182,dajac,2023-09-08T11:58:00Z,nit: empty line can be removed.,0,0.9827284216880798
1319810543,14182,dajac,2023-09-08T12:31:31Z,nit: int?,0,0.9853635430335999
1319811185,14182,dajac,2023-09-08T12:32:12Z,could we elaborate a bit more on why the sorting is important here?,0,0.9816389083862305
1319812206,14182,dajac,2023-09-08T12:33:18Z,i wonder if we could reuse the linked list that we already used in rackawareroundrobinassignment instead of re-creating a new one from scratch. is there a reason why we need it?,0,0.861292839050293
1319812750,14182,dajac,2023-09-08T12:33:54Z,nit: should this comment be right before `if (unfilledmembers.containskey(memberid)) {`?,0,0.9871923923492432
1319814872,14182,dajac,2023-09-08T12:36:02Z,"is this really necessary? it is a tad annoying to have to compute the sum of all the unfilled members. if you really want to do this, we could perhaps maintain the total count as we update the unfilled members but i am not sure if it is worth it.",-1,0.9678736925125122
1319816047,14182,dajac,2023-09-08T12:36:57Z,i was wondering whether we could avoid the copy and just update `potentiallyunfilledmembers`. have you thought about this?,0,0.9470959901809692
1319820875,14182,dajac,2023-09-08T12:41:33Z,"yeah, we can have a separate pr to move that class (and add some javadoc to it). i am actually annoyed by the fact that we have two topicidpartition classes but with different content. one with (id, name, partition) and one with (id, partition). this is really misleading...",-1,0.9894726872444153
1319824362,14182,dajac,2023-09-08T12:45:18Z,nit: could we just keep everything on one line?,0,0.9746321439743042
1319824635,14182,dajac,2023-09-08T12:45:35Z,still there :),1,0.9576488137245178
1320217221,14182,rreddy-22,2023-09-08T18:39:21Z,"i added it as a check to ensure we don't have more partitions to assign and less total required assignments count, i.e. jic our calculations are wrong. its not completely necessary",0,0.6096101999282837
1320220040,14182,rreddy-22,2023-09-08T18:42:10Z,in the comments? or should i explain it here,0,0.979955792427063
1320220933,14182,rreddy-22,2023-09-08T18:42:58Z,we sort so that the partition with the least number of options for a matching rack member can receive the assignment first.,0,0.9866364598274231
1321023603,14182,rreddy-22,2023-09-11T05:54:15Z,added in the javadoc,0,0.9853888154029846
1321023849,14182,rreddy-22,2023-09-11T05:54:42Z,"rackaware round robin might not be called in every case, it is only called when userackaware strategy is true. i could make it a global attribute maybe but that seems odd since the queue is only used in these two methods.",0,0.9551395773887634
1321024671,14182,rreddy-22,2023-09-11T05:56:05Z,i remember getting comments to keep the comments at the beginning of the loop instead of inside,0,0.9787184000015259
1321033941,14182,rreddy-22,2023-09-11T06:08:17Z,"yeah you're right, it's an unnecessary extra map, i made it a local map, just wanna still keep it separate cause potentially unfilled members also has ones that have met the quota, but unfilled only has those that still need to be assigned partitions, might be hard to understand what types of members we have at each point. lmk if what i did makes sense or if we can optimize it more",0,0.8669318556785583
1321035644,14182,rreddy-22,2023-09-11T06:10:51Z,"yeah that's true i agree, i wasn't sure what else to call this one, okay i will add a new pr for this.",0,0.7309781312942505
1325561675,14182,dajac,2023-09-14T08:17:15Z,"small nit: in such case, i usually prefer to put the mutated object first in the list of arguments. then, i would also put memberid, then topicid and finally partition to follow their hierarchy. i would also rename targetassignment to assignment because the method is not tight to a target assignment in the end. it could be any assignment map.",0,0.9833565950393677
1325563579,14182,dajac,2023-09-14T08:18:43Z,"bit: this parenthesis seems misplaced, no?",0,0.7148858904838562
1325598891,14182,dajac,2023-09-14T08:44:47Z,"i see... it is a bit annoying to copy the map here but i can live with it if you think that it is better like this. i have another question regarding this code. my understanding is that we basically decide here which members will get the extra partitions. basically, the first members while iterating over the map will get them. when the rack awareness is enabled, i wonder if we could get in a situation where the members with the extra partitions and the unassigned partitions are completely misaligned to due this. let's take an example. we have a group with 10 members (from 1 to 10) subscribed to topic a. topic a has 20 partitions so each member has 2 assigned partitions. all the partitions are available in a single rack. members 1 to 5 are in rack r1 and members 6 to 10 in rack r2. now let's say that we add 5 partitions to a. 3 are in r1 and 2 in r2. if we iterate from 1 to 10 to assign the extra partitions, it means that 1 to 5 will get an extra partitions even though two of the partitions are not in the same rack. is this a possible scenario? it is perhaps a bit too extreme...",-1,0.969471275806427
1325600664,14182,dajac,2023-09-14T08:46:06Z,how about creating the queue just before calling rackawareroundrobinassignment and unassignedpartitionsroundrobinassignment and passing it as a parameter?,0,0.9835330843925476
1325602326,14182,dajac,2023-09-14T08:47:19Z,"ah ah. you got me :). i actually raised this because in rackawareroundrobinassignment, your put it right before the if. that also works because the comment is really about that if.",1,0.9607346057891846
1325604357,14182,dajac,2023-09-14T08:48:52Z,nit: let's log before creating the builder to be consistent with the other branch.,0,0.9869731068611145
1325633887,14182,dajac,2023-09-14T09:07:37Z,nit: we have the same method in rangeassignortest. could we somehow share it for the two suites? we could perhaps introduce an assignortestutil class in this package and add it there.,0,0.9856802225112915
1326815225,14182,rreddy-22,2023-09-15T05:42:57Z,yessir done :),1,0.9237289428710938
1326817433,14182,rreddy-22,2023-09-15T05:46:40Z,i wasn't sure where it went tbh xd,0,0.8075571656227112
1326818424,14182,rreddy-22,2023-09-15T05:48:25Z,"makes sense, i put the order based on the method name like add partition to assignment so first partition then which topic then whose assignment and then which assignment",0,0.9816216826438904
1326819932,14182,rreddy-22,2023-09-15T05:50:52Z,i changed it now so we don't need the queue at all,0,0.9803674221038818
1326826466,14182,rreddy-22,2023-09-15T05:56:06Z,"yeah that's true i didn't think of how we're assigning the extra partitions, used the same logic as before, let me look into it. thanks for catching this!",1,0.9815386533737183
1326838235,14182,rreddy-22,2023-09-15T06:06:32Z,"i think one option would be to iterate through potentially unfilled members instead during the round robin process and if the member is a potential rack match plus can get an extra partition then we can assign it. we basically dynamically decide who gets the extra, instead of deciding before hand",0,0.967767059803009
1326871177,14182,dajac,2023-09-15T06:48:03Z,"yeah, i was thinking about more or less the same. is it an small change?",0,0.9539064168930054
1326872198,14182,dajac,2023-09-15T06:49:18Z,"in this case, i would put it back on the previous line.",0,0.98589688539505
1332072827,14182,rreddy-22,2023-09-20T19:15:32Z,wasn't sadly but its done now,0,0.8971973657608032
50180928,764,hachikuji,2016-01-19T21:48:28Z,"typo in ""messge""?",0,0.9741955399513245
50183536,764,hachikuji,2016-01-19T22:06:29Z,unneeded import (message)?,0,0.9816364645957947
50183902,764,hachikuji,2016-01-19T22:09:14Z,unneeded import (errormapping)?,0,0.9705883860588074
50186812,764,hachikuji,2016-01-19T22:32:18Z,"i wasn't clear from the kip, but is this a broker-wide setting or can it be overridden for each topic?",0,0.9631487727165222
50334745,764,apovzner,2016-01-20T22:57:35Z,"it would be useful to have a comment describing what this method does. especially because in one ""invalid"" case it throws exception, and in another case (when we need to overwrite timestamp) it returns true/false.",0,0.9853248000144958
50335106,764,apovzner,2016-01-20T23:00:58Z,"i am wondering if it would be better to pass 'now' as a parameter. we are calling this method for each message in a set, and getting current time every time. normally getting system time is an expensive call, so maybe better to get it once for a message set, and pass it to this method?",0,0.8722130060195923
50338001,764,apovzner,2016-01-20T23:27:22Z,"i see that in other places you did ""if (magicvalue > magicvalue_v0)"" comparison -- i think that one is better, since we would still want timestamp if we have magicvalue_v2 in the future, for example.",0,0.9756920337677002
50367205,764,becketqin,2016-01-21T07:16:24Z,"i was also thinking about that. currently whatever configurations in logconfig are per topic configurations. and the message timestamp type is a legitimate log config. so currently it is a per topic configuration. i can see some benefit of doing so from migration point of view. because most topics are owned by some applications. we can start to use the new format once all the client of that topic has migrated. and in the final state, we can choose to leave the topics whose owner are not able to migrate to use old format and still have zero-copy.",0,0.9467482566833496
50367268,764,becketqin,2016-01-21T07:17:55Z,good catch :) i remember i had this somewhere but did not find it before submit the pr.,1,0.9906630516052246
50442463,764,hachikuji,2016-01-21T18:36:26Z,"thanks for the explanation. makes sense to me. by the way, i've only done a quick pass on this patch so far, but i'm planning to spend a bit more time in the next couple days.",1,0.8530139923095703
50479362,764,apovzner,2016-01-21T23:04:46Z,"since we are adding timestamp field to producerrecord, i think we should add a comment to producerrecord class description about meaning of timestamp, what happens if user sets null, etc.",0,0.9877907037734985
50479481,764,apovzner,2016-01-21T23:06:04Z,"also would be good to add a comment to recordmetadata class description what timestamp is actually returned (either set by client, producer, or broker).",0,0.9770370721817017
50481259,764,apovzner,2016-01-21T23:23:53Z,"i understand that producer learns about the type of the timestamp after it gets first successful produce response. we are using the type of the timestamp in kafkaproducer.send() to set timestamp in producerrecord. i see that we default to handling timestamp as createtime timestamp if we don't know the type yet. what is the impact of doing this if the correct type turns out to be logappendtime? why don't we just always set timestamp on producer as if is createtime (basically, set local producer time if timestamp in producerrecord is null), and broker then overwrites it if the timestamp type is logappendtime. otherwise, looks like lots of added complexity just to decide whether set timestamp on the producer or not.",0,0.9623344540596008
50484068,764,apovzner,2016-01-21T23:52:00Z,"related to my other comment about learning about timestamp type for topic. so, the first set of produce messages will not have timestamp == inherited_timestamp if timestamp type == logappendtime, right? if setting timestamp to inherited_timestamp is required for compressed messages to work, does it mean we have a bug?",0,0.9734334945678711
50501215,764,becketqin,2016-01-22T04:29:28Z,"the reason we want to set the timestamp to -1 in producer when logappendtime is used for the topic is to avoid broker side recompression. if producer send createtime to a topic setup for logappendtime, recompression will occur on the broker if the received message timestamp is not -1. avoid recompression on broker is the key motivation of kip-31 so we don't want people to lose this feature if they are using logappendtime.",0,0.9744716882705688
50501355,764,becketqin,2016-01-22T04:34:01Z,"it is not required to be inherited_timestamp, but it is good to be so. like i answered in your other comment, if a topic is using logappendtime and a broker receives a message whose timestamp is not inherited_timestamp, it will overwrite it and do the recompression. so the first batch of a new producer might cause recompression on broker side, but after that, no recompression should be needed. i will add some comments so it is more clear.",1,0.8199363946914673
50597218,764,apovzner,2016-01-22T22:03:34Z,"i agree about avoiding broker side recompression. however, i still feel like we can achieve the same behavior with less changes. let me know if i am missing something, but couldn't we just do the following: 1. producer always sets timestamps (either producer client or kafkaproducer), as if timestamp type == createtime. for compressed message: timestamp of the outer message is set to the largest timestamp of the inner messages. 2. broker will overwrite timestamps if type == logappendtime. in case of compressed message, it will overwrite only outer message timestamp, and let inner messages have ""wrong"" timestamps. if message ever gets uncompressed on broker: set all inner timestamps to outer timestamp if type == logappendtime; 3. when messages get uncompressed on consumer (or any case when we don't have timestamp type info): we know that outer timestamp is either max of inner timestamps (if create time) or outer timestamp was overwritten (and so inner timestamps are not valid anymore). we check if outer (compressed message) timestamp == max of inner message timestamps, and if false, set all inner message timestamps to outer timestamp. if there is ever a case that overwriting timestamp results in a timestamp == max of inner message timestamps, this means that producer and broker times are in sync, and inner message timestamps should be close enough to outer timestamp to care overwriting it.",0,0.8494341969490051
50599954,764,becketqin,2016-01-22T22:29:40Z,"in your suggestion, how can we differentiate between the following two scenarios: 1. logappendtime is used, the inner message's largest timestamp happened to be the same as the logappendtime. 2. createtime is used. the compressed messages in both case are exactly the same, but one is using logappendtime and the other one is using createtime. how would the consumer decide which timestamp to use? please also notice that we always do decompression on broker side to verify the message. what we want to avoid is re-compression.",0,0.9810014367103577
50621173,764,dajac,2016-01-23T15:25:29Z,wouldn't it be better to put this conversion in kafkaapis or directly in messageset? i would prefer to keep fetchresponse and fetchresponsepartitiondata as simple as possible and focused on the serialization.,0,0.9871649742126465
50621383,764,dajac,2016-01-23T15:40:43Z,nitpick: indentation is not correct.,0,0.8716122508049011
50645225,764,becketqin,2016-01-24T23:42:32Z,"i agree it makes sense to put the message set format conversion code block into messageset instead of here. however, i make the io threads to do the conversion on purpose because i want to share the workload between kafkaapis threads and io threads. typically, io threads are more light-weighted than kafkaapis threads. if we have to make conversion for some requests, i am trying to put the conversion load on io threads.",0,0.9738481044769287
50743872,764,apovzner,2016-01-25T19:35:46Z,"i should have said ""if message ever gets re-compressed on broker..."" in #2. so we don't over-write timestamp and re-compress just for timestamps. to answer your question and clarify my suggestions, i am basing my suggestion on the assumption that we don't need to be very exact about timestamp -- meaning +- 1 ms is ok. so my proposal above is assuming that if your scenario happen and the inner message's largest timestamp happened to be the same as the current time on broker and we are using logappendtime, this means that producer and broker are in sync, and we don't care whether it is logappendtime or createtime. one more argument against: what if client sets ""bad"" timestamp in one of the inner messages. i realized that in your scenario my suggestion does not work well. i propose the following: on broker, when messages get decompressed, if timestamp type == logapendtime, then set outer message timestamp == current time. check if max timestamp of inner messages also contains this timestamp, and if so, decrement outer message timestamp by 1 ms. in this case, we know that we don't have the scenario above. on consumer, if outer message timestamp != max of inner messages timestamps, we know that this is logappendtime and set all inner message timestamps to outer message timestamp. **summary** i think we either need a cleaner way to get topic's timestamp type on producer or simplify timestamp code by allowing timestamps be not super exact, but no more than +- 1 ms error. the former i think is better solved by getting timestamp type with topic metadata, but that requires another wire protocol change. the latter is proposed above, but here is updated version based on the scenario in the previous comment: 1. producer always sets timestamps (either producer client or kafkaproducer), as if timestamp type == createtime. for compressed message: timestamp of the outer message is set to the largest timestamp of the inner messages. 2. broker will overwrite timestamps if type == logappendtime. in case of compressed message: it will overwrite only outer message timestamp, and let inner messages have ""wrong"" timestamps. if broker happens to overwrite outer message timestamp with with same timestamp, it means that outer timestamp would be equal to max of inner message timestamps. to allow consumer to differentiate between overwritten and not overwritten timestamp, we want to void the case where outer message timestamp == max of inner message timestamps when type == logappendtime. so, when overwriting outer message timestamp with same timestamp, we will decrement (or increment) outer message timestamp by 1 ms. 3. when messages get uncompressed on consumer, we know that outer timestamp is either max of inner timestamps (if create time) or outer timestamp was overwritten (and so inner timestamps are not valid anymore). we check if outer (compressed message) timestamp == max of inner message timestamps, and if false, set all inner message timestamps to outer timestamp.",0,0.9614480137825012
50764320,764,becketqin,2016-01-25T22:09:16Z,"personally i think the timestamp should be accurate. modifying the timestamp sounds very hacky and creates extra complexity. please also notice that the timestamp index built by the followers will be purely depending on the timestamp in outer message of compressed messages. the followers will not even decompress the messages. if we play the trick here, the time index on follower will also be affected. if we want to make things right, then producer should be able to get the necessary topic configuration info from broker, either from topicmetadatarequest or some other requests. so the producer can set the timestamp correctly to avoid server side recompression. but like you said this is a bigger change and it is unnecessary to block on that change. i think the current solution is reasonably clean as of the moment. once the producer is able to get the topic configuration from broker, we can simply migrate to use that. since everything is purely internal, the migration is very simple and transparent to users.",-1,0.7398625612258911
51080192,764,apovzner,2016-01-28T04:59:25Z,"if we are exposing timestamp type in consumerrecord, should we declare timestamptype outside of record?",0,0.9854652285575867
51082542,764,becketqin,2016-01-28T05:50:14Z,it is in kafkaproducer line 437. we just need a one liner now.,0,0.9716191291809082
51165826,764,apovzner,2016-01-28T18:39:07Z,the comment above the method does not match implementation anymore -- we are now only checking acceptable range for createtime timestamps.,0,0.9784085750579834
51221001,764,junrao,2016-01-29T03:00:09Z,it seems that we only reserved 3 bits for compression codec?,0,0.9845591187477112
51221007,764,junrao,2016-01-29T03:00:14Z,it seems that checking lastinneroffset itself is enough.,0,0.9833427667617798
51221024,764,junrao,2016-01-29T03:00:32Z,"since this is always called on the inner records, we probably don't need shallow in the param?",0,0.9824278950691223
51221029,764,junrao,2016-01-29T03:00:36Z,would it be better to name this lastinnerrelativeoffset?,0,0.9870409965515137
51221037,764,junrao,2016-01-29T03:00:44Z,fetch response v2 is actually different from v1 since the message format is different.,0,0.9818442463874817
51221069,764,junrao,2016-01-29T03:00:57Z,could we add timestamp to ?,0,0.9875125288963318
51221090,764,junrao,2016-01-29T03:01:13Z,is it useful for user to specify a -1 timestamp? would that be the same as passing in a null timestamp?,0,0.9891352653503418
51221091,764,junrao,2016-01-29T03:01:18Z,"the record is still sent to a topic/partition, not timestamp.",0,0.9858141541481018
51221099,764,junrao,2016-01-29T03:01:23Z,typo: record.record,0,0.8985579609870911
51221100,764,junrao,2016-01-29T03:01:25Z,typo: record.record,0,0.8985579609870911
51235304,764,becketqin,2016-01-29T08:18:35Z,"currently the message format change is not reflected in the fetch response protocol. the change is in the record class when it parses the bytebuffer. so the fetchresponse fields actually does not change. but i agree that ideally we should define all the wire protocols in protocol. i was planning to do it in another patch because this patch is already big. the comment here is actually not accurate. in fetchresponse v2 we may also see message format v0, because the broker will try to avoid losing zero copy by assuming the client sending fetchrequest v2 knows how to parse message format v0.",0,0.9602192640304565
51301463,764,apovzner,2016-01-29T19:08:50Z,"why do we ever need to recompute crc for timestamp type == createtime? since createtime is default, we should set all right attributes with the timestamp on the producer, and we don't need to update crc or do any related changes to timestamp/attributes on the broker. i think we should be clear about when crc can change on the broker and when it will not.",0,0.9854961037635803
51325920,764,becketqin,2016-01-29T22:37:12Z,we need to verify both the timestamp attribute bit and the actual timestamp. if one of them is not set properly we need to update it and recompute crc.,0,0.9860246777534485
51326334,764,apovzner,2016-01-29T22:42:22Z,"i see, so this is only the migration case, right? upgraded producer will set both attributes and timestamp correctly for the createtime topics, right?",0,0.9837260842323303
51329584,764,becketqin,2016-01-29T23:21:45Z,for migration case and for producers that is not setting the timestamp of outer message correctly somehow. it should be fine since we are not changing the actual timestamps of messages.,0,0.978721022605896
51502629,764,apovzner,2016-02-02T00:07:14Z,"thanks, that makes sense.",1,0.5191644430160522
51516461,764,junrao,2016-02-02T02:52:44Z,"right, perhaps we can make this clearer in the comment. sth like the following: even though fetch response v2 has the same protocol as v1, the record set in the response is different. in v1, record set only includes messages of v0 (magic byte 0). in v2, record set can include messages of v0 and v1 (magic byte 0 and 1). for details, see ref{bytebuffermessageset}.",0,0.9675493240356445
51516607,764,junrao,2016-02-02T02:54:29Z,"would it be better to rename this to wrappertimestamptype? also, since the way to interpret the timestamp is a bit subtle, especially with respect to compressed messages, could you document this in a comment?",0,0.9792225360870361
51516616,764,junrao,2016-02-02T02:54:34Z,"the comment says this is the constructor for version 1, but the code uses the latest version.",0,0.9876441359519958
51516635,764,junrao,2016-02-02T02:54:46Z,"we check version here, but uses the new field name in line 127 as the way to check the version. we should probably use a consistent approach.",0,0.9853398203849792
51516646,764,junrao,2016-02-02T02:54:59Z,could we add a comment before line 95 that we expect the caller to pass in a struct with the latest schema?,0,0.9862887859344482
51516833,764,junrao,2016-02-02T02:57:34Z,"in addition to have the internal versions, we probably should always have an ""0.10.0"" version in trunk so that it's in a releasable state. i was thinking that we always have ""0.10.0"" map to the last case object. in this case, both ""0.10.0"" and ""0.10.0-dv0"" will be pointing to kafka_0_10_0_dv0. when we add kafka_0_10_0_dv1, ""0.10.0"" will be pointing to kafka_0_10_0_dv1 and we will add ""0.10.0-dv1"", but leave ""0.10.0-dv0"" unchanged. in the code, we can just reference the first internal version in which a format change is introduced. then, for people deploy from trunk, they can use the internal version. for people who want to try trunk, they can use ""0.10.0"". also, would it be better to use iv (internal version) instead of dv? finally, it may make sense to make the next major release 0.10 instead of 0.9.1 since we will be including kstream. do you want to poll the mailing list to see if people are ok with this?",0,0.9801282286643982
51516887,764,junrao,2016-02-02T02:58:28Z,"i agree that it's better to do the message conversion in kafkaapis. the reason is that a single network thread is used to handle many socket connections. if the sending of one response is slow (e.g., recompression when converting the message), it slows down the processing of all connections on this network thread. on the other hand, if the processing in a request handler thread is slow, it only slows down that request. other requests are unaffected.",0,0.9739381074905396
51516906,764,junrao,2016-02-02T02:58:52Z,this means that we are paying the overhead of checking hasmagicvalue even after the consumer is upgraded to support both message format v0 and v1.,0,0.9871843457221985
51516922,764,junrao,2016-02-02T02:59:10Z,"should this be a topic level config? the issue is that this has to match the api version that the broker uses. for example, if the broker is on 0.9.x, setting the format in a topic to v1 is invalid, but is hard to enforce.",0,0.9728239178657532
51516927,764,junrao,2016-02-02T02:59:13Z,typo writtern,0,0.9876848459243774
51516929,764,junrao,2016-02-02T02:59:16Z,it simply write => it simply writes,0,0.9857771992683411
51516941,764,junrao,2016-02-02T02:59:28Z,can use innermessageandoffsets instead of messageandoffsets.,0,0.9878033995628357
51516961,764,junrao,2016-02-02T02:59:49Z,"if we don't need to re-compress, should we validate the crc of each of the inner message?",0,0.987395703792572
51516975,764,junrao,2016-02-02T03:00:03Z,"it seems that we only need to convert message format on filemessageset. so, perhaps it's better to move this to filemessageset?",0,0.9853345155715942
51516977,764,junrao,2016-02-02T03:00:08Z,there are a few unused imports.,0,0.9822850227355957
51517004,764,junrao,2016-02-02T03:00:31Z,"this probably shouldn't be info level logging, right?",0,0.9831628799438477
51517033,764,junrao,2016-02-02T03:00:56Z,could we document what the valid values are for message format? it seems that we are piggybacking on the apiversion number. it's probably clearer if just use v0 and v1 that matches the magic value since not every api version change implies a message format change.,0,0.9841036796569824
51525824,764,becketqin,2016-02-02T05:28:21Z,read the code again. that's true. apparently i had some wrong impression about how we process the requests...,-1,0.8324474692344666
51529150,764,becketqin,2016-02-02T06:30:05Z,good catch. we only need to do down convert for fetch request lower than v2.,1,0.9685404300689697
51530067,764,becketqin,2016-02-02T06:38:39Z,"that is indeed a caveat. the reason i make message.format.version a topic level config is because it helps to roll out the change. in many cases topics are owned by different applications, so once the application finishes upgrade we can turn on the new message format for them without waiting for others. one way to enforce this is to add sanity check in both kafkaconfig and topicconfighandler. we can check to make sure the message format version config is valid.",0,0.9639838933944702
51531865,764,becketqin,2016-02-02T07:08:00Z,had some comments on the kip about this. i feel fine either way. the good thing about piggybacking apiversion is it is easy to validate the config. and from user's perspective it may be easier to understand. e.g. during upgrade they can simply put their previous kafka version there and after upgrade they just need to change it to the upgraded version. so users don't need to remember the magic values to put.,1,0.9339029788970947
51615655,764,junrao,2016-02-02T18:54:10Z,it's probably clearer to rename this to sth like magicvalueinallmessages().,0,0.981115460395813
51615665,764,junrao,2016-02-02T18:54:14Z,indentation,0,0.982236921787262
51615681,764,junrao,2016-02-02T18:54:20Z,could you attach gwen's comment here?,0,0.9877750873565674
51615706,764,junrao,2016-02-02T18:54:26Z,could we include the valid property values in the doc?,0,0.9884299039840698
51615770,764,junrao,2016-02-02T18:54:47Z,"we should use the magic configured for this topic and convert each message to the right version if needed, right?",0,0.98219233751297
51615946,764,junrao,2016-02-02T18:55:53Z,"could we put those comments in a more prominent place like the beginning of the class? with v1 message format, we are adding a timestamp, a timestamp type attribute, and are using a relative for inner message. it would be useful to document the format in a bit more details for both the outer and the inner message. for example, should the timestamp type attribute be set for inner messages?",0,0.9836048483848572
51634795,764,becketqin,2016-02-02T21:05:21Z,"gwen gave the following feedback on the voting thread. ""2. apiversion has real version numbers. message.format.version has sequence numbers. this makes us look pretty silly :)""",1,0.9931661486625671
51637287,764,becketqin,2016-02-02T21:23:12Z,"i was thinking only applying the new message format to the messages appended after the change, so the log has a clear cut-off offset where all the new format comes after that. it is probably not necessary. what do you think?",0,0.977449893951416
51672466,764,junrao,2016-02-03T02:51:10Z,could we add a comment to explain what the timestamp is?,0,0.984890878200531
51672513,764,junrao,2016-02-03T02:51:55Z,the comment still says using v1 format.,0,0.9870284795761108
51672525,764,junrao,2016-02-03T02:52:14Z,it's probably useful to use the message format v1 on the topic. this can avoid the recompression overhead when compression is enabled.,0,0.9852147698402405
51672530,764,junrao,2016-02-03T02:52:20Z,it's probably useful to use the message format v1 on the topic. this can avoid the recompression overhead when compression is enabled.,0,0.9852147698402405
51672563,764,junrao,2016-02-03T02:52:53Z,"the thing is that the way topicconfigcommand works is that it just writes the config in zk and then writes the config notification. topicconfighandler just follows the notification. if we add the check in topicconfighandler, we need to remove the config in zk, which makes things more complicated. we can probably just leave this as a topic level config with the caveat that the config may be ignored if the broker property doesn't match.",0,0.9743489027023315
51672667,764,junrao,2016-02-03T02:54:32Z,"the changes in this class is a bit complicated, makes the code a bit hard to read. this and the following are some suggestions on simplification. do we need convertnoncompressedmessages()? since we can't do things in place, could we just use the path that deals with recompression to handle it? this will save some duplicated code.",0,0.843879759311676
51672737,764,junrao,2016-02-03T02:55:35Z,"requirerecompression is a bit confusing. for example, requirerecompression will be true if the source data is compressed and the broker requires no compression. perhaps we can rename it to sth like inplaceconversion and negate the test?",-1,0.7627809047698975
51672760,764,junrao,2016-02-03T02:56:06Z,"passing in messagesettimestampassignor makes the code a bit harder to read. i was wondering if we can obviate that and always scan the messages to get the max timestamp. this will add a bit overhead of making another iteration of all messages, but will simplify the code. the overhead should be small.",0,0.9545045495033264
51672770,764,junrao,2016-02-03T02:56:15Z,"so far, we have been using case classes to represent enum in scala (see compressioncodec). could we follow the same convention?",0,0.9871847033500671
51672776,764,junrao,2016-02-03T02:56:24Z,"hmm, producer request v2 is supposed to send message of v1, right? actually, should we enforce that on the broker?",0,0.9866093993186951
51672781,764,junrao,2016-02-03T02:56:34Z,"hmm, what is %s for now? also, do we want to just log the text ""fetchrequest""?",0,0.9888511300086975
51672789,764,junrao,2016-02-03T02:56:43Z,would it be better to use the latest version of the message?,0,0.9859874844551086
51672844,764,junrao,2016-02-03T02:57:49Z,"right, we can use sth like v0, v1 to make it consistent.",0,0.98432457447052
51682035,764,junrao,2016-02-03T06:06:48Z,"converting to message format v1 allows us to track timestamp at the message level, which will be useful for things like removing the tombstone.",0,0.9883629679679871
51768874,764,becketqin,2016-02-03T18:57:25Z,"hi jun, currently we always do re-compression when compacting the log, even if message format v1 is used. do you mean we should change that so if a compressed message set does not change after compaction we simply write the original message set back? if we do that (and we probably should), it seems it does not matter whether message format v0 or v1 is used, because it only depends on whether there is message in the message set got compacted out or not.",0,0.9670741558074951
51817003,764,hachikuji,2016-02-04T01:24:23Z,"took me a while to wrap my head around this line. it seems like the `lastinnerrelativeoffset` and `wrapperrecordoffset` are constants within the life of this instance, so i'm wondering if we could instead use a single constant (e.g. `absolutebaseoffset`) for this difference? then this line would just become: [code block] which is a lot more readable.",0,0.9390135407447815
51831822,764,junrao,2016-02-04T05:42:22Z,"that's not what i meant. since this message will be eventually appended to the log through log.append, if it's compressed and of format v0, we need to recompress it. if it's format v1, the recompression can be avoid. also, since v1 carries more metadata, it seems that we should always try to use message v1 if possible.",0,0.9758923649787903
51961629,764,becketqin,2016-02-05T00:39:38Z,"hi jun, do we also want the change in old producer request and old producer? it seems it will be deprecated pretty soon. so in the current patch i did not even change the scala producerrequest format, but i probably should just leave the scala producer version to 1. besides that, i realized that we have quite a few tools still using old consumer. i will update them.",0,0.8789441585540771
52074957,764,becketqin,2016-02-05T21:26:46Z,ack :),1,0.8799719214439392
52267507,764,junrao,2016-02-09T04:50:22Z,"reworded this a bit the default on-disk message format in 0.10.0 in v1. if a consumer client is on a version before 0.10.0, it only understands message format v0. in this case, the broker is able to convert messages of format v1 to v0 before sending a response to the consumer on an older version. however, the broker can't use zero-copy transfer in this case. to avoid such message conversion before consumers are upgraded to 0.10.0, one can set the message format to v0 after upgrading the broker to 0.10.0. this way, the broker can still use zero-copy transfer to send the data to the old consumers. once most consumers are upgraded, one can change the message format to v1 on the broker.",0,0.9869472980499268
52267511,764,junrao,2016-02-09T04:50:31Z,the comment is not accurate since the producer doesn't know the timestamp type.,0,0.7862319350242615
52267516,764,junrao,2016-02-09T04:50:38Z,are these comments correct? the timestamp in producerrecord is always set by the producer.,0,0.9875907897949219
52267522,764,junrao,2016-02-09T04:50:44Z,could we add a comment on the timestamp field?,0,0.9868740439414978
52267534,764,junrao,2016-02-09T04:51:06Z,"typo dv also, could we leave some comments so that people know what to do when changing the protocol again before 0.10.0 is released?",0,0.9891312122344971
52267543,764,junrao,2016-02-09T04:51:13Z,we no longer need this since 0_10_0 will just point to the latest iv.,0,0.9826309084892273
52267549,764,junrao,2016-02-09T04:51:21Z,the changes in this file seem no longer needed.,0,0.9720789790153503
52267569,764,junrao,2016-02-09T04:51:50Z,"i had a comment on this in the previous round of review. it seems that during compaction, it would be better to write the message in the configured message format : (1) this reduces the message conversion during fetch. (2) converting to message format v1 allows us to track timestamp at the message level, which will be useful for things like removing the tombstone.",0,0.9844775199890137
52267574,764,junrao,2016-02-09T04:51:56Z,should we just represent this as a byte to be consistent with message.magic?,0,0.9828631281852722
52267583,764,junrao,2016-02-09T04:52:05Z,should we assert that wrappermessagetimestamp is only set if compression is on and timestamptype is logappend?,0,0.9884493947029114
52267592,764,junrao,2016-02-09T04:52:10Z,adjust => adjusts,0,0.9847394227981567
52267595,764,junrao,2016-02-09T04:52:18Z,"could we make put the message in the exception clearer? e.g., the payload is null.",0,0.9842295050621033
52267604,764,junrao,2016-02-09T04:52:27Z,the confusion is that torelativeoffset() doesn't really return the relative offset as defined in line 150. would it be better to rename it to toinneroffset()?,0,0.8634577989578247
52267612,764,junrao,2016-02-09T04:52:41Z,"for compressed messages, we don't really set the timestamptype for inner messages. so, we need to make this clear. also, the inner message offset is not really the relative offset.",0,0.9766263365745544
52267620,764,junrao,2016-02-09T04:52:58Z,"since the offset of the inner message is not really the relative offset, we can probably just talk about how to derive the ao from the inner offset.",0,0.9836716055870056
52267622,764,junrao,2016-02-09T04:53:03Z,io is defined but not used.,0,0.9793910980224609
52267631,764,junrao,2016-02-09T04:53:19Z,"i left this comment in the previous review. do we need convertnoncompressedmessages()? since we can't do things in place, could we just use the path that deals with recompression to handle it? this will save some duplicated code.",0,0.9870470762252808
52267646,764,junrao,2016-02-09T04:53:35Z,is this check needed since we can only do in-place if magic is > 0?,0,0.9844492077827454
52267649,764,junrao,2016-02-09T04:53:38Z,5th -> 4th?,0,0.962826132774353
52267651,764,junrao,2016-02-09T04:53:42Z,should we change the description for attribute?,0,0.9871396422386169
52267666,764,junrao,2016-02-09T04:53:56Z,could we add a comment to explain when do we expect wrappermessagetimestamp and wrappermessagetimestamptype to be not none?,0,0.9858113527297974
52267675,764,junrao,2016-02-09T04:54:05Z,"in line 168, should we set timestamptype in attribute?",0,0.9902660250663757
52267679,764,junrao,2016-02-09T04:54:08Z,indentation,0,0.982236921787262
52267681,764,junrao,2016-02-09T04:54:12Z,there are unused imports.,0,0.9703279137611389
52267687,764,junrao,2016-02-09T04:54:19Z,we only return the max timestamp of the inner messages if timestamptype is createtime.,0,0.9878865480422974
52267690,764,junrao,2016-02-09T04:54:24Z,would it be better to change samplemagicvalue to firstmagicvalue?,0,0.9867466688156128
52267700,764,junrao,2016-02-09T04:54:32Z,the message in the exception can be mis-leading since validatemagicvaluesandgettimestamp may not be called on a set of uncompressed messages.,0,0.9739750027656555
52267706,764,junrao,2016-02-09T04:54:51Z,"the method only iterates shallow messages. so, perhaps changing the method to magicvalueinallwrappermessages and adjusting the comments?",0,0.9795362949371338
52267737,764,junrao,2016-02-09T04:55:43Z,we can probably just check if all messages are on v0 since not all existing messages necessarily match the message format config.,0,0.9885470867156982
52267746,764,junrao,2016-02-09T04:55:59Z,it's probably better to log the # of bytes in the messageset instead of # of messages. the later will invoke the iterator and is more expensive.,0,0.970143735408783
52267748,764,junrao,2016-02-09T04:56:04Z,incorrect indentation since this is the parameter for responsesize().,0,0.8447492718696594
52267763,764,junrao,2016-02-09T04:56:17Z,"we want to make it clear that the performance impact is only during the upgrade period. once the clients are upgraded or if people are just starting to use 0.10, there is no performance impact.",0,0.9826411604881287
52356387,764,becketqin,2016-02-09T19:02:42Z,"hi jun, this patch is using the message format version configured for this topic when doing compaction. the configuration is passed in in line 373. do you mean something else?",0,0.9758728742599487
52380036,764,becketqin,2016-02-09T21:52:37Z,"having a separate `convertnoncompressedmessages()` saves one round of memory copy. in `convertnoncompressedmessages()` we read from the old format and write the converted format directly into the new byte buffer. so there is only one memory copy. if we let the path that deals with re-compression to handle it, we need to first convert messages to required format (first memory copy), then write them together to a new byte buffer (second memory copy).",0,0.9869614839553833
52387545,764,junrao,2016-02-09T22:48:26Z,"hmm, i don't see the logic of format conversion though. for example, if there are uncompressed messages of v0 and the format of the topic is configured with v1, we should write messages of v1 to the new log segment. currently, it seems that we just keep the original message format.",0,0.9726459980010986
52389495,764,becketqin,2016-02-09T23:03:43Z,we always return the max timestamp of the inner messages as long as they are in v1.,0,0.9892337322235107
52405180,764,becketqin,2016-02-10T01:44:59Z,"hi jun, the tests on the configuration here is trying to address the following problem. after people just upgrade to 0.10.0.0, most of the fetch request are still in v1. in this case, if we check whether all the messages are v0 or not, we are essentially iterating over the file message set. by checking the configuration, we can avoid that. after people set message format to v1, we will only do the iterative check for old consumers (hopefully there won't be many at that point). the caveat of this approach is mentioned in the comments. after user set the message format to v1, if they decide to change the message format back to v0. the old consumer may see message v1 because of the discrepancy between actual message format and the config as you pointed out. do you prefer to simply take the performance cost right after people finish upgrade? this cost will go away after all the clients are upgraded, but that could be an extended period.",0,0.9698002338409424
52503273,764,becketqin,2016-02-10T18:41:47Z,"ah, you are right. i'll fix that.",0,0.678087055683136
52550562,764,becketqin,2016-02-11T00:34:48Z,"hi jun, i actually hesitated a little here. it seems this constructor should only be used by producer, so the timestamp should always be createtime. i added the timestamp type to constructor pretty lately because checksummessageformatter also needs to construct message in order to compute checksum. currently checksummessageformatter only takes key and value and always assume the compression type to be nocompression. this works because all the messages, including inner messages of compressed messages, should not have compression codec. however, because timestamp type can be different from message to message, we need to include timestamp type when computing checksum. we also need compression type because for compressed messages, inner message timestamp type is always createtime even when the timestamp type of the message is logappendtime defined by wrapper message. i did not find any usage of checksummessageformatter. i asked joel about this class, and it looks we used to use it in system test, but now we are not using it anymore. do you think we can simply remove this class?",0,0.8839922547340393
52609487,764,junrao,2016-02-11T14:44:42Z,"thanks, got your point. so, setting the message version to 0 in the config not only implies that future messages will be written in version 0, but all existing messages are of version 0 too? we should at least document this, but i am not sure if this is enough to warn people about the impact of switching back and forth of the message format config. could you run some experiments about the performance impact of doing the message format check?",1,0.8479955196380615
52780786,764,becketqin,2016-02-12T18:46:05Z,"hi jun, i ran the following experiment with the configuration check removed. i.e. always verify messages for fetch request v1. 1. start a new broker with message.format.version=v0. 2. produce 3000000 messages to topic with 128 partition using console producer. 3. consume the messages using console consumer in this rb (sending v2 fetch request, so no message format verification needed.) 4. consume the messages using console consumer in current trunk (sending v1 fetch request, so message verification is needed) the log below prints out the time cost on the verification code block: [code block] the first 4 lines are from v2 requests. the fifth line is from v1 and v2 mixed. the last 4 lines are from v1 requests. time unit is nano seconds. it seems the traversal cost is expensive.",0,0.9587090015411377
52814031,764,junrao,2016-02-12T23:47:08Z,"ok, then we can keep the version check there. could we update the config/upgrade doc to make it clear that by setting the message version on a topic, the user is certifying that all existing data are on that version and if that's not the case, the consumer before 0.10 will break?",0,0.9884122014045715
52815492,764,junrao,2016-02-13T00:08:23Z,"hi, jiangjie, independent of checksummessageformatter, shouldn't we set the attribute based on the timestamptype passed in? the caller is responsible for setting the timestamptype.",0,0.9877340793609619
52838521,764,junrao,2016-02-14T06:25:35Z,could we add the doc for timestamptype?,0,0.988291323184967
52838529,764,junrao,2016-02-14T06:26:33Z,"since this will be part of the java doc, could we explain what the timestamp will be?",0,0.9885079264640808
52838534,764,junrao,2016-02-14T06:27:44Z,timestam -> timestamp type?,0,0.9855908155441284
52838535,764,junrao,2016-02-14T06:27:46Z,do we need the createtime at the end? ditto for the logappendtime at the end of line 30.,0,0.9369301199913025
52838538,764,junrao,2016-02-14T06:28:26Z,"if createtime is used, are we returning -1 for timestamp?",0,0.9894277453422546
52838543,764,junrao,2016-02-14T06:29:13Z,create times => createtime,0,0.9829004406929016
52838565,764,junrao,2016-02-14T06:32:40Z,the message format => that message format,0,0.9863643050193787
52838575,764,junrao,2016-02-14T06:34:35Z,need to remove prinitln.,0,0.9698787331581116
52838577,764,junrao,2016-02-14T06:35:01Z,should we throw kafkaexception instead?,0,0.9780338406562805
52838580,764,junrao,2016-02-14T06:35:43Z,"since the inner offset is not really the relative offset, we can probably just refer to it as inner offset and point to the description in the later text.",0,0.9850205183029175
52838587,764,junrao,2016-02-14T06:36:03Z,producer -> the producer create => creates,0,0.9818474650382996
52838590,764,junrao,2016-02-14T06:36:36Z,followings situation => following situations,0,0.9803689122200012
52838592,764,junrao,2016-02-14T06:36:54Z,probably better to rename to expectedinneroffset?,0,0.9875913858413696
52838595,764,junrao,2016-02-14T06:37:24Z,"it doesn't seem that we need to valid the input message here since this is already done in log,analyzeandvalidatemessageset().",0,0.988219141960144
52838598,764,junrao,2016-02-14T06:38:07Z,would it be better to return a magicandtimestamp so that the caller doesn't have to iterate the message set again to get the magic?,0,0.9866803288459778
52838602,764,junrao,2016-02-14T06:38:33Z,numfetch and totaltime are unused.,0,0.9741520881652832
52838603,764,junrao,2016-02-14T06:38:51Z,"the value is now in bytes, not messages.",0,0.9851130247116089
52838608,764,junrao,2016-02-14T06:40:00Z,the whether -> whether,0,0.9787867665290833
52839564,764,becketqin,2016-02-14T08:36:19Z,"it seems that if we do not have the creattime at the end, java doc will show the entire qualifier, i.e. org.apache.kafka.common.record.timestamptype#createtime. this works but seems a little verbose. alternatively we can import the timestamptype class so we don't need to have a display name for the ``. do we have a convention for java doc in kafka? it seems we have different styles in the code base.",0,0.9749173521995544
52839682,764,becketqin,2016-02-14T08:48:20Z,"if createtime is used, we are returning user provided timestamp if it exists or the time when the record was handed to the producer.",0,0.9890172481536865
52847115,764,junrao,2016-02-14T19:01:21Z,"it seems that we need to reset absolutebaseoffset when we are done iterating the inner records. otherwise, the next record could be uncompressed and we will set the offset incorrectly. could we add a unit test that covers this?",0,0.9827079176902771
52847119,764,junrao,2016-02-14T19:01:28Z,incomplete sentence,0,0.49796152114868164
52847121,764,junrao,2016-02-14T19:01:36Z,"reworded this a bit. see if it's clearer. since the api protocol may change more than once within the same release, to facilitate people deploying code from trunk, we introduce internal versions since 0.10.0. for example, the first time that we introduce a version change in 0.10.0, we will add a config value ""0.10.0-iv0"" and a corresponding case object kafka_0_10_0-iv0. we will also add a config value ""0.10.0"" that will be mapped to the latest internal version object, which is kafka_0_10_0-iv0. when we change the protocol a second time while developing 0.10.0, we will add a new config value ""0.10.0-iv1"" and a corresponding case object kafka_0_10_0-iv1. we will change the config value ""0.10.0"" to map to the latest internal version object kafka_0_10_0-iv1. config value of ""0.10.0-iv0"" is still mapped to kafka_0_10_0-iv0. this way, if people are deploying from trunk, they can use ""0.10.0-iv0"" and ""0.10.0-iv1"" to upgrade one internal version at a time. for most people who just want to use released version, they can use ""0.10.0"" when upgrading to 0.10.0 release.",0,0.980137288570404
52847126,764,junrao,2016-02-14T19:02:02Z,"we should use the message format specified for the internal topic. in addition, we have to be a bit careful here, during a rolling upgrade, if a broker's inter-broker protocol version is still before 0.10.0, even if the message format is for v1, we will still want to use message format v0. otherwise, if another broker is still on the pre 0.10.0 code, it can't read the v1 message in the internal topic. ditto to the magic value setting below.",0,0.76486736536026
52847133,764,junrao,2016-02-14T19:02:21Z,"there is a similar issue here. during rolling upgrade to 0.10.0, if a broker's inter-broker protocol version is still before 0.10.0, even if the message format is for v1, we will still want to use message format v0. otherwise, if another broker is still on the pre 0.10.0 code, it can't read the v1 message in the internal topic for things like log cleaning.",0,0.9662381410598755
52847134,764,junrao,2016-02-14T19:02:33Z,"similar issue as before, we need to further guard the message format based on inter protocol version so that we only use message format ready for every broker.",0,0.9849373698234558
52847137,764,junrao,2016-02-14T19:02:50Z,it seems that we may need to change the message format when copying out uncompressed messages too.,0,0.967649519443512
52847141,764,junrao,2016-02-14T19:02:54Z,the inner message offset is not really relative.,0,0.9430155754089355
52847144,764,junrao,2016-02-14T19:02:57Z,the inner message offset is not really relative.,0,0.9430155754089355
52847146,764,junrao,2016-02-14T19:03:06Z,it seems that timestamptype can only be none if magic is 0?,0,0.9756459593772888
52847149,764,junrao,2016-02-14T19:03:19Z,could we also add the need for this to be consistent with inter broker protocol (otherwise the setting will be ignored)?,0,0.9882712960243225
52847150,764,junrao,2016-02-14T19:03:23Z,are the changes here needed?,0,0.984384298324585
52847151,764,junrao,2016-02-14T19:03:32Z,"since the fail and assertions are in the callback and we eat the exceptions, we probably need to propagate the failure to the main test method?",0,0.9781635999679565
52847154,764,junrao,2016-02-14T19:03:40Z,can we get the cause and check the exact exception time? ditto below.,0,0.9162316918373108
52847180,764,junrao,2016-02-14T19:05:18Z,it seems that we need to call validatetimestamp() in this case as well?,0,0.9876790642738342
52847192,764,junrao,2016-02-14T19:06:14Z,invalidmessageexception is used for corrupted messages. could we use a different exception and error code?,0,0.9327041506767273
52847218,764,junrao,2016-02-14T19:08:19Z,"thinking about this again, since it's possible for us to change the message format more than once within the same release and we need to make sure message format is consistent with inter protocol version, it's probably better to just use the values in apiversion to specify the message format. we can probably extend each of the case object in apiversion to add a magic field to indicate the message version associated with each protocol version. sorry for going back and forth on this one.",-1,0.9897833466529846
52850892,764,becketqin,2016-02-14T23:16:33Z,"hmm, absolutebaseoffset is only non-negative for inner iterators. the outer iterators always have absolutebaseoffset=-1. because we create a separate independent inner iterator for each compressed message set, the same absolutebaseoffset should be used by all the messages in that compressed message set. after we finish iterating one compressed message set and return to the outer iterator, the absolutebaseoffset of inner iterator will not affect the outer iterator, i.e. the outer iterator absolutebaseoffset remains -1. so even the next record is an uncompressed record, it should not be affected.",0,0.9751300811767578
52851922,764,becketqin,2016-02-15T00:20:05Z,"hi jun, we are doing message format conversion, right? if another broker is on old code and sends fetchrequest v1, we will down convert the message to v0. so it should not break even if leader has message format v1 on disk and follower is fetching using inter-broker protocol version before 0.10.0. i am wondering if we should simply let the internal topic message format comply with inter-broker protocol version. the reason is this guarantees no message format conversion is needed for internal topic replication. and it avoids manually setting message format version config for the internal topic.",0,0.926217257976532
52852265,764,becketqin,2016-02-15T00:36:02Z,regarding the message format check. currently we do validate both broker and topic level configuration to make sure message format version is on or below inter-broker protocol version. so is it sufficient to simply use the message format version in the config?,0,0.9876809120178223
52852401,764,becketqin,2016-02-15T00:43:01Z,"sorry for the confusion, ""timestamptype"" in the comments should actually be ""wrappermessagetimestamptype"".",-1,0.9829508662223816
52852569,764,becketqin,2016-02-15T00:52:19Z,good catch. this might cause the test to just hang. it looks that in other multi-threaded test we have timeout in main thread. maybe we can do the same thing here.,1,0.8844577074050903
52852973,764,becketqin,2016-02-15T01:14:15Z,"i was also thinking about this when creating kafka-3203. currently we are also throwing invalidmessageexception if we non-keyed message for compacted topic. should we add invalidmagicbyteexception, invalidcodecexception, invalidtimestampexception and corresponding error mapping?",0,0.9649492502212524
52861805,764,junrao,2016-02-15T06:01:37Z,"yes, perhaps we can just add invalidtimestampexception in this patch and add others in kafka-3203.",0,0.9885632991790771
52861828,764,junrao,2016-02-15T06:02:18Z,"well, it may not hang. it just that if the assertion fails, the test may not fail since it only causes an exception in the callback thread. we can probably do sth like maintaining a successcount and check that at the end of flush.",0,0.9843988418579102
52861864,764,junrao,2016-02-15T06:03:24Z,"yes, you are right. didn't see the message format check in kafkaconfig. i think it's still better and simpler to just use the message format specified for the internal topic. this way, one can wait until inter protocol is upgraded to 0.10.0 in all brokers and then upgrade the message format w/o any conversion overhead. if we rely upon inter-broker protocol, there will still be some conversion while changing the inter-broker protocol in all brokers.",0,0.942757785320282
52861870,764,junrao,2016-02-15T06:03:36Z,"thanks for the explanation. yes, i think this is fine since absolutebaseoffset is final.",1,0.8449673056602478
52861920,764,junrao,2016-02-15T06:04:11Z,"ok, sounds good.",1,0.787392258644104
52862221,764,junrao,2016-02-15T06:05:32Z,"could we also add sth like the following. in particular, after the message format is set to v1, one should not change it back to v0 since it may break the consumer on versions before 0.10.0.",0,0.989071249961853
52862231,764,junrao,2016-02-15T06:05:39Z,"could we add the following breaking change in 0.10.0? messageformatter def writeto(key: array[byte], value: array[byte], timestamp: long, timestamptype: timestamptype, output: printstream)",0,0.9893976449966431
52862239,764,junrao,2016-02-15T06:05:55Z,indentation,0,0.982236921787262
52862242,764,junrao,2016-02-15T06:06:01Z,are the changes in this file needed?,0,0.9848979115486145
52862251,764,junrao,2016-02-15T06:06:09Z,should we use magic v1 in this test?,0,0.9847666621208191
52862254,764,junrao,2016-02-15T06:06:13Z,typo converion,0,0.9635652303695679
52862293,764,junrao,2016-02-15T06:06:47Z,it's not clear why this is needed. isn't the default of message version v1?,0,0.9672262072563171
52862309,764,junrao,2016-02-15T06:06:56Z,could we put the block from 185 to 191 in a method and reuse it in the subsequent blocks?,0,0.9864827990531921
52862322,764,junrao,2016-02-15T06:07:02Z,should we generate message of v1?,0,0.9881482720375061
52862344,764,junrao,2016-02-15T06:07:12Z,could we avoid duplicating the code btw v0 and v1?,0,0.9858430027961731
52862367,764,junrao,2016-02-15T06:07:23Z,"should we use message v1? since v1 is the default message format, it seems that v1 should be the format that we use in most tests.",0,0.9886753559112549
52862383,764,junrao,2016-02-15T06:07:31Z,"hmm, the overhead in message v1 is larger than message.minmessageoverhead.",0,0.9858875870704651
52862396,764,junrao,2016-02-15T06:07:36Z,"this same process can be used to upgrade from 0.8.x to 0.10.0, right?",0,0.9880546927452087
52865660,764,becketqin,2016-02-15T07:05:21Z,"just to clarify, by ""there will still be some conversion while changing the inter-broker protocol"", you meant downgrading inter-broker protocol, right? if user are bumping up inter-broker protocol, there will be no conversion. if so, considering inter-broker protocol downgrading is relatively rare and the impact is only during inter-broker protocol downgrade, does it still worth requiring user to change internal topic configuration as an extra step?",0,0.9730422496795654
52865992,764,becketqin,2016-02-15T07:12:43Z,"right, we have already have successcount like check. the test hangs because we usually call flush() in main thread to ensure all the messages are sent. some callbacks won't fire if sender thread dies due to assertion failure, hence flush() blocks forever. i will instead use producer.close(timeout) in main thread so it does not wait forever for the callbacks.",0,0.979029655456543
52869635,764,becketqin,2016-02-15T08:16:10Z,"yes, so i subtracted the additional timestamp length.",0,0.9869280457496643
52922474,764,junrao,2016-02-15T17:00:51Z,"if the message format is tied to the inter-broker protocol, the first broker that upgrades its inter-broker protocol to 0.10.0 will start to have v1 messages in its log. since the rest of the brokers' inter-broker protocol is still before 0.10.0, they can only send v1 fetch request. therefore, the first broker has to convert v1 messages down to v0 in the fetch response. if we decouple the message format from inter-broker protocol, we can first keep message format to be v0. after every broker upgrades inter-broker protocol to 0.10.0 and starts using v2 fetch request, we then change message format to v1. at that point, there is no message format conversion needed.",0,0.9849147796630859
52962132,764,ijuma,2016-02-16T02:14:23Z,`if user` would read better as `if the user`.,0,0.9881501197814941
52962884,764,ijuma,2016-02-16T02:29:30Z,`overwritten by broker with broker local time when broker append` would read better as `overwritten by the broker with the broker local time when it appends`,0,0.987054705619812
52963204,764,ijuma,2016-02-16T02:35:41Z,"`in either of the cases above, the timestamp that has actually been used will be returned to the user in`",0,0.9860038161277771
53015522,764,ijuma,2016-02-16T14:19:28Z,"shouldn't these be called `no_timestamp_type`, `create_time` and `log_append_time` since this is java code? i personally prefer the scala convention (which is what we are using here), but it is inconsistent with all the java enums i looked at.",0,0.9674046039581299
53017909,764,ijuma,2016-02-16T14:36:37Z,this doesn't seem to be used at the moment.,0,0.8390977382659912
53018211,764,ijuma,2016-02-16T14:38:50Z,"sorry if this has been mentioned elsewhere, but why don't we reuse the java `timestamptype` instead of introducing a duplicate instance in scala code?",-1,0.9685578942298889
53018917,764,ijuma,2016-02-16T14:44:21Z,"why are we using an atomiclong here? this code doesn't have to be thread-safe, right (we are adding to an arraylist a few lines below with no locking for example)?",0,0.9831889867782593
53035417,764,ijuma,2016-02-16T16:27:18Z,"why we are using a linkedlist here? it rarely makes sense to use it, even the person who wrote it says so ([a link]",0,0.7467074394226074
53036739,764,ijuma,2016-02-16T16:35:11Z,maybe `arraydeque` would be better?,0,0.986393392086029
53040684,764,ijuma,2016-02-16T16:57:43Z,it would probably be good to mention that `inneriter` will always have at least one element (and hence why we can just call `next()` on it without calling `hasnext()` first).,0,0.9832422733306885
53040990,764,ijuma,2016-02-16T16:59:20Z,maybe reference `magic_value_v1` instead of hardcoding `1` here?,0,0.9886455535888672
53041472,764,bill-warshaw,2016-02-16T17:02:23Z,"how would you feel about adding a testing constructor for this class that matches the existing signature, and would just use dummy values for the timestamp and `timestamptype`? eliminating that constructor will break compilation for any unit tests that rely on building `consumerrecord`s",0,0.9851948618888855
53048549,764,ijuma,2016-02-16T17:47:32Z,case 1 and 2 are the same at the moment. we could fall-through from case 1 to case 2 instead of having the same statement twice.,0,0.9875446557998657
53056249,764,becketqin,2016-02-16T18:39:32Z,do you mean the unit tests in projects other than kafka?,0,0.9855125546455383
53056903,764,bill-warshaw,2016-02-16T18:44:02Z,"yes. it's a minor change to update anywhere these constructors are used in unit tests, but any test that instantiates a `consumerrecord` isn't going to compile as soon as a user upgrades past `0.9.0.0`. we've used the `` annotation in the past to denote certain constructors that are only there for unit-testing.",0,0.9881263971328735
53058002,764,becketqin,2016-02-16T18:50:05Z,that makes sense. originally client side and server side timestamptype have some different methods. and i was thinking to combine the java and scala timestamptype class when we migrate server from message to record. we can probably combine the two classes in this patch.,0,0.9789551496505737
53106467,764,becketqin,2016-02-17T00:54:53Z,"i am not sure if we should add the testing constructor for other projects. it is a little bit weird to have a testing constructor which never used by kafka but for some unknown external project. technically speaking consumerrecord should only be constructed by kafka, but not other projects. if we do so, arguably we should maintain the constructor backward compatibility for any public class, even though most of them are not supposed to be constructed by any user.",-1,0.9541425108909607
53110159,764,bill-warshaw,2016-02-17T01:39:29Z,"if `consumerrecord` is only intended to be instantiated by kafka, then i withdraw my comment. internal apis shouldn't be forced to remain backwards-compatible.",0,0.9773125648498535
53142209,764,ijuma,2016-02-17T09:58:29Z,"`consumerfetcherthread` and `simpleconsumer` still use this class. given that, are we sure that we don't need to add a mapping here?",0,0.987313449382782
53143828,764,ijuma,2016-02-17T10:13:32Z,would this read better as `messagetimestampmaxdifferencems`?,0,0.9887967109680176
53144348,764,ijuma,2016-02-17T10:18:06Z,should we be catching `apiexception` instead of individual cases like this?,0,0.9846034646034241
53202790,764,becketqin,2016-02-17T17:52:22Z,only produce will see this error code. so i think we are fine here.,0,0.9603079557418823
53203160,764,becketqin,2016-02-17T17:54:35Z,"i agree that would read better (in fact i used to use that name), but it seems we have `""*maxms""` for other configurations, so i just followed the convention.",0,0.9793745279312134
53204217,764,becketqin,2016-02-17T18:00:52Z,i don't have strong opinion on this. one benefit of having individual cases is that it is clear what kind of api exceptions are expected since not all api exceptions can be thrown from replica manager.,0,0.6942984461784363
53263334,764,junrao,2016-02-18T02:08:56Z,"this comment is a bit hard to understand. given the comments at the beginning, we probably don't need the comment here.",-1,0.916182279586792
53263338,764,junrao,2016-02-18T02:09:02Z,relative => inner,0,0.9825204014778137
53263354,764,junrao,2016-02-18T02:09:15Z,the way timestamp set is following => the way that timestamp is set is the following,0,0.9835045337677002
53263360,764,junrao,2016-02-18T02:09:21Z,is set => are set,0,0.9810221791267395
53263365,764,junrao,2016-02-18T02:09:26Z,following => the following,0,0.9772782921791077
53263370,764,junrao,2016-02-18T02:09:35Z,note => note; in a stream compressing way => in a streaming way,0,0.9535869359970093
53263375,764,junrao,2016-02-18T02:09:38Z,avoids => avoid,0,0.9718456268310547
53263382,764,junrao,2016-02-18T02:09:43Z,do we still need this comment?,0,0.9815558791160583
53263386,764,junrao,2016-02-18T02:09:50Z,it seems that minheadersize is the same as minmessageoverhead. could we consolidate them?,0,0.9879119992256165
53263400,764,junrao,2016-02-18T02:10:02Z,"would it be better to rename this to magicandlargesttimestamp()? also, the comment is outdated since we now return the magic as well.",0,0.9862015843391418
53263409,764,junrao,2016-02-18T02:10:07Z,could we use the constant variable instead of 0?,0,0.9875428676605225
53263420,764,junrao,2016-02-18T02:10:18Z,incorrect indentation. the original one is correct.,0,0.8913492560386658
53263431,764,junrao,2016-02-18T02:10:37Z,unused import here. could you check other classes too?,0,0.9880659580230713
53263446,764,junrao,2016-02-18T02:10:54Z,we probably shouldn't mention 0.10.0-iv0 since it's not intended for public usage.,0,0.9677116274833679
53263518,764,junrao,2016-02-18T02:11:50Z,"reworded the text a bit below. see if it's better. the maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message, if message.timestamp.type=createtime. a message will be rejected if the difference in timestamp exceeds this threshold. this configuration is ignored if message.timestamp.type=logappendtime.",0,0.9877001047134399
53263527,764,junrao,2016-02-18T02:11:58Z,"just to be consistent with what's in writeto, perhaps we should write the timestamp before key?",0,0.9877007007598877
53263537,764,junrao,2016-02-18T02:12:07Z,"to avoid duplicating code, could we pull line 237 to 245 into a private method and then reuse?",0,0.9881636500358582
53263541,764,junrao,2016-02-18T02:12:11Z,invalid => invalid; ditto below.,0,0.9650160074234009
53263556,764,junrao,2016-02-18T02:12:21Z,"message.format.version change is an optimization. so, it's not really required. we can probably just cover that in the section on performance impact.",0,0.9758034944534302
53263559,764,junrao,2016-02-18T02:12:25Z,is this any different from any other topic?,0,0.940314769744873
53263566,764,junrao,2016-02-18T02:12:33Z,"instead of using v1/v0 in the message format, it's probably easier to understand if we just use the api version.",0,0.9822774529457092
53263572,764,junrao,2016-02-18T02:12:40Z,"we can just say that ""for clients that are upgraded to 0.10.0.0, there is no performance impact.""",0,0.9856882095336914
53291250,764,ijuma,2016-02-18T09:44:46Z,fair enough.,0,0.908961832523346
53291541,764,ijuma,2016-02-18T09:47:25Z,my concern is that it's easy to miss new `apiexception` instances that could be thrown by the code above since we don't get help by the compiler. but we can consider handling this in a separate pr as you are maintaining the existing approach.,0,0.9017773270606995
53322688,764,ijuma,2016-02-18T14:48:18Z,"is there a reason why we don't pass the timestamp as a parameter to `analyzeandvalidatemessageset`? that would mean that `timestamp` could be a `val` instead of `var`. it's a straightforward change, but it would mean that we read `config.messagetimestamptype` outside the synchronized block. is that a problem?",0,0.9825992584228516
53342228,764,ijuma,2016-02-18T16:43:31Z,do we really need to mention the same thing so many times? it seems to me that it would be enough to mention once that message format 0 does not have a timestamp field and message format 1 does.,0,0.9731254577636719
53345876,764,ijuma,2016-02-18T17:05:16Z,"do we need this overload with timestamp and no timestamptype? there are only 3 usages in tests, i think i'd remove it.",0,0.9874011874198914
53383523,764,becketqin,2016-02-18T21:15:23Z,"if we do that, it seems possible to cause inconsistency order of message offset and timestamp. for example, message a comes and is stamped t1 by the broker, but before it is appended to the log, message b comes and is stamped t2 (t2 > t1) and gets appended to the log. after that, message a is appended. in this case, message a will have a smaller timestamp but a larger offset than message b, which is a bit confusing. we can put everything in the synchronized block, but it seems not worth doing if we only want to change a var to a val.",0,0.8423341512680054
53387576,764,becketqin,2016-02-18T21:44:34Z,"i am ok either way. as far as i understand, the purpose of the pre-existing constructor is to hide the payloadoffset and payloadsize from caller.",0,0.9796055555343628
53390466,764,ijuma,2016-02-18T22:06:34Z,"makes sense, thanks.",1,0.8964961767196655
53390818,764,ijuma,2016-02-18T22:09:44Z,"ok. since it was already there, better to handle the excessive use of constructor overloading separately.",0,0.9761911630630493
53413279,764,junrao,2016-02-19T01:51:17Z,can this be private?,0,0.9878947138786316
53413289,764,junrao,2016-02-19T01:51:25Z,the following properties => the following property,0,0.9808309674263
53413303,764,junrao,2016-02-19T01:51:33Z,message format 0.10.0 => the message format in 0.10.0,0,0.9855514764785767
53413305,764,junrao,2016-02-19T01:51:35Z,of format 0.10.0 to earlier format => of the format in 0.10.0 to an earlier format,0,0.986212968826294
53413325,764,junrao,2016-02-19T01:51:48Z,"could we add what the interface is changed from? also, def is scala specific. we just need to include the java interface.",0,0.9886072278022766
53413342,764,junrao,2016-02-19T01:52:02Z,indicate the client support quota => indicate that the client supports quota,0,0.9857248067855835
53413403,764,junrao,2016-02-19T01:53:09Z,reworded this a bit to the following. see if it's better. ditto in topiccommand. this configuration will be ignored if the value is on a version newer than that specified in inter.broker.protocol.version in the broker.,0,0.9786167740821838
53413412,764,junrao,2016-02-19T01:53:16Z,is the above addressed?,0,0.9855552911758423
53415057,764,becketqin,2016-02-19T02:18:05Z,it seems we cannot add scope modifier to a code block. compiler gives the following error: [code block] `verifyconvertedmessageset` itself seems private by nature and only accessible in `testmessageformatconversion`.,0,0.9740234017372131
53417265,764,becketqin,2016-02-19T02:50:09Z,"hi jun, this comment seems not accurate based on the current code. what we actually check is the message format version, not kafka version. for example, the current code will allow the message.format.version to be set to 0.9.0 even if the inter.broker.protocol.version is 0.8.2, because the underlying message.format.versions of those two kafka versions are the same. at some point i thought there was a use case for this, but i cannot think of any now. it is probably better to enforce the check as you described. i will make this change in the updated patch.",0,0.9370082020759583
1235169801,13870,dajac,2023-06-20T12:07:23Z,nit: could we prefix all those attributes with `genericgroup`?,0,0.989421010017395
1235170208,13870,dajac,2023-06-20T12:07:48Z,we can't use the same config both both the consumer and the generic group because we have two configs for each.,0,0.9634954929351807
1235171243,13870,dajac,2023-06-20T12:08:49Z,nit: we can remove this one as there is the same phrase in the javadoc.,0,0.9889150261878967
1235178394,13870,dajac,2023-06-20T12:15:13Z,i am not a fan of returning a `group` here because it means that the caller have to cast the returned value. is it possible to avoid it?,-1,0.9711384177207947
1235178804,13870,dajac,2023-06-20T12:15:34Z,should we move this to the request validation?,0,0.9868306517601013
1235179626,13870,dajac,2023-06-20T12:16:19Z,i would remove this because it will be outdated extremely quickly.,0,0.9397155046463013
1235180677,13870,dajac,2023-06-20T12:17:16Z,should we have a method helper to validate the request?,0,0.9863858222961426
1235188456,13870,dajac,2023-06-20T12:24:19Z,nit: would it make sense to update `plainprotocolset` to take `request.protocols()`?,0,0.9891895055770874
1235190243,13870,dajac,2023-06-20T12:25:52Z,"when the group is created to the first time, i think that we need to write a record to the log; the group could be reverted in the timeline hash map otherwise.",0,0.9877025485038757
1235202608,13870,dajac,2023-06-20T12:36:20Z,we need to discuss whether we want to start the heartbeat timer here or not. see [a link].,0,0.9816650748252869
1235206095,13870,dajac,2023-06-20T12:39:01Z,"do we still need `hassatisfiedheartbeat` in the new model? if the timeout expires, it seems to me that it means that the member has failed to heartbeat in time; the timer would have been reset otherwise.",0,0.9797383546829224
1235232078,13870,dajac,2023-06-20T12:59:58Z,i wonder if we should use a different timer for this case. have you considered it?,0,0.9155920743942261
1235241285,13870,dajac,2023-06-20T13:07:13Z,"instead of storing the initial rebalance timeout and the initial rebalance delay in the group, could we imagine passing them as arguments to `trycompleteinitialrebalanceelseschedule`? that could simplify the logic as everything would be self contain here.",0,0.9851797819137573
1235274474,13870,dajac,2023-06-20T13:31:31Z,what happens if the group instance id is an empty string?,0,0.9760164022445679
1235276378,13870,dajac,2023-06-20T13:32:56Z,i suppose that being here means that group instance id is null.,0,0.980156660079956
1235277768,13870,dajac,2023-06-20T13:33:58Z,i have seen this code in a few place. it would be great to avoid it if possible.,0,0.5541678071022034
1235310632,13870,dajac,2023-06-20T13:56:02Z,shouldn't we use `completablefuture ` and complete the future exceptionally with the exception corresponding to the error?,0,0.9808643460273743
1235497178,13870,jeffkbkim,2023-06-20T16:11:16Z,i think we should store generic groups separately. the added benefit here is that we wouldn't have to create a new record when a new group was created as you have mentioned in the comment below. wdyt?,0,0.9778377413749695
1235653740,13870,jeffkbkim,2023-06-20T18:24:23Z,i removed this; we have request validation in groupcoordinatorservice#joingroup. what do you think of having all request validation there?,0,0.9886378645896912
1235733198,13870,jeffkbkim,2023-06-20T19:26:09Z,"i don't think this fits well because we may have other records to append in this method. as mentioned above, i will store the generic groups in a separate hash map to prevent this from happening.",0,0.9670975208282471
1235734010,13870,jeffkbkim,2023-06-20T19:26:49Z,see [a link],0,0.9835211038589478
1235752587,13870,jeffkbkim,2023-06-20T19:46:36Z,"so that i understand: during completing rebalance, we schedule both pending sync (rebalance timeout) and heartbeats (session timeout). in practice, session timeout << rebalance timeout so heartbeats would expire and remove members. with cooperative rebalancing members should still be able to fetch records during completing rebalance phase. we want to extend the heartbeat here to rebalance timeout so that members are not removed by session timeout. is this correct? if so, i agree removing the heartbeat schedule sounds like the best approach since members are removed when pending sync expires anyways.",0,0.9425783753395081
1235808438,13870,jeffkbkim,2023-06-20T20:44:35Z,if the member is awaiting on a join/sync response then we can't remove the member on hb expiration right?,0,0.9856101870536804
1235813521,13870,jeffkbkim,2023-06-20T20:50:21Z,are you suggesting a different key? what would be the benefit?,0,0.9789430499076843
1235818207,13870,jeffkbkim,2023-06-20T20:54:59Z,initial rebalances don't have check and complete as try complete always returns false so this works. thanks,1,0.9731529951095581
1235822238,13870,jeffkbkim,2023-06-20T20:58:34Z,the existing protocol allows empty group instance ids for static member,0,0.9889096617698669
1235823024,13870,jeffkbkim,2023-06-20T20:58:57Z,"you're right, removed.",0,0.9714857935905457
1238417804,13870,dajac,2023-06-22T11:51:17Z,"i am not convinced. the downside is that it will be harder to guarantee to uniqueness of the group id. it also means that we would have to check both maps for all other operations (e.g. list, delete, etc.). i think that it would be better to keep them in a single map. for this particular case, we could just have two methods: `getormaybecreateconsumergroup` and `getormaybecreategenericgroup`.",0,0.8468470573425293
1238418966,13870,dajac,2023-06-22T11:52:26Z,i think that static validation could be done in the group coordinator service; however we have to keep the validation which depends on internal values in the state machine.,0,0.987736165523529
1238484735,13870,dajac,2023-06-22T12:52:04Z,"that's correct. however, it may be better to just cancel the previous one.",0,0.9848572015762329
1238491877,13870,dajac,2023-06-22T12:58:00Z,i think that the non-error case is actually incorrect based on the implementation in the runtime. the issue is that the future will be completed immediately after the records are written. this means that we would send the response before the record is committed. i think that the future should be completed only when the records are committed.,0,0.9775880575180054
1238494924,13870,dajac,2023-06-22T13:00:19Z,"what does happen when this exception is thrown? i mean, where is it handled?",0,0.9662342667579651
1238559395,13870,dajac,2023-06-22T13:48:16Z,did you consider using a switch here? it seems that it would fit nicely.,0,0.9764285683631897
1238565407,13870,dajac,2023-06-22T13:52:35Z,nit: should we have an method such as `hasassignment()` in member?,0,0.986971914768219
1238585947,13870,dajac,2023-06-22T14:06:54Z,this feels a bit like a hack. i was wondering if we could push that call to `completegenericgroupjoin(group)` into the `genericgroupjoinnewmember` and `genericgroupjoinexistingmember` paths instead of handling it here for all cases. is it something that you have considered?,-1,0.9654759168624878
1238591771,13870,dajac,2023-06-22T14:11:10Z,"this is correct. btw, if we remove it, i think that we need to ensure that the session timeout is cancelled when a member rejoins.",0,0.986855149269104
1238593470,13870,dajac,2023-06-22T14:12:26Z,"correct. however i think that the fundamental issues is that we do not cancel the session timeout while doing a rebalance. this is why we have this condition here. if we fix this, we may be able to remove it.",0,0.9681864976882935
1238594022,13870,dajac,2023-06-22T14:12:53Z,right. separation of concerns would be the benefit.,0,0.9494092464447021
1238626957,13870,dajac,2023-06-22T14:37:10Z,it seems that the condition was `group.is(empty)` in scala. what's the reason for changing it?,0,0.9802659153938293
1238627417,13870,dajac,2023-06-22T14:37:28Z,nit: extra empty line.,0,0.9629546403884888
1238630708,13870,dajac,2023-06-22T14:39:46Z,"actually, it seems that `completegenericgroupjoin` is already called in a few places on those paths.",0,0.9879085421562195
1238633046,13870,dajac,2023-06-22T14:41:05Z,nit: should we have an overload of `supportsprotocols` which takes `request.protocols()`?,0,0.9893788695335388
1238643069,13870,dajac,2023-06-22T14:48:13Z,nit: could we move this to the test then?,0,0.9857842326164246
1238647097,13870,dajac,2023-06-22T14:51:16Z,nit: let's remove this one as well.,0,0.981564462184906
1238724392,13870,dajac,2023-06-22T15:49:12Z,"one issue here is that if `generaterecordsandappendfuture` thrown an exception (e.g. due to a bug), the request will never be completed because the future is not available yet. if we reuse `coordinatorwriteevent`, we could subscribe to the future returned by it and complete the response when an exception is raised.",0,0.9799948334693909
1238725344,13870,dajac,2023-06-22T15:49:57Z,we probably need to convert some of the exceptions like i did for the consumer group heartbeat request.,0,0.9836508631706238
1239316537,13870,jeffkbkim,2023-06-23T04:48:54Z,are you referring to any lingering heartbeats at this point? i think we can just cancel them here right,0,0.9811338186264038
1239318379,13870,jeffkbkim,2023-06-23T04:53:31Z,"i think we can cancel the existing heartbeat when a member rejoins during a rebalance. this will still expire if the member does not rejoin which is what we want. also, moving the new member join timeout to a different key will help remove this `hassatisfiedheartbeat`. is that what you had in mind?",0,0.9824487566947937
1239320095,13870,jeffkbkim,2023-06-23T04:57:15Z,i expected that kafkaapis#handlejoingrouprequest will handle them. is that not the case?,0,0.9851847887039185
1240399005,13870,jeffkbkim,2023-06-23T21:09:13Z,"this is now further worsened with the new records on creating a group. the only ""non-hacky"" approach i can think of is just returning `list , record>` which the runtime would append & commit then complete in order. but this adds a lot of complexity for something we actually won't use in practice. the other approach (which i have implemented) is to ignore the result from `completegenericgroupjoin` when invoked from the join group path. this works because `completegenericgroupjoin` only produces records when a member expires. also, when a new group is created we don't have any other records to append. however, this still feels a bit hacky. not sure how to resolve this.",0,0.5122588276863098
1240415098,13870,jeffkbkim,2023-06-23T21:23:12Z,"i thought the ""initial"" rebalance only applied to when the group is first created from [a link] but according to [a link] it looks like we want this for an empty group as well so, i will revert this change. however, it's awkward because here we consider ""initial rebalance"" to be an empty group. but a different part of the code checks generation id == 0. maybe it's because we don't know the previous state from groupcoordinator#addmemberandrebalance: [code block] i think we need to revert the change and include `initialrebalancedelayms` to the genericgroup object and rely on that to check whether the group is undergoing an initial rebalance.",0,0.8886046409606934
1240441622,13870,jeffkbkim,2023-06-23T21:58:30Z,"i'm a bit confused, is the coordinator write operation future the result we wait for committing?",-1,0.8257025480270386
1243806647,13870,dajac,2023-06-27T14:04:01Z,"how about the following? we keep track whether the group was newly created in a boolean. when we get the result from those methods, we check if the group is new, if it is, we check if the result has at least one record. if it does not, we recreate it while adding an empty record for the group.",0,0.9862622022628784
1246778958,13870,dajac,2023-06-29T15:21:28Z,"yeah, it seems that the current implementation is inconsistent.",0,0.6974483728408813
1246964799,13870,CalvinConfluent,2023-06-29T18:24:56Z,the timer is not used yet. is it a place holder here?,0,0.9854428768157959
1246972433,13870,CalvinConfluent,2023-06-29T18:33:21Z,"i guess i missed some of the previous discussions, but why it is always either stable or empty when we load a group? does it mean the rebalancing process will be reverted if the coordinator fails?",0,0.8168886303901672
1246984793,13870,CalvinConfluent,2023-06-29T18:46:27Z,"the genericgroupjoinmember can returns a result, why don't we use the return value?",0,0.9869869351387024
1246995181,13870,CalvinConfluent,2023-06-29T18:56:21Z,do we need to handle the illegalstateexception(when member id is not known) and complete the responsefuture here?,0,0.9835249185562134
1247810650,13870,dajac,2023-06-30T12:31:40Z,"sorry, i was not clear. i meant that we need to port this [a link] here.",-1,0.9872035384178162
1247812716,13870,dajac,2023-06-30T12:34:06Z,"nit: i am not a fan of this validation. i wonder if we should just have two helpers: `isgroupidnotnull` and `isgroupidnotempty`. in this pr, we would only need `isgroupidnotempty`. what do you think?",-1,0.9718772768974304
1247814090,13870,dajac,2023-06-30T12:35:49Z,"i wonder if we need to handle the future returned by `schedulewriteoperation` as well. at minimum, we may want to react to errors. this could for instance happen if something goes wrong before the join group handling is event triggered.",0,0.9345040321350098
1247815228,13870,dajac,2023-06-30T12:37:09Z,nit: `completionfuture` or smth similar may be a better name here because we could have an operation without any records.,0,0.9882519841194153
1247815765,13870,dajac,2023-06-30T12:37:47Z,how about adding a boolean `replayrecords` to the coordinatorresult?,0,0.9884949326515198
1247816731,13870,dajac,2023-06-30T12:38:40Z,"i wonder if we should complete both future here. as `schedulewriteoperation` returns a future, it may be missed used otherwise. what do you think?",0,0.9345203638076782
1247817889,13870,dajac,2023-06-30T12:39:56Z,nit: could we revert this?,0,0.9639876484870911
1247820936,13870,dajac,2023-06-30T12:43:22Z,"`topicpartition` should also be required, i think.",0,0.9862319827079773
1247822722,13870,dajac,2023-06-30T12:45:23Z,i think that the group should be deleted in this case.,0,0.9823387265205383
1247825718,13870,dajac,2023-06-30T12:48:37Z,i wonder if we could avoid passing the version to this method by adding `-1` as the default value of `rebalancetimeout` in `groupmetadatavalue`. it seems that we could rely on this to decide here. another way that i was thinking about would be to pass the `record` to the replay method as it contains all the available information. have you considered this?,0,0.9143146276473999
1247826747,13870,dajac,2023-06-30T12:49:45Z,"we only write a record when the rebalance completes. this implies that the record is always empty or has members. as you pointed out, a failure happening before the rebalance complete is lost.",0,0.9529162049293518
1247831310,13870,dajac,2023-06-30T12:54:40Z,have you considered checking if the group exists in the map instead of adding this field? using a field like this has the disadvantage that we must ensure that it is set to false. i think that your implementation already misses it.,0,0.9557456374168396
1247837102,13870,dajac,2023-06-30T13:00:46Z,don't we need to fail the future if the write fails? or is it done somewhere else?,0,0.9613608717918396
1247839533,13870,dajac,2023-06-30T13:03:09Z,i am not satisfied with this logic here. i think that other folks won't understand this... we need to come up with a better way. i will think about it. i don't recall if i already asked this but would it be possible to push `completegenericgroupjoin` into `genericgroupjoinnewmember` and `genericgroupjoinexistingmember` instead of having it here?,-1,0.9626320600509644
1247843963,13870,dajac,2023-06-30T13:07:41Z,"hum... those exceptions will be caught by the `coordinatorwriteevent` and used to complete the future there. so, i suppose that they will be propagated to the api layer via this mechanism. do i get this right?",0,0.7930262088775635
1247846953,13870,dajac,2023-06-30T13:10:13Z,could we remove this? `genericgroupnewmemberjointimeoutms` is very likely passed to this object by the test itself so i am not sure to understand why we need to expose it to the test. is there a reason?,0,0.873919665813446
1253477738,13870,jeffkbkim,2023-07-05T18:25:13Z,"i don't think this is the right place; we need to add the logic inside group metadata manager. i have done so in the sync pr. the reason is that for generic group apis, the append future is what we want the logic for when handling log append/commit errors. whereas for the new protocol, the consumer group heartbeat waits to return the results from the append/commit.",0,0.9652077555656433
1253484339,13870,jeffkbkim,2023-07-05T18:32:34Z,i'll remove this for now and add it back if we decide to pass it in later.,0,0.984038770198822
1253487385,13870,jeffkbkim,2023-07-05T18:36:08Z,the approach is hacky. will be thinking of a different approach to resolve this,-1,0.9222529530525208
1253522689,13870,jeffkbkim,2023-07-05T19:11:59Z,"i will take your suggestion for this pr. however, it does make more sense to have the logic in one place instead of using isgroupidnotnull/isgroupidnotempty based on the request.",0,0.984351396560669
1253525703,13870,jeffkbkim,2023-07-05T19:15:48Z,this is only used when records are generated (and need to be appended to the log) so i think append future makes more sense. `completionfuture` will be confusing alongside coordinator event's `future` field. wdyt?,0,0.9842012524604797
1253814655,13870,jeffkbkim,2023-07-06T01:27:38Z,for 1) doesn't it require a bump in the group metadata value version to add the default value? 2) i don't see much value in this and it feels more different to handle it this way compared to other record types in replicatedgroupcoordinator#replay(record),0,0.9636751413345337
1253817939,13870,jeffkbkim,2023-07-06T01:33:42Z,will revisit this after refactoring the coordinatorresult return type / generate multiple records discussion. the reason that a field was set is because where we add the group to `groups` (and initialize the append future) and where we set it as a return type (l1265) are at different places. once the group is added we can't check via groups.get(groupid).,0,0.9873184561729431
1253948284,13870,jeffkbkim,2023-07-06T05:26:40Z,the write event will catch the exception and complete the event's future. i added a handler to groupcoordinatorservice.java for these unexpected exceptions.,0,0.9885713458061218
1253948390,13870,jeffkbkim,2023-07-06T05:26:50Z,added a previousstate to genericgroup. we will rely on this instead to confirm that a group is undergoing an initial rebalance (previous state == empty),0,0.9876266121864319
1253948479,13870,jeffkbkim,2023-07-06T05:27:00Z,"yeah, i will log an error for this",0,0.9807443022727966
1254577233,13870,dajac,2023-07-06T15:07:30Z,i think that we can remove this and `metadataimage` as [a link] was merged.,0,0.9881889820098877
1254579000,13870,dajac,2023-07-06T15:08:56Z,why do we only handle `illegalstateexception` here? why if we get an unexpected npe for instance.,0,0.9008775949478149
1254579343,13870,dajac,2023-07-06T15:09:12Z,nit: this could be static.,0,0.9882864356040955
1254580740,13870,dajac,2023-07-06T15:10:16Z,nit: should we move those two back to where they where?,0,0.9662965536117554
1254582473,13870,dajac,2023-07-06T15:11:39Z,could we move this one back to where it was? it should stay together with the other `withconsumergroup*` methods.,0,0.9872583746910095
1254582995,13870,dajac,2023-07-06T15:12:04Z,why did we move this one?,0,0.93467116355896
1254584209,13870,dajac,2023-07-06T15:13:07Z,nit: empty line could be removed.,0,0.9837834239006042
1254584535,13870,dajac,2023-07-06T15:13:21Z,nit: should we revert this change?,0,0.9512226581573486
1254584801,13870,dajac,2023-07-06T15:13:33Z,nit: should we revert this change?,0,0.9512226581573486
1254585208,13870,dajac,2023-07-06T15:13:52Z,nit: should we revert this change?,0,0.9512226581573486
1254585768,13870,dajac,2023-07-06T15:14:19Z,nit: should we revert this change?,0,0.9512226581573486
1254587698,13870,dajac,2023-07-06T15:15:51Z,1) good question. the schema remains the same so it should be ok. it only adds a default value to the field.,1,0.9080381393432617
1254612652,13870,dajac,2023-07-06T15:36:23Z,"i am not sure to follow. it seems to me that you could have a local boolean to track this. for instance, before calling `getormaybecreategenericgroup`, you could initialise a variable `groupexists` by checking the map.",0,0.9504061937332153
1254999681,13870,jeffkbkim,2023-07-06T22:53:31Z,"i misunderstood, moved to using a local variable",-1,0.5035062432289124
1255794837,13870,dajac,2023-07-07T13:05:30Z,would it make sense to move this block into the `if (isnewgroup && result == empty_result)`?,0,0.9876809120178223
1255797868,13870,dajac,2023-07-07T13:08:02Z,remember this [a link]? don't we need to convert the exception here as well? this is why i was suggesting to do it in the service to ensure that we do it in all cases.,0,0.9865657687187195
1255798698,13870,dajac,2023-07-07T13:08:41Z,nit: javadoc?,0,0.9874899983406067
1255799314,13870,dajac,2023-07-07T13:09:08Z,nit: empty line could be removed.,0,0.9837834239006042
1255799771,13870,dajac,2023-07-07T13:09:29Z,nit: empty line.,0,0.8843977451324463
1255800519,13870,dajac,2023-07-07T13:10:02Z,nit: empty line.,0,0.8843977451324463
1255803548,13870,dajac,2023-07-07T13:12:27Z,nit: incomplete javadoc.,0,0.9198463559150696
1255807406,13870,dajac,2023-07-07T13:15:14Z,nit: `containskey`?,0,0.9879432320594788
1255809962,13870,dajac,2023-07-07T13:17:08Z,nit: empty line.,0,0.8843977451324463
1255812336,13870,dajac,2023-07-07T13:18:48Z,nit: do we need this as all the states are covered?,0,0.9844741821289062
1255826174,13870,dajac,2023-07-07T13:28:59Z,nit: should we inline this condition and move the comment within the branch?,0,0.9884763956069946
1255827611,13870,dajac,2023-07-07T13:30:02Z,nit: should we name this variable `newmember`?,0,0.9889779686927795
1255828754,13870,dajac,2023-07-07T13:30:54Z,nit: this could be inlined.,0,0.9874518513679504
1255828976,13870,dajac,2023-07-07T13:31:03Z,nit: empty line.,0,0.8843977451324463
1255830986,13870,dajac,2023-07-07T13:32:33Z,nit: how about using: `.setmembers(isleader ? group.currentgenericgroupmembers() : collections.emptylist())`?,0,0.9879090189933777
1255832177,13870,dajac,2023-07-07T13:33:23Z,nit: i think that the error code is zero by default so we don't have to set it.,0,0.9809468388557434
1255832458,13870,dajac,2023-07-07T13:33:35Z,nit: empty line.,0,0.8843977451324463
1255833047,13870,dajac,2023-07-07T13:34:01Z,nit: empty line.,0,0.8843977451324463
1255833259,13870,dajac,2023-07-07T13:34:11Z,nit: ditto about error code.,-1,0.9093214869499207
1255833655,13870,dajac,2023-07-07T13:34:27Z,nit: empty line.,0,0.8843977451324463
1255836858,13870,dajac,2023-07-07T13:36:43Z,nit: empty line.,0,0.8843977451324463
1255838176,13870,dajac,2023-07-07T13:37:41Z,nit: the code style is a bit inconsistent between this line and l2526. i don't have a preference but it would be great if we could use the same format everywhere.,0,0.8433465361595154
1255839487,13870,dajac,2023-07-07T13:38:39Z,i think that we can remove those. it is clear that we do nothing for this state if it is not listed before. there are a few other cases.,0,0.9757688641548157
1255840000,13870,dajac,2023-07-07T13:39:00Z,is this used anywhere?,0,0.9868593215942383
1255849529,13870,dajac,2023-07-07T13:45:55Z,nit: empty line.,0,0.8843977451324463
1255851195,13870,dajac,2023-07-07T13:46:55Z,nit: empty line.,0,0.8843977451324463
1255863985,13870,dajac,2023-07-07T13:56:07Z,we could inline this as suggested earlier.,0,0.9866465330123901
1255864318,13870,dajac,2023-07-07T13:56:20Z,we can omit setting the error code.,0,0.96772301197052
1255865580,13870,dajac,2023-07-07T13:57:08Z,ditto.,0,0.859873354434967
1255868223,13870,dajac,2023-07-07T13:58:55Z,we need to update the javadoc here. i also wonder if we could find a better name now as it may also complete the join phase.,0,0.9153063893318176
1255878155,13870,dajac,2023-07-07T14:05:34Z,nit: we usually use `maybe`. i understand that this comes from the old purgatories but it may be better to use the correct naming convention.,0,0.9829468727111816
1255881371,13870,dajac,2023-07-07T14:07:59Z,nit: empty line.,0,0.8843977451324463
1255883963,13870,dajac,2023-07-07T14:09:59Z,nit: you can replace `{}-{}` with `{}` and directly pass the topicpartition.,0,0.9887617230415344
1255885261,13870,dajac,2023-07-07T14:10:54Z,nit: package private for testing.,0,0.987280547618866
1255886494,13870,dajac,2023-07-07T14:11:43Z,nit: empty line.,0,0.8843977451324463
1255889149,13870,dajac,2023-07-07T14:13:25Z,nit: empty line.,0,0.8843977451324463
1255892012,13870,dajac,2023-07-07T14:15:01Z,why do we need a copy here?,0,0.9622910022735596
1255894010,13870,dajac,2023-07-07T14:16:12Z,could we expand this comment a little?,0,0.9836527109146118
1255894583,13870,dajac,2023-07-07T14:16:34Z,we can remove this now.,0,0.9855049252510071
1256037213,13870,jeffkbkim,2023-07-07T15:48:20Z,which illegal state exception are you referring to?,0,0.8704423904418945
1256038506,13870,jeffkbkim,2023-07-07T15:49:17Z,"as discussed offline, we will complete both futures. the append future will be completed first and the event future will complete the join response if it's not already completed.",0,0.9852163791656494
1256056130,13870,jeffkbkim,2023-07-07T16:02:32Z,updated to all errors.,0,0.9699582457542419
1256069184,13870,jeffkbkim,2023-07-07T16:08:58Z,reverted the ordering,0,0.9805397987365723
1256110776,13870,jeffkbkim,2023-07-07T16:37:10Z,the issue is that the records need to be generated while the group is empty. after performing `genericgroupjoinnewmember()` the group will have added the member metadata. the existing protocol only allows records for empty groups or groups that have a defined protocol. this only applies to join group requests with `requireknownmemberid = false` or group instance id.,0,0.9831933975219727
1256152143,13870,jeffkbkim,2023-07-07T17:10:29Z,the main concern i had was completegenericgroupjoin() can be invoked by the timer which would miss this conversion but i guess it's not really an issue.,0,0.9754528999328613
1256157423,13870,jeffkbkim,2023-07-07T17:14:57Z,i added this in case we add a new state in the future. should i remove it?,0,0.9857314229011536
1256163265,13870,jeffkbkim,2023-07-07T17:19:38Z,isn't it more readable to keep it?,0,0.9680088758468628
1256180440,13870,jeffkbkim,2023-07-07T17:33:38Z,in `groupmetadatamanager#expirependingsync()` we remove members from the set while iterating,0,0.9876353144645691
1258225411,13870,dajac,2023-07-10T12:59:31Z,i wonder if we should remove this because it will log all errors now.,0,0.689180314540863
1258226163,13870,dajac,2023-07-10T13:00:04Z,i am a bit confused here. don't we need to apply this conversion to `responsefuture` as well?,-1,0.943250298500061
1258226528,13870,dajac,2023-07-10T13:00:20Z,you can remove this one because it can't happen now.,0,0.965605616569519
1258226646,13870,dajac,2023-07-10T13:00:26Z,ditto.,0,0.859873354434967
1258228530,13870,dajac,2023-07-10T13:01:52Z,"it may be better to inline this code because the handling could be different depending on the request type. if i remember correctly, it is slightly different for offset commits for instance.",0,0.9873866438865662
1258228818,13870,dajac,2023-07-10T13:02:07Z,could we bring this back?,0,0.9822591543197632
1258229353,13870,dajac,2023-07-10T13:02:32Z,nit: should we add `throws groupidnotfoundexception`?,0,0.9879859089851379
1258230722,13870,dajac,2023-07-10T13:03:38Z,i think that we should rather add this to the `onloaded` method rather than here. the issue is that it will also log all the non-compacted records and that will be misleading.,0,0.8811678886413574
1258231101,13870,dajac,2023-07-10T13:03:55Z,nit: `data structure`?,0,0.9873184561729431
1258231284,13870,dajac,2023-07-10T13:04:03Z,nit: remove empty line.,0,0.9759849309921265
1258232766,13870,dajac,2023-07-10T13:05:13Z,"for my understanding, we don't fail the future here because the event future will do it. am i correct?",0,0.9141645431518555
1258235016,13870,dajac,2023-07-10T13:06:59Z,i see. i wonder if we could have a `newgroupemptymetadatarecord` which generate an empty record for the group in this case to avoid this issue. would this work? i am asking because i think that centralising would simplify the code.,0,0.9667306542396545
1258236219,13870,dajac,2023-07-10T13:07:54Z,nit: `maybe...`?,0,0.8232406377792358
1258269899,13870,dajac,2023-07-10T13:30:30Z,nit: i was considering whether we should have an helper in the joinrequest class for this. it could be something like `joinrequest#requireknownmemberid(short version)`. that advantage is that it would centralize all the version handling in one place. we could do the same for the other similar cases. what do you think?,0,0.9721052050590515
1258278071,13870,dajac,2023-07-10T13:35:54Z,"we can keep it, i suppose.",0,0.9755903482437134
1258280008,13870,dajac,2023-07-10T13:37:15Z,"nit: could we expand this error a little? it would be great if it could capture that it failed to update the metadata for a static member, etc.",0,0.9524194002151489
1258280313,13870,dajac,2023-07-10T13:37:27Z,i would remove them.,0,0.9718248844146729
1258281079,13870,dajac,2023-07-10T13:37:58Z,"nit: `"" + ""` the `+` in this case is not needed.",0,0.9851120114326477
1258287486,13870,dajac,2023-07-10T13:42:02Z,"i just noticed that whenever we use `joinreason`, we also have the `joingrouprequestdata`. how about adding a helper in `joinrequest` class to get the reason from `joingrouprequestdata`? then, we don't have to pass it anymore to all the methods and we can remove the logic to compute it in `genericgroupjoin`. what do you think?",0,0.9808535575866699
1258291357,13870,dajac,2023-07-10T13:44:19Z,nit: `replayrecords`?,0,0.9854505062103271
1258295996,13870,dajac,2023-07-10T13:47:02Z,i was wondering if the following is simpler: [code block] then [code block] i leave it up to you.,0,0.9832241535186768
1258313403,13870,dajac,2023-07-10T13:57:05Z,why is this false?,0,0.7986961007118225
1258314600,13870,dajac,2023-07-10T13:57:49Z,it may be better to validate the full response here.,0,0.9837982058525085
1258314933,13870,dajac,2023-07-10T13:58:02Z,do we need to add tests for the errors convertion?,0,0.9824455976486206
1258319481,13870,dajac,2023-07-10T14:01:24Z,should we revert this?,0,0.9289711117744446
1258320244,13870,dajac,2023-07-10T14:02:02Z,could we revert this?,0,0.9640122652053833
1258320551,13870,dajac,2023-07-10T14:02:16Z,why are we changing this?,0,0.889305055141449
1258320790,13870,dajac,2023-07-10T14:02:26Z,nit: empty line.,0,0.8843977451324463
1258356121,13870,dajac,2023-07-10T14:29:27Z,this feels weird.... you pass the expected result and you alter it here. i think that it would be better to separate concerns and to return records and future to the caller and to let it do the validation.,-1,0.9843584299087524
1258356713,13870,dajac,2023-07-10T14:29:54Z,"do we need this? if we do, we should replace `e.printstacktrace();`.",0,0.9871689081192017
1258356890,13870,dajac,2023-07-10T14:30:03Z,ditto.,0,0.859873354434967
1258362905,13870,dajac,2023-07-10T14:34:12Z,is this needed? i would have thought that the group should have been created by the first request.,0,0.9860668778419495
1258367695,13870,dajac,2023-07-10T14:37:48Z,nit: empty line.,0,0.8843977451324463
1258368278,13870,dajac,2023-07-10T14:38:12Z,is this needed as well?,0,0.9858583807945251
1258375164,13870,dajac,2023-07-10T14:43:18Z,"why do we need to handle the first request differently? is it because it may generate a record? if so, i would not do this in every tests but only in one test focused on this.",0,0.9584877490997314
1258375867,13870,dajac,2023-07-10T14:43:48Z,"nit: `intstream.range(0, groupmaxsize + 1)` that you just used above is pretty nice. i wonder if we could use it here as well.",0,0.6296588182449341
1258376361,13870,dajac,2023-07-10T14:44:07Z,do we need this?,0,0.983482837677002
1258378853,13870,dajac,2023-07-10T14:45:53Z,ditto.,0,0.859873354434967
1258379838,13870,dajac,2023-07-10T14:46:31Z,nit: you should try to use the stream api more often.,0,0.9871034026145935
1258387036,13870,dajac,2023-07-10T14:51:10Z,"in scala, we had `unknown_member_id` here. is the change expected?",0,0.9891723394393921
1258391017,13870,dajac,2023-07-10T14:53:33Z,"in scala, this test runs with a dynamic member and a static member. we don't do the static part here. why?",0,0.9484565854072571
1258394371,13870,dajac,2023-07-10T14:55:54Z,we were asserting the leader here.,0,0.9804583787918091
1258396521,13870,dajac,2023-07-10T14:57:25Z,there is a `+ 1` in scala. don't we need it here?,0,0.9874659180641174
1258398177,13870,dajac,2023-07-10T14:58:35Z,nit: you can do: `group.allmembers().iterator().next()`.,0,0.9826635718345642
1258400111,13870,dajac,2023-07-10T15:00:00Z,there is a + 1 in scala.,0,0.9840561151504517
1258406471,13870,dajac,2023-07-10T15:04:08Z,there is `unknown_member_id` in scala?,0,0.9878879189491272
1258410034,13870,dajac,2023-07-10T15:06:24Z,is this a new test?,0,0.980134904384613
1258924230,13870,jeffkbkim,2023-07-10T21:17:10Z,this would log all errors while appending/committing and if `generaterecordsandresponse` throws an unexpected exception. shouldn't we log them? it doesn't seem like we do for `consumergroupheartbeat()` -- maybe just filter out the coordinator not available / not coordinator error codes?,0,0.9796842336654663
1258933631,13870,jeffkbkim,2023-07-10T21:30:02Z,"the responsefuture if completed inside genericgroupjoin will have an error code corresponding to the join group business logic. basically, we have already completed with the appropriate error if the response future is already completed at this line. the append future error is from the append/commit process which needs to be converted if we complete the response error here.",0,0.9875854253768921
1258934915,13870,jeffkbkim,2023-07-10T21:31:46Z,where should i look to confirm/learn this?,0,0.9753658771514893
1258937169,13870,jeffkbkim,2023-07-10T21:35:02Z,"confirmed that `storegroup` and `storeoffsets` have different handling. this will still be shared amongst join/sync/leave group, so i'll rename this to `appendgroupmetadataerrortoresponseerror`, wdyt?",0,0.9882281422615051
1258999406,13870,jeffkbkim,2023-07-10T23:18:33Z,is your suggestion to iterate through all groups & members and log each member after loading a partition is complete?,0,0.9883221983909607
1259002211,13870,jeffkbkim,2023-07-10T23:23:59Z,that's correct,0,0.9789699912071228
1259029305,13870,jeffkbkim,2023-07-11T00:24:18Z,great suggestion. thanks,1,0.9889129996299744
1259030830,13870,jeffkbkim,2023-07-11T00:28:01Z,a successful join group request will store the response future into the member's `awaitingjoinfuture` (could also complete if the join phase completes),0,0.9860548377037048
1259040832,13870,jeffkbkim,2023-07-11T00:43:14Z,we get illegal state exception if it's not initialized and since it doesn't affect the old protocol i thought it best to initialize it here.,0,0.9519701600074768
1259047855,13870,jeffkbkim,2023-07-11T00:53:11Z,"this is not to create a new group (note the `createifnotexists=false` argument) but to retrieve the group to do more validations such as group state, generation id, group size, etc. added a helper method `genericgroup()` to simplify the calls.",0,0.9891890287399292
1259049772,13870,jeffkbkim,2023-07-11T00:55:49Z,"for all tests, we always generate a new record. some tests hide this as it's called in `groupmetadatamanagercontext#joingenericgroupasdynamicmember()`. maybe we can simplify this and just manually create an empty group for all tests except 1 where we test the new record. wdyt?",0,0.9864948987960815
1259054321,13870,jeffkbkim,2023-07-11T01:01:57Z,addressed in above comment.,0,0.9842442870140076
1259059291,13870,jeffkbkim,2023-07-11T01:08:34Z,"for all places i use the old for each / for loops, there is an error `variable used in lambda expression should be final or effectively final` because i reuse variables (mainly joingrouprequestdata & responsefutures). i can use new variables instead, would that be better?",0,0.9863523244857788
1259062674,13870,jeffkbkim,2023-07-11T01:13:15Z,i was following the new protocol as it made more sense but i have changed to reflect the old behavior.,0,0.9498337507247925
1259095013,13870,jeffkbkim,2023-07-11T02:11:36Z,thanks for the catch. will add it.,1,0.6729753017425537
1259096806,13870,jeffkbkim,2023-07-11T02:14:34Z,there's a +1 on all advance clocks in scala. i haven't actually looked but assumed that it's in place due to how the purgatory works. the java timer implementation does not require a +1,0,0.9806078672409058
1259097546,13870,jeffkbkim,2023-07-11T02:16:06Z,have replied to a thread above,0,0.9842236638069153
1259098122,13870,jeffkbkim,2023-07-11T02:17:16Z,related to when a group is not found. have reverted and updated the error code,0,0.964638888835907
1259098972,13870,jeffkbkim,2023-07-11T02:19:19Z,"yes, that's correct.",0,0.9735580086708069
1259103526,13870,jeffkbkim,2023-07-11T02:28:15Z,simplified the code a bunch. thanks for the suggestion!,1,0.9785451889038086
1259115771,13870,jeffkbkim,2023-07-11T02:53:23Z,"i'll think a bit more on this as it will require a large change in this class. one of the reasons i had it like this is that we mostly care about the responsefuture in the tests and wanted to hide the record/append future validations. the timer could also produce records which require setting things in advance. i agree it is unclean, i'll address this in the next commit.",0,0.9076195955276489
1259765086,13870,dajac,2023-07-11T13:46:46Z,yes. i would actually create a special test to validate this case and simplify all the others.,0,0.9820360541343689
1259767721,13870,dajac,2023-07-11T13:48:47Z,nit: empty line.,0,0.8843977451324463
1259774315,13870,dajac,2023-07-11T13:53:31Z,should we move `genericgroup` to the context?,0,0.9866614937782288
1259776117,13870,dajac,2023-07-11T13:54:42Z,nit: empty line.,0,0.8843977451324463
1259776394,13870,dajac,2023-07-11T13:54:53Z,nit: empty line.,0,0.8843977451324463
1259779633,13870,dajac,2023-07-11T13:57:09Z,i find the helpers a bit confusing. it is not clear what's the difference between `joingenericgroup` and `sendgenericgroupjoin` for instance. is it possible to simplify them?,-1,0.8653128147125244
1259789131,13870,dajac,2023-07-11T14:03:57Z,how do end up in this state here? is there some code to advance the timer to complete the prepare phase?,0,0.980908989906311
1259793958,13870,dajac,2023-07-11T14:07:28Z,this is really surprising. `verify*` suggests that this method only verifies something but it also has side effects. i think that this should rather be done in the context like i did for the new protocol.,0,0.6968194246292114
1259795334,13870,dajac,2023-07-11T14:08:23Z,we need to align on this one as i also have an implementation [a link]. they look pretty close but they are different.,0,0.9468933939933777
1259836068,13870,dajac,2023-07-11T14:35:58Z,do we need to add a test for this one?,0,0.9789541363716125
1260282790,13870,jeffkbkim,2023-07-11T21:06:25Z,`sendgenericgroup...` methods send the request and return the future. `joingenericgroup...` methods invoke `sendgenericgroup` methods then advance the timer to move the group to completing rebalance state.,0,0.9887014627456665
1260298077,13870,jeffkbkim,2023-07-11T21:24:18Z,"yeah, i noticed. i don't mind using the other implementation. looks like java's priority queue does arbitrary ordering for the same priority so they should have the same behavior",0,0.7456019520759583
1260497268,13870,jeffkbkim,2023-07-12T02:39:33Z,"with the latest changes, i renamed `joingenericgroup...` to ``joingenericgroupasdynamicmemberandcompletejoin` and `joingenericgroupandcompletejoin` to make it more explicit. let me know if this is more readable.",0,0.9844873547554016
1260497352,13870,jeffkbkim,2023-07-12T02:39:42Z,replied to comment below.,0,0.9797008037567139
1260500922,13870,jeffkbkim,2023-07-12T02:46:27Z,"removed this method, and now individual tests do the validation. one exception is for timer operation expirations - as the majority of the cases will not result in any records, i have done the validation inside mockcoordinatortimer.",0,0.988018274307251
1263424766,13870,dajac,2023-07-14T07:56:38Z,"yeah, i think that it depends on what we mean by unexpected. i would remove it for now given that we also log something when the append future fails. we can always bring it back later if needed.",0,0.9821328520774841
1263429592,13870,dajac,2023-07-14T08:01:29Z,that makes sense.,0,0.9674917459487915
1263430125,13870,dajac,2023-07-14T08:02:02Z,that seems reasonable. we can see later if we could also share this logic with the consumer group heartbeat handling.,0,0.972254753112793
1263432212,13870,dajac,2023-07-14T08:04:12Z,extremely small nit: should you move `topicpartition` to the top? this is a common attribute.,0,0.975825309753418
1263432742,13870,dajac,2023-07-14T08:04:46Z,nit: could you also move this one to the top of the attributes?,0,0.9881658554077148
1263435000,13870,dajac,2023-07-14T08:07:27Z,"nit: i was wondering whether it would make sense to move this to `coordinatorresult`. we could have a static public constant called `empty`. then, we could use `coordinatorresult.empty` in the code. this is a pattern that we already use in a few other places. what do you think?",0,0.9743221998214722
1263435600,13870,dajac,2023-07-14T08:08:05Z,nit: could we revert this change?,0,0.9760466814041138
1263436098,13870,dajac,2023-07-14T08:08:37Z,nit: add javadoc for unknownmemberidexception.,0,0.989312469959259
1263437064,13870,dajac,2023-07-14T08:09:38Z,nit: there is a constructor which does not take the response. we could use it and remove `null` here. there are a few other cases. i won't mention them again.,0,0.9851433634757996
1263437658,13870,dajac,2023-07-14T08:10:17Z,nit: the format of the javadoc in is incorrect here.,0,0.911678671836853
1263439020,13870,dajac,2023-07-14T08:11:42Z,correct. i think that you saw that in my other pr. the issue with logging here is that it will log state metadata as well and we don't want this.,0,0.9283624887466431
1263441311,13870,dajac,2023-07-14T08:14:13Z,is this one covered by a unit test?,0,0.9828906655311584
1263443960,13870,dajac,2023-07-14T08:16:52Z,i was wondering if it would be better to complete the future directly here as well in order to be consistent. i think that you did this in the sync handling if i understood you correctly. what do you think?,0,0.9680421352386475
1263446381,13870,dajac,2023-07-14T08:19:16Z,"note: we will have to also verify the number of member after the group is loaded, i think. this is something for another pr but to keep in mind.",0,0.9710912704467773
1263447316,13870,dajac,2023-07-14T08:20:21Z,nit: could we prefix this one and the two others with `genericgroup`?,0,0.9888188242912292
1263450237,13870,dajac,2023-07-14T08:22:52Z,would it make sense to make the copy on the other side? it is a bit weird to anticipate this here because we don't do this for other accessors. i am usually tempted to return unmodifiable collections in the case to prevent this kind of issue.,-1,0.9733573794364929
1263452425,13870,dajac,2023-07-14T08:25:00Z,nit: `testjoingroupappend...`?,0,0.9815232157707214
1263454213,13870,dajac,2023-07-14T08:26:50Z,nit: could we move this next to the other final private attributes? could we also invest private final to be consistent with the others?,0,0.98870450258255
1263454828,13870,dajac,2023-07-14T08:27:31Z,nit: could we move this one back to its original place?,0,0.9805764555931091
1263458200,13870,dajac,2023-07-14T08:30:58Z,"nit: what the reason for this? if you don't catch it, the test will also fail.",0,0.6649163961410522
1263459890,13870,dajac,2023-07-14T08:32:34Z,nit: let's revert this.,0,0.840391993522644
1263459980,13870,dajac,2023-07-14T08:32:39Z,nit: let's revert this.,0,0.840391993522644
1263460377,13870,dajac,2023-07-14T08:33:01Z,nit: `null` could be removed.,0,0.9836868643760681
1263461288,13870,dajac,2023-07-14T08:33:57Z,nit: `null` could be removed.,0,0.9836868643760681
1263463518,13870,dajac,2023-07-14T08:36:11Z,"this catch is a bit suspicious here. i suppose that it would also catch the error thrown by `assertequals`, no?",0,0.6708056926727295
1263465299,13870,dajac,2023-07-14T08:37:56Z,"nit: while we are here, would it make to normalize the name of all tests starting with `should`? they should ideally start with `test...` like the others.",0,0.9844080805778503
1263471443,13870,dajac,2023-07-14T08:44:23Z,"it seems based on the usages of this method that only one timeouts is expected all the time. should we enforce it as well? more generally, i was wondering if having a `assertemptytimeout` helper method and using `assertemptytimeout(context.sleep(...))` would have a better separation of concerns. i leave this up to you.",0,0.9705637693405151
1263905173,13870,jeffkbkim,2023-07-14T16:11:41Z,that forces the coordinatorresult class to become non-generic which i don't think we want.,0,0.9673125743865967
1263922655,13870,jeffkbkim,2023-07-14T16:30:21Z,then do you think we can move `appendgroupmetadataerrortoresponseerror` back to groupmetadatamanager?,0,0.9885956645011902
1263925546,13870,jeffkbkim,2023-07-14T16:33:50Z,"to confirm, you're saying we should call `acceptjoiningmember` while loading members?",0,0.9865022897720337
1264075041,13870,jeffkbkim,2023-07-14T19:22:59Z,will keep it as assertemptyresult as the timeout is not empty (can be) but we want to assert that the coordinator result is.,0,0.9877321720123291
1264953365,13870,dajac,2023-07-17T07:04:25Z,ah.. did not think about that.,-1,0.7855980396270752
1264954924,13870,dajac,2023-07-17T07:06:34Z,"yeah, possibly.",0,0.971184253692627
1264955867,13870,dajac,2023-07-17T07:07:49Z,no. i think that the current coordinator triggers a rebalance if the number of members is higher than the max when a group is loaded.,0,0.9831531643867493
1264961072,13870,dajac,2023-07-17T07:13:31Z,do we really need to keep the try..catch?,0,0.9677760004997253
1264962406,13870,dajac,2023-07-17T07:14:49Z,nit: `assertnooremptyresult`?,0,0.9863421320915222
1264964347,13870,dajac,2023-07-17T07:17:13Z,this request timeout was coming from the delayed produce op in the purgatory. we don't have this anymore.,0,0.7264243960380554
1264965443,13870,dajac,2023-07-17T07:18:40Z,this was not addressed.,0,0.7236999869346619
1264967746,13870,dajac,2023-07-17T07:21:18Z,this was not addressed.,0,0.7236999869346619
1264968675,13870,dajac,2023-07-17T07:22:25Z,"yeah, we have to stick to the old one here.",0,0.9666318297386169
1265547819,13870,jeffkbkim,2023-07-17T15:32:01Z,i was thinking about the illegal state exceptions. wouldn't we hide the issue then? maybe we can log only for non api exceptions. wdyt?,0,0.9782148599624634
1265554449,13870,jeffkbkim,2023-07-17T15:37:23Z,this is required if we want to use the streams api. let me know if we should just use the for each loop,0,0.9861564636230469
1265574666,13870,jeffkbkim,2023-07-17T15:54:25Z,thought i addressed this. addressed it now,0,0.9682860970497131
1265577548,13870,jeffkbkim,2023-07-17T15:56:48Z,changed to logging only when the response future is not complete,0,0.9863072037696838
1265644331,13870,jeffkbkim,2023-07-17T16:51:05Z,updated and added a test case,0,0.981532871723175
1265807220,13870,dajac,2023-07-17T19:25:12Z,"this would still log in expected cases, no? for instance, when the coordinator for the group is inactive, loading, etc. if you really want to log something, you could perhaps log only if `exception` is not a kafkaexception or only when it is a runtimeexception for instance.",0,0.9885272979736328
1265807612,13870,dajac,2023-07-17T19:25:41Z,gotcha. it is fine like this.,1,0.7186943292617798
1265816192,13870,jeffkbkim,2023-07-17T19:35:47Z,ah makes sense. logging only when it is not a kafka exception makes sense.,0,0.9756105542182922
1266079310,13870,jeffkbkim,2023-07-18T01:36:33Z,i think our last discussion was to also revert this to the existing behavior right? i.e. not implement [a link],0,0.9813038110733032
1266264686,13870,dajac,2023-07-18T05:59:19Z,that's correct.,0,0.974586009979248
1266267667,13870,dajac,2023-07-18T06:00:53Z,should we replace this by a constant if we can't change it based on config?,0,0.982466459274292
1266269140,13870,dajac,2023-07-18T06:02:42Z,"so we actually need to reschedule the timer here, right?",0,0.9827119708061218
1266270587,13870,dajac,2023-07-18T06:04:21Z,nit: could we say `joingroup request {} hit....`?,0,0.9869301319122314
1267070768,13870,jeffkbkim,2023-07-18T17:00:13Z,yes. updated,0,0.9782312512397766
565612146,9944,jolshan,2021-01-27T20:29:10Z,i think i may want to do this in a simpler way. i want to keep track if we have ids for all the topics and i'm not sure if there is a better way to figure out when a topic is no longer in a session besides checking all the topic partitions.,0,0.7280423045158386
566449639,9944,rajinisivaram,2021-01-28T22:26:23Z,we don't use `get` prefix for getters,0,0.9825425148010254
566449805,9944,rajinisivaram,2021-01-28T22:26:42Z,comment needs updating?,0,0.9752081632614136
566453611,9944,rajinisivaram,2021-01-28T22:34:18Z,"we can use integer::sum as the last arg, but do we even need to maintain `partitionspertopic`?",0,0.9882314801216125
566458667,9944,rajinisivaram,2021-01-28T22:45:05Z,could just parameterize `findmissing`?,0,0.9882135391235352
566464590,9944,rajinisivaram,2021-01-28T22:57:33Z,"there are several places where we use this combination of two maps, should we create a class that maintains a bidirectional map?",0,0.9859319925308228
566465893,9944,rajinisivaram,2021-01-28T23:00:16Z,can we end up with cases with some topics with ids and some without?,0,0.986977756023407
566466426,9944,rajinisivaram,2021-01-28T23:01:33Z,the fact that you are running this code implies `apikeys.fetch.latestversion() >= 13`?,0,0.9868606925010681
567146583,9944,jolshan,2021-01-29T23:21:36Z,some of these tests may be flaky so i'm going to keep an eye on them.,0,0.8429841995239258
567172089,9944,rajinisivaram,2021-01-30T01:12:02Z,the whole fetchrequest class is quite hard to follow without reading the kip and looking at multiple places. it will be good to add some comments at the class level.,0,0.8657199144363403
567172368,9944,rajinisivaram,2021-01-30T01:13:50Z,"since we have session ids and topic ids in the context of a fetch request, we should probably qualify `topicid`",0,0.9881895780563354
567172755,9944,rajinisivaram,2021-01-30T01:15:54Z,`this.partitions.addall(partitions)`?,0,0.9870758652687073
567173386,9944,rajinisivaram,2021-01-30T01:19:17Z,does one non-zero id mean we have all ids?,0,0.9798920750617981
567173468,9944,rajinisivaram,2021-01-30T01:19:41Z,this suggests we can have a combination of zero and non-zero?,0,0.9812055826187134
567173993,9944,rajinisivaram,2021-01-30T01:22:18Z,it will be good to see if can separate out new and old forms of fetchrequest/response. it is not a big deal since it is just wrapping the protocol layer.,0,0.977674663066864
567174143,9944,rajinisivaram,2021-01-30T01:23:34Z,shouldn't we be using versions and expect non-zero ids in new versions?,0,0.9807714819908142
567174731,9944,rajinisivaram,2021-01-30T01:27:08Z,we need to remember to set this based on which version this is being merge to.,0,0.9842166900634766
567175350,9944,rajinisivaram,2021-01-30T01:30:45Z,nit: indentation,0,0.9879170060157776
567175593,9944,rajinisivaram,2021-01-30T01:32:32Z,does an unresolved partition have all these fields populated? or do we have it here because the topic may be resolved later?,0,0.9797126054763794
567175893,9944,rajinisivaram,2021-01-30T01:34:49Z,is this part intentionally commented out?,0,0.9323654174804688
567188080,9944,jolshan,2021-01-30T03:13:51Z,no that should be removed :),1,0.7603038549423218
567188108,9944,jolshan,2021-01-30T03:14:14Z,we need to keep the data from the fetch request for when we resolve the partition.,0,0.9852831363677979
567188287,9944,jolshan,2021-01-30T03:16:00Z,the idea is that we should only be able to send this request version if we had an id for each topic. i do need to take a closer look at this,0,0.9708164930343628
567188652,9944,jolshan,2021-01-30T03:19:22Z,i had trouble getting the version into the response. the constructor is used in some places where we don't have access to the version.,-1,0.7805281281471252
567188957,9944,jolshan,2021-01-30T03:22:37Z,that's true,0,0.9749451279640198
567189013,9944,jolshan,2021-01-30T03:23:35Z,i think this was a mistake. i need to see why i wrote it this way.,-1,0.9225524663925171
567189128,9944,jolshan,2021-01-30T03:24:54Z,i should also move that comment (and maybe simplify it) to the partitioniterator where i moved the code for removing partitions with stale ids.,0,0.9821257591247559
568033865,9944,jolshan,2021-02-01T18:10:10Z,"i remember why i did this. i wanted to not get a set of the zero id when the version was old. i think if we are able to get better versioning logic, this should be fixed easily.",0,0.9605996012687683
568034891,9944,jolshan,2021-02-01T18:11:54Z,abstractresponse does not maintain version like abstractrequest. so i'm not sure the best way to proceed with this.,-1,0.7697387337684631
568078414,9944,jolshan,2021-02-01T19:20:40Z,"i'm thinking it may be possible if we had a response from a broker that supported topic ids and then a response from one that did not. of course, this should eventually get resolved, but i didn't know if it was worth it to try to avoid fetches that are unsupported in a few more cases.",0,0.9695554375648499
568140154,9944,junrao,2021-02-01T21:07:54Z,space after comma,0,0.9835553765296936
568196064,9944,junrao,2021-02-01T22:51:09Z,gettopicids => topicnamestoids?,0,0.9852682948112488
568196201,9944,junrao,2021-02-01T22:51:32Z,gettopicnames => topicidstonames?,0,0.9854246973991394
568201144,9944,junrao,2021-02-01T22:58:56Z,"hmm, why do we need to do collect() at the end? the returned value doesn't seem be be used.",0,0.978087306022644
568201276,9944,junrao,2021-02-01T22:59:07Z,"hmm, why do we need to do collect() at the end?",0,0.9709886908531189
568216529,9944,junrao,2021-02-01T23:34:43Z,it's a bit weird to add a comment that breaks the if/else clause. perhaps we could put the comment inside the `else if`?,-1,0.9797967076301575
568222532,9944,junrao,2021-02-01T23:50:06Z,"it seems that the following code makes changes to unresolvedpartitions, not topic ids.",0,0.983366072177887
568223807,9944,junrao,2021-02-01T23:53:42Z,should we change `hashcode() `and `equals()` to include topicid?,0,0.9882214665412903
568230940,9944,junrao,2021-02-02T00:12:40Z,what's the definition of 'interesting'?,0,0.9679373502731323
568231067,9944,junrao,2021-02-02T00:13:05Z,"should we add the new params to the javadoc above? in particular, could we explain the relationship between responsedata and iderrors? also, could we name the params clearer? for example, responsedata => partitionswithmatchingtopicid, iderrors => partitionswithoutmatchingtopicid.",0,0.988572359085083
568832800,9944,junrao,2021-02-02T18:26:24Z,"since we are adding some complexity, it would be useful to make the code a bit easier to understand for other people. for example, perhaps we could add comments to explain (1) what partitions will be included in unresolvedpartitions vs partitionmap? (2) are partitions mutually exclusive between unresolvedpartitions and partitionmap? (3) how are partitions in unresolvedpartitions and partitionmap handled different for fetch response?",0,0.9764400124549866
569824849,9944,junrao,2021-02-03T23:29:26Z,topicnames => topicidtonamemap?,0,0.9863144159317017
569829415,9944,junrao,2021-02-03T23:41:13Z,is there a reason to use 0 instead of the default capacity for the hashmap?,0,0.9788211584091187
569830803,9944,junrao,2021-02-03T23:45:03Z,we could probably just get rid of session since it's part of the session object. ditto below.,0,0.9253479838371277
569832071,9944,junrao,2021-02-03T23:48:16Z,"now that the constructor code is a bit more now, perhaps we could just forward `builder()` to `builder(int initialsize, boolean copysessionpartitions) `?",0,0.9891618490219116
569832450,9944,junrao,2021-02-03T23:49:14Z,id => topicid ?,0,0.9847603440284729
569834804,9944,junrao,2021-02-03T23:55:33Z,"hmm, we should be adding tp.partition() to the hashset and not using it for the initial capacity, right?",0,0.983742356300354
569862273,9944,junrao,2021-02-04T00:49:57Z,it seems that topicnames is unused?,0,0.974060595035553
570397481,9944,junrao,2021-02-04T17:11:52Z,"it seems this is about a topic. so, unresolvedpartitions is better named as unresolvedtopic?",0,0.9614178538322449
570588361,9944,junrao,2021-02-04T22:29:45Z,"hmm, not sure if we need to distinguish here. it seems that it's easier to just always send a unknown_topic_id since the propagation of all topic ids could be delayed?",0,0.9219382405281067
570596351,9944,junrao,2021-02-04T22:46:08Z,"now that we are changing the semantics for this method to only iterating resolved partitions, it would be useful to have a more appropriate method name to make it clear. also, it seems that some of the callers need to iterate all partitions including unresolved ones (e.g., those checking for cluster action permissions) while some others need to iterate resolved ones (e.g, those checking for topic level permissions).",0,0.9844746589660645
570606630,9944,junrao,2021-02-04T23:08:08Z,"this method is kind of weird. it's only used in kafkaapis where topic name has already been resolved. the only reason for this method is that fetchcontext.updateandgenerateresponsedata() generates fetchresponse, which is used in createresponse(). instead, could we have fetchcontext.updateandgenerateresponsedata() return a different class that includes the resolved partitions?",-1,0.9855604767799377
570607999,9944,junrao,2021-02-04T23:11:22Z,perhaps we could log both the resolved partitions' size and unresolved partitions' size.,0,0.9867373108863831
570648997,9944,junrao,2021-02-05T00:58:06Z,it's kind of weird to pass in a request into fetchsession.,-1,0.983660876750946
570650572,9944,junrao,2021-02-05T01:02:52Z,"hmm, do we need to check version here? fetchresponse.fetchdataanderror() already checked the version.",0,0.9890652894973755
570652174,9944,junrao,2021-02-05T01:07:51Z,"could we name the methods better to make it easier to understand? for example, createnewsession => generateresolvedpartitions createnewsessioniderrors => generateunresolvedpartitions",0,0.9853245615959167
572203478,9944,junrao,2021-02-08T16:52:18Z,the metadata cache could change between the two calls. could we have a single call to metadata cache that returns both topicnames and topicids?,0,0.9897022247314453
572208853,9944,junrao,2021-02-08T16:58:58Z,"`topicids.getordefault(part.topic(), uuid.zero_uuid)` if we always expect the topic to be found in topicids, we should just throw an exception instead of using a default. if this is expected, we probably should convert it to an unresolved partition?",0,0.9866858720779419
572218700,9944,junrao,2021-02-08T17:12:09Z,it seems that toforgetids is intended for unresolved topicids. could we name it more clearly together with toforget and add some comment?,0,0.9870579838752747
572220577,9944,junrao,2021-02-08T17:14:48Z,"i am not sure that i follow the logic here. it seems that we always put the forgot topic into unresolvedids. it seems that we should check the partitions size? also, perhaps rename partitions to sth like unresolvedpartitions?",-1,0.5356272459030151
572228756,9944,junrao,2021-02-08T17:24:43Z,should we use mustadd()?,0,0.9855945110321045
572235515,9944,junrao,2021-02-08T17:33:23Z,do we need this part of the logic? it seems that the same is already done through fetchreqeust.fetchdataanderror().,0,0.9893895983695984
572274967,9944,junrao,2021-02-08T18:31:40Z,"this excludes the partition in the response. however, it seems we need to send an error back for this partition?",0,0.9802036285400391
572281866,9944,junrao,2021-02-08T18:42:34Z,this seems unused?,0,0.9358466863632202
572287008,9944,junrao,2021-02-08T18:50:42Z,could we add the new param to the javadoc?,0,0.9884663820266724
572308958,9944,junrao,2021-02-08T19:25:33Z,should we use the latest version or fetchrequestversion guarded by ibp?,0,0.9889806509017944
572350818,9944,jolshan,2021-02-08T20:31:46Z,sorry this was unclear. i meant changes involving topic ids. i will adjust this comment.,-1,0.9871571660041809
572351801,9944,jolshan,2021-02-08T20:33:35Z,'interesting' was the name of the map of partitiondata. i believe they are topic partitions that are authorized and exist.,0,0.9585086703300476
572351945,9944,jolshan,2021-02-08T20:33:51Z,sounds good to me,1,0.9722663164138794
572354491,9944,jolshan,2021-02-08T20:37:24Z,i think i was just matching `sessionpartitions` above,0,0.9884748458862305
572355958,9944,jolshan,2021-02-08T20:39:51Z,yeah. good catch. i'm going to experiment with this code a bit to see if it's faster to maintain this set or just get a set of topics from the map of topic partitions in` fetchrequestdata`,1,0.9724411368370056
572356813,9944,jolshan,2021-02-08T20:41:16Z,"the reason i name it this is we maintain such an object for each partition that was unresolved. if we simply have one object per topic, we would need a way to know all the partitions for the topic that were requested.",0,0.9821265339851379
572357857,9944,jolshan,2021-02-08T20:43:16Z,"i've gone back and forth on this. one one hand, you are right that this is confusing in the case where we are doing and upgrade and id propagation is delayed. on the other hand, in the non-upgrade case, returning an unknown_topic_id error when topic ids are not even supported might not be as informative.",0,0.7004640698432922
572363402,9944,jolshan,2021-02-08T20:52:25Z,"i agree. i think it stems from exactly what you said...that `fetchcontext.updateandgenerateresponsedata()` generates a response only for it to be generated again. currently ` fetchcontext.updateandgenerateresponsedata()` does include all partitions (resolved and unresolved). the issue is that the partitions need to be down-converted. the way this works is that the partitions are pulled from the fetchresponse object itself. however, the issue is that i've changed responsedata and since this is the newest version of the response, it will try to reconstruct the map instead of pulling the object `partitiondata`. (which is too slow) i thought about changing the method to always return the map when it is not null, but that caused some issues in some places as well. i can look into this again though.",0,0.9509348273277283
572367849,9944,jolshan,2021-02-08T20:59:54Z,this is for adding unresolved partitions in the session but not in the request. i can add comments to clarify what is happening.,0,0.9850607514381409
572370494,9944,jolshan,2021-02-08T21:04:38Z,"good point, it should probably be along the lines of `if (fetchrequestversion >= 13 && !fetchdata.canusetopicids) 12 else fetchrequestversion` to match how it is sent below.",0,0.5722175240516663
572373623,9944,jolshan,2021-02-08T21:09:56Z,"if we run into this scenario, does it make sense to always return with an unknown_topic_id error? sometimes partitions will be skipped over anyway when `mustrespond` is false, so should those also return unknown_topic_id?",0,0.9728240370750427
572377972,9944,jolshan,2021-02-08T21:13:56Z,i realize this is a bit confusing. addpartitions method takes a list what this line is doing is grabbing the iderror object and adding partitions to it.,-1,0.9205002188682556
572381787,9944,jolshan,2021-02-08T21:20:43Z,"ah. this is confusing due to how i named things. basically, i'm collecting a set of partitions `partitions` for a given topic where the id was not resolved. then i'm adding them to unresolvedids. this is a mapping from the topic id to all the partitions that should be forgotten. i can rename and add comments to clarify what is happening here.",-1,0.9173358678817749
572413017,9944,jolshan,2021-02-08T22:11:24Z,"i thought about this, but i was worried about some weirdness where we need to support partitions before and after they have an id. (the partitions are techincally equivalent, but equals wouldn't reflect that) this may also cause problems in cases where ids may change. consider the code ` val cachedpart = session.partitionmap.find(new cachedpartition(topicpart))` this is used in the path of deleting partitions with stale ids. we would need to know the topic id to find the partition here. i could see potential issues where we no longer have the id and would have trouble removing it.",-1,0.598490834236145
572470829,9944,jolshan,2021-02-09T00:21:46Z,when you mention that some callers need to iterate over all partitions like cluster action -- i'm a little confused. i thought the request context was passed into authhelper for that.,-1,0.6395236253738403
572472724,9944,jolshan,2021-02-09T00:25:21Z,i think we do since this is looking at the partitions cached in the session. i'll take another look though.,0,0.9805721044540405
572475014,9944,jolshan,2021-02-09T00:27:59Z,i think this is used for handling the case of older request versions.,0,0.9882700443267822
572512463,9944,junrao,2021-02-09T02:00:07Z,i was referring to the following code. it seems to need to iterate every partition through fetchcontext so that the unknown_topic_or_partition error code can be added for each partition. [code block],0,0.9851705431938171
573033865,9944,jolshan,2021-02-09T16:28:11Z,ok. i understand now. i think in this case though the expected behavior is to return unknown_topic_id if the topic id is unresolved.,0,0.9808295965194702
573046669,9944,jolshan,2021-02-09T16:43:18Z,"i just realized that fetchrequest.latestallowedversion is the version we use to build the request (latest and earliest are the same.) but this is a bit confusing, so i'll probably just use the logic mentioned above.",0,0.821183443069458
573102028,9944,junrao,2021-02-09T17:53:19Z,"yes, we want to return unknown_topic_id for all partitions in this case. the unresolved partitions in this pr could also return the unsupported error code.",0,0.9891725778579712
574846728,9944,jolshan,2021-02-11T21:42:38Z,get rid of the word session in the variable name? i was following sessionpartitions as above. or get rid of this altogether?,0,0.9758560657501221
574909648,9944,jolshan,2021-02-11T23:57:11Z,i'm trying to think if we could have a situation where the partition already exists but without topic id. (like an older version of the request was sent previously?) maybe i could check if it was not already added like how it is done below for resolved partitions added to the session.,0,0.959873616695404
592335738,9944,chia7712,2021-03-11T12:54:16Z,i don't find any usage of this method. is it essential to keep this map in `topicnames`?,0,0.9640573263168335
592360300,9944,chia7712,2021-03-11T13:30:13Z,"it seems this method is used by server only. is it possible to have empty topic name when `kafkaapis` calls it? if not, we can remove this empty check and replace this method by `toresponsedatamap`",0,0.9856027364730835
592520900,9944,jolshan,2021-03-11T16:41:47Z,"i think i added it for completeness, but perhaps we don't need it.",0,0.9688583612442017
592524660,9944,jolshan,2021-03-11T16:46:21Z,"yes. we may have topic ids that could not be resolved. these topics will not have a topic name. i agree that this isn't the cleanest solution, but it was the one that worked while keeping topicpartitions as keys for the map.",0,0.9560089111328125
592530926,9944,chia7712,2021-03-11T16:53:36Z,maybe we should remove the usage of this method first. is it useful if we make all callers use auto-generated data (topic and partition) instead of this map (topicpartition)?,0,0.986855149269104
592536126,9944,jolshan,2021-03-11T16:59:57Z,"i can remove it. i was keeping it as a placeholder for now. i was hoping to find a way to not regenerate the map that we just passed in to make the fetchresponse. i'm also not quite sure what you mean by ""auto-generated data""",0,0.777641236782074
592542384,9944,chia7712,2021-03-11T17:08:03Z,"make all callers use fetchresponsedata instead of map[topicpartition, ...]. in other words, fetchresponse does not return topicpartition anymore.",0,0.9866330623626709
592546512,9944,jolshan,2021-03-11T17:13:17Z,ah i see. i'd have to take a look. i'm wondering if we would still need to convert to topic names for certain methods.,0,0.9485186338424683
592761061,9944,jolshan,2021-03-11T22:16:27Z,"yeah, so for example, `topicpartition`s are given to `replicamanager.fetchmessages` where it is used heavily. i think we still want the map for now. one thing i was confused about with this code is why we generate `unconvertedfetchresponse` with `updateandgenerateresponsedata`. we pass in the map to create `unconvertedfetchresponse`. with the optimization to lazily compute the map, recompute it a few lines of code later in `createresponse`. i'm hoping to avoid this somehow. (i think the optimization is great everywhere else though and i was heading in that direction originally with this pr)",0,0.9192736148834229
592885424,9944,chia7712,2021-03-12T03:27:47Z,"you are right. i feel it is the side-effect caused mixing `topicpartition` and generated code in production. the callers have to create a heavy copy to update some fields of passed data. btw, that is what [a link] want to resolve. the pr makes all code use auto-generated data so they can update fields of passed auto-generated data instead of creating a copy.",0,0.5923886895179749
593283525,9944,jolshan,2021-03-12T16:04:20Z,got it. i think the issue here then is that some of the information can not be auto-generated data. we need topic names for certain methods but names will not be in the auto-generated data.,0,0.9727007150650024
593293236,9944,jolshan,2021-03-12T16:17:49Z,"i suppose we could set them server side, but when we iterate though the topics, we would need to not include those whose topic ids could not be resolved.",0,0.9844589233398438
593737385,9944,chia7712,2021-03-13T11:08:59Z,"as we resolve all ids before check permission, does it produce `topic_authorization_failed` with topic name even if it has no read permission to such topic (line#717)?",0,0.989083468914032
593738472,9944,chia7712,2021-03-13T11:20:21Z,remove those code?,0,0.9724900722503662
593739424,9944,chia7712,2021-03-13T11:29:33Z,not sure whether this idea is valid. could we resolve all ids to names and then keep using previous code to handle fetch requests? for example: the code of deleting topic resolve ids to names first and then process the deletion by names. that is a good pattern to me as we don't need to trace id/name everywhere.,1,0.552078127861023
593771946,9944,jolshan,2021-03-13T16:35:08Z,"for the most part, this is what we do. but we also have to keep track of unresolved names right? fetchsession makes this more complicated. we may get a topic id that we can't resolve, but with a subsequent update we can. i'm not 100% sure of the logistics of fetch sessions, but it doesn't seem like a good practice to leave unresolved ids out of the session.",0,0.5201236009597778
593772326,9944,jolshan,2021-03-13T16:37:56Z,"i would think so? the goal was for when the ids are resolved, the path would be the same. and i think we decided that topic_authorization_failed is the correct error when we don't have read permissions?",0,0.9843334555625916
593842004,9944,chia7712,2021-03-14T04:48:57Z,sorry for my unclear comment. my point was that the topic name is included by the response even if there is no read permission to “resolve the topic is”. that looks like a security issue that we expose the topic name.,-1,0.989464521408081
593922148,9944,jolshan,2021-03-14T16:01:06Z,ah right. i will fix that.,0,0.8805373311042786
595284658,9944,jolshan,2021-03-16T15:31:23Z,i went to fix this but i realized something. correct me if i'm wrong. the newest version of fetch will only return topic ids (not topic names) so we won't expose topic names. the older version of fetch sends topic names so it will have to send topic names back. i don't think the name is ever incorrectly exposed.,0,0.9267027974128723
603506960,9944,jolshan,2021-03-29T18:09:58Z,removed this object,0,0.9809792041778564
603507748,9944,jolshan,2021-03-29T18:11:16Z,i simplified this path as well.,0,0.9853693842887878
617932245,9944,junrao,2021-04-21T22:26:04Z,extra newline.,0,0.9692660570144653
622349780,9944,junrao,2021-04-28T16:32:41Z,id => topicid ?,0,0.9847603440284729
622349941,9944,junrao,2021-04-28T16:32:54Z,id => topicid ?,0,0.9847603440284729
625164696,9944,jolshan,2021-05-03T15:23:38Z,"with the top level error change, we are no longer marking the partitions as `partitionswitherror`. i'm wondering if this is something we still want to do somehow to allow the broker's metadata time to update.",0,0.9221934080123901
625372843,9944,junrao,2021-05-03T21:15:05Z,"when will topicresponse.topic() be """"?",0,0.9805225729942322
625422142,9944,junrao,2021-05-03T23:09:32Z,an situation => a situation,0,0.9787513613700867
625429072,9944,junrao,2021-05-03T23:30:12Z,"it's a bit weird for `forgottentopics()` to have a side effect that changes the internal data structure since requests are typically immutable. it's all not consistent with topartitiondatamap(). if we do want to modify the internal data structure, we probably want to name the method more properly. also, why do we return a list of forgottentopic instead of list of topicpartition? the latter is easier to understand and it doesn't seem that we need topicid in forgottentopic,",-1,0.9739658236503601
625431122,9944,junrao,2021-05-03T23:36:39Z,no need for extra new line.,0,0.9710507392883301
625432217,9944,junrao,2021-05-03T23:40:13Z,version seems unused?,0,0.9705610871315002
625433357,9944,junrao,2021-05-03T23:43:56Z,"hmm, it seems that we can't pass in an empty topicids since partition iterator is not empty?",0,0.9675259590148926
625440965,9944,junrao,2021-05-04T00:09:25Z,does topicid need to be a var?,0,0.9850860834121704
625443921,9944,junrao,2021-05-04T00:19:34Z,"hmm, if the topicid has changed, it seems that we should send an error (e.g. invalidtopicid) back to indicate the topicid is no longer valid so that the client could refresh the metadata?",0,0.9750199913978577
625446144,9944,junrao,2021-05-04T00:27:26Z,could we explicitly define the type of topicnames ?,0,0.9876869320869446
625451257,9944,junrao,2021-05-04T00:46:05Z,the calculation of version is duplicated between here and replicafetcherthread. could we share them somehow?,0,0.9893346428871155
625454055,9944,junrao,2021-05-04T00:56:19Z,"since there is only a single tp, does topics need to be a set?",0,0.9796170592308044
626749507,9944,jolshan,2021-05-05T17:09:36Z,i ended up deciding to end the session and throw a top level error when we have an unknown topic id.,0,0.9348798990249634
626894717,9944,junrao,2021-05-05T21:01:53Z,"since topartitiondatamap() handles all versions, could we just simply call topartitiondatamap()? then, i am not sure if we need to call topartitiondatamap() in the constructor.",0,0.9823810458183289
626897100,9944,junrao,2021-05-05T21:06:16Z,it seems it will be clearer if we put this in an else clause.,0,0.9825389385223389
626899596,9944,junrao,2021-05-05T21:11:05Z,it seems that we could share the code to populate this.data and this.metadata. we only use `this` in this method. should we just remove it?,0,0.9881225228309631
626906972,9944,junrao,2021-05-05T21:24:45Z,do we need this method? it seems it's the same as toresponsedatamap().,0,0.987860381603241
626907992,9944,junrao,2021-05-05T21:26:38Z,could we add the new param to javadoc?,0,0.9884737133979797
626945454,9944,junrao,2021-05-05T21:55:31Z,it seems that this can just be a local val instead of an instance val?,0,0.9865078926086426
626947091,9944,junrao,2021-05-05T21:57:30Z,do the new fields need to be included in tostring()?,0,0.985030472278595
626952683,9944,junrao,2021-05-05T22:09:42Z,could we build the full tosendtopicids and tosendtopicnames once and reuse in both full and incremental?,0,0.9888752698898315
626953162,9944,junrao,2021-05-05T22:10:50Z,the above comment needs to be changed accordingly.,0,0.9774772524833679
626954746,9944,junrao,2021-05-05T22:14:32Z,perhaps extra and omitted should be extrapartition and omittedpartitions to make it clear?,0,0.9818885922431946
626958184,9944,junrao,2021-05-05T22:23:00Z,could we add the javadoc for the new param?,0,0.9883484244346619
627026623,9944,jolshan,2021-05-06T01:58:33Z,realized this was no longer the case and removed in the most recent commit.,0,0.9670253992080688
627027261,9944,jolshan,2021-05-06T02:00:45Z,"i originally did this when dealing with unresolved partitions. i was wondering if it would be better to not create a second data structure. if creating another structure (as done before) is not a problem, we can go back to that.",0,0.9739879965782166
627027404,9944,jolshan,2021-05-06T02:01:20Z,ah good catch on this.,1,0.8877222537994385
627514050,9944,jolshan,2021-05-06T15:15:14Z,"this is a good point. in general, i think i need to go through the session logic for handling different scenarios. (what happens when we have a session with different version requests--should we allow that to happen, etc) depending on this, we may want topicid to be a var (to update the id when we change request versions). i'll write up a summary of the logic i'm thinking of when i get it worked out.",1,0.8639697432518005
627516643,9944,jolshan,2021-05-06T15:18:19Z,the difference is that we already have the topic names here. i added it for the optimization when we build the response data map again in kafkaapis (so we don't have to look up the topic ids again). but it is a little silly. one option is just to put that logic in the one place it is used instead of having such a method.,-1,0.962504506111145
627518693,9944,jolshan,2021-05-06T15:20:46Z,"yeah. that seems cleaner. so the idea is that the constructor, won't set fetchdata for either version.",0,0.9535160660743713
627519381,9944,jolshan,2021-05-06T15:21:33Z,"as mentioned below, we can simply not set fetchdata here and use the other two assignments.",0,0.9860624670982361
627522339,9944,jolshan,2021-05-06T15:25:02Z,would this work if we added a new topic to the session? i would think that we would need to add the new topic's info and the map is unmodifiable. please correct me if this is not the case.,0,0.9727631211280823
627523117,9944,jolshan,2021-05-06T15:26:00Z,"i think the original idea was that i wanted to make sure that we don't go from request version 12 up to version 13 in the same session. but in general, i need to rethink this whole approach, so this will very likely change. as mentioned in another comment, i'll write up the logic i'm thinking about so we are on the same page.",0,0.9514192342758179
627523900,9944,jolshan,2021-05-06T15:26:58Z,"i wasn't sure on this, but i can add them. maybe it makes sense just to add topicids though? (not both maps)",0,0.9588907361030579
627723205,9944,jolshan,2021-05-06T19:56:00Z,ah another artifact from before. good catch.,1,0.9687348008155823
627724561,9944,jolshan,2021-05-06T19:58:26Z,ah wait. the iterator is empty here. we create a new one `(new fetchsession.resp_map).entryset.iterator` and do not use `updates`. this is because the session is an error one.,0,0.9721618890762329
627767360,9944,jolshan,2021-05-06T21:11:12Z,rewrote this comment to be more concise.,0,0.9804344773292542
627776011,9944,jolshan,2021-05-06T21:27:29Z,"ah i realize that since this is a single topic, we can change this logic.",0,0.9416115283966064
627840199,9944,jolshan,2021-05-07T00:05:48Z,decided that we can use either version throughout the course of a session. removed instance val,0,0.9873398542404175
628405414,9944,jolshan,2021-05-07T17:55:55Z,"after running through some tests i realized why this didn't work. we can go from version 13 to version 12 within the session, but we can't go from 12 to 13. this is because we have may have topics without ids in the session. we will try to return them using version 13 and they are all zero uuid. (we also have this issue when we send a full request version 12 and the subsequent request is empty. we could try to send version 13 request since we vacuously have ids for all topics in the request, but if we do have responses for the topics, then we will try to send them back without topic ids) if we tried to resolve them, we may end up in a case where there is no valid id and also no way to communicate this (since we send back ids). so i think we do need to store the state of the previous request version in the session.",0,0.9371222853660583
648811500,9944,jolshan,2021-06-10T02:49:34Z,"i noticed that i get topic ids from metadata here and in the replica fetcher thread, i get from the metadata cache. i don't think it is a big deal since we add to the fetchdata using the same source, but it might make sense to use fetchrequestdata's topicids() instead.",0,0.9803522825241089
649585182,9944,junrao,2021-06-10T23:00:31Z,space after foreach.,0,0.9845805764198303
649603470,9944,junrao,2021-06-10T23:57:50Z,from topic name for topic id => from topic name to topic id ?,0,0.9835767149925232
649607001,9944,junrao,2021-06-11T00:09:33Z,should we include topicid in hashcode() and equals()?,0,0.987346351146698
650157796,9944,junrao,2021-06-11T17:31:30Z,do we need to handle unknown_topic_id here too?,0,0.985954225063324
650161415,9944,junrao,2021-06-11T17:38:16Z,"since metadatasnapshot could change anytime, it's more consistent if we save a copy of metadatasnapshot and derive both maps from the same cached value.",0,0.9875546097755432
650163078,9944,junrao,2021-06-11T17:41:14Z,could we use case to avoid unnamed reference _._2 to make it easier to read?,0,0.9883952140808105
650165036,9944,junrao,2021-06-11T17:44:44Z,"since metadatache could change, it's probably slightly better to get topicidstonames and topicnamestoids once from metadatache so that they are consistent.",0,0.9844070672988892
650166656,9944,junrao,2021-06-11T17:47:42Z,is the test apikeys.fetch.latestversion >= 13 necessary? this code is added when we introduce version 13 as the latest fetch version.,0,0.9892275333404541
650169478,9944,junrao,2021-06-11T17:52:40Z,is the test apikeys.fetch.latestversion >= 13 necessary? this code is added when we introduce version 13 as the latest fetch version.,0,0.9892275333404541
650612574,9944,jolshan,2021-06-14T01:59:16Z,734fd7f fixes this,0,0.9881438612937927
651075127,9944,junrao,2021-06-14T15:55:51Z,the kip talks about bootstrapping the topicid for the metadata topic. is that part done already? i don't see it included in this pr.,0,0.9810793399810791
651086239,9944,junrao,2021-06-14T16:10:24Z,"if we get fetchsessiontopicidexception, the existing session is going to be invalid. so, it seems that we should start a new session? the same thing seems to apply to unknowntopicidexception",0,0.9797573685646057
651096649,9944,junrao,2021-06-14T16:24:39Z,could we do the topicids part once after the if/else block to avoid duplication?,0,0.9883881211280823
651099635,9944,junrao,2021-06-14T16:28:37Z,does this work with topic recreation? will a client be stuck with the old topicid when topic is recreated?,0,0.9772372841835022
651124339,9944,junrao,2021-06-14T17:04:08Z,should we set sessiontopicids and sessiontopicnames to empty map if canusetopicids is false?,0,0.9857279658317566
651163378,9944,junrao,2021-06-14T18:03:14Z,"i am wondering if this solves the problem completely. the decision to use version 13 fetch request also depends on the kafka version on the broker. so, even if the client has all topic ids, the client may still send version 12 fetch requests to a broker. so, canusetopicids doesn't accurate capture the state whether a version 13 fetch request has been used. another possibility is to handle the switching from version 12 to 13 of the fetch requests on the server side in fetchsession. fetchsession already stores usestopicids. so, if usestopicids is false and a fetch request passes in topicid, we could send an error to the client to force the client to establish a new session. if we do this, we probably don't need to cache the canusetopicids in client fetch session. we can just calculated canusetopicids independently for each request. will this approach be better?",0,0.9071267247200012
651170786,9944,junrao,2021-06-14T18:15:00Z,it might be useful to include the topic name and topic id (old and new) for those inconsistent topic ids.,0,0.9867904782295227
651293905,9944,junrao,2021-06-14T21:35:11Z,"maxversion is not necessary the exact version used for fetch request. the exact version is determined in networkclient.dosend() based on the response of apiversions. so, here, it seems that we need to pass in the exact version number?",0,0.9884203672409058
651294705,9944,junrao,2021-06-14T21:36:47Z,should we force close the fetchsession in this case too?,0,0.984541654586792
651309361,9944,junrao,2021-06-14T22:05:50Z,"since topartitiondatamap() is only called here, should we just inline it here?",0,0.9893536567687988
651310206,9944,junrao,2021-06-14T22:07:39Z,should we document fetch_session_topic_id_error too?,0,0.9798787832260132
651310982,9944,junrao,2021-06-14T22:09:16Z,should unknown_topic_id be fetch_session_topic_id_error now?,0,0.9807126522064209
651314171,9944,junrao,2021-06-14T22:16:16Z,should we just inline toresponsedatamap() here?,0,0.9879319071769714
651314503,9944,junrao,2021-06-14T22:17:04Z,we choose to cache responsedata here but not in fetchrequest. is there a particular reason for this inconsistency?,0,0.9802691340446472
651329577,9944,jolshan,2021-06-14T22:53:56Z,"are you referring to creating a new topic id for the metadata topic? for now, we are simply using the sentinel id.",0,0.9867498278617859
651331247,9944,jolshan,2021-06-14T22:58:05Z,this happens inside of `fetchsessionhandler.handleresponse`. we set the session to close upon the next request. the code path for fetcher is slightly different so it made sense for that code to have it there.,0,0.9886186122894287
651331636,9944,jolshan,2021-06-14T22:59:05Z,"this is no longer a partition level error. we can only get it as a top level error. if it is a top level error, i believe we return an empty map and do not go down this code path.",0,0.9684022068977356
651332118,9944,jolshan,2021-06-14T23:00:22Z,"if we try to put in a new topic id, the session should be closed.",0,0.9831647872924805
651332908,9944,jolshan,2021-06-14T23:02:23Z,ah i see what you are saying here. i think this will still close the session when we send the request. the other option is to set a boolean similar to `missingtopicid` (maybe just change to `inconsistenttopicid` that signals to close the session earlier (upon build),0,0.9492848515510559
651333015,9944,jolshan,2021-06-14T23:02:46Z,that makes sense to me.,0,0.9582882523536682
651334106,9944,jolshan,2021-06-14T23:05:39Z,"i think we already do something like this on the broker. we only get to the point of having a session if the broker had an id for all the topics in the request. i don't think we can calculate on a request basis since we may respond with topics that did not have ids associated. i may be misunderstanding what you are saying, but i'm very wary of trying to switch between versions 12 and 13 in the same session.",-1,0.8559715151786804
651335121,9944,jolshan,2021-06-14T23:08:31Z,i see what you mean. it is a little tricky to get the version from the fetchresponse itself. would `resp.requestheader().apiversion()` work?,0,0.9521445035934448
651335255,9944,jolshan,2021-06-14T23:08:49Z,this closes the session in handler.handlerresponse.,0,0.9868892431259155
651335666,9944,jolshan,2021-06-14T23:09:59Z,i think i just have the wrong things here completely. there should be inconsistent_topic_id here as well.,-1,0.9481399059295654
651336157,9944,jolshan,2021-06-14T23:11:15Z,i think this inconsistency existed before i touched the code. :grinning_face_with_sweat:,-1,0.9452798366546631
651373234,9944,junrao,2021-06-15T01:01:41Z,"got it. could we clean the existing code up a bit? since fetchsessionhandler.handleresponse() already handles the closing of the session on error, it seem that we could get rid of fetchsessionhandler.handleerror(t). also, it seems that if fetchresponse.error() != none, we want to throw the error as an exception. finally, if fetchsessionhandler.handleresponse() returns false, we probably want to throw an exception too?",0,0.9786609411239624
651933919,9944,junrao,2021-06-15T15:59:07Z,got it. we can keep the code as it is then.,0,0.9631126523017883
651939380,9944,junrao,2021-06-15T16:06:10Z,"if we are switching from version 12 to version 13 for a session, prevsessiontopicid will be null. should we also populate inconsistenttopicids in this case to force a new session in the client?",0,0.9781937599182129
651943909,9944,junrao,2021-06-15T16:11:49Z,"i added another comment in fetchsession. if the session starts with no topicid and a fetch request switches to using topicid, could the server just return an error to force a new session? will this avoid the need to track canusetopicids as a state? overall, it's probably a bit better to add a bit complexity on the server to simplify the development on the client since we implement the client multiple times in different languages.",0,0.9809959530830383
651946576,9944,junrao,2021-06-15T16:15:00Z,"yes, i think that works.",0,0.9637601375579834
651947708,9944,junrao,2021-06-15T16:16:03Z,thanks. sounds good.,1,0.9599065780639648
651969184,9944,jolshan,2021-06-15T16:42:29Z,i think there are other errors that can occur when trying to send the request which is why we have fetchsessionhandler.handleerror(t). but this all can probably be cleaned up a bit/improved so i will take a look.,0,0.9844101667404175
651970044,9944,jolshan,2021-06-15T16:43:38Z,"if we switch from 12 to 13, we will not get to this point. we will throw a fetch_session_id_error before we get here.",0,0.8989768028259277
651971564,9944,jolshan,2021-06-15T16:45:41Z,this is something that we are doing in fetchsession. we close the session if the requests switch between 12 and 13 (or vice versa). is the idea that we will just send the request based on the topic ids provided to the builder (if we have an id for each topic) and let the session code on the server handle it?,0,0.9866209030151367
651976677,9944,junrao,2021-06-15T16:52:21Z,"yes, if that makes the client code simpler and more consistent. for example, in [a link] the client also chooses to let the server handle the closing of the session.",0,0.9877927899360657
651977071,9944,junrao,2021-06-15T16:52:49Z,got it. make sense.,0,0.8901485800743103
651985270,9944,jolshan,2021-06-15T17:03:49Z,"i thought about this, and originally we compared the topic ids in the session by grabbing cached partitions and comparing to the ids in the request. since we have a new mechanism (the topic id map) we may no longer need to do this and i can add the id to the hashcode and equals methods.",0,0.9841070175170898
652228425,9944,jolshan,2021-06-15T23:27:39Z,this one is slightly different as we are checking the ibp to get fetchrequestversion. we could have an ibp where the version is lower than 12.,0,0.986747145652771
652250666,9944,jolshan,2021-06-15T23:53:46Z,i was just thinking about this and realized we may send new error types to clients that may not be able to handle them. i need to review this code again.,0,0.9295932054519653
652835907,9944,jolshan,2021-06-16T16:04:40Z,"ok. just went through logic for old clients 1. unknown_topic_id should not be returned since we won't ever use topic ids (version 12 requests and below)"" 2. fetch_session_topic_id_error should not be returned since we won't send version 13+ in a session and will always have zero uuids 3. inconsistent_topic_id should not be returned, as we won't have topic ids in the request/session. the only thing i can think of is downgrading a client while a session is open. i'm not sure if this can happen.",0,0.7323894500732422
652838939,9944,jolshan,2021-06-16T16:08:28Z,"though in most cases, if we canusetopicids we likely have ibp 2.8, or are upgrading to it.",0,0.9877001047134399
652875100,9944,jolshan,2021-06-16T16:55:24Z,one option is to do what the raftmetadatacache does and simply create a copy of the maps themselves in topicnamestoids() and topicidstonames(),0,0.9877424240112305
653921888,9944,jolshan,2021-06-17T20:43:55Z,"i think the main reason we keep the state in the session for using topic ids is that some requests may not contain any new/updated partitions and we need to know which version to send. we don't want to close the session and simply send the version that was sent last time. i do think this code is quite confusing as is, so i think i can simply a lot of it.",0,0.7914099097251892
654039106,9944,jolshan,2021-06-17T23:06:25Z,"ah, i found another use -- we lookup partitions toforget using the hashcode. right now, toforget is a list of topic partitions and we don't directly use the id provided in the request. we could look up the topic id from the topic id map and use it (we could also remove from the session map if we do remove the topic)",0,0.9756273627281189
654673513,9944,jolshan,2021-06-18T20:57:32Z,"this is causing build failures, will update to prevent this.",0,0.9515230059623718
655561404,9944,junrao,2021-06-21T17:07:25Z,"the inconsistent_topic_id check in replicamanager is not very precise since the topicid could change immediately after the check. i am thinking that another way to do this is to validate the topicid in the session again when we are generating the fetch response. we could pass in the latest topicnametoid mapping from the metadata cache to updateandgenerateresponsedata(). if the topicid is different from those in the fetch session, we could generate a top level inconsistent_topic_id error. we could then get rid of the inconsistent_topic_id check in replicamanager.",0,0.981205940246582
655565663,9944,junrao,2021-06-21T17:14:12Z,is there a benefit to have fetch_session_topic_id_error in addition to inconsistent_topic_id? could we just always use inconsistent_topic_id?,0,0.9831352233886719
655574477,9944,junrao,2021-06-21T17:28:11Z,"in the latest pr, it seems that canusetopicids is updated on every build() call and can be a local val?",0,0.9895933866500854
655574856,9944,junrao,2021-06-21T17:28:40Z,could we do this once at the beginning of build()?,0,0.9876158833503723
655590483,9944,junrao,2021-06-21T17:52:19Z,should we add topicid in tostring()?,0,0.9867411255836487
655593298,9944,junrao,2021-06-21T17:56:38Z,i thought that inconsistent_topic_id is always a top level error now?,0,0.9695437550544739
655598054,9944,junrao,2021-06-21T18:04:11Z,could we first save metadatasnapshot to a local val and then derive both maps so that they can be consistent?,0,0.9878443479537964
655599428,9944,junrao,2021-06-21T18:06:40Z,could we first save _currentimage to a local val and derive both maps from it so that they are consistent?,0,0.9876367449760437
655603017,9944,junrao,2021-06-21T18:12:38Z,then could we try/catch just leaderendpoint.sendrequest and call fetchsessionhandler.handleerror(t) on exception? this will make the code easier to understand.,0,0.9868124127388
655604345,9944,junrao,2021-06-21T18:14:53Z,could we just use errors.forcode() to translate errorcode to exception generically?,0,0.9849627017974854
655614034,9944,junrao,2021-06-21T18:30:41Z,"since we cache fetchdata before, perhaps we could cache it in the new implementation too? this will make it more consistent with fetchresponse. ditto for toforget().",0,0.9800041317939758
655614908,9944,junrao,2021-06-21T18:32:10Z,extra empty line.,0,0.9553989171981812
655621465,9944,junrao,2021-06-21T18:42:57Z,"since this tests non-existing topics, why do we pass in topicnames for fetch requests?",0,0.9837819337844849
655622855,9944,junrao,2021-06-21T18:45:21Z,"this is an existing issue, but could we use case to remove unnamed references _._1?",0,0.9889642000198364
655627698,9944,junrao,2021-06-21T18:53:31Z,could we share the common code btw testcontrollernewibp() and testcontrolleroldibp()?,0,0.9885380268096924
655629132,9944,junrao,2021-06-21T18:55:47Z,should we remove this line? ditto in a few other places in this file.,0,0.9116137623786926
655642933,9944,jolshan,2021-06-21T19:19:02Z,ah apologies i did not clean up as well as i should have.,-1,0.9570187330245972
655643270,9944,jolshan,2021-06-21T19:19:42Z,i can try to pick up all the changes i made that do this.,0,0.9737277626991272
655647688,9944,jolshan,2021-06-21T19:27:27Z,and i discussed this a bit. it seems that the metadata cache may be less accurate than the log itself and that is why we did away with the metadata check. i am also a little unsure (i'd have to check the code) but i'm not sure if the topicid can change. are we saying that the partition and/or the underlying log can change in this code block? i think we can say we will read from the partition with that id. [code block],0,0.8049190044403076
655648541,9944,jolshan,2021-06-21T19:28:56Z,"i think the main reason why i made the session id error was that the inconsistent topic id error's message was too specific for this use case. i suppose we could just make all the errors here session errors. i do like the inconsistent id error specifying the log (and being on the partition with the issue), but we can change this.",0,0.9406681060791016
655649094,9944,jolshan,2021-06-21T19:29:53Z,"it is both a top level and partition error here. i kind of like being able to identify the partition (kind of wish the other errors could do this in some cases), but we can change this.",0,0.9282543063163757
655649425,9944,jolshan,2021-06-21T19:30:29Z,ok. i see what you mean here.,0,0.9771440625190735
655649858,9944,jolshan,2021-06-21T19:31:17Z,ah good point. i can look into this.,1,0.825808584690094
655810138,9944,jolshan,2021-06-22T01:27:11Z,"i think because we still want to build the request. my understanding is that the topic is non-existing on the receiving side, but we still want to receive and handle the response.",0,0.9622366428375244
660013467,9944,junrao,2021-06-28T18:14:42Z,"it seems that we should never change the topicid in sessiontopicids? perhaps we should use putifabsent. similarly, if the topicid changes, i am not sure if we should update partitionmap below.",0,0.9758146405220032
660016282,9944,junrao,2021-06-28T18:19:08Z,do we need to include the new fields in tostring()?,0,0.9860650300979614
660018415,9944,junrao,2021-06-28T18:22:37Z,should we use usetopicid instead of version?,0,0.9862427711486816
660032238,9944,junrao,2021-06-28T18:45:23Z,should we rename error to toplevelerror to make it clearer?,0,0.9835213422775269
660032853,9944,junrao,2021-06-28T18:46:25Z,"typically, if there is a topic level error, we set the same error in every partition through fetchrequest.geterrorresponse(). should we do the same thing here? ditto for incrementalfetchcontext.updateandgenerateresponsedata().",0,0.9725518822669983
660034212,9944,junrao,2021-06-28T18:48:30Z,error => toplevelerror?,0,0.9832269549369812
660038680,9944,junrao,2021-06-28T18:55:42Z,"ok, this is fine. i was thinking that when topicid changes, a pending fetch request could still reference the outdated partition object and therefore miss the topicid change. this is unlikely and can be tighten up by clearing the segment list when a partition is deleted. regarding the metadata propagation, it's true that right now, we propagate the leaderandisrrequest before the updatemetadatarequest. with raft, the topicid will always flow through metadata update first, followed by the replicamanager. when we get there, maybe we could simplify the the logic a bit.",0,0.8966169953346252
660061129,9944,jolshan,2021-06-28T19:31:39Z,"if a topic id changes, the fetchsession will become a fetcherrorsession and close. i can change to putifabsent if it makes things clearer, but all this state will go away upon an error + session close.",0,0.9827567338943481
660061358,9944,jolshan,2021-06-28T19:32:04Z,i suppose it won't hurt :),1,0.9484634399414062
660061496,9944,jolshan,2021-06-28T19:32:18Z,we can do that to make things clearer.,0,0.972877025604248
660062652,9944,jolshan,2021-06-28T19:34:17Z,"i think this goes back to the question of whether it is useful for us to have information on the specific partition that failed. if we do this, should we also return the error values for the other fields as we do in fetchrequest.geterrorresponse?",0,0.9879635572433472
660068452,9944,jolshan,2021-06-28T19:44:25Z,"i'm still not sure i follow ""pending fetch request could still reference the outdated partition object and therefore miss the topicid change"" my understanding is that the log is the source of truth and we will either read from the log if it matches and not read if it doesn't. i see we could get an error erroneously if the partition didn't update in time, but i don't see us being able to read from the log due to a stale partition. or are you referring to the getpartitionorexception(tp) call picking up a stale partition and both the request and the partition are stale? in this case, we will read from the log, but will identify it with its correct id. the client will handle based on this.",0,0.8495228886604309
660122565,9944,jolshan,2021-06-28T21:16:00Z,"i guess the only issue with using fetchrequest.geterrorresponse is that we may have different topics in the response than in the request. sessionerrorcontext deals with this by simply having an empty response besides the top level error. i'm wondering if we should do something like this. (likewise, with the unknown_topic_id error, should we also just send back an empty response?)",0,0.8992765545845032
660127887,9944,jolshan,2021-06-28T21:25:48Z,"taking a second look, seems like we just use partitionmap.size. not sure if it is useful to have sessiontopicids size (and if the whole map is too much). i'm thinking maybe just including the usestopicids boolean.",0,0.935320258140564
660199209,9944,jolshan,2021-06-29T00:33:08Z,"we need to do something like this to easily get the top level error with no partition response for unknown_topic_id. i think this works, but we may want a version check as well just to be safe.",0,0.9728067517280579
660206465,9944,junrao,2021-06-29T00:57:22Z,"this kind of special treatment for unknown_topic_id is a bit weird. if you look at the comment above, the reason for setting the same error code in all partitions is for backward compatibility when we don't have a top level error code. so, we probably can just check the request version. if version is >=13, we just always return a top level error code with no partitions.",-1,0.9777485132217407
660209346,9944,junrao,2021-06-29T01:06:54Z,"this can also cause a bit confusing that we are treating inconsistent_topic_id differently from other top-level errors. since the only possible top level error is inconsistent_topic_id, perhaps we can change toplevelerror to hasinconsistenttopicid. ditto in incrementalfetchcontext.",0,0.5649397373199463
660211602,9944,junrao,2021-06-29T01:14:20Z,"a fetch request may pass the topicid check in replicamanager and is about to call log.read(), when the topicid changes. i was wondering in that case, if log.read() could return data that corresponds to the old topicid. it seems that's not possible since log.close() closes all segments.",0,0.9836200475692749
660228129,9944,jolshan,2021-06-29T02:06:34Z,yeah. i agree it is a bit weird. we can update as you mentioned.,-1,0.9601898193359375
660228674,9944,jolshan,2021-06-29T02:08:16Z,"the topic id should not change in the log once it is set. i think what you said in the last sentence is correct. my understanding is that if the log is closed, it can not read from it anymore.",0,0.9760081171989441
661716207,9944,junrao,2021-06-30T18:27:18Z,"could we adjust the above comment on ""the error is indicated in two ways: by setting the same error code in all partitions, and by setting the top-level error code. the form where we set the same error code in all partitions is needed in order to maintain backwards compatibility with older versions of the protocol in which there was no top-level error code."" ?",0,0.9868435263633728
661716835,9944,junrao,2021-06-30T18:28:20Z,"if we can't merge this in 3.0, we will need to change the tag to 3.1.",0,0.9869862198829651
661788073,9944,jolshan,2021-06-30T20:26:49Z,we should adjust this to say we will no longer set on all partitions for versions 13+?,0,0.9870820045471191
661822644,9944,junrao,2021-06-30T21:27:16Z,right,0,0.9538289308547974
671728971,9944,chia7712,2021-07-17T18:30:04Z,"i noticed following warning message from our cluster (building on trunk). [code block] according to this code, changing the version in session is disallowed (please correct me if i misunderstood). should fetch thread keep version in session meta? or change the log level to `debug`?",0,0.9857289791107178
671730072,9944,chia7712,2021-07-17T18:40:57Z,"if there is a removing partition, the topic id is not added to this builder. the fetch request with version=13 will carry `topic='xxx'` and `id=aaa...`. however, the topic name get reset to empty string by kafka protocol. hence, the following error message is produced. [code block] if this is an expected behavior, should we change the log level from `error` to `debug`? or add more docs to say `this error may be returned transiently when xxx`?",0,0.9862346053123474
671754420,9944,jolshan,2021-07-17T23:12:32Z,hi i'm tracking this bug here and will work on the fix: [a link],0,0.9663993120193481
671754618,9944,jolshan,2021-07-17T23:14:47Z,"in general, we should not send a request without a valid name or id. we remove partitions from a session by not including them in the builder -- so theoretically, we should already have the topic id. the only case we don't is when we are in a session that doesn't use topic ids. i will fix this behavior to also check that the topics being removed have ids in the session, otherwise send a v12 request.",0,0.9830020070075989
671754732,9944,chia7712,2021-07-17T23:16:05Z,thanks for response and tracking! will watch the issue!,1,0.9777184128761292
671754759,9944,jolshan,2021-07-17T23:16:31Z,"changing the version is not allowed. i'm not sure i follow what you mean by keeping version. current usestopicids is set based on the version when the session is first created and maintained throughout the session. i think we will see this error transiently, but please let me know if you continue to see this issue after i fix the bug below.",0,0.866710901260376
671755992,9944,chia7712,2021-07-17T23:33:04Z,thanks for explanation. will test it after you fix the issue!,1,0.9663150310516357
671773887,9944,jolshan,2021-07-18T03:16:33Z,this one too: [a link] i have an idea of how to fix this one as well and it should make a big difference based on the testing i've done so far.,0,0.924608051776886
1146803694,13443,jeffkbkim,2023-03-23T20:35:42Z,this usually suggests that the code can be simplified. do we see this issue?,0,0.9864773750305176
1146805063,13443,jeffkbkim,2023-03-23T20:37:10Z,is it necessary to use list?,0,0.9861482381820679
1146877129,13443,philipnee,2023-03-23T21:23:46Z,hey do you want to move the document above the class definition?,0,0.9870815873146057
1148105873,13443,jeffkbkim,2023-03-24T22:19:19Z,do these methods need to be protected?,0,0.9804731607437134
1148110690,13443,jeffkbkim,2023-03-24T22:24:26Z,when should we throw partitionassignorexception? should we throw when topics are not co-partitioned?,0,0.9795641303062439
1148119606,13443,jeffkbkim,2023-03-24T22:36:05Z,can we just define this as minrequiredquota?,0,0.9876667261123657
1148125546,13443,jeffkbkim,2023-03-24T22:48:14Z,i might be missing something - is it possible to decrease the number of partitions? there seems to be a related kip: [a link] but i don't see the new record.,0,0.9576268196105957
1148129063,13443,jeffkbkim,2023-03-24T22:54:58Z,do we want to sort for every retainedpartitionscount?,0,0.9874650239944458
1148132025,13443,jeffkbkim,2023-03-24T23:01:45Z,"can you help me understand why we're incrementing? remaining is the number of partitions remaining to meet the min required quota so if we're giving one of the extra partitions to this member, my intuition tells me that remaining should decremented here.",0,0.979603111743927
1148134237,13443,jeffkbkim,2023-03-24T23:08:04Z,can we create a new arraylist and add it at the end instead of accessing the map each time to add a new partition in l131?,0,0.9880635142326355
1148141785,13443,jeffkbkim,2023-03-24T23:29:17Z,i think we can make this more efficient. removing all elements from one list with another will take o(n^2) assuming both have same size.,0,0.9772687554359436
1148145596,13443,philipnee,2023-03-24T23:38:46Z,"i got pointed out several times to make the param final. i think it's a good practice, wdyt?",1,0.8879756331443787
1148146400,13443,philipnee,2023-03-24T23:41:25Z,"i don't think we need this comment, the intent is pretty obvious.",0,0.9027865529060364
1148149978,13443,philipnee,2023-03-24T23:51:23Z,is it possible to do? [code block],0,0.9875926375389099
1148150169,13443,philipnee,2023-03-24T23:52:05Z,"this and step 2 can be more descriptive. but we probably don't need to explicitly describe the step, i guess.",0,0.9722496867179871
1149558270,13443,philipnee,2023-03-27T17:05:32Z,i wonder if we should put this in common - i assume there's a lot of common use case for pair,0,0.9517629146575928
1149567823,13443,philipnee,2023-03-27T17:15:08Z,i would refactor this into a separated function as it's kind of long.,0,0.9850733876228333
1149569835,13443,philipnee,2023-03-27T17:17:12Z,"you could avoid null check using getordefault(topicid, new hashset<>())",0,0.989168643951416
1149570091,13443,philipnee,2023-03-27T17:17:29Z,"the comment is also not needed, null check here is pretty indicative.",0,0.9665505290031433
1149572710,13443,philipnee,2023-03-27T17:20:07Z,i'm not entirely clear about the point of conversion here: i think it is because of line 181. there couldn't use use the foreach/for( ... : ...) syntax?,0,0.77089923620224
1149630814,13443,rreddy-22,2023-03-27T18:17:17Z,i tried to simplify it as much as possible but since we wanted to many properties the code is a little complex,0,0.9208174347877502
1149644261,13443,rreddy-22,2023-03-27T18:28:14Z,"no its not necessary but it's easier to work with, is there a reason why we should use collection instead of list?",0,0.97359699010849
1149647453,13443,rreddy-22,2023-03-27T18:31:26Z,"it's specific to the data structures we're using for the assignor so i made it protected so only classes that use the same maps can use it, to avoid confusion.",0,0.986401379108429
1149648624,13443,rreddy-22,2023-03-27T18:32:36Z,"this was added by david in the kip, i'm not sure when he meant for this exception to be thrown.",0,0.8332340717315674
1149650468,13443,rreddy-22,2023-03-27T18:34:27Z,"it's easier to understand if it's first named as numpartitionsperconsumer, i also tried to keep as many original variable names as possible so it's simpler to compare it with the client side/ existing range assignor",0,0.9811558723449707
1149655641,13443,rreddy-22,2023-03-27T18:37:49Z,oh! i wasn't sure if it was possible but i just designed the algorithm for all sorts of metadata changes. we could remove it and maybe if/when the removal of partitions is possible we can add it back. removed the code and the test case for now,0,0.5533537864685059
1149658306,13443,rreddy-22,2023-03-27T18:40:15Z,"my bad, moved it before the for loop",-1,0.9840462803840637
1149659044,13443,rreddy-22,2023-03-27T18:41:02Z,"remaining = minrequiredquota - completedquota in cases where there are extra partitions after equally dividing the partitions amongst the consumers they will receive more than the minimum required quota, we're essentially increasing the quota by 1 -> requiredquota = minreq + 1 newremaining = requiredquota - completedquota = minreq + 1 - completedquota = minreq - completed + 1 = remaining + 1",0,0.9801196455955505
1149666320,13443,rreddy-22,2023-03-27T18:48:32Z,"okay yeah makes sense, i'll try to do it with a counter",0,0.9450721740722656
1152197788,13443,jeffkbkim,2023-03-29T16:24:47Z,collection allows iterating over elements which is the only use i see with subscribedtopics. it makes it more generic there's no need to use list here,0,0.986011803150177
1152198768,13443,jeffkbkim,2023-03-29T16:25:38Z,can we make these private?,0,0.9878204464912415
1152199939,13443,jeffkbkim,2023-03-29T16:26:38Z,"you should clarify that, we should be throwing the exception here if that's expected.",0,0.9840230941772461
1152204557,13443,jeffkbkim,2023-03-29T16:29:48Z,we don't use this variable at all except renaming to minrequiredquota. the comments in l170-171 already explain well what the variable represents,0,0.9858365058898926
1152261139,13443,rreddy-22,2023-03-29T17:15:23Z,"yep clarified, we'll add those cases soon!",0,0.7299954891204834
1152265456,13443,rreddy-22,2023-03-29T17:19:13Z,cool i'll rename it,1,0.9682624936103821
1152272541,13443,rreddy-22,2023-03-29T17:26:17Z,yess thanks !,1,0.9203778505325317
1152275571,13443,rreddy-22,2023-03-29T17:29:21Z,"since its already private, its treated as a final param so prolly not necessary here",0,0.9719091057777405
1152276204,13443,rreddy-22,2023-03-29T17:29:59Z,"got it, removed",0,0.98277747631073
1152284259,13443,rreddy-22,2023-03-29T17:36:42Z,"we need the integers that are not in the range [0, numpartitions] on comparison with assignedpartitions i.e we're calculating the difference between the set of assignedpartitions and the total set of partitions for that topic",0,0.9838115572929382
1152285443,13443,rreddy-22,2023-03-29T17:37:50Z,i just figured it would be easier to follow/correlate the code with the steps mentioned in the java doc,0,0.9668303728103638
1152306205,13443,rreddy-22,2023-03-29T17:58:36Z,ohh got it! thanks! changed it!,1,0.9837618470191956
1152313744,13443,rreddy-22,2023-03-29T18:05:48Z,"we need the order of the partitions to be guaranteed and sorted when we're retaining the prev assignment, that's why we had to convert it to a list first.",0,0.9863370060920715
1152314761,13443,rreddy-22,2023-03-29T18:06:51Z,okay i'll refactor it!,0,0.8309330940246582
1152318162,13443,rreddy-22,2023-03-29T18:10:19Z,changed it!,0,0.8484563231468201
1152434986,13443,philipnee,2023-03-29T20:14:32Z,i think the point is final makes the params unmodifiable.,0,0.9504493474960327
1152440653,13443,philipnee,2023-03-29T20:21:08Z,wait why is it specific? this is just a generic tuple no?,0,0.9388478994369507
1153765068,13443,rreddy-22,2023-03-30T20:40:33Z,sry my bad! i was thtinking about the putlist and putset,-1,0.9909253120422363
1156050423,13443,jeffkbkim,2023-04-03T14:32:42Z,this can be removed,0,0.9870893359184265
1156090957,13443,jeffkbkim,2023-04-03T15:03:49Z,should this be topic2name?,0,0.9883397817611694
1156091273,13443,jeffkbkim,2023-04-03T15:04:06Z,nit: consumer c,0,0.974294900894165
1156108091,13443,jeffkbkim,2023-04-03T15:17:35Z,"for expectedassignment, can we add a layer for each memberid? this is blindly matching with any member's assignment which doesn't seem right. then we won't have to remove from the expectedassignment which is also not ideal",0,0.9191880822181702
1156116922,13443,jeffkbkim,2023-04-03T15:24:40Z,you can use map.values() instead of entryset() if you don't need the key.,0,0.9872129559516907
1156117116,13443,jeffkbkim,2023-04-03T15:24:49Z,same here,0,0.982987642288208
1156125078,13443,jeffkbkim,2023-04-03T15:31:14Z,"how do we know [0, 1] went to the same member from the initial assignment?",0,0.9861343502998352
1156240340,13443,rreddy-22,2023-04-03T17:18:04Z,this is a method though so private is implicitly final right?,0,0.9841963648796082
1156241130,13443,rreddy-22,2023-04-03T17:18:52Z,no we want all the mappings to be with uuid,0,0.9840478897094727
1156251873,13443,jeffkbkim,2023-04-03T17:29:52Z,"no, i'm referring to `assignmenttopicmetadata(topic1name, 3)`",0,0.9850550889968872
1156255508,13443,rreddy-22,2023-04-03T17:32:34Z,"no, this was done because we don't know which member gets which assignment. the order of members is not guaranteed at the time of assignment since they are stored in a hash map. so we're testing if the sets are correct and not testing the exact 1:1 mapping",0,0.9765483736991882
1157238218,13443,Hangleton,2023-04-04T13:20:44Z,are you referring to adding the `final` modifier to the parameter `assignmentspec` or the method `consumerspertopic`?,0,0.9872811436653137
1160097876,13443,rreddy-22,2023-04-06T17:54:18Z,ohhh yess thanks!,1,0.9766531586647034
1160098997,13443,rreddy-22,2023-04-06T17:55:36Z,going to add another test for stickiness,0,0.9722475409507751
1160919328,13443,jeffkbkim,2023-04-07T19:34:00Z,"""map of assigned partitions by topicid"" is more readable to me. wdyt?",0,0.9850666522979736
1160920086,13443,jeffkbkim,2023-04-07T19:35:49Z,in kafka we typically name getters as the field itself. in this case it would be `members()`,0,0.9813979864120483
1160921964,13443,jeffkbkim,2023-04-07T19:39:58Z,same on getters,0,0.9856650829315186
1160923243,13443,jeffkbkim,2023-04-07T19:42:41Z,"this doesn't look right in the javadoc. also can we get rid of all of the hyphens after colons? "":-"" to "":"" also, i think [code block] is more readable",0,0.979239821434021
1160925170,13443,jeffkbkim,2023-04-07T19:46:40Z,you can use for numbered lists,0,0.9848190546035767
1160925256,13443,jeffkbkim,2023-04-07T19:46:52Z,"same here for ordered list. also, ""generate a map of consumerspertopic with member subscriptions."" not sure we actually need this point",0,0.9844537377357483
1160927503,13443,jeffkbkim,2023-04-07T19:51:37Z,we need another layer of lists,0,0.9841757416725159
1160929729,13443,jeffkbkim,2023-04-07T19:56:12Z,nit: can we \ all variables \ ?,0,0.985672116279602
1160933184,13443,jeffkbkim,2023-04-07T20:00:32Z,i don't think quota = minquota... is very helpful. how's,1,0.5974084734916687
1160934110,13443,jeffkbkim,2023-04-07T20:02:31Z,how's,0,0.9730865955352783
1160937277,13443,jeffkbkim,2023-04-07T20:10:03Z,"was this comment actually addressed? also, i'm wondering if just creating `member` private class which contains [code block] fields. the current use of the pair class makes the code harder to read.",0,0.9487152695655823
1160938321,13443,jeffkbkim,2023-04-07T20:12:17Z,"the method yes, but the param no. you can still modify assignmentspec inside the method",0,0.9888477325439453
1160939242,13443,jeffkbkim,2023-04-07T20:14:29Z,how's `consumersbytopic`?,0,0.9853128790855408
1160940413,13443,jeffkbkim,2023-04-07T20:17:16Z,nit: `members`,0,0.9760708808898926
1160941760,13443,jeffkbkim,2023-04-07T20:20:15Z,i think [code block] looks simpler. wdyt?,0,0.9838095903396606
1160948260,13443,jeffkbkim,2023-04-07T20:34:27Z,nit: per topicid,0,0.9856696724891663
1160952656,13443,jeffkbkim,2023-04-07T20:44:09Z,do we really need to extract putlist and putset out? it makes the code harder to read. i don't see much benefit from this.,-1,0.6911263465881348
1160953630,13443,jeffkbkim,2023-04-07T20:46:16Z,we can use keyset() here. we're not using the value,0,0.9813289642333984
1160954169,13443,jeffkbkim,2023-04-07T20:47:26Z,nit: `unassignedpartitionspertopic`,0,0.9738227128982544
1160959103,13443,jeffkbkim,2023-04-07T20:55:25Z,we can remove this comment,0,0.9877796173095703
1160967563,13443,jeffkbkim,2023-04-07T21:13:02Z,nit: i.e.,0,0.9592586159706116
1160972155,13443,jeffkbkim,2023-04-07T21:20:08Z,"nit: there's 2 spaces after ""="". also, let's break down the line into 2 lines.",0,0.9801012277603149
1160977912,13443,jeffkbkim,2023-04-07T21:33:40Z,"nit: ""should get i.e. number of partitions per consumer""",0,0.9844106435775757
1160979189,13443,jeffkbkim,2023-04-07T21:37:41Z,"nit: i think we can remove "" = numpartitionsperconsumer"" also `int excesspartitioncount` is simpler and more readable to me. wdyt?",0,0.9853256344795227
1160980503,13443,jeffkbkim,2023-04-07T21:40:55Z,"the numbering is off and ""potentially unfilled consumer"" and l204 ""add to the potentially unfilled consumers""",0,0.9786834716796875
1160982741,13443,jeffkbkim,2023-04-07T21:47:34Z,"we are not ""assigning"" here, we're just increasing the quota. ""after possibly increasing the remaining quota with an excess partition"" makes more sense to me.",0,0.9627081751823425
1160987340,13443,jeffkbkim,2023-04-07T21:55:53Z,are we actually deleting here? we're moving the pointer and grabbing a subset of the unassigned partitions. let's update the comments if we changed the code,0,0.9881414175033569
1160992340,13443,jeffkbkim,2023-04-07T22:03:34Z,"nit: `list partitionstoassign`, `int unassignedpartitionpointer`",0,0.9878653883934021
1164463357,13443,rreddy-22,2023-04-12T17:51:48Z,changed in interface changes,0,0.9835907816886902
1164463758,13443,rreddy-22,2023-04-12T17:52:14Z,changed in interface changes pr,0,0.9819498658180237
1164463893,13443,rreddy-22,2023-04-12T17:52:21Z,changed in interface changes pr,0,0.9819498658180237
1164465796,13443,rreddy-22,2023-04-12T17:54:07Z,done,0,0.9764507412910461
1164469564,13443,rreddy-22,2023-04-12T17:57:55Z,sounds good thanks!,1,0.9819860458374023
1164470089,13443,rreddy-22,2023-04-12T17:58:28Z,done!,0,0.514024555683136
1164884200,13443,rreddy-22,2023-04-13T02:03:12Z,changed to memberspertopic,0,0.9848013520240784
1164884866,13443,rreddy-22,2023-04-13T02:03:51Z,removed the whole comment cause unnecessary,0,0.9176502227783203
1164893597,13443,rreddy-22,2023-04-13T02:12:37Z,changed it,0,0.9793054461479187
1164894366,13443,rreddy-22,2023-04-13T02:13:41Z,removed,0,0.9654131531715393
1164894487,13443,rreddy-22,2023-04-13T02:13:50Z,done,0,0.9764507412910461
1164899524,13443,rreddy-22,2023-04-13T02:17:50Z,ok,0,0.9667208194732666
1164901673,13443,rreddy-22,2023-04-13T02:19:25Z,i edited it but i want to keep it in cause its important,0,0.9472737312316895
1164901770,13443,rreddy-22,2023-04-13T02:19:32Z,ok,0,0.9667208194732666
1164902619,13443,rreddy-22,2023-04-13T02:20:32Z,doesn't exist anymore,0,0.5393503904342651
1164905279,13443,rreddy-22,2023-04-13T02:23:32Z,removed comment,0,0.95928555727005
1164906229,13443,rreddy-22,2023-04-13T02:24:25Z,each consumer gets one extra partition and i think the current name clarifies that,0,0.9852383732795715
1164906996,13443,rreddy-22,2023-04-13T02:25:13Z,done mb with the numbers,0,0.9881049394607544
1164908245,13443,rreddy-22,2023-04-13T02:26:48Z,cool changed it,1,0.9387449622154236
1164908509,13443,rreddy-22,2023-04-13T02:27:06Z,yeah sorry updated the comments,-1,0.9863388538360596
1164911085,13443,rreddy-22,2023-04-13T02:30:03Z,done,0,0.9764507412910461
1169925559,13443,dajac,2023-04-18T12:00:00Z,should we revert this change now?,0,0.9548511505126953
1169925666,13443,dajac,2023-04-18T12:00:06Z,should we revert this change now?,0,0.9548511505126953
1169925763,13443,dajac,2023-04-18T12:00:11Z,should we revert this change now?,0,0.9548511505126953
1169958192,13443,dajac,2023-04-18T12:25:56Z,all the html makes the text quite messy. should we just remove it?,-1,0.8850889801979065
1169959223,13443,dajac,2023-04-18T12:26:47Z,should this section go to the javadoc of `assign`? that would be closer to the implementation.,0,0.9880644679069519
1169966483,13443,dajac,2023-04-18T12:32:52Z,"nit: there is an extra space after `=`. moreover, it seems that we don't mutate `assignedpartitionsfortopic` so we could actually use `collections.emptyset()` instead of `new hashset<>()`.",0,0.9880362749099731
1169982137,13443,dajac,2023-04-18T12:45:18Z,nit: a small stylistic comment: it would be better to structure such line as follow: [code block] i find this more readable than those long lines.,0,0.980063796043396
1170005574,13443,dajac,2023-04-18T13:00:45Z,"is there a reason why we don't do step 4 and 5 directly in the `memberspertopic.foreach((topicid, membersfortopic)` loop?",0,0.9802173376083374
1170007516,13443,dajac,2023-04-18T13:02:11Z,nit: i have noticed that you use `computeifabsent` in a few places where `put` would just work.,0,0.984432578086853
1170010343,13443,dajac,2023-04-18T13:04:31Z,"nit: whenever possible, let's use `collections.singletonmap`, `collections.emptymap`, `collection.emptylist`, etc.",0,0.9888136982917786
1170013892,13443,dajac,2023-04-18T13:07:19Z,nit: let's format such line as follow: [code block],0,0.9857104420661926
1170014726,13443,dajac,2023-04-18T13:07:58Z,nit: is `new arraylist<>` necessary here? there are many other cases.,0,0.988055408000946
1170017991,13443,dajac,2023-04-18T13:10:28Z,i have a few utils [a link]. we could reuse them here as well. they allow you to define as assignment as follow: [code block] it makes the code easier to read.,0,0.9817866683006287
1170021475,13443,dajac,2023-04-18T13:13:12Z,i wonder if it would be better to actually create the expected `groupassignment` and to compare the computed one against it. we could then just use `assertequals` and this would verify the full output.,0,0.9301564693450928
1170322124,13443,rreddy-22,2023-04-18T16:52:38Z,"we discussed this before when i was writing the tests, that is how i did it earlier but i realized that the order of members isn't guaranteed in the hashmap so we don't know exactly what order the assignor used to predict the expected assignment",0,0.964712917804718
1170357303,13443,dajac,2023-04-18T17:23:07Z,"if two maps have the same content, they will be equal, no? the order of the members does not matter here.",0,0.9613384008407593
1170658513,13443,rreddy-22,2023-04-18T23:21:37Z,remove the whole thing or just the html tags,0,0.9825811982154846
1170658595,13443,rreddy-22,2023-04-18T23:21:47Z,cool,1,0.9731137156486511
1170659867,13443,rreddy-22,2023-04-18T23:24:20Z,done,0,0.9764507412910461
1170662644,13443,rreddy-22,2023-04-18T23:30:19Z,the order in which the consumers were assigned partitions is unknown to us since at the time of computing the coordinator accesses the members map (order not guaranteed) so we can't predict which member gets which partitions in the first place. it could result in flaky tests,0,0.8925994634628296
1170981380,13443,dajac,2023-04-19T08:13:23Z,gotcha. i understand what you meant now.,0,0.6350269317626953
1171070403,13443,dajac,2023-04-19T09:23:44Z,just the html tags. the explanation is useful.,0,0.9592124223709106
1171777998,13443,rreddy-22,2023-04-19T19:37:45Z,"you're right, i've removed them!",0,0.8509288430213928
1171778657,13443,rreddy-22,2023-04-19T19:38:30Z,"the formatting is really off without them, that's why we had to add them",0,0.9629641771316528
1171781883,13443,rreddy-22,2023-04-19T19:42:18Z,"i removed most of them and converted them to put before, i'll check again",0,0.9759306311607361
1171782048,13443,rreddy-22,2023-04-19T19:42:27Z,got it,0,0.9009029269218445
1171783796,13443,rreddy-22,2023-04-19T19:44:36Z,like calculate unassigned partitions and assign them at the same time?,0,0.9811739921569824
1171913729,13443,rreddy-22,2023-04-19T22:33:48Z,re-checked and computeifabsent is the best safe way to do it,0,0.9642717838287354
1172314693,13443,dajac,2023-04-20T09:18:19Z,it does not have to be at the same time. i was wondering if there a reason why we need to do step 4 and 5 afterwards with all the unfilled members vs doing it per topic right after step 3.,0,0.934453547000885
1172321570,13443,dajac,2023-04-20T09:23:13Z,let's try at minimum to align/indent/format things correctly. it does not look good as it is.,-1,0.8263821601867676
1172322335,13443,dajac,2023-04-20T09:23:53Z,nit: we usually indent with 4 spaces in this case.,0,0.9861056804656982
1172324109,13443,dajac,2023-04-20T09:25:26Z,this is not correctly indented. it should be as follow: [code block],0,0.9714975953102112
1172325053,13443,dajac,2023-04-20T09:26:15Z,"nit: could we use `collections.singletonmap(topic1uuid, new assignmenttopicmetadata(3))`?",0,0.9887765049934387
1172325341,13443,dajac,2023-04-20T09:26:30Z,`singletonlist`?,0,0.9878096580505371
1172824513,13443,rreddy-22,2023-04-20T16:20:00Z,"i had changed it in my ide and it looked good, idky the formatting changed in the pr :( will take a look at it thanks!",1,0.8411949276924133
1173050527,13443,rreddy-22,2023-04-20T20:17:51Z,okay,0,0.9661229848861694
1173172297,13443,rreddy-22,2023-04-20T23:26:12Z,done,0,0.9764507412910461
1173174594,13443,rreddy-22,2023-04-20T23:31:42Z,we need a set of sets so i added something similar in my test so facilitate the needs of this test case,0,0.9784278869628906
1173177108,13443,rreddy-22,2023-04-20T23:37:24Z,we could've computed if the partition is still unassigned in step 5 directly and assigned it but since this is a range assignor i need all the available partitions in in a sorted list and the list provided is sorted since we iterate through 0-n where n is the total partitions and only add it to unassigned list iff it doesn't exist in the sticky partitions list,0,0.9861680865287781
1173177198,13443,rreddy-22,2023-04-20T23:37:37Z,i hope i understood the question correctly,0,0.6509170532226562
1173179837,13443,rreddy-22,2023-04-20T23:43:38Z,also the entire unfilled members per topic list needs to be populated since the ranges depend on how many partitions were assigned to the prev member,0,0.9849777221679688
1175267055,13443,dajac,2023-04-24T13:14:17Z,would it be possible to directly use `memberassignment` instead of `map ` here? that would save allocating a hashmap at the end.,0,0.9888428449630737
1175273145,13443,dajac,2023-04-24T13:19:07Z,"i still wonder if we could combine steps 4 and 5 in this loop. for instance, could we do something like this? * we start by creating a sorted set with all the partitions of the topic. * then for each member, we do what is already done but instead of populating `assignedstickypartitionspertopic`, we remove assigned partitions from the sorted set. * then we go through the unfilled members and allocated the remaining partitions in the sorted set. this could potentially reduce the number of data structures.",0,0.9299167394638062
1175274363,13443,dajac,2023-04-24T13:20:01Z,should we break this loop when there are no more partitions left to be assigned?,0,0.9694161415100098
1175279644,13443,dajac,2023-04-24T13:24:14Z,nit: we need to close ` `.,0,0.978976845741272
1175280542,13443,dajac,2023-04-24T13:24:54Z,nit: ` ` does not seem to be required.,0,0.9522545337677002
1175552910,13443,rreddy-22,2023-04-24T16:48:56Z,we need to able to modify the map > throughout the code as we assign partitions and since targetpartitions in memberassignment is private final we can't modify it once its initialized. this is why i had to do it this way.,0,0.9835942387580872
1175567311,13443,rreddy-22,2023-04-24T17:03:25Z,"theoretically the sum of all the ""remaining"" values in the unfilled members list for the topic will be equal to the total unassigned partitions so we don't need to break the loop cause it happens automatically. i could add a check to ensure this is the case, i've added a check in the uniform assignor anyways just for a correctness check.",0,0.985516369342804
1175689958,13443,rreddy-22,2023-04-24T19:17:01Z,steps 3 & 4?,0,0.980414628982544
1175701652,13443,rreddy-22,2023-04-24T19:30:51Z,we would need to have a map called partitions and to remove every assigned partition each removal would cost o(logn) so for n removals worst case o(nlogn). the time complexity of just calculating at the end is o(n). so its really just time vs space. we save space of one map o(n+m) in this method but we spend more time for removal.,0,0.9549159407615662
1175703194,13443,rreddy-22,2023-04-24T19:32:33Z,2maps and o(n) time vs 1map (potentially takes up more space if its a tree set for sorted order) and o(nlogn) time,0,0.9851130247116089
1176483468,13443,dajac,2023-04-25T13:01:28Z,"this is not entirely correct. yes, the assignment is private final but this does not prevent you from mutating the hash map. it only prevents you from re-assigning the attribute.",0,0.9577029347419739
1176489630,13443,dajac,2023-04-25T13:06:30Z,"i agree that the sorted set may not be the best so let's put this aside for now. coming back to my other point, would it be possible to compute the unassigned partitions and to assign them directly in this loop? i mean after the current logic in the loop. it does not have to be combined. i understand that we can't assign partitions while we check if we want to keep existing ones or not. if we do this, we could potentially eliminate step 3 or more precisely combine it with the next step. this would simplify the data structures overall, i think.",0,0.9285790920257568
1176631579,13443,jeffkbkim,2023-04-25T14:47:25Z,nit: unassignedpartitionspertopic,0,0.9837730526924133
1176636568,13443,jeffkbkim,2023-04-25T14:50:24Z,"nit: accessing the field looks straightforward enough, do we need this?",0,0.9681705236434937
1176654241,13443,jeffkbkim,2023-04-25T15:00:47Z,"nit: `(""member "" + memberid)`",0,0.9813046455383301
1176661712,13443,jeffkbkim,2023-04-25T15:06:20Z,"we can also change this to `int` once is removed. also, it would be good to describe what this remaining field represents",0,0.9835276007652283
1176666308,13443,jeffkbkim,2023-04-25T15:09:50Z,what if the member already has min required quota + 1 assigned to it? i think it's handled in l192,0,0.98698890209198
1176688479,13443,jeffkbkim,2023-04-25T15:26:48Z,"how's ""it has min req partitions but it may get an extra partition so it is a potentially unfilled member""?",0,0.9868944883346558
1176692608,13443,jeffkbkim,2023-04-25T15:29:52Z,"how's ""if remaining > 0: it has not met the minimum required quota and therefore is unfilled.""",0,0.9711170196533203
1176694961,13443,jeffkbkim,2023-04-25T15:31:44Z,nit: memberandremainingassignments,0,0.9817342758178711
1176836313,13443,jeffkbkim,2023-04-25T17:39:36Z,"do we have a test case where a consumer had 4 partitions, reassignment computes 3 + 1 including the extra partition and we ensure all 4 partitions stick? a case to test whether extra partition is also sticky",0,0.9872714877128601
1177109065,13443,rreddy-22,2023-04-25T22:01:44Z,"oh sorry my bad, i've always learnt that final means you can't modify the value after, but i guess for a map you can't modify the reference but can change the values. i'll see what i can change thanks!",-1,0.9881858825683594
1177128215,13443,rreddy-22,2023-04-25T22:30:12Z,"i think i made a new function cause the assign function was getting super long but yeah we can put just the calculation of unassigned partitions in the same loop, changed it now thanks! sry the step numbers were confusing",1,0.7741032242774963
1177128655,13443,rreddy-22,2023-04-25T22:30:59Z,i think you mean step 4? step 3 is filling in the potentially unfilled members map and that i can't elminate.,0,0.9769399166107178
1177136376,13443,rreddy-22,2023-04-25T22:45:36Z,yeah it is handled 173-179,0,0.9800648093223572
1177139606,13443,rreddy-22,2023-04-25T22:51:57Z,this whole function is removed now,0,0.9799603819847107
1177156557,13443,rreddy-22,2023-04-25T23:27:09Z,"removed, since it was derived from a generic pair class, missed removing it, thanks for the catch!",1,0.9424124956130981
1177156668,13443,rreddy-22,2023-04-25T23:27:23Z,done,0,0.9764507412910461
1177168353,13443,rreddy-22,2023-04-25T23:53:27Z,changed,0,0.9773849844932556
1177168484,13443,rreddy-22,2023-04-25T23:53:41Z,renamed to memberwithremainingassignments,0,0.9814543128013611
1177177698,13443,rreddy-22,2023-04-26T00:15:03Z,added another test just in case,0,0.986389696598053
1177178765,13443,rreddy-22,2023-04-26T00:17:29Z,"not straightforward anymore with the new code, so kept it",0,0.9481114745140076
1177432844,13443,dajac,2023-04-26T07:05:14Z,should those be part of the preceding ` `?,0,0.9841863512992859
1177433390,13443,dajac,2023-04-26T07:05:47Z,nit: does it have to be public?,0,0.9775604009628296
1177434215,13443,dajac,2023-04-26T07:06:42Z,"nit: let's use the javadoc format. also, i would not mention `potentiallyunfilledmembers` and `unfilledmembers` here. let's describe the purpose only.",0,0.9886075854301453
1177434539,13443,dajac,2023-04-26T07:07:06Z,"nit: if we put javadoc for attributes, let's do it for all of them.",0,0.9864700436592102
1177435182,13443,dajac,2023-04-26T07:07:52Z,"nit: as this class is purely internal, i think that we could make the attributes public and remove the getters. they don't bring anything here.",0,0.9731054902076721
1177435368,13443,dajac,2023-04-26T07:08:04Z,nit: javadoc?,0,0.9874899983406067
1177436746,13443,dajac,2023-04-26T07:09:29Z,nit: the javadoc is not aligned correctly.,0,0.8450852036476135
1177437828,13443,dajac,2023-04-26T07:10:37Z,nit: i would remove all the references to variables in the javadoc. they will get out of sync quickly. let's use plain english instead.,0,0.984870195388794
1177438770,13443,dajac,2023-04-26T07:11:38Z,"now that we have all the logic in the main loop, it seems that those maps are not necessary anymore. we could just use lists/sets defined in the loop.",0,0.9837603569030762
1177447096,13443,dajac,2023-04-26T07:20:03Z,now that we have everything in the main loop could we combine step 3 into step 5 and avoid having to recreate memberwithremainingassignments objects here? it seems that we could just adjust the `remaining` when we assign partitions. is it possible?,0,0.9873533248901367
1177447497,13443,dajac,2023-04-26T07:20:30Z,we already have `numpartitionsfortopic`. could we reuse it?,0,0.9892286062240601
1177450105,13443,dajac,2023-04-26T07:23:08Z,nit: we usually put a space before and after the `:`.,0,0.9844388365745544
1177452306,13443,dajac,2023-04-26T07:25:12Z,nit: we can remove this empty line.,0,0.9862961769104004
1177466123,13443,dajac,2023-04-26T07:37:01Z,"i have a general comment about the comments in the code. i think that your comments are very useful to understand the logic. however, they are a bit spread all over the places. i wonder if it would be possible to re-group them a bit. for instance in this case, we could either have one comment for the entire block or one comment per branch. [code block] or [code block]",0,0.8718517422676086
1177506264,13443,dajac,2023-04-26T08:13:32Z,nit: `testoneconsumerwithnosubscribedtopics`?,0,0.9869167804718018
1177508192,13443,dajac,2023-04-26T08:15:02Z,indentation of the arguments seems to be off. it should be like this: [code block],0,0.9707715511322021
1177509263,13443,dajac,2023-04-26T08:15:56Z,"nit: it is usually better to use assertequals for collections as it gives more information when it fails. `assertequals(collections.emptymap(), groupassignment.members())`.",0,0.9862673282623291
1177510234,13443,dajac,2023-04-26T08:16:35Z,nit: `testoneconsumersubscribedtononexistenttopic`?,0,0.9862686991691589
1177511835,13443,dajac,2023-04-26T08:17:38Z,nit: the closing parenthesis of `assignmentmemberspec` should be on a new line and aligned with `new assignmentmemberspec`. the closing parenthesis of `singletonmap` should be aligned with `map `.,0,0.9881981015205383
1177530072,13443,dajac,2023-04-26T08:29:30Z,"nit: this comment feels a bit weird here. i also wonder if this comment is necessary. the subscriptions are clear based on the specs. if you want to keep it, i would rather put it before `members` or you could also have one comment before each `members.put`.",-1,0.9793649911880493
1177541233,13443,dajac,2023-04-26T08:38:56Z,"as i told you offline, i am not a fan of this method. the main issue is that it does not really verify the co-partitioning. moreover, it does not verify the member ids. i am thinking about two alternatives: option 1: [code block] option 2: we could perhaps use a `treemap` instead of an `hashmap` for the members that we pass into the `assignmentspec`. the `treemap` guarantees the order so the algorithm may be deterministic with this. if it is, we could simply compute the expected `groupassignment` and use `assertequals`.",-1,0.8421794772148132
1177543425,13443,dajac,2023-04-26T08:40:49Z,"this is a perfect example to illustrate my previous comment. in this case, `consumera` cannot get `topic3uuid` but we don't really verify this.",0,0.9396622180938721
1177545492,13443,dajac,2023-04-26T08:42:35Z,nit: here we could use my `mkassignment` helper method and inline the current assignment. the would reduce the boilerplate.,0,0.9875963926315308
1177546403,13443,dajac,2023-04-26T08:43:25Z,nit: indentation is off here.,0,0.9875524044036865
1177549003,13443,dajac,2023-04-26T08:45:28Z,nit: indentation is not correct here. there are a few other cases in this file.,0,0.9739800691604614
1177550694,13443,dajac,2023-04-26T08:46:56Z,nit: this empty line could be removed.,0,0.9853678345680237
1177553020,13443,dajac,2023-04-26T08:48:55Z,"in this case, the expected assignment seems to be deterministic so we could just use `assertequals`. this seems to be true for most of the `testreassignment` test cases.",0,0.9863184690475464
1177565215,13443,dajac,2023-04-26T08:58:36Z,should we add tests where we remove or add more than one members?,0,0.9820338487625122
1178059673,13443,rreddy-22,2023-04-26T15:37:31Z,"i got comments before to add tags and put the variable names, thats why i did it",0,0.9796055555343628
1179556594,13443,rreddy-22,2023-04-27T18:44:47Z,changing multiple subscriptions has similar effects as adding and removing consumers and that test exists so i didn't add another one.,0,0.9464649558067322
1179557943,13443,rreddy-22,2023-04-27T18:46:26Z,on it,0,0.9784435033798218
1179746842,13443,rreddy-22,2023-04-27T22:26:20Z,changed,0,0.9773849844932556
1179749224,13443,rreddy-22,2023-04-27T22:28:52Z,"it was public in the client assignor so i kept it public, should i change it to private?",0,0.9862577319145203
1179787876,13443,rreddy-22,2023-04-27T23:13:05Z,regrouped as much as possible,0,0.9772956967353821
1179789140,13443,rreddy-22,2023-04-27T23:14:40Z,oh okay got it,1,0.5672568678855896
1179793263,13443,rreddy-22,2023-04-27T23:23:24Z,added them since during reassignment its not really clear what the old subscriptions were but i removed them wherever it wasn't required,0,0.9689004421234131
1179796793,13443,rreddy-22,2023-04-27T23:31:11Z,"this was my concern too which is why i had asked for advice and this was the best idea we had all come up with, but i like the treemap idea i'm gonna go ahead and do that",1,0.7167342305183411
1179797144,13443,rreddy-22,2023-04-27T23:31:54Z,i verified with print statements so there's no issue with the code however jic that was also a concern,0,0.9509758949279785
1179797402,13443,rreddy-22,2023-04-27T23:32:24Z,"i like the treemap idea, i wish we thought of this sooner :(",-1,0.9881771206855774
1179966618,13443,dajac,2023-04-28T06:10:02Z,ack. we can keep it as public.,0,0.9578892588615417
1179967228,13443,dajac,2023-04-28T06:10:57Z,i understand that the code is doing the right thing. what i meant is that the assertions would not catch all issues.,0,0.9154654741287231
1179968856,13443,dajac,2023-04-28T06:13:40Z,interesting... it is weird to have variable names in the description. plain english is much better than `memberspertopic`.,-1,0.9876235723495483
1179969167,13443,dajac,2023-04-28T06:14:13Z,"yeah, sorry for this. i only thought about it when i raised this comment.",-1,0.9885534048080444
1182715705,13443,rreddy-22,2023-05-02T15:32:13Z,changing it,0,0.9781528115272522
1188009097,13443,rreddy-22,2023-05-09T00:34:03Z,done,0,0.9764507412910461
1188009762,13443,rreddy-22,2023-05-09T00:35:53Z,i think for readability its fine to have currentassignment for b and then just pass it,0,0.9413512945175171
1188270445,13443,dajac,2023-05-09T07:55:42Z,"i still find the html hard to read mainly because it is hard to visually know what is part of the main list and what is part of the sub-list. i wonder if we could indent things better. for instance, we could format it as follow. this is just a suggestion, there may be other ways. [code block]",-1,0.7956156134605408
1188270698,13443,dajac,2023-05-09T07:55:58Z,we could use an `int` here.,0,0.9887668490409851
1188271077,13443,dajac,2023-05-09T07:56:18Z,nit: `topicids` -> `topic ids`?,0,0.9886321425437927
1188272308,13443,dajac,2023-05-09T07:57:26Z,i was thinking about this one. this should never happen because the `targetassignmentbuilder` handle this. therefore i wonder if we should throw a `partitionassignorexception` error with the same error here. what do you think?,0,0.8881102204322815
1188273956,13443,dajac,2023-05-09T07:58:59Z,"i have the same comment regarding the html here. moreover, let's remove those variables in the test and replace them with regular text.",0,0.9883646965026855
1188274698,13443,dajac,2023-05-09T07:59:38Z,nit: `step 1` alone reads weird. could we say `step 1: something...`?,-1,0.9813597202301025
1188278175,13443,dajac,2023-05-09T08:02:57Z,"nit: as `topicdata` is never reused, should we just define `numpartitionsfortopic` as `assignmentspec.topics().get(topicid).numpartitions()`?",0,0.9886738657951355
1188281712,13443,dajac,2023-05-09T08:06:21Z,this comment looks out of context here. would it make sense to have a comment which covers both `minrequiredquota` and `nummemberswithextrapartition` and explains all of this?,0,0.9814348220825195
1188283167,13443,dajac,2023-05-09T08:07:43Z,nit: let's add a small explanation here as well.,0,0.9754101037979126
1188283174,13443,rreddy-22,2023-05-09T08:07:43Z,all tests are checked with 1:1 mapping now so this is taken care of now,0,0.9785652756690979
1188284004,13443,rreddy-22,2023-05-09T08:08:27Z,plain english for everything?,0,0.9825124740600586
1188291620,13443,dajac,2023-05-09T08:15:42Z,"nit: i wonder if we should just remove this part of the comment or shorten it. the important part, i think, is that we retain at max the min require quota.",0,0.9670159220695496
1188300132,13443,dajac,2023-05-09T08:23:09Z,"i feel like there are too many comments here. could we try to simplify and to re-group them? for instance, we could structure it as follow: [code block]",-1,0.8348630666732788
1188302467,13443,dajac,2023-05-09T08:25:15Z,nit: it would be good to explain why `ascending order` is required here.,0,0.9636304378509521
1188303243,13443,dajac,2023-05-09T08:26:00Z,nit: indentation should be 4 spaces in order to be consistent with how you did it previously. the same applies to l226.,0,0.9874342083930969
1188307585,13443,dajac,2023-05-09T08:29:55Z,"i am curious. is there a reason why you structured it like this? everywhere, we usually structure it as follow: [code block] this is more readable in my opinion.",0,0.6546679735183716
1188323433,13443,rreddy-22,2023-05-09T08:43:39Z,changed it thanks!,1,0.9441241025924683
1188374768,13443,dajac,2023-05-09T09:25:54Z,nit: we should also assert the size.,0,0.9859868884086609
1188375282,13443,dajac,2023-05-09T09:26:23Z,is this still useful now that we have `assertassignment`?,0,0.9861331582069397
1188378752,13443,dajac,2023-05-09T09:29:18Z,let's remove step 5 here and include it in step 4.,0,0.986443281173706
1188385263,13443,dajac,2023-05-09T09:34:38Z,this is interesting. should we still create a member in this case but with an empty assignment?,0,0.6742382645606995
1188387610,13443,dajac,2023-05-09T09:36:26Z,nit: you can use `mkassignment` to replace those. there are other similar cases.,0,0.9881507158279419
1188811581,13443,rreddy-22,2023-05-09T15:51:39Z,"it takes away from the fact that its step one if we write everything in the same line, i wanted to draw attention to it",0,0.9145069718360901
1188817725,13443,rreddy-22,2023-05-09T15:56:30Z,i had it before and then i was told to remove it,0,0.9770721793174744
1188819218,13443,rreddy-22,2023-05-09T15:57:42Z,"this was fixed already, please see the new code, it says outdated on the top",0,0.9851577281951904
1188821039,13443,rreddy-22,2023-05-09T15:59:12Z,"i think its fine honestly, its different from step 4. if its too much in one step there isn't really much point in breaking it up right?",0,0.894791841506958
1188821932,13443,rreddy-22,2023-05-09T15:59:57Z,that's what i asked and you had told me that either way is fine. i can change it to anything depending on how the rest of the code works,0,0.9367698431015015
1188823115,13443,rreddy-22,2023-05-09T16:00:55Z,we don't need it but we wanted separate property tests right?,0,0.9810836911201477
1188832049,13443,rreddy-22,2023-05-09T16:08:31Z,i just wanted to do it topic wise so its easier to understand but i'll change it,0,0.921377420425415
1188856580,13443,dajac,2023-05-09T16:29:27Z,[code block] is also fine. my point is that `step 1` alone is weird.,-1,0.9795844554901123
1188857767,13443,dajac,2023-05-09T16:30:29Z,"interesting... i feel like this part is more important than all the rest, no?",0,0.43741193413734436
1188857900,13443,dajac,2023-05-09T16:30:36Z,ack.,0,0.7720441818237305
1188858930,13443,dajac,2023-05-09T16:31:36Z,"yeah, it was because we were not able to use equals. now that we can use it, i am not sure that this one bring any value. does it?",-1,0.6022350788116455
1188873259,13443,dajac,2023-05-09T16:43:17Z,"yeah, that's right. it does not matter from the targetassignmentbuilder perspective. we can keep it as it is.",0,0.9739733934402466
1188891203,13443,rreddy-22,2023-05-09T16:59:51Z,done.,0,0.9759407639503479
1188891494,13443,dajac,2023-05-09T17:00:11Z,i think that it is better to have one comment for the entire block of code. it makes reading it easier.,0,0.9446765780448914
1188893117,13443,dajac,2023-05-09T17:01:47Z,nit: indentation is still inconsistent here.,0,0.967720091342926
1188893187,13443,dajac,2023-05-09T17:01:51Z,nit: indentation is still inconsistent here.,0,0.967720091342926
1188893478,13443,dajac,2023-05-09T17:02:07Z,nit: ` : `.,0,0.9646991491317749
1188898373,13443,dajac,2023-05-09T17:06:58Z,`currentsize` does not exist any more. this is why i don't like to use variable names in comments :),1,0.51866215467453
1189210485,13443,rreddy-22,2023-05-09T23:13:29Z,"it looks a bit wonky after formatting it like that, i don't think there's a great way to add this html",-1,0.9693425297737122
1189212267,13443,rreddy-22,2023-05-09T23:17:31Z,i did it in a way that looks best to me in the next commit,0,0.9377778172492981
1189213049,13443,rreddy-22,2023-05-09T23:19:18Z,"nop we can remove it, ig whoever wants it later can write it again",0,0.9744110107421875
1189214614,13443,rreddy-22,2023-05-09T23:23:00Z,okayyy,0,0.857880175113678
1189216148,13443,rreddy-22,2023-05-09T23:26:11Z,sorry,-1,0.9871875047683716
1189216494,13443,rreddy-22,2023-05-09T23:26:54Z,sorry fixed,-1,0.9850955605506897
1189229522,13443,rreddy-22,2023-05-09T23:57:16Z,i got comments saying don't repeat something that's already been mentioned before so i'm pretty sure i had something there and then removed it,0,0.9470527768135071
1189229707,13443,rreddy-22,2023-05-09T23:57:46Z,its already in the java doc step by step so that is merely there to make sure people understand which step we're talking about,0,0.9803343415260315
1189229928,13443,rreddy-22,2023-05-09T23:58:14Z,sure,0,0.9371067881584167
1189231170,13443,rreddy-22,2023-05-10T00:01:09Z,"i removed it, its not that necessary, i just wanted people to have more information on things that i personally got confused about",-1,0.835322380065918
1189231412,13443,rreddy-22,2023-05-10T00:01:40Z,"same explanation as before, i was told not to repeat things that have already been mentioned :(",-1,0.9848462343215942
1189231570,13443,rreddy-22,2023-05-10T00:01:58Z,i removed it,0,0.9800844192504883
1189235728,13443,rreddy-22,2023-05-10T00:11:46Z,okay i wont use variable names again,0,0.9847940802574158
1189237663,13443,rreddy-22,2023-05-10T00:16:32Z,thats how it was before and i was told to change it,0,0.9450918436050415
1189295560,13443,dajac,2023-05-10T02:31:46Z,ok. i was not aware of this.,-1,0.7773529887199402
1189296233,13443,dajac,2023-05-10T02:32:48Z,i understand. it was just misplaced in my opinion.,-1,0.7138544321060181
1189296779,13443,dajac,2023-05-10T02:33:30Z,ok. i was not aware of this. sorry for this.,-1,0.9884786009788513
1189296913,13443,dajac,2023-05-10T02:33:41Z,ack.,0,0.7720441818237305
1189297499,13443,dajac,2023-05-10T02:34:49Z,"looks good, thanks.",1,0.9419525265693665
281150684,6592,miguno,2019-05-06T11:43:38Z,doesn't guard against npe (`data` might be null).,0,0.9216352701187134
281151355,6592,miguno,2019-05-06T11:45:36Z,why isn't there an additional constructor with a default `comparator`?,0,0.9648746848106384
281152067,6592,miguno,2019-05-06T11:47:38Z,"also, why does the serde need a `comparator` at all?",0,0.9772352576255798
281263059,6592,miguno,2019-05-06T16:41:25Z,we should use try-with-resources here (for `datainputstream`).,0,0.9883894920349121
281263464,6592,miguno,2019-05-06T16:42:38Z,we should use try-with-resources here (for `bytearrayoutputstream` and `datainputstream`).,0,0.9890291690826416
281263644,6592,miguno,2019-05-06T16:43:05Z,"this also fixes the problem that, in the current code, the `bytearrayoutputstream` was not closed.",0,0.9843276143074036
281264102,6592,miguno,2019-05-06T16:44:24Z,asking because neither a `list ` nor a `deserializer ` need a `comparator`.,0,0.9777308702468872
281285669,6592,yeralin,2019-05-06T17:43:15Z,put it on a discussion: [a link] thank you for your input! i highly appreciate it :),1,0.9933910369873047
287207631,6592,mjsax,2019-05-24T03:52:15Z,i think we should call `deserializer.configure(...)` here,0,0.9881004095077515
287207698,6592,mjsax,2019-05-24T03:52:47Z,i think we should call `deserializer.close()` here,0,0.9798319935798645
287208093,6592,mjsax,2019-05-24T03:56:00Z,should we get the `size` first and pass it into `arraylist` constructor to make it more efficient?,0,0.987737774848938
287208576,6592,mjsax,2019-05-24T04:00:08Z,forward call to `serializer`,0,0.9890679717063904
287460369,6592,yeralin,2019-05-24T17:55:17Z,is it sufficient for testing listserde?,0,0.9880578517913818
287470423,6592,mjsax,2019-05-24T18:26:10Z,"we should also test `null` and empty array imho. please, add new test methods for both cases.",0,0.9888123273849487
296436321,6592,mjsax,2019-06-22T06:33:31Z,"as mentioned on the kip discussion, `bytesdeserializer` should not be included.",0,0.9844468235969543
296436331,6592,mjsax,2019-06-22T06:34:22Z,i using `stream.of` the best was to populate the map? seems to be unnecessarily complex to me?,-1,0.5609550476074219
296436380,6592,mjsax,2019-06-22T06:37:34Z,"i would add test for all primitive types. the test should also check the expected `byte[]` array size after serialization and test a ""round trip"". we should also have a test for non-primitive type round-trip. lastly, i would add a test for deserializing different list-types. also `null` corer case should be tested.",0,0.9881112575531006
303481813,6592,yeralin,2019-07-15T14:59:13Z,replaced it with simpler approach: [code block],0,0.9847193956375122
304072719,6592,yeralin,2019-07-16T19:04:30Z,where should i place all of these new test cases? should i create a new class?,0,0.9759035110473633
307013332,6592,mjsax,2019-07-24T20:46:22Z,add new test methods to this test should be sufficient.,0,0.9843155741691589
307015039,6592,mjsax,2019-07-24T20:50:28Z,both `_doc` variables should me moved to `commonclientconfigs`,0,0.9874120950698853
307015480,6592,mjsax,2019-07-24T20:51:21Z,nit: remove whitespace before `default` (similar for the other 3 `_doc` strings),0,0.9884853363037109
307016006,6592,mjsax,2019-07-24T20:52:38Z,"why `or default_list_value_serde_inner_class` ? for the key, we only care about the key part. (similar below for value -- we should only care about the value part.)",0,0.979921817779541
307016504,6592,mjsax,2019-07-24T20:53:53Z,we should explain that this config is only used if `key.deserializer` is set to `listdeserializer`. similar for the type config below.,0,0.9888203740119934
307016893,6592,mjsax,2019-07-24T20:54:47Z,the class does not implement `deserializer` but `list`.,0,0.9830337166786194
307017972,6592,mjsax,2019-07-24T20:57:33Z,can we actually include uuid type? it always 16 bytes.,0,0.9897828698158264
307018186,6592,mjsax,2019-07-24T20:58:04Z,nit: maybe call this `fixedlengthdeserializers` -- it's not about primitive types.,0,0.9849531054496765
307026623,6592,abbccdda,2019-07-24T21:20:06Z,"avoid star import, same for the rest",0,0.9698415994644165
307036896,6592,mjsax,2019-07-24T21:50:20Z,both new configs should be added below: [code block] similar for `producerconfig` and `streamsconfig`,0,0.9877436757087708
307037138,6592,mjsax,2019-07-24T21:51:10Z,"i think this could be `string` or `class` type. not sure. for any case, we should test for both cases.",0,0.983958899974823
307037211,6592,mjsax,2019-07-24T21:51:24Z,same here,0,0.982987642288208
307037543,6592,mjsax,2019-07-24T21:52:22Z,should we have two try-catch blocks? one for `listclass` and one for `inner` ?,0,0.988275408744812
307037605,6592,mjsax,2019-07-24T21:52:35Z,nit: remove `this` (not required),0,0.9868379235267639
307037957,6592,mjsax,2019-07-24T21:53:41Z,how do we know that all list types implement a constructor like this? should we have a fall back to default constructor?,0,0.9814357161521912
307038250,6592,mjsax,2019-07-24T21:54:41Z,rename similar to listdeserializer and add uuid type?,0,0.9890896677970886
307038415,6592,mjsax,2019-07-24T21:55:13Z,rename? why not use `boolean`?,0,0.9829124212265015
307038590,6592,mjsax,2019-07-24T21:55:50Z,this could also be `class` type?,0,0.9883028864860535
307296391,6592,yeralin,2019-07-25T13:31:34Z,"fixed, had to change my intellij config.",0,0.9808456897735596
307302882,6592,miguno,2019-07-25T13:44:40Z,"why is the `bytearrayoutputstream` not covered by try-with-resources? it should, no?",0,0.9780780673027039
307305083,6592,miguno,2019-07-25T13:48:24Z,"shouldn't we also add `bytesserializer` and `bytearrayserializer` here? same question for deserialization. edit: i did notice that we do some ""testing for primitives"" by doing `contains()` on `primitiveserializers`. +1 to also adding uuid serializer (and deserializer).",0,0.983230710029602
307308603,6592,miguno,2019-07-25T13:55:01Z,"why is this needed only for non-primitives, and not always?",0,0.960966944694519
307309387,6592,yeralin,2019-07-25T13:56:31Z,i guess smth like this: [code block],0,0.9753522872924805
307309648,6592,miguno,2019-07-25T13:57:02Z,"i think the list serde should return null (after a round trip) if and only if the input was null. if the input was an empty list, then the list serde should instead return an empty list. that is, i believe the serde needs to distinguish between the absence of a collection (indicated by null) and a collection that happens to be empty.",0,0.9775152802467346
307311596,6592,yeralin,2019-07-25T14:00:36Z,changed to boolean primitive. what do you think is the best name for it instead of `isprimitive`? `isfixedlength` maybe?,0,0.9877110123634338
307312643,6592,yeralin,2019-07-25T14:02:48Z,i was following impl of `sessionwindowedserializer`,0,0.9855983853340149
307316124,6592,yeralin,2019-07-25T14:09:34Z,mentioned during the kip discussion: [code block] i'll add uuid (de)serializers,0,0.988756000995636
307320943,6592,yeralin,2019-07-25T14:19:01Z,you mean we can directly cast it to `class` object? i.e. `class listtype = (class) configs.get(listtypepropertyname);`,0,0.9860827326774597
307321201,6592,yeralin,2019-07-25T14:19:28Z,i was following impl of `sessionwindoweddeserializer`,0,0.9810221791267395
307322886,6592,yeralin,2019-07-25T14:22:49Z,"yes, i think it will make errors more descriptive",0,0.9210320711135864
307323343,6592,yeralin,2019-07-25T14:23:38Z,probably add a warning log? what do you think?,0,0.9692990779876709
307326098,6592,yeralin,2019-07-25T14:28:36Z,"if i understand your question correctly: this was an optimization feature. if we have a collection of fixed length elements like `integer`, `long`, `uuid`, etc. we don't actually need to encode each element's size. that's why i have this extra if statement. if that's what you were asking",0,0.9630290269851685
307329101,6592,yeralin,2019-07-25T14:33:43Z,smth like: [code block],0,0.9855740666389465
307332736,6592,yeralin,2019-07-25T14:40:14Z,what `importance` should these configs be set to?,0,0.9846304059028625
307336073,6592,yeralin,2019-07-25T14:46:23Z,"should i add `doc`s for `default_list_key/value_serde_inner_class` configs? i was looking at `default_windowed_key/value_serde_inner_class` configs in `streamsconfig` class, and they don't have docs underneath them.",0,0.9889757633209229
307429344,6592,mjsax,2019-07-25T18:03:55Z,yes,0,0.9564858078956604
307429932,6592,mjsax,2019-07-25T18:05:13Z,i think low (or maybe medium) because it's dependent config,0,0.9786932468414307
307431168,6592,mjsax,2019-07-25T18:08:12Z,"yes. the user can use the config two ways: [code block] both should be supported and the code need to be able to handle both cases. hence, we should get is as `object` and use `instanceof` to check the type.",0,0.9877421855926514
307432566,6592,mjsax,2019-07-25T18:11:21Z,this may indicate a bug in `sessionwindoweddeserializer`,0,0.9784706830978394
307433215,6592,mjsax,2019-07-25T18:12:50Z,don't think we need a warning. wondering if we should use try-catch or better pro-actively check if an int-constructor exists?,0,0.9582259654998779
307433392,6592,mjsax,2019-07-25T18:13:16Z,sgtm,0,0.9783707857131958
307433534,6592,mjsax,2019-07-25T18:13:36Z,seems like a bug in `sessionwindowedserializer`,0,0.5283147692680359
307434421,6592,mjsax,2019-07-25T18:15:42Z,"sound like something we should fix, ie, add corresponding doc entries to `streamsconfig`",0,0.9583009481430054
307444815,6592,yeralin,2019-07-25T18:39:33Z,"yep, i think medium is more appropriate since it is a interconnected config scheme",0,0.9495958089828491
307448021,6592,yeralin,2019-07-25T18:47:13Z,something like this i presume: [code block],0,0.9767261743545532
307448892,6592,yeralin,2019-07-25T18:49:17Z,"we kind of implicitly check if int-constructor exists using this try-catch block, right?",0,0.9858981370925903
307464495,6592,yeralin,2019-07-25T19:28:42Z,"ok i added the following tests: `listserdeshouldroundtripprimitiveinput(): arrays.aslist(1, 2, 3)` `listserdeshouldrountripnonprimitiveinput(): arrays.aslist(""a"", ""b"", ""c"")` `listserdeshouldreturnemptycollection(): arrays.aslist()` `listserdeshouldreturnnull(): null` `listserdeserializershouldreturnbytearrayofsize(): arrays.aslist(1, 2, 3) => 16` `listserdeshouldreturnlinkedlist() new linkedlist<>()` `listserdeshouldreturnstack() new stack<>()` i think i covered it all. btw you said *all primitive types*, you mean all 6 of them, right?",0,0.9807552099227905
309339359,6592,mjsax,2019-07-31T17:22:07Z,seems this variable is still misssing the corresponding doc string? (same for `default_list_value_serde_inner_class` below),0,0.9883027672767639
309341518,6592,mjsax,2019-07-31T17:26:44Z,"we should point out, that this config is only affective iff `key.deserializer` is set to `listdeserializer`.",0,0.9869685769081116
309342714,6592,mjsax,2019-07-31T17:29:33Z,"seems you still did not add the config to the static `config` variable below. (this must be done for consumerconfig, producerconfig, and streamsconfig)",0,0.9881690740585327
309344282,6592,mjsax,2019-07-31T17:33:18Z,"not: remove space before `"" default...""` also, this variable should be moved to `commonclientconfigs` imho. (same commend for value below.)",0,0.9831361174583435
309344677,6592,mjsax,2019-07-31T17:34:24Z,this comment is not addressed yet,0,0.9355717897415161
310367315,6592,mjsax,2019-08-04T01:40:26Z,"`note when list serde class is used` -> seems be a little fuzzy if one does not know the context. it might be better to be very explicit. what about: [code block] we should be similarly explicit, for the ""inner serde"" configs.",0,0.9826845526695251
310367323,6592,mjsax,2019-08-04T01:41:02Z,avoid unnecessary reorderings (this class does not contain any actual code change).,0,0.9720820188522339
310367328,6592,mjsax,2019-08-04T01:41:34Z,as above (similar for other files below).,0,0.9855080246925354
310367336,6592,mjsax,2019-08-04T01:42:10Z,nit: fix indention and align to existing code,0,0.9887131452560425
310367353,6592,mjsax,2019-08-04T01:43:38Z,should be type `class` (similar below); cf. `key_deserializer_class_config`,0,0.9870720505714417
310367365,6592,mjsax,2019-08-04T01:44:10Z,as above: `class` and fix indention,0,0.9863609075546265
310618942,6592,yeralin,2019-08-05T14:00:08Z,"`default_key_serde_class_config` is not accessible from `comminclientconfigs` since it lives in `streamsconfig`, the same applies for `listserde.class.getname()`",0,0.9869484901428223
329244889,6592,mjsax,2019-09-27T20:45:58Z,"should this be `map , integer>` ? seem we should declare it as `static` ?",0,0.987842321395874
329245133,6592,mjsax,2019-09-27T20:46:40Z,should it be `class listclass` ? (or `class ` if we don't introduce `l`),0,0.988166868686676
329249087,6592,mjsax,2019-09-27T20:58:26Z,"i am wondering, if we should get the `list` type as generic (not sure). `public class listdeseializer , t> implements deserializer `",0,0.974052906036377
329250304,6592,mjsax,2019-09-27T21:02:21Z,should this be `class >` (or maybe `class ` if we introduce `l extends list ` as class generic?,0,0.9873805046081543
329250920,6592,mjsax,2019-09-27T21:04:18Z,we should limit this suppression to the method for which we really need it instead of the whole class,0,0.9825679659843445
329251104,6592,mjsax,2019-09-27T21:04:55Z,`constructor >` (or `constructor ` if we introduce `l`),0,0.9862922430038452
329251296,6592,mjsax,2019-09-27T21:05:33Z,update return type to `l` (if we introduce `l`),0,0.9884003400802612
329251591,6592,mjsax,2019-09-27T21:06:32Z,update return type to `l` (if we introduce `l`),0,0.9884003400802612
329251673,6592,mjsax,2019-09-27T21:06:45Z,update return type to `l` (if we introduce `l`),0,0.9884003400802612
329252615,6592,mjsax,2019-09-27T21:10:07Z,avoid global suppress,0,0.9552559852600098
329253153,6592,mjsax,2019-09-27T21:12:14Z,`list >` should be `static`,0,0.9855123162269592
329253861,6592,mjsax,2019-09-27T21:14:49Z,`class ` (or just `class `?),0,0.9884563684463501
329254244,6592,mjsax,2019-09-27T21:16:20Z,"should we change to `listserde , t> extends wrapperserde >` (cf. `listdeserializer` comments) note: we should not use `wrappedserde ` because the wrapper `serializer` uses `list ` but not `l` (not sure if we want to tie the serializer type to a fixed list type, but i guess we should not).",0,0.9885413646697998
329254510,6592,mjsax,2019-09-27T21:17:21Z,add missing `<>` to `new listserializer<>(...)`,0,0.9857429265975952
329255698,6592,mjsax,2019-09-27T21:21:49Z,"if we fix the generics, we don't need this suppress",0,0.9860821962356567
340187181,6592,vvcephei,2019-10-29T16:29:06Z,"it's better to avoid ""double-brace initialization"", which is actually declaring a new anonymous subclass of hashmap just to add some stuff to it in one statement. a little while back, i added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.utils#mkmap`, and the accompanying `org.apache.kafka.common.utils.utils#mkentry`.",0,0.985813558101654
340190515,6592,vvcephei,2019-10-29T16:34:53Z,"this shouldn't be necessary. i believe the config parser will coerce the value to the type you declared the configuration as, `type.class`. might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.",0,0.9726302623748779
340191653,6592,vvcephei,2019-10-29T16:36:58Z,"that class is different because it doesn't actually `define` the config, it's just an undeclared ""extra"" config that gets passed around to be interpreted inside the serde. actually, this _is_ a bug, and that config _should_ be `define`d there the way you do it here.",0,0.9545009732246399
340192387,6592,vvcephei,2019-10-29T16:38:20Z,"+1, just add this suppression on the methods that need it.",0,0.9777136445045471
340237949,6592,vvcephei,2019-10-29T17:58:44Z,"these new tests look good. i agree, though, that we should test round trip + length for each of the primitive types (short, integer, long, float, double, and uuid). just because it would be easy to mess up just one of them, so we really should have test coverage for them all.",1,0.8928233981132507
342316240,6592,mjsax,2019-11-04T23:10:31Z,should we add a similar sentence like `this configuration will be read if....` to `commonclientconfigs#default_list_key_serde_inner_class_doc ` (similar for value) ?,0,0.9895053505897522
342320732,6592,mjsax,2019-11-04T23:27:37Z,nit: merge both lines: `byte[] payload = new byte[primitivesize == null ? dis.readint() : primitivesize];`,0,0.9884923696517944
342321230,6592,mjsax,2019-11-04T23:29:29Z,nit: indentation should be 4 spaces?,0,0.9866399168968201
342321277,6592,mjsax,2019-11-04T23:29:38Z,nit: indentation should be 4 spaces?,0,0.9866399168968201
342326150,6592,mjsax,2019-11-04T23:48:49Z,nit: move this class definition to l127 (after `static public final class uuidserde extends wrapperserde {`) to group all defined serde classes.,0,0.9895044565200806
342326188,6592,mjsax,2019-11-04T23:48:58Z,can be removed (if we change the class to `extends wrapperserde `),0,0.9878172278404236
342326296,6592,mjsax,2019-11-04T23:49:23Z,the cast to `(deserializer >)` is not necessary if we change the class to `extends wrapperserde `.,0,0.9875982403755188
342326601,6592,mjsax,2019-11-04T23:50:40Z,nit: add those into section `// medium` and insert in alphabetical order within the section,0,0.9877553582191467
342337097,6592,mjsax,2019-11-05T00:35:31Z,nit: this method should be after static method `static public serde void() {` to keep stuff grouped,0,0.9884613752365112
342345719,6592,mjsax,2019-11-05T01:14:54Z,"i was playing with the code a little bit, and turns out using `class ` instead of `class ` might actually be too strict. compare my other comments.",0,0.9495654106140137
342345818,6592,mjsax,2019-11-05T01:15:29Z,not 100% sure -- but we need tests for this cases. the `configure()` code is untested atm,0,0.9866377115249634
342346108,6592,mjsax,2019-11-05T01:17:14Z,we could change the signature to [code block] to make it type safe... but there are issue (i also mentioned this for `listdeserializer` above -- also compare my comment below),0,0.9888908863067627
342346253,6592,mjsax,2019-11-05T01:17:59Z,"also could make types mores strict via `extends wrapperserde ` again, as mentioned above, not sure if this might be too strict.",0,0.9749104380607605
355461955,6592,JakobEdding,2019-12-09T13:56:55Z,"typo, `deerializer`",0,0.9858039617538452
364943202,6592,zorgz,2020-01-09T20:23:31Z,inner.serialize() can return null here in case of the list entry is null for example then npe will follow at [a link],0,0.9880978465080261
364993597,6592,yeralin,2020-01-09T22:35:10Z,"hmmm that's an interesting edge case. i cannot just return null since a list might contain real values i.e. `list data = {'a', null, 'c'}` i have to serialize `null` somehow...",0,0.9143922328948975
365021029,6592,zorgz,2020-01-10T00:13:25Z,i get it with abstractkafkaavroserializer and my custom array serde abstractkafkaavroserializer code: [code block],0,0.98604416847229
368185579,6592,mjsax,2020-01-18T00:13:59Z,nit: should be `deserializer ` to avoid warnings about using a raw type,0,0.9866118431091309
368185717,6592,mjsax,2020-01-18T00:14:55Z,nit: should be ` >` to avoid warning about using a raw type,0,0.9867662191390991
368186003,6592,mjsax,2020-01-18T00:16:30Z,nit: should be `class >` (2 times) -- (not `serde` compare comment above) and we want to avoid warning about using a raw type also `innerserde -> innerdeserializerclass`,0,0.9874655604362488
368187510,6592,mjsax,2020-01-18T00:25:38Z,"this is `listdeserializer` hence, shouldn't we use `consumerconfig.list_key_deserializer_inner_class_config` ? the ""serde"" config should be used in kafka streams codebase only? (same for value, and for both inner types in the next line).",0,0.9897363185882568
368188170,6592,mjsax,2020-01-18T00:29:56Z,nit: should be `serializer ` to avoid warnings about using a raw type,0,0.9883082509040833
368188407,6592,mjsax,2020-01-18T00:31:15Z,"as above: use `producerconfg.list_key_serializer_inner_class_config` instead of ""serde"" config parameters (2 times) also `innerserdepropertyname -> innerserializerpropertyname`",0,0.9876148700714111
368188720,6592,mjsax,2020-01-18T00:33:05Z,nit: `innerserdepropertyname -> innerdeserializerpropertyname`,0,0.9846550226211548
368189063,6592,mjsax,2020-01-18T00:35:29Z,nit: `innerserde -> innerserializerclassorname`,0,0.9864904880523682
368189160,6592,mjsax,2020-01-18T00:36:10Z,should be: [code block],0,0.9871029257774353
368189561,6592,mjsax,2020-01-18T00:38:33Z,should be: [code block],0,0.9871029257774353
368189677,6592,mjsax,2020-01-18T00:39:28Z,"`""serde class ""` -> `""serializer class ""`",0,0.9847501516342163
368191352,6592,mjsax,2020-01-18T00:51:39Z,"that is a tricky question. there are multiple ways how we could encode this, but this seem to be a design question that required to go back to the kip discussion? for example, we could skip the optimization of fixed-length types and encode the length for every entry -- a length of `-1` would indicate a `null`. or we introduce a ""header"" that tells us if there are `null` in the list (either a bit-array for short list or a ""list of null positions"") example for list of null positions would be: ` ` ie, with the example for above, we encode `1-1- - `. as bit array, it would be ` ` ie, with the example for above, we encode `1-0100000- - `",0,0.8706873655319214
368191525,6592,mjsax,2020-01-18T00:53:02Z,should be ` >` to avoid raw type warning and make build pass,0,0.9875779747962952
368191582,6592,mjsax,2020-01-18T00:53:30Z,"should be ` , inner>` to avoid raw type warning and make build pass",0,0.9875220656394958
368191860,6592,mjsax,2020-01-18T00:55:56Z,"i am wondering now, why we actually need `commonclientconfigs.default_list_key_serde_inner_class` (maybe there was a reason by i forgot) -- can't we add the ""serde"" configs only to `streamsconfig`?",0,0.9093786478042603
369420107,6592,mjsax,2020-01-22T08:21:25Z,"thinking about it once more, it might not work what i suggested, because if you want to call `serde.listserde(arraylist.class, ...)` the `arraylist` does not specify any inner type information (but is a raw type) and thus it won't compile. i guess, we need to leave it as-is, and suppress the ""raw type"" warning (might be worth to add a comment why the raw type warning cannot be avoided for this case).",0,0.971911609172821
369420640,6592,mjsax,2020-01-22T08:22:46Z,"same as below -- i guess my suggestion does not work in practice (it's correct that it would avoid the raw type warning, but it would make the api unusable in practise because we want to be able to pass in raw type list classes).",0,0.9704872965812683
370513438,6592,mjsax,2020-01-24T08:15:57Z,"i was thinking about this case more. i really think, that the fix-length optimization is valuable as it reduced the serialized byte size by 50% for e.g. integer lists. for the other two proposals, it's harder to judge which one is better. i see the following (dis)advantages for each: null-index-list: - low overhead for dense lists with few nulls (for zero nulls, it’s 4 byte overhead, for each null, it’s additional 4 bytes) - the longer the lists, the smaller the overhead bit-array: - low overhead for short lists (4 bytes for byte array length + list-lenght/8 bytes for the byte-array itself) - not ideal for long lists with few nulls hence, for short list both might be equally ok. for long lists, it depends of they are dense or sparse (for long-dense list, null-index-list seems to be better, for long-sparse-lists, bit-array seems to be better). it will be hard to tell which one is better, hence, i would suggest that we only implement the null-index-list list for now, because i assume that dense lists are more common and it works better for long dense lists than the bit-array idea. however, to allow us to support different serialization format in the future, we should add one more magic byte in the very beginning that encodes the choose serialization format. in our case, we will will have one format and the magic byte will always be ""zero"". if we add the byte-array format, we can just set the magic byte to one to indicate the other format. and we could even add more formats of people have a better idea how to do it later on. btw: we could actually already go with two formats: - 0 => optimized-fixed-length-encoding plus null-index-list - 1 => variable length encoding using `-1` in the length field to indicate `null` (no header to mark nulls is required at all for this case). if we agree on this design, we should update the kip accordingly. \cc : would love to hear your feedback, too.",0,0.6186109185218811
371434275,6592,yeralin,2020-01-27T19:23:57Z,"thank you for your input your outline makes sense, i like the idea of `null-index-list`, and i'm happy to jump back to the kip. however, could we please wrap up this round of review? make sure that all generics, docs, tests are in place. once it is clean and polished, i can start updating the kip and implementing this new feature. what do you think? p.s. rebased the branch with latest `trunk` and pushed another commit with review changes",1,0.9822508692741394
372120739,6592,mjsax,2020-01-28T23:41:43Z,"can be simplified to `(""unchecked"")`",0,0.9859683513641357
372121895,6592,mjsax,2020-01-28T23:45:47Z,`innerdeserializer` could be null; we should handle to case to avoid a npe calling `getclass()`,0,0.9880017638206482
372123553,6592,mjsax,2020-01-28T23:51:31Z,"there a two independent configs for the list-type and inner-type, hence it might be better to handle both independently: [code block]",0,0.9866144061088562
372123738,6592,mjsax,2020-01-28T23:52:12Z,as above; simplify,0,0.9824113249778748
372125306,6592,mjsax,2020-01-28T23:57:44Z,use `kafkaexception` instead of `runtimeexception`,0,0.9863491058349609
372125767,6592,mjsax,2020-01-28T23:59:23Z,in `utils.newinstance()` we catch exceptions more fine grained -- might be worth to do the same here?,0,0.984348714351654
372126337,6592,mjsax,2020-01-29T00:01:19Z,use `kafkaexception` instead of `runtimeexception`,0,0.9863491058349609
372126509,6592,mjsax,2020-01-29T00:01:57Z,as above,0,0.9783914685249329
372126925,6592,mjsax,2020-01-29T00:03:37Z,"should we throw `kafkaexception` instead? also, we need to add an error message that clarifies which class was not found.",0,0.9794772863388062
372128389,6592,mjsax,2020-01-29T00:08:53Z,as above: `serializer` could be `null` and we should handle this case gracefully,0,0.9877545237541199
372128852,6592,mjsax,2020-01-29T00:10:43Z,maybe add a `null` check and throw `configexception` with detailed error message similar to the `null`-check for `listclass` in the `listdeserializer#configure(...)`? i think `instanceof` would be false for `null` and thus the `null` check within `utils.newinstance(...)` would not be executed.,0,0.986466109752655
372129532,6592,mjsax,2020-01-29T00:13:33Z,use `kafkaexception` instead of `runtimeexception`,0,0.9863491058349609
372129790,6592,mjsax,2020-01-29T00:14:31Z,we should add a `null` check to allow closing a deserializer that was not properly setup,0,0.979761004447937
372129838,6592,mjsax,2020-01-29T00:14:42Z,we should add a `null` check to allow closing a serializer that was not properly setup,0,0.9825491905212402
372131801,6592,mjsax,2020-01-29T00:22:12Z,`serializer` -> `serde`,0,0.9862304329872131
372131842,6592,mjsax,2020-01-29T00:22:22Z,`serializer` -> `serde`,0,0.9862304329872131
372131861,6592,mjsax,2020-01-29T00:22:27Z,`serializer` -> `serde`,0,0.9862304329872131
372132594,6592,mjsax,2020-01-29T00:25:25Z,this method is hard to read... can we format it differently? (maybe a empty line before `return...` is sufficient?),0,0.8279527425765991
378457483,6592,yeralin,2020-02-12T19:14:33Z,"`catch (instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception e)` kind of long, but i agree for it to be more fine grained",0,0.9761797189712524
453892518,6592,yeralin,2020-07-13T19:50:12Z,make sure that the serialization flag is known to the application.,0,0.9858387112617493
453892850,6592,yeralin,2020-07-13T19:50:48Z,it's probably better to wrap it into `if/else` construct instead.,0,0.9833399057388306
453893460,6592,yeralin,2020-07-13T19:52:01Z,"by default, if we are dealing with a list of primitives, we are using `serializationstrategy.null_index_list` vs. a list of non-primitives (`uuid`, `string`, or some custom object) `serializationstrategy.negative_size`.",0,0.953961193561554
453894509,6592,yeralin,2020-07-13T19:54:14Z,"this is what i was talking about in [a link] even if we are dealing with primitives, and a user chooses `serializationstrategy.negative_size`, we would have to encode each primitive's size in our payload.",0,0.9534648060798645
453894647,6592,yeralin,2020-07-13T19:54:32Z,should it be parametrized?,0,0.9786325097084045
613642681,6592,ableegoldman,2021-04-14T23:09:28Z,"just wondering, what is the reason for this change?",0,0.6793548464775085
613647496,6592,ableegoldman,2021-04-14T23:23:03Z,"should it be valid for this to be null? i would think that these serdes should be configured either by instantiating it directly via this constructor, or via the default constructor + setting configs (eg list.key.serializer.inner). it doesn't seem to make sense to use this constructor and not pass in valid arguments. wdyt about throwing an exception if either parameter is `null` -- not sure if configexception or illegalargumentexception is more appropriate, up to you",0,0.9390372037887573
613648141,6592,ableegoldman,2021-04-14T23:24:53Z,nit: use `private static` ordering (for consistency with the rest of the code base),0,0.989701509475708
613649139,6592,ableegoldman,2021-04-14T23:27:36Z,"if the `listclass` and `inner` have already been set by invoking the non-default constructor, but the user also set the `list.key.deserializer.inner` configs, should we verify that the configs match and throw a configexception otherwise?",0,0.9899095296859741
613651922,6592,ableegoldman,2021-04-14T23:36:10Z,what about the `list_key_deserializer_inner_class_config`?,0,0.9873453974723816
613657189,6592,ableegoldman,2021-04-14T23:52:12Z,"hey, sorry that i'm jumping in here after there's been a long discussion which i missed, but i'm wondering why the serialization strategy would be configurable? iiuc the serialization strategy correctly, one of them basically means ""constant-size data/primitive type, don't encode the size only length of list"" while the other means ""variable-size data, encode the size of each element only"" i assume this is to allow users to indicate that their data is constant size when its a non-primitize type, to avoid the need to encode this same size data -- that makes sense to me. but i think we can simplify the api a bit so we don't have to let users shoot themselves in the foot, as you said earlier :slightly_smiling_face: how about: if it's a primitive type, and we can detect this (i think we should be able to), then we never encode the size info. if a user opts to do so, just log a warning and ignore it. by the way, this might also be due to some earlier discussion i missed, but i find the names of the two serializationstrategy enums super confusing. how about just `variable_size` and `constant_size`? imo it's better to describe what the enum actually _means_ than how its implemented, you can read the code to understand the latter. but you shouldn't need to read the code to understand what a config means. plus, this way we have flexibility to change the underlying implementation if we ever need to without also having to change the enum names which are now a public api",-1,0.9871270656585693
613658493,6592,ableegoldman,2021-04-14T23:56:23Z,"what is this? can you give it a name that describes what it means a little more -- iiuc this is a sentinel that indicates ""this list has variable-sized elements so we encode each element's size"". that said, coming up with names is hard -- you can probably do a better job than me but just to throw out a suggestion, what about something like `variable_size_sentinel`?",0,0.9405573606491089
613658799,6592,ableegoldman,2021-04-14T23:57:19Z,"nit: can we use `double.size` instead of just `8`, that way it's super clear that this value actually means?",0,0.9880505204200745
614950753,6592,yeralin,2021-04-16T15:54:30Z,hmmm `double.size` returns 64: [code block],0,0.9869281649589539
614954404,6592,yeralin,2021-04-16T15:59:41Z,otherwise the build will fail with: [code block] was addressed in [a link],0,0.9758304953575134
615005374,6592,yeralin,2021-04-16T17:14:20Z,"it was introduced in [a link] however, now i am looking at it and seems like we actually don't need any of: [code block] since we are operating only with: [code block] good observation, i'll remove these unused configs.",1,0.5554498434066772
615008995,6592,yeralin,2021-04-16T17:20:31Z,that's a good idea. i think `illegalargumentexception` is the most appropriate. something like: [code block],1,0.7686755657196045
615010709,6592,yeralin,2021-04-16T17:23:38Z,"i was following the logic defined in similar (de)serializers like `sessionwindowedserializer`. there they are doing similar thing, simply checking whether a (de)serializer is null, then trying to get a value from configs. they don't perform any verification. what do you think? should we divert from that approach?",0,0.9647513031959534
615020981,6592,yeralin,2021-04-16T17:41:33Z,"hey, no worries. for: i think i am already doing that in the constructors: [code block] if a user doesn't pass `serstrategy` flag, we pick the best one for her based on passed serializer. if a user passes her own `serstrategy` flag, we simply obey to it. however, we don't print any warning logs, since i assumed if the user passes the flag, then she probably knows what she is doing. what do you think? i could add a warning log otherwise.",1,0.7959264516830444
615021158,6592,yeralin,2021-04-16T17:41:56Z,"as per flag names, totally agree. changing them to `variable_size` and `constant_size`.",0,0.9764777421951294
615075349,6592,yeralin,2021-04-16T19:23:08Z,"basically, if we are following `variable_size` serialization strategy **and** we have a `null` entry in our list, we encode this null entry as `-1`, so that during deserialization when we encounter `-1`, we append `null` entry to our list. example, to serialize a list like `{""a"", ""b"", null, ""c""}` of strings, the payload would look smth like: [code block]",0,0.9827630519866943
615075871,6592,yeralin,2021-04-16T19:24:11Z,could be called something like `null_entry_value` instead maybe?,0,0.9879834651947021
618823378,6592,ableegoldman,2021-04-22T23:51:07Z,"yes, i think we should. and it's not even a diversion from the approach elsewhere because there's a kip in progress to do so in classes like `sessionwindowedserializer` as well",0,0.9819814562797546
618823669,6592,ableegoldman,2021-04-22T23:52:16Z,"cool. i think the fewer configs overall, the better. if we can get away with just the serde configs then let's do so to keep the api surface area smaller for users :thumbs_up:",1,0.9798643589019775
618824127,6592,ableegoldman,2021-04-22T23:53:50Z,"ah, my bad. i think the variable i had in mind is actually called `double.bytes`. not 100% sure it's defined for all possible primitive types, but i would hope so",-1,0.989273726940155
618824748,6592,ableegoldman,2021-04-22T23:55:45Z,that sounds good to me :thumbs_up:,1,0.9419543147087097
618826368,6592,ableegoldman,2021-04-23T00:00:19Z,"awesome. maybe i misunderstood this comment: or maybe you just wrote that a while ago and it's out of date. anyways what we're doing now sounds good, no reason to encode extra data even if the user selects this strategy for some reason. but i do think we should at least log a warning telling them they made a bad choice and it will be ignored. most likely they just didn't understand what the parameter meant, and it's a good opportunity to enlighten them",1,0.946161150932312
618826641,6592,ableegoldman,2021-04-23T00:01:13Z,"ooooh ok, that makes a lot more sense now. i think your suggestion for the name sounds good",1,0.9467775225639343
618910174,6592,yeralin,2021-04-23T03:14:35Z,"yep, that checks out. only for `uuid` i'd have to leave hardcoded `36`.",0,0.9877954721450806
620449322,6592,yeralin,2021-04-26T16:17:55Z,"now, i am thinking about it. it seems a bit extra to compare the classes defined between the constructor and configs. maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? forcing the user to set only one or the other.",0,0.9661548137664795
620457633,6592,yeralin,2021-04-26T16:28:34Z,"hmmm, i thought you wanted to simply warn the user that the serialization strategy she chose is not optimal. but seems like you want to ignore the choice completely. then it doesn't make sense to expose this flag at all for the user to change. me and were discussing it earlier [a link]",0,0.8836420774459839
620716670,6592,ableegoldman,2021-04-26T23:20:45Z,"that works for me. tbh i actually prefer this, but thought you might consider it too harsh. someone else had that reaction to a similar scenario in the past. let's do it :thumbs_up:",0,0.42171889543533325
620720140,6592,ableegoldman,2021-04-26T23:29:50Z,"ah, sorry if that wasn't clear. yes i was proposing to ignore the choice if a user selects the `variable_size` strategy with primitive type data. and to also log a warning in this case so at least we're not just silently ignoring it. but i think you made a good point that perhaps we don't need to expose this flag at all. there seems to be no reason for a user to explicitly opt-in to the `variable_size` strategy. perhaps a better way of looking at this is to say that this strategy is the default, where the default will be overridden in two cases: data is a primitive/known type, or the data is a custom type that the user knows to be constant size and thus chooses to opt-in to the `constant_size` strategy. wdyt? we could simplify the api by making this a boolean parameter instead of having them choose a `serializationstrategy` directly, something like `isconstantsize`.",-1,0.9863994121551514
620802248,6592,yeralin,2021-04-27T02:27:58Z,"hmmm, reasoning was that in the future we could introduce **more** serialization strategies [a link] as per ignoring the choice, also from [a link] ... personally, i have a slight preference to allow both strategies for all types as i think easy of use is more important, but i am also fine otherwise. here is my thought process, if a user chooses a serialization strategy, then she probably knows what she is doing. ofc, the user will have a larger payload, and we certainly will notify her that the serialization strategy she chose is not optimal for the current type of data, but i don't think we should strictly forbid the user from ""shooting herself in the foot"".",0,0.47984883189201355
620804518,6592,ableegoldman,2021-04-27T02:34:31Z,"my feeling is, don't over-optimize for the future. if/when we do want to add new serialization strategies it won't be that hard to pass a kip that deprecates the current api in favor of whatever new one they decide on. and it won't be much work for users to migrate from the deprecated api. i'm all for future-proofness but imo it's better to start out with the simplest and best api for the current moment and then iterate on that, rather than try to address all possible eventualities with the very first set of changes. the only exception being cases where the overhead of migrating from the initial api to a new and improved one would be really high, either for the devs or for the user or both. but i don't think that applies here. that's just my personal take. maybe would disagree, or maybe not. i'll try to ping him and see what he thinks now, since it's been a while since that last set of comments. until then, what's your opinion here?",-1,0.5822257995605469
621475071,6592,yeralin,2021-04-27T18:13:14Z,"ok, in this case, i think the best course of action is to completely remove `serializationstrategy` flag, and replace it with a simple boolean. do not expose it to the user, and automatically choose the strategy based on the type of data. if you agree, i'll go ahead and make the change.",0,0.9808028936386108
621676170,6592,ableegoldman,2021-04-27T23:05:42Z,"just to clarify you mean don't expose this to the user at all, right? that sounds completely fine to me. if there are enough people trying to serialize lists of custom classes with all constant data size who want this optimization exposed for general use, then someone will request the feature and we can go back and add it in. then we can debate what the api should look like at that time, and keep things simple for now. personally i suspect the vast majority of non-primitive data types are not going to be constant size anyways. given the above, i think whether to track the strategy as an actual `serializationstrategy` enum vs a boolean flag becomes a matter of code style and personal preference, since it's no longer exposed to the user. so it's up to you whether you find the enum or the flag to be more readable or clean",0,0.662790834903717
629768563,6592,ableegoldman,2021-05-11T00:34:30Z,"same here, --> `public static`. can you also leave it on one line? i know it's super long, but that's just the style we use in kafka",0,0.9610865116119385
629769396,6592,ableegoldman,2021-05-11T00:35:57Z,"super nit: we put the modifier first, ie use `public static` ordering.",0,0.989237904548645
629770618,6592,ableegoldman,2021-05-11T00:40:07Z,"nit: kafka coding style doesn't use the `get` prefix in getters, ie this should be named `innerdeserializer` (same applies for any other getters in this pr, i won't bug you by commenting on every single one of them)",0,0.9819532036781311
629772320,6592,ableegoldman,2021-05-11T00:45:41Z,"is the unchecked warning coming from something in the test itself, or just from using the serde? it should be possible to just use the serde without getting a warning. i don't see anything in the test that looks suspicious so i'm guessing we need another suppression somewhere in the serde implementation?",0,0.9654921293258667
629772466,6592,ableegoldman,2021-05-11T00:46:11Z,super nit: extra blank line,0,0.9650247693061829
629776651,6592,ableegoldman,2021-05-11T01:00:18Z,"i found it a bit difficult to understand what was going on here since i'm reading this first, before the serialize implementation, but i take it we just encode the indices of any null values at the beginning of the serialized list? can you leave a comment pointing that out, either here on the method itself or else down below where the method is used?",0,0.7406110167503357
629777825,6592,ableegoldman,2021-05-11T01:04:18Z,"since we no longer expose the serializationstrategy or let users explicitly select it, these two equality checks should have both be true or both be false, right? might read a bit easier if we only check `serstrategy == serializationstrategy.variable_size` here, and then just verify that `primitivesize` is not null when we parse the serialization strategy flag at the top. wdyt?",0,0.9866464138031006
629781672,6592,ableegoldman,2021-05-11T01:17:17Z,"since we don't know what the underlying list structure is, using `get(index)` like this could be pretty costly -- for example with a linkedlist this will be o(n), which makes it o(n^2) overall. might be safer to just iterate through the list with a plain `for int i` loop and take note of the nulls that way",0,0.9039350152015686
629781907,6592,ableegoldman,2021-05-11T01:18:05Z,nit: put the `out.writeint` on its own line,0,0.9888899326324463
629782907,6592,ableegoldman,2021-05-11T01:21:16Z,"same as my suggestion in listdeserializer, can you add a quick comment here or above the `serializenullindexlist` method explaining what this is doing (like you have above with `// write serialization strategy flag`)",0,0.9886128306388855
629784136,6592,ableegoldman,2021-05-11T01:25:13Z,"also similar to a comment in listdeserializer: it should not be possible for only one of these to be true, so let's just check one or the other here. in fact maybe we can get rid of the `isfixedlength` flag entirely now, since `serializationstrategy.variable_size` means exactly the same thing (or rather, the opposite of it)",0,0.9833005666732788
630539763,6592,yeralin,2021-05-11T21:04:20Z,would something like this work? [code block],0,0.9865165948867798
630542548,6592,yeralin,2021-05-11T21:09:26Z,the problem is [a link] list `static public` first. ![a link],0,0.8896510601043701
630550102,6592,yeralin,2021-05-11T21:23:30Z,"unfortunately, it is unavoidable [a link] had to do it this way and sacrifice type safety for easier usage of this serde.",0,0.5190114974975586
630603333,6592,ableegoldman,2021-05-11T23:27:32Z,"ah, i didn't notice...tbh we should probably just fix all of them, but it's fine with me to leave that out of this pr and just conform to this for now. i'll leave it up to you",0,0.8420537114143372
630605834,6592,ableegoldman,2021-05-11T23:34:18Z,"thanks for the context, it is what it is (and i agree with your decision to prioritize ease of use). i was more wondering whether we might be missing a `suppresswarnings(""unchecked"")` on one of the methods in the implementation, so that the user isn't forced to do the suppression themselves. but i can't quite tell where the warning is coming from, since it seems like we do already suppress unchecked warnings in `listdeserializer#createlistinstance` where the casting occurs? is it possible this was just left over from an earlier version, and we no longer need all the suppressions on these tests?",1,0.6486332416534424
630606384,6592,ableegoldman,2021-05-11T23:36:01Z,"yep, exactly (not sure why i said to use `for int i`, obviously that suffers from the same problem -- the iterator is what i had in mind)",0,0.9775803089141846
631151867,6592,yeralin,2021-05-12T15:33:20Z,this is a common practice leaving empty lines at the end of files: [a link],0,0.9830465912818909
631158775,6592,yeralin,2021-05-12T15:40:10Z,"no, unfortunately they are still needed. afaik, suppression warnings cannot be propagated upwards. in `listdeserializer#createlistinstance` we indeed using `suppresswarnings(""unchecked"")` due to casting. however, in tests it is used bc `stack.class` (or `arraylist.class`, `linkedlist.class`, etc) is a raw-type and does not guarantee the required inner type (`integer` in this case). the only way to deal with these warnings is to create some wrapper classes as suggested, like: `public static class integerarraylist extends arraylist {}` but i do not this it is a scalable and clean solution. pretty much every time a user is calling `serdes.listserde(...)` they will have to put suppresswarnings statement. it is a limitation of java language. as said:",0,0.9287431836128235
631327191,6592,ableegoldman,2021-05-12T19:06:47Z,"well, it's not at the end of the file right? but if you'd prefer to keep it that's fine too, was just a ""super nit"" suggestion :slightly_smiling_face:",0,0.7805290818214417
631328727,6592,ableegoldman,2021-05-12T19:09:22Z,"can you move this up to the top of this file, under the `streams changes in 3.0` section? it's in reverse order, so the newest stuff goes at the top.",0,0.9889771342277527
631334877,6592,ableegoldman,2021-05-12T19:19:33Z,"ah, i see, it's from the implicit casting of the parameters. that makes sense, i was just wondering since i didn't see any ""obvious"" casting in the test code itself. thanks for the explanation",1,0.9313209652900696
631339580,6592,yeralin,2021-05-12T19:27:24Z,"omg i am blind. sorry, you are right!",-1,0.9903552532196045
212770210,5567,vvcephei,2018-08-24T22:37:13Z,i need to expose these so that i can query the window spec in ktableimpl,0,0.9872223734855652
212770275,5567,vvcephei,2018-08-24T22:37:50Z,"upon second look, i think i'll move these into a utility class to not pollute ktableimpl",0,0.9827013611793518
212770518,5567,vvcephei,2018-08-24T22:39:27Z,the basic idea is to traverse back through the topology until we find the window spec and get the grace period from it.,0,0.9854391813278198
212770687,5567,vvcephei,2018-08-24T22:40:59Z,on-the-side fixup of the generic types for groupby.,0,0.9886965751647949
212770823,5567,vvcephei,2018-08-24T22:42:02Z,"this is where the buffering would take place. right now, we throw an exception unless we detect that we can pass-through the record.",0,0.986507773399353
212770994,5567,vvcephei,2018-08-24T22:43:20Z,`suppress` is split into interface/impl mostly to support these kinds of internal methods.,0,0.9846442937850952
212771115,5567,vvcephei,2018-08-24T22:44:11Z,decided to start using fuzzing to avoid magic numbers in the tests. let me know if you prefer it different.,0,0.970819890499115
212771290,5567,vvcephei,2018-08-24T22:45:40Z,"`mockprocessorcontext` is pretty nice for unit tests, but we need `internalprocessorcontext` for the suppress processor.",0,0.9808167815208435
212771356,5567,vvcephei,2018-08-24T22:46:17Z,so you can just print the result of `forwarded()` for debugging.,0,0.9899699091911316
212771502,5567,vvcephei,2018-08-24T22:47:22Z,had to fix this to actually get the right timestamp forwarded.,0,0.8909769058227539
212771525,5567,vvcephei,2018-08-24T22:47:35Z,just to quit spamming the logs.,-1,0.9031357169151306
213025428,5567,vvcephei,2018-08-27T15:56:16Z,"this preserves the existing behavior that if both `to.timestamp` and `this.timestamp` are unset, the forward time would be `-1`.",0,0.9880900382995605
213039753,5567,vvcephei,2018-08-27T16:46:07Z,"which i think is reasonable, since this context would only be used for unit tests.",0,0.9801787734031677
213190515,5567,guozhangwang,2018-08-28T05:49:13Z,nit: `bytestouseforsuppressionstorage` -> `numbytestostore`?,0,0.9887549877166748
213190554,5567,guozhangwang,2018-08-28T05:49:30Z,`numberofkeystoremember` -> `numkeystoremember`?,0,0.9875088334083557
213192247,5567,guozhangwang,2018-08-28T06:01:31Z,`intermediateevents` -> `emitintermediateresults`?,0,0.9880581498146057
213192826,5567,guozhangwang,2018-08-28T06:05:43Z,nit: `intermediateemitconfig`?,0,0.9877668619155884
213193035,5567,guozhangwang,2018-08-28T06:07:02Z,"hmm.. this makes me thinking if we should consider duplicate the `bufferfullstrategy` to `finalbufferfullstrategy` and `intermediatebufferfullstrategy` and also the corresponding caller `bufferconfig` as well, to replace runtime error with complication error?",0,0.9745469689369202
213193122,5567,guozhangwang,2018-08-28T06:07:34Z,why not `timewindows`?,0,0.9614658951759338
213194261,5567,guozhangwang,2018-08-28T06:14:53Z,"let's use `topologyexception` instead of `illegalargumentexception` here, ditto below.",0,0.983304500579834
213194430,5567,guozhangwang,2018-08-28T06:15:50Z,actually today we have undefined operator for windowed-table / windowed-table join at all. but the logic itself looks good :p,1,0.9795151352882385
213196512,5567,guozhangwang,2018-08-28T06:28:15Z,"nit: just define two static `timedefinition ` and `timedefinition , v>`, one with context.timestamp and one with window end time?",0,0.9900064468383789
213321144,5567,bbejeck,2018-08-28T13:50:40Z,since [a link] should this be `suppress suppress` for consistency with the rest of the api?,0,0.9872102737426758
213326969,5567,bbejeck,2018-08-28T14:04:48Z,one meta-comment about the static methods on the interfaces in `suppress`. would we want to consider making them `default` instead of `static` in case down the line we want to implement any of these interfaces to have different behavior in the various methods?,0,0.9880086183547974
213333450,5567,bbejeck,2018-08-28T14:20:32Z,nit: we can get rid of the `else` here,0,0.9874725341796875
213336080,5567,bbejeck,2018-08-28T14:26:44Z,is this intentional or left over debugging?,0,0.9544680714607239
213376919,5567,vvcephei,2018-08-28T16:07:30Z,"this is actually ""suppress intermediate events"". it looks like this in the dsl: with static import: `table.suppress(intermediateevents(...))` without static import: `table.suppress(suppress.intermediateevents(...))` does that seem right?",0,0.9829972982406616
213377265,5567,vvcephei,2018-08-28T16:08:30Z,"yeah, i was thinking something similar... i'll sketch something up.",0,0.9287391901016235
213377504,5567,vvcephei,2018-08-28T16:09:14Z,how do you know it's a `timewindows`?,0,0.9723314642906189
213377758,5567,vvcephei,2018-08-28T16:09:57Z,ok. thanks. that sounds much better.,1,0.956969141960144
213379204,5567,vvcephei,2018-08-28T16:14:23Z,"i see. well, it's permitted by the api, so i'd rather keep the sanity check. actually, it seems like the only problem with further manipulations of windowed tables is that we won't know to use a windowed store (as by that point, we only know it's a ktable). might be worth revisiting this at some point...",0,0.9431407451629639
213383840,5567,vvcephei,2018-08-28T16:28:32Z,"yes, it should! thanks for the catch and the reference.",1,0.9750102758407593
213385791,5567,vvcephei,2018-08-28T16:34:57Z,"in general, this is something that's good to start thinking about. i think we have two kinds of interfaces/non-final classes: ones that are for implementing and ones that are for encapsulation. for implementing: serde, windows, statestore, etc. for encapsulation: ktable, materialized, etc. to me, `suppress` is in the latter category: since we cast it to `suppressimpl` immediately, it's not possible to pass in any other implementations of it. the interface/impl split is purely to provide a clean division of external/internal members. the regular java access modifiers are insufficient for this purpose, since suppressimpl's internal members need to be accessed from other internal classes, but outside of its package.",0,0.5388562083244324
213387916,5567,vvcephei,2018-08-28T16:41:18Z,"it's intentional. we first randomly generate a seed, then we create a (pseudo)random for test data generation from the seed. if the test fails, we can deterministicaly reproduce the (pseudorandom) test exactly, but only if we know the seed. that said, i want to play around with it some more, and see if i can get it to only print the seed if there are test failures. also, there's currently no option to run the tests with the seed, but you could always just drop in the literal when you're debugging locally.",0,0.9471741318702698
213389544,5567,vvcephei,2018-08-28T16:45:31Z,see prior response,0,0.9804162383079529
213393351,5567,vvcephei,2018-08-28T16:56:01Z,"hmm, i don't know if i want to spend a bunch of time of this idea. i think what i'll do is switch to a fixed seed, so that we get deterministic testing while keeping the statement that there's nothing special about the values we're testing with.",0,0.7490905523300171
213414494,5567,vvcephei,2018-08-28T17:59:15Z,how about `maxbytes`?,0,0.9882166981697083
213477348,5567,vvcephei,2018-08-28T21:24:05Z,"ah, it can't be static because of the generic parameters, but i can make it final, which would bring us to one anonymous class per instance ... but you get a new instance every time you call one of the builder methods anyway, so it's the same thing. i think this is what i was originally thinking when i left it like this.",0,0.9286981225013733
213479566,5567,vvcephei,2018-08-28T21:32:00Z,"actually, no it shouldn't ;) `suppress`'s bounds on `k` and `v` need to be tight, since the operator will actually serialize and deserialize the records (1. when it is size-constrained, 2. when it spills to disk, and 3. because this operator needs a changelog).",1,0.5834032893180847
213479948,5567,vvcephei,2018-08-28T21:33:31Z,"i previously missed that last point... it means that suppress requires serdes and not just serializers, and it needs them always, not just when it's size constrained or spilling to disk.",0,0.9362370371818542
213480277,5567,vvcephei,2018-08-28T21:34:44Z,"oh, and i've also just now realized that it should be called `suppressed`, not `suppress`, in keeping with the rest of the config objects... this is a lot of changes. i think we'll probably have to recast votes this time.",-1,0.6753295660018921
213753581,5567,vvcephei,2018-08-29T16:45:49Z,"sorry, i was being silly, but upon second reading, it looks snarky... `windows ` is the tightest bound we can put on the window spec at this point, since this processor takes any window spec.",-1,0.9909638166427612
213760382,5567,vvcephei,2018-08-29T17:07:37Z,changed the name to `suppressed` in keeping with the other config objects.,0,0.9823725819587708
213819571,5567,vvcephei,2018-08-29T20:17:47Z,added these methods in lieu of the bufferfullstrategy enum,0,0.9886929392814636
213819739,5567,vvcephei,2018-08-29T20:18:25Z,"added `serialized` as a top-level property of the buffer, since the buffer itself will likely need a changelog for resilience.",0,0.988793671131134
213820442,5567,vvcephei,2018-08-29T20:20:42Z,utility class just to encapsulate the graph search for looking back up the topology for the grace period (and verifying it's configured the same on all incoming branches),0,0.9886365532875061
213820698,5567,vvcephei,2018-08-29T20:21:33Z,i'll fill this in in the next pr.,0,0.9814406633377075
213820934,5567,vvcephei,2018-08-29T20:22:26Z,"added this ""test"" to demonstrate what compiles and what doesn't.",0,0.9851186275482178
213822461,5567,vvcephei,2018-08-29T20:27:16Z,this allows us to insist on a `strictbufferconfig` for the final results use case.,0,0.9886084794998169
214188984,5567,vvcephei,2018-08-30T21:37:52Z,"i had a potentially kooky idea... what if instead of bumping up the node index here, we just tack ""suppress"" on to the parent node name somehow? this way, it would become fine to slap suppressions into topologies and restart without any other changes (because it wouldn't cause all the other nodes to get re-numbered). this might be especially important if we intend to insert suppressions in the future for optimization reasons. thoughts?",0,0.7530213594436646
214207725,5567,guozhangwang,2018-08-30T23:14:02Z,"could you elaborate a bit more on `just tack ""suppress"" on to the parent node name somehow?` what is the concrete proposal of the naming scheme?",0,0.985981822013855
214481155,5567,bbejeck,2018-08-31T21:38:59Z,"hmm, i'd have to see the concrete proposal. if we follow that approach wouldn't we still need to implement some sort of counter in the case of having multiple ""suppress"" nodes? then i think we'd still have the same issue, adding a new suppress operator would change the numbering scheme of the suppress nodes in the topology.",0,0.9810382723808289
214482095,5567,bbejeck,2018-08-31T21:44:40Z,we should have a unit test for this class covering both base cases as well as the success result,0,0.9758157730102539
214483409,5567,bbejeck,2018-08-31T21:51:23Z,this base case and the one below could be refactored into a method [code block] wdyt?,0,0.9896620512008667
214980375,5567,vvcephei,2018-09-04T16:21:43Z,"yeah, it would be like: [code block] so the suppressions would still be guaranteed a unique name, but any renumbering would only affect suppressions that are peers under the same ktable node.",0,0.9875286817550659
214982312,5567,vvcephei,2018-09-04T16:28:04Z,"yes, it seems like this would also work, but tbh it seems a little roundabout to me. is the objective to avoid duplicates of the error string? maybe we could just extract the exception construction into a method: [code block] then again, i have doubts about whether adding an extra method to de-duplicate the (to me) simple logic of creating the exception is worth it at all. especially considering that there's no particular reason that the exception message needs to be exactly the same in these two cases. what say you?",0,0.6229370832443237
214983712,5567,vvcephei,2018-09-04T16:32:32Z,"i should say: i don't want to add it to *this* pr (which is already large). if you think there's merit to this idea, i would tackle it in another pr.",0,0.8336302042007446
215067976,5567,vvcephei,2018-09-04T21:10:15Z,this is where we insist on strict buffering for final results.,0,0.9733423590660095
215068069,5567,vvcephei,2018-09-04T21:10:32Z,see: [a link],0,0.9812784790992737
215315559,5567,bbejeck,2018-09-05T15:21:49Z,"makes sense to me to require users to specify how to handle the different scenarios as each user will have different needs concerning when they want a result emitted. but i'm wondering if we want to restrict users from having to supply a `strictbufferconfig` in all cases. i think there could be a case when faced with the option of either shutting down or emitting an early ""non-final"" result; there is a subset of users that would prefer an initial possible duplicate result vs. a production shut-down. so maybe the type could be ` ` unless of course, i'm wrong with my assumptions about the semantics of `strictbufferconfig.shutdownwhenfull`.",0,0.6884652972221375
215333841,5567,bbejeck,2018-09-05T16:09:07Z,what are the semantics around `strictbufferconfig.unboundedbuffer`? wouldn't have the same behavior as the `strictbufferconfig.spilltodiskwhenfull` option? what is the behavior of `shutdownwhenfull`?,0,0.9845626950263977
215339913,5567,vvcephei,2018-09-05T16:27:17Z,"there are several buffering options available that provide strict buffers: * unbounded (just keep allocating more until you get an oome) * bounded, shut down gracefully when full * unbounded, using disk instead of memory i think this provides plenty of options. i'm not sure we want to get into providing an option that says ""emit final results only (unless it turns out you need more memory than you allocated, in which case emit both intermediate and final results)"". 1, that's pretty confusing. 2, the main justification for ""final results mode"" is that the destination is some kind of system that doesn't permit updates. if we *claim* to support final-results-only, but send updates instead, we risk causing harder-to-debug downstream failures.",-1,0.8887169361114502
215340550,5567,vvcephei,2018-09-05T16:29:14Z,"an unbounded buffer has no specified bounds. it will just grow until the application runs out of heap. ""spill to disk"" and ""shut down when full"" are both bounded. you specify some limits on the size of the buffer or the number of keys, and it either shuts down gracefully or switches to disk when it runs out of space.",0,0.9830721616744995
215341057,5567,bbejeck,2018-09-05T16:30:36Z,i'm not opposed to the idea; i guess we'll need to weigh the pros and cons of having a separate approach to naming some nodes.,-1,0.5737602114677429
215342060,5567,bbejeck,2018-09-05T16:34:06Z,"the overall objective was merely to reduce the duplication in code, as the two blocks seemed the same to me less the condition triggering the exception. but you have a point so maybe leave as is.",0,0.9817073941230774
215347029,5567,bbejeck,2018-09-05T16:49:32Z,"could maybe use `embeddedkafkacluster.deletealltopicsandwait` instead, as we've had problems in the past with test flakiness by not deleting internal topics.",0,0.9815720319747925
215350959,5567,bbejeck,2018-09-05T17:02:18Z,why not use `inegrationtestutils.produce..` method variants?,0,0.9830241203308105
215352500,5567,bbejeck,2018-09-05T17:07:10Z,"same here, why not use one of the `integrationtestutils.waitutill...` methods for consuming records?",0,0.9868042469024658
215352630,5567,bbejeck,2018-09-05T17:07:35Z,was this line intentional or leftover debugging?,0,0.9604479670524597
215354084,5567,bbejeck,2018-09-05T17:11:57Z,"we'll need a timeout here because unless i'm missing something, this method could block forever (or at least make the test run longer than necessary) if the expected number records aren't received. another plug for using `integrationtestutils.wait..` methods as those methods provide timeout functionality.",0,0.9855360388755798
215357092,5567,bbejeck,2018-09-05T17:19:52Z,thanks for adding the integration test. i'm thinking we'd want to add test methods using the different `strictbufferconfig` options and the `eagerbufferconfig`.,1,0.9269862174987793
215360179,5567,bbejeck,2018-09-05T17:29:35Z,"great coverage, thanks for adding",1,0.9863675236701965
215371772,5567,vvcephei,2018-09-05T18:05:33Z,"ah, good catch. thanks!",1,0.9874899983406067
215373053,5567,vvcephei,2018-09-05T18:09:55Z,"to improve these tests' readability, i created a simplified ""record"": `kvt`. this allows us to produce a batch of records, all with potentially different timestamps, at once. the `integrationtestutils` methods only accept a collection of `keyvalue`, all with the same timestamp, or a collection of `v`, all with the same key and timestamp.",0,0.985224723815918
215373138,5567,vvcephei,2018-09-05T18:10:12Z,"basically, the same explanation as above.",0,0.9792183041572571
215373244,5567,vvcephei,2018-09-05T18:10:32Z,doh! this is left over. sorry.,-1,0.990830659866333
215373535,5567,vvcephei,2018-09-05T18:11:31Z,fair enough. i'll add a timeout.,0,0.9582486152648926
215374308,5567,vvcephei,2018-09-05T18:14:00Z,"agreed. currently, no actual buffering is implemented. attempts to do anything but immediately emit will throw an exception. this is verified by the processor test. in the next pr, i implement buffering, and i have the integration tests for the different strategies there.",0,0.979162871837616
215374466,5567,vvcephei,2018-09-05T18:14:27Z,thanks! i actually used the idea code coverage tool for this one :),1,0.9926100373268127
215375753,5567,vvcephei,2018-09-05T18:18:23Z,"i considered adding to the utils, but i would also have to add kvt. it seems unnecessary at this point to dump a new method and keyvalue-esque class, which are only used in this test, into util.",0,0.9859002232551575
215378941,5567,vvcephei,2018-09-05T18:27:54Z,"ah, i remember what i was thinking: that if we run integration tests in parallel, we should only delete the topics we need to. but maybe we don't parallelize the methods within a test class, and we don't share embedded clusters between test classes?",0,0.9391119480133057
215663637,5567,bbejeck,2018-09-06T15:09:45Z,"fair enough. but imho i can't envision a case where users will voluntarily let a production system shut down, but again that's just my opinion.",0,0.7083297967910767
215673339,5567,bbejeck,2018-09-06T15:34:05Z,nit: do you need `cleanstateaftertest`? in `getcleanstartedstreams` you already call `driver.cleanup` and delete all topics in `cleanstatebeforetest`,0,0.9876313805580139
215677905,5567,vvcephei,2018-09-06T15:46:05Z,"the (maybe imaginary) scenario i had in mind was: * your business logic depends on exact buffering behavior (otherwise you wouldn't be using ""final"") * you want to bound how much memory the app uses * you discover that in practice the app needs more memory than your bound it seems like in a situation like this, you would like a graceful shutdown with a clear message so that you can reconsider your options. * maybe you take a look at your metrics and discover that you can decrease the window grace period, thereby relieving memory pressure * maybe you change the environment so you can allocate more memory to the task unless you are using iq or doing something time-sensitive like high-frequency trading, shutting the app down for short periods of time when it's misbehaving should be acceptable. having hard failures like this can actually be more operationally friendly than grey failures like frequent gc or apps stealing memory from each other. but of course, it depends on the situation. there is a possibility of implementing more complex behaviors, such as pausing some tasks to allow others to flush more work, but i don't think we need to think about that right now. that was all for context. at the end of the day, if we don't think we need the ""graceful shutdown"" mode, i'd rather not implement it.",0,0.8035300374031067
215678896,5567,vvcephei,2018-09-06T15:48:47Z,it's a belt-and-suspenders thing. we want it at the end so that the tests don't leave garbage around (for example the last test). i also added it at the beginning just in case a prior run got forcibly killed and never had a chance to clean up.,0,0.9742999076843262
215804228,5567,mjsax,2018-09-06T23:07:21Z,nit: `by the supplied { suppressed} specification.` (or `configuration`?),0,0.9868583679199219
215804652,5567,mjsax,2018-09-06T23:09:17Z,nit: `k` -> `key` and `v` -> `value` (we should try to avoid abbreviations) should we add `final`?,0,0.9897089600563049
215805094,5567,mjsax,2018-09-06T23:12:13Z,"seem i am missing something, but why do we need `k, v` as generic types here?",0,0.8062755465507507
215805317,5567,mjsax,2018-09-06T23:13:35Z,nit: `eagerbcimpl` -> `eagerbufferconfigimpl` (avoid abbreviations -- make the code unnecessarily harder to read for newcomers),0,0.97596275806427
215805813,5567,mjsax,2018-09-06T23:16:33Z,as above,0,0.9783914685249329
215806026,5567,mjsax,2018-09-06T23:17:59Z,seem the interface lacks some javadocs to explain this?,0,0.9468563795089722
215806779,5567,mjsax,2018-09-06T23:23:38Z,`boundedbykeys` -> `maxbufferedkeys` (cf. comment below),0,0.9882990121841431
215807022,5567,mjsax,2018-09-06T23:25:12Z,"if we rename above, rename this to `withmaxbufferedkeys` ? (other interfaced -- eg, `produced` -- also use `withxx` for all non-static methods as counterpart to `xx` for static ones. might be nice to follow this pattern? better suggestions are welcome.",0,0.8482600450515747
215807451,5567,mjsax,2018-09-06T23:27:42Z,as above: `maxbufferedbytes` ?,0,0.9879085421562195
215807482,5567,mjsax,2018-09-06T23:27:54Z,`withmaxbufferedbytes` ?,0,0.9867991805076599
215807736,5567,mjsax,2018-09-06T23:29:19Z,"nit: to follow other interface, the non-static methods should have the `with` prefix (similar below)",0,0.9867886304855347
215808672,5567,mjsax,2018-09-06T23:35:23Z,"for the case you describe, `emitfinalresultsonly` seem to be the wrong user choice, and they should use `intermediateevents` with ""infinite time duration"" and limited buffer size.",0,0.9478495717048645
215809634,5567,mjsax,2018-09-06T23:42:03Z,"i understand the desire, however, it would not solve the overall re-naming issue -- i would prefer to have a holistic solution for the problem instead of introducing complex code that does not really help.",0,0.6941636800765991
215809978,5567,mjsax,2018-09-06T23:44:29Z,`findandverifywindowgraceorthrow` (and remove the comment) ? (self-documenting code ftw :)),0,0.9816395044326782
215810340,5567,mjsax,2018-09-06T23:46:44Z,nit: comment unnecessary,0,0.643379807472229
215810366,5567,mjsax,2018-09-06T23:47:00Z,comment unnecessary,0,0.6717628240585327
215810406,5567,mjsax,2018-09-06T23:47:25Z,comment unnecessary,0,0.6717628240585327
215810981,5567,mjsax,2018-09-06T23:51:32Z,can we use ` ` directly here? also let `buildfinalresultssuppression` return this type instead of windowed?,0,0.9889260530471802
215811536,5567,mjsax,2018-09-06T23:55:09Z,"""all parents"" ? `suppress` is only available for `ktable` and thus there should be only one parent node? also, do we need to handle chaining of `.suppress()` within `extractgraceperiod`? i also don't understand how there could be multiple parent grace periods (and thus, why do they need to match -- there should only be one anyway?) -- do i miss something? i also just realize, that windowed-ktables have another issue: we cannot only not join two, but we can also not `.filter(..., materialize)` because this would also create an ever growing key-value store instead of a windowed store... \cc thoughts?",0,0.6859450340270996
215813625,5567,mjsax,2018-09-07T00:10:34Z,"wy not use `new unsupportedoperationexception(""not implemented yet."")` :)",0,0.7452382445335388
215813819,5567,mjsax,2018-09-07T00:11:58Z,"nit: is a negative value valid? if `duration` does not check this, we should check and throw?",0,0.984085202217102
215814619,5567,mjsax,2018-09-07T00:17:50Z,"don't understand the second check? why must the record-time (or window-end-time) be less-or-equal to current stream-time? for record-time, this should be true all the time, but for window-end time, i don't think this is true -- why do we want to fail for this case?",0,0.9160597920417786
215815381,5567,mjsax,2018-09-07T00:23:16Z,could this be `private`?,0,0.9880291819572449
215816045,5567,mjsax,2018-09-07T00:28:20Z,`keyvaluetimestamp`,0,0.9822604060173035
215816087,5567,mjsax,2018-09-07T00:28:39Z,`keyvaluetimestamp`,0,0.9822604060173035
215816526,5567,mjsax,2018-09-07T00:32:14Z,"""shouldaccept only"" -- sound like a negative test but i don't see any exception? the `doesn't compile because the buffer is eager` part is weird... the condition you express is ensured via the interface -- ie, it does not compile. thus, i don't think we need a negative test.",-1,0.9655055999755859
215816861,5567,mjsax,2018-09-07T00:35:06Z,"i am fine with this; however, it might be better to take `system.currenttimemillis()` as seed and log the seed -- if it fails, we can reproduced using the logged seed? also: it's multiple test methods and i don't think that the execution order is defined. thus, we should initialize the with known seed, for each test, ie, via ``",0,0.8843045234680176
215817497,5567,mjsax,2018-09-07T00:40:48Z,`end` could be `0` and thus `nextint(end)` would throw. use `end = 1 + random.nextint(integer.max_value - 1);` above,0,0.9852820038795471
215817777,5567,mjsax,2018-09-07T00:43:16Z,should `timestamp` not fall into the window boundaries? not sure if it's important for the test?,0,0.9654958248138428
215818040,5567,mjsax,2018-09-07T00:45:22Z,why do we need an extra test for this? seems to be covered in `finalresultssuppressionshouldthrow` ?,0,0.9840330481529236
215818075,5567,mjsax,2018-09-07T00:45:38Z,as above,0,0.9783914685249329
215818472,5567,mjsax,2018-09-07T00:48:45Z,"there is already an `internalstreamsconfig` in `streamspartitionsassignor` -- if we want to use it multiple time, should we make it a public internal call that we can reuse here instead of duplicating code? maybe in a new package `...streams.internals` ?",0,0.9885342717170715
215993196,5567,vvcephei,2018-09-07T15:14:19Z,"good catch on the abbreviations. about `final`, i'll check. it might not be allowed in an interface method header.",1,0.8043689727783203
215993869,5567,vvcephei,2018-09-07T15:16:21Z,"hmm. maybe we don't... i used to have serdes in the buffer config, but they are gone now. also, we need k/v in `suppressed` so that we can bound the k to be windowed for final updates. i'll try and drop them. it would be awesome if we don't need them.",1,0.7012720704078674
215994325,5567,vvcephei,2018-09-07T15:17:42Z,"it's actually `eagerbritishcolumbiaimpl`, but i can see how you'd get confused.",0,0.9613706469535828
215995058,5567,vvcephei,2018-09-07T15:19:44Z,thanks for the suggestion. i've really struggled to come up with good names for these static/instance methods that make sense in context. i'll give this a shot.,1,0.91898113489151
215997251,5567,vvcephei,2018-09-07T15:26:19Z,"i figured that ""verify"" means ""orthrow"". the comment is part of a series that explains why the casts in this method are safe. i think that it would be very difficult to understand later why it's ok to cast `k` to `windowed`, and then why we would cast the resultant suppression back to `k`.",0,0.9752876162528992
215998650,5567,vvcephei,2018-09-07T15:30:34Z,"no, the final results suppression is defined only for windowed tables, by design. as the comments explained, we happen to know that k is a windowed, but the generic bound is still just `k extends object`, so we have to ""forget"" our knowledge that k is a windowed in order to return the result properly typed. this is what i was trying to explain in the comments, and your question illustrates why i think the comments are necessary. but i guess i need to try harder to make the comments explain this situation fully.",0,0.8926952481269836
216000969,5567,vvcephei,2018-09-07T15:37:15Z,"the last point is correct. i thought that we were already aware of this shortcoming... but now i don't remember who i was talking to about it. about the parents... the immediate parent of suppress is a single ktable, but may not be the one with a defined grace period. it might be a filter, in which case we need to examine the parent of the filter, or it might be a join, in which case we need to examine *both* parents of the join. the fact that we currently have a design flaw that prevents this situation doesn't imply that we should encode this limitation here. once we fix that design flaw, we would have to remember that we also coded that flaw into this method and come back to revert it to the state it's in right now!",0,0.870930016040802
216002077,5567,vvcephei,2018-09-07T15:40:42Z,"` ̄\_(ツ)_/ ̄` sure, that would work too. i'm removing this exception in the next pr, so i don't think it matters much. using the specifically defined exception makes it slightly easier to make sure i remove all usages of it in the next pr, as i can delete the exception class and the code won't compile until i remove all usages.",0,0.9131925702095032
216002534,5567,vvcephei,2018-09-07T15:42:13Z,i don't see why i need to worry about that here.,0,0.5097622871398926
216004459,5567,vvcephei,2018-09-07T15:48:09Z,"as you pointed out, a record in an open window will have a time greater than the current stream time. this means we should buffer it (when it's implemented) and *not* immediately emit it.",0,0.9812321662902832
216004765,5567,vvcephei,2018-09-07T15:49:08Z,"hmm, i'll check. i don't think so, but i don't remember why.",0,0.8186623454093933
216005077,5567,vvcephei,2018-09-07T15:50:07Z,k ;),1,0.6619885563850403
216006317,5567,vvcephei,2018-09-07T15:54:01Z,"the purpose of this ""test"" is explicitly to demonstrate what compiles and what doesn't. it's of course not possible to write code that doesn't compile in order to demonstrate that it doesn't compile, so i wrote the code and commented it out. if you'd like to ""run"" the test, you can uncomment the ""negative test"" lines and verify they are not permitted. if you think this is silly, i can rename the test.",0,0.646400511264801
216007362,5567,vvcephei,2018-09-07T15:57:30Z,"what you are describing is what i had initially. it seemed a little too fancy, though. i think if we like this approach, we should consider bringing in a real fuzzing framework instead of hand-rolling it. about ``, this is a good point. i'll do it.",1,0.8941883444786072
216008190,5567,vvcephei,2018-09-07T16:00:14Z,"in practice, it would, but since the processor itself doesn't make any assumption between the record timestamp and the window boundary, it doesn't matter for the test. in fact, the test verifies that the processor makes no such assumption.",0,0.9827178120613098
216008629,5567,vvcephei,2018-09-07T16:01:31Z,"it's a stub of a test that i have in the next pr. when i extracted this one and replaced buffering with exceptions, i just replaced all the test bodies with verification of the exception.",0,0.9842086434364319
216008726,5567,vvcephei,2018-09-07T16:01:55Z,explained above.,0,0.9793800115585327
216009989,5567,vvcephei,2018-09-07T16:06:32Z,"i considered that, but it seemed better to keep the mockprocessorcontext in test-utils as decoupled as possible from the internals of streams. in general, when we're modifying streams code, we exercise a lot of freedom in modifying internals, and i don't want to risk accidentally changing the behavior of the mock if we decide to add some more stuff to the one used by streamspartitionassigner. if it helps, i can give this one a different name...",0,0.8748655319213867
216041459,5567,guozhangwang,2018-09-07T18:01:14Z,`eagerbritishcolumbiaimpl` yeah that's what i thought too!,0,0.7814887166023254
216042101,5567,guozhangwang,2018-09-07T18:03:42Z,how about `emitintermediateevents` to be better aligned with `emitfinalresultsonly`?,0,0.9869858622550964
216043674,5567,guozhangwang,2018-09-07T18:09:34Z,could you elaborate why we need `bc extends bufferconfig ` as its template?,0,0.9887784123420715
216044564,5567,guozhangwang,2018-09-07T18:12:29Z,`kstreamwindowaggregate` is used only for time windowed aggregations (the class name was added when we only have time windowed at that time). for session windowed aggregations we have `kstreamsessionwindowaggregate`.,0,0.9884806871414185
216044943,5567,guozhangwang,2018-09-07T18:13:49Z,"with this idea, whether or not we insert a suppression or not would not affect any downstream operators, right? why that would not solve the re-naming issue?",0,0.9774108529090881
216046368,5567,guozhangwang,2018-09-07T18:18:38Z,"nit: why put this class under `suppress`? we usually try to get consistent hierarchy among main v.s. test directories unless there is a strong motivation not to. i.e. it is fine to have `ktablesuppressprocessortest.java` under `suppress`, but this class may just be `ktablesuppresstest` under `kstream/internals`.",0,0.983922004699707
216068984,5567,vvcephei,2018-09-07T19:47:04Z,"yeah, this is another spot where i really struggled with naming. i liked `suppress(intermediateevents())` aka ""suppress intermediate events"", but the version for final would be like ""suppress all but final events"", and `suppress(allbutfinalevents()` just seems too confusing, so i compromised. note that this method isn't saying to _emit_ the events, but actually the opposite: to _suppress_ them. i think the symmetric name would be `suppressintermediateevents()`, which looks a little redundant in practice: `suppress(suppressintermediateevents())` or `suppress(suppressed.suppressintermediateevents())` :/ another idea would be to choose one of the synonyms. since we are accomplishing this suppression via buffering, we could call it `bufferintermediateevents` or just `buffer`... thoughts?",-1,0.872037947177887
216070493,5567,vvcephei,2018-09-07T19:53:12Z,"ah! this has a name: ""curiously recurring generics"" (or ""curiously recurring template"" from c++). this allows us to declare builder methods in the interface that return an instance of whatever subclass was used to invoke the method. such as `bc bufferkeys(final long maxkeys)`. when we call this on an eager config, we get back an eager config, and when we call it on a strict config, we get back a strict config. if you recall the weird comment in windows that says ""all subclasses should override this method so they can return the correct type"", we were looking for the same property. if we had used this pattern, we wouldn't have needed that comment, as the overridden methods would automatically take on the correct return type.",-1,0.404914528131485
216071247,5567,vvcephei,2018-09-07T19:56:14Z,"sure, i can do that. i agree 100% on the unit tests. for this semi-integration test, i stuck it in this package just because `internals` already has like 1.5m test classes in it. i'll move it.",0,0.8965838551521301
216071967,5567,vvcephei,2018-09-07T19:59:15Z,"i think `kstreamwindowaggregate` is used for any subclass of `windows`, of which `timewindows` is one. it's definitely not `sessionwindows`, since `sessionwindows` is not a subclass of `windows`, but it could be `unlimitedwindows` or any user-supplied `windows` subclass.",0,0.9889622330665588
216142211,5567,mjsax,2018-09-08T22:26:18Z,ack -- was just a thought.,0,0.9283084273338318
216142224,5567,mjsax,2018-09-08T22:27:34Z,"i understood the comments -- was just not sure if we can improve the code. if we cannot change the generic type, it's fine.",0,0.9521496891975403
216142390,5567,mjsax,2018-09-08T22:36:05Z,"hmmm... i did originally not consider ktable-ktable join -- however, a grace period is only defined for windowed aggregations, right? thus, this would only make sense if two windowed-ktables are joined? thus, if we consider that we might fix joining two windowed-ktables in the future (was is broker atm), i am wondering, if we should use the maximum grace period over both base-join-tables as required bound for the suppression, instead of forcing both base-windowed-tables to have the same grace period configured?",0,0.9509820342063904
216142405,5567,mjsax,2018-09-08T22:37:35Z,i guess `<=` is ok (it was a nit) -- was just wondering if we should use `==` instead.,0,0.9831711649894714
216142501,5567,mjsax,2018-09-08T22:43:20Z,"why should we buffer it? if `suppress.isimmediateemit()` is true, i though we would not buffer it but emit it immediately to obey the config? or do i miss understand the semantics of `isimmediateemit()`?",0,0.925519585609436
216142530,5567,mjsax,2018-09-08T22:45:25Z,"well, i guess nobody will ever uncomment those lines to test if it does not compile -- seems to be dead code to me.",0,0.568886935710907
216142579,5567,mjsax,2018-09-08T22:47:58Z,"ack. fine with me to not go too fancy. however, for this case i don't see why we need `random` at all, and not just hardcode some values for window-start-time etc -- if we seed with `42`, we will get some (unknown) but fixed values anyway -- so what do we gain to use `random` ? we can just put some fixed values into the code directly.",0,0.9455759525299072
216149809,5567,mjsax,2018-09-09T07:22:32Z,i don't see a big risk in 'coupling' for this case -- but not a big deal anyway. renaming doesn't buy us anything. just leave it as is.,0,0.7857297658920288
216149889,5567,mjsax,2018-09-09T07:27:07Z,"because it does not help us, if somebody inserts a `filter()` for example. the overall renaming issue is, that inserting new operator results in re-indexing. this would be a ""local"" solution for `suppress()` only, but no global solution for all operators. thus, my concern is, that we end up with different solutions for different operators for the same underlying issue. it's about consistency. does this make sense?",0,0.8381075263023376
216358799,5567,vvcephei,2018-09-10T15:08:27Z,"ah, sorry, i misunderstood the root of your question. since the type system doesn't have evidence that `k` extends `windowed`, we have to do a cast to assign to ` `. i separated it into the next line just to avoid doing too much in one line of code.",-1,0.9854487776756287
216361603,5567,vvcephei,2018-09-10T15:15:53Z,"yeah, we could make it more permissive that way. this is a discussion for the future when we do fix that operation, but it seems safest to support that join only when both streams have the exact same window configuration (otherwise there's no guarantee that the streams have any keys in common). in such a situation, we wouldn't have to worry about enforcing it here. but for now, i was thinking to be strict about the common grace periods as a basic precaution against mixing window types. (even though the grace period isn't part of the windowed key).",0,0.9186593294143677
216365179,5567,vvcephei,2018-09-10T15:24:25Z,"hmm i guess my method name is misleading. it's not that the suppression is configured like ""emit immediately"" (there is no such config option, but maybe there should be). rather, it's an internal utility method to indicate whether the buffer config allows us to just emit events that are on-time or late, rather than buffering them. regardless, we still need to buffer future events if there is room to buffer them. this logic is just a little murky right now because there isn't a buffer yet. so this logic is an attempt to emit any event that we can determine right away is legal to emit, since any buffering operation is actually an exception in this pr. i guess i could have made it simpler by just unilaterally throwing an exception for any record here, but i thought it would be nice to have some non-exceptional paths to have tests for. even though the implementation details will change when we add the buffer, any tests that currently check for events getting immediately emitted should continue to pass on the buffer-based implementation.",-1,0.5325231552124023
216370098,5567,vvcephei,2018-09-10T15:37:27Z,"yes, this is the downside i was concerned about. i won't make any change to this in this pr. i've created a jira to continue the discussion: [a link]",-1,0.6559852361679077
216394282,5567,guozhangwang,2018-09-10T16:49:09Z,"i see. and with this reasoning i think i also like `intermediateevents` as well. how about `suppress(intermediateevents())` and `suppress(untilwindowends())` since the latter should be only called for windowed table result, and hence putting the keyword `window` as part of the func name should be fine?",0,0.8368052840232849
216394504,5567,guozhangwang,2018-09-10T16:49:54Z,ack.,0,0.7720441818237305
216405880,5567,vvcephei,2018-09-10T17:23:55Z,"ooh! i like it! (although i think i'll say `untilwindowcloses`, since it waits for the grace period after the ""end"" of the window (which reminds me that i should make sure the window lifecycle is well documented for the 2.1 release))",1,0.9913561344146729
216517843,5567,mjsax,2018-09-11T00:52:49Z,"cannot follow here. can you elaborate? also, thinking about this once more: why do we need to force `suppress` to have a larger grace period that it's parents?",0,0.9470929503440857
216518207,5567,mjsax,2018-09-11T00:55:52Z,ack.,0,0.7720441818237305
216826714,5567,vvcephei,2018-09-11T21:20:33Z,"what i meant is that if the left stream and the right stream have completely different window specs, then the join will be completely disjoint. this is probably a programming mistake, and i think it's better to fail fast.",0,0.5782883763313293
216827058,5567,vvcephei,2018-09-11T21:21:45Z,about: i didn't understand. we set suppress's suppression time *equal* to the grace period of the parent.,0,0.8927326798439026
216870298,5567,mjsax,2018-09-12T01:08:21Z,"this makes sense -- however, if no suppress operation is defined, this would not be detected -- and if we put a check somewhere else, suppress does not need to check it either. does it? additionally, even if suppress does this check, i would exclude the grace period from the check. from my understanding, this method should checks that the grace period is larger than the window-size of the upstream ktable -- we don't need to set the grace-period, but just take whatever the users specified for it. there is no comparison of parent grace period and suppress grace period? and there is no need? or do i miss something?",0,0.9744861721992493
217177283,5567,vvcephei,2018-09-12T20:28:55Z,"yeah, i think we're miscommunicating. suppression does not have a ""grace period"", it only has the ""emit after"" config. the method `findandverifywindowgrace` only extracts the exact specified grace period, as configured upstream. we pass the value we get back to `org.apache.kafka.streams.kstream.internals.suppress.suppressedimpl#buildfinalresultssuppression`, which then creates a `suppressed` configuration using that time (the extracted grace period) as the ""emit after"" config, along with setting the `timedefinition` to the window end time. together these configs cause suppression to emit immediately right at the end of the grace period (as configured somewhere upstream).",0,0.8709907531738281
217179331,5567,vvcephei,2018-09-12T20:34:57Z,"you raised a separate question about whether we should be strict or permissive if the suppression node actually has multiple parents which specify two different grace periods. i favored strict because i think this makes the situation more debuggable and comprehensible. but you are correct in stating that it's not a correctness issue, since the grace period doesn't affect the key. for this reason, i would be ok with logging a warning and just using the larger grace period. the consideration we need to weigh is in that situation with two different windowed tables getting merged/joined, assuming they only differ in grace period, how can we ensure that all operators follow the same strategy of taking the larger grace period. it affects windowed store retention as well as suppression. i think taking the larger is a reasonably obvious choice, so maybe it's not a big deal, though.",0,0.9098845720291138
217476838,5567,mjsax,2018-09-13T17:51:03Z,"thanks for clarification! would be good to get input from about this. should we fail? or should we pick ""max""? i still favor ""max"", but it's not a deal breaker if we fail instead. nevertheless, i don't think `suppress` should check the window spec (size/advance etc) -- if a user does a ""weird"" join and we want to disallow it, this check should be done in `join()` instead.",1,0.9653345942497253
217514478,5567,bbejeck,2018-09-13T19:58:51Z,"i would favor taking the `max` as well, as, imho, we can't account for all use cases so better to chose max. we should document the behavior so users can be made aware of what happens with setting different grace periods would it be too much to make this a configurable item? i'm not sure as we have several config items to consider already.",0,0.9269284605979919
217805092,5567,guozhangwang,2018-09-14T18:34:31Z,"regarding the `.filter(..., materialize)` issue, yes this is a known bug. i think has raised a kip for fixing this. regarding the windowed-ktable / ktable join, there are some very old discussions before on how to tackle it ([a link] is filed recently), and the idea at that time was: 1) we would require the joining table's window-spec to be well aligned, i.e. they must have the same length. note since window boundaries are the same as they are all starting from the epoch time, it means that same window length guarantees aligned windows, and each the join operation becoming joining each paired windows of the table. we do not yet have session windows at all so this was not discussed, but with session windows it is definitely more complicated.. as for grace period, i think we do not need to make it strict that requires grace to be the same as well. personally i think either `min` or `max` are fine (i'm slightly leaning towards `min` though :p).",0,0.9607577919960022
217850548,5567,mjsax,2018-09-14T21:46:34Z,"why `min`? `max` seems to be inclusive and guarantees to respect the configs of both upstream operators, while `min` does not?",0,0.9852911233901978
217853758,5567,vvcephei,2018-09-14T22:05:17Z,"ok, * fwiw: i 100% agree that it's not this component's job to verify other aspects of the window spec. it should only care about grace period. * i think the semantics are perfectly well defined with `max`, and i buy these arguments that it's unnecessary to fail. i'd like to log a warning (just during the topology build) in case the mis-match was accidental. : i agree with , i don't think that `min` has the right semantics. the purpose of configuring the suppression interval equal to the grace period to begin with is that we already know that the window results will never be updated after the grace period ends. if we set the suppression smaller than the grace period (or in this case _one_ of the grace periods), then there will be an inconsistency between the aggregation results upstream vs. downstream of suppression. in fact, it's generally ok if we make the suppression interval _larger_ than the grace period. it just means that we'll emit the final result ""after"" the window closes, not ""at"" the window close. thus, `max` satisfies everyone's semantics and ensures consistent results throughout the topology. the ""more graceful"" parent will see its final results close after its grace period expires, and the ""less graceful"" one has to wait longer, but they will both never see their materialized state differ from the results downstream of the suppression.",0,0.45516690611839294
217856097,5567,guozhangwang,2018-09-14T22:22:06Z,"to me the grace period for a window is letting users to trade-off between latency and correctness, and hence users may actually prefer latency over correctness in some cases, so i said in the previous comment that personally i'd prefer `min`, just to express this intention :) anyways, i do not have strong preference which option to go, and i'm also fine with `max` if most people feel that way.",1,0.804287850856781
217861650,5567,mjsax,2018-09-14T23:04:37Z,"from my understanding, using max will be the default behavior -- users can still manually specify a smaller one, right? it must just be larger than window-size?",0,0.9825723171234131
217868845,5567,guozhangwang,2018-09-15T00:24:11Z,"grace period is the additional time on top of the window-size, and assuming that the window-size of the joining tables are the same, the grace period of 0 can also be used right?",0,0.9868653416633606
218138620,5567,vvcephei,2018-09-17T16:29:29Z,"ok, recall that we are talking about the special case in which the suppress operation has two parents who have different grace periods configured. in this case, ""max"" means that the suppression will be configured with the larger of the two parents' grace periods. normally, suppression only has one parent, in which case, it's configured to suppress for n ms, where n equals it's parent's grace period. n might be 0. if you select ""final results"", there is *no* option to configure the suppression interval. it is _always_ taken from the parent(s)'s configured grace period. to do anything else would threaten consistency. however, it's always possible just to do regular intermediate suppression, and choose any time you like, larger or smaller than the window size. you're just not guaranteed to get exactly one result per key/window if you pick any time shorter than window size + grace period.",0,0.9812331199645996
218451116,5567,vvcephei,2018-09-18T14:16:33Z,it is used in the static factory method of the interface.,0,0.9869363903999329
218604503,5567,bbejeck,2018-09-18T21:40:20Z,nit: can we take this out?,0,0.9778487086296082
218611217,5567,vvcephei,2018-09-18T22:07:06Z,"sure. i actually used this multiple times during this refactoring, but i think it'll be stable and therefore less useful now.",0,0.9614412784576416
218622057,5567,mjsax,2018-09-18T23:03:37Z,"this was not included in the kip, but is also public api. i think, we need to update the kip accordingly. similar to `strictbufferconfig` below? or is this for internal use only? for this case, we might want to move them to `internal` package but not nest them within `suppressed` interface.",0,0.9889174699783325
218622547,5567,mjsax,2018-09-18T23:06:19Z,"this method is not mentioned in the kip either. (or is it renamed `withbufferedkeys` -- if yes, should the return type not be `bufferconfig` as describe in the kip?) it seems there is a glitch between the pr and the kip -- will not comment on it further -- please revisit and update pr and/or kip to align both (for kip updates, please follow up on the mailing list; just a fyi email if it's just renaming bunch of methods).",0,0.9810406565666199
218623475,5567,mjsax,2018-09-18T23:11:32Z,kip has different generic types.,0,0.978847086429596
218626835,5567,mjsax,2018-09-18T23:30:21Z,nit: remove `this`,0,0.9810076355934143
218628237,5567,mjsax,2018-09-18T23:39:08Z,nit: `grace` -> `defaultgrace`,0,0.9870742559432983
218628588,5567,mjsax,2018-09-18T23:41:03Z,"should we not honor the grace period as specified in `suppress` and use default one only, if user did not specify one (ie, maybe optimized to `min(usergrace, defaultgrace)` -- not sure if this optimization is desired or not, or if we should ""blindly"" accept `usergrace` even if it's larger than `defaultgrace` what does not by anything and only increases latency...?) also, first parameter in `buildfinalresultssuppression` is called `windowclosetime`, thus, should this be `windowsize + grace` (or `maxwindowsize + grace` for multiple parents) ?",0,0.985752522945404
218631401,5567,mjsax,2018-09-18T23:57:34Z,can we define this as `timedefinition ` ? (and get rid of `getdefaulttimedefinition()`),0,0.9885077476501465
218633801,5567,mjsax,2018-09-19T00:13:26Z,naming: `withuntiltimeelapses` sounds clumsy -- `withelapsetime` ?,0,0.5274683237075806
218634055,5567,mjsax,2018-09-19T00:15:19Z,`*not*` -> ` not ` (or other html markup),0,0.9859998822212219
218634393,5567,mjsax,2018-09-19T00:17:30Z,this is discussed in the kip. should it be defined within the interface? or removed from the kip if it's not public api but impl detail?,0,0.988720715045929
218634430,5567,mjsax,2018-09-19T00:17:49Z,nit: indention,0,0.7653846144676208
218634537,5567,mjsax,2018-09-19T00:18:21Z,nit: remove empty line,0,0.9813840389251709
218655637,5567,vvcephei,2018-09-19T03:07:11Z,"yes, i plan to update the kip if you all liked this interface.",0,0.9627973437309265
218656056,5567,vvcephei,2018-09-19T03:10:50Z,"the user is not capable of specifying a suppress time for final results suppressions (see `suppressed.untilwindowclose`). only a buffer config. the grace period is the only way to ""set"" the suppression time. i'll rename the parameter to `graceperiod` this is correct, since the time definition for final results mode uses the window end as the starting point.",0,0.9826169610023499
218656226,5567,vvcephei,2018-09-19T03:12:22Z,"we can make it a ` `, but only if we drop the `static`. the static may be nice for performance, since we only need one function class & instance, but i'm not sure if it matters that much.",0,0.9646939039230347
218656366,5567,vvcephei,2018-09-19T03:13:29Z,"agreed. double preposition :( . on the other hand, i'm not sure what an ""elapse time"" might be. i'll try to think of something.",-1,0.9781595468521118
218656587,5567,vvcephei,2018-09-19T03:15:10Z,"yeah, if there were no objections on `suppressed`, i was basically going to smash what i had in the kip with it and send out an update. it's still fundamentally the same proposal, but i like the interface we've arrived at via this discussion a _lot_ better than what i originally proposed. so thanks!",1,0.9832985997200012
218659126,5567,vvcephei,2018-09-19T03:37:21Z,"but i don't like that this wasn't immediately obvious, so i'll make some clarifying changes.",-1,0.9734960794448853
218666331,5567,mjsax,2018-09-19T04:38:29Z,i see. than i need to have a closer look -- i usually compare the pr with the kip and try to catch gaps... if you don't update the kip on purpose (what is ok) i need to change my strategy.,0,0.9103053212165833
218666810,5567,mjsax,2018-09-19T04:43:23Z,why this limitation? let's say i have [code block] does this make sense?,0,0.9729520678520203
218666974,5567,mjsax,2018-09-19T04:45:10Z,"this is not runtime critical -- and having a few more objects (we don't have about hundreds) is not overhead concern imho. it would be cleaner with specify type and get rid of the ""cast helper method"" imho.",0,0.9717706441879272
218667036,5567,mjsax,2018-09-19T04:45:41Z,"maybe ""flushdelay"" ? or ""suppressperiod"" ?",0,0.9871647357940674
218667438,5567,mjsax,2018-09-19T04:48:30Z,independent of the kip update. why return `eagerbufferconfig` here instead of `bufferconfig`? just curious. what is the advantage/disadvantage for each case?,0,0.9721531271934509
218667521,5567,mjsax,2018-09-19T04:49:12Z,"nit: `maxkeystostore` -> `max[numberof]keystostore` ? (also, why `keys`? maybe `records` is better/more accurate?); do we need `tostore`? maybe we can strip this?",0,0.98895663022995
218667577,5567,mjsax,2018-09-19T04:49:42Z,"nit `max[numberof]keystostore`? (or `records` -- cf, above)",0,0.9890812635421753
218668072,5567,mjsax,2018-09-19T04:54:26Z,`boundedbysize` above vs. `withbytesbound` -- should we align both?,0,0.987852931022644
218668328,5567,mjsax,2018-09-19T04:55:56Z,`passes` -> `passed` ? `expires` -> `expired` ?,0,0.9883362650871277
218668393,5567,mjsax,2018-09-19T04:56:40Z,why `eventually` ?,0,0.9641063213348389
218668694,5567,mjsax,2018-09-19T04:59:25Z,"follow up: for `untilwindowcloses` it makes sense what you say -- my argument is, that offering only `untilwindowcloses` might not be flexible enough.",0,0.9821809530258179
218669272,5567,mjsax,2018-09-19T05:03:07Z,"i am not 100% convinced about `boundedbykeys` -- no better suggestion atm though. maybe tomorrow, or anybody else has some more ideas? maybe: `bufferconfig.maxrecords().withmaxrecords()` ? `bufferconfig.maxbytes().withmaxbytes()`?",0,0.7535079121589661
218840039,5567,vvcephei,2018-09-19T15:00:07Z,"sure, will do right now... including the cover page.",0,0.9374240040779114
218854676,5567,vvcephei,2018-09-19T15:36:19Z,"your example use case is legitimate, and it is indeed something that we sacrifice here. allow me to paraphrase: [code block] this was a point of discussion early on in the kip. the downside of this api is that querying ""count"" and observing ""output"", we will see divergent results, since ""count"" will permit some records that the suppression drops (say, any record that arrives more than 10ms later than its window). we felt that if the operator's job is to emit only ""final result"" of the window's aggregation, then that's exactly what it should do. redefining the window parameters is out of scope. however, to your second comment, i didn't follow. we don't _just_ offer `untilwindowcloses`. you could alternatively do: [code block] this won't give you ""final results"", since it will still emit updates if they are needed. final thought: like i said, i don't think it's unreasonable what you proposed, but i think it's better to start with something simple and safe. if people are asking for this api later on, we can always add it.",0,0.9403370022773743
218855860,5567,vvcephei,2018-09-19T15:39:04Z,"not in this case, since the sentence is in future tense. if i changed the verb to `would`, then it would be subjunctive, and we should say ""passed"" and ""expired"".",0,0.9740669131278992
218856509,5567,vvcephei,2018-09-19T15:40:45Z,"because the upstream state is updated immediately, but the suppression buffers the update and only emits it after the grace period passes. _then_ they will be consistent.",0,0.9877076745033264
218864237,5567,vvcephei,2018-09-19T15:59:54Z,"i've taken these naming suggestions. re: `eagerbufferconfig` -> `bufferconfig`, this works perfectly, it just didn't occur to me!",0,0.9437305927276611
218864734,5567,vvcephei,2018-09-19T16:01:10Z,"as discussed elsewhere, this is not a default. it's just the (only) grace period.",0,0.9812271595001221
218867967,5567,vvcephei,2018-09-19T16:10:53Z,i've imported 12mb of javascript libraries to italicize this word. i hope that's ok.,0,0.5250665545463562
218918921,5567,vvcephei,2018-09-19T18:38:52Z,"this is the ""partially built"" config you get when you call `untilwindowclose`. it's only partial because we need to get the grace period during the topology build.",0,0.9883330464363098
218958071,5567,mjsax,2018-09-19T20:47:00Z,ack. thanks for clarification. it's a complex discussion... sorry for repeating part of the kip discussion here.,-1,0.990578830242157
218958929,5567,mjsax,2018-09-19T20:49:50Z,"grammar... at least i can play the ""i am not a native speaker""-card :)",1,0.7725794911384583
218958970,5567,vvcephei,2018-09-19T20:50:00Z,no worries. there are indeed a lot of nuances to keep track of.,1,0.8702676296234131
218959457,5567,vvcephei,2018-09-19T20:51:41Z,"heh, no worries. hope i didn't come on too strong.",1,0.9218396544456482
218959897,5567,mjsax,2018-09-19T20:53:04Z,"that is only regular latency. also, suppress did not emit anything before -- i wouldn't the ""missing result"" not consider an inconsistency? i understand what you are trying to say, but ""eventual consistency"" might not be the best term here imho. (might be a nitpick though...)",0,0.7915318012237549
218962219,5567,vvcephei,2018-09-19T21:00:43Z,"that is a good point. i was thinking of ""final results emitted"" in aggregate, as in the downstream state is eventually consistent with the upstream state. it sounds like your reading is more like ""each result emitted is eventually consistent with its upstream version"". i think this reading is actually the more likely one. and, as you point out, this statement is almost nonsense: if you look at each result when it gets emitted, it is fully consistent with the upstream state. and of course, ""eventual consistency"" as a term probably opens up a whole bag of worms we don't want to deal with anyway, as people may bring assumptions (and bad associations) from distributed databases. i'll just say ""will match the upstream"" instead.",1,0.8113015294075012
219002231,5567,mjsax,2018-09-20T00:14:40Z,sounds good.,1,0.9202015399932861
219380904,5567,mjsax,2018-09-21T04:33:21Z,"do we need this here? ie, do we care if `streamsconfig` is logged in the test? if we do care, it might be good to do one pr that fixes it for all test? or at least make `internslstreamsconfig` it's own class for sharing?",0,0.9867894053459167
219381301,5567,mjsax,2018-09-21T04:37:44Z,meta comment: why is this called `initialized`? or should it be `initialize` ? where does it come from? could we fix it? or is it public api?,0,0.9857026934623718
219381463,5567,mjsax,2018-09-21T04:39:42Z,nit: simply to `private static long anylong = 5;`,0,0.9859089255332947
219381518,5567,mjsax,2018-09-21T04:40:14Z,as above,0,0.9783914685249329
219381601,5567,mjsax,2018-09-21T04:41:04Z,don't understand the test name. seem you test for `shouldemitimmediatelyifuntiltimelimitiszero` ?,0,0.8620061874389648
219382014,5567,mjsax,2018-09-21T04:43:38Z,as above,0,0.9783914685249329
219383229,5567,mjsax,2018-09-21T04:51:40Z,"why do we use a stateless here and a stateful above? if you want to test both cases, might be worth to add corresponding standalone tests?",0,0.9864875674247742
219383308,5567,mjsax,2018-09-21T04:52:39Z,wondering if this test subsumes the test from above?,0,0.9510297179222107
219384557,5567,mjsax,2018-09-21T05:04:20Z,"if you don't trust the regular cleanup, the question is why? also, should we apply this patter to other tests, too?",0,0.9252164363861084
219384803,5567,mjsax,2018-09-21T05:05:27Z,"this class seems to be duplicated below -- even if it's trivial, might be worth to share the code?",0,0.9854660034179688
219385047,5567,mjsax,2018-09-21T05:08:28Z,this can be an `else` as `committransaction()` would flush -- not even sure if flushing would be valid without calling `begintransaction()` before,0,0.9884030222892761
219385150,5567,mjsax,2018-09-21T05:09:39Z,"not sure if i understand. if it's a the same argument, could you not use `integrationtestutils.waitutill..` twice instead of duplicating the code?",0,0.9719513654708862
219516422,5567,vvcephei,2018-09-21T14:26:31Z,"this change does fix it for all tests that use the mockprocessorcontext. i'm happy to remove this change from this pr and do a separate one, if you're not happy with the current state of it. i wouldn't want to mess with extracting it and bloating the current pr even more than it currently is. i think it's better not to log the config for unit tests. i disabled it because the extra logging made it hard for me to read the unit test output. logging the config is really only useful during runtime so we know what configurations people are running when they post logs to the mailing list. when a test fails, you can easily just look at the test's configuration. bill brought this up earlier. i can make a non-logging config for sharing between mockprocessorcontext and the topologytestdriver. i'm hesitant to share the config class between the test utils and production code, as the risk of making an apparently harmless change in one context and screwing up the other is non-trivial. let me know if you want me to remove this from this pr now, or i can also just create a jira to make a class for the test-utils to share.",1,0.5351664423942566
219516922,5567,vvcephei,2018-09-21T14:28:15Z,it's in internalprocessorcontext. i'll fix it in a separate pr today.,0,0.9874597787857056
219517355,5567,vvcephei,2018-09-21T14:29:27Z,"uh, yeah, i changed the api and not the test name :/",-1,0.9542478919029236
219536345,5567,vvcephei,2018-09-21T15:25:42Z,i'll check...,0,0.9754828214645386
219536496,5567,vvcephei,2018-09-21T15:26:10Z,"ah, ok.",0,0.9559962749481201
219540617,5567,vvcephei,2018-09-21T15:38:56Z,"ah, my apologies to . you are right. this is not the same argument as above, and the `waituntilminrecordsreceived` is fine here.",-1,0.48090529441833496
219544268,5567,vvcephei,2018-09-21T15:50:06Z,"specifically, the ""if"" i described above happens to me when i am debugging integration tests. if you set a breakpoint and then hit the ""stop"" button, it doesn't get a chance to run the normal ""after"" cleanup. depending on whether the test uses a randomized state directory or not, this will either give you dirty state for the next run, or it'll just consume more and more disk space in `/tmp` until you run out. i have had both happen to me in the last few months. i do think we should use the same pattern for all the integration tests.",0,0.905264675617218
219544784,5567,vvcephei,2018-09-21T15:52:00Z,"yes, now it does. they were separate when this method was checking for an exception. good catch!",1,0.9902646541595459
219546526,5567,vvcephei,2018-09-21T15:57:30Z,"the stateless node is the starting point for the search. the two parents are stateful nodes because the test needs the parents to be windowed aggregations, which are stateful. the child node could be stateful as well, but it's not necessary. do you think this test should be duplicated to make sure the search works using both a stateless and a stateful processing code as the starting point?",0,0.9869269728660583
219551965,5567,vvcephei,2018-09-21T16:16:47Z,"ok, here you go: [a link] i'll pull this code from this pr.",0,0.977573037147522
219553532,5567,vvcephei,2018-09-21T16:22:11Z,here you go: [a link],0,0.9794679284095764
219597029,5567,mjsax,2018-09-21T18:58:08Z,"i understood the setup -- the question is, is there any difference in stateful/stateless parent that is worth testing? if not, we should use the same for all tests (otherwise, it's confusion --- at least to me -> ""why do you need to use the one or the other?"" question arrises)",0,0.959495484828949
710561967,11331,jolshan,2021-09-16T23:19:51Z,nit: remove comment -- we add unresolved names now too.,0,0.9797995686531067
710590303,11331,jolshan,2021-09-16T23:59:44Z,can remove redundant this.topic == null,0,0.9712496995925903
710592488,11331,jolshan,2021-09-17T00:03:37Z,since we moved an inconsistent topic id check to the fetchresponse.of method we may want to remove this and similar checks in other contexts,0,0.9838771224021912
710592733,11331,jolshan,2021-09-17T00:04:05Z,nit: fix spacing in imports -- there are a few of these in the pr,0,0.9839439392089844
712488389,11331,jolshan,2021-09-20T20:24:23Z,not sure if i should go through and rename some of these to `topicidpartition`,0,0.908347487449646
712491310,11331,jolshan,2021-09-20T20:29:01Z,nit: spacing,0,0.9861822128295898
712495759,11331,jolshan,2021-09-20T20:35:55Z,"i commented out this test, since i removed the behavior to catch inconsistent ids at this stage. i can try to simulate catching the inconsistent id later, but not sure if that is helpful to show in a test.",0,0.9793930053710938
715684131,11331,dajac,2021-09-24T14:55:31Z,"when a session is used, resolving the topic ids is not really necessary here because we should already have the names in the session or we would resolve them later anyway. i wonder if it would be better to do this entirely in the `fetchmanager.newconext` based on the context type. have you considered something like this?",0,0.9075074791908264
715684533,11331,dajac,2021-09-24T14:56:02Z,do we still need this `sessiontopicids` mapping if we have the topic id in the `topicidpartition`?,0,0.9884248971939087
715685093,11331,dajac,2021-09-24T14:56:44Z,nit: could we add an overload to `partitionresponse` which takes a `topicidpartition`? this would reduce the boiler plate code a bit here.,0,0.9893130660057068
715686005,11331,dajac,2021-09-24T14:57:54Z,could we direclty check if the topic name is null here and put the unresolved ones to `erroneous`? this would avoid the filter on the next line.,0,0.9829903841018677
715687416,11331,dajac,2021-09-24T14:59:43Z,should we create `tp` after this check? we could also create a `topicpartition` as we don't really use `topicidpartition` for the metric.,0,0.9887470602989197
715690689,11331,dajac,2021-09-24T15:03:55Z,side note here: i think that we should implement `override def elementkeysareequal(that: any): boolean` from the `implicitlinkedhashcollection.element` interface to make it clear that we do this for comparing elements in the collections.,0,0.9872192144393921
715690947,11331,dajac,2021-09-24T15:04:17Z,could we add a scaladoc for this method which explains what we do and why?,0,0.983062744140625
715691830,11331,dajac,2021-09-24T15:05:25Z,this might not be necessary if we won't resolve topic ids in the request in all cases (see my previous comment).,0,0.9828163981437683
715695751,11331,dajac,2021-09-24T15:10:21Z,"do we still need to return `inconsistent_topic_id` a top level error? fetcher prior to this change would need it, for sure. with this pr, we actually don't want the fetcher to treat it as a top level error but rather as a partition error. we need to think/discuss this a little more, i think.",0,0.9737153053283691
715697860,11331,dajac,2021-09-24T15:13:12Z,not related to this line. don't wee need to update the fetcher to handle the topic id errors at the partition level?,0,0.968292236328125
715735268,11331,jolshan,2021-09-24T16:04:14Z,we could i suppose? i think the only difference is whether we pass in these values or the fetch request itself (+ topicname map). i don't know if how we handle changes based on context type (besides full/sessionless sessions not having forgotten topics). we could save time translating though if we end up having something like an error session.,0,0.9803271889686584
715736288,11331,jolshan,2021-09-24T16:05:50Z,hmmm maybe not. looks like i just put into this map but never get anything.,0,0.9150970578193665
715738000,11331,jolshan,2021-09-24T16:08:24Z,yes we will need to do that.,0,0.9624539613723755
715740312,11331,jolshan,2021-09-24T16:11:26Z,"yeah. we can change this but the issue was with how we deal with this partition after the error is returned. with the changes to the fetchsessionhandler, we will be able to distinguish the topics, but the implementation i have now still delays partitions on a topic partition level. we don't want to delay the topic partition with the valid id though! there may be something we can do to handle this case.",0,0.9420807361602783
715740801,11331,jolshan,2021-09-24T16:12:12Z,we should do that in addition to this method?,0,0.9838418960571289
715743267,11331,jolshan,2021-09-24T16:16:04Z,"i'm not sure i follow here. we have an unresolved partition in the session and we are updating it. why would we not resolve the partition? i suppose it will get picked up by the foreach partition resolving process, but not sure how the earlier comment applies here.",0,0.8920494914054871
718910814,11331,jolshan,2021-09-29T21:51:26Z,it seems like right now `elementkeysareequal` is just `equals`. is the idea in implementing this to prevent someone else from doing so and not using `equals`/the logic from equals?,0,0.9831415414810181
718911636,11331,jolshan,2021-09-29T21:53:20Z,or is it that the javadoc says things like `key.elementkeysareequal(e) and key.hashcode() == e.hashcode()` so we should be using elementkeysareequal in fetchsession?,0,0.9891951084136963
718912221,11331,jolshan,2021-09-29T21:54:28Z,^ this is still something we need to resolve.,0,0.6367050409317017
719649068,11331,jolshan,2021-09-30T18:15:00Z,reassigning partitions takes a topic id partition unfortunately. but i suppose we can change that. not sure if we want to distinguish between reassigning partitions if we had two with the same name in the session.,-1,0.5069408416748047
719668223,11331,jolshan,2021-09-30T18:42:24Z,"for the replica fetcher, we could choose not delay partitions with this error. seems like in the fetcher, we just choose whether to update metadata. so maybe this won't be too difficult. alternatively, we change the fetching flow to contain topic id earlier in the process and so we can include in the error response as well. that would be a lot of work. still need to think through the current setup to make sure we aren't losing critical data in this state.",0,0.8810019493103027
727155822,11331,dajac,2021-10-12T13:48:07Z,"i have been looking at the changes in the `fetchsessionhandler` as well at the changes in the related classes. i am a bit worried by two things: 1) the `fetchsessionhandler` is quite complicated now, at least a bit more than before; and 2) the reliance on the request version is spread in many places now. it seems that we could get away with a simpler solution which, i think, cover all the cases as well. at the moment in the `fetchsessionhandler`, we track the `added`, `removed` and `altered` partitions and the `fetchrequest` is constructed based `next` (`added` + `altered`) and `removed`. now imagine that we would track another list `replaced` (or `upgraded`...). we would add a partition to this list when we detect that the topic id of the partition in `next` is different from the one in the session. then, we would pass that new list to the `fetchrequestbuilder` as well. in the builder, we would add it to the forgotten set if version >= 13 or ignore it otherwise. i have tried to implement this based on `trunk`: [a link] i think that we should be able to do something similar based on your version which uses `topicidpartition`. the pros is that the version handling remains in the `fetchrequest` class. the cons is that it does not allow to restart the session immediately without doing a round-trip to the broker, which is not a big deal as this could only happen during the upgrade. what do you think? would this approach cover all the cases?",-1,0.8603329658508301
727909392,11331,dajac,2021-10-13T10:12:09Z,i have simplified the code and removed a few maps along the way. here is the diff: [a link],0,0.9853460788726807
727996093,11331,dajac,2021-10-13T12:12:52Z,with ismael's pr ([a link] this trick does not work any more. we need to think about an alternative/better approach.,0,0.5817356109619141
728096221,11331,ijuma,2021-10-13T14:00:29Z,"hmm, how does my pr affect this?",0,0.5237416625022888
728115288,11331,dajac,2021-10-13T14:19:30Z,"actually, you're right. that is not entirely true. i thought that the `requirenonnull` for the `topic` in one of the [a link] would prevent this to work. however as we use the other `topicidpartition` constructor in this case, it is not impacted by the `requirenonnull`.",0,0.9697281122207642
728124707,11331,dajac,2021-10-13T14:28:47Z,"in this case, it would be nice if we would have a `topicidpartition` which contains an optional topic name. for the context, the issue is that we might have partitions in the fetch requests for which the topic name is unknown or not yet known by the broker.",0,0.9834913611412048
728127262,11331,ijuma,2021-10-13T14:31:14Z,"we should probably remove that non null check, since it's weird to have it only in that one path. i can submit a pr.",0,0.5488607287406921
728132912,11331,dajac,2021-10-13T14:36:38Z,"sounds good, thanks!",1,0.9822825789451599
728455837,11331,jolshan,2021-10-13T21:20:16Z,"i think we may even be able to get away with fewer maps. i see in the commit you have we add to topicids at the start but i'm not sure that works if we have more than one id for a topic. i was thinking if we stored the id in the fetch data, we wouldn't need to build a map from ids to names. do we still use that anywhere?",0,0.9629918932914734
735854783,11331,jolshan,2021-10-25T18:25:53Z,todo: we can also put toforget back after the update step as we handle forgetting using different ids.,0,0.9882822632789612
735863741,11331,jolshan,2021-10-25T18:38:22Z,"todo 2: if we have an update with an unresolved name, should we change the name to be unresolved here? i think we should but want to confirm.",0,0.9857153296470642
735935021,11331,jolshan,2021-10-25T20:22:50Z,do we not care to change ids if the data is equal? we wouldn't usually send a request and i don't know if it is possible to even have the same data in such a case.,0,0.7325251698493958
741789472,11331,dajac,2021-11-03T10:20:45Z,could we iterate over `sessionpartitions` and directly populate `sessiontopicnames` by using `putifabsent` or even `put`? the grouping seems unnecessary to me here unless i am missing something.,0,0.9822140336036682
741791658,11331,dajac,2021-11-03T10:22:16Z,"as `tosend` is not used before l288, how about putting this line over there?",0,0.9868645071983337
741793046,11331,dajac,2021-11-03T10:23:03Z,not related to this pr but could we use `collections.emtpymap` here? that would avoid allocating a `hashmap` all the times.,0,0.9891946315765381
741795602,11331,dajac,2021-11-03T10:25:08Z,same comment as before.,0,0.982180118560791
741796143,11331,dajac,2021-11-03T10:25:34Z,nit: could we align like it was before?,0,0.983318567276001
741796825,11331,dajac,2021-11-03T10:26:09Z,nit: this change and the following ones do not seem necessary. i would revert them back.,0,0.9230871200561523
741797904,11331,dajac,2021-11-03T10:27:04Z,is this method still used? i can't find any usages of it.,0,0.9529553651809692
741798898,11331,dajac,2021-11-03T10:27:52Z,it seems that this method is not used anymore. could we remove it?,0,0.977001965045929
741801854,11331,dajac,2021-11-03T10:30:20Z,"this block is identical to the previous one. should we pull it into a helper method? (yeah, i know, i wrote this...)",0,0.9740270376205444
741804871,11331,dajac,2021-11-03T10:32:43Z,should we add a comment here which explains that the topic name might be null in `topicidpartition` if we were unable to resolve it?,0,0.9829796552658081
741806142,11331,dajac,2021-11-03T10:33:46Z,i would also add a small comment here.,0,0.9848887920379639
741817990,11331,dajac,2021-11-03T10:46:40Z,"putting this here but it is not related to this line. it seems that we have an opportunity in `processfetchrequest` to better handle the `fetch_session_topic_id_error` error. at the moment, it delays all the partitions. it seems to me that we could retry directly, no? if you agree, we could file a jira and address this in a subsequent pr.",0,0.9757973551750183
741818303,11331,dajac,2021-11-03T10:47:08Z,"yeah, that would be great. `topicpartition.topicpartition` looks really weird while reading.",-1,0.952261209487915
741823983,11331,dajac,2021-11-03T10:55:09Z,nit: should we format the code as follow? [code block],0,0.9888442158699036
741826013,11331,dajac,2021-11-03T10:58:00Z,`that.canequal(this)` seems weird to me. it seems that we could just remove it.,-1,0.9757059216499329
741938548,11331,dajac,2021-11-03T13:30:57Z,nit: the if/else inline reads a bit weird. should we extract the if/else? [code block],-1,0.9520807266235352
741939805,11331,dajac,2021-11-03T13:32:18Z,nit: we could add another constructor which takes a `topicidpartition`.,0,0.9886991381645203
741940362,11331,dajac,2021-11-03T13:32:52Z,is `usestopicids` used anywhere in this method?,0,0.9850833415985107
741943413,11331,dajac,2021-11-03T13:35:54Z,nit: how about naming it `cachedpartitionkey`? we could also benefits from passing `topicidpartition` to the constructor directly.,0,0.9883481860160828
741945969,11331,dajac,2021-11-03T13:38:24Z,nit: it might be better to encapsulate this in `cachedpartition`. we could add a method called `maybesettopicname` or piggy back on `updaterequestparams`.,0,0.9876610040664673
741964245,11331,dajac,2021-11-03T13:56:41Z,nit: there is an extra space after `== null`,0,0.9861108064651489
741967434,11331,dajac,2021-11-03T13:59:40Z,nit: we can remove the parenthesis here.,0,0.9867461323738098
741968413,11331,dajac,2021-11-03T14:00:35Z,i wonder if we should reply with `unknown_topic_id` for the topics whose are not resolved.,0,0.7856240272521973
741968554,11331,dajac,2021-11-03T14:00:43Z,nit: we can remove the parenthesis here.,0,0.9867461323738098
741969873,11331,dajac,2021-11-03T14:02:00Z,nit: we can use `tp.partition` here and a few other places.,0,0.9894037246704102
741974511,11331,dajac,2021-11-03T14:06:51Z,nit: parenthesis after `partitionindex` could be omitted.,0,0.9871866703033447
741976525,11331,dajac,2021-11-03T14:08:55Z,nit: parenthesis after partitionindex could be omitted.,0,0.9866417646408081
741982676,11331,dajac,2021-11-03T14:15:06Z,i already mentioned this before but it seems that we could retry immediately in this case when the session was upgraded/downgraded. that would avoid having to wait for the backoff.,0,0.9853230714797974
741983857,11331,dajac,2021-11-03T14:16:13Z,nit: `topicidpartition.topic` should work.,0,0.9862896800041199
741985410,11331,dajac,2021-11-03T14:17:34Z,nit: we could add another `apply` method to `topicpartitionoperationkey` which accepts a `topicidpartition`. that will be convenient.,0,0.9770705699920654
741987160,11331,dajac,2021-11-03T14:19:01Z,nit: `tp.topic`,0,0.9801281094551086
741990473,11331,dajac,2021-11-03T14:22:18Z,do we still use this constructor?,0,0.9872401356697083
742113471,11331,jolshan,2021-11-03T16:20:20Z,the idea was to not do a put operation for every partition but instead every topic. maybe grouping is slower though.,0,0.9536413550376892
742114292,11331,jolshan,2021-11-03T16:21:11Z,good catch,1,0.9703027606010437
742116109,11331,jolshan,2021-11-03T16:23:08Z,"fetch_session_topic_id_error occurs when we switch from not using topic ids in the request to using them (or vice versa). i think maybe we'd want to delay partitions to get the latest metadata, but not sure.",0,0.9754706025123596
742119691,11331,jolshan,2021-11-03T16:26:48Z,hmmm. so we'd sort out the ones with null names? what benefit are we thinking we'll get from this?,0,0.9366760849952698
742121483,11331,jolshan,2021-11-03T16:28:40Z,i think i wrote all of these before the class was updated. but i will change them. :),1,0.9840383529663086
742232425,11331,jolshan,2021-11-03T18:40:50Z,yeah. it's used in 49 places. some of the places i intentionally left as zero uuids. i can convert all of them to uuid.zero_uuid if we think this may be bug prone.,0,0.968082845211029
742285803,11331,jolshan,2021-11-03T19:58:44Z,"this was here before my change, but i can remove it.",0,0.986702024936676
742920899,11331,dajac,2021-11-04T14:58:23Z,nit: is it worth bringing back this line on the previous one as there is space now? it might be too long though.,0,0.9601801633834839
742926299,11331,dajac,2021-11-04T15:03:40Z,would it be more appropriate to move the above assertions to `fetchrequesttest`?,0,0.988061785697937
742928420,11331,dajac,2021-11-04T15:05:55Z,"should we also test when the current topic-partition in the session does not have a topic id? in this case, it should not be added to the `toreplace` set.",0,0.987593948841095
742931656,11331,dajac,2021-11-04T15:09:21Z,why do we use 12 here?,0,0.9679327011108398
742933244,11331,dajac,2021-11-04T15:11:00Z,it is curious that we don't assert the forgotten partitions here. is there a reason?,0,0.925049901008606
742935279,11331,dajac,2021-11-04T15:13:04Z,is there any reason for this change?,0,0.9415552020072937
742936005,11331,dajac,2021-11-04T15:13:51Z,do we still need this change?,0,0.9810842871665955
742938518,11331,dajac,2021-11-04T15:16:26Z,do we still need this change?,0,0.9810842871665955
742938637,11331,dajac,2021-11-04T15:16:34Z,ditto. there is a few other cases in this file.,0,0.9686524868011475
742939518,11331,dajac,2021-11-04T15:17:24Z,nit: there are two spaces after `=`.,0,0.9837478995323181
742944210,11331,dajac,2021-11-04T15:22:16Z,the pr changed how some errors are handled in the `fetcher`. do we have any tests for this new behavior?,0,0.9882160425186157
742950222,11331,dajac,2021-11-04T15:28:22Z,nit: it seems that we could use `topicidpartition` directly and remove `topicids` map entirely. we could also pass the `topicidpartition` to `buildfetchmetadata`.,0,0.9884004592895508
742954020,11331,dajac,2021-11-04T15:32:15Z,`0.equals(0)` was very likely put here by mistake.,0,0.9671559929847717
742963289,11331,dajac,2021-11-04T15:42:04Z,nit: we could get the topic id from `tp*.topicid`.,0,0.9875806570053101
742968374,11331,dajac,2021-11-04T15:47:22Z,nit: i would expand this comment a little and stress the fact that topic names are lazily resolved when the partitions are iterated over.,0,0.9763123989105225
742969700,11331,dajac,2021-11-04T15:48:38Z,should we assert that the `topicidpartition` received here contains the topic name?,0,0.9864020943641663
742975252,11331,dajac,2021-11-04T15:54:17Z,should we iterate over the partitions in the context to check the `topicidpartition`?,0,0.9878295660018921
742978184,11331,dajac,2021-11-04T15:57:14Z,it seems to be that it would be simpler to declare `fooid` and `barid` and to use them instead of getting them from the map.,0,0.985932469367981
742979446,11331,dajac,2021-11-04T15:58:29Z,i wonder if we should add a third topic which is never resolved. what do you think?,0,0.8012382388114929
742987345,11331,dajac,2021-11-04T16:06:50Z,should we add any tests for the new logic in kafkaapis?,0,0.9861391186714172
742993451,11331,dajac,2021-11-04T16:13:22Z,this is not ideal. could we validate that the topic id is correct as well?,-1,0.6873263120651245
743011890,11331,dajac,2021-11-04T16:33:33Z,"i wonder if we could add a few more unit tests. for instance, we should test the equals/hash methods of the cachedpartition (and possibly other methods there). we might want to add some for other classes as well. what do you think?",0,0.9676077961921692
743041695,11331,dajac,2021-11-04T17:06:58Z,"i think that the grouping is slower because it has to allocate another map, sets for each uuid, etc.",0,0.9826922416687012
743044369,11331,dajac,2021-11-04T17:10:17Z,"i think that would for instance happen when the controller fails over to an older ibp during an upgrade. this should remove the topic ids which means that v12 will be used for the next fetch request and trigger a fetch_session_topic_id_error. in this particular case, re-trying directly would be the optimal way to proceed for a follower. i wonder if they are other cases to consider here. for the consumer, it is definitely different.",0,0.9093395471572876
743044970,11331,dajac,2021-11-04T17:10:57Z,right. it seems to be that the `canequal(this)` does not make any sense here. could you double check?,0,0.9664168953895569
743046003,11331,dajac,2021-11-04T17:12:18Z,i guess that it does not change much in the end. i was considering this in order to be consistent with how we handle this for the consumer.,0,0.9512028098106384
743046927,11331,dajac,2021-11-04T17:13:29Z,"yeah, that's a good question. i guess that that constructor is convenient for tests but might be bug prone in the regular code. i am tempted to remove it entirely.... what do you think?",-1,0.9342284202575684
743239514,11331,jolshan,2021-11-04T22:13:41Z,i moved some back.,0,0.9796304702758789
743240074,11331,jolshan,2021-11-04T22:14:51Z,ah good catch.,1,0.9452776908874512
743240526,11331,jolshan,2021-11-04T22:15:49Z,"to clarify -- are you referring to a case where we upgraded? ie, it started with no id in the first request and added one in the second request?",0,0.9831205606460571
743241204,11331,jolshan,2021-11-04T22:17:09Z,i could theoretically check replace in the other test that checks multiple scenarios,0,0.9843064546585083
743241513,11331,jolshan,2021-11-04T22:17:46Z,i'm not sure i follow. did you mean the other test file?,0,0.6719473600387573
743242346,11331,jolshan,2021-11-04T22:19:26Z,"this was the case i tested when we had the bug of sending v13 for this scenario. the idea was that the session was empty and we had the correct topic id usage, not whether forgotten partitions were added correctly. i can add a check for forgotten partitions for completeness.",0,0.9873327612876892
743242849,11331,jolshan,2021-11-04T22:20:26Z,it likely had something to do with how the mock client was handling metadata. but that may have been for the older version where we checked nodeapiversion. i can try to switch it back.,0,0.9882835149765015
743243111,11331,jolshan,2021-11-04T22:20:49Z,nope. looks like another change i forgot to cleanup.,0,0.8001625537872314
743243975,11331,jolshan,2021-11-04T22:22:40Z,i think i'm misunderstanding something here. did you mean to say append?,-1,0.8525985479354858
743349235,11331,jolshan,2021-11-05T02:23:35Z,are you referring to how we changed unknown_topic_id and inconsistent_topic_id? for these cases we have testfetchinconsistenttopicid and testfetchunknowntopicid which check that we update the metadata for a partition level error.,0,0.9889265298843384
743349370,11331,jolshan,2021-11-05T02:23:52Z,these tests changed from returning a top level error to partition level error.,0,0.9859864711761475
743350813,11331,jolshan,2021-11-05T02:28:10Z,what logic are we thinking? checking that the unresolved topics are handled correctly?,0,0.9531080722808838
743351017,11331,jolshan,2021-11-05T02:28:54Z,i can add some for the equals and hash methods in cachedpartition. what classes were you thinking of for others?,0,0.9877043962478638
743354926,11331,jolshan,2021-11-05T02:42:15Z,hmm. i'm not quite sure why this would not make sense. i believe it is checking the types are correct.,-1,0.7034531235694885
743355748,11331,jolshan,2021-11-05T02:44:59Z,i think we would want to keep the authorization error. since it just logs a message. the unknown_topic_id error would request a metadata update which doesn't make sense when there is an authorization error.,0,0.9821003079414368
743360648,11331,jolshan,2021-11-05T03:01:38Z,or are you just referring to a case where we don't ever have topic ids?,0,0.9583327770233154
743361897,11331,jolshan,2021-11-05T03:05:57Z,looks like most of these changes were done by this commit: [a link] so i can remove them pretty easily.,0,0.9763912558555603
743365481,11331,jolshan,2021-11-05T03:18:35Z,i have no idea why this is here.,-1,0.7678654193878174
743369512,11331,jolshan,2021-11-05T03:33:09Z,"not quite sure what you meant here but i added this for now: `context1.foreachpartition((topicidpartition, _) => assertequals(topicids.get(""foo""), topicidpartition.topicid))`",0,0.9830652475357056
743370419,11331,jolshan,2021-11-05T03:36:47Z,"we could do that, but then this check will be a bit more complicated. `context2.foreachpartition((topicidpartition, _) => assertequals(topicnames.get(topicidpartition.topicid), topicidpartition.topic))`",0,0.9802022576332092
743370521,11331,jolshan,2021-11-05T03:37:06Z,i can think more on this.,0,0.9634098410606384
743370708,11331,jolshan,2021-11-05T03:37:39Z,still todo for friday,0,0.9568890333175659
743574922,11331,dajac,2021-11-05T11:16:18Z,"sorry, i meant below assertions not above. yes, it seems that they are testing the logic of the `fetchrequest` itself and not really the logic of the fetchsessionhandler.",-1,0.9849281907081604
743575635,11331,dajac,2021-11-05T11:17:38Z,correct. i was referring to the upgrade case. we might need to handle the downgrade case for [a link],0,0.9853687882423401
743576928,11331,dajac,2021-11-05T11:20:00Z,"yeah, it would be good to assert what we expect in `data2` for completeness.",0,0.9588791131973267
743577292,11331,dajac,2021-11-05T11:20:37Z,"yes, i was referring to those. ack, i missed them during my first read.",-1,0.9542982578277588
743578252,11331,dajac,2021-11-05T11:22:24Z,"yeah, i meant exactly that. how about using `assertpartitionsorder` helper? the assertion would be more complete.",0,0.9850345253944397
743578382,11331,dajac,2021-11-05T11:22:41Z,you could use `assertpartitionsorder` helper here as well.,0,0.9893423318862915
743578530,11331,dajac,2021-11-05T11:22:54Z,that is right.,0,0.9623538851737976
743745314,11331,dajac,2021-11-05T15:09:43Z,should we add or extend a test in `fetchertest` to cover this change? i would like to have one which ensure that the request sent is populated correctly (especially the replaced part) by the fetcher based on the session handler. it seems that we don't have such test in the suite at the moment.,0,0.9815042018890381
743749915,11331,dajac,2021-11-05T15:15:11Z,should we add a few unit tests to validate the changes that we have done in this class? we could add a few to fetchrequesttest (not use if it already exists though).,0,0.9885091185569763
743750508,11331,dajac,2021-11-05T15:15:55Z,do we have a unit test for this one and for `forgottentopics`?,0,0.9848211407661438
743751246,11331,dajac,2021-11-05T15:16:48Z,there are a few more cases where we could put the partition data back on the previous line in this file.,0,0.9879818558692932
743753319,11331,dajac,2021-11-05T15:19:17Z,"sorry, i wanted to say happen.",-1,0.9854052662849426
743753874,11331,dajac,2021-11-05T15:19:55Z,"anyway, we don't need to address this in this pr. i just wanted to point out that there is an opportunity for an improvement.",0,0.9021502733230591
743755936,11331,dajac,2021-11-05T15:22:10Z,do we have unit tests covering those cases? there are almost no changes in `abstractfetcherthreadtest` so it seems that we don't. are they somewhere else perhaps?,0,0.9786677956581116
743756690,11331,dajac,2021-11-05T15:23:01Z,i guess that we could remove it now.,0,0.9826539158821106
743759128,11331,dajac,2021-11-05T15:25:46Z,"should we use the same name for both `maybesetunknownname` and `mayberesolveunknownname`? i guess that you could differ by their argument. if we add unit tests for other methods of this class, should we cover all the methods that we have changed or added as well?",0,0.9866977334022522
743763229,11331,dajac,2021-11-05T15:30:37Z,do we have tests verifying this change?,0,0.9851720333099365
743764793,11331,dajac,2021-11-05T15:32:14Z,should we use `equals` instead of `==`? we use `equals` at l304 btw.,0,0.9895409941673279
743830587,11331,jolshan,2021-11-05T16:56:46Z,so you are asking for a test that is checking the fetcher builds the request correctly? is this a test for the fetcher or the builder?,0,0.9868278503417969
743830862,11331,jolshan,2021-11-05T16:57:08Z,i can do that but it will take some time. :grinning_face_with_sweat:,1,0.6068028807640076
743836225,11331,dajac,2021-11-05T17:04:29Z,we should have a test in the fetcher which ensure that the builder received the correct information. then we could have one for the request which ensure that the builder does its job correctly as well.,0,0.9846887588500977
743839587,11331,jolshan,2021-11-05T17:09:17Z,"the part i don't understand is that this building is in a method that sends the requests. i'm not sure how to pull that out and test specifically that the fetcher is getting the correct info. the fetcher is simply pulling from the fetchsessionhandler's build fetchrequestdata, so i feel like that is sufficient unless i'm missing something.",0,0.9027377367019653
743841128,11331,jolshan,2021-11-05T17:11:26Z,"i thought about the same name, but i thought it was a slightly different approach --> looking up in the map where it is maybe there vs. supplying the name.",0,0.9737446904182434
743908454,11331,dajac,2021-11-05T18:56:22Z,"right. you might have to assert on the request in the fetcher as well. as you said, we can't really get the data out from the builder otherwise.",0,0.9864245057106018
743909554,11331,dajac,2021-11-05T18:58:13Z,"yeah, i agree with you. perhaps, we could just remove the maybesettopicname and move its logic into the update request params method.",0,0.9780307412147522
743949497,11331,jolshan,2021-11-05T20:09:27Z,"ok, so we'll pass a name and the reqdata in that method.",0,0.9879122376441956
743968305,11331,jolshan,2021-11-05T20:47:38Z,so i can write a separate callback for each one that checks the id.,0,0.988987147808075
743973388,11331,jolshan,2021-11-05T20:58:27Z,"hmm, so this looks like another case of not having a test file for the java (unit test version) i can create that and add the tests you've been mentioning here. alternatively i can put the tests in the scala integration test file. seems like there are unit tests mixed in there too.",0,0.97513347864151
743973792,11331,jolshan,2021-11-05T20:59:21Z,so #11459 doesn't touch the fetchsessionhandler code. but i can still add these cases.,0,0.9893383979797363
743976846,11331,jolshan,2021-11-05T21:06:19Z,"i don't think processfetchrequest is tested anywhere. there tests for the much higher level method dowork, so i can try to write one like that and check if there is that partition with error?",0,0.9832596778869629
743977547,11331,jolshan,2021-11-05T21:07:56Z,"i think i have the same confusion here as i do for the fetcher tests. i agree that changes should be tested, but i'm not really sure how to do this here.",-1,0.6820946931838989
743979130,11331,jolshan,2021-11-05T21:11:07Z,"i think for correctness either works, but i will switch to equals for consistency.",0,0.9826960563659668
743981159,11331,jolshan,2021-11-05T21:15:45Z,ah i'm already doing this. :grinning_face_with_sweat: ok. sounds good.,1,0.9830775856971741
743983833,11331,jolshan,2021-11-05T21:21:23Z,sorry i'm still a bit confused. the request is sent in this method. we don't get access to the request. we have access to the data that is tested in fetchsessionhandler and that is passed into this method where the request is built and sent.,-1,0.9883365035057068
743997732,11331,jolshan,2021-11-05T21:56:17Z,nice. this works well.,1,0.9167478084564209
744103895,11331,dajac,2021-11-06T09:18:49Z,"we must be able to verify that the request sent out by this method is correct. in the unit tests, we mock the network client for this purpose. if i remember correctly, we can pass a request matcher to it. i need to look into the existing unit tests for this class to see how we have done it for other cases. we might already have tests verifying that the version of the fetch request sent out is correct based on wether topic ids are used or not. if we do, i suppose that we could proceed similarly.",0,0.9831621646881104
744104240,11331,dajac,2021-11-06T09:22:33Z,let's create that file and put new unit tests there. that is the way it should be.,0,0.9818496108055115
744138150,11331,jolshan,2021-11-06T15:41:50Z,got it. i guess i was wondering if there would be an issue if we change semantics/expected flow for fetch again.,0,0.9766884446144104
744138204,11331,jolshan,2021-11-06T15:42:12Z,confirmed this was a strange quirk from 4 years ago,0,0.9103429317474365
744177445,11331,jolshan,2021-11-06T22:57:45Z,"seems like the other issue is that fetchsessionhandler.fetchrequestdata constructor is private. so if i want to test in another file i need to either make the constructor public, create a fetchsessionhandler and duplicate the code here, or just put the values into the builder directly (skipping the class). i'm open to just putting the values directly if that makes sense.",0,0.9821593165397644
744875433,11331,dajac,2021-11-08T16:10:05Z,`buildfetch` seems to be well isolated so it should be quite easy to write a few unit tests for it. `buildfetch` returns a `builder` so you will have to build the request in order to inspect it.,0,0.9857703447341919
744877634,11331,dajac,2021-11-08T16:12:31Z,"yeah, that should work. otherwise, we could also make the method package private and add a few unit tests for it.",0,0.9802273511886597
744880575,11331,jolshan,2021-11-08T16:15:40Z,i guess the part i didn't understand is that buildfetch's builder is tested in fetchsessionhandler tests. but i guess there is one more method call we can test.,0,0.9780184626579285
744883112,11331,jolshan,2021-11-08T16:18:27Z,is there a reason we do this? if the previous data had a topic id and this one doesn't we should send a different fetch request version and the session will be closed.,0,0.9800613522529602
744892585,11331,dajac,2021-11-08T16:28:38Z,"without this, when a topic id is set back to ""zero"", the former topic id is added to the replaced set which is a bit unintuitive, i think. in the end, it does not matter too much because the version is downgraded in this case so the replaced set is ignored. i was debating if it worth handling this case explicitly here.",0,0.6819067597389221
744905470,11331,jolshan,2021-11-08T16:43:11Z,"i realize we may still want this as if the partition data is exactly the same, we will actually ignore the downgrade which is not good.",0,0.8552163243293762
744906035,11331,jolshan,2021-11-08T16:43:48Z,i have a test where this happens. :grinning_face_with_sweat:,-1,0.8030948042869568
744942958,11331,dajac,2021-11-08T17:27:58Z,right. here i would like to have tests which ensure that the builder is fed correctly based on the fetchsessionhandler's data.,0,0.9750588536262512
745010308,11331,jolshan,2021-11-08T19:00:45Z,do we need to reassign to empty map here?,0,0.9806345701217651
745033891,11331,jolshan,2021-11-08T19:35:27Z,i added the initialization in the other builder since we were missing it.,0,0.9839206337928772
745050242,11331,dajac,2021-11-08T19:59:14Z,that is a good question. i thought that it is better to empty the map if we don't use topic ids instead of keeping a out-of-date mapping. what do you think?,1,0.8505526781082153
745050475,11331,dajac,2021-11-08T19:59:35Z,thanks!,1,0.9308210611343384
745053425,11331,jolshan,2021-11-08T20:04:05Z,i think the session will already have an empty map or close but it don't think it makes a big difference with or without this change.,0,0.9525666832923889
745060151,11331,dajac,2021-11-08T20:14:32Z,i am not sure that i follow. we should only test the fetchrequest/builder in fetchrequesttest.,0,0.7221990823745728
745091391,11331,jolshan,2021-11-08T21:04:31Z,i ended up making the new test file. i was confused because i thought the data object needed to be tested but it doesn't. i think this can be resolved.,0,0.9385695457458496
745182731,11331,jolshan,2021-11-08T23:56:28Z,"for my understanding, is this line necessary? we are assigning the same topic partition, right?",0,0.9802713990211487
745478693,11331,dajac,2021-11-09T10:24:12Z,nit: it might be worth expanding this comment a little more.,0,0.8824434280395508
745487251,11331,dajac,2021-11-09T10:34:59Z,nit: could we use `assertequals`? the advantage is that it ensure that the map contains only what we want.,0,0.9859673380851746
745488238,11331,dajac,2021-11-09T10:36:18Z,nit: could we use `assertequals` here as well?,0,0.9890318512916565
745492071,11331,dajac,2021-11-09T10:41:12Z,nit: i wonder if doing the following would be a bit more complete? [code block],0,0.9562646746635437
745495072,11331,dajac,2021-11-09T10:45:06Z,"no, it is not. i kept it for completeness.",0,0.8962241411209106
745497189,11331,dajac,2021-11-09T10:47:49Z,nit: could we actually compare the content of both collections instead of only verifying their size? that would be more complete.,0,0.9782147407531738
745499051,11331,dajac,2021-11-09T10:50:23Z,"nit: in this case, we could actually do the following which seems a bit better: [code block] then, we can use `tp.topicpartition` when we need it. what do you think?",0,0.9790230393409729
745499747,11331,dajac,2021-11-09T10:51:11Z,nit: could we put this on the top of the test?,0,0.9856248497962952
745505533,11331,dajac,2021-11-09T10:58:49Z,"nit: would it be simpler to do the following? [code block] we have to use `new topicidpartition(topicid1, new topicpartition(null, 0))` because [a link] is not merged yet. the advantage of this way is that it test the whole map, including the ordering.",0,0.9852010011672974
745506626,11331,dajac,2021-11-09T11:00:14Z,"i am not sure that we gain much by testing this because testing `fetchdata` already verify that all the partitions are included, no?",0,0.8131479024887085
745511442,11331,dajac,2021-11-09T11:06:56Z,"this is a bit weird. i would have expected a `null` as the topic name if `topicnames` does not contain the mapping, no?",-1,0.9874060750007629
745512157,11331,dajac,2021-11-09T11:08:07Z,can't we use `assertequals`? it seems that it should work here.,0,0.9862494468688965
745515647,11331,dajac,2021-11-09T11:13:12Z,"as discussed, we must test this.",0,0.9786050319671631
745518340,11331,dajac,2021-11-09T11:16:58Z,nit: should we put `topicid` first to be consistent with `topicidpartition`'s constructor?,0,0.9883344173431396
745518525,11331,dajac,2021-11-09T11:17:17Z,could we add a unit test for this?,0,0.9866430759429932
745518658,11331,dajac,2021-11-09T11:17:30Z,could we add a unit test for this new method?,0,0.9866166114807129
745518818,11331,dajac,2021-11-09T11:17:43Z,could we add a unit test for this one as well?,0,0.9862457513809204
745571481,11331,dajac,2021-11-09T12:31:38Z,"nit: fyi, you could use an anonymous class in this case: ``` val fetcher = new mockfetcherthread(fetchbackoffms = fetchbackoffms) { override def fetchfromleader(fetchrequest: fetchrequest.builder): map[topicpartition, fetchdata] = { } }",0,0.9847224354743958
745576080,11331,dajac,2021-11-09T12:38:04Z,nit: a space is missing before `10`.,0,0.9846886396408081
745576158,11331,dajac,2021-11-09T12:38:10Z,ditto.,0,0.859873354434967
745577596,11331,dajac,2021-11-09T12:40:05Z,nit: there is an extra space after `foreach(`.,0,0.9808634519577026
745580364,11331,dajac,2021-11-09T12:43:45Z,nit: i am not a fan of this. i would usually prefer something like the following in this case. i guess that it is a matter of taste so i leave it up to you. [code block],-1,0.9650909304618835
745595523,11331,dajac,2021-11-09T13:03:52Z,should we assert the content of `context2`?,0,0.9871158003807068
745595783,11331,dajac,2021-11-09T13:04:14Z,"i guess that `respdata1` is used by mistake here, isn't it? this is a good example why it is better to use `assertequals` to verify collections instead of iterating over them. the assertions that you have below have not caught this.",0,0.9811336994171143
745597673,11331,dajac,2021-11-09T13:06:56Z,`startswithtopicids` and `endswithtopicids` are a bit misleading here. i suppose that they refer to either the broker knows about the topic id or not (present in its metadata cache). am i right?,0,0.7451203465461731
745612156,11331,dajac,2021-11-09T13:25:35Z,nit: a space is missing before `{` and `}` should be on a new line for blocks.,0,0.9872334003448486
745612631,11331,dajac,2021-11-09T13:26:10Z,ditto about the code format.,0,0.9051349759101868
745613827,11331,dajac,2021-11-09T13:27:41Z,"the size is implicitly verified by the next assertion. we could remove it, i guess.",0,0.9882217049598694
745613931,11331,dajac,2021-11-09T13:27:47Z,ditto.,0,0.859873354434967
745615375,11331,dajac,2021-11-09T13:29:29Z,can't we use `assertequals` here?,0,0.9860833287239075
745686335,11331,dajac,2021-11-09T14:46:02Z,"thinking a little more about this one. how about doing the following? we could define an helper method `fetchmessages` which wraps `replicamanager.fetchmessages` (takes the same arguments) and returns `seq[(topicidpartition, fetchpartitiondata)]`. this would avoid all these callbacks that we have here.",0,0.9798259139060974
745693355,11331,dajac,2021-11-09T14:52:41Z,"should we do another round before this one to ensure that a partition would be removed from the context while still having an `incrementalfetchcontext`? we could perhaps have multiple partitions in the context, resolved and unresolved, and then we could remove them one by one.",0,0.9872534871101379
745699410,11331,dajac,2021-11-09T14:58:37Z,"should we pass `topicnamesforrequest1` instead of `topicnames` here? in practice, we already use the same mapping in all cases when the context is created.",0,0.988903820514679
745701165,11331,dajac,2021-11-09T15:00:19Z,should we make it private?,0,0.9808743596076965
745701266,11331,dajac,2021-11-09T15:00:25Z,should we make it private?,0,0.9808743596076965
745751523,11331,dajac,2021-11-09T15:49:55Z,"should we verify what the context contains? this is very likely the most important point to verify in this test, no?",0,0.9766197800636292
745789936,11331,dajac,2021-11-09T16:25:51Z,i find those block of code really hard to read. i wonder if we could simplify them.,-1,0.9429388046264648
745863973,11331,jolshan,2021-11-09T17:47:25Z,is `assertmapequals` not already doing this? it seems like we check all entries and make sure there is nothing left over.,0,0.9806348085403442
745864456,11331,jolshan,2021-11-09T17:47:59Z,unless you are referring to the sessiontopicnames line. :grinning_face_with_sweat:,-1,0.9449003338813782
745865347,11331,jolshan,2021-11-09T17:49:03Z,assertequals for the tosend/toreplace lists/map?,0,0.9888784289360046
745867608,11331,jolshan,2021-11-09T17:51:48Z,are we thinking this would be in the if block? or in a separate one outside?,0,0.983740508556366
745869793,11331,dajac,2021-11-09T17:54:22Z,"yes, i was referring to `sessiontopicnames`.",0,0.9832175970077515
745869947,11331,dajac,2021-11-09T17:54:34Z,right.,0,0.9566289782524109
745871819,11331,dajac,2021-11-09T17:56:55Z,"yeah, that could remain in the if block. we could simply replaces those two lines, i guess.",0,0.9867526292800903
745924906,11331,jolshan,2021-11-09T18:58:38Z,i caught a bug with our partitiondata.equals method from implementing this. (we should be using .equals and not ==),-1,0.6480135321617126
745925751,11331,jolshan,2021-11-09T18:59:58Z,"i was mostly testing the serialization here, but maybe that's not important? i can remove if we don't need that.",0,0.9754239320755005
745930497,11331,jolshan,2021-11-09T19:06:49Z,the expectedname will be null if it is not in the map. map.get returns null if the id is not in the map.,0,0.9833636283874512
745941900,11331,jolshan,2021-11-09T19:23:09Z,"is this different than assertpartitionsorder(context2, seq(foo0, foo1, emptyzar0))?",0,0.9877039194107056
745942320,11331,jolshan,2021-11-09T19:23:44Z,i can change the ordering of these asserts so they are consistent with the earlier ones,0,0.9845890402793884
745943714,11331,jolshan,2021-11-09T19:25:42Z,you are correct. i can change to `startswithtopicidsinmetadatacache` etc if that is not too verbose.,0,0.9851157069206238
745947154,11331,jolshan,2021-11-09T19:30:38Z,would we pass in the topicidpartition we want to match as well?,0,0.9870908260345459
745963579,11331,dajac,2021-11-09T19:54:23Z,gotcha. i missed it. changing the order to be consistent makes sense.,1,0.518211841583252
745965419,11331,dajac,2021-11-09T19:57:02Z,hum.. i was thinking that the method would return the partitions and we would do the assertion after. that would make the helper generic enough to be reused in other places as well. i guess that either ways would work.,0,0.9218237400054932
746038595,11331,jolshan,2021-11-09T21:01:47Z,oh so we wouldn't do the filter as part of the method?,0,0.9638490676879883
746051435,11331,dajac,2021-11-09T21:14:01Z,correct. the method would return the full response. then we can assert it.,0,0.9846985936164856
746077096,11331,jolshan,2021-11-09T21:56:06Z,we can do that. i believe this is being tested via `testfetchsessionwithunknownid` already. but an explicit test will be good.,0,0.7205263376235962
746078020,11331,jolshan,2021-11-09T21:57:39Z,"i can add another one that is more explicitly testing this method, but it is tested via `testupdatedpartitionresolvesid`",0,0.9887725710868835
746096126,11331,jolshan,2021-11-09T22:28:59Z,"i think the issue with that approach is it doesn't quite cover the four cases, right? i could keep as is, but have a second partition that just uses ids and resolve that one on the second round.",0,0.9821799993515015
746100239,11331,jolshan,2021-11-09T22:36:15Z,hmm. could i also just remove the filter and do that after to use just the single callback?,0,0.9845833778381348
746217460,11331,jolshan,2021-11-10T03:15:51Z,"is this replacing `testupdatedpartitionresolvesid`? this is definitely cleaner, but i'm not sure we are covering the same cases here. for context, the test i mentioned before is testing different update scenarios (i probably named it poorly). mostly the idea is that the update method works correctly. (ie, we update a partition that once had a topic id to one that does not, etc). maybe that is covered in some of the other tests i've added (like `def maybeupdaterequestparamsorname`) and we can just remove that test. what do you think? i'll also think about this a bit more.",0,0.9489710330963135
746220127,11331,jolshan,2021-11-10T03:24:38Z,alternatively i can just rewrite this.,0,0.9838498830795288
746220311,11331,jolshan,2021-11-10T03:25:14Z,^ this is what i've done.,0,0.7486015558242798
746376488,11331,dajac,2021-11-10T09:05:48Z,"yeah, that works as well.",0,0.9753931164741516
746404173,11331,dajac,2021-11-10T09:29:25Z,"i wrote that test to illustrate how we could improve the readability. my concern is that they are so many lines/assertions in `testupdatedpartitionresolvesid` and `testtoforgetcases` that we get distracted and we have almost missed the most important assertions - the ones which validate what the session contains (`assertpartitionsorder`). `assertpartitionsorder` is actually the piece which ensures that the names are resolved or not, right?",0,0.7648313045501709
746420015,11331,dajac,2021-11-10T09:47:54Z,"could we simplify all of that by defining two `topicidpartition`? for instance, we could have the following: [code block] then, we can use them where we need them.",0,0.9880573749542236
746423986,11331,dajac,2021-11-10T09:52:41Z,we usually prefer to not use `any*` but to rather provide the expected values.,0,0.9802731275558472
746425514,11331,dajac,2021-11-10T09:54:31Z,we have two paths (fetch from follower and fetch from consumer) in `handlefetchrequest` where we handle unknown topic names. should we parameterize the test to cover both of them?,0,0.9886278510093689
746433053,11331,dajac,2021-11-10T10:03:26Z,"i am not sure that i understand the value that we get out of this logic. `updateandgenerateresponsedata` creates a fetchresponse based on its input. therefore, the response that we assert is not so surprising in the end, right? it will contain `inconsistent_topic_id` if when the method gets it as an input. this logic would make sense for a test which verifies `updateandgenerateresponsedata` but looks like a distraction in a test which verify the name resolution logic. am i missing something here?",0,0.6233118176460266
746433401,11331,dajac,2021-11-10T10:03:52Z,nit: you could use `assertequals` as it calls `equals`.,0,0.9890062808990479
746461644,11331,dajac,2021-11-10T10:38:21Z,i guess that it does not hurt to keep it.,0,0.7657209634780884
746783340,11331,jolshan,2021-11-10T16:45:20Z,"there are two places it may be resolved -- either in the update method if the partition with the new id is sent in the request or in the assertpartitionsorder. i was also trying to ensure the correct error messages are returned in the response specifically via `updateandgenerateresponsedata`, but maybe we don't care about this here?",0,0.9572348594665527
746785542,11331,jolshan,2021-11-10T16:47:42Z,i copied this from the test above. :grinning_face_with_sweat: wasn't sure if we wanted consistency amongst the tests.,-1,0.9383446574211121
746789815,11331,jolshan,2021-11-10T16:52:21Z,"sure. we can remove it. i think i was concerned about the correct handling of the resolved partitions (ie, we get a response back that we can actually parse), but maybe that's not really necessary.",0,0.6676512360572815
746803000,11331,dajac,2021-11-10T17:06:46Z,"do you mean the correct handling of the resolved partitions by `updateandgenerateresponsedata`? i think testing `updateandgenerateresponsedata` is a good thing in general. perhaps, we should just put this into a separate test specific to that method? we should also test it for all context types with and without topic id, i guess.",0,0.955327033996582
746805054,11331,dajac,2021-11-10T17:09:04Z,"right. the question is how to validate that the first update method works? you have to get the partitions from the session as well, isn't it?",0,0.9830187559127808
746807276,11331,jolshan,2021-11-10T17:11:51Z,i suppose so. i wonder if we should even include the update method at all then...,0,0.537070631980896
746826740,11331,dajac,2021-11-10T17:35:47Z,what do you mean?,0,0.9683603048324585
746829235,11331,jolshan,2021-11-10T17:39:01Z,"if we always resolve when iterating through the partitions, then do we need to resolve via the update method?",0,0.9841881990432739
746836952,11331,jolshan,2021-11-10T17:49:20Z,is there a way to make such a test without duplicating the newcontext portions?,0,0.983504056930542
746852321,11331,dajac,2021-11-10T18:01:40Z,"yeah, that is not really necessary as you said. i don't mind if you remove it.",0,0.8832172155380249
746867390,11331,jolshan,2021-11-10T18:22:07Z,should this be a check when topic is null?,0,0.9805295467376709
746870544,11331,dajac,2021-11-10T18:26:06Z,that could be :grinning_face_with_smiling_eyes:,0,0.8825968503952026
746873252,11331,jolshan,2021-11-10T18:29:51Z,i've concluded that your new test will now cover the necessary cases (especially with your new commit) so i think we can just remove this.,0,0.9839426279067993
176640732,4756,ijuma,2018-03-23T05:14:32Z,we don't use logback for anything else. i'd suggest keeping it consistent with the project.,0,0.9798785448074341
176640868,4756,ijuma,2018-03-23T05:15:57Z,`scalalogging` is already defined in this file.,0,0.9880298972129822
176640906,4756,ijuma,2018-03-23T05:16:15Z,this is already defined in this file.,0,0.9872085452079773
176645062,4756,debasishg,2018-03-23T06:02:06Z,done ..,0,0.9689553380012512
176645077,4756,debasishg,2018-03-23T06:02:13Z,removed.,0,0.9311882257461548
176645090,4756,debasishg,2018-03-23T06:02:21Z,removed.,0,0.9311882257461548
176799631,4756,guozhangwang,2018-03-23T16:56:25Z,do we need to import these two dependencies? could we use kafka's own embeddedkafkacluster?,0,0.9873881936073303
176799962,4756,guozhangwang,2018-03-23T16:57:34Z,does it worth to include this dependency at test runtime? cc .,0,0.9881191849708557
176800608,4756,guozhangwang,2018-03-23T16:59:42Z,could we add the default for short and bytebuffer as well?,0,0.9893304705619812
176801533,4756,guozhangwang,2018-03-23T17:02:47Z,i'm wondering if we could provide default serdes for windowed key as well? see `o.a.k.streams.kstream.windowedserdes` for java code.,0,0.9891238212585449
176802156,4756,guozhangwang,2018-03-23T17:05:08Z,nit: how about rename to `flatvaluemapperfromfunction` for better understanding? ditto below.,0,0.9250431656837463
176802758,4756,guozhangwang,2018-03-23T17:06:56Z,"just for my own education: is it necessary to add `, _` in the end? what are the possible classes we want to still include?",0,0.968072772026062
176803277,4756,guozhangwang,2018-03-23T17:08:49Z,nit: newline for the second parameter.,0,0.9889209270477295
176805401,4756,guozhangwang,2018-03-23T17:16:14Z,why we can ignore the topic here? ditto below?,0,0.8118652105331421
176806499,4756,guozhangwang,2018-03-23T17:20:01Z,"nit: `long2long(_)` to be consistent with others? actually, do we need to explicitly call it? i thought it will be implicitly triggered anyways from `predef`.",0,0.9872527718544006
176809033,4756,guozhangwang,2018-03-23T17:28:54Z,"could we add this syntax sugar in the implicit conversion so all classes like `kgroupedstream`, `ktable` and `streamsbuilder` can use it?",0,0.9895551204681396
176809497,4756,guozhangwang,2018-03-23T17:30:34Z,why do we need the `asvaluemapper` here explicitly? ditto below.,0,0.9639678001403809
176812165,4756,guozhangwang,2018-03-23T17:39:43Z,"do we have to convert two parameters to a tuple and then apply the function.tupled? i'm asking this because this is on the critical code path (called per map per record), and if there is non-negligible overhead..",0,0.9817137122154236
176812703,4756,guozhangwang,2018-03-23T17:41:40Z,"no `scalastyle:off null` before, is this intentional?",0,0.9548534154891968
176812967,4756,guozhangwang,2018-03-23T17:42:37Z,nit: space after comma.,0,0.9863386750221252
176816332,4756,guozhangwang,2018-03-23T17:53:26Z,"is it a syntax sugar as `branch`? i'd prefer to keep java and scala interfaces consistent, so that if we think it is worthwhile we'd better add it in java apis as well, otherwise we should remove it from scala apis. wdyt?",0,0.9863357543945312
176817831,4756,guozhangwang,2018-03-23T17:57:29Z,"this is a deprecated api in java, we should replace it with materialized.",0,0.9888741970062256
176819139,4756,guozhangwang,2018-03-23T18:01:58Z,nit: default to `info`?,0,0.987890362739563
176819498,4756,guozhangwang,2018-03-23T18:03:20Z,the file `logs/kafka-server.log` seems not appropriate as it is not for kafka broker logs right?,0,0.9796217679977417
176820184,4756,guozhangwang,2018-03-23T18:05:54Z,"this is a meta comment: i'd suggest we consider adding logback generally for kafka, instead of sneaking in for streams scala wrapper. we can still use log4j for now. see [a link] cc",0,0.978602409362793
176897781,4756,debasishg,2018-03-24T03:00:43Z,this library `scalatestembeddedkafka` has a nice integration with scalatest. hence it makes writing tests easier and we don't have to bother starting / managing the embedded kafka instance. the test code becomes very concise.,0,0.6424025893211365
176897811,4756,debasishg,2018-03-24T03:02:24Z,it's only to demonstrate custom serdes. we picked up avro since (afair) suggested this example in one of the earlier pr discussions. this example goes to show that custom serdes can be handled as seamlessly as primitive ones.,0,0.9882721304893494
176897854,4756,debasishg,2018-03-24T03:05:35Z,we need this for sam type conversion which is not fully supported in scala 2.11. in scala 2.12 we don't need this. this code base runs both in scala 2.11 and scala 2.12.,0,0.9881604909896851
176898091,4756,debasishg,2018-03-24T03:18:32Z,"the `, _` takes care of the other imports that don't need to be renamed like `serialized`, `joined` etc.",0,0.9873911738395691
176898176,4756,debasishg,2018-03-24T03:23:51Z,don't find the `topic` being used in de-serializer implementations e.g. [a link],0,0.9796897172927856
176898673,4756,debasishg,2018-03-24T03:40:43Z,"we need to call it explicitly. `predef` has an implicit conversion between `long` and `java.lang.long` but not between `ktable[k, long]` and `ktable[k, java.lang.long]` which we are dealing with here.",0,0.988430380821228
176899296,4756,ijuma,2018-03-24T04:05:50Z,"yes, let's stick to log4j in this pr.",0,0.9860312938690186
176899431,4756,debasishg,2018-03-24T04:10:36Z,this may not be relevant here. we were using scalastyle plugin with sbt. guess we can ignore it for now.,0,0.9760414958000183
176899457,4756,debasishg,2018-03-24T04:11:36Z,maybe we can have a `package object` with such stuff that can be reused across abstractions. better than repeating for every class. will do this.,0,0.8885395526885986
176899731,4756,debasishg,2018-03-24T04:27:28Z,we can add the following: [code block] but this one also may be useful when the user just needs to pass in the `keyserde`. she need not construct any `materialized` which is abstracted within the implementation of the api. suggestions ?,0,0.9887329339981079
176899763,4756,debasishg,2018-03-24T04:29:11Z,should we remove `logback.xml` ?,0,0.987951934337616
176928234,4756,guozhangwang,2018-03-25T04:15:10Z,generally speaking ak repo tend to avoid dependencies unless it is necessary. i'm wondering if we can improve on kafka's own embeddedkafkacluster to have the same functionalities as the `net.manub:scalatest-embedded-kafka-streams`.,0,0.983180046081543
176928257,4756,guozhangwang,2018-03-25T04:17:34Z,"are these interfaces only used for built-in primitive types, or are they going to be extended by users for their own serdes, like avro? if it is the latter case we cannot enforce users to always ignore the topic.",0,0.9802730083465576
176928265,4756,guozhangwang,2018-03-25T04:18:35Z,ack. makes sense. scala `predef` is not as smart as applying to nested types yet.,-1,0.8269831538200378
176928266,4756,guozhangwang,2018-03-25T04:18:57Z,ack.,0,0.7720441818237305
176928367,4756,guozhangwang,2018-03-25T04:28:27Z,"i'd vote for keeping java / scala api consistent, and we are going to remove deprecated apis in future releases anyway. in current api we'd only have one additional overload: [code block] i think for users who do not want to specify the store name at all, they can rely on [code block] to still hide the `materialized` parameter with implicit conversion. for users who do want to specify the store name, but want to rely on type conversion, we could call `withkeyserde` and `withvalueserde` internally in the implicit conversion so that user only need to give `materialized.as(storename)` does that work?",0,0.9644521474838257
176928378,4756,guozhangwang,2018-03-25T04:28:53Z,"yup, please remove that file as well.",0,0.9723582863807678
176929613,4756,debasishg,2018-03-25T05:46:27Z,"we can definitely use kafka's own `embeddedkafkacluster` to integrate with scalatest. in `net.manub:scalatest-embedded-kafka-streams`, the main value add is integration with scalatest and hence you don't have to explicitly start / stop server as part of the test. also with kafka streams it has very nice constructs like the one we use here .. [a link] .. note you just have to define the transformations and do the publish and consume as part of a closure. no need to start / stop the topology. hence the test code becomes very concise. of course it depends on the opinion of the committee but i think this would be a great addition to the dependency. here's a suggestion .. we use `net.manub:scalatest-embedded-kafka-streams` for now. after all it's a *test* dependency. and work on a separate pr to make the integration between `embeddedkafkacluster` and scalatest better and in line with the functionalities offered by the library. wdyat ?",1,0.6494660973548889
176930041,4756,debasishg,2018-03-25T06:12:10Z,+1 .. will remove this overload for `count`.,0,0.9787977337837219
176931307,4756,debasishg,2018-03-25T07:21:36Z,the implementation [a link] is only for *stateless* serdes implementation where nothing gets stored in topics. for stateful implementation involving topics the user can provide her own implementation of `scalaserde`. we provide this as a reference implementation of stateless serdes that we use in implementing `avroserde` in the test. of course we can decide if we should bundle this as part of the source or test. but we thought that the implementation may be useful to users implementing stateless custom serdes. thoughts?,0,0.9731041193008423
176931378,4756,debasishg,2018-03-25T07:25:00Z,+1,0,0.696722686290741
176931381,4756,debasishg,2018-03-25T07:25:14Z,+1,0,0.696722686290741
176931387,4756,debasishg,2018-03-25T07:25:27Z,+1,0,0.696722686290741
176931389,4756,debasishg,2018-03-25T07:25:38Z,+1,0,0.696722686290741
176931394,4756,debasishg,2018-03-25T07:25:56Z,+1,0,0.696722686290741
176931402,4756,debasishg,2018-03-25T07:26:13Z,+1,0,0.696722686290741
176931414,4756,debasishg,2018-03-25T07:26:42Z,will change the name to `kafka-streams-scala.log`,0,0.9866216778755188
176931419,4756,debasishg,2018-03-25T07:26:52Z,+1,0,0.696722686290741
176985739,4756,mjsax,2018-03-26T05:49:58Z,nit: those are actually sorted alphabetically -- can we clean this up? thx.,0,0.9582555890083313
176985752,4756,mjsax,2018-03-26T05:50:06Z,as above.,0,0.978552520275116
176986121,4756,mjsax,2018-03-26T05:54:10Z,"should we add those exclusions? i know that we put exclusions when introducing findbugs because it is not possible to introduce it and rewrite all the code -- but for new code, we should consider changing the code. i am not a scale person though -- can you elaborate on this?",0,0.896198034286499
176986532,4756,mjsax,2018-03-26T05:58:09Z,should this be `bytearraykeyvaluestore`? -- we don't use abbreviations in the java code base.,0,0.986652135848999
176987291,4756,mjsax,2018-03-26T06:05:20Z,why do we need an `asinstanceof` here? (same below),0,0.9843355417251587
176987359,4756,mjsax,2018-03-26T06:05:52Z,why do we not import `bytes` ?,0,0.9681963324546814
176987713,4756,mjsax,2018-03-26T06:09:03Z,"nit: should we use `[k, v, vr]` as in java?",0,0.9896440505981445
176988085,4756,mjsax,2018-03-26T06:12:20Z,nit: name `v` instead of `vr` ?,0,0.987721860408783
176988134,4756,mjsax,2018-03-26T06:12:39Z,nit: name `v` instead of `t` ?,0,0.9869865775108337
176988730,4756,mjsax,2018-03-26T06:16:53Z,nit: `kvo` -> `keyvalueother` ?,0,0.9880101084709167
176988977,4756,mjsax,2018-03-26T06:19:03Z,"for my own education. what is a ""stateless serde"" ?",0,0.803242564201355
176989413,4756,mjsax,2018-03-26T06:22:09Z,"nit: remove spaced -> `{keyvalue, consumed}`",0,0.988214373588562
176989878,4756,mjsax,2018-03-26T06:26:05Z,this should only take 4 parameters. we simplified the api and this method is deprecated (cf. [a link],0,0.9859011769294739
177137368,4756,debasishg,2018-03-26T15:39:23Z,+1 ..,0,0.8949370980262756
177184454,4756,mjsax,2018-03-26T18:09:25Z,"nit: i am not a fan of adding links in javadocs, because links might break; better reference to the corresponding class as javadoc cross reference? also: i am wondering if we should remove this method from the wrapper in the first place? imho, it's not a good idea to add deprecated api in new code?",-1,0.9723793864250183
177185072,4756,mjsax,2018-03-26T18:11:39Z,"a `valuetransformer` also have `init()`, `punctuate()` and `close()` method. why is this code much simpler than the wrapper for `transform()` above?",0,0.9850656390190125
177185869,4756,mjsax,2018-03-26T18:14:29Z,"as above. what about `init()`, `punctuate()`, and `close()` ?",0,0.9861128926277161
177188532,4756,mjsax,2018-03-26T18:23:14Z,"i agree that both apis should be consistent. does a `split` add much value compare to `branch`? btw, this might be related to [a link] i am also open to add a `split()` if we think it's useful.",0,0.9773626923561096
177189344,4756,mjsax,2018-03-26T18:26:04Z,why do we only allow to specify a `keyserde` but not replace the store with a different one? scala noob question: would it be possible to have a single `count` / `reduce` etc instead of overloads and use `option` and implicits to infer optional arguments?,0,0.985671877861023
177201338,4756,seglo,2018-03-26T19:06:51Z,"i'm a fan of `net.manub:scalatest-embedded-kafka-streams`, but i understand the concern about bringing in more deps. i only mentioned it on the dev-kafka list because i didn't think there was much value in improving the embedded kafka implementation in `kafka-stream-scala` and making it a public interface because `scalatest-embedded-kafka` already existed. i wasn't aware of `embeddedkafkacluster`. if `scalatest-embedded-kafka` were brought into the project then there will be drift between the version of kafka broker in code and whatever this test lib references. i like your suggestion: perhaps we can do this now for this pr, but keep it simple. i could work on it if you're busy.",1,0.6056163311004639
177206327,4756,vvcephei,2018-03-26T19:25:44Z,"i'd like to confirm that this option is actually safe. is this a best practice at this point for targeting 2.11? also, how can we know we're not dragging in other (potentially unwanted) experimental compiler features with this?",0,0.9814551472663879
177206719,4756,vvcephei,2018-03-26T19:27:21Z,"cool. in that case, maybe we should also add 'streams:streams-scala:examples' and put it there?",1,0.9755240082740784
177207156,4756,vvcephei,2018-03-26T19:28:57Z,nit: this is a bit cumbersome. can we do project(':streams:scala-wrapper') and archive: 'kafka-streams-scala-wrapper' or some such instead?,-1,0.9252214431762695
177210106,4756,vvcephei,2018-03-26T19:39:58Z,"i have used `net.manub:scalatest-embedded-kafka-streams` before, and it *is* very nice. but i also worry about adding dependencies to the core project, even test deps. if our tests become a bit uglier, or if we have some test-util class that duplicates some of the functionality you're using, i would consider that to be a worthy tradeoff for dropping the dependency. i would absolutely support planning to come back in a follow-up pr to build out support for testing scala code and then terraforming these tests to use the new support. or even delaying this pr until a test-support one is available.",1,0.554780125617981
177211622,4756,vvcephei,2018-03-26T19:46:08Z,"i think it's because we're presenting the `serde[java.lang.long]` as a `serde[scala.lang.long]`, but casting the serde won't automatically cast the parameters and returns of its methods. i'm surprised you don't get cast class exceptions trying to use the java long serde as a scala long serde. unless i'm wrong about what this is for...",0,0.801539421081543
177214912,4756,vvcephei,2018-03-26T19:58:11Z,"+1 on not including this method in the wrapper. the code that would use this library is not written yet, so it's better if deprecated methods are simply not available.",0,0.9682133197784424
177215699,4756,vvcephei,2018-03-26T20:00:27Z,i agree.,0,0.9386655688285828
177222153,4756,ijuma,2018-03-26T20:23:09Z,"there is no such thing as a `scala.long` at runtime, scala changed to use the same classes as java for boxing around the 2.8 timeframe if i remember correctly. previously there was a `richlong`, `richint`, etc. in any case, this seems like a variance issue, but i didn't look into it.",0,0.9656265377998352
177225591,4756,seglo,2018-03-26T20:35:21Z,"this seems to be a false positive. findbugs is reporting that `serializer` and `deserializer` should be defined as a different type name than what it's inheriting. iirc the consensus earlier is that we want type names the same as the base types they're wrapping (which includes traits and interfaces imo). i've updated the findbugs rule exclusion to be specific to the types generating the violation, rather than the entire `scalaserde` file.",0,0.9794425368309021
177227080,4756,seglo,2018-03-26T20:40:17Z,"i assume it was to disambiguate with `serdes.bytes`, but that's not a problem. i'll update it.",0,0.9875756502151489
177227812,4756,seglo,2018-03-26T20:42:47Z,i've renamed the type param to `va` to match the java dsl.,0,0.988576352596283
177228111,4756,seglo,2018-03-26T20:43:44Z,i've renamed the type param to `va` to match the java dsl. is that ok?,0,0.9881590008735657
177228492,4756,guozhangwang,2018-03-26T20:45:05Z,thanks for your thoughts. we do have plans to publish testing-util artifacts inside ak in the future. and in fact we have been doing so for kafka-streams module as a first step and going to do that for kafka-core and kafka-clients soon. in kafka-clients testing utils we are going to include some improved version of embeddedkafkacluster for users to easily write their integration tests that involve interacting with a mock a kafka cluster. so i'd suggest we stay with the uglier implementation with the existing embedded kafka cluster and not bring in the dependency.,1,0.9069098830223083
177230451,4756,guozhangwang,2018-03-26T20:51:18Z,"i see. i guess i was a bit misled by the name itself: i was thinking ""stateless"" is for the stateless operators in kafka streams dsl, and thinking the inclusion of topic name or not does not necessarily depend on whether the serde is used for stateful or stateless operations. your explanation makes sense now. maybe we can add some comments on top of `statelessserde` claiming that this serde class is used for serde where topic names does not affect the serde logic, i.e. topic name will be ignored. if users need some serde mechanism that does differentiate on topic names, please implement the other underlying `serde` interface.",0,0.6622669696807861
177231716,4756,guozhangwang,2018-03-26T20:55:24Z,it is discussed in [a link] i think the name `stateless` may be a tart misleading but i cannot come up with a better name yet.,0,0.5538133978843689
177232798,4756,guozhangwang,2018-03-26T20:59:16Z,"i'm a bit on the fence for introducing avro as ""the one"" serde in our demonstration examples rather than keeping kafka and avro separate, since there are many protobufs / etc fans in the community. how about adding avro examples in eco-system repos, e.g. in lightbend / confluent / etc's own examples repo they can add their own example? cc",0,0.827755868434906
177238405,4756,seglo,2018-03-26T21:19:47Z,"i agree it looks concerning, i'll need to check what other potential features this brings in, unfortunately there's no way to be more specific about just enabling sam type conversion afaik. we could remove this flag, but we would need to desugar all the places where conversions occur.",0,0.9567181468009949
177268099,4756,mjsax,2018-03-26T23:44:21Z,"maybe `simpleserde` as name ? ""stateless"" seems to be confusing.",0,0.6339439153671265
177268698,4756,mjsax,2018-03-26T23:47:33Z,+1 sounds reasonable to me.,0,0.8941138386726379
177289406,4756,debasishg,2018-03-27T02:19:29Z,- cool .. then we can remove the test `streamtotablejoinscalaintegrationtestimplicitserdeswithavro` and the dependencies from `build.gradle` .. ok ?,1,0.9833253622055054
177289806,4756,debasishg,2018-03-27T02:21:20Z,"for the time being, we can remove `split` from the scala api and rethink if / when it's implemented as a java api",0,0.9862026572227478
177290643,4756,debasishg,2018-03-27T02:28:37Z,in scala there's an implicit conversion between `scala.long` and `java.lang.long` but not between `serde[scala.long]` and `serde[java.lang.long]` - hence the cast. in fact picked this trick from [a link],0,0.9851346611976624
177296715,4756,debasishg,2018-03-27T03:19:43Z,"- i think i may be missing something here. we are allowing the user to pass in the `store` *and* `keyserde`. and we create the `materialized` out of the 2 with `long` as the value serde. however we were allowing the user to pass in the `keyserde` optionally and in case the user does not supply one we assumed it will be taken from the config. this is actually a remnant from the earlier thoughts where we thought passing serdes through config may be a good idea. however in the current context, we should not make `keyserde` optional. here's the suggestion for the changed api .. [code block] an alternative option could have been to allow the user to pass in the `materialized` instance itself (like we do in the `reduce` function). the problem with that alternative is that the java api expects `java.lang.long` as the value serde, while the scala api needs to take a `scala.long`. and there is no way we can convert a `materialized.as[k, scala.long, bytearraykeyvaluestore]` to `materialized.as[k, java.lang.long, bytearraykeyvaluestore]` without a cast. hence the divergence in the api signature between `count` and `reduce`. please share if u have any other thoughts.",0,0.9514269828796387
177297602,4756,debasishg,2018-03-27T03:24:58Z,"hi - regarding the above, we had a discussion on the 2 approaches on this thread only and the universal suggestion was to use the same name across scala and java apis. in fact in the initial version that we posted, we had different names (`kstream` / `kstreams`). the reasoning of using the same names is that the renaming of imports in the user code needs to be done only very occasionally when we mix usage of scala and java apis.",0,0.9850408434867859
177305370,4756,debasishg,2018-03-27T04:29:40Z,"here, the deprecation is on `punctuate`, which is part of the contract of `transformer`. how do we remove this ? we can *only* remove this when `punctuate` is removed from `transformer` ? or am i missing something ?",0,0.9801062941551208
177306580,4756,debasishg,2018-03-27T04:41:33Z,we don't need to provide implementation of `valuetransformer` here since the passed in `() => valuetransformer[a link] for sam type conversions in scala.,0,0.9892725944519043
177306659,4756,debasishg,2018-03-27T04:42:17Z,same logic as `valuetransformer` above.,0,0.9868131875991821
177320316,4756,debasishg,2018-03-27T06:34:09Z,thanks for your thoughts .. we will remove the dependency on `net.manub:scalatest-embedded-kafka-streams` and use `embeddedkafkacluster` instead.,1,0.9489136338233948
177420275,4756,seglo,2018-03-27T13:20:12Z,"there's no list of what's brought in with the experimental flag, unless you grep the compiler code. the purpose of the sam type conversion feature in 2.11 was only to get early feedback and only properly finished in 2.12. as its name suggests it's not meant to be used in production code. since kafka is still targeting 2.11 it makes sense to not include this flag to build a releasable artifact. i'll remove the flag and desugar the conversions.",0,0.9838498830795288
177438559,4756,vvcephei,2018-03-27T14:10:55Z,"thanks for the explanation, i missed that discussion. sorry to bring it back up! thanks! am i correct in thinking that only affects our code, and not our users' code? i.e., if they are using 2.12, they can pass in lambdas as arguments, right?",-1,0.9864211082458496
177440570,4756,seglo,2018-03-27T14:16:01Z,"yes, this change won't affect end users at all. if kafka drops scala 2.11 support then we can bring back the sam conversions as they're available without any ominous compiler flags.",0,0.9865474700927734
177441103,4756,vvcephei,2018-03-27T14:17:26Z,"huh! well, that explains it. i have seen the conversions of the raw types, and also suffered from type errors that `serde[scala.long]` != `serde[java.lang.long]`, so i just assumed that `scala.long` was a different class than `java.long`. thanks for the explanation, .",1,0.9743520617485046
177442727,4756,vvcephei,2018-03-27T14:21:33Z,"oh, right, i thought this was one of your scala replacement classes. what i have been doing for cases like this is throwing an `unsupportedoperationexception` in the body. it's not as good as not having the method, but it def. ensures it can't be used. and you don't have to maintain the code that's in the body.",0,0.9142541289329529
177449950,4756,vvcephei,2018-03-27T14:40:09Z,"that makes sense. my 2 cents: we're presenting the scala kgroupedstream basically *as* the java one, but not implementing the interface so that we can smooth over a couple of specific gaps. i think this is a good call, but it's also a huge risk for cognitive dissonance and developer confusion, since they will read the java version of the docs and try to use that knowledge in scala. therefore, it's important to be super disciplined about making sure the methods available are as close to the java interface as possible. clearly, moving serdes, etc., to implicit params is the kind of thing we *do* want to do. but i think that presenting `count(string,serde[k])` instead of `count(materialized[k, long, keyvaluestore[bytes, array[byte]]]` is too far off. i do agree that the method should take a scala type. apparently, it's perfectly fine to cast `serde[scala.long]` to `serde[java.long]`. does that same logic apply here? alternatively, we can actually convert the `materialized[java]` to a `materialized[scala]`.",1,0.6329205632209778
177457781,4756,debasishg,2018-03-27T15:00:05Z,.. sure we can do the following instead .. [code block] wdyt ?,0,0.9808346629142761
177531590,4756,vvcephei,2018-03-27T18:44:36Z,"ok, i'm already a little nervous about the cast in one direction, so this feels super gross, but would this work? [code block] please understand i'm wincing as i type this.",-1,0.9812415838241577
177532059,4756,mjsax,2018-03-27T18:46:17Z,"well, we allowing to pass in a store ""name"" (string) but not a store. note, that `materialized` allows to replace default rocksdb with an in-memory story, disable change-capture-logging or even use a custom store implementation.",0,0.9893519282341003
177532408,4756,guozhangwang,2018-03-27T18:47:27Z,sounds good.,1,0.9202015399932861
177532680,4756,guozhangwang,2018-03-27T18:48:20Z,sounds good.,1,0.9202015399932861
177533039,4756,guozhangwang,2018-03-27T18:49:18Z,that sounds better.,0,0.9165825247764587
177534627,4756,debasishg,2018-03-27T18:54:13Z,how about the api that i suggested above ? it takes materialized much like the java api though we need a cast. - in my implementation we have 1 cast and the other map for the long conversion in ktable.,0,0.979582667350769
177537597,4756,mjsax,2018-03-27T19:04:24Z,i understand that you cannot change the java `transformer` interface and must implement the deprecated method when calling `new transformer` -- what i was wondering is about `scala.transformer` interface -- should we add one and remove `punctuate` from it?,0,0.9811490774154663
177540520,4756,vvcephei,2018-03-27T19:13:02Z,"sorry, i should have acked your implementation. i was actually proposing an evolution of it. it just seems a bit unfortunate to have to add a real function invocation to the topology in order to do the cast back to `scala.long`. the version i proposed just does a cast back out without adding anything new to the topology. does that make sense? at the risk of sounding like an idiot, if it's fine to do the cast on the way in, then it should be fine again on the way out, right?",-1,0.9894012808799744
177542082,4756,vvcephei,2018-03-27T19:17:17Z,"fwiw, i think adding a new scala interface just to remove a method that we plan to remove from the java interface is not necessary. better just to implement it and move on. also, it would be a bit trickier to swap in a scala replacement for `transformer` than for the top-level dsl classes, since implementations of the java `transformer` won't implement the scala `transfomer`, so you wouldn't be able to plug them in via the scala dsl wrapper. but there's otherwise no reason this shouldn't work.",0,0.9214175939559937
177554002,4756,mjsax,2018-03-27T20:01:50Z,"ack. was just an idea. i don't really speak scala (yet) -- this is an exercise to learn something about it... if we need to have it, i vote to throw an exception to forces users to use the new api.",0,0.7429003715515137
177564717,4756,mjsax,2018-03-27T20:39:26Z,"this and all other classes are public api. thus, we should improve the javadocs for those classes and also add javadocs for all methods. i guess we can c&p from existing java classes.",0,0.981044352054596
177636021,4756,debasishg,2018-03-28T04:25:29Z,- cast is a runtime operation and my philosophy is to minimize its use. and `scala.predef` indeed uses `long2long` to do such conversions. hence i would like to prefer using proper functions when available instead of the cast.,0,0.9273144602775574
177638616,4756,debasishg,2018-03-28T04:56:34Z,"ok, will remove `split` from `kstream` for now.",0,0.9888870120048523
177660176,4756,debasishg,2018-03-28T07:32:08Z,renamed to `simplescalaserde` ..,0,0.9865521788597107
177660317,4756,debasishg,2018-03-28T07:32:45Z,removed!,0,0.9279177188873291
177662427,4756,debasishg,2018-03-28T07:42:53Z,- looking for suggestions. should we copy/paste javadoc from java classes or use `` annotation ? the problem with copy is maintenance - when one changes someone needs to be careful enough to change the other.,0,0.9516289234161377
177685679,4756,debasishg,2018-03-28T09:12:55Z,- removed all dependencies on `net.manub:scalatest-embedded-kafka` and `net.manub:scalatest-embedded-kafka-streams`. now using `embeddedkafkacluster` instead for tests. also removed the test that used avro - hence dependency on `avros` eliminated.,0,0.9874332547187805
177793180,4756,deanwampler,2018-03-28T15:34:39Z,"a little more detail; what this import is saying is ""import these items, but give them an alias, then import everything else without an alias"".",0,0.9882307052612305
177826543,4756,guozhangwang,2018-03-28T17:22:58Z,thanks !,1,0.9308210611343384
177950361,4756,mjsax,2018-03-29T04:19:27Z,good question. not sure. i agree that maintaining javadocs twice is a hassle and error prone. but might be annoying for user if it's only linked on the other hand. would be good to hear what others thing. \cc,1,0.8122463822364807
178029830,4756,seglo,2018-03-29T11:41:02Z,"adding javadocs to all the public api methods in the pr is the same amount of work any way we do it. from an end user perspective i agree it would be nice to have the same (or slightly tweaked, as necessary) javadocs for all public api methods, plus a `` or `` tag to the corresponding java api method. it will be a small burden to maintain it going forward so i defer to the ak committers to make the call on the format.",0,0.9594849348068237
178136346,4756,guozhangwang,2018-03-29T18:01:06Z,"i'd vote for using `` and `` to avoid maintaining two copies, because we have some public classes following this pattern in the repo (like [a link] and from the past i find most people would not remember or bother to update two places than one. i think the web docs (in `docs/streams`) needs to be updated as well, especially in the `upgrade-guide.html` page, as well as the `streams-api` page.",0,0.9687367081642151
178136538,4756,guozhangwang,2018-03-29T18:01:48Z,"for `streams-api` page above, i meant [a link]",0,0.9839866161346436
178139790,4756,ijuma,2018-03-29T18:13:51Z,"some thoughts: - i think the consumer and kafkaconsumer pattern is bad. the documentation should have been on `consumer` instead. the `adminclient` follows the latter pattern. - i think it's a poor user experience to ask users to read the docs in the java class. my recommendation would be to at least include a short description in the scala docs along with a link to the relevant java documentation. the short description is less likely to change and it helps users make progress without having to jump to the java code all the time. however, for more detailed information (which is more likely to change), they can check the java code.",-1,0.9773504734039307
178448558,4756,mjsax,2018-04-01T05:20:06Z,"i tend to agree with comment about `kafkaconsumer`/`consumer` pattern -- it's quite annoying to not get the javadocs directly. thus, even if it's a burden it seems to be worth to maintain two copies.",-1,0.9616504907608032
178450057,4756,debasishg,2018-04-01T07:16:38Z,- i have started writing the scaladocs in the commit [a link] .. pls review if it's following the correct pattern,0,0.9785664081573486
178976326,4756,guozhangwang,2018-04-03T22:07:53Z,nit: period at the end of the sentence.,0,0.9765511751174927
178976444,4756,guozhangwang,2018-04-03T22:08:35Z,maybe mention again which artifact to include in order to import this package.,0,0.983593761920929
178976955,4756,guozhangwang,2018-04-03T22:11:09Z,we do not need indentation in the code block; the following code blocks are formatted correctly.,0,0.9879752993583679
178977137,4756,guozhangwang,2018-04-03T22:12:07Z,this is not introduced in this pr: duplicated `provides`.,0,0.9878575801849365
179201680,4756,seglo,2018-04-04T16:20:47Z,"i fixed the typos in this line, but i'm not sure what you mean by it not being introduced in this pr. this line is to indicate the presence of the kafka streams dsl for scala library.",0,0.928019106388092
179202074,4756,seglo,2018-04-04T16:22:13Z,i copied the formatting from the streams main page which indented the wordcount examples: [a link],0,0.9876178503036499
179202109,4756,seglo,2018-04-04T16:22:22Z,:+1:,0,0.7570654153823853
179202130,4756,seglo,2018-04-04T16:22:28Z,:+1:,0,0.7570654153823853
179202465,4756,seglo,2018-04-04T16:23:36Z,i removed the initial indentation for this example on this page to make it consistent with the others.,0,0.9847588539123535
179268477,4756,guozhangwang,2018-04-04T20:15:02Z,"i meant the duplicated `provides` exist before this pr, so it is not a regression introduced from this pr.",0,0.9860379099845886
181648477,4756,mjsax,2018-04-16T07:54:15Z,"""is available here"" is bad phrasing. `here` -> `in the developer guide`",-1,0.9570642709732056
181649571,4756,mjsax,2018-04-16T07:58:35Z,`to include it your maven` -- sounds weird,-1,0.9857001304626465
181649928,4756,mjsax,2018-04-16T08:00:05Z,i am wondering if this is correct? should the scala version not be included here?,0,0.9496042132377625
181650115,4756,mjsax,2018-04-16T08:00:56Z,"don't we need the scala version, here?",0,0.9887852668762207
181650350,4756,mjsax,2018-04-16T08:01:54Z,don't we need the scala version here?,0,0.9881568551063538
181650623,4756,mjsax,2018-04-16T08:03:07Z,typo: is a wrapper around `stream[s]builder`,0,0.9875475168228149
181650718,4756,mjsax,2018-04-16T08:03:31Z,nit: `wordcount` ?,0,0.9857860207557678
181650779,4756,mjsax,2018-04-16T08:03:47Z,typo: `stream[s]builder`,0,0.987293004989624
181652632,4756,mjsax,2018-04-16T08:11:33Z,scala version missing?,0,0.9732905030250549
181652730,4756,mjsax,2018-04-16T08:12:00Z,scala version missing?,0,0.9732905030250549
181652863,4756,mjsax,2018-04-16T08:12:40Z,"i think, we should not have indention here for better rendering",0,0.9634857773780823
181653308,4756,mjsax,2018-04-16T08:14:23Z,nit: should be added such the alphabetical order is maintained.,0,0.9840695261955261
181653441,4756,mjsax,2018-04-16T08:14:56Z,can't we merge this with the one from above?,0,0.9813020825386047
181656561,4756,mjsax,2018-04-16T08:27:10Z,this seems to be rather short compared to `stream` and `table` docs from above.,0,0.9366998672485352
181656843,4756,mjsax,2018-04-16T08:28:06Z,"maybe we can add, that a store must still be ""connected"" to a `processor`, `transformer`, or `valuetransformer` before it can be used?",0,0.989039421081543
181657170,4756,mjsax,2018-04-16T08:29:17Z,"maybe add, that global stores do not be added to `processor`, `transformer`, or `valuetransformer` (in contrast to regular stores).",0,0.9888038039207458
181658989,4756,mjsax,2018-04-16T08:36:36Z,"maybe add a sentence, that stores must be added via `addstatestore` or `addglobalstore` before they can be connected to the `transformer` ?",0,0.9882688522338867
181659066,4756,mjsax,2018-04-16T08:36:53Z,as above?,0,0.9795584082603455
181659114,4756,mjsax,2018-04-16T08:37:05Z,as above?,0,0.9795584082603455
181659257,4756,mjsax,2018-04-16T08:37:38Z,as above?,0,0.9795584082603455
181660310,4756,mjsax,2018-04-16T08:41:42Z,"maybe explain, that there is not ordering guarantee for the merged result stream for records of different input streams? relative order is only preserved for record of the same input stream?",0,0.9822505116462708
181662152,4756,mjsax,2018-04-16T08:48:00Z,markup seems weird? why do you have javadoc comment markup? would a single `#` not be sufficient?,-1,0.9624370336532593
181904753,4756,guozhangwang,2018-04-16T22:31:18Z,"for different scala version compiled packages, their project name is actually the same. and here people only need to specify the version of the artifact itself, which will be the kafka version. users can, indeed, build kafka-streams-scala with different scala versions other than the default one, but that is to be done before they include it in the dependency. for maven, it will always be whatever is uploaded to maven central.",0,0.9845709204673767
181909480,4756,guozhangwang,2018-04-16T22:57:47Z,"cc -hamill we are adding a few new sections in web docs regarding the streams scala api, which may be affecting [a link]",0,0.9872701168060303
181909865,4756,guozhangwang,2018-04-16T23:00:09Z,"i think the scala version cannot be changed when specifying the `kafka-streams-scala` artifact, as it is encapsulated when that artifact is compiled already. please correct me if i'm wrong.",0,0.9521142244338989
181910307,4756,guozhangwang,2018-04-16T23:02:43Z,i think we do not need avro4sversion any more? same as line 86 here.,0,0.9884604215621948
181910344,4756,guozhangwang,2018-04-16T23:02:56Z,this is not needed.,0,0.9661186337471008
181910430,4756,guozhangwang,2018-04-16T23:03:34Z,do we still need `scalatestembeddedkafkaversion`?,0,0.9882756471633911
181910448,4756,guozhangwang,2018-04-16T23:03:40Z,+1,0,0.696722686290741
181910836,4756,guozhangwang,2018-04-16T23:06:10Z,should we add `copyright 2018 the apache software foundation.` as well?,0,0.9855894446372986
181911680,4756,guozhangwang,2018-04-16T23:11:08Z,"ping on this comment again, could you elaborate if my concern is valid or not?",0,0.963954746723175
181911985,4756,guozhangwang,2018-04-16T23:12:59Z,could we remove this line then?,0,0.9865918755531311
181916063,4756,guozhangwang,2018-04-16T23:39:02Z,"nit: move `import org.junit.assert._` after line 22, ditto below elsewhere.",0,0.9832972288131714
181916302,4756,guozhangwang,2018-04-16T23:40:40Z,"nit: replace the `_1/2/3` suffix with some more meaningful name? e.g. `simple`, `aggregate`, `join`?",0,0.9887187480926514
181972834,4756,debasishg,2018-04-17T07:18:17Z,done ..,0,0.9689553380012512
181973173,4756,debasishg,2018-04-17T07:19:47Z,done ..,0,0.9689553380012512
181974944,4756,debasishg,2018-04-17T07:28:02Z,enriched ..,0,0.9678457975387573
181975406,4756,debasishg,2018-04-17T07:30:03Z,done ..,0,0.9689553380012512
181975843,4756,debasishg,2018-04-17T07:31:59Z,done ..,0,0.9689553380012512
181978439,4756,debasishg,2018-04-17T07:43:03Z,done ..,0,0.9689553380012512
181978475,4756,debasishg,2018-04-17T07:43:11Z,done ..,0,0.9689553380012512
181978790,4756,debasishg,2018-04-17T07:44:41Z,done ..,0,0.9689553380012512
181979232,4756,debasishg,2018-04-17T07:46:16Z,done ..,0,0.9689553380012512
181979824,4756,debasishg,2018-04-17T07:48:50Z,done ..,0,0.9689553380012512
181980358,4756,debasishg,2018-04-17T07:50:55Z,done ..,0,0.9689553380012512
181980630,4756,debasishg,2018-04-17T07:52:07Z,removed ..,0,0.8029831051826477
181981140,4756,debasishg,2018-04-17T07:54:09Z,removed ..,0,0.8029831051826477
181982186,4756,debasishg,2018-04-17T07:57:46Z,done ..,0,0.9689553380012512
181984159,4756,debasishg,2018-04-17T08:02:37Z,done ..,0,0.9689553380012512
181985862,4756,debasishg,2018-04-17T08:09:17Z,"i am not sure i understand your concern. the only purpose of this implicit is to allow an implicit conversion from `tuple2` to `keyvalue(key, value)`. just a helper which we found useful in many cases for developing applications or tests.",0,0.8221577405929565
181986497,4756,debasishg,2018-04-17T08:11:46Z,removed the duplicate entry ..,0,0.954858660697937
182133565,4756,guozhangwang,2018-04-17T15:59:15Z,"here is my concern: in `map` and `flatmap`, we call [code block] does that mean that for each pair of k, v pair parameters, we would first construct a `tuple2` object of this case class, and then apply the mapper, and then create a new `keyvalue` from the result `tuple2` object? if that is true, then we are creating a short-lived object for each record processed in `map`. i'm not sure if it will have a pressure on the gc.",0,0.7721256017684937
182333791,4756,debasishg,2018-04-18T07:37:56Z,- you are correct that with the current implementation there will be `tuple2`s created. but it's difficult to say if there will be gc pressure. for that we need to analyze runtime behaviors and see what the jit does. there's of course a way we can fall back to the implementation which does less allocation .. [code block] we did run some tests in bulk to check the diff in performance between the 2 versions. couldn't find much of a difference though.,0,0.9484084248542786
182418338,4756,seglo,2018-04-18T13:05:49Z,:+1:,0,0.7570654153823853
182418770,4756,seglo,2018-04-18T13:07:07Z,:+1:,0,0.7570654153823853
182424831,4756,ijuma,2018-04-18T13:25:51Z,not sure what you mean . the scala version is usually part of the artifact name.,0,0.9437008500099182
182448107,4756,seglo,2018-04-18T14:30:39Z,"i'm not very familiar with gradle, but it appears to not support cross building jars in the same manner as sbt. the build needs to be run for each scala version you want a jar for, but the output won't encode the version into the filename. i think what we need to do is add a task to the gradle file, or some other build related packaging script, to pluck the generated `kafka-streams-scala` file, rename it to include the scala version, and then publish it to maven central. ex) the built outputs this when specifying a 2.12 `scala_version` (`./gradlew -pscalaversion=2.12 jar`) [code block] when a release artifact is published we'll publish a file: `kafka-streams-scala_2.12-1.2.0.jar` with the scala major version encoded into the artifact name. a maven user would reference the artifact with: [code block] please let me know if i'm missing something here about the kafka build system. on a related note i found a gradle build plugin that handles cross building projects and referencing scala dependencies in a sbt style here: [a link]",0,0.9022238850593567
182454071,4756,ijuma,2018-04-18T14:45:42Z,"we already so the right thing for core jars. we just need to follow the same approach. and yes, the scala version needs to be encoded in the artifact id. not sure what was trying to say, but doesn't seem correct to me.",0,0.9226040840148926
182461208,4756,seglo,2018-04-18T15:04:21Z,"ok, is the approach you refer to in the core project of the `build.gradle`? i'll take a closer look. wrt the docs is correct that we should update the maven dependency examples to include the scala version.",0,0.987209677696228
182503294,4756,guozhangwang,2018-04-18T17:13:46Z,"what i was saying is that when we build the artifact we already chose which scala version to use compiling the jar and made the scala version as part of the artifact name, so users do not need to specify the scala version in declaring the dependency, but just: [code block]",0,0.9773690700531006
182704470,4756,seglo,2018-04-19T10:40:56Z,i'll correct this to include the scala version (2.11) across all the maven `pom.xml` references.,0,0.9888794422149658
182704820,4756,seglo,2018-04-19T10:42:14Z,we don't need to specify the scala version here. the `%%` operator in sbt will automatically determine the right artifact based on the running scala version.,0,0.9885044693946838
182705719,4756,seglo,2018-04-19T10:46:15Z,:+1:,0,0.7570654153823853
182705959,4756,seglo,2018-04-19T10:47:21Z,:+1:,0,0.7570654153823853
182706259,4756,seglo,2018-04-19T10:48:44Z,:+1:,0,0.7570654153823853
182706791,4756,seglo,2018-04-19T10:51:22Z,:+1:,0,0.7570654153823853
182707211,4756,seglo,2018-04-19T10:53:13Z,"i followed the convention of preceding java examples which also have indentation, but i'll remove the indentation for the scala example.",0,0.9889652729034424
182711723,4756,seglo,2018-04-19T11:13:11Z,:+1:,0,0.7570654153823853
182742751,4756,mjsax,2018-04-19T13:21:46Z,that's what i meant by my comment -- sorry for expressing myself unclear.,-1,0.9770776033401489
184075333,4756,miguno,2018-04-25T14:16:17Z,"this doesn't look right to me. the latest `trunk` build of kafka only generates the following artifact(s): [code block] the maven coordinates for the artifacts above have an `artifactid` of `kafka-streams-scala`, not `kafka-streams-scala_2.11`.",0,0.8809592723846436
184082552,4756,miguno,2018-04-25T14:34:24Z,"this example code doesn't compile, because e.g. the import for `streamsbuilder` is missing (from package `org.apache.kafka.streams.scala`). i would probably double-check the other examples that are shown in the documentation, too.",0,0.9863446950912476
184119748,4756,guozhangwang,2018-04-25T16:11:54Z,"looking at the `build.gradle` again, today we only build `kafka-streams-scala` with the default scala versions defined in `dependencies.gradle`, 2.11.12. if we want to publish multiple artifacts with different scala versions we should follow the `core` project pattern, i.e. sth. like: [code block] we could also consider just building one artifact with the default scala version, in this case we would remove the suffix here and add the explanation which scala version users should be expected to use.",0,0.9842812418937683
184124327,4756,seglo,2018-04-25T16:25:25Z,"i recommend releasing versions of `kafka-streams-scala` for both major versions of scala currently supported by kafka. we should copy build and release conventions used by kafka core so that both artifacts are produced. i'm not very familiar with gradle or the kafka release process, so i wasn't sure how far to go with this, but now that that gradle snippet is right in front of me it's clear that the same should be done for this library. i believe recommended this earlier, but i didn't make the appropriate update before the merge. ~~ how are multiple versions of kafka core published at part of the release process? is the build script called twice with appropriate `scalaversion` parameter?~~ nevermind, i see how it's done now. only making the library available to scala 2.11 will leave behind a lot of users that are already on 2.12, which has been out for several years now. cross building (building an artifact per version of scala) will also make it a trivial matter to support future of versions of scala in the release process.",0,0.8220609426498413
184148190,4756,miguno,2018-04-25T17:42:03Z,"i agree that we should generate artifacts for both 2.11 and 2.12, like we do for kafka core.",0,0.9675416946411133
184153041,4756,guozhangwang,2018-04-25T17:56:24Z,sounds good. could you submit a follow-up pr to modify `build.gradle` for publishing multiple artifacts for different scala versions of `kafka-streams-scala` then?,1,0.957767128944397
184153302,4756,guozhangwang,2018-04-25T17:57:11Z,could you take a look?,0,0.98567134141922
184193473,4756,seglo,2018-04-25T20:20:20Z,"yes. i'm travelling atm, but i'll make a new pr in the next few days.",0,0.9441167116165161
184193680,4756,seglo,2018-04-25T20:21:11Z,yes. i'll test the snippets in the build pr.,0,0.9840012788772583
186375027,4756,miguno,2018-05-07T09:37:32Z,"the single parameter for `transform()` is a `transformer`, not a `transformersupplier`. the variable needs renaming and the javadocs updating.",0,0.9889190793037415
186387729,4756,miguno,2018-05-07T10:44:02Z,i raised [a link] for this.,0,0.9833565950393677
65546724,1446,enothereska,2016-06-02T14:13:40Z,"these name changes are not strictly part of this fix, i'm wondering if we can open a minor pr for these while having this pr focus on streams only (to avoid confusion).",0,0.963170051574707
65564787,1446,aartigupta,2016-06-02T15:42:11Z,"agreed, theses were not intended for this fix, they managed to sneak their way in. my bad, fixed it now",-1,0.9884037375450134
65923002,1446,jklukas,2016-06-06T16:32:36Z,the line break here seems unnecessary.,0,0.6606476306915283
65923529,1446,jklukas,2016-06-06T16:36:02Z,"since there are now two implementations of `streamsmetrics`, is it confusing to have them both named `streamsmetricsimpl`? this could be `threadstreamsmetrics` and the other could be `processornodestreamsmetrics`.",0,0.9823353886604309
65947627,1446,enothereska,2016-06-06T18:56:29Z,do we still need the subsequent variable?,0,0.9869203567504883
65948134,1446,enothereska,2016-06-06T18:59:27Z,i wonder if there is a way to use the other sensor calls for the latency sensor too. or will this one always remain special?,0,0.8309311270713806
65948578,1446,enothereska,2016-06-06T19:02:06Z,"would it be better for `metrics` to be passed in the `processornode` constructor instead? for example, like it's done in the `streamthread` constructor.",0,0.9887872338294983
65948746,1446,enothereska,2016-06-06T19:03:11Z,same comment as above about passing in constructor instead.,0,0.986407995223999
65948820,1446,enothereska,2016-06-06T19:03:36Z,same comment as above about passing in constructor instead.,0,0.986407995223999
65951530,1446,enothereska,2016-06-06T19:20:32Z,is it correct to do the commit sensor recording for task.node() or even here? why not do it in `streamtask's` `commit`?,0,0.9875370860099792
65951650,1446,enothereska,2016-06-06T19:21:19Z,is it correct to do the punctuation sensor recording for task.node() or even here? why not do it in `streamtask's` `punctuate`?,0,0.9867265224456787
66099715,1446,aartigupta,2016-06-07T15:58:00Z,"there seem to be two ways to make this happen a. for the processornode to accept metrics in the constructor, the processornodefactory would have to have a pointer to metrics, which would imply that addprocessor in topologybuilder would need to have that, and since metrics is internal to kstreams, users of topologybuilder do not have a pointer to metrics. alternatively b. the build method of processornodefactory can take metrics in addition to applicationid and then a processornode can be constructed by passing metrics in the processornode constructor as opposed to piggy backing on the streamsmetrics which the current review request shows (which is not uniform with streamthread...) b, would look like this [code block]",0,0.9782335758209229
66102111,1446,aartigupta,2016-06-07T16:11:35Z,"you are correct, previously this made sense since we did not expose adding arbitrary sensors onto the base metrics registry, but now that we do, having this in the interface stands out as odd that said there seems to be a lot of boiler plate code around tags, parsing and logging. // first add the global operation metrics if not yet, with the global tags only sensor parent = metrics.sensor(scopename + ""-"" + operationname); addlatencymetrics(metricgroupname, parent, ""all"", operationname, this.metrictags); [code block] what do these tags buy us ? (it is not clear :) ) if we can get rid of the tags, then does it make sense to have an a base implementation of the streamsmetrics interface, because with the exception of the actual sensors contained in them, the two implementations start to look very similar protected class processornodestreamsmetrics implements streamsmetrics .... protected class threadstreamsmetrics implements streamsmetrics ....",0,0.9813847541809082
66291188,1446,aartigupta,2016-06-08T16:35:15Z,"you are right, this was not the right place. streamtask's commit is the right place. fixed locally and working on a unit test and integration test to ""count down"" commit and punctuate metrics to ensure correctness.",0,0.9267498850822449
91086491,1446,ijuma,2016-12-06T14:23:19Z,should this be `recordlevel`?,0,0.988031268119812
91086702,1446,ijuma,2016-12-06T14:24:24Z,"we don't need the `sensor` prefix in the name. also, are these the only two levels we care about?",0,0.9806613922119141
91231975,1446,aartiguptaa,2016-12-07T06:08:57Z,"info would map to the level we use for normal production runs, and debug could be used to optimize the job in the development or instrumentation/debugging phase. can't think of any more use cases, maybe trace could be a finer level, but personally have never found that useful.",0,0.9737900495529175
91587971,1446,guozhangwang,2016-12-08T19:25:50Z,"nit: new line between functions, ditto below.",0,0.9797717928886414
91588145,1446,guozhangwang,2016-12-08T19:26:45Z,"also we need to add the javadoc for those newly added functions, especially explain the `recordlevel`.",0,0.9887280464172363
91588780,1446,guozhangwang,2016-12-08T19:29:50Z,"we can reuse `recordlevel.sensor_info_str` etc here, to avoid split places of those global constant strings.",0,0.9888251423835754
91589025,1446,guozhangwang,2016-12-08T19:31:07Z,could this result in npe? may be we can directly throw an illegalargumentexception here.,0,0.9806461334228516
91589076,1446,guozhangwang,2016-12-08T19:31:25Z,"how about returning ""unknown"" or ""illegal_level"" than null?",0,0.9639301896095276
91590844,1446,guozhangwang,2016-12-08T19:39:29Z,"this is a meta comment: in additional to skip `record`, we can probably go further to even avoid registering the sensor at all in the reporter. its benefits are: 1. the reporter will not show these metrics at all (i.e. they will not display in the monitoring ui, for example), whereas today the reporter will still show these metrics but the value is always the initialized value (most likely 0). 2. we can further reduce the overhead of function calls as well as the registry space; i'm not sure by how much though. admittedly this will require a larger change on `o.a.k.common.metrics`. what do you think ?",0,0.9190223217010498
91591063,1446,guozhangwang,2016-12-08T19:40:45Z,ditto above.,0,0.9270309805870056
91591235,1446,guozhangwang,2016-12-08T19:41:40Z,is this really part of this pr?,0,0.972942590713501
91592681,1446,guozhangwang,2016-12-08T19:48:09Z,"won't time be always null here, since it is never initialized?",0,0.9747811555862427
91594176,1446,guozhangwang,2016-12-08T19:55:40Z,"`streams-processor-node-metrics` to be consistent with other group names, and only include the node name in the tags as `put(""processor-node-id"", name);` (not sure why you added a ""-"" before the name?).",0,0.9873557686805725
91594356,1446,guozhangwang,2016-12-08T19:56:39Z,"nit: ""processor-node"" to be more clear with other scope, for example ""producer-metrics"" also have a per-node sensor level, where `node` there means the destination brokers.",0,0.9889206886291504
91595483,1446,guozhangwang,2016-12-08T20:02:31Z,"this is not introduced in this patch, but we could fix it together: in line 1133 below [code block] we'd better change it to [code block]",0,0.9823927879333496
91596211,1446,guozhangwang,2016-12-08T20:06:29Z,"again, to be consistent the sensor name better be the form of `(sensornameprefix + "".node-forward-time""): to add a `.` after the prefix, and we do not need the `name` as the suffix since it is already used in tags.",0,0.9883522391319275
91596966,1446,guozhangwang,2016-12-08T20:10:50Z,"the explanation does not sound right to me. i think it is ""the average per-second number of records processed by this processor"". also maybe we can rename the variable name to `nodethroughputsensor` to be more meaningful?",-1,0.595344603061676
91596999,1446,guozhangwang,2016-12-08T20:11:03Z,ditto for other sensor names.,0,0.9756596088409424
91597224,1446,guozhangwang,2016-12-08T20:12:24Z,seems like the explanation text are not updated after copying :p,1,0.6890230178833008
91597427,1446,guozhangwang,2016-12-08T20:13:33Z,"is the creation and deconstruction rate really useful? i feel the creation and deconstruction latency is more useful, since for rate it is mostly 0 unless there is a rebalance.",0,0.9762858152389526
91597796,1446,guozhangwang,2016-12-08T20:15:57Z,"also we do not need the prefix in metric name, but only in sensor name.",0,0.9877387285232544
91598240,1446,guozhangwang,2016-12-08T20:18:23Z,"and following that comment, the sensor name can be changed to `(sensornameprefix + "".process-throughput"")`, and the metrics name can be changed to `""record-process-rate""`.",0,0.9877462387084961
91598693,1446,guozhangwang,2016-12-08T20:21:13Z,"i think this is not a per-node sensor, but rather a per-task sensor right? shall we create a `taskmetrics` class accordingly for this layer?",0,0.9863596558570862
91598975,1446,guozhangwang,2016-12-08T20:22:59Z,"by layer i mean three layers: thread, task, node, and for task i think just one sensor ""commit"" is good enough, for punctuating the node-level metrics should be sufficient to cover.",0,0.9820742011070251
91599246,1446,guozhangwang,2016-12-08T20:24:37Z,why we want to pass in these as parameters instead of computing them internally? it seems `streamsmetricsimpl` is still only used once.,0,0.9859552979469299
91599430,1446,guozhangwang,2016-12-08T20:25:45Z,why we do not want to use `computelatency` any more?,0,0.9765931367874146
91668435,1446,aartiguptaa,2016-12-09T07:13:36Z,"removed it for now, don't remember why and when this was added.",0,0.913824200630188
91676685,1446,aartiguptaa,2016-12-09T08:42:53Z,"done, that makes it consistent. feeling better about it after that refactor.",0,0.6149107217788696
91679111,1446,aartiguptaa,2016-12-09T09:02:50Z,fixed the variable name to streamsmetrics (was sensors) streamsmetricsimpl is used 12 times. also fixed the computation,0,0.9880425930023193
91680753,1446,dguy,2016-12-09T09:16:06Z,why protected?,0,0.9030063152313232
91685809,1446,dguy,2016-12-09T09:49:32Z,why not record this inside `init`? it seems wrong to expose a field of `processornode`,0,0.9260883331298828
91700552,1446,enothereska,2016-12-09T11:25:12Z,"unfortunately 2 different tasks on the same thread can register the same two metrics and we'll get an exception in the thread library (current test fails because of this). so the prefix is not sufficient just for the sensor, but is also needed for the metric.",0,0.8344361782073975
91821831,1446,guozhangwang,2016-12-10T00:43:02Z,"that's right, but shouldn't the `sensornameprefix` contains that? currently it only contains the taskid but i think it should include both since each task can have its own copy of the topology. as for the group name, it is used for grouping metrics that may come from different classes even (see producer's `sender` and `selector` classes), so it should not include the node id, but rather just ""streams-processor-node-metrics"".",0,0.9863986372947693
91821954,1446,guozhangwang,2016-12-10T00:45:08Z,"this is at the very critical path of streams, called millions of times per sec, so calling `time.nanoseconds()` on each call is really expensive if `debug` level is used.",0,0.8695042133331299
91822004,1446,guozhangwang,2016-12-10T00:45:45Z,+1.,0,0.8624979853630066
91822140,1446,guozhangwang,2016-12-10T00:47:38Z,do we still need to keep this variable as it is now in the taskmetrics already?,0,0.9846255779266357
91922123,1446,enothereska,2016-12-12T10:40:57Z,done.,0,0.9759407639503479
91923060,1446,enothereska,2016-12-12T10:46:48Z,done.,0,0.9759407639503479
91923083,1446,enothereska,2016-12-12T10:46:56Z,done.,0,0.9759407639503479
91924605,1446,enothereska,2016-12-12T10:56:27Z,i'm not sure i understand your comment. `sensornameprefix` contains the task id. we use that for both sensor and metric name. with your last comment you seem to be saying the same we're saying. unless i misunderstood it. so as action item i'm just re-adding `sensornameprefix` to the metric name? (i can probably rename `sensornameprefix` to just `prefix` since it's used for sensor and metric). anything else? thanks.,1,0.6457766890525818
91926667,1446,enothereska,2016-12-12T11:10:52Z,fixed.,0,0.9810503125190735
91927862,1446,enothereska,2016-12-12T11:19:14Z,actually i still need protected because source and sink node have to use this field.,0,0.9834486842155457
92004035,1446,dguy,2016-12-12T18:07:12Z,can this be private now?,0,0.9882070422172546
92006773,1446,dguy,2016-12-12T18:21:24Z,"in this method and `punctuate` the blocks of code are largely the same. is this pattern going to be common? if it is just in this class, then i'd probably create a method in here that accepts a `runnable` and have `process` and `punctuate` delegate to it, i.e., [code block]",0,0.9845514893531799
92021599,1446,enothereska,2016-12-12T19:31:49Z,annoyingly sourcenode uses it.,-1,0.9823256134986877
92027755,1446,guozhangwang,2016-12-12T20:01:12Z,"my suggestion is to remove the suffix of `name`, which is the processor name in sensor, since it is already included in the tags. take the `jmxreporter` as an example, it generates the mbean for streams as: [code block] where `kafka-streams` is the prefix passed in `kafkastreams`, and `streams-processor-node-metrics` is the pre-defined `metricgrpname `. you can see here that the processor name suffix in attribute names are redundant, and more generally for any reporters implementations, metrics will be grouped by ""group name"" and ""tags"".",0,0.9801610112190247
92028572,1446,guozhangwang,2016-12-12T20:05:35Z,"tags are not used at all, actually do they need to be added? see my previous comment.",0,0.9857168197631836
92028877,1446,guozhangwang,2016-12-12T20:07:04Z,tags are not used here.,0,0.9572919011116028
92029084,1446,guozhangwang,2016-12-12T20:08:02Z,"this additional tag pair `""processor-node-id"" -> name` is redundant since it is already added in line 168.",0,0.9832333922386169
92029769,1446,guozhangwang,2016-12-12T20:11:32Z,"i left a follow-up comment about not needing to include `name` in the prefix anymore, let me know what do you think.",0,0.986525297164917
92033622,1446,guozhangwang,2016-12-12T20:33:02Z,"one more meta comment about `scopename`, `entityname` and `operationname`: in latency sensors they are managed as a two-layer metrics with the top-level metrics as: 1. `prefix.scopename-operationname`; which is the parent of all: 2. `prefix.scopename-entityname-operationname`; which means that whenever any of the children get updated, the parent also gets update. so for state store operations. `scopenames` are `in-memory-state`, `rocksdb-state` etc, and `entitynames` are specific store names, and `operationname` are `put`, `get` etc. in addition, the `scopename` is also used in the group name, so you can think of groupnames as `streams-in-memory-state-metrics` `streams-rocksdb-state-metrics` `streams-processor-node-metrics` `streams-task-metrics` `streams-metrics` /* this is actually per-thread metrics */ etc where scope is `processor-node`, `task`, etc. in your implementation, the `scopename` is removed from the sensor name, which i think is a good fix as it would redundant since it is already in the group name. however, the parental hierarchy is not encoded in the scopename / entityname / operationname in this function, and i'm wondering if it still makes sense to still capture this hierarchy in these names while still letting users specify ""additional"" parents in the last parameters?",0,0.984959065914154
92224454,1446,enothereska,2016-12-13T17:42:54Z,"ok, it's latency now.",0,0.9741557240486145
92228908,1446,enothereska,2016-12-13T18:05:21Z,one problem here is the `prefix` which so far has been hardcoded in `streamthread.java`,0,0.9809431433677673
92230530,1446,guozhangwang,2016-12-13T18:12:51Z,"i'm not sure i understand your comment above? btw following my comment below i think we still cannot remove the `scopename` from the sensor name, since otherwise they will be collapsed into the same sensor.",0,0.9394177794456482
92235489,1446,enothereska,2016-12-13T18:36:31Z,i only have 2 cases of this so far. worried about one more layer of indirection.,-1,0.9709288477897644
92237153,1446,enothereska,2016-12-13T18:44:00Z,"i see, sure. thanks.",1,0.944851815700531
92248305,1446,enothereska,2016-12-13T19:35:26Z,"with my latest commit i think i have got things consistent, could you have a look if you can. with `jconsole` i can verify that i can see the sensors and metrics.",0,0.9673457741737366
92681462,1446,mjsax,2016-12-15T19:25:52Z,"of -> or ""to ensure name well-formedness and conformity "" -> to ensure that metric names are well-formed and conform",0,0.9716529250144958
92709588,1446,mjsax,2016-12-15T22:00:00Z,in `processornode` we also do should we do the same here? what about a more general way to measure this latency? it seems we do not do this correctly right -- we could abstract `nodemetrics` such that it can be private in and avoid code duplication. i am also wondering why `this.processor.init(...)` is only called `processornode` and not in `sourcenode` or `sinknode`.,0,0.9434218406677246
92719109,1446,guozhangwang,2016-12-15T22:57:38Z,"honestly i am not sure if we should ever be ""completely generic"" or not. but if we feel that we should do it, then we can simply expose them as [code block] in stead of still enforcing the naming convention in terms of `scope, entity, operation`? or simply just expose the internal `metrics` to let users call its `sensor` functions directly: [code block] if we do not want to allow ""completely generic sensor registry"", then i'd suggest renaming the functions to `addgenericsensor` and make it very clear how the `scope / entity / operation` names will be used to construct the group-name, sensor name, or even tags, etc in the javadoc.",-1,0.509770393371582
92724770,1446,guozhangwang,2016-12-15T23:40:34Z,"this is not introduced in this pr, but i'm wondering if there is any value we add this specific `addcachesensor` instead of just using the ""generic adding sensor"" functions since we have already introduced them in this pr. afterwards there is only one place using it for recording `cache hits` with `min, max, avg` which to me is quite generic usage.",0,0.9401394724845886
92725173,1446,guozhangwang,2016-12-15T23:43:58Z,we could save this `nanoseconds` with `mayberecord` pattern as well with debug level.,0,0.9878573417663574
92725338,1446,guozhangwang,2016-12-15T23:44:59Z,we could apply the `mayberecord` pattern in the `meteredstore` as well for all these debug level sensors.,0,0.9891344308853149
92725404,1446,guozhangwang,2016-12-15T23:45:36Z,ditto above.,0,0.9270309805870056
92725740,1446,guozhangwang,2016-12-15T23:48:22Z,there are a couple of other places where we can potentially save `nanoseconds` calls (left comments on those places where `sensor_debug` sensors may require getting the startns and endns). so i feel this could be a common pattern to add.,0,0.9749123454093933
92870610,1446,enothereska,2016-12-16T19:24:35Z,"this pr is not about allowing users to register their own sensor yet, for the scope of this pr these are helper functions for our own usage internally. i'd like to separate the two if possible.",0,0.9720841646194458
92999354,1446,enothereska,2016-12-19T09:57:26Z,"good catch, thanks!",1,0.9874116778373718
92999461,1446,enothereska,2016-12-19T09:58:00Z,thanks!,1,0.9308210611343384
93007886,1446,enothereska,2016-12-19T10:48:03Z,ok.,0,0.9735831022262573
93012648,1446,enothereska,2016-12-19T11:19:33Z,the answer is that we'll provide helper functions but also expose the metrics registry as well.,0,0.9889249205589294
93102705,1446,enothereska,2016-12-19T19:32:23Z,"done, thanks.",1,0.727206826210022
93230666,1446,ijuma,2016-12-20T12:50:12Z,maybe `the higher recording level for metrics` or something like that?,0,0.9811510443687439
93230738,1446,ijuma,2016-12-20T12:50:39Z,adding a config typically requires a kip. are we planning to do that?,0,0.9833835959434509
93231030,1446,ijuma,2016-12-20T12:52:30Z,why is this not simply `info` and `debug`?,0,0.9621066451072693
93231096,1446,ijuma,2016-12-20T12:52:55Z,why do we expose this instead of getting it via the enum?,0,0.9548816084861755
93231227,1446,ijuma,2016-12-20T12:53:51Z,"typically, this would be done by iterating over the enums (i.e. `recordlevel.values()`) and then it doesn't have to be changed if we add more levels. any reason why we can't do that?",0,0.9846979975700378
93231324,1446,ijuma,2016-12-20T12:54:33Z,"instead of doing this, we can simply override `tostring` in each enum. however, if we go with my suggestion of renaming the enum values, the `tostring` will be the right one by default, i think.",0,0.9869311451911926
93231397,1446,ijuma,2016-12-20T12:55:07Z,this should disappear with my suggestion.,0,0.9731444120407104
93232020,1446,ijuma,2016-12-20T12:59:15Z,"we shouldn't really be using the `ordinal` in this way imo. we should expose a method in the `recordlevel` class to return a boolean in this case. for example, the invocation could look like `recordlevel.shouldrecord(config.recordlevel)`. also, using the `ordinal` internally can work, but it's a bit opaque (i.e. if people change the order of definition, they break the code). one often adds a new parameter to the enum instance to make it clearer.",0,0.9784398674964905
93232147,1446,ijuma,2016-12-20T13:00:06Z,`shouldrecord`? `mayberecord` sounds like it would record it for you.,0,0.9856622815132141
93275266,1446,enothereska,2016-12-20T16:39:03Z,ok,0,0.9667208194732666
93275350,1446,enothereska,2016-12-20T16:39:25Z,what do you think?,0,0.9750949144363403
93275549,1446,enothereska,2016-12-20T16:40:24Z,ok,0,0.9667208194732666
93275798,1446,enothereska,2016-12-20T16:41:36Z,good point.,1,0.9406068921089172
93276750,1446,enothereska,2016-12-20T16:46:33Z,yup.,0,0.7401779294013977
93276771,1446,enothereska,2016-12-20T16:46:38Z,yup.,0,0.7401779294013977
93276794,1446,enothereska,2016-12-20T16:46:44Z,"yup, thanks.",1,0.9536188244819641
93277891,1446,enothereska,2016-12-20T16:51:44Z,"makes sense, thanks.",1,0.8964961767196655
93283534,1446,enothereska,2016-12-20T17:18:07Z,ok,0,0.9667208194732666
93296992,1446,guozhangwang,2016-12-20T18:33:22Z,"yup, sounds good to me.",1,0.9820929765701294
93298089,1446,guozhangwang,2016-12-20T18:39:23Z,do we really want to expose this function as a public api ?,0,0.9821778535842896
93298423,1446,guozhangwang,2016-12-20T18:41:15Z,"so what is the final decision for these two functions? i saw that you have already exposed the underlying `metrics` registry directly; in this case do we still need these two functions? personally i feel it is not necessary any more, but if you have a strong opinion maybe we should at least rename it to `addgenericsensor` to be consistent with other two.",0,0.9080947637557983
93298928,1446,guozhangwang,2016-12-20T18:43:54Z,shall we add a `recordthroughput` function as well?,0,0.989237368106842
93304064,1446,ijuma,2016-12-20T19:10:19Z,"thanks for the updates. looking better. :) one thing i wasn't too clear about. for the `shouldrecord` case, we can pass a number to make the comparison more efficient. it's pretty similar to using `ordinal`, but the number is explicit instead of being based on the order of definition. classes like `apikeys` and `securityprotocol` do that. we could also just use the ordinal if it's just used internally. another thing is that enums get a `name` method that returns the declaration name. in this case `info` and `debug`. so, again, if it's an internal thing, we could potentially reuse that. defining it explicitly is fine too (we tend to do that for public enums. finally, we don't use getter notation in kafka so `getvalue()` should be `value` (if we decide to keep it).",1,0.9900227189064026
93305783,1446,enothereska,2016-12-20T19:19:21Z,sure. it's useful internally as well. this pr is primarily for internal needs so far.,0,0.8453792929649353
93310227,1446,guozhangwang,2016-12-20T19:43:16Z,"the issue is that, streamsmetrics is a public class so any public functions of this interface will be accessible to users as well. if we really want to add it to let users be able to use it, we need to think about how to clearly differentiate with `recordlatency`, when to use which, etc. personally i'd rather not exposing it but only for internal usage, and let users to make their own optimizations if they want.",0,0.9479026794433594
93505557,1446,junrao,2016-12-21T19:39:40Z,do we need to expose a similar config on the broker side since the broker also uses the client side metrics in certain cases?,0,0.9872449040412903
94743881,1446,enothereska,2017-01-05T10:22:16Z,done.,0,0.9759407639503479
94746977,1446,enothereska,2017-01-05T10:44:00Z,ok.,0,0.9735831022262573
94748307,1446,enothereska,2017-01-05T10:53:17Z,"ok, removing.",0,0.9602046608924866
94751245,1446,enothereska,2017-01-05T11:16:35Z,yeah probably. will add. thanks.,1,0.906838595867157
94757229,1446,enothereska,2017-01-05T12:09:16Z,"will do this, ideally before feature freeze, but definitely before code freeze. stay tuned.",0,0.941311240196228
95413470,1446,guozhangwang,2017-01-10T17:22:32Z,i am not sure if it is needed: `metrics.sensor` will recursively link parent sensor to its children; `metrics.removesensor` will recursively remove its children sensor as well.,0,0.9125780463218689
95413953,1446,enothereska,2017-01-10T17:25:00Z,"`addlatencymetrics` is supposed to return 1 sensors, but it creates 2 internally. one of them, the parent, is never exposed to the user, so the user has no way of deleting it. with this solution, the user deletes the child sensor and we internally delete the parent sensor.",0,0.9864713549613953
95415769,1446,guozhangwang,2017-01-10T17:33:39Z,"got it, thanks.",1,0.922481119632721
95559941,1446,enothereska,2017-01-11T11:24:12Z,"done now, thanks",1,0.8701021671295166
95629070,1446,guozhangwang,2017-01-11T17:30:33Z,is this intentional? ditto below.,0,0.9045606851577759
191968009,5101,lindong28,2018-05-31T01:29:34Z,why do we need to change it to 0? do we expect to initialize `controllercontext.epochzkversion` to -1?,0,0.9880455136299133
192005699,5101,lindong28,2018-05-31T07:05:43Z,nits: we probably don't need `{` here so that the code style is consistent with the existing code.,0,0.9845041036605835
192008864,5101,lindong28,2018-05-31T07:22:46Z,"here `setdatarequest/setdataresponse` is replaced with `multioprequest/multiopresponse`. this may cause problem for existing code (e.g. `zookeeperclient.send()`) whose logic relies on the type of the request. instead of adding a new subclass of asyncrequest, would it be better to modify the existing request (maybe the asyncrequest) to include the expected controller epoch version so that, when the expected controller epoch exists, zookeeperclient.send() will take care of the version check?",0,0.985869288444519
192020116,5101,hzxa21,2018-05-31T08:13:18Z,"i think the `initialcontrollerepochzkversion` represents the initial value when the controller epoch znode first gets created so it should be set to 0 for consistency just like `initialcontrollerepoch`. also, during cluster initialization (i.e controller epoch znode does not exists), we explicitly set `controllercontext.epochzkversion` to `initialcontrollerepochzkversion`, which was 1 before. ([a link] this will cause problems for the first controller to update zk states after this patch because the actual znode version is 0. this is not a problem before because we didn't use `controllercontext.epochzkversion` to fence zk state updates and after controller failover, we will update it by reading controller epoch znode. this change is only for readbility. actually we can just remove the line to set `controllercontext.epochzkversion` to `initialcontrollerepochzkversion` and keep `initialcontrollerepochzkversion` to be 1.",0,0.9798405766487122
192020231,5101,hzxa21,2018-05-31T08:13:50Z,thanks for pointing out. will fix that.,1,0.8396823406219482
192023554,5101,hzxa21,2018-05-31T08:27:18Z,"that is a good point. the reason why i add the multiop subclass is that we can extend `zookeeperclient` to handle arbitrary multi() operations, not specifically for checking controller epoch version and updating zk states. also, i think `zookeeperclient` should only be aware of zookeeper related context not the kafka related context (e.g. controller epoch version) for cleanness. instead of modifying asyncrequest, do you think it is better to add some helper functions in `kafkazkclient` to wrap around the check and set/update/create logic? also, i am a little bit confused on what are the problems caused by `zookeeperclient.send()` if we use `zookeeper.multi()` for `multioprequest`. can you give me more contexts on that?",1,0.6130698919296265
192188682,5101,lindong28,2018-05-31T18:09:13Z,cool. this makes sense.,1,0.9798417091369629
192206415,5101,lindong28,2018-05-31T19:10:04Z,"i think it is reasonable not to have kafka specific thing in zookeeperclient. on the other hand we don't have to -- we can provide anther zk path and expected version as parameters to these apis, the api should return proper error without executing the original request if the version of the path is different from the expected version. this solution is probably not kafka specific. not sure that we don't need arbitrary multi() operations in the near future. currently we only need to check the zk version of another path when controller changes zookeeper state. after checking the code, it seems that there is no current problem caused by using multioprequest. but some information (e.g. `createresponse.name` and `setdataresponse.stat`) is discarded in the response which may potentially be problem in the future. in general it seems more flexible to be able to use different case class for different requests so that we can have different parameters (as is the case now) and apply different processing logic to different case class. just my opinion. if you like the current solution, maybe you can keep it and other committers can comment on this.",0,0.9581183791160583
192302796,5101,hzxa21,2018-06-01T05:46:08Z,i see what you mean. that makes sense to me. i will update the pr to differentiate set/update/create with check parameters provided in `zookeeperclient` to expose different information. thanks for the explanation.,1,0.9606310725212097
194241899,5101,lindong28,2018-06-10T00:17:10Z,should the comment be `expected controller epoch zkversion`?,0,0.9888284802436829
194241972,5101,lindong28,2018-06-10T00:24:23Z,do we need the `path` field here? can we remove this class and replace it with e.g. `zkversioncheckresultcode: resultcode`?,0,0.9895303249359131
194242568,5101,lindong28,2018-06-10T01:08:00Z,"in general we want to the exception returned to the caller to uniquely identify the problem. but here we can output the badversionexception if either the controller epoch zkversion is bad or the data znode zkversion is bad. it maybe confusing. it is probably simpler to create a new exception, e.g. `controllerepochzkversionmismatchexception` and do the following before checking `setdataresponse.resultcode`: [code block]",0,0.9529187083244324
194242678,5101,lindong28,2018-06-10T01:17:21Z,"can we name it `case class zkversioncheck(path: string, zkversion: int )`",0,0.9869376420974731
194242922,5101,lindong28,2018-06-10T01:34:55Z,typo,0,0.983373761177063
194243046,5101,lindong28,2018-06-10T01:44:43Z,we can name it to be `controllerepochzkversion` to be consistent with `controllercontext.epochzkversion`? same for other uses of `controllerepochversion`.,0,0.9896711707115173
194243176,5101,lindong28,2018-06-10T01:55:46Z,"the current patch checks `resultcode`, and based on its value, adds additional logic to check `checkresult`. similar to the comment for `updateleaderandisr`, could we simplify the logic here by checking `deleteresponse.checkresult` before the existing logic of checking the resultcode?",0,0.9895016551017761
194243224,5101,lindong28,2018-06-10T02:00:42Z,it seems that we will return `badversionexception` for two different scenarios. can we output a unique exception if the controller znode has different version from what is expected?,0,0.8339287042617798
194244953,5101,lindong28,2018-06-10T04:37:09Z,"`generateasyncresponsewithcheckresult()` is called for `createrequest`, `setdatarequest` and `deleterequest`. however, most of the code (or logic) in `generateasyncresponsewithcheckresult()` is different for these three requests anyway. would it be more intuitive and simpler to remove the method `generateasyncresponsewithcheckresult()` and moves its request-specific logic in `send()`? we can put the logic that is common to all requests, e.g. the first part of generateasyncresponsewithcheckresult(), in a method if needed.",0,0.9801118969917297
194577297,5101,hzxa21,2018-06-11T23:28:09Z,yes. will fix it.,0,0.9663767218589783
194577987,5101,hzxa21,2018-06-11T23:32:42Z,"the path is needed to generate keeper exception with path information without assuming it to be controller epoch path. if we are going to generate the `controllerepochzkversionmismatch` exception in `kafkazkclient` instead of `keeperexception` in `zookeeperclient`, i think we can remove the path and just keep the resultcode.",0,0.9891229271888733
194578905,5101,hzxa21,2018-06-11T23:38:42Z,"thanks for the suggestion. it is simpler and cleaner this way. btw, i think we can just use `controllermoveexception()` in this case. also, related to your comment on my last commit, instead of putting the exception in some data structures, can we just simply throw the exception when the check fails? in this case, we can skip processing unnecessary controller event until we hit `controllerchange` event. to optimize it further, we can also catch 'contollermoveexception' explicitly in the `controllereventthread` and let the controller resigns immediately.",1,0.9266027808189392
194578945,5101,hzxa21,2018-06-11T23:38:58Z,sure. will do.,0,0.8554428815841675
194578974,5101,hzxa21,2018-06-11T23:39:07Z,thanks. will fix.,1,0.9210065007209778
194578989,5101,hzxa21,2018-06-11T23:39:14Z,sure.,0,0.9536533951759338
194579028,5101,hzxa21,2018-06-11T23:39:29Z,will fix it. thanks for pointing out.,1,0.9016104340553284
204258438,5101,lindong28,2018-07-22T23:09:20Z,maybe rename `controllermovelistener` to `controllermovedlistener` so that it is more consistent with the existing name `eventprocessedlistener`.,0,0.9869927167892456
204258805,5101,lindong28,2018-07-22T23:21:35Z,type: should be `emptyeventqueueandreelect`. also it seems the name `cleareventqueueandreelect` is more consistent with the existing method names.,0,0.988896906375885
204258904,5101,lindong28,2018-07-22T23:24:44Z,"nits: we typically just use `e: controllermovedexception` here for simplicity. `cme` does not provide much information since most users would still need to read the actual type to understand what it is. if it makes sense, can you rename it here and in other places of the patch?",0,0.9855372309684753
204259174,5101,lindong28,2018-07-22T23:32:47Z,in general the code may be more consistent and readable if we name the variable after this type. and `zkversioncheck` seems more informative than the `checkinfo`. can you rename the `checkinfo` here and in other places of the patch (including local variable)?,0,0.9844919443130493
204259221,5101,lindong28,2018-07-22T23:34:24Z,"would it be better to rename `controllerepochzkversion` to `expectedcontrollerepochzkversion`? the current method signature seems to suggest that the `controllerepochzkversion` will be written to the znode. if it makes sense, can you rename the variable here and in other places of the patch?",0,0.9897422790527344
204259339,5101,lindong28,2018-07-22T23:37:53Z,i am wondering whether it will be useful to print the expected/current controllerepoch and zkversion. not sure if this information is already printed when controller processes `reelect` etc.,0,0.6984046697616577
204259617,5101,lindong28,2018-07-22T23:45:57Z,"just in case this patch causes any issue, it may be useful if we still print the message such as `error completing reassignment of partition ...`. if it makes sense, can you add the additional log based on the existing log (if exists) here and in other places where the `controllermovedexception` is caught and thrown?",0,0.9878681898117065
204259978,5101,lindong28,2018-07-22T23:56:12Z,"can we specify `zkversion` in the name, e.g. `controllerzkversioncheck`? also, can you add the return type to the method signature?",0,0.9900931715965271
204260316,5101,lindong28,2018-07-23T00:05:52Z,"it seems that checkopresult should be either `checkresult` or `errorresult`. maybe we should throw illegalstateexception otherwise? by doing so we could simplify the signature of `getmultiopresults` to `(code, opresult)`. and we can also simplify the signature of e.g. `createresponse` such that zkversioncheckresultcode is of type `code`.",0,0.9892228841781616
204260401,5101,lindong28,2018-07-23T00:08:58Z,would it be simpler to name it `zkversioncheck`?,0,0.9881125092506409
204260465,5101,lindong28,2018-07-23T00:10:59Z,can you add the return type to the signature of `checkop()`?,0,0.9897298812866211
210026725,5101,hzxa21,2018-08-14T16:53:58Z,done.,0,0.9759407639503479
211706198,5101,hzxa21,2018-08-21T18:12:07Z,done.,0,0.9759407639503479
211706290,5101,hzxa21,2018-08-21T18:12:24Z,done.,0,0.9759407639503479
211706505,5101,hzxa21,2018-08-21T18:13:01Z,done.,0,0.9759407639503479
211706631,5101,hzxa21,2018-08-21T18:13:27Z,done.,0,0.9759407639503479
211707860,5101,hzxa21,2018-08-21T18:16:52Z,that is a good point. i have added a log in the reelect controller event to print out this information.,1,0.965221643447876
211708052,5101,hzxa21,2018-08-21T18:17:25Z,done.,0,0.9759407639503479
211708354,5101,hzxa21,2018-08-21T18:18:20Z,done.,0,0.9759407639503479
211708407,5101,hzxa21,2018-08-21T18:18:30Z,done.,0,0.9759407639503479
211708530,5101,hzxa21,2018-08-21T18:18:49Z,yes. done.,0,0.9706167578697205
211708610,5101,hzxa21,2018-08-21T18:19:02Z,done.,0,0.9759407639503479
211709050,5101,hzxa21,2018-08-21T18:20:15Z,done.,0,0.9759407639503479
211709057,5101,hzxa21,2018-08-21T18:20:16Z,done.,0,0.9759407639503479
211719034,5101,lindong28,2018-08-21T18:50:34Z,"not sure if this line invokes the callback. maybe we should change it to controllermovedlistener.apply(). if the existing version does not actually execute this callback, then it means all existing test does not catch this issue. then it may be worthwhile adding a test.",0,0.9852283000946045
211720966,5101,lindong28,2018-08-21T18:56:54Z,"nits: it seems a bit confusing that we print more information (i.e. newreplicas) for `controllermovedexception` than all other exception. it may be better to make the log information consistent and still print `error(s""error completing reassignment of partition $tp"", e)`.",0,0.7503942847251892
211721256,5101,lindong28,2018-08-21T18:57:52Z,"can we still print `error(s""error completing preferred replica leader election for partitions ${partitions.mkstring("","")}"", e)` for consistency?",0,0.9893770217895508
211721459,5101,lindong28,2018-08-21T18:58:29Z,nits: can we replace `epoch version is now` with `epoch zk version is now`,0,0.9831750988960266
211731340,5101,lindong28,2018-08-21T19:32:32Z,"since `kafkacontroller.incrementcontrollerepoch()` will always print controllercontext.epochzkversion, the only extra information we are seeking here is the current zkversion of the controller epoch znode. it seems that we only need this information when the broker observes controllermovedexception when it thinks it is controller. since `reelect` is triggered in every broker every time there is controller movement, it may not be very intuitive or necessary to print the extra log here in `relect.process()`. another thing to note that that we would like to know the zkversion of the controller epoch znode that causes the controllermovedexception, but this zk version may have changed after the controller observes controllermovedexception but before the controller processes reelect event. so it is better to read the zkversion earlier (e.g. in `controllereventthread.dowork()`) than later. the best solution is probably to include the expected zkversion in the message of `controllermovedexception` thrown by `maybethrowcontrollermoveexception()`.",0,0.9709152579307556
211734782,5101,lindong28,2018-08-21T19:44:24Z,"given that there may be other zookeeper operation other than `controllerzkversioncheck` which can also check the zkversion of the corresponding znode, some response may also show `zkversioncheckresultcode != code.ok` and cause `maybethrowcontrollermoveexception` to throw `controllermovedexception` even if it is not for the `controllerzkversioncheck`. will this be a problem? also, any chance we can also include the expected zkversion in the message of `controllermovedexception`?",0,0.982995331287384
211735664,5101,lindong28,2018-08-21T19:47:24Z,"for code style consistency, can you change the code to use one of the following styles: [code block] or [code block]",0,0.9873138070106506
211738667,5101,lindong28,2018-08-21T19:57:09Z,"nits: i am not sure what is the expected code style here. but if there is no clear standard and it is not very obvious, it is probably simpler to keep the existing style so that we avoid back-and-force change in the open source community.",0,0.8827134966850281
212047310,5101,hzxa21,2018-08-22T17:51:22Z,done.,0,0.9759407639503479
212050784,5101,hzxa21,2018-08-22T18:01:05Z,"yes, i think it is better to include the expected zkversion in the zookeeper response and extract the information from the response when throwing `controllermovedexception`. i have added `zkversioncheckresult: option[zkversioncheckresult]` to achieve this.",0,0.9871010780334473
212059088,5101,hzxa21,2018-08-22T18:24:40Z,make sense. i have removed the extra logs and included the expected zkversion in the message of `controllermovedexception`.,0,0.9871912002563477
212059196,5101,hzxa21,2018-08-22T18:24:57Z,done.,0,0.9759407639503479
212059233,5101,hzxa21,2018-08-22T18:25:04Z,done.,0,0.9759407639503479
212059283,5101,hzxa21,2018-08-22T18:25:13Z,done.,0,0.9759407639503479
212059557,5101,hzxa21,2018-08-22T18:26:05Z,i have changed it to `controllermovedlistener.apply()`. will add a test in future commits.,0,0.9886081218719482
212083665,5101,lindong28,2018-08-22T19:43:26Z,nits: can we also replace `-1` with `zkversion.matchanyversion`?,0,0.989654004573822
212085220,5101,lindong28,2018-08-22T19:49:09Z,it seems that we need extra indentation for the body of the `if` statement.,0,0.9831464886665344
212086207,5101,lindong28,2018-08-22T19:52:42Z,`zoodefs` seems to be unused.,0,0.9712258577346802
212086264,5101,lindong28,2018-08-22T19:52:52Z,`checkresult` seems to be unused.,0,0.9810155630111694
212086460,5101,lindong28,2018-08-22T19:53:36Z,`checkresult` and `errorresult` seems to be unused.,0,0.9846587181091309
212128308,5101,hzxa21,2018-08-22T22:18:47Z,fixed.,0,0.9810503125190735
212128341,5101,hzxa21,2018-08-22T22:18:56Z,removed.,0,0.9311882257461548
212128387,5101,hzxa21,2018-08-22T22:19:03Z,removed.,0,0.9311882257461548
212128438,5101,hzxa21,2018-08-22T22:19:10Z,removed.,0,0.9311882257461548
212144205,5101,junrao,2018-08-22T23:42:44Z,"hmm, technically, only when the error code is badversion, it's an indication that the controller has moved. for other errors, we probably just want to propagate as they are to the caller.",0,0.9659672975540161
212144563,5101,junrao,2018-08-22T23:44:48Z,could this just be controllermovedlistener()?,0,0.9890632033348083
212147981,5101,junrao,2018-08-23T00:05:44Z,"we probably need to be a bit careful about bumping up the controller epoch at the beginning of oncontrollerfailover(). currently, the reading and the incrementing of the controller epoch is done independently after the controller path has been created successfully. this can create the following problem. broker a creates the controller path and is about to call oncontrollerfailover(). admin deletes the controller path and broker b creates the controller path, reads the controller epoch and updates it to 1. broker a reads the controller epoch and updates it to 2. now broker b is the controller, but its controller epoch is outdated. one way to address this issue is to use multi() when creating the controller path. to elect a new controller, a broker first reads the current controller epoch from zk and then do a multi() to (1) write the controller path (2) do a conditional update to the controller epoch. not sure if this is the best way though.",0,0.9607951045036316
212153922,5101,junrao,2018-08-23T00:48:34Z,we log e here but not in line 260. it would be useful to be consistent.,0,0.9706566333770752
212155652,5101,junrao,2018-08-23T01:01:49Z,could this be private?,0,0.9868327379226685
212155764,5101,junrao,2018-08-23T01:02:40Z,could this be private?,0,0.9868327379226685
212793210,5101,hzxa21,2018-08-25T08:48:27Z,done.,0,0.9759407639503479
212793216,5101,hzxa21,2018-08-25T08:48:36Z,yes. done.,0,0.9706167578697205
212793218,5101,hzxa21,2018-08-25T08:48:43Z,yes. done.,0,0.9706167578697205
212793233,5101,hzxa21,2018-08-25T08:49:02Z,that is a good point. fixed.,1,0.9654821157455444
212793237,5101,hzxa21,2018-08-25T08:49:13Z,yes. fixed.,0,0.9799623489379883
212793993,5101,hzxa21,2018-08-25T09:25:41Z,"thanks for pointing this out. this is indeed a very dangerous race condition. if it happens, the current controller (broker b) cannot update any zookeeper state due to controller epoch zkversion mismatch and no other broker can become the controller because the current controller (broker b) does not release the ""lock"" for `\controller` znode. wrapping `\controller` creation and `\controller_epoch` update in a zookeeper transaction can prevent this race condition and i think it is a safe option. i will make the change and see whether there will be performance overhead in the perf testing.",1,0.8937020897865295
212843697,5101,lindong28,2018-08-26T23:56:09Z,"hey , it seems that what you and jun suggested to do is to have a single multiops that 1) updates controller path, 2) read controller epoch and 3) updates controller epoch. another alternative approach is to have a single multiops that 1) updates controller path and 2) reads controller epoch with its zkversoin. then the controller can updates controller epoch with the addition zkversion check. do you think the alternative approach would avoid the race condition and ensure correctness? if so, i am wondering if the alternative would be easier to reason about. i find it a bit easier because the it follows the idea that all zookeeper write operation by controller will be based on the controller epoch zkversion check, except for the controller znode write operation which by design can not rely on the controller epoch zkversion check. and a multiop that does one write and one read seems simpler than a multiop that does write-read-write.",0,0.8707916736602783
212868803,5101,hzxa21,2018-08-27T05:26:48Z,"from a design and code readability perspective, i agree with what you have proposed (first atomic read `\controller_epoch` and create `\controller`, then update `\controller_epoch`). from the implementation perspective, zookeeper does not have a `read` op meaning that we cannot perform `read` operation with the `multi` (see [a link] basically, we use the time when a broker succeeds in incrementing the controller epoch as the ""commit"" point of the controller election and use the time when a broker succeeds in creating `\controller` znode as the ""prepare"" point. so for the correctness of the controller election ""commit"", we need to ensure `\controller_epoch` doesn't change from ""prepare"" to ""commit"". to achieve, we can implement the logic using zk `multi` following the steps: 1. read `\controller_epoch` to get the current controller epoch **e1** with zkversion **v1** 2. create `\controller` if `\controller_epoch` zkversion matches **v1** (use zk `multi`) 3. update `\controller_epoch` to be **e1+1** if its zkversion matches **v1** (zk conditional set)",0,0.9781532287597656
212913449,5101,hzxa21,2018-08-27T09:12:14Z,pr updated to address this issue.,0,0.9829471707344055
213035777,5101,lindong28,2018-08-27T16:31:37Z,"if `oncontrollerfailover()` throws `controllermovedexception` after controller has registered itself as controller, it seems possible that some events may have already been inserted into the controller event queue. should we propagate the `controllermovedexception` to `controllereventthread` in order to clear the controller event queue? also, i think in most places we will just name the exception varaible as `e` and throwable variable as `t`. naming them e1, e2, and specifically naming a throwalble as `e2`, seems unusual. i know this style is used in the existing controller code. i am wondering if we can change this.",0,0.9884324669837952
213040676,5101,lindong28,2018-08-27T16:49:32Z,i am wondering if the code will be more readable by removing this method and putting these three lines in `elect()` directly. the method is used only once and it is very short. and the two additional lines used to update the in-memory controllercontext seems more inline with the update of `activecontrollerid` in `elect` than with the name of `tryregistercontroller()`.,0,0.9547460675239563
213041250,5101,lindong28,2018-08-27T16:51:44Z,"if there is no existing controller, `getcontrollerepoch` returns `none`. should we still try to register controller in this case?",0,0.9888315200805664
213041939,5101,lindong28,2018-08-27T16:54:32Z,can we rename this method to `maybecreatecontrollerznode` so that it is more consistent with the existing names such as `kafkacontroller.maybetriggerpartitionreassignment()`?,0,0.9892539978027344
213043734,5101,lindong28,2018-08-27T17:01:26Z,currently the variable `timestamp` is passed all the way from `elect()` to `kafkazkclient.trycreatecontrollerznode()`. would it be simpler to replace this variable with `time.milliseconds` in `kafkazkclient.trycreatecontrollerznode()`?,0,0.9891782999038696
213087554,5101,lindong28,2018-08-27T19:29:41Z,"since it is not very intuitive from the method name to understand the meaning of the returned value `(int, int)`, can we add java doc for the returned value? since the new implementation of this method will try to create/update controller znode and increments controller epoch in a safe manner, would it be better to rename the method `registercontrollerandincrementcontrollerepoch`?",0,0.9850236177444458
213089263,5101,lindong28,2018-08-27T19:35:44Z,"info level logging is needed if user always want to see the message and it is usually used when something major is completed, e.g. server is started, rather than when something is attempted. it seems that ""try to create.."" and ""try to increment controller..."" may be more appropriate to be debug level logging if they are needed. the controller epoch and zkversion have been logged at info level in `elect()`.",0,0.9857295751571655
213097271,5101,lindong28,2018-08-27T20:03:39Z,"prior to this patch, if setcontrollerepochraw fails and the error is not `nonode`, controllermovedexception will be thrown which will be caught and `triggercontrollermove()` will be executed. after this patch, if setcontrollerepochraw returns a non-ok error code, we will always throw controllermovedexception(), which will be caught in the upper layer without executing `triggercontrollermove()`. i am wondering if we should throw illegalstateexception if the error code suggests something other than controller move, so that we can still execute `triggercontrollermove()` in this scenario.",0,0.9245508313179016
213100747,5101,junrao,2018-08-27T20:16:30Z,"for errors other than badversion, we should just propagate the original error as an exception.",0,0.9102867245674133
213112066,5101,junrao,2018-08-27T20:54:22Z,"not sure if we need to explicitly do the creation here. when the controller path is removed, every broker's controller listener will fire, which will trigger the controller election logic again.",0,0.9754763841629028
213118760,5101,hzxa21,2018-08-27T21:18:09Z,you are right. we should propagate the exception here. done.,0,0.9304028749465942
213118780,5101,hzxa21,2018-08-27T21:18:13Z,done.,0,0.9759407639503479
213122229,5101,hzxa21,2018-08-27T21:30:23Z,"no. previously we create `/controller_epoch` on-demand if it does not exist when we try to increment controller epoch. imo, this makes the code hard to read and reason about, especially after this patch because in that way we need to either create `/controller_epoch` if not exists and retry the atomic operation or we have two different atomic operations (one for check+create, the other one for create+create). i think `/controller_epoch` should pre-exists before we actually use it, like other persistent zk paths (e.g. /brokers, /admin/delete_topics) . so i have included `/controller_epoch` in the ""persistentzkpaths"" so that it will be created if not exists on broker startup. in this case, `getcontrollerepoch` should not return none unless admin deletes `/controller_epoch` explicitly, which will ruin the cluster anyway. one drawback of pre-creating `\controller_epoch` is that admin now cannot re-initialize controller epoch by simply deleting `\controller_epoch`. instead, admin should delete `/controller` and `/controller_epoch`, then re-create `\controller_epoch` to achieve this. but i don't know whether that is a valid use case. may i have your opinion?",0,0.9084398150444031
213122263,5101,hzxa21,2018-08-27T21:30:31Z,done.,0,0.9759407639503479
213122308,5101,hzxa21,2018-08-27T21:30:40Z,i agree. fixed.,0,0.9220938086509705
213122347,5101,hzxa21,2018-08-27T21:30:45Z,done.,0,0.9759407639503479
213122376,5101,hzxa21,2018-08-27T21:30:49Z,done.,0,0.9759407639503479
213124615,5101,junrao,2018-08-27T21:39:33Z,"this is called on controllermovedexception. in this case, we know that another broker has become the controller. we just need to clear the event queue, mark the controller as inactive and call oncontrollerresignation() . there is no need to do the controller election. if the new controller is gone afterward, every broker's controller path watcher will be triggered and a controller election will be tried. we probably should rename this method accordingly. also, we probably want to consolidate this method and triggercontrollermove() somehow. to me, the latter will just do what this method does and one more thing, removing the controller path.",0,0.9611538052558899
213126066,5101,hzxa21,2018-08-27T21:45:16Z,"per [a link] `/controller_epoch` should exists and `setcontrollerepochraw` should not return `nonode`. if that does happen, we will rely on admin to recover and `triggercontrollermove()` will not help. i agree that throwing `controllermovedexception` is not a good idea. maybe we should just throw `illegalstateexception` and indicate that is a fatal error. what do you think?",0,0.7747291922569275
213136758,5101,junrao,2018-08-27T22:37:02Z,perhaps we should just fold the logic in here to cleareventqueueandreelect() and always let eventmanager handle controllermovedexception.,0,0.9884436726570129
213137736,5101,junrao,2018-08-27T22:42:18Z,could we just do the conditional controller epoch update and the creation of the controller path together in trycreatecontrollerznode()? this avoids an extra zk step.,0,0.9878379106521606
213140323,5101,junrao,2018-08-27T22:56:14Z,it process => it processes,0,0.981097936630249
213140367,5101,junrao,2018-08-27T22:56:27Z,what's ple?,0,0.9836085438728333
213141257,5101,junrao,2018-08-27T23:00:57Z,"suspend()/resume() are deprecated. we can probably simulate this by adding a new controller event type. within the event, we can let it wait on a countdownlatch. once the controller is moved, we can unblock the countdownlatch.",0,0.9882147312164307
213142512,5101,junrao,2018-08-27T23:08:35Z,should we assert the return value?,0,0.9865918755531311
213142665,5101,junrao,2018-08-27T23:09:21Z,it seems that the last one is enough?,0,0.9727454781532288
213142925,5101,lindong28,2018-08-27T23:10:34Z,"prior to this patch, we only include znode in zkdata.persistentzkpaths() if there is no need for the data in the znode. this patch changes this behavior such that we create znode will null data and we assume epoch is -1 if the data is null. the previous approach says that either the znode does not exist, or the znode exists with valid data. the new approach says that either the znode exists with null, or the znode exists with valid data. i personally prefer the previous approach and i would prefer not to define a znode with null data and add additional code to handle that case. and in general it is probably better to keep the existing code if there is no difference in correctness/performance and the difference in code style is not very obvious w.r.t which one is better. it looks like the main concern with the previous approach is about code complexity. how about we have create and call method `maybecreatecontrollerepochznode` at the beginning of `registercontroller()`?",0,0.8770601153373718
213143236,5101,junrao,2018-08-27T23:12:20Z,this is an existing issue. could you add a space after the comma in the next line?,0,0.9889898300170898
213144214,5101,lindong28,2018-08-27T23:18:33Z,"now that `controllermovedexception` may be handled differently from other exceptions, the logic would be cleaner if we use this exception only when we know the another broker is the controller. thinking about it more, illegalstateexception means something impossible has happened inside the controller state. in this case the exception can happen if controller fails to write to controller epoch znode, which is possible from controller's point of view since zookeeper service is out of controller of the controller. how about `zookeeperclientexception(...)` and include error code in the message of the exception?",0,0.97409588098526
213144670,5101,junrao,2018-08-27T23:21:30Z,"since createandregister has side effect, we should do createandregister().",0,0.987267792224884
213145071,5101,junrao,2018-08-27T23:23:46Z,should we clear events?,0,0.983380138874054
213151722,5101,hzxa21,2018-08-28T00:07:57Z,thanks for the suggestion. i have added `maybecreatecontrollerepochznode` and avoid crearting the znode on broker start up.,1,0.721440851688385
213158074,5101,hzxa21,2018-08-28T01:00:08Z,thanks for the comment. i have updated the pr to throw `controllermovedexception` only when we see badversion in `setcontrollerepochraw`. i also applied the same idea to `maybecreatecontrollerznode`.,1,0.9330989122390747
213179550,5101,hzxa21,2018-08-28T04:11:44Z,"if we don't try to trigger `elect` after we clear the queue and the new controller goes away before we clear the queue, the watch may have put `reelect` in the queue before the clear happens. in this case, that broker will miss controller election. from the correctness point of view, this may not be a problem because at least one other broker will conduct the controller election and become the controller. it is safe to clear and resign if we don't care about fairness in controller election.",0,0.7677590250968933
213436446,5101,junrao,2018-08-28T19:05:53Z,"great point. we could just do reelect here as you suggested. i was thinking that we could also potentially inline the logic (clear the event queue, mark the controller as inactive and call oncontrollerresignation()) here instead of enqueuing the logic to the event queue. however, it seems that the former may be simpler.",1,0.8434471487998962
213610117,5101,omkreddy,2018-08-29T09:38:39Z,"nit: we can remove ""unit""",0,0.9881702661514282
213726027,5101,omkreddy,2018-08-29T15:29:31Z,do we need [code block] flag? looks like none of the tests depends on deletetopicenable=false. all tests are passing without this line.,0,0.9768593907356262
213727391,5101,omkreddy,2018-08-29T15:32:47Z,do we need these changes? tests are passing without these changes.,0,0.98408442735672
213880720,5101,hzxa21,2018-08-30T01:26:49Z,done.,0,0.9759407639503479
213880874,5101,hzxa21,2018-08-30T01:28:21Z,you are right. changed to throw `controllermovedexception` instead.,0,0.9698614478111267
213880937,5101,hzxa21,2018-08-30T01:28:56Z,agree. code refactored.,0,0.9793052077293396
213880947,5101,hzxa21,2018-08-30T01:29:03Z,done.,0,0.9759407639503479
213881008,5101,hzxa21,2018-08-30T01:29:37Z,"yes, you are right. fixed.",0,0.8729472756385803
213881027,5101,hzxa21,2018-08-30T01:29:43Z,fixed.,0,0.9810503125190735
213881117,5101,hzxa21,2018-08-30T01:30:27Z,i use that to stand for preferredleaderelection. fixed the comments to make it more clear.,0,0.9853910207748413
213881217,5101,hzxa21,2018-08-30T01:31:14Z,remove the deprecated methods and added the additional event for the test.,0,0.9848071336746216
213881231,5101,hzxa21,2018-08-30T01:31:20Z,yes. fixed.,0,0.9799623489379883
213881242,5101,hzxa21,2018-08-30T01:31:27Z,yes. fixed.,0,0.9799623489379883
213881251,5101,hzxa21,2018-08-30T01:31:33Z,done.,0,0.9759407639503479
213881264,5101,hzxa21,2018-08-30T01:31:38Z,done.,0,0.9759407639503479
213881314,5101,hzxa21,2018-08-30T01:31:59Z,done.,0,0.9759407639503479
213881326,5101,hzxa21,2018-08-30T01:32:04Z,done.,0,0.9759407639503479
213881555,5101,hzxa21,2018-08-30T01:34:03Z,yes. i added that for `testcontrollermoveontopicdeletion` but it turns out we don't actually need to enable topic deletion to test throwing and handling `controllermovedexception` happening in `topicdeletion` event. fixed.,0,0.9821626543998718
213881574,5101,hzxa21,2018-08-30T01:34:10Z,removed.,0,0.9311882257461548
214443770,5101,lindong28,2018-08-31T18:44:42Z,would logic be more intuitive to just treat the controllermovedexception as `controllerchange` event and do `mayberesign()`? the code would be simpler since this approach doesn't need `markinactiveandresign`.,0,0.9873917698860168
214444603,5101,lindong28,2018-08-31T18:48:10Z,"nits: ""controller move listener"" -> ""controllermovedlistener"". also, it seems simpler to just remove `trigger controller move listener immediately` as we typically do not log which method is executed next other than logging the event itself. developer is expected look into the code and understand what happens next in the code after this event.",0,0.9878467917442322
214444932,5101,lindong28,2018-08-31T18:49:39Z,can you remove `awaitonlatch` if it is not used?,0,0.9885352253913879
214447851,5101,lindong28,2018-08-31T19:00:50Z,"this line throws `nosuchelementexception` if controller epoch does not exist. it seems better to do `getcontrollerepoch.getorelse(throw new illegalstateexception(""...""))`.",0,0.986406147480011
214524631,5101,lindong28,2018-09-01T22:51:44Z,would it be more consistent with the other code in this method to do `case code.ok =>`?,0,0.9871195554733276
214524720,5101,lindong28,2018-09-01T22:59:50Z,"when sre deletes controller znode, multiple brokers may be doing `elect()` concurrently and all but one broker will find that the controller znode alread exists. prior to this patch, these brokers will log `debug(s""broker $activecontrollerid was elected as controller instead of broker ${config.brokerid}"")` if controller znode exists and the controller id is not this broker. after this patch, these brokers will log `error(s""error while creating ephemeral at ${controllerznode.path}, node already exists and owner ${getdataresponse.stat.getephemeralowner} does not match current session ${zookeeperclient.sessionid}"")` and `error(s""error while electing or becoming controller on broker ${config.brokerid} because controller moved to another broker"", e)` if controller znode exists and the controller id is not this broker. since we expect most brokers to find znode to be created by another broker during `elect()`, we probably want to keep the old behavior instead of having error level logs.",0,0.9841734170913696
214524844,5101,lindong28,2018-09-01T23:09:45Z,"it seems that we can enter this state only if broker executes `registercontrollerandincrementcontrollerepoch()` and finds that the controller znode has already been created by itself. the question is, is this possible? previously if broker tries to create controller znode and node already exists, the broker will simply read the controller id from the controller znode and move on. this patches added quite a few new logic in `controllernodeexistshandler()`, e.g. uses zk session id to detect whether the controller znode is created by this broker, handles the scenario that the controller znode is created by this broker. so the new code is more complicated than the previous version. can you explain a bit why we need these new logic?",0,0.973275363445282
214525056,5101,lindong28,2018-09-01T23:28:05Z,is it possible for error code to be `code.ok` while `zkversioncheckresult.opresult` is of type `errorresult`?,0,0.9887324571609497
214525058,5101,lindong28,2018-09-01T23:28:33Z,is it possible for `controllerepochznode.path` to be different from `zkversioncheck.checkpath`?,0,0.9889541864395142
214534027,5101,hzxa21,2018-09-02T09:15:22Z,"yes. for example, if we wrap `check` + `create` in zookeeper `multi`, and `multi` fails due to `create` fails, the result of `check` will be of type `errorresult` with `code.ok` as error code.",0,0.9880450367927551
214534041,5101,hzxa21,2018-09-02T09:15:47Z,`awaitonlatch` is used in `controllerintegrationtest`,0,0.9880836606025696
214534378,5101,hzxa21,2018-09-02T09:28:42Z,"in short, the purpose of `controllernodeexistshandler` is to mimic `checkedephemeralcreate `, which previously is used to create `/controller` ephemeral node. in `checkedephemeral`, we need to double check the owner of the node if we saw `code.nodeexists`. i think the purpose of the check and the additional logic is to handle transient network connection loss while creating the ephemeral. let's say our client sent a `create` request to zookeeper to create ephemeral znode and zookeeper receives this request and successfully creates the znode but fail to send back the response to our client because of transient network issue. in `retryuntilconnected`, our client tries to resend the request and gets the `code.nodeexists`. in this case, our client actually successfully creates and owns the znode.",0,0.9843583106994629
214534566,5101,hzxa21,2018-09-02T09:36:15Z,currently no. the check here is for general purpose and safety because the zkversioncheck can apply on any znode if needed.,0,0.9880478382110596
214535433,5101,hzxa21,2018-09-02T10:15:22Z,agree. fixed.,0,0.9699246883392334
214535436,5101,hzxa21,2018-09-02T10:15:28Z,done.,0,0.9759407639503479
214535441,5101,hzxa21,2018-09-02T10:15:39Z,done.,0,0.9759407639503479
214535445,5101,hzxa21,2018-09-02T10:15:54Z,yes. done.,0,0.9706167578697205
214535450,5101,hzxa21,2018-09-02T10:16:05Z,agree. fixed.,0,0.9699246883392334
214542290,5101,lindong28,2018-09-02T14:12:48Z,"the creation of the ephemeral znode `/controller` is probably a bit different from the creation of other ephemeral znode. the broker which creates the ephemeral znode `/controller` is explicitly specified in the znode data. thus the old approach, which reads the broker id from the controller znode after seeing `code.nodeexists`, seems ok. and that old approach seems to handle the network connection loss scenario described here. i am wondering if we can use the old approach since its logic looks simpler. what do you think?",0,0.9497255682945251
214542333,5101,lindong28,2018-09-02T14:14:01Z,cool. i see.,1,0.9802844524383545
214542476,5101,lindong28,2018-09-02T14:17:24Z,got it. could you add a comment above the case class `` that says `used only by test`? this is similar to e.g. `replicamanager.markpartitionoffline(...)`.,0,0.985579252243042
214542542,5101,lindong28,2018-09-02T14:19:30Z,got it.,0,0.8921144008636475
214542750,5101,lindong28,2018-09-02T14:25:53Z,"btw, for the case `getdataresponse.stat.getephemeralowner != zookeeperclient.sessionid`, we know this case may happen and the code will automatically recover from this. in this case it is probably better to log at warning level instead of error level. here is a good explanation for how to choose log level. [a link]",0,0.9398767948150635
214760829,5101,hzxa21,2018-09-03T22:52:10Z,"i am a little bit confused about what do you mean by the old approach. are you referring to `checkedephemeralcreate`? the logic in `controllernodeexistshandler ` is essentially the same as `checkedephmeralcreate` when the node already exists, except that `controllernodeexistshandler` will read `/controller_epoch` to get back the epoch zkversion when the owner of `/controller` is the current broker.",-1,0.5655273795127869
214780256,5101,lindong28,2018-09-04T03:43:44Z,"my bad. i missed the fact that the controller znode was created using `kafkazkclient.checkedephemeralcreate()` which has the logic similar to what you are doing here. it seems that the most important logic in the `kafkazkclient.checkedephemeralcreate` is to translate `code.nodeexists` to `code.ok` for the znode creation operation if `getdataresponse.stat.getephemeralowner == zookeeperclient.sessionid`. this logic was added in [a link] by onur. my understanding is that, in case of connection issue between broker and zookeeper, it is possible for controller znode to be successfully created and yet the return code is `code.nodeexists`. `kafkazkclient.checkedephemeralcreate` will handle this scenario properly. it will be good for to clarify whether this understanding is correct so that we can decide whether we should keep this logic. here is another question. with the current patch, if the controller znode creation has failed due to znode exists exception and then broker find that `getdataresponse.stat.getephemeralowner == zookeeperclient.sessionid`, it seems `registercontrollerandincrementcontrollerepoch()` can return `(newcontrollerepoch, stat.getversion)` if `epoch == newcontrollerepoch`. but is controller epoch incremented in this case? if not, then it seems something is wrong?",-1,0.9891101717948914
214995831,5101,hzxa21,2018-09-04T17:11:11Z,"i re-think about your previous suggestion for checking the payload of `/controller` only and i think it will work. i will check with onur offline to understand more about `checkedephemeralcreate` and confirm. in terms of your second concern, if we already see `getdataresponse.stat.getephemeralowner == zookeeperclient.sessionid`, that means `/controller` has been created successfully. since the only code path to create `/controller` is within a zookeeper transaction along with the `/controller_epoch` update, we can infer that the controller epoch must get incremented in this case.",0,0.9628797173500061
215069911,5101,hzxa21,2018-09-04T21:17:26Z,"discussed with onur offline, the purpose of `getafternodeexists` in `checkedephemeral` is indeed used to handle the case when zk connection loss happens. after digging around both zookeeper and kafka codes, we think it is safe to remove the extra complexity for `controllernodeexistshandler` in this pr when we make `/controller` creation and `/controller_epoch` update atomic. so the logic will be: 1). try to create `/controller_epoch` if not exists 2). read `/controller_epoch` from zk 3). atomically create `/controller` and update `/controller_epoch` 4). if 3) throws nodeexistsexception, read `/controller` and if controller id in zk equals the current broker id and if controller epoch in zk equals the expected epoch, successfully finish controller election; otherwise, throw controllermovedexception.",0,0.9735865592956543
215105046,5101,junrao,2018-09-05T00:26:22Z,"since we are doing a conditional setdata in line 117, we don't need the check operation here.",0,0.9877105355262756
215107229,5101,junrao,2018-09-05T00:41:49Z,"if the client loses a connection to a zk server in the middle of an operation, the client will get a connectionlossexception. normally, we handle this by retrying through retryrequestsuntilconnected(). so, we probably need to create a similar routine to retry on connectionlossexception when doing transaction.commit() too. the controller path could have been created successfully when connectionlossexception was incurred. a retry could result in either nodeexistsexception or badversionexception. you handled the former properly in the code below. we will need to do the same thing for the latter.",0,0.9766073822975159
215109171,5101,junrao,2018-09-05T00:56:27Z,"for any other types of exceptions, we want to just propagate the keeperexception to the caller.",0,0.9881105422973633
215109447,5101,junrao,2018-09-05T00:58:36Z,"in the common case, the controller epoch path already exists. so, perhaps it would be better to always do getcontrollerepoch first and then try maybecreatecontrollerepochznode if we hit a nonodeexception.",0,0.986861526966095
215109576,5101,junrao,2018-09-05T00:59:41Z,the info level will be too verbose if we call maybecreatecontrollerepochznode() on every controller election.,0,0.9509549140930176
215112397,5101,junrao,2018-09-05T01:22:17Z,"""before the pre-defined logic is triggered and before it processes controller change."" it seems that we just need one of the two before?",0,0.9856675863265991
215135718,5101,junrao,2018-09-05T04:55:18Z,"hmm, i am not sure this is safe. the controller path could have been deleted and grabbed by another broker in the window between line 123 and here. then, we would have grabbed the wrong controller epoch.",0,0.5888569951057434
215176421,5101,hzxa21,2018-09-05T08:22:50Z,"you are right. but in line 133 we will check the epoch value. if it is different from what we expected, we will throw `controllermovedexception`. in the case of `/controller` gets deleted between line 123 and 127, and another broker becomes the controller, the controller epoch will increment accordingly, causing line 133 to fail.",0,0.9794877171516418
215359852,5101,junrao,2018-09-05T17:28:33Z,ah. ok. that's fine then.,0,0.9446791410446167
215360130,5101,junrao,2018-09-05T17:29:25Z,"should we explicitly call return here? otherwise, it seems that we are always throwing controllermovedexception.",0,0.9192098379135132
215418284,5101,hzxa21,2018-09-05T20:40:41Z,that's right. fixed.,0,0.9648096561431885
215418324,5101,hzxa21,2018-09-05T20:40:47Z,done.,0,0.9759407639503479
215418651,5101,hzxa21,2018-09-05T20:41:51Z,here we don't catch other types of exceptions so the keeperexception is already propogated to the caller.,0,0.9747810363769531
215420284,5101,hzxa21,2018-09-05T20:47:19Z,done.,0,0.9759407639503479
215420905,5101,hzxa21,2018-09-05T20:49:25Z,"this log will only get print when `/controller_epoch` is absent, which is typically when the cluster gets initialized, not on every controller election.",0,0.9888625741004944
215420928,5101,hzxa21,2018-09-05T20:49:31Z,fixed.,0,0.9810503125190735
215420986,5101,hzxa21,2018-09-05T20:49:43Z,ah... my bad. fixed.,-1,0.9881564378738403
215444417,5101,junrao,2018-09-05T22:25:17Z,"on connectionlossexception, it's not efficient to blindly retry immediately. instead, it's better to wait until the zk connection is ready before retry. you can check how this is done in retryrequestsuntilconnected().",0,0.9847219586372375
215444912,5101,junrao,2018-09-05T22:27:36Z,"it is possible that the controller_epoch path is created by another broker between getcontrollerepoch() and createcontrollerepochznode(). in this case, we want to get the controller epoch again, instead of throwing controllermovedexception.",0,0.9882857799530029
215447046,5101,junrao,2018-09-05T22:37:52Z,it seems that every usage of kafkacontroller.initialcontrollerepoch and kafkacontroller.initialcontrollerepochzkversion as 0 requires subtraction by 1. could we just define them as 0?,0,0.9870045781135559
215448079,5101,junrao,2018-09-05T22:43:14Z,"according to zk doc, multi propagates the error from one of the operations. the badversionexception could be the result of a retry after connectionlossexception. so, it seems that we need to handle it in the same way as nodeexistsexception.",0,0.8885393142700195
215462227,5101,hzxa21,2018-09-06T00:10:45Z,got it. thanks for pointing this out.,1,0.9468005299568176
215462635,5101,hzxa21,2018-09-06T00:13:29Z,"if the controller_epoch path is created by another broker between getcontrollerepoch() and createcontrollerepochznode(), i was thinking whether we can infer that other broker wins in this round of controller election even if it hasn't created the controller znode. after a second thought, i think we should follow what you suggested for extra safety because if the broker fails to talk to zk for some reason, the cluster will get into a no-controller state.",0,0.9787078499794006
215466660,5101,hzxa21,2018-09-06T00:45:31Z,"correct me if i am wrong, i think there are two cases when we see badversionexception here: 1. another round of controller election kicks in and the controller does switch. it is safe to throw `controllermovedexception` in this case. 2. the current broker loss zk connection after zk successfully finishes the transaction, **but the controller znode is gone before the next retry**. in this case, another round of controller election will be triggered by zk watcher `handledeleted`. so i think it is also safe to throw `controllermovedexception` here.",0,0.8843203783035278
215467856,5101,hzxa21,2018-09-06T00:55:55Z,yes. done.,0,0.9706167578697205
215467866,5101,hzxa21,2018-09-06T00:56:00Z,fixed.,0,0.9810503125190735
215467880,5101,hzxa21,2018-09-06T00:56:06Z,done.,0,0.9759407639503479
215561349,5101,omkreddy,2018-09-06T09:42:13Z,nit: missing expectedcontrollerepochzkversion params in method comments,0,0.9815430045127869
215570923,5101,omkreddy,2018-09-06T10:12:30Z,can we use initialcontrollerepochzkversion constant in place of zero?,0,0.9890908598899841
215576221,5101,omkreddy,2018-09-06T10:31:49Z,looks like this line is not required.,0,0.9524890184402466
215711690,5101,hzxa21,2018-09-06T17:28:21Z,added.,0,0.9763525128364563
215711716,5101,hzxa21,2018-09-06T17:28:29Z,sure. done.,0,0.9161409735679626
215711801,5101,hzxa21,2018-09-06T17:28:43Z,thanks for pointing out. removed.,0,0.6485938429832458
215738649,5101,junrao,2018-09-06T18:52:06Z,perhaps it's better to name this maybecreatecontrollerepochznode?,0,0.982132077217102
215740626,5101,junrao,2018-09-06T18:58:19Z,"i was thinking about case 2, but with the controller path still there. the zk multi api doesn't say that it will run the operations in a multi request in any particular order. so, during the retry on a connectionlossexception, it may be possible that the conditional update of the controller epoch path is executed first and a badversionexception is thrown?",0,0.9745964407920837
215769317,5101,hzxa21,2018-09-06T20:38:10Z,"thanks for the prompt reply! i actually checked both client and server side codes of zookeeper, the implementation honors the order and the thrown exception will correspond to the first error it sees. but since the muli api doesn't explicitly say that it is the case or it will maintain this guarantee in the future, i agree to also handle badversion the same way as nodeexists for safety given that the performance overhead is little.",1,0.9632775187492371
215773516,5101,hzxa21,2018-09-06T20:49:54Z,done.,0,0.9759407639503479
215773534,5101,hzxa21,2018-09-06T20:49:58Z,done.,0,0.9759407639503479
215775823,5101,junrao,2018-09-06T20:57:12Z,could this be private?,0,0.9868327379226685
215779888,5101,hzxa21,2018-09-06T21:11:24Z,done.,0,0.9759407639503479
215847375,5101,lindong28,2018-09-07T05:09:12Z,"i have two questions here: 1) when would we enter a scenario that `controllerid == curcontrollerid` and `epoch != newcontrollerepoch)`? 2) currently when this happens, `checkcontrollerandepoch` will throw `controllermovedexception()`, which is caught in `kafkacontroller.elect()` and trigger `mayberesign()`. however `mayberesign()` will do nothing because `controllerid == curcontrollerid` and this broker is considered to be the active controller. in this case no other broker will be controller. and the current broker will not function properly as controller because it has not executed `oncontrollerfailover()`. so maybe we should throw `illegalstateexception` here if `controllerid == curcontrollerid` and `epoch != newcontrollerepoch)`?",0,0.9565625786781311
215847674,5101,lindong28,2018-09-07T05:12:27Z,"in `maybecreatecontrollerepochznode()`, we throw `illegalstateexception(...)` if we first find controller epoch znode exists and then find it disappeared. following the same logic, it is probably consistent and reasonable to throw `illegalstateexception(...)` if `checkcontrollerandepoch(...)` can not read controller epoch, right?",0,0.9827414155006409
215849517,5101,lindong28,2018-09-07T05:28:04Z,"if `registercontrollerandincrementcontrollerepoch()` has successfully written the broker id to controller znode but then an illegalstateexception is thrown (e.g. in the case `controllerid == curcontrollerid` and `epoch != newcontrollerepoch` described in the other comment), an illegalstateexception will be thrown which is caught in `elect()` and `triggercontrollermove()` will be executed. however, since the `activecontrollerid` has not been updated, `isactive()` is evaluated to false and `triggercontrollermove()` will do nothing. maybe we should first do `activecontrollerid = zkclient.getcontrollerid.getorelse(-1)` in `triggercontrollermove()`. also, to be consistent with most other usage of `isactive()`, can we do something like the code below instead of using if/else? [code block]",0,0.9805803298950195
215849923,5101,lindong28,2018-09-07T05:31:43Z,nits: can we use `controllercontext.epochzkversion` instead of using `expectedcontrollerepochzkversion` to be consistent with other usage of `controllercontext.epochzkversion` in this patch?,0,0.9899398684501648
215851146,5101,lindong28,2018-09-07T05:41:07Z,nits: `successfully create` => `successfully created`,0,0.9826123714447021
216039463,5101,hzxa21,2018-09-07T17:54:48Z,"1. because we first get /controller and then get /controller_epoch (rather than do it atomically), it is possible that after we see `controllerid == curcontrollerid` and before we get /controller_epoch, another round of controller election is triggered. in this case, we will see `epoch != newcontrollerepoch`. 2. when we see `epoch != newcontrollerepoch`, `controllerid == curcontrollerid` does not hold because another broker must become the controller. in this case, `mayberesign` will work fine.",0,0.9823435544967651
216039681,5101,hzxa21,2018-09-07T17:55:27Z,make sense to me. will fix it.,0,0.8810514211654663
216044300,5101,hzxa21,2018-09-07T18:11:45Z,"in `oncontrollerresignation`, `controllercontext` will be reset. so here we need to keep the value before `oncontrollerresignation` and reuse it in deletion.",0,0.9889216423034668
216048155,5101,hzxa21,2018-09-07T18:25:39Z,yes. fixed.,0,0.9799623489379883
216048195,5101,hzxa21,2018-09-07T18:25:45Z,done.,0,0.9759407639503479
216048226,5101,hzxa21,2018-09-07T18:25:51Z,fixed.,0,0.9810503125190735
216049295,5101,lindong28,2018-09-07T18:30:20Z,thanks for the explanation. this makes sense.,1,0.6843767166137695
216049364,5101,lindong28,2018-09-07T18:30:36Z,this makes sense.,0,0.9669486284255981
216108832,5101,junrao,2018-09-07T23:23:46Z,": actually, i am wondering if it's simpler to replace lines 116-124 with a check that the ephemeral owner of the controller path equals to the zk session id (like we did before in checkedephemeralcreate()). the controller path or the controller epoch path could change after that check. but that's fine and will be handled by the next zk event on the controller path change.",0,0.9042732119560242
216150289,5101,hzxa21,2018-09-09T07:49:41Z,it is safe to replace the /controller payload check with session id check but we still need to read /controller_epoch to get back the corresponding zk version if we loss connection when doing the zk transaction.,0,0.9883679747581482
216521044,5101,junrao,2018-09-11T01:18:07Z,"hmm, to me, if the ephemeral owner of the controller path equals to the zk session id, it means that at that particular time, the controller path and the controller epoch path are created by the current zk session, and therefore the controller epoch used for creation should be valid. this seems to be equivalent as checking the value of the controller path and the controller epoch value. in both cases, after the check, the controller could change again. however, that will be handled by the zk watcher event.",0,0.9811815619468689
216524610,5101,lindong28,2018-09-11T01:45:34Z,"my understanding is that the approach using ephemeral owner has the same performance and correctness guarantee as the current approach which uses epoch from the znode data. the approach using ephemeral owner is probably more intuitive/readable because it exactly handles the root cause of `nodeexistsexception | _: badversionexception`, i.e. `checkcontrollerandepoch()` should effectively translate nodeexistsexception/badversionexception to `code.ok` if and only if `ephemeral owner of the controller path equals to the zk session id`. and it is also more consistent with the existing logic in `checkedephemeralcreate()`. if it sounds reasonable, maybe we can have a minor followup patch (without requiring a jira ticket) to improve it.",0,0.9693031311035156
216723540,5101,junrao,2018-09-11T15:57:24Z,"i was thinking that the ephemeral owner approach will be cheaper since we only need to read the controller path, not both controller path and the controller epoch path.",0,0.9675583243370056
216757532,5101,hzxa21,2018-09-11T17:41:08Z,"from the correctness and performance point of view, checking `/controller` payload and checking `/controller` ephemeral owner is the same. the question is whether we need to read `/controller_epoch`. the reason why i do it is because if `nodeexistsexception| badversionexception` happens, we no longer have the `stat` (new zkversion) of `/controller_epoch` even though the `/controller_epoch` update succeeds in zookeeper server. we can avoid the extra read on `/controller_epoch` if we can assume that zkversion is always incremented by one. since `/controller_epoch` zkversion is critical for us after this patch and zookeeper doc does not explicitly say that this assumption holds, i think it is safer to do one extra read during controller election.",0,0.8543752431869507
217395000,5101,junrao,2018-09-13T14:01:19Z,: that's a great point. thanks. then we can just keep the code as it is.,1,0.9860959649085999
263337259,6295,enothereska,2019-03-07T11:13:10Z,not clear from the kip why you need to keep track of both downstream and upstream offset.,0,0.9608013033866882
263338227,6295,enothereska,2019-03-07T11:16:00Z,looks like it's missing the methods like shouldcheckpointtopic. i'm assuming that is because this is still wip.,0,0.9179772138595581
263340233,6295,enothereska,2019-03-07T11:22:15Z,the methods here are slightly different from what was described in the kip but you're using the helper class to create adminclient so i'm on with it (as long as we update the kip at some point).,0,0.9874590635299683
263461244,6295,ryannedolan,2019-03-07T16:27:17Z,"the discussion so far has been about emitting upstream offsets and then translating them within remoteclusterutils. however, i've found it's just as easy for the checkpoints to be translated already, which drastically simplifies remoteclusterutils. i'm not certain both upstream and downstream offsets are really necessary here, but it's nice as a sanity check when tailing the checkpoint stream, at least.",0,0.9203964471817017
263462174,6295,ryannedolan,2019-03-07T16:29:15Z,i'll update the kip and call out the changes to the discuss thread prior to marking this ready-for-review.,0,0.984305739402771
263469394,6295,ryannedolan,2019-03-07T16:44:58Z,"i plan to remove those methods from the kip, for a few reasons: 1) the same logic is encoded in the config, for the most part. e.g. shouldcheckpointtopic is just combining the topic and group whitelists. if we already have those properties, it's best not to provide a second mechanism to redefine the behavior here. i think regexes are sufficiently powerful. 2) i want to enable using the same replication policy for both the connectors and the clients. the clients don't care about most of the methods in the kip, so it's best not to make a client define them. 3) i want replication policies to be pretty much static across an entire organization, not per-cluster. the organization decides what remote topics look like, and then all connectors and clients know how to interpret them. so anything related to specific topics or groups doesn't fit that goal. it's possible that replicationpolicy is no longer a good name for this, but i think it works.",0,0.8927146792411804
266605739,6295,williamhammond,2019-03-18T19:29:17Z,should non-replicated topics be filtered before being passed in potentially should this be an exception? in `mirrorclient#upstreamclusters` do we need to filter nulls similar to how `mirrorclient#replicationhops` needs to filter -1?,0,0.9855421781539917
266610210,6295,ryannedolan,2019-03-18T19:41:47Z,"thanks for the suggestion. i think it's reasonable to throw an exception here and in replicationhops(), but i'll need to add an additional method like hassource() or something. seems like a good trade to reduce magic numbers and nulls.",1,0.9567000269889832
269820527,6295,williamhammond,2019-03-28T00:27:21Z,shouldn't this be false?,0,0.9186363816261292
269831729,6295,ryannedolan,2019-03-28T01:45:38Z,thanks :),1,0.9818400740623474
271842542,6295,ryannedolan,2019-04-03T17:05:46Z,"update: i've broken the missing methods out into topicfilter, groupfilter, configpropertyfilter, instead of having them all in replicationpolicy. lmk what you think.",0,0.9848635792732239
272189918,6295,viktorsomogyi,2019-04-04T13:53:44Z,nit: i think it'd be better to keep this and the zkclient on info level as they might be useful in a troubleshooting scenario.,0,0.9667651653289795
272195234,6295,viktorsomogyi,2019-04-04T14:05:26Z,"have you considered using the protocol generator framework that is available for clients or would it make this more complicated than necessary? as i see you're simply using these messages as payload and they're not really protocol messages but we might gain something as they generate hashcode and equals methods. also, why are these (checkpoint, heartbeat) not protocol messages?",0,0.9817758202552795
272263389,6295,ryannedolan,2019-04-04T16:28:32Z,"will do, thanks",1,0.8670674562454224
272269172,6295,ryannedolan,2019-04-04T16:44:13Z,"as you say, these aren't really protocol messages, as they are not requests or responses, so i don't think the generator stuff would be a good fit here. maybe there are parts of it i could use. i suppose we could use json here as well. these are simple, unstructured records, so there isn't much to be gained from encoding in json, but it would be nice to get rid of some of this code.",0,0.9591530561447144
272558159,6295,kujon,2019-04-05T12:09:56Z,i'm wondering: what is the advantage of using `-1` over say `null` to represent no value?,0,0.9307151436805725
273276967,6295,ryannedolan,2019-04-08T23:31:34Z,that would work too. whatever is more conventional in kafka is fine with me.,0,0.800881564617157
274046687,6295,ryannedolan,2019-04-10T16:18:38Z,let's change to latency.,0,0.9840876460075378
274671893,6295,halorgium,2019-04-11T21:25:14Z,this needs the `security_protocol` added. [code block],0,0.9893186688423157
281541554,6295,viktorsomogyi,2019-05-07T09:14:22Z,as i understand this is a standard property of the connector config but i think it could be omitted in this case as we're always using mirrorsourceconnector. perhaps we can dynamically add this config in mirrormaker on creation time. or is it there because of the mirrorsinkconnector you'll create according to the kip?,0,0.9851022958755493
281572293,6295,viktorsomogyi,2019-05-07T10:47:32Z,"i think it would be safer to use the `await(long, timeunit)` method with a reasonable value (maybe taking it from a config) with both this one and with `startlatch` so we won't wait if the other thread died and never gonna count down.",0,0.9839498996734619
281855279,6295,ryannedolan,2019-05-07T22:35:30Z,thanks for catching! fixed.,1,0.9616977572441101
282122493,6295,ryannedolan,2019-05-08T15:33:19Z,"yes, mirrormaker fills this in for you normally. this config file is provided just for running mirrorsourceconnector in ""standalone mode"" as follows: ./bin/connect-standalone.sh config/connect-standalone.properties config/connect-mirror-source.properties i.e. without the top-level mm2 driver doing the work for you. organizations that already have a connect-as-a-service cluster will find this useful as well, as they may wish to leverage their existing cluster and just configure it to run the mm2 connectors.",0,0.9738934636116028
282141748,6295,ryannedolan,2019-05-08T16:16:57Z,"this latch is being used as a signal that stop() has been called, so we can't timeout here. but i've added a timeout to the shutdown hook and added a `finally` to ensure that stop() is called.",0,0.9876266121864319
282144470,6295,ryannedolan,2019-05-08T16:23:54Z,"i was able to drop this file entirely, and just use the existing connect-log4j.properties file. it's a little verbose that way, but no more so than connect-distributed.sh.",0,0.9054396748542786
284428968,6295,viktorsomogyi,2019-05-15T20:06:42Z,nit: exception is not thrown by anyone,0,0.9767773747444153
284431092,6295,viktorsomogyi,2019-05-15T20:12:24Z,"there is no clusters config, i think you should add `clusters=upstream`. i get an npe without it: [code block]",0,0.9856369495391846
284432272,6295,viktorsomogyi,2019-05-15T20:15:29Z,the adminclient requires a bootstrap.server property. would it make sense to pass either the source or the target's bootstrap.server property? [code block],0,0.9898291230201721
284433973,6295,viktorsomogyi,2019-05-15T20:20:06Z,also on a second note i think it'd be nice to give the users some meaningful error here.,0,0.9659119248390198
284434170,6295,viktorsomogyi,2019-05-15T20:20:36Z,what should be the real version?,0,0.9821364283561707
284443402,6295,viktorsomogyi,2019-05-15T20:45:39Z,"i would consider using `optional ` here and probably in other places in this interface too. these are interface methods, used in a bunch of places and i think it's better to enforce null checks in a safe way.",0,0.9827584624290466
284444200,6295,viktorsomogyi,2019-05-15T20:47:42Z,`.evolving` (and generally to all interfaces),0,0.9857140779495239
284446688,6295,viktorsomogyi,2019-05-15T20:54:18Z,distinct is not needed because of it'll be collected into a set.,0,0.9841895699501038
284446809,6295,viktorsomogyi,2019-05-15T20:54:38Z,not needed either.,0,0.9658166170120239
284447065,6295,viktorsomogyi,2019-05-15T20:55:22Z,this method doesn't seem to be used. what's the purpose?,0,0.9489278793334961
284447829,6295,viktorsomogyi,2019-05-15T20:57:31Z,nit: these are not thrown anywhere,0,0.9379691481590271
284448042,6295,viktorsomogyi,2019-05-15T20:58:06Z,"nit: could be made private, or is there a reason for this to be protected?",0,0.9825114607810974
284448576,6295,viktorsomogyi,2019-05-15T20:59:36Z,this method doesn't seem to be used.,0,0.9398366808891296
284450836,6295,viktorsomogyi,2019-05-15T21:05:45Z,nit: this doesn't seem to be used nor contains the required information.,0,0.9747371077537537
284453686,6295,viktorsomogyi,2019-05-15T21:13:32Z,"usually the kafka convention of internal topic notation is double underscore, such as `__topic-name`. i wonder if we'd should to apply this here too. also it seems to me that there internal topics are `mm2-offsets...`, `mm2-status...`, `mm2-offset-syncs` and `mm2-configs...` for the source and target clusters so we might be able just dynamically populate the topic blacklist for these and that way we'd probably leave the `.internal` notation. just putting this out for conversation.",0,0.9422367215156555
284455448,6295,viktorsomogyi,2019-05-15T21:18:55Z,"why do we need to throw `executionexception, timeoutexception` in these methods?",0,0.9779908657073975
284458764,6295,viktorsomogyi,2019-05-15T21:28:42Z,would it make sense to be the implementation of `org.apache.kafka.common.utils.scheduler`?,0,0.9882495403289795
284459118,6295,viktorsomogyi,2019-05-15T21:29:39Z,nit: `interruptedexception` is not thrown.,0,0.9606521725654602
284459418,6295,viktorsomogyi,2019-05-15T21:30:27Z,this doesn't seem to be used.,0,0.7894418835639954
284460793,6295,viktorsomogyi,2019-05-15T21:34:18Z,nit: this isn't actually used.,0,0.8833725452423096
284461711,6295,viktorsomogyi,2019-05-15T21:37:08Z,what should be the real version?,0,0.9821364283561707
284462552,6295,viktorsomogyi,2019-05-15T21:39:45Z,nit: these can be private,0,0.9866172075271606
284462956,6295,viktorsomogyi,2019-05-15T21:41:01Z,how much effort would be to expose this property? as far as i can tell all we need is to provide a config and then we'd be good to go.,0,0.8807917833328247
284463213,6295,viktorsomogyi,2019-05-15T21:41:53Z,nit: what is the real version? :),1,0.9485751986503601
284464247,6295,viktorsomogyi,2019-05-15T21:45:17Z,as i see this is assigned only in `start()` but i think just for the sake of clean code we should use a `final object` to lock.,0,0.9878330230712891
284464701,6295,viktorsomogyi,2019-05-15T21:46:34Z,nit: this is not used,0,0.9602260589599609
284464776,6295,viktorsomogyi,2019-05-15T21:46:47Z,nit: this is not used,0,0.9602260589599609
284523993,6295,kamalcph,2019-05-16T03:04:56Z,nit: unused variable.,0,0.9586113691329956
284524085,6295,kamalcph,2019-05-16T03:05:38Z,topic_filter_class_doc -> group_filter_class_doc,0,0.9808523058891296
284524187,6295,kamalcph,2019-05-16T03:06:13Z,unused variable.,0,0.9458374977111816
284524413,6295,kamalcph,2019-05-16T03:07:52Z,whether to include `__transaction_state` internal topic here?,0,0.9861364364624023
284524591,6295,kamalcph,2019-05-16T03:09:16Z,could you change the method name in symmetry to the topic name? (offsetsyncstopic()),0,0.9890851378440857
284524745,6295,kamalcph,2019-05-16T03:10:37Z,give a name to this scheduler to track it in threaddump.,0,0.9873243570327759
284524882,6295,kamalcph,2019-05-16T03:11:36Z,give a name to this thread.,0,0.9839304089546204
284525104,6295,kamalcph,2019-05-16T03:13:08Z,"once a lock is taken, no other operation should be done outside the try-catch block. call the `consumer.close()` either inside the try-catch or before taking the lock.",0,0.9886765480041504
284525159,6295,kamalcph,2019-05-16T03:13:30Z,unlock the taken lock.,0,0.9827303886413574
284525244,6295,kamalcph,2019-05-16T03:14:10Z,ie is not thrown. could you please remove the `throws ie`?,0,0.9875229001045227
284526932,6295,kamalcph,2019-05-16T03:26:01Z,consider taking the `lock` before the try-catch block as it's best practice.,0,0.9724746346473694
284611735,6295,kamalcph,2019-05-16T09:13:17Z,"you may have to update the description of the max, min and avg for record_age, replication_latency and checkpoint_latency metric name templates. (eg) the **maximum** age of incoming ...",0,0.9890519976615906
284612564,6295,kamalcph,2019-05-16T09:15:13Z,"`pause()` and `resume()` methods are unused. and, you can merge both these methods by taking action as a parameter.",0,0.9886646270751953
284613640,6295,kamalcph,2019-05-16T09:17:47Z,nit: pending todo.,0,0.9786398410797119
284614159,6295,kamalcph,2019-05-16T09:18:56Z,unused variable.,0,0.9458374977111816
284614303,6295,kamalcph,2019-05-16T09:19:17Z,unused variable.,0,0.9458374977111816
284614370,6295,kamalcph,2019-05-16T09:19:26Z,unused variable.,0,0.9458374977111816
284615520,6295,kamalcph,2019-05-16T09:22:05Z,it's better to unlock the taken lock.,0,0.9806126952171326
284648386,6295,arunmathew88,2019-05-16T10:48:23Z,"from my experience with large kafka clusters, one node being down for maintenance or so is very common, so for topics with more than one replica in source topic, we should have at least 2 replicas in destination, for the data to be realistically available in failover scenarios. just my thought.",0,0.8738611340522766
284898791,6295,ryannedolan,2019-05-16T21:07:51Z,"this config is for the mirrorsourceconnector alone, not a top-level mm2.properties file. the properties required in either case are distinct. i can see this is a source of confusion, so i'll add a comment here. i think maybe we need an example mm2.properties file as well.",0,0.9666844010353088
284899900,6295,ryannedolan,2019-05-16T21:11:03Z,"you're using the wrong config file (see above). you need something like: clusters = upstream, downstream upstream.bootstrap.servers = ... downstream.bootstrap.servers = ... then, the mirrormaker driver sets up a bunch of connectors with the required properties, which will look like the connect-mirror-source.properties here.",0,0.9386617541313171
284900808,6295,ryannedolan,2019-05-16T21:13:47Z,"i think optional is supposed to be used only within the context of the java 8 streams api. it's not unusual to return nulls in java, nor in this code base. (though coming from scala this hurts a bit :grinning_face_with_smiling_eyes:)",-1,0.7949186563491821
284945642,6295,ryannedolan,2019-05-17T00:41:48Z,"will fix, thanks.",1,0.9177144765853882
284947928,6295,ryannedolan,2019-05-17T00:59:12Z,"let's add min.insync.replicas here too, as this is likely to cause problems. h/t",0,0.9786074161529541
284948127,6295,ryannedolan,2019-05-17T01:00:47Z,"yeah let's blacklist anything with `__` prefix, thanks.",1,0.8073899745941162
284948535,6295,ryannedolan,2019-05-17T01:04:18Z,"yeah, herder requires an advertisedurl, tho we don't use it. i'll change this to `not used` to avoid confusion.",0,0.7369422912597656
284948676,6295,ryannedolan,2019-05-17T01:05:40Z,"we can drop these, thanks.",1,0.7101507186889648
284950066,6295,ryannedolan,2019-05-17T01:16:28Z,"i've left this as-is because it's convenient to test whether a topic has a source with `topicsource(topic) != null`, rather than to define and use a separate method like `hassource()` or something.",0,0.9784760475158691
284950514,6295,ryannedolan,2019-05-17T01:19:51Z,"`toset()` will throw an exception if it finds duplicates. this seems unlikely unless someone defines a really strange `replicationpolicy`, but i think it's worthwhile to avoid the exception just in case.",0,0.9787043333053589
284952693,6295,ryannedolan,2019-05-17T01:35:53Z,"this is just a convenience method, but i believe it is worthwhile. otherwise it is a bit cumbersome to recreate externally: [code block]",0,0.5359588861465454
284954715,6295,ryannedolan,2019-05-17T01:51:24Z,this is useful for external tooling.,0,0.9839173555374146
284957873,6295,ryannedolan,2019-05-17T02:16:00Z,"i think the `__` should be limited to topics internal to kafka proper. the topics `mm2-offsets...`, `mm2-status...`, and `mm2-config...` are based on connect's defaults, `connect-offsets`, `connect-config` etc, which are not internal per se. i've added .internal to these so that you don't need to configure mm2 to blacklist itself, thought it's an interesting idea to just blacklist them automatically.",0,0.7459782361984253
285062422,6295,enothereska,2019-05-17T10:08:44Z,the readme could be re-worded a bit to start with a quickstart simplest case and then build from there to increasingly more complex cases. this could be done at a later pass too.,0,0.9872879981994629
285063053,6295,enothereska,2019-05-17T10:10:54Z,could we add a sentence on what the implications of this are? it's not immediately clear what should happen if mm runs with same source and target...perhaps nothing at all?,0,0.9132179021835327
285063661,6295,enothereska,2019-05-17T10:12:45Z,should we check in such a sample file in the config folder?,0,0.9880946278572083
285064156,6295,enothereska,2019-05-17T10:14:12Z,nit: mm2.properties or mm2.config?,0,0.9874712824821472
285480888,6295,viktorsomogyi,2019-05-20T08:40:35Z,"yea that would be helpful, people could use it as a template.",0,0.8713799118995667
285488395,6295,viktorsomogyi,2019-05-20T08:57:43Z,"well, oracle's own example uses optional in the context of return values so i think it'd be idiomatic to do so: [a link] generally i agree that in this codebase we often return nulls but if you look at for instance the transactionmanager, it uses optionals this way, so i think it's definitely encouraged here too :) [a link]",1,0.9669718146324158
285507212,6295,viktorsomogyi,2019-05-20T09:42:38Z,on this note we probably want to document that it doesn't work for transactional topics (also as this was one of the first questions on the summit :) ),0,0.9133560657501221
285510919,6295,viktorsomogyi,2019-05-20T09:51:48Z,i think it would make sense to pass `true` (or use the single param super constructor). it helps debugging the config.,0,0.9805230498313904
285513326,6295,viktorsomogyi,2019-05-20T09:57:38Z,`type.list` would be better maybe?,0,0.984816312789917
285518598,6295,viktorsomogyi,2019-05-20T10:10:50Z,i'd like to make a general point but i didn't know any specific places so i'd put it here. it'd be helpful from the usability perspective to validate configs. i've tried to specify this config: [code block] you can notice that i put a `;` in the cluster separator config but nothing thrown an exception saying that i haven't specified the correct clusters (mm2 just started up and shut down).,0,0.9272323250770569
285562725,6295,viktorsomogyi,2019-05-20T12:21:22Z,we might pass `true` if that makes sense.,0,0.9857162833213806
286460327,6295,viktorsomogyi,2019-05-22T12:22:07Z,nit: maybesendoffsetsync?,0,0.9858075380325317
286465012,6295,viktorsomogyi,2019-05-22T12:34:12Z,i was wondering if - would it make sense to make this configurable? - wouldn't this be mostly the same as configuring the `max.in.flight.requests.per.connection` property of the `offsetproducer` and have you thought about using just that config?,0,0.9702119827270508
286471163,6295,viktorsomogyi,2019-05-22T12:48:53Z,i think it would be better to use some timeout here as it spams the log with the below warn message.,0,0.9848390817642212
286475429,6295,viktorsomogyi,2019-05-22T12:58:11Z,as far as i understand offsets would be synced eventually so i think we might want to reconsider if this is a warn level log message (maybe even lower it to debug?).,0,0.9867953062057495
286585537,6295,jeremy-l-ford,2019-05-22T16:41:55Z,should the returned classloader be restored at the end of the method?,0,0.9877558946609497
286638392,6295,harshach,2019-05-22T18:58:03Z,there seems to be null some places and other places -1. if possible can we standardize or leave a comment.,0,0.9853449463844299
288238131,6295,jeremy-l-ford,2019-05-28T18:17:28Z,"i have been testing this branch and used the connector.class option noted above in my configuration. i noticed that records were being copied 3x instead of the expected 1. debugging through the source, apparently that configuration will override the connector name that is setup during mirrormakerconfig.connectorbaseconfig. since mirrormaker attempts to setup the source, health, and checkpoint connectors, i actually ended up with 3 source connectors.",0,0.9819559454917908
288280080,6295,ryannedolan,2019-05-28T20:07:25Z,"-l-ford funny problem! i think this, along with others' experiences here, indicates i need to remove this sample configuration altogether, and just provide a top-level configuration file like in the ""quick start"" above. the connector configuration is just confusing. moreover, it doesn't really demonstrate anything beyond the existing generic connect-standalone.properties file. i'll remove this file, thanks.",-1,0.8853820562362671
289196474,6295,OneCricketeer,2019-05-30T22:26:56Z,"related to i assume with the addition of record header copying, it will also only work for when `log.message.format.version` >= `0.11.0` ? at least, we've noticed that when clients try to use headers (or transactional producers) after broker upgrades, but before log format changes, then they are usually throwing `unknownserverexception`. --- one workaround i did (for an smt) was to conditionally copy the headers to the transformed record. e.g. [a link]",0,0.9834704995155334
289495296,6295,jeremy-l-ford,2019-05-31T18:03:55Z,try/finally close the consumer,0,0.9820366501808167
290088869,6295,ryannedolan,2019-06-04T00:36:16Z,let's just remove the log message altogether.,0,0.983889102935791
290090082,6295,ryannedolan,2019-06-04T00:43:44Z,"i'm not certain, but the other drivers (connect-standalone, connect-distributed) do it this way. i'll just cargo-cult here.",0,0.9795103669166565
290369229,6295,ryannedolan,2019-06-04T15:50:36Z,"my intention is to support 0.11.0 onwards, at least for now. we can revisit making headers optional to support older versions, but i think this probably isn't the only thing that would break before 0.11.0.",0,0.9800017476081848
290371819,6295,ryannedolan,2019-06-04T15:55:40Z,i dropped this file to avoid confusion.,0,0.9636666178703308
290372405,6295,ryannedolan,2019-06-04T15:56:58Z,"this method doesn't contain a conditional branch (the existing maybesendoffsetsync does), so i'll leave this as is.",0,0.9863135814666748
290372816,6295,ryannedolan,2019-06-04T15:57:53Z,"i dropped the logging entirely. there is no harm if tryacquire fails, so better to not spam the log as you say.",0,0.9727166295051575
290407619,6295,ryannedolan,2019-06-04T17:22:51Z,"fixed. this was b/c mm was finding only a single cluster (""upstream;downstream"") and had no source->target pairs to replicated. i've added an exception ""no source->target replication flows"" in this case, which should at least point you in the right direction.",0,0.9873550534248352
291329247,6295,vpernin,2019-06-06T19:06:16Z,is this intended to not set the interrupted flag again ? same question elsewhere like in mirrorsourcetask.cleanup().,0,0.9584857821464539
291333700,6295,vpernin,2019-06-06T19:19:28Z,is there a risk the semaphore not to be released if the async send fails internal before invoking this callback ?,0,0.9568745493888855
291354482,6295,vpernin,2019-06-06T20:19:21Z,"the underlying client method seems to use a default timeout of long.max_value, timeunit.milliseconds. i'm worried that it can prevent the jvm to stop ?",-1,0.8704021573066711
291590085,6295,vpernin,2019-06-07T13:24:28Z,the kip seems to refresh.topics is true by default. the property refresh_topics_enabled is named refresh.topics.enabled and the default does not seem to be refresh_topics_enabled_default used. so the topics are not refreshed by default.,0,0.9863974452018738
291660048,6295,ryannedolan,2019-06-07T16:11:37Z,the default is set here: [a link] and used here: [a link] i've verified this works as expected. happy to take suggestions if this is not clear.,1,0.9776688814163208
291839414,6295,williamhammond,2019-06-09T14:58:07Z,don't we need a catch for `org.apache.kafka.common.kafkaexception` as well when calling `consumer.close()`?,0,0.9867863059043884
291840811,6295,williamhammond,2019-06-09T15:44:07Z,i feel like i must be missing something obvious but since the source admin client will be an instance of `kafkaadminclient` since we're calling `[a link] to create the client and the `kafkaadminclient` overrides close as such [a link] are we not actually releasing resources but calling close without a duration? i'm probably misremembering something about inheritance but either way i think we should be passing in a duration here since the default close just is kind of odd vpernin pointed out.,-1,0.8886860609054565
296221720,6295,jeremy-l-ford,2019-06-21T12:51:34Z,"based on [a link] seems like the consumer may be null when attempting to close it. also, should the call to close the producer be in a separate try/catch to at least attempt to close the producer in the case where closing the consumer causes an exception?",0,0.9568275809288025
297175786,6295,vpernin,2019-06-25T13:03:58Z,"you're right. i might miss something obvious, but the propagation of topic creation on downstream cluster does not seem to work. the mirrorsourceconnector.refreshtopicpartitions detects a new topic properly and and it requests a task reconfiguration. but the code that really proceed to the topic creation seems to be in mirrorsourceconnector.createtopicpartitions and this task is only executed once at startup and not at the reconfigure phase.",0,0.9248084425926208
298207543,6295,vpernin,2019-06-27T14:30:17Z,"shouldn't we have a check on the enabled status of the herder like b->a.enabled = false ? with a simple setup enabled on the a->b direction and disabled on the b->a, i see that the herder b->a is created and heartbeats are emitted to cluster[a].topic[heartbeats], to its replicated on cluster[b].topic[a.heartbeats] and also on cluster[b].topic[heartbeats].",0,0.9866952896118164
298289975,6295,arunmathew88,2019-06-27T17:34:21Z,"as per the kip the mirrored topic should be writable by mirror maker only, how is this ensured? i couldn't find a filter rejecting any write acls to the topic in this call?",0,0.9831483364105225
298543696,6295,vpernin,2019-06-28T10:37:46Z,"shouldn't we have a public way to deserialize heartbeat object, heartbeat.deserializerecord not being public ?",0,0.9467373490333557
299083439,6295,ryannedolan,2019-07-01T14:55:06Z,"this behavior is subtle but correct. we want heartbeats going everywhere, even to clusters that aren't a target of any source->target replication. this is because we need heartbeats to exist upstream in order to replicate them downstream. if we are replicating a->b, we don't want to emit heartbeats only to b -- that wouldn't really tell us much, except that mm can send to b. what we want to know is how long it takes records to travel from a to b. so we emit heartbeats to a and _replicate them_ to b. this lets us monitor latency between a and b even when no other records are being replicated. specifically, we create herders between every pair of clusters (a fully-connected mesh) and emit heartbeats everywhere. then, for the subset of ""enabled"" replications, we start at least one mirrorsourceconnector task. these tasks _always_ replicate heartbeats, so the result is ""a.heartbeat"" in cluster b whenever a->b is enabled. we could _only_ emit records upstream (i.e. only to sources and not targets) and achieve this same result, but heartbeats are useful for more than measuring cross-cluster latency. emitting heartbeats everywhere makes various other tooling possible. for example, you can query any single cluster and find out about every other cluster just by consuming the heartbeat topic, since heartbeats will have come from everywhere.",0,0.9594384431838989
299085902,6295,ryannedolan,2019-07-01T14:59:43Z,i'm fine with that.,0,0.9388526678085327
299213804,6295,ryannedolan,2019-07-01T20:55:04Z,connector.reconfigure() by default just calls stop() and start(config). there is no other logic related to reconfiguration at present.,0,0.9876882433891296
299324123,6295,vpernin,2019-07-02T06:45:34Z,"ok, i understand this conception. maybe, this clear explanation has its place in the kip and the documentation.",0,0.9792519211769104
299339279,6295,vpernin,2019-07-02T07:32:33Z,"i'm just noticing, that in my case, the creation of a new topic (matching replication pattern) upstream is not propagated downstream. the subject of the reconfigure process is just a attempt to explain the problem. kmm2 need to be restarted, so mirrorsourceconnector.createtopicpartitions is called. connector.reconfigure() does indeed stop and start, which would work, but this is not invoked. we call context.requesttaskreconfiguration() and it does not do that.",0,0.9376348257064819
308616567,6295,o-kasian,2019-07-30T09:16:29Z,"this should probably be `this.herderpairs = config.enabledclusterpairs().stream()`, otherwise `a->b.enabled` makes no sense",0,0.975548267364502
308690793,6295,o-kasian,2019-07-30T12:27:26Z,"`kafka/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/mirrorsourceconnector.java:106` offset sync topic is created in `target`, however offsetproducer uses `config.sourceproducerconfig()` it results in messages like `error while fetching metadata with correlation id 416 : {mm2-offset-syncs.backup.internal=unknown_topic_or_partition}` in logs, and is not able to write offset mappings",0,0.9798362255096436
308953520,6295,ryannedolan,2019-07-30T21:35:28Z,"good catch, thanks!",1,0.9874116778373718
308954111,6295,ryannedolan,2019-07-30T21:37:07Z,see this earlier comment: [a link] i'll add a comment in the code somewhere to explain.,0,0.9864505529403687
310134951,6295,mimaison,2019-08-02T13:37:55Z,`record.value()` can be null here. this leads to [a link],0,0.9876170754432678
310137707,6295,mimaison,2019-08-02T13:44:46Z,"the order of the arguments is inverted, `(short) 1` should be the 2nd argument and the replication factor the 3rd one. the prototype is `createtopic(string topicname, short partition, short replicationfactor, map adminprops)`",0,0.987748920917511
310138665,6295,mimaison,2019-08-02T13:46:59Z,"the order of the arguments is inverted, `(short) 1` should be the 2nd argument and the replication factor the 3rd one. the prototype is `createtopic(string topicname, short partition, short replicationfactor, map adminprops)`",0,0.987748920917511
311630254,6295,mimaison,2019-08-07T15:50:11Z,"should this use `config.sourceadminconfig()` instead of `config.targetadminconfig()` ? otherwise, i'm getting: [code block] and the topic is only created in the target cluster.",0,0.9879777431488037
311789488,6295,ryannedolan,2019-08-07T22:29:05Z,"fixed, thanks",1,0.882018506526947
311789612,6295,ryannedolan,2019-08-07T22:29:31Z,"fixed, thx",0,0.9780348539352417
311790132,6295,ryannedolan,2019-08-07T22:31:41Z,"fixed, thx",0,0.9780348539352417
312966989,6295,mimaison,2019-08-12T14:53:36Z,`x.getkey()` is the topic name. we need to iterate over `topicconfigs.values().entries()` instead to filter out topic properties.,0,0.987179160118103
312967159,6295,mimaison,2019-08-12T14:53:56Z,should we also filter configs with `static_broker_config` as the source?,0,0.9886417984962463
314489069,6295,ryannedolan,2019-08-15T20:41:47Z,"i dropped the enabledclusterpairs() method, so marking this resolved.",0,0.9890221357345581
314559556,6295,ryannedolan,2019-08-16T01:52:52Z,great catch! i've fixed and added a unit test.,1,0.9931915402412415
314801873,6295,ryannedolan,2019-08-16T16:46:05Z,i _think_ isdefault() will catch that case? not sure.,0,0.9699525237083435
314809527,6295,mimaison,2019-08-16T17:08:11Z,`isdefault()` only matches `configsource.default_config`. see [a link],0,0.9863578081130981
314812870,6295,ryannedolan,2019-08-16T17:17:16Z,"ah, thanks . fixed.",1,0.9044304490089417
317319292,6295,ryannedolan,2019-08-23T22:20:08Z,we never block on the semaphore -- only trywait() -- so there is no chance of deadlocking at least. i don't think there is any other consequence if we don't get around to releasing a semaphore.,0,0.9310464262962341
317335237,6295,ryannedolan,2019-08-24T00:15:52Z,"do you mean to implement the ..utils.scheduler interface here, or to instead use the internal kafka.utils.kafkascheduler? the latter would work just fine, but i'm reluctant to depend on something in kafka.utils.",0,0.9644923806190491
317342841,6295,ryannedolan,2019-08-24T03:22:37Z,"fixed, thx",0,0.9780348539352417
317343051,6295,ryannedolan,2019-08-24T03:30:54Z,"it's hard to imagine a case where you'd need to tweak this property. i guess if you had offsets.lag.max set to zero, which means every replicated record would cause an offset sync, then you'd run up against the max outstanding offset syncs limit pretty quick. but i don't know why you'd do that. normally offset syncs are very sparse, and it never matters if you drop a few occasionally. so this is mostly an arbitrary number, and anything greater than 0 will work fine.",0,0.9223586320877075
317346004,6295,ryannedolan,2019-08-24T05:39:36Z,"fixed, thx",0,0.9780348539352417
317346028,6295,ryannedolan,2019-08-24T05:41:12Z,"thanks guys, this does seem like a problem. fixed by adding a configurable timeout.",1,0.9089357256889343
323912773,6295,qihongchen,2019-09-12T19:31:32Z,"there's no argument for `""metatadata=%s""`, it should be removed, or add an argument for it (correct the typo as well).",0,0.9881730675697327
326590142,6295,dataGeeek,2019-09-20T11:43:38Z,"knowntargettopics state is currently only refreshed at two occasions: * startup of the connector, before topics in downstream cluster are created and therefore stays empty * new partitions/ dead partitions in upstream cluster are found. in the case of no creation of new partitions in upstream cluster, the state remains empty, which blocks config syncing, since only configs of knowntargettopics will be synced. i propose refreshing the state of knowntargettopics at startup after topics in downstream cluster are created and have provided a pr: [a link]",0,0.9686745405197144
327205321,6295,ryannedolan,2019-09-23T16:15:16Z,great find! merged.,1,0.9905530214309692
327276472,6295,dataGeeek,2019-09-23T18:56:10Z,"your're welcome! besides that, our tests of the mm2 were very promising. great work and lgtm",1,0.9926853179931641
328867657,6295,junrao,2019-09-26T23:41:46Z,"hmm, why do we need to call commitrecord twice?",0,0.9780676960945129
328867839,6295,junrao,2019-09-26T23:42:42Z,should we version the value schema for potential future extension? ditto is other newly added schemas.,0,0.9863907098770142
328867958,6295,junrao,2019-09-26T23:43:24Z,could we add the javadoc for each of the public method in this and other user facing classes?,0,0.988716721534729
328867995,6295,junrao,2019-09-26T23:43:34Z,is it useful to have a metric that just captures the lag of the current record?,0,0.9844575524330139
328868071,6295,junrao,2019-09-26T23:43:57Z,should we add max in the description? ditto in a few other places.,0,0.9288934469223022
328868144,6295,junrao,2019-09-26T23:44:25Z,"hmm, the downstream offset doesn't alway advance faster than the upstream. for example, when mirroring a compacted topic, the downstream offset could advance slower than upstream when the upstream offsets have holes.",0,0.9715858101844788
328868189,6295,junrao,2019-09-26T23:44:40Z,"hmm, how do we make sure that the latest offset in offsetsyncstore match what's needed for the consumer offset?",0,0.9821507930755615
328868228,6295,junrao,2019-09-26T23:44:51Z,do we need debug by default? it could slow down the tests on jenkins.,0,0.9882716536521912
328868442,6295,junrao,2019-09-26T23:46:06Z,calling system.currenttimemillis() on every record could be expensive.,0,0.9342790842056274
328868644,6295,junrao,2019-09-26T23:47:12Z,should we update lastsyncupstreamoffset and lastsyncdownstreamoffset only after the offsets have been successfully written to the offset sync topic?,0,0.9894578456878662
328868859,6295,junrao,2019-09-26T23:48:22Z,should offsetsync topic always be single partition?,0,0.9887464642524719
328869797,6295,junrao,2019-09-26T23:53:43Z,should we replicate prefix acls too?,0,0.988229513168335
329268348,6295,ryannedolan,2019-09-27T22:13:48Z,"offset syncs (and checkpoints and heartbeats) are sparse and rare in practice, so this topic is very small. it's only written to when the upstream and downstream offsets for a partition don't match what is expected, which is approximately as rare as duplicate records being sent to a topic. mm2 can run for days without sending a message here. so there isn't a need to have multiple partitions, and doing so would complicate the logic for scanning the topic for a given offset, to some extent.",0,0.8049567937850952
329268969,6295,ryannedolan,2019-09-27T22:15:59Z,"good point, will fix.",1,0.9518482089042664
329274932,6295,ryannedolan,2019-09-27T22:46:42Z,"yes that would be useful, however, not nearly as useful as latency of each record, since latency is more easily aggregated over entire topics (and, externally, over entire clusters), and is much more relevant to the operator. consider that an mm2 operator would not know how to compare a lag of 100 offsets in one partition to a lag of 1 offset in another partition, as they could both represent <1s behind real-time, depending on the size of messages etc. so while offset lag may be very useful to an operator of a specific app consuming from specific topics, it is unlikely useful to an mm2 operator replicating entire clusters.",0,0.9664116501808167
329277034,6295,ryannedolan,2019-09-27T22:59:00Z,"a sourcetask implementation is unlikely to implement both methods. they are nops by default. if it does, it's unlikely an implementation would do the same thing in both methods. if it does, the interface does not guarantee that commitrecord() is called exactly once per record anyway (or even at least once). and indeed other methods, e.g. stop() and commit(), make no such guarantees either. i'd be in favor of deprecating commitrecord(record) to avoid confusion here, but that is out of scope for this kip and pr.",0,0.8945149183273315
329835717,6295,ryannedolan,2019-10-01T00:07:02Z,done,0,0.9764507412910461
329835749,6295,ryannedolan,2019-10-01T00:07:10Z,done,0,0.9764507412910461
329835788,6295,ryannedolan,2019-10-01T00:07:20Z,done,0,0.9764507412910461
329835885,6295,ryannedolan,2019-10-01T00:07:49Z,done,0,0.9764507412910461
329863044,6295,ryannedolan,2019-10-01T03:00:19Z,"good idea, this would improve accuracy of the offset syncs and checkpoints. i've made this change locally and don't see any problems. however, i'd rather not make a functional change this close to a code freeze. let's make this improvement in a short follow-up pr.",0,0.5733123421669006
330097541,6295,junrao,2019-10-01T14:42:48Z,"since this is a public api change, i think it's important to think through the impact to connector developers. i am thinking that we can (1) provide a default implementation of commitrecord(sourcerecord record, recordmetadata metadata) in sourcetask that calls commitrecord(sourcerecord record) by ignoring recordmetadata to provide backward compatibility; (2) only use commitrecord(sourcerecord record, recordmetadata metadata) in workersourcetask; (3) mark commitrecord(sourcerecord record) as deprecated to encourage people to use the new api and document the behavior if both methods are implemented (the implementation for the old api will be ignored). any thought on this?",0,0.9388659000396729
330130857,6295,rhauch,2019-10-01T15:41:22Z,"so far, the connect api exposes only a few kafka client types in a few areas (right now just `sinktask`). we should be careful and explicit about making the `sourcetask` interface use `recordmetadata`. but assuming that's okay, i think having connect call two distinct `commitrecord(...)` methods with different signatures is at best confusing for developers (which do i implement) and at worst a potential source of error. we have resolved similar evolutions in the past by following the approach that mentioned, and i think that makes the most sense here. (we've not always deprecated the older method when it still applicable, but in this case i think we'd want to deprecate the older method.) however, before we introduce a new variant of an existing method, we should also consider whether we might need to again modify the signature in the future. if so, we should consider whether it makes sense to create a new interface type to pass to the method that would make it easier in the future. i'm not sure that we do, since the `workersourcetask` calls this from within the producer callback and only when the exception is not null, meaning there currently is no other data available to the invocation.",0,0.9515377283096313
330134311,6295,rhauch,2019-10-01T15:47:50Z,this pr probably needs to mention it is also implementing kip-416.,0,0.9876633286476135
330137341,6295,ryannedolan,2019-10-01T15:53:53Z,happy to deprecate the older method if we have concensus here.,1,0.8548126220703125
330149902,6295,ewencp,2019-10-01T16:20:22Z,"given we can use default implementations now, just providing a default implementation and not deprecating seems better. afaik, `recordmetadata` has never been requested before, but a number of connectors use the existing signature for `commitrecord`. calling twice and having to understand that does seem confusing, but having overloads and simplified versions doesn't -- you just get to choose to implement something simpler. we've been pretty conservative with deprecation in the connect and that has served us well wrt broad compatibility -- i think only `onpartitionsassigned/revoked` for sink tasks and a couple of configs have gone through this, and still haven't been removed (with little maintenance cost afaik), which means we've remained cleanly compatible in most ways all the way back to 0.9. i'm generally for deprecation and removal (e.g. there's lots of core configs that i think are unnecessary and could be cleaned up), but only if the cost is worth it. in this case, there *is* a transition cost since the existing api is being used, and i'm not sure the reduction in confusion is worth it (vs some simple api docs explaining default impl).",0,0.8212293982505798
330154422,6295,rhauch,2019-10-01T16:30:30Z,"good point about not deprecating, . i could definitely go either way, and definitely see value in not deprecating and leaving it up to the implementer to choose which they'd implement. but i do think overriding one method is better than having to potentially override both methods for different purposes. because this is changing the connect api, it does seem like we need to come to consensus and approve kip-416 before this pr can be merged, though.",1,0.5586310029029846
330162479,6295,ryannedolan,2019-10-01T16:49:07Z,"that would be neat, but there are landmines here. we don't want a prefix pattern to accidentally apply to topics on another cluster, so we can't just copy prefixes across. we could maybe expand a prefix ""foo"" on cluster ""primary"" to an equivalent ""primary.foo"" prefix, but that would only work if replicationpolicy used something like the default topic renaming convention -- a custom naming convention like ""topic-dc1"" would not work with prefixes this way. we could maybe find all prefix patterns and replicate them as explicit literal patterns. so a prefix of ""foo"" turns into literals ""primary.foo-1"", ""primary.foo-bar"", etc. but even that is a little dangerous, as it is not easily reversible. for example, what happens when an upstream prefix acl is deleted? if there is a safe way to do this, i haven't thought of one yet. we should stick with literals only for now.",0,0.9394686818122864
330168213,6295,ryannedolan,2019-10-01T17:01:31Z,"my vote is for keeping both methods (as implemented here), since this doesn't break or deprecate existing code, nor is it especially confusing to see the same method with overloaded parameters in an interface, especially when neither are required to implement. i think the confusing part is just in the workersourcetask implementation, not the sourcetask interface -- it's a little surprising to see the same method called twice here. i suggest we add a comment here and move on. thoughts?",0,0.7354393601417542
330203738,6295,ryannedolan,2019-10-01T18:20:07Z,"done, thanks.",1,0.727206826210022
330206785,6295,AndrewJSchofield,2019-10-01T18:26:49Z,"i'd prefer to see kip-416 introduce `public void commitrecord(sourcerecord sourcerecord, recordmetadata recordmetadata)` which is called in exactly the same situations as the existing `public void commitrecord(sourcerecord sourcerecord)`. the new method might be called with null record metadata. the implementor has a choice of which to implement.",0,0.9877675771713257
330209568,6295,rhauch,2019-10-01T18:32:48Z,", i disagree that the confusing part is just in the `workersourcetask` implementation. i believe it is confusing that both methods might be called with the same record, and that there is no benefit from doing that. so the issue i have is that i believe the proposed changes to the connect api make it less clear how to properly implement it. it is much clearer for the api to offer two methods and to say the framework always calls the new one, the new one by default calls the old one, and that task implementations can override one or none of them. then it is entirely up to the task implementation to decide whether to even treat these conditions as distinct.",-1,0.789858877658844
330213298,6295,ryannedolan,2019-10-01T18:41:02Z,"just clarifying, are you suggesting we take 's suggestion, except we don't deprecate the existing method? i.e. have the new method call the old? does that satisfy your concern as well?",0,0.9556509852409363
330304627,6295,rhauch,2019-10-01T22:28:58Z,", yes, i am suggesting that we follow 's suggestion minus deprecating the old method. iow, we'd do the following: 1) add the new method that by default calls the old method; and 2) change all uses in the connect runtime (namely in workersinktask and its test class) to use the new method and update kip-416 accordingly.",0,0.9854267835617065
330323913,6295,ryannedolan,2019-10-01T23:50:39Z,sounds like we have concensus. will update shortly.,0,0.9742327928543091
330852160,6295,ryannedolan,2019-10-03T03:33:55Z,i made the change. happy with either approach.,1,0.8720129728317261
331279220,6295,junrao,2019-10-03T22:24:15Z,could we add some comments to make it clear that one only needs to implement one of the commitrecord()?,0,0.9873459935188293
331279346,6295,ryannedolan,2019-10-03T22:24:53Z,"agree, there is room for improvement here. an obvious improvement would be to track latency only for the last record in each batch. i can address this in a later pr.",0,0.963279664516449
331283010,6295,ryannedolan,2019-10-03T22:40:15Z,"we don't use the offsetsyncstore's offsets until we create a checkpoint. if the offsets are invalid or too far behind (-1 here), the checkpoint is not emitted for that topic-partition. so a downstream consumer would see an older checkpoint record for that topic-partition, which in turn was computed from a previous (valid) offset-sync. when replication first starts, there will be no checkpoints. once offsetsyncstore is primed with offset-offset pairs, checkpoints will be emitted. if, say, mm2 fails to send to the offset-syncs topic for whatever reason, there will be no checkpoints until this process succeeds. both offset-syncs and checkpoints are ""opportunistic"" in the sense that it is never _essential_ that they are sent at any given point in time in order for downstream consumers to be correct. so we only send them when we are in a good state and have enough information to send a valid checkpoint.",0,0.9831873774528503
331283663,6295,ryannedolan,2019-10-03T22:43:07Z,"yes, this is actually handled here. any holes upstream will trigger an offset-sync immediately. if such an offset-sync _fails_, for whatever reason, it just means that a checkpoint will not be emitted until the next sync... generally a few seconds later. i'll call out a unit test that shows this in action.",0,0.9855713844299316
331284770,6295,ryannedolan,2019-10-03T22:47:52Z,"holes in a compacted topic are handled, as shown here.",0,0.9838768839836121
331301537,6295,junrao,2019-10-04T00:10:16Z,"unused exceptions interruptedexception, timeoutexception. also, does this test cover anything more than the previous test?",0,0.986504316329956
331494794,6295,omkreddy,2019-10-04T13:16:35Z,"we need to include javadocs section for newly added public interfaces/classes. example: [a link] i assume, we will be adding kafka website documentation as part of kafka-8930. [a link] also looks like test failures are related.",0,0.9788394570350647
331577566,6295,ryannedolan,2019-10-04T16:08:07Z,"ah thanks i'll fix the javadocs this morning. for the website documentation, we'll need to keep the existing mirror-maker section for now, but i'll add a section re mm2, probably in a separate pr. the failing tests seem to be related to flakiness in the connect integration test framework. i'll see what i can do.",1,0.9364230632781982
331732524,6295,ryannedolan,2019-10-05T04:44:20Z,"fixed. in the second test, additional topics are added, detected, and replicated. detecting new topics will trigger a task rebalance in the middle of the test, which doesn't happen in the first. granted, it might make sense to collapse these into a single test rather than bring up and tear down the clusters twice.",0,0.9829283952713013
331732663,6295,ryannedolan,2019-10-05T04:49:34Z,added a couple lines locally. will hold on to the commit for now -- i don't want to trigger another build at the moment.,0,0.9305837154388428
331746988,6295,rhauch,2019-10-05T13:37:45Z,", we need to clearly specify that `metadata` parameter can be null, and then in the javadoc above specify what this means for the source task, namely that a transform dropped/skipped the record and it was not written to kafka. imo this is necessary so that developers of connector implementations know what the behavior is so they can properly implement their task. (the javadoc was not in [a link] i also think that it's also worth mentioning here that `sourcetask` implementations need only implement this method *or* the older `commitrecord(sourcerecord)` *or* neither method, but that generally they do not need to implement both since connect will only call this method. again, this will help developers that are implementing their own `sourcetask` what they need to do.",0,0.9784213304519653
331750101,6295,ryannedolan,2019-10-05T15:15:01Z,i improved the javadocs further. should be clear now.,0,0.9690395593643188
331750119,6295,ryannedolan,2019-10-05T15:15:46Z,i collapsed the two integration tests into one -- seems to save 30 seconds or so.,0,0.9560127258300781
331795997,6295,ijuma,2019-10-06T15:42:24Z,is there a reason why this is not using the `time` interface? we generally never use `system.currenttimemillis()` in kafka.,0,0.9825489521026611
331800260,6295,ryannedolan,2019-10-06T17:14:55Z,"good idea, we should replace these in a subsequent pr.",1,0.9406134486198425
381865765,6295,amanullah92,2020-02-20T09:06:17Z,"this directive (a->b.enabled) is missing in kip in the ""running mirrormaker in production section""-- i got the cluster up but no replication was happening. until i saw this and fixed this. i am new to mirrormaker/connect framework- forgive me if this is a well known thing.",0,0.8235635757446289
526479473,9485,rajinisivaram,2020-11-18T22:58:26Z,we should document what this default implementation does and why a custom implementation may want to override this default.,0,0.9830960035324097
526479478,9485,rajinisivaram,2020-11-18T22:58:26Z,we should document what this default implementation does and why a custom implementation may want to override this default.,0,0.9830960035324097
526481573,9485,rajinisivaram,2020-11-18T23:03:40Z,nit: indentation,0,0.9879170060157776
526482899,9485,rajinisivaram,2020-11-18T23:07:07Z,"this looks identical to the code block above for prefix, we could just run the same code in a loop that checks both allow literals and prefixes.",0,0.9860419631004333
526483476,9485,rajinisivaram,2020-11-18T23:08:45Z,we should have exactly one call to `logauditmessage` that says whether access was allowed or denied.,0,0.9881426692008972
526486028,9485,rajinisivaram,2020-11-18T23:15:24Z,"request.principal can be a custom extension of kafkaprincipal, we cannot use tostring for comparison",0,0.9884004592895508
526487176,9485,rajinisivaram,2020-11-18T23:18:26Z,not sure it is worth making a whole copy of this structure for a method that is not used frequently. it will be good to add microbenchmarks to `aclauthorizerbenchmark` to understand how the new method performs.,0,0.9720954298973083
526487761,9485,rajinisivaram,2020-11-18T23:19:56Z,"same as in the authorizer default method, we cannot use request.principal().tostring()",0,0.9887648820877075
526489152,9485,rajinisivaram,2020-11-18T23:23:54Z,"we should optimize for the case where there are no deny acls. there is no point in finding all matching allow entries in that case, we would just need to check for one allow.",0,0.9869317412376404
526494014,9485,rajinisivaram,2020-11-18T23:37:05Z,make this all the methods below `private`,0,0.9877196550369263
526494298,9485,rajinisivaram,2020-11-18T23:37:54Z,we coul just inline all the methods below instead of separate methods for host etc.?,0,0.9893020987510681
526495928,9485,rajinisivaram,2020-11-18T23:42:06Z,"hmm, produce s authorized for topic anyway. why would we use a very expensive authorizebyresourcetype here?",0,0.9726022481918335
526496224,9485,rajinisivaram,2020-11-18T23:42:56Z,"first authorize should use `logifallowed=true`, `logifdenied=false`",0,0.9885127544403076
526496998,9485,rajinisivaram,2020-11-18T23:44:48Z,`durability`?,0,0.9841708540916443
526499159,9485,rajinisivaram,2020-11-18T23:50:40Z,it may be better to put the mock tests into another test class. that wouldn't request zookeeper for example.,0,0.9874114394187927
526499504,9485,rajinisivaram,2020-11-18T23:51:38Z,"as before, references to durability in authorizer tests are confusing.",-1,0.5689426064491272
526500688,9485,rajinisivaram,2020-11-18T23:54:50Z,are we going to add tests here?,0,0.9837069511413574
526502000,9485,rajinisivaram,2020-11-18T23:58:19Z,we should run the microbenchmarks in aclauthorizerbenchmark to make sure we don't add too much overhead here.,0,0.984078049659729
526503975,9485,rajinisivaram,2020-11-19T00:03:44Z,don't we reuse this in multiple tests? how do we guarantee that no state is preserved between tests?,0,0.970197856426239
526504244,9485,rajinisivaram,2020-11-19T00:04:32Z,we could mock this fully instead of using aclauthorizer?,0,0.9837806224822998
526504251,9485,rajinisivaram,2020-11-19T00:04:33Z,we could mock this fully instead of using aclauthorizer?,0,0.9837806224822998
529008307,9485,ctan888,2020-11-23T21:29:27Z,"yeah, that's right. construct a kafkaprinciple instance with params referred from principal.gettype() and getname() commit 89df4d7600cad4e3785d0d95624d0918efce1f44",0,0.9724221229553223
529008818,9485,ctan888,2020-11-23T21:30:18Z,"yeah, that's right. construct a kafkaprinciple instance with params referred from principal.gettype() and getname() commit 89df4d7600cad4e3785d0d95624d0918efce1f44",0,0.9724221229553223
529031043,9485,ctan888,2020-11-23T22:15:54Z,yes. using an arraylist to group allow-literals & allow-prefixes in order to deduplicate the logic using a loop commit 188536ad8df13fc327008e59c9787ad2230a7186,0,0.9870170950889587
529089666,9485,ctan888,2020-11-24T00:45:42Z,good point. deferred the collection generation until we need it. commit 3906f978e62255ff266f081bf646a4b3c6b896ad,1,0.9737257957458496
529089823,9485,ctan888,2020-11-24T00:46:09Z,good catch. commit 3906f978e62255ff266f081bf646a4b3c6b896ad,1,0.9633054137229919
529090156,9485,ctan888,2020-11-24T00:47:03Z,yeah. but i'd guess that the compiler will optimize for us. commit 3906f978e62255ff266f081bf646a4b3c6b896ad,0,0.9730393290519714
532327560,9485,ctan888,2020-11-30T03:20:04Z,"commit 230ee36b9147a11d7ce299aa9fcbb590324faf68 added the authorizebyresourcetype() api to the benchmark and simulate the worst case: every allow acl on the same resource has a dominant deny acl. adjust the `resourcecount` parameter to ""10000"", ""40000"", ""80000"" since each cluster is unlikely to have more than 10k resources. also, since we are testing against the worst case mentioned above, i think the ""10000"" cases are adequate for us. performance result here: [a link]",0,0.9761880040168762
532327775,9485,ctan888,2020-11-30T03:21:02Z,"commit 230ee36b9147a11d7ce299aa9fcbb590324faf68 added the authorizebyresourcetype() api to the benchmark and simulate the worst case: every allow acl on the same resource has a dominant deny acl. adjust the `resourcecount` parameter to ""10000"", ""40000"", ""80000"" since each cluster is unlikely to have more than 10k resources. also, since we are testing against the worst case mentioned above, i think the ""10000"" cases are adequate for us. performance result here: [a link]",0,0.9761880040168762
532336627,9485,ctan888,2020-11-30T04:03:00Z,yes. commit 254af37df5e2d6ec462e7b70497ceb655edea596,0,0.9871024489402771
532337358,9485,ctan888,2020-11-30T04:06:39Z,right. deleted the else branch. commit 254af37,0,0.9874186515808105
532337445,9485,ctan888,2020-11-30T04:06:59Z,commit 254af37,0,0.9879187941551208
532337761,9485,ctan888,2020-11-30T04:08:19Z,i was trying to prove that the new api can work properly with multiple add / remove operations. changed to `testauthorizeranymultipleaddandremove` for now. any naming suggestion? commit b0aa305d8c043075ef0bb7b41d2c37e0072284c5,0,0.9752538800239563
532338240,9485,ctan888,2020-11-30T04:10:31Z,the mockauthorizer is an aclauthorizer using the interface default to do `authorizebyresourcetype`. i was trying to prevent the duplicated code and ease the test implementation. do you think we can keep it here?,0,0.9861344695091248
532341814,9485,ctan888,2020-11-30T04:27:40Z,right. didn't realize that staitc variables in the permgen area will stay there during the whole unit test process. turn the class variable into the instance variable.,0,0.976758599281311
532342253,9485,ctan888,2020-11-30T04:29:39Z,"if we are mocking this fully, we'd probably need tests on the `authorize` api which the interface default `authorizebyresourcetype` is based on. also, we'll have much more duplicated code in order to implement all the interfaces.",0,0.9769594669342041
532343635,9485,ctan888,2020-11-30T04:36:10Z,i was trying to prove that the new api can work properly with multiple add / remove operations. changed to `testauthorizeranymultipleaddandremove` for now. any naming suggestion? commit b0aa305d8c043075ef0bb7b41d2c37e0072284c5,0,0.9752538800239563
532343754,9485,ctan888,2020-11-30T04:36:40Z,no. i was going to but that would add tons of duplicated codes. so i added the interface default test logic into aclauthorizertest. file deleted.,0,0.9866513013839722
532346213,9485,ctan888,2020-11-30T04:48:19Z,yes. let's document this after we finally settle down all the implementations.,0,0.9818854928016663
533501963,9485,rajinisivaram,2020-12-01T15:29:01Z,"this looks odd, do we really need these to index into arrays?",-1,0.8732110261917114
533502417,9485,rajinisivaram,2020-12-01T15:29:33Z,why do we create arraylist(arrays.aslist)?,0,0.9804957509040833
533503119,9485,rajinisivaram,2020-12-01T15:30:24Z,we could get host address and store in a variable outside the loop.,0,0.9886041879653931
533503166,9485,rajinisivaram,2020-12-01T15:30:27Z,why is this inside the for loop? we could just create one principal and use it inside the loop.,0,0.9809913635253906
533505561,9485,rajinisivaram,2020-12-01T15:33:34Z,an enummap may be neater.,0,0.9853330254554749
533510467,9485,rajinisivaram,2020-12-01T15:39:45Z,we should probably move this common code to securityutils and use it both here and in the default implementation.,0,0.9870807528495789
533510477,9485,rajinisivaram,2020-12-01T15:39:46Z,we should probably move this common code to securityutils and use it both here and in the default implementation.,0,0.9870807528495789
533513021,9485,rajinisivaram,2020-12-01T15:42:54Z,"we have lost the resource type for auditing, we should include a resource pattern with empty name or something.",0,0.971316397190094
533564908,9485,rajinisivaram,2020-12-01T16:49:59Z,"ok, i seem to have forgotten this. why is this code different from the one in the default implementation?",0,0.6279680132865906
533567312,9485,rajinisivaram,2020-12-01T16:53:18Z,we should try to preserve the format for this for compatibility with scripts that parse these logs.,0,0.9877469539642334
533622127,9485,rajinisivaram,2020-12-01T18:15:06Z,do we have a benchmark for updates (not authorize)?,0,0.986423909664154
533623715,9485,rajinisivaram,2020-12-01T18:17:41Z,"if `denyallresource` is true, we can just return denied?",0,0.9864605665206909
533626460,9485,rajinisivaram,2020-12-01T18:21:58Z,looks like a lot of duplicate code here. we should see how to share code for all this. can we move the default implementation into securityutils and share some of the matching implementation across the classes?,0,0.6122524738311768
533630212,9485,rajinisivaram,2020-12-01T18:27:59Z,should this be `&&` since we we only need one?,0,0.9853090643882751
533644589,9485,rajinisivaram,2020-12-01T18:51:24Z,"i wasn't sure what the result shows (not that familiar with the output format, sorry) the useful comparisons would be: 1) for authorizebyresourcetype, what is the performance advantage we get by using this duplicate cache versus just using `aclcache`. 2) what is the impact on updates which hold a lock for maintaining two caches (without the pr vs with this pr) 3) does this pr impact regular authorize() calls? i think the answer is no. in any case, it seems unnecessary to maintain a second cache with all acls. we never use authorizebyresourcetype for anything other than topics, so it seems a waste to store acls for other resource types here. we could just use `super.authorizebyresourcetype` for other types.",-1,0.9046558737754822
533720425,9485,rajinisivaram,2020-12-01T21:04:39Z,this should perhaps be called delegatingauthorizer rather than mockauthorizer since it is not a mock and requires zk.,0,0.9871200323104858
533720971,9485,rajinisivaram,2020-12-01T21:05:42Z,"i am not sure why we would make this change. if we need the change because we have become slower, we need to understand why.",-1,0.8789572715759277
533722349,9485,rajinisivaram,2020-12-01T21:08:29Z,spelling: principal,0,0.9496626853942871
533723836,9485,rajinisivaram,2020-12-01T21:11:24Z,"we probably want to retain the old benchmark as-is and add a different one for `authorizebyresourcetype`. we were testing a common pattern before, but now we seem to be testing a very unlikely scenario. while this may be useful for testing `authorizebyresourcetype`, it is not what we want for regression testing the authorizer.",0,0.9531217813491821
533724379,9485,rajinisivaram,2020-12-01T21:12:21Z,spelling: principal (multiple places),0,0.9626501202583313
533727081,9485,rajinisivaram,2020-12-01T21:17:34Z,can we move testing of `interfacedefaultauthorizer.authorizer` into another class? this is `aclauthorizertest` and testing of `interfacedefaultauthorizer` seems unrelated to this test.,0,0.985575795173645
533737220,9485,ctan888,2020-12-01T21:37:01Z,right. delegatingauthorizer is more reasonable as a design pattern naming here.,0,0.9841998815536499
533765909,9485,ctan888,2020-12-01T22:32:01Z,"the underlying algorithm of authorizebyresourcetype() implementation in aclauthorizer has several characteristics: 1. if any ""allow resource"" of the given ace does not have a dominant ""deny resource"", the api will return immediately 2. the complexity is o(n*m) where `n` is the number of ""allow resources"" of the given ace, 'm' is the number of ""deny resources"" of the given ace, but not related to the number of ""ace"" in the cluster. $1 means that, given an ace, suppose `p%` of its ""allow resource"" does not have a dominant ""deny resource"", if `resourcecount` is `r`, on average, after checking `r * p * 0.01` ""allow resources"", the api will return. a) if we are let the ""dominant deny resource"" distribute evenly, like use the (loop index % something) to determine which ""allow resource"" should have a dominant ""deny resource"", we end up iterating the same amount of the ""allow resource"" and returning from the api call every time, which is `r*p*0.01` b) if we are determine which ""allow resource"" should have a dominant ""deny resource"", the result will be too noisy. we may iterate only 1 resource or iterate all resources based on the randomize algorithm and seed. $2 means that, the api time cost is not related to the number of ""ace"" but is hyperbolically increasing when `resourcecount` is increasing. under the assumption in (1), the actual complexity would be (r * r * p * 0.01) as a result, we should get an insight into how long does the worst case takes, as `t`. then we can estimate some reasonable values of `p` and then estimate the api cost by `t * p`. so i was directly testing the worst case, where p = 1, which means 100% of the ""allow resource"" will have a dominant ""deny resource. the complexity hence would be (r^2). it's rare that a cluster can have 200k ""allow resources"" and 200k corresponding ""dominant deny resources"" for each user, and it's not fair to have a relatively smaller `aclcount` and huger `resourcecount`, as the api is optimizing the performance by indexing on `ace`.",0,0.9788789749145508
533915036,9485,ctan888,2020-12-02T05:57:25Z,enummap make sense. commit 1a139ce744a279e4424188008ee5158186b0fcbe,0,0.9846563935279846
533915142,9485,ctan888,2020-12-02T05:57:49Z,yeah. took out. commit 1a139ce744a279e4424188008ee5158186b0fcbe,0,0.9792394638061523
533915261,9485,ctan888,2020-12-02T05:58:12Z,enummap make sense. commit 1a139ce744a279e4424188008ee5158186b0fcbe,0,0.9846563935279846
533915275,9485,ctan888,2020-12-02T05:58:15Z,enummap make sense. commit 1a139ce744a279e4424188008ee5158186b0fcbe,0,0.9846563935279846
533916889,9485,ctan888,2020-12-02T06:03:33Z,right. just as what we've done to principle. commit 29ac8628089ddf1210072bbf52e01a41e123a718,0,0.9525761008262634
533919425,9485,ctan888,2020-12-02T06:10:11Z,commit f6d2a39706998160ebe77a854b8bf64268eec68a,0,0.9872971773147583
533922526,9485,ctan888,2020-12-02T06:19:38Z,commit 6ab95d3668b3de27a7f6f58fc171a1e2e8925f69,0,0.9860860109329224
533922580,9485,ctan888,2020-12-02T06:19:47Z,commit 6ab95d3668b3de27a7f6f58fc171a1e2e8925f69,0,0.9860860109329224
534447773,9485,ctan888,2020-12-02T20:05:42Z,"use ""none"" for the pattern name and ""unknown` for the pattern type commit cebbbd47a8e7d318e327e3a279072c718b535abd",0,0.9887440204620361
534447894,9485,ctan888,2020-12-02T20:05:57Z,leave the message as it is now. commit cebbbd47a8e7d318e327e3a279072c718b535abd,0,0.9880273342132568
534477631,9485,ctan888,2020-12-02T20:59:42Z,"i just realized that, in order to check the dominant denies, my aclauthorizer implementation is calling `string::startwith` which also has an o(d) complexity where `d` is the length of the ""deny pattern"" string of the given acl. so the complexity would be o(n * m * d). so given all ""allow pattern"" and ""deny pattern"" of a given ace, we have 2 algorithms now 1. iterate through all the prefixes of the `allow pattern` string and check if any prefix is contained in the set of `deny pattern`, which has a complexity of o(n * a), where `a` is the length of the ""allow pattern"" string. my interface default is using this approach. 2. iterate through all the ""deny patterns"", which has a complexity of o(n * m * d), where d is the length of the `deny pattern` string. my aclauthorizer is using this approach. comparasion: since the average of the `allow pattern` string length should be close to that of the `deny pattern`, we can say `a = d`. so o(n * a) = o(n * d) > o(n * m * d), which means approach 1 is much better. conclusion: i'll change aclauthorizer to use approach 1.",0,0.9616429805755615
534589923,9485,ctan888,2020-12-03T01:07:31Z,right. just as what aclauthorizer does. commit 18c5c04ad4d8c98dc3cdaa6d15bf70b9991a6b88,0,0.9825087785720825
534751595,9485,ctan888,2020-12-03T06:51:40Z,"yeah, moved to securityutils. commit 30899c45ac50b70625baa2e5f12f58cfe9d79404",0,0.9823288321495056
534755163,9485,ctan888,2020-12-03T06:53:59Z,"now the only difference is that the aclauthorizer is indexing on ace, so the number of ace won't impact the query efficiency.",0,0.9842128753662109
534763817,9485,ctan888,2020-12-03T06:59:40Z,"i think adding some dominant denies won't change the performance pattern of aclauthorizer::acls and aclauthorizer::authorize. 1. aclauthorizer::acls just return all the matching acls by the filter rule. the portion btw ""allow"" and ""deny"" resources doesn't matter. 2. aclauthorizer::authorize will iterate the and filter out the allow and deny aces respectively. since it's using resourcepattern as its indexing method, the portion btw ""allow"" and ""deny"" resources doesn't matter as well.",0,0.9766111373901367
534983615,9485,ctan888,2020-12-03T09:12:16Z,"move the interface default test to a new class. also, created a util class for code sharing. commit 6c550fd04a0c1912e669bf18d60dee27dd03e53c",0,0.9878173470497131
536305219,9485,ctan888,2020-12-04T18:46:54Z,commit 7af4a7ff7ed2dddc06cf11ab7ff2d4b9fee5fb56,0,0.9868768453598022
537657552,9485,ctan888,2020-12-07T16:46:03Z,good catch commit 031c2f41e6611df3d18ef9b709c7d98c91b93326,1,0.8909368515014648
537667755,9485,ctan888,2020-12-07T16:58:58Z,please see below,0,0.9676119089126587
538522173,9485,lbradstreet,2020-12-08T15:49:08Z,"nit, unnecessary whitespace in `i++`.",0,0.9648433923721313
538524117,9485,lbradstreet,2020-12-08T15:50:45Z,i think it's useful to understand how the cache performs at smaller sizes as well as larger sizes. is there a reason we went with a fixed size and fixed number of resources now?,0,0.9754027724266052
538528015,9485,lbradstreet,2020-12-08T15:54:15Z,it might be better for the purpose of this microbenchmark to setup the cache with the desired size ahead of the time and then measure the time to update the cache with one entry. otherwise you risk measuring a lot of the setup costs rather than the cost of the typical usage.,0,0.979690432548523
538553851,9485,lbradstreet,2020-12-08T16:16:33Z,"if you take an async profile of this benchmark method you end up spending most of the time in building the entries and immutable set, and barely any time on `aclauthorizer#updatecache`.",0,0.9657348990440369
538613769,9485,ctan888,2020-12-08T17:09:18Z,"oh, i'm just demonstrating the chart 3 i uploaded. i'll change them back.",0,0.9821203351020813
538618149,9485,ctan888,2020-12-08T17:13:15Z,"do you think we'll keep this `testupdatecache` and merge it into trunk? if so, let's setup the cache ahead of time. but i think this benchmark is mainly for comparing the trunk with my branch, which means that we probably won't merge this `testupdatecache` into master, which also means the same procedure constructing some memory records are acceptable since we are taking the time cost difference.",0,0.9853639006614685
538618817,9485,ctan888,2020-12-08T17:13:55Z,yeah. agree. let's see what think about the above discussion,0,0.9204719662666321
538768554,9485,ctan888,2020-12-08T20:04:09Z,thanks. fixed.,1,0.8839593529701233
539594382,9485,rajinisivaram,2020-12-09T19:42:17Z,"this package is part of the public api, but the class looks like it should be internal?",0,0.9893087148666382
539595584,9485,rajinisivaram,2020-12-09T19:44:19Z,perhaps resourceaclentry or something along those lines would be better than `resourceindex` since this class has no notion of index.,0,0.9864480495452881
539599430,9485,rajinisivaram,2020-12-09T19:50:25Z,can we remove the todo comments?,0,0.9887480735778809
539602809,9485,rajinisivaram,2020-12-09T19:55:39Z,"in the typical case, we have a large number of `allowliterals` and `allowprefixes`, no `denyliterals` or `denprefixes`. i think it would make sense to special case `denyliterals.isempty && denyprefixes.isempty`. in this case, we don't need to find all matching resources, we just need to check that there is at least one matching resource.",0,0.9827290773391724
539604360,9485,rajinisivaram,2020-12-09T19:58:05Z,why can't this be a `set` instead of `list of sets`?,0,0.9690840840339661
539604845,9485,rajinisivaram,2020-12-09T19:58:51Z,`aclentry.wildcardprincipalstring`,0,0.9834046959877014
539607223,9485,rajinisivaram,2020-12-09T20:02:33Z,this method can be in securityutils and shared with the default authorizer?,0,0.9901660084724426
539607563,9485,rajinisivaram,2020-12-09T20:03:07Z,private def?,0,0.9741846919059753
539612536,9485,rajinisivaram,2020-12-09T20:11:00Z,"we cannot do this here. `authorizerwrapper` is used to wrap any custom authorizer using the old authorizer api. `alloweveryoneifnoaclisfoundprop` is a custom config of `simpleaclauthorizer` and `aclauthorizer`, we cannot use that with any custom authorizer. we should find a way to support the config for simpleaclauthorizer that doesn't impact other custom authorizers.",0,0.9832329154014587
539614719,9485,rajinisivaram,2020-12-09T20:14:37Z,does this work with an acl with wildcard host?,0,0.9836665391921997
539614739,9485,rajinisivaram,2020-12-09T20:14:38Z,does this work with an acl with wildcard host?,0,0.9836665391921997
539615189,9485,rajinisivaram,2020-12-09T20:15:25Z,"the main logic of this could potentially be moved to securityutils since the default authorizer implementation, aclauthorizer and the wrapper all do this.",0,0.9888417720794678
539630084,9485,rajinisivaram,2020-12-09T20:37:40Z,why do we need this in teardown?,0,0.8579103350639343
539631425,9485,rajinisivaram,2020-12-09T20:40:04Z,a lot of these changes look unnecessary,-1,0.5881969332695007
539632426,9485,rajinisivaram,2020-12-09T20:41:50Z,looks like this hasn't been reverted?,0,0.9546502232551575
539632653,9485,rajinisivaram,2020-12-09T20:42:14Z,revert?,0,0.8850228786468506
539634789,9485,rajinisivaram,2020-12-09T20:45:38Z,why? this no longer reflects the comment above. can we revert?,0,0.9217844605445862
539635426,9485,rajinisivaram,2020-12-09T20:46:42Z,we should revert changes to existing benchmark because it hard to tell why these changes were made and what impact it has on the original benchmark.,0,0.9266058206558228
539638872,9485,rajinisivaram,2020-12-09T20:52:14Z,it makes sense to merge the benchmarks to trunk. let's make sure it measures just updatecache.,0,0.9827579855918884
539730884,9485,ctan888,2020-12-09T23:41:08Z,shall we make the class constructor package-private or make this class an inner class of aclauthorizer?,0,0.9888890981674194
539734315,9485,ctan888,2020-12-09T23:47:14Z,i used index as it's used as the index of the hashmap. what about something like `resourcenamefilter`?,0,0.9880797266960144
539734983,9485,ctan888,2020-12-09T23:48:51Z,yeah. removed.,0,0.9629202485084534
539736828,9485,ctan888,2020-12-09T23:53:14Z,yes. commit 2fd4babe2c27ee0723fa1cd720ca35d2bbefe57b,0,0.9859995245933533
539737110,9485,ctan888,2020-12-09T23:53:55Z,commit 2fd4babe2c27ee0723fa1cd720ca35d2bbefe57b,0,0.9868108630180359
539737287,9485,ctan888,2020-12-09T23:54:20Z,sure,0,0.9371067881584167
539751258,9485,ctan888,2020-12-10T00:28:50Z,yes. commit 1dc143fc78a3b9927189751255346ef0b6cafd90 if (nodeny) { ..if (hasallow) { ....return authorize.allowed ..} else { ....return authorize.denied // since no allow exists ..} },0,0.9832609295845032
539782093,9485,ctan888,2020-12-10T01:50:16Z,because we don't wanna reconstruct a new large set containing all the matching resources. we are constructing a list of ~ 3 * 3 * 3 elements which refer to existing hashsets maintained by `updatecache`.,0,0.9774935245513916
539787542,9485,ctan888,2020-12-10T02:03:20Z,i was trying to share it but it seems like the different collection type btw java and scala is a headache. we'll then need some java converters or instantiate a java collection in the scala code. do you think it deserves this?,-1,0.8931666016578674
540418386,9485,ctan888,2020-12-10T18:56:44Z,"given that we probably don't want to change the deprecated authorizer interface, i can only think of one way to achieve this: besides checking if the `alloweveryoneifnoaclisfoundprop` exists and if it equals to `true`, i added another check to authorize on a hardcoded session, operation, and resource. since configure() will be called immediately after the authorizer instantiation, it's guaranteed that no acls would exist when we do this check. override def configure(configs: util.map[string, _]): unit = { ..baseauthorizer.configure(configs) ....shouldalloweveryoneifnoaclisfound = (configs.asscala.get( ......aclauthorizer.alloweveryoneifnoaclisfoundprop).exists(_.tostring.toboolean) ........&& baseauthorizer.authorize( ..........new session(kafkaprincipal.anonymous, inetaddress.getbyname(""1.2.3.4"")), ............read, new resource(topic, ""hi"", patterntype.literal))) } commit 2ed79a0a7788f8841475badfd1c26adf0eb3435c",0,0.9789557456970215
540655651,9485,ctan888,2020-12-11T03:03:41Z,"good catch. commit 8263bd319f63d39808f90129db55427b98385dd4 since it's a bit hard to test `allowanyoneifnoaclfound` and many other logics in the integration test, i added a new test class `authorizerwrappertest`.",1,0.9660647511482239
540658692,9485,ctan888,2020-12-11T03:13:10Z,commit 8263bd3 changed the authorizerwrapper logic and optimized the performance a bit. now authorizerwrapper#denyallresource will 1. only use authorizer#acls() to filter out the `wildcardresource` with the pattern type `literal`. 2. check if any of the filtered out bindings match the `request principle` and `request host`. so it's behavior diverges more from the interface default now.,0,0.9886106848716736
540705023,9485,ctan888,2020-12-11T05:43:38Z,"otherwise ""deny all"" will remain in zk during the whole test process since zk won't be restarted or re-instantiated.",0,0.9792540073394775
540706117,9485,ctan888,2020-12-11T05:46:49Z,"since `authorizerinterfacedefaulttest`, `aclauthorizertest`, and `authorizerwrappertest` are sharing some test utils, we need to make this method signature abstract a bit, in order to make it usable by authorizertestfactory.",0,0.9887310862541199
541202572,9485,ctan888,2020-12-11T19:35:27Z,yeah. i was doing resourcename = resourcename + 95 to re-use this variable. we can revert it.,0,0.9808140993118286
541206048,9485,ctan888,2020-12-11T19:38:55Z,yes.,0,0.969875693321228
541206648,9485,ctan888,2020-12-11T19:39:31Z,yes,0,0.9564858078956604
541212190,9485,ctan888,2020-12-11T19:45:19Z,"the existing benchmark does not have any deny resource in it. adding some deny bindings whose percentage is controlled by parameters will be an improvement to the existing benchmark and help us understand the performance better. i've reverted all changes other than adding some deny bindings. also, i moved those memory intense operations into the phase so now the benchmark just measures updatecache(). does the benchmark look good to you now? commit 6536cea788210860a764f3f0a6901244e8d974fe",0,0.8817354440689087
541779975,9485,ctan888,2020-12-12T21:02:27Z,reverted other test changes commit 4f9b79a810c4da3030fe262d4bfdc97df4945e8c,0,0.9876593947410583
542039322,9485,ctan888,2020-12-14T00:14:52Z,"benchmark result: [a link] performance pattern doesn't change, except `testupdatecache` runs much faster now.",0,0.9841640591621399
542790510,9485,rajinisivaram,2020-12-14T21:10:16Z,"we have to move the class outside of the public package, so putting it alongside aclauthorizer makes sense.",0,0.9840011596679688
542830098,9485,rajinisivaram,2020-12-14T21:47:04Z,"since this is the javadoc of a public api, we should move the details on how the default implementation works outside of the javadoc. we can move this list of comments inside the method.",0,0.9884002208709717
542851551,9485,rajinisivaram,2020-12-14T22:07:06Z,"we don't currently have anything in the default implementation to support super.users right? unlike `allow.everyone.if.no.acl.found` which is not particularly suitable for production use, `super.users` is a commonly used config that is likely to be in use in a lot of deployments. the simplest fix may be to `authorize()` with a hard-coded name and return allowed if `authorize()` returns allowed before any of the logic below is executed.",0,0.9786943793296814
542854629,9485,rajinisivaram,2020-12-14T22:09:57Z,this needs to be an immutable map or a concurrenthashmap since we read this without lock.,0,0.9843519330024719
542855316,9485,rajinisivaram,2020-12-14T22:10:36Z,we need to check if the principal is a super.user and return allowed for super users before executing any of the logic below.,0,0.9887526631355286
542860969,9485,rajinisivaram,2020-12-14T22:16:10Z,"ok, makes sense",0,0.9742665886878967
542861839,9485,rajinisivaram,2020-12-14T22:16:57Z,"ok, let's leave as is.",0,0.9493744373321533
542871579,9485,rajinisivaram,2020-12-14T22:26:24Z,"this is too hacky. and it breaks if anonymous has all access (e.g. because inter-broker listener alone uses plaintext). we could check `baseauthorizer.isinstanceof[simpleaclauthorizer]` perhaps. it is not perfect since it would break if there was a custom authorizer that extended simpleaclauthorizer, but doesn't support alloweveryoneifnoaclisfoundprop and the prop was set to true. but that seems like an unlikely scenario.",-1,0.9639384746551514
542879143,9485,rajinisivaram,2020-12-14T22:33:41Z,this sequence doesn't work with super.users. we probably should do something like: [code block],0,0.9510198831558228
542881770,9485,rajinisivaram,2020-12-14T22:36:27Z,we could have done principal.tostring() once in the caller rather than convert everytime.,0,0.9893486499786377
542884517,9485,rajinisivaram,2020-12-14T22:39:08Z,zk is reinstantiated for every test.,0,0.9829511046409607
542887409,9485,rajinisivaram,2020-12-14T22:41:58Z,"as in the other class, we don't need this in teardown",0,0.9575265645980835
542888614,9485,rajinisivaram,2020-12-14T22:43:13Z,we should add tests for super users.,0,0.9845613241195679
542890465,9485,rajinisivaram,2020-12-14T22:45:10Z,why are we storing these?,0,0.9570863246917725
542892942,9485,rajinisivaram,2020-12-14T22:47:34Z,why?,0,0.6633803844451904
542893393,9485,rajinisivaram,2020-12-14T22:48:00Z,why was this changed from aclauthorizer to authorizer?,0,0.9674753546714783
542893665,9485,rajinisivaram,2020-12-14T22:48:15Z,why are we storing this?,0,0.9445488452911377
542900213,9485,rajinisivaram,2020-12-14T22:54:40Z,it would be better to move this inside authorizerinterfacedefaulttest since it is specific to that test.,0,0.9883529543876648
542906008,9485,rajinisivaram,2020-12-14T23:00:35Z,"for map, you would say `key` rather than `index`. but this is not a `resource` or `resourcename` - it has no resource name, it is not a filter, but it includes accesscontrolentry. maybe just resourcetypekey is sufficient, but you could also include something to indicate it includes the accesscontrolentry if you want. either way, putting it along with aclauthorizer would make naming less critical.",0,0.984093189239502
543080612,9485,ctan888,2020-12-15T06:30:16Z,sure. commit 25e0bfcc97f956ceb4254ab8c457fe5d8d250e82,0,0.9766674041748047
543093393,9485,ctan888,2020-12-15T07:00:05Z,"so we have three approaches here: 1. use .getclass 2. use .isinstanceof 3. only configure the property with the key ""aclauthorizer.alloweveryoneifnoaclisfoundprop"" in the authorizerwrapper instance construction so no other property will get in. neither of them is perfect but approach 2 also seems better to me. commit 1217394c0c3767ac11df958c02a681c8cbc8382b",0,0.7962737083435059
543099934,9485,ctan888,2020-12-15T07:14:00Z,yeah. i was trying to restrict the type in order to remind people to construct a kafkaprinciple first. but tostring() is an expensive operation. commit 16576f85a858648cfc4ff882b554ddc65922021c,-1,0.5865158438682556
543114091,9485,ctan888,2020-12-15T07:41:41Z,"i replied here. maybe i shouldn't have resolved it. [a link] since authorizerinterfacedefaulttest, aclauthorizertest, and authorizerwrappertest are sharing some test cases, we need to make this method signature abstract a bit, in order to pass the method reference to authorizertestfactory.",0,0.9866677522659302
543116084,9485,ctan888,2020-12-15T07:45:14Z,"for this method, i changed the signature back to aclauthorzier as the authorizertestfactory is not depending on it.",0,0.9896676540374756
543117875,9485,ctan888,2020-12-15T07:48:38Z,removed as we are not removing acls in teaddown() anymore. commit 825a8ba77ad1766f998a71a9a15f21e73daad84a,0,0.9892894625663757
543117908,9485,ctan888,2020-12-15T07:48:42Z,commit 825a8ba77ad1766f998a71a9a15f21e73daad84a,0,0.987910270690918
543117954,9485,ctan888,2020-12-15T07:48:48Z,commit 825a8ba77ad1766f998a71a9a15f21e73daad84a,0,0.987910270690918
543118616,9485,ctan888,2020-12-15T07:49:54Z,removed as we are not removing acls in teaddown() anymore. commit 825a8ba,0,0.988165020942688
543120808,9485,ctan888,2020-12-15T07:53:47Z,make sense. commit e31f157eaac1213445dd284fd2209a29f4fa18fd,0,0.9805915951728821
543134773,9485,ctan888,2020-12-15T08:18:45Z,"would scala ""foreach"" throw any exception when read operation races with write in hashmap / hashset? if not, i think we can tolerate some read inconsistency as zk is also broadcasting the acl changes asynchronously to brokers.",0,0.9878240823745728
543174139,9485,ctan888,2020-12-15T09:18:00Z,"i tested a bit, using 1 bg thread adding and removing elements to a mutable.hashset while the main thread constantly iterating the hashset using ""foreach"". the ""foreach"" call doesn't throw any exception. but i'm a bit unsure what would happen if the iteration hits a bucket where some elements are being added to or deleted from. let me test what's the overhead using the immutable map. i'd prefer this approach as we're expecting much more read than write to the hashset.",0,0.8464009761810303
543744087,9485,ctan888,2020-12-15T22:49:36Z,good catch. this is super important. commit dae1a788b70ebc03eab265b1027a4b43ad8e773b,1,0.9851626753807068
543744182,9485,ctan888,2020-12-15T22:49:47Z,good catch. this is super important. commit dae1a788b70ebc03eab265b1027a4b43ad8e773b,1,0.9851626753807068
543745352,9485,ctan888,2020-12-15T22:52:00Z,"test added for authorizerinterfacedefaulttest, aclauthorizertest, authorizerwrappertest. commit dae1a788b70ebc03eab265b1027a4b43ad8e773b",0,0.9857640862464905
543805858,9485,ctan888,2020-12-16T01:18:49Z,"use immutable collections: benchmark (aclcount) (denypercentage) (resourcecount) mode cnt score error units aclauthorizerbenchmark.testaclsiterator 50 100 200000 avgt 5 4132.824 ± 2967.122 ms/op aclauthorizerbenchmark.testauthorizebyresourcetype 50 100 200000 avgt 5 46.733 ± 5.397 ms/op aclauthorizerbenchmark.testauthorizer 50 100 200000 avgt 5 6.844 ± 0.915 ms/op aclauthorizerbenchmark.testupdatecache 50 100 200000 avgt 5 7219.696 ± 4018.189 ms/op jmh benchmarks done use mutable collections: aclauthorizerbenchmark.testupdatecache 50 100 200000 avgt 5 4927.832 ± 2570.786 ms/op when aclcount = 50, denypercentage = 100, resourcecount = 200000, the time cost is 2.3 seconds more with immutable collections. but since adding 50 * 20000 acl bindings only takes ~7 seconds, i think the performance should be acceptable.",0,0.9788761138916016
543813486,9485,ctan888,2020-12-16T01:39:14Z,removed.,0,0.9311882257461548
543814295,9485,ctan888,2020-12-16T01:41:28Z,resourcetypekey sounds good: commit 7fe92c6436432760adf9465c3f0bcf3c91104b10,0,0.5219417214393616
543814563,9485,ctan888,2020-12-16T01:42:04Z,make resourcetypekey an inner class of aclauthorizer commit 7fe92c6436432760adf9465c3f0bcf3c91104b10,0,0.9877875447273254
543814681,9485,ctan888,2020-12-16T01:42:19Z,good catch. this is super important. commit dae1a78,1,0.988783061504364
543817949,9485,ctan888,2020-12-16T01:51:12Z,commit 62c44ade550a90671ff41bfb847e2bc28adc7baa,0,0.9879108667373657
544223127,9485,rajinisivaram,2020-12-16T11:29:11Z,use `op` rather than read since that fits with why we are allowing access. we also need a test that verifies that permission to read everything doesn't imply `authorizebyresourcetype` for write.,0,0.9880792498588562
544223630,9485,rajinisivaram,2020-12-16T11:29:58Z,use `logifallowed=true` since we are granting access in that case.,0,0.9881780743598938
544229673,9485,rajinisivaram,2020-12-16T11:40:14Z,can we used named arguments for the booleans: `authorized = false` - we should update all usages of `logauditmessage` below.,0,0.9897760152816772
544232558,9485,rajinisivaram,2020-12-16T11:44:53Z,"we should make this a `case class`. we can then remove all the methods (equals, hashcode and tostring) since we get those for free.",0,0.9877182245254517
544239742,9485,rajinisivaram,2020-12-16T11:56:47Z,"not a `custom` principal, just a `principal`.",0,0.9847387075424194
544239749,9485,rajinisivaram,2020-12-16T11:56:48Z,"not a `custom` principal, just a `principal`.",0,0.9847387075424194
544240156,9485,rajinisivaram,2020-12-16T11:57:27Z,all these tests are using `read` which happens to work for the default implementation since we used read there.,0,0.9887479543685913
544244813,9485,rajinisivaram,2020-12-16T12:05:14Z,can we check how much work it would be to convert `authorizertestfactory` into an `abstract baseauthorizertest` class that the three xxxauthorizertest classes extend? having to repeat these tests in all three places makes it too easy to miss one in the future.,0,0.9843894839286804
544246252,9485,rajinisivaram,2020-12-16T12:07:37Z,nit: principle => principal,0,0.9734391570091248
544545938,9485,ctan888,2020-12-16T18:57:59Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9884797930717468
544545948,9485,ctan888,2020-12-16T18:58:00Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9884797930717468
544545971,9485,ctan888,2020-12-16T18:58:04Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9884797930717468
544546002,9485,ctan888,2020-12-16T18:58:07Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9884797930717468
544546101,9485,ctan888,2020-12-16T18:58:15Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9884797930717468
544546172,9485,ctan888,2020-12-16T18:58:22Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9884797930717468
544546946,9485,ctan888,2020-12-16T18:59:31Z,"yeah. since i've changed `read` to `op`, this has been resolved.",0,0.9800732731819153
544547081,9485,ctan888,2020-12-16T18:59:40Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9884797930717468
544713670,9485,ctan888,2020-12-17T00:09:14Z,"commit 092fec70a9547ec07cba999e77be1c0cf79fa275 commit e5e3d18f57ab22df20133f9841905af384d9b641 these two commits are condensing the class methods and members into the baseauthorizertest. in baseauthorizertest, the only abstract method is an authorizer provider. after overriding the provider, those test cases in it are sufficient to run. now the test code looks much cleaner. if the changes look too much to you, we can revert 092fec70a9547ec07cba999e77be1c0cf79fa275 and move the head to e5e3d18f57ab22df20133f9841905af384d9b641",0,0.9320581555366516
545246428,9485,rajinisivaram,2020-12-17T16:56:46Z,`resourceindex` => `resourcetypekey` and omit `new`.,0,0.987125813961029
545247397,9485,rajinisivaram,2020-12-17T16:58:03Z,couldn't we just check:`resourcecache.contains(resourcekey)` ?,0,0.9878189563751221
545261128,9485,rajinisivaram,2020-12-17T17:17:49Z,"`resourceindex` => `resourcetypekey`, also we can omit new for resourcetypekey since it is a case class.",0,0.9891992211341858
545264795,9485,rajinisivaram,2020-12-17T17:23:02Z,`private def`,0,0.9825103878974915
545264898,9485,rajinisivaram,2020-12-17T17:23:10Z,`private def`,0,0.9825103878974915
545267737,9485,rajinisivaram,2020-12-17T17:27:13Z,we can use `map` instead of `match`: [code block],0,0.9888412356376648
545270222,9485,rajinisivaram,2020-12-17T17:30:45Z,"`resourceindex` => `resourcetypekey`, omit `new`",0,0.9862755537033081
545270292,9485,rajinisivaram,2020-12-17T17:30:53Z,"`resourceindex` => `resourcetypekey`, omit `new`",0,0.9862755537033081
545273561,9485,rajinisivaram,2020-12-17T17:35:05Z,`candenyall` => `denyall` since `can` doesn't fit with `deny`,0,0.9846469163894653
545280654,9485,rajinisivaram,2020-12-17T17:45:19Z,"suggestions to improve this (feel free to ignore/update): ``` custom authorizer implementations should consider overriding this default implementation because: 1) the default implementation iterates all aclbindings multiple times, without any caching for resource types. more efficient implementations may be added in custom authorizers that directly access cached entries. 2) the default implementation cannot integrate with any audit logging included in the authorizer implementation. 3) the default implementation does not support any custom authorizer configs or other access rules apart from acls.",0,0.9704517126083374
545282374,9485,rajinisivaram,2020-12-17T17:47:45Z,add a comment to say that we check for one hard-coded name to ensure that super users are granted access regardless of deny acls.,0,0.9866043925285339
545287419,9485,rajinisivaram,2020-12-17T17:55:22Z,can we make this comment two lines instead of 4 since each sentence seems short enough to fit into a line?,0,0.982069194316864
545325909,9485,rajinisivaram,2020-12-17T18:53:16Z,"`patterntype.unknown` looks odd in audit logs, `any` may be better.",0,0.9830580353736877
545363933,9485,rajinisivaram,2020-12-17T19:55:50Z,the nested for loop can be replaced with: [code block],0,0.9875013828277588
545365855,9485,rajinisivaram,2020-12-17T19:58:45Z,we can make this a `val` by using an arraybuffer instead of list that we keep recreating,0,0.9875521659851074
545366101,9485,rajinisivaram,2020-12-17T19:59:08Z,"as before, we can use a single for loop instead of nested loop",0,0.9845708012580872
545367497,9485,rajinisivaram,2020-12-17T20:01:27Z,can use `denyliterals.exists(_.contains(resourcepattern.wildcard_resource))`,0,0.9874294400215149
545368045,9485,rajinisivaram,2020-12-17T20:02:13Z,"can use `allowprefixes.exists(_.exists`, similarly for `allowliterals`.",0,0.9871446490287781
545368198,9485,rajinisivaram,2020-12-17T20:02:31Z,nit: space before {,0,0.9810949563980103
545369571,9485,rajinisivaram,2020-12-17T20:04:55Z,can be `!denyliterals.exists(_.contains(literalname))`?,0,0.9856153726577759
545399101,9485,rajinisivaram,2020-12-17T20:57:59Z,we should use the same pattern as the usage of `aclcache` where we get a `aclcachesnapshot` at the start of the method and then use the same snapshot throughout the method rather than use a changing value of resourcecache within the loop.,0,0.9880946278572083
545410322,9485,rajinisivaram,2020-12-17T21:19:25Z,could just close `interfacedefaultauthorizer` instead of creating an `authorizers` collection?,0,0.989167332649231
545411361,9485,rajinisivaram,2020-12-17T21:21:34Z,the `authorizer` parameter is not used. can't we just move this into the test method `testauthorizebyresourcetypenoaclfoundoverride` above?,0,0.9891647696495056
545411829,9485,rajinisivaram,2020-12-17T21:22:24Z,can't this be `aclauthorizer`?,0,0.985403299331665
545412639,9485,rajinisivaram,2020-12-17T21:24:09Z,"there is only one authorizer, we could just use it directly instead of creating a seq",0,0.9865965247154236
545413800,9485,rajinisivaram,2020-12-17T21:26:29Z,"looks like there is opportunity to move some of this stuff into baseauthorizertest, but we can do that in a follow-up later.",0,0.9837903380393982
545471749,9485,ctan888,2020-12-17T23:26:46Z,[code block] i think the resourcepattern constructor is preventing us passing patterntype.any. it's only usable with filter.,0,0.9845987558364868
545525163,9485,ctan888,2020-12-18T02:04:45Z,right. to prevent the phantom problem.,0,0.9751938581466675
545527187,9485,ctan888,2020-12-18T02:11:19Z,"i think that the zookeeperclient has a different metric group name. i'm not sure how the name will be used though. and yes, we can do that in a follow-up pr later.",0,0.949195146560669
545529131,9485,ctan888,2020-12-18T02:17:51Z,commit b6a766b228034a442e3a6e8b71ecee78eefdbfd3,0,0.9853500127792358
545529436,9485,ctan888,2020-12-18T02:18:49Z,commit b6a766b,0,0.9878316521644592
545529534,9485,ctan888,2020-12-18T02:19:03Z,commit b6a766b,0,0.9878316521644592
545531049,9485,ctan888,2020-12-18T02:24:18Z,commit b6a766b,0,0.9878316521644592
545531079,9485,ctan888,2020-12-18T02:24:22Z,commit b6a766b,0,0.9878316521644592
545576162,9485,ctan888,2020-12-18T05:09:08Z,commit b6a766b,0,0.9878316521644592
545576394,9485,ctan888,2020-12-18T05:10:16Z,commit b6a766b,0,0.9878316521644592
545576579,9485,ctan888,2020-12-18T05:11:03Z,commit b6a766b,0,0.9878316521644592
545576700,9485,ctan888,2020-12-18T05:11:32Z,commit b6a766b,0,0.9878316521644592
545576808,9485,ctan888,2020-12-18T05:11:58Z,![a link] commit b6a766b,0,0.9747505784034729
545577772,9485,ctan888,2020-12-18T05:15:41Z,// check a hard-coded name to ensure that super users are granted // access regardless of deny acls.,0,0.9864559173583984
545577832,9485,ctan888,2020-12-18T05:15:56Z,commit b6a766b,0,0.9878316521644592
545577865,9485,ctan888,2020-12-18T05:16:03Z,commit b6a766b,0,0.9878316521644592
545577952,9485,ctan888,2020-12-18T05:16:18Z,commit b6a766b,0,0.9878316521644592
545578070,9485,ctan888,2020-12-18T05:16:49Z,"right, though it's only a list of 8. commit b6a766b",0,0.9830495715141296
545578559,9485,ctan888,2020-12-18T05:18:28Z,commit b6a766b,0,0.9878316521644592
545578734,9485,ctan888,2020-12-18T05:18:58Z,yes. didn't realize the existence of this syntax be4. thanks. commit b6a766b,1,0.9602110385894775
545579837,9485,ctan888,2020-12-18T05:23:04Z,commit b6a766b,0,0.9878316521644592
545581171,9485,ctan888,2020-12-18T05:27:40Z,commit b6a766b,0,0.9878316521644592
545584468,9485,ctan888,2020-12-18T05:39:14Z,right. we can bring the ! to the front. commit 9407b1697d976fc6cff90703573a64f7a3c9f348,0,0.9584061503410339
545584783,9485,ctan888,2020-12-18T05:40:19Z,commit b6a766b,0,0.9878316521644592
545584825,9485,ctan888,2020-12-18T05:40:28Z,yes. commit b6a766b,0,0.9867189526557922
545584872,9485,ctan888,2020-12-18T05:40:35Z,yes. commit b6a766b,0,0.9867189526557922
545585037,9485,ctan888,2020-12-18T05:41:19Z,yes. renamed to aclauthorizer. commit b6a766b,0,0.9888168573379517
545585355,9485,ctan888,2020-12-18T05:42:34Z,yes. remove the seq construction and make a single class member call. commit b6a766b,0,0.988667905330658
76054354,1776,ijuma,2016-08-24T13:20:34Z,the scala `enumeration` class has a bunch of problems and we typically use adts. an example is `rackawaremode`.,0,0.9764899015426636
76104237,1776,benstopford,2016-08-24T17:43:14Z,changed - thanks bud.,1,0.8862308859825134
76720190,1776,junrao,2016-08-30T02:00:43Z,delta is no longer valid. typo evalutated,0,0.8745335340499878
76720206,1776,junrao,2016-08-30T02:00:53Z,"is that only used for testing? if so, could we define it under src/test?",0,0.988701581954956
76720217,1776,junrao,2016-08-30T02:01:03Z,do we need this new class? rate.windowsize() is modified this way to address kafka-2443 and kafka-2567. it would be better if all sensors are of the same type of rate.,0,0.9854357838630676
76720224,1776,junrao,2016-08-30T02:01:07Z,kip says using comma separated.,0,0.9881526827812195
76720231,1776,junrao,2016-08-30T02:01:11Z,the kip says it's comma separated.,0,0.981613039970398
76720243,1776,junrao,2016-08-30T02:01:17Z,"perhaps we can avoid calling split(""-"") twice by doing that once first?",0,0.967574954032898
76720245,1776,junrao,2016-08-30T02:01:25Z,"to be consistent with the existing naming, perhaps the params can be brokerid and brokerconfig?",0,0.9889026284217834
76720249,1776,junrao,2016-08-30T02:01:26Z,space after if,0,0.9781984090805054
76720258,1776,junrao,2016-08-30T02:01:31Z,shouldn't we do this check before line 127?,0,0.981105387210846
76720265,1776,junrao,2016-08-30T02:01:37Z,it's clearer if we use quota.upperbound(limit) in this and the next line.,0,0.9878867864608765
76720272,1776,junrao,2016-08-30T02:01:41Z,this can be private?,0,0.9885194897651672
76720336,1776,junrao,2016-08-30T02:02:47Z,"does this guarantee that the minbytes requirement is met? for example, suppose that all replicas are throttled and quota is not exceeded at this point. however, when we call forcecomplete(0, we could get fewer bytes than minbytes and return the fetch response prematurely. same question in case c on line 94. if the fetch offset is on an old segment from the last segment, we force a return immediately. however, it could be that the quota is violated and we will return an empty response.",0,0.9830189347267151
76720343,1776,junrao,2016-08-30T02:02:51Z,"to be consistent, should broker be brokers?",0,0.9841675162315369
76720349,1776,junrao,2016-08-30T02:02:55Z,no need to change this line?,0,0.979885995388031
76720356,1776,junrao,2016-08-30T02:03:04Z,this can be private?,0,0.9885194897651672
76720360,1776,junrao,2016-08-30T02:03:07Z,an => a,0,0.9705461263656616
76720364,1776,junrao,2016-08-30T02:03:12Z,could we use the defined name for quota.replication.throttled.replicas?,0,0.9887295365333557
76720369,1776,junrao,2016-08-30T02:03:16Z,missing license header.,0,0.5075617432594299
76720377,1776,junrao,2016-08-30T02:03:19Z,extra space after object,0,0.984885573387146
76720409,1776,junrao,2016-08-30T02:03:46Z,perhaps noquota is better?,0,0.9850311279296875
76720415,1776,junrao,2016-08-30T02:03:51Z,"for clarity, would it be better to rename leaderreplication and followerreplication to leaderquotamanager and followerquotamanager?",0,0.9865527749061584
76720426,1776,junrao,2016-08-30T02:04:01Z,no need for the package name org.apache.kafka.common.utils. ditto two lines below.,0,0.9797938466072083
76720437,1776,junrao,2016-08-30T02:04:14Z,do we really need fetchresponseprocessingcomplete()? could we just do the logic here in processpartitiondata?,0,0.9885146021842957
76720447,1776,junrao,2016-08-30T02:04:22Z,"is this still needed? if not, it seems that we don't need to expose bound() as a public api in replicationquotamanager.",0,0.9875682592391968
76720504,1776,junrao,2016-08-30T02:05:11Z,"does this need to be info? also, don't need to reference logger. there are a few other places like that.",0,0.986063539981842
76720509,1776,junrao,2016-08-30T02:05:16Z,typo excedded,0,0.9881256818771362
76720512,1776,junrao,2016-08-30T02:05:21Z,"hmm, shouldn't we pass in fetch.messageset.sizeinbytes to quota.isquotaexceededby()?",0,0.9858302474021912
76720516,1776,junrao,2016-08-30T02:05:27Z,do we have to read from the log again? it seems that we can just set fetch.messageset to an empty bytebuffermessageset.,0,0.9883092641830444
76720525,1776,junrao,2016-08-30T02:05:31Z,unused import coreutils,0,0.9780722856521606
76720529,1776,junrao,2016-08-30T02:05:37Z,readonlyquota seems a bit too general. perhaps sth like replicaquota?,0,0.8884662985801697
76720550,1776,junrao,2016-08-30T02:05:41Z,bound() => upperbound() to make it clear?,0,0.9879000186920166
76720605,1776,junrao,2016-08-30T02:06:24Z,"this may not be enough since the sensor can be removed after it's inactive for some time (say, throttled replicas are removed). when that happens, sensor will be pointing to an obsolete object. to be safe, we probably need a getorcreatequotasensors() method like in clientquotamanager.",0,0.9859793782234192
76720612,1776,junrao,2016-08-30T02:06:26Z,could this be a val instead of a method?,0,0.9854388236999512
76720626,1776,junrao,2016-08-30T02:06:32Z,"it seems that this can be private? also, getquota() can be just quota().",0,0.9890224933624268
76720637,1776,junrao,2016-08-30T02:06:41Z,"does this need to be at info? also, not need to use logger. info() is enough.",0,0.9763240218162537
76720651,1776,junrao,2016-08-30T02:06:52Z,"hmm, should bound() return int? with things like infiniband, it actually can be legit to set a quota larger than 2gb/sec.",0,0.9885252118110657
76815241,1776,benstopford,2016-08-30T15:11:18Z,"our standard mechanism won't permit commas in config, hence i proposed this. i did actually change the kip.",0,0.9851921796798706
76815773,1776,benstopford,2016-08-30T15:13:40Z,will change to quota.isquotaexceededby(fetchmetadata.fetchminbytes).,0,0.9891370534896851
76816162,1776,benstopford,2016-08-30T15:15:42Z,i'll fix all logging etc when i have something i'm prepared to merge. this is just a first cut remember.,0,0.9772486686706543
76817729,1776,benstopford,2016-08-30T15:22:59Z,yes - that's better.,0,0.9137827754020691
76817871,1776,benstopford,2016-08-30T15:23:42Z,that makes sense. will change. thanks for the heads up.,1,0.9466050863265991
76817957,1776,benstopford,2016-08-30T15:24:08Z,no should be long everywhere. will change.,0,0.9403268694877625
76819932,1776,benstopford,2016-08-30T15:33:39Z,"sorry - deleted previous. as i understand it the fetch, here, is just a single partition's data. thus i'm keeping a running total of throttled bytes in all partitions, checking against the quota to see when the 'proposed' fetch will exceed to. remember isquotaexceededby() doesn't record anything. let me know if i'm missing something.",-1,0.9818453788757324
76946201,1776,ijuma,2016-08-31T08:38:48Z,these should be final and probably exposed via an accessor.,0,0.9863775968551636
76947111,1776,ijuma,2016-08-31T08:44:36Z,"i think ben just meant the `value` parameter to be called `delta`. from an api perspective, it seems like it would make sense to also have a public `checkquota` method if we expose a `checkquotawithdelta`.",0,0.9884054660797119
76948313,1776,ijuma,2016-08-31T08:52:43Z,"not sure i understand, we support multiple items separated by commas in configs via the `list` type.",0,0.975038468837738
76948517,1776,ijuma,2016-08-31T08:54:18Z,not sure if these formatting changes are intended.,0,0.8468212485313416
76948664,1776,ijuma,2016-08-31T08:55:22Z,nitpick: we don't usually include the type annotation for simple local variables like this.,0,0.9815810322761536
76948830,1776,ijuma,2016-08-31T08:56:22Z,it seems to me that the `partitions.map(_.tostring)` doesn't do anything since the default behaviour is to call `tostring` on each element anyway.,0,0.9824692010879517
76958141,1776,ijuma,2016-08-31T09:55:37Z,"generally in scala, you would write this like: [code block]",0,0.9858200550079346
76958968,1776,ijuma,2016-08-31T10:00:47Z,nitpick: we don't need the `string` type annotation.,0,0.9882274270057678
76959741,1776,ijuma,2016-08-31T10:05:48Z,can we not make a copy of kafkaconfig instead?,0,0.9812885522842407
76959836,1776,ijuma,2016-08-31T10:06:36Z,`unboundedquota` maybe?,0,0.9854803681373596
76960609,1776,ijuma,2016-08-31T10:09:22Z,"given that the containing class is `quotamanagers`, it seems like it may be ok to not repeat `quotamanager` for each field. if we do rename it as per jun's suggestion, then we probably should rename `client` too.",0,0.9874502420425415
76961281,1776,ijuma,2016-08-31T10:14:22Z,"this class seems a bit inconsistent in that it groups the client replication types in a map, but not the replication ones. it seems like it might be better to either have them all as fields or all in maps. is there a reason to do it this way instead?",0,0.8745677471160889
76961490,1776,ijuma,2016-08-31T10:16:00Z,it would be nice if a `time` instance was passed instead of hardcoding `systemtime` here.,0,0.9685071110725403
76962421,1776,ijuma,2016-08-31T10:23:20Z,there should be no `unit.` here.,0,0.9827500581741333
76964270,1776,ijuma,2016-08-31T10:37:15Z,nitpick: methods should start with lowercase letter.,0,0.9875565767288208
77510050,1776,benstopford,2016-09-05T11:45:24Z,renamed value->delta. added an (unused) method: public void checkquotas(),0,0.9866926074028015
77542394,1776,benstopford,2016-09-05T16:27:23Z,dynamic configs don't support commas. i've added a task to look at changing this.,0,0.912468433380127
77543779,1776,benstopford,2016-09-05T16:44:59Z,thanks,1,0.6094269156455994
77544027,1776,ijuma,2016-09-05T16:49:06Z,"they should do, see `cleanup.policy` for an example. there's a test in `logcleanerintegrationtest.testcleanscombinedcompactanddeletetopic` that verifies this.",0,0.988923192024231
77544671,1776,benstopford,2016-09-05T16:56:04Z,ok,0,0.9667208194732666
77544719,1776,benstopford,2016-09-05T16:56:56Z,thanks,1,0.6094269156455994
77544895,1776,benstopford,2016-09-05T17:00:00Z,"yes, good spot. thank you.",1,0.9714609384536743
77545048,1776,benstopford,2016-09-05T17:02:02Z,agreed. changed.,0,0.9793924689292908
77545600,1776,benstopford,2016-09-05T17:08:33Z,yeah - it was just used by a test. have changed to test the ensurevalid method instead.,0,0.9870256781578064
77545753,1776,benstopford,2016-09-05T17:11:11Z,done. thanks,1,0.943500280380249
77545866,1776,benstopford,2016-09-05T17:13:16Z,sure can,0,0.9565137028694153
77545936,1776,benstopford,2016-09-05T17:14:33Z,thanks,1,0.6094269156455994
77545961,1776,benstopford,2016-09-05T17:14:59Z,good idea. thanks.,1,0.9704252481460571
77546037,1776,benstopford,2016-09-05T17:16:39Z,added. thanks,1,0.9347068667411804
77546111,1776,benstopford,2016-09-05T17:17:55Z,thanks,1,0.6094269156455994
77546161,1776,benstopford,2016-09-05T17:18:51Z,unboundedquota sounds good to me.,1,0.9121138453483582
77549097,1776,benstopford,2016-09-05T18:16:57Z,yeah - i should have put a comment on that. it's a historical artefact from the way the original client quota managers worked. i knew i had to rework it. it should be a bit better now.,0,0.8667351603507996
77549138,1776,benstopford,2016-09-05T18:17:51Z,done,0,0.9764507412910461
77549657,1776,benstopford,2016-09-05T18:30:34Z,nope. hangover from when we had separate throttled replica fetcher threads. removed.,0,0.9086612462997437
77554690,1776,ijuma,2016-09-05T20:36:09Z,you can express the the rhs of `==` as: [code block],0,0.9879401922225952
77554722,1776,ijuma,2016-09-05T20:36:44Z,is this a left-over debugging thing? it seems like you don't need this var at all.,0,0.9332685470581055
77625349,1776,benstopford,2016-09-06T12:36:06Z,nope. removed.,0,0.8746764659881592
77626384,1776,benstopford,2016-09-06T12:43:41Z,"that test verifies you can create a logconfig object, but doesn't verify that you can update that same log config from the configcommand, which you can't currently.",0,0.9895338416099548
77627001,1776,ijuma,2016-09-06T12:48:10Z,"interesting, this is an issue for kip-71 too then. cc",0,0.8567328453063965
77632698,1776,dguy,2016-09-06T13:23:27Z,"hmm, yes indeed. it appears configcommand doesn't like commas. topiccommand otoh does.",0,0.756814181804657
77806141,1776,benstopford,2016-09-07T11:44:55Z,thanks,1,0.6094269156455994
77806226,1776,benstopford,2016-09-07T11:45:37Z,ok,0,0.9667208194732666
77806309,1776,benstopford,2016-09-07T11:46:13Z,good idea.,1,0.9657697081565857
77855115,1776,benstopford,2016-09-07T16:14:31Z,"have extracted the logic from the clientquotamanager and reused, which, i think, is better!",0,0.8859408497810364
77855598,1776,benstopford,2016-09-07T16:17:02Z,sure can.,0,0.9159873723983765
77855719,1776,benstopford,2016-09-07T16:17:42Z,yes. thanks,1,0.9150292873382568
77855772,1776,benstopford,2016-09-07T16:18:04Z,will do all these at the end.,0,0.9828345775604248
77855817,1776,benstopford,2016-09-07T16:18:21Z,this was changed,0,0.9847129583358765
77856461,1776,benstopford,2016-09-07T16:22:17Z,"i wouldn't typically add accessors here, although i would have some years back. if you're super keen on this kind of stuff i'll change.",0,0.9449849724769592
77856804,1776,benstopford,2016-09-07T16:24:06Z,nope. removed,0,0.9357771873474121
77857026,1776,benstopford,2016-09-07T16:25:25Z,good spot. thank you.,1,0.9745610356330872
77857237,1776,benstopford,2016-09-07T16:26:34Z,cool. thanks.,1,0.9779167771339417
77862056,1776,benstopford,2016-09-07T16:53:20Z,changed,0,0.9773849844932556
77868592,1776,benstopford,2016-09-07T17:31:01Z,"interesting. so it's not actually used anywhere. the value is just passed into the quota managers, following the same pattern used in the clientquotamanager. so maybe we don't need to change kafkaconfig at all? what do you think?",0,0.9444069862365723
77873545,1776,ijuma,2016-09-07T17:59:02Z,"i'm not super-keen on the accessors, it's just the general kafka convention. i'm keen on the fields being `final` though. also, do we want `value` and `bound` to be nullable? if not, then they should be lowercase `double`.",0,0.6056467294692993
77880926,1776,benstopford,2016-09-07T18:44:11Z,ok,0,0.9667208194732666
77881060,1776,benstopford,2016-09-07T18:44:55Z,thanks,1,0.6094269156455994
77881100,1776,benstopford,2016-09-07T18:45:11Z,ok,0,0.9667208194732666
77881343,1776,benstopford,2016-09-07T18:46:39Z,ah yes. thanks,1,0.909209132194519
77881777,1776,benstopford,2016-09-07T18:49:13Z,it most certainly is. thank you. i'll do a refactor of these tests in my final pass.,1,0.9659789800643921
77893695,1776,benstopford,2016-09-07T20:06:14Z,ok - changed,0,0.9755723476409912
77974298,1776,ijuma,2016-09-08T09:34:33Z,"we are leaking the thread right? if you just want to execute something in the background, you can do something like: [code block] if you store the future, you can also await on the result or just completion by using `await.result` or `await.ready` (probably not applicable in this case, but worth knowing).",0,0.9879321455955505
78008266,1776,benstopford,2016-09-08T13:45:41Z,thanks. good to know.,1,0.9664340615272522
78140580,1776,ijuma,2016-09-09T07:45:12Z,nitpick: `value` and `bound` should be lowercase `double` since they can't be null (annoying that scala and java are different in this respect so it's a bit confusing when writing code in both languages).,-1,0.6920729875564575
78140755,1776,ijuma,2016-09-09T07:46:58Z,nitpick: should be `brokers` to be consistent with the other ones? or should the other ones be made singular?,0,0.9881991147994995
78141062,1776,ijuma,2016-09-09T07:49:48Z,nitpick: no return needed and no blocks are needed. example: [code block],0,0.9875439405441284
78141122,1776,ijuma,2016-09-09T07:50:16Z,i'd include the `broker` variable in the message.,0,0.9879316687583923
78141182,1776,ijuma,2016-09-09T07:50:49Z,i think it would be a bit better if this method returned an `int` and the caller just wrapped the result in `seq(...)`.,0,0.9824491739273071
78141363,1776,ijuma,2016-09-09T07:52:32Z,"seems like this code would be a bit nicer if we had a `val supportedtypes = set(configtype.topic, configtype.client, configtype.broker)` somewhere.",0,0.9379501938819885
78141952,1776,ijuma,2016-09-09T07:58:20Z,"maybe something like: [code block] i think you also need to handle errors if the format doesn't match what you expect, right? at the moment, we will get unhelpful `arrayoutofboundsexception`s and `numberformatexception`s.",0,0.9833964705467224
78142068,1776,ijuma,2016-09-09T07:59:32Z,"i see that there's a `throttledreplicavalidator`, is that ensuring that things will be in the right format by the time we get here?",0,0.9871123433113098
78142129,1776,ijuma,2016-09-09T08:00:03Z,nitpick: space after `:`,0,0.9732754826545715
78142280,1776,ijuma,2016-09-09T08:01:30Z,"unless i am missing something, i think this should take a `string` since the caller is passing it a `string`. then you don't need `tostring` below.",0,0.9878374338150024
78142342,1776,ijuma,2016-09-09T08:02:13Z,this message doesn't mention `broker`. another case where having a definition of supported types would make the code more robust.,0,0.9883644580841064
78142470,1776,ijuma,2016-09-09T08:03:42Z,wouldn't it be better to have a `shutdown()` in `quotas` that closes all of them?,0,0.977436363697052
78142661,1776,ijuma,2016-09-09T08:05:36Z,it doesn't seem like this is used any more.,-1,0.6024250984191895
78142693,1776,ijuma,2016-09-09T08:05:55Z,do we still need this?,0,0.9832133054733276
78142931,1776,ijuma,2016-09-09T08:08:06Z,"maybe this should be `def props(map: map[string, string])` and then you would use it like: [code block]",0,0.9852869510650635
78143052,1776,ijuma,2016-09-09T08:09:27Z,thanks for changing the calling code. can we remove this method then?,1,0.8131021857261658
78143150,1776,ijuma,2016-09-09T08:10:18Z,have you seen `testutils.producemessages`?,0,0.9859727621078491
78143190,1776,ijuma,2016-09-09T08:10:43Z,`unit.` should not be here.,0,0.9369078278541565
78147862,1776,benstopford,2016-09-09T08:52:10Z,"good point. i've changed to ""add/remove entity config for a topic, client or broker"" (command only lets you change one at a time)",1,0.9638081192970276
78147928,1776,benstopford,2016-09-09T08:52:40Z,thanks,1,0.6094269156455994
78148028,1776,benstopford,2016-09-09T08:53:24Z,good idea. thanks,1,0.9857035279273987
78148279,1776,benstopford,2016-09-09T08:55:32Z,ok,0,0.9667208194732666
78149087,1776,benstopford,2016-09-09T09:02:07Z,definitely!,1,0.9193860292434692
78149712,1776,benstopford,2016-09-09T09:06:56Z,yep. that's the idea.,0,0.9581373929977417
78150344,1776,benstopford,2016-09-09T09:11:59Z,"it just means the tostring has to be called in the ensurevalid method, so six of one and half a dozen of the other. unless i'm missing something.",0,0.98216313123703
78150565,1776,benstopford,2016-09-09T09:13:27Z,done (with enumerated list),0,0.9867604970932007
78150976,1776,benstopford,2016-09-09T09:16:47Z,ok.,0,0.9735831022262573
78151082,1776,benstopford,2016-09-09T09:17:29Z,thanks,1,0.6094269156455994
78151223,1776,benstopford,2016-09-09T09:18:29Z,yep. it's the definitive list of broker configs you can change.,0,0.9812899231910706
78151950,1776,benstopford,2016-09-09T09:23:48Z,have removed & refactored original. was a bit pointless.,-1,0.966160774230957
78152713,1776,ijuma,2016-09-09T09:30:00Z,"no, you don't need to do that because of the pattern matching clause. you have to pass `s` instead of `value`.",0,0.9858090281486511
78154280,1776,benstopford,2016-09-09T09:42:58Z,have changed,0,0.9697598814964294
78154318,1776,benstopford,2016-09-09T09:43:19Z,thanks,1,0.6094269156455994
78159088,1776,benstopford,2016-09-09T10:28:01Z,"ah, gottcha. thanks",1,0.9764022827148438
78160093,1776,benstopford,2016-09-09T10:37:03Z,"i've consolidated onto a single class, keeping simplerate. this encompasses a different approach to fixing kafka-2567 whilst being a little simpler to test.",0,0.9653307199478149
78160165,1776,benstopford,2016-09-09T10:37:41Z,ok,0,0.9667208194732666
78160327,1776,benstopford,2016-09-09T10:39:04Z,done. thanks.,1,0.8661708235740662
78231105,1776,benstopford,2016-09-09T18:54:39Z,"i've added support for comma separated lists in the configcommand. you specify the list using a square bracket: k1=v1,k2=[v2,v3]",0,0.9854899644851685
78249903,1776,apurvam,2016-09-09T21:12:02Z,nitpick: would it be better to just use `messageset` from line 118 instead of doing `partitiondata.tobytebuffermessageset` again? this way you save an allocation.,0,0.9886628985404968
78259626,1776,apurvam,2016-09-09T22:40:41Z,would this be better as a typed enum rather than a string? makes compile time checks stronger.,0,0.9837383031845093
78265368,1776,apurvam,2016-09-10T00:04:53Z,"this message doesn't match the test. shouldn't it be ""throttled replication of n ms should > m ms""",0,0.9705033898353577
78269010,1776,junrao,2016-09-10T02:01:24Z,timems in the comment is no long valid.,0,0.842541515827179
78269016,1776,junrao,2016-09-10T02:01:46Z,"having two different rates is going to make it harder for developers to decide which one to use. if this is strictly better than rate, perhaps we should just change rate.windowsize(). if this is just for testing, perhaps we can create simplerate in test?",0,0.9718002676963806
78269021,1776,junrao,2016-09-10T02:01:54Z,"the comment in line 470 doesn't seem to match the test. also, space before 0.",0,0.9529798626899719
78269023,1776,junrao,2016-09-10T02:02:00Z,is this comment accurate?,0,0.9796374440193176
78269027,1776,junrao,2016-09-10T02:02:03Z,space before {,0,0.9769270420074463
78269029,1776,junrao,2016-09-10T02:02:07Z,space after if,0,0.9781984090805054
78269031,1776,junrao,2016-09-10T02:02:13Z,this doesn't seem to be used?,0,0.9678369760513306
78269033,1776,junrao,2016-09-10T02:02:17Z,does --execute block?,0,0.98692387342453
78269036,1776,junrao,2016-09-10T02:02:20Z,b/s => bytes/sec ?,0,0.9877663850784302
78269040,1776,junrao,2016-09-10T02:02:33Z,addthrottle => maybeaddthrottle ?,0,0.9850135445594788
78269041,1776,junrao,2016-09-10T02:02:37Z,unused import javaconverters,0,0.982804536819458
78269052,1776,junrao,2016-09-10T02:03:12Z,"if quota is not exceeded, should we check (accumulatedsize + accumulatedthrottledsize) >= fetchmetadata.fetchminbytes?",0,0.9892336130142212
78269056,1776,junrao,2016-09-10T02:03:18Z,extra space before result,0,0.9838083386421204
78269059,1776,junrao,2016-09-10T02:03:22Z,a few unused imports.,0,0.9768722057342529
78269063,1776,junrao,2016-09-10T02:03:29Z,the upper bound => the upper bound in bytes/sec ?,0,0.9882982969284058
78269069,1776,junrao,2016-09-10T02:03:42Z,unused import,0,0.9649426341056824
78269090,1776,junrao,2016-09-10T02:04:27Z,would it be better to just check quota.isquotaexceeded once and make the same decision for each throttled partition on whether it should be included or not?,0,0.9892464280128479
78269091,1776,junrao,2016-09-10T02:04:31Z,there is already a trace statement in abstractfetcherthread that logs each fetch request. do we still need this trace logging?,0,0.9899508357048035
78269148,1776,junrao,2016-09-10T02:07:42Z,unused imports metricname and rate.,0,0.9745487570762634
78269151,1776,junrao,2016-09-10T02:07:48Z,allreplicas instead?,0,0.9814976453781128
78269161,1776,junrao,2016-09-10T02:08:16Z,the above may not be 100% safe since the metric could be expired and removed between the two statements. it's safer if we save metrics.metrics.get(ratemetricname) to a local val and then check null and update the config.,0,0.9872649908065796
78269165,1776,junrao,2016-09-10T02:08:23Z,"since sensor() has side effect, it would be clearer if all references to sensor are sensor().",0,0.9864897727966309
78269169,1776,junrao,2016-09-10T02:08:44Z,"the convention is to use trace() which does does the if check already. also, for string formatting, we are moving towards the s notation instead of format. ditto in a few other places.",0,0.9803534746170044
78269173,1776,junrao,2016-09-10T02:08:56Z,partitions == allreplicas should probably be partitions eq allreplicas?,0,0.987136960029602
78269178,1776,junrao,2016-09-10T02:09:08Z,"to be consistent, if there is no return value, we just do method() {}.",0,0.9871290922164917
78269179,1776,junrao,2016-09-10T02:09:11Z,"if partitions is empty, should we remove that topic from the map?",0,0.9857274889945984
78269182,1776,junrao,2016-09-10T02:09:18Z,is there a reason to remove these? it seems the test is still useful.,0,0.9789929986000061
78269185,1776,junrao,2016-09-10T02:09:21Z,unused import,0,0.9649426341056824
78269187,1776,junrao,2016-09-10T02:09:25Z,10 sec seems inaccurate now?,0,0.8657703995704651
78269190,1776,junrao,2016-09-10T02:09:29Z,is this really done in a separate thread?,0,0.9779661297798157
78269192,1776,junrao,2016-09-10T02:09:33Z,1 second seems inaccurate now?,0,0.8340327739715576
78269194,1776,junrao,2016-09-10T02:09:34Z,20s seems inaccurate now?,0,0.8839707374572754
78269197,1776,junrao,2016-09-10T02:09:37Z,remove unit,0,0.9783926010131836
78269199,1776,junrao,2016-09-10T02:09:41Z,is len 100 or 1?,0,0.9825567603111267
78269200,1776,junrao,2016-09-10T02:09:44Z,unused imports,0,0.9686665534973145
78269203,1776,junrao,2016-09-10T02:09:49Z,could this and next method be private?,0,0.9873721599578857
78269206,1776,junrao,2016-09-10T02:09:56Z,"do we ""put replicas for all partitions on the not-started brokers""?",0,0.98751300573349
78269212,1776,junrao,2016-09-10T02:10:06Z,the text in here and line 172 seem inaccurate.,0,0.5507435202598572
78269223,1776,junrao,2016-09-10T02:10:35Z,"with this, after recording the bytes, the quota could be exceeded? the earlier approach where we use quota.isquotaexceed(expectedbytes) seems more conservative and is less likely for quota to be exceeded. is there a reason not to use quota.isquotaexceed(expectedbytes)?",0,0.9844217300415039
78298061,1776,junrao,2016-09-11T16:29:39Z,"it seems that we need to handle case c better. if the follower is lagging on old segments and the quota is exceeded, we may return an empty result well before max wait. returning an empty result early occasionally is fine. however, in this case, it seems that this can happen continuously.",0,0.9800319671630859
78298089,1776,junrao,2016-09-11T16:31:28Z,"there could be a subtle issue with timeout. say we check the quota and it's exceeded, and we will put the delayedfetch in the purgatory. if no more bytes are produced, the delayedfetch has to wait for maxwait. however, quota could become available before maxwait (and we won't get a chance to check). one potential way to address this is that if quota is exceeded, we calculate the amount of time that needs to pass before quota is available. we set the timeout in delayedfetch to the be smaller of that time and maxwait. then, if delayedfetch expires, in delayedfetch.oncomplete(), if minbytes is not satisfied and maxwait hasn't been exceeded. we put delayedfetch to purgatory again.",0,0.9719803929328918
78318335,1776,benstopford,2016-09-12T06:02:51Z,thanks,1,0.6094269156455994
78320891,1776,benstopford,2016-09-12T06:39:58Z,yes. agree.,0,0.9607426524162292
78321116,1776,benstopford,2016-09-12T06:43:20Z,thanks. changed.,1,0.7721272110939026
78321156,1776,benstopford,2016-09-12T06:43:49Z,thanks,1,0.6094269156455994
78321274,1776,benstopford,2016-09-12T06:45:31Z,good spot. thanks,1,0.9856686592102051
78321313,1776,benstopford,2016-09-12T06:46:10Z,yes it is. have clarified the test comment a bit.,0,0.9824897050857544
78321694,1776,benstopford,2016-09-12T06:51:30Z,thanks,1,0.6094269156455994
78321704,1776,benstopford,2016-09-12T06:51:34Z,thanks,1,0.6094269156455994
78321742,1776,benstopford,2016-09-12T06:52:05Z,oops - thanks,1,0.8956856727600098
78321998,1776,benstopford,2016-09-12T06:54:54Z,no. mistake. thanks,1,0.7294183969497681
78322063,1776,benstopford,2016-09-12T06:55:42Z,done,0,0.9764507412910461
78322189,1776,benstopford,2016-09-12T06:57:17Z,done. thanks,1,0.943500280380249
78322192,1776,benstopford,2016-09-12T06:57:21Z,done. thanks,1,0.943500280380249
78322413,1776,benstopford,2016-09-12T07:00:09Z,yes. that's a great spot. thank you.,1,0.9894810914993286
78322533,1776,benstopford,2016-09-12T07:01:44Z,thanks,1,0.6094269156455994
78322678,1776,benstopford,2016-09-12T07:03:28Z,good spot,1,0.9642012715339661
78322720,1776,benstopford,2016-09-12T07:03:59Z,thanks,1,0.6094269156455994
78323225,1776,benstopford,2016-09-12T07:09:45Z,sure thing.,0,0.9316359758377075
78323280,1776,benstopford,2016-09-12T07:10:27Z,thanks. removed,0,0.7752184867858887
78323319,1776,benstopford,2016-09-12T07:10:54Z,thanks,1,0.6094269156455994
78323346,1776,benstopford,2016-09-12T07:11:08Z,ok. cool,1,0.9507402777671814
78325258,1776,benstopford,2016-09-12T07:31:41Z,i've changed this both here and also in the clientquotamanager (which had the same logic),0,0.988477349281311
78325391,1776,benstopford,2016-09-12T07:33:06Z,yes - good call. thanks,1,0.9818994998931885
78326425,1776,benstopford,2016-09-12T07:43:20Z,thanks for the heads up. changed,1,0.8275603652000427
78327387,1776,benstopford,2016-09-12T07:51:33Z,ok - makes sense.,0,0.9647176861763
78328609,1776,benstopford,2016-09-12T08:02:26Z,ok - thanks for the heads up - have changed tidied up where this was wrong elsewhere too.,0,0.6932000517845154
78333596,1776,ijuma,2016-09-12T08:40:30Z,probably unintended change?,0,0.7035260200500488
78333653,1776,ijuma,2016-09-12T08:40:58Z,probably unintended change?,0,0.7035260200500488
78404954,1776,benstopford,2016-09-12T16:22:47Z,"no, i missed that somehow. have added it now.",-1,0.5929274559020996
78406716,1776,benstopford,2016-09-12T16:32:52Z,how strange. that was removed when i merged from my previous branch. good spot.,1,0.9690176248550415
78407140,1776,benstopford,2016-09-12T16:35:15Z,thanks,1,0.6094269156455994
78407153,1776,benstopford,2016-09-12T16:35:20Z,thanks,1,0.6094269156455994
78407241,1776,benstopford,2016-09-12T16:36:03Z,it certainly isn't! thanks.,1,0.9521583318710327
78407355,1776,benstopford,2016-09-12T16:36:44Z,thanks,1,0.6094269156455994
78407542,1776,benstopford,2016-09-12T16:38:05Z,thanks,1,0.6094269156455994
78407632,1776,benstopford,2016-09-12T16:38:36Z,thanks,1,0.6094269156455994
78407763,1776,benstopford,2016-09-12T16:39:17Z,thanks,1,0.6094269156455994
78407832,1776,benstopford,2016-09-12T16:39:39Z,thanks,1,0.6094269156455994
78408120,1776,benstopford,2016-09-12T16:41:14Z,sure can,0,0.9565137028694153
78408614,1776,benstopford,2016-09-12T16:44:06Z,clarified. thanks,1,0.8875202536582947
78410438,1776,benstopford,2016-09-12T16:54:31Z,"yes - the idea seemed like a good one, but it led to some complexities. the main problem was that the ratio of the requestsize:quotasize correlated with the amount the throttle would be undercut. also, if you asked for more than the quota in a single request you could never make progress. the upshot was that the behaviour was a little unintuitive, and the simpler mechanism seems to work well on aggregate. so after thinking about it for a while i decided to ditch the isexceededby(bytes) approach. keep it simple ... and this way it more closely matches the way the follower works more closely. i hope that makes sense.",0,0.8460527658462524
78411666,1776,benstopford,2016-09-12T17:02:01Z,"i did consider this issue. you are right that we could make the leader algorithm more responsive by altering the timeout (i didn't think of that - good idea). for now i'm inclined to raise a jira for this as a future enhancement. it shouldn't affect throttling significantly. the extra delay will even out over time. also, this problem exists on the follower too so the optimisation is only of value for the leader side of the throttle. the main concern i have is actually the lack of smarts on the follower, particularly if throttled partitions enter the isr, as the follower logic is very basic.",0,0.6026901006698608
78412609,1776,benstopford,2016-09-12T17:07:49Z,thanks,1,0.6094269156455994
78412775,1776,benstopford,2016-09-12T17:08:59Z,thanks,1,0.6094269156455994
78432823,1776,benstopford,2016-09-12T18:56:06Z,good spot. i think this should be as simple as: [code block] but i'll need to write a test which will take a little time.,1,0.9560902714729309
78783831,1776,junrao,2016-09-14T16:25:33Z,"yes, the follower has a similar issue. there is already logic to add a delay per partition. so, if a partition is throttled in the follower, we can calculate a delay from quota and delay the partition accordingly. we probably also need to change the backoff logic in abstractfetcherthread a bit. instead of always backing off for a fixed amount of time, it's probably better to backoff based on the smallest delay among all partitions. i agree that this is probably not a common issue. it only becomes a big issue if the maxwait or replica backoff time are configured very large (say close to the metric window \* sample size). so, we can address that in a followup jira.",0,0.9388908743858337
78865421,1776,junrao,2016-09-14T23:43:57Z,"processconfigchanges() only gets called if there is overridden config on brokerid in zk. so, if that doesn't exist, it seems that we won't apply the static default throttledreplicationlimit in broker property file?",0,0.9883026480674744
78865431,1776,junrao,2016-09-14T23:44:05Z,extra space after :,0,0.9803276658058167
78865451,1776,junrao,2016-09-14T23:44:17Z,throttle should be type long?,0,0.9868886470794678
78865458,1776,junrao,2016-09-14T23:44:22Z,convention: use trace().,0,0.9855020046234131
78865572,1776,junrao,2016-09-14T23:45:23Z,unused import,0,0.9649426341056824
78865576,1776,junrao,2016-09-14T23:45:27Z,typo bakc,0,0.98499596118927
78865588,1776,junrao,2016-09-14T23:45:34Z,"perhaps we should just test excluding the property, which is consistent with the test in line 484?",0,0.9858130812644958
78865602,1776,junrao,2016-09-14T23:45:40Z,should we make limit long since throttledreplicationratelimitprop is of type long?,0,0.9882404804229736
78865609,1776,junrao,2016-09-14T23:45:44Z,take => taken,0,0.9837632179260254
78865626,1776,junrao,2016-09-14T23:45:49Z,are we using a separate thread?,0,0.9826816916465759
78865633,1776,junrao,2016-09-14T23:45:55Z,are we using a separate thread?,0,0.9826816916465759
78865643,1776,junrao,2016-09-14T23:46:00Z,should this be private?,0,0.9837396740913391
78893471,1776,junrao,2016-09-15T05:47:04Z,"i think we can just get rid of the static config throttledreplicationratelimitprop and just rely on the dynamic broker level config, which is more flexible.",0,0.982201874256134
78959050,1776,benstopford,2016-09-15T13:10:37Z,"yes - i raised a bug for this, but it's not a big deal so lets lose the config it as you say.",0,0.7559295892715454
78959367,1776,benstopford,2016-09-15T13:12:20Z,thanks. done,1,0.8847576975822449
78959375,1776,benstopford,2016-09-15T13:12:24Z,thanks. done,1,0.8847576975822449
78959967,1776,benstopford,2016-09-15T13:15:33Z,thanks,1,0.6094269156455994
78959976,1776,benstopford,2016-09-15T13:15:37Z,thanks,1,0.6094269156455994
78961026,1776,benstopford,2016-09-15T13:20:52Z,"we have that already on line 428. are you concerned about it being there, or objecting to the format of the test?",-1,0.53672194480896
78961219,1776,benstopford,2016-09-15T13:21:56Z,ok,0,0.9667208194732666
78979265,1776,benstopford,2016-09-15T14:38:40Z,"the nice thing about having it in the config is validation. if we remove the prop, we'd probably need another list of dynamic broker configs somewhere. what do you think?",0,0.8074803948402405
78994469,1776,junrao,2016-09-15T15:38:36Z,"yes, we are doing similar things in kip-55. we are deprecating the static client quota configs in the broker in favor of dynamic quotas. so, for new broker configs, if it can be made dynamically, it seems it's less confusing to also add a static config in the broker property.",0,0.9700227975845337
79071084,1776,apurvam,2016-09-15T21:57:41Z,"you should log a message here, with information of the old and new quota topic for the broker/topic/partition being modified. otherwise these dynamic changes without any auditing will be impossible to debug.",0,0.9868046045303345
79080424,1776,benstopford,2016-09-15T23:03:46Z,it should be visible from the logging in the dynamicconfigmanager (line 106). do you not see that?,0,0.9867977499961853
79080650,1776,apurvam,2016-09-15T23:05:40Z,"yes, i see it now. sorry for the false alarm.",-1,0.986876368522644
1379392210,14690,kirktrue,2023-11-01T22:26:33Z,"now that i'm noticing, is this a public api violation? it's not in `internals` and we're adding a `public` method :thinking_face:",0,0.9309017658233643
1379396122,14690,kirktrue,2023-11-01T22:31:10Z,nit: more idiomatic: [code block],0,0.9821871519088745
1379398154,14690,kirktrue,2023-11-01T22:34:25Z,"i'm probably confused by taking the naming of the `onheartbeatrequestsent` method too literally, but the request hasn't been _sent_, only _enqueued_. do we need to call this when it's really _sent_ or is enqueued ""good enough?""",0,0.8001819252967834
1379399402,14690,kirktrue,2023-11-01T22:36:41Z,"this is the case where the consumer is not in a group _presently_, right? a consumer without a configured group id wouldn't get to this point, would it?",0,0.9793893694877625
1379400497,14690,kirktrue,2023-11-01T22:38:28Z,"as i understand, this is saying the consumer will leave the `acknowledging_reconciled_assignment` state as soon as the next heartbeat is sent off, rather than the next heartbeat is received, right? what happens if that heartbeat request gets lost?",0,0.9791443943977356
1379402695,14690,kirktrue,2023-11-01T22:42:06Z,"sorry to retread this: how are `leaving_group` and `sending_leave_request` different? they both will call the `onpartitionslost()` callback first, right?",-1,0.9883925318717957
1379404682,14690,kirktrue,2023-11-01T22:45:53Z,does the consumer transition from `join` to `reconciling` mean that the first heartbeat response after the join request will (may?) contain an assignment?,0,0.9868043661117554
1379407419,14690,kirktrue,2023-11-01T22:50:32Z,`targetassignment()` looks to only be used by unit tests at the moment. does it make sense to remove it from the interface and leave it as a method on the implementation only?,0,0.9859064817428589
1379408357,14690,kirktrue,2023-11-01T22:52:23Z,can this be called directly via the `applicationeventprocessor` when the consumer sends an event to the network thread to state it is closing? the only other place i see it called at the moment is from a unit test.,0,0.9874487519264221
1379413852,14690,kirktrue,2023-11-01T23:02:28Z,"the ide is showing this line with a warning because it's invoking `get()` without a `ispresent()` check. i know that it's being set in `settargetassignment` right above, but can we refactor this code to make it more obvious to the compiler (and any humans reading it)? here's a quick take: [code block] that way all the logic is together and we can remove `settargetassignment()`, too. just a thought.",0,0.9787013530731201
1379415462,14690,kirktrue,2023-11-01T23:05:54Z,would you mind making a constant for `-1` just so it's easier to grep through the code and find places where the consumer is in this state?,0,0.9863796830177307
1379415743,14690,kirktrue,2023-11-01T23:06:34Z,"same here, regarding the magic numbers.",0,0.9838363528251648
1379418198,14690,kirktrue,2023-11-01T23:11:23Z,"i guess it's ok to use `consumermetadata` directly like this as we ""own"" updating it on the consumer network thread.",0,0.986129105091095
1379419317,14690,kirktrue,2023-11-01T23:13:40Z,"yes, we'll have to resolve how the callbacks fit into this model that uses `future`s, because the callbacks need to be invoked on the application thread.",0,0.9874398708343506
1379420036,14690,kirktrue,2023-11-01T23:15:16Z,i made a comment up above about removing `targetassignment()` from the `membershipmanager` interface because it was only used for testing. does the removal of this statement imply that it will be used in non-testing later?,0,0.9851711392402649
1379420603,14690,kirktrue,2023-11-01T23:16:23Z,"would it be ""wrong"" to have the method implementation log the message instead of throwing an error?",0,0.8786076307296753
1379420811,14690,kirktrue,2023-11-01T23:16:48Z,this makes sense!,1,0.7091817259788513
1379422902,14690,kirktrue,2023-11-01T23:20:46Z,"two questions: 1. `topic` wants to unify the topic id and topic name information, but it explicitly allows either to be `null`. technically, since there are no checks, both values could be `null`. is that intentional? 2. notwithstanding the above, can we add this class without a kip? if not, can we move it to `o.a.k.common.internals`?",0,0.977292537689209
1379423191,14690,kirktrue,2023-11-01T23:21:23Z,"this would throw a `nullpointerexception`, wouldn't it?",0,0.9790025949478149
1380063605,14690,AndrewJSchofield,2023-11-02T13:00:44Z,"i see what means, but this package is not part of the public javadoc. the closest that the public interface has to exposing this kind of information is `org.apache.kafka.common.cluster`.",0,0.9864134788513184
1380073097,14690,AndrewJSchofield,2023-11-02T13:07:41Z,"i'm surprised that the previous valid states for fatal is not all of the other states, such as fenced.",-1,0.7248225808143616
1380077957,14690,AndrewJSchofield,2023-11-02T13:11:42Z,`topicidpartition`? you do know the topic ids and they're relevant for guarding against topics which have been recreated.,0,0.9869802594184875
1380079966,14690,AndrewJSchofield,2023-11-02T13:13:15Z,"i suggest ""skip sending the heartbeat to the coordinator"". i do like the method naming convention you're establishing with ""skip"" in the name.",0,0.7323482632637024
1380080844,14690,AndrewJSchofield,2023-11-02T13:14:02Z,"just ""leaving"" would match the other states better.",0,0.9791353344917297
1380083241,14690,AndrewJSchofield,2023-11-02T13:16:03Z,`transitiontojoining`?,0,0.987980306148529
1380083590,14690,AndrewJSchofield,2023-11-02T13:16:20Z,`transitiontofatal`?,0,0.9868721961975098
1380086392,14690,AndrewJSchofield,2023-11-02T13:18:34Z,"personally, i'd capture the value of `state()` in a local variable and then use it twice, rather than calling the method twice. there are a couple of instances of this.",0,0.9882757663726807
1380088445,14690,AndrewJSchofield,2023-11-02T13:20:16Z,"i think so. also, the set return by `consumermetadata` is immutable.",0,0.9860535264015198
1380090093,14690,AndrewJSchofield,2023-11-02T13:21:37Z,i think that theoretically it could and the action you've proposed is correct.,0,0.9809891581535339
1380092591,14690,AndrewJSchofield,2023-11-02T13:23:36Z,interesting :),1,0.9480985403060913
1380121804,14690,AndrewJSchofield,2023-11-02T13:31:50Z,i would say that it needs a kip in this package.,0,0.9862563014030457
1380144482,14690,AndrewJSchofield,2023-11-02T13:35:57Z,`objects.hashcode()` is your friend.,0,0.9836122393608093
1380218718,14690,lianetm,2023-11-02T14:17:40Z,totally! i missed that,1,0.9791530966758728
1380372614,14690,lianetm,2023-11-02T15:53:22Z,"that was considering that the member could only got to fatal from states where it sends heartbeat, when receiving non-retriable errors in the heartbeat response (and states like fenced or leaving do not send heartbeat)",0,0.9812265634536743
1380393617,14690,AndrewJSchofield,2023-11-02T16:06:13Z,that's ok. i was just asking an innocent question. makes sense to me.,0,0.704832136631012
1380592053,14690,lianetm,2023-11-02T17:59:27Z,"i expect that topic class will be exposed at some point, as we spread the usage of topic id in the client code, that's why i added it there, but totally missed that it could then require a kip. so i just moved it to the internal package, as it is truly only internal for now.",0,0.8858903050422668
1380659584,14690,lianetm,2023-11-02T19:06:20Z,"i moved it to the internals for now, as it's truly for internal use (even though i expect we might want something similar later on as we use topicid more in the client code).",0,0.9879329800605774
1380660843,14690,lianetm,2023-11-02T19:07:45Z,"you're right, this is the case where a consumer, with a groupid, is not part of the group (either it hasn't called subscribed, or it called unsubscribe)",0,0.9604055881500244
1380683789,14690,lianetm,2023-11-02T19:31:50Z,"this is the check we discussed earlier about target assignment and subscription. leaving it for now only so you can see exactly what it is, but we can remove it then if we still think it should be better to let the broker drive this.",0,0.9873514771461487
1380693973,14690,lianetm,2023-11-02T19:43:42Z,"good catch, i needed it public at some point but it ended up not being needed in the end. so putting it back to package-private and ""visible for testing""",1,0.9018669128417969
1380694833,14690,lianetm,2023-11-02T19:44:42Z,"totally, it seemed it was needed here at some point but not anymore. removing it & cleaning up, thanks!",1,0.9677466750144958
1381667636,14690,dajac,2023-11-03T13:17:23Z,nit: i think that we tend to indent with 4 spaces in this case.,0,0.9768113493919373
1381676706,14690,dajac,2023-11-03T13:25:32Z,"i think that this is not enough because we only need to send it if it has changed and we also need to re-send them on failure. i was thinking about introducing a stateful builder object for the request which remembers the last fields sent out and decider whether the fields must be set or not. on errors, we could just reset the builder to re-send all fields. i think that could possibly always set all the fields in this pr and tackle this separately as we need to solve it more generally. what do you think?",0,0.8782659769058228
1381679771,14690,dajac,2023-11-03T13:27:57Z,i am not a big fan of the `not_in_group` name because the consumer could still have a group id configured and commit offsets to a group. this is why i used `unsubscribed` earlier. i wonder if we could find a better name... what do you think?,-1,0.9766124486923218
1381680532,14690,dajac,2023-11-03T13:28:35Z,could we extend the description to explain what we do in this state? i would also do it for the others.,0,0.9849495887756348
1381683004,14690,dajac,2023-11-03T13:30:21Z,"so i i understand it correctly, the member transitions to this state as soon as the reconciliation is done and then transition to stable as soon as the ack is sent out. did i get it right?",0,0.9812219738960266
1381683686,14690,dajac,2023-11-03T13:30:53Z,do we call `lost` in this case?,0,0.9831470847129822
1381686009,14690,dajac,2023-11-03T13:32:50Z,i also wonder if we should call it `acknowledging` to follow the naming of the other states. thoughts?,0,0.7548902034759521
1381688086,14690,dajac,2023-11-03T13:34:36Z,"my understanding is that `leaving` do the pre-leaving steps (e.g. pause partitions, commit offsets, etc) while `sending_leave_request` sends out the actually leave request. perhaps, using `prepare_leaving` and `leaving` would make it clearer. thoughts?",0,0.9814572334289551
1381690930,14690,dajac,2023-11-03T13:36:52Z,i think that we already define them in the `consumergroupheartbeatrequest` class. we could reuse them.,0,0.9835224747657776
1381692974,14690,dajac,2023-11-03T13:38:13Z,`targetassignment` seems to be accessible directly. do we really need to pass it here?,0,0.987129271030426
1381801641,14690,dajac,2023-11-03T14:44:53Z,"okay. i think that we could get into this situations in two cases. 1. an assigned topic was just created and the metadata request got to a broker unaware of it yet. in this case, ignoring it means that the newly created topic will never be consumed by the member. or, at least, it won't be consumed until another assignment is received. in the current implementation, i think that the fetcher will keep retrying on those topics. ideally, we would need something similar here. 2. an assigned topic was just deleted before the member got the chance to get the metadata. this is somewhat the opposite case. in the case of 1., we could argue that we should just keep retrying until it succeeds and it should eventually succeed. in this case of 2., it would never succeed if the topic is deleted so the member will never send an ack and will eventually be kicked out from the group. to make it worst, the member won't receive an new assignment without the deleted topic because the previous assignment is not ack'ed. the issue is that there is no way to differentiate the two cases. ideally, we should set the subscription based on the topic ids instead of the topic names. however, this does not resolve the need to have the topic names for the callbacks. there are really annoying... another thing that i wanted to point out is that it is not all or nothing. for instance, the member could get 10 partitions assigned to him and only one is unresolvable.",0,0.9151262044906616
1381802659,14690,dajac,2023-11-03T14:45:40Z,"as discussed offline, i would remove this. in my opinion, the member should just follow what the coordinator provide and should not try to be too smart here.",0,0.9008565545082092
1381802850,14690,dajac,2023-11-03T14:45:49Z,nit: extra line.,0,0.9749673008918762
1381810747,14690,dajac,2023-11-03T14:52:17Z,i wonder if we should also check if the target assignment is still the same one. i am not sure if it is possible but could we have a callback coming really late and the state machine could have already transitioned to fenced and rejoined the group and got a new assignment so be in reconciling state again?,0,0.8201112747192383
1381814507,14690,dajac,2023-11-03T14:55:03Z,"one concern that i have with using the manager directly is that it does not seem to populate the metadata cache afterwards. so, we would resolve topics once here and then the fetcher would redo it because the metadata cache does not have the topics. this is not ideal.",0,0.6893492341041565
1381819971,14690,dajac,2023-11-03T14:58:48Z,from the kip:,0,0.9874953627586365
1382108731,14690,philipnee,2023-11-03T18:50:20Z,we should just return early here. `return completablefuture.completedfuture(null);`,0,0.9864990711212158
1382450219,14690,philipnee,2023-11-04T19:50:27Z,i believe the reconciliation result is completed by the main thread.,0,0.973388671875
1382665763,14690,lianetm,2023-11-05T22:51:45Z,`unsubscribed` describes the state better to me too. renamed it and added comments explaining better how the member gets there and what it can do while in this state.,0,0.9815568923950195
1382666152,14690,lianetm,2023-11-05T22:54:17Z,"you're right, this state is only until the next hb is sent, and then the member moves on. if the hb with the ack is lost, what happens is that, when the rebalance timeout expires, the broker will re-assign the partitions to another member and kick this one out of the group.",0,0.9601590633392334
1382666539,14690,lianetm,2023-11-05T22:56:18Z,"you're right about what each does, and agree with the `prepare_leaving` and `leaving`. renamed them and updated comments, it looks clearer.",0,0.9628409147262573
1382666673,14690,lianetm,2023-11-05T22:57:15Z,"removed all static membership logic for now, given that is it not supported yet.",0,0.9733630418777466
1382666792,14690,lianetm,2023-11-05T22:57:56Z,done,0,0.9764507412910461
1382666862,14690,lianetm,2023-11-05T22:58:42Z,totally. done.,1,0.5652515888214111
1382667315,14690,lianetm,2023-11-05T23:01:42Z,"good point. i reused the -1, and removed the static membership constant and logic from our side given that it is not supported yet.",1,0.9520816802978516
1382667377,14690,lianetm,2023-11-05T23:02:08Z,"you're right, not needed, removed.",0,0.9725365042686462
1382668541,14690,lianetm,2023-11-05T23:08:59Z,"good point, this was not the right way so i updated how metadata is used here, all based on the metadata object now (request update when needed, and get notified when it happened). this ensures that the centralized cache is updated, and this is actually how other managers interact with metadata (ex. `offsetsrequestmanager` when it needs metadata to find leaders).",0,0.6383362412452698
1382724053,14690,lianetm,2023-11-06T02:20:05Z,"exactly, that's the case the transition is covering.",0,0.9831171035766602
1382728096,14690,lianetm,2023-11-06T02:31:49Z,"makes sense, i will include the changes for the initial approach sending all, to tune it afterwards and send only what's needed",0,0.983949601650238
1382742662,14690,lianetm,2023-11-06T03:08:57Z,"done. i updated them all, explaining more of what the member does in each and the relationship with the hb requests content and timing.",0,0.9781754016876221
1382772899,14690,lianetm,2023-11-06T04:35:39Z,"yes, we do, based on the epoch (epoch > 0 => onpartitionsrevoked, else onpartitionslost). the prepare leaving will trigger the `onpartitionsrevoked` in most of the cases i expect, but if the member is not in the group anymore it calls `onpartitionslost`. i was mainly thinking about the edge case where a member gets fenced, and while fenced (ex. waiting for user callback to complete), there is a call to unsubscribe. at that point the member would attempt to leave the group, but it is not currently an active member, so will call `onpartitionslost`. makes sense? that being said, i realize that even though the implementation supports that case, it was not a valid transition, so i just added it. will add tests for it shortly.",0,0.98047935962677
1383374287,14690,lianetm,2023-11-06T13:59:51Z,"the callback execution will be completed in the main thread (when implemented), but this is the reconciliation result that completes here in the background thread, that involves not only the callbacks. it involves 3 main async operations: - metadata (to resolve topic names for assignment) - commit - user callbacks (executed in the main thread)",0,0.9846311211585999
1383433245,14690,lianetm,2023-11-06T14:32:23Z,"thanks for confirming . after the change to integrate this with the centralized metadata object and cache, we do achieve this behaviour (we keep retrying until all assigned topic ids are found in metadata)",1,0.9167370796203613
1383435641,14690,lianetm,2023-11-06T14:34:08Z,"totally, all changed, thanks!",1,0.9822269678115845
1383513687,14690,lianetm,2023-11-06T15:26:08Z,"done, i updated it back to sending all fields for now. i will follow up in a next pr to send only what's needed. i expect that it will be the existing `heartbeatstate` the one to extend, to be able to build a `consumergrouprequestdata` based on the last one sent, the member info, and the subscription info (determine difference to send only what changed, and send all on the failed attempts that it already handles for retry/backoff)",0,0.9765201807022095
1383532710,14690,lianetm,2023-11-06T15:36:59Z,"i think we should have both points solved now with the new metadata approach. 1. we continue to request metadata updates as long as there are assigned topic ids not resolved ([a link]. this will solve the first case as you described. 2. we keep a local cache of assigned topicid->topicnames for assigned topics that have been previously resolved. if topic is not in metadata when it comes in a next target assignment it will be resolved from the local cache ([a link], as it is a known/assigned topic. this will solve case 2. thoughts?",0,0.9654844999313354
1383551733,14690,lianetm,2023-11-06T15:48:15Z,"just for the record, it wasn't integrated initially when you took a look but it was added in this pr. and yes, you're right, it is integrated via the applicationeventprocessor and the hbmanager",0,0.965941846370697
1383566278,14690,philipnee,2023-11-06T15:57:47Z,if the reconciliationresult is completed by the main thread then i think the whencomplete block is also completed by the main thread.,0,0.9877930283546448
1383599082,14690,lianetm,2023-11-06T16:19:09Z,"i will share thoughts on this on our next sync with and you , as this is interesting. just for the record, i do agree that spreading topic ids is the right way forward, and we do have them now in the assignment path, but i realized when exploring this suggestion that it is a much bigger change if we move away from `topicpartition`, and we're not ready for it at this point (mainly tricky/ugly because not all paths support topicid yet but most of them access/update the shared `subscriptionstate` component and `topicpartition`) at this point looks to me that we're better of making use of the topic ids kind of ""on the side"", like we're doing now in the `membershipmanager`, that keeps the assigned topicid/names but still uses the same `topicpartition`. this is the same approach followed by the `fetch` and `metadata` paths, that introduced topic ids in a similar ""on the side"" way. there's interesting food for thought here anyway.",0,0.5680186152458191
1383610788,14690,lianetm,2023-11-06T16:27:55Z,"i'm using `send` to align with how the hb manager was naming the existing `onsendattempt` and such, and i think that as seen from the manager point of view it is enough, the membership manager only needs to know that the request is sent out of the hb manager to transition accordingly. it is not literally sent over the network. i would leave send/sent to keep it consistent between the 2 managers, but let me know if you think it would be clearer differently.",0,0.9803512692451477
1383623183,14690,dajac,2023-11-06T16:33:24Z,"i think that a client could still get an unresolvable topic id and be stuck in the reconciling state. for instance, it could happen if the member sees a topic id for the first time and the topic id is deleted just before it could resolve it.",0,0.9685819149017334
1383699023,14690,philipnee,2023-11-06T17:21:25Z,is there any reason we want to combine onpartitionslost and onpartitionsrevoke into a single function? couldn't we directly invoke `invokeonpartitionsrevoke` or `invokeonpartitionslost`? i.e. by the time the consumer is fenced or would know we need to invoke onpartitionslost,0,0.9851105213165283
1383701313,14690,philipnee,2023-11-06T17:23:02Z,"as previously mentioned, it is clearer to directly invoke `invokeonpartitionslost` here. is there a case we don't invoke onpartitionslost?",0,0.9874362945556641
1383780173,14690,philipnee,2023-11-06T18:21:36Z,i don't think the exception will actually be thrown here.,0,0.9085460901260376
1383786483,14690,philipnee,2023-11-06T18:26:42Z,"looking at the current consumer, i think it can be quite complicated in this implementation. maybe what we should do is to invoke the listener on the spot, then send an even to the background thread to leave group.",0,0.9417164921760559
1383791886,14690,philipnee,2023-11-06T18:32:02Z,i'm guessing the idea is we need to ignore the backoff and heartbeat.,0,0.9726182818412781
1383959347,14690,lianetm,2023-11-06T20:42:13Z,"yes, as we discussed for the states that would send heartbeat without waiting for the interval (sending ack for an assignment and leave group requests basically)",0,0.9880102276802063
1383962388,14690,lianetm,2023-11-06T20:44:53Z,"you're right, it should happen in the poll to maintain the current contract. i will just remove it since we don't execute callbacks yet, and it should be included in the pr that introduces the callback execution.",0,0.9710398316383362
1383968073,14690,philipnee,2023-11-06T20:49:52Z,can we use the standard tostring format? topic(topicid=...),0,0.9868739247322083
1383974744,14690,philipnee,2023-11-06T20:54:17Z,can we just fail the consumer?,0,0.9189379811286926
1383979443,14690,lianetm,2023-11-06T20:58:28Z,"the reason is the leave group logic. on leave group it could be lost or revoked, depending on the epoch. on fence or fatal is always lost. i was just reusing the same func for convenience, but will change the fence and fatal transitions to directly invoke the `onpartitionslost` just to make the intention clearer.",0,0.9744386672973633
1383983917,14690,lianetm,2023-11-06T21:02:21Z,"the kip states that we should do exactly this, and actually the consumer would stay functional. `consumer#enforcerebalance will be deprecated and will be a no-op if used when the new protocol is enable. a warning will be logged in this case.` do you have a concern that i may be missing?",0,0.9708871841430664
1383986418,14690,lianetm,2023-11-06T21:04:19Z,"actually i intentionally followed the standard of the topicpartition and topicidpartition tostring implementations, since this new topic class is kind of a sibling, makes sense?",0,0.9815121293067932
1383995398,14690,philipnee,2023-11-06T21:11:42Z,thanks for the clarification!,1,0.939209520816803
1384004581,14690,philipnee,2023-11-06T21:19:24Z,thanks for the clarification!,1,0.939209520816803
1384016549,14690,philipnee,2023-11-06T21:29:38Z,"i think unsubscribe() actually blocks on callback invocation and throw if possible. instead of putting the logic in whencomplete, it seems like we should try to wait till the callback completes then throw if needed. i assume we want to maintain this behavior for the async consumer.",0,0.9853610396385193
1384076305,14690,philipnee,2023-11-06T22:00:43Z,"i think this kafkaexception might not be in the right place because the rebalance listener needs to be invoked on the mainthread, probably before sending out the event. i wonder if we could just remove this whencomplete and rely on the background thread to log the failures during the leave group event. if there's a fatal exception being thrown there, it seems the sensible way is to enqueue to the backgroundeventqueue and handle in the poll. wdyt? in the current code path, i think only exceptions can only be thrown in `onleaveprepare`.",0,0.8338918089866638
1385059304,14690,lianetm,2023-11-07T14:59:12Z,"agree that the unsubscribe blocks on the callbacks, but since we don't have the implementation for how callbacks are going to be executed on this pr this unsubscribe is still not using it. it should come when we nail the implementation details on the follow-up pr (will depend on how we end up doing it, maybe blocking not here, but on the subscribe/unsubscribe events) as for the exception, it will originate in the application thread, where the callback is executed, and it should only be returned to the user when it calls poll, to maintain the current behaviour, so i removed it from here to stay consistent and leave all logic related to the callback execution out, i see the confusion introduced. the when complete should stay because it represents a concept we need, un-related to callbacks: we do need to update the `subscriptionstate` only when the unsubscribe event completes (hb to leave group sent to the broker). we need it know to make sure we are able to run unsubscribe, no callbacks, sending leave group, and clearing up the subscription state after sending the request. trying to leave it in a consistent state with no callbacks. follow-up pr should introduce implementation for executing them, blocking appropriately on the execution, and throwing the exceptions.",0,0.980057954788208
1385082158,14690,lianetm,2023-11-07T15:14:06Z,"agree, done here. note my answer above though, about the cases where we do need revoke or lost, that one should stay.",0,0.9776560068130493
1385085418,14690,lianetm,2023-11-07T15:15:58Z,"just for the record, as discussed offline, none of these futures are expected to be completed in the main thread. this is a reconciliation future, which is much more than the callbacks (metadata, commit, callbacks). and callbacks, when implemented, will be based on events shared between the app thread and the background thread (not based on futures from one thread complete on the other, as that would be problematic)",0,0.9841001033782959
1385350785,14690,lianetm,2023-11-07T18:18:35Z,"agree. just for the record, we're trying to figure out how to properly handle the cases where metadata wouldn't be available for a target assignment (permanently when topic deleted, or even just temporarily). with the current shape where the client attempts to reconcile the full target assignment, what happens now is rather disruptive, as the member would be kicked out of the group after rebalance timeout expires.",0,0.7574857473373413
1387282757,14690,philipnee,2023-11-08T22:48:58Z,this is just a transient state for the member to send the leave group heartbeat with epoch -1/-2 (dynamic/static membership) right?,0,0.987713098526001
1389220863,14690,dajac,2023-11-10T10:31:26Z,do we still need the changes in this class? it seems that we don't use them anymore. i have the same question for the new `topic` class.,0,0.941032886505127
1390582429,14690,lianetm,2023-11-13T03:01:07Z,"you're right, not needed anymore (all metadata interaction is now based on the centralized metadata cache). all removed.",0,0.9835423231124878
1390583612,14690,lianetm,2023-11-13T03:03:33Z,"yes, similar to the acknowledging in the sense that they are just a way to indicate that a heartbeat must be sent without waiting for the interval, and as soon as the request is sent the member transitions out of the state.",0,0.9871283769607544
1390590490,14690,lianetm,2023-11-13T03:20:45Z,"totally valid point. i fixed it, but comparing assignments seemed more complicated and harder to reason about with the current approach. now the target assignment is kind of a moving target, it can be modified anytime not only from the server, but also from metadata updates. so back to the problem of making sure that delayed reconciliations are not applied after a member rejoins, i added just a check based on the current member id, to identify that a reconciliation completed but the member is already re-joining. what do you think? (whenever there are no rejoins in the picture, i expect that the reconciling state check alone should be enough given that reconciliations are always applied sequentially)",0,0.8322325944900513
1391828060,14690,kirktrue,2023-11-14T00:01:15Z,"the closure that the application thread is passing to `whencomplete()` will be run in the background thread, right? the closure is modifying the `subscriptionstate`, it shouldn't cause any problems, but still... since we have access to the `subscriptionstate` in the background thread already, can the background thread just update the `subscriptionstate` directly?",0,0.9847866892814636
1391862343,14690,kirktrue,2023-11-14T01:04:51Z,"there's another `subscribeinternal()` for the topic pattern path. we want this there too, right?",0,0.9857967495918274
1391875622,14690,kirktrue,2023-11-14T01:30:29Z,"i apologize if it's here somewhere, but i don't see where we ""register"" the membership manager with the cluster resource listeners.",-1,0.903835654258728
1391875744,14690,kirktrue,2023-11-14T01:30:45Z,good call!,1,0.987669050693512
1391876960,14690,kirktrue,2023-11-14T01:33:12Z,"the intention of the `completeableapplicationevent` was to have a way for the consumer to block on the results of operations performed in the background thread. since the `consumer.unsubscribe()` api call is non-blocking, i'm thinking this should be a subclass of `applicationevent`.",0,0.9868660569190979
1391879026,14690,kirktrue,2023-11-14T01:37:29Z,are we missing the initialization of `unsubscribed`?,0,0.9725499749183655
1391880921,14690,kirktrue,2023-11-14T01:41:16Z,[code block] `subscription_change` is a bit vague. does it encompass more than the event of the user calling `consumer.subscribe()`?,0,0.944088876247406
1391882860,14690,kirktrue,2023-11-14T01:45:20Z,[code block] suggestion: use the double-underscore to denote to the reader that the variable is intended to remain unused.,0,0.987374484539032
1391883884,14690,kirktrue,2023-11-14T01:47:24Z,"suggestion: consider moving this to an `assignpartitions()` method, similar to the `revokepartitions` method, for consistency and readability.",0,0.9868203997612
1391885027,14690,kirktrue,2023-11-14T01:49:38Z,"suggestion: make `groupinstanceid` and `serverassignor` `optional` as constructor parameters to convey to the callers that they are, indeed, _optional_.",0,0.9886868000030518
1391885243,14690,kirktrue,2023-11-14T01:50:07Z,[code block] haha. i don't really care :smirking_face:,-1,0.9832378625869751
1391888737,14690,kirktrue,2023-11-14T01:56:43Z,[code block] nit: remove extra newline.,0,0.984235405921936
1391889559,14690,kirktrue,2023-11-14T01:58:16Z,[code block] nit: it'll be visually easier to parse with the space before the next sentence.,0,0.9828488230705261
1391890695,14690,kirktrue,2023-11-14T02:00:28Z,"i think this `equals()` call is ok. from looking at `abstractset`, it appears that `sortedset.equals()` is ok to accept any ol' `set` implementation.",0,0.9865021705627441
1392717259,14690,lianetm,2023-11-14T14:50:53Z,"the `consumer.unsubscribe` does block on the callback execution, that's why it is a `completableapplicationevent`. only after the callback completes the unsubscribe can send the actual leave group heartbeat request. makes sense?",0,0.985079824924469
1392732597,14690,lianetm,2023-11-14T14:59:46Z,"i see, i was just intentionally leaving out all the pattern based logic because we don't support it at this point. but this makes me realize that that `subscribeinternal` based on pattern that you mentioned is wired to the `subscribe(pattern pattern)` api call, when it's truly not supported yet. i think we should disable all the subscribe based on patterns until we implement them properly. what do you think?",0,0.9331149458885193
1392733198,14690,lianetm,2023-11-14T15:00:07Z,"good catch, added.",1,0.9664382934570312
1392744058,14690,lianetm,2023-11-14T15:05:01Z,"indeed, only from the state when the leave group hb is sent out. added and test. thanks!",1,0.9395122528076172
1392748787,14690,lianetm,2023-11-14T15:07:53Z,"it's exactly when the user changes the subscription via a call to subscribe. i used the name `subscription_change` because it seemed clear and to be consistent with the existing `assignment_change`, but let me know if you think another name would be better.",0,0.9851844310760498
1392790381,14690,lianetm,2023-11-14T15:32:12Z,"done. just to make sure we are on the same page, the whole snippet marked is not really assign. assign is only ln 581 and ln 591 where the subscription state is updated and calling callbacks, and yes, i extracted those into an `assignpartitions()`. the rest of the checks, cache and errors is related to the revocation (or the transition from revocation to assign) so leaving it here where the revocation and assign are linked.",0,0.9865472316741943
1392802141,14690,lianetm,2023-11-14T15:38:34Z,"he he, i do avoid this, missed it here, fixed ;)",1,0.9055725336074829
1392827512,14690,kirktrue,2023-11-14T15:55:51Z,where does it block? i didn't see a call to `future.get()` when i looked.,0,0.9816728830337524
1392829031,14690,kirktrue,2023-11-14T15:56:51Z,"i never liked `assignment_change` either, but i guess it's consistent, so :thumbs_up:",0,0.6022930145263672
1392830639,14690,kirktrue,2023-11-14T15:57:54Z,"those kinds of things tend to jump out in _other people's_ code, but i frequently miss them in my own :grinning_face_with_smiling_eyes:",-1,0.8907457590103149
1392954694,14690,lianetm,2023-11-14T17:18:17Z,"agree that the equals here does what we want, but actually this made me notice another detail. i wasn't passing the custom comparator when creating the `assignnedpartitions` sorted set. also, for the owned ones, i already have a sorted set a few lines below so just moving it up to reuse it and make the comparison clearer.",0,0.9792032241821289
1393793669,14690,dajac,2023-11-15T07:59:21Z,nit: we could remove this empty line.,0,0.9868703484535217
1393794196,14690,dajac,2023-11-15T07:59:49Z,should we add a unit test for the newly added topic names mapping?,0,0.9862662553787231
1393830838,14690,dajac,2023-11-15T08:30:47Z,"from an architectural point of view, i wonder if this method and the next one are in the right place. intuitively, i would have put them into the membership manager directly because they don't interact with the heartbeat manager state at all. what's your take on this?",0,0.9325689673423767
1393833703,14690,dajac,2023-11-15T08:33:05Z,"have we reached a conclusion on this one? it seems correct to me to consider it as a no-op if the member is already leaving. however, i was wondering whether we should return a future here that will be completed only when the on-going leave operation completes.",0,0.9688688516616821
1393834178,14690,dajac,2023-11-15T08:33:32Z,"nit: we could remove a few empty lines here, i suppose.",0,0.9852283000946045
1393839254,14690,dajac,2023-11-15T08:37:43Z,nit: -1 or -2.,0,0.9477326273918152
1393842585,14690,dajac,2023-11-15T08:40:19Z,could we transition to fatal from prepare leaving and leaving?,0,0.9750797152519226
1393842889,14690,dajac,2023-11-15T08:40:35Z,could we transition to fatal from prepare leaving?,0,0.9742622971534729
1393848768,14690,dajac,2023-11-15T08:45:11Z,`acknowledges the target assignment` is confusing here. my understanding is that it will acknowledge the part of the target assignment that was actually reconciled. am i correct?,-1,0.7478349208831787
1393850232,14690,dajac,2023-11-15T08:46:22Z,nit: i think that we usually put static variables first when declaring attributes.,0,0.9878696799278259
1393852447,14690,dajac,2023-11-15T08:47:55Z,nit: should we move this one to `consumergroupheartbeatrequest` as we already have `leave_group_member_epoch` there?,0,0.9877653121948242
1393854091,14690,dajac,2023-11-15T08:49:07Z,i am confused by this. did we say that we should keep the member id forever when we receive one?,-1,0.974302351474762
1393856821,14690,dajac,2023-11-15T08:51:05Z,"note that it is possible to receive the exact same assignment multiple times. i suppose that in this case, we transition to reconciling and the reconciliation process will be a no-op because the current and the target are the same. did i get it right?",0,0.9865705370903015
1393914776,14690,dajac,2023-11-15T09:32:14Z,nit: i wonder whether we should log this as an error.,-1,0.6691007614135742
1393915412,14690,dajac,2023-11-15T09:32:42Z,should we also react to the future completion here for e.g. log something?,0,0.986793577671051
1393915845,14690,dajac,2023-11-15T09:33:01Z,don't we need to call `subscriptions.assignfromsubscribed(collections.emptyset());` here as well?,0,0.987136960029602
1393916982,14690,dajac,2023-11-15T09:33:50Z,nit: we could remove this empty line.,0,0.9868703484535217
1393917097,14690,dajac,2023-11-15T09:33:55Z,ditto.,0,0.859873354434967
1393958634,14690,dajac,2023-11-15T10:03:02Z,"is this really true? we could have the same topic name in both but with different topic ids for instance. in my opinion, we should move towards using topicidpartition for both the assigned partitions and the partitions ready to reconcile. we can of course tackle separately from this pr.",0,0.9724954962730408
1393958878,14690,dajac,2023-11-15T10:03:13Z,nit: we can remove an empty line here.,0,0.986957311630249
1393960227,14690,dajac,2023-11-15T10:04:15Z,should we trigger both in parallel?,0,0.983616054058075
1393962052,14690,dajac,2023-11-15T10:05:30Z,nit: we could remove this empty line.,0,0.9868703484535217
1393962754,14690,dajac,2023-11-15T10:06:01Z,should we log this as an error?,0,0.9484519362449646
1393968230,14690,dajac,2023-11-15T10:09:53Z,"as i said before, this does not seem correct to me because we should keep the member id forever.",0,0.8628496527671814
1393968517,14690,dajac,2023-11-15T10:10:06Z,nit: we could remove this empty line.,0,0.9868703484535217
1393970046,14690,dajac,2023-11-15T10:11:17Z,nit: we could remove this empty line.,0,0.9868703484535217
1393972135,14690,dajac,2023-11-15T10:12:59Z,what happen in this case? i suppose that the reconciliation will be retried. did i get it right?,0,0.9749518036842346
1393972399,14690,dajac,2023-11-15T10:13:13Z,nit: we can remove the space after the `.`.,0,0.9886177182197571
1393972835,14690,dajac,2023-11-15T10:13:35Z,nit: we could remove this empty line.,0,0.9868703484535217
1393973543,14690,dajac,2023-11-15T10:14:13Z,nit: we could remove this empty line.,0,0.9868703484535217
1393974377,14690,dajac,2023-11-15T10:14:56Z,i agree that the other state transition should take care of updating the state. we should only abort here.,0,0.9593228697776794
1393976328,14690,dajac,2023-11-15T10:16:29Z,nit: we could remove this empty line.,0,0.9868703484535217
1393977197,14690,dajac,2023-11-15T10:17:09Z,"nit: using `ifpresent` would be a bit more idiomatic, i think.",0,0.976803183555603
1393987062,14690,dajac,2023-11-15T10:24:43Z,"i am not sure to understand how the metadata cache knows which new topic ids it should resolve. or does the consumer request metadata for all topics in the cluster? looking at the code, it is may be what it does.",0,0.8414416909217834
1393993623,14690,dajac,2023-11-15T10:29:34Z,+1,0,0.696722686290741
1394012157,14690,dajac,2023-11-15T10:44:58Z,"there is a subtile behaviour changes here. 1) in the legacy implementation, `this.coordinator.onleaveprepare()` is called here and it triggers the callback before returning from `unsubscribe`. 2) `subscriptions.unsubscribe()` is actually called before `unsubscribe` returns as well.",0,0.9867830276489258
1394032677,14690,dajac,2023-11-15T10:55:05Z,"btw, it seems that we could have transitioned to another state while waiting on this one as well.",0,0.9859717488288879
1394042794,14690,dajac,2023-11-15T11:00:07Z,"i also wonder whether if would be possible to parallelize more. for instance, is there a reason not to trigger the revocation and the assignment callbacks at the same time? this would ensure that they are call within one poll; otherwise, it can take multiple calls to poll to complete the assignment. we could consider this as a optimization for the future.",0,0.9228410124778748
1394053638,14690,dajac,2023-11-15T11:09:11Z,`partitionsassigned` could also be empty here so we should handle this case appropriately. e.g. we should not trigger the callback.,0,0.9879686832427979
1394322340,14690,lianetm,2023-11-15T14:55:14Z,filed [a link] for this and i will take care of it right after this pr as a follow-up.,0,0.9701205492019653
1394344222,14690,lianetm,2023-11-15T15:10:46Z,"yes, done.",0,0.9761238098144531
1394493344,14690,lianetm,2023-11-15T16:57:39Z,"yes, that's what it does, get metadata for all topics [a link]. it seems that there was an intention of a partial update [a link] but not fully implemented, so it effectively ends up getting them all anyways.",0,0.9787899851799011
1394570775,14690,lianetm,2023-11-15T18:00:25Z,"yes, you're right, i will rephrase this. it acknowledges the reconciled assignment, which is the subset of the target that was resolved from metadata and actually reconciled.",0,0.9821940660476685
1394581206,14690,lianetm,2023-11-15T18:07:38Z,"done, re-arranged a couple of them.",0,0.9839861392974854
1394585362,14690,lianetm,2023-11-15T18:10:24Z,"totally, done.",0,0.6924738883972168
1394619681,14690,lianetm,2023-11-15T18:28:38Z,"yes, done. it is actually the level used for this in the legacy coordinator.",0,0.9842931628227234
1394629300,14690,lianetm,2023-11-15T18:37:34Z,"cool, thanks for confirming.",1,0.9697032570838928
1394646561,14690,lianetm,2023-11-15T18:51:40Z,"the legacy coordinator does trigger the `onpartitionsassigned` with empty partitions (not the `onpartitionsrevoked` though), so i intentionally left the same behaviour, makes sense? i had also added a note on the [a link] to make sure that we keep that contract when implementing callbacks.",0,0.988059937953949
1394733589,14690,lianetm,2023-11-15T20:03:07Z,"yes, done. that's how it's done for other callbacks (aligned the messages too to make them consistent for all callbacks)",0,0.9872625470161438
1394742401,14690,lianetm,2023-11-15T20:12:53Z,"you're right, we do. added it, along with a log in case of error.",0,0.972770094871521
1394746271,14690,lianetm,2023-11-15T20:17:20Z,"sure, done. logging error in the same way that it's done for other callback failures.",0,0.9836211204528809
1394753399,14690,lianetm,2023-11-15T20:24:11Z,"yes, i just updated this. we're on the same page regarding that the client will keep the member id forever and provide it back....but i was wrongly expecting it would change after rejoining. updated now. the goal is to be able to identify a rejoin, so using the member epoch (expecting that every time a member rejoins will get a bumped epoch).",0,0.9352400898933411
1394759427,14690,lianetm,2023-11-15T20:28:46Z,"you got it right, i expect the same thing (i had this [a link] for that)",0,0.9613838791847229
1394774045,14690,lianetm,2023-11-15T20:42:16Z,"agree, same member id forever. updated this to use the member epoch as a way of identifying that the member has rejoined.",0,0.9797329902648926
1394786770,14690,lianetm,2023-11-15T20:53:01Z,"yes, makes sense to me. it could be bundled up along with the callbacks triggering (both, revocation and assign), so that we trigger them all in the same poll iteration, while still making sure that they are executed in the right order. filed [a link] and i will address that as a follow-up right after this.",0,0.9812226891517639
1394789418,14690,lianetm,2023-11-15T20:55:11Z,"agree, filed [a link] and i will address that as a follow-up right after this (considering all the 3 parts: commit, revoke callback, assign callback)",0,0.9851821064949036
1395130865,14690,lianetm,2023-11-16T04:18:22Z,"agree, i merged them into the membership manager, and this actually goes in the same direction we've discussed about the membership manager becoming a first-class manager (supporting poll, for instance).so for now i integrated it with the `applicationeventprocessor` already, to be able to move these 2 funcs that i totally agree make sense in the membership manager (when tackling the poll for triggering reconciliations, i will extend on this same direction)",0,0.9061107039451599
1395132794,14690,lianetm,2023-11-16T04:22:54Z,"done (now in the membership manager `leavegroup`). no-op if already leaving, and returning the future that will complete when the ongoing leave completes. also handling the case where the member already left (no-op and return right away)",0,0.9864805340766907
1395138233,14690,lianetm,2023-11-16T04:33:38Z,"there is no transition from prepare leaving to fatal with the current usage of fatal (only when receiving fatal errors in hb response), because we don't send hb while in prepare leaving. as for leaving, i would say we shouldn't either, because even if it is a state where we do send hb, we transition out of it as soon as the hb request is ready to be sent (without waiting for the actual send or any response). that being said, this makes me realize that the same reasoning applies for acknowledging, there shouldn't be a way of transitioning from ack to fatal, just because we transition out of it on heartbeat sent.",0,0.9036079049110413
1395138981,14690,lianetm,2023-11-16T04:35:13Z,not with the current usage of fatal as i see it (message above),0,0.9722909331321716
1395143611,14690,lianetm,2023-11-16T04:43:07Z,"agree, filed [a link] to extend topic id usage in the whole assignment reconciliation flow to make sure we handle topic re-creation properly.",0,0.9826833009719849
1395665723,14690,dajac,2023-11-16T13:07:00Z,"we don't send an explicit hb while in prepare leaving. however, we continue to heartbeat so i assume that we could receive an error or be fenced while in this state. regarding the ack case, i think that we could receive a similar response while in ack so the same applies. do you agree?",0,0.9824749827384949
1395667965,14690,dajac,2023-11-16T13:08:56Z,interesting... i wonder if this was done on purpose or if this just a bug. i don't really see the value in calling `onpartitionsassigned` without any partitions. i suppose that we should double check this. we could perhaps file a jira and clarify this separately. what do you think?,0,0.8209787607192993
1395669911,14690,dajac,2023-11-16T13:10:27Z,"let's file a jira to improve this as well. ideally, assuming that we don't use client side regex anymore, the client should only request the topics that it needs.",0,0.9835813045501709
1395677889,14690,dajac,2023-11-16T13:16:48Z,nit: i suppose that this one should go on the previous line.,0,0.9838581681251526
1395680718,14690,dajac,2023-11-16T13:17:46Z,i would remove the todos for which we have jiras.,0,0.9851182699203491
1395687362,14690,dajac,2023-11-16T13:22:10Z,nit: i may be worth logging something here as well to be consistent with `transitiontofatal`.,0,0.9823060631752014
1395689326,14690,dajac,2023-11-16T13:23:36Z,nit: should we also log the member epoch?,0,0.9885929822921753
1395690012,14690,dajac,2023-11-16T13:24:13Z,is this still valid? it looks like we call onpartitionslost explicitly now.,0,0.9889413714408875
1395691085,14690,dajac,2023-11-16T13:25:09Z,i wonder why we clear it here whereas in transitiontofenced we clear it when the callback future is completed. is there a reason for this subtile difference?,0,0.8884119987487793
1395691853,14690,dajac,2023-11-16T13:25:43Z,is there a reason why we don't do this as the first thing in this method? this would be more consistent with transitiontofenced.,0,0.976374089717865
1395693217,14690,dajac,2023-11-16T13:26:48Z,"i think that the next hb should pick it up. otherwise, we could perhaps transition to joining to force an immediate hb. i am not sure that it is worth it.",-1,0.665427565574646
1395697755,14690,dajac,2023-11-16T13:30:35Z,"i am a bit confuse by where we call `clearpendingassignmentsandlocalnamescache`. sometime we call it when the callback future is completed, sometime right after scheduling the callback. i wonder if it would be possible to be more consistent or if there are specific reasons that i did not get.",-1,0.8436686396598816
1395717674,14690,dajac,2023-11-16T13:46:36Z,"note that here we clear the `assignedtopicnamescache` but we only clear the assigned partitions after the callback is executed. this means that we have a period of time during which we are not able to resolve ids from the names in the subscription. i suppose that it does not matter in this case but this could be a source of subtile bugs. as we discussed offline, i think that we really need to update the subscriptions to use topicidpartitions. if this is not possible, an intermediate approach would be to keep the assigned topicidpartitions in this manager and to update the subscriptions with `subscriptions.assignfromsubscribed` when we update it. or, we could also move the bookkeeping of the cache closer to calls to `subscriptions.assignfromsubscribed`.",0,0.9793447852134705
1395721501,14690,dajac,2023-11-16T13:49:34Z,nit: we could use `==` here now.,0,0.9887269735336304
1395722320,14690,dajac,2023-11-16T13:50:12Z,do we need to check the epoch here as well?,0,0.9860893487930298
1395747556,14690,dajac,2023-11-16T14:06:11Z,nit: `t` -> `it`?,0,0.9826712012290955
1395783384,14690,dajac,2023-11-16T14:31:03Z,`the broker will continue to send the assignment to the member.` this is not entirely true. the broker may not send anything.,0,0.9641006588935852
1395862422,14690,lianetm,2023-11-16T15:05:18Z,"agree, rephrased it. this test is just for the case where the broker does keep sending (and the test above for when it does not)",0,0.9856839179992676
1395877609,14690,lianetm,2023-11-16T15:14:22Z,"agree, done. all todos in this class have jiras already.",0,0.9760363698005676
1395894946,14690,lianetm,2023-11-16T15:21:59Z,"you're right, not needed anymore. the member will transition to fatal state but can keep its last member id and epoch.",0,0.9670830368995667
1395907406,14690,lianetm,2023-11-16T15:28:39Z,"no reason, moved it to after the callback completes, consistent with how it is done on fencing, leave and reconcile",0,0.9673128724098206
1395912856,14690,lianetm,2023-11-16T15:32:16Z,"no reason, updated it to make it consistent with the fencing transition",0,0.9439512491226196
1395929369,14690,lianetm,2023-11-16T15:42:56Z,agree that the next hb will pick it up based on the interval (also not seeing much need/value in the forced hb). removed the todo.,0,0.9871511459350586
1395947490,14690,lianetm,2023-11-16T15:55:00Z,"yes, i think we need it too. added.",0,0.9239495396614075
1396006392,14690,lianetm,2023-11-16T16:31:16Z,"i moved the clear cache close to the `assignedfromsubscribed` in this manager, as a first step to align both and have a consistent usage",0,0.9860819578170776
1396013115,14690,lianetm,2023-11-16T16:35:22Z,"agree it was not consistent. i moved it close to the call to `assignpartitions`, so when callbacks complete we have a single `updateassignment` that makes the assignment effective and clears cache if needed.",0,0.9849729537963867
1396088885,14690,lianetm,2023-11-16T17:26:05Z,"agree on handling that separately, but leaving the current behaviour as in the legacy coordinator. i also don't see the value either but it would introduce a change on when the `onpartitionsassigned` is called or not, so let's put some more though on it. filed [a link] to follow-up on this.",0,0.9849765300750732
1396462214,14690,lianetm,2023-11-16T22:50:07Z,"i updated it to align with the current behaviour (callbacks, best effort to send leave group request without any response handling or retry, and call to `subscriptions.unsubscribe` when everything completes). this has the gap of the callback execution that would require a poll. given that we don't support callbacks in this pr, it won't block the flow, but definitely to be solved (i added the details of the challenge to solve in the [a link]",0,0.9432188272476196
1396474166,14690,lianetm,2023-11-16T23:01:39Z,"makes sense, [a link]",0,0.9821365475654602
1396494887,14690,lianetm,2023-11-16T23:26:51Z,"yes, it will be retried on the next reconciliation loop (known shortcoming is how we trigger the reconciliation loops. it will be improved right after with [a link]",0,0.9856692552566528
1396826235,14690,lianetm,2023-11-17T07:55:29Z,"pushed one fix as a first step towards integrating topicidpartitions, which i agree should be the way forward. for now it is integrated in the membershipmanager, only in the reconciliation path where we do have all the info clearly in hand. will continue the integration as follow-up with [a link] as it requires a little bit more thought",0,0.9411216974258423
1398998763,14690,dajac,2023-11-20T10:41:19Z,"i think that this should actually outside of the `else` branch, isn't it?",0,0.9801992774009705
1399012130,14690,dajac,2023-11-20T10:50:03Z,"nit: if we would use `consumergroupheartbeatrequestdata.topicpartitions` in the `hashmap` and the `list`, we could skip this step.",0,0.9878717660903931
1399012491,14690,dajac,2023-11-20T10:50:20Z,nit: we could probably use `computeifabsent` to simplify this code.,0,0.9881023168563843
1399013422,14690,dajac,2023-11-20T10:50:43Z,we still need to conclude on this one.,0,0.9669865965843201
1399026661,14690,dajac,2023-11-20T10:59:17Z,nit: should we move this code into `assignpartitions`?,0,0.9888977408409119
1399044241,14690,dajac,2023-11-20T11:14:04Z,i am curious here. is it better to build a `sortedset` with all elements and then to add it to `assignmentreadytoreconcile` vs adding to `assignmentreadytoreconcile` directly?,0,0.9391385316848755
1399045098,14690,dajac,2023-11-20T11:14:49Z,nit: i have noticed that most of the comments end with a period but not all of them. it may be good to be consistent.,0,0.84659343957901
1408353902,14690,lianetm,2023-11-28T19:58:37Z,"yeah, no value in it. i simplified it by just adding the topicpartition items directly to the `assignmentreadytoreconcile` (in [a link]",0,0.9806592464447021
1408354526,14690,lianetm,2023-11-28T19:59:17Z,"totally, and actually it made me realize it could be further simplified by retaining the assigned. it is included now in the [a link] with the other minor fixes.",0,0.9724510908126831
1408355119,14690,lianetm,2023-11-28T19:59:53Z,"definitely, done in the [a link]",0,0.9857531189918518
1408357542,14690,lianetm,2023-11-28T20:02:32Z,agree. it disappeared anyways after simplifying it all with the use of topicpartitions.,0,0.9820628762245178
1408361923,14690,lianetm,2023-11-28T20:07:07Z,"agree, we were definitely missing here transitions to fatal/fenced that may occur while the member is leaving (any of the 2 phases of leaving). i included the changes to properly handle them in the [a link] so we can continue the conversation there.",0,0.9818781018257141
98550533,2466,mjsax,2017-01-30T21:54:48Z,"this should be added to the first paragraph: [code block] please make sure, that the line is not longer than 120 chars. please adjust other javadocs, too.",0,0.9858660697937012
98553210,2466,mjsax,2017-01-30T22:06:11Z,"`return stream(null, null, keyserde, valserde, topics);` do the call directly instead of the cast.",0,0.9883212447166443
98553705,2466,mjsax,2017-01-30T22:08:30Z,"update to `return stream(offsetreset, null, null, null, topics);` to avoid too many indirections. to this for other overloads, too, please.",0,0.9862073659896851
98554156,2466,mjsax,2017-01-30T22:10:41Z,this should be the only method with actual code. all other overloads should call this one.,0,0.9848795533180237
98554261,2466,mjsax,2017-01-30T22:11:18Z,should not have an implementation but call overloaded method.,0,0.9413995742797852
98554337,2466,mjsax,2017-01-30T22:11:40Z,should not have an implementation but call overloaded method.,0,0.9413995742797852
98554471,2466,mjsax,2017-01-30T22:12:27Z,remove this line -- not required.,0,0.974911093711853
98554659,2466,mjsax,2017-01-30T22:13:24Z,"nit: adjust indention of other parameters; line should not be longer than 120 chars. indent second/third/etc line, too. text can be shorter: [code block] (no need to link to `timestampextractor` as there will be a link in the javadocs anyway.",0,0.9885308742523193
98555452,2466,mjsax,2017-01-30T22:17:42Z,as above.,0,0.978552520275116
98555469,2466,mjsax,2017-01-30T22:17:48Z,as above,0,0.9783914685249329
98555494,2466,mjsax,2017-01-30T22:17:56Z,remove,0,0.9725990891456604
98555525,2466,mjsax,2017-01-30T22:18:06Z,as above,0,0.9783914685249329
98555721,2466,mjsax,2017-01-30T22:19:11Z,remove,0,0.9725990891456604
98555745,2466,mjsax,2017-01-30T22:19:21Z,as above,0,0.9783914685249329
98555929,2466,mjsax,2017-01-30T22:20:16Z,"no reformatting, please",0,0.9664846062660217
98555957,2466,mjsax,2017-01-30T22:20:24Z,"no reformatting, please",0,0.9664846062660217
98556721,2466,mjsax,2017-01-30T22:24:30Z,nice catch!,1,0.9883393049240112
98557646,2466,mjsax,2017-01-30T22:29:44Z,we should not add this to the context -- see comments below.,0,0.9592642784118652
98558044,2466,mjsax,2017-01-30T22:31:50Z,keep this but rename to `defaulttimestampextractor`,0,0.9872909188270569
98558367,2466,mjsax,2017-01-30T22:33:32Z,"add line: `timestampextractor sourcetimestampextractor = source.gettimestampextractor();` and change to `recordqueue queue = createrecordqueue(partition, source, sourcetimestampextractor != null ? sourcetimestampextractor : defaulttimestampextractor);`",0,0.9849807024002075
98770837,2466,mjsax,2017-01-31T21:09:30Z,"nit: ""default { timestampextractor}[,] and"" the rule is ""a and b"" (for two things no comma), but ""a, b, c, and d"" (for three or more things, use commas)",0,0.987327516078949
98771506,2466,mjsax,2017-01-31T21:13:00Z,"nit: please use the same order in all javacode -- above timestampextractor is second -- i don't care which order, but please be consistent. maybe follow parameter order of the method overload that provides all parameters ?",0,0.9428932070732117
98771974,2466,mjsax,2017-01-31T21:15:16Z,"remove ""(if any)""",0,0.9731752276420593
98772167,2466,mjsax,2017-01-31T21:16:10Z,"nit: no ""."" at the end please update everywhere.",0,0.9774817824363708
98773132,2466,mjsax,2017-01-31T21:20:22Z,update javadoc. same below,0,0.9888433218002319
98773266,2466,mjsax,2017-01-31T21:20:59Z,as above,0,0.9783914685249329
98773635,2466,mjsax,2017-01-31T21:22:48Z,nit: can you insert this method further down -- we want to order method overloads with regard to number of parameters -- it simplifies to keep track of what overloads are there.,0,0.9872117638587952
98777135,2466,mjsax,2017-01-31T21:38:44Z,check `source != null` not necessary. in doubt add an assertion.,0,0.9719609618186951
98777360,2466,mjsax,2017-01-31T21:39:46Z,this can be reverted.,0,0.9787043333053589
98777858,2466,mjsax,2017-01-31T21:41:49Z,"does this add anything -- i doubt it? (ie, using a second mock tsextractor)",0,0.8671417832374573
98779356,2466,jeyhunkarimov,2017-01-31T21:48:56Z,which does not make sense: using two separate tsextractors or this test case as a whole?,0,0.8776717782020569
98780572,2466,jeyhunkarimov,2017-01-31T21:54:56Z,once i removed it failed most of the tests of `streamthreadstatestoreprovidertest` class with nullpointerexception.,0,0.9728743433952332
98781354,2466,mjsax,2017-01-31T21:58:42Z,the test is fine -- but what's the value in testing overwrite the default extractor two times.,0,0.9836106300354004
98782371,2466,jeyhunkarimov,2017-01-31T22:03:37Z,i see. so i will remove `mocktimestampextractor2` class and correct the test accordingly.,0,0.9879427552223206
98847610,2466,dguy,2017-02-01T08:44:58Z,guaranteed -> guarantees,0,0.9755076766014099
98847825,2466,dguy,2017-02-01T08:46:39Z,"same as above. i guess this is largely copy & pasted from other javadoc, so the issue is most likely elsewhere",0,0.9871877431869507
98849518,2466,dguy,2017-02-01T08:58:47Z,"topics -> topic. this may well be elsewhere in the java-doc, too",0,0.9822767376899719
98850120,2466,dguy,2017-02-01T09:02:55Z,"i know you've only added the one param here, but seeing as you are changing it can you make all the params `final`?",0,0.9875224232673645
98850172,2466,dguy,2017-02-01T09:03:19Z,make all params `final`,0,0.9845138192176819
98850208,2466,dguy,2017-02-01T09:03:31Z,as above,0,0.9783914685249329
98850243,2466,dguy,2017-02-01T09:03:48Z,as above,0,0.9783914685249329
98850272,2466,dguy,2017-02-01T09:04:01Z,as above,0,0.9783914685249329
98850377,2466,dguy,2017-02-01T09:04:40Z,"here also, would be great if you could make the params `final`",1,0.6153587698936462
98850934,2466,dguy,2017-02-01T09:08:22Z,and again with `final` if you don't mind,0,0.9736132621765137
98851089,2466,dguy,2017-02-01T09:09:29Z,`final` ? all of the fields should be `final` really,0,0.9865559339523315
98851203,2466,dguy,2017-02-01T09:10:13Z,this method can be package-private,0,0.9884668588638306
98851316,2466,dguy,2017-02-01T09:10:54Z,"we should make this `final`, too",0,0.9842286109924316
98853125,2466,dguy,2017-02-01T09:22:44Z,+1 to what said. the `source` should never be null. so you should change the `streamthreadstatestoreprovidertest`. it just needs to have the topic name extracted to a field on line 73. and then that same topic name used on line 189 in `new topicpartition(...)`,0,0.9728149771690369
98853314,2466,dguy,2017-02-01T09:23:49Z,i'd also consider extracting: `source.gettimestampextractor() != null ? ...` into a local as the line is quite long and it will make the code a bit easier to read.,0,0.9766891002655029
98853584,2466,dguy,2017-02-01T09:25:26Z,maybe `shouldaddtimestampextractorpersource` ?,0,0.9875985980033875
98853717,2466,dguy,2017-02-01T09:26:13Z,make all locals `final`,0,0.9832891821861267
99165540,2466,dguy,2017-02-02T16:51:07Z,"i'd probably extract lines 121 -> 130 into a method, i.e, `findsourcenode(...)` also, we -> if",0,0.9876344799995422
99165983,2466,dguy,2017-02-02T16:52:46Z,there is no need to test this as it is calling the same method as above.,0,0.9824128150939941
99167116,2466,dguy,2017-02-02T16:57:08Z,i'm not sure what this test has to do with `streamtask`? to me this test should be in `topologybuildertest`. you don't need a `streamtask` in this case to check that the `timestampextractor` was assigned to the source,0,0.9624353647232056
99200243,2466,mjsax,2017-02-02T19:30:02Z,"i just realized, that we use different wording for topics as array of strings and topic pattern: ""there is no ordering guarantee"" vs ""there are no ordering guarantees"" -- i think we should clean this up for consistency. would you mind to add this fix to this pr? the singular version sounds better, imho.",0,0.6194688677787781
99200386,2466,mjsax,2017-02-02T19:30:57Z,sorry -- mixed it up with `table`.,-1,0.9868326187133789
99201790,2466,jeyhunkarimov,2017-02-02T19:37:55Z,"i found `streamtasktest` the best suitable place, as it was suggested to make `sourcenode.gettimestampextractor()` method available within package. so, it is not accessible inside `topologybuildertest` currently. then i am making `sourcenode.gettimestampextractor()` public and moving the tests to `topologybuildertest`.",0,0.9794678092002869
99202642,2466,mjsax,2017-02-02T19:41:54Z,key -> topic,0,0.9769306182861328
99203389,2466,mjsax,2017-02-02T19:45:19Z,"i am still confused, about `source` being `null`. in the original code (l121) `source` is handed to `createrecrodqueue` and must not be `null` -- because this was never an issues before, i am still puzzled. why it is now.",-1,0.8824993371963501
99204674,2466,mjsax,2017-02-02T19:51:20Z,"i agree with if you test `topologybuilder#addsource()` it should go to `topologybuildertest`, and if you test `kstreambuilder#stream` it should go to `kstreambuildertest` -- this also implies, you should split this test into two. also testing `kstreambuilder#addsource` is redundant because its inherited from `topologybuilder`.",0,0.9826430082321167
99206508,2466,jeyhunkarimov,2017-02-02T19:59:00Z,"when we add the sources by pattern (`kstreambuilder.stream(final pattern topicpattern)`), the source name is given like `""pattern ["" + regex + ""]""`. for example, for `t.*` pattern it would be `""pattern[t.*]""`. in `streamtask`, we search for sources (in 121) by topic name. for example, for topic name`""topic1""`, it gives `null`,because the source name is `""pattern[t.*]""`.",0,0.9863730669021606
99446130,2466,mjsax,2017-02-03T23:55:23Z,"revert this for `.stream(...)`, because it can be multiple here. original comment only applies to `.table()` has has always a single input topic.",0,0.9849430322647095
99499027,2466,mjsax,2017-02-05T20:38:46Z,"can you address this comment, too?",0,0.9867353439331055
99499541,2466,mjsax,2017-02-05T20:58:02Z,can you please add `final` wherever possible.,0,0.9861078262329102
99499677,2466,mjsax,2017-02-05T21:02:29Z,why do you not reuse `kstreambuildertest#builder` ?,0,0.9752593040466309
99499696,2466,mjsax,2017-02-05T21:03:00Z,"it's better to split this test into multiple -- here you test if no source specific extractor is set, thus, this should be a test method `sourceextractorshouldbenull` (or similar) and the test should end here. apply to below tests, too. (split into positive/negative tests and own tests for stream/table -- for stream/table add overload methods same way to test `topologbuilder.addsource()`",0,0.9837806224822998
99500035,2466,mjsax,2017-02-05T21:16:02Z,add `final` wherever possible,0,0.987519383430481
99500140,2466,mjsax,2017-02-05T21:19:41Z,why this change?,0,0.7813909649848938
99500765,2466,mjsax,2017-02-05T21:39:07Z,why not use `topology.sourcetopicpattern()` ? and than check if `partition.topic()` matches the pattern?,0,0.9874706864356995
99500810,2466,mjsax,2017-02-05T21:40:36Z,why this change?,0,0.7813909649848938
99500845,2466,mjsax,2017-02-05T21:42:09Z,apply `final` wherever possible (also within method),0,0.9889715313911438
100309277,2466,jeyhunkarimov,2017-02-09T13:51:52Z,"i think `sourcetopicpattern()` is a method of `topologybuilder`. in `streamtask` on the other hand, we get `processortopology` instance.",0,0.9875400066375732
100309989,2466,jeyhunkarimov,2017-02-09T13:55:31Z,"if we need to find the `topic` of the given source (`streamtask.findsource()`) by pattern, either we have to remove `""pattern [ ]""` part from source name and try all matches, or we can remove it (`""pattern [ ]""` part) when we assign the name for `sourcenode` and directly use its name as `pattern`. i thought the second case would be more usable.",0,0.9852027297019958
100310215,2466,jeyhunkarimov,2017-02-09T13:56:37Z,"because the test classes (`topologybuildertest` for example) cannot access the protected method , i leave it as it is",0,0.9817242622375488
100374990,2466,mjsax,2017-02-09T18:23:53Z,ack. by bad.,-1,0.9836947917938232
100493505,2466,dguy,2017-02-10T08:56:52Z,it would be nice if you made these `final` while you are doing this change.,0,0.8760122060775757
100493542,2466,dguy,2017-02-10T08:57:06Z,+1,0,0.696722686290741
100493741,2466,dguy,2017-02-10T08:58:40Z,`return topology.source(topic);`,0,0.9815506935119629
100493758,2466,dguy,2017-02-10T08:58:50Z,`final`,0,0.9729287028312683
100493997,2466,dguy,2017-02-10T09:00:43Z,"using `assertthat` is nicer as it gives better failure messages. `assertthat(sourcenode.gettimestampextractor(), instanceof(mocktimestaampextractor))` in other places, too",0,0.9508590698242188
100494305,2466,dguy,2017-02-10T09:02:58Z,"typo: kstreamhould... -> kstreamshould in fact i'd probably rename these methods to begin with should, i.e., `shouldaddtimestampextractortostreamwithoffsetresetpersource` etc",0,0.9857516884803772
100494435,2466,dguy,2017-02-10T09:03:54Z,"as per previous `assertthat(..., instanceof(...))` would be better",0,0.9864420890808105
107829914,2466,mjsax,2017-03-24T03:39:21Z,please fix this: `use { } instead`,0,0.9857938885688782
107830212,2466,mjsax,2017-03-24T03:42:17Z,nit: add missing `.` at the end.,0,0.9880428314208984
107830238,2466,mjsax,2017-03-24T03:42:34Z,nit: missing `.`,0,0.9599177837371826
107830487,2466,mjsax,2017-03-24T03:46:55Z,nit: add `final` twice,0,0.9876234531402588
107830501,2466,mjsax,2017-03-24T03:47:08Z,nit: add `final`,0,0.9880309700965881
107830511,2466,mjsax,2017-03-24T03:47:21Z,nit: add `final`,0,0.9880309700965881
107830528,2466,mjsax,2017-03-24T03:47:36Z,add `final`,0,0.9853646159172058
107830534,2466,mjsax,2017-03-24T03:47:45Z,nit: add `final`,0,0.9880309700965881
113301565,2466,mjsax,2017-04-25T20:28:20Z,"just some nitpick: we started to to order all configs alphabetically here -- it make it a little simpler to keep an overview and to maintain the code. would you mind to not move configs that get deprecate and add the new config at the ""right"" place. thanks a lot. :)",1,0.9926623106002808
113312440,2466,mjsax,2017-04-25T21:09:13Z,"just some nitpick: we started to to order all configs alphabetically here -- it make it a little simpler to keep an overview and to maintain the code. would you mind to not move configs that get deprecate and add the new config at the ""right"" place. thanks a lot. :)",1,0.9926623106002808
113312517,2466,mjsax,2017-04-25T21:09:35Z,"for backward compatibility, we need to keep the old default value. btw: we don't do any ordering here yet -- just above. so no need to reorder anything here.",0,0.9828044176101685
113312570,2466,mjsax,2017-04-25T21:09:50Z,as above: need to keep default value.,0,0.937275767326355
113312651,2466,mjsax,2017-04-25T21:10:11Z,you can simple call `serde = defaultkeyserde()` here.,0,0.9882099628448486
113312708,2466,mjsax,2017-04-25T21:10:27Z,"`.configure()` is called within `getconfiguredinstance()` already -- you can remove this line (i know this pattern was there before, but it's wrong -- can you please fit it :)) this can be a single liner within try-catch-block: `return getconfiguredinstance(default_key_serde_class_config, serde.class);`",0,0.758404016494751
113312767,2466,mjsax,2017-04-25T21:10:44Z,as above,0,0.9783914685249329
113312830,2466,mjsax,2017-04-25T21:11:04Z,as above.,0,0.978552520275116
113508449,2466,jeyhunkarimov,2017-04-26T17:02:32Z,"if we want to distinguish between `value_serde_class_config` and `default_value_serde_class_config` for example, in `public serde valueserde()` method, we have to differentiate whether ` serde serde = getconfiguredinstance(value_serde_class_config, serde.class); ` is default or not. if it is default, then we will call `defaultvalueserde()` method. if we don't set the default value to `null`, then its default value will be some object initialized with `serdes.bytearrayserde.class.getname()` class. in this case, it is hard to know whether the old `serde` (`value_serde_class_config`) is overridden (so we return it) or it has default value (so we call `defaultvalueserde() `method). moreover, because we are controlling the access to `value_serde_class_config` via `valueserde()` method, we handle `null` cases here as well. the same applies to `key_serde_class_config` and `timestamp_extractor_class_config` as well.",0,0.9860077500343323
113564584,2466,mjsax,2017-04-26T21:16:04Z,ah. makes sense!,1,0.7523553371429443
113564805,2466,mjsax,2017-04-26T21:17:08Z,it's actually pretty elegant! :),1,0.9933819770812988
113777778,2466,jeyhunkarimov,2017-04-27T19:06:41Z,"i think in `getconfiguredinstance() ` method, `configurable.configure(map configs)` method is called, but in `keyserde() `and `valueserde() `methods we need also to call `serde.configure(map configs, boolean iskey)` method. so i think the two `configure` methods are different.",0,0.9839726686477661
113808802,2466,mjsax,2017-04-27T21:37:30Z,`serde` implements `configurable` -- the object `o` in `((configurable) o).configure(originals());` is the serde object.,0,0.9871137142181396
113811258,2466,jeyhunkarimov,2017-04-27T21:50:46Z,"yes i want to say that `serde.configure(arg1, arg2)` is different from `configurable.configure(arg1)`. so, inside `getconfiguredinstance()` method it is not called `configure(arg1, arg2)` but `configure(arg1)`",0,0.9870123267173767
113829911,2466,mjsax,2017-04-28T00:13:13Z,i did have a closer look into the code. you are right. i also double checked and `serde` does actually not implement `configurable` (so there will also not be two calls what would be bad). sorry for the confusion -- and thanks a lot for pointing out that it is correct as is!!,-1,0.8239784240722656
115824780,2466,guozhangwang,2017-05-10T18:59:48Z,with this change how would the caller differentiate between the case that of a single subscribed topic v.s. a subscribed pattern?,0,0.9841427206993103
115825542,2466,guozhangwang,2017-05-10T19:02:52Z,could we add a similar function in `streamsconfig` as `keyserde` in which we capture the deprecated / new default values there so that we do not need to leak that logic here?,0,0.9888556599617004
115826174,2466,guozhangwang,2017-05-10T19:05:50Z,"related to the question i have before: in the `tostring` function at line 85, we are printing `topics:string`, and we canno tell if it is a pattern or a single topic right?",0,0.9828141927719116
115826873,2466,guozhangwang,2017-05-10T19:09:14Z,"why do we need to augment this function here? i.e. by the time the stream task is created, we should have populated the `sourcebytopics` map with the pattern matched topics already, so i'm not sure if the additional computational logic is needed? cc .",0,0.9794871211051941
115845233,2466,jeyhunkarimov,2017-05-10T20:33:16Z,"actually `""pattern[ ]""` string is just cosmetic part of the code snippet `""pattern["" + pattern + ""]""`. we don't use `""pattern""` string (anywhere in the code) for detecting if it is a single subscribed topic or subscribed pattern.",0,0.9874742031097412
115847989,2466,jeyhunkarimov,2017-05-10T20:45:21Z,you are right. the main reason that i put this extra function is that i was getting many fails in tests. there were some tests with no source nodes defined in the test topology or the defined source nodes are not related with partitions.,0,0.9460504055023193
115850388,2466,guozhangwang,2017-05-10T20:55:16Z,"hmm, maybe it's better to fix these tests than modifying the production-code? e.g. we can add some test-only function to fill the topics from the pattern in `` rule.",0,0.9855318665504456
115850952,2466,jeyhunkarimov,2017-05-10T20:57:43Z,i fixed the tests as well and added this code snippet too. i mentioned this in [a link],0,0.9809426069259644
115852641,2466,jeyhunkarimov,2017-05-10T21:05:15Z,"yes, once the source is defined and added to topology, we cannot tell if it is defined by name or by pattern. this was the case before this pr as well.",0,0.9846327304840088
115853285,2466,jeyhunkarimov,2017-05-10T21:08:34Z,but i got your point,0,0.9087380170822144
115907018,2466,guozhangwang,2017-05-11T05:24:18Z,"thanks for the explanation, makes sense.",1,0.6684368848800659
115907121,2466,guozhangwang,2017-05-11T05:25:37Z,yeah i think if the logic is not needed in real cases then we should not add that since it may hide some potential bugs. as long as the tests can be covered then we can get rid of the unnecessary logic.,0,0.9785568118095398
115925128,2466,jeyhunkarimov,2017-05-11T07:53:51Z,"i recognized this issue: `builder.stream(pattern.compile(""t.*""))`; // this line adds sourcenode with name ""t*"", (before this pr it was `""pattern[t*]""`) after that, in `streamtask:120` when one executes: `final sourcenode source = topology.source(partition.topic());` // where `partition.topic()` is ""t1"" here the `source` will be `null` because `topology.source()` is just key value lookup. so i moved extra extra lookup for patterns from `streamtask` to` topology.source()`",0,0.9608149528503418
116282834,2466,guozhangwang,2017-05-12T17:27:51Z,"hmm, in `topologybuilder#build` when we are adding the source node we will execute the pattern matching from the current topic metadata so the map should already be filled with the actual topic right? i think the problem, as i added in `sourcenodefactory#gettopics`'s comment, is that under debugging / unit testing environment, there is no topic metadata available to pass the topic list to `list gettopics(collection subscribedtopics)`. what we need to do to fix the unit tests then is to call `subscriptionupdates#updatetopics()` before calling `builder.build()` for regex involved tests. [code block]",0,0.9704796671867371
116317477,2466,bbejeck,2017-05-12T20:26:15Z,sorry for jumping in a little late. is correct about the test. an example for unit-testing with regex defined topics using the `topologybuilder` is `topologybuildertest#shouldsetcorrectsourcenodeswithregexupdatedtopics` (line 675),-1,0.9861672520637512
116348919,2466,jeyhunkarimov,2017-05-13T02:50:11Z,thanks for your comments. done.,1,0.7616157531738281
281873083,6694,ableegoldman,2019-05-08T00:04:47Z,nit: use recordqueue.unknown instead of -1,0,0.9879361987113953
281885338,6694,ConcurrencyPractitioner,2019-05-08T01:27:58Z,"no problem, could fix that.",0,0.9664366245269775
282344028,6694,ableegoldman,2019-05-09T05:38:23Z,"can we add separate unit tests to confirm this produces the expected behavior? i think the jira had some examples highlighting why this is a problem, it would be good to convert those into tests to make sure we're really fixing the problem at hand :)",1,0.6364558339118958
282726631,6694,ConcurrencyPractitioner,2019-05-10T02:16:04Z,no problem. added a new test case to confirm behavior.,0,0.8999037742614746
289592039,6694,mjsax,2019-06-01T04:34:51Z,"can we add those method to the end of the class -- we have already a ""section"" for methods that we only need for testing.",0,0.987720787525177
289592091,6694,mjsax,2019-06-01T04:37:43Z,"to be future prove, we should encode a version number as prefix in case we ever what to change this metadata. what about ` : ` with version number ""1"" ? also, line is too long. move both parameters to their own lines.",0,0.9833471179008484
289592181,6694,mjsax,2019-06-01T04:41:15Z,"i am not an expert on this api, but i would expect that even if we commit using the producer, the consumer should still be able to read the metadata. did you verify that we cannot retrieve the metadata if eos is enabled? if this is the case, i would claim it's a bug that need to be fix.",0,0.835990846157074
289592249,6694,mjsax,2019-06-01T04:44:17Z,"we call `addrecords` during regular processing but only need to restore the partition time if a rebalance happened. hence, i don't think this is the right place to add this code. from my understanding, we should do this in `streamthread#rebalancelistener.onpartitionsassigned` instead? \cc to confirm/comment",0,0.9755837917327881
289592273,6694,mjsax,2019-06-01T04:45:41Z,we should not piggy-back test for new features to existing tests. it's better to add a new test method `shouldaddpartitiontimetooffsetmetatdataoncommit`,0,0.9859954714775085
289592283,6694,mjsax,2019-06-01T04:46:20Z,"nit: `shouldrestorepartitiontimeonrestart` -- ""update timestamp"" is a little fuzzy",0,0.9646922945976257
289609768,6694,ConcurrencyPractitioner,2019-06-01T15:48:41Z,"alright, i will check on that.",0,0.9657664895057678
289613688,6694,ConcurrencyPractitioner,2019-06-01T17:51:50Z,just realized the test i added included the test for commit mechanism anyways.,0,0.9867838621139526
289613963,6694,ConcurrencyPractitioner,2019-06-01T18:03:07Z,"ok, so after some checks, i have discovered the following: the producer and consumer are not assigned to the same topicpartition (however, that is not necessarily the reason for the failure i'm about to describe.) i'm not 100% sure if this was supposed to happen. when producer committed the transaction, that is supposed to mean the consumer group coordinator was notified to commit the offsets right? however, when the consumer available to streamtask is called (i.e. [code block]), null is returned (indicating no offsets were committed). producer's sendoffsetstotransaction requires the user to also enter a consumer group id (which is specified by user config) which we send the offsets to commit to. it is possible that unless the user specifies the right consumer group id, we would not be able to retrieve associated metadata.",0,0.9584222435951233
289677945,6694,ConcurrencyPractitioner,2019-06-03T03:17:38Z,"oh, thats a good suggestion. would need to change test location in that case.",1,0.7299537062644958
299187366,6694,abbccdda,2019-07-01T19:36:08Z,should we check for partition existence for 2 calls?,0,0.9880980849266052
299187593,6694,abbccdda,2019-07-01T19:36:56Z,better to append suffix for time variables like `timestampms`,0,0.9861186742782593
301350910,6694,mjsax,2019-07-09T00:14:07Z,"what do you mean by ""for 2 calls""? the call to `partitiontime()`? if the partition does not exists, it's a bug anyway and current code throws a npe. what do we gain by checking if the partition exists? there is still a bug and we would need to throw an exception, too, imho. what do we gain by manually throwing an exception?",0,0.9640317559242249
301351239,6694,mjsax,2019-07-09T00:15:46Z,"it's not a duration, hence, i am not sure if adding `ms` suffix helps much here? `timestamp` is always unix epoch in ms throughout the whole code base and we never add `ms` so far. thoughts?",0,0.961281418800354
301351580,6694,mjsax,2019-07-09T00:17:51Z,might be better to use `recordqueue.unknown` instead of `no_timestamp` (cf. `clear()` below),0,0.9885748028755188
301351875,6694,mjsax,2019-07-09T00:19:26Z,wdyt about this?,0,0.953070342540741
301354251,6694,mjsax,2019-07-09T00:32:55Z,"i sync with guozhang about this. it's not correct to get the committed offsets within `onpartitionsassigned()` callback, because the consumer might not have fetched/updated the offsets from the brokers. however, we should still move the off the main loop. we only need to initialize the partition time if we get a new task assigned. hence, we should move it into `assignedtasks#initializenewtasks()`?",0,0.986221432685852
301355250,6694,mjsax,2019-07-09T00:38:34Z,"not sure what you mean by this? a producer is never _assigned_ any partitions. we use the term _assigned_ for consumers only. can you clarify? absolutely. the `group.id` used to commit offsets via the producer must match the `group.id` used by the consumer to read those offsets. in kafka streams the `application.id` is used as `group.id` for the consumer and it's also passed into `producer.sendoffsetstotransaction()`. hence, i still think that we don't need to handle eos differently to get the partition-time. does this help?",0,0.9563733339309692
301355349,6694,mjsax,2019-07-09T00:39:05Z,nit: revert,0,0.7411880493164062
301668666,6694,ConcurrencyPractitioner,2019-07-09T16:02:31Z,"sure, no problem with that.",0,0.9568349123001099
301685923,6694,ConcurrencyPractitioner,2019-07-09T16:41:21Z,"ah, forgot that producer isn't assigned partitions. let me see what i can do to handle to the eos case then.",0,0.9649847745895386
309349352,6694,mjsax,2019-07-31T17:45:04Z,"this code would crash if the cast fails. to avoid the issue, we should add `setassignmenttostoredtimestamps` to `task` interface (and remove the cast here) and add an empty implementation of the method to `standbytask`. i would also rename the method to `initializetasktime()`",0,0.9851375818252563
309349964,6694,mjsax,2019-07-31T17:46:30Z,we don't need to add this any longer. we added `public long streamtime()` in another pr already.,0,0.9871979355812073
309351486,6694,mjsax,2019-07-31T17:49:54Z,"i think we should throw an exception for this case, because the added partitions of the queue are fixed and should never change (and we should never request the partition time for unknown partitions -- it we do this, it would indicate a bug and would should raise it as an exception). [code block]",0,0.987510085105896
309351989,6694,mjsax,2019-07-31T17:50:59Z,"nit: can we rename this to `partitiontime` (to align the name to `streamtime()` method) -- in kafka, we usually omit the `get` prefix on getter methods, and a record has a ""timestamp"" while for a partition or task it's a ""time"" (of course, both a ""timestamp"" and a ""time"" is just a long and quite similar, whoever, it seems more accurate to refer to their semantic meaning correctly).",0,0.9843462705612183
309352168,6694,mjsax,2019-07-31T17:51:22Z,nit: rename to `setpartitiontime()` (cf. other comment from above) also rename parameter `timestamp -> partitiontime`.,0,0.989163875579834
309352994,6694,mjsax,2019-07-31T17:53:16Z,"similar as above, we should throw an exception here.",0,0.9839453101158142
309354307,6694,mjsax,2019-07-31T17:56:06Z,nit: rename `timestamp -> partitiontime`,0,0.9880834221839905
309354740,6694,mjsax,2019-07-31T17:57:06Z,"why do we need to make `partitiontime` `public` ? in any case, please preserve the javadocs if you move the method.",0,0.9888366460800171
309355477,6694,mjsax,2019-07-31T17:58:36Z,"we merge another pr recently that updates `partitiontime` already (cf. below) -- hence, no need to add this any longer.",0,0.986846387386322
309359552,6694,mjsax,2019-07-31T18:07:51Z,i don't understand the purpose of this method. why not just get the `partitiontime` of the task and commit it?,0,0.670678973197937
309360061,6694,mjsax,2019-07-31T18:09:05Z,do you think it's worth to add a version number for the binary format of the committed offsets (i tend to think we should add a version number). i would also not encode the timestamps as `string` but as 8-byte binary long.,0,0.987781286239624
309362468,6694,mjsax,2019-07-31T18:14:41Z,so we need to log this at info level? seems error might be more appropriate because it actually indicates corrupted metadata? we should also update the error message accordingly: [code block],0,0.9854759573936462
309363884,6694,mjsax,2019-07-31T18:17:51Z,why is the return type not `void` (similar for `setassignmenttostoredtimestamps` below)? seem you added it for testing? i would prefer to keep it `void` and change the tests if possible.,0,0.9823763370513916
309364369,6694,mjsax,2019-07-31T18:18:53Z,nit: remove `get` prefix (similar below for `getpartitiontime()`,0,0.988314151763916
309364980,6694,mjsax,2019-07-31T18:20:05Z,"instead of using 3 broker for this test, we should reconfigure the brokers to allow using eos with a single broker. to do this, we need to set `transaction.state.log.replication.factor=1` in the passed-in broker config (maybe something else... not 100% sure).",0,0.9848575592041016
309366581,6694,mjsax,2019-07-31T18:23:34Z,nit: simplify to `throws exception`,0,0.9874576926231384
309366881,6694,mjsax,2019-07-31T18:24:11Z,this seems to be rather complicate. just hard code the `appid` ?,-1,0.633141040802002
309367084,6694,mjsax,2019-07-31T18:24:29Z,why do we need a store for this test? i think a simple `builder.stream().to()` should be sufficient?,0,0.9882168173789978
309367958,6694,mjsax,2019-07-31T18:26:20Z,"not sure what your comment means. can you elaborate? (i think it makes sense to test with multiple partitions, but i am not sure if i understand the comment -- how id the default key partitioner related?)",-1,0.5408305525779724
309368689,6694,mjsax,2019-07-31T18:27:42Z,"nit: rename `driver -> kafkastreams` (we always name it `kafkastreams` in test, and it would be good to keep the name for consistency)",0,0.9740095734596252
309369523,6694,mjsax,2019-07-31T18:29:34Z,"we don't need to sleep (in general, sleeping is bad practice because it makes test flaky), because when `close()` is called below, it is ensured that offsets are committed.",0,0.9619023203849792
309371664,6694,mjsax,2019-07-31T18:34:30Z,"why do we need this validation step? the partition time or stream time is not exposed in the `context` and thus, i don't understand what this step verifies? why do we need to check the topic name?",0,0.960695743560791
309371951,6694,mjsax,2019-07-31T18:35:09Z,nit: rename `maxtimestamp -> partitiontime`,0,0.9876824021339417
309372240,6694,mjsax,2019-07-31T18:35:52Z,why do we need to write two records?,0,0.964543879032135
309373077,6694,mjsax,2019-07-31T18:37:56Z,this variable is accessed by multiple threads that thus should be declared `volatile`,0,0.9877269864082336
309373488,6694,mjsax,2019-07-31T18:38:57Z,unnecessary comment,-1,0.7226426005363464
309373698,6694,mjsax,2019-07-31T18:39:30Z,no need to call `cleanup()` if we remove the state.,0,0.9860879778862
309375797,6694,mjsax,2019-07-31T18:44:23Z,"we should not care about `record.timestamp()` imho, but instead use a second variable similar to `lastrecordedtimestamp`: something like `map expectedpartitiontimeperpartition`. this allows us to set an expected partition time per partition and compare it to the passed in `partitiontime` (what you now call `maxtimestamp`) if passed in partition time does not match expected partition time, we can just throw an `runtimeexception` what will kill kafkastreams and the test will eventually time out.",0,0.8826233744621277
309375948,6694,mjsax,2019-07-31T18:44:44Z,seem not to be required?,0,0.9778614640235901
309457372,6694,ConcurrencyPractitioner,2019-07-31T22:25:10Z,"ah, this was something i added after i discovered a bug during integration tests. what happened was that offsets are periodically right (that is, it is automated)? so imagine this, the partitiontime has advanced to 10 milliseconds. we commit that time, and then streams experienced some sort of failure (akin to a restart of streams). that would mean the locally stored partitiontime was reset to -1. let's say we start processing again, and the partition time is now 9. what happens is that 9 is the timestamp committed, not 10. it overwrites the previous committed timestamp. so what we need to do is retrieve the previously committed timestamp if there was any, and then commit _that_ one instead, since that is the correct one. i had some second thoughts on this, particularly since it becomes a little difficult to distinguish between restarts, cleanups, or failures which could have the same effect. so i'm not so sure if this is still needed or we still need to modify the behavior for these cases. the thing is without this method, the test that i have added at any rate fails.",0,0.948029100894928
309457844,6694,ConcurrencyPractitioner,2019-07-31T22:27:03Z,"yeah, forgot to remove it during previous debugging.",0,0.8923070430755615
309459876,6694,ConcurrencyPractitioner,2019-07-31T22:34:50Z,"oh, the thing is this logic is neccessary, or otherwise the test will crash. if you were to look closely at [code block] logic, the class updates the partitiontime _after_ timestampextractor was called. this is important, because partitiontime is always passed in first. that means that [code block] is always passed in first when we first start processing, and if we always return maxtimestamp without checking if record.timestamp() is greater, than that means -1 will be returned no matter how many records are passed through timestampextractor. thus, what we do here is stimulate an update to partitiontime _before_ it is actually updated in [code block].",0,0.9370439052581787
309466633,6694,ConcurrencyPractitioner,2019-07-31T23:03:31Z,"alright, will do.",0,0.9570183157920837
309469061,6694,ConcurrencyPractitioner,2019-07-31T23:14:47Z,"actually, on further investigation, this method might not be needed. we will see.",0,0.9696229100227356
309478195,6694,mjsax,2019-08-01T00:01:01Z,"yes. yes, but you code return `return record.timestamp();` anyway. so for the second call of `extract()` method, `partitiontime` (ie, `maxtimestamp`) gets advanced. for a stop-restart of `kafakstreams`, with this fix on restart `partitiontime` should be `unknown` any longer, as it's should be initialized from the commit-metadata that is preserved. hence, we should see `unknown` only a single time, and the integration test should verify that we only see on the first start of `kafakstreams` but not for the second start. i cannot follow here. `partitiontime` is tracked internally and it will be updated after timestampextractor returns, base on the value that is provided in `return`.",0,0.9818945527076721
309749298,6694,ConcurrencyPractitioner,2019-08-01T15:07:52Z,"ah, but if we do throw a nullpointer here, the test i added fails. so i don't know if that is what we really should do.",0,0.8011181354522705
309776403,6694,ConcurrencyPractitioner,2019-08-01T16:01:29Z,"yeah, accidentally removed it when i was rebasing the pr. will add it back.",0,0.9603379964828491
309795005,6694,ConcurrencyPractitioner,2019-08-01T16:45:43Z,"ah, okay. then i will change that.",0,0.9588624238967896
309917436,6694,mjsax,2019-08-01T22:12:31Z,not sure -- but maybe you setup the test incorrectly? `partitiongroup` constructor get a `map partitionqueues` and you should only call `setpartitiontimestamp()` for `topicpartitions` that are provided by this map. could this explain the test issue?,0,0.9866724014282227
309918847,6694,ConcurrencyPractitioner,2019-08-01T22:17:53Z,"oh, that might be the case. i was going through the consumer assignment's topic partitions instead. will check it out.",0,0.9841398000717163
309933316,6694,ConcurrencyPractitioner,2019-08-01T23:23:00Z,"well, i put the sleep there because otherwise the test (eos enabled case) breaks. i have done quite a bit of digging, and it appears what happens is that the committed metadata retrieved is incorrect after the streams restart. i added some debug statements, and the strange thing is though is that committed() doesn't return the right metadata. i made two calls to committed() -- this is during initializetasktime() -- and the first call returns the incorrect metadata (the result suggests that no offsetandmetadata was committed), yet on the second call, it returns the correct metadata (perhaps because this time offsetandmetadata has been persisted and could now be returned by committed()). the sleep() method i put there because it seems that offsetandmetadata needs enough time to actually persist in kafka log in eosenabled=true case, otherwise, consumer#committed() returns inconsistent results.",0,0.7493508458137512
309968392,6694,ConcurrencyPractitioner,2019-08-02T03:13:55Z,"oh, i could remove them. done that.",0,0.9714012145996094
310275056,6694,abbccdda,2019-08-02T19:50:28Z,nit: space before `no-op`,0,0.985428512096405
310275504,6694,abbccdda,2019-08-02T19:52:04Z,is old metadata missing expected after we start off? might be useful to add a debug log or trace if this is not normal.,0,0.986735999584198
310275800,6694,abbccdda,2019-08-02T19:53:05Z,would be favorable to order comparison result according to first citizen. like `metadatatimestamp >= localpartitiontime ? metadatatimestamp : localpartitiontime;`,0,0.9036623239517212
310275999,6694,abbccdda,2019-08-02T19:53:45Z,maybe refactor out a helper for the above condition?,0,0.9855158925056458
310276422,6694,abbccdda,2019-08-02T19:55:06Z,why `-1`?could we define a constant referring to it?,0,0.9830883145332336
310276582,6694,abbccdda,2019-08-02T19:55:38Z,this comment is not needed.,0,0.9620018601417542
310276679,6694,abbccdda,2019-08-02T19:56:00Z,s/time stamp/timestamp,0,0.9835122227668762
310276764,6694,abbccdda,2019-08-02T19:56:17Z,would be good to define `1000` as a variable.,0,0.9623751044273376
310276812,6694,abbccdda,2019-08-02T19:56:26Z,same here,0,0.982987642288208
310319615,6694,mjsax,2019-08-02T22:50:32Z,we can remove this method -- it's declared in the interface and there is no need to have an implementation in `abstracttask`,0,0.9859145879745483
310320109,6694,mjsax,2019-08-02T22:53:28Z,can `setpartitiontime()` be package-private?,0,0.9881238341331482
310320883,6694,mjsax,2019-08-02T22:58:18Z,still not sure why we need this method? (or did you forget to remove it?),0,0.7481582760810852
310321420,6694,mjsax,2019-08-02T23:02:07Z,why do we call `initializetasktime` in `addrecordstotasks()` -- in a previous version it was called in `initializenewtasks()` what seems to be more appropriate -- why did you move it?,0,0.9844953417778015
310321680,6694,mjsax,2019-08-02T23:03:47Z,"nit: `shouldpreservepartitiontimeonkafkastreamrestart` (nothing is reset in this test). (also, avoid naming overlap with `kstream` and `ktable`)",0,0.9848968982696533
310321935,6694,mjsax,2019-08-02T23:05:34Z,why do we need to suffix the appid and topic names with the `testid` ?,0,0.983574628829956
310322139,6694,ConcurrencyPractitioner,2019-08-02T23:06:58Z,"well, since before, we never stored any metadata in kafka log, especially relating to committed timestamps. there is a possibility that an old version of offsetandmetadata is committed where it doesn't contain the committed timestamp, so i suppose this is expected behavior.",0,0.9857573509216309
310322225,6694,ConcurrencyPractitioner,2019-08-02T23:07:37Z,"well, the order in general doesn't seem to matter that much. but could change it.",0,0.9737518429756165
310322293,6694,ConcurrencyPractitioner,2019-08-02T23:08:04Z,"yeah, it looks like it appeared several times in the code, might want to add it as some separate static helper method.",0,0.9860342144966125
310322589,6694,mjsax,2019-08-02T23:10:17Z,"that is weird. \cc how could the happen? if we stop the first instance, the transactions should be committed and afterwards, if we start a new instance, the new consumer client should be able to read the correct offset and metadata. any idea?",-1,0.9898367524147034
310323805,6694,ConcurrencyPractitioner,2019-08-02T23:19:48Z,"oh, tried to run a test without this method, but abstracttasktest would break unfortunately if this method is not implemented in abstracttask (apparently, abstracttask's constructor is called, and compiler complains about it as a result).",0,0.6905128955841064
310324030,6694,ConcurrencyPractitioner,2019-08-02T23:21:31Z,"oh, actually, yeah, we can remove this method. we could just modify the abstracttasktest itself.",0,0.9860062599182129
310324216,6694,ConcurrencyPractitioner,2019-08-02T23:22:56Z,"sure, there shouldn't be any problems.",0,0.9753595590591431
310324305,6694,ConcurrencyPractitioner,2019-08-02T23:23:33Z,"ok, no problem.",0,0.9606370329856873
310324616,6694,ConcurrencyPractitioner,2019-08-02T23:26:15Z,just thought it would be a good idea to include more information in the the id names. they can be hardcoded.,0,0.8980057835578918
310324663,6694,ConcurrencyPractitioner,2019-08-02T23:26:36Z,done.,0,0.9759407639503479
310327228,6694,ConcurrencyPractitioner,2019-08-02T23:51:20Z,"ok, i realized what is happening. during the process to close a streamtask, the partitiontimes are reset to -1 first before the local partition times are committed. effectively, what is occurring is that we are committing -1 during close() due to the order of operations we are performing it. i have found a solution to it, so i will push a change shortly.",0,0.9635221362113953
310327593,6694,mjsax,2019-08-02T23:55:17Z,good find!,1,0.9875446557998657
310704615,6694,ConcurrencyPractitioner,2019-08-05T17:10:51Z,"how would you do that though? i don't think offsetandmetadata could store an 8-byte binary long directly, so we have to use encode and decode the byte array as some string. is that how we should do it?",0,0.9853805899620056
310707714,6694,ConcurrencyPractitioner,2019-08-05T17:19:15Z,i was thinking about using utf8 conversions.,0,0.9654679298400879
310722093,6694,mjsax,2019-08-05T17:56:43Z,"good pointed. i missed that the type is `string` (expected it to be `byte[]`). hence, for efficient encoding, and to allow us to add a magic/version byte, we should first serialize the timestamp, prefix it with a magic byte and then ""deserialize"" it to `string`. [code block]",1,0.9385164976119995
310764557,6694,ConcurrencyPractitioner,2019-08-05T19:50:43Z,"okay. i pushed a version of what i thought was pretty close to the process you were describing. mind taking a look? at the moment, it doesn't seem to work though. i did some research and what we are using is basically utf8 encodings. it did look like however that some information was lost. (i did some debug statements and found that the decoded value was 1007 instead of 1000, somewhat bizarre).",0,0.9203904867172241
310803256,6694,ConcurrencyPractitioner,2019-08-05T21:39:26Z,"alright, i have done thorough investigations and here is what i found. i came across the following on stack overflow: [a link] if one looks closely, they would quickly realize that utf8 is not fit for the task at hand. in reality, we would need to do something like using base64 encodings instead (which is supposedly part of java since version 1.8). however, gradle does not allow the usage of base64 since it ""could not be found"" according to the compiler anyways. in conclusion, i don't think the current approach as it is will work. if things don't progress any further, i'd suggest sticking with the original idea of just sticking the long unencrpyted directly into the string (plus a version number). your thoughts ?",0,0.9074348211288452
311705840,6694,mjsax,2019-08-07T18:42:09Z,`task` is of type `task` -- no need to cast :),0,0.49042564630508423
311707813,6694,mjsax,2019-08-07T18:46:49Z,"good find! how did you try to use it? everything from the standard library should be available... i would prefer to use base64 if we can. if not possible, we can still fall back to using string, but i would really like to avoid it if we can.",1,0.976202666759491
311713153,6694,mjsax,2019-08-07T18:59:17Z,nit: avoid changes in unrelated files,0,0.9740197658538818
311714343,6694,mjsax,2019-08-07T19:02:03Z,why not do this unconditionally? if it's not `clear` we won't commit anyway. it's seems cleaner to avoid to many branches and it's not on the hot code path so the overhead of updating `partitiontime` is not relevant.,0,0.9266714453697205
311714674,6694,mjsax,2019-08-07T19:02:49Z,i am not sure why we need this variable? can you elaborate?,0,0.6457279324531555
311817120,6694,ConcurrencyPractitioner,2019-08-08T00:45:54Z,"alright, that's fine.",0,0.9362761974334717
311817419,6694,ConcurrencyPractitioner,2019-08-08T00:47:53Z,"oh, because we need to differentiate between a commit that is triggered by a regular process or by a close. if we call partitiontime() in a commit triggered by a close() call, then partitiontime() would always return -1. (recall that due to the order of operations in close, the partition times has been reset to -1 first before the commit call was made).",0,0.9730498194694519
311819651,6694,ConcurrencyPractitioner,2019-08-08T01:01:37Z,"ah okay, so this is the error that i've found. [code block] notice that the package name does not start with java. it might be some third party library that gradle does not account for.",0,0.9791497588157654
311819717,6694,ConcurrencyPractitioner,2019-08-08T01:02:01Z,this might help explain why base64 might not be used.,0,0.9837355613708496
311820182,6694,ConcurrencyPractitioner,2019-08-08T01:05:13Z,yeah. my bad. didn't realize t extends task.,-1,0.9886504411697388
311849604,6694,mjsax,2019-08-08T04:14:21Z,seem you include the wrong class/package: [a link],0,0.9366132616996765
311850528,6694,mjsax,2019-08-08T04:20:46Z,is the any advantage of this library compare to [a link] \cc,0,0.9866579174995422
311851742,6694,mjsax,2019-08-08T04:30:36Z,"thanks. understood. it might be better, to actually change `stream#commit(boolean startnewtransaction)` to accept a second parameter `map partitiontimes` to pass in the information. in `close()` before we actually ""loose"" the timestamps we preserve them and pass into `commit()` later. in a regular `commit()` we get the timestamps from the `partitiongroup` (ie, some code that is now in `commit(boolean)` would go into `commit()`). this would avoid the requirement to introduce the flag and make the code more readable, because decision are more local an encapsulated in each method without cross-method dependencies.",1,0.9198191165924072
311852052,6694,mjsax,2019-08-08T04:32:39Z,we should return `recordqueue.unknown` instead.,0,0.9883477091789246
311852198,6694,mjsax,2019-08-08T04:33:39Z,"same as above: also, we should log a warn message there, that the the found metadata is corrupted and cannot be decoded.",0,0.9880034923553467
311859113,6694,ConcurrencyPractitioner,2019-08-08T05:20:50Z,"actually, just realized that this library existed. :p didn't know until later. will remove this dependency (the old bouncycastle one).",1,0.9355627298355103
311862190,6694,ijuma,2019-08-08T05:38:39Z,sounds good.,1,0.9202015399932861
312137582,6694,ConcurrencyPractitioner,2019-08-08T16:48:16Z,"oh, sure, that would work.",0,0.887279748916626
312165368,6694,mjsax,2019-08-08T17:51:53Z,"passing in `null` is not idea imho. at this point, we _know_ that we want to get the timestamps from the `partitiongroup`. hence, seems better to build up the correct `map< topicpartition, long>`, by looping over all committed offsets: [code block]",0,0.9773917198181152
312165647,6694,mjsax,2019-08-08T17:52:27Z,i think we don't need this method if we apply my other suggestions,0,0.9763174057006836
312166158,6694,mjsax,2019-08-08T17:53:38Z,"input parameter `partitiontimes` should always contain the correct partition time, hence, we can just get it: [code block]",0,0.9874927997589111
312166420,6694,mjsax,2019-08-08T17:54:11Z,nit: `partitiontimemap` -> `partitiontimes`,0,0.9883282780647278
312167539,6694,mjsax,2019-08-08T17:56:37Z,this block can be moved outside of the `try-catch-block`,0,0.9886907339096069
312167714,6694,mjsax,2019-08-08T17:56:57Z,i guess we can remove this comment,0,0.9860755801200867
312169542,6694,mjsax,2019-08-08T18:00:42Z,might be good to add an `else` and also add a debug log stating that no committed offset was found,0,0.9853613972663879
312170299,6694,mjsax,2019-08-08T18:02:20Z,this method is not only _receiving_ but also _setting_ the partition time. what about renaming it to `initializepartitiontime()`,0,0.9888019561767578
312170692,6694,mjsax,2019-08-08T18:03:15Z,return type is `void` -- remove this line,0,0.9838459491729736
312171157,6694,mjsax,2019-08-08T18:04:15Z,nit: add comment `// visible for testing` (same for decodetimestamp() below) also add test methods to `streamtasktest` to test both methods.,0,0.9896851778030396
312171865,6694,mjsax,2019-08-08T18:05:40Z,"nit: (simplify to) `""unsupported offset metadata version found. supported version {}. found version {}.""`",0,0.9871942400932312
312235875,6694,mjsax,2019-08-08T20:47:29Z,nit: could we use `getstartedstreams()` again?,0,0.9891871809959412
312237424,6694,mjsax,2019-08-08T20:51:27Z,"`assertthat(task.decodetimestamp(consumer.committed(partition1).metadata()), equalto(default_timestamp));` simplify `task.cosumer` -> `consumer`",0,0.9864144921302795
312238609,6694,mjsax,2019-08-08T20:54:22Z,nit: remove unnecessary comment,0,0.9713148474693298
312239083,6694,mjsax,2019-08-08T20:55:32Z,nit: remove unnecessary comment,0,0.9713148474693298
312239225,6694,mjsax,2019-08-08T20:55:50Z,nit: remove unnecessary comment,0,0.9713148474693298
312289819,6694,mjsax,2019-08-09T00:06:23Z,"this test setup defeats the purpose fo this test. if eos is enabled, the producer is used to commit offsets, and thus, we should check if the producer does commit the corresponding metadata correctly. therefore, we need to change the test setup a little bit. in `createstatelesstask()`, we create an anonymous `producersupplier` and we need to get hold off the generated mock-producer instance. we can then use `mockproducer#consumergroupoffsetshistory` to get the committed offsets and metadata.",0,0.968842089176178
312289927,6694,mjsax,2019-08-09T00:07:06Z,as above (similar below),0,0.9773377180099487
312309368,6694,ConcurrencyPractitioner,2019-08-09T02:23:56Z,done that.,0,0.9742528200149536
312581629,6694,mjsax,2019-08-09T17:38:06Z,not 100% sure if we nee this `null` check any longer after the refactoring. \cc wdyt?,0,0.9706094861030579
312588676,6694,mjsax,2019-08-09T17:57:06Z,"seems we should test `partitiontimestamp` above already, when we `verifybuffered(6, 3, 3);` ? also, we should check the returned time for both partitions each time? i would also add a test of `group.streamtime()` for each step in the test (not sure why it's missing -- this would be a good additional improvement).",0,0.9735137224197388
312588867,6694,mjsax,2019-08-09T17:57:43Z,we should test this method in it's own test method,0,0.9842721223831177
312589597,6694,mjsax,2019-08-09T17:59:44Z,"use `assertthrows` instead of the try catch block, and use `assertthat` to verify the exception message. also, this should be two tests, one for ""set"" and one for ""get"".",0,0.9881801605224609
312590312,6694,mjsax,2019-08-09T18:01:52Z,"in addition, we should check if ""stream time"" was updated correctly. nit: `assertequals` take ""excepted value"" as first parameter, so you need to flip both (otherwise the error message would be confusing if the test fails)",0,0.9865142703056335
312592021,6694,mjsax,2019-08-09T18:07:04Z,please rewrite using `assertthat` (or at least `assertequals`) -- similar below,0,0.9872798919677734
312592448,6694,mjsax,2019-08-09T18:08:18Z,"we should add more test method for the different error cases, too.",0,0.9849426746368408
312593338,6694,mjsax,2019-08-09T18:10:52Z,"this whole block (l680-687) can be remove -- there is no need for the test to commit anything in addition. note that the `assert` above tests the previous `commitsync()` what is not useful, as test-code should not test other test-code :)",0,0.9405749440193176
312595808,6694,mjsax,2019-08-09T18:17:49Z,no need to use a nested for loops. this can be simplified to: [code block],0,0.9876559972763062
312634550,6694,ableegoldman,2019-08-09T20:18:36Z,"yeah, i don't see how a partition could be in `consumedoffsets` but not in `partitiontimes`?",0,0.9789782166481018
313846296,6694,cadonna,2019-08-14T12:26:00Z,why do you need this assertion? `close()` waits for `long.max_value` for state `not_running`.,0,0.9868725538253784
313850160,6694,cadonna,2019-08-14T12:36:04Z,the order of the imports in kafka streams is usually as follows: kafka imports and 3rd-party imports in one block a block of `java.*` imports `import static`.,0,0.9887224435806274
314216469,6694,cadonna,2019-08-15T08:26:06Z,"wouldn't creating a new task be better? afaik, that is what happens during a restart. no need to simulate anything. furthermore, it avoids introducing a new method just for testing.",0,0.9712510704994202
314220806,6694,cadonna,2019-08-15T08:39:56Z,"would be good to extract `""stream-task-test""` to a member field of the test and use it in `createconfig()` and here.",0,0.9816315770149231
314221852,6694,cadonna,2019-08-15T08:43:09Z,see above,0,0.9731385707855225
314223844,6694,cadonna,2019-08-15T08:49:05Z,see above,0,0.9731385707855225
314223931,6694,cadonna,2019-08-15T08:49:18Z,why do we need this assertion here?,0,0.9665068984031677
314226105,6694,cadonna,2019-08-15T08:55:49Z,"i see that you tested the different error cases as suggested. however, i would put each test in its own test method.",0,0.9857296943664551
314227123,6694,cadonna,2019-08-15T08:58:51Z,see my comment on the usage of this method in `streamtasktest`.,0,0.9850788116455078
314230884,6694,cadonna,2019-08-15T09:09:53Z,i would put methods to write and read record metadata in their own classes. those classes would be kind of serdes for metadata. such serdes would make the code better testable and separates the concerns of a task and reading and writing metadata which are completely independent. it does not need to be done in this pr. i just wanted to mention it.,0,0.9187840819358826
314236760,6694,cadonna,2019-08-15T09:28:24Z,please remove empty line before this line.,0,0.9813991189002991
314238406,6694,cadonna,2019-08-15T09:33:50Z,"this tests misses to verify whether `streamtime` is set or not. furthermore, i would write two (or three) distinct tests: - `partitiontimestamp` is set (could be further split for `streamtime` is set or not) - `nullpointerexception` is thrown",0,0.9871566891670227
314241100,6694,cadonna,2019-08-15T09:42:10Z,the code block from the beginning of the method until here can be extracted and re-used in this and the previous test methods.,0,0.9867522716522217
314241548,6694,cadonna,2019-08-15T09:43:59Z,"i think, we use `should...` for newly added test methods.",0,0.9874768853187561
314375243,6694,ConcurrencyPractitioner,2019-08-15T15:49:28Z,its just to confirm that there's no problems with the state being removed. thought it would be good to keep that at the very least.,0,0.9273126125335693
314398959,6694,ConcurrencyPractitioner,2019-08-15T16:46:54Z,"yeah, that would probably be a good idea in the future.",1,0.5444178581237793
314402987,6694,ConcurrencyPractitioner,2019-08-15T16:57:09Z,"yeah, it can be removed. its somewhat redundant.",0,0.7577695846557617
320293937,6694,cadonna,2019-09-03T14:11:38Z,here it would be better to call `partitionqueues.get(partition)` only once and store its result in a variable. then check the variable for `null` and call `partitiontime()` on the variable.,0,0.9885590672492981
320294207,6694,cadonna,2019-09-03T14:12:03Z,same as above.,0,0.9746477603912354
321203916,6694,cadonna,2019-09-05T11:18:20Z,"i am wondering whether we can do better here. encoding partition time in base64 seems to me a bit a waste of space. as far as i can see, a 8 byte value is encoded in 11 bytes with base64. would be great, if we could store partition time in 8 bytes. i am also wondering why `metadata` in `offsetandmetadata` is a `string` and not something more bytes friendly.",0,0.6634538173675537
321938111,6694,ConcurrencyPractitioner,2019-09-06T23:14:51Z,"yeah, it is still unclear at this point if the [code block] field in [code block] could be used in this manner. or knows this matter better. anyhow, offsetandmetadata right now is the only medium through which we can checkpoint partition time anyways. so we might be stuck with using the [code block] field.",0,0.9534719586372375
323392057,6694,mjsax,2019-09-11T18:25:53Z,"i know that i recommended to add this parameter, but now, after more refactoring of the code, i am not sure any longer why we need it? it seems that this method is called twice and both calls pass in the result of `extractpartitiontimes()` as parameter -- hence, it seems we can remove the parameter and do the call to `extractpartitiontimes()` within the method itself?",0,0.9804225564002991
323397342,6694,mjsax,2019-09-11T18:37:46Z,"this is a blocking call, and just proposed kip-520 to make it more efficient by allowing to pass in multiple partitions at once. should we wait for kip-520 to be implemented? if now, we should make sure the update this code after kip-520 is merged. i am also wondering how we should handle `timeoutexception` for this call? maybe not, but might be worth to clarify? \cc",0,0.852085530757904
323496050,6694,mjsax,2019-09-11T23:03:23Z,"i don't have the full context on the history, but it would not be easy to change the api... i talked to jason about it, and it seem we can just move forward with this pr as-is, and could do a kip later that allows us to store metadata as `byte[]` type if we really need to change it. atm, the metadata is just a few bytes and the overhead does not really matter imho.",0,0.8791927099227905
323621863,6694,cadonna,2019-09-12T08:40:55Z,agreed,0,0.9622963666915894
324510011,6694,mjsax,2019-09-16T04:55:22Z,i remember now -- can we add a comment to explain that we need to get `partitiontimes` before we `closetopology()` (sorry for my previous comment -- forgot about that),-1,0.949343204498291
324917516,6694,guozhangwang,2019-09-16T22:48:38Z,in my pr ([a link] i've refactored this part in streamtask. i'd suggest we merge that one before this.,0,0.9818311333656311
324926772,6694,ConcurrencyPractitioner,2019-09-16T23:29:05Z,"cool, got it done.",1,0.9263009428977966
325385581,6694,guozhangwang,2019-09-17T21:05:42Z,just realized i need to do another rebase on my pr. so if this pr is closer to be merged i'd suggest you guys just move forward and i will rebase mine later.,0,0.9405209422111511
325432250,6694,ConcurrencyPractitioner,2019-09-17T23:53:00Z,"cool, sounds good. in that case, we could get this one merged since it is about complete.",1,0.9873249530792236
184775884,4931,rhauch,2018-04-27T18:47:37Z,it'd be nice to have javadoc for this interface (and all other public api types) that explains the purpose.,0,0.8768515586853027
184776184,4931,rhauch,2018-04-27T18:48:44Z,"nit: this method returns a list of connector _names_, not connector instances.",0,0.9890105128288269
184776264,4931,rhauch,2018-04-27T18:49:05Z,how about just `connectorstate`?,0,0.9880716800689697
184776561,4931,rhauch,2018-04-27T18:50:16Z,"missing javadoc on the type and method. imo, the javadoc on the interface should fully describe how to provide an implementation (by implementing this class, but what about other interfaces), how to package it (e.g., java service provider file), and how to install it (put it on the plugin path). it should also go into detail about how connect uses this interface, when implementations are instantiated and when the register method is called, and when the close method is called. what exceptions can be thrown by this method? will the supplied context ever be null? what are the behaviors that are expected/allowed? what happens when a resource is already registered?",0,0.983183741569519
184777667,4931,rhauch,2018-04-27T18:54:30Z,"it should be clear that implementations are provided by the framework, but it should be clear what this does and how it can be used by extension implementations.",0,0.9854558110237122
184777830,4931,rhauch,2018-04-27T18:55:11Z,"why not an interface? that would offer us so much more flexibility in the implementation, and all of the implementation details can be hidden from the public api. by having the nested classes here, they are in the public api and need to be managed through kips.",0,0.9806665778160095
184778299,4931,rhauch,2018-04-27T18:57:11Z,minor: let's not add unnecessary whitespace.,0,0.9768897294998169
184778412,4931,rhauch,2018-04-27T18:57:41Z,unnecessary whitespace.,-1,0.505902886390686
184778471,4931,rhauch,2018-04-27T18:57:58Z,this can be `final`.,0,0.9858740568161011
184778842,4931,rhauch,2018-04-27T18:59:34Z,how about javadoc that explains that this class is for hiding the jax-rs framework implementation and for handling registration of duplicate resources.,0,0.9862158298492432
184779307,4931,rhauch,2018-04-27T19:01:24Z,"as i mentioned earlier, we need to use java service provider api to find which plugin has the specified implementation, and we should change plugins to support creating these instances. this code only works if the implementations are on the classpath.",0,0.9880304932594299
184829319,4931,mageshn,2018-04-27T23:48:41Z,yes agreed. i still haven't integrated with the plugin classloader yet. hence used this method for the draft so that we get a better picture of the public interfaces.,0,0.9749743342399597
184829507,4931,mageshn,2018-04-27T23:51:05Z,connectorstatedetails provides both the connectorstate and connector taskstate. the original entity class has a name of connectorstateinfo but didn't want to use the same name because i thought it might be a little confusing,0,0.9699525833129883
184829705,4931,mageshn,2018-04-27T23:53:26Z,"the nested classes are also technically part of the public api since user can access it. but imo, having interfaces for pojo or entities might be a little bit of overhead. the only thing we can hide by making it an interface is the constructor.",0,0.9739319086074829
184830969,4931,rhauch,2018-04-28T00:09:38Z,"using an interface gives us more options on the implementation side, and it helps clarify intentions more explicitly and minimally, without exposing implementation details.",0,0.9753109812736511
184830991,4931,rhauch,2018-04-28T00:09:56Z,or maybe just `connectordetail` or `connectordescription`?,0,0.9885945320129395
184831075,4931,rhauch,2018-04-28T00:11:01Z,"is it intentional that these tasks are ordered? to the indexes correspond to the task id? if not, perhaps a collection is sufficient, or a map keyed by task id.",0,0.9845202565193176
185244935,4931,rhauch,2018-05-01T15:12:34Z,"first, the iterator returned by the `serviceloader.load` method will be instances of `t`, not `class `, so the call to `addplugindesc` above should result in a class cast exception. third, since these are already instantiated by the serviceloader and match the specified type, why not forgo the logic in `addplugindesc` and simply instantiate a `plugindesc like the only thing we need to do is finally, `serviceloader` is `iterable`, which means the iterator logic can be simpler. put all these three together: [code block] in order to do this, we would need to add a `versionable` interface so that connector and rest extension can extend it.",0,0.9777784943580627
185245899,4931,rhauch,2018-05-01T15:16:10Z,"i know that much of this logic was from the original code, but it might be good to add some debug/trace log messages here, especially in the missing `else` condition (e.g., ""skipping {} since it is not a concrete type."").",0,0.9836692214012146
185246193,4931,rhauch,2018-05-01T15:17:10Z,this won't work for interfaces other than `connector`.,0,0.9732217788696289
185256557,4931,mageshn,2018-05-01T15:56:01Z,"good catch on the serviceloader returning an implementation. having said that, do you think we should cache these implementations instead of creating an instance ourselves? i don't personally see a benefit to using the same instance the one returned by the serviceloader.",1,0.8659108281135559
185260491,4931,rhauch,2018-05-01T16:12:16Z,"if we can make this method more generic or general purpose, then this method should probably be called within a conditional block checking whether it implements `configurable`.",0,0.9884467124938965
185261384,4931,rhauch,2018-05-01T16:15:52Z,this method does not have much logic that is specific to `connectrestextension`. have you thought about making this more general-purpose to load any extensions (other than when a more specific method is available)? doing that might make it easier to add future extensions.,0,0.9662309885025024
185262140,4931,rhauch,2018-05-01T16:18:36Z,"the serviceloader is usually just used directly to load all instances of a particular extension point, but that's not really what we do. and really there's nothing special about _how_ serviceloader instantiates the class: it really just does a new instance on the class.",0,0.9446074366569519
185262431,4931,rhauch,2018-05-01T16:19:51Z,"btw, we should have a test case that loads a test implementation of `restextension` using plugins.",0,0.9889817833900452
185384782,4931,mageshn,2018-05-02T03:11:12Z,"yes, i will be adding more tests. once we all agree on the public interfaces, i will update the kip and refine this pr",0,0.9518046975135803
185385261,4931,mageshn,2018-05-02T03:17:30Z,would be good to have state or status in there since its just not a connectordescription,0,0.9688975214958191
185537702,4931,rhauch,2018-05-02T15:26:54Z,"use ""component"" rather than ""plugin""?",0,0.9866788983345032
185539183,4931,rhauch,2018-05-02T15:30:46Z,"how about `connectorhealth`, since this is likely to be used by health check extensions? the `detail` in `connectorstatedetail` just seems superfluous to me.",0,0.5844339728355408
185540424,4931,rhauch,2018-05-02T15:34:18Z,suggest at a minimum:,0,0.9783132076263428
185540807,4931,rhauch,2018-05-02T15:35:30Z,this logic is in two places. how about a helper method? if it were named `vesrionfor(class clazz)` then it could be more easily inlined where it's used.,0,0.9886614084243774
185892000,4931,wicknicks,2018-05-03T18:13:24Z,"maybe you guys have already talked about this, but does it make sense to have a per extension prefix for the configs? similar to how it is done for transformations?",0,0.9837070107460022
185893483,4931,wicknicks,2018-05-03T18:18:40Z,should we pass in `connectrestextensioncontext` with the `newconnectrestextensions(..)` method above? it will be cleaner to create and register the plugin in one place.,0,0.9894018769264221
185903792,4931,wicknicks,2018-05-03T18:56:19Z,"yeah, i agree with randall here. `detail` is not a good fit here. maybe you can use `connectorscontext`?",0,0.9363876581192017
185904747,4931,wicknicks,2018-05-03T18:59:53Z,should we expose connector metrics here? it could be a good fit for the health check resource in the kip).,0,0.9488710165023804
186196449,4931,kkonstantine,2018-05-04T19:43:23Z,i think we are stretching the use `-able` here. i'd suggest `versioned` as one of the less frequent cases where we'd use an adjective that does not and in `-able` but which makes a lot of sense for the functionality that this interface describes.,0,0.9804224371910095
186197396,4931,kkonstantine,2018-05-04T19:47:59Z,javadoc?,0,0.987860381603241
187750001,4931,kkonstantine,2018-05-11T22:52:32Z,i think we are stretching the use -able here. i'd suggest `versioned` as one of the less frequent cases where we'd use an adjective that does not and in -able but which makes a lot of sense for the functionality that this interface describes.,0,0.9751444458961487
187750848,4931,kkonstantine,2018-05-11T23:00:25Z,nit: missing ``,0,0.9547641277313232
187750866,4931,kkonstantine,2018-05-11T23:00:33Z,nit: missing ``,0,0.9547641277313232
187756954,4931,kkonstantine,2018-05-12T00:10:00Z,"if we want to be precise, we shouldn't mention `list` here. this is implementation specific but the interface could return a set or actually anything that is a `collection`. i'd love if we could rephrase the descriptions here to keep our options open.",1,0.7510271072387695
187757323,4931,kkonstantine,2018-05-12T00:15:16Z,"i'd suggest referring to plugin path as only `plugin.path` and basically when it makes more sense referring to the parameter. maybe here you could replace with something like: `for the connect's class loader's to be able to discover the ...""",0,0.9824926853179932
187757374,4931,kkonstantine,2018-05-12T00:16:11Z,typo? `place` -> `placed`? also maybe rephrase into shorter sentences to make easier to follow?,0,0.9844649434089661
187757473,4931,kkonstantine,2018-05-12T00:17:59Z,"i'm torn about upper casing here. feels like lower cased words make more sense: `security (authentication and authorization), logging, request validations, etc`. ...",-1,0.9818684458732605
187757938,4931,kkonstantine,2018-05-12T00:25:48Z,"nit: framework means connect here i assume. so, maybe it's better to call this out as: `connect` or `connect framework`",0,0.9812082052230835
187758006,4931,kkonstantine,2018-05-12T00:27:05Z,nit: again i'd use lower case for anything that's not a name or a code class (mostly): `connect resources`,0,0.9860259890556335
187758037,4931,kkonstantine,2018-05-12T00:27:34Z,nit: extra blank line,0,0.9819577932357788
187758071,4931,kkonstantine,2018-05-12T00:28:08Z,nit: `provides the ability`?,0,0.9864263534545898
187758104,4931,kkonstantine,2018-05-12T00:28:58Z,`the connect framework`? which framework?,0,0.9861781597137451
187758167,4931,kkonstantine,2018-05-12T00:29:55Z,description is missing. i'm not a fan of javadoc that contains only ``. maybe most text could be in the description and `` could be brief.,-1,0.9120141863822937
187758286,4931,kkonstantine,2018-05-12T00:31:44Z,"typos: return a -> return an (no 1+ spaces), ot -> to",0,0.9880707263946533
188085678,4931,kkonstantine,2018-05-14T20:22:57Z,this applies unchecked overriding of the return type. in `connectrestextensioncontext` its `configurable ` and the same should be used in the member field as well as the return type here.,0,0.9884649515151978
188085791,4931,kkonstantine,2018-05-14T20:23:17Z,`configurable ` same as below,0,0.9862609505653381
188086026,4931,kkonstantine,2018-05-14T20:24:04Z,"nit: extra blank line, here and elsewhere in this class.",0,0.9848325848579407
188086886,4931,kkonstantine,2018-05-14T20:26:56Z,"javadoc would be nice, here and in the rest of the public inner classes (especially since we have `abstractstate` elsewhere too)",0,0.6352617740631104
188087495,4931,kkonstantine,2018-05-14T20:28:53Z,"should this be called `taskid`, equivalently to `workerid` above? it'll make initialization and usage clear (i think)",0,0.9876347184181213
188088345,4931,kkonstantine,2018-05-14T20:31:44Z,an `enum` with the same name and the same `tostring` implementation is already defined here: `org.apache.kafka.connect.runtime.rest.entities.connectortype` do we need to add this one?,0,0.9883177876472473
188089609,4931,kkonstantine,2018-05-14T20:35:59Z,it's common to write `username` as `password` (instead of `password`). would you agree changing it wherever we use `username` in this pr? (check with `grep -rl username`),0,0.9890375733375549
188090162,4931,kkonstantine,2018-05-14T20:37:47Z,not clear what's the meaning of `32` here. can we declare an intuitive `static final` variable?,0,0.9793007373809814
188090361,4931,kkonstantine,2018-05-14T20:38:33Z,also a nice candidate for `static final` member variable.,1,0.7355967164039612
188091528,4931,kkonstantine,2018-05-14T20:42:51Z,should we throw `unsupportedcallbackexception` if it doesn't match? especially since we declare it and that's the intended use of this exception according to the interface (actually we're violating the interfaces contract if we don't).,0,0.9379916787147522
188093766,4931,kkonstantine,2018-05-14T20:50:37Z,"probably makes sense to be `static`, especially because of its size.",0,0.9806901812553406
188093995,4931,kkonstantine,2018-05-14T20:51:27Z,nit: should be in the same line as above,0,0.9826493263244629
188094029,4931,kkonstantine,2018-05-14T20:51:33Z,nit: should be in the same line as above,0,0.9826493263244629
188094120,4931,kkonstantine,2018-05-14T20:51:51Z,nit: should be in the same line as above,0,0.9826493263244629
188094141,4931,kkonstantine,2018-05-14T20:51:56Z,nit: should be in the same line as above,0,0.9826493263244629
188094184,4931,kkonstantine,2018-05-14T20:52:05Z,nit: should be in the same line as above,0,0.9826493263244629
188094421,4931,kkonstantine,2018-05-14T20:52:55Z,"`class names`. no caps (same as classloader, etc).",0,0.9851070046424866
188094764,4931,kkonstantine,2018-05-14T20:53:59Z,"nit: you may fit args in one line, as in `newheaderconverter`",0,0.98843914270401
188094969,4931,kkonstantine,2018-05-14T20:54:37Z,nit: extra space between: `of plugins`,0,0.9848346710205078
188096167,4931,kkonstantine,2018-05-14T20:58:50Z,"no caps pls. `empty` -> `empty list`, `null` -> `{ null}`",0,0.9831051230430603
188096202,4931,kkonstantine,2018-05-14T20:58:58Z,"no caps pls. empty -> empty list, null -> { null}",0,0.9834074378013611
188097792,4931,kkonstantine,2018-05-14T21:04:02Z,"also the generic name of this method contradicts its functionality. in not general, but pertains only to `connectrestextension`. should probably be named same as with the others above, until we perform some short of consolidation in the functionality. so `newconnectrestextensionplugins` here",0,0.9798948168754578
188097949,4931,kkonstantine,2018-05-14T21:04:28Z,"for the same reasons as above, this should probably be: `newconnectrestextensionplugin`. the log message bellow shows that this method is specific to `connectrestextensions `",0,0.987699031829834
188099111,4931,kkonstantine,2018-05-14T21:08:33Z,nit: extra blank line,0,0.9819577932357788
188099600,4931,kkonstantine,2018-05-14T21:10:17Z,~java.util.~ collection,0,0.9811279773712158
188100389,4931,kkonstantine,2018-05-14T21:13:15Z,should be `final`,0,0.9822943210601807
188100820,4931,kkonstantine,2018-05-14T21:14:44Z,"if that's a todo comment (which we should avoid adding if we can), it should be marked as `//todo: log ... something more` i'm only guessing what it means here.",0,0.9789247512817383
188100846,4931,kkonstantine,2018-05-14T21:14:51Z,"if that's a todo comment (which we should avoid adding if we can), it should be marked as `//todo: log ... something more`",0,0.984439492225647
188101268,4931,kkonstantine,2018-05-14T21:16:21Z,both exception are unused here.,0,0.9786686897277832
188101632,4931,kkonstantine,2018-05-14T21:17:43Z,"symmetrically to the above similar method, it's better if `result` is declared close to where it's used. here just before the `for (t impl : serviceloader)` loop",0,0.9880974888801575
188102042,4931,kkonstantine,2018-05-14T21:19:11Z,nit: alignment probably better as: [code block],0,0.9806355834007263
188108937,4931,mageshn,2018-05-14T21:47:39Z,there was a debate about moving the required entity class from runtime to api but we decided not to. hence we see this copy. the connecthealth class introduced itself is pretty much same as connectorstateinfo. i personally still think that entities can be part of the public api. but i'm fine either ways.,0,0.7810098528862
188110010,4931,mageshn,2018-05-14T21:52:15Z,"it started as newconnectrestextensionplugins and based on earlier pr discussion, we decided to make it generic. may be i missed out generalizing some of the log statements",0,0.9819741249084473
188802909,4931,rhauch,2018-05-16T23:40:05Z,"i'm fine with `versioned`, since this interface defines something that has a version and is not something that can be versioned.",0,0.9684506058692932
188803007,4931,rhauch,2018-05-16T23:40:51Z,nit: rest should be capitalized.,0,0.983208954334259
188803095,4931,rhauch,2018-05-16T23:41:21Z,"""plugin class loading mechanism"" rather than ""class loader's"".",0,0.9890572428703308
188803391,4931,rhauch,2018-05-16T23:43:26Z,"""implementations should be packaged in a jar that includes the file { meta-inf/services/org.apache.kafka.connect.rest.extension.connectrestextension} that contains the fully-qualified name of the implementation class."" also, ` ` tags should always start on new lines, and for readability should probably be preceded by a blank line.",0,0.9886776804924011
188803420,4931,rhauch,2018-05-16T23:43:39Z,+1 for fixing this.,0,0.7013278007507324
189633739,4931,rhauch,2018-05-21T16:00:00Z,javadoc for this interface. a simple sentence would suffice.,0,0.9831835031509399
189633925,4931,rhauch,2018-05-21T16:00:34Z,javadoc ... a simple sentence would suffice.,0,0.985162079334259
189634016,4931,rhauch,2018-05-21T16:00:54Z,javadoc ... a simple sentence would suffice.,0,0.985162079334259
189634067,4931,rhauch,2018-05-21T16:01:02Z,javadoc ... a simple sentence would suffice.,0,0.985162079334259
189634263,4931,rhauch,2018-05-21T16:01:43Z,javadoc ... a simple sentence would suffice.,0,0.985162079334259
189634410,4931,rhauch,2018-05-21T16:02:07Z,"""rest"" is an acronym and should be capitalized.",0,0.9802733659744263
189634561,4931,rhauch,2018-05-21T16:02:37Z,paragraphs should begin on a new line and have a blank line before them in javadoc.,0,0.9866614937782288
189634630,4931,rhauch,2018-05-21T16:02:48Z,paragraphs should begin on a new line and have a blank line before them in javadoc.,0,0.9866614937782288
189634810,4931,rhauch,2018-05-21T16:03:21Z,"""connect"" is a name and should be capitalized.",0,0.9845749139785767
189635129,4931,rhauch,2018-05-21T16:04:30Z,"use quotes or `{ }` around ""kafkaconnect"" to highlight the importance of that literal.",0,0.9838870167732239
189635519,4931,rhauch,2018-05-21T16:05:38Z,"how about also mentioned that it must be configured in the worker configuration, and providing an example configuration fragment that shows how to use this sample extension.",0,0.9875500798225403
189636428,4931,rhauch,2018-05-21T16:08:40Z,"should this mention that this is a sample implementation? how does it work, and where does it get the credentials? seems like this needs a lot more context to be useful as an example.",0,0.9530219435691833
189637087,4931,rhauch,2018-05-21T16:10:39Z,how about `to connect's rest api` rather than `to connect rest`?,0,0.9885042309761047
189637462,4931,rhauch,2018-05-21T16:11:43Z,nit: this can be defined on one line.,0,0.9872133135795593
189637562,4931,rhauch,2018-05-21T16:12:03Z,nit: this can be one line.,0,0.9860175251960754
189637966,4931,rhauch,2018-05-21T16:13:27Z,"nit: would using `state` rather than `taskstatefromherder` make this a bit more readable, such that the instantiation of the `taskstate` could be done on a single line?",0,0.9877691864967346
189639210,4931,rhauch,2018-05-21T16:17:52Z,why do we need this conditional logic? is it ever called with a classloader that is not a pluginclassloader?,0,0.9797778129577637
189640314,4931,rhauch,2018-05-21T16:22:00Z,"this should be usable by plugin types other than just connect rest extensions, so i think the non-specific name is important. if we want a specific name for the connect rest extension, then we should add that as the public method and keep this as a protected/private method.",0,0.9866337776184082
189640748,4931,rhauch,2018-05-21T16:23:33Z,seems like this boolean check is backwards. shouldn't this method return true if the component is _not_ already registered?,0,0.9642547965049744
189640850,4931,rhauch,2018-05-21T16:23:59Z,"same incorrect boolean logic here, too.",-1,0.5346518754959106
189641853,4931,rhauch,2018-05-21T16:27:28Z,"is this the only rest extension that we'll have in this project? if so, should we have a better and more descriptive name for the project rather than simple `rest-extension`?",0,0.9833493232727051
189966266,4931,rhauch,2018-05-22T16:22:13Z,"perhaps ""connect requires some components implement this interface to define a version string.""",0,0.9866922497749329
189966612,4931,rhauch,2018-05-22T16:23:17Z,"again, capitalize ""connect"" as a name rather than ""connect"" as a verb.",0,0.976500928401947
189966880,4931,rhauch,2018-05-22T16:24:09Z,need javadoc here. what does the string value represent? can this method ever return null or an empty string?,0,0.9896450042724609
189966913,4931,rhauch,2018-05-22T16:24:14Z,need javadoc here. what does the string value represent? can this method ever return null or an empty string?,0,0.9896450042724609
189966983,4931,rhauch,2018-05-22T16:24:29Z,need javadoc here. what does the string value represent?,0,0.9887324571609497
189967160,4931,rhauch,2018-05-22T16:25:04Z,"are there any requirements about whether these can be null or empty? what is `trace`? need javadoc since this is part of the api, and also verify the arguments match the requirements.",0,0.9896904230117798
189967589,4931,rhauch,2018-05-22T16:26:22Z,"""connector"" is not a name and should not be capitalized.",0,0.9464067816734314
189967877,4931,rhauch,2018-05-22T16:27:17Z,"grammar: it's more correct to say ""get the names of the connectors currently running..."", since the names are not running in the cluster. :-) also, do the connectors need to be running for them to be included here? what if they died and were not restarted? i suggest the statement refer to connectors **_deployed_** in this cluster.",1,0.7199282050132751
189968731,4931,rhauch,2018-05-22T16:30:01Z,need javadoc here to define which parameters can be null and/or empty.,0,0.984563410282135
189968885,4931,rhauch,2018-05-22T16:30:28Z,"add javadoc, since this is part of the public api.",0,0.9892653226852417
189968977,4931,rhauch,2018-05-22T16:30:48Z,"add javadoc, since this is part of the public api. which of the parameters are allowed to be null and/or empty?",0,0.9897239208221436
189969183,4931,rhauch,2018-05-22T16:31:28Z,"nit: remove the unnecessary ""the"" on this line.",0,0.9805631637573242
189969774,4931,rhauch,2018-05-22T16:33:18Z,"nit: i'd suggest ""the implementation class must be packaged in a jar that includes the { ...} file containing the fully qualified name of the implementation class.""",0,0.9860512018203735
189970477,4931,rhauch,2018-05-22T16:35:32Z,"suggest: ""when connect's worker configuration uses the rest extension implementation class, upon startup connect will instantiate the implementation and pass the configuration to the instance via { configurable#configure(map)}.""",0,0.9872682690620422
189970682,4931,rhauch,2018-05-22T16:36:13Z,"use ""the connect framework ..."" instead.",0,0.9748305678367615
189970767,4931,rhauch,2018-05-22T16:36:35Z,"nit: singular ""implementation""",0,0.9824831485748291
189971395,4931,rhauch,2018-05-22T16:38:35Z,"rather than use ` ` tags, rst files use two sequential back quotes before and after code-like text.",0,0.9870275259017944
189971743,4931,rhauch,2018-05-22T16:39:36Z,"grammar: ""... allows you to inject into connect's rest api user defined resources like filters.""",0,0.9237250685691833
189971830,4931,rhauch,2018-05-22T16:39:53Z,replace the ` ` tags.,0,0.9832327961921692
190068865,4931,mageshn,2018-05-22T22:09:26Z,other places like metrics reporter use the same convention. tried to be consistent with it.,0,0.9764542579650879
190069307,4931,mageshn,2018-05-22T22:11:13Z,"atm, this is the only implementation. i named it just like other components for transforms. i'm not too particular about the module name being generic. i could call it connect-basic-auth-extension",0,0.9045778512954712
190759541,4931,rhauch,2018-05-24T23:42:08Z,"yeah, maybe `basic-auth-extension` (e.g., to go with `file`, etc.). i'm just concerned that `rest-extension` is pretty generic and actually sounds like it's the api, not a reference impl.",-1,0.8933301568031311
190793197,4931,mageshn,2018-05-25T05:18:35Z,other places like metrics reporter class use the same convention of using <code> tried to be consistent with the same.,0,0.986316978931427
190793246,4931,mageshn,2018-05-25T05:19:06Z,this is fixed,0,0.981425404548645
190955448,4931,mageshn,2018-05-25T17:06:13Z,"the method is now generic enough to instantiate any plugin. irrespective, i think registering resources belongs in restserver.",0,0.9829219579696655
190956787,4931,rhauch,2018-05-25T17:12:32Z,ack.,0,0.7720441818237305
190958825,4931,rhauch,2018-05-25T17:20:37Z,"don't we want these classes to be in a different package than `org.apache.kafka.connect.rest.extension`, since that's the package that exists in the api? the file source and sink, for example, are in `org.apache.kafka.connect.file`. i'd recommend something like `org.apache.kafka.connect.extension.auth.jaas`.",0,0.9794968366622925
190959257,4931,rhauch,2018-05-25T17:22:11Z,"also, since this is a reference implementation, perhaps we could have some javadoc that explains at a high level how this implements the `connectrestextension`, how it works (briefly), and how it is packaged.",0,0.983916699886322
190959594,4931,rhauch,2018-05-25T17:23:23Z,"make sure this package name is changed accordingly. also, this is a good reason why we want a different package name, since this looks like the extension implementation is built-in to the connect framework.",0,0.9379208087921143
190959834,4931,rhauch,2018-05-25T17:24:18Z,"are we okay with people using this in production? if not, we need to say so. if we're okay with it, we should probably outline a few caveats or important things to keep in mind when evaluating whether to use it. for example, passwords will be stored in cleartext in the property file. this alone suggests that maybe we should call it out as a sample reference implementation that may not be suitable for production use.",0,0.9801245927810669
190960784,4931,rhauch,2018-05-25T17:28:23Z,"i think we should highlight the characteristics that users should be aware of, such as that passwords are stored in plaintext in the referenced file, and that because of this it is likely not recommended for production but is instead part of a sample implementation of the connect rest extension and should not be used in production. perhaps the same paragraph with bold `note:` in all of the files in this package.",0,0.985928475856781
190961652,4931,rhauch,2018-05-25T17:31:58Z,can this be private?,0,0.9878947138786316
190961740,4931,rhauch,2018-05-25T17:32:19Z,nit: blank line at the beginning of the method is unnecessary.,0,0.9103023409843445
190962339,4931,rhauch,2018-05-25T17:34:48Z,nit: `into` rather than `in to`.,0,0.974867045879364
190962903,4931,mageshn,2018-05-25T17:36:55Z,ack,0,0.9720376133918762
190996405,4931,rhauch,2018-05-25T19:59:24Z,ping.,0,0.9806817173957825
190996589,4931,rhauch,2018-05-25T20:00:18Z,maybe just `rest_extension`?,0,0.9879756569862366
190996744,4931,rhauch,2018-05-25T20:01:10Z,always need a sentence in javadoc.,0,0.9866809844970703
190996769,4931,rhauch,2018-05-25T20:01:16Z,nit: add a period.,0,0.9844210147857666
190997074,4931,rhauch,2018-05-25T20:02:51Z,"rather than describe the return in the description (2nd sentence), i'd suggest putting it in the param: state of the connector or task; never null or empty it's more concise, and it puts the information where people will look for it.",0,0.9850345253944397
190997151,4931,rhauch,2018-05-25T20:03:12Z,"nit: ""id"" or ""identifier"" (or even ""id""), but not ""id"".",0,0.9809682965278625
190997266,4931,rhauch,2018-05-25T20:03:48Z,"again, remove the 2nd sentence in the description and put it in the param: the worker id; never null or empty",0,0.988235354423523
190997323,4931,rhauch,2018-05-25T20:04:07Z,"again, remove the 2nd sentence in the description and put it in the param: the trace message; may be null or empty",0,0.9883679747581482
190997381,4931,rhauch,2018-05-25T20:04:24Z,"how about `tracemessage`, rather than `trace`?",0,0.9877272844314575
190997661,4931,rhauch,2018-05-25T20:05:49Z,for consistency: * state - the status of connector or task; may not be null or empty * workerid - the workerid associated with the connector or the task; may not be null or empty * tracemsg - any error trace message associated with the connector or the task; may be null or empty,0,0.9888907670974731
190997897,4931,rhauch,2018-05-25T20:06:53Z,how about: the version string; may not be null or empty,0,0.9873780608177185
190998205,4931,rhauch,2018-05-25T20:08:09Z,"`isempty()` just checks whether the length is 0, so a string with 1+ whitespace will be allowed. instead, use: assert state != null && !state.trim().isempty();",0,0.9872428178787231
190998580,4931,rhauch,2018-05-25T20:09:18Z,nit: period.,0,0.974609375
190998660,4931,rhauch,2018-05-25T20:09:41Z,this should be a sentence.,0,0.9748672842979431
190998760,4931,rhauch,2018-05-25T20:10:11Z,"the connector name can this be null or empty? if not, then should check in the constructor. and if the framework calls the constructor, asserts are fine; if users can call it, then `objects.requirenotnull` is better.",0,0.9797559976577759
190999238,4931,rhauch,2018-05-25T20:12:32Z,"same here. sentence, and specify whether it can be null",0,0.9876197576522827
190999527,4931,rhauch,2018-05-25T20:13:58Z,"no need to specify the type; it can only get lost and it's already in the signature. again, full sentences are needed in javadoc, and the state for each task id; never null",0,0.9863751530647278
190999572,4931,rhauch,2018-05-25T20:14:09Z,check the input parameters here.,0,0.9824120402336121
190999619,4931,rhauch,2018-05-25T20:14:23Z,same here.,0,0.9813250303268433
190999676,4931,rhauch,2018-05-25T20:14:45Z,need a sentence in javadoc.,0,0.9827271103858948
190999795,4931,rhauch,2018-05-25T20:15:23Z,"nit: it's sufficient to just say ""describes the status, worker id, and any errors associated with a connector."" no need to include a link to this class.",0,0.9839260578155518
190999885,4931,rhauch,2018-05-25T20:15:51Z,"this is public api, so we need javadoc for this class and the enumeration literals.",0,0.9880285263061523
191000029,4931,rhauch,2018-05-25T20:16:37Z,"""describes the state, ids, and any errors of a connector task."" no link, no capitalized ""connector"", and consistent use of ""id"".",0,0.9859566688537598
191000240,4931,rhauch,2018-05-25T20:17:44Z,"for consistency, use `; may not be null or empty` in parameter descriptions. also, no `-` after the parameter name since javadoc already handles this. fix these everywhere.",0,0.9891340136528015
191000313,4931,rhauch,2018-05-25T20:18:12Z,"full sentence, and ` the task id`",0,0.9862474799156189
191000490,4931,rhauch,2018-05-25T20:19:03Z,"nit: multiple `by` in this sentence, so change this one to `using`.",0,0.987440824508667
191001129,4931,rhauch,2018-05-25T20:21:54Z,perhaps the following helps better explain all of the packaging requirements: [code block],0,0.9850784540176392
191002545,4931,rhauch,2018-05-25T20:29:16Z,nit: [code block],0,0.9873168468475342
191002688,4931,rhauch,2018-05-25T20:30:02Z,the jax-rs { javax.ws.rs.core.configurable}; never null,0,0.9882388114929199
191002712,4931,rhauch,2018-05-25T20:30:12Z,missing a period.,0,0.567818284034729
191003024,4931,rhauch,2018-05-25T20:31:52Z,change to: provides the cluster state and health information about the connectors and tasks. the cluster state information; never null,0,0.9877546429634094
191003130,4931,rhauch,2018-05-25T20:32:27Z,"nit: begin without a link to this class: ""a sample rest extension that authenticates incoming ...""",0,0.9882615208625793
191013751,4931,mageshn,2018-05-25T21:30:44Z,i don't think we can guarantee or enforce the version,0,0.9271019697189331
191061506,4931,ewencp,2018-05-27T00:29:20Z,very minor nit: easier to keep track of these if we group common package prefixes together,0,0.9759617447853088
191061533,4931,ewencp,2018-05-27T00:31:38Z,isn't this the same subpackage we're defining rules for? self-referential imports shouldn't need to be defined here -- imports from the same package shouldn't need special allowance.,0,0.9821583032608032
191061585,4931,ewencp,2018-05-27T00:35:26Z,"this doesn't seem like a good thing to enable -- it's the opposite dependency we would normally want to have here. i see the only use is in a javadoc, can we adjust that so the import is not required? for example, use the fully qualified class name instead of just the class name so we don't rely on the import?",0,0.8970069289207458
191062417,4931,ewencp,2018-05-27T01:50:27Z,"we don't enforce this today, though you could reasonable argue this is a ""bug"" that we don't validate them today. i think documenting this in the interface as an expectation would be reasonable. whether we enforce it or not on various `versioned` implementations might vary -- we could, for example, enforce proper versioning from day 1 of these new rest extensions, whereas for, e.g., connectors, we might want to think about adding validation that produces warnings if they return `null` or empty values, then eventually actually enforcing it (say, with ak 3.0).",0,0.9756032228469849
191062502,4931,ewencp,2018-05-27T01:54:20Z,"do we want these to be asserts or check conditions and throw, e.g., `illegalargumentexception` with a more useful message?",0,0.9865273833274841
191062585,4931,ewencp,2018-05-27T02:00:04Z,"`connectorstate` is the wrong capitalization for a javadoc, i'd also simplify to just ""about the connector and its tasks"", rest of the api docs can give further details.",0,0.9611706137657166
191062771,4931,ewencp,2018-05-27T02:14:01Z,"is this actually what we want? seems like if you wanted to keep a previous `taskstate` and check whether it had changed, this is going to be confusing behavior.",-1,0.8747462034225464
191063008,4931,ewencp,2018-05-27T02:36:32Z,"i'm noticing now that the context object exposes the cluster state, but doesn't explain the semantics for the returned state. since the extension only gets a hook into the context on the register() call, that means this must be returning dynamic state. it seems like you don't necessarily get a consistent snapshot of the state when you call this -- you get a `connectclusterstate`(`impl`) object back, but that object can mutate out from under you since it's backed just by the dynamic herder state. this is actually problematic and kind of difficult for plugin implementations since the calls to get the list of connectors and to get their state are separate and non-atomic. which means there are chances of hitting `notfound` exceptions and maybe others, which aren't clear from the interfaces. is there any reason not to make collection of the cluster state atomic and take a snapshot instead? that has way more intuitive semantics. if we don't do that, i think we need to clearly document the semantics in the javadocs.",-1,0.7035683989524841
191063158,4931,ewencp,2018-05-27T02:52:03Z,"nit: typo ""teh""",0,0.9409974217414856
191063275,4931,ewencp,2018-05-27T03:03:30Z,"seems redundant, we could just refactor out the part up to `getpassword` to a statement before this.",0,0.9569001793861389
191063281,4931,ewencp,2018-05-27T03:04:26Z,is `credentialproperties` guaranteed non-null? it doesn't really seem like it given the logic in `initialize`.,0,0.9361124038696289
191063473,4931,ewencp,2018-05-27T03:19:11Z,"this is global, static state. i think we should be careful to clean this up after the test.",0,0.965005099773407
191063510,4931,ewencp,2018-05-27T03:23:08Z,"yeah, we just don't have a good way to handle multiple formats today. we'll want to adjust to rst-style if we implement kafka-2967",-1,0.5519663095474243
191063925,4931,ewencp,2018-05-27T03:59:08Z,"nit: typo: ""no re-registering"" -> ""not re-registering""",0,0.961758553981781
191063955,4931,ewencp,2018-05-27T04:01:12Z,"doesn't matter much, but seems weird to use `boolean.true` and `boolean.false` instead of just `true`/`false` literals here",-1,0.8841675519943237
191064077,4931,ewencp,2018-05-27T04:10:34Z,"should these calls be protected by exception handlers for each since they're user pluggable? i.e. so if one fails, we don't just skip closing the rest (and the jetty server)?",0,0.9875912666320801
191292103,4931,mageshn,2018-05-29T02:23:49Z,good point. i will add documentation to mention that these are not atomic and could potentially get an exception.,1,0.9596912860870361
191292150,4931,mageshn,2018-05-29T02:24:25Z,good catch. throwing an exception now if the file can't be loaded.,1,0.9714829921722412
191293267,4931,mageshn,2018-05-29T02:37:15Z,added some docs on connectclusterstate. let me know,0,0.9747576117515564
191598513,4931,rhauch,2018-05-29T22:52:14Z,"i also think that it's useful to specify the expectations on an interface like this that's intended to be implemented by others. it provides useful guidance for implementers, whether or not we enforce it now.",0,0.9638249278068542
191599600,4931,rhauch,2018-05-29T22:58:18Z,"with the changes to externalize secrets in [a link], the existing connectclusterstate is going to output the transformed configurations, which may include secrets. do we want to do that? or, would we prefer to get the pre-transformed configurations?",0,0.9866347312927246
191599981,4931,rhauch,2018-05-29T23:00:23Z,nit: javadoc for a class shouldn't really have links to that same class. readers will think that it's something different.,0,0.8568257689476013
191600425,4931,rhauch,2018-05-29T23:02:33Z,"""the connect framework"", not ""connect framework"". check this elsewhere, since it seems like i've requested this change multiple times already and the usage in this commit still is not consistent. :-)",1,0.9447011351585388
191600823,4931,mageshn,2018-05-29T23:04:35Z,"iiuc, kip-297 is for connector configurations and we are only dealing with those here atm.",0,0.9868698716163635
191601149,4931,mageshn,2018-05-29T23:06:29Z,the latest commit already specifies this.,0,0.9868948459625244
191601292,4931,rhauch,2018-05-29T23:07:18Z,"""... current configuration, which may change over time.""",0,0.970125138759613
191601381,4931,rhauch,2018-05-29T23:07:51Z,"the method description in the javadoc says that a `notfoundexception` will be thrown if no connector with the supplied name exists when this method is called, but the `` description says that the method can return null. we should decide: is it better to throw an exception or return null. if we throw an exception, we should add ` notfoundexception if a connector with the supplied name does not exist` to fully document the behavior. (in general, the kafka javadocs are relatively poor on this front.)",0,0.9695911407470703
191602202,4931,rhauch,2018-05-29T23:12:30Z,missing a period to terminate the sentence.,0,0.799072265625
191602750,4931,rhauch,2018-05-29T23:15:29Z,capitalize the first word in the sentence.,0,0.9799545407295227
191602778,4931,rhauch,2018-05-29T23:15:39Z,"capitalize the first word in the sentence. (check for other places, too.)",0,0.9840071797370911
191602947,4931,rhauch,2018-05-29T23:16:39Z,"it'd be better to call the parameter `tracemessage` and then use ""any error message..."" in the description.",0,0.9881221652030945
191603062,4931,rhauch,2018-05-29T23:17:18Z,nit: missing the period to terminate the sentence.,0,0.8699415326118469
191603211,4931,rhauch,2018-05-29T23:18:06Z,nit: should be `class(es)` to match line 33.,0,0.9875002503395081
191603371,4931,rhauch,2018-05-29T23:19:10Z,"nit: ""implementations"" (plural)",0,0.9844902157783508
191603895,4931,rhauch,2018-05-29T23:22:16Z,"we shouldn't use ` `; instead, use a ` ` section around the lines.",0,0.9863095283508301
191604301,4931,rhauch,2018-05-29T23:24:44Z,"these should be ` ` rather than ` `. the latter is more for phrases, not blocks, and loses all indentation and line breaks within a block of code. then you can get rid of the ` ` tags.",0,0.9879854321479797
191605111,4931,rhauch,2018-05-29T23:29:21Z,"good point, but it could be clearer. this implementation can be used in production, but the `propertyfileloginmodule` that also ships with this reference implementation should not be used in production.",1,0.5818702578544617
191605490,4931,rhauch,2018-05-29T23:31:43Z,"should we log a warning in an `else` block for this `if` block? if somebody does not specify the filename, this login module will always fail authentication, right?",0,0.9813306927680969
191605741,4931,rhauch,2018-05-29T23:33:21Z,"for 2.0, should we log this as an error rather than throw an exception? iiuc, this is what you suggested, .",0,0.9822831749916077
191605853,4931,rhauch,2018-05-29T23:34:04Z,nit: why `boolean` rather than `boolean`?,0,0.9824851155281067
191606424,4931,rhauch,2018-05-29T23:37:49Z,"sorry, i now realize that this connectclusterstate is the interface in the api, whereas kip-297 is changing the implementation in the runtime. the api interface doesn't expose the configuration, so that's a good thing.",-1,0.9866042137145996
191618735,4931,mageshn,2018-05-30T01:14:57Z,my understanding was that we enforce it strictly for restextension in 2.0. older implementations can be enforced in 3.0,0,0.9788556694984436
191637634,4931,ewencp,2018-05-30T04:09:22Z,"i think there's confusion in the discussion. i think 's point is that, since we have not enforced correctness in returned values thus far, we should be liberal in what we accept for now. so if they return `null` or an empty value, we should log an error, but not throw an exception that would kill the connector. on 3.0 or some later version, we'd do as this code currently does and throw an exception since we will have given connectors a reasonable grace period to fix their behavior given that we didn't previously enforce the behavior.",0,0.9422631859779358
191638435,4931,ewencp,2018-05-30T04:17:50Z,"i actually think the question is still relevant -- `connectclusterstate` used to be purely immutable and now we'll be exposing an interface that changes based on when you call it. i think it doesn't matter much here, but it is mainly relevant because the docs on `connectclusterstate` aren't really accurate anymore since the contents can change over time. but it's also a weird mix of mutability -- the set of connectors & tasks won't change in the `connectclusterstate` object, you would need to re-callthis method to get updated cluster state. however, the actual values returned for a connector/task config *could* change due to kip-297 replacements.",-1,0.935694694519043
249744367,6177,stanislavkozlovski,2019-01-22T11:38:07Z,should we mention that this configuration enabled a static membership and its lack would mean dynamic membership?,0,0.9863497614860535
249745157,6177,stanislavkozlovski,2019-01-22T11:40:41Z,is there any reason to not maintain backward compatibility here? why not have dynamic members continue to rely on `leavegrouponclose`? (i lack the context of why this setting exists in the first place),0,0.9323325157165527
249749343,6177,stanislavkozlovski,2019-01-22T11:54:37Z,"_this is me thinking out loud. for the record i don't believe we should apply my suggestion in this pr as it would over-complicate things_ i'm wondering whether it will be worth it to think about cleaning up this bloated constructor, it takes almost 20 parameters with no defaults. the book [a link] makes a good point on how bundling up related parameters into separate classes results in code that is more domain-oriented (reads better) and is easier to mock/construct. ([a link] we have done something similar in `groupcoordinator` with its [a link] regardless, i was just interest in hearing people's thoughts on this matter",0,0.5158396363258362
249749782,6177,stanislavkozlovski,2019-01-22T11:55:54Z,should we maintain the present tense? `member.id does not match the record on coordinator`,0,0.9692471027374268
249856731,6177,abbccdda,2019-01-22T16:25:04Z,"yea, good idea! let me update both the doc and kip",1,0.9902356266975403
249862352,6177,abbccdda,2019-01-22T16:37:27Z,"`leavegrouponclose` was set through internal config `internal.leave.group.on.close` which is by default set to true for normal consumer/connect, but set to false for streams. checking groupinstanceid could perfectly remove this internal config without backward compatibility concern (since the config is not exposed)",0,0.9883105754852295
249864434,6177,abbccdda,2019-01-22T16:42:27Z,"hey stanis, i'm also in favor of simplifying the constructor logic here. i will get a jira to resolve this issue once this diff is landed.",0,0.9151687622070312
249864597,6177,abbccdda,2019-01-22T16:42:51Z,done!,0,0.514024555683136
250660764,6177,stanislavkozlovski,2019-01-24T15:47:08Z,could we add a javadoc explaining when we expect to receive this exception and what could cause it? my understanding is that a consumer that was part of the group used a `group.instance.id-member.id` pair and later that pair got updated with a new `member.id` by another consumer? that is what i understand as a possibility from the explanation in the kip:,0,0.9775388836860657
250662548,6177,stanislavkozlovski,2019-01-24T15:50:48Z,could we update the kip as it currently says: [code block] which is not true as we can raise this for joingroup requests as well,0,0.989081621170044
250664415,6177,stanislavkozlovski,2019-01-24T15:54:42Z,nit: should we call this empty_group_instance_id? `unknown` implies that it will be known in some time (like with member.id) but in this case it is intentionally set to none,0,0.9843264222145081
250672375,6177,stanislavkozlovski,2019-01-24T16:11:05Z,nit: could we append the comment above with `if member id required (dynamic membership)` just to make it even more clearer than static members won't be pending members (i know this is noted in `dojoingroup`,0,0.9879634380340576
250672737,6177,stanislavkozlovski,2019-01-24T16:11:59Z,nit: space between comma and `clientid`. i guess that comma could be on the line above,0,0.9875875115394592
250672974,6177,stanislavkozlovski,2019-01-24T16:12:33Z,nit: `informing member` - `inform the member to`,0,0.9845994114875793
250673259,6177,stanislavkozlovski,2019-01-24T16:13:09Z,nit: `should inform` - `inform duplicate instance...` this keeps it consistent with the tense in the other comments,0,0.9776653051376343
250674281,6177,stanislavkozlovski,2019-01-24T16:15:17Z,nit: i think that it will be clearer if we define this variable inside `dojoingroup()`,0,0.9814440011978149
250678345,6177,stanislavkozlovski,2019-01-24T16:24:41Z,nit: `a un-recognized` - `an unrecognized`,0,0.970382034778595
250678917,6177,stanislavkozlovski,2019-01-24T16:26:00Z,good call with splitting this logic into a method! :thumbs_up:,1,0.9864793419837952
250685315,6177,stanislavkozlovski,2019-01-24T16:41:01Z,should we also test `member.isstaticmember`?,0,0.9869884252548218
250686301,6177,stanislavkozlovski,2019-01-24T16:43:27Z,"we don't have `group.getstaticmemberid` in tests anywhere, i think this is a good spot to assert it works as well",1,0.5380036234855652
250688550,6177,stanislavkozlovski,2019-01-24T16:48:38Z,"not sure of the implications here, should we somehow work on removing the static member when the same `memberid` re-joins as a dynamic member? i guess it might not hurt, it will eventually get removed when the member leaves or its heartbeat fails, but we will continue to lock that `group.instance.id` with the `member.id` so new joins from static members with that group.instaince.id won't work. in other words, if a consumer becomes a static member and later re-joins as a dynamic, that `group.instance.id` is still taken. am i correct? that might not be unwanted behavior though",0,0.9404053092002869
250692730,6177,stanislavkozlovski,2019-01-24T16:58:26Z,should we add a test which exercises this code path? i think it's critical for the kip that this works,0,0.9694529175758362
250693889,6177,stanislavkozlovski,2019-01-24T17:01:14Z,"if it's not too much work, maybe we could add a test to ensure `member_id_mismatch` is fatal?",0,0.9677484631538391
250775259,6177,abbccdda,2019-01-24T21:02:21Z,"hey stanis, once i started the implementation, i realized that it's more clear to use the current member.id for static members instead of generating a new one, since we need member.id to track heartbeat & stuffs. i will update the kip to reflect this change. as for the `memberidmismatchexception`, i put the explanation within errors.java as error message to feedback end user.",0,0.938998281955719
250776499,6177,abbccdda,2019-01-24T21:06:21Z,good catch! will address this.,1,0.9878478050231934
250780087,6177,abbccdda,2019-01-24T21:17:15Z,+1,0,0.696722686290741
250780539,6177,abbccdda,2019-01-24T21:18:32Z,"yea of course, will try to see how to make that happen",0,0.9093244671821594
250781826,6177,abbccdda,2019-01-24T21:22:22Z,it should be trivial to test.,0,0.713683545589447
250782168,6177,abbccdda,2019-01-24T21:23:22Z,lol,1,0.9700573682785034
251090933,6177,abbccdda,2019-01-25T18:39:32Z,sounds good!,1,0.984022855758667
251091132,6177,abbccdda,2019-01-25T18:40:01Z,make sense,0,0.9631345272064209
251092116,6177,abbccdda,2019-01-25T18:41:30Z,+1,0,0.696722686290741
251093276,6177,abbccdda,2019-01-25T18:45:00Z,"hey stanis, the condition you proposed here is not possible within the current setup. membership type transformation has to go through service restart, which will inevitably reset the member.id. so there is no way we see a dynamic member joining with its member.id points to a known static member. however this is a vaild concern, which i think by enforcing an assertion would be safer!",0,0.7587700486183167
251669585,6177,Ishiihara,2019-01-29T02:16:43Z,do we want to use assert here? it will crash the broker if this happens.,0,0.9744874238967896
251683035,6177,Ishiihara,2019-01-29T03:46:22Z,"can you also add comments to the case when the member doe not have a valid protocol, why do we want to force rebalance? are we handling the case of rolling upgrades?",0,0.9849862456321716
251684242,6177,Ishiihara,2019-01-29T03:55:07Z,"as a disclaimer, i have forgotten the kafka coding style. do we use assert in code?",0,0.9063885807991028
251685753,6177,Ishiihara,2019-01-29T04:07:32Z,"this should be a fatal exception to the client, right?",0,0.7751117944717407
251686132,6177,Ishiihara,2019-01-29T04:10:02Z,this makes sense. although the name is a bit confusing.,0,0.8718141317367554
251686408,6177,Ishiihara,2019-01-29T04:12:09Z,"this handles consumer restarts, correct? in that case, the member id will be unknown.",0,0.9887246489524841
251936369,6177,abbccdda,2019-01-29T17:27:40Z,the reason to use `assert` is to prevent future implementation from breaking the existing assumption. basically known static member should never be `pending`.,0,0.9854415655136108
251937129,6177,abbccdda,2019-01-29T17:29:40Z,"yes we do have examples using assert, see `oncompletejoin()` in groupcoordinator.scala",0,0.9857962131500244
251937266,6177,abbccdda,2019-01-29T17:29:58Z,yes that's right.,0,0.9659256339073181
251937638,6177,abbccdda,2019-01-29T17:30:57Z,that is correct. in `dounknownjoingroup` we don't have a known member id to process with.,0,0.9841527342796326
251939458,6177,abbccdda,2019-01-29T17:35:28Z,"usually a change of protocol indicates that the group needs to use a different strategy to allocate topic partitions. current logic is to trigger rebalance anyway to find a common agreed strategy for all current members. this diff doesn't change this part of the logic, however this is a good thing to discuss in a separate jira!",1,0.6624777317047119
260423217,6177,hachikuji,2019-02-26T18:25:01Z,"rather than adding more exceptions, should we try to refactor the code?",0,0.9865154027938843
260426269,6177,hachikuji,2019-02-26T18:32:40Z,"i am wondering if `fenced_member_id` would be a clearer indication of the likely problem. in any case, we should try to give the user a helpful exception message.",0,0.9612810015678406
260429304,6177,hachikuji,2019-02-26T18:40:32Z,do we need a new error code for this case? i'm wondering if we could just use unknown_member_id.,0,0.9515126943588257
260432780,6177,hachikuji,2019-02-26T18:48:54Z,nit: a bit more intuitive to put the static member check first. maybe we can also have an `isdynamicmember` or an `isstaticmember` method.,0,0.96485435962677
260437389,6177,hachikuji,2019-02-26T18:59:43Z,"is there a good reason to favor """" over null for indicating that no instance id is provided? i think using null would reduce the chance of providing an invalid value by mistake. in fact, we can reject the use of """" and raise an error. so if a user provides any instance id, it must be valid.",0,0.9803053140640259
260439690,6177,hachikuji,2019-02-26T19:05:19Z,"so clearly the intent is to silently fall back to the old join group logic, which means we become a dynamic member. it may be helpful having a log message indicating that this has happened. one additional note: if the brokers are later upgraded to a version that does support static membership, we don't have any logic to detect it. i think this is probably fine, just worth keeping in mind.",0,0.7082027196884155
260442064,6177,hachikuji,2019-02-26T19:10:47Z,hmm.. i think i missed this addition in the kip. how much effort would it be to pull this change into a separate pr? i think we may need some discussion.,0,0.6204157471656799
260608268,6177,abbccdda,2019-02-27T06:28:52Z,"yes, good suggestion! i got a jira to track this work [a link] will attempt to fix it once this change is merged.",1,0.9878260493278503
260609201,6177,abbccdda,2019-02-27T06:33:25Z,sounds good!,1,0.984022855758667
260611209,6177,abbccdda,2019-02-27T06:44:15Z,maybe unknown instance id is more aligned? it's slightly different comparing with member id unknown.,0,0.9807080626487732
260611350,6177,abbccdda,2019-02-27T06:44:54Z,sounds good.,1,0.9202015399932861
260886942,6177,hachikuji,2019-02-27T18:38:43Z,"our response to this error is to discard our current memberid and rejoin. that seems true regardless whether static or dynamic membership is used, so i thought we may as well make the error consistent. does that make sense?",0,0.9789685010910034
260902762,6177,abbccdda,2019-02-27T19:17:55Z,"it should be ok since the error message clearly states: `the group.instance.id is already in the consumer, however the corresponding member.id is not matching the record on coordinator`",0,0.9820035099983215
260923497,6177,abbccdda,2019-02-27T20:09:39Z,sure,0,0.9371067881584167
260935391,6177,abbccdda,2019-02-27T20:43:08Z,why couldn't we piggy-back the change in this pr? connect could also benefit from using static membership right.,0,0.9808675646781921
261272738,6177,kkonstantine,2019-02-28T16:19:30Z,i agree with this is too significant to be omitted from a kip and we should probably avoid piggybacking such a change in a subtle way in this already big pr. the doc of the config below is indicative that we need to give this more thought. the connect worker is not a consumer and it doesn't use the group membership protocol in the same way. this is even more true with the changes being introduced soon with incremental cooperative rebalancing in connect. the interplay between kip-415 and static membership has not been sufficiently studied yet and therefore i'd suggest not introducing everything at once with the upcoming release.,0,0.8180927038192749
261308442,6177,abbccdda,2019-02-28T17:44:05Z,"sounds great! my original thought was that the change happens on abstract coordinator layer, so consequently we could cover all the subclass use cases (both consumer and connect). i will revert connect related changes.",1,0.989935576915741
261350730,6177,hachikuji,2019-02-28T19:33:17Z,"possibly so, though i am not sure since it does not have local state like streams. in any case, i do not want to see this pr blocked by this discussion, so my thought was to split it out. cc any thoughts about this?",0,0.9399216175079346
261353864,6177,abbccdda,2019-02-28T19:41:27Z,"although we would react the error with same handling logic, i do see the benefit of decoupling error for now, because the error log could better help user triage during consumer incident.",0,0.966497540473938
261403394,6177,hachikuji,2019-02-28T22:05:40Z,apologies for the late comment above. i hadn't refreshed the page and seen the updates.,-1,0.9777252674102783
261448929,6177,abbccdda,2019-03-01T01:09:11Z,it's fine :),1,0.9860475063323975
261759212,6177,hachikuji,2019-03-01T21:11:35Z,"hmm.. the unknown_member_id error is unambiguous in either case. it means that the coordinator isn't aware of the memberid. what debugging benefit is there in having another error code? the reason i'm resisting a little bit is that every error code adds more complexity to the protocol, so we should be sure it's necessary. here is the reason i find it confusing. with a provided instance id, there are two join cases: 1) joingroup(instanceid=""foo"", memberid=""""): the consumer has no memberid and needs to be assigned one. 2) joingroup(instanceid=""foo"", memberid=""xyz""): the consumer has a memberid and expects it to be valid. the group_instance_id_not_found would only make sense if it was a valid error in both cases. but it only applies to the second case. so my suggestion is that we view the second case as having a missing memberid. then the behavior is consistent for static and dynamic members.",0,0.5931679010391235
261792206,6177,hachikuji,2019-03-01T23:41:22Z,i think it would be clearer if we represented this as `option[string]`.,0,0.9870395064353943
261792477,6177,hachikuji,2019-03-01T23:42:56Z,we generally frown on assertions. it is usually better to raise an exception with a clear message.,0,0.8139095902442932
261793705,6177,hachikuji,2019-03-01T23:50:50Z,hmm.. i thought the proposal called for generation of a new memberid when a static consumer is restarted. the purpose is to fence the old static member. how do we avoid two static members from being active at the same time? perhaps i'm missing something?,0,0.9390654563903809
262186803,6177,abbccdda,2019-03-04T18:31:48Z,"i see your point jason, make sense here. the logic is the since `group_instance_id_not_found` is not covering the whole cases (like when member id is unknown), we could just bypass this check.",0,0.9817032217979431
262201770,6177,abbccdda,2019-03-04T19:12:33Z,"good catch! we have slightly diverged from the original proposal, so that we no longer kick off rebalance when static member rejoins with unknown member id. thus the generation could not be used to fence against duplicate static members. will address this problem by replacing with a new member id.",1,0.9849429130554199
262203003,6177,abbccdda,2019-03-04T19:16:05Z,"could you share more details? the reason for using assertion is to avoid creating invalid state from the code change stage. for example, we have [code block] and [code block] it would be great if you shed light on the trade-offs on these cases, thank you!",1,0.9653673768043518
262788694,6177,abbccdda,2019-03-06T04:32:21Z,i think we handle the null case when building the join group request struct?,0,0.9884204864501953
268418696,6177,abbccdda,2019-03-24T05:18:08Z,could you give me some guidance on this? thank you!,1,0.971949577331543
268419130,6177,stanislavkozlovski,2019-03-24T05:44:40Z,"- judging by `groupmetadata#replace()`, the current behavior is to generate a new member id and return it, right? what happens if a misconfigured consumer joins with an existing, duplicate `consumer.instance.id`? it essentially kicks out the old consumer using it (by invalidating its member.id)? does the old consumer try to rejoin with its group.instance.id afterwards? we could get into a bad loop if that is the case",0,0.8733197450637817
268446363,6177,abbccdda,2019-03-24T18:33:39Z,"that’s a very good question. previously my thought was to use conflict member.id to shut down duplicate consumer instances. however, this probably won’t work because upon receiving unknown_member_id exception in either `syncgroup, heartbeat, offsetcommit` requests will immediately reset the generation info which includes the member.id. one approach i could think of is to restrict the caller of `resetgeneration` on client side to only joingroup logic, which means for any other types of requests after receiving unknown_member_id will be rejoining the group with their current generation info (the conflicting member.id). this should be able to help us detect the id collision and shut down duplicate member with member_id_mismatch exception. thoughts?",0,0.6089327931404114
268484117,6177,stanislavkozlovski,2019-03-25T04:13:37Z,"i don't understand, who would receive the unknown_member_id? if consumer a has `member.id=1, instance.id=one` and consumer b joins with `member.id=2, instance.id=one`, wouldn't a receive member_id_mismatch and shut down?",0,0.9647675156593323
268491234,6177,abbccdda,2019-03-25T05:16:58Z,"this won't happen automatically. the flow is like: 1. consumer a with `member.id=1, instance.id=one` is working under stable group. the static member metadata map contains kv entry `one=1`. 2. consumer b starts up, joining with same `instance.id=one` and `member.id=unknown` 3. consumer b enters `dounknownjoingroup` block and successfully gets identity `member.id=2`. the static member metadata map now updates to `one=2` 4. consumer a gets fenced by either `syncgroup, heartbeat, offsetcommit` which informs a with `unknown_member_id` error, which will trigger `resetgeneration()` on client side abstractcoordinator. 5. now consumer a rejoins with `instance.id=one` and `member.id=unknown`, repeating step 2 like b. so eventually a, b will bounce forever within the loop 2~5 unless one of them refuses to reset their assigned member.id. otherwise `member_id_mismatch` shall never trigger.",0,0.9698152542114258
268790882,6177,stanislavkozlovski,2019-03-25T18:27:48Z,"aha, yeah. we can only raise `member_id_mismatch ` in the `joingroup` request because that's the only request that has the group instance id field, right? as you proposed, i think making the consumer issue a new joingroup with the same member.id would be the better approach. otherwise, we'd probably need to add the new field to all the requests. the old functionality of resetting the generation should continue to work just fine, we'd just be adding an extra hop.",0,0.9410208463668823
270133661,6177,guozhangwang,2019-03-28T18:06:11Z,"not clear if this is right to me: from my understanding ([a link] in case 6, we will still require a member.id and hence would reply the error with `member_id_required` if it is not specified, right?",0,0.924885630607605
270134521,6177,guozhangwang,2019-03-28T18:08:12Z,"nit: can we just do this check inside `dojoingroup`, seems unnecessary to create a boolean at the caller and pass in to `dojoingroup`.",0,0.9888213872909546
270136870,6177,guozhangwang,2019-03-28T18:13:59Z,nit for doc: .. for static members only.,0,0.9754012823104858
270137792,6177,guozhangwang,2019-03-28T18:16:15Z,`new member id will be the same`: what does this mean?,0,0.9782631993293762
270139366,6177,guozhangwang,2019-03-28T18:20:10Z,"following the comment of `kafkaapis`: current logic is that if instance.id is not empty, then `requireknownmemberid` would never be required. is that intentional? i think even with non-empty instance.id, if there's no existing entry in static members, we would still return the created member.id with member_id_required to let the client re-join?",0,0.9882135391235352
270140569,6177,guozhangwang,2019-03-28T18:23:13Z,"yeah to be honest we do use assertions somewhere like mentioned in ongrouploaded; they are used to indicate ""this should never happen, and if it happens, it's a bug"". as a hind-sight we can actually just replace with if-throw-illegal-state-exception across the board so that when it happens indeed, it will crash hard but leave us a meaning stack trace.",0,0.8971781134605408
270140799,6177,guozhangwang,2019-03-28T18:23:53Z,hmm... this is not what i was thinking. maybe we can elaborate a bit more on the kip wiki?,-1,0.7600407600402832
270142218,6177,guozhangwang,2019-03-28T18:26:51Z,what if two consumers joining with the same instance id and member id?,0,0.9820260405540466
270236415,6177,guozhangwang,2019-03-28T23:28:56Z,"i think restricting `resetgeneration` to only joingroup request is not the best approach since we do rely on, e.g. heartbeat response to notify consumers as early as possible. on the other hand, this issue would only raise if users mis configure their `instance.id` to have two running instances to have the same id, such issue is similar to producer client that two instances mistakenly configured with the same `transactional.id` and today it is handled by letting one of them to receive a fatal error (`fenced`) and either handle it themselves or die hard -- the bottom line is, brokers would not need to be responsible for abstracting such human errors from clients. so i'd like to present an alternative proposal: 1) when receiving a join group of null member.id, but existing instance.id, create a new member.id just instead of returning the associated member.id to the client (your pr already did this anyways) 2) when receiving a join group of non-empty member.id, and existing instance.id, but is inconsistent with the static members map, return error `member_id_required`. now the only issue is what if two instances come with the same instance.id and the same member.id. i think it would not be possible for new members due to 1) since we always generate a new member.id. ----------------------- edit: after thinking about this and discussing with a bit more, i am now inclined towards the original proposal now, i.e. for all responses other than join-group request, we let it client to not reset generation / member-id immediately, but try to re-join the group again. this logic is simpler because: 1. for static members, not reseting the member-id and re-join, will then result in an fatal `member-id-mismatch`, and hence we can avoid the ping-pong scenario of two mis-configured clients keep kicking each other out by reseting the member id and re-join. 2. for dynamic members, not resetting the member-id and then rejoin will likely to get the same `unknown-member-id` again, and then it can reset generation. the cons is that this requires one more round-trip. but to me, simpler logic that does not require much complexity worth the cost, compared to my proposal above that special handles static and dynamic members on client side much more. 3. moreover, as we move on to kip-429 which will assume the assignors to be ""sticky"" somehow anyways, so even if somehow the member-id is still recognized by the group-coordinator when re-joining and the member happen to be the leader, this unnecessary rebalance triggered will be cheap. cc",0,0.8412917852401733
270628741,6177,abbccdda,2019-03-30T14:51:43Z,i believe the `member_id_required` exception is assumed to be used only for dynamic members now.,0,0.9853052496910095
270645251,6177,abbccdda,2019-03-30T23:46:18Z,"as we have discussed, we shall generate a new member id each time the static member rejoins. so the former consumer will not have the same member.id as the previous one",0,0.9833975434303284
270679831,6177,guozhangwang,2019-03-31T19:00:54Z,"ack, i will update the comment on the kip regarding the updated logic. could you update the kip wiki with that logic and also update the voting thread as well?",0,0.9866994619369507
270680233,6177,guozhangwang,2019-03-31T19:12:21Z,updated the comment in the wiki page: [a link] please double check and also update the wiki page for better illustration if that makes sense.,0,0.9784060716629028
271098896,6177,abbccdda,2019-04-02T00:37:32Z,"i see, so we should choose to throw exception for most times?",0,0.9848640561103821
272441872,6177,guozhangwang,2019-04-05T04:34:35Z,yeah i'd suggest so.,0,0.9722161889076233
273648617,6177,hachikuji,2019-04-09T18:46:33Z,the thing about an empty id might be misleading since we use null to indicate absence. a few more details may also be helpful. perhaps we can say something like this:,0,0.9576777815818787
273671882,6177,hachikuji,2019-04-09T19:49:31Z,nit: perhaps quote the exact config? for example: [code block],0,0.9864404797554016
273673756,6177,hachikuji,2019-04-09T19:54:40Z,i think one of the things we have regretted is not limiting the group.id to a reduced character set. this has made acls more difficult for example. do you think it is worth being stricter about the instance id? potentially we could limit the character set to the same characters we allow for topics.,-1,0.8751928806304932
273674941,6177,hachikuji,2019-04-09T19:57:54Z,let me try one more time. how about `fenced_instance_id`?,0,0.984877347946167
273727881,6177,hachikuji,2019-04-09T22:22:41Z,hmm.. this method is also called when a call to `unsubscribe()` is made. would we not want a static member to leave in this case?,0,0.9837552309036255
273728352,6177,hachikuji,2019-04-09T22:24:20Z,this is unused since we use the generated classes now.,0,0.9834578037261963
273733855,6177,hachikuji,2019-04-09T22:47:16Z,"i think we can be a little clearer in this message. how about simply ""the coordinator reports a more recent member.id associated with the consumer's group.instance.id.""",0,0.9835585951805115
273734276,6177,hachikuji,2019-04-09T22:49:14Z,"i may have asked this before, but do we want to use empty to indicate no group instance id? alternatively, we can let the `groupinstanceid` type be nullable in the schema and we can use null. this would be consistent with the config.",0,0.9887862205505371
273737121,6177,hachikuji,2019-04-09T23:03:22Z,"i'm just saying that it would be clearer to represent the difference between static and dynamic members by using an optional field. otherwise you have to dig into the code to make sure the uses are all safe. for example, we have a bunch of cases below where we are using the empty instance id in calls to `hasstaticmember`. this opens the door to bugs if we are not really careful with our checking. the nice thing about options is that they force us to check for absence.",0,0.9142888784408569
273738245,6177,hachikuji,2019-04-09T23:08:38Z,nit: you can drop the `s` since there are no substitutions.,0,0.9881505966186523
273738796,6177,hachikuji,2019-04-09T23:11:29Z,can you elaborate on this comment? i'm not sure i understand the problem.,-1,0.624269425868988
273739061,6177,hachikuji,2019-04-09T23:12:49Z,i think we should not try to overload `requireknownmemberid`. it makes this pretty confusing.,-1,0.9012727737426758
273739420,6177,hachikuji,2019-04-09T23:14:32Z,"yes, exactly. we like stack traces and nice error messages! a lot of these impossible states have a way of becoming more possible over time.",1,0.9882349967956543
273742089,6177,hachikuji,2019-04-09T23:27:52Z,maybe slightly nicer: [code block],0,0.9122233390808105
273743469,6177,hachikuji,2019-04-09T23:35:19Z,we did get some flack in 2.1 for a change to this format. the problem is that we cannot downgrade once the new format is in use. we will probably have to mention this in the upgrade notes at a minimum. unfortunately i don't see any great options at the moment to avoid this. perhaps we should just switch to json.,0,0.7272025942802429
273744396,6177,hachikuji,2019-04-09T23:40:22Z,i'm trying to think through the implications of this. we are silently discarding the instance id which means that replicas won't know about it. the member will be considered a static member until there is a coordinator change. then it will suddenly become dynamic again and i think that would trigger this assertion: [a link] i think we probably need to avoid using the static membership logic entirely until the ibp supports it.,0,0.873397171497345
274084303,6177,abbccdda,2019-04-10T17:53:39Z,sure!,1,0.7571635842323303
274157146,6177,abbccdda,2019-04-10T20:56:44Z,thanks!,1,0.9308210611343384
274157459,6177,abbccdda,2019-04-10T20:57:38Z,sounds good,1,0.9535238742828369
274162476,6177,abbccdda,2019-04-10T21:11:41Z,fixed. i was about to say the new heartbeat shall be scheduled with new member id.,0,0.9843958616256714
274163062,6177,abbccdda,2019-04-10T21:13:40Z,"yes, for static member we shall never require a rejoin, because its identity is declared by the instance id.",0,0.9888803958892822
274163632,6177,abbccdda,2019-04-10T21:15:25Z,thanks!,1,0.9308210611343384
274261445,6177,abbccdda,2019-04-11T05:23:58Z,"i see, we could discuss offline some time for a holistic solution.",0,0.9267517924308777
274261996,6177,abbccdda,2019-04-11T05:27:51Z,"that sounds reasonable. i'm not sure i'm fully following here because unless broker upgrades to latest, the group instance id should not include the join group because of automatic request downgrade.",0,0.9635432958602905
274263375,6177,abbccdda,2019-04-11T05:35:38Z,"yea, updated explicitly in the kip",0,0.9799984097480774
274263890,6177,abbccdda,2019-04-11T05:38:46Z,"ugh, `empty_group_instance_id` will just be empty string right?",0,0.7748947143554688
274265007,6177,abbccdda,2019-04-11T05:45:00Z,"let me check the code real quick, do you have good example for character set check? right now what i found on admin client is sth like: [code block] which is not very useful.",0,0.8924486637115479
274265965,6177,abbccdda,2019-04-11T05:50:52Z,"i quickly checked `unsubscribe()` use cases, and there are mainly two: 1. illegal topic/partition data, i.e empty topic partitions to subscribe 2. consumer self managed membership (subscription) i think it makes sense to make static member behavior consistent in these two cases, because the effect of leaving is minimal.",0,0.9745565056800842
274266402,6177,abbccdda,2019-04-11T05:53:18Z,this is just for the sake of reducing code duplication and keep if-else blocks intact.,0,0.9844475984573364
274267268,6177,abbccdda,2019-04-11T05:57:41Z,i don't think that comment is needed here. it's just an edge i caught during my experiment.,0,0.8352530002593994
274667775,6177,abbccdda,2019-04-11T21:16:28Z,"we still need an empty string field to make sure we could correctly serialize the member metadata. also checking null for string is not very intuitive in java compared with scala option, so my suggestion is to keep using empty string on client side for now.",0,0.9709383249282837
274731954,6177,guozhangwang,2019-04-12T01:19:13Z,the topic validation logic can be found at `org.apache.kafka.common.internals.topic`,0,0.9845975637435913
274732699,6177,guozhangwang,2019-04-12T01:25:05Z,what's `ibp`?,0,0.986488401889801
274750177,6177,abbccdda,2019-04-12T03:39:32Z,inter broker protocol,0,0.9845464825630188
275141269,6177,abbccdda,2019-04-14T05:38:54Z,sounds like a good idea!,1,0.9894707202911377
275591198,6177,hachikuji,2019-04-16T00:27:22Z,"i'm not sure i follow this. we _can_ serialize null. my point is we should try to be consistent. null is a good way to represent something which is missing. java also has an `optional` type which we could use, but we'd still have to decide what gets transmitted in the protocol.",0,0.9265442490577698
275592368,6177,hachikuji,2019-04-16T00:34:39Z,nit: this could probably be implemented more concisely with a regex.,0,0.9866061806678772
275593388,6177,hachikuji,2019-04-16T00:40:57Z,this method doesn't really make sense if `groupinstanceid` is `none`. wouldn't it clearer to force the caller to ensure that that is the case? same for the other methods below.,0,0.9643679857254028
275595976,6177,hachikuji,2019-04-16T00:58:51Z,"we expose the new joingroup protocol as soon as the binary is updated. the client will begin using it. that itself is fine, but it is not safe for the broker to use the static member logic until we are sure that all brokers support it, as indicated through the ibp. otherwise, the case i mentioned is possible. we seem to have removed the assertion i mentioned above, but i am still not sure the logic is correct. the simplest option would be to set `groupinstanceid` to `none` if the ibp is below `kafka_2_3_iv0`.",0,0.9767597317695618
275596088,6177,hachikuji,2019-04-16T00:59:38Z,shouldn't this be `kafka_2_3_iv0`? do we have any tests?,0,0.9839693307876587
275596574,6177,hachikuji,2019-04-16T01:02:33Z,why not let `groupinstanceid` be represented as an `option` inside `membermetadata` as well?,0,0.98405921459198
275597196,6177,hachikuji,2019-04-16T01:06:07Z,nit: parenthesis are unneeded,0,0.9795230627059937
275607536,6177,abbccdda,2019-04-16T02:13:53Z,i tried one time and it failed due to serialization issue. let me try one more time.,0,0.9784971475601196
275630797,6177,abbccdda,2019-04-16T05:07:57Z,"to make the full e2e consistency, we should consider supporting optional[string] type for part of auto-mated protocol in `joingrouprequest.json` and other protocol classes. otherwise, we still need to have `empty_instance_id` as a special type to handle null case in the serde of request.",0,0.9890649318695068
276082373,6177,abbccdda,2019-04-17T05:19:07Z,good catch!,1,0.9899783134460449
276083793,6177,abbccdda,2019-04-17T05:28:24Z,"i think adding an assertion here would be helpful. would be messy if we do null check in caller every time when we call `replace`, `addstaticmember` and `getstaticmemberid`, what do you think?",0,0.9651319980621338
276084326,6177,abbccdda,2019-04-17T05:31:37Z,"sounds good, i think it's probably better to do the refactoring in one diff for both topic and group instance id.",1,0.6348112225532532
276085073,6177,abbccdda,2019-04-17T05:35:56Z,addressed in groupcoordinator.scala,0,0.9867684245109558
276745404,6177,guozhangwang,2019-04-18T16:45:46Z,how about rename it to `maybereplacegroupinstance` and do the check in the callee and make it no-op if `groupinstanceid` is empty then?,0,0.9857699871063232
276749603,6177,guozhangwang,2019-04-18T16:57:47Z,"the automated protocol supports `nullable string` (it will be serialized and stored as `0xffff` over the wire), and hence could we encode null for this instance id, and then: 1) on client side we can have this parameter nullable, and upon constructing join-group request it will be auto-serialized. 2) on broker side we can have this parameter as `option[string]`, upon deserializing if the returned value is null construct the field as `none`.",0,0.9719964265823364
276750288,6177,guozhangwang,2019-04-18T16:59:51Z,"i think on the broker side we should be using `option` in scala to be consistent with other fields (see my other comment). on the client side though, it is true that since we only recently dropped j7, `optional` is not commonly used elsewhere, and i think having it just as a nullable field is fine (we can, do a universal refactoring on client side using `optional` in another pr but this does not need to be done in this scope).",0,0.965703010559082
276827600,6177,abbccdda,2019-04-18T20:46:28Z,thanks for the info!,1,0.9540320038795471
276828558,6177,hachikuji,2019-04-18T20:49:21Z,"sorry, if this wasn't clear, but here is what you need to add to the schema definition. see the `nullableversions` field. [code block] in the common tongue, 0xffff is -1 :wink:. this is how we represent null arrays and strings.",-1,0.9886866807937622
276836547,6177,abbccdda,2019-04-18T21:14:10Z,"yea, i just figured it out, thank you!!",1,0.9909282326698303
276864867,6177,abbccdda,2019-04-18T23:21:00Z,i agree with renaming but feel slightly against second proposal. i think the goal is to avoid people from passing in null group.instance.id in the code level.,0,0.9436164498329163
277374681,6177,guozhangwang,2019-04-22T17:59:41Z,"i've thought about this a bit more, and also searched in github: [a link] i think a third common case is to use a temporary consumer for its apis, like get offset by timestamp, get log end offset etc; generally speaking for temporary consumer case, they should not use static members (and by default it would not be the case). so i think it really boils down to: for static members, do we consider the admin request kicking it out of the group be the only appropriate way for it to leave in time or not? i.e. even if the consumer shuts down itself, it should not be considered as ""i want to leave"" but another request has to be made to effectively kick him out.",0,0.7529865503311157
277477265,6177,guozhangwang,2019-04-22T23:55:45Z,should we remove this const string then?,0,0.9833374619483948
277478955,6177,guozhangwang,2019-04-23T00:05:31Z,should we still need these calls if we can get rid of const `empty_group_instance_id` with optional?,0,0.9875937104225159
277480160,6177,guozhangwang,2019-04-23T00:12:40Z,nit: i think it worth being an `info` since this should not happen frequently and hence each time it happens we should pay attention.,0,0.8893893361091614
277480223,6177,guozhangwang,2019-04-23T00:13:09Z,also: better include the groupinstanceid as well?,0,0.9883794784545898
277480459,6177,guozhangwang,2019-04-23T00:14:29Z,"as we discussed before, better change `assert` to `throw illegalstateexception` with a meaningful error message; ditto below.",0,0.9783700108528137
277481055,6177,guozhangwang,2019-04-23T00:18:13Z,for all the three callers of it: two already checks `member.isstaticmember` and one has the assert already. so i'd suggest we pass in `groupinstanceid: string` as parameter directly from caller.,0,0.9874607920646667
277481439,6177,guozhangwang,2019-04-23T00:20:36Z,"hmm.. does this function only have one caller who's already checked `group.hasstaticmember(groupinstanceid)`? in this case i think we can just name it `replacegroupinstance` as it should always replace unless we have a bug. originally i was thinking there are multiple callers of it, and some may really turn into a no-op since it is not for static members, but now the call trace seems to indicate only one caller.",0,0.9775611758232117
277481592,6177,guozhangwang,2019-04-23T00:21:38Z,just to confirm: is `map.remove(null)` a no-op with no side-effect?,0,0.987991988658905
277481815,6177,guozhangwang,2019-04-23T00:22:58Z,nit: we can just do `else if` and `else`.,0,0.9879631996154785
277482417,6177,guozhangwang,2019-04-23T00:26:46Z,if this is nullable we can get rid of `empty_group_instance_id` right?,0,0.9874461889266968
277482886,6177,guozhangwang,2019-04-23T00:29:58Z,"actually, for all such `setgroupinstanceid` calls we can by default remove it since without any setters is equal to using `setgroupinstanceid(null)` right?",0,0.9843533635139465
277483066,6177,guozhangwang,2019-04-23T00:31:15Z,do we have unit test coverage on compatibility? i.e. old formatted data can be loaded with new versioned byte code with new fields set to default (null) values?,0,0.989038348197937
277483221,6177,guozhangwang,2019-04-23T00:32:14Z,i think we should remove this part from streams first. there are some open questions that i've in mind and needs to potentially create a new streams kip for it. cc,0,0.9699029326438904
277484517,6177,guozhangwang,2019-04-23T00:41:13Z,"i think `null` default value should still work, e.g. the group-id used `null` as default values above.",0,0.9884757995605469
277503483,6177,abbccdda,2019-04-23T02:57:03Z,the tricky thing is that we couldn't set the key to `null` in `verifiableconsumer` because it will throw exception.,0,0.8308688402175903
277503751,6177,abbccdda,2019-04-23T02:59:19Z,sounds good,1,0.9535238742828369
277503848,6177,abbccdda,2019-04-23T03:00:04Z,"my bad, didn't see the upper comment.",-1,0.9819440841674805
277513354,6177,abbccdda,2019-04-23T04:20:25Z,"we could remove the assertion here, but i guess we still need to throw exception since new caller may forget to check it.",0,0.98616623878479
277515294,6177,abbccdda,2019-04-23T04:36:42Z,yep!,0,0.6378647685050964
277515412,6177,abbccdda,2019-04-23T04:37:41Z,we don't,0,0.8130587339401245
277813801,6177,abbccdda,2019-04-23T18:28:46Z,mind giving me an example for compatibility test? i look around and haven't found one good example.,0,0.7554726600646973
277912948,6177,abbccdda,2019-04-23T23:51:03Z,"after offline discussion with , we sort out following key points: 1) will the static membership affect unit test independence? short answer: no. the reason is because without explicitly setting the `client.id` config for stream instances, the static member id will be changed throughout the restarts since we add a random hash to `client.id`. it will essentially behave the same as current dynamic membership. also one another confusion was that we are changing *max session timeout cap* to 30 min, instead of *default session timeout* which will remain as 10 s for either static or dynamic member. so the out-dated members will be kicked out in 10 seconds as expected. 2) the concern about thread id change throughout restarts. this is a valid concern in case where we configure two stream jobs within one jvm, so the threads will sometime shuffle from job a to job b, which unfortunately breaks the expectation of persistent thread-id numbers. this, however, shall not block us from enabling static membership for streams because the worst case is just doing repetitive rebalances as current dynamic membership. we could choose to address this application layer problem in another diff. the conclusion is that, it does no harm to enable static membership on streams, we are just realizing there are more subtle cases we need to handle. let me know if this addresses your concern, thanks!",0,0.9287827610969543
277927199,6177,guozhangwang,2019-04-24T01:28:38Z,that sounds good. we can check that the passed in `string` (not `option[string]` for simplicity since all current callers actually can pass in the string parameter) is not null and throw otherwise.,1,0.6864354610443115
277927290,6177,guozhangwang,2019-04-24T01:29:16Z,is that the case?,0,0.9778779745101929
277927492,6177,guozhangwang,2019-04-24T01:30:40Z,"you can for example take a look at this pr: [a link] when we update the consumer protocol, we added unit test to make sure old versioned code can still deser it, and similarly in this case, we need to change that new versioned code can still deser old versioned data.",0,0.987112820148468
277927851,6177,guozhangwang,2019-04-24T01:33:11Z,"i'd still suggest we add streams logic leveraging static members in this pr for further discussion than rush it in this pr. for people who wants to use the feature in streams asap, they can still do it by manually set the group.instance.id via consumer config prefix in streamsconfig. but we need to think through all the cases before making it turned on by default in streams.",0,0.9835188984870911
277950657,6177,abbccdda,2019-04-24T04:21:56Z,"i see. however it's currently not possible, since they need to have access to stream internal to set `group.instance.id` config.",0,0.9886321425437927
277953016,6177,abbccdda,2019-04-24T04:40:56Z,thanks!,1,0.9308210611343384
277953572,6177,abbccdda,2019-04-24T04:45:48Z,i feel we could keep option[string] in the function parameters. the reason is for consistent handling of this piece of information in groupcoordinator until we actually extract the string for internal data structure update. the other approach would be using the case switch here which is more option friendly. wdyt?,0,0.973651111125946
278737190,6177,guozhangwang,2019-04-25T21:22:33Z,"got it, that makes sense. i think we would consider fixing the following the static stream-thread suffix number first, and then requiring users who wants to turn on static membership to specify the client-id then (otherwise internally created client-id would never be the same across lives of a streams instance). i saw you've created jira tickets for these tasks.",0,0.9659270644187927
278737600,6177,guozhangwang,2019-04-25T21:23:36Z,"after a second thought i think i agree with you, it's not worth optimizing the parameter while giving up consistency in call traces.",0,0.9200472235679626
278739994,6177,guozhangwang,2019-04-25T21:31:03Z,we should check that `staticmembers` is also empty by default when deserializing from old versions.,0,0.9880962371826172
109102899,2772,michaelandrepearce,2017-03-31T07:29:53Z,"accidental formatting, no need, need to revert.",0,0.6711799502372742
109102944,2772,michaelandrepearce,2017-03-31T07:30:14Z,remove extra space,0,0.9675664901733398
109102987,2772,michaelandrepearce,2017-03-31T07:30:33Z,remove extra un-needed whitespace,0,0.9862701296806335
109103041,2772,michaelandrepearce,2017-03-31T07:30:54Z,is this needed?,0,0.9837570190429688
109103189,2772,michaelandrepearce,2017-03-31T07:31:53Z,"remove accidental, whitespace formatting change.",0,0.9819388389587402
109141852,2772,jeroenvandisseldorp,2017-03-31T11:37:45Z,"you use pretty much everywhere k, v, h as parameter order, so would be more consistent to do so here too.",0,0.9803754687309265
109150487,2772,michaelandrepearce,2017-03-31T12:39:53Z,"good spot, and its a very good point, will adjust to make it more consistent. thanks :)",1,0.9928725957870483
109287859,2772,radai-rosenblatt,2017-04-01T16:01:42Z,"nit pick - returns all headers _in the order they were added in_, also clarify if returns null or some empty collection if nothing found",0,0.9892265796661377
109287981,2772,radai-rosenblatt,2017-04-01T16:09:02Z,header doesnt allow for a null key. should lastheader(null) throw or just return nothing?,0,0.9527243971824646
109288040,2772,radai-rosenblatt,2017-04-01T16:12:35Z,can this inner class be made static? if so would save an outerclass.this call above,0,0.9893496036529541
109292288,2772,michaelandrepearce,2017-04-01T19:32:43Z,"yes this one could have been, it was using java 8 feature previous, was simply quickly removing our usage of java 8, as kip 118 isn't in master and thus would cause a build failure as still needing java 7 support atm. i will change to static inner class for now. didn't actually even need the recordheaders.this call it the method call filter was in scope, but will make it a static inner class. n.b the other closeaware iterator we cannot make static inner, as it needs reference to isclosed, unless we made that an atomic which would be more of an overkill imo.",0,0.9684129357337952
109292305,2772,michaelandrepearce,2017-04-01T19:33:15Z,"good point, behaviour should be as per creating a header with a null, and throw.",0,0.6588730216026306
109292344,2772,michaelandrepearce,2017-04-01T19:34:00Z,"will update java doc with additional detail, was just copying java doc that was as per kip page for the interfaces.",0,0.9880708456039429
110308619,2772,becketqin,2017-04-07T02:56:08Z,can we use standard java doc in the public interface?,0,0.9892833232879639
110308937,2772,becketqin,2017-04-07T03:00:14Z,this java doc seems a little misleading. even for kafka 0.11 we can still use this constructor to construct a consumer record although the headers is empty. and the message format will still be in 0.11.,0,0.8908650279045105
110310796,2772,becketqin,2017-04-07T03:27:30Z,it is a little unfortunate that we have to do this hack just to maintain the backwards compatibility of the serializer and deserializer interface. there were some discussion about this on the side channel that we hope can start to use java 8 so a default implementation can be added to the existing serde interface. personally i think it is fine to just start to set sourcecompatibility to 1.8 in this patch and drop support for java 1.7 given that kip-118 has already passed. this way we can avoid this hack. what do you think?,-1,0.9739354252815247
110314115,2772,becketqin,2017-04-07T04:22:00Z,can we rename this to `closeheaders`?,0,0.9882729649543762
110314866,2772,becketqin,2017-04-07T04:34:55Z,is this change intentional? this change will cause an additional memory copy in `defaultrecord.readfrom()`.,0,0.9861499071121216
110315042,2772,becketqin,2017-04-07T04:37:46Z,it seems we already has a `record.empty_headers`. can we reuse that?,0,0.9891407489776611
110315300,2772,becketqin,2017-04-07T04:41:46Z,"""recordheaders has been closed.""",0,0.983391523361206
110315649,2772,becketqin,2017-04-07T04:47:10Z,it is a little tricky here because we would require the order of the header to be the same as well. i am wondering if this would be a little too demanding.,-1,0.6306341290473938
110316068,2772,becketqin,2017-04-07T04:53:50Z,see previous comment about memory copy.,0,0.985934853553772
110316561,2772,becketqin,2017-04-07T05:02:32Z,is there any special consideration of creating a mutable new header here?,0,0.9864643812179565
110316924,2772,becketqin,2017-04-07T05:08:16Z,do we want to close the headers here?,0,0.986789882183075
110319166,2772,michaelandrepearce,2017-04-07T05:39:29Z,"the discussion in the kip seemed to come to conclusion we only want to close them on produce. as in consume if you consume you may wish via the interceptors to manage the headers again, e.g. remove it. on the front of mutability if you change the headers but consumed again the headers would be per the original messages as it would be created again. this is different to the producer record issue, which is why we closed that during send.",0,0.9792263507843018
110319402,2772,michaelandrepearce,2017-04-07T05:42:32Z,"so here the only thing we do is create the header object which is string, byte[]. as per kip. should note the string is memory copied already. as such we can make this a buffer but a line or two down when we hand over to the header object it would be a byte[]. also same comment as above, in kip we agreed on interface to be byte[] we can change this to a bytebuffer, and personally not opposed to this, just we should note, it would be a change to the kip",0,0.9606615304946899
110319457,2772,michaelandrepearce,2017-04-07T05:43:11Z,"yes we could, alas the import check would fail, i can amend the import check and reuse it. i will do this",0,0.8645751476287842
110319516,2772,michaelandrepearce,2017-04-07T05:44:06Z,"sure, good point, was just copying off the kip document. i will do this.",0,0.6534420251846313
110319547,2772,michaelandrepearce,2017-04-07T05:44:24Z,sure :). i will do this,1,0.9561523795127869
110319762,2772,michaelandrepearce,2017-04-07T05:47:12Z,"so this is to the equality of arraylist equals. i believe therefor we get this for free. as per java doc compares the specified object with this list for equality. returns true if and only if the specified object is also a list, both lists have the same size, and all corresponding pairs of elements in the two lists are equal. (two elements e1 and e2 are equal if (e1==null ? e2==null : e1.equals(e2)).) in other words, two lists are defined to be equal if they contain the same elements in the same order. we should also note ordering is important, as noted in kip discussion as we use the ordering for add/lastheaders, as such if i had two headers but for the same key the order was different, lastheaders would return differently, therefor i would argue the headers are there for not equal.",0,0.9211328029632568
110319886,2772,michaelandrepearce,2017-04-07T05:49:07Z,"this is inline with the comment left when the constructor for timestamp was added. it also is the same, it created a valid / correct message format still, and you can still use the constructor. see constructor directly above, its pretty much a copy and paste job, with just slight modification. constructor comment added when 0.10 changes done. * creates a record to be received from a specified topic and partition (provided for * compatibility with kafka 0.9 before the message format supported timestamps and before * serialized metadata were exposed). * our new constructor comment with 0.11 changes, following same lines. * creates a record to be received from a specified topic and partition (provided for * compatibility with kafka 0.10 before the message format supported headers).",0,0.9597276449203491
110320089,2772,michaelandrepearce,2017-04-07T05:51:45Z,"yes there was. so that it is set so if someone in their consumer interceptors consumes and needs to modify headers. also recordheaders uses array list, which does an empty array memory saving, so really the over head for cleaness of code and keeping in line with producerrecord, for empty headers the overhead is just the recordheaders object, no real sizeable data/memory. if this really is of a concern, we could do null and then have a if null create lazily on the headers() method. though we wouldn't be able to make the same saving on producerrecord as we call the headers() method on send to get them, if we wanted to do the same we would need to introduce a hasheaders() or headerssize() method on the producer/consumer record, so you can avoid calling headers() and initialising the object. also trying to make this saving would cause complexity where we want to provide headers to the ser/des for the linkedin use case's [a link] where they may need or want access to headers, we need to pass headers object, if not to force it to handle null headers also which would uk.",0,0.9721808433532715
110321627,2772,michaelandrepearce,2017-04-07T06:08:18Z,"yes it was, as the kip interface and constructor for a header is byte[]. when we create the headers in producer it will be a byte[] as such this would not be any memory copy, like wise on consume when the header is read a byte[] would need to be returned as such any saving would be negated. if we want bytebuffer, then it would be best to change that you construct headers with a bytebuffer value, and like wise byte[] value(), changes to bytebuffer value(). im not opposed to this, just isn't as agreed in kip, we would update the kip if we changed this.",0,0.7713744044303894
110321649,2772,michaelandrepearce,2017-04-07T06:08:36Z,sure. i will do this.,0,0.8853011131286621
110321692,2772,michaelandrepearce,2017-04-07T06:09:16Z,"yes totally agree, and as per commit comment, this was for lack of java 8 optimisation.",0,0.9790443778038025
110335355,2772,michaelandrepearce,2017-04-07T07:55:24Z,"on seeing what we can do to try alleviate your concern as much as possible we can make it so it uses bytebuffer, again we should note though, that on header.value() will incure a memory copy still, as simply we move when this copy occurs. as such its only incurred if the header is read.",0,0.9797550439834595
110335364,2772,michaelandrepearce,2017-04-07T07:55:29Z,"on seeing what we can do to try alleviate your concern as much as possible we can make it so it uses bytebuffer, again we should note though, that on header.value() will incure a memory copy still, as simply we move when this copy occurs. as such its only incurred if the header is read.",0,0.9797550439834595
110414387,2772,ijuma,2017-04-07T15:17:32Z,"as i explained here [a link] we need to update our system tests infrastructure to run with java 8 before we can make the switch. it may take a bit of time to get that done, so my suggestion was to do what can be done with java 7 in the initial pr and file a jira for the follow-up work once the java 8 switch happens. that way, we can make progress instead of being blocked.",0,0.9786619544029236
110428445,2772,michaelandrepearce,2017-04-07T16:22:17Z,"ok, so i have pushed a commit to revert back to java 7 (again) so this pr could be merged to make progress. i have locally stashed the java 8 changes for later.",0,0.9850307106971741
112817815,2772,hachikuji,2017-04-22T20:16:43Z,nit: is this needed?,0,0.981063961982727
112817938,2772,hachikuji,2017-04-22T20:22:21Z,nit: could we use `record.empty_headers` instead of `null` for all of these?,0,0.9896429777145386
112817953,2772,hachikuji,2017-04-22T20:23:03Z,we should probably update the producer and consumer config documentation to mention these new interfaces. it should probably also be added to the kip.,0,0.9861493110656738
112818039,2772,hachikuji,2017-04-22T20:26:11Z,"does this need to be public? not much harm, but maybe unnecessary.",0,0.7617959976196289
112818193,2772,hachikuji,2017-04-22T20:32:52Z,"could replace this constructor with `this(key, utils.wrapnullable(value))`?",0,0.9892407059669495
112818215,2772,hachikuji,2017-04-22T20:34:10Z,maybe we should cache this value and potentially set the buffer to null?,0,0.985285222530365
112818309,2772,hachikuji,2017-04-22T20:39:09Z,"if we added another method `add(string key, byte[] value)`, would there be any need to expose a concrete implementation of `header`?",0,0.9893488883972168
112818423,2772,hachikuji,2017-04-22T20:45:15Z,"if we want this package to be included in the javadocs (i.e. if we want it to be exposed to users), then we need to update `build.gradle`.",0,0.9883829951286316
112819053,2772,michaelandrepearce,2017-04-22T21:17:13Z,"no its not, was just left in by accident, good spot, will remove.",1,0.5871517658233643
112819065,2772,michaelandrepearce,2017-04-22T21:17:59Z,"makes sense, will update.",0,0.9799602627754211
112819106,2772,michaelandrepearce,2017-04-22T21:19:55Z,"agreed, was hoping that we get to have source in java 8 and thus then don't need these class's. as discussed previously we will do the java 8 changes in separate pr, once kip 118 is implemented.",0,0.9778667092323303
112819124,2772,michaelandrepearce,2017-04-22T21:21:09Z,"agreed. though based on below comment on note on cache and set buffer to null, then for the byte[] constructor, we should then not wrap but simply set the byte array value.",0,0.9822463989257812
112819135,2772,michaelandrepearce,2017-04-22T21:21:43Z,"a nice optimisation, this actually saves us on the produce side, as we don't then need to wrap the byte array and then unwrap it again.",0,0.6104644536972046
112819183,2772,michaelandrepearce,2017-04-22T21:24:22Z,"agreed, i recall during the kip discussion we originally had add(string key, byte[] value) but someone (will need to trawl the history) requested it to be add(header header). im happy having both, as such will add it, and once merged to master will update the kip document and send out a notification.",1,0.9729702472686768
112819919,2772,michaelandrepearce,2017-04-22T22:14:22Z,"no it doesn't. again anyhow once kip 118 (java 8) is done, will raise separate pr, which this would be removed anyhow. this is so we can merge/commit to master with current java 7.",0,0.9893416166305542
112821175,2772,michaelandrepearce,2017-04-22T23:27:53Z,"thanks, will update",1,0.5815900564193726
113302283,2772,hachikuji,2017-04-25T20:31:46Z,"since we now only have the `header` and `headers` classes public, maybe we could locate them under `common`?",0,0.9891742467880249
113338574,2772,michaelandrepearce,2017-04-25T23:51:50Z,"i was purposely wanting to avoid that and use packaging structure to keep things tidy/grouped together as is nicely done with other parts, else the common package level (one level up) would become a dumping ground over a period, if that approach was constantly taken. this is simply allowing package org.apache.kafka.common.record import org.apache.kafka.common.header",0,0.936638355255127
113436597,2772,ijuma,2017-04-26T12:22:16Z,this constructor doesn't take a timestamp. is that intentional?,0,0.9622502326965332
113438319,2772,michaelandrepearce,2017-04-26T12:31:15Z,"yes it was, there is a constructor line 66, that does take timestamp, which this one delegates to. [code block]",0,0.9886292219161987
113439712,2772,ijuma,2017-04-26T12:38:23Z,"yes, but one takes `headers` and the other takes `iterable ` and it's unclear why that is so.",0,0.9704431891441345
113455023,2772,michaelandrepearce,2017-04-26T13:46:11Z,"ah no that is a mistake it should be `iterable `, gotcha now, good spot, will correct it.",1,0.7798848152160645
113456401,2772,michaelandrepearce,2017-04-26T13:51:12Z,fix committed.,0,0.9876684546470642
113772475,2772,hachikuji,2017-04-27T18:42:20Z,fair enough.,0,0.908961832523346
113832198,2772,ijuma,2017-04-28T00:38:49Z,"nit: we typically don't use all caps in our javadocs. it's ok to just say ""all headers"", i think. there are a few cases like this.",0,0.9811847805976868
113832491,2772,ijuma,2017-04-28T00:41:59Z,"i don't think this comment is accurate. [code block] and `arrays.aslist.toarray`: [code block] i'd just remove the comment. the code is implemented as one would expect, we don't need to worry about java's implementation details.",0,0.9485297203063965
113832530,2772,ijuma,2017-04-28T00:42:27Z,"no need for this comment, it just repeats what the code is doing.",0,0.9740134477615356
113833156,2772,ijuma,2017-04-28T00:49:14Z,"as you can see in the code i pasted in the other comment, the first thing that the constructor does is call `c.toarray` so it actually depends on the collection. `arraylist` does `arrays.copyof` today, but could be something else later. i think a single comment at the top saying ""use efficient copy constructor if possible, fallback to iteration otherwise"" is clear and not dependent on implementation details.",0,0.9827022552490234
113833598,2772,ijuma,2017-04-28T00:53:59Z,`headers` is missing from here and from the other `append` that was added.,0,0.9848507642745972
113833664,2772,ijuma,2017-04-28T00:54:42Z,`front` seems to be redundant,0,0.9769710898399353
113833820,2772,ijuma,2017-04-28T00:56:07Z,nit: `standardcharsets.utf_8` is nicer than `charset.forname`,0,0.9453877806663513
113834118,2772,ijuma,2017-04-28T00:58:41Z,"it would be good to exercise a few more methods after `remove` is called. also, it would be good to interleave `add` and `remove` calls in one test.",0,0.9787123203277588
113834436,2772,ijuma,2017-04-28T01:01:31Z,"i was thinking about this and maybe `close` is not the right name. because we can still use the class, we simply cannot mutate it any more. the name that came to mind is `seal`, but maybe that's not clear either. we could do the boring `closeforupdates` or something like that. thoughts?",-1,0.5220139622688293
113834747,2772,ijuma,2017-04-28T01:04:50Z,we should check the keys too in every case in this test.,0,0.9847374558448792
113835397,2772,michaelandrepearce,2017-04-28T01:12:53Z,"close, is what was the end method, in the kip discussion, and is naturally for java what you tend to implement closable interface for.",0,0.988627016544342
113835523,2772,michaelandrepearce,2017-04-28T01:14:22Z,agreed.,0,0.9702104926109314
113835615,2772,ijuma,2017-04-28T01:15:30Z,"this is an internal method, so it's really part of the kip. in java, you typically can't use a class after you call `close()`, so i don't really agree. for example, using try with resources doesn't make sense for this class.",0,0.7859193086624146
113836292,2772,ijuma,2017-04-28T01:22:33Z,"one more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.",0,0.9798523187637329
113837107,2772,michaelandrepearce,2017-04-28T01:33:15Z,"it is true, that as you say, it is meant to be no longer useable. how about setreadonly() inline with file.setreadonly() from java api's",0,0.9872235059738159
113837206,2772,michaelandrepearce,2017-04-28T01:34:34Z,will remove,0,0.9818933010101318
113837251,2772,michaelandrepearce,2017-04-28T01:35:05Z,will add,0,0.9802242517471313
113837325,2772,michaelandrepearce,2017-04-28T01:36:00Z,laptop died as i was committing this will do tomorrow now. could we merge? and i open another pr tomorrow?,0,0.8440187573432922
113837349,2772,michaelandrepearce,2017-04-28T01:36:20Z,will enhance,0,0.9621567726135254
113837395,2772,michaelandrepearce,2017-04-28T01:36:57Z,"sure, more test ideas always welcome",1,0.6862736940383911
113869779,2772,michaelandrepearce,2017-04-28T07:34:41Z,added,0,0.9735139608383179
113869831,2772,michaelandrepearce,2017-04-28T07:34:58Z,added,0,0.9735139608383179
95493943,2330,ewencp,2017-01-11T01:08:45Z,nit typo: mey,1,0.7107691764831543
95495767,2330,ewencp,2017-01-11T01:25:32Z,it seems like the channelbuilder implementations respect the possibility that these are null but we always seem to pass `none` if we don't want an implementation? did the intended usage just diverge during development of the pr? should we stick to only one or the other?,0,0.9728327989578247
95502827,2330,ewencp,2017-01-11T02:37:23Z,"nit throughout -- all lowercase is fine for stuff like comments, but for user-facing messages, it'd be nice to emphasize proper capitalization, grammar, etc.",0,0.8558633923530579
95503095,2330,ewencp,2017-01-11T02:41:00Z,"not critical since these aren't public apis, but there are a bunch of references to methods in these javadocs that could be ``ified.",0,0.9865652918815613
95503684,2330,ewencp,2017-01-11T02:48:51Z,it seems this class isn't even used anywhere. maybe we should just remove it entirely?,0,0.898231565952301
95505219,2330,ewencp,2017-01-11T03:09:58Z,"using the `memorypool` for `networkreceive` only works if everyone actually uses the `memorypool` for all relevant allocations. there are still uses of the other constructores -- this is only used by `kafkachannel`. i just want to verify we know the implications of leaving the other ones. obviously the constructor with `bytebuffer` doesn't need the `memorypool`. a few are used in `saslclientauthenticator`/`saslserverauthenticator`. those seem fairly reasonable (one is unbounded, which doesn't seem ideal, although i'm not sure a bound can easily be placed on it). the last case is in `blockingchannel`. it seems this is only used in controlled shutdown. i assume the kip was mainly targeted at client requests and the controlled shutdown message is constrained enough in its request size that we just don't need to worry about that case? (i'm not sure how completely we want to make the enforcement for this kip, i.e. want to catch everything except stated exceptions to protect against even malicious users or if we are just trying to address ""accidental"" issues caused by clients.)",0,0.9726297855377197
95505706,2330,ewencp,2017-01-11T03:17:19Z,"re: comment, do you have a stacktrace or something from where this happens? would be good to know if there's a valid case or if the condition checked a few lines up should be `receivesize <= 0`. intuitively, a zero length receive seems like it would be invalid (but possible for clients to transmit, and so perhaps handled gracefully even if it is invalid).",0,0.9818028807640076
95505922,2330,ewencp,2017-01-11T03:20:24Z,these don't need `public` on them since it's an interface.,0,0.9853965640068054
95506702,2330,ewencp,2017-01-11T03:31:41Z,would this be worth raising to `warn`? seems like it might be relevant for users to know via the logs that they are effectively throttling reads. or are we assuming the new sensor is sufficient?,0,0.9867236018180847
95508527,2330,ewencp,2017-01-11T04:00:44Z,"this is fine. you can also put those all in an array and just index with `min(ordinal, units.length-1)`.",0,0.9397989511489868
95508782,2330,ewencp,2017-01-11T04:04:41Z,"is there any concern that we might lose track of updating this properly? it's not just an issue with adding new request types; it's also a problem if a request type that didn't have `bytes` or `nullable_bytes` fields is updated to a version of the schema that does have them. i'm skeptical that folks will even know about, let alone remember to update, this list if they introduce such a field. would some sort of static determination based on the full list of schemas be more reliable but equally fast?",-1,0.9091523885726929
95511403,2330,ewencp,2017-01-11T04:44:34Z,"is there any concern about efficiency here? in particular, this allocates a new list and runs an additional linear time algorithm. a simpler alternative that has weaker randomization guarantees would be to select a random starting offset and use a couple of iterators to implement a sort of rotated view of the original list. or perhaps overall it's not a concern since we have a linear cost to process all the keys anyway?",0,0.9599910378456116
95548748,2330,ijuma,2017-01-11T10:15:32Z,"i think it would be nice to avoid unnecessary naming inconsistencies between this and `bufferpool`. it may make sense to deviate in some cases, but could you take a pass and see if some names here or there should be renamed for consistency?",0,0.9626927375793457
95550443,2330,ijuma,2017-01-11T10:25:52Z,"`controlledshutdown` only uses `blockingchannel` if the `inter.broker.protocol.version < 0.9.0.0`, so it's safe to ignore. it's only there to allow rolling upgrades from 0.8.x. i haven't checked the other cases, it would indeed be good to know if there's a good reason why they are not using the memory pool.",0,0.9846071600914001
95582422,2330,rajinisivaram,2017-01-11T13:59:16Z,are there scenarios where you would expect this to be different from `transportlayer#ready()`?,0,0.9882628321647644
95583150,2330,rajinisivaram,2017-01-11T14:03:43Z,perhaps you want to return `this.ready()`? it looks like both ssl and sasl handshakes are done without using the memory pool. so the check should be for any handshake.,0,0.9856036901473999
95584021,2330,rajinisivaram,2017-01-11T14:08:42Z,i am not sure of the value of this loop. it is muting a subset of channels (ones that are not in handshake and have not allocated memory and have started read). channels not muted here and new channels are muted when and only when allocation for read fails. wouldn't it be better to do the same for the subset handled here as well and remove this loop altogether? it seems to me that this loop simply prevents channels from reading the 4-byte size for which space has already been allocated.,0,0.5863804817199707
95589701,2330,rajinisivaram,2017-01-11T14:38:14Z,"not sure about this. `ssltransportlayer#hasbytesbuffered` returns true if there is any data in `netreadbuffer`. if more data is needed to unwrap and no data arrives from the client, i think the handling of `keyswithbytesbuffered` results in a tight polling loop with timeout=0.",0,0.9449976682662964
95611883,2330,rajinisivaram,2017-01-11T16:13:52Z,i think you can have empty message body in sasl exchanges.,0,0.9877465963363647
95612479,2330,rajinisivaram,2017-01-11T16:16:22Z,perhaps we don't want to release `empty_buffer`?,0,0.9815315008163452
95613398,2330,rajinisivaram,2017-01-11T16:19:58Z,"similar to the mute in `poll()` - the mute could be delayed until a buffer needs to be allocated? it is possible that the channel already has a buffer allocated, in which case, we want it to complete read.",0,0.9884290099143982
95638139,2330,ewencp,2017-01-11T18:17:51Z,"it's just more proactive, right? if you're out of memory, you're not going to be able to do anything (beyond the handshake) on any channel anyway. i think the value is that instead of going through a more polling unnecessarily only to end up muting all the channels, you can just do so immediately.",0,0.9014545679092407
95754342,2330,rajinisivaram,2017-01-12T09:41:39Z,"the code looks like it is proactively closing most channels. but actually it closes a small subset of channels. channels can be in one of these states: 1. handshake 2. authentication 3. waiting to receive a message (receive == null) 4. received partial message size (receive != null, buffer == null) 5. received size and partial message body (receive != null, buffer != null) 6. muted after receiving size due to oom 7. explicitly muted 8. disconnect the loop actually handles only 4). it mutes 2) at the moment, but that is pointless since authentication doesn't use the pool, so that needs fixing anyway. 4) already has the size buffer, so there is not much point in muting before size is read, after which it will move to 6) if still oom. muting proactively is not particularly helpful since disconnect processing gets delayed as well, hence 3) is not muted. if we decide to allocate small buffers outside the pool to handle consumers as mickael has suggested, it will be useful to mute only in one place - i.e. when a buffer needs to get allocated and its size is known. i think `isinmutablestate` is unnecessary if muting is done on allocation failure and that makes the code simpler.",0,0.9691483378410339
95868086,2330,radai-rosenblatt,2017-01-12T19:37:53Z,"mostly because i was going after a specific oom scenario - dos by large producer requests. anything can be ""opted-in"" to using memory pools later on, i was trying to solve just one problem.",0,0.8875455260276794
95868466,2330,radai-rosenblatt,2017-01-12T19:39:30Z,i originally had a <= 0 check which triggered while testing my code. it surprised me (as evident by the comment) but i decided to live with it instead of tracking it down. also looks like its an expected scenario. i'll update the comment to reflect this,0,0.8957709074020386
95868992,2330,radai-rosenblatt,2017-01-12T19:41:59Z,"thats a good idea, i'll see if i can improve this.",1,0.9559244513511658
96104452,2330,radai-rosenblatt,2017-01-14T01:43:22Z,"i account for null as a safety net even though using none is clearer. so its both by design. having said that, i'll gladly go for one or the other if there's a style guideline.",0,0.9593954086303711
96104700,2330,radai-rosenblatt,2017-01-14T01:48:29Z,personally i dont think this is a warning - its normal operations. users who care can get at this information in a much better way via the sensors exposed in this kip.,-1,0.49916693568229675
96105233,2330,radai-rosenblatt,2017-01-14T02:00:23Z,this whole clause is (in my opinion) premature optimization of an edge case - trying to guarantee fairness when operating under memory pressure and assuming that selectionkeys iteration order is not pseudo random. i'll improve on it if you insist but i would prefer to wait for real world complaints,0,0.6543580889701843
96512094,2330,radai-rosenblatt,2017-01-17T21:16:12Z,- i've implemented a simple schema visitor and used that to find the relevant api keys for this dynamically. please see the revised code.,0,0.9723595380783081
96512145,2330,radai-rosenblatt,2017-01-17T21:16:26Z,done,0,0.9764507412910461
96512217,2330,radai-rosenblatt,2017-01-17T21:16:50Z,done,0,0.9764507412910461
96512883,2330,radai-rosenblatt,2017-01-17T21:19:43Z,"right now no, this exists as a separate api becuase its a different ""aspect"". ideally under java8 i could have made this a method with a default impl",0,0.9860767126083374
96513168,2330,radai-rosenblatt,2017-01-17T21:21:02Z,again - its an issue of mutability vs ready being 2 logically different things (even if they are tied for the 2 current implementations of transport). you could think of a future qos implementation where inter-broker transports arent mutable (as opposed to client-broker transports),0,0.9747862815856934
96514142,2330,radai-rosenblatt,2017-01-17T21:25:51Z,"ssltransportlayer#hasbytesbuffered returns true if either the net or app buffers have data. its possible that net is done/empty, nothing will ever again be coming out of the socket, but there is data unread in app buffer (so already decrypted, just not read out)",0,0.9877888560295105
96515272,2330,radai-rosenblatt,2017-01-17T21:30:48Z,it looks like this code is only ever called from tests?,0,0.9833027720451355
96522660,2330,radai-rosenblatt,2017-01-17T22:08:37Z,done,0,0.9764507412910461
96522883,2330,radai-rosenblatt,2017-01-17T22:09:40Z,"i have removed the ""mute everything in advance"" loop in favor of letting channels mute themselves.",0,0.982597291469574
96606921,2330,rajinisivaram,2017-01-18T10:42:38Z,"if this code was only called from tests, then channels would remain in `explicitlymutedchannels` forever :-) it is actually called by the broker - mute/unmute to control reading from the channel and hence the need to track explicitly muted channels.",0,0.7712282538414001
96609022,2330,rajinisivaram,2017-01-18T10:54:43Z,"-rosenblatt i agree you do need the logic to read buffered data from `ssltransportlayer`. but i think the implementation needs to ensure that it doesn't end up in a tight polling loop when attempting to drain the buffered data. when there is data in the app buffer, it is reasonable to set timeout=0 and read the data. when there is some data in the net buffer, it is likely that more data is required to unwrap the data to move it from net to app buffer. if there is a network issue that stops any more data arriving, then i think `keyswithbytesbuffered` will set timeout=0 and continue in a polling loop until idle timeout causes the connection to be closed (i.e. 10 minutes of tight polling).",0,0.9324964880943298
96611992,2330,rajinisivaram,2017-01-18T11:11:49Z,-rosenblatt it is also about which layers need to know about these different aspects. does `ssltransportlayer` really need to know about mutability of buffers? and the reason i suggested the change was because `kafkachannel.isinmutablestate()` should return false if either of the conditions in `this.ready()` is false (i.e. transport layer handshake or authenticating). i don't think it makes sense for transport later or authenticator to have to worry about mutability of buffers.,0,0.9619279503822327
96612136,2330,rajinisivaram,2017-01-18T11:12:44Z,see comment below.,0,0.9795164465904236
96726102,2330,radai-rosenblatt,2017-01-18T20:25:46Z,": 1. is it guaranteed that if there's anything in net buffer after a read there must always be more incoming? because if so i can just react solely to data in app buffer. 2. i think i now understand the scenario you describe. my ""best"" idea of how to solve it would be have a boolean return value from pollselectionkeys() to indicate if any ""progress"" has been made. if no progress has been made in the previous call to poll() the next call would not set timeout to 0. my issue with this solution is that getting progress indications out of channel.read() / channel.write() is a non-trivial refactor (they are currently designed to return null or a complete object, would need to be extended)",0,0.625665545463562
96774619,2330,radai-rosenblatt,2017-01-19T01:25:16Z,- i've introduced a simple (relatively...) notion of progress made to try and prevent the tight loop you pointed out.,0,0.9630444049835205
96777022,2330,radai-rosenblatt,2017-01-19T01:47:23Z,- i've dropped transport.ismutable() in favor of just calling ready(),0,0.9742037057876587
96855844,2330,rajinisivaram,2017-01-19T13:10:48Z,it may be better to call `this.ready()` rather than `transportlayer.ready()` authenticators don't use the memory pool and channels don't need to be muted during authentication.,0,0.9876000881195068
96856882,2330,rajinisivaram,2017-01-19T13:17:12Z,"why does this check `datainbuffers`? with ssl, poll will go through this conditional block most of the time and it (the trace in particular) can be confusing. wouldn't the first poll after oom is reset handle the unmute?",0,0.9612950086593628
96858147,2330,rajinisivaram,2017-01-19T13:25:02Z,you want the loop to read even when there is no data from the network. so the condition needs to be something along the lines of `if (channel.ready() && (key.isreadable() || channel.hasbytesbuffered()) && !explicitlymutedchannels.contains(channel) && !hasstagedreceive(channel))`,0,0.9839720726013184
96859079,2330,rajinisivaram,2017-01-19T13:30:26Z,"since`keyswithbytesbuffered` was cleared earlier, it needs to be populated regardless of the status of staged receives. i think `""if(..) { keyswithbytesbuffered.add(..); }""` should be done outside the outer if that checks staged receives.",0,0.9890239238739014
96860499,2330,rajinisivaram,2017-01-19T13:39:14Z,"the current implementation of `addtocompletedreceives` moves receives from staged to completed state if the channel is not muted. i think it will better to replace `!channel.ismute()` with `!explicitlymutedchannels.contains(channel)`. buffers have already been allocated for the staged receives, so we should allow them to make progress and release the buffers.",0,0.9874617457389832
96914943,2330,radai-rosenblatt,2017-01-19T17:41:09Z,"this isnt about handling the unmute, this is about not waiting (up to 300ms currently) on other sockets if we know we have socket(s) with data in buffers that we can read immediately.",0,0.9718135595321655
96919823,2330,radai-rosenblatt,2017-01-19T18:05:03Z,"will do. also, to save on the cost of the explicitlymutedchannels map, do you think its better to replace it with an extra boolean flag on channel? have boolean muted and boolean explicitelymuted? (or rather bool mutedforoom and bool mutedforordering)",0,0.9826818108558655
96948979,2330,rajinisivaram,2017-01-19T20:21:01Z,"i think it would be slightly neater to store the muted state in channel rather than selector (not necessarily to save on cost, it just feels like channel state).",0,0.9720631837844849
96949265,2330,rajinisivaram,2017-01-19T20:22:30Z,there are two if statements - one just above this one sets timeout to zero and that needs to check `datainbuffers`. this one is just unmuting and resetting `outofmemory` flag. not sure why this needs to check `datainbuffers`.,0,0.9366615414619446
97010154,2330,radai-rosenblatt,2017-01-20T04:16:52Z,done,0,0.9764507412910461
97012152,2330,radai-rosenblatt,2017-01-20T04:47:19Z,"youre probably right. if datainbuffers = true it means either: 1. there is data in app buffer. only way (i think?) to get to this situation is that it could not be read out of app buffer because no memory, hence outofmemory will be true, which will be enough to trigger an unmute when memory becomes available 2. there's data only in net buffer. this means must data must come from socket and we have successfully read out everything that may have been in app buffer, so we didnt run oom, so channel is not muted and will show up in a future poll as a read key",0,0.8828470706939697
97012165,2330,radai-rosenblatt,2017-01-20T04:47:27Z,done.,0,0.9759407639503479
97282273,2330,rajinisivaram,2017-01-23T09:49:48Z,"-rosenblatt i tried running this test and the test passes for me when run on its own, but fails consistently when the whole class is run. this assertion is not safe since `ismadeprogresslastpoll()` can be true for various reasons including the key being writable - key may be writable for ssl handshake and so when the handshake completes, madeprogress is set. you could make the flag more conservative in the implementation, but not sure that is worthwhile - you could just remove this assertion from the test.",0,0.9489683508872986
97354296,2330,radai-rosenblatt,2017-01-23T16:19:05Z,"thats odd. the loop above explicitly waits for both handshakes to complete, and there should only ever be those 2 connections. i will remove the offending check, but i dont think its the handshake",-1,0.8515434265136719
97360992,2330,rajinisivaram,2017-01-23T16:44:24Z,"i think the loop waits for handshakes to complete from the client point of view, so the server has done its final writes. but kafka's ssltransportlayer code updates its handshake status a bit lazily, so there is a small window where the server has not yet updated its status after the final write.",0,0.9795213341712952
97428810,2330,rajinisivaram,2017-01-23T22:10:53Z,sslsender?,0,0.988204836845398
97453785,2330,radai-rosenblatt,2017-01-24T00:59:21Z,fixed,0,0.975196123123169
97744192,2330,rajinisivaram,2017-01-25T10:01:45Z,"-rosenblatt this needs to be ""tlsv1.2"" to work with java 7 since the server side properties in tests explicitly set ""tlsv1.2"" and the default tls version in java 7 is lower.",0,0.9869669079780579
97749640,2330,rajinisivaram,2017-01-25T10:29:09Z,"minor typo (doesn't impact the test, but is confusing). i think you want to use `sslserverconfigs` here and remove `sslclientconfigs` setting just above since only one server channel builder is used in the test?",0,0.9687953591346741
97924111,2330,junrao,2017-01-26T02:43:40Z,this seems never used?,0,0.9694334864616394
97924116,2330,junrao,2017-01-26T02:43:46Z,does oomtimesensor need to be volatile?,0,0.9822388887405396
97924129,2330,junrao,2017-01-26T02:43:54Z,sizebytes = > sizeinbytes maxsingleallocationsize => maxsingleallocationbytes?,0,0.9877699613571167
97924148,2330,junrao,2017-01-26T02:44:08Z,"probably better with ""requested size "" + sizebytes + "" <=0 ""?",0,0.9865058064460754
97924251,2330,junrao,2017-01-26T02:45:33Z,"in the case when the memory pool is full for a long time, we may not be able to update oomtimesensor for a long period of time, which can make metric inaccurate. we could probably update the sensor periodically (e.g., based on the window size of sensor) when the allocation is unsuccessful?",0,0.9652778506278992
97924265,2330,junrao,2017-01-26T02:45:45Z,could we just iterate explicitlymutedchannels directly?,0,0.988980770111084
97924301,2330,junrao,2017-01-26T02:45:58Z,perhaps we can use a better name for keyswithbytesfromsocket since selectedkeys() include keys ready for writes too.,0,0.986585259437561
97924332,2330,junrao,2017-01-26T02:46:38Z,"when will keyshandled and selectionkeys have different size? if that happens, it seems that we still need to remove all keys in selectionkeys to clear the ""ready for selection table"" in the nio selector. also, do you know if selectionkeys.clear() clears the ""ready for selection table""?",0,0.9889777302742004
98138485,2330,junrao,2017-01-27T03:01:49Z,this constructor seems never used?,0,0.9748451709747314
98138501,2330,junrao,2017-01-27T03:01:59Z,"not very clear on the above comment. is ""do we do not"" a typo? is the comment in the right place?",0,0.8805938363075256
98138532,2330,junrao,2017-01-27T03:02:26Z,"is the check (madeprogresslastpoll && datainbuffers) necessary? datainbuffers is caused by no memory in the memory pool. it seems that it's simpler to wait for the default selector poll time, which is what we do when the pool is out of memory in other cases.",0,0.9842563271522522
98138539,2330,junrao,2017-01-27T03:02:32Z,could we just clear the set to avoid recreation overhead?,0,0.9841902852058411
98138545,2330,junrao,2017-01-27T03:02:40Z,"is this test needed? if a channel is explicitly muted, it won't be selected by the selector, right?",0,0.9855822920799255
98138556,2330,junrao,2017-01-27T03:02:52Z,is the change needed since it seems memorypool is never null from the caller?,0,0.9845506548881531
98138581,2330,junrao,2017-01-27T03:03:15Z,"since this is a server side metric, it's probably better to use a yammer metric to be consistent. currently, we try only using the client metric on the server side if it needs additional functionality from the client metric (e.g., quota).",0,0.9851969480514526
98138585,2330,junrao,2017-01-27T03:03:18Z,would memorypoolused be better?,0,0.982382595539093
98138605,2330,junrao,2017-01-27T03:03:33Z,"we are not blocking the network threads, right?",0,0.9500215649604797
98138611,2330,junrao,2017-01-27T03:03:38Z,"this is optional. so, it probably should be of medium instead of high?",0,0.9858739376068115
98791618,2330,radai-rosenblatt,2017-01-31T22:53:09Z,probably yes.,0,0.9639668464660645
98792151,2330,radai-rosenblatt,2017-01-31T22:56:07Z,"i dont understand. the sensor is updated on every single tryallocate call - successful or not. only way for the sensor to stop being updated is if the server id idle, in which case there should be plenty of memory available? if you want better accuracy i could update the sensor when calling release() - this by definition means we have memory, so i could zero-out the oom time",0,0.9420431852340698
98793590,2330,radai-rosenblatt,2017-01-31T23:04:19Z,"there's a (hypothetical) corner case where there's data in the ssl app buffer but the underlying socket is done. this means the socket will never come back from a poll call, and you may wait 300ms for no reason instead of servicing the buffer immediately. this is why datainbuffers exists. i agree its simpler to just wait a whole poll cycle, but this is an attempt to shave off the latency. the made progress flag exists because the downside of the above condition is you may be stuck in a tight loop trying to service the buffer and so we dont try if no progress was made previous attempt.",0,0.9071750640869141
98794090,2330,radai-rosenblatt,2017-01-31T23:07:31Z,"explicitlymutedchannels are channels muted because they already have an outstanding request in progress. we never want to service them until they are (explicitely) unmuted and taken out of the set ? so this loop iterates over _all_ channels, unmuting anything that _isnt_ in explicit.",0,0.9791770577430725
98794457,2330,radai-rosenblatt,2017-01-31T23:09:53Z,renamed int readykeys --> numreadykeys and keyswithbytesfromsocket to readykeys,0,0.9878056049346924
98795499,2330,radai-rosenblatt,2017-01-31T23:16:41Z,"not really - because then topoll would be a copy ctr. i need to iterate over keys with buffered data i also need to record keys that (still?) have buffered data these have to be different sets or i would be forced to use a thread-safe collection, as i'll be modifying the structure im iterating over? this set gets ""cycled"" only when under memory pressure, so this is not expected to happen very often. i could pre-allocate both sets as instance variables on the class, if you want",0,0.966854989528656
98797148,2330,radai-rosenblatt,2017-01-31T23:26:50Z,"a channel can be in explicitelymuted and in keyswithbytesbuffered at the same time - ssl may try and read several requests at once into stagedreceives. if it reads once request and then has no memory for the next the channel will be in keyswithbytesbuffered. the 1st request out of staged will be moved to completed, causing the channel to be muted when socketserver picks it up (still on the same thread). under this condition channel.hasbytesbuffered() == true and also !hasstagedreceive(channel), causing data to be read for a channel that already has a request in progress",0,0.9692902565002441
98800869,2330,radai-rosenblatt,2017-01-31T23:52:08Z,"the sizes will differ only if some uncaught exception terminates the loop early (so never, unless bug?). the code path for different sizes is there to try and match what the previous code would produce under those conditions (which are, again, a bug). under ""normal"" operating conditions the sizes should always be the same, which i think makes the clear() calls a faster implementation (n * arraylist.add() + 2*clear() < n * set.iterator.remove()). what do you mean by ""ready for selection table""? looking at the code for openjdk 8 selectors use a normal set, wrapped to disallow external add() calls. all selectors do is call add() on the set of keys, there's no special ""hook"" to react to removes/clears",0,0.9825350046157837
98805695,2330,radai-rosenblatt,2017-02-01T00:30:15Z,"i was trying to be safe, so i ""support"" nulls by translating them to none. if you want me to choose either null or none (instead of both) - just choose which.",0,0.9262905716896057
98806646,2330,radai-rosenblatt,2017-02-01T00:38:25Z,would be much simpler if i could :-d,1,0.9354578852653503
98813839,2330,radai-rosenblatt,2017-02-01T01:38:35Z,"the memorypool interface and implementations are in clients, which has no dep. on yammer. i could either add a dep on yammer (probably bad idea) or introduce an intermediary interface ?",0,0.872727632522583
98814575,2330,radai-rosenblatt,2017-02-01T01:44:32Z,also updated the kip doc,0,0.9859979152679443
115627162,2330,junrao,2017-05-09T23:40:23Z,madeprogressthispoll seems unused?,0,0.967674970626831
115627211,2330,junrao,2017-05-09T23:40:51Z,"selector is shared between client and server. so, it's better not to mention server here.",0,0.9839771389961243
115627311,2330,junrao,2017-05-09T23:41:34Z,is the comment accurate? it seems that the underlying socket may still have bytes when there is buffered data.,0,0.9866700768470764
115627435,2330,junrao,2017-05-09T23:42:31Z,keyswithbytesbuffered => keyswithbufferedread?,0,0.98607337474823
115627563,2330,junrao,2017-05-09T23:43:35Z,previous message => previous receive,0,0.9818506836891174
115627970,2330,junrao,2017-05-09T23:47:05Z,"so it seems the only reason for this method is to optimize iterator.remove (by using keyshandled .clear())? if so, i am not sure if it's worth doing this optimization since this makes the code a bit harder to read.",0,0.885084331035614
115859559,2330,junrao,2017-05-10T21:39:58Z,"would it be simpler to check channel.ismuted() instead of channel.isinmutablestate()? then, the latter can be a private method in kafkachannel.",0,0.9889985918998718
115883466,2330,junrao,2017-05-11T00:30:42Z,"i am wondering if we really need madeprogresslastpoll. in general, if the selector runs out of memory, selector.poll will just block for 300ms in socketserver. if datainbuffers is true, it's due to out of memory. so, it seems that it's more consistent and simpler to just wait for the default 300ms in socketserver?",0,0.9659830331802368
115891794,2330,junrao,2017-05-11T01:58:19Z,"hmm, not sure if this is very reliable since the bytes may still be in the client socket buffer. perhaps a more reliable way is to do a waituntil wrapping selector.poll() on the server side.",0,0.9730864763259888
115892226,2330,junrao,2017-05-11T02:03:23Z,& => && ?,0,0.9792319536209106
115892482,2330,junrao,2017-05-11T02:06:25Z,"since this is only called in testmuteonoom, which is overridden in sslselectortest, perhaps the method can just be private?",0,0.9878571033477783
116027427,2330,junrao,2017-05-11T15:47:43Z,could we track this at nano sec level and pass the value as double in ms for better accuracy?,0,0.9854428768157959
116027727,2330,junrao,2017-05-11T15:48:49Z,could we just set oomperiodsensor in the constructor and get rid of this method?,0,0.9875041842460632
116772044,2330,radai-rosenblatt,2017-05-16T15:13:48Z,:+1:,0,0.7570654153823853
116772303,2330,radai-rosenblatt,2017-05-16T15:14:37Z,:+1: left over from testing,0,0.8972159028053284
116776829,2330,radai-rosenblatt,2017-05-16T15:29:45Z,"- the progress indicator was added to prevent a tight looping schenarion that spotted at jan 18 (see above discussion on an old version of selector, cant find a way to link to it). i believe the issue is that there may be bights in an underlying ssl buffer that would cause timeout = 0",0,0.9249067306518555
116777012,2330,radai-rosenblatt,2017-05-16T15:30:22Z,:+1:,0,0.7570654153823853
116777231,2330,radai-rosenblatt,2017-05-16T15:31:08Z,no because a channel can be muted for 2 reasons - 1 request at a time or memory pressure.,0,0.9678298234939575
116778212,2330,radai-rosenblatt,2017-05-16T15:34:34Z,we subtract the ready set from keyswithbufferedread and to topoll (set of keys we poll from under this condition) ends up being the set of keys for which there is data in buffers but not from the underlying socket (else they would be in the ready set),0,0.9886158108711243
116781172,2330,radai-rosenblatt,2017-05-16T15:44:42Z,:+1:,0,0.7570654153823853
116781268,2330,radai-rosenblatt,2017-05-16T15:45:04Z,:+1:,0,0.7570654153823853
116781973,2330,radai-rosenblatt,2017-05-16T15:47:30Z,"the sender only terminates after it completely flushes its output stream, so i would expect everything to have been written out? also, we accept() both incoming connections before the call to poll so that we know that at least handshaking has been done at that point. given that this is all local networking i think the timing is loose enough (also i've not see this fail in all the times that i've rebased and retested this branch).",0,0.9796633124351501
116783226,2330,radai-rosenblatt,2017-05-16T15:52:21Z,:+1:,0,0.7570654153823853
116784228,2330,radai-rosenblatt,2017-05-16T15:56:04Z,this assignment operator is defined differently for boolean operands (so it doesnt perform a bitwise operation) and so there is no &&=. i'll refactor the code to avoid this (as its rather obscure),0,0.9733368158340454
116801727,2330,radai-rosenblatt,2017-05-16T17:09:41Z,:+1:,0,0.7570654153823853
128666574,2330,junrao,2017-07-21T01:26:26Z,"since dispose() can be called by both network threads and request handler threads, should we make buffer volatile?",0,0.9894418716430664
128906634,2330,junrao,2017-07-22T22:54:57Z,it seems that we can just check !keyswithbufferedread.isempty?,0,0.9558815360069275
128906636,2330,junrao,2017-07-22T22:55:15Z,"hmm, it seems that madeprogresslastpoll needs to be set to false somewhere?",0,0.9563047885894775
128906639,2330,junrao,2017-07-22T22:55:28Z,"since there is no guarantee when the server will receive those bytes, should we put this code block in a waituntil loop?",0,0.9841380715370178
128906644,2330,junrao,2017-07-22T22:55:49Z,"since there is no guarantee when the server will receive those bytes, should we put this code block in a waituntil loop?",0,0.9841380715370178
128906645,2330,junrao,2017-07-22T22:55:56Z,memorypoolavgdepletedpercent => memorypoolutilization?,0,0.9869483709335327
128906650,2330,junrao,2017-07-22T22:56:02Z,memorypoolavgdepletedpercent-avg => memorypoolavgdepletedpercent,0,0.9832146167755127
128906668,2330,junrao,2017-07-22T22:56:13Z,"would it be better to name this queued.max.request.bytes? otherwise, it's not obvious what queued bytes are for.",0,0.9855067729949951
128906671,2330,junrao,2017-07-22T22:56:21Z,"instead of defaulting it to null, should we default it to defaults.queuedmaxbytes?",0,0.9893414974212646
129095498,2330,radai-rosenblatt,2017-07-24T17:07:51Z,will fix,0,0.978933572769165
129099716,2330,radai-rosenblatt,2017-07-24T17:23:54Z,will fix,0,0.978933572769165
129099747,2330,radai-rosenblatt,2017-07-24T17:24:04Z,will fix,0,0.978933572769165
129107398,2330,radai-rosenblatt,2017-07-24T17:53:14Z,"the test asserts on the state of the progress flag, meaning we cant call poll() more than once (2nd+ call will wipe the progress flag). will do",0,0.9873743653297424
129107452,2330,radai-rosenblatt,2017-07-24T17:53:26Z,will do,0,0.9603245854377747
129147307,2330,radai-rosenblatt,2017-07-24T20:39:15Z,will do,0,0.9603245854377747
129147337,2330,radai-rosenblatt,2017-07-24T20:39:21Z,will do,0,0.9603245854377747
129147672,2330,radai-rosenblatt,2017-07-24T20:40:48Z,will do,0,0.9603245854377747
129148372,2330,radai-rosenblatt,2017-07-24T20:43:47Z,the null was the validator. i've simply removed it now,0,0.986703634262085
129403649,2330,junrao,2017-07-25T19:35:22Z,could we add a comment to explain why madereadprogresslastpoll is used for?,0,0.9870790243148804
129403695,2330,junrao,2017-07-25T19:35:36Z,is there a need to set madereadprogresslastpoll here? it seems we only need to set when doing reads?,0,0.979731023311615
129403711,2330,junrao,2017-07-25T19:35:43Z,is there a need to set madereadprogresslastpoll here? it seems we only need to set when doing reads?,0,0.979731023311615
129408331,2330,junrao,2017-07-25T19:55:20Z,"since on the server side, we release memory through requestchannel.dispose(). however, memory is also released here through kafkachannel.close(). will this cause the same memory to be released more than once in certain cases?",0,0.9871926307678223
129412615,2330,radai-rosenblatt,2017-07-25T20:14:00Z,will do,0,0.9603245854377747
129412879,2330,radai-rosenblatt,2017-07-25T20:15:14Z,"i was being cautious. but youre right, given the progress flag is only used in combination with datainbuffers its probably impossible for a poll() round to involving the progress flag to consist solely of handshaking and connecting operations.",0,0.6375748515129089
129412922,2330,radai-rosenblatt,2017-07-25T20:15:26Z,removed (see above comment),0,0.9772023558616638
129419356,2330,radai-rosenblatt,2017-07-25T20:40:32Z,"kafkachannel.receive is a receive _in progress_. once its compete its read out (field is nulled) and the buffer passed to a requestchannel.request. so any given buffer exists either as part of an in-progress receive or as part of a completed receive (that was transferred to request channel). given the transition happens on the same thread that would close a kafkachannel, i dont think this would be a problem?",0,0.9768087863922119
311655316,7170,mjsax,2019-08-07T16:46:14Z,nit: `creates` -> `create`,0,0.9870820045471191
311655490,7170,mjsax,2019-08-07T16:46:41Z,"nit: `deserializers, [and] producer's`",0,0.9829649329185486
311657543,7170,mjsax,2019-08-07T16:51:17Z,"nit: `the number of partitions is determined based on the upstream topics partition numbers.` one may use `merge()` and there may be multiple upstream topic[s] -- for this case, we use max-partitions over all upstream topics. hence, i would be a little bit more fuzzy and avoid ""inherit"" as it implies it's the same number of partitions, but that only holds for the case of a single upstream topic. i would also use ""upstream"" instead of ""input"" because there might be an upstream repartition topic, too.",0,0.9574277997016907
311658732,7170,mjsax,2019-08-07T16:54:06Z,"do we need to have those two lines? we use `` usually to point to similar method, but not to point to overloads. for example, `map()` points to `mapvalues()`, but `map()` would not point to another variant of `map()`. the idea is to point people to different functionality, but if one know about `repartition` we assume they consider all overloads they can use.",0,0.9848244786262512
311658960,7170,mjsax,2019-08-07T16:54:33Z,nit: `creates` -> `create`,0,0.9870820045471191
311659340,7170,mjsax,2019-08-07T16:55:31Z,"nit: `partitions[,] and`",0,0.9862836599349976
311660226,7170,mjsax,2019-08-07T16:57:20Z,"nit: `name[,] and` why ""if repartitioning is required"" ? from my understanding, calling `repartition()` should always repartition, ie, enforce it. that's why we included `groupby()` in the kip -- if one does not want to force repartitioning, but want to control repartition topic properties, one can pass in `repartitioned` into `groupby` but would not use `kstream#repartition`. at least, that was my understanding of the kip?",0,0.9809747934341431
311660448,7170,mjsax,2019-08-07T16:57:52Z,why `(and potentially repartitioned)` ? should be removed imho,0,0.9802306294441223
311660775,7170,mjsax,2019-08-07T16:58:39Z,as above. my comments form above also apply to the third overlaod. not repeating them again.,0,0.9444478750228882
311661094,7170,mjsax,2019-08-07T16:59:23Z,this will not render as expected in the javadocs. you need to you html markup to define bullet points.,0,0.9882816672325134
311661405,7170,mjsax,2019-08-07T17:00:04Z,nit: remove empty lines between members,0,0.9833910465240479
311661640,7170,mjsax,2019-08-07T17:00:37Z,"nit: remove ""if required"" nit: `{ repartitioned}` -> `{ repartitioned}` (no need to link to itself -- it's considered bad practice). both nits apply to other javadocs, too. will not comment on the other ones, but please fix everywhere.",0,0.9829639196395874
311663095,7170,mjsax,2019-08-07T17:04:09Z,should we add an import to avoid the long package name?,0,0.9853997826576233
311668500,7170,mjsax,2019-08-07T17:16:53Z,why not `repartitioned.as(null)` ? this way we can remove `empty()` -- it would align with the pattern we apply in existing code.,0,0.9868487119674683
311670840,7170,mjsax,2019-08-07T17:22:03Z,"compare my other comment: from my understanding, we would always repartition.",0,0.9578609466552734
311672777,7170,mjsax,2019-08-07T17:26:27Z,nit: keep existing formatting or more `.withkeyserde(...)` into its own line.,0,0.9885554909706116
311674136,7170,mjsax,2019-08-07T17:29:29Z,"as the parent class contains the corresponding member, both method should be added there",0,0.9878270030021667
311677453,7170,mjsax,2019-08-07T17:36:40Z,seems do don't need `namedinternal namedinternal` as it's own variable?,0,0.9840697646141052
311693215,7170,mjsax,2019-08-07T18:12:47Z,we should extend existing `addinternaltopic` instead of having two method.,0,0.9862944483757019
311696457,7170,mjsax,2019-08-07T18:20:30Z,updating `repartitiontopicconfig` in this method may not be the best pattern. could we pass the number of partitions into the constructor of `repartitiontopicconfig` instead?,0,0.984296977519989
311708461,7170,lkokhreidze,2019-08-07T18:48:18Z,"yeah, that was something i wanted to verify actually. for example with dsl, user can do something like: `stream(...).mapvalues().repartition()`. in this case repartition topic doesn't make much sense. so i chose to guard against situations like that. open to suggestions.",0,0.8357022404670715
311713308,7170,lkokhreidze,2019-08-07T18:59:38Z,"i added integration test to verify that repartition topic won't be created if key-changing operation isn't performed. if number of partitions is specified, repartition topic will be created though.",0,0.988364577293396
311803123,7170,mjsax,2019-08-07T23:27:48Z,"if we don't repartition if user calls `repartition()` what is the purpose of the operation? the new operator is similar to `through()`, with the difference that kafka streams manages the topic. note, that one motivation for adding `repartition()` was, to allow users to repartition data before `transform()`. atm, this in only possible via `through()` forcing users to create the corresponding topic manually what is cumbersome. if a user does `stream(...).mapvalues().repartition()` i agree that repartitioning is not really required, but i would see this as a user error. at the same time, i see the potential to address this in the optimization layer: if we detect this case, we could remove the `repartition()` operator. it seems to be a subtle difference, but it's semantically two different approaches ihmo -- what you suggest is to keep the operator but to make it a no-op, while i suggest to _remove_ the operator. this would result in the same topology but the code how it is achieve is different and i believe it's an important difference.",0,0.9702193737030029
311879654,7170,lkokhreidze,2019-08-08T06:54:26Z,i like the idea of addressing this on optimization layer. i think this depends on how end implementation would look like and what we gonna agree on in our main discussion thread on this pr. if we gonna have only `repartitioned` operator i guess it make sense to always force repartitioning. if we gonna go with `groupby` and potentially `join` - optimization layer should be smarter about this in that case. i'll wait for an outcome of our discussion and update this accordingly.,1,0.9369486570358276
312410620,7170,lkokhreidze,2019-08-09T09:58:28Z,"i've removed this check from here, but i'll investigate if we can do this in optimization layer as suggested in this thread: [a link]",0,0.9861153364181519
312427351,7170,lkokhreidze,2019-08-09T10:51:54Z,"none of the other members have corresponding methods in parent class. do you think it's still okay to move only this two members? if that's the case, i would prefer moving all of the accessor methods there. i guess accessors are added only to `optimizablerepartitionnode` because accessing members is needed only in case of optimization (`internalstreamsbuilder#getfirstrepartitiontopicname`)",0,0.9868931770324707
312732526,7170,lkokhreidze,2019-08-11T10:18:23Z,"based on comments from i've removed `repartition` operations from optimization logic altogether. now, when calling `repartition` operations, corresponding repartition topic will be always created.",0,0.9888852834701538
316772010,7170,vvcephei,2019-08-22T16:24:53Z,"just as a general note, i 100% sympathize with the impulse to clean stuff up alongside your changes, but it would really help the reviewers if you made a pass over the pr and just removed all changes that aren't related to kafka-8611. it's not a big deal with small changes, but when the pr is over a thousand lines of code, it really adds a lot of distraction when reviewers have to consider cleanup alongside substantial changes.",0,0.46954241394996643
316781727,7170,vvcephei,2019-08-22T16:48:13Z,"i was looking at how this is used, and there are only two usages. in both cases, we create the builder, then call a method that populates the builder, then call `build()`. maybe we can just ditch the builder and invoke the constructor from that static method?",0,0.9823166728019714
316783992,7170,vvcephei,2019-08-22T16:53:45Z,"this invocation has the side effect of incrementing the ""topology name counter"". in other words, this means that inserting a ""repartition"" node with a name will cause all the other processors, stores, and repartition topics in the topology to get renamed anyway. to clarify (because it's confusing) this method increments the counter even if it's not generating a name. should we consider instead making it like suppression, which does not increment the counter if you provide a name?",0,0.9377658367156982
316790193,7170,vvcephei,2019-08-22T17:09:02Z,it seems this method is unused. are we missing test coverage?,0,0.9070714116096497
316790517,7170,vvcephei,2019-08-22T17:09:48Z,"likewise, this one is unused.",0,0.9748414158821106
316790765,7170,vvcephei,2019-08-22T17:10:29Z,thanks for avoiding mutable state in this class!,1,0.8523601293563843
316794184,7170,vvcephei,2019-08-22T17:18:57Z,"it seems like this might be able to just replace `internaltopicnames`. we only add to `internaltopicnames` in one place, where we also (maybe) add to this map. we can't (shouldn't) make the value `null`, but i noticed that `internaltopicproperties` allows its parameter (`numberofpartitions`) to be null, which seems like it should have the same effect as a null `internaltopicproperties`... what do you think about requiring `iternaltopicproperties` to be non-null in `addinternaltopic`, although it might have a null number of partitions. then, we can get rid of `internaltopicnames` and just use `internaltopicnameswithproperties.keyset()`?",0,0.966995894908905
316795023,7170,vvcephei,2019-08-22T17:21:08Z,"if we add this to `equals`, we *must* add it to `hashcode` as well, and we _should_ also add it to `tostring()`.",0,0.987494170665741
316795418,7170,vvcephei,2019-08-22T17:22:03Z,should be final,0,0.9767082333564758
316795547,7170,vvcephei,2019-08-22T17:22:24Z,these three fields should be final as well.,0,0.9841096997261047
316796336,7170,vvcephei,2019-08-22T17:24:14Z,generics can be inferred here.,0,0.9865835309028625
316796825,7170,vvcephei,2019-08-22T17:25:17Z,"variable can be final. i won't comment on final-able variables anymore. do the tests pass? there should be a check that fails on variables that aren't final, but could be.",0,0.9841356873512268
316796993,7170,vvcephei,2019-08-22T17:25:43Z,method should be static,0,0.9864572882652283
316797085,7170,vvcephei,2019-08-22T17:25:55Z,"likewise, this one can be static",0,0.9877168536186218
316798314,7170,vvcephei,2019-08-22T17:28:41Z,"not sure what the intent is here, to increment the number between each test, or between each instance of this integration test class within the jvm... it actually does the latter.",0,0.8447683453559875
316798925,7170,vvcephei,2019-08-22T17:30:02Z,"this can (and should) be a unit test, since we don't need to produce data or run kafka to build and verify the topology.",0,0.9870813488960266
316802639,7170,vvcephei,2019-08-22T17:38:10Z,"maybe consider: [code block] then, this method won't return until streams is actually started, which we've seen can increase test stability.",0,0.9836644530296326
317388374,7170,lkokhreidze,2019-08-25T08:46:32Z,"interesting... yup, checkstyletests pass. i think checkstyle don't cover `try with resources` usage. anyway, it should be final yes, will update this everywhere. thanks.",1,0.979999303817749
317389525,7170,lkokhreidze,2019-08-25T09:19:55Z,"i can change it, sure. but personally i would prefer to have the builder here because 1) it follows same standard as other `baserepartitionnode` implementations 2) static factory method for the `unoptimizablerepartitionnodebuilder` will have a lot of parameters and it'll make code uglier. wdyt?",0,0.5785897970199585
317390219,7170,lkokhreidze,2019-08-25T09:41:47Z,so that each individual test has its own input/output topics. there's code in `` that increments `test_num`,0,0.9876602292060852
317412260,7170,lkokhreidze,2019-08-25T19:50:33Z,done,0,0.9764507412910461
317412281,7170,lkokhreidze,2019-08-25T19:51:11Z,added `streamsgraphtest#shouldnotoptimizewhenrepartitionoperationisdone`,0,0.9841166138648987
317412296,7170,lkokhreidze,2019-08-25T19:51:32Z,done,0,0.9764507412910461
317412304,7170,lkokhreidze,2019-08-25T19:51:38Z,done,0,0.9764507412910461
317412334,7170,lkokhreidze,2019-08-25T19:52:23Z,done,0,0.9764507412910461
317412354,7170,lkokhreidze,2019-08-25T19:53:02Z,added tests.,0,0.9821693301200867
317412360,7170,lkokhreidze,2019-08-25T19:53:11Z,added tests,0,0.9820635318756104
317412366,7170,lkokhreidze,2019-08-25T19:53:23Z,done.,0,0.9759407639503479
317412373,7170,lkokhreidze,2019-08-25T19:53:30Z,done,0,0.9764507412910461
317412377,7170,lkokhreidze,2019-08-25T19:53:38Z,done,0,0.9764507412910461
317412381,7170,lkokhreidze,2019-08-25T19:53:44Z,done,0,0.9764507412910461
317412451,7170,lkokhreidze,2019-08-25T19:55:45Z,"very fair point, totally agree. sorry about that. there're not many changes related to ""cleanup"" in this pr, but if you think it creates noise and makes it harder to do the review, i'll revert all cleanup related code.",-1,0.9898239970207214
320850937,7170,vvcephei,2019-09-04T16:17:30Z,fair enough. thanks for the reply.,1,0.8405054807662964
320859172,7170,vvcephei,2019-09-04T16:35:57Z,"thanks for your understanding. i just mentioned it because it seemed like there wasn't a ton of review activity. just thought i'd share the tactic with you, since rightly or wrongly, the large ""diff"" numbers in the pr can scare off reviewers. for myself, i didn't have trouble overlooking it.",1,0.8273407220840454
320859948,7170,vvcephei,2019-09-04T16:37:42Z,"ah, yeah, there are some limitations to the linter. thanks for taking care of it.",1,0.92047518491745
320861613,7170,vvcephei,2019-09-04T16:41:31Z,"i see. but even though the number gets incremented after each test method, the string `inputtopic` is already fixed when the class is constructed, so it won't automatically get incremented. i think you need to make this a method to achieve the effect you intended.",0,0.9820282459259033
320868518,7170,lkokhreidze,2019-09-04T16:57:19Z,hi thanks for the comment. sorry if i'm missing something... but junit creates new instance of the class before each test case. since those are non-static fields they'll be initialized during each test run with incremented `test_num`. i've verified it one more time and during each individual test topic number gets incremented. here are the screenshots just for the sake of clarity:,-1,0.9585601091384888
321099321,7170,lkokhreidze,2019-09-05T06:51:57Z,"makes total sense, thanks for sharing. i will definitely take this into account for the future prs.",1,0.9733889102935791
321394898,7170,vvcephei,2019-09-05T17:41:10Z,"ok, i'm convinced :) thanks for clearing up my confusion.",1,0.9890032410621643
329290021,7170,mjsax,2019-09-28T01:10:35Z,should we explain the difference to `through()`? something like: [code block] we might also update the docs for `through()` and point to the new operator. we should also cross-link using `` tags,0,0.988751232624054
329290382,7170,mjsax,2019-09-28T01:18:11Z,"while i agree that immutability is great, i am wondering about consistency. the other configuration classes are mutable. do we think that might be of any concern? should we just update all other configuration classes an make them immutable, too? (of course not in this pr...) \cc",1,0.5925599932670593
329290536,7170,mjsax,2019-09-28T01:21:53Z,"nit: remove `this.` (we only use `this` is we must -- applies to other parts, too)",0,0.987119197845459
329290692,7170,mjsax,2019-09-28T01:25:27Z,"this method share a lot of code with `repartition(repartitioned)` -- we should create `private dorepartition(keyvaluemapper, repartitioned)` and all 4 public method should call it and just have a block [code block]",0,0.9792088270187378
329291018,7170,mjsax,2019-09-28T01:33:09Z,"seems we should add this to the parent class? and also use `optimizablerepartitionnode` and `groupedtableoperationrepartitionnode`. as a side cleanup, we should remove the `get` prefix -> `keyserializer()` -- we should also remove the `get` from `baserepartitionnode#getkeyserializer()` (same for value)",0,0.9886528849601746
329291182,7170,mjsax,2019-09-28T01:37:28Z,not sure why we need this? couldn't we use `internaltopicconfig`?,0,0.9509757161140442
329291498,7170,mjsax,2019-09-28T01:45:23Z,wondering if we should treat `numberofpartitions` as a regular config and add to `map topicconfigs` instead using `num.partitions` as parameter name? \cc,0,0.9850744009017944
329291593,7170,mjsax,2019-09-28T01:48:31Z,it seems also a little inconsistent with `internaltopicconfig` that uses `optional` but not `int`...,0,0.7897503972053528
329291663,7170,mjsax,2019-09-28T01:50:38Z,the whole method could be simplified to (and hence removed and embedded): [code block] if we let `#getnumberofpartitions()` return an `optional`.,0,0.9894570708274841
329311990,7170,lkokhreidze,2019-09-28T14:19:49Z,"thought about it, but it felt more natural to introduce separate class rather than using `repartitiontopicconfig` in current design. `repartitiontopicconfig` potentially can be package-private (haven't touched this in current pr) and i wanted to avoid leaking it through other packages. it felt like best to leave construction of `repartitiontopicconfig` in `internaltopologybuilder` class since `internaltopologybuilder` ""knows the best"" how to construct it. idea of this class is to provide bare minimum configs of internal topic properties. hope my way of thinking around this makes sense. wdyt?",0,0.7066090703010559
329329123,7170,lkokhreidze,2019-09-28T22:01:50Z,done.,0,0.9759407639503479
329329133,7170,lkokhreidze,2019-09-28T22:02:31Z,done,0,0.9764507412910461
329329200,7170,lkokhreidze,2019-09-28T22:06:17Z,"fixed, `numberofpartitions` is now optional",0,0.9869863390922546
329329236,7170,lkokhreidze,2019-09-28T22:07:25Z,"did what you suggested. `baserepartitionnode` now has following methods: [code block] i've refactored `groupedtableoperationrepartitionnode`, `optimizablerepartitionnode` and `unoptimizablerepartitionnode` accordingly.",0,0.986566960811615
329329258,7170,lkokhreidze,2019-09-28T22:08:26Z,done,0,0.9764507412910461
329329268,7170,lkokhreidze,2019-09-28T22:08:51Z,done and added more javadocs,0,0.9835638999938965
361869452,7170,lkokhreidze,2019-12-29T20:02:17Z,i've created jira ticket for it: [a link],0,0.9769876003265381
368248756,7170,mjsax,2020-01-18T21:11:21Z,nit: you need to insert ` ` markup if you want to get a new paragraph.,0,0.9852627515792847
368248926,7170,mjsax,2020-01-18T21:15:07Z,i don't think that `{ #through}` is correct markup. should be `{ #through(string)}`,0,0.9844731688499451
368249035,7170,mjsax,2020-01-18T21:16:57Z,`created topic` -> `[the] created topic is considered [an] internal topic` ?,0,0.9867320656776428
368249068,7170,mjsax,2020-01-18T21:18:01Z,"as above -> ` ` (seems other comment from above apply here, too -- won't repeat them)",0,0.9809555411338806
368249232,7170,mjsax,2020-01-18T21:21:51Z,nit: `selector` -> `keyselector` (we recently did a cleanup pr that uses `keyselector` as name is all other method that set a new key -- would be nice to align the names),0,0.9693654179573059
368249741,7170,mjsax,2020-01-18T21:33:51Z,"nit: in other classed, we just add `` tags instead of mentioning it in the text. should we do the same here for consistency?",0,0.9877275228500366
368250067,7170,mjsax,2020-01-18T21:41:06Z,"we can do all `null` checks in a single place within `dorepartition()` -- also, all other methods just say ` can't be null` (ie, please remove `parameter` for consistency)",0,0.9887431859970093
368250271,7170,mjsax,2020-01-18T21:46:00Z,"i don't think we can use `this.keyserde` that should align to the type of the input key, ie, type ` ` -- instead, we should set `keyserde` to `null` if not specified by `repartitioned` and fall back to the default key serde from `streamsconfig` during runtime. (this issue is also indicated by the ""unchecked"" warning that you suppress...)",0,0.9775757789611816
368250370,7170,mjsax,2020-01-18T21:48:15Z,comment seems redundant,0,0.8215762376785278
368250670,7170,mjsax,2020-01-18T21:54:42Z,not sure if i understand why we need this? it seems also to be tricky to understand the code if one calls `repartitiontopicconfig#setnumberofpartitions` and nothing happens because the actual object is of type `immutablerepartitiontopicconfig`.,0,0.6661354899406433
368251040,7170,mjsax,2020-01-18T22:02:16Z,"should be better throw here as this should never be called? what raised the question (we you actually do check the type already: should be flip the hierarchy as being mutable is a superset of being immutable and thus it should be `repartitiontopicconfig extends immutablerepartitiontopicconfig` -- for this case, `immutablerepartitiontopicconfig` would not have this method at all what seems to be cleaner)",0,0.9771960973739624
368251147,7170,mjsax,2020-01-18T22:05:25Z,to what extent is this check different from the check above when we call `validateandgetnumofpartitionsofimmutabletopics` -- or can we remove it here as it's redundant?,0,0.9847186207771301
368251683,7170,mjsax,2020-01-18T22:16:36Z,"i am wondering, if we should really throw an exception for this case? why do we not create this repartition topic with the same number of partitions as specified on the second input topic instead? iirc, for the following case we would also adjust the number of partitions: [code block] this code above is very similar to: [code block] in both cases, the number of partitions of one topic is fixed, while the second one has key-changing operation and thus we can just create a reparition topic that matches the number of partitions of the first topics?",0,0.9662644267082214
368421799,7170,lkokhreidze,2020-01-20T08:40:38Z,thanks for the suggestion. we can do null check in `dorepartition` for `repartitioned` parameter. null check for `selector` parameter should be on upper level since in some cases we do pass selector as `null`. for example: [code block] will update the error msg as well.,1,0.8723878860473633
368425477,7170,lkokhreidze,2020-01-20T08:49:46Z,good call. done.,1,0.9479499459266663
369771654,7170,lkokhreidze,2020-01-22T19:56:18Z,"interesting point. i guess in that case idea would be if in the `copartitiongroup` there's one `immutablerepartitiontopicconfig` and rest are repartition topics, we will enforce number of partitions from `immutablerepartitiontopicconfig`. in cases when there're more than one `immutablerepartitiontopicconfig` we would still throw an exception. does this make sense?",0,0.8333653211593628
369775730,7170,lkokhreidze,2020-01-22T20:05:04Z,"this check covers the case when number of partitions do not match between immutable repartition topics (aka created via `repartition` operation) and _ordinary_ repartition topics. but considering your comment below, different logic is needed here.",0,0.9856369495391846
369784339,7170,lkokhreidze,2020-01-22T20:24:25Z,"originally i've implemented this method with throwing an exception. but it seems like this method is being called from various places, like `streamspartitionassignor#preparetopic`. my thinking was - instead of each individual caller checking if `internaltopicconfig` supports setting number of partitions, it makes more sense to delegate this to the ""builder"" that chooses appropriate implementation based on some logic. `setnumberofpartitions` is part of `internaltopicconfig` so even i flip the hierarchy, i can't avoid `setnumberofpartitions` method. so i don't think it gives any benefit if we flip the hierarchy. i also thought instead of adding new class, i could maybe enhance `repartitiontopicconfig` to support ""immutability"" in cases when topics are for `repartition` operation, but in that case i have to add a flag to the class to indicate that this `repartitiontopicconfig` is actually for `repartition` operation which seems a bit worse compared to introducing new class. thoughts?",0,0.947716474533081
369788818,7170,lkokhreidze,2020-01-22T20:35:33Z,"not ideal, agree. but tbh whole repartition topic management is complicated and is built around the idea of updating the number of partitions during different phases of kafka streams lifecycle. seems like adding new concrete class that indicates ""immutability"" the easiest and safest solution for now without changing current implementation and logic too much. would appreciate your ideas around this. not sure how to accommodate and guarantee immutability of partitions in some other (without introducing some major changes current internal topic management logic. maybe followup ticket is in order?)",1,0.8421006202697754
373849243,7170,lkokhreidze,2020-02-02T14:14:32Z,"hi this is now implemented. logic is the following: if `repartitiontopicconfig`s which have enforced number of partitions have the same value, non-enforced repartition topics (like for mapper) will be created with the num of partitions specified via `repartition` operation. `shoulddeductnumberofpartitionsfromrepartitionoperation` integration tests verifies this case.",0,0.9865706562995911
373849898,7170,lkokhreidze,2020-02-02T14:23:47Z,"hi gave it a bit more thought and decided to ditch this class altogether. `repartitiontopicconfig` and `immutablerepartitiontopicconfig` are exactly the same, just one wouldn't allow setting num of partitions. also, considering your comment about it being tricky to understand when num of partitions can be set or not (which is very valid concern) i've decided to encapsulate necessary logic into `repartitiontopicconfig` and `internaltopicconfig` classes. `internaltopicconfig` now can accept in the constructor `enforcenumberofpartitions` boolean flag: [code block] if `enforcenumberofpartitions` is set as `true`, and somebody decides to call `setnumberofpartitions` method, exception will be raised. i think this should make things much more clear. looking forward to your feedback.",0,0.7846179604530334
373849925,7170,lkokhreidze,2020-02-02T14:24:14Z,this class was removed. check my comment here: [a link],0,0.985355019569397
373863902,7170,lkokhreidze,2020-02-02T18:02:01Z,update: i've added `numberofpartitions` as int this constructor overload to indicate that passing `numberofpartitions` is mandatory when one wants to use this constructor. corresponding internaltopicconfig constructor also uses int.,0,0.989597499370575
392608571,7170,vvcephei,2020-03-14T18:24:49Z,"looking at this again with fresh eyes, i can't remember what advantage this has over `selectkey(keyvaluemapper).repartition(repartitioned)`. can you remember why we decided to add this, ?",0,0.9332874417304993
397650119,7170,lkokhreidze,2020-03-25T07:24:30Z,"hi as far as i remember we didn't have any specific discussion around this operation. main reason why we have added it i think is because of the convenience (merging selectkey and repartition into single operation). similarly how `groupby(final keyvaluemapper selector, final grouped grouped)` does it.",0,0.9837552309036255
398113069,7170,vvcephei,2020-03-25T19:25:52Z,"i see. iirc, your initial thought was to replace `groupby` with `repartition`, but we've gotten away from that design. now, it's more like a managed-topic version of `through` (in fact, this is what the javadoc for the method says). maybe this is why i was confused to see this overload, since it makes less sense to think of changing the key at the last minute before `though` or `to`. are you particularly attached to this convenience overload? i'm just thinking it's a safer bet to add it later if people really want it than to add it now and never really know if it's useful or not.",0,0.9053469300270081
398366211,7170,lkokhreidze,2020-03-26T07:36:34Z,"i can't say i am particularly attached to it, but i think it's useful one. from personal experience, we, at our company, often write topologies similar to this: [code block] here we need to explicitly use through in order to trigger repartitioning by selecting key (and we have to manage topic that we create in advance for `through` operation) new way of doing same thing is quite nice i think: [code block] for us, it's quite common use-case. and.my _guess_ is it will be common use-case for anyone using complex `transform` operations in dsl. does this make sense? on the other hand, if you believe that it's safer to remove `keyvaluemapper` overloads, i'll definitely do it.",1,0.9276973009109497
398927435,7170,vvcephei,2020-03-26T22:20:37Z,"i certainly agree that it would be common to do a `selectkey` before a `repartition`. there's a trade-off to strike between the number of different operations you need and the number of options on a single operation you have to choose from. i guess my hesitation is that it's still two different operations. for example, it also seems like it would be common to do a `map` before a `repartition`, but it's clearly now too much piled on if we have a fourth `repartition` overload also folding in the `map` operation. when i imagine coming to the api as a user, especially for the first time, i worry that i'd already have a lot of documentation to read to understand the implications of `repartition`, and each new overload adds linearly to the amount i have to learn to use the api. plus, i just feel like i would be puzzled about the exact same question i asked above: is this overload just the same as `selectkey().repartition()`, or does it do something subtly different? as you can tell, i worry quite a bit about how we can make sure the api stays as simple as possible while we still add new functionality. i guess this is just a long-winded way of saying that, yes, i would prefer to remove it :) hopefully, this isn't too disappointing for you, since the main motivation was to save on managing the `through` topic, not necessarily to save on that extra `selectkey` operator.",0,0.954239547252655
399058852,7170,lkokhreidze,2020-03-27T06:30:00Z,"thanks john, that's a valid point. agree, i'll remove it.",1,0.9517289996147156
399067977,7170,lkokhreidze,2020-03-27T06:59:31Z,done. i'll resolve this conversation.,0,0.9511416554450989
401253268,7170,vvcephei,2020-03-31T22:30:12Z,[code block] looks like an accidental formatting change.,0,0.8509082794189453
401349352,7170,mjsax,2020-04-01T04:28:23Z,typo: `producer's`,0,0.9839046597480774
401349473,7170,mjsax,2020-04-01T04:28:51Z,`[c]reated`,0,0.9856290221214294
401349644,7170,mjsax,2020-04-01T04:29:27Z,`by [the] current`,0,0.9849680066108704
401349985,7170,mjsax,2020-04-01T04:30:58Z,`explicitly` -> `automatically` ? (not sure which one is better),0,0.9326477646827698
401350251,7170,mjsax,2020-04-01T04:32:09Z,`[c]reated` `by [the] current`,0,0.9867702722549438
401350309,7170,mjsax,2020-04-01T04:32:27Z,`automatically` ?,0,0.9849992394447327
401350867,7170,mjsax,2020-04-01T04:34:46Z,nit: do we need to add the `` tag to every method? seems somewhat redundant (it's already mentioned in class javadocs above)? (similar below for other methods),0,0.9834730625152588
401351951,7170,mjsax,2020-04-01T04:39:27Z,why would we not use an upstream `keyserde` (similar to `valueserde = valserde` l584 above) if `repartitioninternal` has a `null` key serde?,0,0.9814627170562744
401352615,7170,mjsax,2020-04-01T04:42:42Z,why do we need to duplicate this method? might it be better to have just a single one and let caller set a `null` `streampartitioner` is they can't set it?,0,0.9859640598297119
401354459,7170,mjsax,2020-04-01T04:50:33Z,"for a `groupedtableoperationrepartitionnode` we should never have a customized `internaltopicproperties` object, but it should always be `internaltopicproperties.empty()` -- can we simplify this and not pass this parameter at all?",0,0.9872170090675354
401354751,7170,mjsax,2020-04-01T04:51:55Z,similar as above: can we avoid this parameter?,0,0.9852626323699951
401355550,7170,mjsax,2020-04-01T04:55:00Z,"`this.name = objects.requirenonnull(name, ""name can't be null"");` ? also, i believe `topicconfig` should not be `null` either -- can we add a check (also for the existing constructor above?",0,0.9867792129516602
401358667,7170,mjsax,2020-04-01T05:08:44Z,"with parallel test runners, would it be better to call this as first line in `before()` method (and use the returned value instead of calling `get()` in addition -- otherwise, we might get multiple different numbers per test run)? also wondering if we should assign the topic names that use the counter within before? for a clean isolation, it might also be good to add the test number to the `application.id`",0,0.9833903908729553
401359192,7170,mjsax,2020-04-01T05:10:53Z,should we setup all topics name within `before`?,0,0.9872955679893494
401360195,7170,mjsax,2020-04-01T05:14:55Z,"for this particular test, it seems we could detect the issue during topology `build()` already? ie, we could do an additional early check? if we think it's worth doing, we should do it in follow up pr to not drag this pr any longer. \cc (if yes, we could change this test from an integration test to a unit test)",0,0.9819470643997192
401361948,7170,mjsax,2020-04-01T05:21:56Z,"why do we have a `map()` step here? wouldn't this imply a repartition topic that would match whatever number of partitions is used on the other stream? ie, only without the map(), we guarantee that `topicbstream` has a certain number of partitions? with the `map()` step it seems to be the same test `shoulddeductnumberofpartitionsfromrepartitionoperation` as above?",0,0.9860087037086487
401362636,7170,mjsax,2020-04-01T05:24:32Z,"do we need an integration test for this? using `topology#describe()`, i think we could verify this with a unit test.",0,0.9873772263526917
401362888,7170,mjsax,2020-04-01T05:25:34Z,not sure why we need this test?,0,0.7408597469329834
401363128,7170,mjsax,2020-04-01T05:26:37Z,"nit: in test code, the signature can always be simplified to `throws exception` (there is no value to list exceptions) -- same for all test methods in this class (and maybe somewhere else?)",0,0.9886547327041626
401364227,7170,mjsax,2020-04-01T05:30:40Z,similar to above: we should be able to test with via unit tests using `topology#describe()`,0,0.9855391979217529
401364387,7170,mjsax,2020-04-01T05:31:15Z,seems to be unit-test able via `topology#describe()` ?,0,0.9889516234397888
401364523,7170,mjsax,2020-04-01T05:31:46Z,"not sure what this test is about, ie, how does is relate to the `repartition()` feature?",0,0.8897684812545776
401365280,7170,mjsax,2020-04-01T05:34:11Z,not sure what this test actually verifies?,0,0.7028865814208984
401365442,7170,mjsax,2020-04-01T05:34:48Z,using `mockprocessorsupplier` is an old test pattern -- we should use the new `testoutputtopic` instead.,0,0.9879447221755981
401368679,7170,mjsax,2020-04-01T05:46:09Z,"i realize that this contradicts a previous review comment, but i think that the older comment was incorrect, because `repartition()` might be called to just scale out without a key changing operation and thus for this case we should reuse the upstream `keyserde` (note that if there was an upstream key changing operation, `keyserde` would be set to `null` and we would still fall back to the default serdes from the config).",0,0.9766560196876526
401369054,7170,mjsax,2020-04-01T05:47:16Z,why do we introduce a new type ` `? the key type of the input and output kstream does not change during repartitioning.,0,0.9863755106925964
401372458,7170,mjsax,2020-04-01T05:58:29Z,"can you update the kip wiki page accordingly and send an follow up email to the vote thread of the kip to highlight the change as an fyi that the kip was modified (just in case somebody would have an objection, what i don't expect -- it's just custom in the community to do this).",0,0.9842721223831177
402561217,7170,lkokhreidze,2020-04-02T19:32:00Z,"i've followed same standard as other configurations classes (produced, grouped, etc). to keep things consistent maybe worth cleaning up all the config classes with redundant `` tags? (in the follow up pr maybe) wdyt?",0,0.9853053689002991
403061232,7170,lkokhreidze,2020-04-03T14:51:10Z,`application.id` already has test number. will do as you suggested.,0,0.9818440079689026
403097472,7170,lkokhreidze,2020-04-03T15:44:39Z,you're right. this test is redundant. removed it.,0,0.9417656660079956
403098661,7170,lkokhreidze,2020-04-03T15:46:32Z,"wanted to verify that key changing operation with `repartition` works as expected. i think it adds value, especially considering the fact that we've removed `repartition(keyselector` overloads.",0,0.9791770577430725
403109967,7170,lkokhreidze,2020-04-03T16:05:00Z,"this was the ""easiest"" way i could figure out to verify that custom partitioner is invoked when it's set",0,0.9835028052330017
403372355,7170,lkokhreidze,2020-04-03T22:48:53Z,it's related to this comment [a link],0,0.985224723815918
403374045,7170,lkokhreidze,2020-04-03T22:54:37Z,"thought about that, but somehow it felt ""safer"" with integration tests. mainly because i was more comfortable verifying that topics actually get created when using repartition operation.",0,0.8563863039016724
403374128,7170,lkokhreidze,2020-04-03T22:54:55Z,"thought about that, but somehow it felt ""safer"" with integration tests. mainly because i was more comfortable verifying that topics actually get created when using repartition operation.",0,0.8563863039016724
403374331,7170,lkokhreidze,2020-04-03T22:55:41Z,i'll create followup ticket on that.,0,0.9867009520530701
403374552,7170,lkokhreidze,2020-04-03T22:56:35Z,"yes, thanks for reminding me. was meaning to do it.",1,0.880011796951294
403449003,7170,lkokhreidze,2020-04-04T09:36:26Z,done,0,0.9764507412910461
404993384,7170,vvcephei,2020-04-07T17:39:46Z,"yeah, i'd agree with checking as early as possible in the special cases where we can know the partition counts statically. but also agree with doing it in a follow-on ticket, since it's kind of a nice-to-have.",0,0.7119927406311035
404994770,7170,vvcephei,2020-04-07T17:42:00Z,"i had a similar thought, that it looks like good fodder for unit testing, but i did like the safety blanket of verifying the actual partition counts. i guess i'm fine either way, with a preference for whatever is already in the pr ;)",1,0.975678563117981
406532074,7170,mjsax,2020-04-09T23:34:00Z,"yeah. was just a general inquire and we don't really have a guideline for it... if you are interested, it would be great to draft some guidelines (maybe just for kafka streams first, and we could propose them for other client apis, later) as a wiki page and we could discuss them on the dev mailing list?",0,0.8777554631233215
406532691,7170,mjsax,2020-04-09T23:36:34Z,cool. did you create a ticket already? (just want to make sure we don't drop this on the floor.),1,0.9766255617141724
406532989,7170,mjsax,2020-04-09T23:37:44Z,ok. thanks for clarifying.,1,0.6942946314811707
406533537,7170,mjsax,2020-04-09T23:39:49Z,i guess that is fair. (i just try to keep test runtime short if we can -- let's keep the integration test.),0,0.8729293942451477
406533774,7170,mjsax,2020-04-09T23:40:52Z,thanks for clarifying!,1,0.9305846095085144
406535443,7170,mjsax,2020-04-09T23:47:20Z,"seems unnesseary complex? a simple [code block] would do, too :) (feel free to ignore the comment.)",1,0.8928908705711365
406535968,7170,mjsax,2020-04-09T23:49:15Z,"a simple [code block] would be sufficient instead of adding a constructor and those lines could go into `before()`. (as above, feel free to ignore this comment.)",0,0.9823148250579834
406839201,7170,lkokhreidze,2020-04-10T16:39:43Z,"yes, here it is [a link]",0,0.9856376051902771
406899069,7170,mjsax,2020-04-10T19:04:51Z,thank you!,1,0.9661415219306946
365485878,7884,junrao,2020-01-11T01:08:13Z,"ltc => logtoclean ? also, do we need to use another local val since ltc is only used once?",0,0.9889094233512878
365486280,7884,junrao,2020-01-11T01:12:19Z,need to change the javadoc above to currenttime.,0,0.972429633140564
365486311,7884,junrao,2020-01-11T01:12:45Z,could we add the new param to javadoc?,0,0.9884737133979797
366049275,7884,junrao,2020-01-13T21:55:01Z,"we should make it clear the difference btw retaindeletesandtxnmarkers and tombstoneretentionms. also, it's probably better to put they as adjacent params.",0,0.9877031445503235
366061210,7884,junrao,2020-01-13T22:23:48Z,"hmm, iscontrolbatchempty is a bit misleading since batch is not always a control batch.",-1,0.5281013250350952
366064567,7884,junrao,2020-01-13T22:32:30Z,retaintxnmarkers is no longer used in shoulddiscardbatch().,0,0.9822703003883362
366085895,7884,junrao,2020-01-13T23:36:42Z,"it's a bit awkward to have to pass in the same batch to two different methods iscontrolbatchempty and checkbatchretention, during filtering. i was thinking that perhaps that we could just combine them into a single method checkbatchretention(), which returns (batchretention, shouldsethorizon). we could then extend shoulddiscardbatch() to sth like the following. the result of shoulddiscardbatch() can then be used to build the result for checkbatchretention(). [code block]",0,0.6548363566398621
366086360,7884,junrao,2020-01-13T23:38:16Z,"we probably need to do the check based on the batch magic. if magic is >=v2, check based on the new deletehorizonms. otherwise, check based on the old approach.",0,0.987663209438324
366090028,7884,junrao,2020-01-13T23:51:19Z,"it's probably better to have the logic to determine if deletehorizonms should be set here instead of memoryrecords since it's log cleaner specific logic. i was thinking that we could extend checkbatchretention() to return (boolean, shouldsethorizon).",0,0.9838786125183105
366093839,7884,junrao,2020-01-14T00:05:55Z,"hmm, if deletehorizonset is not set, we shouldn't be deleting the tombstone. so, not sure what newbatchdeletehorizonms is intended for.",0,0.8751972317695618
366093991,7884,junrao,2020-01-14T00:06:30Z,"hmm, why are we passing in containstombstonesormarker, which is always false?",0,0.9654290080070496
366095048,7884,junrao,2020-01-14T00:10:34Z,"since deletehorizonms can be obtained from batch, it's not clear why we need to pass that in as a param.",0,0.9780278205871582
366098944,7884,junrao,2020-01-14T00:25:10Z,"i am not sure about this. a round of cleaning can be expensive since we need to read in all existing cleaned segments. that's why by default, we only trigger a round of cleaning if the dirty portion of the log is as large as the cleaned portion. not sure if it's worth doing cleaning more aggressively just to remove the tombstone. so, perhaps we can leave it outside of this pr for now.",0,0.5030641555786133
367151238,7884,ConcurrencyPractitioner,2020-01-15T22:56:48Z,"yep, done so.",0,0.9795750975608826
367151276,7884,ConcurrencyPractitioner,2020-01-15T22:56:54Z,done.,0,0.9759407639503479
367152424,7884,ConcurrencyPractitioner,2020-01-15T23:00:16Z,"oh, this is used as a means to help the tests in logcleanertest.scala pass. logcleanertest usually wants the tombstones removed in a single pass (but that pass is usually used for setting the delete horizon ms, which means without doing the above, we would be unable to remove tombstones). therefore, by adding the [code block] argument (which is passed in by memoryrecords), whenever logcleaner calls clean log with the current time marked as [code block], we will be able to remove the tombstones / control records in one pass.",0,0.9867714047431946
367152628,7884,ConcurrencyPractitioner,2020-01-15T23:00:52Z,"oh, i can remove that.",0,0.9801080822944641
367153616,7884,ConcurrencyPractitioner,2020-01-15T23:03:46Z,"oh, look in comment above. this delete horizon is used for the case where we want to remove the tombstones in a single pass. on the first iteration of log cleaner, we are unable to remove the tombstone because no delete horizon has not been set yet. therefore, when we compute the delete horizon, we need to pass the delete horizon back into [code block] so that tombstones can be removed in one iteration. on second thought, i think we don't need to add an extra parameter to the [code block] method. such logic would only need to be restricted to logcleaner. i.e. we store the delete horizon in another variable in the record filter we implemented in logcleaner.",0,0.9690603613853455
367154887,7884,ConcurrencyPractitioner,2020-01-15T23:07:25Z,"i did some thinking about this. the integration test i added does not pass without this part. because what happens is that in logs with tombstones, there is the possibility that without further throughput, the cleanable logs will always be empty. therefore, as i mentioned in the comment, since we are in a low throughput situation, logcleaner's workload is relatively light anyways. in that case, we can clean tombstones since we don't have much else to do.",0,0.9599932432174683
367675732,7884,junrao,2020-01-16T22:08:25Z,tombstoneretentionms is duplicated in the javadoc.,0,0.9890226125717163
367675858,7884,junrao,2020-01-16T22:08:39Z,could we add currenttime to the javadoc?,0,0.989069402217865
367679076,7884,junrao,2020-01-16T22:17:04Z,this seems never used?,0,0.9694334864616394
367692941,7884,ConcurrencyPractitioner,2020-01-16T22:57:49Z,"there is a way to figure out whether if log cleaner has a heavy workload or not. if cleanable logs has remained empty for a long period of time (for a set threshold), then we can safely say that the log cleaner thread isn't busy since there is no logs to clean. after that threshold has passed, we can start processing logs with tombstones and removing them. this should help us know exactly when we can go back and remove tombstones.",0,0.9815686345100403
367711171,7884,junrao,2020-01-17T00:02:22Z,"perhaps, we can keep track of the largest deletehorizonms in the cleaned portion. we can then trigger a round of cleaning when the current time has passed the largest deletehorizonms.",0,0.9882651567459106
367731735,7884,junrao,2020-01-17T01:29:55Z,"i am not sure that i understand the need for overloading this and the other method. it seems that this is just so that we can remove the tombstone in one pass in the test? if so, could we just design/fix the test accordingly?",-1,0.5284929275512695
367732948,7884,junrao,2020-01-17T01:35:23Z,"hmm, i am still not sure why we need to remove a tombstone in one pass. if a tombstone's delete horizon is not set, it can't be removed in this round of cleaning.",0,0.821471631526947
371018776,7884,ConcurrencyPractitioner,2020-01-26T18:08:45Z,"yep, i realized that was probably unnecessary, so i removed it.",0,0.9635208249092102
371018800,7884,ConcurrencyPractitioner,2020-01-26T18:08:57Z,"yeah, will get rid of that.",0,0.9664740562438965
371019104,7884,ConcurrencyPractitioner,2020-01-26T18:14:07Z,"alright, acknowledged. i think thats a good point.",1,0.9064527153968811
372143661,7884,ConcurrencyPractitioner,2020-01-29T01:09:37Z,"yeah, i found that this approach probably is a lot better.",0,0.8470858931541443
374441552,7884,junrao,2020-02-04T02:08:37Z,deletehorizonms in the next line is no longer present.,0,0.9490563869476318
374442122,7884,junrao,2020-02-04T02:11:12Z,could we move this up to below retaindeletesandtxnmarkers?,0,0.989422619342804
375562926,7884,junrao,2020-02-05T23:18:14Z,it's probably better to name writeoriginalbatch here to sth like recordsfiltered since we combine other information to determine writeoriginalbatch later on.,0,0.9846928119659424
375565104,7884,junrao,2020-02-05T23:24:38Z,it seems that the logic can be simplified a bit. it seems that we can do this branch if writeoriginalbatch is true and needtosetdeletehorizon is false (`needtosetdeletehorizon = (batch magic >= v2 && containstombstonesormarker && batch's deletehorizon not set)`).,0,0.9878779649734497
376105398,7884,junrao,2020-02-06T21:58:24Z,"this may not be the best place to track latestdeletehorizon. perhaps we can return the largest deletehorizon in memoryrecords.filterto() and keep track of latestdeletehorizon in the while loop in line 713. if we do that, i am not sure if we need retrievedeletehorizon() since memoryrecords.filterto() can obtain whether deletehorizon is set from the batch and calculate the new deletehorizon if needed.",0,0.9827854037284851
376109770,7884,junrao,2020-02-06T22:08:23Z,"hmm, it seems that we only want to pass in deletehorizonms if `containstombstonesormarker && deletehorizon is not set`.",0,0.9853074550628662
376111679,7884,junrao,2020-02-06T22:12:46Z,islatestversion => supportdeletehorizon?,0,0.9860098361968994
376120400,7884,junrao,2020-02-06T22:34:58Z,could we put the common logic into a shared method to avoid duplicating most of the code below?,0,0.9856792092323303
376122666,7884,junrao,2020-02-06T22:41:04Z,this method seems unused?,0,0.9517110586166382
376122878,7884,junrao,2020-02-06T22:41:37Z,this method seems unused?,0,0.9517110586166382
376124221,7884,junrao,2020-02-06T22:45:04Z,it seems that we need to reinitialize this value at the start of each round of cleaning.,0,0.9794098138809204
376138391,7884,ConcurrencyPractitioner,2020-02-06T23:23:32Z,"oh, that's a good catch! otherwise, we might end up cleaning the logs over and over again.",1,0.9878088235855103
376142170,7884,ConcurrencyPractitioner,2020-02-06T23:35:23Z,"oh, sure, that's fine. but we also still need to account for the control batch and check whether or not it is empty yet.",0,0.9606726765632629
376147542,7884,junrao,2020-02-06T23:53:27Z,"for a control batch, it's only removed at the batch level. so, if the batch can be deleted at the batch level, we won't get in here. if the batch can't be deleted at the batch level, the record within the batch will always be retained.",0,0.9862380027770996
378016120,7884,ConcurrencyPractitioner,2020-02-12T02:54:11Z,"by current logic, this would actually break the code. since we don't pass a [code block] boolean flag into the memoryrecordsbuilder constructor, the memoryrecordsbuilder class's current logic actually relies on the passed in argument to tell if the delete horizon has been set or not. i.e. (if deletehorizonms > 0l, then we set delete horizon, else we assume that it has not been set). should i change the code correspondingly to accomadate your comment?",0,0.9701720476150513
378017124,7884,ConcurrencyPractitioner,2020-02-12T02:58:14Z,"is this always the case? if i remember correctly in the kip, control batches, if it contains only tombstones, will be persisted in the logs for a set period of time i.e. we need to at some point remove the tombstones first _before_ the control batches can be deleted. therefore, i think it would be very much possible that we need to check for [code block] here.",0,0.9824589490890503
378019351,7884,ConcurrencyPractitioner,2020-02-12T03:08:21Z,"well, i think there is multiple problems we might need to think about: 1. we don't know what the current time is since memoryrecords doesn't have access to a [code block] instance. 2. for control batches, [code block] serves a critical function: we call [code block] there to determine if we can set a delete horizon for our batch. in summation, i think that there are multiple dependencies (located in logcleaner) which must be called from [code block]. it would be more of a hassle i think if we need to figure out a way how to call all these methods from filterto as well.",0,0.8948786854743958
378046269,7884,junrao,2020-02-12T05:26:10Z,": a control batch has only a single marker record (either a commit or abort). when all records before the control batch are removed, we set the deletehorizon for the control batch. when the time passes the deletehorizon, the control batch is removed. a control batch never contains a tombstone.",0,0.9871320724487305
379089454,7884,junrao,2020-02-13T20:03:44Z,"good point on #2. my concern is that the batch could be filtered after retrievedeletehorizon() is called. then, the latestdeletehorizon maintained here won't be very accurate.",1,0.8226130604743958
379094481,7884,junrao,2020-02-13T20:14:36Z,"yes, it's just that in this pr, retrievedeletehorizon() returns deletehorizonms > 0 even for batches where deletehorizonms doesn't need to be set. then, we will be setting deletehorizonms for those batches unnecessarily.",0,0.9286094307899475
381024939,7884,junrao,2020-02-19T01:06:47Z,this batch could be filtered later in memoryrecords.filterto(). so if we maintain latestdeletehorizon here. it may not be accurate.,0,0.9760604500770569
381031162,7884,junrao,2020-02-19T01:29:53Z,"you were correct earlier that for a control marker, deletehorizon should only be set after transactional records before the marker have already been removed. so, we can't just set needtosetdeletehorizon based on containstombstonesormarker. also, i still feel that retrievedeletehorizon() is a bit weird since it mixes deletehorizonms that's already set with the deletehorizonms to be set. so, perhaps it's clearer if we instead have a method containemptymarker() that simply passes along the return value of shoulddiscardbatch(). then `needtosetdeletehorizon = batch.magic() >= 2 && (containemptymarker || containstombstones) && !batch.deletehorizonset())`. if we need to set deletehorizon, deletehorizonms can be computed off tombstoneretentionms, which can be passed into filterto().",-1,0.9399769306182861
381031270,7884,junrao,2020-02-19T01:30:19Z,it seems we should check needtosetdeletehorizon ?,0,0.9899002909660339
381454797,7884,ConcurrencyPractitioner,2020-02-19T18:15:32Z,"alright, sounds cool. this actually makes sense. i got it done.",1,0.9768595099449158
381551654,7884,junrao,2020-02-19T21:21:55Z,this check seems redundant since the caller has verified it already. we can just always return the expected deletehorizon.,0,0.9815444946289062
381552110,7884,junrao,2020-02-19T21:22:56Z,this should now be named containstombstones.,0,0.987581729888916
381554557,7884,junrao,2020-02-19T21:27:44Z,these two lines are awkward. could we pass them through the constructor of recordfilter?,-1,0.8593904376029968
381598053,7884,junrao,2020-02-19T23:03:08Z,"i am not sure that i follow the logic here. to me, the easiest way is to reset log.latestdeletehorizon at the beginning of each round of cleaning. then, we update it with the latestdeletehorizon remaining in each cleaned segment.",0,0.8469168543815613
381599279,7884,junrao,2020-02-19T23:06:12Z,"could we just fold containsemptymarker() into this method and let checkbatchretention() return (batchretention, containsemptymarker)?",0,0.9893456101417542
382869365,7884,junrao,2020-02-22T01:00:22Z,"cleansegments() just cleans a portion of the log. so, we need to reset log.latestdeletehorizon in the caller doclean().",0,0.989310622215271
383572781,7884,junrao,2020-02-24T23:20:23Z,this seems to be only used in tests. could we just create a util method in test?,0,0.987812340259552
383572822,7884,junrao,2020-02-24T23:20:32Z,firstclean is unused.,0,0.9587862491607666
383573289,7884,junrao,2020-02-24T23:21:50Z,"it would be useful to indicate that trackedhorizon is to cover tombstones in legacy message format. so, perhaps we could name it sth like legacydeletehorizonms?",0,0.987027645111084
383574205,7884,junrao,2020-02-24T23:24:38Z,discarding tombstones => discarding legacy tombstones ?,0,0.9867812991142273
383575250,7884,junrao,2020-02-24T23:27:41Z,deletion horizon => legacy deletion horizon ?,0,0.9845544695854187
383576155,7884,junrao,2020-02-24T23:30:28Z,no need for space before (.,0,0.8979650139808655
383577646,7884,junrao,2020-02-24T23:34:52Z,containsemptymarker => containsmarkerforemptytxn ?,0,0.9874217510223389
383578258,7884,junrao,2020-02-24T23:36:54Z,we can just do [code block],0,0.9881619811058044
383579725,7884,junrao,2020-02-24T23:41:45Z,this can be [code block],0,0.9880726337432861
383580041,7884,junrao,2020-02-24T23:42:55Z,it seems this can be simplified to the following? `shouldretaindeletes = !batch.deletehorizonset() || currenttime < batch.deletehorizonms()`,0,0.9823192954063416
383580335,7884,junrao,2020-02-24T23:43:50Z,retaindeletes => retaindeletesforlegacyrecords ?,0,0.9871679544448853
383581756,7884,junrao,2020-02-24T23:48:20Z,batchretentionandemptymarker => batchretentionresult ?,0,0.9862556457519531
383582417,7884,junrao,2020-02-24T23:50:19Z,the tombstones => the tombstones or txn markers,0,0.9875593781471252
383585273,7884,junrao,2020-02-24T23:59:07Z,"not sure if we need these comments. if we do need them, it seems they should be added to the implementation in logcleaner.",0,0.9790284037590027
383585606,7884,junrao,2020-02-25T00:00:14Z,"hmm, this comment seems out of place.",-1,0.6728742718696594
383619974,7884,junrao,2020-02-25T02:02:28Z,this doesn't look right. we need to track not only newly generated deletionhorizon but also existing one if the batch is kept.,0,0.776062548160553
383620136,7884,junrao,2020-02-25T02:03:11Z,batch and containsemptymarker are unused.,0,0.9824423789978027
384268522,7884,ConcurrencyPractitioner,2020-02-26T04:25:16Z,aren't we already keeping track of each individual delete horizon in each batch's first timestamp? my impression was that this result would just return the biggest delete horizon seen so far.,0,0.9792500138282776
384284272,7884,junrao,2020-02-26T05:41:46Z,": if we get into the else branch in line 210, it seems that we still need to call filterresult.updatelatestdeletehorizon() since the batch may contain deletehorizon?",0,0.9845727682113647
384597604,7884,ConcurrencyPractitioner,2020-02-26T16:10:30Z,"oh, i see. makes sense. i misunderstood what the comment was suggesting.",-1,0.7109452486038208
384611807,7884,ConcurrencyPractitioner,2020-02-26T16:30:59Z,"just a note, i actually did resolve this comment with my previous push. turns out i spotted this error while running over the code previously. just didn't realize that it actually resolved this one as well.",0,0.8427818417549133
384793024,7884,junrao,2020-02-26T21:59:46Z,retaindeletesandtxnmarkers => retainlegacydeletesandtxnmarkers ?,0,0.9859091639518738
384795228,7884,junrao,2020-02-26T22:04:17Z,batchretentionandemptymarker => batchretentionresult ?,0,0.9862556457519531
384804732,7884,junrao,2020-02-26T22:24:41Z,"if we get in here, it could be that this batch already has deletehorizon set. if we pass in recordbatch.no_timestamp to buildretainedrecordsinto(), we will lose the deletehorizon. so, we need to pass in the existing deletehorizon to buildretainedrecordsinto() and also reflect that deletehorizon in filterresult.",0,0.9873846769332886
384806582,7884,junrao,2020-02-26T22:28:41Z,typo thoroughput,0,0.986663818359375
384810439,7884,junrao,2020-02-26T22:37:28Z,we probably don't need to assert this since we explicitly inserted some tombstones.,0,0.9805200695991516
384810766,7884,junrao,2020-02-26T22:38:17Z,"to avoid transient failures, we probably want to give long enough maxwaitms, sth like 5 secs.",0,0.9747105836868286
384811017,7884,junrao,2020-02-26T22:38:53Z,this seems unnecessary since we are waiting in cleaner.awaitcleaned() already later.,0,0.9833759665489197
384811420,7884,junrao,2020-02-26T22:39:55Z,this seems to be a complicated way of getting latestoffset. we could just do log.logendoffset.,0,0.7795260548591614
384818440,7884,junrao,2020-02-26T22:56:55Z,"the value of the map is an offset. so, it's weird to put in deletehorizon as the value. also, there seems to be an existing issue with the test. it seems that shouldremain in line 90 should be computed before line 89.",-1,0.9693222641944885
384827619,7884,junrao,2020-02-26T23:22:15Z,"why do we need to set current time to long.maxvalue - tombstoneretentionms - 1? for verifying the removal of the tombstone, it's clearer if we set the currenttime in mocktime before the first round of cleaning and then explicit set current time to be tombstoneretentionms longer than that currenttime in a subsequent round of cleaning to verify that the tombstone is removed. ditto below.",0,0.9824322462081909
384829410,7884,junrao,2020-02-26T23:27:43Z,could we add a comment on why we need two passes?,0,0.9835748672485352
384835414,7884,junrao,2020-02-26T23:46:13Z,"since there is no marker, it seems that containsmarkerforemptytxn should be false.",0,0.9769096374511719
384835749,7884,junrao,2020-02-26T23:47:16Z,"since there is no marker, it seems that containsmarkerforemptytxn should be false.",0,0.9769096374511719
384835973,7884,junrao,2020-02-26T23:48:03Z,"since there is no marker, it seems that containsmarkerforemptytxn should be false.",0,0.9769096374511719
384837927,7884,junrao,2020-02-26T23:54:01Z,could we use recordbatch.no_timestamp instead of -1l?,0,0.9897421598434448
384848752,7884,ConcurrencyPractitioner,2020-02-27T00:28:59Z,"this was one part of the test which i had some problems with. notably, what happens is that we will try to calculate the delete horizon using long.maxvalue as the current time. inherently, an integer overflow error will occur (and we end up with some very low negative number). therefore, i thought that we can get around it by setting the delete horizon to some value which would not have problems with overflow (hence largedeletehorizon having the above value you mentioned.)",0,0.933190107345581
384854011,7884,ConcurrencyPractitioner,2020-02-27T00:46:54Z,"yeah, it definitely is inconsistent with other tests in that there is a thread.sleep(). problem is that this test seems prone to be somewhat flaky. without the sleep, at the present state, it definitely fails.",-1,0.9016039371490479
384855964,7884,ConcurrencyPractitioner,2020-02-27T00:53:07Z,"also, about setting mock time. mock time is in fact never called in doclean. it is called in just clean(). the currenttime supplied to doclean is from clean(). so what you stated probably only applies to methods which call the regular clean() method.",0,0.98589688539505
385391824,7884,junrao,2020-02-27T21:50:31Z,"instead of sleeping, it's more reliable to just do cleaner.awaitcleaned() and assert the return value to be true.",0,0.9837089776992798
385393585,7884,junrao,2020-02-27T21:54:21Z,"hmm, in the previous round of cleaning, the dirty offset is already moved to log.logendoffset. so, this call seems to also hit the timeout. another way is to do testutils.waituntiltrue(log.size() == 0). then, we don't need the code in line 214 to 216.",0,0.9870882034301758
385402234,7884,junrao,2020-02-27T22:13:38Z,"if we set currenttime to largedeletehorizon in the previous round of cleaning, we need to set the current time to long.maxvalue - 1 in order for the marker to be removed.",0,0.988390326499939
385409940,7884,junrao,2020-02-27T22:31:37Z,it doesn't seem that we need to convert this to runtwopassclean().,0,0.9832788109779358
385409985,7884,junrao,2020-02-27T22:31:43Z,it doesn't seem that we need to convert this to runtwopassclean().,0,0.9832788109779358
385410725,7884,junrao,2020-02-27T22:33:33Z,it seems this is a case that we should use runtwopassclean().,0,0.9875662326812744
385412064,7884,junrao,2020-02-27T22:37:09Z,it seems that currenttime should be set to long.maxvalue - 1 to make sure the record still remains after the deletehorizon.,0,0.9875373244285583
385414150,7884,junrao,2020-02-27T22:42:40Z,"it's clearer if we set currenttime to largedeletehorizon here and in the second round of cleaning, set currenttime to long.maxvalue - 1. we also want to change the comment above accordingly.",0,0.9870582222938538
385414334,7884,junrao,2020-02-27T22:43:11Z,"in this case, it seems that one round of doclean() is enough.",0,0.9840600490570068
385416143,7884,junrao,2020-02-27T22:48:06Z,"similar here. if we set currenttime to largedeletehorizon in the first round cleaning, we can just do one round of cleaning with currenttime set to long.maxvalue - 1 and the first marker should be removed.",0,0.9867101311683655
385418628,7884,junrao,2020-02-27T22:55:11Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9870426654815674
385419500,7884,junrao,2020-02-27T22:57:42Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9870426654815674
385419989,7884,junrao,2020-02-27T22:58:59Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9870426654815674
385420266,7884,junrao,2020-02-27T22:59:48Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9870426654815674
385420579,7884,junrao,2020-02-27T23:00:44Z,no need for this change since recovery point is not related to deletehorizon.,0,0.9854546785354614
385420800,7884,junrao,2020-02-27T23:01:15Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9870426654815674
385420835,7884,junrao,2020-02-27T23:01:21Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9870426654815674
385420853,7884,junrao,2020-02-27T23:01:26Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9870426654815674
385422158,7884,junrao,2020-02-27T23:05:04Z,"perhaps it's clearer with ""on the first run, set the delete horizon in the batches with tombstone or markers with empty txn records.""",0,0.9842531085014343
385429375,7884,junrao,2020-02-27T23:27:13Z,"with this pr, we can set currenttime to largedeletehorizon and the marker should still be preserved. we can change the comment above accordingly.",0,0.9860215783119202
385841515,7884,junrao,2020-02-28T18:03:18Z,let's assert that the return value is true.,0,0.9851190447807312
385841874,7884,junrao,2020-02-28T18:04:07Z,this is unnecessary given the waituntiltrue() below.,0,0.9716852307319641
385843938,7884,junrao,2020-02-28T18:09:10Z,"we can be more generous with waittimems. so, using the defaults for both waittimems and pause is probably fine.",0,0.5425836443901062
385848945,7884,junrao,2020-02-28T18:20:20Z,"this is still a bit confusing. could we define 2 vals, beforedeletehorizon and afterdeleteionhorizon? the former takes long.maxvalue - tombstoneretentionms - 1 and the latter takes long.maxvalue. the comment can be changed to sth like ""current time is still before deletehorizon"". it would be useful to do this consistently across other tests.",0,0.7550865411758423
385851682,7884,junrao,2020-02-28T18:26:00Z,the previous comment was not addressed. it doesn't seem that we need to convert this to runtwopassclean().,0,0.9835410714149475
385854943,7884,junrao,2020-02-28T18:32:59Z,"in this case, it seems that one round of doclean() is enough as long as we set currenttime to postdeletehorizon.",0,0.9874338507652283
385855310,7884,junrao,2020-02-28T18:33:46Z,"similar here. if we set currenttime to largedeletehorizon in the first round cleaning, we can just do one round of cleaning with currenttime set to long.maxvalue - 1 and the first marker should be removed.",0,0.9867101311683655
386758173,7884,junrao,2020-03-03T01:56:04Z,"could we add the following comment above? ""the deletehorizon for {producer2: commit} is still not set yet.""",0,0.988298237323761
386758582,7884,junrao,2020-03-03T01:57:36Z,"could we add the following comment above? ""in the first pass, the deletehorizon for {producer2: commit} is set. in the second pass, it's removed.""",0,0.9889188408851624
388490888,7884,junrao,2020-03-05T18:49:32Z,"could we add the following comment? ""in the first pass, deletehorizon is set for the abort marker. in the second pass, the abort marker is removed.",0,0.9890357851982117
388507941,7884,junrao,2020-03-05T19:18:44Z,we could just use one pass of cleaning with currenttime = long.maxvalue.,0,0.9816046953201294
388509040,7884,junrao,2020-03-05T19:20:36Z,"could we add the following comment? ""in the first pass, the deletehorizon for the commit marker is set. in the second pass, the commit marker is removed, but the empty batch is retained for preserving the producer epoch.""",0,0.9886154532432556
388511801,7884,junrao,2020-03-05T19:25:20Z,"could we change the comment to the following? ""aborted records are removed, but the abort marker is still preserved.""",0,0.9871780872344971
388512379,7884,junrao,2020-03-05T19:26:18Z,"could we change the comment to the following? ""in the first pass, the delete horizon for the abort marker is set. in the second pass, the abort marker is removed.""",0,0.9880288243293762
388514252,7884,junrao,2020-03-05T19:29:45Z,"could we change the comment to the following? ""in the first pass, the delete horizon for the first marker is set. in the second pass, the first marker is removed.""",0,0.9880645871162415
388516416,7884,junrao,2020-03-05T19:34:06Z,this can just be one pass cleaning with currenttime = largetimestamp.,0,0.988439679145813
388517353,7884,junrao,2020-03-05T19:35:57Z,"could we add the following comment? ""in the first pass, the delete horizon for the abort marker is set. in the second pass, the abort marker is removed.""",0,0.9882078766822815
391180372,7884,hachikuji,2020-03-11T18:32:07Z,why don't we move these into `abstractlegacyrecordbatch`?,0,0.9779887795448303
391184841,7884,hachikuji,2020-03-11T18:40:03Z,nit: can we use `hasdeletehorizonms`. another option would be to make `deletehorizonms` return an optional long.,0,0.9889904260635376
391187776,7884,hachikuji,2020-03-11T18:45:22Z,"hmm.. it seems a bit brittle to rely on documentation for this. i'm considering if we should change names to better reflect this. for example, maybe we should call this `basetimestamp` and add a new method for `firstrecordtimestamp` or something like that.",-1,0.5818004012107849
391189939,7884,hachikuji,2020-03-11T18:49:05Z,nit: why don't we initialize the variables here? e.g. [code block],0,0.980983316898346
391190505,7884,hachikuji,2020-03-11T18:50:08Z,nit: no need for parenthesis,0,0.9782740473747253
391194791,7884,hachikuji,2020-03-11T18:57:46Z,why do we pass `writeoriginalbatch` here? its value is always `true`.,0,0.9839770197868347
391198263,7884,hachikuji,2020-03-11T19:04:26Z,"if we are not retaining this record, then records have been filtered, so shouldn't `recordsfiltered` be true? the original code used `writeoriginalrecord` instead of `recordsfiltered`, which seems clearer to me. even `batchiterationresult` still preserves the original name.",0,0.9869306087493896
391199350,7884,hachikuji,2020-03-11T19:06:43Z,i think we can name this more specifically to its usage in filtering. perhaps call it `batchfilterresult` or something.,0,0.9865868091583252
391199694,7884,hachikuji,2020-03-11T19:07:21Z,nit: fix alignment,0,0.9872499108314514
391200796,7884,hachikuji,2020-03-11T19:09:30Z,maybe we can call this `filterbatch`,0,0.9857675433158875
391203869,7884,hachikuji,2020-03-11T19:15:37Z,"i guess this should take into account the magic version? if the magic version is older than v2, i think this should return false?",0,0.9846605658531189
391204835,7884,hachikuji,2020-03-11T19:17:28Z,not sure why current time needs to be passed through here. are you trying to save an extra call to `time.milliseconds()` or something?,0,0.9155663847923279
391205039,7884,hachikuji,2020-03-11T19:17:53Z,i think `deleteretentionms` would be a better name since it is more general than tombstone cleanup.,0,0.9825125932693481
391224340,7884,hachikuji,2020-03-11T19:54:15Z,i'm trying to understand why we need to collect this from `checkbatchretention`. why don't we collect this in `iterateoverbatch` as we do for `containstombstones`?,0,0.9692256450653076
391228346,7884,hachikuji,2020-03-11T19:58:33Z,we are only updating `firsttimestamp` when a record gets appended. does that mean we cannot create an empty batch with the delete horizon set? i would expect that the constructor would initialize `firsttimestamp` to `deletehorizonms` if it is greater than 0.,0,0.9873340129852295
391239196,7884,hachikuji,2020-03-11T20:10:52Z,"note that `batchretention` is an enum. if there is some state that it is not sufficient to capture, then we can add a new state.",0,0.987854540348053
391331852,7884,ConcurrencyPractitioner,2020-03-11T23:46:09Z,"yeah, record filter seemed to be the most convenient medium through which we can pass the current time. i don't want to pass in the time instance, so i just passed the time here.",0,0.9753597378730774
391334367,7884,ConcurrencyPractitioner,2020-03-11T23:54:47Z,"ah, perhaps i should've some comments to indicate what is going on. if you would look through the [code block] implementation, you would note that [code block] must be called to determine if the control batch is empty. and the content of that call is stored in containsmarkerforemptytxn. furthermore, this value is crucial for [code block] to function correctly (as it needs to know if the control batch can be removed). therefore, what we decided to do, is that we call oncontrolbatchread at the beginning of checkbatchretention and return it along with the batchretention enum (as we will need to use containsmarkerforemptytxn later for checking whether or not we retain individual records.)",0,0.9630071520805359
391335870,7884,ConcurrencyPractitioner,2020-03-12T00:00:22Z,acknowledged. the name is a bit contradictory with its value assignments.,0,0.5835921168327332
391336806,7884,ConcurrencyPractitioner,2020-03-12T00:03:40Z,"if i am understanding this correctly, an empty batch does not contain tombstones, right? if we append a tombstone as the first record, then the delete horizon will be set. but if there isn't any tombstones, there isn't any delete horizon to set. so how would we set a delete horizon for an empty batch?",0,0.9816036224365234
393876656,7884,ConcurrencyPractitioner,2020-03-17T18:12:54Z,"oh, sorry about the misunderstanding. i see what you mean by that now. you're right. i should take this into account.",-1,0.9860953688621521
393880203,7884,ConcurrencyPractitioner,2020-03-17T18:18:41Z,"good point, version checking would be needed.",1,0.9156211614608765
108020004,2735,hachikuji,2017-03-24T23:58:22Z,i think we should consider turning off `parameternumber` check if we're just going to keep increasing it.,0,0.9835905432701111
108020604,2735,hachikuji,2017-03-25T00:07:22Z,the name seems like it could be a source of confusion. i wonder if we should rename this to something like `pidstate` or `produceridstate` and maintain the actual transaction state separately? do you think the coupling will be so tight that they will need to be tracked in the same class?,0,0.8340328931808472
108021095,2735,hachikuji,2017-03-25T00:15:06Z,i think this comment is out of date.,0,0.6372285485267639
108021197,2735,hachikuji,2017-03-25T00:16:57Z,"i wonder if we should require the string to be null or non-empty. in guozhang's current tc patch, we treat the empty string the same as null, but maybe we shouldn't actually allow the client to send an empty string? seems doing so would be more likely to cause problems than not.",0,0.8473137617111206
108027736,2735,apurvam,2017-03-25T04:24:37Z,"yes. we should not allow empty strings imo. my transactional producer patch treats an empty transactionalid as being 'unset', and i think it makes sense to enforce that across the board.",0,0.9785410761833191
108027961,2735,apurvam,2017-03-25T04:39:37Z,"i don't know what a good name is for this. it currently maintains the `pidandepoch` and the pid->sequence number mappings. eventually, it will also store the transactional id, whether there is an active transaction, and the partitions belonging to the currently active transaction. there is no real coupling between the latter transactional state and the sequence number tracking except for the `pidandepoch`. as such, if we want to separate them, then a clean separation would require 3 classes. my preference would be to keep them all together, and just call it `transactionstate` or `transactionalstate`.",0,0.910207986831665
108027985,2735,apurvam,2017-03-25T04:40:57Z,"i think there is still some value in keeping this check. the reason the number is being bumped here is because the sender constructor has added an argument. the solution would be to have a builder, but then a builder doesn't make sense for the sender. it may make sense to just exempt the `sender` for this check, but i am not sure if that is possible.",0,0.9275620579719543
108027989,2735,apurvam,2017-03-25T04:41:04Z,"i think we should modify this check and throw an `illegalstateexception` if we try to set producer state after the batch is closed, as that should never happen with the current code.",0,0.9852966666221619
108296196,2735,hachikuji,2017-03-27T22:29:39Z,"this should either be `>` or `>= 0`. we could also move this check to the caller. either way, we probably need a test case.",0,0.9875785708427429
108311921,2735,apurvam,2017-03-28T00:32:34Z,this is now fixed.,0,0.9832003116607666
108311947,2735,apurvam,2017-03-28T00:32:54Z,i have addressed this.,0,0.9756816029548645
108320177,2735,hachikuji,2017-03-28T02:00:26Z,we seem to have lost this comment.,0,0.517742395401001
108558825,2735,ijuma,2017-03-28T23:06:29Z,"hmm, are we going to remove these methods before we merge this pr?",0,0.9842012524604797
108558953,2735,ijuma,2017-03-28T23:07:18Z,this seems unused?,0,0.9358466863632202
108559235,2735,apurvam,2017-03-28T23:08:55Z,"yes.. i am about to push changes that removes these, here and in other places.",0,0.8374311923980713
108559389,2735,apurvam,2017-03-28T23:10:03Z,good catch. it was added during the initial implementations to generate pids before the server side code was ready.,1,0.9766612648963928
108571037,2735,junrao,2017-03-29T00:43:59Z,it doesn't seem time is being used.,0,0.7022815942764282
108571055,2735,junrao,2017-03-29T00:44:11Z,"log entry => record batch. perhaps it's clearer to say records received in the follower, instead of replication.",0,0.9875389337539673
108571063,2735,junrao,2017-03-29T00:44:17Z,"hmm, not sure why we need to expire the ids before the dirty offset.",0,0.8179388046264648
108571083,2735,junrao,2017-03-29T00:44:25Z,"it seems that the snapshots are created under a dir named topic-partition. so, it seems we don't need to include ${topicpartition.topic}-${topicpartition.partition} here?",0,0.9877564907073975
108571107,2735,junrao,2017-03-29T00:44:31Z,is this needed since we already did that during initialization of the class?,0,0.986206591129303
108571120,2735,junrao,2017-03-29T00:44:35Z,"it doesn't seem that we are returning a value. if so, we want to remove =.",0,0.963088870048523
108571134,2735,junrao,2017-03-29T00:44:41Z,probably log initpidrequest too?,0,0.9895110726356506
108571140,2735,junrao,2017-03-29T00:44:43Z,we will need to check if the request is authorized.,0,0.9840784072875977
108577375,2735,junrao,2017-03-29T01:54:04Z,"in replicafetcherthread, we probably want to log a warning if logappendinfo.isduplicate is true after the append() call since it's not expected.",0,0.9891590476036072
108577383,2735,junrao,2017-03-29T01:54:12Z,do we need this? it seems that we already validate this in producerequest.validaterecords() when the broker receives the produce request.,0,0.9893596172332764
108577397,2735,junrao,2017-03-29T01:54:23Z,could we make it clear that the latter epoch is the server epoch?,0,0.9873064756393433
108577429,2735,junrao,2017-03-29T01:54:37Z,should we do the same check for expiration when loading a snapshot?,0,0.9869545102119446
108577433,2735,junrao,2017-03-29T01:54:41Z,what is a base name?,0,0.9809808731079102
108577476,2735,junrao,2017-03-29T01:55:14Z,it doesn't seem that we have the logic to take snapshots periodically since this method is only called from tests?,0,0.9595921635627747
108577487,2735,junrao,2017-03-29T01:55:18Z,remove after?,0,0.9797859787940979
108593416,2735,apurvam,2017-03-29T05:23:32Z,"it is actually the producer epoch which is stale in this case, but will clarify the exception message.",0,0.9859994053840637
108593532,2735,apurvam,2017-03-29T05:24:58Z,"good catch, will add a periodic cleaner task.",1,0.9247733354568481
108593569,2735,apurvam,2017-03-29T05:25:31Z,i added a jira to track this in a future pr: [a link],0,0.9844986796379089
108730187,2735,junrao,2017-03-29T16:57:16Z,"it would be inconvenient for a user to have to configure 2 other properties after enabling idempotence. perhaps we could set these 2 values to a reasonable default (e.g., 3 retries) if the user doesn't configure these properties explicitly. if the user explicitly set those properties with an incorrect value, we can then throw an exception.",0,0.9631593227386475
108730238,2735,junrao,2017-03-29T16:57:24Z,"hmm, in sendandawaitinitpidrequest(), we just initiate a pid request w/o checking if we actually can send to the node. not sure if this is safe. networkclient also sends internal metadata request. so, it's possible that an ongoing metadata request is still pending on the same node and the send of pid request will hit an illegalstateexception in networkclient.dosend().",0,0.9733480215072632
108746944,2735,hachikuji,2017-03-29T18:07:27Z,nit: `is true` seems redundant.,0,0.930877685546875
108747353,2735,hachikuji,2017-03-29T18:09:15Z,discussed offline. we agreed it's not actually necessary to block here since the sequence number is not assigned until the batch is ready to be sent anyway.,0,0.9830143451690674
108751964,2735,apurvam,2017-03-29T18:28:51Z,it seems to be called from `kafkaserver.scala:236`,0,0.9832392334938049
108758172,2735,apurvam,2017-03-29T18:53:31Z,not sure i follow. the `producerequest.validaterecords` just checks that the right message format goes with the right version. this check further validates that there is exactly one `recordbatch` in a produce request with the new message format. seems to me that the checks complement each other.,0,0.9805988073348999
108763087,2735,junrao,2017-03-29T19:15:17Z,"producerequest.validaterecords() has the following, right? [code block]",0,0.9876591563224792
108763450,2735,junrao,2017-03-29T19:16:51Z,"apply() is being called, but is time actually being used?",0,0.9826013445854187
108764029,2735,apurvam,2017-03-29T19:19:39Z,you are right. will delete this check.,0,0.945460319519043
108764889,2735,apurvam,2017-03-29T19:23:53Z,"ah. so this is a reduced version of the class in the transactions branch. `time` is used in the `transactionstatemanager`, which is instantiated in the apply method.",0,0.9881689548492432
108766424,2735,apurvam,2017-03-29T19:31:23Z,good catch. deleted.,1,0.9575356841087341
108783378,2735,hachikuji,2017-03-29T20:49:21Z,this is no longer used.,0,0.8691840171813965
108784158,2735,hachikuji,2017-03-29T20:52:32Z,"now that we've merged the crc32c patch, we may as use that.",0,0.9874007105827332
108788282,2735,apurvam,2017-03-29T21:10:42Z,i think this comment is outdated. i updated with the actual logic. the snapshot files will be located inside a `pid-mapping` subdirectory of the log directory. the files themselves will be named with the pattern `$lastoffset.snapshot`.,0,0.9442839622497559
108793143,2735,junrao,2017-03-29T21:34:12Z,"not sure if we strictly needs to iswriteable. currently, during append(), if the current producerbatch is full, we just create a new batch.",0,0.9809576272964478
108822679,2735,apurvam,2017-03-30T01:09:32Z,"actually, i undeleted these lines as they are needed. the `loadsnapshot` can be called in two cases: during initial start, and also when the log is truncated. in the latter case, if there is no previous snapshot, we need to reset to the start offset, which is what this code does.",0,0.9870839715003967
108841803,2735,apurvam,2017-03-30T05:05:10Z,"i have implemented this. the silght modification is that since the only invalid retries config is 0, which is the default, i just override the default to 3 when idempotence is enabled.",0,0.9894640445709229
108842422,2735,apurvam,2017-03-30T05:14:16Z,i just deleted this block from the producer.,0,0.977395236492157
108844057,2735,apurvam,2017-03-30T05:35:50Z,"hmm. you may be right. the reason i introduced `iswritable` is because we can no longer close a batch when it is full. we can only close it at the point of sending in order to set the right sequence number. so i introduced `iswritable` to denote the state where it can no longer take appends, but is not closed. your point is valid: once a batch is considered full for a particular append, no future appends should go to it since there will be another batch at the tail which should get the new appends.",0,0.9277573823928833
108844701,2735,apurvam,2017-03-30T05:42:24Z,"so, looking over it a bit more, i now know why i introduced `iswritable`. the `isfull` method is not only used during append. it is also used to wake the sender up: if the deque is of size one and the only batch in there is not full, the sender will not be woken up to drain until it hits the linger ms. by introducing `iswritable` we can get the batch to be drained slightly quicker. not sure if the extra state is worth that optimization though.",0,0.9520303606987
108957136,2735,junrao,2017-03-30T15:26:11Z,"hmm, in recordaccumulator.append(), we return the following. so if the current batch doesn't have enough space, we will create another one. then dq.size() will be > 1 and isfull will be true anyway. `return new recordappendresult(future, dq.size() > 1 || batch.isfull(), true);`",0,0.9793603420257568
108990172,2735,apurvam,2017-03-30T17:40:56Z,yes. that makes sense. i will drop `iswritable`.,0,0.9799792766571045
108999545,2735,apurvam,2017-03-30T18:18:17Z,i have added this log line.,0,0.9871155023574829
109008262,2735,apurvam,2017-03-30T18:53:33Z,"synced offline, and we agreed this isn't a real problem since both `getreadynode` and `sendandawaitinitpidrequest` call poll. this will mean than any outstanding requests will get a chance to be processed there will be no deadlock.",0,0.9765928983688354
109035640,2735,junrao,2017-03-30T20:57:34Z,a more reliable way to check if a user explicitly sets the config is to check from config.originals(). ditto for configureretries().,0,0.9794115424156189
109035825,2735,junrao,2017-03-30T20:58:23Z,should we add the comment for isduplicate too?,0,0.9849854707717896
109035966,2735,junrao,2017-03-30T20:58:57Z,perhaps we should default to 2 to increase the chance that we can rebuild from a snapshot after truncation?,0,0.98263019323349
109036428,2735,junrao,2017-03-30T21:01:07Z,it seems this method is never called?,0,0.9683615565299988
109036442,2735,junrao,2017-03-30T21:01:10Z,"lasttimestamp => maxtimestamp? also, probably add some comments to make it clear that firstseq, lastseq lastoffset and lasttimestamp refer to what's in the last appended batch?",0,0.9887201189994812
109036449,2735,junrao,2017-03-30T21:01:12Z,remove () to be consistent with how we call other methods?,0,0.9781118631362915
109045847,2735,hachikuji,2017-03-30T21:46:55Z,we should probably mention in the docs that enabling idempotence will change the default configurations for retries and in-flight requests. i think it might also be worth adding at least a `debug` level log message in the code that we are overriding the defaults.,0,0.9828181266784668
109046583,2735,hachikuji,2017-03-30T21:51:11Z,do we have a test case for this?,0,0.9838167428970337
109047045,2735,hachikuji,2017-03-30T21:53:33Z,"nit: we might want to spell out ""producerid"" in log messages, so there's no potential for confusion.",0,0.9803808331489563
109047372,2735,hachikuji,2017-03-30T21:55:32Z,"given that this class will be used to maintain transactional state as well, perhaps we should use a more explicit name. for example, `resetproducerid`, or maybe `invalideproducerid`.",0,0.9882850646972656
109047769,2735,hachikuji,2017-03-30T21:57:49Z,we shouldn't need a placeholder for the exception unless the intention is to not print the stack trace.,0,0.9825829267501831
109048485,2735,hachikuji,2017-03-30T22:01:48Z,maybe we can add the pids to the exception message?,0,0.9870398640632629
109048510,2735,hachikuji,2017-03-30T22:01:59Z,nit: move to previous line,0,0.9848797917366028
109048622,2735,hachikuji,2017-03-30T22:02:28Z,nit: this could be `else if`?,0,0.988086462020874
109049954,2735,hachikuji,2017-03-30T22:10:34Z,"we don't have to do it here, but we should make these messages a bit more user-friendly. for example, here we should mention the fact that an old epoch means that this process is probably a zombie and another producer has taken over.",0,0.9657223224639893
109050497,2735,hachikuji,2017-03-30T22:13:57Z,replace log entries with record batches,0,0.9854421615600586
109050709,2735,ijuma,2017-03-30T22:15:09Z,"i don't have all the context, but isn't `3` pretty low? we don't do exponential back-offs, so the recommendation for no data loss is typically higher.",0,0.9519596099853516
109050957,2735,apurvam,2017-03-30T22:16:37Z,what is the recommendation for no data loss?,0,0.983913242816925
109051026,2735,hachikuji,2017-03-30T22:17:01Z,can we list the possible errors in a comment like we do for other responses?,0,0.9848494529724121
109051149,2735,hachikuji,2017-03-30T22:17:52Z,"we can assert the epoch also? also, this is backwards: the expected value should be listed first.",0,0.9871375560760498
109051741,2735,hachikuji,2017-03-30T22:21:48Z,"i was looking for a test case which verified that the producer pid, epoch, and sequence number are set correctly in the records included with the produce request (e.g. using a `requestmatcher`). do we have one?",0,0.9866499304771423
109051933,2735,hachikuji,2017-03-30T22:22:54Z,what are we aborting? can you clarify in the name?,0,0.9781798124313354
109052070,2735,hachikuji,2017-03-30T22:23:48Z,missing a test case for `reset`?,0,0.944629967212677
109052173,2735,hachikuji,2017-03-30T22:24:29Z,nit: the convention we're using elsewhere is `pid`. same below.,0,0.9868773818016052
109052264,2735,hachikuji,2017-03-30T22:25:01Z,nit: we could probably `import networkclientutils._`,0,0.9786763787269592
109052858,2735,hachikuji,2017-03-30T22:28:31Z,might be a good idea to keep this private. we could add an `increment` method instead of writing to the field directly from external classes.,0,0.9565820693969727
109053045,2735,hachikuji,2017-03-30T22:29:47Z,nit: can we make this `producerid manager`?,0,0.9881340861320496
109053126,2735,hachikuji,2017-03-30T22:30:15Z,nit: no need for the type on the left-hand side.,0,0.9844369888305664
109054302,2735,hachikuji,2017-03-30T22:37:56Z,nit: no need for type on lhs.,0,0.984204113483429
109054659,2735,hachikuji,2017-03-30T22:40:34Z,nit: we can assign `batch.lastoffset - batch.baseoffset +1` to a local variable so it's easier to understand.,0,0.9880196452140808
109054856,2735,hachikuji,2017-03-30T22:41:57Z,why was the comment moved here?,0,0.9342234134674072
109054973,2735,hachikuji,2017-03-30T22:42:36Z,probably we should add something to the comment above about doing pid validation.,0,0.9852702021598816
109055788,2735,hachikuji,2017-03-30T22:47:51Z,"might be worth mentioning that the loop will only iterate once for a duplicate client request to be clear that the values below will not be overwritten. would be nice if we could just break, but alas.",0,0.49976861476898193
109055870,2735,hachikuji,2017-03-30T22:48:25Z,`warn` seems a bit high. could this be `debug`?,0,0.9829434156417847
109056087,2735,apurvam,2017-03-30T22:49:50Z,"actually, this is called from `produceridmappingtest.checkandupdate`. not sure why the ide doesn't find the usage, but the compiler definitely does!",0,0.9638984799385071
109056104,2735,apurvam,2017-03-30T22:49:57Z,changed the name and added a comment.,0,0.9834598898887634
109056127,2735,hachikuji,2017-03-30T22:50:08Z,is this config part of the kip? do we really need it? i know we had discussed at one point just using a reasonable default.,0,0.9836713075637817
109056174,2735,apurvam,2017-03-30T22:50:31Z,good point. i think an `info` level log would be even more appropriate.,1,0.8976133465766907
109056729,2735,hachikuji,2017-03-30T22:54:13Z,"not clear what a ""valid"" entry is. maybe the check should be inverted and phrased as `hasentryexpired`?",0,0.9554223418235779
109057025,2735,hachikuji,2017-03-30T22:56:19Z,seems this loop would be a little clearer if we just built a list of the snapshot files sorted by offset and iterated over it?,0,0.9855940937995911
109057203,2735,hachikuji,2017-03-30T22:57:30Z,"one thing i was thinking about (for another patch) is whether we should have like a minimum number of messages before it's worth doing another snapshot. if only 5 messages have been written since the last snapshot, for example, maybe we can just skip the new snapshot.",0,0.9685781002044678
109057493,2735,hachikuji,2017-03-30T22:59:29Z,was this intentional?,0,0.8377997875213623
109057570,2735,hachikuji,2017-03-30T23:00:02Z,not sure why the variable name was changed: `error` is more accurate.,0,0.9300058484077454
109058568,2735,hachikuji,2017-03-30T23:06:48Z,nit: you can use `fail` instead,0,0.9854385852813721
109058879,2735,hachikuji,2017-03-30T23:09:10Z,nit: seems convention is to have spaces before and after `=`?,0,0.984491765499115
109062426,2735,ijuma,2017-03-30T23:38:20Z,"i don't think we should split the logic between this and `shouldretainmessage`. for example, the latter already checks `record.iscontrolrecord`.",0,0.983996570110321
109065402,2735,apurvam,2017-03-31T00:05:33Z,just added one.,0,0.9846596717834473
109065473,2735,apurvam,2017-03-31T00:06:10Z,ok will update as and when i see them. updated this one.,0,0.984941840171814
109066830,2735,apurvam,2017-03-31T00:20:04Z,"in this case, we want to swallow the exception and try again, since we can't do anything without a pid when idempotence is enabled.",0,0.9854088425636292
109067904,2735,apurvam,2017-03-31T00:32:14Z,"hmm. the only real error codes are when there are transactions, ie. `coordinatornotavailable`, `invalidtransactiontimeout`, and `notcoordinatorfortransactionalid`. i wonder if it makes sense to add these in this patch, or wait till we add transactions.",0,0.9227175712585449
109070585,2735,apurvam,2017-03-31T01:03:23Z,i just added this test.,0,0.9872307181358337
109071152,2735,apurvam,2017-03-31T01:09:52Z,i actually prefer to avoid wildcard imports.,0,0.7144526839256287
109086998,2735,apurvam,2017-03-31T04:42:24Z,not sure how that moved around like that. i think it must have been a fat fingered cut/paste from last night. moved it back now.,-1,0.7352505922317505
109087940,2735,apurvam,2017-03-31T04:58:38Z,"i'll bump it down to info. debug seems too low, since this should happen fairly rarely.",0,0.8816730976104736
109088180,2735,apurvam,2017-03-31T05:02:32Z,"not sure if it would be more clear, but probably more efficient. i made the change this way so that we retain the existing logic for picking the latest snapshot less than the given offset.",0,0.9772851467132568
109088358,2735,apurvam,2017-03-31T05:05:11Z,nope. seems to have been there since fpj's time. i fixed it.,0,0.9762582182884216
109088745,2735,apurvam,2017-03-31T05:10:57Z,"hmm. it is not part of the kip. we agreed that 2 would be a good static value, i think. will update.",0,0.9378606081008911
109089311,2735,apurvam,2017-03-31T05:19:20Z,"the reason to choose a positive name is that we use it to retain unexpired entries. if we choose something like `hasentryexpired` we would have to negate the usage everywhere. seems like both have their tradeoffs, so i would prefer to leave it as is.",0,0.9086195230484009
109090712,2735,apurvam,2017-03-31T05:37:14Z,added the comment.,0,0.9845896363258362
109090729,2735,apurvam,2017-03-31T05:37:25Z,added the comment.,0,0.9845896363258362
109090769,2735,apurvam,2017-03-31T05:37:42Z,added a test case.,0,0.9855746030807495
109090797,2735,apurvam,2017-03-31T05:38:10Z,added a line for `isduplicate`,0,0.9879015684127808
109092828,2735,apurvam,2017-03-31T06:02:38Z,i consolidated all the logic into `shouldretainmessage`.,0,0.9868023991584778
109131783,2735,ijuma,2017-03-31T10:27:02Z,wouldn't `awaitleastloadednodeready` be a clearer name?,0,0.9815986752510071
109132404,2735,ijuma,2017-03-31T10:31:37Z,nit: it's a bit nicer if we return `long` here.,1,0.4950701892375946
109132472,2735,ijuma,2017-03-31T10:32:05Z,"for my benefit, when we do we use `producer_id` and when do we use `pid`?",0,0.969798743724823
109133247,2735,ijuma,2017-03-31T10:36:33Z,"we can avoid the `currenttimemillis` if `timestamptype` is `create_time`. in that case, we can simply use `no_timestamp`. the same applies for a couple of other methods.",0,0.986515998840332
109134063,2735,ijuma,2017-03-31T10:41:54Z,it would probably be useful to include some data in this message. maybe the existing pid/epoch/basesequence and the new proposed values?,0,0.9864867925643921
109134528,2735,ijuma,2017-03-31T10:45:09Z,please add a simple unit test in byteutilstest for this.,0,0.9862198829650879
109134743,2735,ijuma,2017-03-31T10:46:43Z,nit: long line.,0,0.9730140566825867
109135119,2735,ijuma,2017-03-31T10:49:23Z,"hmm, but this same file has been changed to use wildcard imports at the top (e.g. `import org.apache.kafka.common.network._`)?",0,0.9870373010635376
109135874,2735,ijuma,2017-03-31T10:54:46Z,the 5 lines above can be written as: [code block],0,0.9867373108863831
109136849,2735,ijuma,2017-03-31T11:01:42Z,simpler perhaps: [code block],0,0.9823614954948425
109137853,2735,ijuma,2017-03-31T11:09:11Z,"nit: it seems odd to have ""added this test"" as a test comment. something like ""verify behaviour of zkutils.createsequentialpersistentpath since pidmanager relies on it"" seems like the expected style.",-1,0.5579659342765808
109137937,2735,ijuma,2017-03-31T11:09:45Z,why do we have this at error level?,0,0.9178342819213867
109139892,2735,ijuma,2017-03-31T11:22:44Z,"great question. :) infinite is often what is said in talks. but that may not be the right value either. i think it's worth thinking about what the retries help us recover from and how long would we want to keep retrying for. because with the default retry backoff of 100ms, 3 retries get used pretty fast. say that we wanted to keep retrying for 10 seconds, that would be roughly 100 retries. the other side of the coin is: what is the cost of having a high retry number?",1,0.9828464388847351
109161698,2735,ijuma,2017-03-31T13:41:03Z,"nit: i personally find comments that just repeat what the code is doing not so useful. however, if we explained why we need to reset the pid in this case, that would be pretty useful.",0,0.9201231598854065
109162930,2735,ijuma,2017-03-31T13:46:52Z,have we done any performance tests to see the impact of this change? the change i made to close the memory records here made a huge difference to the amount of memory used by the producer due to temporary compression buffers.,0,0.9551491737365723
109163235,2735,ijuma,2017-03-31T13:47:58Z,nit: this could just be `recordsbuilder`. we generally avoid the `get` prefix in kafka.,0,0.9871817827224731
109261455,2735,apurvam,2017-03-31T22:29:59Z,"so i thought about this a bit more. i think it still make sense to validate this on the server side. i assume that the librdkafka clients may not have the request side validation, so it would be good to have server side validation before we write to the log.",0,0.9741911292076111
109266099,2735,apurvam,2017-03-31T23:19:18Z,i added this documentation to the `transactionstate.resetproducerid` method.,0,0.989260196685791
109266180,2735,apurvam,2017-03-31T23:20:06Z,was used during debugging. reverted to debug level.,0,0.9816567301750183
109267210,2735,apurvam,2017-03-31T23:33:57Z,"i think it is a bit arbitrary. it started with pid everywhere, but then started changing gradually to producerid or producer_id.",0,0.824070155620575
109269845,2735,apurvam,2017-04-01T00:10:55Z,"actually, the whole error message is out dated. we should not be calling `setproducerstate` on a closed batch any more. doing so is a bug on the client. updated the message to indicate that.",0,0.6756390929222107
109270153,2735,apurvam,2017-04-01T00:16:23Z,done.,0,0.9759407639503479
109277377,2735,junrao,2017-04-01T04:26:50Z,"similar to this, it seems the default acks=1 doesn't make sense when idempotence is enabled. this is because with acks=1, acked messages could be lost during leader change. then, the producer will be out of sequence. perhaps if idempotence is enabled, we should enforce acks=all.",0,0.9752698540687561
109290030,2735,apurvam,2017-04-01T17:45:08Z,"sounds good. of course, we also depend on some topic level settings like: replication.factor >= 3, min.isr >= 2, unclean.leader.election=false. but i agree, we should do what we can on the client.",1,0.8750513195991516
109290465,2735,apurvam,2017-04-01T18:06:22Z,i added the override for acks. will make a note to update the kip as well.,0,0.9878398776054382
109333086,2735,junrao,2017-04-03T02:43:38Z,entry => record,0,0.9727327823638916
109333094,2735,junrao,2017-04-03T02:43:48Z,i thought we agreed that this check is unnecessary given the check in producerequest?,0,0.9855278134346008
109481971,2735,apurvam,2017-04-03T17:52:20Z,"we did, initially, but then i followed up on that thread (which is now impossible to find on github). here is what i wrote:",0,0.9843329191207886
109488221,2735,junrao,2017-04-03T18:18:32Z,"hmm, producerrequest.validaterecords() is called on the broker side when converting bytes from socket to a request object. so, even if librd client has an issue, the broker should still be able to capture this when constructing producerrequest.",0,0.9885911345481873
36813449,130,hachikuji,2015-08-11T23:46:46Z,can you add some documentation for some of these interfaces?,0,0.9885259866714478
37058213,130,ijuma,2015-08-14T08:32:18Z,"since this class is used a lot, making the name short would help (as long as clarify is maintained). how about calling it `pair`?",0,0.9848889112472534
37058443,130,ijuma,2015-08-14T08:36:39Z,this makes `compareto` inconsistent with `equals`. is that intentional?,0,0.9020313024520874
37058480,130,ijuma,2015-08-14T08:37:14Z,maybe explain why?,0,0.9433277249336243
37058865,130,ijuma,2015-08-14T08:43:02Z,wouldn't this be better as `return new hashset<>(arrays.aslist(elems))`?,0,0.9867302179336548
37059011,130,ijuma,2015-08-14T08:45:43Z,there is already a `join` method in this class. can you not use that?,0,0.9865154027938843
37059086,130,ijuma,2015-08-14T08:47:15Z,rely on auto-boxing for less verbosity?,0,0.8188964128494263
37146536,130,rhauch,2015-08-16T14:46:09Z,"do you mean ""better"" to be more readable? or more efficient? the current code is does less work than `new hashset<>(arrays.aslist(elems))`.",0,0.986748456954956
37147003,130,rhauch,2015-08-16T15:37:38Z,"the `run()` and `close()` methods should not be synchronized. because they are, then once `run()` is called it will block any other synchronized method, including `close()`, and because `run()` only completes when `close()` is called, `run()` will never complete. in other words, the thread will never stop. you should be able to simply remove the `synchronized` keywords with the current code and maintain thread safety of the `running` volatile boolean field: the only method that reads that field is the private `stillrunning()` (called via private `runloop()` which is called via public `run()`), while the only method that writes to the field is `close()`.",0,0.9768877029418945
37147025,130,rhauch,2015-08-16T15:40:33Z,"this `recordsprocessed` field is never changed. if it were, it'd probably need to be made volatile, or better yet changed to be `final atomiclong` so that operations are atomic.",0,0.986610472202301
37147089,130,rhauch,2015-08-16T15:44:05Z,add `lastcommit = now' as a last line in this method?,0,0.9876641631126404
37169892,130,ijuma,2015-08-17T09:13:30Z,", i meant both. by passing the collection to the copy constructor of the `hashset`, the initial size of the internal array is big enough to contain the elements of the collection. this avoids reallocation and rehashing. note that `arrays.aslist` doesn't copy elements, it's just a view over the array. if this view is deemed too expensive (seems doubtful), we could keep the existing code, but then we should pass the correct sizing parameters to the `hashset` constructor.",0,0.9607569575309753
37339719,130,rhauch,2015-08-18T19:05:31Z,"the `producerrecord` class has a constructor that takes the partition number, yet that doesn't appear to be exposed in these two `send(...)` methods. am i missing how to specify the partitioning logic for each of the sent messages? update: okay, it's pretty obvious you can set the `partitioner.class` property in the producer's configuration to the name of the `partitioner` implementation class. doing this makes the `kafkaproducer` pass the message key to the `partitioner` to determine the partition number. is this a best practice, or is it still logical for our `processor` implementation to determine the partition, perhaps based upon something other than they key. if so, then it'd be great to have additional `send(...)` methods that take the partition number.",0,0.9714835286140442
37673148,130,rhauch,2015-08-21T20:09:58Z,"the `createsensor(...)` method called on lines 68-75 uses the `this.metrics` field, and because `this.metrics` is not set until line 76 the result is a `nullpointerexception`. to fix, simply move the `this.metrics = context.metrics();` line before the first call to `createsensor(...)`.",0,0.98673415184021
37675103,130,rhauch,2015-08-21T20:32:23Z,these two lines should get the **de**serializer from the context: [code block],0,0.9873135685920715
37711404,130,rhauch,2015-08-23T22:38:16Z,"this would be easier to implement if the parameter to this method were an `iterable >` than a `list >`. for example, the current `rocksdbkeyvaluestore` uses `byte[]` for the keys and values, and it's pretty easy to wrap that with a parameterized class that uses provided `serializer` and deserializer`instances for the keys and values -- except that the`putall`method cannot be easily implemented as a delegate if it takes a`list`. (in essence, the list has to be fully-copied before the delegation can be made. i'd be happy to provide a patch with this fix.",0,0.965000331401825
38231414,130,guozhangwang,2015-08-28T18:47:48Z,ack.,0,0.7720441818237305
38231825,130,guozhangwang,2015-08-28T18:51:45Z,"does compareto have to be consistent with equals? i though compareto is supposed to be used as comparable for priorityqueue, etc while equals is for identity matching in map, etc?",0,0.9883593320846558
38232147,130,guozhangwang,2015-08-28T18:54:20Z,ack.,0,0.7720441818237305
38232260,130,guozhangwang,2015-08-28T18:55:31Z,ack.,0,0.7720441818237305
38232422,130,guozhangwang,2015-08-28T18:57:01Z,ack.,0,0.7720441818237305
38232732,130,guozhangwang,2015-08-28T19:00:00Z,"not sure if we can use auto-boxing here, since need to explicitly transform string to integer here.",0,0.9526584148406982
38234637,130,guozhangwang,2015-08-28T19:21:50Z,ack.,0,0.7720441818237305
38237786,130,ijuma,2015-08-28T19:55:28Z,"my bad, i misread.",-1,0.9846251010894775
38237961,130,ijuma,2015-08-28T19:56:57Z,it's generally a good idea. the documentation for `comparable` says: [code block],1,0.8116763234138489
38252600,130,guozhangwang,2015-08-28T23:00:23Z,"ok makes sense, however after a second thought i feel by ""consistency"" we want: 1) if compareto() returns none-zero, equals() should return false; 2) if equals() returns true, compareto() should return zero. but: 3) if equals() returns false, compareto() does not necessarily returns none-zero. 4) if compareto() returns zero, equals() does not necessarily returns true. if we enforce 3) and 4) as well, it means sorted set / map will not allow two records who are comparably same to each other as the docs stated; but for our case, we actually want two stamped objects with the same timestamp to still be stored at the same time as keys if we ever want to do so.",0,0.9402942657470703
38252639,130,guozhangwang,2015-08-28T23:01:09Z,ack.,0,0.7720441818237305
38252646,130,guozhangwang,2015-08-28T23:01:20Z,ack.,0,0.7720441818237305
38252729,130,guozhangwang,2015-08-28T23:02:51Z,ack.,0,0.7720441818237305
38252996,130,guozhangwang,2015-08-28T23:07:55Z,i think we can wrap the producer / consumer configs in the streaming / processor congis as you mentioned.,0,0.9874722361564636
38253008,130,guozhangwang,2015-08-28T23:08:11Z,ack.,0,0.7720441818237305
38589091,130,rhauch,2015-09-02T21:48:22Z,"when a `processor` instance is started, the framework calls `init(processorcontext)`, but with the most recent changes it is no longer possible for a `processor` implementation to get the configuration from the `processorcontext`. how can one pass in the configuration into the `processor`? for example, my processor implementation might require several configuration properties to control or alter the default behavior. using the same configuration sure seemed like a natural way to do this. one option is to pass the `streamingconfig` object into the `processordef` constructor, which would change line 94 to be something like: [code block] the `processdef` could then pass the configuration into the constructor of the `processor` implementation. while that works, it seems like this would then require the `topologybuilder` to contain objects that are dependent upon a configuration, and that might not be the same configuration passed into `new kafkastreaming(builder, config);` (line 98 above). it sure seems better and far simpler to instead allow `processor.init(processorcontext)` access to the same configuration that kafkastreaming has when it is initializing the processor. iow, either change `processorcontext` to expose the configuration (as before), or (better yet imo) add a second parameter to `processor.init(...)` so it then becomes: [code block] thoughts? am i missing something more obvious?",0,0.9705774784088135
38593399,130,rhauch,2015-09-02T22:31:44Z,"can `addsource`, `addsink`, and `addprocessor` be changed to return `topologybuilder` instance so that the builder's methods can be chained together. if so, then this: [code block] becomes: [code block] might not be useful in all situations, but in some cases it works quite beautifully. i'd be happy to submit a pull-request for this. update: here's the very simple pr: [a link]",1,0.7938371300697327
38677576,130,guozhangwang,2015-09-03T18:11:44Z,"that is a good point, will review the pr.",1,0.8638738393783569
38678884,130,guozhangwang,2015-09-03T18:21:45Z,"streamingconfig is supposed to only include config values that are used by the kafkastreaming runtime but not in the user logic, if users do want to modify the behavior of their processors based on some streamingconfig values they can either do: [code block] or they can also pass-in the whole streamingconfig object, which of course can be different from the one they passed into kafkastreaming, into their instantiated processordef constructors, although i personally would not recommend this way. generally i think streamingconfig should not be exposed to the processor interface layer, since it is designed to be used only at the runtime level.",0,0.959858775138855
38683389,130,rhauch,2015-09-03T19:00:04Z,"okay, that sounds reasonable.",0,0.9627922773361206
38684688,130,rhauch,2015-09-03T19:12:28Z,"the casting done on line 53 from `processorcontext` to `processorcontextimpl` makes testing difficult, as the tests would require a `processingcontextimpl` rather than an alternative. (see how `kstreamtestdriver` uses a `mockprocessorcontext` for an example.) i assume that `recordcollector()` was removed from `processorcontext` to hide it from `processor` implementations, so this cast can either be kept and the test classes required to use a subclass of `processorcontextimpl`, or the `processorcontextimpl` implements another internal interface that `sinknode` can use here when casting and the test classes can choose to implement. thoughts? (it looks like tests that use `kstreamtestdriver` do so by implementing a tail-end mock processor. i'm trying to create a similar test driver for testing a `processor` and a `topology`. right now the only problem is that the `sinknode` throws a classcastexception on line 53.)",0,0.9796755313873291
38686619,130,rhauch,2015-09-03T19:30:48Z,"another option might be to break the current `processorcontextimpl` into two classes: one that holds the objects that all impls would need (e.g., the (de)serializers, the `recordcollector`, the `streamingconfig`, the `arraydeque `, and maybe the `metrics`), and a subclass that adds `streamtask` and `processorstatemanager`. the `sinknode` could cast to the base impl, and the test drivers could have impls that extend the base impl. if this sounds interesting, let me know and i'll create a pr for easier evaluation and comparison.",0,0.9863986968994141
38795321,130,rhauch,2015-09-04T21:21:44Z,"the fact that the `processorcontextimpl` class is creating its own consumer turns out to be a fairly significant problem for test cases, especially those that directly use `streamtask`. i'd love to introduce a `consumersupplier` (in java 8 it'd simply be `supplier `, but alas) and pass an implementation into this constructor and actually into the `streamtask` constructor. this would then move the creation of this `consumersupplier` into the `streamthread`, which is already creating the `kafkaproducer` and `kafkaconsumer` instances used to consume records to pass to the `streamtask`. and if this is acceptable, is it still desirable to use a _separate_ `kafkaconsumer` instance for the `processorstatemanager`?",0,0.8895169496536255
38795471,130,rhauch,2015-09-04T21:24:00Z,"i've been able to work around this problem by directly using `streamtask`, which internally creates its `processorcontextimpl` instance. however, the only roadblock i have is that the `processorcontextimpl` is explicitly creating a `kafkaconsumes`. see the details in [a link].",0,0.9853655099868774
38967999,130,guozhangwang,2015-09-08T19:20:06Z,"yeah i agree this is kinda awkward. the reason we need a separate consumer for restoring state is that the other consumer is 1) created for the thread and shared among its tasks, and 2) its subscribed topics is determined by the topology statically. while for local state the topic name is defined dynamically and the restoration is only one-time: once it is done you do not need to keep subscribing to it anymore. i think one thing we can do here is to move the creation of the restoration consumer into the processor-state-manager, and set a flag into the processor-state- manager's constructor indicating whether we need to create this consumer (set to false for unit tests, for example).",-1,0.706634521484375
38968103,130,guozhangwang,2015-09-08T19:21:12Z,"btw are you working on adding some unit test classes? since i am also working on some of them, would like to avoid any duplicate work or conflicts :)",1,0.5937017798423767
38974963,130,rhauch,2015-09-08T20:22:45Z,"actually, i've written a `processingtopologytestdriver` class under `src/test` that takes a topologybuilder and will make it very easy for projects that use kafka streams to test their topologies with unit tests that do not use a real kafka. each test method can set up the driver, pass one or more methods to the driver (which then forwards them to the appropriate source), and finally check the messages output by the sinks. it's pretty simple, and it uses mock consumers and producers along with a single `streamtask` to do all the heavy lifting. (this has the benefit of also testing the bulk of the `streamtask` implementation.) so, it'd be great if this test driver could pass the consumer for state manager into the `streamtask` constructor took a consumer (or consumer supplier) so that the tests can inject mocks instead; the `streamtask` constructor already takes a consumer and producer, so taking a second consumer for state management seems consistent. right now `streamtask` is the only thing that constructs a `processingcontextimpl`, so passing the consumer down also seem reasonable. this approach also seems to have minimal impact on other code, and imo is better than passing a flag into the processor state manager's constructor or calling a method on the processor state manager, since right now the the `processorstatemanager` is constructed within the `processingcontextimpl` class which itself is constructed within the `streamtask` constructor. btw, the test driver class and a unit test is ready for a pr, except that the tests that use state management are failing right now because it's trying to create a real consumer for state management. i'll go ahead and make the aforementioned change to pass in the consumer, fix my tests, and submit a pr for review first thing tomorrow.",0,0.8328805565834045
39053621,130,rhauch,2015-09-09T15:00:22Z,the pr is now available: [a link],0,0.9808713793754578
39055740,130,rhauch,2015-09-09T15:16:23Z,", how should i proceed with new unit tests. any suggestions so we don't duplicate effort? is there a better way to coordinate other than comments in this pr?",0,0.9734663963317871
39055851,130,rhauch,2015-09-09T15:17:13Z,added a pr with the simple correction: [a link],0,0.988274097442627
39056201,130,rhauch,2015-09-09T15:19:40Z,"with this configuration of `stream`, the test jars are not build and uploaded to maven. i created a pr ([a link] that corrects this so that the test jars are created and uploaded similarly to how `client` does it.",0,0.9876766204833984
39059471,130,eribeiro,2015-09-09T15:44:26Z,"see, here you should evaluate what is the semantic that `paused` should have. if we want to return a **snapshot** of the paused `topicpartition` then it's better to do: [code block] if we want to return a **dynamic** view of the `paused` then it's better to use: [code block] in either case, we should return an unmodifiable view of the set, because it's not very nice to expose a mutable field directly to callers as above.",0,0.9592465162277222
39059935,130,eribeiro,2015-09-09T15:47:34Z,nit: rename this method to `remove` or `delete`,0,0.9890940189361572
39060300,130,eribeiro,2015-09-09T15:50:39Z,"""returns an empty collection if this list is empty or null""",0,0.9881575703620911
39060354,130,eribeiro,2015-09-09T15:51:00Z,"it is best practice to use `collections.emptylist()` instead of `collections.empty_list` also, would make a difference to return `collections.emptylist()` if the `other` is empty? i mean, like this: ` return other == null || other.isempty() ? collections.emptylist() : other; `",0,0.9795118570327759
39061914,130,eribeiro,2015-09-09T16:02:27Z,private **final**?,0,0.9711988568305969
39062322,130,eribeiro,2015-09-09T16:05:23Z,"why not use `((long) key);` or even `((integer) key)`. no need to call `longvalue()` as the autoboxing is called automatically, afaik.",0,0.9890089631080627
39062772,130,eribeiro,2015-09-09T16:08:56Z,nit: can remove this blank line.,0,0.9856890439987183
39062866,130,eribeiro,2015-09-09T16:09:42Z,it's nice to expose those as: ``public final list keys = new arraylist<>()` same for line 35,0,0.9359152317047119
39062965,130,eribeiro,2015-09-09T16:10:20Z,it's nice to expose those as: `public final list processed = new arraylist<>() same for line 29,0,0.9385747909545898
39063280,130,eribeiro,2015-09-09T16:12:57Z,"paraphrasing joshua bloch, prefer collections to arrays so i would use: [code block]",0,0.9772455096244812
39063561,130,eribeiro,2015-09-09T16:15:18Z,better to make `state` volatile too.,0,0.9805072546005249
39063741,130,eribeiro,2015-09-09T16:16:51Z,"still in this mood, this method could be rewritten as: [code block]",0,0.9837465882301331
39064142,130,eribeiro,2015-09-09T16:20:17Z,"if `state` is different from `created` then lines l#93 and l#94 are unreachable. therefore, why not move them to end of the `if` block? [code block]",0,0.9845989942550659
39064231,130,eribeiro,2015-09-09T16:20:52Z,same as above: lines 121 and 123 can be moved to inside the if block.,0,0.9884635806083679
39065910,130,eribeiro,2015-09-09T16:35:20Z,nit: `private list list = new linkedlist ();`,0,0.9849764108657837
39067165,130,eribeiro,2015-09-09T16:47:24Z,"as all the methods synchronize on the whole body why not make all the methods `synchronized`, like: `public synchronized void close() {` ?",0,0.982642650604248
39067236,130,eribeiro,2015-09-09T16:48:12Z,formatting: break line as: [code block],0,0.9859365224838257
39067357,130,eribeiro,2015-09-09T16:49:14Z,nit: prefer interfaces on field declaration as: `private final deque nodestack = new arraydeque ();`,0,0.9842877388000488
39067577,130,eribeiro,2015-09-09T16:51:20Z,"tip: you can rewrite as `final int[] expectedkeys = {1, 10, 100, 1000};`",0,0.9746696949005127
39067625,130,eribeiro,2015-09-09T16:51:56Z,"tip: you can rewrite as final `string[] expected = {""1:1"", ""10:2"", ""100:3"", ""1000:4""};`",0,0.9803941249847412
39067732,130,eribeiro,2015-09-09T16:52:53Z,"tip: you can rewrite as `string[] expected = {""0:v0"", ""0:v0"", ""1:v1"", ""1:v1"", ""2:v2"", ""2:v2"", ""3:v3"", ""3:v3""};`",0,0.9821102023124695
39067794,130,eribeiro,2015-09-09T16:53:25Z,"tip: you can rewrite as `final int[] expectedkeys = {0, 1, 2, 3};`",0,0.9755046963691711
39089821,130,guozhangwang,2015-09-09T20:11:31Z,i am working on calling for a review round and push the first patch to os now. once that is done further prs can be submitted directly to apache/kafka. could you hold the current changes and rebased them to the apache trunk once this patch is checked in?,0,0.9797629714012146
39090342,130,guozhangwang,2015-09-09T20:16:00Z,ack.,0,0.7720441818237305
39090441,130,guozhangwang,2015-09-09T20:16:43Z,ack.,0,0.7720441818237305
39090503,130,guozhangwang,2015-09-09T20:17:14Z,ack.,0,0.7720441818237305
39090892,130,guozhangwang,2015-09-09T20:20:34Z,"good point, changed to `collections.emptylist()`. the semantics is only to return an empty list if `other` is null, if it is empty then we will still return itself.",0,0.6418257355690002
39090991,130,guozhangwang,2015-09-09T20:21:28Z,ack.,0,0.7720441818237305
39091129,130,guozhangwang,2015-09-09T20:22:51Z,the value integer cannot be cast directly to long.,0,0.9796562194824219
39091209,130,guozhangwang,2015-09-09T20:23:27Z,ack.,0,0.7720441818237305
39091297,130,guozhangwang,2015-09-09T20:24:14Z,ack.,0,0.7720441818237305
39091428,130,guozhangwang,2015-09-09T20:25:18Z,ack.,0,0.7720441818237305
39092030,130,guozhangwang,2015-09-09T20:30:19Z,ack.,0,0.7720441818237305
39092290,130,guozhangwang,2015-09-09T20:32:35Z,since the start() / close() are synchronized the states will not be accessed concurrently. so i think it is not necessary?,0,0.9868082404136658
39092328,130,guozhangwang,2015-09-09T20:32:54Z,ack.,0,0.7720441818237305
39092500,130,guozhangwang,2015-09-09T20:34:28Z,ack.,0,0.7720441818237305
39092546,130,guozhangwang,2015-09-09T20:34:53Z,ack.,0,0.7720441818237305
39092616,130,guozhangwang,2015-09-09T20:35:33Z,we used linkedlist's offerlast / etc functions later so we have to declare it as linkedlist.,0,0.9892786145210266
39092736,130,rhauch,2015-09-09T20:36:21Z,it should be volatile so that different threads see the actual value at the same time.,0,0.9808048605918884
39098298,130,eribeiro,2015-09-09T21:22:58Z,"oh, ok. excuse me for overlooking this. you right.",1,0.531423807144165
39197241,130,eribeiro,2015-09-10T18:40:16Z,"i would suggest to use a more modern approach that is replace int constants by enums. therefore, it becomes: [code block]",0,0.9853214621543884
39197493,130,eribeiro,2015-09-10T18:42:27Z,nit: a nifty trick to use here (reduces the scope of `iter` would be): [code block],0,0.9728652238845825
39198066,130,eribeiro,2015-09-10T18:47:38Z,using lock objects is considered a old fashioned approach. better to use a reentrantlock as below: [code block],0,0.9786746501922607
39198676,130,eribeiro,2015-09-10T18:52:36Z,"nit: maybe name this method as `of`, like `keyvalue.of(10, ""hello"")`",0,0.9828894734382629
39198875,130,eribeiro,2015-09-10T18:54:24Z,"this line and line below can be : `public final list = new arraylist<>();`, as well as line below.",0,0.9879789352416992
39199065,130,eribeiro,2015-09-10T18:56:02Z,lines 34-36 can be simplified as: `return timestamp - othertimestamp;` a nifty trick ;),0,0.9117749929428101
39199114,130,ijuma,2015-09-10T18:56:33Z,"this is not really true. there are advantages and disadvantages when it comes to choosing between `synchronized` and `reentrantlock`. for low contention cases, `synchronized` tends to do better, in fact.",0,0.9473504424095154
39199275,130,eribeiro,2015-09-10T18:58:03Z,it's usually advisable to 1) make pq final; or 2) create a lock field or 3) synchronize the whole method only don't synchronize on a **non final** field.,0,0.9879962801933289
39199569,130,eribeiro,2015-09-10T19:00:44Z,"yeah, you right. my fault. for low contention synchronized is better.",-1,0.9728824496269226
39212009,130,eribeiro,2015-09-10T20:51:24Z,"i feel maybe we need a method to check the status of this class, that is: [code block] wdyt?",0,0.9718230962753296
39214847,130,eribeiro,2015-09-10T21:15:09Z,typo: 'coresponds' should be `correponds`,0,0.9892450571060181
39215090,130,eribeiro,2015-09-10T21:17:13Z,"nit: **i** would name this method as `nulltoempty` to let it clear what it does, but up to you. :)",1,0.9621259570121765
39215276,130,eribeiro,2015-09-10T21:18:57Z,"nit: **i** would name this method `newset`and make it return `set` instead of a `hashset`, but, again, up to you. :) ps: btw, once guava is incorporated into kafka project, the `sets` helper class has methods to replace this one. ;)",1,0.9809884428977966
39228036,130,eribeiro,2015-09-10T23:42:05Z,as above,0,0.9783914685249329
39228037,130,eribeiro,2015-09-10T23:42:05Z,"declare as `public final list keys = new arraylist<>();`, as well as line below",0,0.9870762228965759
39228134,130,eribeiro,2015-09-10T23:43:18Z,"i suppose this is a leftover, right?",0,0.9773569703102112
39228245,130,eribeiro,2015-09-10T23:45:08Z,declare as `private final deque nodestack = new arraydeque<>();`,0,0.9857957363128662
39228751,130,eribeiro,2015-09-10T23:52:50Z,that kafka convention: ` if (condition) statement ` on the following line too.,0,0.9867128133773804
39228814,130,eribeiro,2015-09-10T23:53:34Z,**final** for `keyserializer` and `valserializer`?,0,0.9885410666465759
39228849,130,eribeiro,2015-09-10T23:54:01Z,define as `private final deque fifoqueue;`,0,0.9855641722679138
39471570,130,eribeiro,2015-09-15T03:33:29Z,"hey, why don't we return a empty `iterator` here? you can do this with `collections. emptylist().iterator()`. returning null is usually a code smell. wdyt?",0,0.9869177937507629
39472217,130,eribeiro,2015-09-15T03:50:47Z,can be simplified as `for (int i : expectedkeys) {`,0,0.9857014417648315
39472298,130,eribeiro,2015-09-15T03:53:05Z,format: [code block],0,0.9857390522956848
39472324,130,eribeiro,2015-09-15T03:53:37Z,formatting: no need for curly braces here,0,0.9865648746490479
39472333,130,eribeiro,2015-09-15T03:53:50Z,format: no need for curly braces,0,0.9854987859725952
39472370,130,eribeiro,2015-09-15T03:54:44Z,lines l#53 to l#55 can be simplified as: [code block],0,0.9867466688156128
39472425,130,eribeiro,2015-09-15T03:55:57Z,"i like to rewrite those if-else condition as: `return (stamped == null) ? lastknowntime : stamped.timestamp`, but up to you.",0,0.9839313626289368
39472674,130,eribeiro,2015-09-15T04:02:25Z,formatting: no need for curly braces,0,0.985325813293457
39472691,130,eribeiro,2015-09-15T04:02:50Z,formatting: no need for curly braces.,0,0.9848700761795044
39472770,130,eribeiro,2015-09-15T04:05:04Z,that **snapshot** vs **dynamic view** intention: what do we want here? if it's the current snapshot then it's `return new hashset<>(partitionqueues.keyset());`,0,0.9798426032066345
39472806,130,eribeiro,2015-09-15T04:06:00Z,formatting: no need to curly braces,0,0.9841256141662598
39472985,130,eribeiro,2015-09-15T04:10:55Z,doesn't it need a `new hashset<>(sourcebytopics.keyset())` to return a snapshot as line 46?,0,0.9890570044517517
39473139,130,eribeiro,2015-09-15T04:14:03Z,`list result = new arraylist<>();`,0,0.981642484664917
39473154,130,eribeiro,2015-09-15T04:14:24Z,`list expected = new arraylist<>();`,0,0.9824999570846558
39473162,130,eribeiro,2015-09-15T04:14:41Z,`list expected = new arraylist<>();`,0,0.9824999570846558
39473198,130,eribeiro,2015-09-15T04:15:47Z,can be simplified as `for (int i : expectedkeys) {`,0,0.9857014417648315
39679109,130,rhauch,2015-09-16T20:15:28Z,"it does not appear that `kafkaconsumer` (or rather the `subscriptionstate` class it uses) allows using both `subscribe(...)` and `assign(...)`. given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: [code block]",0,0.9883406162261963
39904068,130,guozhangwang,2015-09-18T21:41:29Z,ack.,0,0.7720441818237305
39904149,130,guozhangwang,2015-09-18T21:42:37Z,ack.,0,0.7720441818237305
39904467,130,guozhangwang,2015-09-18T21:46:39Z,ack.,0,0.7720441818237305
39904581,130,guozhangwang,2015-09-18T21:47:56Z,"the topology's immutable, such that the processornodes and sourcebytopics will not be modified.",0,0.9844551086425781
39904795,130,guozhangwang,2015-09-18T21:50:39Z,"yeah, it will be replaced with the unsubscribe() api introduced in [a link]",0,0.9867035150527954
39912569,130,onurkaraman,2015-09-19T00:12:25Z,so i have very little context in this kip. is there any sort of expected size for the inner iterator? you may get stuck in the constructor's call to findnext() for a long time. it might be less surprising to postpone calling findnext() in hasnext() and next().,0,0.9153062701225281
39916442,130,rhauch,2015-09-19T05:09:32Z,"sounds good. the proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. thanks!",1,0.9905077219009399
40004856,130,guozhangwang,2015-09-21T18:12:02Z,"the iterator will be constructed at around the same time when it is used to get next() (usually in process() call), so i feel postponing findnext() would not change much. but if we encountered some cases that this did become an surprise for users we can change it then.",0,0.9803983569145203
40112156,130,onurkaraman,2015-09-22T16:58:21Z,"minor, but this can alternately be called filternot just like in scala's collections.",0,0.9883596897125244
40122437,130,ijuma,2015-09-22T18:14:01Z,we should use `$junit` here.,0,0.988972008228302
40123138,130,ijuma,2015-09-22T18:19:27Z,there are no plans to incorporate guava by the way.,0,0.8845111131668091
40124198,130,ijuma,2015-09-22T18:26:12Z,"we may not care in this case, but nio.2 in java 7 provides a mechanism to do this in a more efficient way: [a link]",0,0.97742760181427
40125291,130,ijuma,2015-09-22T18:33:44Z,"what is the reasoning for having different prefixes in `kafkastreaming`, `streamingconfig` and `kstream`?",0,0.9819446802139282
40126053,130,ijuma,2015-09-22T18:39:10Z,"also, is it actually useful enough? particularly if there is a `negate` method on `predicate`. in scala, one benefit of `filternot` is when using the underscore notation to make lambdas more concise. in java, that seems less useful.",0,0.9755223989486694
40126098,130,ijuma,2015-09-22T18:39:28Z,`valuesa` -> `values`,0,0.9826148748397827
40127893,130,ijuma,2015-09-22T18:51:40Z,is this actually needed?,0,0.9862609505653381
40128094,130,ijuma,2015-09-22T18:53:14Z,"some of this are private while others are public, is there a reason for that?",0,0.9477585554122925
40128168,130,ijuma,2015-09-22T18:53:46Z,is there a reason why these are not final?,0,0.9432054758071899
40128440,130,ijuma,2015-09-22T18:55:36Z,we should probably have a method that takes the name as a parameter and returns the new name using `index`. less error-prone and easier to change in the future.,0,0.9624633193016052
40128852,130,ijuma,2015-09-22T18:58:43Z,the suggestion to have a method that does this concat becomes even more appealing when seen in the light of subclasses like this one.,0,0.9484894871711731
40128890,130,ijuma,2015-09-22T18:59:07Z,"also, have we considered using an enum instead of strings?",0,0.9875509142875671
40128968,130,rhauch,2015-09-22T18:59:38Z,"currently, since kafka can't use java 8 functions nor static methods on interfaces, there is a `predicate` interface in this package that is semantically equivalent to `java.util.function.bipredicate`. unfortunately, without static methods, it's difficult to create a `not( predicate...)` method. so using `filterout` seems to be the easiest approach.",0,0.9641775488853455
40129636,130,rhauch,2015-09-22T19:04:42Z,"if the `apply` method were changed to `test`, then when kafka moves to java 8 this interface could extend `java.util.function.bipredicate `. that wouldn't really benefit anyone that simply supplied their own lambdas, but it might make it a bit easier or more obvious that existing `bipredicate` implementations could be passed in. regardless, aligning with java 8 might be a good thing in and of itself.",0,0.9510040283203125
40129686,130,ijuma,2015-09-22T19:05:10Z,"i was thinking of adding a default method to `predicate` itself, but i now realise that we can't do that in java 7 without changing it to an abstract class. fair enough.",0,0.9165077805519104
40149196,130,guozhangwang,2015-09-22T21:50:45Z,ack.,0,0.7720441818237305
40149364,130,guozhangwang,2015-09-22T21:52:36Z,"kafkastreaming / streamingconfig is aligned with kafkaproducer (kafkaconsumer) / producerconfig (consumerconfig), and kstream is just a name of the higher-level dsl api.",0,0.9882856607437134
40149430,130,guozhangwang,2015-09-22T21:53:07Z,ack.,0,0.7720441818237305
40149490,130,guozhangwang,2015-09-22T21:53:49Z,ack.,0,0.7720441818237305
40149757,130,guozhangwang,2015-09-22T21:56:22Z,ack.,0,0.7720441818237305
40149780,130,guozhangwang,2015-09-22T21:56:35Z,"some of them are used outside kstream, for example source is used in kstreambuilder, and join is in kstreamwindowed, etc.",0,0.9885827302932739
40150351,130,guozhangwang,2015-09-22T22:02:45Z,"not sure i got the motivation: when we moved to java 8 and removed this interface with bipredicate directly, even with test() existing users still need to make code change, right?",0,0.7693186402320862
40167379,130,rhauch,2015-09-23T02:55:58Z,"renaming `apply` to `test` now gives us a slow, non-breaking migration path so that when moving to java 8 we could: - change `predicate ` to extend `java.util.function.bipredicate ` and remove the `apply` method from `predicate ` since it would unnecessarily override `bipredicate.test(...)`; - change `kstream` methods to use `bipredicate ` instead of this `predicate `; - deprecate `predicate ` and tell people to use `bipredicate` instead. no users would have to change their code, although anyone using `predicate ` directly would get deprecation warnings and could but would not be required to change. in a later release, we can remove `predicate `, and anyone _still_ using it would then have to change their code. otoh, if we keep `apply` as it is now, then when we moved to java 8 and change to `java.util.function.bipredicate `, all users directly using the interface would _have_ to change. of course, neither of these options affects those users who are already on java 8 and using lambdas rather than `predicate ` implementation classes.",0,0.9805182218551636
40215978,130,rhauch,2015-09-23T15:17:20Z,", why is the `rocksdbkeyvaluestore` not parameterized like `inmemorykeyvaluestore`? i have a version of this that is parameterized (yes, it does require passing in key and value serializers and deserializers), and it makes using it very similar to `inmemorykeyvaluestore`. any interest in it?",0,0.9821288585662842
40237923,130,guozhangwang,2015-09-23T18:17:30Z,"agree, do you want to create a new pr?",0,0.9788661599159241
40239203,130,rhauch,2015-09-23T18:27:47Z,", yes i will create a new pr shortly.",0,0.963493287563324
40239945,130,ymatsuda,2015-09-23T18:32:40Z,"i am not sure if we want to migrate to `java.util.function.bifunction` at this point. but, by this change, we can maintain the source level compatibility of user code if we want to migrate. a good idea. what happens to the binary level compatibility? does a user using predicate have to recompile?",0,0.554713785648346
40240252,130,guozhangwang,2015-09-23T18:35:25Z,i think recompilation are not avoidable anyways..,0,0.504096269607544
40240731,130,rhauch,2015-09-23T18:39:28Z,"inserting new class or interface types in the type hierarchy is listed as a [a link] and [a link]. so if we rename the method now, then if/when `predicate ` is changed to extend `java.util.function.bipredicate ` and released clients using `predicate ` should not have to recompile.",0,0.9890096783638
40243229,130,guozhangwang,2015-09-23T19:00:05Z,correct: [a link],0,0.9847277402877808
131572299,3621,becketqin,2017-08-07T04:52:30Z,"not sure if we want to have this interface added while we have not supported the intra broker replica move yet. also, we probably don't want to expose the implementation detail to the users about how the replicas are moved . so it would be better to not ask users to manually specify the replica dir before they do the partition reassignment. so the end state of adminclient after kip-179 and kip-113 would be having two methods for partition movement: 1. a method for partition reassignment in general, include both inter and intra broker reassignment. (e.g. `altertopics()`) 2. a method to only move replicas within a broker. (e.g. `alterreplicadir`) btw, i still feel that having (1) is sufficient. it would be useful to explore possibility of only having (1) so users don't need to deal with two different interfaces for replica movement. with that, regarding this patch, i was thinking doing the following: 1. let `reassignpartitioncommand` take new input format which includes the log dir. 2. do a sanity check in the `reassignparititioncommand` to ensure no intra broker replica movement is specified. otherwise throw `unsupportedoperationexception`. 3. in `reassignpartitioncommand`, it should just send `changereplicadirrequest` to the related brokers before the partition movement. 4. do not add `alterreplicadir()` to the adminclient until the broker supports that. would the above way be sufficient for what we want to achieve for this patch?",0,0.9627960324287415
131573994,3621,lindong28,2017-08-07T05:17:37Z,"thanks for your comment! here is what i think: - i think the interface is useful. the alterreplicadirrequest (renamed from changereplicadirrequest per ismael's comment) is used to 1) create replica in the specified log directory later and 2) move replica to the specified log directory if it has already been created yet. this patch supports the first part and thus the new api `alterreplicadir` in adminclient is useful and well-defined. if we don't add this method and its implementation in adminclient, we would have to implement it in `reassingpartitioncommand` and move the implementation to adminclient later, which seems like unnecessary work. - can you clarify a bit what implementation detail is exposed to user in this patch? - i have thought about the possibility of using only one method in adminclient to do both partition reassignment and replica -> log directory reassignment. my conclusion is that it is still better to put them into two separate methods. for example, if we do both using one method, the method would probably look like `reassignpartition(map > newpartitionassignment, map newreplicadirassignment)`. this method merges two inherently different parameters and functionality into one method, which seems less clean than using two methods. do you any suggestion on how that one method would look like if we were to use only one method for this? - i agree with the tasks 1-3. i still think it is better to put `alterreplicadir` in admclient as long as we documents it properly. but it also works for me to move this code to `reassignpartitioncommand`.",1,0.9842220544815063
131574245,3621,lindong28,2017-08-07T05:21:42Z,and good point about checking that no intra broker replica movement is specified. i will add this logic in `reassignpartitioncommand`,1,0.887977123260498
131777843,3621,lindong28,2017-08-07T22:18:18Z,discussed with offline. i will not add `alterreplicadir()` api in adminclient in this patch. i will add `alterreplicadir()` as a public method in kafkaadminclient so that this method can be used by reassignpartitionscommand in this patch.,0,0.9881623387336731
132356130,3621,becketqin,2017-08-10T03:18:39Z,we have agreed the next major version would be 1.0.0.,0,0.9816363453865051
132356186,3621,becketqin,2017-08-10T03:19:25Z,should this be `describelogdirs`? also why this method is abstract?,0,0.9813995957374573
132356414,3621,becketqin,2017-08-10T03:22:35Z,"not sure if it is worth having this query granularity. it seems that when we query a broker, the cost to query all log directories and query some particular log directories are pretty much the same. and i think typically users would have to query all log dirs in order to get the dir names first. if so, would it be simpler to just use `collection ` instead?",0,0.9581884145736694
132359600,3621,becketqin,2017-08-10T04:03:56Z,it seems a little verbose to have all these options with a timeout. it seems cleaner to merge them to a `timeoutoption` and extends from that.,0,0.9559873938560486
132359818,3621,becketqin,2017-08-10T04:06:38Z,this method does not exist.,0,0.9266400337219238
132359891,3621,becketqin,2017-08-10T04:07:13Z,this method does not exist.,0,0.9266400337219238
132832597,3621,becketqin,2017-08-13T05:19:26Z,this comment seems a little too verbose. do we need to mention this or the api of `alterreplicadirresult` is already clear enough?,-1,0.7065651416778564
132832605,3621,becketqin,2017-08-13T05:19:52Z,1.0.0,0,0.9768909811973572
132832726,3621,becketqin,2017-08-13T05:32:05Z,"hmm, in which case would the future be null?",0,0.9638457894325256
132832899,3621,becketqin,2017-08-13T05:50:43Z,logdirnotavailableexception?,0,0.9877119660377502
132833418,3621,lindong28,2017-08-13T06:36:04Z,good point. i have changed it to take `collection `.,1,0.944612979888916
132833428,3621,lindong28,2017-08-13T06:36:38Z,thanks. i have changed it to 1.0.0.,1,0.9402308464050293
132833468,3621,lindong28,2017-08-13T06:40:22Z,"i think `logdir` may be a bit more verbose than dir. it seems ok to be use `dir` instead of `logdir` as long as logdir will be the only ""dir"". if it is necessary to use `dir` instead of `logdir`, do you think we should rename `describedirsrequest` to `describelogdirsrequest`?",0,0.9839433431625366
132833487,3621,lindong28,2017-08-13T06:41:42Z,"besides, this is an abstract method because its implementation is in adminclient. this follows the same pattern as existing apis in `adminclient`.",0,0.9877084493637085
132833512,3621,lindong28,2017-08-13T06:42:55Z,"thanks. i replaced it with `{ kafkaadminclient#alterreplicadir(map, alterreplicadiroptions)}`",1,0.8785289525985718
132833528,3621,lindong28,2017-08-13T06:44:07Z,"thanks. i replaced it with `{ kafkaadminclient#alterreplicadir(map, alterreplicadiroptions)}`",1,0.8785289525985718
132833575,3621,lindong28,2017-08-13T06:48:34Z,sure. i removed the sentence `updates are not transactional...` from this comment. does this address the problem?,0,0.9831414222717285
132833579,3621,lindong28,2017-08-13T06:48:52Z,sure. fixed now.,0,0.9448716044425964
132833626,3621,lindong28,2017-08-13T06:51:20Z,"this follows the same pattern of the implementation of other existing apis in kafkaadminclient. i don't think future will be null unless there is bug. i think it is ok for the kafkaadminclient to have extra check to protect itself form server side's bug. but if you don't like it, i can also remove it and in the worse case we just see npe if future is null.",0,0.9206939935684204
132833666,3621,lindong28,2017-08-13T06:54:21Z,sure. renamed to `logdirnotavailableexception`.,0,0.9854661226272583
132833688,3621,lindong28,2017-08-13T06:55:55Z,"and if we were to rename it to `describelogdirs`, should we also rename `describereplicadir` to `describereplicalogdirs`?",0,0.9883663058280945
132833755,3621,lindong28,2017-08-13T07:00:42Z,"how about this: i added an abstract class named `configoptions`. this class will have a timems variable and `integer timeoutms()` api. this abstract class can be used to hold all future apis that are shared among all (or most) ""*configoptions"" classes. on the other hand i also think it is ok to keep it as is given that there are is only one common api (i.e. timems()) shared among those classes.",0,0.9664838314056396
132857316,3621,becketqin,2017-08-13T23:56:05Z,"if we do not expect this to happen. shouldn't we throwi illegalstateexception? in this case, if the broker returned a replica that is not in the request, the broker may have somehow misplaced a replica. we should probably alert in this case.",0,0.9626597166061401
132868453,3621,becketqin,2017-08-14T03:29:15Z,"personally i prefer avoiding the potential confusion, especially given dir is a pretty commonly used name in many places. i am not sure if in the future we will have some other dirs, but describedir() itself seem lacking some necessary context to me. and yes, i do feel `describelogdirrequest` is a better name. `describereplicadir` sounds ok though, as replicadir must be a log dir.",0,0.7463542222976685
132868590,3621,becketqin,2017-08-14T03:31:37Z,i am not sure what is the best solution here either. it just feels a little silly that we have all those classes that are essentially identical except the class name.,-1,0.9782342314720154
132868863,3621,becketqin,2017-08-14T03:36:25Z,should this comment be updated?,0,0.9836228489875793
132868995,3621,becketqin,2017-08-14T03:38:36Z,ditto above.,0,0.9270309805870056
132869443,3621,becketqin,2017-08-14T03:47:23Z,"technically speaking we are query the log directory in which the replica locates. i.e. the root_log_dir, not root_log_dir/replica_dir. speaking of this, it might still be better to change the method name to `describereplicalogdir`.",0,0.987646222114563
132871530,3621,becketqin,2017-08-14T04:24:17Z,is the left parenthesis missing?,0,0.9756912589073181
132872895,3621,becketqin,2017-08-14T04:42:22Z,the default lag should probably be something like -1 and preferably a macro. it is also a little weird to allow those non-final fields to be tweaked. see the other comment in `kafkaadminclient`,-1,0.8393210172653198
132873131,3621,becketqin,2017-08-14T04:44:52Z,would it be better to construct the result after the response is returned instead of create the result beforehand and modify it later?,0,0.9839944839477539
132873593,3621,becketqin,2017-08-14T04:53:18Z,"given this change, is the log dir field still needed in the `describedirrequest`? it seems that we can just leave the replica list there and remove the log dir list?",0,0.9890651702880859
132874067,3621,becketqin,2017-08-14T04:59:49Z,"not found and not available seems slightly different. it would be useful to distinguish between ""exist but not available"" vs ""does not exist"".",0,0.9446071982383728
132874436,3621,becketqin,2017-08-14T05:06:23Z,"by ""remaining"" do you mean ""available""?",0,0.9843354225158691
132874540,3621,becketqin,2017-08-14T05:08:34Z,"see the other comment, maybe we don't need the log dir list anymore.",0,0.9841761589050293
132876992,3621,becketqin,2017-08-14T05:44:15Z,"hmm, why are we do the validation after executing the reassignment?",0,0.9732059240341187
132878069,3621,becketqin,2017-08-14T05:59:02Z,"the comment is a little confusing. maybe change to ""remove the preferred log dir since it has already been satisfied."". btw, should we remove it after the log has actually been created? otherwise if storage exception happens during the log creation we may lose the preferred log dir information.",0,0.7506848573684692
132878098,3621,becketqin,2017-08-14T05:59:27Z,can you explain the reason of these changes?,0,0.9833831191062927
132879332,3621,becketqin,2017-08-14T06:13:27Z,"i know this is in the kip, but it still seems a little weird to throw exception in this case as the request is kink of legitimate. not sure if there is a better way though.",-1,0.9604127407073975
132880098,3621,becketqin,2017-08-14T06:22:33Z,"why should this be -1 instead of 0? this is essentially caught up, right?",0,0.9297757744789124
133014020,3621,lindong28,2017-08-14T17:43:13Z,sure. good point. i have updated the patch with the following changes: - renamed describedirsrequest to describelogdirsrequest (same for response) - renamed adminclient api to describelogdirs - renamed adminclient api to describereplicalogdirs,1,0.9834912419319153
133014235,3621,lindong28,2017-08-14T17:44:04Z,i have added the class `abstractoptions` that provides apis to set and get timeoutms.,0,0.9887881875038147
133014767,3621,lindong28,2017-08-14T17:46:14Z,good point. i have updated the patch to throw illegalargumentexception if the future is not found.,1,0.9581288695335388
133015323,3621,lindong28,2017-08-14T17:48:30Z,sure. i replaced this comment with `query the information of all log directories on the given set of brokers`.,0,0.9851431250572205
133015335,3621,lindong28,2017-08-14T17:48:33Z,sure. i replaced this comment with `query the information of all log directories on the given set of brokers`.,0,0.9851431250572205
133015631,3621,lindong28,2017-08-14T17:49:36Z,good point. i have updated the protocol to remove `log_dirs` field from `describelogdirsrequest`.,1,0.9662522673606873
133015745,3621,lindong28,2017-08-14T17:50:00Z,sure. i have renamed `describereplicadir` to `describereplicalogdir`.,0,0.9816679358482361
133021670,3621,lindong28,2017-08-14T18:13:58Z,good point. i replaced `-1` with `describelogdirsresponse.invalid_offset_lag`.,1,0.9675661325454712
133021896,3621,lindong28,2017-08-14T18:14:54Z,left parenthesis actually exists.,0,0.9817972183227539
133022382,3621,lindong28,2017-08-14T18:16:48Z,yeah. i have removed this field from describelogdirsrequest.,0,0.9854098558425903
133023112,3621,lindong28,2017-08-14T18:19:57Z,good point. i have renamed this exception to `logdirnotfoundexception`. i think we can assume `not found` indicates `does not exist` given that we already have `notfoundexception`.,1,0.9494975805282593
133023274,3621,lindong28,2017-08-14T18:20:43Z,i removed the `remaining` from this comment since it appears unnecessary.,0,0.9697598814964294
133026257,3621,lindong28,2017-08-14T18:32:37Z,this is just an extra verification to confirm that we are only sending alterreplicadirrequest for replicas that have not been created yet.,0,0.9849680066108704
133026969,3621,lindong28,2017-08-14T18:35:29Z,good point. i have updated the comment as suggested. and it is only removed after the log has been successfully created.,1,0.9643681049346924
133027534,3621,lindong28,2017-08-14T18:37:25Z,this is because we receive logdir as a strong from alterreplicadirrequest and it is inserted into `preferredlogdirs` as a strong. when we get it from `preferredlogdirs` it will be a strong not a file. it is a minor change. alternatively i can insert preferred log directory into that map as a file. i just feel the current approach is simpler.,0,0.9602881669998169
133028201,3621,lindong28,2017-08-14T18:40:00Z,"imo it is reasonable to throw exception here. this is because it is not guaranteed that the replica will be moved to the destination log directory if the replica is not already on the broker. for example, if the broker restarts after it receives alterreplicadirrequest but before it receives the upcoming leaderandisrrequest, it will forget the cache in the memory.",0,0.9852443933486938
133028267,3621,lindong28,2017-08-14T18:40:15Z,discussed offline. i have updated the patch to remove this logic.,0,0.978431761264801
133028981,3621,lindong28,2017-08-14T18:42:54Z,"are you talking about the `futures` map or the `replicadirinfobypartition`? the former needs to be constructed in advance as does the implementation of other apis in adminclient. the latter needs to be constructed in advance because its result maybe a combination of two entries in the response, i.e. primary and temporary replica of the same partition.",0,0.9882233738899231
134098378,3621,becketqin,2017-08-19T18:52:50Z,can we add a java doc for this class?,0,0.989266037940979
134098547,3621,becketqin,2017-08-19T19:01:19Z,version should be 1.0.0.,0,0.9850334525108337
134098552,3621,becketqin,2017-08-19T19:01:27Z,ditto.,0,0.859873354434967
134098889,3621,becketqin,2017-08-19T19:19:36Z,should we change this name to alterreplicalogdiroptions as well?,0,0.9849272966384888
134100952,3621,becketqin,2017-08-19T21:13:57Z,do we need to have the `replicalogdirinfo` printed? it seems the output format would be pretty verbose.,0,0.9688020348548889
134101186,3621,becketqin,2017-08-19T21:28:44Z,we are still not throw exception here? am i missing something?,0,0.7696965336799622
134101387,3621,becketqin,2017-08-19T21:43:08Z,this assumes the only possibility of error is partition does not exist. is this always true?,0,0.9752875566482544
134101520,3621,becketqin,2017-08-19T21:51:45Z,the class also includes the broker id.,0,0.9884562492370605
134101861,3621,becketqin,2017-08-19T22:14:29Z,alterreplicalogdirrequest?,0,0.9881836771965027
134101922,3621,becketqin,2017-08-19T22:18:15Z,alterreplicalogdirresponse?,0,0.9863170981407166
134101991,3621,becketqin,2017-08-19T22:21:31Z,nit: dir -> dir,0,0.9796056151390076
134102436,3621,becketqin,2017-08-19T22:51:34Z,i see. we probably need more comments to explain this. from the code itself it is weird that we always expect an exception from a future.,-1,0.9718172550201416
134102479,3621,becketqin,2017-08-19T22:54:52Z,we may also need to update the command help message.,0,0.987030565738678
134102637,3621,becketqin,2017-08-19T23:08:57Z,"do we also want to look into the `preferredlogdirs`? in another word, do we want to have the preferred dir shown as temporary dir in the describelogdirresponse even if the replica has not been created yet?",0,0.9883611798286438
134102674,3621,becketqin,2017-08-19T23:13:23Z,should we also assert the log dir is non-null?,0,0.9834221005439758
134102720,3621,becketqin,2017-08-19T23:17:23Z,can we define a val for the number of log dirs?,0,0.9871407747268677
134102789,3621,becketqin,2017-08-19T23:21:43Z,"this test seems a little overlapping with the test in `adminclientintegrationtest.testalterreplicalogdirbeforetopiccreation`, do we need both?",0,0.9859910607337952
134103147,3621,lindong28,2017-08-19T23:50:04Z,sure. i added this comment `this class implements the common apis that are shared by options classes for various adminclient commands`.,0,0.9811872243881226
134103158,3621,lindong28,2017-08-19T23:50:34Z,"sorry, my bad. it is fixed now.",-1,0.9887268543243408
134103164,3621,lindong28,2017-08-19T23:50:58Z,fixed now.,0,0.9813029170036316
134103288,3621,lindong28,2017-08-20T00:00:20Z,"if we were to change it, we probably want to rename `alterreplicadirrequest` to `alterreplicalogdirreqeust`. but this seems a bit verbose to me. i think `alterreplicadirrequest` is probably ok and should not cause any confusion going forward. do you think this may cause confusion if we don't name it `alterreplicalogdirreqeust`?",0,0.7606356143951416
134103332,3621,lindong28,2017-08-20T00:04:53Z,"the current patch doesn't not print `replicalogdirinfo` anywhere to user except possibly in debug log. as far as the implementation of the `replicalogdirinfo` is concerned, i think it makes sense to print all its fields as does in the current patch. do you see any log statement that prints the `replicalogdirinfo` in an unnecessary manner?",0,0.9857075810432434
134103367,3621,lindong28,2017-08-20T00:07:38Z,oops.. i must have made some mistake such that the change is lost.. i have fixed it now.,-1,0.9796342253684998
134103401,3621,lindong28,2017-08-20T00:10:36Z,"i added this `throw new illegalargumentexception(""the partition "" + tp + "" in the response from broker "" + brokerid + "" is not in the request"");`",0,0.9861809611320496
134103422,3621,lindong28,2017-08-20T00:12:57Z,"this assumes that if `logdirinfo.error != errors.none`, then the log directory must be offline on this broker and the `replicainfos` in this `logdirinfo` will be empty. this is a valid assumption as of the current design.",0,0.9848575592041016
134103428,3621,lindong28,2017-08-20T00:13:52Z,"thanks a lot for the detailed review! i have changed it to `the topic name, partition number and the brokerid of the replica`.",1,0.9918209314346313
134103435,3621,lindong28,2017-08-20T00:14:46Z,thanks! fixed now.,1,0.9553532004356384
134103699,3621,lindong28,2017-08-20T00:38:03Z,"i don't think we should do that. including this information in `describelogdirrequest` will complicates the design of related apis and expose an internal optimization detail to user. on the other hand, i don't think it provides any benefit to the user. the purpose of describelogdirrequest is to get the load distribution of log directories on the broker so that user can determine a good reassignment replicas across log directories. is there any information in `preferredlogdirs` that can help with this purpose of the `describelogdirrequest`?",0,0.9576175212860107
134103805,3621,lindong28,2017-08-20T00:50:43Z,sure. i added the following check: [code block],0,0.9837741851806641
134103834,3621,lindong28,2017-08-20T00:55:17Z,not sure if i fully understand your question. do you mean something like `protected def logdircount: int = 1` which is added by this patch in `baserequesttest.scala`? i think we only need to add this when we need to vary the logdircount based on the test. it seems ok and simpler to just set logdircount to 2 for all tests in `adminclientintegrationtest`.,0,0.9771803617477417
134103883,3621,lindong28,2017-08-20T01:01:18Z,"i think it is ok to have both. if `alterreplicadirrequesttest.testalterreplicadirrequestbeforetopiccreation` passes but `adminclientintegrationtest.testalterreplicalogdirbeforetopiccreation` fails, it suggests that something is wrong in the kafkaadminclient. this seems to follow the existing pattern -- tests such as `deletetopicsrequesttest` and `createtopicsrequesttest` probably would not be needed for the same reason given that we already have tests for higher level apis that use them (if not then we should add the test for higher level apis that uses them). but i am not strong on this. i will remove this test if you think it is not necessary.",0,0.965945303440094
134104058,3621,lindong28,2017-08-20T01:19:24Z,good point. i added the following comments in the code: [code block] and i updated the help message for option `--reassignment-json-file` to the following: [code block],1,0.9827028512954712
134106014,3621,becketqin,2017-08-20T04:27:38Z,"i think we usually do not print the field name of a map value, we usually not not print the name field of the value. otherwise shouldn't we print the field name of the key as well? so for maps, it would simply be [key, value]. in this case, each entry could be printed as something like [topic-0-1, (currentlogdir=xxx, temporarylogdir=yyy, temporaryreplicaoffsetlag=zzz)], which is probably clear enough. btw, i forgot to comment that i think we should add documentation about what are the value combination of those fields mean. for example is it possible i get a currentlogdir=null, templogdir=xxx, offsetslage=-1? if so what does that mean.",0,0.9416636228561401
134124244,3621,lindong28,2017-08-20T19:32:23Z,"i see. i didn't understand the question previously. i wasn't aware that the conversion is to not print the name fild of the value. sure. i just changed both the `replicalogdirinfo.tostring()` and `replicainfo.tostring()` so that they don't print the class name in the string. btw, i assume that this conversion only applies to internal classes, which i think is reasonable. for public classes such as `alterreplicadirrequest`, the patch will still print the class name in the `tostring()` method as we do in e.g. `deletetopicsrequest`. i also added comment to fields in the `replicalogdirinfo` as show below. i think each fields can be interpreted independently and there is no need to explain how to interpret various combinations. for the example you mentioned, if currentlogdir=null, templogdir=xxx, offsetslage=-1, it means the primary replica is not found and there is only a temporary replica for this partition on the given broker, which is possible if the primary replica is in an offline log directory. [code block]",0,0.9402881860733032
134592277,3621,junrao,2017-08-22T20:26:50Z,unused import replicainfo. should we add the package name in front of describelogdirsresponse?,0,0.9889962673187256
134594816,3621,junrao,2017-08-22T20:36:53Z,would it be better to change the schema to have log_dir at the top level. sth like log_dirs => [log_dir [partitions]] partitions => [topic [int32]] this representation is more concise and is more consistent with how describe_log_dirs_response_v0 is structured.,0,0.9843168258666992
134616464,3621,junrao,2017-08-22T22:21:47Z,"in handletopicmetadatarequest(), if topics() is null, we treat it as for all topics. if topics() is empty, we just treat it as no topics. it would be useful to use the same approach here for consistency.",0,0.9823706150054932
134632381,3621,junrao,2017-08-23T00:23:26Z,"hmm, if we are representing the dir for the permanent and the temporary replica together here, shouldn't we further keep the lag for both permanent and the temporary replicas? also, it's not clear to me why we don't return the same info in describelogdirsresult.",0,0.9730825424194336
134632961,3621,junrao,2017-08-23T00:28:39Z,"it's probably better to include alterreplicadir() here too. if we think the api may change, we can mark it as unstable.",0,0.9861063957214355
134633840,3621,junrao,2017-08-23T00:37:27Z,this seems no longer used?,0,0.9484261274337769
134638546,3621,junrao,2017-08-23T01:21:01Z,"""on the broker ${replica.brokerid()}"" => ""on broker ${replica.brokerid()}""",0,0.9840293526649475
134639735,3621,junrao,2017-08-23T01:34:04Z,"with this, it's possible for a created log not to be in logs. then, we won't find this log in logmanager.getlog(). when serving requests like offsetbytimestamp, we will probably return unknowntopicpartitionexception, but ideally we want to return kafkastorageexception.",0,0.9862635135650635
134661753,3621,lindong28,2017-08-23T05:46:53Z,my bad. it is removed now. i will go over the patch again to look for unused import.,-1,0.9866639375686646
134662104,3621,lindong28,2017-08-23T05:50:00Z,sure. the original schema is motivated by the idea that alterreplicadir operation naturally maps a replica to a log directory. i am not very sure alterreplicadirrequest needs to be consistent with describelogdirrequest. but i think what you suggested will make the request more compact and smaller in size. i have made the change as suggested. thanks!,1,0.9455313086509705
134663181,3621,lindong28,2017-08-23T05:59:49Z,"the class `replicalogdirinfo` doesn't include that currentreplicalag because this information is not currently used in this patch. previously i think we can include `currentreplicalag` in this when it is needed, i.e. to track reassignment progress in kip-179. i have updated the patch to include `currentreplicalag` in `replicalogdirinfo`. i am not sure i fully understand the second question. what information should we add or remove from `describelogdirsresult`? i think `describelogdirsresult` and `describereplicalogdirresult` has different format because they are used to serve two different use-cases. these two classes are structured in a way that makes the respective adminclient apis easier to use.",0,0.8920729756355286
134663259,3621,lindong28,2017-08-23T06:00:48Z,sure. i have added it back to adminclient.,0,0.9705354571342468
134663285,3621,lindong28,2017-08-23T06:01:03Z,ah.. my bad. it is removed now.,-1,0.9882975220680237
134663350,3621,lindong28,2017-08-23T06:01:36Z,i have fixed this as suggested in multiple places in this method.,0,0.9847853183746338
134663939,3621,lindong28,2017-08-23T06:06:44Z,"after double checking the logic, i think we will actually return `kafkastorageexception` for `offsetbytimestamp` query if log creation failed. this logic is enforced in kip-112. more specifically, after broker receives leaderandisrrequest to create the log, if `logmanager.getorcreatelog()` throws `kafkastorageexception`, `partition.getorcreatereplica()` will also throw exception without putting this replica in the `partition.assignedreplicamap`. later we will execute the following code in `replicamanager.becomeleaderorfollower()`: [code block] this logic makes sure that this partition will map to `replicamanager.offlinepartition` when this broker receives any request from user, including requests for offsetbytimestamp. the response will return `kafkastorageexception` to the user.",0,0.9826483726501465
134683583,3621,lindong28,2017-08-23T08:09:29Z,sure. i have updated the patch as suggested.,0,0.9691935777664185
134794883,3621,cmccabe,2017-08-23T15:57:43Z,"we should use an accessor function for the following fields-- for all the usual reasons we do this in java. (unlike in scala, you cannot write an accessor later to transparently switch over users.)",0,0.9863697290420532
134795363,3621,cmccabe,2017-08-23T15:59:15Z,"is right-- you should handle this case. perhaps the server sent back bad data. the way to handle it is not to throw an exception, but to complete the relevant future(s) with an error. there are a few other cases where we handle bad server data by completing a future with failure in adminclient.",0,0.9239052534103394
134795858,3621,cmccabe,2017-08-23T16:01:02Z,i don't think we should map zero responses to cluster_authorization_failed. what if we need to return different error codes later? we should have an error code per log dir response.,0,0.973914623260498
134807975,3621,lindong28,2017-08-23T16:50:37Z,"currently the only request level error for describelogdirresponse is if the cluster_authorization_failed. this error will happen if and only if the error there is no log directories in the response. this is because if a broker is online and the user is authorized to describe cluster resource, then it is guaranteed that describelogdirresponse should return some log directories. also note that describelogdirresponse does include per-logdir error in the response. thus we don't need request level error for describelogdirresponse at this moment. is there any scenario that will request this error field in the future? if we don't have specific use-case for this field, can we add it only when we need it in the future?",0,0.9841681122779846
134809797,3621,lindong28,2017-08-23T16:58:18Z,good point. i have updated the code to complete all futures with illegalargumentexception when this happens.,1,0.9579616785049438
134815324,3621,lindong28,2017-08-23T17:21:46Z,i noticed that classes such as `updatemetadatarequest.partitionstate` makes its fields public instead of using accessor fields. are accessor fields needed by replicalogdirinfo because it is exposed to user via `adminclient.describereplicalogdir()`?,0,0.9857804179191589
135162431,3621,junrao,2017-08-25T00:33:41Z,should we guard the case that the same partition or the same log dir is specified more than once and error out?,0,0.9824476838111877
135165084,3621,junrao,2017-08-25T01:01:20Z,getpermanentreplicalogdir seems to match gettemporaryreplicalogdir better. ditto on getcurrentreplicaoffsetlag.,0,0.9311109781265259
135166115,3621,junrao,2017-08-25T01:12:42Z,"instead of using (_._2), could we use case to define named variables to make it clear? ditto on line 233.",0,0.9553320407867432
135167112,3621,junrao,2017-08-25T01:22:57Z,"hmm, intuitively, if a replica doesn't exist, setting a log dir for it should succeed, instead of getting an error. perhaps we should return success if the replica doesn't exist or is in the right dir, and throw an unsupported exception for now otherwise.",0,0.9736337065696716
135167447,3621,junrao,2017-08-25T01:26:43Z,do you mean broker 101?,0,0.9862776398658752
135167654,3621,junrao,2017-08-25T01:29:04Z,do you mean broker 102?,0,0.9866865873336792
135168551,3621,junrao,2017-08-25T01:38:48Z,is the comment accurate? it seems the test has invalid log dir.,0,0.9759140610694885
135168609,3621,junrao,2017-08-25T01:39:23Z,is the comment accurate?,0,0.9815764427185059
135168812,3621,junrao,2017-08-25T01:41:35Z,"could we add a test case that the length of ""log_dirs"" doesn't match that in ""replicas""?",0,0.9873284101486206
135168953,3621,junrao,2017-08-25T01:42:54Z,unused import,0,0.9649426341056824
135169300,3621,junrao,2017-08-25T01:46:53Z,"hmm, the event will be processed asynchronously after this call returns. should we guarantee that this event is processed before sending describe_log_dirs request?",0,0.9875776767730713
135182887,3621,lindong28,2017-08-25T04:45:59Z,"i think we don't need to add this logic in `alterreplicadirrequest` because the current implementation will always provide unique partition and log when instantiating `alterreplicadirrequest`. `alterreplicadirrequest` will only be instantiated in `adminclient.alterreplicadir()`. because `adminclient.alterreplicadir()` takes `map replicaassignment` as input, it guarantees that the partition in the `alterreplicadirrequest` will be specified only once. also, `alterreplicadirrequest.tostruct()` will group `topicpartitionreplica` by logdir and thus the logdir in the `alterreplicadirrequest` will be specified only once.",0,0.9838166236877441
135183018,3621,lindong28,2017-08-25T04:48:13Z,i am bit concerned that `getpermanentreplicalogdir` may mislead user into thinking log directory of this partition will never change. how about we rename `gettemporaryreplicalogdir` to `getfuturereplicalogdir`?,-1,0.9272777438163757
135183254,3621,lindong28,2017-08-25T04:51:51Z,sure. i replaced them with the following: [code block],0,0.9859662652015686
135184008,3621,lindong28,2017-08-25T05:03:03Z,"i think it depends on the semantics of alterreplicadirrequest. in my understanding ""alter"" means ""change the proper of something that already exists"". thus broker should not create replica for this partition if this replica does not already exist. and it is reasonable to throw exception to user because user requested to alter log directory of a replica that doesn't exist. does this make sense?",0,0.9739200472831726
135184035,3621,lindong28,2017-08-25T05:03:35Z,my bad. fixed now. thanks.,-1,0.9783037304878235
135184065,3621,lindong28,2017-08-25T05:04:11Z,ah.. fixed now. thanks!,1,0.9715511798858643
135184249,3621,lindong28,2017-08-25T05:07:10Z,my bad.. i replaced the comment with `when we execute an assignment that specifies an invalid log directory`.,-1,0.9895634055137634
135184640,3621,lindong28,2017-08-25T05:13:13Z,no... i have replaced the comment with the following: [code block],0,0.9579986929893494
135184811,3621,lindong28,2017-08-25T05:16:04Z,good point. i have changed the code to do `servers.head.replicamanager.handlelogdirfailure(offlinedir)`.,1,0.9244151711463928
135193414,3621,lindong28,2017-08-25T06:48:56Z,sure. i have added test `shouldfailifproposedhasinconsistentreplicasandlogdirs` for this.,0,0.9843206405639648
135372907,3621,junrao,2017-08-25T23:51:52Z,"yes, the java client behaves as you described. i was mostly concerned about how the broker handles requests from non-java clients.",0,0.9397929906845093
135372918,3621,junrao,2017-08-25T23:52:05Z,perhaps use getcurrentreplicalogdir and get getnewreplicalogdir?,0,0.9877120852470398
135372984,3621,junrao,2017-08-25T23:53:05Z,"hmm, i think alterreplicadirrequest just means the intention to alter the dir. it doesn't mean the change has to be completed. as long as the intention is remembered by the broker, it seems it's reasonable to return success. the weird thing right now is that in reassignpartitionscommand, the happy path is actually based on an exception in the response of alterreplicadirrequest. normally, the happy path should be when the response has no error.",-1,0.9385737776756287
135374404,3621,lindong28,2017-08-26T00:14:00Z,"thanks for the comment ! by non-java clients, do you mean the clients written by third-party and not maintained by in apache kafka repository? here is my thought: - if a thirty party client constructs the `alterreplicadirrequest` using the api `alterreplicadirrequest.builder(map partitiondirs)`, we still guarantee that both log directory and the topicpartition in the resulting `alterreplicadirrequest` will be unique. thus server doesn't have to worry about it. - if a third party client constructs `alterreplicadirrequest` without using our builder, and it constructs `alterreplicadirrequest` with duplicated topicpartition by mistake, the server won't be affected by this. this is because the `alterreplicadirrequest(struct struct, short version)` will generate the `map partitiondirs` which contains well-defined and unique partition to logdir mapping. also, since user constructs `alterreplicadirrequest` without using our builder, we won't help user detect this mistake by changing the code here. btw, this issue seems to also exist in `alterconfigsrequest`, which may contain duplicated entries for the same resource type and resource name. it may be reasonable to handle them in the same way as this patch does. does it make sense?",1,0.9576904773712158
135374956,3621,lindong28,2017-08-26T00:23:36Z,"i agree it doesn't have to be completed as long as it is remembered. however, currently this is only remembered in the memory which may be lost if broker restarts after it receives alterreplicadirrequest but before it receives leaderandisrrequest to create the replica. i think we probably don't want to return success to user and create replica is a different log directory later (if restart happens in the above case). has similar comment regarding the weirdness that we expect response to throw exception. but this weirdness exists only because this patch represents the first part of kip-113. after we fully implement the kip-113, we won't expect to see exception in the happy path. the logic in the reassignment will look like this: - call `adminclient.alterreplicadirrequest(replicaassignment)` without waiting for response - create the reassignment znode so that controller can start replica reassignment across brokers. - call `adminclient.alterreplicadirrequest(replicaassignment)` and verify that there is no error in the response. the implementation of `adminclient.alterreplicadirrequest` will treat `replicanotavailableexception` as a retriable error and retry up to the user-specified timeout. i think it is ok for this weirdness to exist for a short period of time before kip-113 is fully implemented. user won't be affected by this weirdness. does this make sense?",0,0.8497954607009888
135375065,3621,lindong28,2017-08-26T00:25:20Z,sure. i will update the patch to use `getnewreplicalogdir` and rename other fields as appropriate.,0,0.9786913394927979
135376799,3621,lindong28,2017-08-26T01:08:36Z,"after discussing with , i think it may be better to use `getfuturereplicalogdir`. if we were to use `getnewreplicalogdir`, do you think we should rename `is_temporary` field in `describe_log_dirs_response_v0` to `is_new`? if so, it kinds of collide with the `is_new` field in `leader_and_isr_request_partition_state_v1`. it seems a bit confusing. also, if we were to use `getfuturelogdir`, are you ok with renaming the field `is_temporary` to `is_future` in `describe_log_dirs_response_v0`?",0,0.629270076751709
135377833,3621,junrao,2017-08-26T01:36:04Z,"ok, if doesn't do harm on the server, we can punt on this.",0,0.9784913063049316
135377868,3621,junrao,2017-08-26T01:37:01Z,"ok, future is fine then. changing is_temporary to is_future also sounds good.",1,0.8947637677192688
135377870,3621,junrao,2017-08-26T01:37:03Z,"hmm, i thought for verification, we want to use describelogdirs not alterreplicadirrequest? also, for the first adminclient.alterreplicadirrequest(), i am not sure that we want to completely ignore the response. for example, if the request fails with authentication error, we probably want to error out, right? overall, are you saying that alterreplicadirrequest only returns no error if the log dir is in the target log dir? that means most of the time, the request will return error. this seems unintuitive since error should be the exception, not the norm.",0,0.6121724247932434
135378158,3621,lindong28,2017-08-26T01:47:38Z,"yes, we only use `describelogdirs` for verification. in the current patch, `reassignpartitionscommand` only checks for `replicanotavailableexception` using `alterreplicadirrequest` during execution (i.e. when --execute is specified). you are right. i simplified the logic of the first `adminclient.alterreplciadir()` in my previous response. more specifically, after kip-113 is fully implemented, the `reassignpartitionscommand` should use `adminclient.alterreplciadir()` to send `alterreplicadirrequest` without retry. and it should verify that either there is no error or the error is `replicanotavailableexception`. the second `adminclient.alterreplciadir()` should retry `alterreplicadirrequest` upon `replicanotavailableexception` until timeout. `alterreplicadirrequest` can also return no error even if the log directory is not the target log directory, as long as replica already exists on the broker. this is because if the replica already exists on the broker, the broker will create a directory for the temporary replica in the destination log directory. because this information is persisted on the disk rather than in memory, broker will continue to move replica to the destination log directory after restart.",0,0.9562550783157349
136207465,3621,junrao,2017-08-30T22:37:28Z,"the name of the method seems a bit confusing. it's not really clear what withoutdedup really means. could it be just named parsepartitionreassignmentdata()? also, could we document the return value?",-1,0.637355625629425
136208723,3621,junrao,2017-08-30T22:45:52Z,"ok, thanks for the explanation. this is fine then. could we document the error code/exception in alterreplicadirresult?",1,0.9152600169181824
136209635,3621,lindong28,2017-08-30T22:52:06Z,"this name is used following the name of the existing method `zkutils.parsepartitionreassignmentdatawithoutdedup`. if we name it `parsepartitionreassignmentdata` in `reassignpartitionscommand`, should we also rename the method in `zkutils` for consistency? note that there is an existing method `parsepartitionreassignmentdata(jsondata: string): map[topicandpartition, seq[int]]` in zkutils which justifies the use of `parsepartitionreassignmentdatawithoutdedup` in zkutils.",0,0.984437108039856
136210274,3621,lindong28,2017-08-30T22:56:29Z,sure. previously the error is only documented in `alterreplicadirresponse`. just now i added the error code documentation in `alterreplicadirresult` as follows: [code block],0,0.986944317817688
136211210,3621,junrao,2017-08-30T23:03:06Z,perhaps we can just get rid of zkutils.parsepartitionreassignmentdatawithoutdedup since the only caller is zkutils.parsepartitionreassignmentdata?,0,0.9891846179962158
136211869,3621,lindong28,2017-08-30T23:08:07Z,sure. i have updated the patch as suggested. thanks for taking time to review the patch!,1,0.9826077818870544
136690443,3621,becketqin,2017-09-02T06:25:28Z,"can we add a comment here for this? also, if the only possible error is log dir offline, would it be clearer to only check for that error and log an error message or throw exception in other cases?",0,0.9884301424026489
136703340,3621,becketqin,2017-09-02T20:31:09Z,"maybe worth adding a comment? also usually the clients do not infer an error code while the broker did not return it. maybe it is better to let the server to return cluster_authorization_failed. we are doing the same for `describeaclsrequest`. if we do that we will need to add response level error code, which probably makes sense.",0,0.9819706678390503
136710394,3621,ijuma,2017-09-03T07:28:17Z,", jun was referring to clients that don't use our code at all. librdkafka, kafka-python, etc.",0,0.9745570421218872
136711246,3621,ijuma,2017-09-03T08:21:42Z,"sorry for being late on this. why is this `alterreplicadir` instead of `alterreplicadirs` (or some other version that indicates the batch nature)? this is a batch api like every other api so it should indicate that via the name, right?",-1,0.9892308115959167
136711278,3621,lindong28,2017-09-03T08:23:58Z,i see. thanks for the information.,1,0.950271487236023
136711440,3621,lindong28,2017-09-03T08:32:55Z,"i think one reason to use alterreplicadir is that it presents a map from replica -> dir. it is probably a bit different from other names such as describeconfigs, which represents a collection of configs. do you like me to submit a patch to change it to a different name? what do you think about this name?",0,0.9767289161682129
136711492,3621,ijuma,2017-09-03T08:36:14Z,why did we remove this?,0,0.9090880155563354
136711557,3621,ijuma,2017-09-03T08:39:15Z,"thanks for the quick reply. right, it's a map from replica to dir instead of a single replica to dir. the name sounds like the latter to me. before doing a pr, let's see if we get consensus amongst yourself and the reviewers.",1,0.9343971014022827
136711582,3621,lindong28,2017-09-03T08:40:42Z,originally i added a similar comment to the new api. commented that this is unnecessary. i agree with this is unnecessary because `alterconfigsresult` returns `map >` which suggests that some configs may be updated successfully while others fail. thus there is no need to have extra comment in the api documentation to specify this. does this make sense?,0,0.9674686193466187
136712129,3621,ijuma,2017-09-03T09:10:32Z,"while i understand the sentiment, we have to remember that these apis will be used by people who are not familiar with kafka in the same way we are. we often get support questions because things that seem obvious to us are not clear to users. i disagree that we should remove clarification comments like the above in public apis.",-1,0.7436903715133667
136712322,3621,lindong28,2017-09-03T09:20:39Z,"i see. sure, i can submit a minor patch tomorrow for this (or please feel free to just commit a minor patch if you prefer). to keep the api document consistent and for the same reason you described, maybe we should have this comment (i.e. api is not transactional) for all those apis in the adminclient which may partially succeed, e.g. deletetopics?",0,0.9524323344230652
136712993,3621,ijuma,2017-09-03T09:58:32Z,"yes, i think that's a good idea. if you are ok with submitting a pr, that would be great. it's not urgent, we should aim to do it before 1.0.0 is released.",1,0.9487437009811401
136741892,3621,tedyu,2017-09-04T04:16:18Z,is illegalstateexception more approriate for this situation ?,0,0.6147817373275757
136742443,3621,tedyu,2017-09-04T04:27:46Z,nit: the 'else' can be omitted.,0,0.9824405312538147
136772853,3621,lindong28,2017-09-04T08:52:23Z,thanks much for catching this . you are right. i will fix this in [a link],1,0.9852816462516785
136772976,3621,lindong28,2017-09-04T08:53:01Z,originally i think the if/else may be better. the difference is very minor to me. i will remove `else` in [a link],0,0.9251860976219177
399149713,7898,OneCricketeer,2020-03-27T09:54:44Z,"imo, why not rewrite against `org.slf4j`?",0,0.9834716320037842
399149940,7898,OneCricketeer,2020-03-27T09:55:09Z,"based on the comments, how about `2.13.x`?",0,0.9875501990318298
399333888,7898,dongjinleekr,2020-03-27T15:08:24Z,"yes, i am now working with `2.13.1` and it seems like good.",1,0.8884187340736389
399335778,7898,dongjinleekr,2020-03-27T15:11:10Z,"`log4jcontroller` provides a dynamic `logger` querying functionality, not logging itself. it is why it uses log4j `logger`s directly. in contrast, the streams module does not provide those kinds of functionality so it uses slf4j fascade.",0,0.9876505732536316
400595313,7898,OneCricketeer,2020-03-31T01:48:42Z,"is zookeeper duplicated here?? also, does zookeeper transitively bring in log4j anywhere?",0,0.9892101883888245
400595736,7898,OneCricketeer,2020-03-31T01:50:16Z,it seems `org.apache.kafka.*` imports used to be first,0,0.9794512391090393
400596128,7898,OneCricketeer,2020-03-31T01:51:49Z,is the `.map()` needed? [code block],0,0.9883413910865784
400596367,7898,OneCricketeer,2020-03-31T01:52:44Z,"also, `collectors.tocollection(treeset::new)` might be useful",0,0.982724130153656
400596620,7898,OneCricketeer,2020-03-31T01:53:34Z,can `logger == null`?,0,0.986456036567688
400597136,7898,OneCricketeer,2020-03-31T01:55:15Z,it seems these imports used to be first,0,0.9835839867591858
400597441,7898,OneCricketeer,2020-03-31T01:56:30Z,"personally, rather than rely on src/test/resources, i would pull from the classpath... `loggingresourcetest.class.getclassloader().getresource(""log4j2.properties"")`",0,0.9856917262077332
400598244,7898,OneCricketeer,2020-03-31T01:59:26Z,remove this?,0,0.9706291556358337
400598312,7898,OneCricketeer,2020-03-31T01:59:40Z,remove this?,0,0.9706291556358337
400598447,7898,OneCricketeer,2020-03-31T02:00:11Z,this pattern looks different,0,0.9678901433944702
400598659,7898,OneCricketeer,2020-03-31T02:00:56Z,nit: these got rearranged,0,0.9845232963562012
401709877,7898,dongjinleekr,2020-04-01T15:35:11Z,fixed. please have a look at [a link]. :),1,0.978702187538147
401713158,7898,dongjinleekr,2020-04-01T15:39:40Z,"this duplication has been addressed in [a link]. since this setting contols only direct imports only, it does not bring `log4j` transitively.",0,0.9872144460678101
401713391,7898,dongjinleekr,2020-04-01T15:39:59Z,great. i will apply it. :),1,0.9936336278915405
401713720,7898,dongjinleekr,2020-04-01T15:40:27Z,no. log4j2 does not allow `logger == null`.,0,0.9699351191520691
401714074,7898,dongjinleekr,2020-04-01T15:40:58Z,agree. i will have a try.,0,0.8569393157958984
401714449,7898,dongjinleekr,2020-04-01T15:41:30Z,not yet. `log4j-appender` is still using log4j; `log4j2-appender` is under progress. :),1,0.8657900094985962
401714669,7898,dongjinleekr,2020-04-01T15:41:48Z,ditto :smiley:,0,0.660723090171814
401715288,7898,dongjinleekr,2020-04-01T15:42:40Z,"yes, but the reason is that it follows deleted `quickstart/java/src/main/resources/archetype-resources/src/main/resources/log4j.properties`; it has different pattern so i followed it.",0,0.9867830276489258
497371849,7898,tombentley,2020-09-30T09:30:32Z,shouldn't `connect.log.pattern` actually be something like this: [code block] ?,0,0.972794234752655
497376858,7898,tombentley,2020-09-30T09:38:53Z,is the `policies` really necessary if we're only using a single triggering policy? i t_hink_ you could just say [code block],0,0.9853023290634155
497378983,7898,tombentley,2020-09-30T09:42:20Z,use a `\` escaped newline to avoid the very long line.,0,0.9711276292800903
497380746,7898,tombentley,2020-09-30T09:45:17Z,"also since log4j2 i think it's often unnecessary to have to specify` loggers` and `appenders` upfront, they can be determined during parsing. unfortunately the docs don't bother saying when it _is_ necessary, but it would be easy for users to add their `logger....name` and `logger....level` properties only to find it didn't work because they forgot about adding the name to `loggers`, so it would be good to only specify `loggers` if we really need to. same applies to appenders and the other log4j config files too, of course.",0,0.9589676856994629
497381662,7898,tombentley,2020-09-30T09:46:48Z,why was `log4j.rootlogger=off` before but `warn` now?,0,0.9754118323326111
497385774,7898,tombentley,2020-09-30T09:53:23Z,"collect has a overload which takes a supplier of empty maps (i think you also have to provide a lamda for duplicate keys, annoyingly). that would allow you to avoid needing the `new treemap` in the `return`. alternatively just use `foreach` as previously.",0,0.8734414577484131
497387063,7898,tombentley,2020-09-30T09:55:23Z,you can avoid the `if` using `found.orelse(null)`,0,0.9879289269447327
497387624,7898,tombentley,2020-09-30T09:56:17Z,was changing the parameter name really necessary? it makes the diff noisier and the old name wasn't _so_ bad.,0,0.685269296169281
497391073,7898,tombentley,2020-09-30T10:02:20Z,"it's a pre-existing issue, but i think this is slightly incorrect since it would tread `com.foo` as an ancestor of `com.foobar`. really we should be using `startswith` with a logger name that we know ends with a `.`.",0,0.9776135683059692
497392952,7898,tombentley,2020-09-30T10:05:18Z,"this is the second time you've got a `.equals("""")`. it might be worth factoring into a `isrootlogger(logger)` method.",0,0.9849381446838379
497393514,7898,tombentley,2020-09-30T10:06:13Z,why was this necessary?,0,0.9134852290153503
497396302,7898,tombentley,2020-09-30T10:11:25Z,"the default when the level is not set should be the ancestor logger's level, rather than the root logger level, but i guess you're waiting for my pr to be merged, right?",0,0.9851427674293518
497400286,7898,tombentley,2020-09-30T10:18:56Z,"we probably need better coverage in the alter case (`testincrementalalterconfigsforlog4jloglevels()`, below). it tests inheritance from the root logger, but not an ancestor logger. but i guess this is something i should add to my pr.",0,0.976709246635437
497402528,7898,tombentley,2020-09-30T10:23:06Z,"`s""${classof[controllerintegrationtest]}#testcontrollermoveontopiccreation""`, and if not then there should be no need for the `tostring`",0,0.9848543405532837
497402639,7898,tombentley,2020-09-30T10:23:18Z,same comment.,0,0.9818967580795288
497402786,7898,tombentley,2020-09-30T10:23:37Z,same comment.,0,0.9818967580795288
497402868,7898,tombentley,2020-09-30T10:23:48Z,same comment,0,0.9822466969490051
497410244,7898,tombentley,2020-09-30T10:37:28Z,"it's a shame about the new asynchrony here, but i don't see an obvious we of avoiding it.",-1,0.9841169714927673
497412007,7898,tombentley,2020-09-30T10:40:48Z,again it's not really clear to me why this is added,0,0.5837797522544861
497413476,7898,tombentley,2020-09-30T10:43:42Z,"i can see this being a source of difficult to maintain tests, if you have to tweak the latch every time logging statements are added or removed.",0,0.9184653162956238
497415319,7898,tombentley,2020-09-30T10:47:28Z,"do we really need the caller to supply a `name`? it seems to force you to have to construct a unique name each time you want to use it, based on the test class and method name. but all that's needed is uniqueness and the removal of the appender at the end of the test, afaics. so just using a uuid or similar generated name would be sufficient and make call sites rather easier to read.",0,0.9327417016029358
497416562,7898,tombentley,2020-09-30T10:50:02Z,"i wonder if it would simplify the tests if this had methods for asserting the existence of messages (optionally within a timeout) rather than having to use the `setlatch(), await(), getmessages()` pattern in every test.",0,0.9426126480102539
497417343,7898,tombentley,2020-09-30T10:51:31Z,was this really necessary?,0,0.9740452170372009
500806583,7898,dongjinleekr,2020-10-07T07:50:01Z,"oh, i don't know why it is shown as a modification in diff view. in `config/tools-log4j.properties ` root logger level is `warn` by `log4j.rootlogger=warn, stderr`.",0,0.9751015901565552
500807752,7898,dongjinleekr,2020-10-07T07:51:52Z,great. i will improve the formatting and lining. let me see.,1,0.9843573570251465
500821253,7898,dongjinleekr,2020-10-07T08:14:05Z,no. `connect.log.pattern` is get referenced at the lines below: [code block],0,0.9880586266517639
500829824,7898,dongjinleekr,2020-10-07T08:27:30Z,"is this possible? all examples i saw explicitly state `policies`, like: - [a link] - [a link]",0,0.9866225123405457
500830940,7898,dongjinleekr,2020-10-07T08:29:14Z,"oh, i thought making it consistent with `loggingresource#setlevel` would be better.",0,0.9696812629699707
500838684,7898,dongjinleekr,2020-10-07T08:41:15Z,"it is related to a issue between log4j2 2.13.x and powermock; in short, it causes `java.lang.linkageerror` as of present. please see: - [a link] - [a link]",0,0.9866929650306702
500840081,7898,dongjinleekr,2020-10-07T08:43:23Z,right. fixed.,0,0.9636464715003967
500849730,7898,dongjinleekr,2020-10-07T08:58:12Z,"oh my, your approach is much simpler and more clear. okay, i will take this approach.",0,0.5945749878883362
500870442,7898,dongjinleekr,2020-10-07T09:30:27Z,"as you can see below, `new streamsconfig(props);` is called in every test method of this suite. so, this line is redundant. more importantly, it generates duplicated log messages and makes log message related test cases hard to validate.",0,0.9486786127090454
500882458,7898,dongjinleekr,2020-10-07T09:49:59Z,"good proposal. actually, it is the first approach i have taken. however, while running the tests repeatedly, i found that the log messages are not forwarded in designated timeout properly, and the tests go so flaky. each test runs correctly when i run them individually, but 3 ~ 5 tests were randomly failed when i run them in bulk, with `./gradlew :streams:test`. it seems like this symptom is related to the busy wait implementation of `listappender#getmessages` but i can't certain yet. after numerous trial and error, i found that the current approach is a little bit verbose but makes the test suites sustainable. it is the background of this api design.",1,0.6633466482162476
501043518,7898,dongjinleekr,2020-10-07T14:09:17Z,"exactly. however, i thought introducing randomness to the test cases is worse than some verbosity. let's wait for others' opinions.",-1,0.669564962387085
501046635,7898,dongjinleekr,2020-10-07T14:13:18Z,agree. let's add a additional test about that case.,0,0.9772807955741882
501048158,7898,dongjinleekr,2020-10-07T14:15:19Z,exactly.,0,0.9790678024291992
501054972,7898,dongjinleekr,2020-10-07T14:23:52Z,"agree. i am now thinking about a utility class that determines whether a given logger name is a child, descendent, parent, or ancestor of another logger.",0,0.9782506823539734
501060061,7898,dongjinleekr,2020-10-07T14:30:04Z,"well, i found a similar method to what you described in `collectors`, not in `stream#collect`. is this what you mean? [code block]",0,0.9851959943771362
769044309,7898,rafalmag,2021-12-14T21:04:51Z,please use 2.15.0 instead to avoid noise about cve-2021-44228,0,0.9854678511619568
769083607,7898,amuraru,2021-12-14T22:07:30Z,actually 2.16 please,0,0.9851160645484924
769193981,7898,showuon,2021-12-15T02:24:53Z,"we should say, please use the **latest** release of log4j2, please! :)",1,0.9800136089324951
779703586,7898,ispringer,2022-01-06T17:05:23Z,can this be bumped to `2.17.1` ([a link],0,0.9893085956573486
780114085,7898,dongjinleekr,2022-01-07T08:59:50Z,"yes, i did [a link] for [a link] and it will be also applied to this pr. :+1:",0,0.8021487593650818
783853620,7898,viktorsomogyi,2022-01-13T11:03:14Z,i think renaming in this case makes the code a bit clearer and consistent.,0,0.9694240093231201
783871962,7898,viktorsomogyi,2022-01-13T11:29:10Z,nit: instead of `.map(_._2)` you could use `.values`,0,0.9845325350761414
785830903,7898,viktorsomogyi,2022-01-17T10:32:27Z,i think i would also prefer generating a name in the `apply()` method. if someone uses the same name twice it might introduce an error but it's indeed easier to read without the `name` as tom proposed.,0,0.9773650765419006
785843643,7898,viktorsomogyi,2022-01-17T10:48:28Z,ran the tests and it seems like the powermock class loader isn't able to load these classes (as they have previously been loaded?). it doesn't cause a test failure but it's ugly and deferring to the system classloader fixes the issue. maybe has a more specific answer but i think it's fine to have this annotation here. [code block],-1,0.5633763074874878
786045157,7898,dongjinleekr,2022-01-17T14:14:41Z,"got it. i will update the pr to generate the context name automatically, like `logcapturecontext-xxxxxx`.",0,0.9535959362983704
786067964,7898,dongjinleekr,2022-01-17T14:41:52Z,"oh yes, initially `kafkastreamstest` needed `({""javax.management.*"", ""org.apache.log4j.*""})` like `workersourcetasktest` but, it does not need it anymore. it would be better to remove this annotation.",0,0.9826741814613342
788006560,7898,viktorsomogyi,2022-01-19T17:58:25Z,"why don't you change this (and all the similar cases) to the log4j2 property? if i get it right then after the upgrade `-dlog4j.configuration` won't work anyway so while i see the value of notifying the user, i think we should just use the log4j2 property outright. or is there a backward compatibity, so does `log4j.configuration` work under log4j2?",0,0.9868152737617493
788034050,7898,rgoers,2022-01-19T18:34:38Z,"yes, if you set log4j.configuration to reference a log4j.xml (log4j 1 configuration) and you have log4j-1.2-api on the classpath then log4j 2 will process the log4j 1 configuration. we improve this support with every release. substantial improvements will be in 2.17.2 which should come out by the end of the month.",0,0.9716264605522156
788207067,7898,dongjinleekr,2022-01-19T22:42:42Z,thanks for the clarification. it seems like we also have to upgrade to log4j 2.17.2 soon.,1,0.8870444297790527
793571163,7898,dongjinleekr,2022-01-27T12:48:30Z,"for `level#tolevel` semantics, see: - [a link] - [a link] - [a link] as you can see here, all of above follows the same semantics - they fallback to `debug` with unknown level.",0,0.98848956823349
794332702,7898,dongjinleekr,2022-01-28T09:24:29Z,fyi: [a link] cc/,0,0.9850516319274902
797627738,7898,mimaison,2022-02-02T13:53:12Z,nit: can we get rid of the extra spaces and have `name=value` for all these lines like in the other files?,0,0.9890902638435364
803805924,7898,mimaison,2022-02-10T15:36:58Z,is the plan to remove this and use the log4j2 file by default in the next major release?,0,0.9860439300537109
803816355,7898,mimaison,2022-02-10T15:46:17Z,nit: this is not aligned,0,0.9503738880157471
815384279,7898,showuon,2022-02-27T03:54:18Z,nit: can be simplified to: [code block],0,0.9874643087387085
815400322,7898,showuon,2022-02-27T07:36:10Z,+1,0,0.696722686290741
815400528,7898,showuon,2022-02-27T07:38:25Z,"is the additional ending ""space"" expected? and why?",0,0.9545111656188965
815400630,7898,showuon,2022-02-27T07:39:32Z,is the catch block expected?,0,0.9863065481185913
815401329,7898,showuon,2022-02-27T07:47:35Z,nice refactor,1,0.8681209087371826
815401515,7898,showuon,2022-02-27T07:49:17Z,"again, why additional ending space?",0,0.9195641279220581
815401739,7898,showuon,2022-02-27T07:52:04Z,why did we need these 2 supplier? i didn't see them get used in this test.,0,0.9624748229980469
815402457,7898,showuon,2022-02-27T07:59:29Z,"i'm thinking that we should add a clear javadoc in `logcapturecontext`, to explain when we should add `setlatch`, and when we should do `await`. i can see sometimes we don't set latch, but sometimes we set, and sometimes we do `await`, but sometimes not. could you help other developer with it?",0,0.9820917248725891
815403276,7898,showuon,2022-02-27T08:07:11Z,"since we only care about `warn` level in this test, we could create `ktablesource.class` with `warn` log as before, right?",0,0.9859575629234314
815403282,7898,showuon,2022-02-27T08:07:20Z,ditto,0,0.8428916931152344
815403425,7898,showuon,2022-02-27T08:08:34Z,any reason why we change the expected log message here?,0,0.9782251119613647
815404230,7898,showuon,2022-02-27T08:16:29Z,why can't we verify whole messages?,0,0.9354042410850525
815404252,7898,showuon,2022-02-27T08:16:46Z,ditto,0,0.8428916931152344
815404272,7898,showuon,2022-02-27T08:16:53Z,ditto,0,0.8428916931152344
815404434,7898,showuon,2022-02-27T08:18:21Z,nit: could we create log with warn only?,0,0.988649845123291
815404547,7898,showuon,2022-02-27T08:19:35Z,+1,0,0.696722686290741
815404639,7898,showuon,2022-02-27T08:20:46Z,"and, also please add docs for what latch size should be set.",0,0.9875079989433289
815407543,7898,showuon,2022-02-27T08:47:35Z,why did we remove `finally` block for `rocksdbstore.close()`? is there possible that we have resource leak here?,0,0.9832163453102112
815407744,7898,showuon,2022-02-27T08:50:03Z,ditto: potential resource leak?,0,0.8252111673355103
829746139,7898,dongjinleekr,2022-03-18T07:22:54Z,because of `streams/src/test/resources/log4j2.properties`: [code block],0,0.9876508116722107
829748108,7898,dongjinleekr,2022-03-18T07:26:53Z,no. this is a debris from the old code. removed.,0,0.8005936145782471
829777640,7898,dongjinleekr,2022-03-18T08:19:44Z,documentaton on `logcapturecontext` added.,0,0.9891345500946045
830011584,7898,dongjinleekr,2022-03-18T13:42:48Z,the try block with `logcaptureappender` resource was removed; that's the reason.,0,0.9874333739280701
461887873,9039,ableegoldman,2020-07-28T21:23:12Z,"not sure if you did this or your ide did it automatically, but nice :thumbs_up:",1,0.9166667461395264
462625072,9039,ableegoldman,2020-07-29T22:24:57Z,nit: call this `timedifferencems` to be in sync with `gracems`. also it can be private,0,0.9883042573928833
462626773,9039,ableegoldman,2020-07-29T22:29:17Z,nit: also rename the method `timedifferencems` to be consistent with `graceperiodms`,0,0.9874148964881897
462627186,9039,ableegoldman,2020-07-29T22:30:26Z,i think we can remove this suppression (and all the ones below),0,0.9859180450439453
462627276,9039,ableegoldman,2020-07-29T22:30:39Z,nit: extra space after `return`,0,0.9871758818626404
462640050,9039,ableegoldman,2020-07-29T23:06:31Z,"seems like this should have also had a check for `sessionwindows != null`, right? can we add that as well?",0,0.9789055585861206
462646319,9039,ableegoldman,2020-07-29T23:26:36Z,nit: alignment is off by one on the parameters,0,0.9886822700500488
462647029,9039,ableegoldman,2020-07-29T23:29:01Z,"i think it's ok to skip this; since it's a new operator, there's no old topology to be compatible with",0,0.9689759612083435
462647656,9039,ableegoldman,2020-07-29T23:30:52Z,i wonder why we have to do this for `count` but not for `aggregate` and `reduce`? is this intentional or an oversight? cc,0,0.9270836710929871
462653088,9039,ableegoldman,2020-07-29T23:48:39Z,"can we add an `else` here with `builder.withcachingdisabled()`? it doesn't make a difference logically, it just seems easier to understand (again, also in `slidingwindowedcogroupedkstreamimpl`)",0,0.9851190447807312
462653237,9039,ableegoldman,2020-07-29T23:49:12Z,you should be able to remove this suppression and comment (here and in `slidingwindowedcogroupedkstreamimpl`),0,0.9890189170837402
462653505,9039,ableegoldman,2020-07-29T23:50:01Z,let's just remove this comment since it's the only style retention here (also in `slidingwindowedcogroupedkstreamimpl`),0,0.9880378246307373
462653753,9039,ableegoldman,2020-07-29T23:50:47Z,we can remove this,0,0.9872204661369324
462655858,9039,ableegoldman,2020-07-29T23:58:03Z,"i was wondering what this method is actually used for so i checked out the callers of `kstreamwindowaggregate#windows`. there's a method called `extractgraceperiod` in `graphgracesearchutil` where we might actually need to make a small addition to include the new sliding window processor. i think it's for suppression, which needs to figure out the grace period of the upstream operator since grace period doesn't get passed in directly to `suppress`",0,0.9787617921829224
462658903,9039,ableegoldman,2020-07-30T00:08:03Z,"do you think we actually need to enforce that the retention period be a little longer for sliding windows? i was just thinking that since the range scan starts at `timestamp - 2 * windows.timedifference()`, maybe we should actually enforce that the retention period be >= `2 * timedifference + graceperiod` in case we need to get the aggregate value from some older window that has technically expired. haven't checked the math so i'm not sure that's the correct value exactly, but it seems like it might need to be a little bigger. any thoughts?",0,0.9321097135543823
462660320,9039,ableegoldman,2020-07-30T00:13:10Z,"in general it's better to use a more descriptive variable name than a shorted one with a comment. it's not always possible to describe a variable exactly in a reasonable length, but i think in this case we can say `curleftwindowalreadyexists` or `curleftwindowalreadycreated` or something might be better to use `alreadycreated` when we're specifically talking about whether or not a window already exists in the window store, and can use `exists` when we're talking about whether a window is possible regardless of whether it currently has been created or not",0,0.9732534885406494
462661922,9039,ableegoldman,2020-07-30T00:19:14Z,"does that make sense? in particular i feel like we're using `exists` to mean one thing for `left/rightwindowexists`, and then we mean another thing entirely in `prevrightwindowexists`. ie `prevrightwinalreadycreated` is more similar to what we mean by the `left/rightwindowexists` variables",0,0.961858868598938
462662132,9039,ableegoldman,2020-07-30T00:19:57Z,this comment doesn't seem quite correct,-1,0.5777329206466675
462662498,9039,ableegoldman,2020-07-30T00:21:20Z,can we also name this variable a bit more clearly instead of the comment? like `foundcloseststarttimewindow` or something. same with `foundfirstendtime`,0,0.9880185127258301
462663297,9039,ableegoldman,2020-07-30T00:24:13Z,maybe add a comment saying that this condition will only be hit on the very first record. or it might be reasonable to pull this one condition out of the loop and just handle it before entering the loop,0,0.9835809469223022
462663911,9039,ableegoldman,2020-07-30T00:26:22Z,"actually maybe `foundright/leftwindowaggregate` would be good, since that's what ""the window with the closest start/end time to the record"" actually means to us",0,0.9727448225021362
462667387,9039,ableegoldman,2020-07-30T00:38:53Z,"should this be inside the `if (!foundfirst)` condition above? we only want to save the aggregate of the first window we find with a start time less than the timestamp right? also, i think we might need to check that the max timestamp of this window is greater than the current record's timestamp. if not, then the right window will be empty. for example, we have a record a at 10 and a record b at 11 and then process a record at 15. obviously, the new right window will be empty. but the first window we'll find with a start time less than 15 will be [11, 21] with agg b.",0,0.976874053478241
462667988,9039,ableegoldman,2020-07-30T00:40:56Z,nit: put each parameter on its own line,0,0.9879564642906189
462669250,9039,ableegoldman,2020-07-30T00:45:20Z,"seems like we're aggregating with the new value twice; we call `aggregator.apply` once in this if/else branch but then also call it again in `putandforward`, right?",0,0.9854360222816467
462677427,9039,ableegoldman,2020-07-30T01:16:27Z,can we add a comment to clarify that we're checking whether it's a left window because that tells us there was a record at this window's end time,0,0.9863812327384949
462677774,9039,ableegoldman,2020-07-30T01:17:55Z,"i feel like i'm just way overthinking this, but i keep getting these variables confused. maybe we could call this guy `prevrightwindowcanexist`? does that seem to get at its underlying purpose?",-1,0.9704243540763855
462678777,9039,ableegoldman,2020-07-30T01:21:38Z,can we remove this and just `break` out of the loop immediately at the end of the `isleftwindow` condition block?,0,0.9876899719238281
462679991,9039,ableegoldman,2020-07-30T01:26:22Z,"i think we need to pass in the new maximum window timestamp here, not the window start time",0,0.9841601252555847
462682266,9039,ableegoldman,2020-07-30T01:32:45Z,ok i may have lost the trail of logic here...are we just checking `prevrightwinexists` as an indicator of whether we actually found any records to the left of our record within range? could/should we check `foundfirstendtime` instead?,0,0.6556698679924011
462682718,9039,ableegoldman,2020-07-30T01:34:10Z,"since it's a left window, the max timestamp should always be `timestamp`, right?",0,0.9875420928001404
462683258,9039,ableegoldman,2020-07-30T01:36:00Z,can we put this condition into a method and give it a clear name to describe what this means? eg [code block],0,0.9877696633338928
463026843,9039,lct45,2020-07-30T14:13:34Z,"the original just had the check for `sessionmerger != null`, are there scenarios where the sessionmerger would be null but the sessionwindows wouldn't? i did think it was kind of inconsistent to check 'sessionmerger' just that one time and check 'sessionwindows' the other times so maybe it was a mistake",0,0.5965895652770996
463036048,9039,lct45,2020-07-30T14:26:20Z,done!,0,0.514024555683136
463039985,9039,lct45,2020-07-30T14:31:32Z,"that's a good point. i think that `>= 2* timedifference + graceperiod` makes sense. adding graceperiod is just to help with out-of-order records, right? since for a normal record we won't need anything beyond 2*timedifference",1,0.8963899612426758
463046306,9039,lct45,2020-07-30T14:40:00Z,"yeah this makes sense, the boolean naming has definitely been a struggle. i think it's clearer actually if i change `prevrightwinexists` to `prevrightwinpossible` since that's what we're saying. i agree that for `leftwinexists` and `rightwinexists`, `alreadycreated` makes more sense.",0,0.8916639089584351
463047237,9039,lct45,2020-07-30T14:41:16Z,"yeah that's much clearer, and differentiates between the other bools better",0,0.9593267440795898
463056420,9039,lct45,2020-07-30T14:53:37Z,"i'm not sure if it can be moved out of the loop unless we also move a check for if the first is a window whose aggregate we need to update, which is easy to do but gets back to the redundant code that the algorithm had before having one while loop. i did update the comment though",0,0.9711139798164368
463063406,9039,lct45,2020-07-30T15:03:02Z,"yeah i think you're right that the aggregate should be in the `if()`, good catch. we could check max timestamp, but this scenario should be covered already. before we create a right window we do the boolean checks and since any in-order-record won't have either a `foundleftwinfirst` or the `prevrightwinalreadycreated` and one of them needs to be true for the right window to get created after the `while()`. i haven't fully thought through checking with maxtimestamp but it seems like that would work, if that way seems clearer i can alter the algorithm and run through the examples to make sure that covers everything",1,0.706383466720581
463073842,9039,lct45,2020-07-30T15:17:48Z,"aha, i thought there was a scenario where the `putandforward` function wouldn't be so simple. yeah you're right, i updated it so the value of the record is only added in `putandforward`",0,0.8860647678375244
463076565,9039,lct45,2020-07-30T15:21:23Z,"updated above! changed to `prevrightwindowpossible` , lmk if that still seems confusing. i definitely kept getting them all mixed up so i think this will help",0,0.7825818657875061
463077196,9039,lct45,2020-07-30T15:22:21Z,100%,0,0.9072310924530029
463078058,9039,lct45,2020-07-30T15:23:36Z,good catch,1,0.9703027606010437
463083346,9039,lct45,2020-07-30T15:31:00Z,"yeah that's what `prevrightwinexists` is doing right now, we could store the full `valueandtimestamp` for `foundfirstendtime` and check to see if the max timestamp is within the range of recordtime-timedifference",0,0.9811428785324097
463083821,9039,lct45,2020-07-30T15:31:38Z,yes!,0,0.8127877116203308
463088582,9039,lct45,2020-07-30T15:38:57Z,"changed to ` if (leftwinagg.timestamp() < timestamp && leftwinagg.timestamp() > timestamp - windows.timedifferencems()) { valueandtime = valueandtimestamp.make(leftwinagg.value(), timestamp); } else { //left window just contains the current record valueandtime = valueandtimestamp.make(initializer.apply(), timestamp); }`",0,0.9855161309242249
463091437,9039,lct45,2020-07-30T15:42:56Z,"to go with your above comment about the maxtimestamp, i changed this to be `if (!rightwinalreadycreated && rightwinagg.timestamp() > timestamp)` is this clearer or should it still be in a new method?",0,0.9820814728736877
463092579,9039,lct45,2020-07-30T15:44:41Z,"changing both of the `if()` for creating new windows cut down like half of the booleans too, which i think is good",0,0.8010842204093933
464728426,9039,mjsax,2020-08-04T00:19:22Z,"the build should actually fail on wildcard imports... do we have some checkstyle gaps? can you maybe look into that (if not, also ok).",0,0.981571614742279
464728901,9039,mjsax,2020-08-04T00:21:03Z,this pr is rather larger. would it maybe make sense to split it into 2 and add co-group in it's own pr?,0,0.9326033592224121
464729126,9039,mjsax,2020-08-04T00:21:44Z,nit: double `/**`,0,0.9791148900985718
464729311,9039,mjsax,2020-08-04T00:22:28Z,"nit: if you want to have a new paragraph, you need to insert ` ` tag -- otherwise, the empty line is just ignored all it's going to be one paragraph. -- if you don't want a paragraph, please remove the empty line.",0,0.9828149676322937
464729348,9039,mjsax,2020-08-04T00:22:35Z,as above.,0,0.978552520275116
464729534,9039,mjsax,2020-08-04T00:23:14Z,type `[w]indows`,0,0.9858967661857605
464729743,9039,mjsax,2020-08-04T00:23:56Z,`and [a] given` ?,0,0.9848655462265015
464730686,9039,mjsax,2020-08-04T00:26:58Z,"we must use html list markup to get bullet points rendered, ie, ` ` and ` ` (cf [a link]",0,0.9860777854919434
464731092,9039,mjsax,2020-08-04T00:28:25Z,"`are processed` -> sounds like processing time semantics; maybe better `occur in the stream (i.e., event timestamps)`",0,0.9827916026115417
464731554,9039,mjsax,2020-08-04T00:29:58Z,reference to `cogroupedkstream` is missing,0,0.9815923571586609
464731762,9039,mjsax,2020-08-04T00:30:46Z,as above (won't comment on this again) -- please address throughput the whole pr.,0,0.9837342500686646
464732204,9039,mjsax,2020-08-04T00:32:24Z,`timedifference (timedifference)` (redundant) should be `time difference (timedifference)` `must be larger than zero.` -> `must not be negative.`,0,0.982257068157196
464732462,9039,mjsax,2020-08-04T00:33:30Z,i guess a `timedifference` of zero should be allowed to define a sliding window of size `1ms`,0,0.9879671931266785
464732572,9039,mjsax,2020-08-04T00:33:53Z,as above -> should be `timedifferencems < 0`,0,0.9867450594902039
464733014,9039,mjsax,2020-08-04T00:35:30Z,"for consistency: `grace period (grace) must` ? frankly, i am not sure if we need to have ""natural language"" and the parameter name in those error messages -- also above. but we should do it in a consistent manner imho.",0,0.9318643808364868
464734041,9039,mjsax,2020-08-04T00:39:23Z,i agree with sophie that his check seems a little weird. we should check that either both (sessionwindows and sessionmerger) are null or not null.,-1,0.5768560767173767
464735173,9039,mjsax,2020-08-04T00:43:50Z,"i think we should do this check in `init` and use a `runnable` that we just call blindly (ie, depending on the check, we instantiate the one or other `runnable` and each `runnable` implements a different algorithm.",0,0.9863749742507935
464735252,9039,mjsax,2020-08-04T00:44:11Z,why do we suppress instead of fix the issue? (or add an exception to the `suppress.xml` file if we really need it),0,0.975623607635498
464736052,9039,mjsax,2020-08-04T00:47:16Z,"i think we should also drop if `value == null` ? (it seem this `null` check is missing in the existing time/session-window aggregate processors, too)",0,0.9878295660018921
464736550,9039,mjsax,2020-08-04T00:49:24Z,"maybe we have the same issue in other processors, too (we might even have a ticket for it?) but won't we need to preserve `observedstreamtime` across restarts? it's transient atm... (just want to confirm -- maybe it's ok as other processor do it the same way and we need to fix if for all of them at once?)",0,0.982020914554596
464736969,9039,mjsax,2020-08-04T00:51:12Z,the comment seems redundant -- it just says exactly what the next line of code says.,0,0.8313954472541809
464737602,9039,mjsax,2020-08-04T00:53:54Z,"no need to pass in an `instant` -- we should just pass in the `long` directly. it might not be clear from the type hierarchy, but the overloads that accept `long` are only deprecated for the `readonlyxxx` store, but are still available on the ""read/write"" stores to avoid unnecessary runtime overhead.",0,0.9886668920516968
464738212,9039,mjsax,2020-08-04T00:56:11Z,why `+ 1` ?,0,0.9794650673866272
464738932,9039,mjsax,2020-08-04T00:59:18Z,"as above. (also, this code seems to be duplicated; we should move it into `process()` before we call the the actual `processreverse` or `processinorder` methods.",0,0.978118896484375
464739084,9039,mjsax,2020-08-04T00:59:53Z,as above,0,0.9783914685249329
464739153,9039,mjsax,2020-08-04T01:00:07Z,nit: move `key` to the next line,0,0.9889292120933533
464739977,9039,mjsax,2020-08-04T01:03:19Z,why `* 2` ?,0,0.9757137298583984
464740108,9039,mjsax,2020-08-04T01:03:51Z,why `* 2` ?,0,0.9757137298583984
464740325,9039,mjsax,2020-08-04T01:04:45Z,why this?,0,0.6024207472801208
464740712,9039,mjsax,2020-08-04T01:06:18Z,we should not use this annotation (even if we still have code that used it... we are working on migrating test away lazily). we should instead use `assertthrows` and also verify the exception error message. same below.,0,0.9800794720649719
464740960,9039,mjsax,2020-08-04T01:07:06Z,"beside the fact, that zero should be valid imho, what do we gain by testing `0` and `-1` ?",0,0.9849298596382141
464741103,9039,mjsax,2020-08-04T01:07:51Z,this line seems to be unnecessary for this test?,0,0.9343542456626892
464741202,9039,mjsax,2020-08-04T01:08:16Z,this is also a pattern we try to move off. use `assertthrows` instead.,0,0.9881030917167664
464741688,9039,mjsax,2020-08-04T01:10:08Z,"why do we need three tests? if you want to ""randomize"" it, maybe just use `random` to generate `difference` and `grace` input instead of hard coding them?",0,0.9833417534828186
464741801,9039,mjsax,2020-08-04T01:10:33Z,as above.,0,0.978552520275116
464741983,9039,mjsax,2020-08-04T01:11:13Z,what is the difference between `verifyinequality` and `assertnotequals` ?,0,0.984322726726532
464742330,9039,mjsax,2020-08-04T01:12:30Z,this should be two test: - `shouldnotbeequalfordifferenttimedifference` - `shouldnotbeequalfordifferentgraceperiod`,0,0.9846054315567017
464744504,9039,mjsax,2020-08-04T01:20:48Z,why is `endtime = long.max_value`? should it not be `firstbatchtimestamp` ?,0,0.9820550084114075
464744963,9039,mjsax,2020-08-04T01:22:32Z,`firstbatchleftwindow` -> `firstbatchleftwindowstart` maybe also introduce `firstbatchleftwindowend = firstbatchtimestamp`,0,0.9817564487457275
464746013,9039,mjsax,2020-08-04T01:26:26Z,maybe add comment to clarify which input should trigger which output: [code block],0,0.9838826656341553
464746981,9039,mjsax,2020-08-04T01:30:05Z,"we should add a fourth batch with ts like 10k to get the windows when the second batch drops outs, too.",0,0.9849851131439209
465073439,9039,lct45,2020-08-04T14:02:56Z,"would checking both be redundant? it looks like the method that ultimately calls this one will check that sessionmerger is not null for session windows, so i think either both of these will be null or neither will be null",0,0.983430027961731
465079294,9039,lct45,2020-08-04T14:10:57Z,"we want to be able to find the furthest window for which we can create a corresponding right window, so for any record the furthest window we will ever need will start at `timestamp - 2 * timedifference`, but we will need to have these around to calculate new windows, hence the longer retention time.",0,0.9809788465499878
465094963,9039,lct45,2020-08-04T14:30:49Z,"because the windows are sorted, the windows created by each record aren't consecutive, so i added comments describing each window, but only did it for a since all the other keys are processed the exact same way. sample comment: `// a @ secondbatchtimestamp left window created when a @ secondbatchtimestamp processed`",0,0.9763025045394897
465097558,9039,mjsax,2020-08-04T14:34:22Z,"well, yes and no. we can follow two strategies: (1) we rely on the user to only set all `null` (for the non-windowed aggregation case) or either one of `windows`, `slidingwindow`, or `sessionwindow+sessionmerger` and we don't do any verification if the method is called correctly or not. however, for this case, we don't need to do any redundant not-null check and we could just write: [code block] or, (2) we do not ""trust"" the caller and do a proper check that the provided arguments make sense. and the existing code already has such a safe guard and does checks that not multiple windows are passed in and throws an `illegalargumentexception` if the caller makes a mistake. i personally prefer to have a safe guard (especially on the non-hot code path) as it may prevent bugs. however, the current check is not complete, as it does not verify that `sessionmerger` must be not-null when `sessionwindows` is not-null; this may lead to a potentially cryptic `nullpointerexception` later that is harder to understand. if we do the check and throw a proper `illegalargumentexception(""sessionmerger cannot be null for sessionwindows"")` and `illegalargumentexception(""unexpected sessionmerger parameter: should be null because sessionwindows is null"");` help to identify the issue quickly.",0,0.9254104495048523
465099913,9039,mjsax,2020-08-04T14:37:23Z,"ack. makes sense. might be worth to add a comment why we need an ""unexpected"" large retention time.",0,0.9455338716506958
465101059,9039,mjsax,2020-08-04T14:39:00Z,with regard to above: the error message to does align to the required minimum retention time. it says `must be no smaller than its window time difference plus the grace period.`...,0,0.9765254855155945
465111665,9039,lct45,2020-08-04T14:53:23Z,"good catch, will do",1,0.9726763367652893
465191505,9039,lct45,2020-08-04T16:51:54Z,"there seems to be a bug in `timewindoweddeserializer` related to [a link] that ends up setting the windowsize to `long.max_value`. for the purposes of testing, i don't think having it as the max value is totally awful (just somewhat awful) and the window end calculations are all tested in a different set of tests done through topology driver. i'll make a ticket for this bug and try to get it fixed when i'm done with testing",-1,0.9393858909606934
465193735,9039,lct45,2020-08-04T16:55:32Z,"i think just confirming that the correct error will be thrown when someone sets a `timedifference` we don't want. i'll update all the `windowsize` to be `timedifference` and i agree, no need to check that it isn't 0",0,0.9662485122680664
465194845,9039,lct45,2020-08-04T16:57:19Z,"re-examining the test, it looks like it does the same thing as `graceperiodmustnotbenegative()` so i think the test can be removed entirely",0,0.9830760955810547
465205088,9039,lct45,2020-08-04T17:15:08Z,"whoops, not on purpose. thanks for the check",1,0.6555774211883545
465219522,9039,lct45,2020-08-04T17:40:13Z,"to clarify, are you wanting to add records that would fall after the third batch _outside_ of all the existing windows, or so that it will fall into the third batch's windows but not the second batch's windows?",0,0.9851080775260925
465334577,9039,lct45,2020-08-04T21:15:01Z,"we could, but it would only pull out 3ish classes and not very many lines, so i don't think it would make this pr feel much smaller",0,0.8658349514007568
465336976,9039,lct45,2020-08-04T21:20:12Z,so we can check to see if the record that is being processed has an already existing right window (that would start at timestamp+1) without doing another call to the store,0,0.9868338704109192
465339322,9039,lct45,2020-08-04T21:25:19Z,fixed for both,0,0.9801525473594666
465348679,9039,lct45,2020-08-04T21:46:37Z,"they look to be fairly similar, and it seems like the tests use both consistently. `verifyinequality` seems to be more thorough, and to be consistent with the above `equalsandhashcodeshouldbevalidforpositivecases` i think i'll use `verifyinequality` for this test, unless someone has an objection",0,0.9456269145011902
465369865,9039,ableegoldman,2020-08-04T22:40:42Z,"why do we have a single method that accepts all three window types and then checks them all individually to enforce that only one type of window is actually ""set""? seems like we could enforce this implicitly by having a separate method for time, session, and non-windowed aggregates and then just calling the correct signature. ie `sessionwindowedcogroupedkstreamimpl` calls `build(...sessionwindows, sessionmerger) and so on. maybe i'm missing something here because i wasn't following the cogroup kip that closely, but is this even exposed to the user in any way? my understanding is that there's no way for this check to be violated by any kind of user input, because this method is only ever called directly by streams internal code with `null` hardcoded for the unused window types. i think it's more of an internal consistency check for streams than an input validation for the user (and it seems unnecessary: see above)",0,0.9516788125038147
465371635,9039,ableegoldman,2020-08-04T22:45:29Z,"seems like the cogroup stuff makes up a pretty small amount of the overall pr, but up to leah",0,0.9475889801979065
465374004,9039,ableegoldman,2020-08-04T22:52:21Z,"we definitely have the issue in all processors right now lol. it's not any more of a problem for this sliding windows algorithm as for any other operator that defines a grace period, at least. we might end up not dropping a late record that we should have; for sliding windows we'd get one extra window (with this record at the window end) whereas for a hopping/tumbling window we'd get n extra windows (however many overlaps there are)",1,0.8693274259567261
465379071,9039,ableegoldman,2020-08-04T23:07:35Z,not saying all this needs to be cleaned up in this pr. if we check one thing (eg `sessionmerger`) then we should check everything (eg `sessionmerged != null && sessionwindows != null`). we can decide whether we really need to check anything as followup,0,0.9653418064117432
465379566,9039,ableegoldman,2020-08-04T23:09:14Z,maybe we can add this answer as a comment in the code for future readers,0,0.9782276153564453
465380753,9039,ableegoldman,2020-08-04T23:13:03Z,"just to clarify, we don't get any additional output when the stream time is advanced and older windows drop out of the grace period. we've already forwarded their final state when the last record to update that window was processed. not sure if that's what you meant by ""get the windows when the batch drops out"" or not?",0,0.9602131247520447
465382189,9039,ableegoldman,2020-08-04T23:17:51Z,"not sure, i think `and given window grace` makes grammatical sense. but either way",0,0.9639980792999268
465382663,9039,ableegoldman,2020-08-04T23:19:29Z,"it took me a second to understand the structure of this sentence, can we insert an `and` after the `record's timestamp`?",0,0.9856330752372742
465399031,9039,ableegoldman,2020-08-05T00:13:33Z,extra `/*` here,0,0.9849667549133301
465399853,9039,ableegoldman,2020-08-05T00:16:39Z,technically this is an `xor` not an `or` :face_with_tongue:,0,0.9727407693862915
465400403,9039,ableegoldman,2020-08-05T00:18:42Z,"can you revert the line changes here and below? nothing wrong with them, but the fewer lines/classes changed in the pr, the better",0,0.9838400483131409
465401189,9039,ableegoldman,2020-08-05T00:21:40Z,"think you missed changing this in the cogrouped class, this should be 2*timedifference right?",0,0.9690273404121399
465402473,9039,ableegoldman,2020-08-05T00:26:16Z,i think we need a null check here like we have down in `slidingwindowedkstreamimpl#materialize`,0,0.9829683899879456
465407448,9039,ableegoldman,2020-08-05T00:45:26Z,+1 to add a comment on the extra retention (here and in slidingwindowedcogroupedkstreamimpl),0,0.9346644878387451
465407638,9039,ableegoldman,2020-08-05T00:46:16Z,should be `no smaller than twice its window time difference...`,0,0.9709510207176208
465408876,9039,ableegoldman,2020-08-05T00:50:59Z,"+1 to using a random number instead of multiple lines. if it does happen to fail on a specific random number, we should be sure to print that number for reproducing it later. see taskassignorconvergencetest#runrandomizedscenario for example",0,0.9704035520553589
465409330,9039,ableegoldman,2020-08-05T00:52:44Z,"took me a second to understand this test, ""negativecases"" made me think the timedifference/grace were supposed to be negative. +1 to matthias's suggestion for naming (and splitting into two tests)",0,0.8050816059112549
465412482,9039,ableegoldman,2020-08-05T01:03:59Z,"can you leave a todo here to make sure we remember to change this to `reversefetch`? seems unlikely we'd forget, but you never know",0,0.9836390018463135
465414316,9039,ableegoldman,2020-08-05T01:11:09Z,"which check? i was just thinking that, since the window starting at record.timestamp + 1 is basically a special case, we can just pull it out of the loop completely. we don't have to update anything since the record doesn't fall into this window, right? basically just before entering the loop we check `if next.key.window().start() == timestamp + 1` and if so set `rightwinalreadycreated` and then skip to the next record",0,0.9758240580558777
465414863,9039,ableegoldman,2020-08-05T01:13:02Z,"we don't technically need `continue` at the end of each condition, right?",0,0.9768236875534058
465416585,9039,ableegoldman,2020-08-05T01:19:27Z,"awesome! i might still recommend pulling the `rightwinagg != null && rightwinagg.timestamp() > timestamp` check out into a method called `rightwindowisnonempty` or something, but it's definitely a lot easier to understand now even without that :grinning_face_with_smiling_eyes:",1,0.992428719997406
465418942,9039,ableegoldman,2020-08-05T01:28:01Z,"we need to check `leftwinagg` for null, right? also, is it ever possible for `leftwinagg` to be non-null but not satisfy this condition? maybe we can just check `leftwinagg != null` and if so, then assert that `leftwinagg.timestamp() < timestamp && leftwinagg.timestamp() > timestamp - windows.timedifferencems()` is always true (eg throw an `illegalstateexception` if it's not)",0,0.9850650429725647
465419531,9039,ableegoldman,2020-08-05T01:30:09Z,can we remove the `math.max` thing for now and just drop records that are too early for us to process for now?,0,0.9870657920837402
465421190,9039,ableegoldman,2020-08-05T01:36:28Z,"just a note to other reviewers: we're planning to revisit the issue of ""early"" records later and are just dropping them for now to make the general algorithm easier to review and understand. it needs some special handling for the edge case of records that arrive earlier than the full sliding window due to the inability to store windows with negative start times",0,0.9636947512626648
465421265,9039,ableegoldman,2020-08-05T01:36:42Z,nit: put this on one line,0,0.9842095375061035
465421657,9039,ableegoldman,2020-08-05T01:38:18Z,comment doesn't seem to match the query bounds (missing a +1?),0,0.9492268562316895
465421880,9039,ableegoldman,2020-08-05T01:39:08Z,is there any reason this wouldn't just be `window.start + timedifferencems`?,0,0.9872626662254333
465424346,9039,ableegoldman,2020-08-05T01:48:06Z,"same here, let's not pin the start time to 0 for now and just drop the early records",0,0.9834651947021484
465425090,9039,ableegoldman,2020-08-05T01:50:32Z,"yeah especially since we use the same condition for both the forward and reverse case, let's just pull the `rightwinagg != null && rightwinagg.timestamp() > timestamp` out into a separate method",0,0.8838156461715698
465725011,9039,lct45,2020-08-05T13:26:48Z,"yeah that works unless the first window isn't the right window, in which case we would need to process it (save as the rightwinagg, update its aggregate if the current record falls into it, etc) before going to the next record at the top of the while loop. it definitely works and is what we had before, it just makes the code a little less clean.",0,0.8917142152786255
465751597,9039,lct45,2020-08-05T14:05:28Z,"hmmmm yeah, i think if there's something in the left window then we will always initialize `leftwinagg` to something other than null, good catch. we essentially check `leftwinagg.timestamp() < timestamp` in the while loop, so i don't think that should cause a problem, and `leftwinagg.timestamp() > timestamp - windows.timedifferencems()` will never be true because that window would be out of range, right? and we only take the first left agg. long way of saying, i think we can do the null check and nothing else but will know slightly more when we can test it",0,0.8229889869689941
465756356,9039,lct45,2020-08-05T14:12:12Z,"nope, since we aren't storing truncated windows",0,0.9740981459617615
466026007,9039,mjsax,2020-08-05T21:54:05Z,the ticket is already fixed. you need to pass in the `windowsize` into the the constructor of `timewindowdeserializer` to get rid of the problem.,0,0.9879234433174133
466028866,9039,mjsax,2020-08-05T22:00:39Z,"i guess testing both cases would be good. even if testing the former (fall outside of all existing windows) was my original intent. and thank for comment sophie: i tend to forget that we should produce all (non-empty) right windows already upfront/eagerly (and not delayed/lazily when stream-time advances beyond window-end time). in any case, it seems to be a good test case to make sure we don't (re-)emit an (unexpected) window if stream-time jumps ahead?",1,0.754650890827179
466029116,9039,mjsax,2020-08-05T22:01:14Z,ack. was just a thought.,0,0.849778413772583
466032331,9039,mjsax,2020-08-05T22:09:37Z,"we pass in all parameter to sharing to code that creates the `statefulprocessornode` -- not sure if it's the best way to structure the code and i am happy to split it up into multiple methods call (as long as we avoid code duplication). and yes, you are right, it's internal and the checks are just for us to avoid programming errors. users should never be exposed to it. i personally tend to make a lot of mistakes and the more checks we have in place the better imho :) if want's she can just do a side cleanup pr to fix it, and rebase this pr after the cleanup pr was merged? or we do it as follow up. whatever works best for you.",1,0.9851047396659851
466032804,9039,mjsax,2020-08-05T22:10:51Z,thanks for confirming. let keep this issue out for this pr than.,1,0.7686994075775146
466033381,9039,mjsax,2020-08-05T22:12:25Z,i am not a native speaker... don't ask me... mr.john should know -- he has the proper education for it.,-1,0.765198290348053
466042505,9039,lct45,2020-08-05T22:38:04Z,"that should be covered in `kstreamslidingwindowaggregatetest`, which goes through more of the edge cases using the `topologytestdriver` which is a little easier to manipulate than this set up",0,0.9854183197021484
466050097,9039,ableegoldman,2020-08-05T23:00:38Z,"well, if the first window isn't the right window then we just wouldn't call `iterator.next` again, right? so we wouldn't have to do anything at all",0,0.9727613925933838
466051779,9039,ableegoldman,2020-08-05T23:05:45Z,"ok cool, just checking. either `endtime = window.start + timedifferencems` or `endtime = window.end` is fine as long as we're consistent (i guess we only define it in two places, the forward and reverse algorithms?)",1,0.797698438167572
466052825,9039,ableegoldman,2020-08-05T23:08:41Z,"sounds good. we definitely need the null check just to avoid getting an npe, but whether we _only_ need the null check is something we should put to the test",1,0.9527745246887207
466063583,9039,ableegoldman,2020-08-05T23:42:35Z,"no she's right, this problem is not resolved at all. you can pass in `windowsize` to the constructor for `timewindoweddeserializer` all you want but it just gets ignored because the actual deserializer object you instantiate is thrown away. whether you're reading in records through a java consumer or the console consumer (for some reason this test does both), the actual deserializer is always constructed within the consumer based on the configs. there's a config for the windowed inner class which is properly set in `timewindoweddeserializer#configure` but no config for the `windowsize` so there's no way to set it at the moment. tl;dr there's no point in having serde constructors accept parameters, they need to be set through `configure`",0,0.9500380754470825
466070317,9039,lct45,2020-08-06T00:05:50Z,created a ticket for this here: [a link] let me know if the description isn't clear,0,0.9864776134490967
466425932,9039,lct45,2020-08-06T13:49:17Z,"i'm happy to do a pr! looking into it now though, `getstatefulprocessornode` is called by `build`, so i think to really separate it by type we'd need a different `build` _and_ `statefulprocessornode`, otherwise we'd be moving the null checks into `build` and then calling the correct `getstatefulprocessornode`, which does't seem to really fix anything. thoughts? it's easy to create new `build` functions but i figured this might fall under not avoiding code duplication :)",1,0.9896225929260254
466618450,9039,ableegoldman,2020-08-06T18:52:07Z,"i do think we'd need separate `build` methods, since that's where we originally accept multiple windows as arguments (where all but one type is set to null in each caller). but most of `build` doesn't touch the windows arguments so you could probably factor out all the window-independent code into a single method and just have each `build` method call that",0,0.9854433536529541
467231847,9039,mjsax,2020-08-07T19:33:46Z,thanks. i missed the point that this trick to pass in the windowsize only works for kafkastreams when we pass in `serdes` object that are used as provided...,1,0.8129275441169739
467260318,9039,lct45,2020-08-07T20:44:35Z,"sounds good, i'll change that when i implement the reverse iterator in the next pr",1,0.6396371126174927
467296111,9039,ableegoldman,2020-08-07T21:50:49Z,clearly kafka streams is superior to the plain consumer :smiling_face_with_horns:,1,0.8778067827224731
468214782,9039,vvcephei,2020-08-10T22:11:47Z,"haha, my specialty! the distillation of this sentence is ""windows are defined based on a record's timestamp, window size, and window grace period."" i think the meaning is pretty clear, so no need to change anything. just to point it out, there's structural ambiguity about whether the sentence is saying ""a record's (timestamp, window size, window grace period)"" (i.e., three properties of the record), or whether there are three top-level things that define the window. the latter was intended. i think actually inserting ""the"" before ""window"" both times would clear it up: ""windows are defined based on a record's timestamp, the window size, and the window grace period."" another note is that because the second item in the list is so long, the structure of the list gets a little lost. it would be better in this case to use the oxford comma to clearly delineate the boundary between the second and third items. so, although i think this is fine as-is, if you want me to break out the red pen, i'd say: [code block]",1,0.9744510054588318
468216620,9039,ableegoldman,2020-08-10T22:16:48Z,comment on the reverse case left behind,0,0.9859744906425476
468217437,9039,ableegoldman,2020-08-10T22:19:00Z,nit: extra line breaks,0,0.9716575145721436
468217987,9039,ableegoldman,2020-08-10T22:20:29Z,you should check to make sure all of these are still needed. in particular i bet we can get rid of the cogroupedstreamaggregatebuilder suppression once your cleanup pr is merged and this one is rebased,0,0.9729070663452148
468218540,9039,ableegoldman,2020-08-10T22:22:02Z,i think we usually leave the arguments on the same line as the method declaration (even if that line ends up way too long),0,0.9855965971946716
468219113,9039,ableegoldman,2020-08-10T22:23:34Z,"kind of hard to tell, but is the alignment in this method a bit off? might be good to just highlight and auto-indent everything, intellij will take care of any issues if it's configured properly",0,0.9668675065040588
468290069,9039,ableegoldman,2020-08-11T02:28:07Z,nit: extra spaces after the `->`,0,0.9856771230697632
468291563,9039,ableegoldman,2020-08-11T02:34:01Z,"the input is the same for each test so the output is too, right? maybe we can we pull all the output verification into a single method",0,0.9818867444992065
468292711,9039,ableegoldman,2020-08-11T02:38:04Z,"can we add some tests to verify the other materialized properties, specifically the retention? you can just pick a single operator (eg `reduce`) and write a test to make sure data is available (only) within the retention period. also, do you think we can write a test to verify that the default retention is as expected when we don't specify it?",0,0.9878126978874207
468293244,9039,ableegoldman,2020-08-11T02:40:05Z,"this comment needs to be updated, looks like we do allow a grace period of zero in the code/tests",0,0.9870842099189758
468293930,9039,ableegoldman,2020-08-11T02:42:39Z,`assertthrows` :slightly_smiling_face:,0,0.9261782169342041
468294181,9039,ableegoldman,2020-08-11T02:43:41Z,"awesome, thanks for cleaning up some of these older tests :grinning_face_with_smiling_eyes:",1,0.9920030832290649
468653951,9039,lct45,2020-08-11T15:07:03Z,"i pulled it out for all except one, because there's one call to `windowstore` that returns a ` , long>` and the other calls to `windowstore` return a ` , string>`",0,0.9847006797790527
468690429,9039,lct45,2020-08-11T15:58:35Z,"i'm not sure if i'm just missing something, but it doesn't look like there's a way to check what retention is. i created a test to make sure anything lower than our bound throws an exception, but i can't find anywhere the retention time is exposed for me to check what it's set to",0,0.8548656105995178
468796354,9039,lct45,2020-08-11T18:53:42Z,update: the windows themselves are the same but the value is different for each test,0,0.9868975877761841
468814368,9039,ableegoldman,2020-08-11T19:27:39Z,"yeah sorry i should have been more clear, i just meant push some data through and try to query the store to make sure it is/isn't there according to the retention period. you're right, it's not directly exposed anywhere",-1,0.9837263226509094
471797422,9039,ableegoldman,2020-08-17T21:57:26Z,do we still need this one after the cleanup you did?,0,0.9812984466552734
471798256,9039,ableegoldman,2020-08-17T21:59:31Z,"[code block] also i think this set is pretty clearly named, so we probably don't need a comment for it",0,0.9763342142105103
471798801,9039,ableegoldman,2020-08-17T22:00:50Z,nit: can we use the full word `window` in method names at least,0,0.9884639382362366
471801743,9039,ableegoldman,2020-08-17T22:08:09Z,"nit: you could use the version of `fetch` that just takes a single key instead of a key range, since there's only one key here",0,0.986561119556427
471820115,9039,ableegoldman,2020-08-17T23:01:12Z,"can we insert one that's like right on the border of the retention period? so if the streamtime at the end is 2,000 then the window cut off is 800 (or start time of 700), and verify that anything starting before 699 is gone and everything after that is there.",0,0.9890609979629517
471823061,9039,ableegoldman,2020-08-17T23:09:53Z,"for readability, could we mark the final results for each window? we want to make sure all the intermediate results are as expected, but what we really care about is what we got in the end. it would just help to have the critical output easier to find and get oriented in the tests",0,0.5979070067405701
471824209,9039,ableegoldman,2020-08-17T23:13:31Z,it might be nice to use different values for each record (at least within the same key). i don't think there are really any edge cases we should worry about when records have the same value so we may as well use a distinct one to make the tests a bit easier to read,0,0.9547146558761597
471825457,9039,ableegoldman,2020-08-17T23:17:24Z,"i still don't exactly understand why we have a join test in the `kstreamxxwindowaggregatetest`, but thanks for adding it for sliding windows. i'm sure there was a good reason for it, probably long ago",0,0.6195995807647705
471827371,9039,ableegoldman,2020-08-17T23:23:35Z,"sorry that i only just got to looking through this class :disappointed_face: . the tests here look good but can we add some more test coverage of possible edge cases? i know we can't test early records until the next pr, but we should probably have more than just the one test of the core functionality. i know it's really annoying to have to think through all the intermediate output, so maybe you can write a helper method that just grabs the final result of each window in the output? then we could have a number of tests that go through a larger number of input records without you having to spend all day manually processing them yourself :grinning_face_with_smiling_eyes:",-1,0.9914199113845825
472436400,9039,lct45,2020-08-18T19:41:02Z,we don't!,-1,0.8457729816436768
472440045,9039,lct45,2020-08-18T19:48:20Z,"that `fetch` only returns a `windowstoreiterator` instead of a `keyvalueiterator`, which i don't think is a huge deal but we wouldn't get the start/end time of the window which is nice to have for the test",0,0.9704383611679077
472441802,9039,ableegoldman,2020-08-18T19:51:48Z,"oh right, forgot that it doesn't have the window times either. nevermind then",0,0.8271224498748779
474966465,9039,ableegoldman,2020-08-21T20:59:10Z,"can we actually wrap the whole `testprocessorrandominput` test in the try-catch? or at least, everything after the initial setup? would be nice to have the seed in case something weird happens during the processing itself",0,0.9510066509246826
474977836,9039,ableegoldman,2020-08-21T21:28:42Z,"just a minor note, can we order the expected results by window timestamp?",0,0.9892783761024475
475919413,9039,ableegoldman,2020-08-24T22:02:05Z,"nit: can you call this something a bit more direct, eg `verifyrandomtestresults` ?",0,0.9856925010681152
475922761,9039,ableegoldman,2020-08-24T22:10:32Z,nit: `testaggregaterandominput` to match up with other test names,0,0.9870304465293884
475923788,9039,ableegoldman,2020-08-24T22:13:19Z,can you leave a brief comment here explaining why we're doing something slightly more complicated in the aggregator for this test,0,0.9845411777496338
478518760,9039,vvcephei,2020-08-27T15:45:49Z,"i'm reviewing this whole pr as-is, so there's no need to do anything now, but 's specific suggestion is beside the point. the general feedback is that this pr is too large, which it is. we shoot for under 1k, and it's the pr author's responsibility to figure out the best way to break it up. this policy isn't just ""reviewers complaining,"" it's an important component of ensuring ak's quality. long prs overwhelm any reviewer's cognitive capacity to pay attention to every detail, so oversights are more likely to slip through into the codebase, and once they're there, you're really at the mercy of the testing layers to catch them. when the oversights are very subtle, they wind up getting released and then surface as user-reported bugs. reviewers can't guarantee to notice every problem, but our capacity to notice problems is inversely proportional to the length of the pr.",0,0.6281757354736328
478627800,9039,vvcephei,2020-08-27T18:53:31Z,"is this condition supposed to be checking whether records are ""early"" with respect to now? it looks like it should be: [code block]",0,0.9858497381210327
478664149,9039,vvcephei,2020-08-27T20:03:13Z,minor: this could be declared `final` at the assignment on line 161,0,0.9889599084854126
478669986,9039,vvcephei,2020-08-27T20:14:32Z,might not be a bad idea to have an assertion here that the timestamp is actually in the window boundaries.,0,0.8328689932823181
478671190,9039,vvcephei,2020-08-27T20:16:55Z,"is it already guaranteed that this window actually contains the current record? it doesn't look like we're checking that `endtime >= timestamp` anywhere, and it seems like the start of the range (`timestamp - 2 * windows.timedifferencems()`) could give back a window that starts and ends before the current record's timestamp.",0,0.9871026873588562
478702517,9039,vvcephei,2020-08-27T21:20:46Z,"the achilles heel of implementing new ktable features has historically been that we forgot to test them in a context that required the valuegetter to work properly, of which join is a notable use case. i'd actually say it should be required for every ktable operator to have a test where it's the source of a join. for stateless operators, we should test both with and without a materialized argument on the operator.",0,0.9190841913223267
478703452,9039,vvcephei,2020-08-27T21:22:51Z,"i'd normally say we should have a test also to verify we log properly on early records, but you already opened the pr to add early record handling, so we're good.",1,0.814645528793335
478704359,9039,vvcephei,2020-08-27T21:24:45Z,awesome test. thanks!,1,0.9911619424819946
478705942,9039,vvcephei,2020-08-27T21:28:18Z,"aside from join, forgetting to test new operators in front of suppress has also been an issue. it's great to see this test here!",1,0.9880720376968384
478707997,9039,vvcephei,2020-08-27T21:32:52Z,"coming back to this after completing the review, i'd say the biggest advice i'd share is to avoid whitespace changes and cleanups on the side when the pr is so long already. in fact, for my own super-complex prs, i tend to go back over the whole diff and back out anything that's not critically important, just to lighten the load on the reviewers. cleanups are nice to have, but it's better to keep them in their own prs or in more trivial ones.",0,0.7898046374320984
478715664,9039,ableegoldman,2020-08-27T21:50:34Z,"no, the condition is correct. in this context ""early"" just means ""within timedifferencems of the zero timestamp"". we need some special handling to cover this full range of all record timestamps due to the inability to store negative timestamps. this algorithm works correctly for all records outside of this regardless of ""now""",0,0.9844974279403687
478716769,9039,ableegoldman,2020-08-27T21:53:00Z,"to be honest, it might not be so bad to just leave things as is and drop early records, since any sensible timestamps are unlikely to be that close to the epoch. but i do believe users may want to use lower timestamps in their unit testing (`1598565116374` is not a very human readable number) and would be surprised to see these records just dropped.",-1,0.4966868758201599
478717127,9039,ableegoldman,2020-08-27T21:53:52Z,"aha, so there was a good reason for it :grinning_face_with_smiling_eyes:",1,0.8786467909812927
478726427,9039,lct45,2020-08-27T22:17:40Z,is that possible? it's reassigned for every iteration of the `while()`,0,0.9860373139381409
478728829,9039,lct45,2020-08-27T22:24:19Z,"while the range might give a window that starts and ends before the current record's timestamp, the current record would fall into the right window of the records _within_ those windows. ex: timedifference = 10, record @ 30, range from (10,31). the earliest start time of a window we can have is 10, so the earliest `lefttypewindow` we can find is from [10,20]. if there's a record at 2, it's right window would be [21,31], which our record @ 30 would fall within. because this is true for the furthest possible record, it'll be true for the others that we find.",0,0.9754956364631653
478730796,9039,lct45,2020-08-27T22:29:46Z,"i don't think that would be true all the time, since the current record's right window wouldn't contain the current record and is created through this method. if it helps for clarity, i can add a check that if we're _not_ creating the right window then the timestamp needs to be within the window, and otherwise confirm that we're creating the right window",0,0.9797163009643555
478751787,9039,ableegoldman,2020-08-27T23:35:06Z,"i think he means, instead of declaring it once up here and then reassigning it every iteration, we can just do `final keyvalue<> next = iterator.next()` down on line 161. we don't need it outside the loop",0,0.9789182543754578
478753568,9039,lct45,2020-08-27T23:41:39Z,"aha, that makes sense",0,0.9207835793495178
478756346,9039,ableegoldman,2020-08-27T23:51:15Z,"now that you bring it up, that's kind of a weird case for this method, and it's currently handled in a pretty subtle way. for example down on line 233 we are effectively checking for this case, and line 234 just happens to work correctly for it. but it's not at all obvious that we're even handling this case. can we avoid the ternary operator when setting `newagg` and `newtimestamp` and just use a normal if/else to explicitly set both of these for the special case? (ie `if (windowstart == timestamp + 1)`...)",-1,0.930101752281189
479344784,9039,vvcephei,2020-08-28T14:32:35Z,"thanks. from the other thread, it sounds like i misunderstood `putandforward` as adding the `value` to the `window`.",1,0.7994535565376282
479362665,9039,lct45,2020-08-28T15:01:33Z,"yeah it's definitely vague, i'll update",0,0.9770205020904541
480429410,9039,vvcephei,2020-08-31T22:16:28Z,thanks for the confirmation! i agree with your thinking.,1,0.9733876585960388
1655160528,16456,apoorvmittal10,2024-06-26T16:15:11Z,is it possible to use `default_client_rack` already defined in configs?,0,0.9890924692153931
1655173636,16456,apoorvmittal10,2024-06-26T16:25:12Z,nit: [code block],0,0.9873168468475342
1655178863,16456,apoorvmittal10,2024-06-26T16:27:31Z,query: can you please help what issue actually occurs and why we need to update the cache i.e. how can the cache eviction be prevented with the cache update?,0,0.9863831996917725
1655181963,16456,apoorvmittal10,2024-06-26T16:28:54Z,query: is it always guranteed that a non-null share session will exist?,0,0.9885179996490479
1655189309,16456,apoorvmittal10,2024-06-26T16:31:53Z,nit: should we declare the helper methods post `handle` methods?,0,0.9888221025466919
1655198343,16456,apoorvmittal10,2024-06-26T16:35:14Z,nit: do we need this or can work with existing `randombytes`?,0,0.9893229603767395
1655203506,16456,apoorvmittal10,2024-06-26T16:37:46Z,where does this mocked version used later? if we don not define the setter of sharpartitionmanager then ll it make a difference?,0,0.9349734783172607
1656904716,16456,chirag-wadhwa5,2024-06-27T10:37:57Z,it should not make a difference. i removed the mock and passed optional.empty() in setsharepartitionmanager method. did the same in metadatarequestbenchmark.java as well,0,0.9830568432807922
1656905232,16456,chirag-wadhwa5,2024-06-27T10:38:27Z,"didn't realise the existence of randombytes. made the amends, thanks for the review",1,0.7758690714836121
1660544030,16456,chirag-wadhwa5,2024-07-01T06:40:32Z,"upon going through the code again, i guess with the new changes it doesn't make sense at all to update the cache here at all. with no asynchronous process happening between the 2 updates, the second update could be removed altogether. i have made the required changes in the most recent commit. thanks",1,0.9830465912818909
1660544678,16456,chirag-wadhwa5,2024-07-01T06:41:12Z,removed this method in the latest commit. pls refer to the reply for above comment for further context. thanks !,1,0.977251410484314
1662479127,16456,apoorvmittal10,2024-07-02T13:04:06Z,"time is already defined in the class, can we please re-use that: [code block]",0,0.9877220988273621
1662482911,16456,apoorvmittal10,2024-07-02T13:06:44Z,i don't see `option` suffix for other optionals in this class: [code block],0,0.9837172031402588
1662487187,16456,apoorvmittal10,2024-07-02T13:09:35Z,should we be relying on this config for `share groups`?,0,0.9818129539489746
1662490711,16456,apoorvmittal10,2024-07-02T13:11:53Z,"are we introducing this config to ak, i do not see the config in the kip `group.share.enable`. cc:",0,0.9872868657112122
1662494555,16456,apoorvmittal10,2024-07-02T13:14:08Z,can we move this line after checking whether `sharepartitionmanageroption` has a value?,0,0.9887582063674927
1662497106,16456,apoorvmittal10,2024-07-02T13:15:51Z,"do we need `()` or can work without them as like elsewhere, can we please be consistent. [code block]",0,0.9882317185401917
1662497519,16456,apoorvmittal10,2024-07-02T13:16:09Z,same as above and elsewhere.,0,0.9769088625907898
1662550023,16456,apoorvmittal10,2024-07-02T13:39:36Z,can we delay the fetch of this when actually it's required later?,0,0.9845394492149353
1662556294,16456,apoorvmittal10,2024-07-02T13:42:22Z,"it's odd to see that we need to expose `cachedtopicidpartitionsinsharesession` externally. we should not have the release api to have `list topicidpartitions`, only `string groupid, string memberid` should be sufficient. can we please change the `releaseacquiredrecords` api to below, and use `cachedtopicidpartitionsinsharesession` internally only? cc: [code block]",0,0.9314857721328735
1662566850,16456,apoorvmittal10,2024-07-02T13:47:01Z,"i hardly see much of `breakable` usage in entire `kafka` repository. how does the other part of code `breaks` in scala, any idea?",0,0.8483008742332458
1662638990,16456,apoorvmittal10,2024-07-02T14:26:48Z,any advise what's the best way to write such code in scala and kafka?,0,0.9797219038009644
1662644808,16456,apoorvmittal10,2024-07-02T14:29:43Z,"can we declare variables when needed. it's anyways tough to read scala code with `def` inside `def`, declaration of variables without order makes it harder.",0,0.6622229814529419
1662653794,16456,apoorvmittal10,2024-07-02T14:34:04Z,"i am not sure what does this case means i.e. is this check required? if yes, then what handling is done when `sharefetchresponse` is not returned by the method call i.e. how it further gets handled? shouldn't we complete the request and return right away?",0,0.8931148648262024
1662666354,16456,apoorvmittal10,2024-07-02T14:40:39Z,"why the validation of the request is done later prior initializing context and other processing, shouldn't that be the first step?",0,0.9672494530677795
1662673852,16456,apoorvmittal10,2024-07-02T14:44:40Z,query: why do we only authorize in subsequent request i.e. when acknowledge data is present?,0,0.9831595420837402
1662675191,16456,apoorvmittal10,2024-07-02T14:45:14Z,shouldn't this be an `async` call?,0,0.9784374237060547
1663148002,16456,apoorvmittal10,2024-07-02T20:43:48Z,can i get review on this please: [a link],0,0.967210590839386
1663964233,16456,chirag-wadhwa5,2024-07-03T10:26:58Z,"hi, thanks for the review. yes this check is required here, because `sharepartitionmanager.newcontext` might throw errors during its execution. initially, `sharefetchresponse` is defined as a null there. if an error is thrown, then its value is set as an error response. after this check, the acknowledging and fetching only proceeds if `sharefetchresponse` is null. if it is not null, then a final `sharefetchresponse` object is prepared with the error code and appropriate values for the acknowledgements and sent back to the user",1,0.9553038477897644
1663972187,16456,chirag-wadhwa5,2024-07-03T10:33:18Z,"hi, thanks for the review. according to my knowledge, this auth check is only required for acknowledgement and not for fetching. so, if there's nothing to acknowledge, there won't be any need for this auth check.",1,0.8485600352287292
1663976290,16456,chirag-wadhwa5,2024-07-03T10:36:55Z,"thanks for the review. `handleacknowledgements` would internally call `acknowledge` in `sharepartitionmanager`, which is an asyn function returning a future. according to the code that we already have in kip-932 branch, `handleacknowledgements` method returns the value by waiting for the future to execute completely. so, this piece is synchronous. we can maybe return a future from `handleacknowledgements` and wait for its completion here here, but i'm not sure how would that help us in any way.",1,0.7885599136352539
1664101522,16456,apoorvmittal10,2024-07-03T12:21:03Z,"are these intended changes, if yes then we shall have it in separate pr.",0,0.9854918122291565
1664119319,16456,chirag-wadhwa5,2024-07-03T12:34:51Z,"yes, the commit history got changed a bit. it should be fine now with the latest push in place",0,0.9784998893737793
1664122712,16456,apoorvmittal10,2024-07-03T12:37:31Z,is this method being used anywhere now?,0,0.9866190552711487
1664131801,16456,apoorvmittal10,2024-07-03T12:44:00Z,"my concern is on below code, should we complete the api call if `errorresponse` is constructed? ``` case e: exception => sharefetchresponse = sharefetchrequest.geterrorresponse(abstractresponse.default_throttle_time, e) match { case response: sharefetchresponse => response case _ => null",0,0.9507980942726135
1664144313,16456,chirag-wadhwa5,2024-07-03T12:53:07Z,"nope, already taken care of in the latest commit. thanks",1,0.920408308506012
1664178535,16456,adixitconfluent,2024-07-03T13:17:19Z,"i agree with , seeing the `newcontext` function, the possible errors are `invalid_request`, `share_session_not_found` and `invalid_share_session_epoch`. in all such cases, we should be completing the api call with a top level error code there itself.",0,0.9859813451766968
1664193628,16456,adixitconfluent,2024-07-03T13:27:03Z,we can remove this check if we return the api response with top level error code wherever it occurs. wdyt -wadhwa5 ?,0,0.9902432560920715
1664202015,16456,adixitconfluent,2024-07-03T13:32:33Z,"comment should say ""share"" instead of ""regular""",0,0.9808923602104187
1664266986,16456,adixitconfluent,2024-07-03T14:14:03Z,"can we not club all of this ""if"" and the below ""if"" conditions into a single if?",0,0.9825383424758911
1664271714,16456,adixitconfluent,2024-07-03T14:17:13Z,not sure if these dummy values are the ones we want to go ahead. perhaps / would know better which values to use here?,0,0.9234582781791687
1664273428,16456,adixitconfluent,2024-07-03T14:18:21Z,"nit: instead of partitions.size, maybe use partitions size",0,0.986764132976532
1664275271,16456,adixitconfluent,2024-07-03T14:19:23Z,"nit: add a ""."" at the end of comment. can you do this for other added comments as well?",0,0.9844659566879272
1665550477,16456,AndrewJSchofield,2024-07-04T11:08:41Z,"i think so, at least for now. the eventual switch will be `group.version=2` as the second version of the new group coordinator feature. unfortunately, `group.version` has been backed out and will not be re-introduced until 4.0. this is an internal (undocumented) config for the broker. it does the necessary thing, which is to enable the new gc, so it seems like a safe temporary answer here.",0,0.9613097310066223
1665552665,16456,AndrewJSchofield,2024-07-04T11:10:49Z,"it's an internal (undocumented) configuration. as mentioned above, the configuration we are using is temporary for now. i'm happy with it being used until we get the real configs in place.",1,0.9289178252220154
1665590294,16456,chirag-wadhwa5,2024-07-04T11:45:24Z,"that makes sense. thanks for the review, will make the changes in the next commit",1,0.9528403282165527
1665592992,16456,chirag-wadhwa5,2024-07-04T11:47:48Z,"thanks for the review ! yes we can but i did that for better readability, without affecting the execution at all.",1,0.9811626672744751
1665594694,16456,chirag-wadhwa5,2024-07-04T11:49:18Z,"yes, i wanted to have a discussion regarding these dummy values with as well",0,0.9829112887382507
1665597002,16456,chirag-wadhwa5,2024-07-04T11:51:28Z,thanks for the review. i think i copied this comment from the regular fetch request implementation. but yeah its very trivial. i will make the change in the next commit.,1,0.6675467491149902
1665633847,16456,apoorvmittal10,2024-07-04T12:22:03Z,"i find following line from the kip which says following, hence shouldn't we authorize for read on fetch as well? ``` operations which change information about a share group (such as consuming a record) need permission to perform the read action on the named group resource",0,0.985965371131897
1665637301,16456,apoorvmittal10,2024-07-04T12:25:03Z,"also, do we need to re-authorize on every request in session? what behaviour we have on regular fetch? does it authorize everytime or once in session? if we do it only at session establishment, i do get that if an api key is unauthorized then existing session might continue reading/acknowledging, but re-authorization is taxing as well. hence checking what's the flow looks like on regular fetch. cc:",0,0.9816274046897888
1665642977,16456,apoorvmittal10,2024-07-04T12:29:40Z,"hmmm, this is not clean. why can't we have `handleacknowledgements` api to receive `mutable.map[topicidpartition, util.list[shareacknowledgementbatch]]`? then `sharefetch` and `shareacknowledgerequest` can send respective data to `handleacknowledgements` method and we need not to use `asinstanceof` or any type casting.",0,0.8869840502738953
1665645855,16456,apoorvmittal10,2024-07-04T12:32:05Z,isn't the `sharepartitionmanager.acknowledge` already implemented?,0,0.9867881536483765
1665661239,16456,apoorvmittal10,2024-07-04T12:44:44Z,"i do not see any futures handled here hence this maked the processing synchronous, irrespective if other api calls to sharepartitionmanager are async. moreover i am failed to understand the behaviour of `handleacknowledgements` method i.e. i do see `shareacknowledgeresult` is returned right away but there might be a delay in getting reposne from `sharepartitionmanager.acknowledge` method hence how that's handled?",0,0.543260931968689
1665668978,16456,apoorvmittal10,2024-07-04T12:51:03Z,"should we throw an exception here of complete the request by unsupported version error? what's followed in other apis? for kip-714, i added something below: ``` case none => info(""received get telemetry client request for zookeeper based cluster"") requesthelper.sendmaybethrottle(request, subscriptionrequest.geterrorresponse(errors.unsupported_version.exception))",0,0.9876711368560791
1665672326,16456,apoorvmittal10,2024-07-04T12:53:41Z,i see this is a copy from `fetch` but do we need to define same functionality again or create a common `def/method` for both?,0,0.9897406101226807
1665676287,16456,apoorvmittal10,2024-07-04T12:56:43Z,shouldn't this be like below? [code block],0,0.9836448431015015
1665689981,16456,apoorvmittal10,2024-07-04T13:07:43Z,"do you need `asjava` conversion just ofr iteration? if yes, then aren't there better way in scala? [code block]",0,0.9888421297073364
1665702943,16456,apoorvmittal10,2024-07-04T13:18:08Z,"isn't the response is already returned and this is async call, what does `requesthelper.handleerror(request, throwable)` does then?",0,0.9885419607162476
1665708594,16456,apoorvmittal10,2024-07-04T13:22:52Z,"hmm the whole processing is `synchronous`, why can't we work with callbacks i.e. when complete?",0,0.9710928797721863
1665714440,16456,apoorvmittal10,2024-07-04T13:27:37Z,can you please write comment regaridng what exaclty is happening and why we are going to modify the `sharefetchresponse` later? i am not sure if there is a better way of combinig 2 responses and construct `sharefetchresponse` just once rather first generating it in fetch and then modifying same.,0,0.9248560667037964
1665777016,16456,chirag-wadhwa5,2024-07-04T14:18:10Z,"as per my knowledge the regular fetch does not authorize for read operation on the named group. only the topics from where data is to fetched, are authorized for read operation",0,0.9828420281410217
1665987792,16456,apoorvmittal10,2024-07-04T18:19:48Z,should it be in `error`?,0,0.9772412776947021
1665988915,16456,apoorvmittal10,2024-07-04T18:22:26Z,should it be `private def`?,0,0.9832037687301636
1665990669,16456,apoorvmittal10,2024-07-04T18:26:06Z,"i am not sure how costly the api for `asscala` on map is, but should have some cost, so do you want to have conversion in foreack loop?",0,0.9214527010917664
1665993309,16456,apoorvmittal10,2024-07-04T18:31:49Z,"does `topicidnames` seems better? it was hard to relate later in the code what this variable holds, seems more like just name of topics.",0,0.9683266282081604
1665994321,16456,apoorvmittal10,2024-07-04T18:33:51Z,do we validate somewhere that partition index exists for the topic i.e. what if client request for partition 5 when there exists only 4 partitions for topic?,0,0.9881967902183533
1665995004,16456,apoorvmittal10,2024-07-04T18:35:15Z,what exception is being thrown?,0,0.9558650851249695
1665995891,16456,apoorvmittal10,2024-07-04T18:37:21Z,"yeah it's much readable this way, i agree.",0,0.6946871876716614
1665996271,16456,apoorvmittal10,2024-07-04T18:38:21Z,will it not be better to mock `sharepartitionmanager`?,0,0.9699798822402954
1665997840,16456,apoorvmittal10,2024-07-04T18:41:18Z,"this change will be not needed if we use mock, that we should.",0,0.9834463000297546
1665998426,16456,apoorvmittal10,2024-07-04T18:42:41Z,nit: would it better to have these methods defines later when used in tests?,0,0.985511839389801
1666000193,16456,apoorvmittal10,2024-07-04T18:46:23Z,"seems the methods are same as defined in `sharepartitiontest`, shall we move them to common test utils (in java)?",0,0.9890594482421875
1666000611,16456,apoorvmittal10,2024-07-04T18:47:18Z,"i see we are using mock here, why not to define it on the top itself?",0,0.9649309515953064
1666001021,16456,apoorvmittal10,2024-07-04T18:48:11Z,is `asjava` required? isn't it already a java api?,0,0.9889843463897705
1666723067,16456,chirag-wadhwa5,2024-07-05T12:00:46Z,i think it should be just return. `completablefuture.completedfuture[unit](())` shouldn't be there at all because return type of `handlesharefetchrequest` is `unit` and not `completablefuture[unit]`,0,0.9873555302619934
1666735395,16456,chirag-wadhwa5,2024-07-05T12:14:10Z,"yep, this doesn't make sense. if there is an error here, the broker will send out 2 responses for that. i have changed this to the following logic - 1) if throwable is not null, it will simply throw the throwable. 2) i have surrounded the call of `combinesharefetchandshareacknowledgeresponses` with a try catch. if error is not thrown then `requestchannel.sendresponse` with appropriate arguments. if error is thrown, then `requesthelper.handleerror(request, throwable)` with appropriate arguments. also change the log from debug to error here.",0,0.9608680605888367
1668159303,16456,chirag-wadhwa5,2024-07-08T07:55:34Z,"this was a mistake, will remove the try catch block. thanks!",1,0.9639304876327515
1668342690,16456,chirag-wadhwa5,2024-07-08T09:55:53Z,"thanks for the review. actually yes it is required, since the list() is a scala list. there are other ways that do not use asjava, but they span over multiple lines, and would require new variable initialisations, reducing the code readability.",1,0.886713445186615
1669768302,16456,chirag-wadhwa5,2024-07-09T05:47:45Z,hi thanks for reviewing. i think the first occurrence of these methods is in the test just underneath them. isn't that what you mean here ?,1,0.8063942193984985
1669815168,16456,chirag-wadhwa5,2024-07-09T06:31:01Z,"yep, the true place for these methods should be in testutils file, but both sharepartitiontest and kafkaapistest import separate testutils files. sharepartitiontest use the java one and kafkaapistest use the scala one. as far as i know, java does not support aliasing and neither do the older versions of scala.",0,0.9846678376197815
1669817534,16456,chirag-wadhwa5,2024-07-09T06:33:40Z,not currently. i think that can be done using the metadatacache which is accessible in the kafkaapis. i will create a separate jira for this. thanks !,1,0.9826288223266602
1672098926,16456,apoorvmittal10,2024-07-10T11:24:59Z,i raised a query earlier regaridng why we only want to authorize when acknowledgements exist?,0,0.9855367541313171
1672102704,16456,apoorvmittal10,2024-07-10T11:28:08Z,why do we require `.get` here? will it not block the calls?,0,0.9816246628761292
1672103745,16456,apoorvmittal10,2024-07-10T11:28:57Z,why this exception is only about `release`?,0,0.9604692459106445
1672106900,16456,apoorvmittal10,2024-07-10T11:31:48Z,i can find this comment is yet not addressed. i think we discussed that the code shall be asynchronous. in case we are finding it difficult in this pr then please log a jira and work on it post merge of this pr.,0,0.9863471388816833
1672107334,16456,apoorvmittal10,2024-07-10T11:32:14Z,again we have a blocking call here.,0,0.9682486653327942
1672108309,16456,apoorvmittal10,2024-07-10T11:33:07Z,-wadhwa5 did you get a chance to work on this?,0,0.9839795827865601
1672109076,16456,apoorvmittal10,2024-07-10T11:33:49Z,why do we need `breakable` here?,0,0.9661459922790527
1672111524,16456,apoorvmittal10,2024-07-10T11:36:00Z,it's not that important but generally the helper method will come post the usage i.e. test -> helper method.,0,0.9837638139724731
1672112684,16456,apoorvmittal10,2024-07-10T11:37:11Z,so why not to have either in java or scala test utils which can be used by both?,0,0.9827892184257507
1672113400,16456,apoorvmittal10,2024-07-10T11:37:47Z,do we have the jira now? can we please link here?,0,0.9849490523338318
1672117974,16456,apoorvmittal10,2024-07-10T11:41:46Z,yeah but kip-932 defines the behaviour for auth during fetch.,0,0.9856664538383484
1675361989,16456,chirag-wadhwa5,2024-07-12T06:05:25Z,"i think this log is not in the right place. the only thing that throws an exception in the try block is the releasing the acquired records part, moved this log to that position.",0,0.9691835045814514
1675585257,16456,chirag-wadhwa5,2024-07-12T09:30:47Z,created a separate jira to track this - [a link],0,0.9879001379013062
1675597142,16456,chirag-wadhwa5,2024-07-12T09:40:35Z,"hey yep, the jira has been created - [a link]",0,0.9530349373817444
1675597743,16456,chirag-wadhwa5,2024-07-12T09:41:04Z,created a jira - [a link],0,0.9877867102622986
1690482997,16456,junrao,2024-07-24T21:37:14Z,fetchoncomplete => onfetchcomplete?,0,0.9863378405570984
1690501820,16456,junrao,2024-07-24T21:54:18Z,"for consistency, could we remove `this`?",0,0.9891805052757263
1690504262,16456,junrao,2024-07-24T21:56:13Z,this only happens in zk mode. we probably want to improve logging to reflect that.,0,0.9856276512145996
1690509290,16456,junrao,2024-07-24T22:00:30Z,we could get rid of {}.,0,0.9846218824386597
1690510398,16456,junrao,2024-07-24T22:01:36Z,we could get rid of {}. ditto in a few other places.,0,0.9700493216514587
1690517906,16456,junrao,2024-07-24T22:08:19Z,"instead of foreach, perhaps you could do `sharefetchrequest.data.topics.stream().anymatch` ?",0,0.9866757988929749
1690528671,16456,junrao,2024-07-24T22:24:41Z,the convention is to have no space before `:`. ditto in a few other places below.,0,0.8717418313026428
1690529065,16456,junrao,2024-07-24T22:25:21Z,space after `if`. ditto in a few other places below.,0,0.9671338796615601
1690566819,16456,junrao,2024-07-24T23:13:41Z,"hmm, should we get the partitions for fetch from sharefetchcontext instead from the request? the request may not include all partitions in the session since it can be incremental.",0,0.9859136939048767
1690594851,16456,junrao,2024-07-24T23:46:04Z,could this be private?,0,0.9868327379226685
1690595889,16456,junrao,2024-07-24T23:47:38Z,this comment seems out of place.,-1,0.7726109027862549
1690596169,16456,junrao,2024-07-24T23:48:07Z,datas is weird since data is already the plural form of datum.,-1,0.9827289581298828
1690599349,16456,junrao,2024-07-24T23:53:51Z,interestingwithmaxbytes => interestedwithmaxbytes ?,0,0.9731960296630859
1690612220,16456,junrao,2024-07-25T00:14:57Z,could this block of code be replaced with sth like the following using lamda? [code block],0,0.9893814325332642
1691763015,16456,junrao,2024-07-25T16:17:40Z,sharefetch is implemented on the latest version of the client and understands all versions of the message format. why do we need to down convert here?,0,0.9878100156784058
1691773793,16456,junrao,2024-07-25T16:25:50Z,should we use consumer_replica_id?,0,0.987863302230835
1691814103,16456,junrao,2024-07-25T16:45:35Z,"could this code just be `requesthelper.throttle(quotas.fetch, request, maxthrottletimems)`?",0,0.9889793395996094
1691823423,16456,junrao,2024-07-25T16:53:11Z,"if the response is not ready immediately, `combinesharefetchandshareacknowledgeresponses()` needs to be called asynchronously, right?",0,0.9831199049949646
1691825148,16456,junrao,2024-07-25T16:54:42Z,we could get rid of {} here.,0,0.9842574596405029
1691839730,16456,junrao,2024-07-25T17:06:48Z,we are doing this check for fetching already. do we need to do this again?,0,0.9776074290275574
1691841163,16456,junrao,2024-07-25T17:08:02Z,combine with the previous line?,0,0.9829244017601013
1691841383,16456,junrao,2024-07-25T17:08:12Z,topicidnames and clientid seem unused?,0,0.9819483757019043
1691842743,16456,junrao,2024-07-25T17:09:17Z,we can get rid of {}.,0,0.9854977130889893
1693588726,16456,junrao,2024-07-26T20:42:20Z,merge with previous line?,0,0.9781162738800049
1693601483,16456,junrao,2024-07-26T20:59:28Z,merge with previous line?,0,0.9781162738800049
1693602221,16456,junrao,2024-07-26T21:00:34Z,space after `if`,0,0.9828938841819763
1693628707,16456,junrao,2024-07-26T21:41:26Z,this is an existing issue. why do we need to pass in both interestingtopicpartitions and interestingwithmaxbytes? they have the same keyset. could we just pass in interestingwithmaxbytes?,0,0.9665735960006714
1693631675,16456,junrao,2024-07-26T21:45:46Z,"hmm, i am not sure that i understand the logic here. the partition set for topicpartitionacknowledgements is a subset of that for sharefetchresponse, right? if so, there is no remaining acknowledgements.",0,0.809565544128418
1695140156,16456,apoorvmittal10,2024-07-29T12:37:56Z,yeah as per suggestion here: [a link] if we have it consistent across other logs then it would be good: [code block],0,0.9389374256134033
1695145736,16456,apoorvmittal10,2024-07-29T12:42:08Z,is `()` required or we can just write `if(tp.partition == partition) {`,0,0.9860974550247192
1695595126,16456,junrao,2024-07-29T17:23:53Z,`thenapply` => `.thenapply` ?,0,0.9859717488288879
1695660706,16456,junrao,2024-07-29T18:09:47Z,"`isinvalidsharefetchrequest()` checks `ispartitionpresent`. if there is a partition level error, we should send a errors.unknown_topic_or_partition at the partition level, instead of errors.invalid_request at the request level.",0,0.9882073998451233
1695831694,16456,junrao,2024-07-29T20:30:49Z,why do we need `partitiondatas`? could we just iterate `erroneousandvalidpartitiondata.validtopicidpartitions` directly?,0,0.9876025319099426
1695851702,16456,junrao,2024-07-29T20:37:31Z,this can a bit simpler like the following. [code block],0,0.9840860366821289
1695877000,16456,junrao,2024-07-29T20:44:46Z,the convention is to combine with the previous line.,0,0.9819716811180115
1695885553,16456,junrao,2024-07-29T20:47:08Z,could this be private?,0,0.9868327379226685
1695923179,16456,junrao,2024-07-29T20:57:29Z,it seems cleaner if we just create `erroneous` inside `handleacknowledgements()`?,0,0.9855522513389587
1695953996,16456,junrao,2024-07-29T21:05:50Z,indentation,0,0.982236921787262
1695961725,16456,junrao,2024-07-29T21:08:14Z,why does this return a mutable map? ditto for `handleacknowledgements()`.,-1,0.7484058737754822
1695973614,16456,junrao,2024-07-29T21:15:32Z,why do we need to copy the entries to `partitions`? we could just keep using `responsepartitiondata`?,0,0.9879235625267029
1696012525,16456,junrao,2024-07-29T21:59:12Z,could this be private?,0,0.9868327379226685
1696053083,16456,junrao,2024-07-29T22:51:55Z,there is some validation inside `sharepartitionmanager.newcontext`. should we just fold this logic there?,0,0.9890096783638
1696057694,16456,junrao,2024-07-29T22:59:49Z,why is this request invalid?,0,0.9134711027145386
1696066333,16456,junrao,2024-07-29T23:14:22Z,this seems unnecessary since we already tested that the array is empty above.,0,0.9339277148246765
1696077755,16456,junrao,2024-07-29T23:20:21Z,should we set records to `memoryrecords.empty`?,0,0.9867598414421082
1696078584,16456,junrao,2024-07-29T23:21:26Z,merge into previous line?,0,0.9786549210548401
1696079560,16456,junrao,2024-07-29T23:22:33Z,this is not the first request.,0,0.9373613595962524
1696081720,16456,junrao,2024-07-29T23:24:45Z,"is this test useful? in both cases, we mock `sharepartitionmanager.newcontext` to return errors.share_session_not_found regardless whether there is a wrong member id or group id. should we mock `sharepartitionmanager.newcontext` to return a sharesessioncontext with the wrong group/member id?",0,0.9769389033317566
1696083957,16456,junrao,2024-07-29T23:27:07Z,"merge into previous line? also, should we mock sharepartitionmanager.newcontext to return a sharesessioncontext with the wrong epoch instead of directly throwing an exception?",0,0.9737928509712219
1696094681,16456,junrao,2024-07-29T23:35:48Z,"hmm, the expected epoch should be 2 for the last call, right?",0,0.9822592735290527
1696108097,16456,junrao,2024-07-30T00:00:53Z,this is not the first fetch request.,0,0.965327799320221
1696112503,16456,junrao,2024-07-30T00:09:07Z,`sharefetchdata` seems unused?,0,0.9838232398033142
1696113299,16456,junrao,2024-07-30T00:10:46Z,sharefetchdata seems unused?,0,0.9804567098617554
1696113985,16456,junrao,2024-07-30T00:12:00Z,quite a long name. could it be sth like `testhandlesharefetchfetchmessagesreturnerrorcode`?,0,0.8740977644920349
1696114858,16456,junrao,2024-07-30T00:13:37Z,sharefetchdata seems unused?,0,0.9804567098617554
1696116555,16456,junrao,2024-07-30T00:17:09Z,merge with previous line?,0,0.9781162738800049
1696116942,16456,junrao,2024-07-30T00:17:53Z,could this be private?,0,0.9868327379226685
1696116973,16456,junrao,2024-07-30T00:17:58Z,could this be private?,0,0.9868327379226685
1696118317,16456,junrao,2024-07-30T00:20:55Z,"i understand the logic better now. so, this is fine.",0,0.6234207153320312
1696118888,16456,junrao,2024-07-30T00:22:11Z,i understand the code better now. this is fine.,0,0.6209194660186768
1696517878,16456,chirag-wadhwa5,2024-07-30T08:07:31Z,"thanks a lot for the review. i actually had some unit tests in place for this method, that is why left it as public. should i add a comment saying `//visible for testing` ?",1,0.9716743230819702
1696558877,16456,chirag-wadhwa5,2024-07-30T08:33:53Z,"hi, thanks a lot for the review. i guess this comment refers to the code before the last commit. i believe all the issues with asynchronous code have been resolved with that. let me know if you find any other gaps. thanks !",1,0.9866999387741089
1696677665,16456,chirag-wadhwa5,2024-07-30T09:50:14Z,"thanks for the review ! with the new code in place, i believe this problem has also been resolved.",1,0.9884983897209167
1697309981,16456,chirag-wadhwa5,2024-07-30T17:10:39Z,"thanks for the review. actually the code does not down convert anything, its just the variable names and the comments that suggest that. made the required changes",1,0.9575232863426208
1697405173,16456,chirag-wadhwa5,2024-07-30T18:33:05Z,"thanks for the review. you are correct here. but the code actually has that check already, i think this is not needed at all. i will remove this in the next commit",1,0.9370453357696533
1697422741,16456,chirag-wadhwa5,2024-07-30T18:48:42Z,"thanks for the review. actually, the upcoming pr for shareacknowledgerequest would make it clear why it has been one this way. the acknowledgement data sent to `handleacknowledgements` is retrieved using different methods in case of a fetch request and an acknowledge request. these methods can themselves identify some erroneous topic partitions, so that is why the map is being passed on to the method",1,0.921336829662323
1697447600,16456,chirag-wadhwa5,2024-07-30T19:07:17Z,"thanks for the review. given that a single fetch from a partition can sometimes contain significant amount of data, copying the entire map again whenever a new element is added could be a little extensive. but i don't think this choice of using a mutable.map or simply a map would make a huge difference. do you have any better suggestions though ?",1,0.8022757172584534
1697502447,16456,chirag-wadhwa5,2024-07-30T19:53:44Z,"thanks for the review. yes we could use the same, but the definition of some methods of sharefetchcontext require a util.linkedhashmap, so we would anyways require a new variable to store the converted map as it is required as an argument to multiple methods. talking about why do we need a util.linkedhashmap altogether, maybe we could change those method signatures to use a scala map as well, but i think that would out of scope for this pr as it would include making changes to others code as well.",1,0.8506694436073303
1697672536,16456,junrao,2024-07-30T22:29:09Z,"it seems that we never add/remove elements in the returned mutable.map? if the map doesn't need to be mutated, returning just map reduces potential side effect.",0,0.9812288880348206
1697988104,16456,chirag-wadhwa5,2024-07-31T06:48:01Z,"thanks for the review. the logic dictates, that a final share fetch request should only be sent for acknowledging previously fetched records, and not for fetching new records (the new records wouldn't be acknowledged since this is the final request). so, if the the partition max bytes field is non zero for any share partition in the request, that mens the client expects records as a result, which should not be the case, since it is a final fetch request. hence this is an invalid request. i know it is very trivial, but in the long run, the final epoch would be sent via a shareacknowledge request and not a sharefetch request, thereby resolving this altogether",1,0.7728514075279236
1698763204,16456,junrao,2024-07-31T16:03:31Z,thanks for the explanation. make sense. could we add a comment about this?,1,0.8945971727371216
1699474736,16456,chirag-wadhwa5,2024-08-01T06:05:14Z,"thanks for the review. i'm sorry but i don't understand how returning a sharesessioncontext with the wrong group/member id will help. the entire logic to handle the groupid/memberid is in newcontext and if a wrong groupid/memberid is provided in the request, an newcontext throws an error, which is what this test tries to mimic. pls let me know if my understanding is wrong anywhere, thanks !",1,0.9363592267036438
1699483505,16456,chirag-wadhwa5,2024-08-01T06:09:02Z,"thanks for the review. again, i'm sorry but i don't see how that is going to help. the expected behaviour is that the newcontext method should throw an exception in case of wrong epoch. if it successfully returns a sharesessioncontext, then the fetching would proceed without any issues, because that does not care about epochs at all. i have tried to simulate the expected behaviour in the test. pls let me know if my understanding is wrong anywhere, thanks !",1,0.9348175525665283
1699487912,16456,chirag-wadhwa5,2024-08-01T06:10:20Z,"thanks for the review. yes, you are right. actually, the sharefetchmetadata would include the current epoch in the request, but the sharesession would contain the next epoch, as the epoch is bumped in the newcontext method. i have made the change here, as well as in the other functions. thanks again for pointing it out !",1,0.9806694388389587
1699568098,16456,chirag-wadhwa5,2024-08-01T07:22:47Z,"thanks for the review. i already changed this piece of code in the last commit, it does not use any breakable now.",1,0.9304109811782837
1699569869,16456,chirag-wadhwa5,2024-08-01T07:24:21Z,thanks for the review. i think there is a difference between both the if and else cases. i actually used the code from the normal fetch request and the throttling logic is the same as it is there.,1,0.9001449346542358
1699572051,16456,chirag-wadhwa5,2024-08-01T07:26:11Z,"thanks for the review. i think this comment was addressing an issue in the previous version of the pr. i pushed a commit later, which i believe resolved all issues related to asynchronous code. if you find any other gaps, pls let me know. thanks !",1,0.9825300574302673
1700521738,16456,junrao,2024-08-01T17:01:25Z,move the statement to a separate line since this case has multiple statements.,0,0.9832584857940674
1700530866,16456,junrao,2024-08-01T17:09:57Z,could we make `fetchresult` a val by calling `handlefetchfromsharefetchrequest` here?,0,0.9888396859169006
1700533859,16456,junrao,2024-08-01T17:11:42Z,merge into previous line,0,0.9784125685691833
1700558567,16456,junrao,2024-08-01T17:32:45Z,is the todo still needed?,0,0.9859128594398499
1700562536,16456,junrao,2024-08-01T17:35:39Z,this can be a bit simpler like [code block],0,0.980987548828125
1700566242,16456,junrao,2024-08-01T17:39:01Z,no space before (,0,0.8640325665473938
1700574089,16456,junrao,2024-08-01T17:46:10Z,interesting => interested ?,0,0.9496520757675171
1700580952,16456,junrao,2024-08-01T17:50:48Z,shareacknowledgeresult seems unused?,0,0.9779549241065979
1700583206,16456,junrao,2024-08-01T17:52:10Z,this can be a bit simpler like [code block],0,0.980987548828125
1700589809,16456,junrao,2024-08-01T17:55:30Z,merge into previous line,0,0.9784125685691833
1700595263,16456,junrao,2024-08-01T18:00:08Z,"there is no conversion, right? so `converted` is inaccurate.",0,0.819214940071106
1700596185,16456,junrao,2024-08-01T18:01:01Z,add an extra new line below.,0,0.9829705953598022
1700596862,16456,junrao,2024-08-01T18:01:27Z,there is no down conversion.,0,0.9718157649040222
1700603141,16456,junrao,2024-08-01T18:06:24Z,"throttling is done inside this method. so, `invoked before throttling` is inaccurate.",0,0.9490384459495544
1700604916,16456,junrao,2024-08-01T18:08:13Z,could this be private?,0,0.9868327379226685
1700605031,16456,junrao,2024-08-01T18:08:20Z,indentation,0,0.982236921787262
1700609451,16456,junrao,2024-08-01T18:12:26Z,this can be a bit simpler like [code block],0,0.980987548828125
1700619173,16456,junrao,2024-08-01T18:17:45Z,could this be private?,0,0.9868327379226685
1700620774,16456,junrao,2024-08-01T18:19:16Z,could we add the new param to javadoc?,0,0.9884737133979797
1700655193,16456,junrao,2024-08-01T18:42:27Z,we could use a mutable map locally for better efficiency and return it as `map`.,0,0.987603485584259
1700657160,16456,junrao,2024-08-01T18:43:49Z,we could use a mutable map locally for better efficiency and return it as `map`.,0,0.987603485584259
1700662501,16456,junrao,2024-08-01T18:48:30Z,"i mean that since we mock `sharepartitionmanager.newcontext` to return errors.share_session_not_found, we are not really testing whether `sharepartitionmanager.newcontext` could handle incorrect group/member id properly. we are just testing if the caller can behave properly when `sharepartitionmanager.newcontext` returns an error. so, testing just one of incorrect group/member id seems enough.",0,0.9576514363288879
1700679813,16456,junrao,2024-08-01T18:59:08Z,"why is isacknowledgedatapresent true? there is no acknowledgement, right? ditto in a few other cases below.",0,0.7170218825340271
1701337300,16456,chirag-wadhwa5,2024-08-02T06:19:08Z,"understood, thanks a lot",1,0.9425472021102905
1701341077,16456,chirag-wadhwa5,2024-08-02T06:23:02Z,it's not. i have removed it. thanks !,1,0.971062958240509
1701409939,16456,chirag-wadhwa5,2024-08-02T07:22:33Z,"thanks for the review ! during the invocation of `sharepartitionmanager.newcontext` we don't pass any acknowledgements, so there's no way to know whether acknowledgements are present or not, only the variable `isacknowledgedatapresent` provides that information. my understanding says that in the general case, only the first fetch request (with request epoch 0) will not contain any acknowledgements, but all the subsequent requests would. going by that logic, i have set this variable to false in case request epoch is 0, and true in all the other cases.",1,0.9698269963264465
1702138634,16456,junrao,2024-08-02T17:37:00Z,this should be [code block],0,0.9864826202392578
1702139817,16456,junrao,2024-08-02T17:38:28Z,indentation,0,0.982236921787262
1702140987,16456,junrao,2024-08-02T17:39:53Z,merge with previous line?,0,0.9781162738800049
1702141861,16456,junrao,2024-08-02T17:40:47Z,extra new line,0,0.9643937349319458
1702159875,16456,junrao,2024-08-02T17:59:37Z,"`sharefetchmetadata(uuid.zero_uuid, -1)` could just be `newreqmetadata`?",0,0.988593339920044
1702169187,16456,junrao,2024-08-02T18:09:59Z,this is fine. we can leave it as it is.,0,0.8737708330154419
1704485591,16456,junrao,2024-08-05T18:24:21Z,this is unnecessary since `sharepartitionmanager.close()` already calls `persister.stop()`.,0,0.9632517695426941
1704494394,16456,chirag-wadhwa5,2024-08-05T18:33:45Z,"ohh yes, you are right, missed it. thanks. i have pushed the change",1,0.9830469489097595
1325138384,14364,philipnee,2023-09-13T22:32:26Z,just to create a coherent format,0,0.9788858294487
1325368170,14364,philipnee,2023-09-14T05:21:01Z,we should submit a patch to combine groupstate into memberstate.,0,0.9872645139694214
1325381139,14364,philipnee,2023-09-14T05:41:03Z,"it might be helpful to read the test: `public void testheartbeatresponse_errorhandling(final errors error, final boolean isfatal)`",0,0.9841859936714172
1325382420,14364,philipnee,2023-09-14T05:43:03Z,i wonder if this can be moved to the memberstatemanager.,0,0.8635085225105286
1325383326,14364,philipnee,2023-09-14T05:44:36Z,current i'm unable to reference the assignor config in memberstatemanager because it is always null.,0,0.900786817073822
1325999433,14364,lianetm,2023-09-14T13:59:12Z,"totally, but is there a reason why we couldn't just use the `membershipmanager` here already? i though that was the point of unblocking the state pr that includes all that's needed here.",0,0.9367986917495728
1326031428,14364,lianetm,2023-09-14T14:21:24Z,makes sense. let's move it on this same pr i would suggest,0,0.9448190331459045
1326089090,14364,lianetm,2023-09-14T14:56:57Z,"it's null here simply because it wasn't defined when creating the `membershipmanager` in the defaultbackgroundthread. my understanding is: - if the client specifies an assignor (client or server), we should make sure to set it in the `membershipmanager` when creating it in the defaultbackgroundthread [a link]. this will ensure that it is available here to send it on the heartbeatrequest. - if the client did not specified any assignor, then it will be ok to have null here, and we don't need to include anything for it in the heartbeatrequest. we let the group coordinator on the server select the default assignor for the member from the `group.consumer.assignors` config. correct me here if i'm missing something.",0,0.9495231509208679
1326105802,14364,dajac,2023-09-14T15:08:30Z,"that's right. the (server) assignor should be null be default as defined in the [a link]. when null, the server uses the first one in the list on the server side.",0,0.9891926646232605
1326205537,14364,philipnee,2023-09-14T16:14:48Z,thanks for the clarification.,1,0.5439716577529907
1326228037,14364,philipnee,2023-09-14T16:28:49Z,actually - my bad: i think we can just get rid of the groupstate.,-1,0.98697829246521
1326232358,14364,philipnee,2023-09-14T16:31:52Z,"there's a bit of refactoring needed, to keep things in scope for this pr - i will be submitting another pr to address this.",0,0.9735123515129089
1326463429,14364,lianetm,2023-09-14T20:09:54Z,"the subscription state already has it, and it is a component that is all over, so i would try to keep the regex in that single place",0,0.9821583032608032
1326478655,14364,lianetm,2023-09-14T20:24:07Z,"just for the record, that regex that we keep in the client (now on the subscriptionstate), will need to be updated to move away from the java `pattern` and use the new `subscriptionpattern` defined in the protocol i expect.",0,0.9896340370178223
1327513916,14364,philipnee,2023-09-15T16:09:28Z,"sounds good thanks! fwiw, a bit out of the scope here: we discussed the plan to split subscriptionstate to remove (some of) the synchronization locks. as users don't need to access the regex pattern directly (aside from submitting one), it might just live in the background thread once this refactor happens.",1,0.9890075922012329
1329227271,14364,lianetm,2023-09-18T20:14:47Z,this is not using the state from params so i expect the `else` part will never be executed (member should be always in the default unjoined). is it missing mocking the state value using the param i guess?,0,0.9754550457000732
1329251065,14364,philipnee,2023-09-18T20:34:22Z,you are right! i will rewrite this test just mocking the notingroup response.,1,0.8427562117576599
1329477649,14364,philipnee,2023-09-19T02:12:01Z,"i wonder if we could just call this ""shouldheartbeat"" as the server side protocol is tight to the heartbeat",0,0.678246021270752
1330246922,14364,lianetm,2023-09-19T14:38:43Z,"sure, sounds good to me",1,0.9429805874824524
1330274787,14364,dajac,2023-09-19T14:57:39Z,nit: i think that we usually use `()` instead of `{}` in to strings.,0,0.9882442951202393
1330275873,14364,dajac,2023-09-19T14:58:23Z,"should we add javadoc to attributes, classes and methods? i think that we usually do it for all the new java code these days.",0,0.9793362021446228
1330276646,14364,dajac,2023-09-19T14:58:52Z,this is incorrect. the heartbeat interval comes is provided in the response.,0,0.9311414957046509
1330277639,14364,dajac,2023-09-19T14:59:37Z,nit: let's add javadoc to be consistent with the other methods.,0,0.9863670468330383
1330280744,14364,dajac,2023-09-19T15:01:22Z,"i am not sure to follow the `membershipmanager.notingroup()` part here. if we are not in the group, shouldn't we heartbeat to join (or rejoin) it?",0,0.838089108467102
1330281420,14364,dajac,2023-09-19T15:01:42Z,nit: we could use `ifpresent`.,0,0.9894447922706604
1330282085,14364,dajac,2023-09-19T15:02:04Z,nit: this empty line could be removed.,0,0.9853678345680237
1330286961,14364,dajac,2023-09-19T15:04:58Z,"when we transition to failed in updatestate, i think that it analogous to a non retriable error. is our plan to capture all the non-retriable errors before we reach this? we also do some error handling in updatestate. the responsibilities are not clear here.",0,0.9672545790672302
1330288247,14364,dajac,2023-09-19T15:05:56Z,nit: the naming does not respect our conventions here. we should use camel case.,0,0.8356102705001831
1330319691,14364,lianetm,2023-09-19T15:27:08Z,"agree that we need to better define responsibilities. as i see it for now, the membershipmgr should only come into play here when it's time to `updatestate`, and that would be : - when no errors in hb response (to extract relevant state info from the response and transition to `stable`) - when there is a non-retriable error (to transition to `failed`) any retriable error received in the hb response would be handled in the heartbeat manager here, while the state remains unchanged (ex. unjoined). with this approach, there would error handling in both, the heartbeat manager and the membership manager but for different purposes: - heartbeatmanager handles errors to continue retrying the request if needed (until it gets a success or fatal error, in which case it would stop retrying and call `updatestate`) - membershipmanager `updatestate` internally handles fatal errors only, just to update state info accordingly (ex. reset epoch on fence) and do the right transition. thoughts?",0,0.9771212935447693
1330451339,14364,philipnee,2023-09-19T17:04:22Z,i see - i think we've been consistently using { in the refactor. maybe we should change that,0,0.9823713898658752
1330458175,14364,philipnee,2023-09-19T17:11:10Z,will do. sorry for completely missing this part.,-1,0.9870075583457947
1330460386,14364,philipnee,2023-09-19T17:13:24Z,"thanks, just note it here: `group.consumer.heartbeat.interval.ms is defined on the server side and the member is told about it in the heartbeat response.`",1,0.7972326874732971
1330475695,14364,philipnee,2023-09-19T17:25:35Z,"as previously commented, maybe let's use `shouldheartbeat` to be more explicit",0,0.9735843539237976
1330480862,14364,philipnee,2023-09-19T17:28:37Z,i've seen it in quite a few places so i thought we don't have a conventions :grinning_face_with_sweat:,-1,0.755763053894043
1330940223,14364,philipnee,2023-09-20T03:45:13Z,"thanks, i made some update to the manager, in particular, i split the fatal error out of the updatestate, lmk if you like the change, or we could do better.",1,0.7546444535255432
1331809403,14364,lianetm,2023-09-20T15:26:35Z,"this `onfatalerror` does update the state for the member, so separating it from the `updatestate` leads to having the update logic and transitions in 2 places (which i think is harder to follow/troubleshoot). what about we go back to a single `updatestate` responsible for updating state (aka. member info and transitions) . and if we make this single `updatestate` return the optional that it may find in the response, then we could leave the error handling only in the membershipmanager, and the heartbeatmanager could be much simplified. take a look at [a link] draft pr and let me know your thoughts",0,0.9798786640167236
1331811249,14364,lianetm,2023-09-20T15:27:56Z,this whole func would completely disappear if we agree on the something like the draft pr [a link],0,0.9619184732437134
1331828912,14364,lianetm,2023-09-20T15:40:02Z,"again brainstorming based on the [a link], this would be much simplified with the move of the error handling more into the membershipmanager i expect. here, instead of having to paths to update state (now there are 2 calls, one to membershipmanager.updatestate and another for all the error handling), we could simply have something like: [code block]",0,0.9812093377113342
1331895217,14364,philipnee,2023-09-20T16:21:45Z,"why don't we let the heartbeat request manager to handle all the errors? technically, these are heartbeat errors, and it would be more centralized to handle them on the manager. the membershipmanager really could just ensure if the transition is valid.",0,0.9838565587997437
1331944957,14364,lianetm,2023-09-20T17:05:56Z,"sounds good, actually better to move it all to the heartbeat manager, given that it is the more concerned about the hb errors. the membershipmgr in the end only needs to know about what affects the state (success, fencing and fatal failures)",1,0.560753345489502
1331948509,14364,lianetm,2023-09-20T17:09:14Z,"this could still be simplified a lot like i was suggesting in the comment above. not handling all errors, only the fencing/fail ones. for all the rest is a common action that could be done with a single `nonretriableerrorhandler.handle(error.get().exception());`",0,0.9839410185813904
1331997791,14364,lianetm,2023-09-20T17:56:41Z,this will be invoked on any non-retriable error i expect (not only the unreleased_member_id),0,0.9891839027404785
1332028195,14364,lianetm,2023-09-20T18:27:58Z,this could be final now,0,0.9828186631202698
1332033298,14364,lianetm,2023-09-20T18:33:35Z,nit nit: i find it a better format to read the code if adding the separators at the end of the previous line for better alignment (having all the added `propid=` at the beginning of each line),0,0.9717056155204773
1332033928,14364,lianetm,2023-09-20T18:34:17Z,indentation,0,0.982236921787262
1332038622,14364,lianetm,2023-09-20T18:39:21Z,indentation? (i guess it shouldn't be the same as in the requestmanager down below),0,0.9794433116912842
1332041024,14364,lianetm,2023-09-20T18:41:52Z,this is only needed when there is a groupid defined so i would move it completely to the `if (groupstate.groupid != null)` block,0,0.9875364899635315
1332064354,14364,lianetm,2023-09-20T19:06:17Z,"i think we should explain a bit here about the timing of the heartbeat requests, which is also managed by this class. it would be good to explain the timing logic based on the interval as max waiting time, but also mentioning that the manager may send out a hb request without waiting for the interval, ex. when completing processing an assignment.",0,0.9835349321365356
1332069325,14364,lianetm,2023-09-20T19:11:45Z,"given that the `cansendrequest` checks the heartbeat interval, this means that we'll be only sending heartbeats on the interval (heartbeattimer.isexpired()), but we also need to have a mechanism for sending heartbeat requests ""on-demand"" (ex. when rebalance callbacks execution finishes, we should send a hb request right away , without waiting for the interval timer to expire)",0,0.987068772315979
1332077647,14364,lianetm,2023-09-20T19:20:50Z,do we need this at the class level? seems to only be needed in the constructors for initializing the heartbeattimer,0,0.9892132878303528
1332093119,14364,lianetm,2023-09-20T19:38:01Z,final,0,0.9030922651290894
1332115559,14364,lianetm,2023-09-20T20:03:05Z,"i think we should still validate here that the response contains no error (and throw illegalargument if so), as this func now is only expected to be called on successful responses. without such validation, an erroneous call to this func in the case of an error would end up going unnoticed and transition the member to stable.",0,0.9832803010940552
1332177568,14364,kirktrue,2023-09-20T21:00:24Z,can we resolve the error code to an `errors` object via `errors.forcode()`?,0,0.989441990852356
1332178673,14364,kirktrue,2023-09-20T21:01:15Z,"same question here, can we use and compare errors based on `errors` (which we can get via `errors.forcode()`)?",0,0.9882494211196899
1332183105,14364,kirktrue,2023-09-20T21:04:48Z,same request here: use `errors` to remove unnecessary use of raw error `code`.,0,0.986289918422699
1332190917,14364,kirktrue,2023-09-20T21:11:24Z,can we rename `failmember` to be more descriptive?,0,0.9847462177276611
1332191970,14364,kirktrue,2023-09-20T21:12:39Z,"per the related comment, can we rename `failmember` something that is more descriptive of what action _happened_ vs. that action's _result_?",0,0.9856134057044983
1332443272,14364,philipnee,2023-09-21T04:40:54Z,"this is a pretty common pattern to override tostring. do you mean making it doing? [code block] currently everything is in a single line. though - this can be used for logging, so i wonder what would it look like it if we add line separator.",0,0.9422794580459595
1332444068,14364,philipnee,2023-09-21T04:41:41Z,:person_facepalming:,0,0.9838271141052246
1332446857,14364,philipnee,2023-09-21T04:44:25Z,make sense.,0,0.9656602740287781
1332454913,14364,philipnee,2023-09-21T04:54:32Z,i thought it would be more clear on how to implement this after the revocation is implemented or implement it with the assignment logic - can we punt it to a separated pr?,0,0.9849591851234436
1332455723,14364,philipnee,2023-09-21T04:55:43Z,"this is left non-final intentionally - as sometimes we might want to spy the membership class, so the test function can override it.",0,0.983389675617218
1332466756,14364,philipnee,2023-09-21T05:11:46Z,maybetransitiontofailure ?,0,0.9879648685455322
1333624789,14364,lianetm,2023-09-21T21:33:13Z,"agree with the pattern, i was only referring to having the nit of having props aligned : [code block]",0,0.982628583908081
1333629206,14364,lianetm,2023-09-21T21:39:58Z,"ok with having it in a separate pr but let's maybe add a comment/todo here, and think about how to define the interaction between the assignmentreconciler and this hb manager. they need to somehow communicate to trigger a hb request when the callbacks complete successfully (exactly what came out in the assignmentreconciler pr review [a link]",0,0.9834079146385193
1334626047,14364,lianetm,2023-09-22T16:57:01Z,typo membershipmanager,0,0.9854745864868164
1334633010,14364,lianetm,2023-09-22T17:04:49Z,i think this is not only for revocation. i expect members should send a heartbeat request as soon as they complete processing an assignment without waiting for the interval (for both cases: new partitions being added and partitions being revoked). let's double check with,0,0.9696276783943176
1334636930,14364,lianetm,2023-09-22T17:09:23Z,unused since the class level var was removed,0,0.9756787419319153
1334645635,14364,lianetm,2023-09-22T17:19:05Z,"i find it a bit confusing to say that the member won't send hb when it left the group. agree that it holds true when a member intentionally leaves a group (ex. when the consumer is closed), but it's not true for when a member is left out of the group by the server (ex. all fencing scenarios). when left out of a group because of a fencing situation, the member will release its assignment and send hb again to rejoin.",-1,0.8778097629547119
1334652824,14364,lianetm,2023-09-22T17:27:10Z,"i think we're still missing important info in the doc about the hb interval and how it is applied. (the heartbeat sent on the heartbeat interval, that is received from the server on the first hb response. if the member finishes processing an assignment (partitions assigned/revoked) the interval is not honored and the hb request is sent out right away)",0,0.9837620854377747
1334657428,14364,lianetm,2023-09-22T17:32:14Z,uhm we're using a 0 as default `heartbeatintervalms` here. this will only get updated when we get the value from the server in the first hb response. thinking about the case where we send an initial hb request but never get a response...does this 0 then mean that we'll continue to send a hb on every poll iteration?,0,0.9802486300468445
1334659219,14364,lianetm,2023-09-22T17:34:12Z,nit: review punctuation marks usage,0,0.9860619902610779
1334668800,14364,lianetm,2023-09-22T17:45:30Z,"agree that we'll ""update the timer when the response is received"", but i see here that the timer is only used on the case where it is not time to send hb yet (if block above, ln 112). in the case of this return, which is the case when the hb request manager is polled and notices it is time to send the hb, we're always passing `long.max_value` as `timemstillnextpoll`. shouldn't we use the timer here too (that will have its default value if this is a first req, or the one provided by the server in a previous hb response)?",0,0.9855382442474365
1334734541,14364,philipnee,2023-09-22T19:08:25Z,"the cansendrequest should take care of the inflight request. if the request has been sent w/o a response/error, it won't try to send again. for the initial state, i really just need to set to a specific number as we get the hb response from the server. i set to 0 because i think the client should quickly poll the manager against to see if it can send a heartbeat. another alternative is to use `backoffs` to prevent a tight loop there. wdyt?",0,0.9801817536354065
1335289660,14364,lianetm,2023-09-25T01:02:54Z,"got it, seeing that the `cansendrequest` considers inflight requests then it makes sense to set an initial value of 0 i would say, so that we send the first hb as soon as the hm manager starts. i would only suggest to add some tests for the interval, including this case where we might not get a response to our first hb request.",0,0.984522819519043
1335295791,14364,lianetm,2023-09-25T01:20:46Z,`shouldsendheartbeat` returning false when unjoined does not seem right. we do need to send hb when unjoined to be able to join the group. i would say failed is the only state we we shouldn't send hb.,0,0.8617447018623352
1335297785,14364,lianetm,2023-09-25T01:27:16Z,"given that the current `shouldsendheartbeat` returns false when unjoined, i expect the second part of this condition will be true when a members starts for the first time and we'll return a pollresult with empty request list, so we'll never be sending the first hb request?",0,0.9848207831382751
1335304701,14364,lianetm,2023-09-25T01:46:06Z,"this is a non-retriable exception, so i expect we should be calling `membershipmanager.transitiontofailure()`? (same for all other fatal exceptions up to the `unreleased_instance_id`, which is properly doing the transition)",0,0.9869595170021057
1335307959,14364,lianetm,2023-09-25T01:55:36Z,"from the hb request manager point of view, this means that when polled, it won't return any request right? could we assert that to ensure that the request manager is actually not generating requests at this point?",0,0.9876157641410828
1335309021,14364,lianetm,2023-09-25T01:58:34Z,"if we agree on the [a link] regarding missing transitions when handling fatal errors, i expect this will be updated to reflect align with it and check transition to failed on all fatal errors other than the 2 fencing ones.",0,0.9817937612533569
1336389075,14364,philipnee,2023-09-25T21:06:06Z,i think you are right.,0,0.9082234501838684
1336390801,14364,philipnee,2023-09-25T21:08:17Z,the updated pr should invoke maybetransitiontofailurestate() on a few fatal exceptions.,0,0.9839450716972351
1336429379,14364,philipnee,2023-09-25T22:03:13Z,"so when we startup the manager, the timer will be set to 0 until the first heartbeatinterval response is received. which means, we will get a heartbeat request on the first poll. i added a test for this.",0,0.984682559967041
1337234985,14364,lianetm,2023-09-26T13:42:35Z,wrong placeholder {},0,0.8485751152038574
1337235694,14364,lianetm,2023-09-26T13:43:05Z,ditto,0,0.8428916931152344
1337238424,14364,lianetm,2023-09-26T13:44:57Z,"tries ""to"" rejoin",0,0.974493682384491
1337239851,14364,lianetm,2023-09-26T13:45:54Z,"and ""try""",0,0.9553874135017395
1337258265,14364,lianetm,2023-09-26T13:57:51Z,"this format won't show as a proper list in the java doc, we should use ` ` tags (similar for the empty lines)",0,0.9870914220809937
1337263803,14364,lianetm,2023-09-26T14:00:56Z,"true, but the poll is much more than just determining the wait time, so i would add to this something like "" it builds the heartbeat request, including the logic for handling the responses""",0,0.9801581501960754
1337265790,14364,lianetm,2023-09-26T14:02:19Z,comma after expired,0,0.985005259513855
1337269007,14364,lianetm,2023-09-26T14:04:32Z,these empty lines won't show as such in the java doc so let's add tags to ensure we have the separation we want,0,0.9859851598739624
1337275381,14364,lianetm,2023-09-26T14:08:55Z,"just for my understanding, what's the idea behind this todo? i thought we had inflight req handling in the parent `requeststate`, that already identifies `log.trace(""an inflight request already exists for {}"", this);`. and what would be the concurrent scenario if there is a single background thread sending heartbeats and it is not resending while there is one inflight?",0,0.9830711483955383
1337278130,14364,lianetm,2023-09-26T14:10:40Z,extra space after state.,0,0.9847992658615112
1337278315,14364,lianetm,2023-09-26T14:10:47Z,ditto,0,0.8428916931152344
1337282271,14364,lianetm,2023-09-26T14:13:22Z,final,0,0.9030922651290894
1337282860,14364,lianetm,2023-09-26T14:13:46Z,extra line,0,0.9743177890777588
1337295428,14364,lianetm,2023-09-26T14:20:46Z,seems we're not using `memberassignment` in the test anymore? let's remove if unused,0,0.9851810932159424
1337309504,14364,lianetm,2023-09-26T14:28:25Z,"high level comment, i do see this test covering the timing logic for sending, and the response handling on error, but nothing for the successful hb response handling (important to ensure that it is updating the target assignment so that it can be processed by other components). also it would be helpful to have some tests around hb timeouts, mainly to validate the retry logic around that. (just suggestions for better coverage of core actions, ok for me if we prefer to target that in a separate pr)",0,0.8562024831771851
1337418980,14364,philipnee,2023-09-26T15:37:20Z,this is just for comment formatting.,0,0.9851904511451721
1337420489,14364,philipnee,2023-09-26T15:37:58Z,"i think it was a note from before, removed.",0,0.985093355178833
1337423659,14364,philipnee,2023-09-26T15:39:35Z,we don't make these var final in tests because we could change them later,0,0.9759926199913025
1337428627,14364,lianetm,2023-09-26T15:43:11Z,"ok, that's fine but not enough. i think here we also need the tags. if you look at the java doc it shows as a giant block, which i expect it is not what we want.",0,0.9281311631202698
1337639317,14364,lianetm,2023-09-26T18:42:23Z,"agree, with the fix for the `shouldsendheartbeat` this should now work as expected.",0,0.9833085536956787
1340176254,14364,lianetm,2023-09-28T13:40:51Z,seems this is still wrong? same for the following comment,0,0.7386388778686523
1340351740,14364,philipnee,2023-09-28T15:44:05Z,for some reason the change didn't get pushed.,0,0.9507211446762085
1341528842,14364,dajac,2023-09-29T15:42:23Z,i actually missed this in the other pr but the assignor selection should be based on the new `group.remote.assignor` config which should be null by default. null means that the server selects the assignor.,0,0.9742951393127441
1341531725,14364,dajac,2023-09-29T15:44:30Z,don't we need to rejoin with epoch 0 when the member is kicked out of the group? we should actually remove all partitions and trigger the partition lost callback as well before doing so.,0,0.9847346544265747
1341532755,14364,dajac,2023-09-29T15:45:21Z,what's the delay for the next event loop?,0,0.9735004901885986
1341535159,14364,dajac,2023-09-29T15:47:25Z,i wonder if we really need this. i would expect retriable exception to inherit from `retriableexception` and the fatal ones to not inherit from it. is it possible to leverage this somehow?,0,0.5356114506721497
1341535814,14364,dajac,2023-09-29T15:47:51Z,should we have javadoc for all those attributes?,0,0.9884747862815857
1341539358,14364,dajac,2023-09-29T15:50:34Z,"when the reconciliation of the local assignment is completed, we need to send the heartbeat request immediately to ack it. is this going to be another condition here?",0,0.9820339679718018
1341540248,14364,dajac,2023-09-29T15:51:17Z,this answers my previous comment :). note that we also need to do this when partitions are assigned.,1,0.8269611597061157
1341547285,14364,dajac,2023-09-29T15:56:40Z,"most of the fields in the consumergroupheartbeat req/rsp are optional. our aim was to avoid having to send unnecessary information when the group is stable. in this case, the request/response should be as lightweight as possible. there are basically three requires fields: groupid, memberid, memberepoch. those must be set all the time. i am also debating whether groupinstanceid should also be. for all the others, they should only be set if they have changed. we should also send out a full request when we recover from a recoverable error (e.g. fenced, network issues, timeouts, etc.).",0,0.8702791929244995
1341548905,14364,dajac,2023-09-29T15:57:54Z,"on the regex topic, keep in mind that we will support both the java regex and the new sever side one for a while. when the java regex is used, the resolution must be done locally. when the server side regex is used, we must pass it to the server.",0,0.9855359196662903
1341588720,14364,dajac,2023-09-29T16:40:07Z,i don't really get the value of this map given that we handle all (known) errors anyway. should we just move `transitiontofailure` to there?,0,0.9549205899238586
1341590757,14364,dajac,2023-09-29T16:42:44Z,"the name `onfatalerrorresponse` is incorrect here, isn't it? we handle recoverable errors (e.g. fenced_member_epoch). personally, i would prefer to re-group all errors in `onerrorresponse` and have a `switch` covering all of them there. this would simplify the code and avoid repetition such as `errors.forcode(response.data().errorcode())` which is in both places. thoughts?",0,0.9736497402191162
1341591777,14364,dajac,2023-09-29T16:44:00Z,we also pass the `errormessage` to `exception()` here in order to give it back to the user.,0,0.9886283874511719
1341592473,14364,dajac,2023-09-29T16:44:54Z,don't we need to propagate those unknown errors to the user as well? what's our strategy here?,0,0.9746084809303284
1341592782,14364,dajac,2023-09-29T16:45:16Z,nit: we usually declare final attributes before the others.,0,0.9876016974449158
1341593245,14364,dajac,2023-09-29T16:45:51Z,nit: couldn't it be final as well?,0,0.9442489147186279
1341596109,14364,dajac,2023-09-29T16:49:23Z,"why do we need this try catch here? if we remove it, where would the exception be caught?",0,0.974122166633606
1341597457,14364,dajac,2023-09-29T16:50:52Z,nit: `transitiontofenced` to be aligned with the other one?,0,0.9868468642234802
1341597673,14364,dajac,2023-09-29T16:51:08Z,nit: should it be `transitiontofailed`?,0,0.9869297742843628
1341662210,14364,lianetm,2023-09-29T18:00:53Z,"agree, i missed this too. we agreed that we would have no default on the client side, and would let the server choose.",1,0.5187218189239502
1341666380,14364,lianetm,2023-09-29T18:06:37Z,"agree too. it's only when the member leaves the group intentionally (ex. when consumer closes) that i expect this applies, no more hb. (addressed also on [a link] comment)",0,0.9753013849258423
1341669179,14364,philipnee,2023-09-29T18:10:28Z,"yeah possible - but i'll need to encode the 2 exceptions, i.e. unknown member id and fenced epoch, somewhere",0,0.9863914251327515
1341690694,14364,philipnee,2023-09-29T18:37:33Z,"it is a little bit tricky here, because the background thread loop is blocked until either it receives some responses, or the timer of the minimum of the heartbeat, metadata, or request timeout is expired. what we would do is to reset the heartbeatrequeststate so that we could ensure the next event loop will trigger a heartbeat. the timing, however, is a little tricky here, because it can be non-deterministic of when the next heartbeat will be sent.",0,0.8699915409088135
1341699215,14364,philipnee,2023-09-29T18:49:09Z,left a todo. will have a separated pr to fix this.,0,0.9827368259429932
1341767013,14364,philipnee,2023-09-29T20:27:16Z,"actually i think we should, thanks for the catch.",1,0.806556761264801
1341775832,14364,philipnee,2023-09-29T20:41:42Z,"we don't, it is purely for logging purposes. for the case of this exception, maybe we should fail the request and retry.",0,0.9693922996520996
1341778036,14364,philipnee,2023-09-29T20:45:03Z,we probably don't need it after all. because error is thrown when an error is presented in the response.,0,0.958885669708252
1342665614,14364,dajac,2023-10-02T13:03:52Z,"my understanding is that we basically retry on all exceptions here. am i correct? it seems to me that we could also get non-retriable exceptions here (e.g. unsupportedversionexception, etc.). how do we handle those?",0,0.9672877788543701
1342666388,14364,dajac,2023-10-02T13:04:24Z,"we also need to handle `unsupportedversionexception` error, i think.",0,0.9814522862434387
1342667683,14364,dajac,2023-10-02T13:05:20Z,"would it make sense to just call `membershipmanager.transitiontofailed();` in all errors instead of having this one? at the movement, the handling is a little inconsistent.",0,0.965091347694397
1342669966,14364,dajac,2023-10-02T13:06:52Z,nit: we usually put an empty line between cases. it makes it a bit more readable.,0,0.9745091795921326
1342674863,14364,dajac,2023-10-02T13:10:14Z,"when we get this one, i understand that we will mark the coordinator as unknown to rediscover it. is it going to apply the exponential backoff after that?",0,0.9854627847671509
1342677484,14364,dajac,2023-10-02T13:12:26Z,this message is not consistent with the others. should it also start with `groupheartbeatrequest failed due to...`? i would also replace `retrying` by something like `will attempt to find the coordinator again and retry`.,0,0.9096075296401978
1342678720,14364,dajac,2023-10-02T13:13:33Z,"nit: this one is also inconsistent. `+ ""retrying""` could be merged with the previous string. a space misses between `loading.` and `retrying`.",0,0.9615060687065125
1342681301,14364,dajac,2023-10-02T13:15:56Z,"i don't really understand how the error message is handled here. is it going to be added as the message of the exception later on? when i mentioned this in my earlier comment, i means doing this `errors.invalid_request.exception(errormessage)`. this uses the provided error message.",0,0.7543853521347046
1342682876,14364,dajac,2023-10-02T13:17:24Z,does the :thumbs_up_light_skin_tone: mean that you will add it?,0,0.9803341031074524
1342683440,14364,dajac,2023-10-02T13:17:54Z,should we also log something here?,0,0.9864739179611206
1342689429,14364,dajac,2023-10-02T13:23:06Z,i also wonder if having a tailored error message for each error is needed. an alternative would be to group errors and have a generic message for the fatal ones for instance. what do you think?,0,0.7337254285812378
1342694336,14364,dajac,2023-10-02T13:27:18Z,i also noticed that we have the following in the current implementation: [code block],0,0.9835143089294434
1342778930,14364,philipnee,2023-10-02T14:37:07Z,"the heartbeat request depends on the state of the state machine, so for most of the non-retriables, it should transition the state to a failure state to prevent additional requests being sent. the non-retriable also send an error to the handler (`nonretriableerrorhandler`) to send the error to the user to handle the failure case.",0,0.9834596514701843
1342781938,14364,philipnee,2023-10-02T14:39:25Z,"but we don't want errors like `coordinator_not_available` to be fatal, no?",0,0.9534375667572021
1342783380,14364,philipnee,2023-10-02T14:40:41Z,really? :grinning_face_with_sweat: most cases i see don't have an empty line. but i'll add a line anyway.,0,0.53812175989151
1342785385,14364,philipnee,2023-10-02T14:42:21Z,yap - `this.heartbeatrequeststate.onfailedattempt(currenttimems);` basically markets the `lastreceivedms` as the response receive time. then it would trigger the backoff mechanism in the requeststate. i think expo backoff was tested in the test.,0,0.9818975329399109
1342899010,14364,philipnee,2023-10-02T16:14:38Z,yap that's a good idea to make the code easier to follow. we do want to provide some context such as group id or group instance id to group_authorization_failed and unreleased_instance_id respectively. so i'm grouping the following 4 errors [code block],0,0.7188393473625183
1342910020,14364,philipnee,2023-10-02T16:25:52Z,"added some comments directly above the var - is this enough or you actually want this to be presented in the ""javadoc"" of the class section?",0,0.9893380403518677
1342915079,14364,philipnee,2023-10-02T16:31:09Z,i understand the concern about inconsistency but different errors can put the member in a different state,0,0.9430841207504272
1342920121,14364,philipnee,2023-10-02T16:36:57Z,"yap i see the disconnectexception handling, it is implemented by all requests going to the coordinator. here we handle them independently in the request mangers. maybe we could modularize these reaction to make it more unified.",0,0.9757251739501953
1344205855,14364,dajac,2023-10-03T14:29:18Z,my point was that the `exception` received here may not be re-triable (e.g. unsupportedversionexception) and that we may have to take actions on them (e.g. disconnectexception). are you saying that we handle those in another component? my current understanding is that we don't update the state machine based on those exceptions at the moment because `onerrorresponse` is not called. do we understand all the exceptions that we could receive here? we need to handle them all appropriately.,0,0.9666939973831177
1344221907,14364,dajac,2023-10-03T14:36:18Z,it seems that we could get the following ones: [code block] + `timeoutexception`,0,0.9866748452186584
1344230989,14364,dajac,2023-10-03T14:38:36Z,"sorry, i was not clear. i was trying to say that we should just call `membershipmanager.transitiontofailed();` in the relevant errors in the switch.",-1,0.9869924783706665
1344232148,14364,dajac,2023-10-03T14:39:14Z,"do we want to backoff in this case though? it seems to me that we want to retry immediately when the new coordinator is discovered, no?",0,0.9776638150215149
1344236644,14364,dajac,2023-10-03T14:42:12Z,could we please file a jira for this?,0,0.9858139157295227
1344336463,14364,philipnee,2023-10-03T15:50:54Z,i see. sure we could certainly do that.,0,0.5513947606086731
1344462484,14364,philipnee,2023-10-03T17:17:27Z,"i think we might want to refactor the coordinator requests per what you indicated above. a jira is filed: [a link] otherwise, in the onfailure() method, i added the logic to fail the state machine and propagate the error when the error is non-retriable",0,0.9872344136238098
1344497810,14364,philipnee,2023-10-03T17:43:27Z,see `testheartbeatonstartup` in the test. the first poll returns a request.,0,0.9870854020118713
1344512748,14364,philipnee,2023-10-03T17:56:32Z,here you go david: [a link],0,0.9094473719596863
1344515152,14364,philipnee,2023-10-03T17:58:41Z,"thanks - the seems like the right way to do this to only backoff for coordinator_load_in_progress error. onfailedattempt is removed. in the test `testheartbeatresponseonerrorhandling`: next heartbeat is verified ` assertequals(0, heartbeatrequeststate.nextheartbeatms(mocktime.milliseconds()));`",1,0.7505708932876587
1344560113,14364,lianetm,2023-10-03T18:40:40Z,duplicated above,0,0.987354576587677
1344567777,14364,lianetm,2023-10-03T18:47:54Z,"i expect this will be the place where we'll need to make sure to release any assignment we may have, right? whenever a transitiontofailed/fence occurs, the hb manager should call the reconciler to trigger the onpartitionslost/revoked as needed. let's add a todo just as we did for the missing bit of triggering the hb before the interval.",0,0.9825261831283569
1344589907,14364,philipnee,2023-10-03T19:03:45Z,this is actually invalid because the response can be null in this case. i filed a jira kafka-15278 to propagate the time from the networkclientdelegate,0,0.9804320335388184
1344603478,14364,philipnee,2023-10-03T19:08:57Z,i added a test for the heartbeat timeout. see `testbackoffonheartbeattimeout`,0,0.9836629629135132
1345652576,14364,dajac,2023-10-04T11:38:27Z,i would add real javadoc to all attributes or none of them. this is what we have been doing for all the new java code recently.,0,0.9810985922813416
1345661869,14364,dajac,2023-10-04T11:46:16Z,nit: it would be good to be consistent in the log messages. they almost all start with `groupheartbeatrequest failed due...`. why don't we do the same here? i think that this is important to know that the groupheartbeatrequest failed in this case as well. the same applies to coordinator_load_in_progress. `groupheartbeatrequest failed because the group coordinator %s is incorrect. will attempt to find the coordinator again and retry`.,0,0.8586608171463013
1345662992,14364,dajac,2023-10-04T11:47:13Z,nit: `groupheartbeatrequest failed because the group coordinator %s is still in the process of loading state. will retry`.,0,0.9795659184455872
1345667909,14364,dajac,2023-10-04T11:51:33Z,it would be great to split those two in order to have separate error messages. fenced_member_epoch: `groupheartbeatrequest failed because member epoch %s is invalid. will abandon all partitions and rejoin the group` unknown_member_id: `groupheartbeatrequest failed because member id %s is invalid. will abandon all partitions and rejoin the group`,0,0.9634361863136292
1345669627,14364,dajac,2023-10-04T11:53:03Z,should we revert this? it seems that we don't need it anymore.,0,0.6790629625320435
1345670931,14364,dajac,2023-10-04T11:54:19Z,nit: constants are usually formatted as follow: `heartbeat_interval_ms`.,0,0.9891197681427002
1345680555,14364,dajac,2023-10-04T12:01:21Z,nit: we can remove empty line here.,0,0.9881495237350464
1345683631,14364,dajac,2023-10-04T12:03:20Z,so by default `heartbeatrequeststate` is a mock but we don't prefix it with `mock`. this is inconsistent...,-1,0.5483281016349792
1345684050,14364,dajac,2023-10-04T12:03:37Z,could we use `createmanager()` here?,0,0.9886410236358643
1345687969,14364,dajac,2023-10-04T12:06:18Z,nit: bring back on previous line.,0,0.9862611889839172
1345688824,14364,dajac,2023-10-04T12:07:04Z,nit: final to be consistent with the others?,0,0.9802770614624023
1345689109,14364,dajac,2023-10-04T12:07:21Z,nit: remove `this.` to be consistent with the others.,0,0.9841527342796326
1345692568,14364,dajac,2023-10-04T12:10:13Z,should we have a test which verifies that fatal errors update the state machine?,0,0.9750317931175232
1345695035,14364,dajac,2023-10-04T12:12:10Z,should we add a unit which verifies the generated request? we have none doing this...,0,0.5321980118751526
1345696189,14364,dajac,2023-10-04T12:13:08Z,nit: `manually...`. could you please verify all the other comments as well? i don't really care if they start with a capital letter or not but i do care about consistency...,-1,0.8671159744262695
1345697251,14364,dajac,2023-10-04T12:14:00Z,nit: is this really needed? it seems that using `code` would work as well.,0,0.9848724603652954
1345703205,14364,dajac,2023-10-04T12:18:13Z,"it is a bit weird to statically import those two but not the others (also used in this class), no?",-1,0.9860803484916687
1345704121,14364,dajac,2023-10-04T12:18:58Z,nit: could we align `errorcode` on `errorcode`?,0,0.9901384115219116
1345704966,14364,dajac,2023-10-04T12:19:40Z,should we add unsupported version as well?,0,0.9842602610588074
1345951445,14364,philipnee,2023-10-04T14:55:54Z,pretty sure i reverted in the previous commit....hmm,0,0.697458803653717
1346233433,14364,philipnee,2023-10-04T17:32:22Z,"thanks, i'll just get rid of the mock there. probably unnecessary.",0,0.6702820658683777
1346244285,14364,philipnee,2023-10-04T17:41:57Z,i refactored the if else block using switch. i think it should make it a bit more readable.,0,0.9817772507667542
1346245842,14364,philipnee,2023-10-04T17:43:22Z,see above - this section is refactored into swtich.,0,0.9868980646133423
1346258637,14364,philipnee,2023-10-04T17:54:40Z,`ensurefatalerror()` already ensure the transitiontofailed is invoked. `testtransitiontofailure` in the membershipmanagerimpltest also verifies the state transition.,0,0.987929105758667
1346463825,14364,philipnee,2023-10-04T21:05:36Z,added `testvalidateconsumergroupheartbeatrequest` - which validate the fields in the the requestbuilder.build(version) - is that what do you mean?,0,0.9885368347167969
1347439165,14364,dajac,2023-10-05T13:38:54Z,nit: sorry but i missed those yesterday. could we also align those log messages to the other format used: `groupheartbeatrequest failed....`?,-1,0.9898669719696045
1347441115,14364,dajac,2023-10-05T13:40:12Z,nit: empty line.,0,0.8843977451324463
1347441582,14364,dajac,2023-10-05T13:40:31Z,nit: empty line.,0,0.8843977451324463
1347447016,14364,dajac,2023-10-05T13:44:05Z,hum... i don't follow. my point was that we don't have any tests verifying that we actually update the state machine when a fatal __exception__ is received [a link]. or did i miss it?,-1,0.9069878458976746
1347448120,14364,dajac,2023-10-05T13:44:49Z,"yep, thanks.",1,0.7725735306739807
1347449738,14364,dajac,2023-10-05T13:45:50Z,should we verify all the fields? we also set others [a link].,0,0.9889236092567444
1347455966,14364,dajac,2023-10-05T13:49:46Z,nit: assure...,0,0.960555911064148
1347728174,14364,philipnee,2023-10-05T16:57:22Z,done - i left a todo to verify client and server side assignors and pattern regex.,0,0.9884005784988403
1348690378,14364,dajac,2023-10-06T12:58:35Z,"i am not really satisfied by the logging on failures: * when there is a fatal error, it logs a warning follower by an error. * the messages don't really follow the format of the other messages. should we just drop the warning on top? could we update the remaining debug message to follow the structure of the other log messages?",-1,0.9275220632553101
1348885178,14364,philipnee,2023-10-06T15:35:26Z,"thanks, let's drop the warn. i also updated the debug message.",1,0.5405824184417725
1788067718,17373,mumrah,2024-10-04T17:36:06Z,these (and other similar `testruntimeonly`) should be put into the `runtimetestlibs` definition,0,0.9873998165130615
1788068473,17373,mumrah,2024-10-04T17:36:26Z,what's this dependency for?,0,0.9688006043434143
1788082764,17373,mumrah,2024-10-04T17:47:01Z,"this could break some existing kafka installations. if users are extracting in place or copying previous config files to a new installation directory, they will be expecting the log4j.properties to still work.",0,0.9873620271682739
1788846414,17373,frankvicky,2024-10-06T03:28:54Z,hi i add this to fix the warning during build: [code block],0,0.9842891097068787
1810596051,17373,showuon,2024-10-22T12:04:05Z,"we should remove this file, right?",0,0.9849329590797424
1810598884,17373,showuon,2024-10-22T12:06:12Z,"is this right? it's still possible it runs with log4j 1.x, right?",0,0.9867877960205078
1810600249,17373,showuon,2024-10-22T12:07:15Z,we still need reload4j here?,0,0.9887696504592896
1810616327,17373,showuon,2024-10-22T12:18:04Z,"in[a link], we also set the pattern to connectappender, right?",0,0.9883151054382324
1810618105,17373,showuon,2024-10-22T12:19:08Z,should we remove them?,0,0.9720273613929749
1810618615,17373,showuon,2024-10-22T12:19:30Z,should we remove them?,0,0.9720273613929749
1810625227,17373,showuon,2024-10-22T12:23:44Z,i don't understand the changes in the file. we move a log4j.properties in `connect/runtime` to `connect/mirror`? why?,0,0.8328839540481567
1810705740,17373,frankvicky,2024-10-22T13:13:55Z,"yes, there are still some modules (like `tools`) that directly depend on `reload4j`, which we can't remove at the moment. removing it would cause build errors. [code block]",0,0.9859877228736877
1810711392,17373,frankvicky,2024-10-22T13:17:09Z,"yes, we should. however, i'm thinking that removing the zk configurations might be better handled as a follow-up pr, since this one is already quite large. wdyt ?",0,0.95624178647995
1810722170,17373,frankvicky,2024-10-22T13:23:19Z,hmm... i think it's just an issue with github detection. i modified these two files in place. :thinking_face:,0,0.8288927674293518
1810744889,17373,frankvicky,2024-10-22T13:35:57Z,"yes, i think the `connectappender` setting in log4j1 is equivalent to the following, if i haven't misunderstood: [a link]",0,0.9853562712669373
1811786044,17373,showuon,2024-10-23T03:53:04Z,"it looks like it's our test depends on reload4j. in this case, we should try to fix it.",0,0.9850623607635498
1811787630,17373,frankvicky,2024-10-23T03:54:44Z,i see. i will try to deal with this issue.,0,0.8490005731582642
1811789962,17373,showuon,2024-10-23T03:57:47Z,"oh, i missed that! thanks.",1,0.9896270036697388
1811959867,17373,showuon,2024-10-23T06:31:13Z,"i'm not familiar with log4j2, so i don't understand the empty name here. why can't we use `getrootlogger` as above?",0,0.6906368732452393
1811961770,17373,showuon,2024-10-23T06:33:03Z,is this behavior change expected?,0,0.9812198877334595
1811968367,17373,showuon,2024-10-23T06:39:10Z,this is for which method?,0,0.9813779592514038
1811977005,17373,showuon,2024-10-23T06:45:28Z,we don't need `resolvelevel` now because log4j2 will do that for us? do we have test for it?,0,0.9864165782928467
1811982931,17373,showuon,2024-10-23T06:48:50Z,this change is for zk removal?,0,0.9876169562339783
1811990279,17373,showuon,2024-10-23T06:53:19Z,why can't we change the root log level now?,0,0.9680823683738708
1811993482,17373,showuon,2024-10-23T06:54:51Z,"ok, this is replaced with `reconfigure()`, right?",0,0.987101674079895
1811996534,17373,showuon,2024-10-23T06:56:07Z,"i think our goal in this pr, is to remove the reload4j above. thanks for looking into how we can completely remove it!",1,0.9827457666397095
1812025899,17373,showuon,2024-10-23T07:12:23Z,"i'm not familiar with log4j2, just want to confirm will it confuse the setting?",0,0.8635069131851196
1812137033,17373,frankvicky,2024-10-23T08:08:49Z,"yes, exactly. `reconfigure()` provides a more convenient way to hot reload log4j configurations. :grinning_cat:",-1,0.674084484577179
1812147748,17373,frankvicky,2024-10-23T08:14:04Z,"yes, the name `r` might be confusing. my intention was to purely transform from log4j1 to log4j2 without making any further unnecessary changes. however, it can definitely be renamed if needed.",0,0.9406647086143494
1812168338,17373,frankvicky,2024-10-23T08:23:53Z,"yes, i intentionally made this change to align with the removal of zk tests.",0,0.9773787260055542
1812209524,17373,frankvicky,2024-10-23T08:40:17Z,"we could, but to make the test more precise, we should avoid having the test depend on the root logger. we are now focusing on changing the log level of the `kafka` logger, which acts as the top-level logger for the `kafka.server.controllerserver`, `kafka.log.logcleaner`, and `kafka.server.replicamanager` components. this change ensures that we can still control kafka's logging behavior without relying on the root logger.",0,0.9810116291046143
1812297584,17373,frankvicky,2024-10-23T09:12:49Z,"in this test case, we focus on setting the level for the root logger. imho, it would be ideal if we could have a ""clean"" configuration to conduct this test case. if i understand correctly, we can create a new configuration programmatically at the beginning in this way to ensure that the test case is not affected by existing log4j configurations.",0,0.9755592942237854
1812309503,17373,frankvicky,2024-10-23T09:17:09Z,"yes. in log4j2, the `getlevel` method returns either the explicitly set level or the effective level. we can roughly think of it as a combination of two methods (`getlevel` and `geteffectivelevel`) from log4j1.",0,0.9871079325675964
1812370163,17373,showuon,2024-10-23T09:49:10Z,i see. but i still want to see if we can change the root logger to make sure we didn't break existing behavior. maybe we can create one more test for it?,0,0.9697883129119873
1812371827,17373,frankvicky,2024-10-23T09:50:14Z,"yes, log4j2 will do it for us. in log4j2, when we retrieve a logger instance from the `loggercontext`, the `getlevel` method returns the effective log level, which includes any levels inherited from parent loggers up to the root logger. this means that if a logger doesn’t have an explicit level set, `getlevel` will provide the inherited level, so we don’t need to manually traverse the logger hierarchy as we did in the `resolvelevel` method.",0,0.9861465096473694
1812372018,17373,showuon,2024-10-23T09:50:22Z,"ok, could we add some comments for these changes?",0,0.9868567585945129
1812372375,17373,frankvicky,2024-10-23T09:50:36Z,"sadly, we don't have a test for it",-1,0.972892165184021
1812372794,17373,frankvicky,2024-10-23T09:50:55Z,"oops, i will do some clean-up",-1,0.7259085774421692
1812374332,17373,frankvicky,2024-10-23T09:51:54Z,"sure, i will do that.",0,0.9164295792579651
1812375243,17373,frankvicky,2024-10-23T09:52:28Z,sure. :grinning_cat:,1,0.91309654712677
1812406378,17373,showuon,2024-10-23T10:10:40Z,let's add some tests for this class. thanks.,1,0.9425726532936096
1812696648,17373,frankvicky,2024-10-23T12:54:26Z,"ah, i have just found that we already have test cases for it. [a link]",0,0.9793901443481445
1813031963,17373,frankvicky,2024-10-23T15:24:28Z,"[a link] since `log4j-appender` is depending on `clients`, we will need to delete `log4j-appender` module if we want to entirely get rid of `log4j`. [a link] cc.",0,0.9901152849197388
1813405127,17373,mimaison,2024-10-23T19:17:30Z,the link also needs updating (as well as the line number),0,0.9869391918182373
1813427142,17373,mimaison,2024-10-23T19:36:09Z,"i'm not convinced we need that dependency. also it seems to complain about an annotation so at least we should not need it at runtime, so we should not include it in our distribution package. currently it's included in the artifact generated by `releasetargz`.",0,0.8128158450126648
1813429859,17373,mimaison,2024-10-23T19:38:40Z,let's keep the newline,0,0.9822055697441101
1813430705,17373,mimaison,2024-10-23T19:39:25Z,we probably don't need this zookeeper logger,0,0.9709967374801636
1814229869,17373,frankvicky,2024-10-24T04:31:35Z,"fair enough, i will try to solve this one.",0,0.9167504906654358
1814232672,17373,frankvicky,2024-10-24T04:36:33Z,"yes, we need to clean up the zk-related configurations. i plan to split this into a separate jira and pr, as previously discussed with . wdyt ? [a link]",0,0.9819918274879456
1814233350,17373,frankvicky,2024-10-24T04:37:34Z,i have opened a pr for it #17588,0,0.9601736664772034
1814236919,17373,frankvicky,2024-10-24T04:43:17Z,"since this line is directly linked to a file in the `trunk` branch, a better solution might be to modify the document after this pr gets merged. i can file a jira to track this modification if you agree. wdyt?",0,0.9862962961196899
1819719894,17373,ppkarwasz,2024-10-28T20:35:35Z,"the bnd annotations are intentionally in the `provided` maven scope of all log4j artifacts, so that these annotations with `class` retention do not end up in the runtime classpath. you can do the same and add them as `compileonly` in gradle. the compiler warnings should disappear once [a link] is fixed. untile then we will remove the outdated ones (see apache/logging-log4j2#3133) in the next log4j release, which should remove the warning on `level`.",0,0.9884284138679504
1819769400,17373,ppkarwasz,2024-10-28T21:12:45Z,the switch from the legacy to the new configuration format can be based on the presence of specific files: [code block],0,0.988526463508606
1819834263,17373,ppkarwasz,2024-10-28T22:07:16Z,"have you considered switching to a structured configuration format like xml or yaml? the properties configuration format is not the default one and is not even one of the original ones (it appeared in version 2.4). it has [a link] to make it easier to read, but also harder to understand. the xml format does not require additional dependencies. yaml only requires [a link] that will only take an additional 400 kib in kafka's distribution. in yaml the configuration file would look like: [code block]",0,0.9787508249282837
1820021534,17373,frankvicky,2024-10-29T03:08:13Z,"hi , thanks for your feedback! :grinning_face_with_smiling_eyes: as you mentioned, the `.properties` file format indeed has a drawback of understand. i actually struggled when trying to transform the `.properties` file from log4j1 to log4j2 -- it was really painful to understand its meaning and transform them at same time. the yml format looks nice and is more readable, but changing the configuration format might require further discussion, especially since it would introduce additional dependencies to the project. i will file a jira to initiate a discussion on this.",1,0.9063164591789246
1820025144,17373,frankvicky,2024-10-29T03:14:32Z,[a link] c.c.,0,0.9871454238891602
1820029662,17373,frankvicky,2024-10-29T03:22:31Z,thanks for the information. i have already changed its scope to compile time. ptal :grinning_face_with_smiling_eyes:,1,0.981819748878479
1820546264,17373,mimaison,2024-10-29T10:36:02Z,"as long as we still support the old properties format, we can consider switching to a new format if users provide a log4j2 configuration file. i think it's worth starting a thread on the dev list to explain our options and gather some feedback.",0,0.9494220614433289
1820760649,17373,ppkarwasz,2024-10-29T13:06:21Z,", to be precise, users will **always** be able to use the configuration format of their choice, regardless of the format adopted by kafka. the choice of the configuration file format mostly concerns the **default** configuration files shipped in the `*.tar.gz` archive. if kafka ships with a `log4j2.properties` file, users will feel forced to use that one and that is imho a terrible format to work with. i have opened a [a link] to start a discussion about the subject. **ps**: there is currently a primitive [a link] that allows users to automatically convert a `log4j.properties` files into a `log4j2.xml` file. i am currently working on extending the list of formats that can be automatically converted (cf. [a link] but i will probably not have time to support the quirky `log4j2.properties` format.",-1,0.9888162612915039
1820849781,17373,mimaison,2024-10-29T13:52:44Z,"i understand what you mean. my point was that some users may have built custom `log4j.properties` files and run clusters with those, and we want that to continue working. for the new log4j2 files, then yes it makes sense to evaluate the different formats. thanks for opening a thread, it's very useful to get input from an apache logging pmc member to help us make decisions.",1,0.9616014361381531
1820856701,17373,frankvicky,2024-10-29T13:55:50Z,i have file a jira for it. [a link],0,0.9876236915588379
1824026165,17373,ppkarwasz,2024-10-31T07:51:37Z,"this looks pretty much as a maintenance headache for the apache kafka team. what will happen if the user switches logging implementation (at least 3 logging implementations are supported by the log4j api, see [a link]? it looks to me that you only use this for jmx. if that is the case, log4j core provides an [a link]. you just need to enable it, since jmx is a potential source of security problems and is disabled by default. if you need to get and set the levels for other reasons, please open a thread on `dev`. users like to change logger levels programmatically so often, that we'd better offer an implementation independent api for that.",-1,0.9138157367706299
1824185851,17373,mimaison,2024-10-31T10:00:05Z,this is used by kafka connect. we have a rest api that allows changing the log level of all instances in a kafka connect cluster. see [a link] for the details.,0,0.9842479228973389
1824901568,17373,ppkarwasz,2024-10-31T17:41:09Z,"we can probably reach a consensus in the logging pmc to release a new log4j configuration api, that you can use to abstract from the internals of the logging implementation (see [a link]. what is the planned release date for kafka 4.x? if you wait until the end of the year, this class might not be necessary.",0,0.9857403635978699
1825368063,17373,frankvicky,2024-11-01T02:42:16Z,"hi currently, ak 4.0 release is scheduled at january 29th 2025. for further details, you can refer to the release plan: [a link]",0,0.9747860431671143
1832983990,17373,ppkarwasz,2024-11-07T16:26:28Z,"[code block] by default log events are mutable and bound to one thread. they are cleared as soon as the logging call exits. there is a [a link] that you can store in a [a link] on the test classpath, but it is easier to just take an immutable snapshot. you can also replace `logcaptureappender` with [a link] from the [a link]. you can set it up with a config like: ```xml",0,0.9872546792030334
1833659727,17373,frankvicky,2024-11-08T03:51:30Z,"very appreciate! i have applied it and tested it locally; it works like a charm. as for replacing `logcaptureappender`, i think it's a great idea. imho, leveraging an existing tool is better than building our own. i will file a jira to initiate a discussion on this.",1,0.9927113056182861
1843386874,17373,showuon,2024-11-15T08:39:46Z,nit: i thought we'll honor log4j2.properties when both log4j2.properties and log4j.properties exist. no?,0,0.970996618270874
1843393551,17373,frankvicky,2024-11-15T08:45:31Z,"make sense. yes, we can change the order of the if-case to achieve that. i will update it in a follow-up pr.",0,0.9727042317390442
1843491362,17373,ppkarwasz,2024-11-15T09:44:53Z,"i think that `log4j.properties` should have a higher priority than `log4j2.properties`: - fresh installations of kafka 4.x will only have a `log4j2.properties` file. - if we find a `log4j.properties` file, it means that it is either an upgraded installation of kafka or the user copied their customized configuration.",0,0.9848288893699646
1843502542,17373,showuon,2024-11-15T09:51:16Z,"hmm... it makes sense. already, let's keep the log4j.properties as the highest priority. thanks.",1,0.9722430109977722
1843597095,17373,mimaison,2024-11-15T11:01:29Z,why do you want to do it in a separate pr? if we merge as is we instruct users to go check `clients/src/test/resources/log4j2.properties` but instead link to another file. if we update the comment we need to update the link.,0,0.9874711632728577
1843599782,17373,mimaison,2024-11-15T11:04:00Z,why do we recommend creating an xml file? should we point to the migration guide and to the log4j2 example file kafka will have under `config`,0,0.9879887104034424
1843600763,17373,mimaison,2024-11-15T11:05:00Z,same in the other scripts,0,0.9863685965538025
1843603382,17373,mimaison,2024-11-15T11:07:32Z,would `connectconfig` be a better name?,0,0.9854804873466492
1843606711,17373,mimaison,2024-11-15T11:10:35Z,we since removed zookeeper from the existing log4j properties files in trunk ([a link] so let's not re-add zookeeper stuff to remove it again later.,0,0.9877108931541443
1843610478,17373,mimaison,2024-11-15T11:14:24Z,let's keep the newline,0,0.9822055697441101
1843613244,17373,mimaison,2024-11-15T11:17:00Z,we can remove this new line to make it clearer the comment applies to both `org.apache.kafka.consumer` and `org.apache.kafka.coordinator.group`,0,0.986668586730957
1843628839,17373,mimaison,2024-11-15T11:26:47Z,why are we adding this method? this looks like a rebase issue.,0,0.9030519127845764
1843629078,17373,mimaison,2024-11-15T11:27:02Z,let's keep the new line.,0,0.9805101156234741
1843630758,17373,mimaison,2024-11-15T11:28:36Z,is this file still used?,0,0.985317051410675
1843631728,17373,mimaison,2024-11-15T11:29:38Z,can we import `logmanager`?,0,0.9895999431610107
1843633651,17373,mimaison,2024-11-15T11:31:29Z,nit: i know dependencies are not fully ordered but can we insert it roughly where it should be in the list instead of appending at the end.,0,0.9874041080474854
1843640613,17373,mimaison,2024-11-15T11:38:23Z,let's keep the new line. same in a few other files,0,0.9860425591468811
1843652254,17373,mimaison,2024-11-15T11:50:16Z,do we really need this as `implementation`? this is make it part of our release artifact.,0,0.9882692098617554
1843962004,17373,mimaison,2024-11-15T15:02:54Z,"this effectively changes the behavior of the `/admin/loggers` endpoint of the connect rest api. the endpoints accept the logger name in the path `/admin/loggers/{name}`. if the root logger is the empty string, it's not possible to query it anymore. i wonder if we should still expose the root logger as `root` (i assume it's possible to rename it somewhere here or in `loggingresource`). cc wdyt",0,0.9761579036712646
1843981241,17373,frankvicky,2024-11-15T15:14:27Z,i will see if we could avoid it be included in release artifact,0,0.9839434623718262
1844010558,17373,frankvicky,2024-11-15T15:24:06Z,"yes, it looks have a module name prefix is a little bit silly.",-1,0.9439388513565063
1844089662,17373,frankvicky,2024-11-15T15:51:09Z,make sense. i will apply it in next commit,0,0.9651574492454529
1844097109,17373,frankvicky,2024-11-15T15:56:43Z,yes... it seems that this method has been removed in `trunk`. i will remove it in next commit.,0,0.9856389164924622
1844099567,17373,frankvicky,2024-11-15T15:58:30Z,it seems that it's not in use based on ide hint. i will remove it and build to see if we could remove this one.,0,0.985366940498352
1845315012,17373,dongjinleekr,2024-11-17T07:20:30Z,"**we should retain the root logger's name as `root`, against log4j2's naming change.** here is the comment from [a link]: to maintain compatibility with kafka connect's rest api, we need to use `root` to indicate the root logger. since the log4j2 logger names are generally `{package}.{class}` form, defining a `root` named logger is almost not reasonable. so, we don't need to be concerned about it. long time no see :smiley: since it is not mentioned in the [a link], so i will add a subsection explaining this design decision. i got some vacation this week! :smiling_face_with_halo:",0,0.7454783320426941
1845315796,17373,frankvicky,2024-11-17T07:24:38Z,very appreciate your explanation. i will modify it in the next commit. :grinning_cat:,1,0.9894925355911255
1846332278,17373,mimaison,2024-11-18T10:31:56Z,should we remove connect-log4j.properties?,0,0.9886699914932251
1846332506,17373,mimaison,2024-11-18T10:32:07Z,should we remove log4j.properties?,0,0.987781286239624
1846355549,17373,frankvicky,2024-11-18T10:43:48Z,i think it's fine now since our script has sufficient protection. it should work well when upgrading from the old version. i will delete these two configurations in the next commit.,0,0.941462516784668
1846417125,17373,mimaison,2024-11-18T11:20:49Z,yes because otherwise we default to the log4j file so you get the warning everytime you run a command: [code block],0,0.9832514524459839
1846550136,17373,chia7712,2024-11-18T13:04:11Z,we don't need to recreate collection - [code block],0,0.986968994140625
1846556605,17373,chia7712,2024-11-18T13:09:17Z,"why don't we keep the `root` compatibility here? after this pr, users can't set 'root=warn' to change the root level.",0,0.9864673018455505
1846632146,17373,chia7712,2024-11-18T13:55:54Z,we need to keep the null handle to avoid npe,0,0.9764395952224731
1847704612,17373,chia7712,2024-11-19T06:20:06Z,do they use the same reference? or we should use `!equals` instead of `!=`?,0,0.9812017679214478
1847704673,17373,chia7712,2024-11-19T06:20:11Z,ditto,0,0.8428916931152344
1847752728,17373,chia7712,2024-11-19T07:11:00Z,please fix the `connect.py` [a link] [a link],0,0.9886442422866821
1847767385,17373,chia7712,2024-11-19T07:24:24Z,`compileonly` is good enough i think as we don't use the annotation in runtime,0,0.9172952175140381
1847776149,17373,chia7712,2024-11-19T07:28:48Z,could you please remove this method also?,0,0.9861473441123962
1847864958,17373,chia7712,2024-11-19T08:12:33Z,`replicationquotastestrig` has similar code [a link] could we delete it in this pr too?,0,0.9893471002578735
1847870812,17373,chia7712,2024-11-19T08:17:09Z,do we really need `log4j1bridge2api`?,0,0.9892724752426147
1847872407,17373,chia7712,2024-11-19T08:18:21Z,please remove it from [a link] too,0,0.9861451387405396
1847873077,17373,chia7712,2024-11-19T08:18:50Z,ditto [a link],0,0.9577217102050781
1847874109,17373,chia7712,2024-11-19T08:19:37Z,please add it to `license-binary` file,0,0.9871877431869507
1847964777,17373,frankvicky,2024-11-19T09:21:34Z,"some apis rely on it, such as `propertyconfigurator`. however, since we are removing it, we might not need the log4j bridge anymore. i will test this locally.",0,0.9865149855613708
1848323271,17373,dongjinleekr,2024-11-19T13:03:22Z,"when i worked on this issue last, it was required to support the log4j 1.x configuration file.",0,0.9879885911941528
1848672753,17373,chia7712,2024-11-19T16:23:18Z,"in the e2e we could run kafak on different version, so we must check the version before applying the config file.",0,0.9881559610366821
1848672880,17373,chia7712,2024-11-19T16:23:22Z,ditto,0,0.8428916931152344
1848672960,17373,chia7712,2024-11-19T16:23:25Z,ditto,0,0.8428916931152344
1850373880,17373,chia7712,2024-11-20T14:02:53Z,"it seems connect e2e does not run different version for workers, so you can just change them to `connect_log4j2.yaml`. however, please change the `-dlog4j.configuration` to `-dlog4j2.configurationfile`",0,0.9860261678695679
1850375006,17373,chia7712,2024-11-20T14:03:41Z,please noted that the previous version should use `-dlog4j.configuration` and trunk version should use `-dlog4j2.configurationfile`,0,0.9869815707206726
1850378575,17373,chia7712,2024-11-20T14:05:59Z,please add `filepattern`,0,0.9877061247825623
1850514477,17373,ppkarwasz,2024-11-20T15:21:56Z,"since there is only one triggering policy, there is no need to wrap it in a [a link]. btw: there is a typo in the plugin name: it should be `policies`, instead of `polices`.",0,0.9885302186012268
1850545236,17373,frankvicky,2024-11-20T15:35:32Z,thanks for information :grinning_face_with_smiling_eyes:,1,0.9323287010192871
1850570634,17373,frankvicky,2024-11-20T15:50:47Z,it seems that tons of code needs to apply this change. i will prepare it asap.,0,0.9486435055732727
1860858017,17373,mimaison,2024-11-27T15:23:24Z,"with the current code, updating connect loggers does not work. for example, i get: [code block] we should not return an unmodifiablelist here. in the `loggers()` method above we call `add()` on the `list`. here is the stack trace: [code block]",0,0.9623936414718628
1864432648,17373,chia7712,2024-11-30T18:52:38Z,"`get_log4j_config_for_connect(node)` does not point to the ""full"" path, so all related services can't start up as it fails to find the log4j2 config. please use `os.path.join(self.persistent_root, get_log4j_config_for_connect(node))` instead",0,0.9863225221633911
1864432755,17373,chia7712,2024-11-30T18:53:07Z,"ditto. `get_log4j_config_for_connect(node)` is a file name rather than full path. please use `os.path.join(self.persistent_root, get_log4j_config_for_connect(node))` instead",0,0.8316213488578796
1864432782,17373,chia7712,2024-11-30T18:53:14Z,ditto,0,0.8428916931152344
1864435374,17373,chia7712,2024-11-30T19:03:51Z,i don't think those configs file are existent. please remove it,0,0.9663464426994324
1864435870,17373,chia7712,2024-11-30T19:06:10Z,"ditto. use `os.path.join(self.persistent_root, get_log4j_config(node))` instead",0,0.9786110520362854
1864435899,17373,chia7712,2024-11-30T19:06:25Z,"ditto. use `os.path.join(self.persistent_root, get_log4j_config(node))` instead",0,0.9786110520362854
1864456124,17373,chia7712,2024-11-30T19:42:15Z,why do we override the config path? it breaks all e2e since the custom log4j config can't be used.,0,0.9669772386550903
1864456149,17373,chia7712,2024-11-30T19:42:24Z,ditto,0,0.8428916931152344
1864456157,17373,chia7712,2024-11-30T19:42:27Z,ditto,0,0.8428916931152344
1864457267,17373,chia7712,2024-11-30T19:46:59Z,"i’m not sure why we override the `kafka_log4j_opts` here. we typically allow users to define custom `kafka_log4j_opts`. moreover, overriding `kafka_log4j_opts` can break many end-to-end tests, as they often create log4j configurations dynamically and pass them through `kafka_log4j_opts` noted that we do not require users to strictly use the path `$base_dir/../config/log4j2.xml`.",0,0.9649937748908997
1864898855,17373,chia7712,2024-12-01T13:45:14Z,please update it as well. the path is incorrect,0,0.9357463121414185
1893936536,17373,ijuma,2024-12-20T13:23:56Z,why did we do this in many files instead of kafka-run-class?,0,0.9555948376655579
1893938757,17373,ijuma,2024-12-20T13:25:55Z,how come these are `implementation` while `slf4jlog4j` is `testimplementation`?,0,0.9890393018722534
1893939705,17373,ijuma,2024-12-20T13:26:48Z,why is this needed?,0,0.9603567719459534
1893947193,17373,ijuma,2024-12-20T13:34:14Z,"two questions: 1. have we tested that this log configuration results in the same output as the previous one? in particular, we should avoid anything that requires collecting a stacktrace to log (we made sure of that for the previous configuration). 2. have we benchmarked the system to make sure there aren't any regressions due to the new logging library? i saw a jira/pr saying that log4j2 has a particularly costly `getlogger` implementation.",0,0.9742213487625122
1894092841,17373,chia7712,2024-12-20T15:45:05Z,[a link] needs it to configure the log level at runtime,0,0.9885845184326172
1894121803,17373,frankvicky,2024-12-20T16:12:03Z,"i added `spotbugs` to address the compiler warnings. while we could suppress these warnings using `-xlint:all,-classfile`, i prefer not to relax compiler checks. ideally, we should avoid depending on core-specific methods altogether. however, that would require thorough pass to our code. i suggest we create a separate jira ticket to track this architectural improvement as a future enhancement. for further details: [a link]",0,0.971670925617218
1894124425,17373,chia7712,2024-12-20T16:14:07Z,"`jacksondatabindyaml` is required to parse yaml config - see [a link] however, it seems we can do a bit cleanup for `jacksondatabindyaml` as not all modules need to add explicit reference",0,0.9859412312507629
1894164970,17373,chia7712,2024-12-20T16:50:29Z,"i will use log4j-2 transform tool to check the config later ([a link] could you please share the commit to me? i trace the history ([a link] and fails to see the fix about ""avoid anything that requires collecting a stacktrace"". according to official docs ([a link] the performance of ""logging"" has no obvious regression. it seems the story is about `getlogger` - [a link] and [a link] - there is already a pr to fix it #17896 - we can discuss the improvement on it.",0,0.9762998223304749
1894238151,17373,ppkarwasz,2024-12-20T18:05:23Z,"at apache logging we had several other issue reports regarding our usage of annotations in the `provided` scope (see [a link] for example). regarding the [a link] that causes this particular problem: - imho the compiler should not issue any warnings if it is missing, since the annotation has a retention of `class` and is totally invisible at runtime. i submitted [a link] to change the compiler's behavior. - log4j core could theoretically move spotbugs annotations from the `provided` to the `compile` scope, but this could cause legal problems, since the annotation library is licensed under lgpl and this can not be changed (see [a link] this is one of the reasons we keep the library in the `provided` scope, so it does not propagate to consumers.",0,0.9324784874916077
1894553541,17373,ijuma,2024-12-21T04:35:02Z,"yeah, the licensing issue is the reason i wanted to avoid using this library at all. can we use a different library for annotations, one that is apache licensed?",0,0.9233781695365906
1894553658,17373,ijuma,2024-12-21T04:36:54Z,"we should perhaps bite the bullet and just make the slf4jlog4j choice for the server (i.e. include it as `implementation`). after all, unless you choose this, some functionality won't work.",0,0.968531608581543
1898304621,17373,ppkarwasz,2024-12-27T06:48:34Z,"imho the `kafka_ ` artifact should not have these dependencies, these dependencies should be added **only** to the binary kafka distribution. otherwise kafka will leak the log4j core dependencies to its consumers, similarly to what was happening with zookeeper (see [a link]. to add dependencies only to the binary distribution, you could use something similar to apache/eventmesh#4719, i.e. a separate `distonly` gradle configuration. `log4jcontroller` can be rewritten to use log4j core if present or a no-op implementation otherwise, so the log4j core can be declared as an [a link]. **note**: i am working on a `org.apache.logging:logging-admin` artifact (see [a link] that would provide the same functionality as `log4jcontroller`, but in a logging implementation independent way. unfortunately i have a long todo list before i can publish it, so probably it won't be ready for kafka 4.",0,0.985575795173645
1898313661,17373,chia7712,2024-12-27T07:06:32Z,"`log4jcontroller` is used exclusively by the server, so exposing its dependencies should be acceptable.",0,0.9885603785514832
1898356316,17373,ppkarwasz,2024-12-27T08:27:49Z,"in kafka 3.9.0, the dependency on `ch.qos.reload4j:reload4j` is declared `compileonly`: [a link] the dependency is added to the binary distribution in a separate task: [a link] these dependencies should probably be handled in a similar way.",0,0.9879221320152283
1898357031,17373,ppkarwasz,2024-12-27T08:29:30Z,"**note**: no modern library uses log4j 1 in code (they use jcl, slf4j or log4j api), so my guess is that `libs.log4j1bridge2api` could be dropped entirely.",0,0.9692895412445068
1898365578,17373,chia7712,2024-12-27T08:44:31Z,"yes, we can declare them as compileonly and then add them to the distribution. however, the flexibility of replacing the slf4j provider at runtime may break the functionality of log4jcontroller (similar to [a link]. kip-1064 is attempting to use slf4j2's system variable to choose the provider more effectively. pardon me, in the #18290 we decide to allow users to use log4j.properties - so we still need `log4j-1.2-api`, right?",0,0.8694934844970703
1898478552,17373,ppkarwasz,2024-12-27T12:16:27Z,"as far as i can tell, this is the way `log4jcontroller` worked in kafka 3.x: if the optional `ch.qos.reload4j` dependency was absent, the class didn't work. sorry, my mistake.",-1,0.9863515496253967
1898534270,17373,chia7712,2024-12-27T14:12:27Z,"yes, you're right. perhaps we should consider offering similar functionality for other popular slf4j providers, such as logback and jul. wdyt?",0,0.9749071598052979
1898950768,17373,ijuma,2024-12-28T16:39:13Z,"it is true that we previously tried hard to avoid making the logging choice for the maven artifact while making it for the distributed binaries. however, this is brittle and only worked partially. when i tried to fix it in #12148, it caused problems and it was partially reverted (#16260, #16559). also, it's actually bad to silently not support the dynamic logging functionality for the broker (this is _incredibly_ useful in production). so, i think the simplest thing is to make the logging choice explicit for the server modules (the rare user who doesn't want that can still override it with exclusions via their build file) and leave it up to the applications for the client modules. in the future, if there is a way to address these issues, we can change it again. there are two promising and complementary paths: 1. your logging admin library. 2. slf4j2 makes it possible to choose the logging library dynamically instead of via classpath tricks.",-1,0.9622823596000671
1898983229,17373,ppkarwasz,2024-12-28T20:04:38Z,"i pushed the draft to apache logging ([a link] and i'll start to actively work on it. probably you can expect a release by end of january/february. in the meantime i can make a pr for kafka, so that `log4jcontroller` fails softly if log4j core is not present. note that choosing the slf4j implementation does not really tell you which logging implementation is being used: except logback, all the other slf4j implementation are bridges between logging apis. if you use `slf4j-jdk14` you don't know which jul implementation is being used and if you use `log4j-slf4j2-impl` you don't know which log4j api implementation is being used.",0,0.9707713723182678
1899049780,17373,chia7712,2024-12-29T02:16:54Z,"yes, it would be great to display accurate error messages!",1,0.8955168128013611
1166622209,13561,divijvaidya,2023-04-14T09:56:51Z,"should this operation be performed in a separate thread pool which can have a defined quota? (similar to how we perform cleaning for local log using separate cleaner/background threads). i am concerned that this may impact the rate of copy to remote if amount of cleaning is large. also, it's perhaps better to have different scaling characteristics for cleaning from remote vs. copying. copying maybe considered urgent since slowness in copying can potentially fill up disk whereas cleaning from remote may be a lower priority activity.",-1,0.614306628704071
1166661016,13561,divijvaidya,2023-04-14T10:28:00Z,"the current logic may cause deletion of more data than anticipated. this is because it is possible to have remote segments satisfying this condition which are not part of the current leadership epoch chain. calculation of totalsizeearliertolocallogstartoffset may include these segments as well and hence, the calculation of totalsize will include local segments + all remote segments (< local log start offset). the calculated totalsize will be actually larger than the actual total size (where actual total size = size of remote + local log for the active epoch chain). this will lead to higher value of remainingbreachedsize than actual and hence, more data gets deleted than necessary. is this making sense? else i can provide an example to explain it better.",0,0.9795050024986267
1166767890,13561,divijvaidya,2023-04-14T12:20:05Z,"we don't need to calculate this for time based retention. right? if yes, can we refactor the code here so that we perform size calculation (since it requires a full scan over all log segments) only when it's required i.e. for size based retention.",0,0.9847650527954102
1166839800,13561,divijvaidya,2023-04-14T13:30:56Z,we are only interested in segments in state copy_segment_finished or delete_segment_started here. right? (delete_segment_started to clean up any stragglers) can we make this more explicit by filtering on them?,0,0.9859505295753479
1166850232,13561,divijvaidya,2023-04-14T13:40:18Z,could we check for `if (iscancelled() || !isleader())` here again please to short circuit this expensive loop during shutdown.,0,0.9835028052330017
1166854317,13561,divijvaidya,2023-04-14T13:44:11Z,"`iscancelled() || !isleader()` also, please add a log which can help operator understand that this was actually cancelled.",0,0.9801920652389526
1166856223,13561,divijvaidya,2023-04-14T13:45:51Z,please guard this update with `isleader()`,0,0.9864663481712341
1166868212,13561,divijvaidya,2023-04-14T13:56:20Z,"unreferenced segments are not only the ones which have a lower epoch that earliest known epoch, they could also be ones which have an epoch that is not part of active epoch chain. how are we handling that?",0,0.9774342775344849
1166876777,13561,divijvaidya,2023-04-14T14:03:57Z,"i would appreciate your response on [a link] where we discussed that even with caching mechanism, warm up of the cache is going to slow down the copying. i agree that this can be discussed outside the scope of this pr but adding the above thread as fyi.",1,0.5962871313095093
1166892667,13561,divijvaidya,2023-04-14T14:13:29Z,do we need this at a warn level?,0,0.9856637716293335
1166896440,13561,divijvaidya,2023-04-14T14:17:00Z,i would suggest to have address local retention in a separate pr. we can limit this pr to handling remote log retention only.,0,0.9893564581871033
1167074461,13561,Hangleton,2023-04-14T16:53:04Z,"hmm, i don't think it is enough to evict the data for epochs < than the current leader's smallest epoch. with unclean leader election, it is possible to have divergence in-between a log prefix and suffix shared by two replicas.",0,0.907677948474884
1167086128,13561,Hangleton,2023-04-14T17:01:09Z,"hmm, it seems we are iterating over all remote segment metadata every time the expiration task is executed. this could become costly if the rlmm implementation does not cache the said metadata. that could be an explicit implementation constraint for plugin providers. maybe we could also add a small layer a memoization here to avoid traversing the log metadata every time.",0,0.9749230146408081
1180118575,13561,showuon,2023-04-28T08:50:56Z,"good suggestion. but we don't include this part in the original kip, we need another kip to improve it.",1,0.9535068273544312
1180121259,13561,showuon,2023-04-28T08:53:12Z,"we might need to add logs here to describe why we need to update highest offset in remote storage for followers. i think that's for fetch from follower replica feature, right?",0,0.9871153831481934
1180123353,13561,showuon,2023-04-28T08:55:09Z,nit: assume that segments contain size >= 0,0,0.9865727424621582
1180137735,13561,showuon,2023-04-28T09:06:15Z,i agree this could be costly if the rlmm implementation doesn't cache the metadata. but i don't think there's an implementation constraint for plugin providers. they can always cache them in the plugin. i'm thinking it should be enough if we add something about it in the rlmm#listremotelogsegments javadoc.,0,0.956105649471283
1180254846,13561,divijvaidya,2023-04-28T10:41:45Z,"that is fair. as i mentioned in the [a link], i am fine (and would actually prefer) with creating jiras and tackling the perf related comments outside this pr. with this comment, i wanted to make sure we are aware and are tracking things that need fixing in this code.",0,0.6322001218795776
1181520975,13561,satishd,2023-05-01T11:24:07Z,"this is different from local log deletion. it requires the deletion of segments from local storage which need to really delete the files. but incase of remote storages, it does not wait for the data to be deleted but it marks the file or object for deletion in their respective metadata stores. respective garbage collectors in those storages will take care of deleting the data asynchronously. there is no perf impact for these delete calls as they take a much shorter time than copying segments. it is very unlikely that copying segments get affected because of the deletion of segments. deletion checks are happening in every iteration so there will not be many segments that need to be deleted. anyways, we can discuss this separately in a separate jira. on another note, all this logic will go to unifiedlog in future.",0,0.9639438986778259
1181526976,13561,satishd,2023-05-01T11:41:52Z,"log.retention.<> configs indicate the total amount of log segments that can be stored in remote storage. so, it is not just about the segments only related to the current leader epoch lineage. we need to be careful of removing any unreferenced segments and also should not have any segment leaks in the remote storage incase of unclean leader elections. so, it cleans up any unreferenced segments beyond the earliest leader epoch that are also available for retention checks.",0,0.9823195338249207
1181527119,13561,satishd,2023-05-01T11:42:21Z,we do not need any specific check here as we want to clean up any segment that is not yet deleted including copy_segment_started,0,0.985920250415802
1181528820,13561,satishd,2023-05-01T11:46:37Z,unreferenced segments within the current leader epoch chain will eventually move earlier to the earliest epoch of the current leader epoch chain after a few retention checks. that will take care of those kinds of segments.,0,0.9849026799201965
1181529149,13561,satishd,2023-05-01T11:47:19Z,"sure, let us discuss this out side of this pr.",0,0.9643169045448303
1181532348,13561,satishd,2023-05-01T11:56:03Z,unreferenced segments within the current leader epoch chain will eventually move earlier to the earliest epoch of the current leader epoch chain after a few retention checks. that will take care of those kinds of segments.,0,0.9849026799201965
1181545427,13561,showuon,2023-05-01T12:31:09Z,"it's confusing we update `_locallogstartoffset` twice with different value. i think the one in l982 should be removed, right?",-1,0.5741724371910095
1182338603,13561,Hangleton,2023-05-02T09:53:16Z,"hmm, i am not sure this is the right thing to do, because including segments which are not part of a log yields a size which is not truly that of the log. it is possible to design scenarios with a log chronology which allows for premature deletion of data under size-based retention. while i understand that deleting unreferenced segments is consistent with the local log use case, where some data can be lost too, a key difference here between this approach and the current retention semantics applied for local logs is that in the latter case, all segments belong to the current log when the log size is calculated, so that the size-based retention policy always apply to the current log. eviction of unreferenced segments/data in the local case happens via truncation separately from the enforcement of retention policies. but here, both are retention-based and truncation-driven eviction are _de facto_ combined. what are the benefits of diverging from these semantics with tiered segments?",0,0.8445382118225098
1197648143,13561,Hangleton,2023-05-18T10:16:16Z,"i see, yes that's right those segments will eventually fall out of the range of active leader epochs. that should be fine, as long as users know there is no specific enforcement on the time those unreferenced segments will be cleaned up.",0,0.9827191829681396
1203191600,13561,junrao,2023-05-24T00:10:33Z,unnecessary semicolon. ditto in kafkaserver.,0,0.8911691308021545
1203192234,13561,junrao,2023-05-24T00:11:04Z,missing javadoc for new param.,0,0.7798321843147278
1203194554,13561,junrao,2023-05-24T00:12:15Z,should we exit the loop the first time a remote segment offset passes locallogstartoffset?,0,0.9879381060600281
1203195682,13561,junrao,2023-05-24T00:12:59Z,what about overlapping segments between remote and local? do we double count them?,0,0.98312908411026
1203196737,13561,junrao,2023-05-24T00:13:53Z,are we iterating the same remote segment multiple times since a segment could have multiple epochs?,0,0.9836249351501465
1203197683,13561,junrao,2023-05-24T00:14:43Z,"loggering uses $ notation, which is for scala.",0,0.9884025454521179
1203198445,13561,junrao,2023-05-24T00:15:23Z,"hmm, not sure that i follow the comment.",-1,0.6172829866409302
1203200216,13561,junrao,2023-05-24T00:16:50Z,"hmm, logstartoffset could be larger than base offset of the first local segment. so, it seems that we can't just switch to the base offset of the first local segment if remote log is not enabled.",0,0.9860673546791077
1203200822,13561,junrao,2023-05-24T00:17:24Z,should we return here to actually ignore?,0,0.9317739605903625
1203201676,13561,junrao,2023-05-24T00:18:10Z,"yes, agreed. not sure why we need to update _locallogstartoffset here again.",0,0.9809365272521973
1203202960,13561,junrao,2023-05-24T00:19:13Z,"hmm, local retention needs to be bound by last tiered offset, right?",0,0.9857308268547058
1203204099,13561,junrao,2023-05-24T00:20:07Z,"retention time depends on remote storage being enabled, right? ditto in line 2284.",0,0.9818693995475769
1205425110,13561,showuon,2023-05-25T12:13:00Z,"debug(""update {} with remotelogstartoffset: {}"", topicpartition, remotelogstartoffset)",0,0.9892767667770386
1205437354,13561,showuon,2023-05-25T12:20:51Z,additional `$` sign: remote log segment [$]{} ...,0,0.989054799079895
1209013637,13561,showuon,2023-05-29T07:33:46Z,nit: less than,0,0.8902984857559204
1213100593,13561,satishd,2023-06-01T12:47:30Z,`listremotelogsegments(topicidpartition topicidpartition)` are not returned in any specific order.,0,0.9837468266487122
1213102668,13561,satishd,2023-06-01T12:49:15Z,"`totalsizeearliertolocallogstartoffset` computes only the log segments in remote storage beyond local-log-start-offset. the remaining local log segments size is computed separately. so, there will be no overlapping segments.",0,0.9878800511360168
1213107255,13561,satishd,2023-06-01T12:51:17Z,"no, it is taken care of. when we remove a remote log segment, it also updates that entry in rlmm in synchronous manner. so, rlmm store will remove the entry from respective epoch states.",0,0.9886808395385742
1213107956,13561,satishd,2023-06-01T12:51:51Z,updated the comment to make it more clear.,0,0.9804856777191162
1213112946,13561,satishd,2023-06-01T12:55:34Z,"we already set the locallogstartoffset as max of passed logstartoffset and the first segment's base offset. when remote log is not enabled, `logstartoffset` is set as `locallogstartoffset` as computed above.",0,0.9896686673164368
1213113458,13561,satishd,2023-06-01T12:56:00Z,this is addressed with the latest commits.,0,0.9851714968681335
1222183059,13561,junrao,2023-06-07T21:12:47Z,extra new line,0,0.9643937349319458
1222183119,13561,junrao,2023-06-07T21:12:51Z,extra new line,0,0.9643937349319458
1222183188,13561,junrao,2023-06-07T21:12:57Z,extra new line,0,0.9643937349319458
1222189063,13561,junrao,2023-06-07T21:20:34Z,"let's say there is a remote segment with startoffset 100 and endoffset 200. if the locallogstartoffset is 150, we exclude the remote segment. this means that we are undercounting the size, right?",0,0.9848001003265381
1222205974,13561,junrao,2023-06-07T21:43:25Z,"hmm, why do we need a separate retention based on leader epochs? is that not already covered by size/time/startoffset based retention?",0,0.9826777577400208
1222283938,13561,junrao,2023-06-07T23:42:27Z,this is already done in `updatelogstartoffset`. do we need to do it here again?,0,0.989355742931366
1222315217,13561,junrao,2023-06-08T00:38:00Z,we already log the completion of the load loading in logmanager. could we fold this there to avoid double logging?,0,0.9892727136611938
1223300322,13561,junrao,2023-06-08T16:35:58Z,"hmm, this logic doesn't look right. if a client calls `deleterecords`, we call `maybeincrementlogstartoffset` with onlylocallogstartoffsetupdate=false. so, we will go through this branch and update _locallogstartoffset. this will be incorrect if remote log is enabled.",0,0.9286080002784729
1223303905,13561,junrao,2023-06-08T16:39:51Z,is highestoffsetinremotestorage inclusive or exclusive? it would be useful to document that.,0,0.9865598678588867
1223312004,13561,junrao,2023-06-08T16:47:45Z,extra new line,0,0.9643937349319458
1224374293,13561,divijvaidya,2023-06-09T14:22:38Z,please add a debug log here (and other places where we are exiting this function) so that we know while debugging where did we exit the function from.,0,0.9882168173789978
1224420683,13561,divijvaidya,2023-06-09T14:57:29Z,please add an info log on why we exited the function prior to it's completion. it greatly helps debugging when we don't have to guess where the return point was.,0,0.9505364894866943
1226259513,13561,divijvaidya,2023-06-12T08:15:09Z,please add the following check. we don't want to construct an object for retentionsizedata if not required. [code block],0,0.9888366460800171
1226261499,13561,divijvaidya,2023-06-12T08:16:47Z,"please perform an argument validation here. if retentionsize < remainingbreachedsize, then illegalargumentexception. same for retentiontimedata",0,0.98903489112854
1226268535,13561,divijvaidya,2023-06-12T08:21:09Z,this comment has been addressed in the latest code,0,0.987403392791748
1226280821,13561,divijvaidya,2023-06-12T08:31:03Z,nit unnecessary else,0,0.9483489394187927
1226315828,13561,divijvaidya,2023-06-12T08:53:45Z,we need to restore the original value of remainingbreachedsize when remainingbreachedsize < 0? may i suggest re-writing this entire predicate here as: [code block] note that remainingbreachedsize is a member of the class and you don't need to do `retentionsizedata.get().remainingbreachedsize`. also the earlier `if (retentionsizedata.get().remainingbreachedsize > 0) {` is made redundant by the code i suggested.,0,0.987111508846283
1226433742,13561,divijvaidya,2023-06-12T10:25:03Z,nit s/log size after deletion/local log size after deletion asking so that the reader can disambiguate between log size (which is tiered + local) and local log size.,0,0.9893525838851929
1226467554,13561,divijvaidya,2023-06-12T10:50:38Z,should we ensure that we have acquired the partition `lock` first?,0,0.9856993556022644
1226471102,13561,divijvaidya,2023-06-12T10:53:59Z,this should probably be a error level log because we don't expect to call this method when remote storage is disabled. isn't that right?,0,0.9499388337135315
1226517527,13561,divijvaidya,2023-06-12T11:33:37Z,"we are assuming that the state of local log will remain same from this point to the time we use the information computed here (i.e. totalsizeearliertolocallogstartoffset ) to delete the segments. but that is not true since local retention threads are running concurrently and might have moved the locallogstartoffset by the time we use the `totalsizeearliertolocallogstartoffset` computed here. as an example: ### time instant: t1 locallso = 10 lso = 0 lse = 20 tieredeo = 15 in this case we will calculate `totalsizeearliertolocallogstartoffset` as the size from 0-10. ### time instant: t2 local log retention thread deletes some stuff and updates the locallso=14 ### time instant: t3 when we calculate `long totalsize = log.validlocallogsegmentssize() + totalsizeearliertolocallogstartoffset;` at `buildretentionsizedata`, validlocallogsegmentssize returns data from 14-20 and we say that the total size = totalsizeearliertolocallogstartoffset ( i.e. 0-10) + validlocallogsegmentssize (i.e. 14-20). this leads to data from 11-13 not being counted anywhere. this looks like a bug! we need to re-use the values stores at the beginning of the retention calculation otherwise other threads (local retention threads) may change the values behind the scenes. thoughts?",0,0.9554106593132019
1226536841,13561,divijvaidya,2023-06-12T11:50:51Z,"sorry, i am a bit confused here. earlier in the comment [a link] you mentioned that retention size/time configuration applies across all epochs. i.e. if i say retention is 3gb and the total log as per current epoch is 2 gb, but the total data stored in remote +local = 7gb, then i will delete (7-3) = 4gb of data as part of this cleanup. is my understanding correct? if yes, then we seem to be deleting only the current leadership chain here but we are using the breached size from all the epochs calculated earlier. isn't this contradictory?",-1,0.9892276525497437
1226538752,13561,divijvaidya,2023-06-12T11:52:40Z,"even if we are not the leader at this stage, we have deleted the logs in remote. shouldn't we still update the metadata?",0,0.9802138209342957
1234978872,13561,satishd,2023-06-20T09:12:40Z,"it is inclusive, updated with the doc describing about the variable.",0,0.9853713512420654
1234980098,13561,satishd,2023-06-20T09:13:45Z,i guess that is fine as retention size is more about the minimum size available in the topic partition. that segment will be deleted when the local-log-start-offset moves in later cycles.,0,0.9835972189903259
1234980957,13561,satishd,2023-06-20T09:14:25Z,"it was updated based on log-start-offset with `updatelogstartoffset`, but local-log-start-offset can be more than that and it will be updated if needed.",0,0.9894243478775024
1246792402,13561,jeqo,2023-06-29T15:29:31Z,"i also find it strange to repeat the mutations of hwm and local log recovery point in both updates, we can pull those two updates into a single method and call it once?",-1,0.8108523488044739
1246831654,13561,jeqo,2023-06-29T15:52:44Z,"is it correct to update locallogstartoffset directly, but use updatelogstartoffset method to also update related values (hwm and local log recovery)?",0,0.9884361028671265
1247609605,13561,jeqo,2023-06-30T08:46:28Z,"found this a bit confusing. in main operation `onlylocallogstartoffsetupdate` is false by default, but here we are overriding with `onlylocallogstartoffsetupdate` as true, and methods signature are mainly the same. wouldn't be clearer to use the default method with `onlylocallogstartoffsetupdate=true` instead of creating this private method?",-1,0.908599853515625
1247799637,13561,jeqo,2023-06-30T12:19:02Z,nit: [code block],0,0.9873168468475342
1247807726,13561,jeqo,2023-06-30T12:28:17Z,"if i'm reading the call path correctly, this is not the case. `handlelogstartoffsetupdate` function is called only at the end of `cleanupexpiredremotelogsegments` that filters out calls from followers. i guess we could either remote the `isleader` validation here, or move this logic within the lambda itself?",0,0.9858338236808777
1247839591,13561,jeqo,2023-06-30T13:03:12Z,maybe worth adding a log message here stating why cleanup is not happening? or maybe just a comment explaining why this scenario may never happen given the low prob that recordversion < 2 is used.,0,0.9823103547096252
1247868877,13561,jeqo,2023-06-30T13:30:32Z,could we add a log info here similar to copy? [code block],0,0.9897624850273132
1247878833,13561,jeqo,2023-06-30T13:40:08Z,", could you elaborate a bit more what do you mean by ? is this relying on some specific storage backend implementation?",0,0.9767882823944092
1281564595,13561,showuon,2023-08-02T08:20:58Z,", what satish meant, is in most remote storage case, the deletion api won't wait until data deleted in remote storage, instead, it'll mark file as deleted and return immediately. and run background gc in remote storage to delete the deleted flagged file.",0,0.9877150654792786
1281568519,13561,showuon,2023-08-02T08:24:15Z,"i agree with 's suggestion. in this scenario: 1. replica 1 is the leader, and doing remote log segment deletion 2. leadership changed to replica 2 3. replica 1 entering this `handlelogstartoffsetupdate` method under current implementation, we won't update log start offset since it is not the leader anymore. but we should update it! , thoughts?",0,0.9479358196258545
1281575922,13561,showuon,2023-08-02T08:30:07Z,"+1, or at least a debug level.",0,0.9597764015197754
1281648556,13561,showuon,2023-08-02T09:28:21Z,"as commented above, there might be chances that the leadership change during the segment deletion, i think we should update the log start offset before exiting the `cleanupexpiredremotelogsegments` method since if there's no deletion happened, the `logstartoffset` will be empty. wdyt?",0,0.9872418642044067
1281657244,13561,showuon,2023-08-02T09:35:36Z,should we log partition info as below did here?,0,0.9880479574203491
1281660832,13561,showuon,2023-08-02T09:38:41Z,"the comment is not clear: `// segment's first epoch's offset [should] be more than or equal to the respective leader epoch's offset.` the log is not correct: `""[{}] remote segment {}'s first epoch {}'s offset is [less] than leader epoch's offset {}."",`",0,0.9586920142173767
1281664514,13561,showuon,2023-08-02T09:41:56Z,+1,0,0.696722686290741
1281667417,13561,showuon,2023-08-02T09:44:36Z,why don't we log `reason` here?,0,0.9590181112289429
1281671130,13561,showuon,2023-08-02T09:47:59Z,nit: it's weird to see `local log retention size` when user is not enabled the tiered storage. could we add a if check to see if remote storage is enabled or not and print the log accordingly?,-1,0.9849638342857361
1281672320,13561,satishd,2023-08-02T09:48:59Z,"all the size/time/startoffset handlers run based on the current leader’s leader epochs. here, we are removing the segments which have leader epochs earlier to the lowest leader epoch on this broker(partition leader).",0,0.9874733686447144
1281675518,13561,showuon,2023-08-02T09:51:35Z,nice test!,1,0.9879065752029419
1281844159,13561,satishd,2023-08-02T12:37:14Z,good point! addressed in the latest commits to keep the logic simpler.,1,0.9840548634529114
1283024088,13561,satishd,2023-08-03T10:50:15Z,it is not mandatory to update it when this node becomes a follower as the existing follower fetch protocol makes sure that the follower truncates their log-start-offset based on the leader's log-start-ffset.,0,0.9875186085700989
1284241897,13561,satishd,2023-08-04T10:10:50Z,this is not required as the updated code does not use this method.,0,0.980823278427124
1284278935,13561,satishd,2023-08-04T10:54:02Z,good catch.,1,0.9640093445777893
1284280124,13561,satishd,2023-08-04T10:55:05Z,replied in the [a link].,0,0.9854261875152588
1287757841,13561,junrao,2023-08-08T22:37:26Z,identation doesn't match other places in this file.,0,0.907727837562561
1287764297,13561,junrao,2023-08-08T22:50:50Z,"since newlocallogstartoffset is larger than locallogstartoffset(), could we just assign newlocallogstartoffset to _locallogstartoffset?",0,0.9881669878959656
1288778006,13561,junrao,2023-08-09T15:52:12Z,"hmm, i still don't quite understand this part. the leader's epoch chain only gets trimmed from the beginning when segments are deleted due to retention or the advancement of the startoffset by `deleterecord()` call. these are covered by the size/time based retention and logstartoffset based retention. so what additional cases does the following code cover?",0,0.9359996914863586
1288852233,13561,junrao,2023-08-09T16:18:28Z,"here is a corner case. let's say remote log is enabled, but there is no remote segment (all have been deleted due to retention). the new logic will do retention based on `localretentionbytes`, but it should actually do the retention based on `retentionsize`. if that happens, we need to advance logstartoffset, in addition to locallogstartoffset.",0,0.988020122051239
1288860833,13561,junrao,2023-08-09T16:25:57Z,"hmm, this should be false, right? do we have a test case to cover that?",0,0.9456148743629456
1288884433,13561,junrao,2023-08-09T16:41:47Z,this is an existing issue. but there is one direct reference to `_locallogstartoffset` in `fetchoffsetbytimestamp()`. should we change that to use `locallogstartoffset()` instead?,0,0.9851261377334595
1288898898,13561,junrao,2023-08-09T16:54:23Z,"this doesn't look right. if remote log is not enabled, it seems that we should delete based on logstartoffset, not locallogstartoffset.",0,0.8221629858016968
1289488513,13561,satishd,2023-08-10T03:08:13Z,"no, this should be true if the remote storage is not enabled as this segment should be eligible based on other checks like `highwatermark >= upperboundoffset && predicate(segment, nextsegmentopt)`. existing tests in `unifiedlogtest`, `logoffsettest`, `logloadertest`, `logcleanertest` already cover those scenarios.",0,0.9895038604736328
1289566534,13561,satishd,2023-08-10T05:25:05Z,local log size is based on the local retention configs and those are always less than or equal to the complete log retention. i'm unclear about the rationale behind retaining data in local storage using an overall retention size where there are no remote log segments. please provide clarification.,0,0.9824894666671753
1289577612,13561,satishd,2023-08-10T05:42:01Z,nice catch! missed it while merging the conflicts.,1,0.9906202554702759
1289595441,13561,satishd,2023-08-10T06:03:07Z,"this covers scenarios where unclean leader election happens and the remote storage contains segments that are earlier to the current leader's leader-epoch-lineage. for ex: the current leader has the current leader-epoch-cache. [code block] but the earlier broker which got replaced with a new broker which has the current leader's leader-epoch lineage. [code block] but these segments did not expire retention and they were not deleted in the remote storage. but these leader epochs are not there in the current leader's leader epoch as it was chosen with unclean leader election. in this case, we need to remove the segments, that exist beyond the current leader epoch lineage. otherwise, they will never be cleaned up and will continue to accumulate in remote storage.",0,0.9791452884674072
1291679491,13561,junrao,2023-08-11T18:47:15Z,"while you are here, could you also add the missing javadoc for brokertopicstats?",0,0.9898334741592407
1291681393,13561,junrao,2023-08-11T18:49:53Z,thanks for the explanation. it makes sense to me. could you add a comment that this is needed for unclean leader election?,1,0.8741170763969421
1291690729,13561,junrao,2023-08-11T19:02:54Z,"here is what i mean. ideally, the retention behavior should be unchanged with remote storage. consider the following case without remote storage. let's say retentionsize is 100mb and we have only 1 segment of 90mb. the retention logic won't trigger the deletion of the last segment. now, consider the same situation with remote storage enabled, but no remote segments. if localretention is 20mb, the retention logic will delete last segment of 90mb. since the data is not in remote storage. we have deleted the data a bit earlier than expected. a similar issue exists for time-based retention. if remote storage is enabled, but no remote segments, the time-based retention is now based on localrentiontime, not retentiontime. since the former can be smaller than the latter, it means that we could delete the data earlier than expected.",0,0.9687783122062683
1291693299,13561,junrao,2023-08-11T19:06:35Z,"in that case, the name `issegmenttieredtoremotestorage` is a misnomer. if remote storage is disabled, there shouldn't be any segment tiered to remote storage, yet we are setting this val to true.",0,0.9774270057678223
1291698612,13561,junrao,2023-08-11T19:14:23Z,"space after `if`. also, this logic still doesn't look quite right. if remote log is enabled, it seems that we still want to delete local segments whose offset is smaller than logstartoffset.",0,0.9520272016525269
1292935520,13561,showuon,2023-08-14T03:23:22Z,nice catch!,1,0.9883393049240112
1292967294,13561,satishd,2023-08-14T04:41:20Z,"when remote log is enabled, it deletes the local segments whose offset is <= local-log-start-offset. the existing condition without tiered storage is to delete the local log segments <= log-start-offset.",0,0.989440381526947
1292967405,13561,satishd,2023-08-14T04:41:39Z,it was implicit from the condition that it is relevant only when remote storage is enabled. i removed the value and added a condition and the respective comments for better clarity.,0,0.9874019026756287
1293066497,13561,showuon,2023-08-14T07:23:37Z,good point! i think it's worth filing a bug in jira. wdyt ?,1,0.9684990644454956
1293071660,13561,showuon,2023-08-14T07:29:21Z,"so you mean, all the segment deletion will happen again in the new leader, and update the log start offset there. ok, make sense.",0,0.9833223819732666
1293081560,13561,kamalcph,2023-08-14T07:39:13Z,"in the fetch response, the leader-log-start-offset will be piggy-backed. but, there can be a scenario: 1. leader deleted the remote log segment and updates it's log-start-offset 2. before the replica-2 update it's log-start-offset via fetch-request, the leadership changed to replica-2. 3. there are no more eligible segments to delete from remote. 4. the log-start-offset will be stale (referring to old log-start-offset but the data was already removed from remote) 5. if the consumer starts to read from the beginning of the topic, it will fail to read. i realised the case mentioned by and this one is different. both of them can be handled by the new leader gracefully. we can take this task in a follow-up pr if required.",0,0.9798132181167603
1293086543,13561,kamalcph,2023-08-14T07:44:56Z,"to ensure consistency, similar to local, which marks the segment for deletion (renames the file to .delete) and deletes it after 1 minute. (segment.delete.delay.ms). should we move the log-start-offset before the remote log segment deletion? one way to do this is not to delete the remote log segments in `deleteretentiontimebreachedsegments` and `deleteretentiontimebreachedsegments` and only move the `logstartoffset`. in the next iteration, those remote-log-segments will be removed via `deletelogstartoffsetbreachedsegments`. wdyt?",0,0.98649662733078
1293158752,13561,kamalcph,2023-08-14T08:31:22Z,statements in l1065 and l1057 are same. typo error?,0,0.9825229644775391
1293179175,13561,satishd,2023-08-14T08:50:26Z,the case mentioned by you can be addressed in a followup pr. please file a jira.,0,0.9854937791824341
1293185679,13561,kamalcph,2023-08-14T08:56:07Z,nit: [code block],0,0.9873168468475342
1293189650,13561,kamalcph,2023-08-14T08:58:39Z,`optional` is not recommended as parameter in java: [a link],0,0.9870873689651489
1293224397,13561,divijvaidya,2023-08-14T09:28:33Z,can you please address this comment. multiple folks have asked me why this code of line exists which makes me believe that a comment explaining the purpose here would be nice.,0,0.7520400285720825
1293244517,13561,divijvaidya,2023-08-14T09:46:56Z,could we please store the value of log.logendoffset() at the beginning of clean up process and use the stored value for all calculations? asking because endoffset may move behind the scenes while we are processing cleaning. the overall idea is that this cleanup should be executing on a snapshot of log state.,0,0.9887779355049133
1293286722,13561,divijvaidya,2023-08-14T10:26:10Z,"isn't it possible for older epoch chain to become the current chain after another unclean election? for example: time t1: leader epoch chain [code block] time t2: unclean leader election occurs where the new leader loses all existing data and starts with new leader epoch [code block] time t3: unclean leader election occurs again but the old leader from t1 becomes new leader (epoch 8). in this case, the current epoch chain will be 0->1->2->8. but we have deleted data from remote already pertaining to 0,1 and 2, even if it was not eligible for deletion based on retention. to remedy this situation, may i suggest that we delete the unreferenced segments ""only"" if we definitely know that they can be cleaned i.e. when they have exceeded the retention time or when the size in remote itself is greater than retention size. i have to check but i believe that local log solves it in a similar manner.",0,0.9759484529495239
1293305304,13561,divijvaidya,2023-08-14T10:43:56Z,"note that same segment may span across multiple epochs. hence, same segment id will be returned multiple times here and we will count it's size multiple times. may i suggest: [code block] also, if you agree that this was a bug, please add a unit test that should have failed.",0,0.9873857498168945
1293325721,13561,divijvaidya,2023-08-14T11:06:09Z,you need to use this to correctly filter out segments at `findoffsetbytimestamp` method as well please.,0,0.9892128705978394
1293327365,13561,divijvaidya,2023-08-14T11:08:05Z,"i believe we already have public accessor functions in logconfig for these. see logconfig.localretentionms(), logconfig.localretentionbytes() and logconfig.remotestorageenable()",0,0.9846702814102173
1293329291,13561,divijvaidya,2023-08-14T11:10:27Z,you can instead use similar methods already present in logconfig. see logconfig.localretentionbytes() and logconfig.localretentionms() (you will probably have to modify them to add new case of `if (config.remotelogconfig.remotestorageenable)`,0,0.9888936877250671
1293332177,13561,divijvaidya,2023-08-14T11:14:01Z,the code in this pr still uses this method. no? what am i missing?,0,0.955291211605072
1293336126,13561,divijvaidya,2023-08-14T11:19:06Z,the current code uses the leader epoch chain to calculate the size. this comment is resolved in latest code.,0,0.9862371683120728
1293345266,13561,satishd,2023-08-14T11:29:59Z,"let me rephrase what you mentioned here retention.bytes= 100mb segment1 - 90mb when remote storage is not enabled, then this segment is not deleted from local log segments becuas eof the retention size check. retention.bytes= 100mb local.retention.bytes= 20mb segment1 - 90mb when remote storage is enabled, and there are no segments uploaded to remote storage. that means it will not allow this segment to be deleted as it is not yet copied to remote storage based on the introduced check in this pr. if it is copied to remote storage, that means it is not an active segment and there are one or more local segments after this segment. this segment will be eligible for deletion based on the local retention policy as it is already copied to remote storage earlier. am i missing anything here?",0,0.9823134541511536
1293402836,13561,nikramakrishnan,2023-08-14T12:36:13Z,+1. we should add this check to [a link] to ensure we select the segment with correct leader lineage.,0,0.969623863697052
1293823449,13561,junrao,2023-08-14T18:24:26Z,should we do the same for retentionmsbreach to log whether the retention time is for local retention or not?,0,0.9875572919845581
1293851913,13561,junrao,2023-08-14T18:55:48Z,"we want to be a bit careful of using this method. leaderepochcache is mostly derived from the data in the log. however, on new leader epoch from a leader change, the new leader also appends the new epoch to leaderepochcache before any record is appended for the epoch. this could cause a slight mis-match between the epoch chain in the remote segment and leaderepochcache. for example, it's possible for a leaderepochcache to have 10 100 11 200 //no record appended for epoch 11 12 200 where a segment's epoch chain only has 10 100 12 200 we don't want to prevent the remote segment from being deleted through the retention logic because of this slight mismatch on leader epoch chain. does the code allow for this?",0,0.9699860215187073
1293857043,13561,junrao,2023-08-14T19:00:04Z,"yes, it just means that the segment won't be deleted until it's uploaded to the remote store. but this is probably ok.",0,0.9807971715927124
1293857107,13561,junrao,2023-08-14T19:00:09Z,": sorry, i didn't give the right example. this is the case. without remote storage, retention.bytes= 100mb segment1 - 200mb we will delete segment1 (even if it's the active segment). with remote storage, retention.bytes= 100mb local.retention.bytes= 20mb segment1 - 200mb if segment1 is the active segment, it won't be deleted until it rolls and is uploaded to the remote store. it's a very subtle difference.",-1,0.989072322845459
1294602887,13561,satishd,2023-08-15T13:33:11Z,"i do not find a strong reason not to use optional as an argument. :) in the same so link, few other opinions on why it is a weak argument. optional as an argument is used in several other places within this project. i do not have strong opinions and i am fine if we decide to go with that rule across the project when there is a consensus. we can revisit it when we do that.",1,0.8262153267860413
1294603142,13561,satishd,2023-08-15T13:33:25Z,good catch!,1,0.9899783134460449
1294604024,13561,satishd,2023-08-15T13:34:15Z,what is the rationale for this suggestion?,0,0.9669097065925598
1294618085,13561,jeqo,2023-08-15T13:45:28Z,"could we elaborate what's the purpose of this validation? iiuc `(totalsize - retentionsize) > retentionsize`, are we validating that totalsize is not higher than 2 times `retentionsize`?",0,0.9892237186431885
1294843843,13561,satishd,2023-08-15T16:25:07Z,this method is used only from `locally` block and it does not require taking any lock. we moved this method inside the locally block to avoid any confusion and future usage outside of that.,0,0.9888216257095337
1295387916,13561,satishd,2023-08-16T05:15:50Z,"good catch! it was changed while refactoring, added uts to cover that in the latest commits.",1,0.9913734793663025
1295394486,13561,kamalcph,2023-08-16T05:28:16Z,filed kafka-15351 and kafka-15352 to track the cases.,0,0.9841129183769226
1295402786,13561,kamalcph,2023-08-16T05:42:48Z,"for clean code, it creates an anonymous extra class at every usage and we should try to avoid this pattern. [a link]",0,0.9826816916465759
1295607067,13561,satishd,2023-08-16T09:09:02Z,"thanks for the clarification. in the above case with remote storage enabled, it will eventually be deleted from local and remote storages, and updates log-start-offset and local-log-start-offset respectively.",1,0.8380521535873413
1295670320,13561,satishd,2023-08-16T10:02:58Z,"thanks for the clarification, good to know about that.",1,0.9601516723632812
1295701347,13561,satishd,2023-08-16T10:33:17Z,"thanks jun for pointing it out. currently, segment epochs are created from leader epoch cache truncated with start and end offsets. but i added defensive checks to filter the epoch with empty records as they will not have any records/messages in the segments. these changes with uts added in the latest commits.",1,0.9432342052459717
1295713103,13561,satishd,2023-08-16T10:45:11Z,follower replicas do truncation based on leader epoch lineage and catch up with the leader. it is hard to know whether a particular lineage can exist in any of the replicas as replicas can fail and it is hard to say whether a particular replica can come back with in a specific duration. that may cause leakages in remote storage. follower replicas can not delete the remote segments as these may be part of the current leader and it may delete the data that is expected by the leader. the tradeoff taken in case of unclean leader election here is to clean up the epoch lineage earlier to the current leader epoch instead of creating segment leakages in remote storage.,0,0.9633960127830505
1296218455,13561,junrao,2023-08-16T17:19:11Z,this can be simplified a bit to `.foreach{ log => ...}`. ditto for the same code in brokerserver.,0,0.9620693922042847
1296221075,13561,junrao,2023-08-16T17:22:01Z,"yes, i agree that it's not a large and common issue. so, we can leave it as it is for now.",0,0.9502383470535278
1296264710,13561,divijvaidya,2023-08-16T18:04:46Z,"correct, that is why we should not be deleting data that we are unsure about. it's a durability loss! in a trade-off situation, wouldn't we want to trade-off in favour of durability instead of remote storage leak (which can be gc'ed by rsm implementation for such cases). one way to solve is it is to delete the data that we know for sure is ready for deletion, e.g. if we have 10mb of data in remote store for non-active lineage and retention size is 2mb, then we can safely delete the rest of the 8mb. this is because even if this leadership chain becomes active, it will adhere to retention size. in other words, i am not saying that we should not delete non-active lineage data in remote store. i am saying that the non-active lineage data should only be deleted if it when it is violating the retention policies. if we have time based retention, this will ensure that there are no leaks. if we have size based retention, then we can do what you are suggesting. i will not consider this comment as blocking to merge this pr since this is in early access but we should document this risk of data loss as part of release notes and try to arrive at a conclusion before production release. thoughts ?",0,0.8641045689582825
1296731885,13561,satishd,2023-08-17T06:27:15Z,it is hard or impossible to find the non-active lineage deterministically as the failed host can have any subset of the non active lineage. determining which epoch/segments can be marked for deletion under such circumstances is not feasible.,0,0.6746639609336853
1296732476,13561,satishd,2023-08-17T06:27:58Z,"in case of unclean leader election, there is already a durability loss when a non in-sync replica needs to be chosen as a leader and given preference to availability. the approach taken in this pr uses the current tradeoff of durability loss and avoids remote log segment leaks. this is slightly different from local log cleanup which we can clarify in the release notes. retention/cleanup logic spread across multiple layers(outside of kafka) poses significant risks and could lead to more extensive problems. so, it is better that to be handled by kafka's retention mechanism. we will discuss further on finalizing the approach before we make this feature production ready.",0,0.9529825448989868
1297576757,13561,junrao,2023-08-17T18:11:51Z,"hmm, should we use `remotelogenabled()` instead of `config.remotelogconfig.remotestorageenable`? ditto for `localretentionsize`.",0,0.9187085032463074
1297580311,13561,junrao,2023-08-17T18:15:41Z,"has a good point. when doing unclean leader election, the new leader (even if unclean) should still have access to the remote data. so, it probably should never lose that portion of the data?",1,0.9063072800636292
1298029817,13561,satishd,2023-08-18T05:47:39Z,"that is a fair point. if we want to take that approach, we should not delete any segments beyond the current leader's leader epoch lineage. we need to take the risk of rsm plugins having cleanup mechanisms for the segment leaks in the remote storage. these leaks may accumulate over time and create operational issues. it is hard even for rsm plugin owners to deterministically find out whether a segment is unreferenced when there are out-of-sync/offline replicas. i filed [a link] to continue the discussion and take a final call later before productionizing it.",0,0.9360105395317078
1298640349,13561,junrao,2023-08-18T16:25:11Z,what's the impact to 3.6.0? do we need to outline any limitation with unclean leader election in the release notes?,0,0.962035059928894
1299184981,13561,satishd,2023-08-19T13:09:53Z,this is only applicable with tiered storage enabled topics. we will add that in the release notes of tiered storage section about the change in the behavior.,0,0.9889463782310486
1299185257,13561,satishd,2023-08-19T13:12:33Z,good point. added the required filtering check `findoffsetbytimestamp` api.,1,0.9607226848602295
1299221576,13561,junrao,2023-08-19T16:58:45Z,what's the behavior of unclean leader election when tiered storage is enabled?,0,0.9266193509101868
1299640804,13561,satishd,2023-08-21T05:55:11Z,"the remote storage retention cleanup mechanism considers cleaning up the remote log segments that have all the records that are created with a leader epoch precedes to the earliest leader epoch in the current leader's leader epoch lineage. in case of unclean leader election, the earlier leader replica may delete the segments that are copied to remote storage but those are not part of its leader epoch lineage but they may be part of out-of-sync or offline follower replicas and they will not be available for consumption.",0,0.9824068546295166
1299988151,13561,jeqo,2023-08-21T11:33:03Z,"similar to the previous comment on rentetionsizedata: `cleanupuntilms` represents a point in time (`now - retentionms`), while `retentionms` represents a duration (e.g. 1 week in millis). is this comparison correct/needed? if i'm reading this right, this will always be true.",0,0.9885468482971191
1300055517,13561,divijvaidya,2023-08-21T12:39:26Z,"this takes an assumption that the partition has continuous monotonically increasing offsets. but it is not true for a topic that was historically compacted (i.e. compaction is turned off now, that is why ts is enabled). i would suggest to read the next segment and set the startoffset as the start offset of the next segment.",0,0.9826433062553406
1300176481,13561,satishd,2023-08-21T14:16:28Z,good point. i think we discussed this earlier also. let us address this in a followup pr covering topics changing their retention from compaction to delete only retention. filed [a link],1,0.937706708908081
1300178242,13561,satishd,2023-08-21T14:17:49Z,this check will be true when using system time. but added this defensive check if we have tests setting the mock time to set any long values.,0,0.9764053821563721
1300199098,13561,divijvaidya,2023-08-21T14:32:48Z,sure. we can address this separately but i think that should be a blocker jira for 3.6. otherwise we are shipping this pr with a known bug which i am not very comfortable with. this bug is also not very edge case-y as others for which we have started jira items such as bugs related to performance instead this bug impacts correctness. do you agree?,0,0.8553995490074158
1300279331,13561,satishd,2023-08-21T15:23:52Z,"yes, this is planned for 3.6.0. i did not want to block this pr with that as we want to unblock other dependent prs, especially integration test prs.",0,0.978162944316864
1300314011,13561,jeqo,2023-08-21T15:52:59Z,"yeah, but the part i'm missing is why should we throw an exception when this is true. if retention is 1 hour, and `cleanupuntil` is at any point in system time, we are throwing an exception.",0,0.9477998614311218
1300372620,13561,junrao,2023-08-21T16:40:19Z,"hmm, i was just asking about how unclean leader election with tiered storage is handled in 3.6.0. it seems that this pr has removed the logic for retention by leader epoch. in that case, when an unclean leader is elected, does it just use its logendoffset to start writing new data? in that case, do we just hide those remote segments with offsets higher than the new leader's starting logendoffset? will those hidden remote segments be cleaned up eventually?",0,0.9707435965538025
1301361619,13561,satishd,2023-08-22T09:38:39Z,"right, i fixed the validation check. thanks.",1,0.9440690875053406
1304597735,13561,satishd,2023-08-24T16:34:49Z,"syncedup with jun to understand the comment here and clarified them. the retention logic deletes the segments with leader epochs preceding the earliest leader epoch in the current leader. any epochs/offsets which are not there in the current leader epoch lineage but they are within the range, those will be eventually deleted when the current leader's earliest leader epoch moves beyond that. right, it will start writing with its logendoffset with the new epoch. right, they will be eventually removed.",0,0.9829334616661072
1307788374,13561,dopuskh3,2023-08-28T18:52:30Z,"it seems i'm reaching that codepath when running reassignments on my cluster and segment are deleted from remote store despite a huge retention (topic created a few hours ago with 1000h retention). it seems to happen consistently on some partitions when reassigning but not all partitions. my test: i have a test topic with 30 partition configured with 1000h global retention and 2 minutes local retention i have a load tester producing to all partitions evenly i have consumer load tester consuming that topic i regularly reset offsets to earliest on my consumer to test backfilling from tiered storage. my consumer was catching up consuming the backlog and i wanted to upscale my cluster to speed up recovery: i upscaled my cluster from 3 to 12 brokers and reassigned my test topic to all available brokers to have an even leader/follower count per broker. when i triggered the reassignment, the consumer lag dropped on some of my topic partitions: later i tried to reassign back my topic to 3 brokers and the issue happened again. both times in my logs, i've seen a bunch of logs like: [code block] looking at my s3 bucket. the segments prior to my reassignment have been indeed deleted.",0,0.9296901226043701
1308148879,13561,showuon,2023-08-29T03:14:54Z,", thanks for reporting this issue. i've created [a link] for this issue. let's discuss it in jira.",1,0.9230304956436157
1308153773,13561,satishd,2023-08-29T03:26:59Z,thanks for bringing the observed issue here. there are a few more pending changes to be merged which are in review/planned related to this change. i will followup on [a link].,1,0.907403826713562
1433944692,13561,iit2009060,2023-12-21T11:26:05Z,"i gone through the specific code and realised this is actually not impacting the logic 1. while copying the remote segments , remotelogsegmentmetadata stores endoffset using value from the nextsegment base offset. [a link] 2. in my understanding it will be safe to use same logic for historically compacted topics. let me know if my analysis is correct or not ?",0,0.9714102149009705
1434040959,13561,divijvaidya,2023-12-21T12:52:59Z,yes that is correct. copying functionality is not impacted as discussed in [a link] it's only the read-from-remote that is impacted for the historically compacted topic.,0,0.9848968982696533
194783912,5201,bbejeck,2018-06-12T15:27:28Z,"this class is created to contain common information for repartition operations. there are two types of repartitioning currently. when changing a key in a `kstream`s method (`map`, `flatmap` `selectkey` etc) or when performing a `ktable.groupby` operation. the former is eligible for optimization, while the `ktable.groupby` is not.",0,0.9870421886444092
194784561,5201,bbejeck,2018-06-12T15:28:57Z,there are 2 difference between the repartition operations the first is the `serializer` and `deserializer` required,0,0.9846996665000916
194784918,5201,bbejeck,2018-06-12T15:29:54Z,the second difference between repartition operations is the name used to wire up the repartitioning processor.,0,0.9827118515968323
194785793,5201,bbejeck,2018-06-12T15:32:15Z,this class was created to represent the _**non optimizable**_ repartition resulting from a `ktable.groupby` operation,0,0.9876558780670166
194786010,5201,bbejeck,2018-06-12T15:32:50Z,same class just moved to `graph` package,0,0.9886566400527954
194786478,5201,bbejeck,2018-06-12T15:33:53Z,this class represents a repartition operation that _**is eligible**_ to get optimized away.,0,0.9870179295539856
194787418,5201,bbejeck,2018-06-12T15:36:26Z,"the class is the same just moved to a new package. this is the same for all graph objects, so i won't continue to repeat this comment.",0,0.9670935273170471
194790053,5201,bbejeck,2018-06-12T15:43:10Z,"created to represent `ktable` operations (`filter`, `transformvalues`, `mapvalues`)",0,0.9886616468429565
194791681,5201,bbejeck,2018-06-12T15:47:39Z,"for now, this includes the recent changes from (pr #5163) for optional re-use of source topic as changelog topic. this optimization will get folded into this pr in a follow-up push.",0,0.9870490431785583
198283461,5201,vvcephei,2018-06-26T20:18:55Z,it seems like this is happening twice; once inside `addchildnode` and once outside it. (also applies to other occurrences),0,0.9714798331260681
198285554,5201,vvcephei,2018-06-26T20:26:02Z,nit: could be final ;),1,0.8004976511001587
198287289,5201,vvcephei,2018-06-26T20:31:43Z,i think these are never referenced. is there still more to do?,0,0.9805961847305298
198289563,5201,vvcephei,2018-06-26T20:39:02Z,"this is a bit beside the point, but do we actually need this? it's unused in our codebase. do we expect users to subclass `abstractstream`? i think the question is applicable; i'm still hoping we could finish disentangling the internaltopologybuilder from the streamsgraph and internalstreamsbuilder.",0,0.9806933999061584
198289936,5201,vvcephei,2018-06-26T20:40:14Z,"also, on line 76, we're taking note of which nodes need to be copartitioned. do we need to capture this information in the streamsgraph as well?",0,0.9885166883468628
198290842,5201,vvcephei,2018-06-26T20:43:08Z,"aside from these two usages, the only other purpose that the internaltopologybuilder serves in the streamsbuilder hierarchy is to add state stores. i think that if we add this to the logical plan first, then we could completely decouple the internaltopologybuilder from the internalstreamsbuilder.",0,0.9868729710578918
198291738,5201,vvcephei,2018-06-26T20:45:53Z,"might be nice to throw an exception if this check fails. it would clearly be a mistake, and it might be nicer for it to break than to do nothing. (i'm specifically thinking if the builder is created, built, modified, and built again; the second modification would just be lost.)",0,0.9510374665260315
198293629,5201,vvcephei,2018-06-26T20:52:24Z,nit: many variables in here can be final.,0,0.9883605241775513
198294005,5201,vvcephei,2018-06-26T20:53:34Z,this field is never used.,0,0.9352120757102966
198294951,5201,vvcephei,2018-06-26T20:56:39Z,"i wasn't sure why the `nodeidcomparator` implements `serializable`. if it doesn't need to, then you can get rid of that class and that field and just do: [code block]",0,0.9683727025985718
198294955,5201,mjsax,2018-06-26T20:56:39Z,"if we remove the `null` check, should we add one in the constructor?",0,0.9857423305511475
198295985,5201,mjsax,2018-06-26T21:00:04Z,why remove `final`?,0,0.958608090877533
198297056,5201,mjsax,2018-06-26T21:04:17Z,nit: add `final`,0,0.9880309700965881
198298276,5201,mjsax,2018-06-26T21:08:19Z,don't understand the log statement? something missing there?,0,0.8171050548553467
198298348,5201,mjsax,2018-06-26T21:08:34Z,nit: add `final`,0,0.9880309700965881
198298794,5201,mjsax,2018-06-26T21:10:23Z,nit: add `final` (seems some more in the next lines),0,0.986580491065979
198299478,5201,mjsax,2018-06-26T21:12:21Z,nit: move after the following `if` (we not' need to get the `keychangingnode` if we `continue`,0,0.986096203327179
198299936,5201,mjsax,2018-06-26T21:14:03Z,"which ""streamsgraphnode"" ?",0,0.9878424406051636
198301439,5201,vvcephei,2018-06-26T21:19:52Z,super minor nit: i thought the code style says to always put arguments on a new line when splitting args over multiple lines. i only bring this up because i've been doing it that way...,-1,0.611111044883728
198302388,5201,vvcephei,2018-06-26T21:23:31Z,final?,0,0.9590096473693848
198304292,5201,mjsax,2018-06-26T21:30:43Z,why do we need this here?,0,0.9461626410484314
198306976,5201,mjsax,2018-06-26T21:41:28Z,nit: can we use variable instead of getting the names multiple times?,0,0.9885559678077698
198307864,5201,mjsax,2018-06-26T21:45:01Z,why this renaming?,0,0.8355180025100708
198308379,5201,mjsax,2018-06-26T21:47:18Z,"nit: simplify `multipleparentnames` -> `parentnames` (`names` is already plural, should be good enough). im wondering, it it might be better to track the parents in `streamsgraphnode` ?",0,0.9825369715690613
198308755,5201,mjsax,2018-06-26T21:49:00Z,when could this be `null`?,0,0.9807872772216797
198308922,5201,mjsax,2018-06-26T21:49:33Z,when would this be not empty?,0,0.978594183921814
198310099,5201,mjsax,2018-06-26T21:54:40Z,"why doe we assume, that a stateful operator has always one parent? what about a materialized table-table join?",0,0.9750877618789673
198310662,5201,mjsax,2018-06-26T21:57:09Z,nit: remove empty line,0,0.9813840389251709
198311099,5201,mjsax,2018-06-26T21:59:19Z,nit: introduce variable to get name only once?,0,0.985991895198822
198311844,5201,mjsax,2018-06-26T22:02:37Z,"this is done for both join, right? (ie, update comment?)",0,0.987006425857544
198312036,5201,mjsax,2018-06-26T22:03:28Z,nit: `steam - table join [only]`,0,0.9871377944946289
198312756,5201,mjsax,2018-06-26T22:06:45Z,"why do we need this check? it seem that `parentnode` cannot be `null`, and that it would be `this` always, too? (assuming one parent node, what is not generic)",0,0.9795038104057312
198312832,5201,mjsax,2018-06-26T22:07:10Z,as above.,0,0.978552520275116
198313052,5201,mjsax,2018-06-26T22:08:18Z,"why not extend `statefulprocessornode` ? why remove the generic type? can't it be windowed, too? what about custom stores in `transform()` ?",0,0.984533429145813
198313486,5201,mjsax,2018-06-26T22:10:19Z,nit: add `final`,0,0.9880309700965881
198314691,5201,mjsax,2018-06-26T22:15:52Z,"would it be better to put a generic ` ` her and change to `tablesourcenode `? also, should we take `builder.windowedtable()` into account already? pretty sure the kip will be accepted.",0,0.9876941442489624
198319640,5201,mjsax,2018-06-26T22:40:51Z,nit: `final`,0,0.9817487597465515
198320164,5201,mjsax,2018-06-26T22:43:53Z,as above,0,0.9783914685249329
198368837,5201,guozhangwang,2018-06-27T05:14:07Z,"this is added for users that want to extend `abstractstream`, one use case of it is [a link] regarding `internaltopologybuilder` and `internalstreamsbuilder`: we need to pass in `internaltopologybuilder` into the `streamsgraphnode` because their `writetotopology` (this is the one that translates the logical node into one or more physical nodes) needs it, and those graph nodes are accessed from the `internalstreamsbuilder`, so i think we still need to let it hold a reference of the `internaltopologybuilder` anyways.",0,0.9801445007324219
198368989,5201,guozhangwang,2018-06-27T05:15:10Z,+1,0,0.696722686290741
198369331,5201,guozhangwang,2018-06-27T05:18:00Z,"if they are used for the optimization rules that are to be added later, we should remove them from this pr. i'm now not so sure if wants to add the optimizations in this pr, but i'd suggest we do it in a forth one given the current pr is pretty large already.",0,0.9446660280227661
198369849,5201,guozhangwang,2018-06-27T05:22:25Z,"if users call `streamsbuilder#build()` multiple times, which we cannot forbid programmatically, we should still only call this function once; on the other hand, if users add a few more operations into the streams topology and then call `build()` again we should probably re-run optimization and generate a new topology, i.e.: [code block]",0,0.9842959642410278
198369989,5201,guozhangwang,2018-06-27T05:23:37Z,"+1, if we are not going to write / serialize the logical plan anywhere we do not need to do that.",0,0.932971179485321
198370646,5201,guozhangwang,2018-06-27T05:29:03Z,kgroupedtableimpl also have a duplicated `createrepartitionnode`.,0,0.9889300465583801
198370821,5201,guozhangwang,2018-06-27T05:30:05Z,may need some more explanation of this optimization rule.,0,0.9757477641105652
198370939,5201,guozhangwang,2018-06-27T05:31:08Z,"meta comment: if we are going to add more optimization rules in `optimize()`, should we keep this pr as a plain one that do not enforce any optimizations, so that we can then consider each function separately, that helps more concentrated reviews and reduce large pr burdens.",0,0.9809251427650452
198371994,5201,guozhangwang,2018-06-27T05:38:31Z,this is nice cleanup.,1,0.8839730620384216
198372212,5201,guozhangwang,2018-06-27T05:40:13Z,meta comment: seems we have migrated the node classes in a previous pr so could you update the description of this pr to remove the statement that we changed the package here?,0,0.9893395304679871
198372226,5201,guozhangwang,2018-06-27T05:40:20Z,+1,0,0.696722686290741
198372742,5201,guozhangwang,2018-06-27T05:44:19Z,should we override this for all the subclasses so that we can have a more informative intermediate logical plan representation for debugging purposes?,0,0.983903169631958
198372787,5201,guozhangwang,2018-06-27T05:44:40Z,+1.,0,0.8624979853630066
198372943,5201,guozhangwang,2018-06-27T05:45:50Z,"i cannot tell how this includes the source topic reuse logic, could you explain a bit?",0,0.96275794506073
198933994,5201,bbejeck,2018-06-28T18:04:46Z,ack,0,0.9720376133918762
198937951,5201,bbejeck,2018-06-28T18:18:14Z,ack,0,0.9720376133918762
198938045,5201,bbejeck,2018-06-28T18:18:33Z,ack merge mistake,0,0.6375678181648254
198938944,5201,bbejeck,2018-06-28T18:21:36Z,ack. removed for now as part 3 is for writing physical plan using graph. part 4 will contain optimization only,0,0.9867907166481018
198939184,5201,bbejeck,2018-06-28T18:22:19Z,same as above will clean up in part 4,0,0.983537495136261
198939337,5201,bbejeck,2018-06-28T18:22:47Z,same as above,0,0.9772257208824158
198939460,5201,bbejeck,2018-06-28T18:23:08Z,"ack, will clean up in part 4",0,0.9837788939476013
198940600,5201,bbejeck,2018-06-28T18:26:37Z,"the repartition node just created, will clarify in part 4",0,0.9868339896202087
198941179,5201,bbejeck,2018-06-28T18:28:21Z,ack removed,0,0.9837851524353027
198942912,5201,bbejeck,2018-06-28T18:33:21Z,ack,0,0.9720376133918762
198944739,5201,bbejeck,2018-06-28T18:39:12Z,"during work on this pr, i started to consider this name was a better fit if you insist i can revert.",0,0.9392798542976379
198945962,5201,bbejeck,2018-06-28T18:43:21Z,"ack on the name. for now, i'd prefer to leave `parentnames` in the `processornode` as we specifically add multiple parent names in `kstream#merge`. or maybe refactor always to take a list `parentnames` that would simplify the logic edit: i take that back, we want to rely on getting the parent name for the current graph node by calling `parentnode.name()` the multiple parent names comes from the case mentioned above and are needed for the `internalstreamsbuilder` to complete the merge processor, so i'll leave as is for now.",0,0.9678658843040466
198950446,5201,bbejeck,2018-06-28T18:57:39Z,"i've removed this line, left over from a previous refactoring.",0,0.9851932525634766
198951509,5201,bbejeck,2018-06-28T19:00:48Z,"only used for merge node, so it's empty most of the time. i'll look to see if i can refactor internally.",0,0.9861702919006348
198952083,5201,bbejeck,2018-06-28T19:03:02Z,"table-table joins are represented in a separate node, `ktablektablejoinnode`. i used a specific node for this case imho there is too much information needed in the table-table join to generalize.",0,0.983065128326416
198952415,5201,bbejeck,2018-06-28T19:04:17Z,ack,0,0.9720376133918762
198954002,5201,bbejeck,2018-06-28T19:10:24Z,ack,0,0.9720376133918762
198955006,5201,bbejeck,2018-06-28T19:14:43Z,ack,0,0.9720376133918762
198955044,5201,bbejeck,2018-06-28T19:14:52Z,ack,0,0.9720376133918762
198955718,5201,bbejeck,2018-06-28T19:17:29Z,"since the optimization is pushed out to a 4th pr, this method is removed. i'll clean up in 4th pr. the original idea was to prevent any errors by calling `clearchildren` _*after*_ the children of a given parent node have migrated to another parent. probably better to eliminate the checks and document the calling order when updating the graph.",0,0.9803277850151062
198955766,5201,bbejeck,2018-06-28T19:17:40Z,same comment from above,0,0.9867594838142395
198960187,5201,bbejeck,2018-06-28T19:33:56Z,ack,0,0.9720376133918762
198963636,5201,bbejeck,2018-06-28T19:47:40Z,"i removed the generic type from the class definition and changed the `materializedinternal` from `s` to `keyvaluestore<bytes, byte[]` as it matches the `materializedinternal` parameter used in `ktable#filter`, `ktable#mapvalues`, `ktable#transformvalues`. i can revert that if you want. looking at `statefulprocessornode` it's only used from `kstream` for `process` and `transform`, but those methods never pass a strore builder or materialized, just store names. what makes sense to me is to refactor `statefulprocessornode` to remove the store builder then have `tableprocessornode` extend `statefulprocessornode` . wdyt? i'm not sure what you mean custom stores in `transform()`, `kstream#transform` takes a list of store names which is captured in the `statefulprocessornode` is that what you are referring to?",0,0.9849154949188232
198964111,5201,bbejeck,2018-06-28T19:49:32Z,ack,0,0.9720376133918762
198970765,5201,bbejeck,2018-06-28T20:14:03Z,"ack, required some other minor changes, you'll have to let me know what you think",0,0.9707301259040833
198972710,5201,bbejeck,2018-06-28T20:20:48Z,"edit: i've put the generic type back, but requires a cast internally, you have to let me know what you think",0,0.971181333065033
198976922,5201,bbejeck,2018-06-28T20:35:09Z,removed from this pr and delayed to 4th pr with optimization,0,0.9830612540245056
198977076,5201,bbejeck,2018-06-28T20:35:46Z,ack,0,0.9720376133918762
198977160,5201,bbejeck,2018-06-28T20:36:09Z,removed until 4th pr with optimization,0,0.9803476333618164
198977315,5201,bbejeck,2018-06-28T20:36:42Z,this is required by findbugs.,0,0.9880121946334839
198977471,5201,bbejeck,2018-06-28T20:37:15Z,ack,0,0.9720376133918762
198981153,5201,bbejeck,2018-06-28T20:49:36Z,"that was the intent, build once then subsequent calls return the same physical plan from rebuilding. as for updates, i'm thinking the use case would be to build the topology incrementally and call build at the end versus incremental calls to build, in which case the current approach still works.",0,0.9847905039787292
198982348,5201,bbejeck,2018-06-28T20:53:43Z,"this is intentional. today, when a repartition is required, the `internaltopologybuilder` creates a repartition operation and immediately writes it to the physical plan. so we need to capture the repartition as a graph node and pass the new node to the `internalstreamsbuilder` for possible metadata collection for optimization. in other cased graph nodes are created in classes that don't subclass the `abstractstream`.",0,0.9799860715866089
198982978,5201,bbejeck,2018-06-28T20:56:08Z,ack removed optimization in favor of pushing a 4th pr with optimizations only once 3rd pr is merged.,0,0.9859553575515747
199006843,5201,bbejeck,2018-06-28T22:31:33Z,"ack will try to collapse the two in 4th pr, but for now, the `createreparitionnode` is removed from `internalstreamsbuilder` until 4th pr",0,0.986962616443634
199012496,5201,guozhangwang,2018-06-28T23:02:02Z,"hmm.. for step 4) / 5), now the `topologybuilt` would still be true and hence we would return the same topology, but that is incorrect right?",0,0.9626865386962891
199014145,5201,guozhangwang,2018-06-28T23:12:05Z,"could you explain to us a bit more? i'm still scratching my head now on when do we call `abstractstream#addgraphnode` v.s. `parentnode.addchildnode; builder.maybeaddnodeforoptimizationmetadata(repartitionnode);` because their logic are just the same, right?",0,0.7509927749633789
199272791,5201,mjsax,2018-06-29T20:30:11Z,"i am 51:49 to keep the old name (so, i don't insist in reverting). \cc wdyt?",0,0.950132429599762
199274082,5201,mjsax,2018-06-29T20:36:06Z,ack. makes sense that `transform` does not apply here as this is a `*table*processornode`.,0,0.9846643805503845
199282205,5201,bbejeck,2018-06-29T21:16:21Z,"yep, i'll have to put some thought into what's relevant without being too spammy",0,0.6965885758399963
199286587,5201,bbejeck,2018-06-29T21:40:26Z,ack updated,0,0.9850276708602905
199288962,5201,bbejeck,2018-06-29T21:53:38Z,"what i was thinking of was the developer would build an initial topology with the last statement being the `builder.build()...` then at that point execute the program and observe the printed topology. then go back and update the topology again and run the program a separate time and watch the results. but thinking about it more, that is an opinionated/subjective view of how to develop, and we should not restrict to one style. i'll put something to detect if the topology has changed then rebuild if true.",0,0.8944559097290039
199289400,5201,bbejeck,2018-06-29T21:56:25Z,"i try to follow that as well, but maybe i'm missing something because i thought the args were all on one line here.",0,0.6555675268173218
199291907,5201,bbejeck,2018-06-29T22:11:22Z,"yes, the logic is the same. but `groupedstreamaggregatebuilder` does not subclass `abstractstream` so we need to make those two calls separately. secondly, in the example above we are building 2 graph nodes. the repartition node and the stateful processor node for the aggregation. today when we need to repartition for an aggregation, the `internaltopologybuilder` creates a repartition operation and it becomes the parent of the aggregation operation. so the repartition node needs to be a child of the current `streamsgraphnode` in the `groupedstreamaggregatebuilder` but it must be the parent of the aggregation graph node. does this make sense?",0,0.9739975929260254
205591823,5201,bbejeck,2018-07-26T20:28:02Z,"for removing the restriction of only building topology once, i've decided on the ""traditional"" approach when traversing a graph to only visit (in this case write its contents to the `internaltopologybuilder`) graph nodes not already visited. i feel a similar approach should work with optimization. but since this pr does not include the optimization, i'd prefer to defer any discussions on what will and won't work for multiple `build()` calls until we have the pr for applying the optimization pushed.",0,0.9586029648780823
206391213,5201,guozhangwang,2018-07-31T04:22:32Z,nit: you can configure the ide to turn auto-newline-beyond-column-limit off :),1,0.8314725756645203
206392683,5201,guozhangwang,2018-07-31T04:36:58Z,nit: this.streamsgraphnode can be replaced with parentnode.,0,0.9893177151679993
206393083,5201,guozhangwang,2018-07-31T04:40:49Z,why change collection to set? the former is more generalized right?,0,0.9729361534118652
206393265,5201,guozhangwang,2018-07-31T04:42:32Z,the `streamsgraphnode#internalstreamsbuilder()` seems not used anywhere?,0,0.9869807362556458
206393456,5201,guozhangwang,2018-07-31T04:44:33Z,"ack, lgtm.",0,0.9864194989204407
206395841,5201,guozhangwang,2018-07-31T05:06:50Z,"i know it is cherry-picked from 's pr, but it seems we drops this type information in the logical streamsgraphnode anyways. maybe can comment whether we still need this?",0,0.986809492111206
206395968,5201,guozhangwang,2018-07-31T05:07:45Z,why we pass `null` before and now we need to pass in the `transformnode`? was it a bug before and we fixed it here?,0,0.9611998200416565
206396093,5201,guozhangwang,2018-07-31T05:08:34Z,nit: `processnode`.,0,0.9882975220680237
206397008,5201,guozhangwang,2018-07-31T05:16:05Z,"the comments here are a bit confusing: line 63 is for both globaltable-stream join and table-stream join, and line 66 is for table-stream join only.",-1,0.5374405980110168
206397146,5201,guozhangwang,2018-07-31T05:17:28Z,nit: selectkeymapnode.,0,0.9892371296882629
206397274,5201,guozhangwang,2018-07-31T05:18:43Z,"we did not add a new logical node here anymore in this pr, is this intentional?",0,0.9328472018241882
206397509,5201,guozhangwang,2018-07-31T05:20:37Z,nit: rename to `parentgraphnode`.,0,0.9883225560188293
206398136,5201,guozhangwang,2018-07-31T05:26:19Z,"these four graph nodes: thiswindowedstreamsnode, thisstreamsgraphnode, otherwindowedstreamsnode, otherstreamsgraphnode, seems not needed any more since we now use an ""umbrella"" joingraphnode that contains all the information, right? ditto for other join implementations. if it is indeed the case, then i'm wondering why our unit test does not fail, as it will unnecessarily add more processor nodes, and hence should cause some unit test to fail.",0,0.6707432866096497
206399370,5201,guozhangwang,2018-07-31T05:36:22Z,nit: groupbymapnode.,0,0.9865836501121521
206399786,5201,guozhangwang,2018-07-31T05:39:58Z,should be `optimizablerepartitionnode{ + super.tostring() + }`?,0,0.9878409504890442
206400130,5201,guozhangwang,2018-07-31T05:42:46Z,ditto here.,0,0.8612397909164429
206400597,5201,guozhangwang,2018-07-31T05:46:48Z,nit: since we have another class named `processornode` already could we still name it `statelessprocessornode`?,0,0.9896109104156494
206401093,5201,guozhangwang,2018-07-31T05:50:22Z,"the `streamsgraphnode#parentname` and here `parentnames` relationship is a bit awkward, as the only difference is for `merge`. could we just use `parentnames` on the `list streamsgraphnode` directly, and replace `setparentnode` with `addparentnode`. and in all other nodes we just call `addparentnode` only once, while for `merge` we call it twice for each fo the merging streams.",0,0.9522933959960938
206401149,5201,guozhangwang,2018-07-31T05:50:49Z,see my other comment above: we can replace this logic with the `addparentnode`.,0,0.9871024489402771
206401318,5201,guozhangwang,2018-07-31T05:52:07Z,i think this coding restyle is really not necessary.,0,0.8748103380203247
206401445,5201,guozhangwang,2018-07-31T05:53:16Z,"just to be general enough, we should just loop over all parent nodes from the list and add all their node names here.",0,0.9858652353286743
206401533,5201,guozhangwang,2018-07-31T05:53:56Z,why changing collection to list?,0,0.8967577219009399
206401753,5201,guozhangwang,2018-07-31T05:55:37Z,for line 35 above: see my other comment: `internalstreamsbuilder` seems not used anywhere.,0,0.9861637949943542
206402166,5201,guozhangwang,2018-07-31T05:58:28Z,"ditto above: if we take the underlying `streamsgraphnode` to have `list of parentnodes`, then for all such callers we will generalize to loop over all parent nodes and add their node names. although for now we will only have two parents for `merge`, and one parent for any other types.",0,0.9823006391525269
206402321,5201,guozhangwang,2018-07-31T05:59:35Z,the `storebuilder` should be templated as `storebuilder `. ditto elsewhere.,0,0.9758211970329285
206402481,5201,guozhangwang,2018-07-31T06:00:44Z,same here.,0,0.9813250303268433
206402673,5201,guozhangwang,2018-07-31T06:02:11Z,should we just do `final processortopology topology = builder.build();` and remove the line below? same elsewhere.,0,0.987445592880249
206402910,5201,guozhangwang,2018-07-31T06:03:58Z,nit: add final.,0,0.9837174415588379
206566399,5201,vvcephei,2018-07-31T15:06:46Z,nit: alignment is off.,0,0.9758564233779907
206566569,5201,vvcephei,2018-07-31T15:07:13Z,nit: alignment is off.,0,0.9758564233779907
206567717,5201,vvcephei,2018-07-31T15:10:00Z,nit: alignment is off.,0,0.9758564233779907
206567780,5201,vvcephei,2018-07-31T15:10:10Z,nit: alignment is off.,0,0.9758564233779907
206571206,5201,vvcephei,2018-07-31T15:18:46Z,nit: alignment is off.,0,0.9758564233779907
206571401,5201,vvcephei,2018-07-31T15:19:13Z,nit: alignment is off.,0,0.9758564233779907
206574955,5201,bbejeck,2018-07-31T15:28:16Z,ack,0,0.9720376133918762
206575220,5201,vvcephei,2018-07-31T15:28:59Z,"yeah, in this case, the type parameter is unused, and we're also suppressing warnings. i think we can either ditch the parameter or remove the suppression. fwiw, i have a todo after this pr is merged to make another pass to eliminate warnings and unnecessary suppressions, so feel free to just drop the type parameter, and i'll figure out whether the suppression is necessary later on. so as to not expand this pr further.",0,0.9593191742897034
206576264,5201,vvcephei,2018-07-31T15:31:34Z,"we were never actually using the graph before, right? so a missed node might go unnoticed until now, when we actually build the topology from the graph.",0,0.9693975448608398
206576886,5201,vvcephei,2018-07-31T15:33:19Z,this is (and was) a weird line break.,-1,0.9803304076194763
206577284,5201,vvcephei,2018-07-31T15:34:10Z,`notnullkeypredicate`?,0,0.9877579212188721
206586295,5201,bbejeck,2018-07-31T15:57:32Z,ack,0,0.9720376133918762
206586526,5201,bbejeck,2018-07-31T15:58:11Z,"can't recall, i think it was related to changes for optimization implementation, i'll revert for now.",0,0.885263204574585
206587699,5201,bbejeck,2018-07-31T16:01:11Z,"ack, removed edit: put back for now to avoid findbugs error.",0,0.9855502843856812
206591585,5201,bbejeck,2018-07-31T16:13:05Z,looking from the history looks like it was a bug but fixed here.,0,0.7313457727432251
206591870,5201,bbejeck,2018-07-31T16:14:02Z,ack,0,0.9720376133918762
206596270,5201,bbejeck,2018-07-31T16:27:39Z,"ack, updated",0,0.9853017926216125
206597007,5201,bbejeck,2018-07-31T16:29:54Z,ack,0,0.9720376133918762
206597490,5201,vvcephei,2018-07-31T16:31:23Z,"if so, then this comment would apply to all the other nodes as well.",0,0.9876196384429932
206599239,5201,vvcephei,2018-07-31T16:37:04Z,"i thought it was a little weird previously that `statefulprocessornode` extends `statelessprocessornode`, since subclassing is generally an ""is a"" relationship. so it was previously saying ""statefuprocessornode is a statelessprocessornode"", which is silly of course. maybe we can call it `processorgraphnode` to avoid a collision?",-1,0.9474103450775146
206600066,5201,vvcephei,2018-07-31T16:39:49Z,:+1: i think this was from my misinterpretation of the code style.,-1,0.5205230116844177
206601158,5201,bbejeck,2018-07-31T16:43:32Z,"yes, it's intentional. what i found during testing is that we don't need to create a node here. i initially had a logical node at this point, but it never rendered any details for the physical plan, as it's methods on the `kgroupedstreamimpl` that provide details for the next operation of the physical plan, thus we only need to create a new logical node when one of those operations are specified. when i did create a new logical plan node here, it contained no details to render, so i needed to put in checks for `null` `processorparameters`. having a placeholder node was somewhat probalmatic, so instead of a ""dummy"" node which i found to be confusing as well, i removed creating a new node at this point, and imho is better off this way.",0,0.9603245854377747
206603371,5201,vvcephei,2018-07-31T16:50:47Z,duplicate test line?,0,0.9756743311882019
206613580,5201,bbejeck,2018-07-31T17:21:48Z,ack,0,0.9720376133918762
206616617,5201,bbejeck,2018-07-31T17:30:27Z,ack,0,0.9720376133918762
206620359,5201,bbejeck,2018-07-31T17:41:30Z,"ack, reverted",0,0.9650743007659912
206620751,5201,bbejeck,2018-07-31T17:42:42Z,ack,0,0.9720376133918762
206640577,5201,guozhangwang,2018-07-31T18:41:11Z,"actually, my point is that the private `internalstreamsbuilder` field is not used anywhere either, so we can remove both this field as well as the getter function.",0,0.9847560524940491
206640980,5201,guozhangwang,2018-07-31T18:42:26Z,thanks for confirming :) just want to make sure it is not a regression.,1,0.9870277643203735
206641195,5201,guozhangwang,2018-07-31T18:43:13Z,thanks!,1,0.9308210611343384
206672496,5201,bbejeck,2018-07-31T20:28:50Z,"hmm, i'm not sure. while i agree with you that the `streamsgraphnode#parentname` and here `parentnames` relationship is a bit awkward but i think changing `setparentnode` to `addparentnode` can be equally as awkward. while i'm up for changing this in some way i'd prefer to leave how we establish the parent-child relationship the same, as we'd be making a cross-cutting change for just the `merge` case, and here it's isolated for just `merge`. edit: i get what you are saying, i'll try to change and see if i can get it to work. edit part ii: updated and implemented as you suggested, good call.",0,0.7104879021644592
206672618,5201,bbejeck,2018-07-31T20:29:12Z,replied above,0,0.9832709431648254
206674028,5201,bbejeck,2018-07-31T20:33:46Z,ack. but i think we need to come together on this as a team.,0,0.7322941422462463
206729312,5201,bbejeck,2018-08-01T01:15:36Z,"ack, done",0,0.9810035228729248
206729719,5201,bbejeck,2018-08-01T01:19:01Z,"out of convenience, reverted",0,0.792119026184082
206729744,5201,bbejeck,2018-08-01T01:19:15Z,"ack, updated",0,0.9853017926216125
206730023,5201,bbejeck,2018-08-01T01:21:47Z,"i think it's needed for optimization pr, but i'll remove here and will add back if necessary",0,0.9760097861289978
206731569,5201,bbejeck,2018-08-01T01:34:23Z,ack,0,0.9720376133918762
206732565,5201,bbejeck,2018-08-01T01:41:57Z,"actually, we still need both the `streamsbuilder.build()` call returns a `topology` while the `internaltopologybuilder.build()` returns a `processorytopology`. while the method names seem to be a bit overloaded, the terminology and methods pre-date this pr, so maybe we can do a follow-up pr to look at renaming and clarifying things some.",0,0.982194721698761
206733189,5201,bbejeck,2018-08-01T01:47:36Z,ack,0,0.9720376133918762
206737233,5201,bbejeck,2018-08-01T02:20:55Z,"the graph node is indeed required, and the tests are passing correctly. implementing the join for optimization was possibly the most ""intricate"" detail to get correct. previously when we generated the entire physical plan upfront, the parent names for the two `kstreamjoinwindow` instances were generated inside the `kstreamimpljoin.join` method and passed to the internalstreamsbuilder to wire up the processors. the first pass of the `streamstreamjoinnode` followed this approach, and everything was wired together in one operation. but the problem is with that approach we lose the ability to optimize any join nodes much for the same reason as before, we write everything required for the join to the `internaltopologybuilder` and lose any concept if optimization has occurred and what the new parent node is. either stream involved in a join can be eligible for optimization concerning repartitioning. in that case, we need to be able to use the updated parent node names for either or both of the `kstreamjoinwindow` instances involved in the join. so what has been done here is to add the two `kstreamjoinwindow` instances explicitly as child nodes of the two `kstream` instances passed as parameters from the `dojoin` method. the key point here is that one or both of the original `kstream` instances may have required a repartitioning. this fact requires us to explicitly attach the `kstreamjoinwindow` as a child node of the passed in `kstream` instance so if a repartition optimization does occur; the correct parent name is used by the `kstreamjoinwindow` when the physical plan is written. as for your question of adding too many processors, when traversing the graph the nodes representing the `kstreamjoinwindow` processors have their details written, but in the `streamstreamjoinnode` the previous calls writing the details for the `kstreamjoinwindow` processors out for the physical plan have been removed. thus the number of processors written out in the physical plan is correct.",0,0.896754264831543
206737456,5201,bbejeck,2018-08-01T02:22:56Z,ack,0,0.9720376133918762
206737468,5201,bbejeck,2018-08-01T02:23:04Z,ack,0,0.9720376133918762
206737593,5201,bbejeck,2018-08-01T02:24:13Z,ack,0,0.9720376133918762
206737755,5201,bbejeck,2018-08-01T02:25:41Z,ack,0,0.9720376133918762
206737805,5201,bbejeck,2018-08-01T02:26:04Z,ack,0,0.9720376133918762
206737992,5201,bbejeck,2018-08-01T02:27:35Z,ack,0,0.9720376133918762
206738254,5201,bbejeck,2018-08-01T02:29:41Z,"ack fixed, need to update intellij formatting",0,0.9842776656150818
206738426,5201,bbejeck,2018-08-01T02:30:29Z,ack,0,0.9720376133918762
206739044,5201,bbejeck,2018-08-01T02:33:00Z,ack,0,0.9720376133918762
206750808,5201,guozhangwang,2018-08-01T04:13:11Z,"ack, thanks for clarifying.",1,0.6102174520492554
206751900,5201,guozhangwang,2018-08-01T04:24:07Z,"my question is that, in this function we call the following `addgraphnode` calls: [code block] and in the returned `kstreamimpl` we passed in `joingraphnode`. note the `parentgraphnode` is passed as the latest node added to the topology for now, and hence it looks like although `thisstreamsgraphnode` and `otherstreamsgraphnode` each added a child, they do not have any parents, and hence these two ""branches"" are sort-of dangling as they are not connected to the topology graph at all.. could you maybe explain a bit more on this logic?",0,0.9689843654632568
206930443,5201,bbejeck,2018-08-01T15:38:42Z,"great question. in building the topology graph, it's not possible for a graph node to not have a parent. it is easier for me to explain the logic best with some examples. first, let's consider no repartitioning [code block] in this case we a repartition did not occur in `dojoin`, so the `thisstreamsgraphnode` and `otherstreamsgraphnode`, from the `lhs` and `other` `kstream` instances respectively, represent the graph nodes for `streama` and `streamb` and the parent node is `root`. anything created directly from the `streambuilder` always has the parent node of `root`. if a `kstream` instance is created by another upstream operation like `builder.stream(""topicb"").filter(...)` , then its parent would be the graph node representing the `filter` operation. in this case in the `thisstreamsgraphnode` and `parentgraphnode` are the same instance, and it ends up with two child nodes, the `thiswindowedstreamsnode` and the `joingraphnode`. i prefer to keep these two nodes separate as we don't need to keep track of repartitioning, i find the logic more clear to use the graph nodes from the `lhs` and `other` `kstream` instances. next repartitioning is required: [code block] now a repartition occurred in `dojoin` and the `thisstreamsgraphnode` is now a repartition graph node, with its parent being the `selectkey` graph node and the grandparent node is the original `streama` graph node. if `streamb` had required a repartition the parent-child structure would be the same, the `otherstreamsgraphnode` would be a repartition node with the parent being the graph node representing the key changing operation and the grandparent node representing the original `streamb` graph node. so at all times the `thisstreamsgraphnode` and `otherstreamsgraphnode` have parents of either `root` or some other upstream `kstream` operation and the `thisstreamsgraphnode` and `otherstreamsgraphnode` need to add the respective window stream processor graph nodes as children, so the physical plan is rendered correctly. does this make sense?",1,0.8689082264900208
1187976451,13639,jeffkbkim,2023-05-08T23:11:16Z,will this be changed to all groups once we begin implementing the old apis?,0,0.9874575734138489
1187980069,13639,jeffkbkim,2023-05-08T23:19:59Z,"nit: ""at least a subset""",0,0.982174277305603
1187980194,13639,jeffkbkim,2023-05-08T23:20:15Z,"nit: ""the member""",0,0.9698048233985901
1187981608,13639,jeffkbkim,2023-05-08T23:23:38Z,i'm wondering if this would hide the fact that ownedtopicpartitions should not be null.,0,0.9250792860984802
1187987623,13639,jeffkbkim,2023-05-08T23:38:27Z,"nit: ""has a larger member epoch"" a bug in setting the member epoch in the client side or in storing the epoch in the server side would result in the consumer never finding a coordinator right? if the client is expected to update its member epoch only from server side response then it seems that a server side bug would be more likely.",0,0.942267894744873
1187994938,13639,jeffkbkim,2023-05-08T23:56:47Z,(adding comment to this line since it's related) might be confusing things but shouldn't we include the partitions to revoke in the heartbeat response? i think i remember something along the lines that the consumer will calculate the diff from its view of the owned partitions vs. this heartbeat response and will try to revoke.,0,0.8512692451477051
1188015174,13639,jeffkbkim,2023-05-09T00:50:17Z,aren't these thrown in `throwifconsumergroupheartbeatrequestisinvalid` if it's not the first heartbeat request?,0,0.9823694825172424
1188024098,13639,jeffkbkim,2023-05-09T01:14:37Z,"i think adding what reconciliation we're doing at this stage would be helpful. also to confirm, target assignment records are actual diffs from a previous state whereas current assignment record holds the entire state right?",0,0.9699295163154602
1190415641,13639,jolshan,2023-05-10T21:35:49Z,maybe we can explain the mapping here.,0,0.9783546924591064
1190416089,13639,jolshan,2023-05-10T21:36:34Z,(i guess it is just name and assignor though),0,0.9823594689369202
1190417026,13639,jolshan,2023-05-10T21:38:00Z,or will we have another method for generic groups?,0,0.9834572672843933
1190428691,13639,jolshan,2023-05-10T21:56:05Z,what happens if we send an unsupported assignor on any request besides the first?,0,0.9710264205932617
1190433019,13639,jolshan,2023-05-10T22:03:23Z,"maybe slightly off topic, but just for my understanding topicpartitions is a data structure that contains topic id + partitions for that topic? reading this name, it was not immediately clear that these all belonged to the same topic. not a huge deal, but maybe something in naming that we missed and can think about amending in the future.",0,0.9322039484977722
1190436747,13639,jolshan,2023-05-10T22:10:11Z,could we also say we don't match if there is one or more owned partition that is not in the target set?,0,0.9832012057304382
1190445435,13639,jolshan,2023-05-10T22:26:47Z,i'm also a bit concerned by saying this error because it assumes we got a bump from another coordinator and could obscure bugs. it's good the thrown error at least mentions the epoch though.,0,0.6903126239776611
1190447106,13639,jolshan,2023-05-10T22:30:17Z,how do we continue from this state? do we eventually get a bumped epoch response?,0,0.975435197353363
1190454574,13639,jolshan,2023-05-10T22:46:37Z,it should be null on every request besides the first one right? this method handles both the first heartbeat and future ones though right? so it needs to handle null and non null fields?,0,0.9867523908615112
1190455545,13639,jolshan,2023-05-10T22:48:44Z,do we expect these changes to happen fairly often? is info a bit high of a log level?,0,0.9799739122390747
1190477811,13639,jolshan,2023-05-10T23:38:47Z,"is the incrementing on line 497 the only way groupepoch will be greater than the targetassignmentepoch? this is a little confusing to me since i would expect the target to be higher. i think saying generic ""groupepoch"" also confuses me about the source of the data.",-1,0.8275013566017151
1192164806,13639,clolov,2023-05-12T09:55:14Z,"i am most certainly missing a crucial piece of information, but the only mention i could find of a partition epoch is in the rejected alternatives of [a link]. has the need for this been discussed someplace else so i can have a further read?",0,0.7782856822013855
1192170321,13639,dajac,2023-05-12T10:00:38Z,"in this case, i need a method which returns a consumergroup. if we can reuse it, i am fine with this. otherwise, we can use another method and extracts some logic from this one.",0,0.9726423025131226
1192173471,13639,dajac,2023-05-12T10:03:46Z,reworked the comment.,0,0.9788752794265747
1192174161,13639,dajac,2023-05-12T10:04:29Z,`ownedtopicpartitions` can be null.,0,0.9800541400909424
1192179523,13639,dajac,2023-05-12T10:10:14Z,"this scenario could happen if a zombie coordinator is kept around. the consumer could get a higher epoch from the new coordinator and end up talking to the zombie by mistake (based on stale metadata). we did something similar in the controller in the part so i used the same approach here. this seems safe to me as the consumer should only learn a new epoch from the coordinator. of course, in case of a bug, this could become an issue. the alternative would be to be defensive and to fence the member in this case and force it to restart at epoch 0. the benefits of this option is that it is more robust but also more disruptive. should we be conservative in this case?",0,0.8862301707267761
1192180394,13639,dajac,2023-05-12T10:11:09Z,"i think that providing the expected assigned partitions is actually more robust because it forces the consumer to revoke all the other partitions, even the ones that we would not know about on the server side.",0,0.980643630027771
1192180723,13639,dajac,2023-05-12T10:11:31Z,correct. those could be `null` here as well.,0,0.9868646264076233
1192182531,13639,dajac,2023-05-12T10:13:24Z,reworked the comment.,0,0.9788752794265747
1192184441,13639,dajac,2023-05-12T10:15:39Z,good point. it should be checked there as well.,1,0.948699951171875
1192188074,13639,dajac,2023-05-12T10:19:34Z,"correct. `topicpartitions` contains a topic id and a list of partition ids. sure, we could consider renaming this.",0,0.9801605343818665
1192194658,13639,dajac,2023-05-12T10:27:10Z,right. the member will get a response with the correct epoch.,0,0.979658842086792
1192195549,13639,dajac,2023-05-12T10:28:12Z,they should be occasional. we log similarly in the current protocol and those logs are really helpful. we can lower them down in the future if they become an issue.,0,0.6941553950309753
1192198495,13639,dajac,2023-05-12T10:31:30Z,"at the moment, this is the only way but other ways will come. i think that it is safe to trigger the computation whenever the group epoch is larger than the target assignment epoch. we bump the group epoch when the group has changed (e.g. new members, new subscriptions, etc.). then, we update the target assignment when we detect that it is older than the group metadata. however, the member epoch should always be lower or equals to the target assignment epoch. regarding ""groupepoch"", i am not sure to understand your point. are you saying that the name is confusing?",0,0.8730013370513916
1192204200,13639,dajac,2023-05-12T10:37:34Z,this is indeed not in the kip because this is an implementation detail. we need to track epoch of partitions in order to know if they are free or not. an epoch with an old epoch basically means that the partition has not been revoked yet.,0,0.9857014417648315
1194138883,13639,jeffkbkim,2023-05-15T17:24:33Z,that's a great point. thanks,1,0.9900951385498047
1194141365,13639,jeffkbkim,2023-05-15T17:27:01Z,maybe topicandpartitions? topic partitions generally is used to refer to topic-partition tuples,0,0.986653745174408
1194145192,13639,jeffkbkim,2023-05-15T17:31:00Z,"maybe it would be good to include a comment on the relationship between the group, target assignment, and member epochs.",0,0.9797279238700867
1194151379,13639,jeffkbkim,2023-05-15T17:37:05Z,"actually the consumergroup fields, groupepoch and assignmentepoch, already have comments",0,0.9873396158218384
1194171285,13639,jeffkbkim,2023-05-15T17:55:33Z,is there a reason we use expectedsize = 1?,0,0.9823320508003235
1194188439,13639,jolshan,2023-05-15T18:10:17Z,i think the comment makes things a little clearer. but i guess my confusion was it seems like this should always cause the assignment to change. i think i also got a bit confused because on earlier prs i thought that the target assignment epoch was the epoch we get we at at when the assignment is complete. but maybe i am confused somewhere.,-1,0.7075337171554565
1194189770,13639,jeffkbkim,2023-05-15T18:10:57Z,should we throw an illegal state exception if new member is null?,0,0.9200027585029602
1194198701,13639,jolshan,2023-05-15T18:17:35Z,is this still a todo? ditto to above.,0,0.8439475893974304
1194201125,13639,jolshan,2023-05-15T18:19:32Z,this method is a bit long and complicated. in the comments (and maybe the javadoc for the method) could we break it up into logical chunks.,0,0.6085643768310547
1194201173,13639,jeffkbkim,2023-05-15T18:19:34Z,"""an"" immutable map",0,0.9779530167579651
1194207204,13639,jeffkbkim,2023-05-15T18:24:06Z,"nit: ""or -1 if the partition does not exist.""",0,0.9828068017959595
1194218869,13639,jolshan,2023-05-15T18:36:19Z,could we be a bit more specific in what each of these replays do? ie. for this one we update or remove a member depending on if the value is null. others set subscription metadata etc. i don't think the class names are enough to explain what each is doing -- especially since the names are so similar.,0,0.9721704721450806
1194225263,13639,jolshan,2023-05-15T18:42:15Z,"when we are in the state between making the assignment and installing it, how do we guard against generating new assignments? is this part of the state transitions?",0,0.9240089654922485
1194246241,13639,jolshan,2023-05-15T18:58:27Z,nit: an,0,0.9631584286689758
1194249412,13639,jolshan,2023-05-15T18:59:35Z,"can we say ""keyed by __""",0,0.9848745465278625
1194251237,13639,jolshan,2023-05-15T19:01:20Z,"this is ""updated"" because the member had changes and we want to use the assignor to make a new assignment?",0,0.9868708848953247
1194252036,13639,jolshan,2023-05-15T19:02:16Z,"nit ""replaces""",0,0.9783501625061035
1194368824,13639,jolshan,2023-05-15T21:13:28Z,i thought the java doc for timelinehashmap doesn't allow null values.,0,0.9800113439559937
1194380191,13639,jolshan,2023-05-15T21:28:27Z,can we reuse computesubscriptionmetadata here?,0,0.9893157482147217
1194394646,13639,jeffkbkim,2023-05-15T21:47:43Z,nit: replaces,0,0.9679281115531921
1194394856,13639,jolshan,2023-05-15T21:48:02Z,are the topic partitions not empty here? (like empty is different than null?),0,0.950566291809082
1194395409,13639,jeffkbkim,2023-05-15T21:48:58Z,"how's ""computes a new subscription metadata with a member's updated topic subscriptions""?",0,0.9849452376365662
1194397156,13639,jolshan,2023-05-15T21:51:41Z,i see we check for null or !empty.,0,0.9741942882537842
1194404457,13639,jeffkbkim,2023-05-15T21:58:32Z,nit: memberid is more readable for me. also from [a link] have we looked into this?,0,0.9809373021125793
1194427256,13639,jeffkbkim,2023-05-15T22:38:09Z,nit: javadoc on params,0,0.9870671629905701
1194427427,13639,jeffkbkim,2023-05-15T22:38:29Z,nit: javadoc on params,0,0.9870671629905701
1194427551,13639,jeffkbkim,2023-05-15T22:38:45Z,nit: javadoc on params,0,0.9870671629905701
1194427668,13639,jeffkbkim,2023-05-15T22:38:59Z,ditto on javadoc,0,0.9821701049804688
1194427886,13639,jeffkbkim,2023-05-15T22:39:21Z,nit: we can remove this,0,0.9871219992637634
1194430597,13639,jeffkbkim,2023-05-15T22:44:50Z,nit: does this have to be in its own line?,0,0.9725623726844788
1194432103,13639,jeffkbkim,2023-05-15T22:47:50Z,(not completely related) older record types i.e. groupmetadatavalue have camelcase field names. when did we change the format to upper camelcase?,0,0.9857075810432434
1194435189,13639,jeffkbkim,2023-05-15T22:54:06Z,"nit: ""it does not""",0,0.693166971206665
1194437607,13639,jeffkbkim,2023-05-15T22:58:42Z,what happens if the member id is not empty but the member epoch is 0 to indicate it's a new member? does this mean that the client can choose its member id? i don't think it should right?,0,0.9634546637535095
1194440425,13639,jeffkbkim,2023-05-15T23:04:18Z,nit: i think we should differentiate the member from the memberepoch. the member points to the existing member stored in the consumer group whereas the memberepoch points to the epoch of the member from the heartbeat request,0,0.9841984510421753
1194446025,13639,jeffkbkim,2023-05-15T23:16:30Z,nit: can we add a newline between the if statement and updatedmember?,0,0.9885962605476379
1194447475,13639,jeffkbkim,2023-05-15T23:19:39Z,can we do `for (consumergroupmember member : members.values()) {`?,0,0.9878214001655579
1194449829,13639,jeffkbkim,2023-05-15T23:25:01Z,"more of a comment for `consumergroup.preferredserverassignor()`, but we're iterating through all members to get the preferred assignor, every time we need bump the target assignment epoch. have we considered saving the count?",0,0.9852803349494934
1194455250,13639,jeffkbkim,2023-05-15T23:37:27Z,"we don't perform a reconciliation phase on leave group because once the existing members heartbeat, the metadata manager will notice the bumped groupepoch (l619) and so targetassignmentepoch < groupepoch will trigger the reconciliation. is this correct? why do we need to create target assignment records here then?",0,0.9834926128387451
1194457005,13639,jeffkbkim,2023-05-15T23:41:03Z,"i think targetassignments size does represent the number of members but shouldn't this be ""assignments"" or ""target assignments""?",0,0.9851130247116089
1194459578,13639,jeffkbkim,2023-05-15T23:46:13Z,i think we would want at least a way to detect that something is wrong since with the current approach the bug could go unseen.,0,0.9803565144538879
1194463847,13639,jeffkbkim,2023-05-15T23:56:59Z,"what's ""this""? that's right. the target assignment epoch is what every member will try to converge to by revoking/assigning partitions. once we build the target assignment, we bump the target assignment epoch (l532)",0,0.986330509185791
1194464178,13639,jeffkbkim,2023-05-15T23:57:46Z,i also think that would be very helpful,1,0.6860347986221313
1194465375,13639,jeffkbkim,2023-05-16T00:00:46Z,david can correct me but the coordinator will continue to compute new target assignments even if we're in the process of installing an existing one and the group would try to converge to the latest assignment,0,0.9860135912895203
1194477394,13639,jolshan,2023-05-16T00:27:22Z,"when we bump the group epoch, it seems like we will also always reassign. so i guess i was just trying to figure out if there is a case where the group epoch is different from the assignment epoch.",0,0.9711304306983948
1194479029,13639,jolshan,2023-05-16T00:31:08Z,ok. that's what i was expecting to happen. so if that's expected it is fine. i just wonder if it is extra work.,0,0.8648409843444824
1200087476,13639,dajac,2023-05-22T07:39:20Z,"yes, it is. this is part of another pr.",0,0.9751570224761963
1200129689,13639,dajac,2023-05-22T08:15:50Z,ack. let me expand the comments.,0,0.9520643949508667
1200134115,13639,dajac,2023-05-22T08:18:37Z,ack. i plan to rename those records but this will come when my main prs are merged.,0,0.9751377701759338
1200138816,13639,dajac,2023-05-22T08:22:14Z,that's correct.,0,0.974586009979248
1200143037,13639,dajac,2023-05-22T08:25:37Z,"right. this is ""updated"" because the member may have been updated so we need to use the latest (non-persisted) information from the member to select the correct assignor.",0,0.9870833158493042
1200145207,13639,dajac,2023-05-22T08:27:19Z,right but `compute` gives you `null` if the key is not present.,0,0.9875875115394592
1200149162,13639,dajac,2023-05-22T08:30:23Z,`computesubscriptionmetadata` is slightly different so i can't reuse it directly here.,0,0.9832656383514404
1200149897,13639,dajac,2023-05-22T08:30:59Z,the topic partitions should be an empty list when joining or re-joining.,0,0.9843041300773621
1200153306,13639,dajac,2023-05-22T08:33:53Z,i think that i should use `assignedpartitions.size()`.,0,0.9881961941719055
1200154967,13639,dajac,2023-05-22T08:35:12Z,we could.,0,0.9726674556732178
1200227960,13639,dajac,2023-05-22T09:12:37Z,`exist` is a bit misleading here as `-1` is returned if the partition does not have an epoch set.,0,0.9084289073944092
1200233059,13639,dajac,2023-05-22T09:16:45Z,i put it like this to follow the style of the other methods in this file.,0,0.9832417964935303
1200233985,13639,dajac,2023-05-22T09:17:32Z,i think that we have always been using upper camelcase in requests/responses. groupmetadatavalue is likely wrong here.,0,0.9362697601318359
1200235936,13639,dajac,2023-05-22T09:19:07Z,epoch equals to zero does not only indicate a new member. it also indicates a rejoining member. the member could indeed set the member id when it joins but it is not supposed to. it is a small quirk in the protocol.,0,0.9571247696876526
1200237262,13639,dajac,2023-05-22T09:20:08Z,that makes sense. let me use `receivedmemberepoch`.,0,0.9882072806358337
1200239503,13639,dajac,2023-05-22T09:21:58Z,let me put the condition on one line.,0,0.9853643774986267
1200293273,13639,dajac,2023-05-22T10:07:04Z,`memberid` is already used... let me check if keeping a map is worth it.,0,0.9761466383934021
1200402995,13639,dajac,2023-05-22T11:47:16Z,"i think that keeping a map of topicmetadata to member ids does not work because the content of topicmetadata could change as well. however, we could keep a map of topic name to number of subscribers. that would reduce the computation. i did the change. let me know what you think.",0,0.9735236763954163
1200415899,13639,dajac,2023-05-22T11:58:51Z,that's fair. we could remove it.,0,0.9538543224334717
1200462722,13639,dajac,2023-05-22T12:41:30Z,that makes sense. done.,0,0.9192262887954712
1200467372,13639,dajac,2023-05-22T12:45:37Z,it may be better to not do this after all. let me remove it for now in order to be on the safe side. we can always bring it back if we find it useful in the future.,0,0.9594714641571045
1202837929,13639,jolshan,2023-05-23T18:36:53Z,"so across all types of groups (generic, consumer) we can only have one type of group with a given name. we can't have a foo consumer group and a foo generic group. are we also enforcing this when we create groups? looks to be the case if we only create groups via getormaybecreateconsumergroup",0,0.9850558042526245
1202846284,13639,jolshan,2023-05-23T18:43:31Z,i see in the json comments for instance id: `null if not provided or if it didn't change since the last heartbeat; the instance id otherwise.` but this seems inconsistent with what we are saying here. it should only be provided in the first request?,0,0.9031902551651001
1202846585,13639,jolshan,2023-05-23T18:43:45Z,ditto for rack id,0,0.9700660109519958
1203077539,13639,jolshan,2023-05-23T22:08:38Z,"i'm not sure i follow `note the member is the persisted member anytime in this method` are we saying that the member is written to disk? or something else? i think the word ""anytime"" is confusing me.",-1,0.7660167217254639
1203079411,13639,jolshan,2023-05-23T22:10:12Z,do we want a log message for the first time joining the group?,0,0.9876099824905396
1203083017,13639,jolshan,2023-05-23T22:13:51Z,do we add a newmembersubscriptionrecord when the member is updated (not new) too?,0,0.9872085452079773
1203084630,13639,jolshan,2023-05-23T22:15:36Z,"i suppose the naming here with ""new"" and the usage below for `newgroupsubscriptionmetadatarecord` confused me.",0,0.9443539977073669
1203119594,13639,jolshan,2023-05-23T22:52:09Z,"rereading this and the kip -- is the only time we have a different assignment epoch from the group epoch is when assignment fails? i also assume that other members should learn about this assignment. i think i'm missing how that is done -- is this through the records methods? so for the next heartbeat request of another member, line 552 would see updatedmember.nextmemberepoch() != targetassignmentepoch as true since the group epoch and assignment epoch would be equal, but the member epoch would still be behind?",0,0.9238505363464355
1203132909,13639,jolshan,2023-05-23T23:08:24Z,would it be useful to have a helper method to delete a member?,0,0.9878599047660828
1203150079,13639,jolshan,2023-05-23T23:29:41Z,if the partition did not exist it would also be -1 though right? there's just two possible cases?,0,0.9836832880973816
1203152667,13639,jolshan,2023-05-23T23:32:36Z,"should we also mention in the java doc that we update the assignors here. i know we say in method, but maybe good to mention at the top too. (i was a little confused earlier why we needed both the new and the old members as parameters when this was called in the other class)",0,0.9781063795089722
1203158830,13639,jolshan,2023-05-23T23:40:12Z,is there a reason we use this method instead of put? shouldn't each topic name be absent?,0,0.973739504814148
1203181594,13639,jolshan,2023-05-24T00:01:53Z,"if we compute and return null, isn't that trying to set null values? or am i missing something.",0,0.5308172106742859
1203184877,13639,jolshan,2023-05-24T00:04:45Z,i guess i'm also wondering why we don't use empty set. unless this is because we want to overload null as mentioned in the getepoch method.,0,0.9519771933555603
1203192959,13639,jolshan,2023-05-24T00:11:42Z,ok so null is not ok -- it must be explicitly empty.,0,0.9778909683227539
1203222949,13639,jolshan,2023-05-24T00:35:51Z,do we also test that the other members also update their assignments?,0,0.9864423274993896
1203224577,13639,jolshan,2023-05-24T00:37:10Z,nit: member 2?,0,0.9776870012283325
1203225900,13639,jolshan,2023-05-24T00:38:17Z,i guess we sort of duplicate the code and test in testreconciliationprocess,0,0.9875134825706482
1203578132,13639,dajac,2023-05-24T07:17:06Z,that's right. we enforce this in `getormaybecreateconsumergroup`.,0,0.9877925515174866
1203601651,13639,dajac,2023-05-24T07:33:47Z,good catch. let me fix this.,1,0.9796533584594727
1203610206,13639,dajac,2023-05-24T07:39:48Z,i wanted to callout that `member` is different from `updatedmember` in this method but i think that the names are clear. let me remove that comment. it is more confusing than anything else.,-1,0.7756106853485107
1203610761,13639,dajac,2023-05-24T07:40:12Z,epoch 0 means that a new member joins or an existing member rejoins. let me update the log.,0,0.9887186288833618
1203611994,13639,dajac,2023-05-24T07:41:02Z,`new` means that a new record is created. a new record is created when the member is created or updated.,0,0.9836227297782898
1203615232,13639,dajac,2023-05-24T07:43:16Z,"we already have `consumergroup.removemember(memberid)` but it does not apply here. in this case, we really want to update the member with sentinel values.",0,0.9872289896011353
1203623275,13639,dajac,2023-05-24T07:46:37Z,i have clarified the javadoc.,0,0.9852069020271301
1203625806,13639,dajac,2023-05-24T07:47:54Z,it is a mistake. we can use `put` as you suggested.,-1,0.606926441192627
1203627084,13639,dajac,2023-05-24T07:48:37Z,that's right.,0,0.9678665995597839
1204465047,13639,jeffkbkim,2023-05-24T16:15:47Z,nit: the number of members supporting each server assignor name. is more readable to me,0,0.9823495745658875
1204467377,13639,jeffkbkim,2023-05-24T16:17:36Z,nit: the metadata associated with each subscribed topic name,0,0.9849543571472168
1204468514,13639,jeffkbkim,2023-05-24T16:18:36Z,nit: the target assignment per member,0,0.985903799533844
1204471728,13639,jeffkbkim,2023-05-24T16:21:27Z,"nit: it removes its partition epochs from this map. when a member gets a partition, it adds the epoch to this map.",0,0.9880246520042419
1204475716,13639,jeffkbkim,2023-05-24T16:25:01Z,"for this line and the following couple lines, does expected size of 0 create a hash table with size 1 as it's a power of 2? i'm confused because the expected size intuitively should not be 0.",0,0.8157928586006165
1204477868,13639,jeffkbkim,2023-05-24T16:27:01Z,"i think justine or someone else may have mentioned in another pr but for getters, just having the ` the current group epoch` makes more sense. i'm not sure if this line adds much value as well as for other getter methods",0,0.9496424794197083
1204492401,13639,jolshan,2023-05-24T16:40:28Z,"ok -- so the idea is member stays the same from when it is first ""gotten"", but updatedmember is the one we change through the method?",0,0.9871375560760498
1204493167,13639,jolshan,2023-05-24T16:41:11Z,i slowly figured this out as i read the pr. :grinning_face_with_sweat: did we also say earlier we were changing the record names?,-1,0.4843166172504425
1204494016,13639,jolshan,2023-05-24T16:42:05Z,"yeah, i suppose i was meaning a method to add the sentinel values. but if it is only done here, maybe it is not useful.",0,0.9536337852478027
1204494893,13639,jeffkbkim,2023-05-24T16:42:57Z,nit: returns the existing,0,0.9880622625350952
1204509686,13639,jeffkbkim,2023-05-24T16:54:37Z,do you think we should log something if topicimage == null? can both the topicsimage and/or subscribed topic names be outdated here?,0,0.9865152835845947
1204522037,13639,dajac,2023-05-24T17:06:23Z,"yeah, let me try to re-explain it with my words. basically, we have three epochs: the group epoch, the assignment epoch, and each member has its own epoch. - when the group changes (e.g. new member, updated subscription, etc), the group epoch is bumped in order to note that the topology of the group has changed. - when the assignment epoch is smaller than the group epoch, it means that the assignment for the group is stable so we need to recompute it. we generate a new assignment with the epoch matching the group epoch in order to note that the assignment is for the latest group topology. - when a member has a smaller epoch than the assignment epoch, it means that its assignment is stale so we need to reconcile it to converge it to that epoch. all the epochs are equal when the group is stable. this means that all the members have converged to the desired assignment. so for the next heartbeat request of another member, line 552 would see updatedmember.nextmemberepoch() != targetassignmentepoch as true since the group epoch and assignment epoch would be equal, but the member epoch would still be behind? yeah, we could have a difference between the assignment epoch and the group epoch when the assignment is not computed immediately. in the current implementation, we almost never have this but keep in mind that we will support client side assignors. in this case, the computation will take some time so we will see it more. the member learn about their assignment when they heartbeat. this is when we do the reconciliation process. we reconcile a member in two cases: 1) the member is not stable; 2) the target assignment has changed since the last time we reconciled the member. this is done [a link].",0,0.9235622882843018
1204523103,13639,dajac,2023-05-24T17:07:24Z,that's right.,0,0.9678665995597839
1204523524,13639,dajac,2023-05-24T17:07:52Z,i will do this but only when all my code is merged. it will create a mess otherwise...,-1,0.9394668936729431
1204535515,13639,jolshan,2023-05-24T17:19:36Z,i assume if we just got member1's partitions we would still be in assigning state.,0,0.9868472218513489
1204538473,13639,jolshan,2023-05-24T17:22:14Z,or i guess can we just get member1's partitions while member2 is still revoking?,0,0.9879107475280762
1204556978,13639,jolshan,2023-05-24T17:38:55Z,"just for my understanding, we will send the same request again when we receive the error. we will already have a group id and member id server side, and we will reuse them. ideally, the assignment works and we continue. is this correct?",0,0.9731089472770691
1204564082,13639,jolshan,2023-05-24T17:46:03Z,would it be helpful to use a new epoch here to see that it changes?,0,0.9859936237335205
1204571671,13639,jeffkbkim,2023-05-24T17:52:01Z,"after updating member 1 in l315, we have [code block] in serverassignors. preferredserverassignor() in l317 decrements ""range"" so the copy should have [code block] shouldn't this be `asserttrue(assignor.equals(optional.of(""uniform"")));`?",0,0.9875164031982422
1204579244,13639,jolshan,2023-05-24T17:58:03Z,is there ever a time the next member epoch is not the same as the member epoch?,0,0.9502127170562744
1204582235,13639,jolshan,2023-05-24T18:00:53Z,"would it make sense to also check member states here? i know we had something similar in the other file, but we are also testing the group states here.",0,0.9865678548812866
1204597635,13639,jolshan,2023-05-24T18:17:53Z,"if we have more than one assignor with the same max value, we choose one randomly (based on map iteration order). is this intended?",0,0.985562801361084
1204599222,13639,jolshan,2023-05-24T18:19:39Z,ah i see this below.,0,0.9576252698898315
1204607029,13639,jolshan,2023-05-24T18:26:24Z,preferredserverassignor not modifying the state was really throwing me off here. not sure if comments will help.,-1,0.9110808372497559
1204613085,13639,jolshan,2023-05-24T18:32:41Z,we aren't actually removing member1 here but computing what would happen if we did. this is a bit confusing to follow.,-1,0.9110162854194641
1204613762,13639,jolshan,2023-05-24T18:33:21Z,did we mean to have null instead of member3 here?,0,0.9805236458778381
1204623123,13639,jolshan,2023-05-24T18:43:16Z,we have member 2 as range and member 3 as uniform so that's why it is 50/50,0,0.9679259657859802
1204872093,13639,jeffkbkim,2023-05-25T00:13:04Z,i am curious as well. i notice 3 places [code block] that both set member epoch and next member epoch to `targetassignmentepoch`,0,0.9179030060768127
1204874200,13639,jeffkbkim,2023-05-25T00:18:00Z,"i'm confused because i was referring to member 2 here: range: 1 (member 2) uniform: 1 (member ~~1~~ 3) after `consumergroup.updatemember(updatedmember1);` in l315. in l317, we call `preferredserverassignor()` which gets a copy, then will decrement the count of ""range"" since member1 (range) is passed in as the oldmember argument. so shouldn't the count for ""range"" be 0? i think i'm missing something",-1,0.5380010008811951
1204875457,13639,jeffkbkim,2023-05-25T00:21:10Z,are we using this variable?,0,0.9863055944442749
1204877037,13639,jeffkbkim,2023-05-25T00:25:13Z,are we using this?,0,0.9835898280143738
1204878528,13639,jeffkbkim,2023-05-25T00:29:01Z,"can we use `targetassignment` and explain the mapping of member id to its assignment? ""assignments"" is ambiguous since we also have current assignments throughout the new protocol.",0,0.9856314659118652
1204879910,13639,jeffkbkim,2023-05-25T00:32:29Z,"btw, i was wondering if we could name this targetassignmentepoch. similar to my comment on `assignments`.",0,0.9801650047302246
1204881034,13639,jeffkbkim,2023-05-25T00:35:20Z,i think we can use put here too right?,0,0.9795209765434265
1204882557,13639,jeffkbkim,2023-05-25T00:39:25Z,are we using this?,0,0.9835898280143738
1204882590,13639,jeffkbkim,2023-05-25T00:39:32Z,are we using this?,0,0.9835898280143738
1204883474,13639,jeffkbkim,2023-05-25T00:41:49Z,"should these be `epoch`s? to me, offset seems more partition related.",0,0.9839956164360046
1204883836,13639,jeffkbkim,2023-05-25T00:42:51Z,i'm noticing a bunch of unused methods. are we planning to use these in the following prs?,0,0.9521504044532776
1204885916,13639,jeffkbkim,2023-05-25T00:48:17Z,we use a record key's raw version in recordhelpers. should we choose a convention to follow?,0,0.9883443117141724
1204889028,13639,jeffkbkim,2023-05-25T00:56:16Z,i think adding a comment above this line to indicate we're now testing a non-new/rejoining member will be helpful. and maybe a comment when we first start testing new/rejoining member's heartbeat requests,0,0.960870087146759
1204889641,13639,jeffkbkim,2023-05-25T00:57:56Z,this is `topicsimage.empty` right?,0,0.9829657673835754
1204903807,13639,jeffkbkim,2023-05-25T01:29:38Z,"curious, what happens if the member acknowledges but does not actually revoke i.e. a buggy client? would that member and the new owner of the partition fetch from the same partition? i'm guessing there's no guards against that",0,0.9602599143981934
1204907417,13639,jeffkbkim,2023-05-25T01:38:31Z,shouldn't the metadata manager respond with `assignedtopicpartitions`? what happens if the previous heartbeat respond was lost?,0,0.9810186624526978
1204909101,13639,jeffkbkim,2023-05-25T01:42:27Z,ditto on assignedtopicpartitions (and pendingtopicpartitions for member3),0,0.9859756827354431
1204909313,13639,jeffkbkim,2023-05-25T01:42:58Z,the revocation is acknowledging the new assigned partitions revoked from member 1 right?,0,0.9851572513580322
1204910503,13639,jeffkbkim,2023-05-25T01:45:42Z,why is the topic id ordering different here?,0,0.9341181516647339
1204914720,13639,jeffkbkim,2023-05-25T01:55:28Z,i think i'm getting confused here - do we create a new current assignment record whenever we respond back to a member? i might be remembering incorrectly but i thought the current assignment was created when the member transitions to stable (after revoking partitions and acknowledging assigned partitions),-1,0.5116722583770752
1205093788,13639,dajac,2023-05-25T07:16:03Z,"from the javadoc of `compute`: [code block] we don't keep the empty set because we want to clean the map. otherwise, it would keep sets for non-existing partitions for instance.",0,0.9885026216506958
1205138023,13639,dajac,2023-05-25T07:57:02Z,right.,0,0.9566289782524109
1205155041,13639,dajac,2023-05-25T08:11:49Z,sure.,0,0.9536533951759338
1205155348,13639,dajac,2023-05-25T08:12:06Z,right.,0,0.9566289782524109
1205156348,13639,dajac,2023-05-25T08:12:57Z,that's correct. -1 is returned when the partition is not in the map. this could be because the partition does not exist or because the partition does not have an epoch yet.,0,0.9850996136665344
1205157172,13639,dajac,2023-05-25T08:13:38Z,"as it is used only once here, it is not worth it in my opinion.",-1,0.7804127335548401
1205165820,13639,dajac,2023-05-25T08:21:08Z,"correct. yes, we can. member 3 gets member 1's partitions when the are available but it does not have to wait on member 2.",0,0.9833585619926453
1205169546,13639,dajac,2023-05-25T08:23:21Z,correct. the request will be retried with the group id and the member id (if the member already has one).,0,0.9846649765968323
1205178313,13639,dajac,2023-05-25T08:30:26Z,"that's right. there is only one case where it is not. when a member must revoke partitions, it stays in its current epoch so member epoch is different from the next epoch in this case. the rational of keeping track of the next epoch here is to basically prevent recomputing the state while the member is in revoking state. without it, we would have to recompute it on every heartbeat.",0,0.9702136516571045
1205203837,13639,dajac,2023-05-25T08:51:33Z,make sense.,0,0.9656602740287781
1205211076,13639,dajac,2023-05-25T08:57:20Z,the capacity will be 2 (the min capacity).,0,0.9754928350448608
1205218229,13639,dajac,2023-05-25T09:03:13Z,"i would not because it could be common to not have metadata about a topic yet. this will spam the logs. we will always use the latest topics image that we have got. the subscribed topic names is never outdated as it always represent the subscriptions provided by the consumer. however, it may not be known/exist yet.",0,0.9666911959648132
1205219753,13639,dajac,2023-05-25T09:04:28Z,correct.,0,0.9719478487968445
1205238390,13639,dajac,2023-05-25T09:20:29Z,updated the test. i had a mistake in these.,-1,0.7622506022453308
1205239034,13639,dajac,2023-05-25T09:21:03Z,i have renamed it to `computepreferredserverassignor`. now `preferredserverassignor` only returns what the group has.,0,0.9882922768592834
1205239532,13639,dajac,2023-05-25T09:21:29Z,i have put more comments. i hope it helps.,1,0.8603162169456482
1205247698,13639,dajac,2023-05-25T09:25:36Z,nope. let me remove it.,0,0.9511692523956299
1205248818,13639,dajac,2023-05-25T09:26:06Z,nope. removed.,0,0.8746764659881592
1205252133,13639,dajac,2023-05-25T09:28:54Z,nope.,0,0.8550663590431213
1205252262,13639,dajac,2023-05-25T09:29:01Z,nope.,0,0.8550663590431213
1205253148,13639,dajac,2023-05-25T09:29:44Z,right but this is what they are in the end in our context. keeping offset is better here.,0,0.9769922494888306
1205254844,13639,dajac,2023-05-25T09:31:08Z,i have removed all of them but this one. i will use it in the future.,0,0.9663131833076477
1205256385,13639,dajac,2023-05-25T09:32:26Z,"using the constants is fine here. in recordhelpers, i did not use them in order to not change the version by mistake.",0,0.979577362537384
1205264178,13639,dajac,2023-05-25T09:39:07Z,added comments.,0,0.9829500913619995
1205264648,13639,dajac,2023-05-25T09:39:30Z,right.,0,0.9566289782524109
1205266764,13639,dajac,2023-05-25T09:41:24Z,"that's right. this is basically a violation of the protocol. note that the previous owner won't be allowed to commit offsets. we can't do much at this protocol level. however, we could imagine passing the member epoch while fetching so the leader could reject stale member epoch. that would strengthen the overall protocol.",0,0.9664212465286255
1205271089,13639,dajac,2023-05-25T09:45:14Z,"the assignment is only provided in the following cases: 1. the member reported its owned partitions; 2. the member just joined or rejoined to group (epoch equals to zero); 3. the member's assignment has been updated. in the case of a lost response, the client would hit a timeout/network error. in this case, the client is expected to send a ""full"" heartbeat with the owned partitions set so it will get a ""full"" response.",0,0.9871662259101868
1205271405,13639,dajac,2023-05-25T09:45:29Z,see my previous reply.,0,0.9819321632385254
1205273140,13639,dajac,2023-05-25T09:46:58Z,"member 3 has nothing to revoke here. this comment is wrong, let me update it.",-1,0.8826019167900085
1205275881,13639,dajac,2023-05-25T09:49:21Z,hmm.. i don't know. let me check this.,0,0.786076545715332
1205278404,13639,dajac,2023-05-25T09:51:27Z,it is the other way around. we persist the current assignment when it changes based on the reconciliation. we provide the assignment to the client when the current assignment change.,0,0.9870093464851379
1206048854,13639,jolshan,2023-05-25T22:10:08Z,clarified offline -- null returned in compute removes the entry.,0,0.985029399394989
1206050414,13639,jolshan,2023-05-25T22:13:07Z,that's totally fair. just confirming :),1,0.9916316866874695
1206053946,13639,jolshan,2023-05-25T22:19:58Z,is nextmemberepoch a bit confusing here? it seems more like a target epoch.,0,0.7780154943466187
1206060783,13639,jeffkbkim,2023-05-25T22:33:47Z,nit: group size,0,0.9462621212005615
1206063165,13639,jeffkbkim,2023-05-25T22:39:03Z,"do we have a test case for this? i expect that when we accept a request with the previous epoch, we compute the diff from the request's owned partitions and the target assignment and respond to the consumer (assignedtopicpartitions, pending assignment if exists). which would be identical to what we do for the expected member epoch.",0,0.9866982102394104
1206064411,13639,jolshan,2023-05-25T22:41:41Z,this and the server assignor test are much more readable. thanks!,1,0.9843750596046448
1206066309,13639,jeffkbkim,2023-05-25T22:45:49Z,nit: existing and the new target assignment,0,0.9869912266731262
1206317753,13639,dajac,2023-05-26T07:02:21Z,"yeah, i agree. let me use `targetmemberepoch`.",0,0.9821793437004089
1206322259,13639,dajac,2023-05-26T07:07:55Z,"this is covered in `testconsumergroupmemberepochvalidation`. if the member comes with the previous epoch and its owned partitions is a subset of its assigned partitions, we accept it and it goes through the regular process. if nothing has changed since the last heartbeat, it will just receive the current assignment/epoch.",0,0.9883021712303162
178980194,4812,guozhangwang,2018-04-03T22:27:42Z,"i think you can still use the log4j format here, e.g. [code block] with four parameters, the last one is auto interpreted as the exception; maybe we can validate if this is the case.",0,0.9878309369087219
178981229,4812,guozhangwang,2018-04-03T22:32:42Z,"if it is a per-thread metric, i'd suggest we pre-register them at the beginning of the application. this way some other tools like `jmxtool` do not need to wait for the object name to show up. wdyt?",0,0.9878911972045898
179188828,4812,vvcephei,2018-04-04T15:42:45Z,"sounds good. i meant to make a comment before you read this to say that there had been a concern in the discussion about having metrics reported from processor nodes (when the proposal was at the node level) that would never actually skip records, thereby polluting the metrics. i thought i'd throw the lazy registration pattern in just to see what you all thought. i'll switch it back to pre-registration.",1,0.8585277199745178
179312182,4812,vvcephei,2018-04-04T23:24:35Z,"confirmed, switching to the variant you mentioned still prints: [code block]",0,0.9884569644927979
179586187,4812,guozhangwang,2018-04-05T20:09:33Z,"same here, we can get rid of `string.format`.",0,0.9885982275009155
179587232,4812,guozhangwang,2018-04-05T20:13:34Z,"we are stripping the prefix for this sensor: is it intentional? note that for jmx reporter, the sensor name would not be included in any fields.",0,0.9761897921562195
179587354,4812,guozhangwang,2018-04-05T20:13:59Z,"`skippedrecordssensor` should not be null, right?",0,0.9856898784637451
179589855,4812,guozhangwang,2018-04-05T20:24:03Z,"nit: flattening to a very long single line, is it intentional?",0,0.9106429815292358
179589896,4812,guozhangwang,2018-04-05T20:24:11Z,ditto below and in other tests like `testpauseresume`,0,0.9817588329315186
179590319,4812,guozhangwang,2018-04-05T20:25:54Z,nit: alignment.,0,0.9832351207733154
179590486,4812,guozhangwang,2018-04-05T20:26:32Z,ditto here.,0,0.8612397909164429
179590561,4812,guozhangwang,2018-04-05T20:26:52Z,ditto here.,0,0.8612397909164429
179590584,4812,guozhangwang,2018-04-05T20:26:58Z,here.,0,0.9788460731506348
179591415,4812,guozhangwang,2018-04-05T20:30:09Z,why do we remove this sensor?,0,0.9624488353729248
179592552,4812,guozhangwang,2018-04-05T20:34:32Z,should we record the thread-level `skipped record` sensor here?,0,0.9882027506828308
179592840,4812,guozhangwang,2018-04-05T20:35:43Z,"hmm.. i did not see we have recorded the sensor for deserialization error here, why this test passed?",0,0.8270983099937439
179626142,4812,vvcephei,2018-04-05T23:17:50Z,"heh, what a coincidence! i think so, and that's actually part of the motivation for this change i'm proposing to the metrics.",-1,0.728620171546936
179627246,4812,vvcephei,2018-04-05T23:26:31Z,"i disabled these tests because part of their function is to verify the number of metrics we register. this currently fails because we're registering a lot more metrics. if we decide to go with this overall strategy, i'll rethink these tests.",0,0.9186954498291016
179627503,4812,guozhangwang,2018-04-05T23:28:22Z,"just `implements internalstreamsmetrics` should be sufficient, since `internalstreamsmetrics` extends `streamsmetrics`?",0,0.9878563284873962
179771434,4812,bbejeck,2018-04-06T14:16:43Z,for `testlatencymetrics` and `testthroughputmetrics` maybe use `` instead ? not a big deal but by getting an `ignored` test count there's a better chance these two tests won't fall through the cracks.,0,0.9803547263145447
179774999,4812,bbejeck,2018-04-06T14:28:05Z,for the `task.addrecords` with a long list of `consumerrecord<>` seems like the only difference with each record is the offset. maybe create a method that takes an `int[]` with offsets and returns a `list `?,0,0.9879364371299744
179775146,4812,vvcephei,2018-04-06T14:28:31Z,"ah, yeah, in an earlier pass they were independent interfaces.",0,0.9807009696960449
179828056,4812,mjsax,2018-04-06T17:42:13Z,nit: remove `this`,0,0.9810076355934143
179828169,4812,mjsax,2018-04-06T17:42:41Z,nit: move `topology` to next line,0,0.9874640703201294
179830023,4812,mjsax,2018-04-06T17:49:58Z,"nit: add `final` to the parameters to cleanup code ""on the side""",0,0.9893039464950562
179830080,4812,mjsax,2018-04-06T17:50:08Z,nit: add `final`,0,0.9880309700965881
179830701,4812,mjsax,2018-04-06T17:52:31Z,"when would `skippedrecordssensor` be `null`? (i know this is just ""move"" code but still wondering why we need this)",0,0.9797096252441406
179831780,4812,vvcephei,2018-04-06T17:56:31Z,"ah, that's how you do it. i tried `(ignore=true)` like testng, but that obviously doesn't work...",-1,0.6758342385292053
179833851,4812,mjsax,2018-04-06T18:04:32Z,"because `info` level is default, should we remove `sensor.recordinglevel.info` in the above calls?",0,0.9893919229507446
179835194,4812,mjsax,2018-04-06T18:09:51Z,nit: is this suppression necessary? i don't think that gradle builds put a warning -- might be your local ide setting only?,0,0.9799858331680298
179835363,4812,mjsax,2018-04-06T18:10:36Z,nit: do we need this? (cf. my other comment about `suppresswarnings`),0,0.9799422025680542
179835676,4812,mjsax,2018-04-06T18:11:38Z,as above.,0,0.978552520275116
179835819,4812,mjsax,2018-04-06T18:12:14Z,as above.,0,0.978552520275116
179836521,4812,mjsax,2018-04-06T18:15:06Z,nit: `topic` -> `partitionsfortopic`,0,0.9867445826530457
179836693,4812,mjsax,2018-04-06T18:15:47Z,nit: `partitions` -> `partitionsforchangelog`,0,0.9874870777130127
179838008,4812,mjsax,2018-04-06T18:20:42Z,very nice!,1,0.986493706703186
179872407,4812,vvcephei,2018-04-06T20:49:38Z,it won't. that's an artifact that i need to fix.,0,0.8367155194282532
179872830,4812,vvcephei,2018-04-06T20:51:34Z,"meh. i personally favor explicit settings, so if anything, i'd actually add it here, but i'm happy to do whichever you all prefer.",1,0.9481261968612671
179873240,4812,vvcephei,2018-04-06T20:53:25Z,"yeah, i have my ide set on paranoid mode. i can disable this inspection if you don't want to see supressions like this. or i can inline the parameter value, which is what the inspection was complaining about.",0,0.5104480981826782
179873711,4812,vvcephei,2018-04-06T20:55:39Z,"double-brace initialization is actually not great for a number of reasons. i've been terrraforming it whenever i encounter it, but for some reason i decided to suppress this one instead. i'll plan to remove the suppression and the double-brace initialization in the final draft.",-1,0.6454182267189026
179873858,4812,vvcephei,2018-04-06T20:56:24Z,thanks!,1,0.9308210611343384
179885340,4812,vvcephei,2018-04-06T21:56:56Z,"during `thread.runonce(-1);`, it'll encounter an exception ""asdfasdfasdf"" as an integer and increment the metric.",0,0.988139271736145
179885776,4812,vvcephei,2018-04-06T21:59:23Z,it was not. i've fixed it.,0,0.9540345072746277
179886374,4812,vvcephei,2018-04-06T22:03:30Z,fixed.,0,0.9810503125190735
179886390,4812,vvcephei,2018-04-06T22:03:38Z,it was when i made it lazy. i've fixed it.,0,0.8920764327049255
179893704,4812,mjsax,2018-04-06T22:56:44Z,"i am fine with removing the overload that has a default and add info explicitly here. (to me, it's more about consistency---i immediately assume that this sense is different to the others, even if it's not if the code pattern is different).",0,0.9666270613670349
179893837,4812,mjsax,2018-04-06T22:58:03Z,"i personally would prefer getting rid of the annotation -- to me, annotations are noise in the code and distracting.",-1,0.8456611037254333
179893976,4812,mjsax,2018-04-06T22:59:10Z,for my own education: why? refactoring is fine with me.,0,0.9545829892158508
179929221,4812,mjsax,2018-04-07T22:12:01Z,why this change?,0,0.7813909649848938
179929312,4812,mjsax,2018-04-07T22:17:23Z,nit: do we need to `[]` around each value? `[]` is used for collections or list -- might be confusing to add them?,0,0.9839170575141907
179929318,4812,mjsax,2018-04-07T22:17:38Z,as above.,0,0.978552520275116
179929326,4812,mjsax,2018-04-07T22:18:01Z,as above.,0,0.978552520275116
179929377,4812,mjsax,2018-04-07T22:18:23Z,nit: remove space,0,0.9679564833641052
179929389,4812,mjsax,2018-04-07T22:19:24Z,nit: indention,0,0.7653846144676208
179929538,4812,mjsax,2018-04-07T22:26:03Z,"nit: move `new file` to new line for consistent formatting (note, that `processorstatemanager.checkpoint_file_name)` is second parameter of `file` constructor.",0,0.9897379279136658
179929549,4812,mjsax,2018-04-07T22:26:46Z,as above.,0,0.978552520275116
179929590,4812,mjsax,2018-04-07T22:28:52Z,did this slip? or did you leave it intentionally?,0,0.8284428715705872
179929609,4812,mjsax,2018-04-07T22:29:56Z,did this slip?,0,0.8697061538696289
179929657,4812,mjsax,2018-04-07T22:33:29Z,"adding this implies, that we have to maintain the same code twice. should we extract this into some internal method that we can call here to avoid code duplication? what about other thread-level metrics?",0,0.9821532368659973
179929685,4812,mjsax,2018-04-07T22:35:09Z,for my own education: what is this? (btw: can we remove `this` below?),0,0.9762974977493286
180160009,4812,bbejeck,2018-04-09T16:50:49Z,"nit: i realize this was pre-existing in a single line, but since there are several parameters, maybe put each param on its own line.",0,0.9830938577651978
180167095,4812,bbejeck,2018-04-09T17:16:08Z,"super nit: what about `asserttrue((double)metrics.metric(skippedratemetric).metricvalue() > 0.0);` however, i don't have a strong opinion in this one.",0,0.7360950112342834
180172747,4812,vvcephei,2018-04-09T17:35:53Z,it's a private method with an unused return value. making it void helps the reader to understand the code without having to trace through usages.,0,0.9853770136833191
180176820,4812,vvcephei,2018-04-09T17:50:26Z,"good question. i have developed the habit of delimiting variables in log messages, as it disambiguates the structure of the message for the reader. without delimiters, there are several edge cases that would make the log message difficult to read. for example, if the key were `""value""` and the value were `""""` with the old format, you get: [code block] whereas, if the key were `""""` and the value were `""value""`, you get [code block] the only difference between these strings is where the extra space is. with delimiters, you have: [code block] it's the kind of thing that saves people from #1 making a bad assumption about the nature of the problem and burning hours before they realize their mistake, or #2 being unable to clearly understand the error message and having to load it in a debugger just to understand what the values of the arguments actually are. it sounds like your concern is about the ambiguity of `[]` as delimiters, since they already indicate a list. can we keep delimiters but pick a different character? other paired delimiters are `<>` and `{}`, and `""""` and `''` also come to mind. wdyt?",1,0.8554922342300415
180180359,4812,vvcephei,2018-04-09T18:02:43Z,"i've been mulling over the same thing, and that was part of what i was trying to achieve with my experiment before. i think i have a better solution now, so maybe you can take another look after my next update and see what you think.",0,0.762558102607727
180183446,4812,vvcephei,2018-04-09T18:13:40Z,"that also works, but `assertnotequals` is a little nicer in that it'll print the actual value on failure, whereas `asserttrue` only tells you that it was `false` on failure. i suppose i could add a utility method `assertgreater` that prints the values on failure, but in this case, i'm really just making sure that the metric got moved. i don't care that much to assert what it got moved to, or i would override the time implementation and assert the exact expected value.",-1,0.760016143321991
180183779,4812,vvcephei,2018-04-09T18:14:53Z,"we can remove `this` below. the weakeraccess inspection tells you that it's possible to restrict the access scope of `cancel()`. i think this particular case was warning me that `cancel()` could be package-private instead of public. but the static analyzer can only look at the code in the project. we know that we do want the method to be public, so i added a supression for this inspection. an alternative would be to write black-box tests in a different package (just like real user tests would be), and the static analyser wouldn't warn us anymore, since it would have an example of a usage requiring public access.",0,0.9805808067321777
180195011,4812,mjsax,2018-04-09T18:54:07Z,"i personally thank, that having `=` (without `[]`) is good enough as the `=` makes it clear: [code block] thus, it's not ambiguous to me (i agree that having no delimiter at all would be bad). it's just that i like uniform formatting, and this would introduce a new style -- i am fine with change to this style, but we should agree on one style and rewrite code (on the side) if it does not fit the 'style guide'. \cc",1,0.9113274812698364
180196390,4812,mjsax,2018-04-09T18:59:05Z,"will do, after you pushed an update :)",1,0.9081630706787109
180238210,4812,guozhangwang,2018-04-09T21:34:54Z,"i'm do not feel very comfortable to define the metrics name in scattered places, because it means whenever we'll update the name we have to remember to update all the places (for this sensor the other place we declared it is [code block] so which line gets called first, it will create the sensor, while keeping the other just as an no-op. ), and that's why i liked 's proposal for wrapping the sensor names in the leveled metrics, and passing those metrics across different modules than re-declaring the sensors in different places. this makes me feel more urgent to do the refactoring of the metrics hierarchy.",-1,0.8296757340431213
180239208,4812,guozhangwang,2018-04-09T21:39:14Z,"i tend to prefer `key=[value]`, but i do not have a scientific reason for that: i just feel it is more ""vivid"" :p",1,0.9038844108581543
180239876,4812,guozhangwang,2018-04-09T21:41:57Z,"again, if we could pass around the `threadmetrics` here, it will make the code more readable: we can make it very clear at which places we record some task metrics like `taskmetrics.sensora.record()` and where do we record thread-level metrics like `threadmetrics.skippedrecordssensor.record()`. but i think it is better to be left as a follow-up pr as this one is already pretty big.",0,0.9041544795036316
180240234,4812,guozhangwang,2018-04-09T21:43:20Z,nice improvement,1,0.9079623818397522
180243194,4812,vvcephei,2018-04-09T21:56:21Z,"yeah, i keep getting wrapped around the axle thinking about stuff like this. hopefully, i'll be able to deliver a reasonable implementation for this pr, and i'll continue to mull about a way to pass the right metric context around the code base.",-1,0.5325648188591003
180243791,4812,vvcephei,2018-04-09T21:59:20Z,"i'm about to push a commit to put the skipped-records sensor in particular in a common place, since it winds up getting accessed from so many different places in the code. i'm hoping that will be good enough for now, and we can seek an elegant enclosing-scope metrics implementation in the future.",0,0.9022725224494934
180246639,4812,vvcephei,2018-04-09T22:12:53Z,"i can dig the desire to have uniform style on log messages. i'll also point out that the logs are part of the public api, so we can't just go terraform them willy-nilly, but instead we'd have to change them only in scope of the relevant kips, which makes it difficult to change, or even establish, a log style. nevertheless, if we don't already have a clear style for streams logs, i'll advocate for some kind of enclosing delimiter on substitutions. i continue to agree that square brackets are confusing w.r.t. common `list#tostring()` formats, so i think we should agree on a different enclosing delimiter. i agree that `=` is better than nothing, but it's still ambiguous when the substitution is 0 or more whitespace characters, while `[]` vs `[ ]` gives you more of a clue. no choice here is going to be perfect, but my experience is that this format saves enough debugging time to be worth the visual noise.",0,0.8254767060279846
180576030,4812,guozhangwang,2018-04-10T21:39:40Z,"what's the purpose of keep track of the metric names? if it is for preventing double-registering, i think relying on maintaining the metrics name inside the sensor would not always work, since multiple sensors would be added into the `metrics` registry, and we still cannot prevent different sensors trying to register the same metrics.",0,0.9714840054512024
180576708,4812,guozhangwang,2018-04-10T21:42:38Z,we do not need the non-arg constructors since it will be defined by default.,0,0.9860921502113342
180577126,4812,guozhangwang,2018-04-10T21:44:29Z,no callers seem to provide any non-empty `tags`?,0,0.9816531538963318
180577282,4812,guozhangwang,2018-04-10T21:45:10Z,ditto here.,0,0.8612397909164429
180577454,4812,guozhangwang,2018-04-10T21:45:56Z,"if we always create the skipped record sensor upon creating the thread, then we should always get the sensor right? if that case, should we simply throw if the `getsensor` returns null?",0,0.9852460026741028
180578491,4812,guozhangwang,2018-04-10T21:50:26Z,"this is a meta comment: i think we have seen two approaches here: 1. pass along the metrics objects across different modules (in some classes, we will pass multiple metrics objects for different levels, like threadmetrics and taskmetrics) in order to record their sensors. 2. in the current pr: only pass alone the metrics registry (i.e. the `metrics` object) along different modules, but standardize the sensor name construction, and get the sensor by its raw name directly whenever necessary to record the sensor. i am slightly in favor of the second one since we could pass long fewer parameters, i.e. only a single `metrics` object which can be accessed 1) from processorcontext, 2) in multiple internal classes.",0,0.9268947839736938
180578769,4812,guozhangwang,2018-04-10T21:51:35Z,this is a detailed comment: what's the rantionale of naming it `commonstreamsmetrics`? is it for thread-level metrics only? i.e. should we just move this static function into `threadmetrics`?,0,0.9866487383842468
180607694,4812,mjsax,2018-04-11T00:47:33Z,"we never discussed this explicitly; it's just a matter of fact that we use `key=value` so far from what i can remember. the question is, how much we gain if we start to rewrite to a different format and how much work it it. with regard to ambiguity: you can always construct an (academic?) example for which any formatting strategy ""break"" and is ambiguous... if we agree on `key=[value]` i am fine with it. still not sure, if we gain much (but if you think we do, it's fine with me to change)",0,0.7540865540504456
180815261,4812,vvcephei,2018-04-11T16:20:42Z,"i have pulled this change into a separate pr: [a link] the intent is to make it a no-op if you add the same metric to the same sensor twice, as opposed to the current behavior, in which the `registry.registermetric(metric)` throws an exception if the metric is already registered. with this change, you'll still get an exception if the metric is already registered in another sensor, but if it's already in the same sensor, you just get a no-op success.",0,0.9778628349304199
180815535,4812,vvcephei,2018-04-11T16:21:38Z,"this privatizes the constructor, guaranteeing that the class cannot be instantiated. it's a way of enforcing that the class be used only for its static members.",0,0.9827577471733093
180815880,4812,vvcephei,2018-04-11T16:22:44Z,"it's laying the groundwork for a future change in callers can compose thread-level tags, task-level tags, etc.",0,0.9862580299377441
180816071,4812,vvcephei,2018-04-11T16:23:20Z,"to do this properly, though, the class should also be final. i'll make that change.",0,0.9676757454872131
180816181,4812,vvcephei,2018-04-11T16:23:38Z,same rationale.,0,0.9750064015388489
180817574,4812,vvcephei,2018-04-11T16:28:17Z,"this method is used to idempotently create or retrieve the sensor. in other words, the mechanism by which we create the sensor when we create the thread is that it calls this method, and the sensor is null, so it creates it. you're correct in that if we do that, then all other usages will just return the existing sensor. i'm not sure i see the value in separating creation from retrieval so that we can throw an exception if you retrieve it without creating it first.",0,0.9614967107772827
180824861,4812,vvcephei,2018-04-11T16:51:39Z,"yeah, i'm still undecided on whether approach 1 or 2 is better. but i did decide that i don't want to make a call on it in this pr. if you'd like me to resolve this sooner rather than later, i can follow up immediately with another pr to reorganize the metrics. the reason i pulled skipped-records out into a commonstreamsmetrics class is that that metric is common across all components in streams. it's accessed by both our framework-level code and also by the user-space dsl-provided processors. thus, it needs to live in a spot where all those components have visibility on it. there's a distinction between metrics that are aggregated at the thread level and metrics that belong to `streamthread`. it'll be difficult to really do a good job in this pr with that distinction, though, without refactoring the whole metrics hierarchy. since we're already over 2,000 loc, i'd really like to move such a refactoring to another pr. what i have done in this pr is as minimal as i can manage to expose the skipped-records sensor to our processors.",0,0.7199392318725586
180866308,4812,bbejeck,2018-04-11T19:09:05Z,"i also prefer `key=[value]`, but can't say it's for any specific reason other than personal preference.",0,0.9687605500221252
180870195,4812,bbejeck,2018-04-11T19:23:52Z,is this line intentional?,0,0.8850133419036865
180870791,4812,bbejeck,2018-04-11T19:26:16Z,"the `hasitem` matcher is new to me, nice one!",1,0.990487277507782
180876468,4812,bbejeck,2018-04-11T19:47:38Z,"do we need a separate class for this? we could add the `getmetricbyname` method to `streamstestutils` instead, additionally, it doesn't access anything package private so it should be fine to make the method public",0,0.9855089783668518
180878303,4812,bbejeck,2018-04-11T19:54:39Z,"meant to say this before, nice addition!",1,0.9799050092697144
180930916,4812,vvcephei,2018-04-11T23:50:42Z,oops. i put it there when i needed a place for a breakpoint. sorry!,-1,0.9910950660705566
180931250,4812,vvcephei,2018-04-11T23:53:06Z,"thanks! it's predicated on us using log4j as the implementation for slf4j in the unit tests, so if that changes, we'll have to put in a different log appender. but that seems unlikely, and it's handy to have this in the mean time.",1,0.973124086856842
180932520,4812,vvcephei,2018-04-12T00:01:29Z,"i can move it to streamtestutils if you like. i made `getmetricbyname` package-private to prevent other code from calling it, since it's intended for these tests only. making it public would open this method up to be called beyond the intended scope. i'd rather defer that until we have a use case we think calls for broadening the scope.",0,0.9796604514122009
181250474,4812,guozhangwang,2018-04-12T23:26:24Z,"thanks for the explanation, that makes sense.",1,0.5615201592445374
181250828,4812,guozhangwang,2018-04-12T23:28:41Z,"i had another meta question while discussing offline, and i'll leave it here for discussion: since different meters belong to the different metrics levels, should we move these static functions to the corresponding `xxmetrics` instead? i'm thinking about that since we have some meters that exist in multiple levels, like commit rate. in the future if we move them all to this class then we need to get one function for each level as their tags naming conventions are different, and hence it is not really `common` streams metrics.",0,0.961886465549469
181251041,4812,guozhangwang,2018-04-12T23:30:03Z,similar to my other comment on `commonstreamsmetrics`: could we move these static functions to the corresponding level metrics class?,0,0.9884555339813232
181252004,4812,guozhangwang,2018-04-12T23:36:39Z,"i'd suggest in the future try to only piggy-back different changes into the same pr if we think they are either correlated or if they are really trivial. having a single pr mingled with multiple changes has several drawbacks: 1. it makes git history a bit harder to trace: think, ""git blame"" would be tricker to reason. 2. it tends to generate bigger prs than necessary, making reviewer less willing to start working on them :p 3. if multiple rounds of reviews are needed, even requiring major code refactoring, it will surprisingly introduce regressions during those iterations as by-products of the multiple changes.",1,0.9152353405952454
181252540,4812,guozhangwang,2018-04-12T23:40:36Z,i'm not sure why we need to pass around `streamsmetricsimpl` from streamthread to everywhere else now?,0,0.8421563506126404
181410527,4812,vvcephei,2018-04-13T14:43:21Z,"previously, we passed around the interface only to cast it back to `streamsmetricsimpl` in line 80 of this file. all i did was make taskmetrics declare that it really does want a `streamsmetricsimpl` instead of a `streamsmetrics` explicitly. if we're going to cast it anyway, why not just use the type system?",0,0.9869285225868225
181412307,4812,vvcephei,2018-04-13T14:49:06Z,"i thought it would be nice if the metrics naming conventions were all in one place, to help us maintain consistency. right now, we have one (internal) naming convention enforced via our (public) metrics api: `streamsmetrics`, but we also have a bunch of metrics with no defined naming convention declared, e.g., in `streamsmetricsthreadimpl`. i think it'll be simpler for people to use the metrics if we maintain consistency throughout the whole streams code-base, and it'll be simpler to maintain consistency if we keep all the naming conventions in one file.",0,0.8621135354042053
181424139,4812,vvcephei,2018-04-13T15:25:18Z,"there are two different concepts of belonging in play here. 1. grouping: a metric ""belongs"" to the thread level if it's aggregated at that level 2. ownership: a metric ""belongs"" to the thread level if streamthread needs a reference to it. grouping and ownership are orthogonal here. there are several metrics that are aggregated at the thread level and are also owned by streamthread, like the committimesensor. grouping is easy to determine; all you have to do is look at the metric name. to tell that committimesensor is owned by streamthread, you can trace the references to the sensor. it's never passed outside of streamthread, so it's owned by streamthread. other metrics are still grouped by thread but owned by other classes, such as the taskcreatedsensor. all of streamthread, abstracttaskcreator, taskcreator, and standbytaskcreator have references to this metric, so they all share the ownership. now that i'm looking at it, streamthread never uses the reference, so it could be owned only by abstracttaskcreator and its children. finally, we get to the skippedrecordssensor. this metric is still grouped by thread, but ownership is shared among 14 classes. two of them are framework classes (globalstreamthread and streamthread), and 12 of them are user-space processor classes. since ownership for skippedrecordssensor is so dispersed, i decided to just make its ownership global, aka common. anything in the entire streams codebase can get a reference to the skippedrecordssensor. i wouldn't move all the metrics into the global ownership space just because i moved one, and i wouldn't give streamthread a reference to a metric just because that metric happens to be aggregated by thread. am i making sense?",0,0.9638402462005615
182273476,4812,guozhangwang,2018-04-17T23:43:48Z,"i understand the separation of ownerships of metrics, my question is: right now the `skippedrecordsmeter` assumes this metric is grouped at the thread-level, and hence the second parameter is a `threadname`. what if in the future we add a per-task level `skippedrecordsmeter(final metrics, final taskid)`? would that be put in this `commonstreamsmetrics` as well? practically speaking either is fine, and i think i was originally leaning towards not having a `commonstreamsmetrics` conceptually since that for each meter, it is going to be aggregated at a specific layer anyways. but if people think that it is better of having a `commonstreamsmetrics` where we put these metrics so that all dependent classes would just depend on `o.a.k.streams.processor.internal.metrics`, i'm fine with it as well.",0,0.8984944820404053
182274054,4812,guozhangwang,2018-04-17T23:47:54Z,ditto.,0,0.859873354434967
182274130,4812,guozhangwang,2018-04-17T23:48:31Z,"since we will have a different kstreamwindowreduceprocessor for each topology, each task, each thread, the thread.currentthread() will always be the same; it is okay to get the meter at the constructor and cache it, than trying to search for it in the registry each time. ditto below.",0,0.9545861482620239
182274177,4812,guozhangwang,2018-04-17T23:48:46Z,ditto.,0,0.859873354434967
182274189,4812,guozhangwang,2018-04-17T23:48:53Z,ditto.,0,0.859873354434967
182274204,4812,guozhangwang,2018-04-17T23:49:00Z,ditto.,0,0.859873354434967
182274440,4812,guozhangwang,2018-04-17T23:50:36Z,ditto.,0,0.859873354434967
182274531,4812,guozhangwang,2018-04-17T23:51:12Z,ditto.,0,0.859873354434967
182274558,4812,guozhangwang,2018-04-17T23:51:21Z,ditto.,0,0.859873354434967
182275004,4812,guozhangwang,2018-04-17T23:54:24Z,ditto.,0,0.859873354434967
182275021,4812,guozhangwang,2018-04-17T23:54:31Z,ditto.,0,0.859873354434967
182275061,4812,guozhangwang,2018-04-17T23:54:41Z,ditto.,0,0.859873354434967
182275088,4812,guozhangwang,2018-04-17T23:54:53Z,ditto.,0,0.859873354434967
182275337,4812,guozhangwang,2018-04-17T23:56:46Z,do we need to pass the sensor all the way down here? could we fetch it from the `commonstreamsmetrics` directly as well? note that each thread will create its own `recorddeserializer` objects that are exclusively owned by the thread itself.,0,0.9895142316818237
182275382,4812,guozhangwang,2018-04-17T23:57:02Z,please see my comment in `recorddeserializer`,0,0.9857404828071594
182275534,4812,guozhangwang,2018-04-17T23:58:07Z,this import is not needed?,0,0.9858779907226562
182275652,4812,guozhangwang,2018-04-17T23:58:50Z,"similar as above, do we still need to pass this sensor along, than getting it from `commonstreamsmetrics` directly?",0,0.9876012802124023
182275731,4812,guozhangwang,2018-04-17T23:59:27Z,as above in `recorddeserializer`.,0,0.9881770014762878
182275826,4812,guozhangwang,2018-04-18T00:00:09Z,ah right. thanks.,1,0.8765627145767212
182275969,4812,guozhangwang,2018-04-18T00:01:17Z,"same as above, could we just get it from `commonstreamsmetrics` now?",0,0.9891300201416016
182276400,4812,guozhangwang,2018-04-18T00:04:31Z,could you point to me where do we remove this sensor upon shutting down now?,0,0.9875952005386353
182276649,4812,guozhangwang,2018-04-18T00:06:46Z,why passing `threadclientid` twice?,0,0.9515940546989441
182277627,4812,guozhangwang,2018-04-18T00:14:01Z,actually i've been thinking .. could we move the construction of the `taskmanager` and its `taskcreators` into the constructor of `streamthread` directly from `create` call? then we can get the threadname from `currentthread.name()` directly and do not need to pass this parameter around any more.,0,0.9822378754615784
182278148,4812,guozhangwang,2018-04-18T00:18:07Z,"for test util classes, they are usually put in `org.apache.kafka.test` package. this allows a larger scope of utilization by non-streams unit tests.",0,0.9883158802986145
182278220,4812,guozhangwang,2018-04-18T00:18:37Z,and you can put them in `streams.test.o.a.k.test` folder.,0,0.9871900677680969
182278443,4812,guozhangwang,2018-04-18T00:20:20Z,this looks like a general test util function than a streams-specific test util function. how about moving it to `org.apache.kafka.test.testutils`?,0,0.9871973991394043
182826571,4812,vvcephei,2018-04-19T17:34:08Z,"using the interface is really only useful in our public processorcontext interface. using the streamsmetrics interface in our internals just forces us to cast it back to streamsmetricsimpl all over the place. i've changed it to s.m.i. here and elsewhere to cut down on the casting. the only things that should need to cast now are components that get the metrics via processorcontext, and they should always perform that cast as early as possible to prevent post-initialization runtime exceptions.",0,0.9651581048965454
182827178,4812,vvcephei,2018-04-19T17:36:18Z,override to refine the type from streammetrics to streammetricsimpl in support of internal usages.,0,0.98792564868927
182829844,4812,vvcephei,2018-04-19T17:45:17Z,"it's used by the nodemetrics implementation (it might have been unused when you made this comment, though)",0,0.9887745380401611
182830330,4812,vvcephei,2018-04-19T17:46:54Z,"i've removed commonstreamsmetrics, so we need either to pass the sensor or the whole streamsmetricsimpl. the sensor is smaller scope, so i just did the sensor for now.",0,0.9815987944602966
182830606,4812,vvcephei,2018-04-19T17:47:51Z,the same rationale from `recordcollectorimpl` applies.,0,0.9879429936408997
182834003,4812,vvcephei,2018-04-19T17:58:48Z,"this is an internal class, and this javadoc doesn't say anything that the method signature doesn't say. i added a new constructor and changed the existing one, so i just removed the doc rather than updating it.",0,0.9855497479438782
182834401,4812,vvcephei,2018-04-19T18:00:09Z,"this existed only so a test could override it. instead, i added a constructor arg for the test to pass and removed this method.",0,0.9882440567016602
182837476,4812,vvcephei,2018-04-19T18:10:55Z,"i refactored these to flatten the metric definition, since it was super hard to figure out what metrics were actually being created. maybe you can forgive me for this because i actually found a bug: the description of the total metrics say that it counts the number of calls, but it previously summed the recorded values. (was via createmeter -> new meter -> new total)",-1,0.735891580581665
182840375,4812,vvcephei,2018-04-19T18:20:40Z,"i'd like to add tasklevel names and tags, but it doesn't work with the current way most of the corresponding sensors get created. ultimately, i'd like to flatten all the metrics definitions like i did with streamthreadmetricsimpl, which would make it possible to define the task and node level conventions here as well. but i don't want to do that in this pr.",0,0.8300334811210632
182840948,4812,vvcephei,2018-04-19T18:22:39Z,"defining and providing skippedrecordssensor here now, since it's now needed in contexts where the implementation is not a streamthreadmetricsimpl.",0,0.9884180426597595
182843117,4812,vvcephei,2018-04-19T18:30:00Z,"similar to the metrics in streamthread, by getting rid of the meter and flattening these metrics, i realized that the total computation was incorrectly a total rather than a count.",0,0.9735109806060791
182843558,4812,vvcephei,2018-04-19T18:31:36Z,these metrics never get removed. is that ok?,0,0.9685096740722656
182845636,4812,vvcephei,2018-04-19T18:38:54Z,"this is required per the docs, but we previously only added it in production code paths. now we add it in all code paths.",0,0.9883516430854797
182846028,4812,vvcephei,2018-04-19T18:40:13Z,"this is required per the docs, but we previously only added it in production code paths. now we add it in all code paths.",0,0.9883516430854797
182846606,4812,vvcephei,2018-04-19T18:42:13Z,"the skipped records metrics are now always present. rather than updating the hard-coded value, i did this to make the test less brittle.",0,0.9611135721206665
182847809,4812,vvcephei,2018-04-19T18:46:25Z,"i can move them there. the reason i put them here was to restrict the scope in which log4j was an allowed import (i had to add an exception). co-locating this class in any other package will allow other code to accidently depend on log4j when it should depend on slf4j instead. i was also uncertain about whether it would be a good idea to expose this class for general use in kafka tests... wdyt? if you're not concerned about supporting this class for the whole project, maybe `o.a.k.test.log4jappender` package would be the best of both worlds?",0,0.8766432404518127
182849325,4812,vvcephei,2018-04-19T18:51:39Z,i replaced the override-with-capture strategy in this test with just a regular streamsmetrics and verifying the invocation by checking that the total metric is == 1.,0,0.9853597283363342
182850930,4812,vvcephei,2018-04-19T18:57:02Z,"""virtual"" just in case people go looking for the actual thread in the thread dump. i also thought about using `thead.currentthread()`, but it wouldn't necessarily be the same thread when the tests run.",0,0.9871646165847778
182851149,4812,vvcephei,2018-04-19T18:57:37Z,"same thinking regarding ""virtual""",0,0.98001629114151
182914835,4812,guozhangwang,2018-04-19T23:45:56Z,"ah i see, overlooked `log4j` dependency; let's keep it as is then.",0,0.9787605404853821
182915655,4812,guozhangwang,2018-04-19T23:51:21Z,why this need to be public now?,0,0.9539761543273926
182915744,4812,guozhangwang,2018-04-19T23:52:01Z,"good point, let's add a todo marker and remove them in a follow-up pr: so we do not drag too long on this one.",0,0.5034841895103455
182916297,4812,guozhangwang,2018-04-19T23:56:06Z,sounds good!,1,0.984022855758667
182916817,4812,guozhangwang,2018-04-20T00:00:03Z,"i guess my previous comment was a bit misleading :p actually i'm not against the `commonstreamsmetrics` and `threadmetricsconventions` classes, but i think we could have one such class for each different layer than having a `common` class, for the reason i mentioned before. but since you have removed it i'm also fine with passing along the sensors as well. we can consider which one is better in the near future and if we can do another code refactoring, but let's not block on this pr for too long.",0,0.49494606256484985
182917077,4812,guozhangwang,2018-04-20T00:02:10Z,sounds good!,1,0.984022855758667
182917552,4812,guozhangwang,2018-04-20T00:06:12Z,good call!,1,0.987669050693512
182917825,4812,guozhangwang,2018-04-20T00:08:20Z,cool.,1,0.9692254066467285
182918255,4812,guozhangwang,2018-04-20T00:11:55Z,"hmm.. why we create the sensor in `streamsmetricsmpl` while removing it in `streamsmetricsthreadimpl`? it seems a bit inconsistency.. could we still create in `streamsmetricsthreadimpl`, and let `streamsmetricsimpl` to get a hold of the sensor object assuming it is already created then (i.e. set `sensor == null` in constructor, and in `skippedrecordssensor(): if (sensor == null) try get it from the metrics`)?",0,0.8453295230865479
182918502,4812,guozhangwang,2018-04-20T00:14:29Z,not sure i understand this comment: it was indeed defined as a `count()` before as well right?,0,0.9037274718284607
183065396,4812,vvcephei,2018-04-20T14:18:25Z,"no, it was previously: [code block] but the `count` there is only used for updating the rate. here's the metric constructor: [code block] you can see that it's using `total` for the ""total"" metric, which i guess makes sense given the parameter name. but according to the description of our ""total"" metric, what we really wanted to do was keep a count of occurrences, which should be a `count` stat.",0,0.982675313949585
183075990,4812,vvcephei,2018-04-20T14:52:56Z,"ok, when i took another look, i found that `hitratiosensor` does get removed, but its parent doesn't. also neither sensors have scoped names, so every `record()` will actually update *all* hit ratio metrics for *all* caches. that seems like a bigger deal, so i've already prepared a follow-up pr. i'll send it next once this one is merged.",0,0.9642839431762695
183081167,4812,vvcephei,2018-04-20T15:08:22Z,"because i moved streamsmetricsimpl to the `...internal.metrics` package, but i took a look, and it was only used (properly) by `processornode`. `streamtask` also used it, but only by specifically wrapping the operation in a `runnable` and passing it to the metric to immediately be run. i've added [a link] to simplify `streamtask`'s usage to not need this method, and move the method to `processornode`.",0,0.9845356345176697
183091285,4812,vvcephei,2018-04-20T15:40:35Z,"i tried that, but it wound up making things messier than i expected (because there are other callers to streamsmetricsimpl, and because it makes the ownership of this sensor ambiguous). instead, i added [a link] which gives smi the ability to remove its own sensors, and then i called to it from the two places (streamthread and globalstreamthread) that actually need to unload metrics when they shut down. wdyt?",0,0.8472723364830017
183114250,4812,guozhangwang,2018-04-20T17:09:29Z,"i see. that makes sense. i think it was not introducing any issue only because we only call that `sensor.record()` not `sensor.record(n)` so `count` and `total` are actually the same: `record()` is the same as `record(1)`, but i agree that it should really be `count`, to avoid any potential bugs.",0,0.9583244919776917
183114732,4812,bbejeck,2018-04-20T17:11:29Z,nit: just thinking if this change is necessary as `nodemetrics` is an internal class so a cast here from `processorcontext` to `internalprocessorcontext` should not be a big deal and keeps `processornode` more generic. edit: nm read a comment below about using type system and i agree.,0,0.9818781018257141
183116528,4812,bbejeck,2018-04-20T17:18:41Z,why remove this?,0,0.8541896343231201
183130635,4812,guozhangwang,2018-04-20T18:13:14Z,"i did not completely get your explanation re: `because there are other callers to streamsmetricsimpl, and because it makes the ownership of this sensor ambiguous`. could you elaborate a bit more?",0,0.6659268140792847
183161064,4812,bbejeck,2018-04-20T20:27:06Z,nit: `shouldlogandmeteronskippedrecords` -> `shouldlogandmeteronskippedrecordswithnullvalue` ?,0,0.9866952896118164
183164652,4812,bbejeck,2018-04-20T20:43:09Z,line 503 the javadoc should change as the constructor for `streamsmetricsimpl` only takes `metrics` and a `string` parameter.,0,0.9898136258125305
183166451,4812,bbejeck,2018-04-20T20:51:34Z,maybe consider replacing `stack` with `deque` as `stack` is synchronized and `ownedsensors` only adds in the constructor and removes values in `synchronized` block already.,0,0.9885343909263611
183182512,4812,vvcephei,2018-04-20T22:29:21Z,"this is just used in one spot. it's easier to read the code if the log message is located at the spot where it gets logged rather than at the top of the file. in earlier versions of java, code like this was beneficial for performance, since the string is an object that can just get allocated and instantiated once statically, rather than dynamically on every invocation. but nowadays, the compiler and jit compiler are smarter than that, so there really no benefit to coding this way, and you still pay the comprehensibility cost of having to follow the indirection. i didn't want to make it a ""thing"", though, so i only inlined the message i needed to change.",0,0.7696780562400818
183182785,4812,vvcephei,2018-04-20T22:31:55Z,"ah, good eye. i might just ditch the javadoc, since it's an internal class and its function is pretty obvious.",1,0.9678977131843567
183182905,4812,vvcephei,2018-04-20T22:33:10Z,"ooh, good call. i will do that and probably avoid using stack again.",1,0.9389667510986328
183185297,4812,vvcephei,2018-04-20T22:54:13Z,"sorry; i misread your suggestion. i thought you wanted the streamsmetricsimpl to take the sensor as a constructor argument. aside from the streamthread (via streamthreadmetricsimpl), several other classes directly invoke the streamsmetricsimpl constructor and thus obtain a streamsmetricsimpl that is not a streamthreadmetricsimpl. namely, globalstreamthread, mockprocessorcontext, and topologytestdriver. when the code paths downstream of these points need to record a skipped record, they will get a null sensor back. it wouldn't be possible to get it from the metrics registry at that point, though, because the skipped records sensor is scoped by thread (or ""virtual"" thread for the test-utils), and the sensor would never have been created for globalstreamthread, mockprocessorcontext, or topologytestdriver. so the only way to get it at that point is to have either the caller of the smi constructor or the smi itself create the sensor (either at construction or at call-time). the previous implementation with the public static getter was effectively saying that the one who wants it in a particular context first creates it, but it's problematic because no-one owns it. and indeed, in my implementation, the sensor never got destroyed. in practice i think it's not a huge deal because i'm sure it's rare for a streams app to shut down and start up again with the same metrics registry, and i think the threads live as long as the app. but still, we have this model of unloading metrics when they're out of scope, and i think it's a good one. so that brings us to the current implementation. in the current implementation, the skipped records metric is clearly owned by the streamsmetricsimpl, which it may as well be, since that is the smallest scope in which it's needed. it's the first metric to be owned by smi, so i had to create a removeall method, and make sure it's invoked in the right places. but that seems appropriate; every other scope that owns metrics has such a method.",-1,0.9826728105545044
329311213,7378,jukkakarvanen,2019-09-28T13:57:09Z,this is still using deprecated pipeinput because there is partition verification. can we drop here partition verification which is null here?,0,0.9898502826690674
329311302,7378,jukkakarvanen,2019-09-28T14:00:55Z,this is still using deprecated pipeinput because there is partition verification. can we skip partition assertion here or do we need some other way to get producerrecord?,0,0.9890806674957275
330105303,7378,vvcephei,2019-10-01T14:55:39Z,"yes, it seems to be not what this test is checking on. i think we can drop it here.",0,0.9596775770187378
330108688,7378,vvcephei,2019-10-01T15:01:12Z,"it seems like the purpose of this test class is to verify the test driver. since the partition is effectively not part of the test driver's (non-deprecated) api, i think we can drop it. technically, as long as the deprecated interface is still in the public api, we should still exercise it, but i think in this case it's extremely unlikely we would break the partition field in the future, and it's probably not that risky anyway. i'd vote just to skip the partition assertion here.",0,0.9530908465385437
330248099,7378,jukkakarvanen,2019-10-01T20:01:43Z,moved to use testoutputtopic and partition assertion removed.,0,0.987781286239624
330248275,7378,jukkakarvanen,2019-10-01T20:02:10Z,moved to use testoutputtopic and partition assertion removed.,0,0.987781286239624
330345901,7378,vvcephei,2019-10-02T01:55:47Z,"note: the unused suppression indicates that we're missing test coverage. if we want to add test coverage, we can at the same time address the weakeraccess warning by putting the test in a different package than this class. i.e., a true test of a class's public api should be located outside that class's package, so it wouldn't have access to package-private members.",0,0.9858168363571167
330346143,7378,vvcephei,2019-10-02T01:57:20Z,"it might be a good idea to note that this only advances the _stream_ time, not the wall-clock time, and therefore doesn't trigger punctuations.",0,0.9825351238250732
330346457,7378,vvcephei,2019-10-02T01:59:28Z,"would it be handy to also print out the other constructor argument fields here? (serializers in particular, not sure if the times are that interesting)",0,0.9831868410110474
330346561,7378,vvcephei,2019-10-02T02:00:05Z,should we also require non-null deserializers?,0,0.9835246801376343
330347517,7378,vvcephei,2019-10-02T02:07:04Z,"i'm curious why these suppressions were necessary. i'd have thought that the package-private members would all have been here because they were needed by the i/o topic classes. is it because idea thinks that protected is ""stronger"" than package-private?",0,0.9513300061225891
330347991,7378,vvcephei,2019-10-02T02:10:28Z,"you should double-check, but i think java will automatically do this in string concatenation. (it was news to me when i learned it a couple of months back)",0,0.9685481190681458
330348273,7378,vvcephei,2019-10-02T02:12:15Z,probably should use a (slf4j) logger instead of stdout here.,0,0.9873955845832825
330348480,7378,vvcephei,2019-10-02T02:13:29Z,these tests are beautiful,1,0.962336003780365
330348611,7378,vvcephei,2019-10-02T02:14:17Z,there seems to be a lot of overlap between these and the input tests. could they just be one test class that covers both?,0,0.9559566974639893
330348785,7378,vvcephei,2019-10-02T02:15:25Z,[code block] thanks for keeping the test coverage for deprecated methods.,0,0.6418581008911133
330369097,7378,jukkakarvanen,2019-10-02T04:37:38Z,suppresswarnings removed and comment clarified,0,0.9858919978141785
330369142,7378,jukkakarvanen,2019-10-02T04:37:54Z,added,0,0.9735139608383179
330369166,7378,jukkakarvanen,2019-10-02T04:38:07Z,added,0,0.9735139608383179
330369686,7378,jukkakarvanen,2019-10-02T04:42:09Z,not sure the reason.,-1,0.7921515703201294
330369748,7378,jukkakarvanen,2019-10-02T04:42:38Z,replaced with another style tostring,0,0.9841448068618774
330369769,7378,jukkakarvanen,2019-10-02T04:42:49Z,dobe,0,0.9795158505439758
330369794,7378,jukkakarvanen,2019-10-02T04:43:02Z,thanks,1,0.6094269156455994
330370023,7378,jukkakarvanen,2019-10-02T04:44:51Z,merged,0,0.972292959690094
330370105,7378,jukkakarvanen,2019-10-02T04:45:29Z,typo fixed,0,0.9863081574440002
331089257,7378,bbejeck,2019-10-03T14:59:10Z,"nit: i **_think_** that streams convention now is to mark methods as `` now vs. using ``. my reasoning for this is that these test methods will go away once the deprecated method under test is removed. this applies here and other deprecated tests below. however, this is a minor point. \cc",0,0.9582417011260986
331091087,7378,bbejeck,2019-10-03T15:02:10Z,super nit: `deprecatd` -> `deprecated` here and below,0,0.9874224662780762
331099773,7378,bbejeck,2019-10-03T15:18:38Z,nit: `configure topic` -> `configure the topic`,0,0.985855758190155
331122381,7378,bbejeck,2019-10-03T16:02:51Z,why did we eliminate the partition check in the `assertnextoutputrecord` method?,0,0.9819554686546326
331124616,7378,bbejeck,2019-10-03T16:07:47Z,nit: `you need to have own testinputtopic object` -> `you need a testinputtopic object`,0,0.9761717319488525
331125926,7378,bbejeck,2019-10-03T16:10:37Z,as above,0,0.9783914685249329
331126553,7378,bbejeck,2019-10-03T16:12:02Z,nit: `send` -> `sent`,0,0.9870471954345703
331131776,7378,bbejeck,2019-10-03T16:23:46Z,"do we still need this comment? seems to me the other topic is expecting a `string` as well, but i could be missing something.",0,0.943988025188446
331134784,7378,bbejeck,2019-10-03T16:30:39Z,"a minor point, but isn't this supposed to swap the key and value on output?",0,0.9794098138809204
331189754,7378,vvcephei,2019-10-03T18:33:18Z,"ah, yes, good catch, . adding the deprecation annotation will also satisfy the compiler, and it is indeed better. as you say, it documents that this method will also be removed when the other one is removed. it's not such a concern for a test, but the other big benefit is that it prevents ""deprecation laundering"": suppressing would make it ok for another method to call this one, whereas deprecating this method would also notify all callers that _this_ method is using deprecated functionality.",1,0.9420804977416992
331191034,7378,vvcephei,2019-10-03T18:36:17Z,"partitions are not part of the `testrecord` api in the kip, so it's not possible to make assertions on it in the new api. we can add the field later on if requested. i don't remember offhand why we didn't include it; maybe something to do with the symmetry of the api.",0,0.9771363139152527
331212689,7378,jukkakarvanen,2019-10-03T19:27:54Z,"ok, modified",0,0.9832219481468201
331212945,7378,jukkakarvanen,2019-10-03T19:28:27Z,fixed,0,0.975196123123169
331214169,7378,jukkakarvanen,2019-10-03T19:31:26Z,added,0,0.9735139608383179
331215421,7378,jukkakarvanen,2019-10-03T19:34:39Z,fixed,0,0.975196123123169
331215484,7378,jukkakarvanen,2019-10-03T19:34:49Z,fixed,0,0.975196123123169
331216194,7378,jukkakarvanen,2019-10-03T19:36:24Z,removed,0,0.9654131531715393
331225577,7378,jukkakarvanen,2019-10-03T20:00:01Z,there are two stream. this is using this: builder.stream(input_topic).to(output_topic); output_topic_map is where values are swapped,0,0.9852345585823059
331226741,7378,jukkakarvanen,2019-10-03T20:02:58Z,fixed,0,0.975196123123169
331233340,7378,jukkakarvanen,2019-10-03T20:19:25Z,"i removed all unnecessary field from testrecord compared to producerrecord and consumerrecord to keep it simple. this way we can utilize standard assertions and do not need to ignore the partition and use outputverifier kind of contructions. i don't see many use cases in normal stream application verification where partion is needed as we see here where this is only test class checking partition. if there are need to verify partition, i would add for example extra method readproducerrecord and use deprecated method until this is possible added if there is need for it.",0,0.9856348633766174
331344364,7378,mjsax,2019-10-04T05:22:30Z,nit: `inputtopic` -> `rightinputtopic`,0,0.9861131310462952
331344534,7378,mjsax,2019-10-04T05:23:36Z,"why do we need to pass `null` as third parameter? saw this in some other tests, too.",0,0.9855610728263855
331344660,7378,mjsax,2019-10-04T05:24:33Z,nit: `inputtopicright`,0,0.9853159785270691
331345200,7378,mjsax,2019-10-04T05:27:59Z,nit: add `asserttrue(outputtopic2.isempty());` (as done in the original test code),0,0.9886049032211304
331345336,7378,mjsax,2019-10-04T05:28:48Z,as above,0,0.9783914685249329
331345361,7378,mjsax,2019-10-04T05:28:57Z,as above,0,0.9783914685249329
331346249,7378,mjsax,2019-10-04T05:35:02Z,nit: `final instant initialwallclocktime = instant.ofepochmilli(0)`,0,0.9835970997810364
331346966,7378,mjsax,2019-10-04T05:39:36Z,nit: [code block],0,0.9873168468475342
331347564,7378,mjsax,2019-10-04T05:43:28Z,nit: `create [a new instance via]`,0,0.9852864742279053
331347785,7378,mjsax,2019-10-04T05:44:37Z,nit: `message` -> `record` nit: `{ keyvalue} pairs.` (not add `.` at the end.,0,0.9870309233665466
331347943,7378,mjsax,2019-10-04T05:45:33Z,"nit: `if you have multiple source topics, you need to create a { testinputtopic} for each.`",0,0.9243785738945007
331348093,7378,mjsax,2019-10-04T05:46:36Z,`kafka` -> `record` (same next line for value),0,0.9878677129745483
331348378,7378,mjsax,2019-10-04T05:48:14Z,nit: `messages` -> `records`,0,0.9874496459960938
331348642,7378,mjsax,2019-10-04T05:49:54Z,"we can omit javadocs for non-public methods -- similar below -- wondering if we need this constructor? it's internal and hence, topologytestdriver can always use the one with all parameters.",0,0.9890496730804443
331349765,7378,mjsax,2019-10-04T05:56:06Z,"topologytestdriver supports event/stream time punctuations -- hence, this comment is a little bit miss leading. i would suggest: [code block]",0,0.9785240888595581
331349882,7378,mjsax,2019-10-04T05:56:40Z,"in the kip, the method is still called `advancetimems` -- can you update the kip?",0,0.9895542860031128
331351096,7378,mjsax,2019-10-04T06:02:48Z,"nit `send input record to the topic and then commit the record.` (note, in kafkastreams we use the abstractions of records, that are typed, while messages are untyped lower lever `byte[]` arrays). similar below.",0,0.9882528185844421
331351274,7378,mjsax,2019-10-04T06:03:41Z,`key` -> `value`,0,0.9828086495399475
331351440,7378,mjsax,2019-10-04T06:04:44Z,"should we add ""may auto advance topic time"" to the other methods?",0,0.9861043095588684
331351655,7378,mjsax,2019-10-04T06:05:49Z,nit: `{ keyvalue}` nit: remove double whitespace (2 times -- also more below),0,0.9875221848487854
331351999,7378,mjsax,2019-10-04T06:07:47Z,"`time will auto advance` -- well, only if the advance is not zero. should we be more precise?",0,0.9855491518974304
331352367,7378,mjsax,2019-10-04T06:09:56Z,`keyserializer.getclass().getsimplename()` (similar for value),0,0.9868258833885193
331352477,7378,mjsax,2019-10-04T06:10:34Z,nit: `{ testoutputtopic}` nit `from [a] topic`,0,0.9861186742782593
331352569,7378,mjsax,2019-10-04T06:10:58Z,nit: `create [a new object via]`,0,0.9849836230278015
331352610,7378,mjsax,2019-10-04T06:11:17Z,nit: `message` -> `record`,0,0.986604630947113
331352696,7378,mjsax,2019-10-04T06:11:46Z,same as for input topic,0,0.9845036268234253
331352981,7378,mjsax,2019-10-04T06:13:21Z,nit: [code block],0,0.9873168468475342
331353098,7378,mjsax,2019-10-04T06:13:57Z,nit: [code block],0,0.9873168468475342
331353157,7378,mjsax,2019-10-04T06:14:19Z,`kafka` -> `record` (same for value),0,0.9875144958496094
331353208,7378,mjsax,2019-10-04T06:14:39Z,we can omit javadocs here,0,0.9881911277770996
331353431,7378,mjsax,2019-10-04T06:15:48Z,nit `[r]ecord` nit `from [the] output topic and return the record's value.`,0,0.9865259528160095
331353468,7378,mjsax,2019-10-04T06:15:58Z,i think we can omit this,0,0.9796642065048218
331354197,7378,mjsax,2019-10-04T06:19:42Z,`read one record from the output topic and return its key and value as pair.`,0,0.9882679581642151
331354239,7378,mjsax,2019-10-04T06:20:00Z,nit: `{ keyvalue}`,0,0.9852541089057922
331355498,7378,mjsax,2019-10-04T06:26:03Z,`kafka` -> `{ topologytestdriver}`,0,0.9806828498840332
331355674,7378,mjsax,2019-10-04T06:26:53Z,"`a key/value pair, including timestamp and record headers, to be sent...`",0,0.9874260425567627
331355924,7378,mjsax,2019-10-04T06:28:09Z,`if [a] record does` `{ testinputtopic} will auto advance it's time when the record is piped.`,0,0.9883473515510559
331356123,7378,mjsax,2019-10-04T06:29:01Z,remove `with a specific instant` (unclear what this means).,0,0.9698312878608704
331356208,7378,mjsax,2019-10-04T06:29:26Z,the key of the record,0,0.9845890402793884
331356259,7378,mjsax,2019-10-04T06:29:38Z,the value of the record,0,0.9815380573272705
331356323,7378,mjsax,2019-10-04T06:29:55Z,the record headers,0,0.9870820045471191
331356516,7378,mjsax,2019-10-04T06:30:54Z,remove `as instant` (that is clear from the parameter type). nit `if { null}`,0,0.9854826927185059
331356647,7378,mjsax,2019-10-04T06:31:29Z,it's unclear when `now()` or internally tracked time is used -- we should be more specific?,0,0.9838677644729614
331357009,7378,mjsax,2019-10-04T06:33:10Z,`with specified timestamp` -> sounds is if there would not be anything else specified. simply to `create a new record.`?,0,0.9879891872406006
331357212,7378,mjsax,2019-10-04T06:34:07Z,nit: `timestampms` ? nit: `since [the beginning of the] epoch` ? nit: `{ null`},0,0.9868864417076111
331357301,7378,mjsax,2019-10-04T06:34:32Z,as above: explain when which case is used?,0,0.980991542339325
331357761,7378,mjsax,2019-10-04T06:36:36Z,nit: add braces,0,0.987166702747345
331357774,7378,mjsax,2019-10-04T06:36:40Z,nit: add braces,0,0.987166702747345
331358003,7378,mjsax,2019-10-04T06:37:37Z,similar comments as above -- also applies to other constructors,0,0.9877018332481384
331358093,7378,mjsax,2019-10-04T06:38:00Z,`with { null} key`,0,0.9845320582389832
331358460,7378,mjsax,2019-10-04T06:39:30Z,should we add: `objects.requirenonnull(record)`?,0,0.9876060485839844
331358507,7378,mjsax,2019-10-04T06:39:43Z,as above,0,0.9783914685249329
331358629,7378,mjsax,2019-10-04T06:40:15Z,nit: `create a { testrecord} from a { consumerrecord}.`,0,0.9868708848953247
331358675,7378,mjsax,2019-10-04T06:40:26Z,as above.,0,0.978552520275116
331359572,7378,mjsax,2019-10-04T06:44:10Z,"nit: `{ #createinputtopic(string, serializer, serializer) create}` (make `create` the link directly)",0,0.9867637753486633
331359756,7378,mjsax,2019-10-04T06:44:55Z,`and use the` -> `and use a` `to supply input records` (plural),0,0.9860810041427612
331359883,7378,mjsax,2019-10-04T06:45:33Z,as above -> make `create` the link `and use a`,0,0.9855902791023254
331359975,7378,mjsax,2019-10-04T06:45:52Z,`any output records of the topology`,0,0.9852500557899475
331360311,7378,mjsax,2019-10-04T06:47:19Z,`outputtopic2`,0,0.983761727809906
331361415,7378,mjsax,2019-10-04T06:52:06Z,"if `key == null`, size should be `consumerrecord.null_size` (same for value)",0,0.988979697227478
331361500,7378,mjsax,2019-10-04T06:52:31Z,as above,0,0.9783914685249329
331362053,7378,mjsax,2019-10-04T06:54:47Z,seems we encoded the size incorrectly...,0,0.6356731057167053
331364079,7378,mjsax,2019-10-04T07:02:53Z,nit: add braces (preferred for all blocks),0,0.9881225228309631
331364419,7378,mjsax,2019-10-04T07:04:17Z,remove,0,0.9725990891456604
331365084,7378,mjsax,2019-10-04T07:06:48Z,"if `time == null && record.timestamp() == null` we pass `timestamp==0`; is this intended? sounds like an error case to me (should we throw an exception, or can this never happen anyway?)",0,0.9522257447242737
331365575,7378,mjsax,2019-10-04T07:08:41Z,why do we handle this case differently?,0,0.8784346580505371
331366050,7378,mjsax,2019-10-04T07:10:41Z,"i know the context of the kip, but i think it's hard to understand for users what this means. `this method can be used if the result is considered a stream. if the result is considered a table, the list will contain all updated, ie, a key might be contained multiple times. if you are only interested in the last table update (ie, the final table state), you can use { #readkeyvaluestomap()} instead.`",0,0.973212718963623
331366098,7378,mjsax,2019-10-04T07:10:51Z,`map` ?,0,0.9861487150192261
331366171,7378,mjsax,2019-10-04T07:11:05Z,as above,0,0.9783914685249329
331367846,7378,mjsax,2019-10-04T07:17:13Z,"we should point out in the javadocs, that null-values don't have delete semantics! ie, if the last update to a key is a delete/tombstone, the key will still be in the map (with null-value). also, i think we should not allow `null` keys, but throw an exception for this case.",0,0.9784812927246094
331368233,7378,mjsax,2019-10-04T07:18:39Z,`keydeserializer.getclass().getsimplename()` (same for value),0,0.9866513013839722
331368853,7378,mjsax,2019-10-04T07:20:50Z,we can omit javadoc for non-public methods,0,0.9878701567649841
331368920,7378,mjsax,2019-10-04T07:21:02Z,we can omit javadoc for non-public methods,0,0.9878701567649841
331368970,7378,mjsax,2019-10-04T07:21:14Z,we can omit javadoc for non-public methods,0,0.9878701567649841
331369932,7378,mjsax,2019-10-04T07:24:27Z,use `final illegalargumentexception exception = assertthrows(...)` instead of try-catch,0,0.9830682873725891
331554734,7378,jukkakarvanen,2019-10-04T15:16:23Z,renamed,0,0.9686685800552368
331556004,7378,jukkakarvanen,2019-10-04T15:19:02Z,"reason for those null parameter in testrecord contructor is limited variation of constructors with long. it would not require header parameter (null) if instant would be used, which is the prefered way for the future.",0,0.9877622127532959
331557898,7378,jukkakarvanen,2019-10-04T15:23:07Z,renamed,0,0.9686685800552368
331559215,7378,jukkakarvanen,2019-10-04T15:25:51Z,fixed,0,0.975196123123169
331559316,7378,jukkakarvanen,2019-10-04T15:26:05Z,fixed,0,0.975196123123169
331560205,7378,jukkakarvanen,2019-10-04T15:28:05Z,fixed and order aligned,0,0.982903778553009
331561533,7378,jukkakarvanen,2019-10-04T15:31:12Z,changed,0,0.9773849844932556
331562321,7378,jukkakarvanen,2019-10-04T15:33:02Z,changed,0,0.9773849844932556
331562657,7378,jukkakarvanen,2019-10-04T15:33:48Z,changed,0,0.9773849844932556
331568443,7378,jukkakarvanen,2019-10-04T15:47:06Z,done,0,0.9764507412910461
331568499,7378,jukkakarvanen,2019-10-04T15:47:14Z,done,0,0.9764507412910461
331568797,7378,jukkakarvanen,2019-10-04T15:47:54Z,fixed,0,0.975196123123169
331570268,7378,jukkakarvanen,2019-10-04T15:51:22Z,this is removed,0,0.9805853962898254
331570450,7378,jukkakarvanen,2019-10-04T15:51:47Z,removed contructor and javadoc,0,0.9881495237350464
331571591,7378,jukkakarvanen,2019-10-04T15:54:24Z,changed,0,0.9773849844932556
331572126,7378,jukkakarvanen,2019-10-04T15:55:35Z,updated,0,0.9681491851806641
331573167,7378,jukkakarvanen,2019-10-04T15:57:47Z,replaced all messages,0,0.9811670184135437
331573595,7378,jukkakarvanen,2019-10-04T15:58:46Z,fixed,0,0.975196123123169
331578731,7378,jukkakarvanen,2019-10-04T16:11:15Z,changed,0,0.9773849844932556
331578775,7378,jukkakarvanen,2019-10-04T16:11:21Z,removed,0,0.9654131531715393
331578924,7378,jukkakarvanen,2019-10-04T16:11:44Z,removed,0,0.9654131531715393
331579069,7378,jukkakarvanen,2019-10-04T16:12:06Z,removed,0,0.9654131531715393
331580264,7378,jukkakarvanen,2019-10-04T16:14:56Z,changed,0,0.9773849844932556
331582622,7378,jukkakarvanen,2019-10-04T16:21:05Z,added,0,0.9735139608383179
331585568,7378,jukkakarvanen,2019-10-04T16:28:45Z,fixed,0,0.975196123123169
331585636,7378,jukkakarvanen,2019-10-04T16:28:58Z,clarified,0,0.97712641954422
331585726,7378,jukkakarvanen,2019-10-04T16:29:12Z,changed,0,0.9773849844932556
331587844,7378,jukkakarvanen,2019-10-04T16:34:56Z,to my understanding null can happen either topic does not exist or no input piped to that topic. this is to able to throw error if topic does not exist at all.,0,0.96194988489151
331590978,7378,jukkakarvanen,2019-10-04T16:43:40Z,i needed to modify like that to get some old test to work. it might be some non valid test.,0,0.9638634920120239
331591058,7378,jukkakarvanen,2019-10-04T16:43:55Z,removed,0,0.9654131531715393
331591666,7378,jukkakarvanen,2019-10-04T16:45:28Z,added,0,0.9735139608383179
331592830,7378,jukkakarvanen,2019-10-04T16:48:43Z,fixed,0,0.975196123123169
331592861,7378,jukkakarvanen,2019-10-04T16:48:50Z,fixed,0,0.975196123123169
331593078,7378,jukkakarvanen,2019-10-04T16:49:29Z,", what this means, is actions needed from my side",0,0.948050320148468
331593792,7378,jukkakarvanen,2019-10-04T16:51:26Z,changed record2 to read from outputtopic2,0,0.9874873161315918
331594180,7378,jukkakarvanen,2019-10-04T16:52:29Z,changed,0,0.9773849844932556
331596166,7378,jukkakarvanen,2019-10-04T16:57:43Z,done,0,0.9764507412910461
331596244,7378,jukkakarvanen,2019-10-04T16:57:54Z,done,0,0.9764507412910461
331596343,7378,jukkakarvanen,2019-10-04T16:58:10Z,done,0,0.9764507412910461
331596809,7378,jukkakarvanen,2019-10-04T16:59:24Z,done,0,0.9764507412910461
331596839,7378,jukkakarvanen,2019-10-04T16:59:29Z,done,0,0.9764507412910461
331598905,7378,jukkakarvanen,2019-10-04T17:05:12Z,added,0,0.9735139608383179
331598928,7378,jukkakarvanen,2019-10-04T17:05:16Z,added,0,0.9735139608383179
331599147,7378,jukkakarvanen,2019-10-04T17:05:53Z,replaced,0,0.9711619019508362
331600525,7378,jukkakarvanen,2019-10-04T17:09:46Z,changed,0,0.9773849844932556
331600579,7378,jukkakarvanen,2019-10-04T17:09:54Z,done,0,0.9764507412910461
331603570,7378,jukkakarvanen,2019-10-04T17:17:58Z,replaced in all places,0,0.9748395085334778
331604119,7378,jukkakarvanen,2019-10-04T17:19:22Z,"i removed time generator logic text, it is functionality of testinputlogic, not needed here.",0,0.9884220957756042
331604682,7378,jukkakarvanen,2019-10-04T17:20:59Z,done,0,0.9764507412910461
331604752,7378,jukkakarvanen,2019-10-04T17:21:08Z,done,0,0.9764507412910461
331604866,7378,jukkakarvanen,2019-10-04T17:21:25Z,same as above,0,0.9772257208824158
331604966,7378,jukkakarvanen,2019-10-04T17:21:43Z,same as above,0,0.9772257208824158
331605927,7378,jukkakarvanen,2019-10-04T17:24:12Z,changed,0,0.9773849844932556
331606011,7378,jukkakarvanen,2019-10-04T17:24:23Z,changed,0,0.9773849844932556
331606681,7378,jukkakarvanen,2019-10-04T17:26:01Z,changed multiple occurences,0,0.9856051802635193
331607233,7378,jukkakarvanen,2019-10-04T17:27:15Z,removed,0,0.9654131531715393
331608046,7378,jukkakarvanen,2019-10-04T17:29:11Z,replaced,0,0.9711619019508362
331608817,7378,jukkakarvanen,2019-10-04T17:31:05Z,changed,0,0.9773849844932556
331610034,7378,jukkakarvanen,2019-10-04T17:34:27Z,done,0,0.9764507412910461
331610133,7378,jukkakarvanen,2019-10-04T17:34:42Z,done,0,0.9764507412910461
331610298,7378,jukkakarvanen,2019-10-04T17:35:10Z,removed,0,0.9654131531715393
331610965,7378,jukkakarvanen,2019-10-04T17:36:58Z,changed,0,0.9773849844932556
331611197,7378,jukkakarvanen,2019-10-04T17:37:26Z,removed,0,0.9654131531715393
331611349,7378,jukkakarvanen,2019-10-04T17:37:50Z,done,0,0.9764507412910461
331612150,7378,jukkakarvanen,2019-10-04T17:39:42Z,changed,0,0.9773849844932556
331612202,7378,jukkakarvanen,2019-10-04T17:39:49Z,changed,0,0.9773849844932556
331612485,7378,jukkakarvanen,2019-10-04T17:40:27Z,replaced,0,0.9711619019508362
331613185,7378,jukkakarvanen,2019-10-04T17:42:15Z,instance as in inputtopic,0,0.9846439361572266
331613689,7378,jukkakarvanen,2019-10-04T17:43:33Z,done,0,0.9764507412910461
331613912,7378,jukkakarvanen,2019-10-04T17:44:03Z,done,0,0.9764507412910461
331614099,7378,jukkakarvanen,2019-10-04T17:44:31Z,done,0,0.9764507412910461
331615408,7378,jukkakarvanen,2019-10-04T17:47:52Z,clarified,0,0.97712641954422
331615881,7378,jukkakarvanen,2019-10-04T17:49:09Z,done,0,0.9764507412910461
331617799,7378,jukkakarvanen,2019-10-04T17:53:54Z,added,0,0.9735139608383179
331621072,7378,mjsax,2019-10-04T18:02:07Z,ack.,0,0.7720441818237305
331622341,7378,mjsax,2019-10-04T18:05:40Z,"no -- i just acknowledged that you basically move code that was already ""wrong"", so not your fault to use `0` instead of `consumer.null_size` :) -- no action needed.",0,0.8342214226722717
331623203,7378,mjsax,2019-10-04T18:08:08Z,ack.,0,0.7720441818237305
331634638,7378,mjsax,2019-10-04T18:36:08Z,this must be `output_topic_2`,0,0.9871065616607666
331638698,7378,jukkakarvanen,2019-10-04T18:46:45Z,i don't understand the original test. why it is checking output_topic_2 if it is not in topology at all.,0,0.7449778914451599
331643505,7378,jukkakarvanen,2019-10-04T18:59:40Z,i pushed the version with outputtopic2 removed,0,0.9882692098617554
331648099,7378,mjsax,2019-10-04T19:12:52Z,"well. overwriting the timestamp is fine, however, if we don't pass in `final instant time`, we should just pass `record.timestamp()` into `piperecord()` -- i checked out the code applied the following change an run test (and they passed---hence, i think it fine to be more strict) [code block]",0,0.9456087946891785
331654063,7378,mjsax,2019-10-04T19:30:36Z,"the original intent of the test was to ensure, we don't write into non-exiting topics, ie, create a topic out of nowhere -- but with the new abstraction that cannot happen anyway i guess.",0,0.9777421355247498
331659853,7378,jukkakarvanen,2019-10-04T19:47:53Z,some tests failing if making change like this.,0,0.557876467704773
221138500,5709,bbejeck,2018-09-28T04:25:41Z,added for access to contents of `grouped`. i added this class to follow the pattern we currently use for configuration classes.,0,0.9886484742164612
221138726,5709,bbejeck,2018-09-28T04:28:29Z,i did this to be consistent with `sessionwindowedkstreamimpl`,0,0.9871516227722168
221138924,5709,bbejeck,2018-09-28T04:30:40Z,needed to change the topology as we now use the topic name of the first merged/replaced repartition topic when performing repartition topic optimization.,0,0.9856411814689636
221138954,5709,bbejeck,2018-09-28T04:31:00Z,same as above,0,0.9772257208824158
221139121,5709,bbejeck,2018-09-28T04:32:38Z,same here and below needed to update the expected topology as now we use the topic name of the **_first_** merged repartition topic for the new optimized repartition topic.,0,0.988572359085083
221139255,5709,bbejeck,2018-09-28T04:34:12Z,"most of the loc in this class are boilerplate to create the topologies for the tests, and the expected optimized and non-optimized topologies.",0,0.9839199185371399
221141350,5709,bbejeck,2018-09-28T04:58:47Z,required to keep the merge nodes in the same order as they are added to the graph. they may be used later when performing an optimization if the merged node represents key-changing operations up-stream.,0,0.9875637888908386
221141409,5709,bbejeck,2018-09-28T04:59:37Z,keep `optimizablerepartitonnodes` in the same order as they are added.,0,0.9859594702720642
221141573,5709,bbejeck,2018-09-28T05:01:13Z,now grab the topic name from the first existing repartition topic that will get merged/replaced.,0,0.9847917556762695
221142005,5709,bbejeck,2018-09-28T05:05:25Z,keep the key-changing parent nodes for the merge node in order.,0,0.986447811126709
221142221,5709,bbejeck,2018-09-28T05:07:11Z,keep the `optimizablerepartitionnode`s in order as they are mapped to merge nodes,0,0.9872121214866638
221284385,5709,vvcephei,2018-09-28T15:03:18Z,"maybe a nit: you could alternatively return `return new grouped<>(name, keyserde, valueserde);` from this and the following methods and then make the three variables `final`. personally, i'd feel more comfortable making them `protected` (for `groupedinternal`'s access) if they were final.",0,0.972328782081604
221284484,5709,vvcephei,2018-09-28T15:03:37Z,"i assume this is in reference to [a link] just jotting down some thoughts: if this were iface/impl, all the state would be private, and there'd be no need for the `protected` copy constructor. but if we decide we like kafka-7435, we'd apply it to all the config objects, and converting this one would be low incremental cost. i'm :+1: for defaulting to the common pattern.",0,0.8095648884773254
221287987,5709,vvcephei,2018-09-28T15:13:45Z,nit: maybe just call this `name` for consistency?,0,0.9850191473960876
221288250,5709,vvcephei,2018-09-28T15:14:23Z,nit: formatting,0,0.9857796430587769
221288991,5709,vvcephei,2018-09-28T15:16:34Z,"hmm. i failed to notice this in the kip... should this be `named` like `grouped.named`? seems like a minor kip update that would be ok at this point, but valuable to establish consistency now.",0,0.9594184160232544
221289641,5709,vvcephei,2018-09-28T15:18:32Z,"nit: maybe just call the constructor. the other static method doesn't apply any defaults, so there's no benefit to the chained method call.",0,0.97687166929245
221291992,5709,vvcephei,2018-09-28T15:25:33Z,"""xxx"" could also be configured via `grouped`, right?",0,0.9883639812469482
221293611,5709,vvcephei,2018-09-28T15:30:39Z,"did you mean to also insert a ` ` here, so the html would be formatted the same as this javadoc?",0,0.988958477973938
221294337,5709,vvcephei,2018-09-28T15:32:58Z,"maybe we can also add note to the javadoc, like ` since 2.1. use { groupbykey(grouped)} instead.` ?",0,0.9883701801300049
221294537,5709,vvcephei,2018-09-28T15:33:25Z,ditto on the deprecation notice in the javadoc.,0,0.9843182563781738
221295115,5709,vvcephei,2018-09-28T15:35:12Z,i didn't follow: it seems like there's no restriction that `kr` is the same as `k`. or did you mean something else?,0,0.8479243516921997
221295243,5709,vvcephei,2018-09-28T15:35:40Z,similar question re: ` `,0,0.9418331980705261
221295702,5709,vvcephei,2018-09-28T15:36:53Z,"similar question re: ""xxx"" and `grouped.named`",0,0.9864313006401062
221296087,5709,vvcephei,2018-09-28T15:38:09Z,nit: missing the `` for `grouped`,0,0.9824889898300171
221296127,5709,vvcephei,2018-09-28T15:38:16Z,nit: missing the `` for `grouped`,0,0.9824889898300171
221296539,5709,vvcephei,2018-09-28T15:39:41Z,"this one should be ``, right?",0,0.9794110059738159
221296735,5709,vvcephei,2018-09-28T15:40:24Z,similar comment re: ` `,0,0.9579242467880249
221296798,5709,vvcephei,2018-09-28T15:40:37Z,super nit: alignment ;),1,0.7983270883560181
221297424,5709,vvcephei,2018-09-28T15:42:48Z,similar question about:,0,0.9644410610198975
221299721,5709,vvcephei,2018-09-28T15:50:08Z,"similar questoin re ""xxx""",0,0.984027624130249
221299939,5709,vvcephei,2018-09-28T15:50:52Z,similar question re: `` javadoc,0,0.9839962124824524
221301291,5709,vvcephei,2018-09-28T15:55:07Z,"sounds good. if this is an important semantic property of `mergenodes`, perhaps we should declare the variable as a `linkedhashset` as well?",1,0.9401758313179016
221301788,5709,vvcephei,2018-09-28T15:56:52Z,"similar to my question about `mergenodes`, should we go ahead and declare `keychangingoperationstooptimizablerepartitionnodes` as a `linkedhashmap >` to document that the insertion order is preserved at both levels?",0,0.9861159324645996
221303796,5709,vvcephei,2018-09-28T16:03:59Z,ditto,0,0.8428916931152344
221303825,5709,vvcephei,2018-09-28T16:04:07Z,ditto,0,0.8428916931152344
221304091,5709,vvcephei,2018-09-28T16:05:09Z,"would you be ok with renaming ""name"" to ""nodename"" to disambiguate?",0,0.9882416129112244
221304694,5709,vvcephei,2018-09-28T16:07:18Z,did we want to give priority to the explicitly named repartition topics?,0,0.9807543754577637
221304981,5709,vvcephei,2018-09-28T16:08:16Z,nit: alignment,0,0.9832958579063416
221305467,5709,vvcephei,2018-09-28T16:09:52Z,"nit: since the `groupedstreamaggregatebuilder` needs to know everything that's in `groupedinternal`, maybe we can just pass the whole config object in to cut down on the param list?",0,0.987862229347229
221305778,5709,vvcephei,2018-09-28T16:10:58Z,"thanks! i just noticed this yesterday, and it did trip me up a little.",1,0.9832699298858643
221307699,5709,vvcephei,2018-09-28T16:18:09Z,what's the code path that leads to `repartitiontopicbasename.endswith(repartition_topic_suffix)`? i couldn't find it.,0,0.9672987461090088
221309541,5709,vvcephei,2018-09-28T16:24:52Z,"i think if you mark this method as `` as well, it will also suppress the warnings, which might be better because it preserves the deprecation notice from the interface.",0,0.9889621138572693
221309956,5709,vvcephei,2018-09-28T16:26:13Z,ditto,0,0.8428916931152344
221310171,5709,vvcephei,2018-09-28T16:27:05Z,ditto to `kstreamimpl`,0,0.9412216544151306
221310476,5709,vvcephei,2018-09-28T16:28:07Z,ditto to `kstreamimpl`: it might be better to mark this class ``,0,0.9542500376701355
221310586,5709,vvcephei,2018-09-28T16:28:31Z,thank you!,1,0.9661415219306946
221314587,5709,vvcephei,2018-09-28T16:44:00Z,should this be `shouldkeeprepartitiontopicnameforgroupbykeynowindows`?,0,0.9877837300300598
221353167,5709,bbejeck,2018-09-28T19:06:35Z,ack,0,0.9720376133918762
221356038,5709,bbejeck,2018-09-28T19:18:35Z,"i can but this change isn't specific to the semantics of merge nodes themselves, it's more about bookkeeping and keeping them in the same order as they are added when building the graph. since this is private variables i'll make the change.",0,0.9858943223953247
221356652,5709,bbejeck,2018-09-28T19:21:19Z,"ack, same as above",0,0.9843222498893738
221356700,5709,bbejeck,2018-09-28T19:21:33Z,"ack, same as above",0,0.9843222498893738
221356733,5709,bbejeck,2018-09-28T19:21:46Z,"ack, same as above",0,0.9843222498893738
221358640,5709,bbejeck,2018-09-28T19:29:32Z,ack,0,0.9720376133918762
221361859,5709,bbejeck,2018-09-28T19:43:47Z,ack,0,0.9720376133918762
221361903,5709,bbejeck,2018-09-28T19:43:55Z,ack,0,0.9720376133918762
221369563,5709,bbejeck,2018-09-28T20:15:44Z,"ack, copy-paste error",0,0.9561876058578491
221369692,5709,bbejeck,2018-09-28T20:16:16Z,i'll add but i believe that was pre-existing,0,0.980022668838501
221369921,5709,bbejeck,2018-09-28T20:17:13Z,ack,0,0.9720376133918762
221370454,5709,bbejeck,2018-09-28T20:19:29Z,ack,0,0.9720376133918762
221371198,5709,bbejeck,2018-09-28T20:22:39Z,"pre-existing, fixed",0,0.9855772852897644
221371933,5709,bbejeck,2018-09-28T20:25:25Z,"pre-existing, you'll notice the other java doc has the same thing, i'll update though",0,0.9862268567085266
221373333,5709,bbejeck,2018-09-28T20:30:45Z,fixed,0,0.975196123123169
221378081,5709,bbejeck,2018-09-28T20:51:02Z,ack,0,0.9720376133918762
221378533,5709,bbejeck,2018-09-28T20:52:52Z,ack,0,0.9720376133918762
221379140,5709,bbejeck,2018-09-28T20:55:35Z,ack,0,0.9720376133918762
221379486,5709,bbejeck,2018-09-28T20:57:04Z,ack,0,0.9720376133918762
221379642,5709,bbejeck,2018-09-28T20:57:43Z,ack,0,0.9720376133918762
221380525,5709,bbejeck,2018-09-28T21:01:54Z,"legacy comments, fixed",0,0.9870439171791077
221380620,5709,bbejeck,2018-09-28T21:02:14Z,ack,0,0.9720376133918762
221380780,5709,bbejeck,2018-09-28T21:03:07Z,ack,0,0.9720376133918762
221382112,5709,bbejeck,2018-09-28T21:09:24Z,ack,0,0.9720376133918762
221383257,5709,bbejeck,2018-09-28T21:15:18Z,"i had the same thought, but so far we've only discussed grabbing the first repartition topic name. i'm inclined to leave as is because 1) users don't care about the name as much as it doesn't change and break the topology and 2) imho will add some complexity without a significant benefit",0,0.5742315649986267
221383379,5709,bbejeck,2018-09-28T21:15:47Z,"i had the same thought, i think this just slipped.",-1,0.7726319432258606
221386486,5709,bbejeck,2018-09-28T21:32:45Z,"it comes from the `repartitiontopicnameprefix` passed as a parameter when calling `createrepartitionedsource`. since we may get an existing repartition topic name, we don't want to append `-repartition` at the end and change it. for example, we may get `kstream-aggregate-state-store-0000000005-repartition` for a repartition topic name resulting from an optimization operation and appending another `-repartition` would break the topology. as the java docs and our other docs state, we append as single `-repartition` to the repartition topic name we wouldn't want to double append. but i'll update this with a comment explaining why we do this check.",0,0.9824690818786621
221386734,5709,bbejeck,2018-09-28T21:33:53Z,ack,0,0.9720376133918762
221386797,5709,bbejeck,2018-09-28T21:34:13Z,ack,0,0.9720376133918762
221387336,5709,bbejeck,2018-09-28T21:36:49Z,ack,0,0.9720376133918762
221387515,5709,bbejeck,2018-09-28T21:37:46Z,"yeah, especially as `serialized` is deprecated, good catch!",1,0.9855272769927979
221388695,5709,bbejeck,2018-09-28T21:44:18Z,good catch actually `shouldkeeprepartitiontopicnameforgroupbynowindows`,1,0.6278407573699951
221431415,5709,vvcephei,2018-09-29T15:28:25Z,ack. it's probably also likely that the user who names some repartition topics names them all; another reason the extra complexity wouldn't buy anything.,0,0.9467951655387878
221431492,5709,vvcephei,2018-09-29T15:31:49Z,i agree we shouldn't append multiple suffixes. it just wasn't clear where the pre-suffixed string could come from. thanks for the clarification!,1,0.9676355719566345
221442359,5709,mjsax,2018-09-29T23:12:46Z,"this is ok, because not part of 2.0, right?",0,0.983014702796936
221442399,5709,mjsax,2018-09-29T23:15:37Z,"missing `, or ` and missing space before `operations`",0,0.9776460528373718
221442444,5709,mjsax,2018-09-29T23:18:45Z,`set the name` -- the specified name is part of the topic name -- think we should be more precise (note: i would not describe the used naming pattern in javadocs though) similar below in method javadocs.,0,0.9857402443885803
221442610,5709,mjsax,2018-09-29T23:30:15Z,nit: missing `.` at the end,0,0.9756535887718201
221442612,5709,mjsax,2018-09-29T23:30:21Z,nit: missing `.` at the end,0,0.9756535887718201
221442618,5709,mjsax,2018-09-29T23:30:47Z,"nit: missing `.` at the end oxford comma? nit: `{ name}, { keyserde}, and { valueserde}.` (similar below)",0,0.9859606027603149
221442626,5709,mjsax,2018-09-29T23:31:33Z,nit: `{ grouped}` similar below.,0,0.9875062704086304
221442659,5709,mjsax,2018-09-29T23:34:34Z,agreed with john. we should keep immutability. existing code also creates new objects. (similar below) also update javadocs `return this` above.,0,0.9833042621612549
221442678,5709,mjsax,2018-09-29T23:36:03Z,nit: fix indention,0,0.9871826171875
221442709,5709,mjsax,2018-09-29T23:38:20Z,return `new joined(...)`,0,0.9852163791656494
221442733,5709,mjsax,2018-09-29T23:40:00Z,nit: missing space,0,0.7560148239135742
221442771,5709,mjsax,2018-09-29T23:43:03Z,nit: update `xxx` to ` ` (or `<name>` to be more precise),0,0.9895833730697632
221442809,5709,mjsax,2018-09-29T23:46:11Z,"`the name for a repartition topic`: it's not the name, but part of the name only",0,0.9797652363777161
221442824,5709,mjsax,2018-09-29T23:47:42Z,"nice catch! (can you double check other javadocs, too. could be c&p error.)",1,0.9932645559310913
221442832,5709,mjsax,2018-09-29T23:48:24Z,nit: missing space,0,0.7560148239135742
221442841,5709,mjsax,2018-09-29T23:49:16Z,nit: missing space,0,0.7560148239135742
221442855,5709,mjsax,2018-09-29T23:50:04Z,nit: remove one space before `and the name...`,0,0.9851679801940918
221442858,5709,mjsax,2018-09-29T23:50:29Z,remove `<`,0,0.9756131768226624
221442872,5709,mjsax,2018-09-29T23:51:51Z,`maybe being` sounds a little odd to me... (not a native speaker though),-1,0.8937219381332397
221442895,5709,mjsax,2018-09-29T23:54:38Z,nit: why does left hand side needs to specify classed instead of interface?,0,0.9730273485183716
221442905,5709,mjsax,2018-09-29T23:55:17Z,why is `set` not sufficient?,0,0.9267056584358215
221442912,5709,mjsax,2018-09-29T23:55:43Z,why not `set` left hand side?,0,0.9749953150749207
221442930,5709,bbejeck,2018-09-29T23:57:12Z,"yes, that's correct. i checked out the `2.0` branch to confirm.",0,0.9848047494888306
221442957,5709,mjsax,2018-09-29T23:59:41Z,"nit: this is the user specified name, that is part of the repartition topic name -- we should rename this",0,0.9793150424957275
221442960,5709,mjsax,2018-09-30T00:00:39Z,nit: the use specified name is part of the repartition topic only -- we should rename this to `name` or `username`?,0,0.9888850450515747
221443004,5709,mjsax,2018-09-30T00:04:03Z,could we set `name` instead of `null` here and simplify other code (cf. my comments below) ?,0,0.9884058237075806
221443009,5709,mjsax,2018-09-30T00:04:28Z,remove `name` parameter ? (cf. comment above),0,0.9853209853172302
221443020,5709,mjsax,2018-09-30T00:05:18Z,i think we can remove `repartitiontopicbasename` entirely (cf. my comments from above),0,0.9883246421813965
221443050,5709,mjsax,2018-09-30T00:07:57Z,"cannot follow here... do you aim for existing topologies with generated names, and user update code to ""pin"" names? for this case, user would pass it name, without `-repartition` suffix? user, would also need to drop ` ` prefix in the name she passed to `grouped`.",0,0.9879655241966248
221443054,5709,mjsax,2018-09-30T00:08:40Z,nit: remove empty lines,0,0.9810540080070496
221443072,5709,mjsax,2018-09-30T00:09:37Z,"do we need this annotation again? though we would need a `(""deprecation"")` here instead?",0,0.986401379108429
221443096,5709,mjsax,2018-09-30T00:10:07Z,nit: 4 space indention only,0,0.982340931892395
221443107,5709,mjsax,2018-09-30T00:10:22Z,as above,0,0.9783914685249329
221443114,5709,mjsax,2018-09-30T00:10:54Z,nit: 4-space indention plus move `builder` down one line,0,0.9865070581436157
221443122,5709,mjsax,2018-09-30T00:11:19Z,as above,0,0.9783914685249329
221443126,5709,mjsax,2018-09-30T00:11:37Z,nit: 4-space indention,0,0.9854394197463989
221443137,5709,mjsax,2018-09-30T00:12:20Z,"no need to deprecate an internal class imho. maybe add `(""deprecation"")` instead?",0,0.9874017834663391
221443198,5709,mjsax,2018-09-30T00:16:18Z,should this not fail here in `groupbykey()` already? maybe use `try-fail-catch` pattern here.,0,0.9858936071395874
221443199,5709,mjsax,2018-09-30T00:16:39Z,nit: missing `t`,0,0.9517562985420227
221443236,5709,mjsax,2018-09-30T00:20:43Z,"not sure why this should not be allowed? to be more precise: i understand why the code fails, however, it's very unintuitive for the user why this would fail -- looks like valid code and imho, users should be allowed to write this code: both operations can reuse the same repartition topic anyway (and with optimization turned on, they will, if i don't miss anything). not sure if we can fix this easily to be honest, but accepting this as ""by design"" would not be user friendly. maybe we can merge both repartition topics into one for this case, too?",-1,0.597069501876831
221461753,5709,vvcephei,2018-09-30T14:39:15Z,"i suggested this. while it is normally better to use an interface on the lhs, it should only be done if the interface provides the correct semantics. i.e., you should be able to swap out any two implementations of the interface and maintain correct behavior. normally, when we work with maps or sets, we do indeed need just the semantics they promise (i.e., a k/v mapping, or the set property), and we could in theory use any implementation without changing the correctness of the program. but in this case, it seemed like the correct behavior of this class depends on maintaining these collections in insertion order. unfortunately, java does not have an interface for an ordered map or set. therefore, the most general ""interface"" that provides the correct semantics is actually just the implicit interface of linkedhashmap/set itself.",0,0.9586050510406494
221461770,5709,vvcephei,2018-09-30T14:39:48Z,this is also my fault... see [a link],-1,0.9861125349998474
221461780,5709,vvcephei,2018-09-30T14:40:14Z,this is also my fault... see [a link],-1,0.9861125349998474
221462040,5709,vvcephei,2018-09-30T14:51:38Z,"imho, it's better to pass along the deprecation instead of suppressing it. they both cause the compiler not to issue warnings about the use of deprecated apis in the method body. this difference is that if we suppress it here, then any `groupby` calls on a `kstreamimpl` reference *will not* issue a warning, whereas calls on a `kstream` reference will issue the warning as desired.",0,0.9862462282180786
221462114,5709,vvcephei,2018-09-30T14:54:50Z,this is the same thinking as [a link] .,0,0.9818106889724731
221470735,5709,guozhangwang,2018-09-30T19:41:53Z,"also we should indicate that it is for setting the repartition topic ""if necessary: streams will not always create the repartition topic for grouped operation"".",0,0.9887480735778809
221470841,5709,guozhangwang,2018-09-30T19:44:56Z,this just occurred to me that `grouped.named()` is a bit weird when writing it down. could we rename it to `grouped.as()` or `grouped.for`? wdyt,-1,0.5860698223114014
221471094,5709,guozhangwang,2018-09-30T19:51:00Z,`will be` -> `may need to be created in kafka if a later operator depends on the newly selected key.` ditto elsewhere.,0,0.9724979996681213
221471436,5709,guozhangwang,2018-09-30T20:00:14Z,"`repartitiontopicname` and `repartitiontopic` is a bit confusing. i'd suggest just keeping the `groupedinternal` as a field to replace key/valueserde and `repartitiontopicname` in the constructor and retrieve its fields later. ditto for other internal class's constructors (you already replaced serdes with the object in some classes, just trying to suggest consistency here).",-1,0.8119910359382629
221471570,5709,guozhangwang,2018-09-30T20:03:37Z,"i cannot follow here too.. the `createrepartitionedsource` should always be called before the optimization kicks in, so the passed in name should always be the raw names right?",0,0.9839131236076355
221471689,5709,guozhangwang,2018-09-30T20:07:31Z,+1,0,0.696722686290741
221471765,5709,guozhangwang,2018-09-30T20:09:21Z,not clear what is this test used for?,0,0.8817374110221863
221471837,5709,guozhangwang,2018-09-30T20:11:46Z,"i think the reason is that we do not check for unique names at grouped / joined, and hence only when later when the repartition topics are indeed going to be created the exception will be thrown. this looks fine to me.",0,0.8349775075912476
221471891,5709,guozhangwang,2018-09-30T20:14:32Z,"seems for joined we do not have a test to check for naming uniqueness yet, could we add one?",0,0.9830137491226196
221476261,5709,mjsax,2018-09-30T22:37:37Z,"i don't think that suppress works for any callers of `kstreamimpl#groupby` -- from my understanding, there will be a warning for all callers independently of a suppress annotation -- callers would need to add their own annotation to suppress the warning for them. a `suppresswarning` only suppressed warning from the body/implementation of this method (ie, if we would call any other deprecated method). i also don't think we need `` as this annotation is inherited anyway. however, this is an internal class anyway, and thus, not public. thus, i don't have a strong opinion on this.",0,0.9692821502685547
221476305,5709,mjsax,2018-09-30T22:39:26Z,ack. thanks for clarification.,1,0.8435558676719666
221476351,5709,mjsax,2018-09-30T22:41:33Z,that's a good point. `grouped.as()` sounds ok (`grouped.for()` sounds weird to me though).,0,0.5677921175956726
221476723,5709,bbejeck,2018-09-30T22:56:31Z,ack,0,0.9720376133918762
221477923,5709,bbejeck,2018-09-30T23:41:23Z,ack,0,0.9720376133918762
221477926,5709,bbejeck,2018-09-30T23:41:26Z,"ack, changed the suggested order a bit, but imho the message is the same.",0,0.9861964583396912
221477927,5709,bbejeck,2018-09-30T23:41:28Z,ack,0,0.9720376133918762
221477928,5709,bbejeck,2018-09-30T23:41:30Z,ack,0,0.9720376133918762
221477929,5709,bbejeck,2018-09-30T23:41:32Z,ack,0,0.9720376133918762
221477932,5709,bbejeck,2018-09-30T23:41:35Z,ack,0,0.9720376133918762
221477934,5709,bbejeck,2018-09-30T23:41:37Z,ack,0,0.9720376133918762
221477937,5709,bbejeck,2018-09-30T23:41:40Z,"ack, updated other methods as well.",0,0.9884240031242371
221477940,5709,bbejeck,2018-09-30T23:41:43Z,ack,0,0.9720376133918762
221477941,5709,bbejeck,2018-09-30T23:41:46Z,ack,0,0.9720376133918762
221477959,5709,bbejeck,2018-09-30T23:41:52Z,ack,0,0.9720376133918762
221477965,5709,bbejeck,2018-09-30T23:41:55Z,ack,0,0.9720376133918762
221477967,5709,bbejeck,2018-09-30T23:41:57Z,ack,0,0.9720376133918762
221477968,5709,bbejeck,2018-09-30T23:42:01Z,ack,0,0.9720376133918762
221477969,5709,bbejeck,2018-09-30T23:42:03Z,ack,0,0.9720376133918762
221477999,5709,bbejeck,2018-09-30T23:43:22Z,"yeah i agree, updated.",0,0.9586125016212463
221478087,5709,bbejeck,2018-09-30T23:46:58Z,"additionally, i would in most circumstances agree with specifying the interface, but since these are private variables on an internal class, there is no ""leaking"" of an implementation.",0,0.9864696264266968
221478133,5709,bbejeck,2018-09-30T23:49:12Z,ack,0,0.9720376133918762
221478190,5709,bbejeck,2018-09-30T23:50:40Z,ack,0,0.9720376133918762
221482476,5709,bbejeck,2018-10-01T01:40:31Z,ack,0,0.9720376133918762
221482479,5709,bbejeck,2018-10-01T01:40:35Z,ack,0,0.9720376133918762
221483107,5709,bbejeck,2018-10-01T01:51:12Z,ack already done,0,0.9859992861747742
221483292,5709,bbejeck,2018-10-01T01:54:33Z,ack,0,0.9720376133918762
221483725,5709,bbejeck,2018-10-01T02:02:28Z,ack,0,0.9720376133918762
221484247,5709,bbejeck,2018-10-01T02:11:42Z,ack,0,0.9720376133918762
221484591,5709,bbejeck,2018-10-01T02:17:43Z,ack,0,0.9720376133918762
221485045,5709,bbejeck,2018-10-01T02:24:39Z,"as pointed out, the error does not occur until we go to build the topology and the duplicate topic name is detected and at that point, the error is thrown. i can update with the `try-fail-catch` pattern, but have we established this as a convention of unit tests vs using the `(expected=...)` approach?",0,0.9785091280937195
221485076,5709,bbejeck,2018-10-01T02:25:06Z,ack,0,0.9720376133918762
221490175,5709,bbejeck,2018-10-01T03:40:05Z,"just asserting that the different repartition topic base names resulted in successfully building the topology, but this is covered from other tests, so i'll remove it",0,0.9860171675682068
221490839,5709,mjsax,2018-10-01T03:48:48Z,"i personally highly prefer the try-fail-catch pattern, because it allows to narrow down which operation throws the exception. the current test would pass if the same exception is thrown one line above. imho, the `expected` annotation should only be used, if no other part in the test code could potentially throw the same exception (what is rarely the case).",0,0.6359111666679382
221490975,5709,bbejeck,2018-10-01T03:50:34Z,ack,0,0.9720376133918762
221491369,5709,bbejeck,2018-10-01T03:55:57Z,"ack, i believe i've cleaned this up.",0,0.6963471174240112
221492650,5709,bbejeck,2018-10-01T04:14:00Z,"ack, `grouped.as` is better, i'll update.",0,0.9862637519836426
221496830,5709,bbejeck,2018-10-01T05:12:28Z,"i agree, but imho it's exposing some unintuitive behavior with respect to creating multiple repartition topics. and yes with optimizations turned on users will be able to write code in this form. but as it stands now, by explicitly naming a repartition i don't see how we can re-use a single `kgroupedstream` instance, as before we relied on the auto-generated names to handle the creation of multiple repartition topics. i'm not sure i follow, do you mean in this case we do an automatic optimization and merge repartition topics ""in-line""? if so, i'm inclined to say yes we can, but i'm thinking this may be done best in a follow-on pr. wdyt?",0,0.945818305015564
221509793,5709,mjsax,2018-10-01T07:08:07Z,"something like this -- the idea would be to set a ""flag"" on the `kgroupedstream` (same for `kgroupedtable`?) after the first `count()/reduce()/aggregate()` is executed and to remember the created repartition topic. and for this case, consecutive `count()/reduce()/aggregate()` would skip creating a new changelog topic but reuse the already created one. for backward compatibility, we would only do this if `grouped.as` is specified. it might be a little bit hacky, but might be worth it... thoughts?",0,0.9130262136459351
221629926,5709,bbejeck,2018-10-01T14:29:31Z,"i like the idea; i'll try and implement that now edit: looking at this i have some more thoughts. why limit to just when people name the repartition topic? since we have a graph now, we can keep a reference to the repartition graph node and at this point in the code always re-use this node for repartitioning. but this could be tricky as this will still affect an existing topology. for example, consider a user with multiple `kgroupedstream` calls where a repartition is required. while this means we have created multiple repartition topics, this also means that we have incremented the processor counter n times (n being the number of repartition topics). if we adopt this approach, and the user names the repartition topic, and we reuse the first created repartition topic, we'll change the number of all downstream operations including changelog topics and any other repartition topics. this ""skipping incrementing"" is similar to what happened when re-using a source topic for source `ktable` changelogs. while i realize most users will probably name all repartition topics, by doing so, they'll have to ensure they name any changelog topics as well if we reuse the repartition topics in-line. with the current optimization approach the numbering isn't affected, we move the nodes around. additionally, i""m not sure how this will affect the current optimization approach (maybe change it, as i think if we keep repartition node references as we go we could have ""automatic"" partial merging ?) i'm thinking this approach is could worth looking into, but as an immediate follow-on pr to this one as this requires some thought. wdyt?",1,0.8787609338760376
221679349,5709,mjsax,2018-10-01T16:47:28Z,"for backward compatibility. for new topologies, we should not need to care, because i would assume that users turn on optimization.",0,0.9221245646476746
221817992,5709,mjsax,2018-10-02T03:36:39Z,nit: `create [a] repartition topic` -- or `create repartition topic[s] for`,0,0.9857925772666931
221818181,5709,mjsax,2018-10-02T03:38:51Z,nit `uses [as] part` ?,0,0.9871434569358826
221818570,5709,mjsax,2018-10-02T03:42:41Z,`for` -> `as` ?,0,0.9862716197967529
221818628,5709,mjsax,2018-10-02T03:43:25Z,`@{grouped}` -> `{ grouped}` or `{ grouped}`,0,0.9844919443130493
221818784,5709,mjsax,2018-10-02T03:45:18Z,`{ grouped}` and `{ grouped}` is mixed comparing different methods -- we should unify.,0,0.9880281686782837
221819043,5709,mjsax,2018-10-02T03:48:20Z,"comparing javadocs with `joined`: there we point out that `null` is ok for `serdes` and the usage from config `serdes` -- we should do this here, too.",0,0.9867746829986572
221819137,5709,mjsax,2018-10-02T03:49:40Z,"comparing javadocs with `joined`: there we point out that `null` is ok for `serdes` and the usage from config `serdes` -- we should do this here, too. also for `` docs -- check other methods, too, please.",0,0.9861325025558472
221819376,5709,mjsax,2018-10-02T03:52:36Z,nit: `..` -> `.`,0,0.975188672542572
221819613,5709,mjsax,2018-10-02T03:55:02Z,`xxx` -> ` `,0,0.9795598983764648
221820266,5709,mjsax,2018-10-02T04:02:10Z,nit: remove var `newjoined` (also not used for left-hand-side code),0,0.9869173765182495
221820519,5709,mjsax,2018-10-02T04:05:01Z,"was this a bug, to pass in `null` as value serde? did guozhang's pr introduce this?",0,0.9608682990074158
221820603,5709,mjsax,2018-10-02T04:06:08Z,similar here?,0,0.9843258261680603
221820654,5709,mjsax,2018-10-02T04:06:39Z,nit: remove `this.`,0,0.9779589176177979
222098442,5709,bbejeck,2018-10-02T20:22:58Z,ack,0,0.9720376133918762
222099260,5709,bbejeck,2018-10-02T20:25:29Z,ack,0,0.9720376133918762
222099946,5709,bbejeck,2018-10-02T20:27:48Z,ack,0,0.9720376133918762
222102316,5709,bbejeck,2018-10-02T20:35:30Z,ack,0,0.9720376133918762
222103740,5709,bbejeck,2018-10-02T20:40:05Z,"ack, going with `{ grouped}`",0,0.9868799448013306
222110689,5709,bbejeck,2018-10-02T21:01:45Z,ack,0,0.9720376133918762
222115262,5709,bbejeck,2018-10-02T21:16:56Z,ack,0,0.9720376133918762
222115412,5709,bbejeck,2018-10-02T21:17:29Z,ack,0,0.9720376133918762
222115625,5709,bbejeck,2018-10-02T21:18:15Z,ack,0,0.9720376133918762
222117740,5709,bbejeck,2018-10-02T21:26:03Z,"we need this right now to work with generics as the `repartitionforjoin` signature is ` repartitionforjoin(final joined ` but the right-hand side is ` ` and the left-hand side is ` `. i know it's a bit of a hack, but i think it's worth the trade-off for being able to pass a single `joined` parameter, vs. all of the required components of `joined`. having the single `joined` parameter was introduced from the serdes inheritance pr. if you insist i can revert to what it was before.",0,0.9246132969856262
222117869,5709,bbejeck,2018-10-02T21:26:26Z,introduced by the serdes inheritance pr,0,0.9851363301277161
222117907,5709,bbejeck,2018-10-02T21:26:35Z,same as above,0,0.9772257208824158
222118272,5709,bbejeck,2018-10-02T21:27:49Z,ack,0,0.9720376133918762
222129874,5709,mjsax,2018-10-02T22:15:53Z,ack. makes sense.,0,0.9650564193725586
51845565,812,xiaotao183,2016-02-04T09:11:53Z,sasl_callback_handler_class must be part of `addclientsaslsupport` in order to take effect,0,0.9889535903930664
52296579,812,rajinisivaram,2016-02-09T11:36:07Z,"yes, of course. thank you, will add the missing line.",1,0.7060158848762512
54384085,812,ijuma,2016-02-29T09:11:37Z,don't we have to update this to have a separate `loginmanager` per mechanism?,0,0.9847516417503357
54396485,812,rajinisivaram,2016-02-29T11:11:12Z,"the implementation uses a single login context with multiple login modules to support multiple mechanisms. since login is associated with login context rather than login module, one loginmanager per login type is sufficient.",0,0.9880163073539734
58483193,812,junrao,2016-04-05T03:44:57Z,could we just use configs.getstring and avoid casting? there are a few other places like that.,0,0.980225145816803
58483211,812,junrao,2016-04-05T03:45:09Z,"in the server mode, should we even check haskerberos since saslconfigs.gssapi_mechanism is for the client?",0,0.9902783036231995
58483235,812,junrao,2016-04-05T03:45:26Z,"it seems that we have an existing issue in the handling of case initial. if we can't completely write all bytes of the sasl token, we have to rely on the next call of authenticate() to finish writing the remaining bytes. however, when the write completes, we will go to the initial state and try to send the token again. it seems that we should be transitioning to the intermediate state after the write completes. the same issue seems to exist when transitioning from send_mechanism to receive_mechanism_response, if we can't write all bytes in saslmechanismrequest in one send call.",0,0.9749312996864319
58483242,812,junrao,2016-04-05T03:45:35Z,should we always return the enabled mechanism list?,0,0.9886356592178345
58483259,812,junrao,2016-04-05T03:45:51Z,could we handle an explicit exception due to the first packet not being a mechanismrequest? i was thinking that we can catch all exceptions from saslmechanismrequest(bytebuffer buffer) and convert that to a schemaexception.,0,0.9869694709777832
58483268,812,junrao,2016-04-05T03:46:00Z,"hmm, the client may not understand mechanismresponse if it doesn't send mechanismrequest in the first place.",0,0.9678685665130615
58483270,812,junrao,2016-04-05T03:46:09Z,"similar to saslclientauthenticator, it seems that we need to deal with the case that not all bytes in netoutbuffer can be sent in a single authenticate() call.",0,0.986011266708374
58483294,812,junrao,2016-04-05T03:46:39Z,"could you update the security section of the documentation on the support of new mechanism, how to specify and plug in plainloginmodule, and what it takes to enable multiple mechanisms on the broker side?",0,0.9894523620605469
58537309,812,ijuma,2016-04-05T13:30:28Z,"this is just a `map`, so we can't use `getstring`. i wanted to change `configure` to take a `config` type for this reason, but it would break api classes unfortunately.",0,0.7405529022216797
58747063,812,rajinisivaram,2016-04-06T17:28:42Z,"you are right, server doesn't need to check the sasl mechanism. but it can disable kerberos if gssapi is not included in `enabledmechanisms`. have updated the check.",0,0.9770352840423584
58747189,812,rajinisivaram,2016-04-06T17:29:29Z,"thank you, i have fixed setting of sasl state.",1,0.8527494668960571
58747357,812,rajinisivaram,2016-04-06T17:30:17Z,have updated to include enabled mechanisms in response for successful response.,0,0.982401430606842
58747425,812,rajinisivaram,2016-04-06T17:30:35Z,done.,0,0.9759407639503479
58747950,812,rajinisivaram,2016-04-06T17:33:26Z,"yes, i wasn't sure whether to send the response in this case. but i thought it would be useful to send it before the connection is closed since it may be useful if you are looking at the bytes returned for debugging purposes.",0,0.9829075932502747
58747999,812,rajinisivaram,2016-04-06T17:33:41Z,"done, same as before.",0,0.9831531643867493
58748697,812,rajinisivaram,2016-04-06T17:38:14Z,i have opened another jira (kafka-3517) to update the docs. will submit a pr.,0,0.9796455502510071
59741966,812,ijuma,2016-04-14T15:51:06Z,`apikeys.forid` (which is called by `getrequest` and by ourselves) throws `illegalargumentexception` if the api key is not within range. should we be catching that and throwing a more informative error?,0,0.9733027219772339
59842206,812,rajinisivaram,2016-04-15T08:30:30Z,"thank you for the review. since the first gssapi token starting with 0x60 (when handshake request is omitted) can also be an invalid api key (unlikely since `requestheader.parse` will probably throw `schemaexception`, but still possible i suppose), i changed the code to revert to gssapi for `illegalargumentexception` as well.",1,0.8918854594230652
60461201,812,junrao,2016-04-20T18:21:17Z,could we add the place-holder for those two error codes in errormapping?,0,0.9876700639724731
60461220,812,junrao,2016-04-20T18:21:22Z,should we also add the illegalsaslsate error code?,0,0.9480082988739014
60461542,812,junrao,2016-04-20T18:23:15Z,should we include throws kafkaexception in the signature of configure() and close()? it's uncaught exception anyway.,0,0.9718320965766907
60461708,812,junrao,2016-04-20T18:24:18Z,"it seems that for both client and server, login uses the same clientcallbackhandler. the existing code works like that. is that correct? if so, perhaps we should rename clientcallbackhandler to sth more generic?",0,0.9880335927009583
60461752,812,junrao,2016-04-20T18:24:33Z,"hmm, it's a bit weird that we instantiate a clientcallbackhandler here and also in defaultlogin. could we just create it once and reuse?",-1,0.9747139811515808
60461827,812,junrao,2016-04-20T18:24:56Z,"hmm, should we do that? so for, we only guarantee old version of java client can talk to new version of server. but there is no guarantee that new version of java client can talk to old version of server. so, it seems simpler to always let the new client send saslhandshakerequest. this also makes it easier to add apiversionrequest in the future (kip-35).",0,0.9811084866523743
60461839,812,junrao,2016-04-20T18:25:02Z,would it be better to rename this to receiveresponseortoken()?,0,0.9874621033668518
60461878,812,junrao,2016-04-20T18:25:14Z,"since we can receive both sasl tokens or a response, perhaps we should rename servertoken to sth more general?",0,0.9880437254905701
60461893,812,junrao,2016-04-20T18:25:19Z,"for consistency, should we rename clientcallbackhandler to saslclientcallbackhandler?",0,0.9889845848083496
60461901,812,junrao,2016-04-20T18:25:24Z,the comment seems obsolete.,0,0.5939311981201172
60461930,812,junrao,2016-04-20T18:25:30Z,should we change init to sth like handshake_request to match what's in the client?,0,0.9848189353942871
60461969,812,junrao,2016-04-20T18:25:41Z,could we rename the above to plainsaslproducer and plainsaslconsumer to distinguish from plain text port?,0,0.9895121455192566
60499829,812,rajinisivaram,2016-04-20T22:37:50Z,done.,0,0.9759407639503479
60499881,812,rajinisivaram,2016-04-20T22:38:21Z,"yes, added.",0,0.9807703495025635
60499925,812,rajinisivaram,2016-04-20T22:38:42Z,removed exception from signature.,0,0.9751715660095215
60500580,812,rajinisivaram,2016-04-20T22:43:47Z,"yes, it was like that with kerberos, and i imagine the class was reused to avoid code duplication. but actually i think it is better to use a different class for login to make the logic clearer and more readable. i have added a different callback handler in defaultlogin with just the callbacks for login. there is some overlap with the client callback handler. let me know what you think.",0,0.9682365655899048
60500774,812,rajinisivaram,2016-04-20T22:45:22Z,see note above.,0,0.9786888360977173
60501307,812,rajinisivaram,2016-04-20T22:49:28Z,"we need this for rolling upgrade from 0.9.0.x to 0.10.0 when sasl is used for inter-broker communication. we can remove this in the release that follows (the next minor release perhaps), thus providing a non-disruptive upgrade path. will that be ok?",0,0.9873462319374084
60501331,812,rajinisivaram,2016-04-20T22:49:37Z,done.,0,0.9759407639503479
60501345,812,rajinisivaram,2016-04-20T22:49:46Z,done.,0,0.9759407639503479
60501397,812,rajinisivaram,2016-04-20T22:50:17Z,"renamed and moved to top-level class, consistent with saslservercallbackhandler.",0,0.9872558116912842
60501417,812,rajinisivaram,2016-04-20T22:50:28Z,removed comment.,0,0.9028335213661194
60501435,812,rajinisivaram,2016-04-20T22:50:34Z,done.,0,0.9759407639503479
60501449,812,rajinisivaram,2016-04-20T22:50:44Z,done.,0,0.9759407639503479
60517713,812,junrao,2016-04-21T02:13:03Z,"very good point. for backward compatibility, we can probably just guard that by inter.broker.protocol version. if the version is >= 0.10.0, we will use the new protocol. otherwise, use the old one.",1,0.9611966013908386
60558377,812,rajinisivaram,2016-04-21T10:25:56Z,"thank you, that makes sense. i have updated the code and the kip. since the version comparison code is in `core`, to avoid duplicating too much logic in `clients`, i am checking for 0.9.0 rather than 0.10.0. hope that is ok.",1,0.9691222906112671
60589714,812,junrao,2016-04-21T14:27:50Z,"hmm, we want to check inter.broker.protocol.version >= 0.10.0. this is easier if we can use the case object in core. since we only need to use the old protocol when saslclientauthethicator is used at the broker side. perhaps, we can check inter.broker.protocol.version in the broker code and pass a flag into inter.broker.protocol.version. the places where we use saslclientauthethicator are in replicafetcherthread, controllerchannelmanager, and kafkaserver (for controlled shutdown). when used in clients (producer/consumer), saslclientauthethicator will always use the new protocol.",0,0.9758560657501221
60611214,812,rajinisivaram,2016-04-21T16:16:29Z,thank you for the review. i have moved the version check to `core`.,1,0.9208711981773376
60831292,812,ijuma,2016-04-23T16:54:18Z,"i wonder if we should be adding server-only configs here, it doesn't seem like there is much benefit (although i understand that we may have done that for some configs in the past).",0,0.847931444644928
60831331,812,ijuma,2016-04-23T16:55:54Z,is it worth mentioning the following as a reference for mechanism names in a comment? [a link],0,0.9877122044563293
60831526,812,ijuma,2016-04-23T17:06:02Z,"nevermind, we do actually need this because we use this property in `common` classes.",0,0.9853153228759766
60831568,812,ijuma,2016-04-23T17:10:29Z,why do we need these as fields?,0,0.970455527305603
60831627,812,ijuma,2016-04-23T17:13:32Z,nit: is there a `the` missing between `supported` and `requested`?,0,0.9891799688339233
60831641,812,ijuma,2016-04-23T17:14:15Z,nit: replace `in` with `given`?,0,0.9860592484474182
60831687,812,ijuma,2016-04-23T17:17:28Z,nit: `the` missing before `mechanism`?,0,0.986076295375824
60831696,812,ijuma,2016-04-23T17:17:52Z,this should be final.,0,0.9756804704666138
60831745,812,ijuma,2016-04-23T17:20:01Z,this should be final and the `arraylist` should be assigned only after it's fully constructed (this ensures thread-safety).,0,0.9871962070465088
60831757,812,ijuma,2016-04-23T17:20:46Z,nit: space missing before `:`,0,0.9414767026901245
60831862,812,ijuma,2016-04-23T17:28:38Z,"would this not be slightly better if we used `errors.forcode` and then did a switch on the enum? also, we should not compare to `0`, we should use `errors.none`.",0,0.9821053743362427
60831892,812,ijuma,2016-04-23T17:30:51Z,this is the same code that is in `networkclient.correlate`. maybe we can make that a static public method and reuse it.,0,0.9873461127281189
60831968,812,ijuma,2016-04-23T17:34:26Z,can we please group final fields first and then the non final fields? it makes easier to understand what gets set during construction versus mutable fields.,0,0.984961748123169
60832031,812,ijuma,2016-04-23T17:36:29Z,"i think suggested that we should send the enabled mechanisms in the successful case, but i don't understand the purpose. this bloats the response for the common case without any benefit that i can see. thoughts ?",0,0.6148588061332703
60832070,812,ijuma,2016-04-23T17:38:14Z,"nit: for fields that are initialised during `configure`, i think it's better to keep them `null` until `configure` is called. it makes it easier to debug if something goes wrong.",0,0.9846127033233643
60832315,812,ijuma,2016-04-23T17:54:52Z,i'm wondering if this is really necessary. could we instead add the sasl properties to the properties returned by this method via a utility method that added them only if necessary? it seems like we don't gain much by doing it this way and it adds one more parameter to a very large number of parameters already.,0,0.9185646772384644
60832411,812,ijuma,2016-04-23T18:02:18Z,did you really mean to have different indenting between lines? i think it would be nicer if these 3 lines were at the same indentation. we can change `jaassection.tostring` if it's relying on the current behaviour.,0,0.9848909974098206
60833139,812,ijuma,2016-04-23T18:50:31Z,maybe we don't need `option` here. `option` is useful when we want the behaviour of `none` to be different than the empty case.,0,0.9858381152153015
60833170,812,ijuma,2016-04-23T18:52:29Z,"it's more readable if we write this as `map { case (user, password) => (s""user_$user"" -> password }` or something like that.",0,0.9883047342300415
60833256,812,ijuma,2016-04-23T18:58:26Z,you can do something like [code block],0,0.9874047636985779
60833263,812,ijuma,2016-04-23T18:59:29Z,it's generally preferable to use `getorelse` with an appropriate message for the case when one passes a `none` when a `some` is expected.,0,0.9870109558105469
60833297,812,ijuma,2016-04-23T19:02:24Z,"hmm, maybe the way you did is better since subsequent lines are a continuation of previous lines.",0,0.969692587852478
60833355,812,ijuma,2016-04-23T19:07:30Z,it seems that this is used for inter-broker communication. shouldn't we be using the same pattern we used for `interbrokersecurityprotocol`?,0,0.986781656742096
60833773,812,ijuma,2016-04-23T19:39:34Z,not worth having an empty `return` annotation.,-1,0.698531985282898
60833788,812,ijuma,2016-04-23T19:40:57Z,i think it would be nicer if we had a separate `abstractlogin` that `kerberoslogin` inherits from. inheritance from concrete classes is good to avoid as it tends to be brittle.,0,0.8686079382896423
60834053,812,ijuma,2016-04-23T19:56:47Z,"because these tests take a while to run, would it make sense to only have `saslmultimechanismconsumertest`?",0,0.9798591136932373
60834178,812,ijuma,2016-04-23T20:05:49Z,do we need some negative tests (eg clients connects with unsupported mechanism and client tries sasl handshake after connection is established).,0,0.9278982281684875
60847448,812,junrao,2016-04-24T16:37:46Z,"could we add some comments here and saslclientcallbackhandler to distinguish between the two (e..g, which callbacks are expected in each handler)? also, it seems that passwordcallback is never supposed to be called during login?",0,0.9902194142341614
60847587,812,junrao,2016-04-24T16:45:41Z,"my feeling is that always returning enabledmechanisms makes the protocol a bit simpler. also, the client can always know what the available mechanisms are.",0,0.9078516960144043
60852892,812,ijuma,2016-04-24T22:07:27Z,we have `auth` and `authenticator` packages. what's the thinking regarding when to use one versus the other?,0,0.9869499802589417
60853278,812,ijuma,2016-04-24T22:42:18Z,is the plan to allow users to provide their own `login`? is that why we have a `configure` method instead of passing the parameters via the constructor?,0,0.9861102104187012
60853355,812,ijuma,2016-04-24T22:46:25Z,nitpick: is it worth having this as a field? seems like we could just create it and pass it to the `logincontext` constructor.,0,0.9874001145362854
60853535,812,ijuma,2016-04-24T23:01:36Z,"this should be in the ""assigned in `configure`"" section of fields.",0,0.9882176518440247
60853576,812,ijuma,2016-04-24T23:05:17Z,i think i'd configure this right after creating the callback handler instead of in this method.,0,0.9879149198532104
60853631,812,ijuma,2016-04-24T23:09:48Z,we should use interpolation instead of string concat here.,0,0.9861086010932922
60853650,812,ijuma,2016-04-24T23:11:20Z,"`send` is already doing this, right?",0,0.9864343404769897
60853663,812,ijuma,2016-04-24T23:13:41Z,"can you please add a comment on how the `pendingsaslstate` is used? it seems correct to me, but it will be helpful for others reading the code.",0,0.981597900390625
60853704,812,ijuma,2016-04-24T23:16:52Z,i wonder if more of this code is generic and should be pushed somewhere else.,0,0.6967084407806396
60853743,812,ijuma,2016-04-24T23:21:02Z,this cast is redundant.,0,0.8715046644210815
60853821,812,ijuma,2016-04-24T23:25:22Z,"if the server is expecting gssapi, would it not disconnect the client? if we want to wrap any `schemaexception` into an `authenticationexception`, we should probably include the rest of the code in this method into the `try` block. and we would probably want to catch `illegalargumentexception` too.",0,0.9877920746803284
60853909,812,ijuma,2016-04-24T23:32:00Z,is there some other information we can provide for the non kerberos case?,0,0.9876452088356018
60853932,812,ijuma,2016-04-24T23:33:39Z,calling `getprivatecredentials` and `getpubliccredentials` twice is a bit messy. not sure if we can make it better though.,-1,0.9322272539138794
60854042,812,ijuma,2016-04-24T23:39:23Z,this can still be final right?,0,0.9858127236366272
60854807,812,ijuma,2016-04-25T00:29:16Z,does this imply that we should not ship this with our production-ready code?,0,0.9298416376113892
60855186,812,ijuma,2016-04-25T00:51:30Z,it may be worth saying that only `plain` is supported.,0,0.9865434765815735
60855233,812,ijuma,2016-04-25T00:53:44Z,perhaps it would be good to include some more information (ie the number of tokens was not correct),0,0.9834167957305908
60855240,812,ijuma,2016-04-25T00:54:12Z,style nit: i think this should be `authorizationid`.,0,0.9880401492118835
60855258,812,ijuma,2016-04-25T00:54:48Z,we should use `isempty` instead of `length == 0`,0,0.9864505529403687
60855285,812,ijuma,2016-04-25T00:55:58Z,is it worth concatenating the message given that we are passing the exception as the cause anyway?,0,0.9824056029319763
60855298,812,ijuma,2016-04-25T00:56:58Z,should we be returning `null` here?,0,0.9797699451446533
60855309,812,ijuma,2016-04-25T00:57:37Z,i guess it's ok to leave as is because the method that returns this needs to match the name provided by `saslserver`.,0,0.9832716584205627
60855865,812,ijuma,2016-04-25T01:12:23Z,it seems to me that this should be the other way around: [code block],0,0.9726396799087524
60856113,812,ijuma,2016-04-25T01:25:21Z,indenting.,-1,0.7923130989074707
60856117,812,ijuma,2016-04-25T01:25:34Z,indenting.,-1,0.7923130989074707
60856366,812,ijuma,2016-04-25T01:32:18Z,can we group final fields please?,0,0.9876400828361511
60856398,812,ijuma,2016-04-25T01:32:56Z,"as for the client, it would be good to have a comment explaining why we need a `pendingsaslstate`",0,0.9823887944221497
60856514,812,ijuma,2016-04-25T01:35:50Z,there's an extra space after `=`.,0,0.9828792214393616
60856547,812,ijuma,2016-04-25T01:37:35Z,i would configure the callback handler after creating it.,0,0.9858629107475281
60856567,812,ijuma,2016-04-25T01:38:38Z,"not sure about this magic, i don't think we do that for inter-broker communication. it may be better to add some validation to `kafkaconfig` for consistency.",0,0.909532368183136
60856584,812,ijuma,2016-04-25T01:39:18Z,i think it would be better to leave this as `null` until it is initialised in `configure`.,0,0.9859722852706909
60856700,812,ijuma,2016-04-25T01:43:58Z,we should use interpolation instead of string concatenation.,0,0.9845967888832092
60857015,812,ijuma,2016-04-25T01:55:44Z,do we actually need this `removeinterestops`? it seems to me that we remove it in `flushnetoutbufferandupdateinterestops` before we reach here.,0,0.9878724813461304
60857041,812,ijuma,2016-04-25T01:56:04Z,can you please explain why we need this now? it may be worth a comment.,0,0.935295581817627
60894701,812,rajinisivaram,2016-04-25T10:48:10Z,done.,0,0.9759407639503479
60894764,812,rajinisivaram,2016-04-25T10:48:51Z,removed fields.,0,0.9644595980644226
60894790,812,rajinisivaram,2016-04-25T10:49:00Z,added.,0,0.9763525128364563
60894807,812,rajinisivaram,2016-04-25T10:49:10Z,added.,0,0.9763525128364563
60894823,812,rajinisivaram,2016-04-25T10:49:21Z,done.,0,0.9759407639503479
60894837,812,rajinisivaram,2016-04-25T10:49:33Z,done.,0,0.9759407639503479
60894885,812,rajinisivaram,2016-04-25T10:49:48Z,added space.,0,0.977220892906189
60894913,812,rajinisivaram,2016-04-25T10:50:01Z,done.,0,0.9759407639503479
60895052,812,rajinisivaram,2016-04-25T10:51:30Z,couldn't find a good place for the common code. added a static method in `networkclient` for use in both `networkclient` and `saslclientauthenticator`.,0,0.8874034285545349
60895106,812,rajinisivaram,2016-04-25T10:52:03Z,leaving as is as-per jun's suggestion.,0,0.9791993498802185
60895309,812,rajinisivaram,2016-04-25T10:54:01Z,"agree that there are too many parameters already. but a similar pattern is used for producers and consumers as well. rather than change them all to call additional methods, leaving as-is for now. this keeps it consistent with the way ssl properties are set.",0,0.9827513098716736
60895385,812,rajinisivaram,2016-04-25T10:54:42Z,updated.,0,0.9759359955787659
60895402,812,rajinisivaram,2016-04-25T10:54:53Z,done.,0,0.9759407639503479
60895427,812,rajinisivaram,2016-04-25T10:55:06Z,done.,0,0.9759407639503479
60895436,812,rajinisivaram,2016-04-25T10:55:15Z,done.,0,0.9759407639503479
60895583,812,rajinisivaram,2016-04-25T10:56:36Z,"since the property is used by common code rather than broker-specific code, the same property is used for both clients and broker.",0,0.9866021871566772
60895608,812,rajinisivaram,2016-04-25T10:56:48Z,removed.,0,0.9311882257461548
60895633,812,rajinisivaram,2016-04-25T10:56:59Z,done.,0,0.9759407639503479
60895764,812,rajinisivaram,2016-04-25T10:58:19Z,i think it is useful to have at least one test for sasl/plain that doesn't use gssapi since some codepaths are not enabled when gssapi is disabled. i have removed one of the sasl/plain tests and left one in.,0,0.9736131429672241
60895960,812,rajinisivaram,2016-04-25T11:00:26Z,i have another changeset with unit tests for sasl in the `clients` project. i will rebase and submit that once this is committed.,0,0.9876592755317688
60896246,812,rajinisivaram,2016-04-25T11:03:27Z,"i have added comments. `passwordcallback` shouldn't be called with the standard login modules during login. but since you may want to plugin custom login modules, especially for plain, it makes sense to throw an appropriate exception if it was called.",0,0.98843914270401
60896528,812,rajinisivaram,2016-04-25T11:06:31Z,"is probably the best person to answer the question. since `auth` already contained interfaces, i added interfaces to that package (the new ones are currently not exposed externally, but we may want to make these externally configurable at some point). `authenticator` contained sasl authentication implementation and it continues to hold the same.",0,0.9654648303985596
60896686,812,rajinisivaram,2016-04-25T11:07:58Z,"yes, the original kip was proposing to expose `login` to plugin new authentication mechanisms. the cut-down kip no longer needs that, but it made sense to keep it configurable for the future.",0,0.9870014190673828
60896698,812,rajinisivaram,2016-04-25T11:08:13Z,removed.,0,0.9311882257461548
60896709,812,rajinisivaram,2016-04-25T11:08:22Z,done.,0,0.9759407639503479
60896753,812,rajinisivaram,2016-04-25T11:08:45Z,done.,0,0.9759407639503479
60896777,812,rajinisivaram,2016-04-25T11:08:54Z,done.,0,0.9759407639503479
60896799,812,rajinisivaram,2016-04-25T11:09:07Z,"yes, removed.",0,0.977724015712738
60896815,812,rajinisivaram,2016-04-25T11:09:16Z,done.,0,0.9759407639503479
60896823,812,rajinisivaram,2016-04-25T11:09:26Z,removed.,0,0.9311882257461548
60896983,812,rajinisivaram,2016-04-25T11:11:18Z,"client would get disconnected, but i am not sure if gssapi includes an error response in that case. catching exception from the whole block now.",0,0.9217827320098877
60897075,812,rajinisivaram,2016-04-25T11:12:25Z,can't think of anything that is generic and useful for other mechanisms in this case.,0,0.8999119997024536
60897383,812,rajinisivaram,2016-04-25T11:15:28Z,"could move it into another variable, but it adds more code, so leaving as is.",0,0.9865403771400452
60897403,812,rajinisivaram,2016-04-25T11:15:38Z,"yes, updated.",0,0.9839699864387512
60897700,812,rajinisivaram,2016-04-25T11:18:42Z,"rewrote the comment. it is simlar to digest-md5 implementation in zookeeper where clear passwords are stored on disk. it can be used in production, but you may want to write your own.",0,0.9880821704864502
60897719,812,rajinisivaram,2016-04-25T11:18:54Z,done.,0,0.9759407639503479
60897732,812,rajinisivaram,2016-04-25T11:19:03Z,done.,0,0.9759407639503479
60897762,812,rajinisivaram,2016-04-25T11:19:21Z,done.,0,0.9759407639503479
60897773,812,rajinisivaram,2016-04-25T11:19:30Z,removed.,0,0.9311882257461548
60898494,812,rajinisivaram,2016-04-25T11:27:33Z,empty response indicates to the client that the authentication has completed successfully. null response would possibly need changes to the client code.,0,0.9821617603302002
60898519,812,rajinisivaram,2016-04-25T11:27:51Z,updated.,0,0.9759359955787659
60898535,812,rajinisivaram,2016-04-25T11:28:01Z,done.,0,0.9759407639503479
60898552,812,rajinisivaram,2016-04-25T11:28:08Z,done.,0,0.9759407639503479
60898566,812,rajinisivaram,2016-04-25T11:28:17Z,done.,0,0.9759407639503479
60898573,812,rajinisivaram,2016-04-25T11:28:24Z,done.,0,0.9759407639503479
60898589,812,rajinisivaram,2016-04-25T11:28:34Z,removed space.,0,0.9437882304191589
60898751,812,rajinisivaram,2016-04-25T11:30:11Z,"it was written this way when callback handler class was configurable in the original kip. since it is no longer configurable, i have moved the construction to `createsaslserver` when the mechanism is known.",0,0.9897145628929138
60898799,812,rajinisivaram,2016-04-25T11:30:35Z,replaced with error check and validation in `kafkaconfig`.,0,0.9860702157020569
60898811,812,rajinisivaram,2016-04-25T11:30:44Z,done.,0,0.9759407639503479
60898835,812,rajinisivaram,2016-04-25T11:30:54Z,removed.,0,0.9311882257461548
60900182,812,rajinisivaram,2016-04-25T11:46:04Z,"have added a comment. `saslserverauthenticator.complete()` used to check `saslserver.iscomplete` earlier and didn't rely on the sasl state. it is useful to keep the state up-to-date for debug anyway, and now that it is kept uptodate, `saslserverauthenticator.complete()` can use it too.",0,0.9773145914077759
60916629,812,ijuma,2016-04-25T13:57:25Z,thanks.,0,0.5150366425514221
60916703,812,ijuma,2016-04-25T13:57:50Z,"ok, fine.",0,0.9312459826469421
60917166,812,ijuma,2016-04-25T14:00:30Z,thanks. i guess what i was trying to say is that i don't know if we will ever get the schema exception since the server will just disconnect us. but it would be good to verify that via tests. it can be done in a separate pr though.,1,0.8383232951164246
60917208,812,ijuma,2016-04-25T14:00:43Z,"ok, fine.",0,0.9312459826469421
60917226,812,ijuma,2016-04-25T14:00:49Z,ok.,0,0.9735831022262573
60917392,812,ijuma,2016-04-25T14:01:46Z,ok.,0,0.9735831022262573
60917610,812,ijuma,2016-04-25T14:03:10Z,"my comment was based on: [code block] however, if our code expects an empty byte array, it's fine to leave as is.",0,0.9810336828231812
60917684,812,ijuma,2016-04-25T14:03:45Z,sounds good.,1,0.9202015399932861
60917800,812,ijuma,2016-04-25T14:04:27Z,sounds good.,1,0.9202015399932861
60917907,812,ijuma,2016-04-25T14:05:16Z,thanks.,0,0.5150366425514221
60918260,812,ijuma,2016-04-25T14:07:32Z,"can you please file a jira for that and also think about system tests that we need? some of it is just a matter of using the plain mechanism in some tests. the other important case is testing upgrades and different broker/client versions. we already have many of these tests, so it may just be a matter of expanding them.",0,0.9844282865524292
60918411,812,ijuma,2016-04-25T14:08:23Z,the fact that it's common code is an implementation detail. we can pass the parameter via `channelbuilders` to deal with that. let's see what thinks.,0,0.9824845194816589
60918481,812,ijuma,2016-04-25T14:08:48Z,ok.,0,0.9735831022262573
60918614,812,ijuma,2016-04-25T14:09:37Z,rajini did this.,0,0.9767706394195557
60918664,812,ijuma,2016-04-25T14:09:55Z,"looks good, thanks.",1,0.9419525265693665
60919159,812,ijuma,2016-04-25T14:13:13Z,"this may seem a bit nitpicky, but it makes a difference from a java memory model perspective, the assignment to the final field should happen after the list has been populated.",0,0.9611337184906006
60919232,812,ijuma,2016-04-25T14:13:39Z,would it make sense to move this down to `defaultlogin`?,0,0.985352098941803
60919291,812,ijuma,2016-04-25T14:13:57Z,maybe we don't need this here either (subclasses can implement it).,0,0.9817704558372498
60919588,812,ijuma,2016-04-25T14:16:03Z,nitpick: there should be a space before `{`.,0,0.9840055704116821
60919616,812,ijuma,2016-04-25T14:16:13Z,nitpick: there should be a space before `{`.,0,0.9840055704116821
60949617,812,ijuma,2016-04-25T17:06:25Z,this doesn't seem to be changed?,0,0.9645044803619385
60956336,812,rajinisivaram,2016-04-25T17:48:32Z,done,0,0.9764507412910461
60956492,812,rajinisivaram,2016-04-25T17:49:28Z,"sorry, there were two sets of code changes here, i had missed one, but have updated now.",-1,0.9866514205932617
60957054,812,rajinisivaram,2016-04-25T17:52:45Z,"agree. i suppose it depends on whether sasl mechanism is treated as a property of the sasl protocol or a higher level protocol itself. there are other instances of client-side properties (eg. service name) which don't have an ""inter.broker"" prefix when used in the broker. i am happy with either, so will wait and see what thinks.",0,0.5306562781333923
60957655,812,ijuma,2016-04-25T17:56:06Z,good point about service name.,1,0.864082932472229
60957839,812,rajinisivaram,2016-04-25T17:57:03Z,will add a test in kafka-3617 along with the other unit tests.,0,0.984620213508606
60958025,812,rajinisivaram,2016-04-25T17:58:09Z,done.,0,0.9759407639503479
60958055,812,rajinisivaram,2016-04-25T17:58:19Z,moved.,0,0.9811305403709412
60958076,812,rajinisivaram,2016-04-25T17:58:28Z,done.,0,0.9759407639503479
60958107,812,rajinisivaram,2016-04-25T17:58:40Z,done.,0,0.9759407639503479
60959856,812,rajinisivaram,2016-04-25T18:09:05Z,done.,0,0.9759407639503479
60963638,812,ijuma,2016-04-25T18:30:32Z,i asked offline about this and he suggested the `sasl.mechanism.inter.broker.protocol`. the reason why i think this is different than `sasl.kerberos.service.name` is that it's easy to be confused when one sees `sasl.mechanism` and `sasl.enabled.mechanisms`.,0,0.977745532989502
60993752,812,rajinisivaram,2016-04-25T21:36:01Z,"ok, makes sense. i have added updated the pr.",0,0.9766504764556885
61186244,812,harshach,2016-04-27T00:14:38Z,authenticator for pluggable authenticator that we use.,0,0.9885955452919006
37835370,165,onurkaraman,2015-08-25T06:09:30Z,`votes.maxby(_._2)._1`,0,0.9741345643997192
37835755,165,onurkaraman,2015-08-25T06:18:59Z,`allmembermetadata.tomap` converts to an immutable map,0,0.985653281211853
37836136,165,onurkaraman,2015-08-25T06:27:03Z,"given that the session timeouts are defined per member, should this instead be: [code block]",0,0.9887865781784058
37836633,165,onurkaraman,2015-08-25T06:38:14Z,"another minor point, but i think it's cleaner to keep all group-specific checks in dojoingroup similar to how it was before.",0,0.9739209413528442
37842937,165,onurkaraman,2015-08-25T08:21:18Z,"i think we can replace collect with the less obscure map: `supportedprotocols.find{ case (p, d) => protocol == p }.map{ case (p, d) => d }`",0,0.9859607219696045
37890199,165,onurkaraman,2015-08-25T16:58:37Z,`return metadata != null ? metadata.equals(that.metadata) : that.metadata == null;`,0,0.9819493889808655
37895582,165,onurkaraman,2015-08-25T17:44:30Z,`def candidateprotocols = {`,0,0.9822429418563843
37895610,165,hachikuji,2015-08-25T17:44:46Z,"i was thinking that ""member"" at the root seemed a little vague in configuration.",0,0.961168646812439
37895692,165,hachikuji,2015-08-25T17:45:28Z,agreed.,0,0.9702104926109314
37895693,165,onurkaraman,2015-08-25T17:45:28Z,"same as above: `def currentmembermetadata: map[string, array[byte]] = {`",0,0.9868285059928894
37896333,165,hachikuji,2015-08-25T17:50:59Z,intellij generated this line! wonder why their template is so weird...,-1,0.9846039414405823
37898046,165,onurkaraman,2015-08-25T18:05:02Z,"your addgroup change now takes in (groupid, protocoltype). it probably won't change the outcome of the tests, but better for clarity to match up with the intended usage.",0,0.9870555400848389
37901060,165,onurkaraman,2015-08-25T18:27:58Z,"github annoyingly picked the diff window for me. just to clarify, i was only suggesting you move the following check: `else if (group.protocoltype != protocoltype)`",-1,0.8642506003379822
37904617,165,ewencp,2015-08-25T18:56:51Z,this confused me a bit since previously this class was purely additive wrt the set of topics. is there a case where you can actually lose a subscription by doing this? i'm thinking if the user does something to the subscriptions during a callback?,0,0.6868948936462402
37904628,165,ewencp,2015-08-25T18:56:54Z,"nit, but since this is a nested class that will probably always be referred to by `metadata.metadatalistener`, `listener` would probably be more concise/less redundant.",0,0.9884526133537292
37904632,165,ewencp,2015-08-25T18:56:57Z,"i think this is the right default assignor, but just to be clear this is changing a default. we're still ok with this since we haven't released this yet, but are there any concerns with inconsistency with the old consumer?",0,0.9721912741661072
37904642,165,ewencp,2015-08-25T18:57:03Z,this comment doesn't seem useful...,-1,0.9571406245231628
37904654,165,ewencp,2015-08-25T18:57:07Z,we could make this private since the `success` and `failure` methods seem to be the preferred way of constructing these objects and ensure you construct a valid combination (i.e. guarantees the right fields are null depending on the value of `succeeded`).,0,0.9884375929832458
37904666,165,ewencp,2015-08-25T18:57:11Z,"can we may be document what `groupsubscription` is more clearly somewhere else, maybe even just on this class's javadoc? it took me a bit of digging to figure out what it was -- i was confused why we were getting (and using) something called group subscription when a join group had failed. maybe a bit of renaming could also help? aggregategroupsubscription or aggregaterequestedgroupsubscription?",0,0.9461089968681335
37904681,165,ewencp,2015-08-25T18:57:16Z,this doesn't currently build for me because iterator's `remove()` method is not implemented.,0,0.9463982582092285
37904688,165,ewencp,2015-08-25T18:57:21Z,"is there a reason for this extra level that just contains the subscription struct field? i get that other implementations might want subscription info + other metadata, but does abstractpartitionassignor need this?",0,0.9884020686149597
37904699,165,ewencp,2015-08-25T18:57:23Z,this could be a static final -- doesn't need to be a separate object for every call to `schema()`,0,0.987143337726593
37904706,165,ewencp,2015-08-25T18:57:25Z,"i'm not sure i understand how versioning will work for this data format. do we need to also include a schema version number as part of this `write()` call? otherwise, how would we introduce a v1? it doesn't look like this is handled in partitionassignmentprotocol since the version of the schema isn't exposed anywhere in this interface.",0,0.9246596693992615
37904713,165,ewencp,2015-08-25T18:57:29Z,why not just `subscription.toarray()`,0,0.9864119291305542
37904720,165,ewencp,2015-08-25T18:57:32Z,"same question, why not `topics.toarray()`",0,0.98404860496521
37904726,165,ewencp,2015-08-25T18:57:36Z,"any other ideas besides controller for naming these classes? this is a different part of the code, but we've already got kafkacontroller on the broker.",0,0.9870660901069641
37916318,165,hachikuji,2015-08-25T20:38:44Z,"i don't think it's possible since we await all pending requests to the coordinator before sending a new join group request, but i'll have to look into it. this is definitely one of the messier aspects of this patch. it may get easier after kafka-2388 since subscriptions are no longer additive, but the hard part is ensuring that the metadata topic list matches the union of all topics subscribed by the group. one option might be to only update the metadata topic list based on the subscriptions defined in the join group response. that would mean we'd always need two rounds of the rebalance when subscriptions change, which seems unfortunate. i'll see if there are any nicer options.",0,0.8697873950004578
37917400,165,hachikuji,2015-08-25T20:47:58Z,"as long as we document the difference, it's probably fine. i can't imagine any cases where users would have a hard dependence on the range assignor. and since a lot of users probably won't override the default, i think we should have it set to the better strategy.",0,0.9395594000816345
37917723,165,hachikuji,2015-08-25T20:50:41Z,"yep, i didn't catch it locally because java 8 provides a default implementation.",0,0.9493066668510437
37918344,165,ewencp,2015-08-25T20:55:35Z,"not a big deal, but `collections.singletonmap` is a nice shortcut for building maps like this.",0,0.7729167938232422
37918767,165,hachikuji,2015-08-25T20:58:29Z,"initially i was trying to include a generic byte array in the protocol which extensions could provide a schema to support their own custom metadata. that got a little too complex to manage, so i decided to leave it up to custom assignors to define the full metadata schema (including subscriptions) that they depend on. in short, the extra level can be removed now.",0,0.9568337202072144
37919217,165,hachikuji,2015-08-25T21:02:08Z,manager?,0,0.9721108675003052
37919626,165,ewencp,2015-08-25T21:05:40Z,test for inconsistent metadata? or are we just assuming the other test is good enough since that's handled in abstractpartitionassignor?,0,0.9880629777908325
37922433,165,ewencp,2015-08-25T21:32:02Z,"so this basically means that not only do we enable rolling upgrades where you add a new protocol, restart everything, and can then later remove the new protocol, but we actually require it (unless you shut down the entire group and then start again from scratch)?",0,0.982052743434906
37922449,165,hachikuji,2015-08-25T21:32:13Z,"this has probably not been thought all the way through, but any version embedded in the metadata itself cannot really be leveraged in the protocol. new versions of an assignor can support old versions of the metadata, but the opposite won't generally work. if the user wants to have a change to the metadata without bringing the cluster down, then they'd have to provide separate assignors supporting the different metadata versions. the protocol allows each assignor to provide a single version which the coordinator can use to ensure compatibility. i think the question is whether this version should identify the version of the metadata, the version of the assignor, or whether we need an additional version field to be able to express both. in general, the only thing the coordinator can do with these versions is check that they match for all members, so it would seem a little unfortunate to have to add another. it is also possible to use the name of the assignor to communicate version differences. for example, instead of ""roundrobin,"" this should be ""roundrobin-v0."" then if we need to change the metadata, we would implement abstractpartitionassignorv1 and a roundrobinassignorv1 which uses the name ""roundrobin-v1.""",0,0.9641368985176086
37924821,165,hachikuji,2015-08-25T21:57:27Z,"that is right. if you attempt to upgrade the protocol without providing both versions, then the new group members (with the new protocol) would be rejected until all old members have left. this is consistent with the current implementation. i proposed previously to have the coordinator choose the protocol which the largest number of members support, but you seemed concerned that this would effectively halve the group's capacity for a short duration in a rolling upgrade. i still think that might be a more useful update mechanism in practice, but the implementation might be tricky since rejected members would have to retry at a later time which could lead to unnecessary (and costly) rebalancing. the advantage of the approach implemented here is that the code is simple.",0,0.9227655529975891
37927101,165,ewencp,2015-08-25T22:23:44Z,"i think this is fine -- the rolling upgrade with 2 protocols should be the common and suggested path if you need to do this anyway. since this is only an issue if you don't configure your consumers for a seamless upgrade, i actually don't think it's bad to have pretty harsh behavior like this. if someone screws up and misconfigures something, they'll figure it out a lot faster if they bounce consumers and they can't even get back into the group, whereas the majority vote would work but halve the capacity. i think either way is fine, but i agree this code is simpler and has reasonable results.",0,0.5476093292236328
37927178,165,ewencp,2015-08-25T22:24:43Z,"that works. we have a ton of xmanager classes on the broker, but it's a generic enough name component that it shouldn't be confusing.",0,0.9224779605865479
37927752,165,ewencp,2015-08-25T22:31:56Z,"sorry, i think we've already discussed this like 3 times and i just keep getting confused about it. the reason this code confused me is because we have `consumer_metadata_v0`, which implies at some point we could add `consumer_metadata_v1` to this class and support both/upgrading. i think i see now how we could actually still (potentially) only have `abstractpartitionassignor`, but then versioned concrete classes.",-1,0.988645076751709
37927905,165,ewencp,2015-08-25T22:33:48Z,do we even want the range assignor anymore then? is it needed for anything that the other assignors we'd want to implement wouldn't?,0,0.9837071299552917
37929097,165,hachikuji,2015-08-25T22:48:28Z,"haha, it still confuses me too. i think i sort of blindly applied the same pattern that was used for schema definitions in the protocol class. i can drop the v0, but the trouble with assignor versioning won't go away quite that easily. one concrete suggestion might be to make the protocol version a string instead of an int to allow more information to be embedded in the version. we could then use it to track both the protocol and metadata versions. i can also add some documentation on the groupprotocol and partitionassignor interfaces to try to make intended usage clearer.",-1,0.7228311896324158
37929523,165,hachikuji,2015-08-25T22:53:56Z,"yeah, that's a good point. maybe we leave it for now and address it in a separate jira? i can default to rangeassignor for consistency with the current version.",0,0.5090946555137634
37932986,165,ewencp,2015-08-25T23:40:09Z,"yeah, i think that's fine. we probably need a jira for any other built-in assignors we want to ship with 0.8.3 anyway, e.g. i assume we'll have a copartitioning implementation for kstreams.",0,0.9809128642082214
38051685,165,guozhangwang,2015-08-27T00:29:55Z,which version did you use and which edit feature did you turn on? your intellij is definitely overly-smart ;),1,0.9753127098083496
38051966,165,guozhangwang,2015-08-27T00:35:56Z,"i would prefer defaulting to range just for consistency. we have seen similar cases in the producer where the behavior of partitioner's hashing function changes a bit, causing offset manager migrated for mirror-makers and hence resetting offset and data duplicates.",0,0.9816255569458008
38602589,165,ewencp,2015-09-03T00:32:28Z,"why are we splitting the handling of metadata between both `metadata` and `fetcher` now? is this just so that this topic-partition metadata is not persistent in `metadata` since calling `partitionsfor` doens't really imply anything about whether you'll continue to need updated metadata for the topics passed in here? even so, this split seems less than ideal...",0,0.6809693574905396
38602592,165,ewencp,2015-09-03T00:32:32Z,"any reason for using an empty list here rather than `null` as a sentinel? the empty list approach seems like it could lead to confusing results if you have a programmatically generated list which can sometimes be empty. right now it's not a problem since we only expose `listtopics` and `partitionsfor(onetopic)`. but wasn't there a proposal for something like `partitionsfor(string... topics)`, in which case this could affect the public api.",0,0.9700114727020264
38602607,165,ewencp,2015-09-03T00:32:44Z,"does this really make sense? for this to occur, we'd need to have everyone agree on the metadata since that was checked above, but then they'd have to be missing metadata on one of those topics. wouldn't at least the one consumer that included that topic have metadata for it? is the goal here that we continue processing the ones we have metadata for so we can at least make progress? if we do this, is there anything that's forcing the metadata to be refreshed (like the inconsistentmetadata result does)? if not, wouldn't this cause us to sometimes knowingly ignore some topics which we might be able to make progress on immediately if we refreshed and rejoined the group?",0,0.8941762447357178
38602625,165,ewencp,2015-09-03T00:33:07Z,"you might want to rename this for clarity. i saw `hashsets` being passed into the `metadatasnapshot` constructor in `consumergroupcontroller` and since i knew `hash()` is called on that, i was worried the `hashsets` might have been a mistake. they're not, and that makes sense given the protocol we came up with, but the current method names aren't clear about what's being hashed. my first thought was `metadatahash()`, but that doesn't exactly help... maybe `topicmetadatahash()`?",0,0.6116368770599365
38602735,165,ewencp,2015-09-03T00:35:35Z,we can always go the `max.in.flight.requests.per.second` route with maximum verbosity and prefix with `group.member.`!,0,0.9645101428031921
38661233,165,hachikuji,2015-09-03T15:46:57Z,"since we depend on the metadata matching the subscription set in this patch, i wanted to remove any other calls which can affect it. the alternative would be to always intersect the subscription and metadata before computing the hash sent along in the join group. either way should work, but i actually think it's a good thing not having the persistent metadata state updated by partitionsfor(). can you explain a little more why this is less than ideal?",0,0.883913516998291
38661343,165,hachikuji,2015-09-03T15:47:56Z,fair enough. i can use null instead.,0,0.9605855345726013
38664475,165,ewencp,2015-09-03T16:15:09Z,"it's just not great having multiple paths that make the same type of request if possible. but i see why we at least want different handling of this request/response, and there was another jira to make this exact change anyway.",0,0.6146900653839111
38664724,165,hachikuji,2015-09-03T16:17:49Z,"the case i was trying to handle is non-existing topics. the current behavior of the consumer is to keep trying to fetch metadata for the non-existing topic in the hope that it will eventually be created, and to continue consuming from other subscribed topics. if one of the consumers does have metadata (perhaps because the topic was just created), then the metadata hash will be inconsistent and members will refetch. if the topic is later created, we will discover it when we update metadata and the consumers will rejoin.",0,0.96949702501297
38667583,165,ewencp,2015-09-03T16:46:31Z,"ok, that makes sense in that it allows consumers to make progress even if a topic needs to be created. if auto topic creation is not enabled, then this might be the only way to make progress if one of the topics doesn't yet exist. but doesn't this also mean that if you have auto topic creation enabled and the consumer group starts up before any producers, then it might have to wait an entire metadata refresh timeout before any data is consumed from that topic, even if producers start sending data to it immediately? i think this is fine (and it's a one-time delay, 5 or 10 minutes by default iirc), just want to make sure we understand the implications of doing this.",0,0.8562459945678711
38669112,165,hachikuji,2015-09-03T17:01:48Z,"yeah, that's right, and i agree it's a little unfortunate to have to wait the full refresh interval, though i assume most cases would have the topic already created or created by producers. probably the main case where this would be encountered is in testing. one thing we could try to do is stagger metadata refreshes randomly in the group so that they are not all synchronized around the join group completion. that would reduce the expected time to discover metadata changes in general. it might also make sense to set the default metadata refresh rate a little lower for client-side assignment since we can't depend any longer on the broker discovering changes for us anymore.",0,0.8873960375785828
41659964,165,ewencp,2015-10-09T18:04:02Z,"this is out of date, right? no more metadatahashes in this version?",0,0.9731112122535706
41661913,165,ewencp,2015-10-09T18:20:56Z,"is this version for the consumer protocol itself? that can't be in the struct, can it? doesn't it need to prefix the struct so you can decide which schema to decode with?",0,0.987467348575592
41662735,165,ewencp,2015-10-09T18:28:24Z,"is this just temporary until we add better support in the configs for multiple assignors? i'd imagine we need to think through the exact semantics, if ordering matters at all, etc. is the plan to eventually just switch this to a comma-separated list of class names? one thing i found with copycat was that the more things that needed to be configured via the same config dictionary, the more problematic kafka's standard approach to configuration became because you could easily hit cases where there were conflicting settings. not sure if a) that'll be an issue here or b) if we even want to support assignors that have _that_ much config, but something worth thinking about before committing to this specific approach to specifying assignors.",0,0.8878637552261353
41664701,165,hachikuji,2015-10-09T18:45:40Z,"yes, you are right. i wrote it that way initially, but changed it several times as i was considering compatibility implications. assuming forward compatibility, for example, you just parse blindly even if the version is higher. however, newer versions would need to check the version before doing any parsing, so it should still be parsed separately. i'll update the patch. in general, the versioning problem is complex enough to merit its own discussion, so the goal here is to keep things as simple as possible.",0,0.9395622611045837
41664757,165,ewencp,2015-10-09T18:46:10Z,seems like this comment is not true now? intentional change or are we missing a check here?,0,0.736605167388916
41664863,165,ewencp,2015-10-09T18:47:24Z,"agreed. as long as we address it in a blocker follow up patch, i'm happy to defer that discussion until after this patch.",1,0.9621010422706604
41665659,165,ewencp,2015-10-09T18:55:06Z,"nice. it took me a minute to figure out how the combination of join group and sync were working, but the futures made this work out very nicely. this is quite a bit cleaner than i thought it was going to be.",1,0.9773979783058167
41666054,165,ewencp,2015-10-09T18:58:56Z,can probably remove this comment since #290 is addressing this as part of kafka-1843.,0,0.9883117079734802
41666648,165,ewencp,2015-10-09T19:05:01Z,"minor, but it'd be good to document the `m` and `s` type parameters. the current javadoc doesn't explain what ""state"" means here.",0,0.986573338508606
41666750,165,ewencp,2015-10-09T19:06:01Z,"what does `gen` in `gentype` stand for? this is a very minor naming issue, but since i understand the generalized group functionality and am unsure what is trying to be communicated with this name, i imagine it might confuse others as well.",0,0.7980437278747559
41670166,165,hachikuji,2015-10-09T19:40:29Z,"haha, gen is short for generic. awful name, i know. i'll take any suggestions. basically i just wanted to have the type information ride along with the schema. maybe generictype? paramtype?",-1,0.9870874881744385
41671402,165,ewencp,2015-10-09T19:54:43Z,"minor cleanup, but there seem to be a few cases like this where the response to two cases is identical and you could collapse them into one conditional block.",0,0.9834831953048706
41671988,165,ewencp,2015-10-09T20:00:59Z,"yeah, i was going to suggest `validatedtype`, but i see that validate is already part of `type` and you've just refined the return type. it's unfortunate that `type` isn't already generic. i'd just expand the name to `generictype`.",-1,0.8983227610588074
41674067,165,hachikuji,2015-10-09T20:23:43Z,"honestly, type could probably be made generic without a huge impact. the usage kind of suggests that intention anyway. that might be worthwhile refactoring for a follow-up patch, but probably not a good idea to jam in here. i'll change to generictype for now.",0,0.9659879207611084
41676221,165,guozhangwang,2015-10-09T20:46:53Z,nit: rename assignors to assignorsmap? it's a bit misleading to have two variables with the same name here.,-1,0.5288840532302856
41678401,165,guozhangwang,2015-10-09T21:10:21Z,is this indentation intentional?,0,0.9410359263420105
41678754,165,hachikuji,2015-10-09T21:14:18Z,"not intentional, just intellij getting a little aggressive trying to ""fix"" the indentation. i'll fix it in the next commit.",-1,0.49836552143096924
41679809,165,guozhangwang,2015-10-09T21:26:55Z,why does consumers need to fetch the metadata for group subscription? if it is not subscribed to some topics their partitions will never to assigned to itself right?,0,0.9748367667198181
41680449,165,guozhangwang,2015-10-09T21:34:04Z,this class should be in clients/src/test instead of clients/src/main.,0,0.9881479144096375
41680691,165,hachikuji,2015-10-09T21:37:09Z,"the leader is the only member who sees the group subscription; for everyone else, groupsubscription() will just return that member's subscription. we depend on the leader's metadata in order to set assignments, so it must have metadata available for the full group's subscription. we could just issue one metadata request when the leader is preparing to do the assignment, but that opens the door to the leader missing metadata changes affecting topics it itself is not subscribed to. more concretely, suppose the leader is subscribed to [a], but one follower is subscribed to [a,b]. if the follower notices an increase in b's partitions, it can trigger a rebalance, but there's no guarantee that the partition change will be visible by the leader when it fetches topic metadata. therefore we register the leader to watch for changes to b as well. eventually, when the leader sees the change, it can rebalance. does that make sense?",0,0.9745332598686218
41682690,165,guozhangwang,2015-10-09T22:02:14Z,could this ever happen in the normal case? i think the key-set of consumerspertopic should always be a super-set of key-set of partitionspertopic?,0,0.9814062118530273
41682946,165,hachikuji,2015-10-09T22:05:44Z,"yeah, you are right.",0,0.9084950089454651
41683260,165,guozhangwang,2015-10-09T22:09:55Z,this can be private; also what is the benefit of making it templated instead of using string directly?,0,0.9882792234420776
41684230,165,guozhangwang,2015-10-09T22:24:14Z,there are some overlap between this gentype with org.apache.kafka.common.protocol.types.schema. but schema.validate() returns a struct instead of a generic t type. could we try to merge these two?,0,0.9884282946586609
41685576,165,guozhangwang,2015-10-09T22:47:08Z,"a related question to ewen's comment above: how will this version() function be used, for both assignment and subscription?",0,0.986746609210968
41687689,165,hachikuji,2015-10-09T23:34:03Z,"the leader provides compatible versions of assignments given the respective versions specified in member subscriptions. for this patch, i have assumed full forwards and backwards compatibility of the embedded group protocol, which allows any member to be elected leader during an upgrade scenario and still perform correctly. there are two cases to consider: 1. the leader is on the old version: in this case, forwards compatibility allows the leader to go ahead and parse subscriptions from all members (even those on newer versions) and generate assignments corresponding to its older version. backwards compatibility ensures that the newer members will be able to parse the assignments with older versions. for example, if the leader is on version 0 and a follower is on version 1, the leader will parse the version 1 subscription as a version 0 subscription and provide it a version 0 assignment. 2. the leader is on the new version: in this case, the leader can parse both new and old subscription versions. depending on the protocol, it can choose to send assignments to members corresponding to their respective subscriptions, or it can choose the oldest version and send assignments based on it. using a similar example as above, if the leader is on version 1 and the follower is on version 0, then the leader can parse the version 0 subscription and send a version 0 assignment. obviously this strict compatibility model might be challenging to implement in practice, depending in particular on the protocol format (it would be relatively straightforward if we chose json, for example). alternatively, if we exposed version information in the joingroup protocol, then the coordinator would be able choose the member with the highest version, which would let us weaken the compatibility assumption. the tradeoff is that we'd need to complicate the protocol a bit to carry version information from each member along with their respective subscriptions and assignments. this gets even trickier if you allow assignment strategies to include their own embedded data format, so i was hoping to get a simple approach in place first before having a more complete discussion. perhaps for now i can just add some documentation on the groupprotocol class to clarify the current compatibility assumptions?",0,0.967720091342926
41709461,165,ijuma,2015-10-11T11:44:04Z,"this seems like a generic method and not specific to strings, so it seems right to me to do it generically (unless we can implement a faster version by making it specific, which doesn't seem to be the case here). a few questions: - should it be in `utils` instead of here? - `consumers` parameter name should be `collection` probably - would ` >` be a better bound? that's what `collections.sort` uses.",0,0.9763458371162415
41724298,165,guozhangwang,2015-10-12T05:24:35Z,"that makes sense, could you rephrase the above a little bit as comments to groupsubscription?",0,0.9875124096870422
41724379,165,guozhangwang,2015-10-12T05:27:38Z,"the only place sorted() is called is in the above roundrobinassignor where t is string, so i am wondering if this function is specific to roundrobinassignor only or not; if it is general i agree with you that we should keep it with generics and move it to utils, otherwise we can just make it private to roundrobinassignor and with string only.",0,0.9839076995849609
41727098,165,guozhangwang,2015-10-12T06:49:25Z,add some explanations about generic m(etadata) and s(tate).,0,0.9869307279586792
41775541,165,guozhangwang,2015-10-12T16:39:54Z,i'm wondering if we can put the parse() function in a centralized place since their implementations are all similar?,0,0.97015780210495
41778171,165,guozhangwang,2015-10-12T17:08:05Z,"could we avoid having two metadata.listener, one in kafkaconsumer and one here? if not, i would prefer to let coordinator have a variable field listener instead of letting itself implement the interface itself.",0,0.9854025840759277
41778848,165,guozhangwang,2015-10-12T17:15:34Z,what scenario would require leaderid in dosync?,0,0.9838136434555054
41781687,165,guozhangwang,2015-10-12T17:45:31Z,"a general comment: maybe we can rename groupcoordinator to coordinator, and coordinator to consumercoordinator, and the server-side consumercoordiantor to groupcoordinator. do you think the names are more clear that way?",0,0.984271228313446
41783220,165,hachikuji,2015-10-12T18:00:32Z,"yeah, that sounds reasonable. maybe instead of coordinator, we can call it abstractcoordinator?",0,0.9758638739585876
41786233,165,guozhangwang,2015-10-12T18:29:47Z,update the comments for this function.,0,0.9848339557647705
41787479,165,guozhangwang,2015-10-12T18:41:13Z,"this metadatasnapshot is only written upon metadata update, but not read in dosync: we still use the above metadata object, and actually it seems not used anywhere. is this intentional?",0,0.9297397136688232
41791203,165,guozhangwang,2015-10-12T19:18:58Z,good catch.,1,0.9640093445777893
41791349,165,guozhangwang,2015-10-12T19:20:17Z,"if we are not assigning a different error code here, maybe we want to shift the rest error codes left? and same above for 23 / 24 / 25. edit: actually 23 and 25 are still used, scratch that part.",0,0.9848368763923645
41792646,165,guozhangwang,2015-10-12T19:36:12Z,is this still a possible error code? we may need to update the possible error codes for join / sync / commit / fetchoffset responses.,0,0.9845945835113525
41793002,165,guozhangwang,2015-10-12T19:39:52Z,add a comment pointing out this is for leader id.,0,0.987037181854248
41793506,165,guozhangwang,2015-10-12T19:45:41Z,"this is not introduced in this patch, but why we are returning group_coordinator_not_available for offsetcommit if (!isactive.get), while return not_coordinator_for_group for offsetfetch for the same condition? do you know if there is any motivation?",0,0.9808629751205444
41793618,165,guozhangwang,2015-10-12T19:46:52Z,what are the possible error codes for this response? i ask this since moving forward we will move this into the protocol as well so it's better keep track of those for now.,0,0.9854254722595215
41797594,165,hachikuji,2015-10-12T20:27:34Z,i've added a commit to clarify current versioning assumptions of the embedded metadata/assignment format. let me know if that is sufficient for now. i think we'll still want to consider this in a little more detail in a follow-up issue after this is checked in.,0,0.9804062843322754
41801442,165,hachikuji,2015-10-12T21:07:40Z,"i think i had made it generic initially because the consumer had an object representation, but i agree it's a little silly here. since it is a general function, perhaps i'll go ahead and relocate it to utils.",-1,0.7551805377006531
41802182,165,guozhangwang,2015-10-12T21:16:15Z,why do we remove the check on subscriptionlistener.revoked?,0,0.952397882938385
41802812,165,guozhangwang,2015-10-12T21:22:55Z,generation id is not incremented here?,0,0.9850159883499146
41803001,165,guozhangwang,2015-10-12T21:24:49Z,why error code is 1 instead of 0? also we probably should use errors.offset_out_of_range.code() for readability.,0,0.9873784184455872
41804236,165,guozhangwang,2015-10-12T21:38:31Z,"when we receive a join group in this state from a single member, does that mean we will transit to preparingrebalance and then immediately back to awaitingsync?",0,0.9865961670875549
41804868,165,guozhangwang,2015-10-12T21:45:30Z,do we still have this event in the fsm diagram now?,0,0.9875172972679138
41805021,165,guozhangwang,2015-10-12T21:47:38Z,is syncerrorcode always none.code?,0,0.9874984622001648
41805157,165,guozhangwang,2015-10-12T21:49:32Z,update comments.,0,0.9858714938163757
41807478,165,guozhangwang,2015-10-12T22:19:36Z,"maybe we do not need to have the item here in the fsm, but just list for all possible ""input"": join, sync, heartbeat, offset-commit, offset-fetch, and events like ""member failed"", ""leader timed out while syncing""; and what are the possible ""output"" (i.e. the response) and the state-change (i.e. the transition). some input may not trigger state-change while some other may trigger, and the same input may also end in different state change (e.g. the last join-group request from the group or not). that will make the state machine diagram more clear.",0,0.9841283559799194
41808846,165,guozhangwang,2015-10-12T22:37:29Z,"i think we should, probably piggy-backing on load_balance_in_progress.",0,0.9760141372680664
41809554,165,guozhangwang,2015-10-12T22:47:44Z,"since maybepreparerebalance and proporgateassignment are all synchronized on the group, when the group is still in awaiting sync either all members still have their callback yet to trigger, or all of them should have sent the response in callback right? also the comments are not very accurate: if the group is in the awaiting sync, cancel the sync response for all of them if possible to have all its members rejoin.",0,0.6871064901351929
41809935,165,guozhangwang,2015-10-12T22:53:42Z,in the current implementation we can return the sync response multiple times to members' requests as long as they have the right generation-id and are within the group. i think it does not have any side-effects for now but just want to clarify with you.,0,0.9757950901985168
41810084,165,guozhangwang,2015-10-12T22:56:11Z,do we need to call completeandschedulenextheartbeatexpiration in both dojoin and dosync? why we need to reschedule in dosync?,0,0.9852254986763
41810875,165,guozhangwang,2015-10-12T23:08:04Z,"and with the fsm, we can write handlexxx in coordinator in a way that is aligned with the fsm as the following (personally i feel it may make future implementation and reviews easier): handlexxx: 1. check coordinator arability and group availability, 2. if group is available call doxxx. 3. otherwise proper error code, or create group first then call doxxx. doxxx: switch (group.state) case state1: this request should not be received in this state, return some error-code. case state2: do some actions based on the group metadata, and probably transit group to another state. case statex: ... etc and similarly for events like failed consumers, call onyyy: onyyy: switch (group.state) case state1: this event should not happen in this state, throw exception. case state2: do some actions based on the group metadata, and probably transit group to another state. case statex: ... etc",0,0.9732042551040649
41822373,165,hachikuji,2015-10-13T02:47:56Z,"it looks like the offset fetch is the only request where we return not_coordinator_for_group for that case. it's a little unclear which error code should be preferred, but i would tend to think that not_coordinator_for_group would be the right one since it would force the client to rediscover the coordinator, which is probably what we want when we're shutting down. on the other hand, when we're starting up, we'd want to use group_coordinator_not_available. what do you think?",0,0.9759418964385986
41822535,165,hachikuji,2015-10-13T02:53:23Z,"woops, i'll add the assertion back. i think at one point i had added code to only invoke the revocation callback when we were leaving a valid generation, so the expected revokecount was actually zero and the check on revoked was unneeded. later on, i removed the check to be consistent with the current code, but forgot this assertion.",0,0.947715699672699
41822701,165,hachikuji,2015-10-13T02:58:23Z,"seems like it's just testing serialization, so 1 was probably chosen for convenience. i'll change to errors.none instead.",0,0.9791009426116943
41823037,165,hachikuji,2015-10-13T03:07:32Z,"if we already transitioned to awaitingsync, then the members of the current generation have already been sent to the leader and the other members have received the generationid. if a new joingroup arrives before the leader has sent syncgroup, then we can either reject the joingroup and continue waiting, or we can just transition to preparingrebalance and have all members rejoin. i chose the latter since there didn't seem much point in stabilizing the group only to have the rejected member force a rebalance anyway after we transitioned to stable.",0,0.9729484915733337
41823511,165,hachikuji,2015-10-13T03:21:59Z,i think this is a good idea. it is difficult in the existing implementation to check where each case fits and whether all cases have been covered.,1,0.6707329750061035
41895691,165,hachikuji,2015-10-13T17:14:07Z,"the transition from awaitingsync to stable happens when the leader submits the assignment for the generation in its syncgroup request. other members (followers) may submit syncgroup before or after this transition occurs. if before, we hold onto the request until the leader has synced; if after, we return immediately. an alternative would be to await all syncgroup requests before returning any of them, but that seems unnecessary since the group already synchronized in the joingroup barrier and the generation has been incremented. it is possible that some members will receive the assignment and others may crash before receiving anything, but the worst thing that happens in that case is that a rebalance is triggered. the generation protects us from inconsistent assignment.",0,0.8910254240036011
41901890,165,guozhangwang,2015-10-13T18:02:07Z,i am ok either way.,0,0.9311926364898682
41902685,165,guozhangwang,2015-10-13T18:08:32Z,"i think we would better return group_coordinator_not_available for (!isactive), and not_coordinator_for_group for (!iscoordinatorforgroup(groupid)) for all requests / conditions, but on the server side we should check the latter first before the former, so that consumers will get not_coordinator_for_group if it is ever the case and rediscover.",0,0.9838811159133911
41907724,165,guozhangwang,2015-10-13T18:46:55Z,"that is fine, then in preparingrebalance state we could get syncgroup requests from leader / followers, and need to return an error code to let them re-send the joingroup. is that the case?",0,0.9891074895858765
41908099,165,guozhangwang,2015-10-13T18:50:10Z,rep. first paragraph: yeah makes sense. rep. second paragraph: i am not favoring in adding another synchronization barrier unless we have to. let's sync up some time about the state transition again.,0,0.7534080743789673
42170845,165,guozhangwang,2015-10-15T19:45:25Z,"wondering if we can do the following: 1. assignment / subscriptions extend assignor.assignment / subscriptions interface and extend struct. 2. the schema object of assignment / subscriptions will be relying on consumer_protocol_header_schema, assignment_v0 and subscription_v0 (maybe we can move them to a consumerprotocol sub-class inside abstractpartitionassignor). 3. use schema.write / read to serialize / deserialize the assignment / subscriptions. 4. remove generictype class and subscriptionschema / assignmentschema functions. is there any blockers for that?",0,0.9863160252571106
42174780,165,hachikuji,2015-10-15T20:20:19Z,wouldn't it be a little restrictive to require all assignor implementations to use kafka structures for serialization?,0,0.9839282035827637
42175026,165,ewencp,2015-10-15T20:22:18Z,"isn't the drawback with that is that you _must_ use kafka's struct then? that seems pretty inconvenient if there's a chance your data format will change but you can guarantee compatibility, e.g. a resource-based assignor is likely to evolve the set of configs it has over time. in particular, i think this would mean that if you wanted to make any change that could be handled compatibly by your code but that doesn't fit into struct's compatibility rules, you would have to change assignor name/sub protocol name, which also means going through the multiple-assignors + 2 rolling bounces upgrade process.",0,0.7330812811851501
42175057,165,guozhangwang,2015-10-15T20:22:33Z,i feel it is general enough. what kind of serdes are not compatible with kafka structures?,0,0.9369763731956482
42176271,165,hachikuji,2015-10-15T20:32:23Z,we might be able to make that work if we change the format to something like this: [code block] then users can provide any metadata they need in the userdata field.,0,0.9887872338294983
42178482,165,ewencp,2015-10-15T20:50:20Z,"what's the real benefit of requiring kafka's structs and doing so directly? it has the drawback i mentioned and it also keeps you from being able to manually handle multiple versions if you wanted to (you could check the version number before trying to decode, but only if you have control over the deserialization process). it looks to me like it just saves a few lines of code for us, and _maybe_ is a bit simpler for implementers of assignors since generictype will be removed.",0,0.954731822013855
42179615,165,hachikuji,2015-10-15T20:58:41Z,"one benefit of having a common serialization for subscriptions/assignment is that admin tooling can then depend on it. i think it might not be too bad if we implemented the userdata suggestion above. then we could actually keep the struct serialization hidden from users and give them control over userdata, which lets them do whatever they want.",0,0.9561956524848938
42180627,165,guozhangwang,2015-10-15T21:07:42Z,could this function ever be triggered? requestfuturecompletionhandler only have the oncomplete() api which will always trigger firesuccess().,0,0.9900701642036438
42181904,165,ewencp,2015-10-15T21:18:59Z,"i kind of buy that argument, but that tooling can't do anything useful with kafka structs that it doesn't already know the format of since the schema is only recorded in code. it might make writing the tooling simpler since it only has to deal with one format, but with kafka structs i don't think it actually enables anything that you couldn't get even with the more general form. i'm fine if we go with requiring schema/struct, i'm mostly wary because copycat is relying on this as well and i don't think we have as clear an idea of the exact requirements there as we do with a lot of the assignors -- right now its really simple, just the config topic offset that the worker is currently on, but i'm not sure what else might eventually make it in there. i personally like having the possibility to make certain incompatible schema changes without requiring config changes + rolling bounces (i.e. the possibility to keep those changes seamless for the user).",-1,0.49151235818862915
42182802,165,hachikuji,2015-10-15T21:26:49Z,"this makes me want to add back the protocoltype field in the joingroup request. then if the protocol type is ""consumer,"" tools would be able to parse metadata directly by using consumerprotocol. they wouldn't be able to touch userdata, but that seems reasonable.",0,0.9858046174049377
42185251,165,hachikuji,2015-10-15T21:48:56Z,"consumernetworkclient does fail some requests before they are sent, but i don't think disconnectexception is possible.",0,0.9169877171516418
42189757,165,hachikuji,2015-10-15T22:34:12Z,"ok, so here's a summary of the changes i'm suggesting: 1. change consumer metadata schema to the following: [code block] assignment stays as it currently is (are there any cases where an assignor implementation would need to propagate additional information in the assignment)? 2. migrate the subscription/assignment schemas currently in abstractpartitionassignor back into consumerprotocol. 3. change the partitionassignor interface to look something like this: [code block] 4. add protocoltype field to joingroup request: [code block] for the consumer, the protocol type will be ""consumer"" and this will allow tools to use consumerprotocol to parse subscription/assignment metadata (assuming we will eventually expose it in describegroup or something similar). what do you think?",0,0.9664024114608765
42190485,165,ewencp,2015-10-15T22:42:19Z,"so then does that include the changes was talking about? the basic approach sounds fine, and the organization is similar to how i updated the copycat code when i rebased onto this code -- i kept a copycatprotocol class, though it ended up just holding a few static methods + inner classes. but this is a solution for making generic tooling for consumers possible. you could do all of this and still restrict the format to kafka structs as proposed, right?",0,0.9112797379493713
42193354,165,guozhangwang,2015-10-15T23:15:10Z,is this class needed?,0,0.9864785075187683
42195737,165,guozhangwang,2015-10-15T23:49:11Z,"i was originally mainly think about code simplicity, not about tooling connivence much. i am wondering for copycat, is a topics field always necessary and representative of the resource partitions? i get 's point that enforcing the whole protocol to be restricted to kafka structures would be less flexible in terms of compatibility, and if we only do that by extracting `topics` from subscriptions while keep `userdata` and `assignment` still generic types then it does not buy us much regarding code simplicity either. so i am now ok with the current approach of keeping `generictype`. the only other comment is as below: we probably can save the abstractpartitionassignor as its only `assign` function is more like a helper function, hence putting the schemas in a `consumerprotocol` class along with the helper functions, and only keep one `partitionassignor` interface for users to instantiate.",0,0.8136874437332153
42195884,165,hachikuji,2015-10-15T23:51:18Z,my suggestion is limited in scope to the new consumer. copycat can still implement metadata however it wants.,0,0.9818259477615356
42197214,165,ewencp,2015-10-16T00:11:39Z,"following up, i got a clearer explanation from offline. the change is specific to the consumer groups, copycat still has control over its serialization via its abstractcoordinator subclass since that class just deals with `byebuffer`s. so i think this plan with the extra user data makes sense.",0,0.967190682888031
42197590,165,guozhangwang,2015-10-16T00:17:50Z,"talked to offline, my previous understanding was incorrect that other services like copycat and kafkastreams also need to implement `partitionassingor`, which is actually only gonna be used by the new consumer. hence for others they can always decide to implement their only schemas that is not restricted to kafka schema / struct.",0,0.9438771605491638
42278727,165,guozhangwang,2015-10-16T19:07:24Z,we can remove the package prefix.,0,0.9887941479682922
42281759,165,hachikuji,2015-10-16T19:40:04Z,"yes, that's right, since the generation is required, i think it should be ok. of course this implies that the coordinator keeps sync state around while in the stable state. one thing we've discussed is allowing the coordinator to discard this state some time after the group becomes stable (maybe after one session timeout). this would reduce the memory footprint of the group on the broker in the steady state. this is probably worth looking at once this patch is out of the way.",0,0.9545419216156006
42284440,165,guozhangwang,2015-10-16T20:08:39Z,totally agree.,0,0.9180122017860413
42426323,165,guozhangwang,2015-10-19T21:10:14Z,"could you also update the comments here according to the discussed fsm? basically we only need the responding logic for each event within a state, and the transit logic between across states.",0,0.9875736832618713
42427091,165,guozhangwang,2015-10-19T21:17:31Z,"i think we said in this case we will also return rebalance_in_progress, and hence we can remove unknown_member_id from possible error codes in syncresponse?",0,0.9862884283065796
42427602,165,guozhangwang,2015-10-19T21:21:52Z,"in the current protocol the leader should never submit the sync request twice, or in otherwords submit a sync group request without receiving a join group response; and if they do it would be due to a re-send upon ack failed, etc. hence i think in the stable state we should not distinguish leader with others any more and just treat everyone as the same.",0,0.9416215419769287
42428212,165,guozhangwang,2015-10-19T21:27:19Z,"i think it's better the follow the same pattern as we do in handlexxx here, e.g. move the checking such as `rebalancepurgatory.checkandcomplete()` if the state is in `reparerebalance``, or``maybepreparerebalance``if state is in``awaitingsync``or``stable``. also with the current implementation we will transit from awaitingsync to preparerebalance if any of the members failed, but with my proposed protocol we could only trigger that transition if the leader fails. is there any problem doing this?",0,0.9825458526611328
42428592,165,guozhangwang,2015-10-19T21:30:37Z,"i forgot to add this event in the fsm before, it should be treated as similar to onconsumerfailure.",0,0.9798671007156372
42429156,165,guozhangwang,2015-10-19T21:36:07Z,move this condition after the first one as we want to send rebalance_in_progress before illegal_generation: they may not cause difference for now but just be careful for future updates. or just use `match case` on states and only do generation / member-id checks for `stable` state.,0,0.9840782880783081
42429312,165,guozhangwang,2015-10-19T21:37:34Z,if the state is in `preparerebalance` we can accept if generation is from the previous one?,0,0.988842248916626
42429493,165,guozhangwang,2015-10-19T21:39:13Z,nit: onexpirerestablaize.,0,0.983633816242218
42429521,165,guozhangwang,2015-10-19T21:39:31Z,nit: onexpireheartbeat.,0,0.8709149956703186
42429678,165,guozhangwang,2015-10-19T21:40:58Z,"also according to what we discussed offline, maybe we can rename ""restabilize"" to ""join"" since it is only for the first phase of rebalance.",0,0.9839979410171509
42437210,165,hachikuji,2015-10-19T23:02:31Z,"i think that is right. the generation is incremented after the join completes, so we allow commits from the current generation in preparerebalance.",0,0.984062135219574
42437479,165,guozhangwang,2015-10-19T23:06:06Z,"ah right, my bad.",-1,0.9863943457603455
42469221,165,onurkaraman,2015-10-20T08:45:08Z,it may be more intuitive to return unknown_member_id when group == null.,0,0.9865885376930237
42531198,165,guozhangwang,2015-10-20T18:04:34Z,"i think i agree, it is also for consistency with hb and leave requests.",0,0.9728521108627319
42575975,165,becketqin,2015-10-21T01:50:05Z,should this be getconfiguredinstances()?,0,0.9880908727645874
42576026,165,becketqin,2015-10-21T01:51:12Z,"minor, kafka convention is not using brackets for single line statement.",0,0.9691526293754578
42576335,165,becketqin,2015-10-21T01:58:16Z,can we put some of the methods in a separate util class?,0,0.9881982207298279
42576376,165,guozhangwang,2015-10-21T01:59:01Z,"currently our configs are still going to pass-in a single partitioner which is then be used as a singleton list, hence we use `getconfiguredinstance` here.",0,0.988178551197052
42577420,165,hachikuji,2015-10-21T02:20:40Z,i think might be right. providing multiple instances is to support changes in a rolling upgrade scenario.,0,0.9813019633293152
42578537,165,becketqin,2015-10-21T02:44:19Z,"the name is a little bit misleading here. when rebalance occurs, no one actually leaves the group, right? also, according to the comments for this method: _invoked when the group is left (whether because of shutdown, metadata change, stale generation, etc.)_ at very least it looks metadata change actually will not kick anyone out of the group, but only trigger a rebalance.",0,0.7674803733825684
42578745,165,becketqin,2015-10-21T02:47:22Z,do we have any use case in mind for this method? it looks somewhat overlapping with consumerrebalancelistener.onpartitionsassigned().,0,0.9886992573738098
42578814,165,becketqin,2015-10-21T02:49:10Z,empty comments.,0,0.7080585360527039
42578959,165,hachikuji,2015-10-21T02:52:02Z,two potential use cases i know of. one is sticky partitioning where the partitioner sends the old assignment in the subscription for the next round so that the leader can keep partition movement minimal. the other is for kafka streams ( knows more about this use case).,0,0.9858771562576294
42642563,165,hachikuji,2015-10-21T15:52:10Z,"yeah, that's a fair point. perhaps beforerejoin would be more accurate?",0,0.9685529470443726
42643752,165,hachikuji,2015-10-21T16:01:01Z,actually i don't think it's too inaccurate since you are leaving the generation. perhaps onleavegeneration?,0,0.8220353722572327
42653027,165,becketqin,2015-10-21T17:15:33Z,"i'm not sure how it would work for sticky partition case. to make the leader honor the sticky partition (move as less partition as possible), the current leader needs to know the global assignment from the previous rebalance. but here we only have the assignment of this particular consumer. if we want to have sticky partition assignor perhaps we can let every consumer include their current assignment in the joingrouprequest and let the leader parse them.",0,0.9425709247589111
42653813,165,hachikuji,2015-10-21T17:21:38Z,"the idea is to have the local assignment returned in onassignment included in the user data of the next subscription. all subscriptions are forwarded to the leader, so it would be able to use the previous assignments found in the member's subscription userdata to compute the next assignments.",0,0.9877975583076477
42654165,165,guozhangwang,2015-10-21T17:24:16Z,"`onassignment` is only triggered after the syncing phase by everyone, not only by the leader. it is different from `consumerrebalancelistener.onpartitionsassigned()` such that the latter only gives the list of partitions, while the former contains extra userdata that can be associated with the assigned partitions. for kafka streams it is important to use this userdata to infer the further mapping from consumer's partitions to task's partitions.",0,0.9866834282875061
42683684,165,becketqin,2015-10-21T21:18:44Z,"i kind of think we should be careful about those terminologies. otherwise we can easily confuse people. another example is `dosync` and `performsync`, from the name it is hard to tell the difference. i suggest we do the following for abstractcoordinator: 1. rename `dosync` to `generateassignments`, and there is no need to pass in `leaderid` because it is always going to be itself. 2. separate `performsync` to `onelectedasgroupleader` and `oneelectedasgroupmemeber`. we can invoke them in joingroupresponsehandler.handle() 3. rename `onleave` to `ongroupjoinstart` 4. rename `onjoin` to `ongroupjoinfinish` 5. rename `sendjoingrouprequest` to `performgroupjoin` so the sequence becomes: 1. ongroupjoinstart 2. performgroupjoin 3. ongroupjoinfinish in performgroupjoin(): 1. sendjoingrouprequest 2. joingroupresponsehandler.handle() \* onassignedasgroupleader (only valid for leader) \* generateassignments \* sendsyncgrouprequest() with assignments or \* onassignedasgroupmember (only valid for member) \* sendsyncgrouprequest 1. syncgroupresponsehandler.handle() - getpartitionassignment and complete the future. except for that, the client side code structure looks good to me. i will continue to review the server side code.",0,0.9771556854248047
42685152,165,becketqin,2015-10-21T21:30:55Z,got it. thanks for the explanation.,1,0.9162863492965698
42689244,165,hachikuji,2015-10-21T22:05:54Z,"thanks for the suggestions! a few notes: 1. i agree with renaming dosync. initially i was thinking of this phase as ""state synchronization,"" but in the end, it seemed that the assignment terminology was easier to understand, so i did some renaming, but didn't catch all. i think, however, that leaderid is needed in the general case because the member doesn't know its own id (the copycat patch is already depending on this). 2. yeah, we can do this. maybe more concisely, we can use `onbecomeleader` and `onbecomefollower`? 3. this suggestion is equally confusing in my mind. it seems more natural to phrase this in terms of the generation. instead of `onleave`, my suggestion would be `ongenerationend`. 4. similarly, `onjoin` becomes `ongenerationbegin`. 5. i guess that's fair since it's not only sending the join group.",1,0.9489585161209106
42718108,165,becketqin,2015-10-22T07:27:54Z,"about (3) and (4), i think the confusion comes from we are reusing the term **join** here while we already have a joingrouprequest. but i am also a little concerned about exposing the concept of **generation**. **generation** is a purely implementation detail so it would be nice not to expose that to user. my original thinking was `onrebalancebegin()` and `onrebalanceend()`. it is a precise description and avoids reusing joingroup, but it exposes the concept of **rebalance** to user. that was why i switched to `ongroupjoinbegin` and `ongroupjoinend` - because it is very easy for user to understand. people who overrides those two methods don't need to have ideas about internal details such as joingrouprequest, generation, rebalance, etc. they only need to know: 1. **ongropujoinstart** - do something before taking action to join/rejoin the group. 2. **generateassignments** - run the customized resource assigning algorithm. 3. **ongroupjoinfinish** - do something after you joined the group from user's point of view they are only doing a group join (it has nothing to do with joingroupreqeust). group join looks more intuitive than names related to rebalance or generation. i just want to reason a little bit on the names. because those method names are essentially public api that user will override, i feel making them easy to understand is important.",-1,0.7470390796661377
42779406,165,hachikuji,2015-10-22T17:35:35Z,"yep, totally agree on the importance of naming. this issue is clearly related to the discussion on kafka-2674. i think there are two ways we can approach this: 1. the callbacks are used to indicate phases of rebalance. there is an initial call when the rebalance begins and another call when the rebalance ends. maybe we could change the names in this case to `onjoinbegin` and `onjoinfinish`. 2. the callbacks are used to indicate group membership. in this case, the first call would always be onjoin and every onjoin would be paired with a corresponding onleave. in this case, onleave would get invoked in close if there is an active group. i think you are favoring 1., while the current rebalancelistener used by the consumer and the abstractcoordinator is suggesting 2. to the user. whichever we decide, we need to make the naming consistent. i actually don't have a strong preference either way, but i think it comes down to the following question: are there any cases where the onpartitionsrevoked() function is going to do anything different than what would be done on close(). if they always do the same thing, then we should probably make user's life easier and implement 2. if not, then we should keep 1.",0,0.8750947713851929
42831631,165,becketqin,2015-10-23T04:03:50Z,"good point about the correlation with rebalance listener methods. you are right, we should make them consistent. it looks we are trying to address two different kinds of programmers: 1. people who are using kafkaconsumer. 2. people who are developing their clients(producer/consumer/processor, etc) and extending abstractcoordinator. majority of the programmers belongs to (1). what they need to provides today are: - consumerrebalancelistener - `onparitionsrevoked()` - `onparitionsassigned()` - partitionassignor - `assign()` - `onassignment()` - `subscription()` the programmers in case (2) need to think about: - `ongroupjoinstart()` - `generateassignment()` - `ongroupjoinend()` to make everything consistent, perhaps we can change the consumerrebalancelistener interface to: - consumerrebalancelistener - `ongroupjoinstart()` - `ongroupjoinend()` as said in kafka-2674, my only concern about this approach is that if later on we want to add a `beforecommittingoffset()` to rebalance listener, that's going to be a bit weird. but there is always a workaround to turn off auto commit and let user have full control over the state when `ongroupjoinstart` is called. so i guess this is less a problem. does this approach make sense? btw, wrt **leave**, here is my understandings about onleave() if we have one. if we have an onleave(), it should only be called when a consumer has been kicked out of the group, i.e. its generation id is no longer valid. otherwise, the consumer is technically still in the group. that means onleave() should not be called during a normal rebalance because the generation id is still valid.",1,0.500117301940918
42897321,165,hachikuji,2015-10-23T18:21:35Z,"hey , can you have a look at #354? maybe we can continue discussion there? my current position is basically to make the naming consistent with the implementation. right now, the implementation of onleave is actually closer to ongroupjoinstart (or onjoinprepare as i named it in that patch). i think it's worth discussing whether onleave would be more useful in practice, but we need to think it through. it seems to me like onjoin and onleave, if implemented according to their naming, would be a more intuitive paradigm for developers to build off of, but it is a little inconsistent with prior usage of rebalance callbacks.",0,0.8249868154525757
43426682,165,becketqin,2015-10-29T18:35:45Z,what would happen if coordinator shuts down after this test passes?,0,0.9540423154830933
43427203,165,becketqin,2015-10-29T18:39:49Z,"minor, it might be slightly cleaner if we throw exception when some error occurs and catch the exception in handlejoingroup() and call responsecallback. we might also want to add error log message when exception is thrown.",0,0.986332356929779
43428250,165,becketqin,2015-10-29T18:48:07Z,do we need to pass in member.memberid? can we simply pass in member?,0,0.9872937202453613
43442917,165,hachikuji,2015-10-29T20:54:28Z,"yep, good point.",1,0.9126344323158264
43444426,165,hachikuji,2015-10-29T21:07:18Z,"nod, i was following the pattern of the other handlers. throwing exceptions might let us remove a little boilerplate, but either approach works for me. and i agree on logging.",0,0.9739632606506348
43449219,165,becketqin,2015-10-29T21:50:26Z,it seems fine. we always shutdown socketserver and kafkaapis before shutting down coordinator.,0,0.8804102540016174
43451430,165,becketqin,2015-10-29T22:12:19Z,the comments here seems not accurate.,-1,0.7112417817115784
43457097,165,becketqin,2015-10-29T23:24:31Z,what if the leader send syncgrouprequest late? should we start counting down after we send syncgroupresponse because the consumer only starts to heartbeat after syncgroupresponse is received.,0,0.9770968556404114
43664832,165,hachikuji,2015-11-02T18:50:00Z,"actually i think it's right. if the follower's metadata is different, then we force a rebalance.",0,0.9718299508094788
43665262,165,hachikuji,2015-11-02T18:53:14Z,"we start the clock after join group completion. if the leader fails to send syncgroup within one session timeout after the join group phase has completed, then we will transition to preparing rebalance (i think i have a test case for this). if the leader sends syncgroup after this transition, then it will be given a rebalance_in_progress error.",0,0.9848682880401611
1806596264,17539,apoorvmittal10,2024-10-18T14:25:57Z,"question for my understanding: do we need to this calculation? as i can see fetch params already has minbytes in request to replica manager hence isn't the response from replica manager should be empty if minbytes criteria is not satisfied? so the question arise that how do we differentiate between empty reponse from replica manager log read, if that's beacus of min bytes or there is no data in the log? in either case we should continue holding the request in purgatory? wdyt?",0,0.9670721292495728
1806619158,17539,adixitconfluent,2024-10-18T14:39:49Z,"hi , iiuc, minbytes is utilized in `replicamanager.fetchmessages` functionality [a link] not in `replicamanager.readfromlog`. the way it calculates the `accumulatedbytes` is the same way i have done it in my code ([a link]. i don't see the usage of `params.minbytes` in `readfromlog` functionality",0,0.9859973192214966
1806639708,17539,apoorvmittal10,2024-10-18T14:53:04Z,i think you are right. i also see only reference of param minbytes in fetchmessages and not in readfromlog. also the readfromlog says upto maximum in description and nothing about minbytes. then the pr change sounds good but i was wondering why do we accept complete fetchparams in readfromlog when we don't utilize something like minbytes there. not sure if we should have minbytes support in readfromlog itself. maybe out of scope of this pr. can help is with more context.,0,0.7996060848236084
1806669871,17539,apoorvmittal10,2024-10-18T15:15:54Z,"hmmm, is this same for regular fetch operations as well?",0,0.9859143495559692
1806671945,17539,apoorvmittal10,2024-10-18T15:17:28Z,and why don't we want to release the partition locks from oncomplete?,0,0.982833743095398
1806680209,17539,apoorvmittal10,2024-10-18T15:24:01Z,"in most scenarios the request might have minbytes, hence do you always want to initialize a hash map? mostly it will be overriden with `responsedata` map. so can't it be null? moreover can't it be simpy a boolean variable i.e. boolean minbytessatisfied = false if (accumulatedbytes.get() >= sharefetchdata.fetchparams().minbytes) replicamanagerfetchsatisfyingminbytes = responsedata; => if (accumulatedbytes.get() >= sharefetchdata.fetchparams().minbytes) minbytessatisfied = true; if (replicamanagerfetchsatisfyingminbytes.isempty() && !hasrequesttimedout) { => if (!minbytessatisfied && !hasrequesttimedout) { return replicamanagerfetchsatisfyingminbytes; => return collections.emptymap()",0,0.9850417971611023
1806682789,17539,apoorvmittal10,2024-10-18T15:26:07Z,now we can come to this code path getting no result from `replicamanagerfetchdata`. hence is the log line still correct?,0,0.9879524111747742
1806685722,17539,apoorvmittal10,2024-10-18T15:28:25Z,"do you need this extra variable or can just write later, if needed? and then no need of else block below. replicamanagerfetchdatafromtrycomplete = replicamanagerfetchdata(topicpartitiondata, true);",0,0.9884087443351746
1806689153,17539,apoorvmittal10,2024-10-18T15:31:10Z,"fetchresponsedata can still be empty, though processfetchresponse handles the empty check, is it intended? though no harm, just checking with you.",0,0.9791526198387146
1806690387,17539,apoorvmittal10,2024-10-18T15:32:10Z,what about if partitions were locked but no response in data aarived then will the lock be correctly released?,0,0.9870622754096985
1806716182,17539,adixitconfluent,2024-10-18T15:53:21Z,"in this case, we want to call `sharefetchutils.processfetchresponse(sharefetchdata, fetchresponsedata, sharepartitionmanager, replicamanager)` before we want to release the locks. that part is in `oncomplete`, hence we don't release the lock",0,0.9863706827163696
1806722986,17539,adixitconfluent,2024-10-18T15:59:04Z,"yeah, it makes sense. i'll make the change.",0,0.9594025611877441
1806725239,17539,adixitconfluent,2024-10-18T16:01:03Z,"now that i think again, i should return a map with key as topic partition and value as `fetchpartitiondata` object containing 0 records and since we have not been able to satisfy all the fetch request criterias. your thoughts?",0,0.983328104019165
1806729605,17539,adixitconfluent,2024-10-18T16:04:48Z,"yeah, since `processfetchresponse` can handle it, that's why i didn't add any check here",0,0.9859304428100586
1806735371,17539,adixitconfluent,2024-10-18T16:10:17Z,"for that case, even when the data is not received from replica manager, the fetchresponsedata should still have keys as the locked topic partitions and values as empty data, so it should work. am i wrong in that understanding?",0,0.7431859374046326
1807312461,17539,adixitconfluent,2024-10-19T12:35:26Z,"i can get rid of it, but then the variable name `replicamanagerfetchdatafromtrycomplete` won't make sense if it is getting some values in `oncomplete`. i just feel that the code is more readable this way.",0,0.9503347873687744
1807413812,17539,adixitconfluent,2024-10-19T16:31:47Z,"hi , i went through the code for oncomplete of `delayedfetch` ([a link], it seems that it returns whatever it gets from `replicamanager.readfromlog`, so the current code is correct in that case. please let me know if i am wrong. cc -",0,0.9360517859458923
1809360360,17539,apoorvmittal10,2024-10-21T19:07:23Z,should it be atomiclong?,0,0.9853137135505676
1809365166,17539,apoorvmittal10,2024-10-21T19:10:32Z,"info seems to be too much here, how helpful this log would be in info mode? can we move it to debug please.",0,0.788091778755188
1809366048,17539,apoorvmittal10,2024-10-21T19:11:07Z,wouldn't this be too common? should we move it trace?,0,0.9766087532043457
1809378335,17539,apoorvmittal10,2024-10-21T19:17:15Z,will it not depend on `readfromlog` api response i.e. if you sent 3 partitions then is it guaranteed that replica manager will return all 3 partitions in response?,0,0.9893548488616943
1809417014,17539,apoorvmittal10,2024-10-21T19:44:11Z,should we maintain the order by `linkedhashmap` as earlier?,0,0.9868564009666443
1809422393,17539,adixitconfluent,2024-10-21T19:47:48Z,"reading `readfromlog` functionality, i don't see an indication where it doesn't return all the partitions sent to it, however i'll still make the change to use `topicpartitiondata` to be on the safe side.",0,0.9890077114105225
1809669520,17539,junrao,2024-10-21T23:53:47Z,"1. this approach is ok, but probably not the most efficient. `replicamanager.readfromlog` is relatively expensive. to avoid calling it on every hwm change, the delayedfetch maintains the file position of the fetch offset and compares it with the file position of hwm to estimate the fetchable bytes. we could potentially do the same thing here. this requires us to maintain the file position for sharepartition.endoffset. 2. ideally, we need to take into account the size of those non-acquirable batches in sharepartition when estimating the fetchable bytes.",0,0.953627347946167
1810373760,17539,apoorvmittal10,2024-10-22T09:40:25Z,thanks a lot for suggestion . this is good. i have aquestion on 2. though it's an ideal solution but the next fetch offset being prior to endoffset should be rare i.e. when some records are released or timedout. so i think we can avoid calculating non-acquirable and proceed to fetch anyways if our criteria from end offset to hwm meets. we can have the min bytes check after the fetch as currently in the pr. wdyt?,1,0.985536515712738
1810810655,17539,adixitconfluent,2024-10-22T14:11:40Z,"hi , agreed this is a much better approach. just one clarification - you mean the file position of the latest offset that was fetched for the share partition, right?",0,0.8958806395530701
1811067709,17539,junrao,2024-10-22T16:44:46Z,"yes, this sounds reasonable. we can just ignore the non-acquirable records for now. basically, we need to maintain endoffset as a `logoffsetmetadata`, which contains segment position. we can then use `logoffsetmetadata.positiondiff` to calculate the available bytes.",0,0.9812273979187012
1812510188,17539,apoorvmittal10,2024-10-23T11:13:22Z,can it reside in share module under `fetch`?,0,0.9893125891685486
1812512229,17539,apoorvmittal10,2024-10-23T11:14:53Z,"isn't by default it will be null, do we need to define it here?",0,0.9792126417160034
1812513907,17539,apoorvmittal10,2024-10-23T11:16:09Z,"you made a new class for this, shouldn't we pass that here?",0,0.972926676273346
1812514360,17539,apoorvmittal10,2024-10-23T11:16:29Z,is it need to be default scoped?,0,0.9854457378387451
1812516782,17539,apoorvmittal10,2024-10-23T11:18:26Z,"so in a fetch result of 10 batches we should store the last batch info, is that correct? if yes then shouldn't name of variable be appropriately defined?",0,0.987653911113739
1812517165,17539,apoorvmittal10,2024-10-23T11:18:45Z,merge with previous line.,0,0.9680562019348145
1812518313,17539,apoorvmittal10,2024-10-23T11:19:39Z,why do we need this?,0,0.9493659734725952
1812520317,17539,apoorvmittal10,2024-10-23T11:21:10Z,will this log line print anything meaningful? i don't see tostring in `fetchpartitiondata`. should we return what's required here?,0,0.9893865585327148
1812521637,17539,apoorvmittal10,2024-10-23T11:21:49Z,should it be default scoped? if used for tests then please write // visible for testing.,0,0.9881392121315002
1812523220,17539,apoorvmittal10,2024-10-23T11:22:45Z,how the exception will be handled with this method? do we have a test case when exception is thrown by this replica manager call?,0,0.9883884787559509
1812747750,17539,adixitconfluent,2024-10-23T13:20:10Z,i've moved it to protected. it cannot be private since it is utilized in `delayedsharefetch`,0,0.9873141646385193
1812784514,17539,adixitconfluent,2024-10-23T13:36:51Z,"we store the last fetched offset's properties in `logoffsetmetadata` class like the message offset, file position etc. hence, naming it `latestfetchoffsetmetadata` makes more sense than `latestfetchbatchmetadata`. wdyt?",0,0.9875534772872925
1812833979,17539,AndrewJSchofield,2024-10-23T13:56:54Z,"nit: i hesitate to correct your greek, but the singular of ""criteria"" is ""criterion"". maybe ""isminbytessatisfied"" would be simpler than worrying about greek grammar.",0,0.9566553235054016
1812914606,17539,adixitconfluent,2024-10-23T14:33:31Z,i've added the handling and test case for this in my latest commit,0,0.9852295517921448
1813543008,17539,junrao,2024-10-23T20:50:30Z,"we need to check if the two offset metadata are on the same segment first before using `positiondiff`. also, we need to handle the case when hwm doesn't have offset metadata. we can just follow the logic in `delayedfetch`.",0,0.9884603023529053
1813549471,17539,junrao,2024-10-23T20:53:30Z,we need to check `sharefetchdata.fetchparams().isolation` to decide whether to use hwm or laststableoffset.,0,0.9886849522590637
1813657687,17539,junrao,2024-10-23T21:31:18Z,"it's kind of late to set the offset metadata here since we will acquire the fetch records and move the next fetch offset. this means the cached offset metadata doesn't match the next fetch offset. i was thinking of doing the following. in `trycomplete`, if the offset metadata doesn't exist, we call `replicamanager.readfromlog` to populate the offset metadata. we can then proceed with the minbyte estimation. if sharepartition.endoffset moves, we invalidate the offset metadata.",0,0.9784817099571228
1815509020,17539,junrao,2024-10-24T18:07:15Z,"the `acquire` call always comes after `delayedsharefetch.trycomplete`, which already updates `latestfetchoffsetmetadata`. so, it seems that we don't need to update `latestfetchoffsetmetadata` in `acquire`?",0,0.9878325462341309
1815510878,17539,junrao,2024-10-24T18:09:01Z,we need to reset `latestfetchoffsetmetadata` every time `endoffset` changes.,0,0.9863882660865784
1815515373,17539,junrao,2024-10-24T18:12:55Z,"it's possible that `maybeupdatefetchoffsetmetadatafortopicpartitions` calls `readfromlog`, which returns enough bytes. in that case, it's more efficient to reuse the fetched result instead of calling `readfromlog` again in `oncomplete`.",0,0.9882533550262451
1815520277,17539,junrao,2024-10-24T18:17:19Z,perhaps it's clearer to make sharepartition.latestfetchoffsetmetadata() an optional?,0,0.9885502457618713
1815531648,17539,junrao,2024-10-24T18:27:27Z,"in delayedfetch, if a partition no longer exists, we complete the operation immediately.",0,0.9872588515281677
1815542651,17539,junrao,2024-10-24T18:37:09Z,could this just be a `long`?,0,0.9825072884559631
1815548051,17539,junrao,2024-10-24T18:42:00Z,"hmm, we don't want to read all partitions if only one partition's offset metadata is missing, right?",0,0.9800849556922913
1815562399,17539,junrao,2024-10-24T18:55:14Z,"1. perhaps ""we maintain the latest fetch offset metadata to estimate the minbytes requirement more efficiently.""? 2. also, could we keep it together with `endoffset` since they are related.",0,0.9878018498420715
1815586235,17539,adixitconfluent,2024-10-24T19:18:47Z,"yeah, but in case there are multiple partitions for which offset metadata is missing, i thought that its better to make a single `readfromlog` call instead of multiple `readfromlog` calls. thus, using all the topic partitions in one call itself. wdyt?",0,0.9848839044570923
1815592778,17539,adixitconfluent,2024-10-24T19:25:07Z,"`updatelatestfetchoffsetmetadata()` is only called from `trycomplete` when we find that there is a share partition whose offset metadata is not present (because in that case only, we call `readfromlog`). however, for any other case, we can only update the `latestfetchoffsetmetadata` via `acquire` method only. else we'll have to call `readfromlog` from `trycomplete` in all scenarios to directly update share partition's `latestfetchoffsetmetadata`. anything wrong in that understanding?",0,0.9882493019104004
1815599413,17539,adixitconfluent,2024-10-24T19:31:09Z,"iiuc, everytime we fetch new records from `readfromlog`, i utilize the `logoffsetmetadata` object from the response to update the `latestfetchoffsetmetadata` object while doing the acquire. hence, this way i have the most recent fetched offset's metadata that i always update through `acquire` method. most of the time, it is going to be the endoffset's metadata itself, as soon as new data is produced to the topic partition. anything else that i need to do here?",0,0.9774492383003235
1815731593,17539,junrao,2024-10-24T21:50:37Z,"hmm, if a previously acquired batch times out, sharepartition will change endoffset. this means that the cached latestfetchoffsetmetadata no longer matches the next fetch offset, right?",0,0.9830445051193237
1815739504,17539,junrao,2024-10-24T21:56:47Z,"hmm, to me `acquire` seems to be the wrong place to update `latestfetchoffsetmetadata`. we update `latestfetchoffsetmetadata` with the fetch offset and then acquire a few batches after the fetch offset. this typically moves the next fetch offset, which makes `latestfetchoffsetmetadata` useless for the next fetch.",0,0.9496720433235168
1815741519,17539,junrao,2024-10-24T21:59:31Z,maybe we can first make a pass to collect all partitions missing offset metadata and then make a single `readfromlog` with those partitions?,0,0.98897385597229
1816504391,17539,apoorvmittal10,2024-10-25T11:20:03Z,wouldn't `fetchoffsetmetadataupdateresult` be a better name?,0,0.9838441014289856
1816509367,17539,apoorvmittal10,2024-10-25T11:24:10Z,do we need the variable name to have suffix `trycomplete`? i don't find the suffix is any helpful.,0,0.968966007232666
1816510686,17539,apoorvmittal10,2024-10-25T11:25:23Z,"why to have method names with such suffix, are they helping? [code block]",0,0.9793727993965149
1816519200,17539,apoorvmittal10,2024-10-25T11:33:01Z,is it handled?,0,0.9853642582893372
1816530978,17539,apoorvmittal10,2024-10-25T11:43:00Z,"how frequent it is to see missing fetch offset information, mostly at start only right? they why to initialize this variable, can't it be lazily loaded, if required?",0,0.9817795157432556
1816619673,17539,apoorvmittal10,2024-10-25T12:46:27Z,so the update should be safe with multiple threads as we have acquired the lock on share partition which guards us from 2 threads trying to update the offset metadata. but we should write comments on the share partition update method that the caller of the method should ensure that share partition fetch lock is acquired prior invoking the updatelatestfetchoffsetmetadata.,0,0.9886088371276855
1816620754,17539,apoorvmittal10,2024-10-25T12:47:18Z,can it be in a separate method i.e. divide methods.,0,0.9839851260185242
1816621221,17539,apoorvmittal10,2024-10-25T12:47:39Z,merge the lines.,0,0.9801228642463684
1816657075,17539,apoorvmittal10,2024-10-25T13:09:30Z,"so this iteration will always be executed for every share fetch when the `missingfetchoffsetmetadatatopicpartitions` will rarely be true, only when a new sharepartition is created. hence, i was thinking why not to have such update only on sharepartition initialization. though i understand that current `readfromlog` api requires fethchparams but is there an api which can supply the logoffsetmetadata when requested with topic partition and specific offset(start offset of share partition)? wdyt?",0,0.9765419960021973
1816661560,17539,apoorvmittal10,2024-10-25T13:12:17Z,can it go in a method please.,0,0.9851560592651367
1816667130,17539,apoorvmittal10,2024-10-25T13:16:10Z,why do we satisfy the min byte criteria if share partition is null?,0,0.9801957011222839
1816668262,17539,apoorvmittal10,2024-10-25T13:17:03Z,"should the varibale in sharepartition be optional? we always should have that, correct?",0,0.9848244786262512
1816670642,17539,apoorvmittal10,2024-10-25T13:18:48Z,"sorry, i didn't understand when we can have the offset in share partition > partition end offset?",-1,0.9868156313896179
1816678081,17539,apoorvmittal10,2024-10-25T13:22:04Z,again this will be rare hence shall we delay initiliazing linkedhashmap.,0,0.8724679946899414
1816687484,17539,apoorvmittal10,2024-10-25T13:25:21Z,can it be non-null and empty ever i.e. do you require your second condition?,0,0.9845720529556274
1816691162,17539,apoorvmittal10,2024-10-25T13:27:47Z,"can it ever occur that you have non-empty `logreadresponsefromtrycomplete` but `topicpartitiondata` came from fresh aquisition from line 98 (topicpartitiondata = acquirablepartitions();). i think never, can you just write comments for this.",0,0.9763826131820679
1816693860,17539,apoorvmittal10,2024-10-25T13:29:27Z,please correct the alignment of comments.,0,0.9830764532089233
1816695469,17539,apoorvmittal10,2024-10-25T13:30:31Z,why it's optional?,0,0.941804051399231
1816703702,17539,apoorvmittal10,2024-10-25T13:35:20Z,so if we are fetching from offset 0 and gets response from log for 0-1000 offsets then `logresult.info().fetchoffsetmetadata` contains information for 0 offset or 1000th offset i.e. which offset metadata does it hold?,0,0.9891738891601562
1816704806,17539,apoorvmittal10,2024-10-25T13:36:05Z,class comments please.,0,0.9822770953178406
1816705073,17539,apoorvmittal10,2024-10-25T13:36:17Z,empty line break please.,0,0.9461568593978882
1816711409,17539,apoorvmittal10,2024-10-25T13:40:35Z,that's my queustion with this comment [a link] do we ever get the lastfetchoffsetmetadata or we always update with fetchoffsetmetadata?,0,0.9864493012428284
1816800887,17539,adixitconfluent,2024-10-25T14:34:41Z,i can confirm this will return information about 0th offset.,0,0.9886566400527954
1816813489,17539,apoorvmittal10,2024-10-25T14:41:03Z,so this suggestion is not apt as we need the refreshed information [a link],0,0.7674736976623535
1816818571,17539,adixitconfluent,2024-10-25T14:44:21Z,"hi , i understand your point now. here's my proposed solution changes- 1. remove update of `latestfetchoffsetmetadata` via `acquire` method 2. in `oncomplete`, after i complete the call of `sharefetchutils.processfetchresponse`(which internally completes the call of `acquire` method), i will do a `readfromlog` for `topicpartitiondata` with their latest fetch offset and update the share partition's `latestfetchoffsetmetadata`. note this call to `readfromlog` will always happen despite the `trycomplete` `readfromlog` happens or not. please let me know what you think of this approach.",0,0.9061198830604553
1816827231,17539,adixitconfluent,2024-10-25T14:49:08Z,"hi , understood, so if there is any calls to acknowledge/acquisition lock timeout/release acquired records on session close, i should update the latestfetchoffsetmetadata to `optional.empty()`. then when the next trycomplete call comes, it will update the `latestfetchoffsetmetadata` and we will have the most recent result. or is my understanding incorrect?",0,0.9829755425453186
1816829826,17539,adixitconfluent,2024-10-25T14:50:57Z,"i did it because the value can be null, so we thought it would be better to keep it as optional [a link]",0,0.9804964661598206
1816830605,17539,adixitconfluent,2024-10-25T14:51:32Z,"you're right, i don't need it.",0,0.8239420056343079
1816832978,17539,adixitconfluent,2024-10-25T14:52:57Z,"not necessary, it can be null as well. hence, we use optional here.",0,0.986440122127533
1816851362,17539,adixitconfluent,2024-10-25T15:02:51Z,"it might not be true ever in case we are using `fetchisolation.high_watermark`, but i think it can be true in case we use `fetchisolation.log_end` and `fetchisolation.txn_committed` which might be used in the future in share fetch requests.",0,0.989312469959259
1817193502,17539,junrao,2024-10-25T18:39:55Z,"i was thinking about an alternative approach by maintaining `latestfetchoffsetmetadata` every time we update `endoffset`. in the common case, we move `endoffset` to `lastoffset` of an acked batch. the file position in `latestfetchoffsetmetadata` can just be updated by adding the batch size to the file position of the previous `latestfetchoffsetmetadata`. this way, in the common case, we only need to call `readfromlog` once per fetch request, instead of twice (once for getting `latestfetchoffsetmetadata` and another for getting the data) in the current approach.",0,0.9697638750076294
1817933790,17539,adixitconfluent,2024-10-26T21:36:55Z,"hi , i am not sure if i understand the approach completely. iiuc, 1. i agree with the common case where during `oncomplete` we can update the file position by directly adding the batch size. but, there are cases where we return true from `isminbytessatisfied` if `fetchoffsetmetadata` was on a different segment than the `endoffsetmetadata` ([a link]. in those case, we don't know the number of bytes that got accumulated in the response. same goes for the case `fetchoffsetmetadata.messageoffset > endoffsetmetadata.messageoffset`, how do we know whta is the number of bytes to add? 2. i am assuming that with this approach, we do not need to do any handling during acquisition lock timeout/acknowledgements/release acquired records on session close. please correct me if i am wrong. ps - thanks a lot for taking out the time to explain me and reviewing this pr.",0,0.9485191702842712
1817943465,17539,junrao,2024-10-26T22:31:36Z,": here is the rough idea. 1. if endoffset advances forward, we incrementally update its file position by the size of batches going forwarded. 2. the tricky thing is how the offset metadata picks up a new segment being rolled. as we increase the file position, endoffset will eventually reach the baseoffset of the next segment. this means that the next fetch request will be satisfied immediately since the hwm is on a different segment. when we acquire the data (for batches at the beginning of the segment), we can check if the offset metadata in the fetch data has the same offset as endoffset but on a different segment. if so, we update the offset segment of endoffset. 3. if the endoffset goes backward (due to timeout/acknowledgements/release) or endoffset is being initialized for the first time, we just call readfromlog to get the offset metadata. 4. `trycomplete` will have the same logic to deal with the uncommon cases where the offset metadata is not available or the offset metadata is on the same segment. the only difference is that it won't update latestfetchoffsetmetadata any more since the update happens when endoffset changes.",0,0.9305978417396545
1818144589,17539,junrao,2024-10-27T17:18:30Z,"while this alternative approach is more efficient, it's probably also more complicated. so, it's also ok to just take the current approach to start with. in the current approach, (1) if any call moves `endoffset`, we reset the `latestfetchoffsetmetadata` to optional.empty(). in `trycomplete`, if `latestfetchoffsetmetadata` is empty, we call `readfromlog` and update `latestfetchoffsetmetadata`.",0,0.9827092885971069
1818157944,17539,adixitconfluent,2024-10-27T18:40:29Z,"yes, it is handled here [a link]",0,0.9879900813102722
1818158187,17539,adixitconfluent,2024-10-27T18:41:37Z,the explanation is present in this conversation thread [a link],0,0.9856233596801758
1818159160,17539,adixitconfluent,2024-10-27T18:47:48Z,"hi , agreed with the simpler approach. i have made the following changes in my latest commit- i reset the `latestfetchoffsetmetadata` to optional.empty() if - 1. `acquire()` results in non-empty acquired records in `sharefetchutils`. 2. acquisition lock timeout is called. 3. release acquired records on session close is called. i haven't made the change in `acknowledge()` method of `sharepartition`, since in the common case all the `acquired` records will moved to `acknowledged` state and endoffset doesn't change then. this functionality has been added in previous commits. please review my pr whenever you can. thanks!",0,0.9669262170791626
1819587266,17539,junrao,2024-10-28T18:52:02Z,could we make fetchoffsetmetadata optional instead of relying on `null`?,0,0.9886293411254883
1819590569,17539,junrao,2024-10-28T18:54:40Z,this is getting a bit hard to track since we need to make this call in all places where endoffset changes. could we have a method for updating both `endoffset` and `latestfetchoffsetmetadata`? then we can replace all code that changes `endoffset` with this method.,-1,0.7336582541465759
1819592494,17539,junrao,2024-10-28T18:55:41Z,latestfetchoffsetmetadata => fetchoffsetmetadata?,0,0.9862702488899231
1819610603,17539,junrao,2024-10-28T19:10:15Z,it's probably clearer to put those in an `else` clause?,0,0.9838565587997437
1819618734,17539,junrao,2024-10-28T19:16:42Z,we could just initialize `missingfetchoffsetmetadatatopicpartitions` with `new linkedhashmap<>()`. ditto in `combinelogreadresponse`.,0,0.9843770265579224
1819637938,17539,junrao,2024-10-28T19:27:56Z,"hmm, it would be better for `logreadresponse` to only be empty, but never `null`.",0,0.9837186932563782
1819645608,17539,junrao,2024-10-28T19:34:59Z,do we need this wrapper class `fetchpartitionoffsetdata`? it seems that it's simpler for `readfromlog` to `return map `. we can then convert `logreadresult` to `map ` in `oncomplete`.,0,0.9889278411865234
1819664109,17539,junrao,2024-10-28T19:48:44Z,"every passed in partition to `readfromlog` will be included in the response. so, there is no need to pass in both `missingfetchoffsetmetadatatopicpartitions` and `replicamanagerreadresponsedata`. we do want to check the error code for each partition. in regular fetch, if any partition has an error code, we send a response immediately. we can just do the same here.",0,0.9871986508369446
1819665350,17539,junrao,2024-10-28T19:49:52Z,i thought we agreed that we want to send a response immediately if a sharepartition can't be found. is that handled?,0,0.9855688214302063
1819666995,17539,junrao,2024-10-28T19:51:27Z,could we just make a single `sharepartitionmanager.sharepartition` call per `trycomplete` to avoid having to check null repeatedly?,0,0.9885562062263489
1819670828,17539,junrao,2024-10-28T19:54:58Z,"ideally, we need to handle the exception at the partition level in the caller.",0,0.9862064719200134
1819677154,17539,junrao,2024-10-28T20:01:02Z,"this condition seems unnecessary. we need to set `logreadresponse` as long as `fetchoffsetmetadataupdateresult.replicamanagerreadresponse` is not empty, right?",0,0.9829126596450806
1824747173,17539,adixitconfluent,2024-10-31T16:04:06Z,"hi , i had updated it at a different place but now i've added that as the first step in trycomplete ([a link]. as you had also mentioned, this prevents us from making multiple share partition null checks at different places in the code.",0,0.9854539632797241
1824903292,17539,junrao,2024-10-31T17:42:42Z,"we are still calling `sharepartitionmanager.sharepartition` in multiple places (`anysharepartitionnolongerexists`, `acquirablepartitions`, `isminbytessatisfied` and `maybeupdatefetchoffsetmetadatafortopicpartitions`), each of which needs to handle null sharepartition since the sharepartition could disappear any time. i was thinking that we could get all sharepartitions once at the beginning and pass them around to other methods. this way, the null handling is only done once.",0,0.9760050177574158
1824914771,17539,junrao,2024-10-31T17:52:44Z,maybeupdatefetchoffsetmetadatafortopicpartitions => maybereadfromlogandupdatefetchoffsetmetadata ?,0,0.9842668175697327
1824931761,17539,junrao,2024-10-31T17:59:44Z,"could we just return an empty map? this way, the caller doesn't need to do the null check.",0,0.986927330493927
1824937560,17539,junrao,2024-10-31T18:01:45Z,topicpartitiondatafromtrycomplete => partitionstocomplete ? logreadresponse => partitionsalreadyfetched ?,0,0.9875245094299316
1824959019,17539,junrao,2024-10-31T18:09:14Z,this code can be a bit more concise. [code block],0,0.9832537770271301
1826092331,17539,adixitconfluent,2024-11-01T17:19:18Z,"hi , i have changed the exception handling to a top level exception handling in `trycomplete` to combat with this scenario.",0,0.9857202172279358
1826157479,17539,junrao,2024-11-01T18:24:00Z,there is no need to pass in `fetchoffsetmetadata` since it's always empty. updateendoffsetandfetchoffsetmetadata => updateendoffsetandresetfetchoffsetmetadata?,0,0.9884545207023621
1826160028,17539,junrao,2024-11-01T18:26:20Z,let's be consistent with the usage of `this`. most other places don't use `this`.,0,0.9866058230400085
1826160780,17539,junrao,2024-11-01T18:27:06Z,all callers hold the lock. so we could remove the locking here and add a comment that the caller is expected to hold the lock when calling this method.,0,0.9884862899780273
1826166921,17539,junrao,2024-11-01T18:33:29Z,this problem is still there?,0,0.9509830474853516
1826169337,17539,junrao,2024-11-01T18:35:52Z,this check is unnecessary since partitionsalreadyfetched initializes to empty.,0,0.9725388884544373
1826174394,17539,junrao,2024-11-01T18:41:05Z,should we reset `partitionstocomplete` and `partitionsalreadyfetched` too when we release the locks?,0,0.9881515502929688
1826180030,17539,junrao,2024-11-01T18:47:20Z,should we just assign the return value to partitionstocomplete directly? we already acquired the locks for those partitions and partitionstocomplete is the only place to track them for releasing.,0,0.9892655611038208
1826183958,17539,junrao,2024-11-01T18:51:35Z,this code can be a bit simpler. [code block],0,0.9837372899055481
1826185041,17539,junrao,2024-11-01T18:52:48Z,updatefetchoffsetmetadataformissingtopicpartitions => updatefetchoffsetmetadata ?,0,0.9857265949249268
1826187006,17539,junrao,2024-11-01T18:54:51Z,perhaps do this in the caller? then the purpose of the method is simpler and the method name can just be `maybereadfromlog`.,0,0.988469660282135
1826561286,17539,adixitconfluent,2024-11-02T12:32:50Z,"hi , we can do that but then once we are in the `else` of this check -` if (anytopicidpartitionhaslogreaderror(replicamanagerreadresponse) || isminbytessatisfied(topicpartitiondata))`, after we have release the partitions lock, we also need to do `partitionstocomplete.clear()`. hence, i've tried to avoid doing this by assigning `partitionstocomplete` once we are sure that we can do a `forcecomplete()`",0,0.9702109694480896
1826562798,17539,adixitconfluent,2024-11-02T12:43:59Z,"hi , i am not actually too sure if i definitely need this check. ideally, i don't think there can be any value in `sharepartitions` which can be null, but this [a link] in `sharepartitionmanager` is confusing me, plus there is this jira [a link] where we will be refactoring share partition initialization. so, this can act as a safety check for now, and i can remove this in a future pr once the refactor is complete, and we are sure we don't send null share partitions. what do you think? cc -",0,0.7065008282661438
1828181101,17539,junrao,2024-11-04T18:14:18Z,sharefetchdata => partitionstocomplete ? partitionstocomplete => partitionsacquired ?,0,0.988837480545044
1828190239,17539,junrao,2024-11-04T18:22:08Z,it's kind of weird for this method to return the input. it's more natural for this method to return nothing.,-1,0.9823951125144958
1828196542,17539,junrao,2024-11-04T18:26:13Z,"hmm, when we hit an exception, do we guarantee that `partitionstocomplete` has been set?",0,0.9827562570571899
1828254033,17539,junrao,2024-11-04T19:14:00Z,"we need to return an optional `fetchoffsetmetadata` if the value returned from `nextfetchoffset` changes. if `findnextfetchoffset` is false, `nextfetchoffset` returns a value based on endoffset. this case is already covered in this pr. if `findnextfetchoffset` is true, `nextfetchoffset` returns a value not depending on endoffset. so, we should return empty here if `findnextfetchoffset` is true.",0,0.9881574511528015
1828280371,17539,junrao,2024-11-04T19:36:40Z,"it seems that sharepartitions is always a subset of sharefetchdata.partitionmaxbytes()? if that's the case, i agree that we don't need anysharepartitionnolongerexists. however, it would be useful to make sure that the caller passes in sharepartitions and sharefetchdata.partitionmaxbytes() with the same set of partition keys.",0,0.9872739315032959
1828303188,17539,junrao,2024-11-04T19:55:05Z,this comment doesn't match the code.,-1,0.5076264142990112
1828307832,17539,junrao,2024-11-04T19:59:05Z,quite a long name. how about sth like testtrycompletereturnsfalsewhenminbytesnotsatisfied?,1,0.6115430593490601
1828314722,17539,junrao,2024-11-04T20:04:40Z,"hmm, not sure how this test is different from the next one. if this is testing fetching for the first time, sp0.fetchoffsetmetadata() should return empty, right?",0,0.9417001008987427
1828321808,17539,junrao,2024-11-04T20:10:46Z,"could we change `combinelogreadresponse` to also take `partitionsalreadyfetched`? this way, we can get rid of `delayedsharefetch.updatelogreadresponse`.",0,0.9893785119056702
1828532884,17539,apoorvmittal10,2024-11-04T23:28:40Z,we initialize the variable in constructor then re-assign while creating another linkedhashmap in acquirablepartitions() method. are we are initializing `partitionstocomplete` here to save null check? can't we re-use already initialized linkedhashmap()?,0,0.9885602593421936
1828533813,17539,apoorvmittal10,2024-11-04T23:30:01Z,again we reset `partitionsalreadyfetched` to response from `replicamanagerreadresponse`. why to have such instances created when anyways we have to re-assign?,0,0.9824635982513428
1828538998,17539,apoorvmittal10,2024-11-04T23:37:46Z,"we have now passed `sharepartitions` map which contains topicidpartition and sharepartition itself then why are we iterating on `sharefetchdata.partitionmaxbytes().keyset()` and doing a null check, why not to iterate in `sharepartitions` map itself? also make the map of `sharepartitions` in spm as of type linkedhashmap then.",0,0.9891068339347839
1828539471,17539,apoorvmittal10,2024-11-04T23:38:32Z,same elsewhere.,0,0.9803135991096497
1828542474,17539,apoorvmittal10,2024-11-04T23:43:20Z,"shouldn't we iterate on `sharepartitions` map passed in delayed share fetch which will guarantee that sharepartition cannot be null it can only be fenced (fenced handling has been separate), hence no null check is required. also no `anysharepartitionnolongerexists()` method call is required.",0,0.9867309331893921
1828547060,17539,apoorvmittal10,2024-11-04T23:50:42Z,"nit: i personally find the code hard to read with nested if/else blocks, same is the case here. though i leave it on you. ``` if (topicpartitiondata.isempty()) { log.trace(""can't acquire records for any partition in the share fetch request for group {}, member {}, "" + ""topic partitions {}"", sharefetchdata.groupid(), sharefetchdata.memberid(), sharefetchdata.partitionmaxbytes().keyset()); return false; } // in case, fetch offset metadata doesn't exist for one or more topic partitions, we do a // replicamanager.readfromlog to populate the offset metadata and update the fetch offset metadata for // those topic partitions. map replicamanagerreadresponse = updatefetchoffsetmetadata(maybereadfromlog(topicpartitiondata)); if (!anytopicidpartitionhaslogreaderror(replicamanagerreadresponse) && !isminbytessatisfied(topicpartitiondata)) { log.debug(""minbytes is not satisfied for the share fetch request for group {}, member {}, "" + ""topic partitions {}"", sharefetchdata.groupid(), sharefetchdata.memberid(), sharefetchdata.partitionmaxbytes().keyset()); releasepartitionlocks(topicpartitiondata.keyset()); return false; } partitionstocomplete = topicpartitiondata; partitionsalreadyfetched = replicamanagerreadresponse; .... ....",0,0.9759787917137146
1828550191,17539,apoorvmittal10,2024-11-04T23:56:01Z,there are 2 checks in the if condition (anytopicidpartitionhaslogreaderror and isminbytessatisfied) but the log says that minbytes criteria is not satified. i this correct log statement?,0,0.9884614944458008
1828552140,17539,apoorvmittal10,2024-11-04T23:59:15Z,we are re-assigning the already initalized variables in constructor. i would say we should have null check handling in `oncomplete` rather creating resources which never gets utilized.,0,0.9829257726669312
1828561128,17539,apoorvmittal10,2024-11-05T00:14:37Z,so did we not chose to implement [a link] rather initialize with linkedhashmap which will hardly be filled?,0,0.9777345061302185
1828563750,17539,apoorvmittal10,2024-11-05T00:18:54Z,shouldn't the name be `maybeupdatefetchoffsetmetadata` as it depends on the log read result?,0,0.9869329333305359
1828564729,17539,apoorvmittal10,2024-11-05T00:20:32Z,nit: will `foreach` be more convenient here then you don't need to call entry.getkey and entry.getvalue?,0,0.9793287515640259
1828566030,17539,apoorvmittal10,2024-11-05T00:23:01Z,isn't the log incorrect as it says the the log does not contain topicidpartition rather the response exists but it errored. also do you need to log `replicamanagerlogreadresult` or complete `replicamanagerreadresponsedata`? shouldn't we be logging former which corresponds to topic id partition?,0,0.9875106811523438
1828571399,17539,apoorvmittal10,2024-11-05T00:31:55Z,seems an incorrect error handling of release acquired partitions to me. say line 155 acquires partitions and `topicpartitiondata` is set. and we get an exception in `isminbytessatisfied` method (which anyways call getpartitionorexception method) or elsewhere then the locks released at line 193 will not release any locks as they are invoked on `partitionstocomplete` which is not yet set. moreover if forcecomplete call is successful then the acquired partitions will anyways not be released.,0,0.7835842370986938
1828573589,17539,apoorvmittal10,2024-11-05T00:35:25Z,what meant was that it should not be a top level rather partition level error.,0,0.9774961471557617
1828579315,17539,apoorvmittal10,2024-11-05T00:45:30Z,i understand there can't be concurrent calls to trycomplete but i didn't get this comment. though forcecomplete() cannot be called twice. but forcecomplete() on expiration can be on different thread and trycomplete() on different (that's my understanding as per delayedoperation code i have seen) can this change any behaviour here?,0,0.9650973677635193
1828580776,17539,apoorvmittal10,2024-11-05T00:47:59Z,"can be merged together. ``` sharefetchdata.future().complete(sharefetchutils.processfetchresponse(sharefetchdata, fetchpartitionsdata, sharepartitionmanager, replicamanager));",0,0.986310601234436
1828758874,17539,adixitconfluent,2024-11-05T05:45:48Z,"my bad, i've corrected it.",-1,0.9822061061859131
1828775451,17539,adixitconfluent,2024-11-05T06:04:52Z,"my bad, you're right, i've adjusted the mock to return `optional.empty()` for the first time and `optional.of(new logoffsetmetadata(0, 1, 0))` for the second time (post `readfromlog` call)",-1,0.9593358039855957
1828820632,17539,adixitconfluent,2024-11-05T06:55:13Z,"hi , you're right, i've changed the line to `releasepartitionlocks(topicpartitiondata.keyset())`",0,0.9721329212188721
1828824435,17539,adixitconfluent,2024-11-05T06:59:40Z,"yes, there have been comments above where i left some variables as null, and it was pointed out that i need to initialize them to avoid null checks at different places, then we just need to do empty checks.. hence, i've implemented it in this manner.",0,0.9700241684913635
1828825732,17539,adixitconfluent,2024-11-05T07:01:05Z,"same reason as above, we are avoiding any null checks. we just check for empty scenarios by doing this.",0,0.9727749228477478
1828831006,17539,adixitconfluent,2024-11-05T07:06:21Z,"i have been asked to add else blocks in the above comments on this pr, hence i don' think i should change it again. [a link]",0,0.9594494104385376
1828836294,17539,adixitconfluent,2024-11-05T07:12:01Z,"now, we reset fetchoffsetmetadata everytime the `endoffset` changes (see the usages of function `updateendoffsetandresetfetchoffsetmetadata` in `sharepartition`). so, it can be frequent now that the fetchoffsetmetadata is empty. [a link]",0,0.9884875416755676
1828845131,17539,adixitconfluent,2024-11-05T07:20:53Z,"since, i am using `continue` in the loop, i prefer to do it using for instead of foreach.",0,0.9547653198242188
1828852012,17539,adixitconfluent,2024-11-05T07:27:04Z,"yes, the log statement is correct because because `isminbytessatisfied` can run only if `anytopicidpartitionhaslogreaderror` returns false. we should only check `isminbytessatisfied` if `anytopicidpartitionhaslogreaderror` returns false. if `anytopicidpartitionhaslogreaderror` return true, then we do a `forcecomplete`.",0,0.9868150949478149
1828853882,17539,adixitconfluent,2024-11-05T07:28:50Z,"my bad, you're right about both.",-1,0.9825900197029114
1828860825,17539,adixitconfluent,2024-11-05T07:35:27Z,"you're right, i've changed the line to `releasepartitionlocks(topicpartitiondata.keyset())`. if the `forcecomplete` is successful, then the partition locks are released from `oncomplete` finally block and it doesn't concern here.",0,0.9813668727874756
1828877645,17539,adixitconfluent,2024-11-05T07:50:46Z,"what i mean is that `partitionsalreadyfetched` value can't be changed once we enter this point in `oncomplete` via `forcecomplete` either by expiration or by a `trycomplete` successful call. iiuc, `forcecomplete` uses this `atomicboolean` variable `completed` which is used as locking mechanism for `forcecomplete`. this should ensure atomicity of global variables between `trycomplete` and `forcecomplete` we use in `delayedsharefetch`. i'll change the comment to explain this better.",0,0.9822041392326355
1828902626,17539,adixitconfluent,2024-11-05T08:10:20Z,"yes, i'll remove `anysharepartitionnolongerexists()` and also iterate on `sharepartitions` rather than using `sharefetchdata.partitionmaxbytes()`. will remove the null checks from our code.",0,0.9891273379325867
1829020183,17539,adixitconfluent,2024-11-05T09:31:37Z,"hey , we are doing partition level error handling in `oncomplete` using `sharepartitionmanager.handlefetchexception`. when we get an exception in this line `replicamanager.getpartitionorexception`, we directly call `forcecomplete` (mentioned in above comments), and that does a partition level handling.",0,0.9870527386665344
1829235324,17539,apoorvmittal10,2024-11-05T12:03:46Z,"if the concern is with additional null check then i would recommend general helper methods. my concern is with creating additional maps when they are always re-referenced. ``` private void addtonullablemap(map map, k key, v value) { if (map == null) { map = new linkedhashmap<>(); } map.put(key, value); } private boolean ismapempty(map map) { return map == null || map.isempty(); }",0,0.9697026014328003
1829237621,17539,apoorvmittal10,2024-11-05T12:05:33Z,i leave it on to decide then.,0,0.9793654680252075
1829240438,17539,apoorvmittal10,2024-11-05T12:07:57Z,"it's missing yet, you can log a jira for me to fix as i am doing handling anyways.",0,0.9846057891845703
1829256794,17539,adixitconfluent,2024-11-05T12:19:58Z,logged a jira [a link] for the same.,0,0.9878355860710144
1830198129,17539,junrao,2024-11-05T23:15:54Z,why is this a linkedhashmap instead of just a hashmap?,0,0.9664720296859741
1830199934,17539,junrao,2024-11-05T23:18:33Z,"this is actually a super set of the partitions to complete. so, it's better to just keep the name sharefetchdata. it would be useful to add a comment that the partitions to be completed are given by sharepartitions and is a subset of sharefetchdata.",0,0.9849836230278015
1830201006,17539,junrao,2024-11-05T23:20:05Z,why is this a linkedhashmap instead of just a hashmap?,0,0.9664720296859741
1830203044,17539,junrao,2024-11-05T23:23:08Z,missingfetchoffsetmetadatatopicpartitions => partitionsmissingfetchoffsetmetadata?,0,0.9839189648628235
1830208462,17539,junrao,2024-11-05T23:31:16Z,this can be a bit simpler. [code block],0,0.9822428226470947
1830209083,17539,junrao,2024-11-05T23:32:13Z,anytopicidpartitionhaslogreaderror => anypartitionhaslogreaderror ?,0,0.9843065738677979
1830230584,17539,junrao,2024-11-06T00:06:59Z,"this part of the exception is still quite confusing to me. if we hit the exception, should we release the locks before calling forcecomplete()? otherwise, `forcecomplete` will try to acquire the same locks again, but can't. it will also help to narrow the try/catch to where the exception can be thrown.",-1,0.7533316016197205
1830231877,17539,junrao,2024-11-06T00:09:06Z,"we can skip clearing these two maps here since the operation is completed at this point. in `oncomplete()`, we don't clear these two maps. so, this will make the behavior more consistent.",0,0.9856929779052734
1830238005,17539,junrao,2024-11-06T00:19:06Z,"this is an existing issue. in the line below, we are logging for each partition, but sharefetchdata contains the full request. [code block]",0,0.9878409504890442
1830242539,17539,junrao,2024-11-06T00:26:42Z,testtrycompletereturnsfalsewhenminbytesnotsatisfiedonfirstfetch => testtrycompletewhenminbytesnotsatisfiedonfirstfetch?,0,0.9866402745246887
1830242838,17539,junrao,2024-11-06T00:27:17Z,testtrycompletereturnsfalsewhenminbytesnotsatisfiedonlatestfetch => testtrycompletewhenminbytesnotsatisfiedonsubsequentfetch ?,0,0.9871569275856018
1830269891,17539,junrao,2024-11-06T01:14:59Z,"hmm, apoorv had a good point in his comment ([a link] there seems to be a potential problem. it's possible that thread1 calls `trycomplete`, finds `completed` to be false, and is about to set `partitionsalreadyfetched`. the expiration thread then calls `forcecomplete` and sets `completed` to true and proceeds to here. now, thread1 continues and updates `partitionsalreadyfetched`. the expiration thread will pick up the wrong `partitionsalreadyfetched`.",0,0.9262264370918274
1830395752,17539,adixitconfluent,2024-11-06T05:07:55Z,"yes, i think changing the log line to below makes more sense. [code block]",0,0.9842811822891235
1830410313,17539,adixitconfluent,2024-11-06T05:31:34Z,"makes sense, i've changed the catch block to [code block]",0,0.9853860139846802
1830454251,17539,adixitconfluent,2024-11-06T06:27:58Z,"hi jun, reading online regarding the performance of linkedhashmap and hashmap - linkedhashmap offers better performance when iterating through elements since they maintain an ordered entry list, while a hashmap offers better performance when accessing large datasets. furthermore, when storing objects, linkedhashmap stores objects in key-value pairs, while hashmap stores them in hash table. the type of key used also affects performance. since now we are iterating over `sharepartitions` within the function `acquirablepartitions`, i thought it would be more efficient to use linkedhashmap over hashmap.",0,0.951804518699646
1830461947,17539,adixitconfluent,2024-11-06T06:36:58Z,"hi , i've created a ticket [a link] to track this issue and if it fine to you, i would prefer to address the issue in a future pr.",0,0.9625873565673828
1830468964,17539,adixitconfluent,2024-11-06T06:44:58Z,"similar reason as [a link], i did it for performance efficiency. we are iterating over `partitionsacquired` in `releasepartitionlocks`, hence i thought it would be more efficient to use linkedhashmap over hashmap.",0,0.9654706716537476
1831062681,17539,apoorvmittal10,2024-11-06T13:56:10Z,the reason i suggested to use linkedhashmap was to maintain the fetch order of partitions. as per kip - [a link] i will add the rotation in sharepartitionmanager to ensure the behaviour.,0,0.9877414703369141
1831731314,17539,junrao,2024-11-06T21:26:53Z,"if ordering is important, should we explicitly define it as linkedhashmap in all the places?",0,0.9860910177230835
1831742440,17539,junrao,2024-11-06T21:37:58Z,should we reset partitionsacquired and partitionsalreadyfetched?,0,0.9887537956237793
1831747806,17539,junrao,2024-11-06T21:43:40Z,let's add a comment that the minbytes estimation currently assumes the common case where all fetched data are acquirable.,0,0.9867910146713257
1831878254,17539,apoorvmittal10,2024-11-07T00:08:42Z,"yeah, good point. we should.",1,0.6952345967292786
1832911918,17539,junrao,2024-11-07T15:47:22Z,"since the ordering is important, let's use linkedhashmap.",0,0.9871940016746521
1832912856,17539,junrao,2024-11-07T15:47:55Z,"since the ordering is important, let's use linkedhashmap.",0,0.9871940016746521
1832915380,17539,junrao,2024-11-07T15:49:24Z,"since the ordering is important, let's use linkedhashmap.",0,0.9871940016746521
1832921605,17539,junrao,2024-11-07T15:52:49Z,this means `trycomplete` will never get non-empty `fetchoffsetmetadata` and its calculation of minbytes will be off. we need to think through how to address this.,0,0.9780787825584412
111506681,2849,mjsax,2017-04-13T23:26:33Z,why not using validatetransactionalid here ?,0,0.9731364250183105
111517794,2849,junrao,2017-04-14T01:40:50Z,"every time the epoch advances, it seems that we need to write the transactionalid mapping message to the transactional log and we want to write that in epoch order since the transactional log is a compacted topic.",0,0.9841443300247192
111517806,2849,junrao,2017-04-14T01:41:01Z,"in the design, the epoch will wrap around.",0,0.9848655462265015
111517818,2849,junrao,2017-04-14T01:41:12Z,could we rename the method to sth like gettransactionstate?,0,0.988319993019104
111517825,2849,junrao,2017-04-14T01:41:19Z,"hmm, we need to add the transactionalid -> pid mapping to the transactional log, right?",0,0.985609233379364
111517832,2849,junrao,2017-04-14T01:41:26Z,a few unused imports such as kafkaexception and random.,0,0.9853213429450989
111517837,2849,junrao,2017-04-14T01:41:32Z,$error => errors: $error ditto for line in 1412.,0,0.9336194396018982
111528069,2849,junrao,2017-04-14T04:32:31Z,"hmm, how is transactionmetadata.timestamp used? if it's intended to expire a transaction, should we keep the time when the first partition is added? we probably also want to rename the field to sth like txnstarttime to make it clear.",0,0.9886831641197205
111528074,2849,junrao,2017-04-14T04:32:39Z,"hmm, is it intentional to use acks =1 instead of acks=-1? if so, could we add a comment how the potential data loss is dealt with?",0,0.9601238965988159
111528088,2849,junrao,2017-04-14T04:33:00Z,"hmm, in the design doc, the key for transactional status message is the following. is the doc outdated? is it true that we are combining the transactional status message and the transactionalid mapping message into a single one? key => version type pid version => 0 (int16) type => 1 (int16) pid => int64",0,0.9855597019195557
111528094,2849,junrao,2017-04-14T04:33:07Z,"in the design doc, the value for transactional status message is the following. is the doc outdated? value => version epoch status [topic [partition]] version => 0 (int16) epoch => int16 status => byte topic => bytes partition => int32",0,0.9878271222114563
111528102,2849,junrao,2017-04-14T04:33:14Z,"the comment in line 38 doesn't include txn_timestamp_field. also, could we add a doc for each field?",0,0.989855170249939
111528120,2849,junrao,2017-04-14T04:33:41Z,"hmm, what's the default txntimeout in the producer? the server side default is 15 minutes, definitely too long for a timeout for the callback during log append.",0,0.9669384956359863
111653276,2849,junrao,2017-04-15T00:34:08Z,do we still need this object?,0,0.9865676164627075
111653293,2849,junrao,2017-04-15T00:34:35Z,"hmm, it seems that if the connection is not ready, we should just wait until it's ready or until the request timeout has been reached, instead of sending an error back immediately.",0,0.969096302986145
111653317,2849,junrao,2017-04-15T00:35:10Z,"hmm, i am wondering if checks like this are synchronized properly. for example, the following sequence seems possible. (1) handleaddpartitionstotransaction() is called and validatetransactionalid() check passes. (2) leader of the partition changes to a different broker and changes back. (3) now txnmanager.appendtransactiontolog() may succeed but transactionstatemanager may still be loading the transaction state.",0,0.9694375395774841
111653333,2849,junrao,2017-04-15T00:35:27Z,"hmm, is it possible for txnmanager.gettransaction() to return none because leader change in the transaction topic?",0,0.9871941208839417
111653336,2849,junrao,2017-04-15T00:35:33Z,"map { case (topic, partitionids) .. } ?",0,0.9861809611320496
111653338,2849,junrao,2017-04-15T00:35:37Z,"""pid mapping message"" seems no longer valid",0,0.9628124237060547
111653340,2849,junrao,2017-04-15T00:35:40Z,pidmessageformatter => transactionlogformatter ?,0,0.9877569675445557
111653344,2849,junrao,2017-04-15T00:35:45Z,key => transactionalid ?,0,0.9876684546470642
111653357,2849,junrao,2017-04-15T00:35:56Z,"currently, there are a couple of cases when the following illegalstateexception is thrown. (1) a producer times out on a commit/abort request and resends the request on a different socket channel. (2) a different producer has initialized the pid on the same transactional id. it seems that in both cases, perhaps we want to send back a retriable error (e.g., coordinatorbusy) to that the client so that it can retry until successful?",0,0.957000732421875
111653362,2849,junrao,2017-04-15T00:36:02Z,this is not the replica fetcher.,0,0.9507431983947754
111653364,2849,junrao,2017-04-15T00:36:06Z,do we need this tag since we know this thread is from this broker.,0,0.9883310198783875
111653370,2849,junrao,2017-04-15T00:36:17Z,"since both the request and the response will be small, perhaps we could just use the default receive buffer.",0,0.9876103401184082
111653378,2849,junrao,2017-04-15T00:36:30Z,"not sure if this is needed, but should we ensure that we send writetxnmarkersrequest with a lower coordinatorepoch before a higher one?",0,0.9862797260284424
111653405,2849,junrao,2017-04-15T00:36:48Z,"(1) the reason for the disconnect could be that the current leader is down and a new leader is elected. so, we should go through the path dealing with errors.not_leader_for_partition to rediscover a potential new broker to send the request to. (2) not sure if this truly needed, but do we need to ensure that the ordering of controller epoch is preserved during re-enqueue?",0,0.9792411923408508
111653412,2849,junrao,2017-04-15T00:36:58Z,"since there are different types of epochs now, could we name this coordinatorepoch to make it clear?",0,0.9874851107597351
111653448,2849,junrao,2017-04-15T00:37:22Z,partitionlock gives people the impression that this is a lock for a transaction topic partition. perhaps rename this to sth like statelock?,0,0.9855979084968567
111653453,2849,junrao,2017-04-15T00:37:30Z,there doesn't seem be a corrupted list?,0,0.9632248878479004
111653475,2849,junrao,2017-04-15T00:37:53Z,"hmm, shouldn't we load up to log end offset instead of hw? the latter can be slightly smaller than log end offset and in that case, we may miss the portion of the log between log end offset and hw.",0,0.9830101132392883
111653484,2849,junrao,2017-04-15T00:38:10Z,"hmm, ownedpartitions is updated in the scheduler, which means when this method returns, there is no guarantee that ownedpartitions has been updated. then, a client could still update the transaction log even after handletxnemigration() is called? ditto in loadtransactionsforpartition(0.",0,0.985527515411377
111653491,2849,junrao,2017-04-15T00:38:17Z,"hmm, invalid_fetch_size seems to be for fetch requests, will log append throw this?",0,0.983898937702179
111653493,2849,junrao,2017-04-15T00:38:25Z,"not clear what "" since the metadata does not match anymore"" is.",0,0.8698835372924805
111653508,2849,junrao,2017-04-15T00:38:56Z,"we synchronize on metadata in different classes like transactioncoordinator, transactionmarkerchannelmanager, transactionstatemanager and delayedtxnmarker. this makes a bit hard to reason about concurrency. would it be better to consolidate all concurrent accesses to transactionstatemanager or a new class and only do synchronization on methods inside that class?",0,0.8230206370353699
111653523,2849,junrao,2017-04-15T00:39:23Z,we need to add the acl check for each of the new request. this can be done in a separate pr if needed.,0,0.9878144264221191
111653527,2849,junrao,2017-04-15T00:39:32Z,we need to set transactionstopicreplicationfactor and transactionstopicminisr to 1 in config/server.properties so that local testing could work.,0,0.9880074262619019
111781296,2849,junrao,2017-04-17T17:40:42Z,"hmm, if polltimeout is maxlong, networkclient.poll() could be blocked for a long time waiting for the response to come back. this means if there are new requests for other brokers coming in, their processing will be delayed.",0,0.9822973012924194
111781327,2849,junrao,2017-04-17T17:40:51Z,"hmm, in general, it's useful not to reconnect on a failed connection, is setting reconnectbackoff to 0 intentional?",0,0.929036021232605
111781351,2849,junrao,2017-04-17T17:40:59Z,"should we use metadatatowrite instead of metadata? also, could we just fold maybeaddpendingrequest() into addrequesttosend()?",0,0.9892058372497559
111781396,2849,junrao,2017-04-17T17:41:13Z,perhaps it's better to make transactionmetadata.topicpartitions a private val and expose methods for manipulation so that it's easier to track when the state is changed?,0,0.9859061241149902
111829832,2849,junrao,2017-04-17T21:49:29Z,"hmm, shouldn't we be using the transaction timeout in the producer config instead of integer.max_value?",0,0.9864046573638916
111829857,2849,junrao,2017-04-17T21:49:40Z,"this may throw brokerendpointnotavailableexception and we probably need to handle this explicitly. otherwise, some request handler threads will fail unexpectedly.",0,0.9453093409538269
111829897,2849,junrao,2017-04-17T21:49:52Z,"we have to be a bit careful here. it's possible when a broker is restarted, it's ip and port have changed. so, we need to update the ip/port in brokerstatemap if needed.",0,0.9523830413818359
111830152,2849,junrao,2017-04-17T21:51:22Z,it seems that we need to call this during transactioncoordinator.handletxnemigration() as well?,0,0.9890598058700562
111830246,2849,junrao,2017-04-17T21:51:57Z,"here, we are draining the requests to every broker whether the broker channel is ready or not. it's probably better to only take requests from brokers whose connection is ready.",0,0.982025146484375
111830264,2849,junrao,2017-04-17T21:52:04Z,max.transaction.timeout.ms => transaction.max.timeout.ms,0,0.9773415923118591
111932482,2849,dguy,2017-04-18T11:43:14Z,because this case is handled differently,0,0.961781919002533
111933023,2849,dguy,2017-04-18T11:46:43Z,it will be used to expire the transactions from the `transactionmetadatacache` in `transactionmanager`. it was my understanding that the timestamp should be updated to the the current timestamp (at least is supposed to be in the endtxnrequest case),0,0.9857105612754822
111933363,2849,dguy,2017-04-18T11:48:48Z,according to point 2 [a link],0,0.9865579009056091
111933574,2849,dguy,2017-04-18T11:50:12Z,yes - this was initially missing in the `initpidrequest` i've updated it so it does add it to the log,0,0.9886931777000427
111934136,2849,dguy,2017-04-18T11:53:42Z,?,0,0.9320514798164368
111966880,2849,dguy,2017-04-18T14:23:40Z,not sure i completely agree. it says in the javadoc for `requestcompletionhandler`: [code block],0,0.973170816898346
111967313,2849,dguy,2017-04-18T14:25:15Z,"yep, i'm not sure what the thinking is/was behind that. ?",-1,0.6875368356704712
111972450,2849,dguy,2017-04-18T14:43:30Z,"so, i think you are saying we need to always call `metadatacache.getaliveendpoint(...)` even if we have a node for the given brokerid already in `brokerstatemap`?",0,0.9869806170463562
111978219,2849,dguy,2017-04-18T15:03:43Z,i am not sure it is a retriable error in this case. once the previous `endtxnrequest` has completed then a subsequent `endtxnrequest` for the same transactionalid should also fail - right?,0,0.8237454295158386
111997154,2849,dguy,2017-04-18T16:13:24Z,"hmmm. interesting! i don't think we want to clear everything, but just those transactionalids where the partition has emigrated? though, that is not immediately clear to me based on the current design. also there may well be in-flight-requests corresponding to the emigrated partitions. not sure which error response should be sent back for those.",1,0.8052840232849121
111997381,2849,dguy,2017-04-18T16:14:27Z,not sure - ?,-1,0.6347987651824951
112013590,2849,junrao,2017-04-18T17:23:17Z,"that sounds good. however, it seems that transactionmetadata needs 2 different timestamps. (1) the last timestamp when there is some activity from the pid. (2) the timestamp when the last open transaction is started. (1) will be used to expire pid and (2) will be used to abort a long transaction.",0,0.5608404278755188
112013865,2849,junrao,2017-04-18T17:24:25Z,"ok, could we add a comment. sth like ""it's possible for a complete message to be lost with acks=1 when the leader for the transaction coordinator changes. if so, we will re-add the complete message during handletxnimmigration()""",0,0.9593132138252258
112014229,2849,junrao,2017-04-18T17:25:53Z,"there are 2 cases when a channel is not ready: (1) the channel was ready and is disconnected now. (2) the channel is not ready and is being connected. in case (1), the callback will be called. in case (2), the current usage of networkclient is that the caller shouldn't send requests until the channel is ready. otherwise, we will be unnecessarily taking requests out of the queue, submitting it to networkclient and only to re-enqueue the failed requests.",0,0.7814626097679138
112014271,2849,junrao,2017-04-18T17:26:05Z,"yes, every time that we add a new request to a broker id, it's possible for the broker's ip/port to change. we need to update the cached ip/port in brokerstatemap.",0,0.9886512756347656
112014403,2849,junrao,2017-04-18T17:26:42Z,"yes, we should fail the subsequent endtxnrequest. but it seems that we want the client to backoff a bit and keep retrying until success. if we are not sending back a retriable error, the client will think the endtxnrequest actually permanently failed, which is not the case here.",0,0.9546309113502502
112014452,2849,junrao,2017-04-18T17:26:54Z,"yes, only clearing transactionalids where the partition has emigrated. for in-flight-requests, we probably want to return a nottransactioncoordinator error.",0,0.9843496680259705
112138268,2849,dguy,2017-04-19T08:04:51Z,not sure - ?,-1,0.6347987651824951
112138822,2849,dguy,2017-04-19T08:08:13Z,"so, i think in the second case we probably want to check if the broker is ready before it gets to this point. as we've already drained the queue and will need to re-enqueue?",0,0.9831461310386658
112142569,2849,ijuma,2017-04-19T08:27:58Z,"as long as the `networkclient` is instantiated with an appropriate request timeout, this code is fine. the actual timeout here will be `the minimum of timeout, request timeout and metadata timeout` (as specified in the docs for`networkclient.poll`)",0,0.9769881963729858
112143022,2849,ijuma,2017-04-19T08:30:17Z,"unless we want a timeout that's lower than `requesttimeout`, of course.",0,0.9841896891593933
112282085,2849,apurvam,2017-04-19T18:38:13Z,we synced up on this with jun offline. the doc is outdated. we havea ticket here to track updates we need to make to the doc: [a link],0,0.9431647062301636
112286609,2849,apurvam,2017-04-19T18:57:54Z,"i think would have the most context on that, but i don't think we should not set it to 0. this is the connection to the leaders to write the abort marker. if the connection is disconnected, there is little reason to try to establish it again. i think the default of 50ms is reasonable here.",0,0.9734641313552856
112286690,2849,apurvam,2017-04-19T18:58:18Z,that makes sense to me.,0,0.9582882523536682
112286926,2849,apurvam,2017-04-19T18:59:24Z,"the comment is out of date. the original version of the patch had a notion of 'corrupted partitions', but the definition what is corrupted was not clear and we dropped the notion altogether.",0,0.8941490650177002
112287416,2849,apurvam,2017-04-19T19:01:30Z,the default on the producer as of now is 60 seconds. i think perhaps 120seconds on the broker is reasonable?,0,0.9840657114982605
112300739,2849,apurvam,2017-04-19T20:05:37Z,the config is being added as part of my patch. shall we introduce an overload of `initpidrequest.builder` which just takes a `transactionalid` and assigns some default timeout? my patch will use the two parameter builder and pass in the timeout from the producer config.,0,0.988534152507782
112302162,2849,apurvam,2017-04-19T20:12:25Z,"we can avoid this by using the `networkclientutils.awaitready` method, as used in [a link] that will ensure that the destination node is ready before sending the initial request. so you could peek into the queue to get the destination, ensure that it is ready, and if so, send the request. however, if it is not ready after a particular time, you will have to rediscover the correct node to send the request to (presumably because the old broker is down and the leader has moved).",0,0.986822247505188
112306365,2849,apurvam,2017-04-19T20:31:43Z,"yes, we have to do this across the board. i filed a jira so that we can make the change in one pr so that it is easier to make sure we are consistent. [a link]",0,0.9756714105606079
112311456,2849,junrao,2017-04-19T20:55:25Z,"the broker has a request timeout, but it's probably better for the client could pass along the timeout in the rpc request?",0,0.9878582954406738
112311549,2849,junrao,2017-04-19T20:55:48Z,"ideally, we only want to take requests off a queue when the channel to the corresponding broker is ready. however, if one broker's connection is not ready, we don't want to delay the sending of requests for other brokers. one way to achieve this is to have a separate queue per broker.",0,0.9777830243110657
112311627,2849,junrao,2017-04-19T20:56:05Z,"hmm, waiting for a 30 secs request timeout is still too long if there is another request in the queue ready to be processed.",0,0.9509155750274658
112317720,2849,apurvam,2017-04-19T21:25:58Z,"jun raises a good point. right we should have two timestamps in the messages we write to the transaction log. one is the `entrytimestamp` which is the current time and which is used to expire the transactionalid. the other is the `transactionstarttime` which is the timestamp of the first `addpartitionstotransaction` request for a transaction. this is used to expire transactions on the broker. as it stands, we have only the `entrytimestamp` and so a transaction could be open for ever if it gets updates very slowly. this would hold up the progress of the lso on all the partitions involved in the transaction, which is not a desirable outcome. would you be able to add the new timestamp and add a note to update doc on this ticket? [a link]",1,0.8615902662277222
112415717,2849,dguy,2017-04-20T10:05:21Z,seems to make sense to me. any reasoning behind this?,0,0.9331009984016418
112417500,2849,dguy,2017-04-20T10:14:35Z,"it seems so. it is handled like this in `groupmetadatamanager#preparestoregroup`, too",0,0.9696952700614929
112419986,2849,dguy,2017-04-20T10:28:20Z,"there already is an overload, but it also sets the timeout to `integer.max_value`",0,0.9877310395240784
112426248,2849,dguy,2017-04-20T11:05:31Z,"actually, i think this should be `producerepoch`? afaik `coordinatorepoch` is `partition.getleaderepoch`",0,0.9869045615196228
112462355,2849,dguy,2017-04-20T14:08:30Z,i'm not sure.,-1,0.7445111274719238
112472596,2849,dguy,2017-04-20T14:47:19Z,"we achieve that now as we just don't bother sending the request if the broker isn't ready. it gets re-enqueued, but it might need to be as the broker may now be down. i guess i'm missing something here, but i don't really see what.",0,0.7373992800712585
112494867,2849,junrao,2017-04-20T16:09:46Z,"hmm, i don't see invalid_fetch_size or invalidfetchsizeexception being generated in the code base. if we don't want to clean this up in this patch, could we at least file a followup jira to track this?",0,0.9855930209159851
112498072,2849,junrao,2017-04-20T16:23:54Z,"my point is on efficiency. if a channel is not ready to begin with, keep re-enqueuing the same request again and again just adds overhead. so, it's better to wait until a channel is ready and then start processing the requests intended on that channel. on the other hand, if a channel is ready, we send a request to that channel and the channel is disconnected before the response is received, we need to re-enqueue the requests for reprocessing. but that's done in the callback in the clientrequest already.",0,0.9414295554161072
112554067,2849,apurvam,2017-04-20T20:33:47Z,"the transaction timeout is passed in in the initpidrequest. it will apply to all transactions in that session. on the producer, the default for this timeout is 60s.",0,0.9882212281227112
112562609,2849,apurvam,2017-04-20T21:14:42Z,"so the transaction coordinator is colocated with the leader the topics in the transaction log which it owns. when we do a `txnmanager.appendtransactiontolog` and the coordinator has moved, the leader for the topic should also have moved. in that case, we will get a `not_leader_for_partition` error, and send back a `not_coordinator` error code, in which case the client will send another `findcoordinator` request.",0,0.9882638454437256
112572188,2849,apurvam,2017-04-20T22:13:35Z,"i agree with that this is inefficient. the producer model where we have a background sender thread and one queue per broker is more efficient, since it avoids busy waiting. however, we agreed that we can make this improvement in the future, after the initial integration is done. i filed this ticket to keep track of the work item: [a link]",0,0.9386729001998901
112572768,2849,apurvam,2017-04-20T22:17:41Z,"followed up with offline. the main case to guard against is when the partition moves to another broker, and then moves back between the call to `validatetransactionalid` an `txnmanager.appendtransactiontolog`. in this case, when the call back for `appendtransaction` executes, the coordinator may still be loading the cache, and it is unclear what we should do . we agreed that the best thing probably is that when a partitino emigrates, we should track down in flight operations (and requests sitting in the purgratory), and error them out with a `not_coordinator` code. is it feasible to do the latter in a simple fashion?",0,0.973228394985199
112622713,2849,dguy,2017-04-21T07:09:13Z,"ok, so that is what we are already using.",0,0.9855424165725708
112623812,2849,dguy,2017-04-21T07:17:40Z,"yes it would be inefficient in the case that there is only a single broker or all brokers are not ready. in other cases it will not necessarily be so inefficient as the request will be re-enqued, but not immediately retried. other requests, to potentially, other brokers will be tried etc, before the requests for the not ready broker is retried. anyway, that said, having a queue per broker is better.",0,0.9686510562896729
112623904,2849,dguy,2017-04-21T07:18:24Z,so should we just default this to something much lower? what would be a reasonable timeout?,0,0.9398249983787537
112651788,2849,dguy,2017-04-21T09:44:05Z,thanks. yeah i should be able to do that,1,0.8739866018295288
112805167,2849,dguy,2017-04-22T08:05:58Z,", correct it doesn't look it is generated anywhere. i'll remove it from here and i've filed: [a link]",0,0.9831715226173401
112806295,2849,dguy,2017-04-22T09:31:16Z,"i already changed `handletxnemigration` to remove the inflight operations that we know about, i.e., the ones in purgatory. once they complete they will error with `not_coordinator`. however this is only useful for the case where we writing the txn markers. for the other cases, if the coordinator is still loading the cache and the `transactionalid` is not yet cached we will respond with `not_coordinator`. however, if the cache is is loading it may have an old record for the `transactionalid`. should we do a check in the callback, i.e., [code block]`",0,0.984714925289154
113041521,2849,junrao,2017-04-24T19:59:12Z,be consistent on whether to use () when calling clientid() ?,0,0.987765908241272
113042021,2849,junrao,2017-04-24T20:01:29Z,this still needs to be addressed. the loading in groupcoordinator has the same issue.,0,0.9816192388534546
113083208,2849,junrao,2017-04-25T00:00:43Z,"i am a bit worried about all those independent checks on transactional state w/o any coordinator level locking. for example, in theory, a coordinator emigration and immigration could have happened after the check in line 104. then, the appendmetadatatolog()/initpidwithexistingmetadata() call could mess up some state. i was thinking that another way of doing this is to maintain a read/write lock for the coordinator partition. immigration/emigration will hold the write lock while setting the state. other calls like initpid will hold the read lock, do the proper coordinator state check, initiate the process like appending to the log and then release the read lock (we already have such a partition level lock in partition, not sure if it's easily reusable). this will potentially give us better protection and make things easier to reason about.",-1,0.969761848449707
113083220,2849,junrao,2017-04-25T00:00:50Z,"hmm, appendmetadatatolog() is not doing exactly the same as if the metadata has existed. it seems that we will be missing all those checks on metadata state in initpidwithexistingmetadata()?",0,0.8928734064102173
113083240,2849,junrao,2017-04-25T00:01:00Z,should we just do the eq check on reference instead?,0,0.9837669134140015
113083247,2849,junrao,2017-04-25T00:01:04Z,"i assume that entrytimestamp is used for expiring a transactional id if there is no activity. if so, this needs to be updated on any activity related to a transactional id such as addpartitions, abort/commit and initpid. also, could we rename this to sth like lastaccesstimestamp? it would also be useful to document the usage of the two timestamps in transactionmetadata.",0,0.988874077796936
113083250,2849,junrao,2017-04-25T00:01:05Z,"hmm, transactionstarttime needs to be set when we add the first partition to the transaction.",0,0.9847956895828247
113083255,2849,junrao,2017-04-25T00:01:08Z,"hmm, in this case, the coordinator is not really in a loading state. it seems that we need a new error like concurrent_transactions?",0,0.9673689007759094
113083261,2849,junrao,2017-04-25T00:01:11Z,"this can be tricky to handle completely. (1) should we also cancel any ongoing loading due to the previous immigration? (2) there could be outstanding transactional requests (e.g., initpid) waiting in producer purgatory after the log append call. ideally, we should mark the coordinator as not available, trigger a check on requests associated with the coordinator's partition in the purgatory so that they can responds with a coodinator_not_available error.",0,0.7025007605552673
113083269,2849,junrao,2017-04-25T00:01:17Z,"if we are doing this optimization, we need to make sure that the handleaddpartitionstotransaction() call first completes any pending transaction, i.e, the markers from a previous transaction must have been sent successfully and the complete transaction entry has been added to the transaction log. otherwise, the producer may start publishing the data for the next transaction before the transaction marker has been added for the previous transaction.",0,0.9861499667167664
113083272,2849,junrao,2017-04-25T00:01:18Z,it seems that we should just keep retrying until successful or the broker is no longer the transaction coordinator.,0,0.9818503260612488
113083277,2849,junrao,2017-04-25T00:01:22Z,good question. we could either keep retrying or mark the coordinator in a bad state.,1,0.8492957353591919
113083280,2849,junrao,2017-04-25T00:01:26Z,the only place that brokerstatemap is needed outside of this class is in transactionmarkerchannelmanager for draining events. perhaps we can make brokerstatemap private and expose a method like drainqueuedtxnmarkers() instead? this makes it a bit easier to track the accesses to the map.,0,0.9864805340766907
113083290,2849,junrao,2017-04-25T00:01:30Z,"hmm, what about those pending requests already in the selector()? ideally we need to drain them too. not sure what's the best way to do that.",0,0.6873533725738525
113083300,2849,junrao,2017-04-25T00:01:33Z,"hmm, not sure why we need to do flatmap instead of just map.",0,0.8423081040382385
113083312,2849,junrao,2017-04-25T00:01:36Z,metadatapartition can be a bit confusing. how about coordinatorpartition?,-1,0.7662534117698669
113083333,2849,junrao,2017-04-25T00:01:53Z,this can be in a future patch. it would be useful to record this in some metric so that we know the state of transaction coordinator.,0,0.9860466122627258
113083342,2849,junrao,2017-04-25T00:01:55Z,should we do the eq test to only test for reference equal?,0,0.981833279132843
113083350,2849,junrao,2017-04-25T00:02:00Z,"is that enough? for transactions in the prepare state, shouldn't we try to write the txn markers to added partitions and bring those transactions to the complete state too?",0,0.9895827770233154
113083356,2849,junrao,2017-04-25T00:02:03Z,should we clear out loadingpartitions and stop any ongoing loading on that partition?,0,0.985110878944397
113083359,2849,junrao,2017-04-25T00:02:05Z,this method seems cheap. is there a reason for running this in the scheduler?,0,0.8760805726051331
113083367,2849,junrao,2017-04-25T00:02:09Z,the above issue is still not resolved.,0,0.9159812927246094
113083375,2849,junrao,2017-04-25T00:02:11Z,"hmm, do we need this check if we make sure all outstanding transactions are aborted on emigration and new transactions can only be started after the coordinator loading completes?",0,0.9864227175712585
113083384,2849,junrao,2017-04-25T00:02:16Z,inaccurate comment. internal topics are not just offset topic now.,-1,0.8448477387428284
113088713,2849,junrao,2017-04-25T01:01:00Z,"if the thread is blocked in networkclient.poll and some new requests are added to the queue, it seems that we need to wake up networkclient so that new requests can be processed immediately.",0,0.9824085831642151
113088732,2849,junrao,2017-04-25T01:01:10Z,we should just wait until the target broker is available.,0,0.9805423021316528
113088785,2849,junrao,2017-04-25T01:01:42Z,"hmm, instead of throwing illegalstateexception, it seems that we should just keep retrying until successful?",0,0.9519606828689575
113089004,2849,junrao,2017-04-25T01:04:11Z,"since the timeout in delayedtxnmarker is infinite. i am wondering if we really need a txnmarkerpurgatory. in transactionmarkerrequestcompletionhandler, we are already updating the pending partitions as the client response comes back. the response that removes the last pending partition can just trigger the calling of completioncallback.",0,0.9798914790153503
113090851,2849,junrao,2017-04-25T01:26:07Z,"if the broker's message format is < v2, currently, when appending to the log, we simply convert it to an old format. in this case, we want to error out and respond to the client with a transactionnotsupported error.",0,0.9833986759185791
113091081,2849,junrao,2017-04-25T01:28:07Z,"since we are sending new type of requests across the brokers, we need to check inter broker protocol and error out if the new request is not supported.",0,0.9811128377914429
113123510,2849,dguy,2017-04-25T07:28:27Z,yep any reason why we are using hw?,0,0.9810689091682434
113124537,2849,dguy,2017-04-25T07:34:51Z,it isn't clear to me what this is supposed to be saying either. ?,0,0.5257081389427185
113125360,2849,dguy,2017-04-25T07:40:11Z,yes. we need to do that. discussed this with offline yesterday and we thought it might be better to do in a follow up patch as this patch is already quite large. thoughts?,0,0.9397062063217163
113125813,2849,dguy,2017-04-25T07:43:13Z,i guess it is because `loadtransactions` is run in the scheduler. so they won't interleave. ?,0,0.9855685830116272
113127361,2849,dguy,2017-04-25T07:52:28Z,"ok. i can do that by adding a check in the while loop in `loadtransactionmetadata`, i.e, `while(curroffset < highwatermark && loadingpartitions.contains(partitionid) && ...)` will that be ok?",0,0.9855049252510071
113127705,2849,dguy,2017-04-25T07:54:19Z,i'm not really sure what i'm supposed to be checking here?,-1,0.8460112810134888
113128786,2849,dguy,2017-04-25T08:00:21Z,i'm not sure how i can cancel all inflight requests. say for instance `transactionstatemanager.appendtransactiontolog(..)` is called and then on another thread `handletxnemigration` is called and removes the partition. how do i abort the inflight `transactionstatemanager.appendtransactiontolog(..)` call.,0,0.733853280544281
113129466,2849,dguy,2017-04-25T08:04:29Z,"thanks - yeah that makes sense. i was thinking about locking, too, but wasn't sure of the correct level to do it at, but the partition level seems ok. will look into it. thanks for the suggestion",1,0.9694007039070129
113130366,2849,dguy,2017-04-25T08:09:55Z,"i'm not sure what was meant by the comment, but i think you are correct in that we should do `initpidwithexistingmetadata()` in the case that they aren't the same. any thoughts?",0,0.9240559935569763
113165211,2849,dguy,2017-04-25T11:03:40Z,in which case should i default it something like -1 here?,0,0.9848131537437439
113165318,2849,dguy,2017-04-25T11:04:22Z,true. any thoughts on this?,0,0.9735760688781738
113165961,2849,dguy,2017-04-25T11:08:10Z,i think we can handle (1) by: 1. in `removetransactionsforpartition` we remove the partition from `loadingpartitions` 2. in `loadtransactionmetatdata` we only perform the loop when `loadingpartitions.contains(partition) i have to think a bit more about 2,0,0.9798530340194702
113166353,2849,dguy,2017-04-25T11:10:21Z,i think this case is already handled by `handleinitpid()`,0,0.9883264899253845
113167929,2849,dguy,2017-04-25T11:19:30Z,they will error out with `not_coordinator` on completion. will that suffice? i'm not sure how we can cancel inflight requests in the `networkclient`,0,0.9239882826805115
113168889,2849,dguy,2017-04-25T11:25:14Z,i probably should just use flatten. my scala knowledge is not the best,-1,0.6749038696289062
113169486,2849,dguy,2017-04-25T11:28:53Z,in `initpidwithexistingmetadata` we also need to wait on the transaction to complete if there is an inflight transaction in the `prepareabort` or `preparecommit` phase.,0,0.9877734780311584
113172390,2849,dguy,2017-04-25T11:45:47Z,how would i do that?,0,0.9360095858573914
113173083,2849,dguy,2017-04-25T11:49:47Z,ok i guess i'll need todo that in `transactionmarkerchannel#addrequesttosend`,0,0.9858988523483276
113178448,2849,ijuma,2017-04-25T12:15:40Z,"`flatmap` is preferable to `map` and then `flatten`. i am guessing jun's question is because `txnmarkerentry` sounds like an element, but it's actually a `list`. maybe it should be renamed?",0,0.9846138954162598
113178626,2849,ijuma,2017-04-25T12:16:27Z,"also, you can write it a bit more concisely by doing `buffer.flatmap(_.txnmakerentry).asjava` (x doesn't add anything over the underscore).",0,0.9883973002433777
113195654,2849,dguy,2017-04-25T13:34:40Z,"the tc maintains multiple partitions, so we'd need to have a lock per partition. you mentioned that there is a read/write lock on partition - i believe you are referring to `leaderisrupdatelock`... i can't see any other locks in `partition`. anyway, do we want to expose this for other classes to use? i'd probably think not. if we maintain a lock per partition then perhaps it should be done by the `transactionstatemanager` and then we'd need to add/remove locks in the immigration/emigration. i think we'd also need to add another method on `transactionstatemanager`, say `partitionlock(partitionid)` that returns an `option[reentrantreadwritelock]`. the calls in `transactioncoordinator` to `iscoordinatorfor` could then be replaced with calls to `partitionlock(partitionid)` - if the lock exists they take a read lock. if it doesn't exist then respond with `errors.not_coordinator` does this seem sensible?",0,0.9680275321006775
113330271,2849,guozhangwang,2017-04-25T22:48:31Z,in that case do we really need this change in this pr? maybe we can just remove this change as it is actually doing the same still.,0,0.9826627969741821
113330372,2849,guozhangwang,2017-04-25T22:49:15Z,are these changes intentional? the original ordering seems ok to me.,0,0.9827074408531189
113331290,2849,guozhangwang,2017-04-25T22:55:50Z,"thinking about this a bit more, i wonder if the `coordinatorepoch` should also be in the internal entry as well, since different txn log partition leader's epoch hence the coordinator epoch would be different?",0,0.969115674495697
113331531,2849,guozhangwang,2017-04-25T22:57:33Z,"edit: in the existing branch i have already made those changes a while back: [a link] the design doc however is not updated. i saw you did a groupby on the `coordinatorepoch` instead, so that each write marker request will only contain one `coordinatorepoch`, but since on the broker side, this coordinator epoch is checked inside the `log` layer anyways i felt it is better to change this field as a per-marker-entry field in the protocol.",0,0.9835740327835083
113332359,2849,guozhangwang,2017-04-25T23:03:23Z,"i did this in the original commit but: since this thread is owned by the broker only, we do not need this tag. instead we can just pass an empty tag map.",0,0.9865386486053467
113347218,2849,guozhangwang,2017-04-26T01:15:54Z,nice catch. currently we do not have a broker-side `reconnect.backoff` config yet so different modules just hand-code different values. but moving forward i felt we may want to introduce a new config for inter-broker reconnect backoff.,1,0.9659132361412048
113348424,2849,guozhangwang,2017-04-26T01:29:27Z,nit: indentation on the comment line 69.,0,0.9879059791564941
113348812,2849,guozhangwang,2017-04-26T01:33:43Z,sounds good to me.,1,0.9596179723739624
113351582,2849,guozhangwang,2017-04-26T02:00:13Z,nit: new line after condition,0,0.9866553544998169
113352248,2849,guozhangwang,2017-04-26T02:07:55Z,"yeah i was ""piggy-backing"" on this error code since this is the only retriable error code that the client recognizes in my incomplete patch. and i do agree that we should introduce another retriable error code here.",0,0.9320225119590759
113352808,2849,guozhangwang,2017-04-26T02:14:28Z,"since we return immediately after the `preparexx` marker is written. in both `initpid` and `addpartition` request handling the metadata state could be in `preparexx` or `ongoing`, so we need to handle them in both these two places, better in a consistent way. in the design doc we said the request will be held on the broker side indefinitely until the current transaction is rolled-forward or rolled back complete. we did this in `initpid`, but here we are directly returning a non-retriable error code. i was planning to do these handling on both places in a separate pr but since is already adding the logic for `initpid` now maybe we can discuss about that now: after thinking about it a bit more i felt maybe its better to return a retriable exception either immediately (with the new error code we need anyways for the above case) or after some timeout (with the `timeout` error code) on both places, and let the client to back-off and retry. doing this we can avoid ever increasing the in-memory structures like like the per-broker queues and the purgatory. thoughts?",0,0.9714787006378174
113353056,2849,guozhangwang,2017-04-26T02:17:12Z,"i'm wondering if we should bound the size of this blocking queue or it will cause tc-broker oom when some of the txn involved partition leaders are temporarily / permanently available. my feeling is that we do not and here is my reasoning (cc ): 1. we have two in-memory structures whose size is unbounded, this blocking queue and the txn purgatory. 2. when there are some partitions unavailable, hence the current preparexx transaction cannot be completed, they will take one slot on each of the above structures; 3. then when new request is coming from the same pid, either `initpid` or `addpartitions`, they will not proceed. hence the above structures will have at most one parked item for each producer. see my other comment about handling the `initpid` and `addpartitions` request while the previous txn has not completed.",0,0.8244680762290955
113353166,2849,guozhangwang,2017-04-26T02:18:28Z,"as long as we clear the txn purgatory, even if there are inflight request during the time. when they come back as responses, either succeeded or failed, since the corresponding delayed operation has already gone its callback will effectively be reduced to a no-op. so i think that is fine.",0,0.973747968673706
113353266,2849,guozhangwang,2017-04-26T02:19:50Z,chatted with offline. i did this mainly to just mimic group coordinator's loading behavior. but after discussing with him i think it is safer to read up to leo (we probably need to do the same for gc as well),0,0.9062783718109131
113353374,2849,guozhangwang,2017-04-26T02:21:23Z,yup. let's do that in follow-up prs.,0,0.755288302898407
113353582,2849,guozhangwang,2017-04-26T02:23:52Z,"the log entry was wrong, maybe just ""since the the appended log did not successfully replicate to all replicas"". does that sound better?",0,0.8992088437080383
113353750,2849,guozhangwang,2017-04-26T02:26:03Z,"since we now have one queue per broker, and 1) we drain all the elements in the queue whenever trying to send; 2) we wake up the client whenever we are adding new elements to the queue; i think it is not as critical to set lower values?",0,0.9790392518043518
113353816,2849,guozhangwang,2017-04-26T02:26:52Z,"agree, maybe we can have a read-write lock on the txn metadata cache and only release the read lock after the txn log has been appended locall?",0,0.9868043661117554
113354061,2849,guozhangwang,2017-04-26T02:29:31Z,i think 's comment is that we did some checking on the txn metadata's state in `initpidwithexistingmetadata` whereas we did not do such checking before calling `appendmetadatatolog`. have explained to him that it is because at line 129 we are assured that the metadata is just newly created and hence it's always `ongoing`. maybe the comment itself has been outdated after the addition of the `initpidwithexistingmetadata` logic.,0,0.9801667332649231
113354470,2849,guozhangwang,2017-04-26T02:33:57Z,"what's the motivation of trying to drain all the queued elements? since the max inflight request is only 1 in the network client, even if we construct multiple requests for a certain destination only the first request will succeed in sending right? in that case could just do the 1) peek-first 2) if-ready-send-and-pop pattern?",0,0.9758283495903015
113379063,2849,dguy,2017-04-26T07:07:11Z,we don't have one queue per broker yet. that was going to be in a follow up pr,0,0.9679020047187805
113379863,2849,dguy,2017-04-26T07:12:57Z,"actually, i don't think we need this debug message as the error cases are all logged previously. i'll just remove it.",0,0.9835188388824463
113386204,2849,dguy,2017-04-26T07:51:34Z,per partition? or a global lock?,0,0.9880155920982361
113388847,2849,dguy,2017-04-26T08:05:39Z,will the kip need to be updated with the new error?,0,0.9662917852401733
113392736,2849,dguy,2017-04-26T08:26:59Z,"so this should change back to what you previously had? we originally had your code, but during the merge with other changes it was probably removed. that is why i did the groupby on `coordinatorepoch`.",0,0.9881539940834045
113395115,2849,dguy,2017-04-26T08:40:00Z,"question more for my own understanding than anything else: if `initpid` is holding on to the request on the broker until the transaction is completed, then i think `addpartitions` should never be called when the transactionid is in a `preparexx` state. is that correct?",0,0.9646106362342834
113395718,2849,dguy,2017-04-26T08:43:18Z,this is largely a refactoring of your code from here: [a link] :-p,1,0.9158855676651001
113454320,2849,dguy,2017-04-26T13:43:12Z,"on second thoughts, i'll add a single read/write lock in the coordinator as it is much simpler than having to maintain multiple. if that is not ok, we can revisit.",0,0.9849039316177368
113457671,2849,dguy,2017-04-26T13:55:37Z,i'm not sure i understand (2). when you refer to there being outstanding requests in the producer purgatory is that w.r.t `replicamanager.appendrecords(...)`?,0,0.8108559250831604
113499063,2849,apurvam,2017-04-26T16:22:42Z,we should probably have one or more jira's to track these.,0,0.9803904294967651
113501224,2849,guozhangwang,2017-04-26T16:32:02Z,"this is about the inter-broker protocol version. details are here: [a link] maybe just leave a todo marker and i can address it in a follow-up pr, so we would not drag too long for this one?",0,0.9857839941978455
113501426,2849,guozhangwang,2017-04-26T16:32:56Z,responded in another comment. let's do this incrementally in another pr and just leave a todo in this pr. otherwise we would be looking at a 10k diff,0,0.9792487621307373
113506336,2849,dguy,2017-04-26T16:53:53Z,ok i've filed: [a link],0,0.9830417633056641
113506744,2849,dguy,2017-04-26T16:55:31Z,i've filed [a link],0,0.9844158291816711
113510250,2849,junrao,2017-04-26T17:10:10Z,"yes, we can probably also just check if the partition is still in ownedpartitions.",0,0.9888076186180115
113511035,2849,junrao,2017-04-26T17:13:41Z,"if you set the coordinator state first and trigger a check in the purgatory, the checking of the iscomplete() logic should realize that the coordinator is no longer valid and error out.",0,0.9618682861328125
113512025,2849,junrao,2017-04-26T17:18:18Z,"most operations just need to hold a read lock. only emigration/immigration need to hold a write lock. so, perhaps having a single lock per broker is also fine as long as we don't hold the lock for too long (i.e., we should mostly be just setting critical states while holding the lock. any expensive stuff should be done outside the lock).",0,0.9720256924629211
113512989,2849,junrao,2017-04-26T17:22:29Z,"we can set it to -1, but it may not matter. transactionstarttime is only useful when aborting a transaction that's started. if the transaction is in empty state, transactionstarttime is probably not going to be used. it's more important to set transactionstarttime on adding the first partition.",0,0.9849137663841248
113513257,2849,junrao,2017-04-26T17:23:39Z,"yes, we can remember this and update the kip with all the changes in a batch.",0,0.9886576533317566
113513973,2849,junrao,2017-04-26T17:26:53Z,"yes, i was referring to delayed events in the producer purgatory after the replicamanager.appendrecords(...) call. we can trigger a check of those delayed events and let them error out (since the check will find out that the broker is no longer the coordinator).",0,0.9787203073501587
113515117,2849,junrao,2017-04-26T17:31:52Z,"hmm, is it? handleinitpid() seems to just call appendmetadatatolog(). there is no guarantee that abort/commit marker from the previous transaction has been sent by the inter broker thread.",0,0.9873682856559753
113515688,2849,junrao,2017-04-26T17:34:14Z,"well, if the response fails because of disconnection, we shouldn't keep retrying right?",0,0.9649153351783752
113517731,2849,dguy,2017-04-26T17:42:47Z,in `handleinitpid` if metadata exists it calls `initpidwithexistingmetadata` that waits for the previous transaction to complete,0,0.9888191819190979
113537029,2849,dguy,2017-04-26T19:05:32Z,is calling `delayedproducepurgatory.checkandcomplete(topicpartitionoperationkey)` the correct thing to do in this case?,0,0.9868742823600769
113538220,2849,dguy,2017-04-26T19:11:47Z,"yep, it does get set when the first partition is added.",0,0.9871511459350586
113550754,2849,guozhangwang,2017-04-26T20:12:19Z,"`initpid` is only called only for the lifetime of a producer, when the producer client completed the current txn and is about to start the next one, it will not call `initpid` but just `addpartitions` as the first request. only when producer client fails-over the new instance (i.e. in its next life) will send an `initpid` again.",0,0.9884097576141357
113594739,2849,apurvam,2017-04-27T00:45:09Z,"the code as it is seems correct to me. if you get `addpartitions`, you should be in an ongoing state. i also think the `empty` state is invalid in this case.",0,0.9830996990203857
113594825,2849,apurvam,2017-04-27T00:45:54Z,"or is `empty` just signally `no_ongoing_transaction`? if so, it is a valid state.",0,0.9867069125175476
113595652,2849,apurvam,2017-04-27T00:54:41Z,"i guess you mean [code block] (note the absence of the negation in my if). i think this is reasonable. more generally, if we don't find the transaction metadata in the `appendtotransactionlog` callback, or if the coordinatorepoch is different from what we expect, we should just return not_coordinator. the client will retry and eventually succeed.",0,0.985236644744873
113595956,2849,apurvam,2017-04-27T00:57:49Z,"also, cc ..",0,0.9847666025161743
113596678,2849,apurvam,2017-04-27T01:06:30Z,"i guess current point was that a valid state here could also be `prepare`, if the previous transaction is still completing, in which case we should return `concurrent_transactions`, and have the client retry with backoff.",0,0.988916277885437
113634970,2849,dguy,2017-04-27T07:54:21Z,"- cool makes sense now. so i guess we should do the same thing in `initpid` and `addpartitions`, i.e., respond with `concurrent_transaction` or block until the previous transaction has completed",1,0.9868608117103577
113831631,2849,guozhangwang,2017-04-28T00:32:12Z,this is already addressed.,0,0.9862598776817322
114487301,2964,ijuma,2017-05-03T07:46:13Z,there's no need to have the `errors` type parameter here. that check always succeeds.,0,0.9830615520477295
114488311,2964,ijuma,2017-05-03T07:53:55Z,this can be written more clearly as: [code block],0,0.9864118099212646
114488522,2964,ijuma,2017-05-03T07:55:26Z,"hmm, as discussed previously, it's preferable to use a case class instead of many unnamed parameters.",0,0.9825458526611328
114505601,2964,dguy,2017-05-03T09:40:51Z,"do we need to update these tuples to be `(error, null, null)`? i.e., we are expecting a triple as the result",0,0.9849503040313721
114507297,2964,dguy,2017-05-03T09:50:44Z,looks like this is not used anymore?,0,0.928246259689331
114509240,2964,dguy,2017-05-03T10:02:25Z,why do we need to do this?,0,0.882576584815979
114510129,2964,dguy,2017-05-03T10:07:39Z,should we not just retry in this case? we've already written `preparexx` to the log and i thought we need to complete the transaction? how will the transaction be completed?,0,0.9853075742721558
114510837,2964,dguy,2017-05-03T10:09:49Z,the comment is incorrect. i don't think we are returning anything to the client. if the transaction has been emmigrated than it the commit should be completed by the new partition leader,0,0.9488341808319092
114511374,2964,dguy,2017-05-03T10:12:53Z,"i think we also need a check `case errors.not_coordinator` in which case we should just log an move on. also, in this case i think we need to retry?",0,0.9862723350524902
114512933,2964,dguy,2017-05-03T10:22:15Z,how are we cleaning up cases like this where it has failed? what are the implications for consumers etc?,0,0.8478965163230896
114513958,2964,dguy,2017-05-03T10:28:55Z,why do we need to update the `txnstarttimestamp` here and in the `completecommit` case?,0,0.9848217368125916
114514040,2964,dguy,2017-05-03T10:29:26Z,could this be `case prepareabort | preparecommit` ? i think they are identical,0,0.9864689111709595
114514118,2964,dguy,2017-05-03T10:30:00Z,`case completeabort | complete commit` ? i think they are identical,0,0.9833909273147583
114515680,2964,dguy,2017-05-03T10:41:41Z,"we have the situation here that when this method returns nothing has actually happened yet, i.e., the removal is done on a different thread. so what happens if we get a request at the same time for another transactionalid that is in the same partition? are we just relying/hoping it will eventually fail?",0,0.9551337957382202
114515990,2964,dguy,2017-05-03T10:44:02Z,is this an exceptional condition? could we just log it and move on?,0,0.9636222124099731
114516182,2964,dguy,2017-05-03T10:45:16Z,should we change this to have `coordinatorepochandtxnmetadata` as a param rather than the 2 separate params?,0,0.9874747395515442
114675298,2964,guozhangwang,2017-05-03T23:20:50Z,ack,0,0.9720376133918762
114675858,2964,guozhangwang,2017-05-03T23:24:58Z,"edit: the reason i made it as unnamed parameters is that the `sendtxnmarkers` function is not long used as a parameter but also directly called elsewhere. and it has been reduced from 8 params to 4, so i feel this is better cost-effective?",0,0.9795331358909607
114677405,2964,guozhangwang,2017-05-03T23:37:23Z,"ack. this needs to be tweaked a bit since the inner map is a `pool`, let me know if you like the new pattern or not.",0,0.9477014541625977
114677702,2964,guozhangwang,2017-05-03T23:40:09Z,ack.,0,0.7720441818237305
114677859,2964,guozhangwang,2017-05-03T23:41:42Z,ack,0,0.9720376133918762
114677949,2964,guozhangwang,2017-05-03T23:42:25Z,this is needed as `groupby` to generate the grouped map keyed by the node object.,0,0.9888098835945129
114678445,2964,guozhangwang,2017-05-03T23:46:55Z,"from `appendtransactiontolog` the only error codes we would pass in the callback are: [code block] and anything falling into `other` should be considered fatal as they should not happen (if they happen that should be a bug), and `unknown` comes from `message_too_large` or `record_list_too_large` which are also doomed as fatal.",0,0.9550825953483582
114678501,2964,guozhangwang,2017-05-03T23:47:30Z,ack. updating the comment.,0,0.9711183905601501
114678943,2964,guozhangwang,2017-05-03T23:51:37Z,"from `delayedtxnmarker` when we call `completioncallback` we will only return `none` and hence any other error codes would not be expected and considered as fatal right? note that the write-marker-response could contain error codes like `unknown_topic_or_partition`, but this is handled in the `transactionmarkerrequestcompletionhandler`, in which case we will retry.",0,0.9886731505393982
114679087,2964,guozhangwang,2017-05-03T23:53:00Z,"generally this default is just for any un-expected error codes (i.e. there is a bug in the protocol, that broker returns some error codes not defined) to fail-fast.",0,0.9720732569694519
114679260,2964,guozhangwang,2017-05-03T23:54:19Z,"good point, ack.",1,0.9716634750366211
114679267,2964,guozhangwang,2017-05-03T23:54:22Z,"good point, ack.",1,0.9716634750366211
114679565,2964,guozhangwang,2017-05-03T23:57:09Z,"i have not reviewed your expiration pr so my understanding might be inconsistent, but here is how i read the existing code: `txnstarttimestamp` is only set when there is an active txn ongoing, otherwise it should always be set to -1 (i.e. the above check on the new metadata). and expiration will simply skip the metadata when this field is -1.",0,0.9812607765197754
114680315,2964,guozhangwang,2017-05-04T00:03:32Z,"this will be in completed in another pr for the locking mechanism, and here is a sketch: 1. we will add a per-broker read-write lock on tc. 2. all request-handling logic need to grab the read lock before accessing the cache for checking state until appending to the local log call returns. 3. the loading / removing thread will grab the write lock when removing / adding the sub-map for that partition into the cache. 4. implementation-wise, we will modify `statelock` for that read-write lock. the main purpose is to avoid log appending out-of-order, e.g. consider the following order: [code block]",0,0.9795106053352356
114680536,2964,guozhangwang,2017-05-04T00:05:22Z,"hmm, that is a good point. i think it can happen that `onfollower` called twice but the second call's triggered thread gets executed before the first call. so yeah we could just log it and move on.",1,0.6929599642753601
114681378,2964,guozhangwang,2017-05-04T00:13:26Z,"edit: similarly for `addloadedtransactionstocache`, but slightly different: we only have one background thread inside `scheduler` and we are checking on `loadingpartitions` so that no requests will be handled while loading so no new entries will be appended to the log. so even we have two loading tasks scheduled, it is safe for the second loaded metadata to replace the first loaded sub-map via `put`, so if `isdefined` we can just log it.",0,0.9870060682296753
114682211,2964,guozhangwang,2017-05-04T00:22:34Z,"i have been thinking about it, the main reason that i keep it separately is that it can be called in two paths: handler thread call it directly and the callback from writemarkersender call it separately. in the latter case the two values are separate so i ended up keep them as is.",0,0.9678464531898499
114723919,2964,dguy,2017-05-04T08:41:09Z,"in step 2 isn't the log append callback happening on another thread? so how do we release the read lock? i guess i'm missing something but i'm reading it like this: [code block] which would mean the read lock would be given up as soon as the `appendtolog` call returns, but that doesn't mean the write to the log has actually completed as it might go into purgatory and be completed by another thread. i guess you have some other idea?",0,0.9278343915939331
114724163,2964,dguy,2017-05-04T08:42:42Z,my understanding is that it only needs to be set when we add the first partition to a new transaction.,0,0.9761852622032166
114724204,2964,hachikuji,2017-05-04T08:43:01Z,"why is it safe to access `transactionmetadatacache` without a lock? it seems we protect mutations with the state lock, but since it is not a concurrent collection, don't we need to protect reads as well?",0,0.9820480346679688
114724432,2964,dguy,2017-05-04T08:44:33Z,"ok - that makes sense. however, if this does happen how would we recover from it? we'd have uncommitted data in the logs which would block consumers using read committed. do we have any plans to deal with this?",0,0.9724740982055664
114724503,2964,dguy,2017-05-04T08:45:02Z,yeah - duh! i missed that!,1,0.9837946891784668
114724840,2964,hachikuji,2017-05-04T08:47:07Z,"not from this patch, but should this be `transactionstatemanager`?",0,0.9869790077209473
114725329,2964,hachikuji,2017-05-04T08:50:12Z,nit: this is not aligned.,0,0.8599094152450562
114726156,2964,hachikuji,2017-05-04T08:54:40Z,"hmm... it doesn't seem right to synchronize on the instance of `coordinatorepochandtxnmetadata`. we construct a new one in every call to `addtransaction`, right? also, we're still synchronizing on the metadata elsewhere in this file.",0,0.9395183324813843
114726879,2964,hachikuji,2017-05-04T08:58:33Z,"nit: `error`? in spite of the name of `errors`, there is only one error. a few more of these in this class if you're keen.",0,0.982222318649292
114728807,2964,hachikuji,2017-05-04T09:09:58Z,"this is a comment throughout, but it seems we rarely check the result of `preparetransitionto`. perhaps that function should just raise an invalid state exception if the state transition is invalid? otherwise we should get in the habit of adding the checks.",0,0.9352483153343201
114729513,2964,hachikuji,2017-05-04T09:13:50Z,"nit: not from this patch, but should this be `responsecallback`? it's nice to keep naming consistent and we use this name in `handleinitpid` and `initpidwithexistingmetadata`. it's also helpful that the name expresses that this callback returns to the user.",0,0.9261347651481628
114730909,2964,hachikuji,2017-05-04T09:21:29Z,shouldn't we be using `newmetadata` somehow?,0,0.9818632006645203
114732285,2964,hachikuji,2017-05-04T09:28:44Z,"nit: not from this patch, but couldn't we add a couple constructors to `initpidresult` and remove these functions? or maybe just add default values for pid and epoch.",0,0.9884663820266724
114737164,2964,hachikuji,2017-05-04T09:57:30Z,the reuse of `transactionmetadata` here is super confusing. it seems we just need a struct to propagate the new state to the completion callback. maybe we could do this with an immutable case class instead? maybe `transactionstatetransition` or something.,-1,0.9082018136978149
114739243,2964,hachikuji,2017-05-04T10:09:36Z,"typo: ""competed""",0,0.9334561228752136
114740699,2964,hachikuji,2017-05-04T10:18:53Z,"this is pretty confusing stuff. my understanding is that once this append completes, we'll invoke `transationmetadata.completetransitionto`. in this case, it will be the same `transactionmetadata` object passed to itself. might not be incorrect, but it's definitely weird. by the way, you can replace `epochandmetadata.transactionmetadata` with `metadata`.",-1,0.9782163500785828
114749671,2964,ijuma,2017-05-04T11:19:41Z,"similar to a comment that i left in a different pr, adding type annotations here triggers a pattern match and it's brittle if there are cases where the match can fail, but the compiler can't prove it (any time there is a subclass involved). it's one of the cases where relying on type inference is safer (it will always infer a safe type).",0,0.9609718918800354
114750267,2964,ijuma,2017-05-04T11:24:05Z,"btw, a better way to represent this would be using `either[errors, (int, transactionmetadata)]`. even better would be to have a type for the tuple on the right, but even without it, it would make the flow way clearer imo.",0,0.9853672981262207
114807366,2964,guozhangwang,2017-05-04T15:12:07Z,"when a transaction is completed, should we reset the starttimestamp to -1 again to avoid being expired?",0,0.9876692891120911
114807926,2964,guozhangwang,2017-05-04T15:14:05Z,ack.,0,0.7720441818237305
114877797,2964,guozhangwang,2017-05-04T20:20:46Z,when this happens usually ops people need to be involved to manually truncate the log before starting. but i think this code can also be improved a bit for a more graceful shutdown. do you have any ideas?,0,0.9715643525123596
114878149,2964,guozhangwang,2017-05-04T20:22:13Z,"as i said we only need to make sure the the log entry is appended to the local data segment (even not required to flushed on disk), not necessarily replicated complete.",0,0.988373339176178
114879314,2964,guozhangwang,2017-05-04T20:27:35Z,"1. please see my previous comment: we will modify the `statelock` into a read-write lock and the only operations that could mutate the top-level map `transactionmetadatacache` will be covered (the checking / append-to-log will be covered in read lock). 2. for the lower-level map `pool[string, transactionmetadata]`, its operations are thread safe and any modifications to the inner `transactionmetadata` will be covered by the object `synchronized` itself and all modifications will be in-place than object override.",0,0.9863908290863037
114879417,2964,guozhangwang,2017-05-04T20:28:03Z,ack.,0,0.7720441818237305
114879969,2964,guozhangwang,2017-05-04T20:30:42Z,"i have also thought about that, e.g. having sth. like [code block] and call it without overriding defaults upon checking failure cases, but i found it is less readable. if you feel strong about it i can change.",0,0.9063668251037598
114880965,2964,guozhangwang,2017-05-04T20:35:07Z,"yeah that is a good question, ideally we should sycnrhonize on `txnmetadata` only, since coordinator epoch will only likely be changed during loading / removal of the metadata. will refactor on this part.",0,0.8727191686630249
114902795,2964,guozhangwang,2017-05-04T22:33:08Z,ack.,0,0.7720441818237305
114903066,2964,guozhangwang,2017-05-04T22:35:06Z,"we check it in `transactionmetadata`, that the new state is equal to the pending state.",0,0.9887479543685913
114903584,2964,guozhangwang,2017-05-04T22:38:28Z,"i just refactored the code a bit around `initpid`, since it is a special case compared with others: 1. in other cases, we first create a new metadata as a place holder of all the pending updates to the original object and then only update it in the callback after append / send marker completes; 2. in `initpid` case, we would try first inserting a dummy into the cache but set its pending state, as `empty -> empty`; if there is an existing entry already we would either a) abort its existing txn first b) return retriable error code or c) update epoch / txn timeout and do the same as case 1) above. the new code path looks better to me know. let me know what do you think.",0,0.9782626628875732
114903764,2964,guozhangwang,2017-05-04T22:39:39Z,ack.,0,0.7720441818237305
114903788,2964,guozhangwang,2017-05-04T22:39:51Z,done.,0,0.9759407639503479
114903866,2964,guozhangwang,2017-05-04T22:40:32Z,"not sure i understand this comment, could you elaborate a bit?",-1,0.5968115925788879
114904861,2964,guozhangwang,2017-05-04T22:47:50Z,ack.,0,0.7720441818237305
114905004,2964,guozhangwang,2017-05-04T22:48:54Z,ack.,0,0.7720441818237305
114906261,2964,hachikuji,2017-05-04T22:58:09Z,"but if we know the transition is invalid here, then we could skip appending to the log, right? i feel we should just make `preparetransitionto` raise an exception if the attempted transition is invalid.",0,0.9782334566116333
114916468,2964,guozhangwang,2017-05-05T00:32:04Z,discussed offline.,0,0.9721526503562927
114916529,2964,guozhangwang,2017-05-05T00:32:46Z,"edit: discussed offline, realized it is a different issue than i thought about. refactored this part a bit as well.",0,0.9736990332603455
114917535,2964,guozhangwang,2017-05-05T00:45:44Z,"edit: i realized that in many cases i would return a `null`, and it will cause the annotated type to be `any` at compilation time. so i think it is actually better to enforce type annotations in this case.",0,0.9827868938446045
114917644,2964,ijuma,2017-05-05T00:47:01Z,"yeah, you should never use `null` in scala generally. using an `either` here avoids all the issues.",0,0.9787037968635559
114920333,2964,junrao,2017-05-05T01:27:36Z,not sure checking coordinatorepoch here is enough since coordinatorepoch could change when we append the log.,0,0.974584698677063
114921338,2964,guozhangwang,2017-05-05T01:42:57Z,"got it, thanks!",1,0.9699772596359253
114973551,2964,dguy,2017-05-05T11:06:35Z,ok - i missed the local bit. thanks,1,0.9704866409301758
115104932,2964,junrao,2017-05-05T23:36:30Z,"in scala, == tests object equality. i think we want to test reference equality here. if so, we should use eq for testing.",0,0.9852586984634399
115106324,2964,junrao,2017-05-05T23:57:42Z,"hmm, this means that in preparetransitionto(), we need to transition from one state to itself. not sure if all states are allowed to transition from itself.",0,0.9603735208511353
115106407,2964,junrao,2017-05-05T23:59:24Z,"since now there are different types of epoch, would it be better to name this prepareincrementproducerepoch?",0,0.9861444234848022
115106983,2964,junrao,2017-05-06T00:10:02Z,should we include pendingstate in hashcode() and equals()?,0,0.9881836771965027
115107794,2964,junrao,2017-05-06T00:26:22Z,"hmm, when transitioning from empty to ongoing, it seems it's ok for newmetadata.txnstarttimestamp to be larger than current txnstarttimestamp. it's only when transitioning from ongoing to ongoing that we don't want txnstarttimestamp to change.",0,0.9728163480758667
115107921,2964,junrao,2017-05-06T00:29:38Z,"yes, it seems damian's understanding makes sense.",0,0.9442174434661865
115108280,2964,junrao,2017-05-06T00:39:21Z,it seems the comment should be the same as in line 185: let client backoff and rety instead of retry immediately.,0,0.9878895878791809
115147118,2964,junrao,2017-05-07T16:09:38Z,highwatermark below should be renamed to logendoffset?,0,0.9892020225524902
115147657,2964,junrao,2017-05-07T16:32:52Z,"since removetransactions() is cheap, not sure if this needs to be run in a scheduler. also, perhaps it's useful to wait for the scheduler to have no pending task here before return? any pending loadtransaction task should be completed very quickly after removetransactions() is called.",0,0.974000096321106
115163421,2964,junrao,2017-05-08T02:03:38Z,does brokerrequestqueue.destination need to be volatile?,0,0.9849023222923279
115163433,2964,junrao,2017-05-08T02:03:50Z,"hmm, the while loop may tie up a request handler thread, which is not ideal.",0,0.9629732370376587
115163443,2964,junrao,2017-05-08T02:04:02Z,"since the timeout for delayedtxnmarker is infinite, do we need a purgatory or just a map?",0,0.974433183670044
115163467,2964,junrao,2017-05-08T02:04:23Z,"hmm, in the disconnected case, shouldn't we check txnstatemanager.gettransactionstate as well in case an emmigration has happened?",0,0.9848747849464417
115163478,2964,junrao,2017-05-08T02:04:41Z,"since multiple immigration/emigration could have happened when the response comes back, a more reliable way is to check if the current coordinator epoch is still the same as what's in the request.",0,0.9838957786560059
115163488,2964,junrao,2017-05-08T02:04:51Z,should we also remove the entries keyed by transactionalid in purgatory?,0,0.9738171696662903
115163567,2964,junrao,2017-05-08T02:06:01Z,"structure wise, maybe it's better to do this as part of transactionmetadata.completetransitionto() so that we can limit the place where internals of transactionmetadata are modified?",0,0.9874639511108398
115163598,2964,junrao,2017-05-08T02:06:23Z,"hmm, is this right? we watch on transactionalid, not producerid. also, since txnmarkerpurgatory is passed around to different classes, it's bit hard to track who is calling checkandcomplete on this purgatory. an alternative way is to expose an access method to txnmarkerpurgatory in transactionchannelmanager and let all classes call that method.",0,0.926002562046051
115294821,2964,hachikuji,2017-05-08T16:43:35Z,no strong preference if you already rejected the option.,0,0.9429624676704407
115317861,2964,hachikuji,2017-05-08T18:23:05Z,nit: the `toshort` is not needed.,0,0.9863193035125732
115317895,2964,hachikuji,2017-05-08T18:23:14Z,maybe we could use the `ongoing` state explicitly?,0,0.9879825115203857
115320070,2964,hachikuji,2017-05-08T18:32:24Z,nit: the whole body of `handleinitpid` is misaligned.,0,0.9132166504859924
115321540,2964,hachikuji,2017-05-08T18:38:41Z,"hmm.. if the user is trying to add partitions before the previous transaction has completed, shouldn't that be invalid_txn_state?",0,0.9783192276954651
115322180,2964,hachikuji,2017-05-08T18:41:26Z,nit: i think this is more than an optimization: it is necessary for correctness because there is no guarantee that the client will receive the result of the endtxnrequest.,0,0.9693580865859985
115322387,2964,hachikuji,2017-05-08T18:42:17Z,"nit: comment misaligned. also, pity we can't merge this branch with `completecommit` somehow.",-1,0.9843403100967407
115323214,2964,hachikuji,2017-05-08T18:45:52Z,"hmm... isn't it possible that a client resends an endtxnrequest while we are still in `preparecommit` or `prepareabort`. as long as the outcome matches, it seems we should accept those requests and perhaps return concurrent_transactions? also, can we list the states we're catching here explicitly?",0,0.9811215400695801
115323957,2964,hachikuji,2017-05-08T18:49:13Z,maybe we should log something in the else case?,0,0.9855785369873047
115324352,2964,hachikuji,2017-05-08T18:51:00Z,"could we check for the case explicitly with `txnmanager.iscoordinatorfor(transactionalid)`? if the transactionalid did not migrate, then maybe it should be an illegal state.",0,0.9716078042984009
115325045,2964,hachikuji,2017-05-08T18:53:47Z,nit: add newline,0,0.9848806858062744
115337072,2964,hachikuji,2017-05-08T19:51:23Z,this should be `epochandmetadata.transactionmetadata`?,0,0.9888218641281128
115337702,2964,hachikuji,2017-05-08T19:54:22Z,same here: `epochandmetadata.transactionmetadata`.,0,0.988520085811615
115338461,2964,hachikuji,2017-05-08T19:57:45Z,seems this class doesn't depend on the containing instance of `transactionmarkerchannel`. can we move it outside or to the companion object?,0,0.9886061549186707
115339106,2964,hachikuji,2017-05-08T20:01:02Z,nit: `private[transaction]`?,0,0.9864778518676758
115339988,2964,hachikuji,2017-05-08T20:05:42Z,"might be worth noting that `size` is o(n). also, maybe `queued` is redundant given the name of the class. maybe it could just be `totalrequests`?",0,0.9865776300430298
115340279,2964,hachikuji,2017-05-08T20:06:54Z,could this be `private[transaction]`? also i found the name a bit misleading: would `transactionmarkerqueue` or `transactionmarkeraccumulator` be closer?,0,0.9460428953170776
115340733,2964,hachikuji,2017-05-08T20:09:05Z,maybe `brokerrequestqueues`?,0,0.9878167510032654
115350244,2964,hachikuji,2017-05-08T20:51:55Z,"it would be nice to decouple `transactionstatemanager` from `transactionmarkerchannel`. one way to do this is to move the building of the `requestandcompletionhandler` objects into `requestgenerator`. you can let `drainqueuedtransactionmarkers` return something like `map[int, list[txnidandmarkerentry]]`. then `transactionmarkerchannel` would not need a reference to `transactionstatemanager`. also, the generator pattern is a little odd. could we just make `interbrokersendthread` an abstract class with an abstract method `generaterequests`? in that case, you could let `transactionmarkerchannelmanager` extend directly from `interbrokersendthread` and implement the request generation.",0,0.9570261836051941
115351637,2964,hachikuji,2017-05-08T20:58:10Z,kind of unfortunate that we have a dependence on `networkclient` only in order to invoke this `wakeup()`. i'm wondering if the callers could do it instead and we can remove the dependence? that will help to decouple the objects which will make testing easier.,-1,0.9734799265861511
115352392,2964,hachikuji,2017-05-08T21:01:56Z,why do we do this? maybe worth a comment.,0,0.9504485726356506
115353412,2964,hachikuji,2017-05-08T21:07:07Z,also it seems like a good idea to verify that the state of the transaction is still what we expect.,0,0.8213887810707092
115353802,2964,hachikuji,2017-05-08T21:09:02Z,i think `request_timeout` might be another possibility.,0,0.9874629378318787
115354587,2964,hachikuji,2017-05-08T21:13:06Z,i wonder if you can add a comment explaining when this case can happen.,0,0.6693941354751587
115356024,2964,hachikuji,2017-05-08T21:20:23Z,sounds good. will that be part of this patch?,1,0.949487030506134
115356574,2964,hachikuji,2017-05-08T21:23:11Z,the cast to `filerecords` is not totally safe. i fixed the same problem in `groupmetadatamanager` recently.,0,0.6639460325241089
115356894,2964,hachikuji,2017-05-08T21:24:41Z,nit: pattern match?,0,0.9870941042900085
115359708,2964,hachikuji,2017-05-08T21:37:56Z,"a cache change due to emigration/immigration would be handled by the epoch check, right? are there any cases where `completetransitionto` itself could fail?",0,0.9871962070465088
115377273,2964,guozhangwang,2017-05-08T23:25:55Z,ack.,0,0.7720441818237305
115377857,2964,guozhangwang,2017-05-08T23:30:27Z,"we could be loading for partition x while removing for partition y in this case, so waiting for the removing to complete may still take long time right? another benefit to let all three operations (loading, removing-partition, expiring-txns) to be execute by the same back ground thread is that locking mechanism would be a bit easier to reason (this is not part of this pr): only background thread would grab the write lock, and the handler thread will only try to grab read lock, and handler thread would not add / remove any entries from the maps but just modify the objects in-place.",0,0.9783163666725159
115378256,2964,guozhangwang,2017-05-08T23:33:08Z,"not sure i understand your question? `coordinatorepoch` is the value passed from the caller, which is the epoch of the cached metadata object before append is called, and here we are checking if it is still the same epoch by reading from the cache again. plus inside `completetransitionto` we also check that other fields inside metadata are expected.",0,0.9881072640419006
115378411,2964,guozhangwang,2017-05-08T23:34:33Z,ack.,0,0.7720441818237305
115378474,2964,guozhangwang,2017-05-08T23:35:07Z,ack.,0,0.7720441818237305
115378959,2964,guozhangwang,2017-05-08T23:38:52Z,"we only allow `empty` -> `empty` transition, and it is a special case for adding a txnid for the first time, the inserted entry will be empty and its pending state also empty. only when the pending state is cleared after the txn log write returns it is considered ""created succesfully"". as for this function itself, it is only used when `initpid` is received while the current pid has an ongoing txn, i.e. it is `ongoing`, and later we check if it is `ongoing` we will abort the txn first and return `concurrent_txn` to let user retry.",0,0.9840644001960754
115378997,2964,guozhangwang,2017-05-08T23:39:07Z,ack.,0,0.7720441818237305
115379242,2964,guozhangwang,2017-05-08T23:41:29Z,"that is true: when the pid is first created, there is no txn yet, the starttime is set to ""-1"", when we received the first addpartitions we will update the starttime to `now`, and it will not be updated until it has completed, and then a new addpartition is received indicating the start of a new txn for this pid.",0,0.9851495027542114
115379741,2964,guozhangwang,2017-05-08T23:45:48Z,ack.,0,0.7720441818237305
115379921,2964,guozhangwang,2017-05-08T23:47:17Z,good point! ack.,1,0.9835514426231384
115380508,2964,guozhangwang,2017-05-08T23:51:53Z,"yeah i have thought about that too.. the approach is that if we cannot locate the broker to offer to its queue then in order for this thread to return we likely need to put it in an ""unknown broker"" queue first, and periodically we can check the queue and migrate to the found brokers. does that make sense?",0,0.9567453265190125
115381202,2964,guozhangwang,2017-05-08T23:57:25Z,"i have not made up my mind about infinite timeout, and would like to have another discussion with you (as i left some comments in damian's previous patch: [a link] for now i'll add a todo marker and do that in a follow-up once we have a conclusion.",0,0.9211649298667908
115381919,2964,guozhangwang,2017-05-09T00:02:41Z,"we check that in the `appendtologcallback` callback in `txnmarkerchannelmanager`. generally speaking here is the reasoning: 1. for the handler logic, the only error code that we should not retry is ""coordinatorepochnotvalid"", in which we should complete the delayed operation immediately with a meaningful error code (currently it is always `none` ). 2. then in `appendtologcallback`, we check the error code, and if it is due to received `coordinatorepochnotvalid` we can simply ignore the rest of the operations.",0,0.9843601584434509
115382316,2964,guozhangwang,2017-05-09T00:05:42Z,"ack. i have re-factored the handling logic here to cover all the error codes, please take a look at the modified file.",0,0.9308117628097534
115382553,2964,guozhangwang,2017-05-09T00:07:44Z,"not sure i understand the comment, we are indeed canceling for the transactionalid right?",0,0.7898110747337341
115382668,2964,guozhangwang,2017-05-09T00:08:47Z,ack.,0,0.7720441818237305
115388039,2964,guozhangwang,2017-05-09T00:57:01Z,ack.,0,0.7720441818237305
115388145,2964,guozhangwang,2017-05-09T00:57:55Z,ack.,0,0.7720441818237305
115388336,2964,guozhangwang,2017-05-09T00:59:38Z,"well, since we return to the user right after we have appended the log, in which case the state has updated to `preparexx`, the client code is possible to send another `addpartitions` while the sending markers are still on the flight. in this case we should not return a fatal error but let client retry.",0,0.9881876111030579
115388370,2964,guozhangwang,2017-05-09T01:00:07Z,"okay, will update the comments.",0,0.9837158918380737
115388416,2964,guozhangwang,2017-05-09T01:00:37Z,ack.,0,0.7720441818237305
115388582,2964,guozhangwang,2017-05-09T01:02:29Z,good point! ack.,1,0.9835514426231384
115388842,2964,guozhangwang,2017-05-09T01:05:18Z,"edit: actually i think for most cases this case should be covered in `txnmetadata.pendingtransitioninprogress`, the only edge case that we have migrated to `preparexx` but have not prepareto `completexx` (note they should happen fairly consecutively). anyways, will add them to cover it as well.",0,0.9860906600952148
115389069,2964,guozhangwang,2017-05-09T01:08:13Z,ack.,0,0.7720441818237305
115389114,2964,guozhangwang,2017-05-09T01:08:46Z,"good point, ack.",1,0.9716634750366211
115536083,2964,hachikuji,2017-05-09T16:28:18Z,"ack, makes sense.",0,0.9721857905387878
115614545,2964,guozhangwang,2017-05-09T22:09:10Z,ack.,0,0.7720441818237305
115614791,2964,guozhangwang,2017-05-09T22:10:33Z,ack.,0,0.7720441818237305
115614938,2964,guozhangwang,2017-05-09T22:11:25Z,ack. this will be part of the minor refactoring that exhausts all the possible error codes in the writetxnmarker responses.,0,0.9867631793022156
115616278,2964,guozhangwang,2017-05-09T22:20:04Z,"actually i just realized we do not need to check the coordinator epoch anymore, since it is already checked in `appendtransactiontolog#updatecachecallback`, which is executed before calling this callback, so the error code returned is already reflecting the fact if [code block] so we can directly go head with the error code here.",0,0.9849621057510376
115624264,2964,guozhangwang,2017-05-09T23:17:10Z,"ack. after thinking about this, i'm going to merge the `markerchannel` into `markerchannelmanager` since it is always a one-to-one mapping.",0,0.9745963215827942
115624364,2964,guozhangwang,2017-05-09T23:17:56Z,ack.,0,0.7720441818237305
115624544,2964,guozhangwang,2017-05-09T23:19:24Z,ack.,0,0.7720441818237305
115624880,2964,guozhangwang,2017-05-09T23:21:56Z,ack.,0,0.7720441818237305
115624941,2964,guozhangwang,2017-05-09T23:22:30Z,ack. let me know wdyt about the after-refactoring.,0,0.9800457954406738
115625053,2964,guozhangwang,2017-05-09T23:23:25Z,ack.,0,0.7720441818237305
115625404,2964,guozhangwang,2017-05-09T23:26:02Z,"i'm not sure either, it is from the old code. my understanding is that `networkclient` is only pollable from the `sendthread`, and hence `wakeup` is not required. but maybe i'm missing something here, cc",0,0.9084016680717468
115628649,2964,guozhangwang,2017-05-09T23:52:22Z,rebased this already.,0,0.985121488571167
115628821,2964,guozhangwang,2017-05-09T23:53:43Z,could you elaborate a bit? we only have logic for the `if` condition?,0,0.9857162833213806
115629030,2964,guozhangwang,2017-05-09T23:55:31Z,"good point, we could consider throw exception directly instead of returning false. there are a few of those suggestions that we can do in a follow-up pr. i have marked those places with `todo`s.",0,0.908845841884613
115636450,2964,guozhangwang,2017-05-10T01:06:03Z,"i checked the source code, `timeoutexception` can only be thrown from producer / consumer internals, but they will never be returned from the broker side. so this should not be a possibility?",0,0.9819387197494507
115643581,2964,hachikuji,2017-05-10T02:26:46Z,did you also look for uses of `errors.request_timeout`?,0,0.988415002822876
115647476,2964,guozhangwang,2017-05-10T03:21:13Z,you mean `request_timed_out`? there is no `request_timeout` in errors. for the latter case i searched the code and found no return errors from broker-side.,0,0.989573061466217
116116648,2964,hachikuji,2017-05-11T22:25:56Z,"after we remove `transactionmarkerchannel`, maybe we can claim its name for this class?",0,0.9892376661300659
116124062,2964,hachikuji,2017-05-11T23:17:38Z,"can we mention the partition number? also, ""may likely has emigrated"" -> ""has likely emigrated""?",0,0.9819230437278748
116124812,2964,hachikuji,2017-05-11T23:23:57Z,"if the epoch has changed, is it still necessary or safe to continue with the logic below? in particular, we could still remove the partitions from `transactionmetadata`. maybe we should just return?",0,0.9879584312438965
116125417,2964,hachikuji,2017-05-11T23:28:33Z,we discussed offline changing this to assert a valid transition instead of returning a boolean. we could do this in a follow-up if you prefer.,0,0.9863595366477966
116125544,2964,hachikuji,2017-05-11T23:29:31Z,"should we return here? otherwise, the call to `completesendmarkersfortxnid` will be invoked below. not sure it's a problem, but seems odd. also, i'm not sure i fully understand the chain of operations that this should trigger. it seems that `removemarkersfortxnid` cancels the `delayedtxnmarker`, which means its callback won't get invoked. but what happens to the state of the `transactionmetadata`? it seems like it will just remain indefinitely in one of the prepare states. for coordinatorfenced, that seems ok; we rely on the partition to ultimately be evicted. how about producerfenced? i'm actually having a tough time imagining a scenario where we would hit that error. the only one that comes to mind is if the coordinator has become a zombie, in which case we should get blocked by the coordinator epoch. are there any others? in any case, i think it would be helpful to add some comments here clarifying the scenario and the handling expectation.",0,0.8849819898605347
116155904,2964,guozhangwang,2017-05-12T05:39:45Z,"it is done already, but was not pushed somehow, could you check again now?",0,0.9860715270042419
116156002,2964,guozhangwang,2017-05-12T05:40:42Z,this call is just for removing the delayed operation in the txn marker purgatory. i think it is still safe.,0,0.9467621445655823
116156202,2964,guozhangwang,2017-05-12T05:44:07Z,"`transactionmetadata` should be removed by the emmigration handler thread, and in the future the pid expiration scheduler's thread. other handling logic should never remove the entry, but just to update the entry in-place. and about returning here: good catch! yeah we should not call `completesendmarkersfortxnid` in this case. will fix now.",1,0.9805067777633667
116312856,2964,junrao,2017-05-12T20:00:37Z,reaperenabled doesn't seem be be used.,0,0.9514625072479248
116323993,2964,junrao,2017-05-12T21:03:33Z,is appending w/o synchronization on coordinator epoch safe? we don't want to write to the log if the coordinator epoch has changed. the most reliable way is probably to hold a read lock on transactionstatemanager.statelock() while doing the log append.,0,0.9889899492263794
116338170,2964,junrao,2017-05-12T22:54:25Z,"hmm, not sure if this is completely safe. in removetransactionsfortxntopicpartition(), we modify loadingpartitions in the scheduler and here, we modify loadingpartitions in the method directly. this means that if an emmigration is followed immediately by an immigration, the updating of loadingpartitions by emmigration could happen after the updating of loadingpartitions by immigration, which will leave the state incorrect.",0,0.9567497968673706
116339508,2964,junrao,2017-05-12T23:08:39Z,"the issue of changing the transaction states in the scheduler is that when this call returns, the new transaction states are not necessarily reflected. so, another request after this call may still see the old states?",0,0.980469286441803
116340857,2964,junrao,2017-05-12T23:24:13Z,"txnmarkerpurgatory registers each item under transactionalid and txntopicpartition. we are only removing the item registered under transactionalid. so, which process will be removing the item registered under txntopicpartition, especially the reaper thread is not running in txnmarkerpurgatory?",0,0.9887162446975708
116342175,2964,junrao,2017-05-12T23:42:41Z,"since we always send none as error in delayedtxnmarker, it seems that we can just get rid of error?",0,0.9834488034248352
116343892,2964,junrao,2017-05-13T00:10:43Z,"yes, it's just that in the case that a transaction coordinator's epoch has changed, there is no need to keep resending the writemarker request to the brokers.",0,0.9870880842208862
116638694,2964,guozhangwang,2017-05-16T01:44:41Z,ack.,0,0.7720441818237305
116638797,2964,guozhangwang,2017-05-16T01:46:02Z,"yup, it is going to be done in the locking pr that i'm also working on now. just trying to keep each pr small to make it easier for reviews.",0,0.8666841387748718
116638956,2964,guozhangwang,2017-05-16T01:47:58Z,good catch! ack.,1,0.9918825030326843
116639242,2964,guozhangwang,2017-05-16T01:51:08Z,it is in the `transactionmarkerchannelmanager#removemarkersfortxntopicpartition`.,0,0.9876580238342285
116639395,2964,guozhangwang,2017-05-16T01:52:49Z,"hmm that is right, but i feel we will probably need to add other possible error codes as we as fixing various error cases under integration tests, so i'd rather keep it as is for now. if after exactly-once has been quite stable and we still do not have any other error code we can remove it. but let mw add a todo for now in case we forgot..",0,0.9489424824714661
116650638,2964,guozhangwang,2017-05-16T03:53:57Z,makes sense. i will add the check.,0,0.979056179523468
116653014,2964,guozhangwang,2017-05-16T04:29:03Z,"got it. however, if we just do the removal in the handler thread, then the immigrate-then-emigrate issue may occur. on the other hand, we cannot depend on scheduler do not have pending request since we are periodically schedule txn-expiration and pid-expiration with that scheduler as well. so here is what i will do: add a removal partitions which will be modified in the handler thread, then get txn metadata will check if the txn partition is in the removal partitions set. then in the locking pr, i will add the read-write-lock so that checking will be monitored by the read lock. wdyt?",0,0.9772428870201111
79560389,1884,dguy,2016-09-20T08:35:42Z,private?,0,0.9682251811027527
79560800,1884,dguy,2016-09-20T08:38:32Z,"delegate to the other constructor: `this(config, 0, window_change_log_additional_retention_default)`",0,0.9866725206375122
79562570,1884,dguy,2016-09-20T08:49:18Z,if the topic exists we need to make sure the number of partitions is the same. if it isn't the same then we should throw an exception.,0,0.9791414141654968
79563507,1884,dguy,2016-09-20T08:54:49Z,doesn't look like this method is used anywhere?,0,0.9468697309494019
79566464,1884,dguy,2016-09-20T09:12:18Z,is this needed? it is not used anywhere,0,0.9808356761932373
79566488,1884,dguy,2016-09-20T09:12:26Z,as above,0,0.9783914685249329
79566646,1884,dguy,2016-09-20T09:13:21Z,this doesn't need to be a field. could be a local in the constructor,0,0.9875059127807617
79566686,1884,dguy,2016-09-20T09:13:42Z,as above,0,0.9783914685249329
79566702,1884,dguy,2016-09-20T09:13:50Z,as above,0,0.9783914685249329
79567055,1884,dguy,2016-09-20T09:15:58Z,"nit: using an instance variable to reference a static. should be: `this.metadata = new metadata(streamsconfig.getlong(streamsconfig.retry_backoff_ms_config), streamsconfig.getlong(streamsconfig.metadata_max_age_config));`",0,0.9874651432037354
79568023,1884,dguy,2016-09-20T09:21:29Z,should this just use `streamsconfig.metric_reporter_classes_config`? and then i don't see why we need line 100,0,0.9851449728012085
79568120,1884,dguy,2016-09-20T09:22:09Z,`streamsconfig.connections_max_idle_ms_config`,0,0.9867560863494873
79568305,1884,dguy,2016-09-20T09:23:19Z,"as above. next 4 lines should use the class to reference static fields, i.e., `streamsconfig.reconnect_backoff_ms_config`",0,0.9873287677764893
79568817,1884,dguy,2016-09-20T09:25:55Z,`private static final max_iterations` ?,0,0.9872578978538513
79569302,1884,dguy,2016-09-20T09:28:55Z,nit: my preference is that all immutable parameters and fields are `final`. so: `streamskafkaclient(final streamsconfig streamsconfig)` and below: `final time time = ...` etc,0,0.9801167845726013
79569654,1884,dguy,2016-09-20T09:31:03Z,"should we make this into a final static field? i.e., `max_inflight_requests` or similar? i.e., what is 100?",0,0.9880961179733276
79569944,1884,dguy,2016-09-20T09:32:32Z,"what is the 0 for? can we make it into a static final field, so it has a name?",0,0.9883437156677246
79570181,1884,dguy,2016-09-20T09:33:38Z,do we need this? don't think it is used anywhere,0,0.9810024499893188
79570479,1884,dguy,2016-09-20T09:35:10Z,"i don't currently see this being used anywhere. is it going to cause shutdown problems if this isn't closed properly? i.e., will there be non-daemon threads hanging around that cause the jvm to not shutdown?",0,0.9029673337936401
79570684,1884,dguy,2016-09-20T09:36:23Z,`if (...) { .. }`,0,0.9850892424583435
79570848,1884,dguy,2016-09-20T09:37:04Z,this should probably throw `streamsexception` as that is the top-level exception for streams,0,0.9874559044837952
79571533,1884,dguy,2016-09-20T09:40:52Z,we should change `internaltopicconfig.toproperties(...)` to return a `map ` then we won't need to copy the properties into the `topicconfig` map below,0,0.9860907793045044
79571804,1884,dguy,2016-09-20T09:42:36Z,"nit: as mentioned above. my preference is for params and locals to be final if possible. i know it i adds few extra characters, but it shows intent and can prevent unnecessary bugs",0,0.8639316558837891
79571936,1884,dguy,2016-09-20T09:43:23Z,move this down to line 149 and do the init and assignment on a single line,0,0.9878165125846863
79572482,1884,dguy,2016-09-20T09:46:38Z,i don't think you need this callback. you can just pass `null` if the callback isn't necessary,0,0.9804033041000366
79573826,1884,dguy,2016-09-20T09:53:54Z,it would be good if we could say why it failed. is there a mapping from the error code to a string we could use?,0,0.9664106965065002
79573949,1884,dguy,2016-09-20T09:54:37Z,do we need this method?,0,0.9856400489807129
79575520,1884,dguy,2016-09-20T10:02:57Z,i don't think this should be a field. it probably needs to be done before each request as 1. the least loaded node will change. 2. this node might not be up when the request is made.,0,0.9685204029083252
79576598,1884,dguy,2016-09-20T10:08:42Z,perhaps maxiterations should be a timeout instead? also i think it reads cleaner like so: [code block],0,0.9752339124679565
79576919,1884,dguy,2016-09-20T10:10:44Z,as above we should probably change `maxiterations` for a timeout,0,0.9873649477958679
79577022,1884,dguy,2016-09-20T10:11:19Z,why not just re-use the `systemtime` from above?,0,0.9792976379394531
79577074,1884,dguy,2016-09-20T10:11:44Z,do we need this? it isn't used anywhere.,0,0.9740719199180603
79577318,1884,dguy,2016-09-20T10:13:16Z,move this down to line 279,0,0.9864648580551147
79577973,1884,dguy,2016-09-20T10:17:14Z,nit: looks like the formatting has been unnecessarily changed.,0,0.6796741485595703
79578001,1884,dguy,2016-09-20T10:17:27Z,nit: formatting?,0,0.9839620590209961
79578105,1884,dguy,2016-09-20T10:18:09Z,do we need this? i don't think we ever delete topics? also the test is commented out,0,0.9870951771736145
79578334,1884,dguy,2016-09-20T10:19:20Z,test commented out. also we may not need this if we merge `streamskafkaclient` and `internaltopicmanager` into a single class.,0,0.9895305633544922
79650885,1884,hjafarpour,2016-09-20T16:16:12Z,"yes, made it private :)",1,0.9227235317230225
79650926,1884,hjafarpour,2016-09-20T16:16:26Z,removed this constructor.,0,0.9798523187637329
79652102,1884,hjafarpour,2016-09-20T16:22:05Z,added the check for the number of partitions.,0,0.9865393042564392
79652577,1884,hjafarpour,2016-09-20T16:24:21Z,made them local in the constructor.,0,0.9846434593200684
79652760,1884,hjafarpour,2016-09-20T16:25:17Z,"they were there from the previous iteration. not being used anymore, removed them.",0,0.9758375287055969
79655027,1884,hjafarpour,2016-09-20T16:35:23Z,i used the similar way of creating networkclient in kafkaconsumer. for the streamkafkaclient i can make it a constant as you mentioned. it would be good to update the kafkaconsumer too.,0,0.951942503452301
79655809,1884,hjafarpour,2016-09-20T16:38:26Z,"yes, corrected them.",0,0.9794419407844543
79656213,1884,hjafarpour,2016-09-20T16:40:12Z,"good point, moved it to the request method as a local variable.",1,0.8738463521003723
79657266,1884,hjafarpour,2016-09-20T16:44:47Z,we were thinking about having streamskafkaclient available for other uses too. i'm removing this for now and we can add it later if we need it.,0,0.9806069731712341
79657548,1884,hjafarpour,2016-09-20T16:46:06Z,this was here from the previous version and i kept it. i'm going to remove it now since it is not being used.,0,0.9772197604179382
79658172,1884,hjafarpour,2016-09-20T16:49:07Z,that's a good practice. made all of the params that won't change final.,1,0.9527360200881958
79659263,1884,hjafarpour,2016-09-20T16:54:20Z,made it null.,0,0.8872308731079102
79659681,1884,hjafarpour,2016-09-20T16:56:25Z,i could get the error name or message. i am adding error name to the message.,0,0.9775418043136597
79659793,1884,hjafarpour,2016-09-20T16:56:59Z,it's not being used but we can have it in the streamskafkaclient for future use.,0,0.985958993434906
79666863,1884,hjafarpour,2016-09-20T17:28:40Z,changed them to timeouts.,0,0.9832034111022949
79667197,1884,hjafarpour,2016-09-20T17:30:15Z,needed for checking the partition number.,0,0.9835337996482849
79667509,1884,hjafarpour,2016-09-20T17:31:26Z,i'm removing these tests then.,0,0.9709991216659546
79777362,1884,dguy,2016-09-21T07:54:43Z,i'd probably use the same importance level as was used in the consumer or producer config,0,0.9825548529624939
79777945,1884,dguy,2016-09-21T07:58:22Z,"i know i said make this private... looking again it isn't actually used anywhere apart from the constructor, so it can be removed.",0,0.9819626212120056
79778569,1884,dguy,2016-09-21T08:02:37Z,"i have a pr to remove this method, [a link] as it is unused. if you want to remove it i'll close the pr? also, if you do remove it then you can also remove line 37. edit: sorry the pr was merged before i'd seen your update.",-1,0.9884755611419678
79779302,1884,dguy,2016-09-21T08:07:32Z,"a better way to do this would be to pass in the streamskafkaclient, i.e., `public internaltopicmanager(final streamskafkaclient streamskafkaclient, final int replicationfactor, final long windowchangelogadditionalretention)` why? well the `streamsconfig` is only used to construct the `streamskafkaclient` and it would mean in unit tests we can pass in a stub or mock for `streamskafkaclient`. we can then remove the no-arg constructor on line 60 (it is only used in `mockinternaltopicmanager`)",0,0.9786309003829956
79782495,1884,dguy,2016-09-21T08:27:12Z,"strictly not part of this pr, but might as-well make these params `final` :-)",1,0.740132749080658
79783003,1884,dguy,2016-09-21T08:29:39Z,`final`,0,0.9729287028312683
79785267,1884,dguy,2016-09-21T08:42:57Z,"i'm thinking in `streamskafkaclient.gettopicmetadata(..)` we could just return the `metadataresponse.topicmetadata` regardless of the `error().code()`. so then i think we will never get `null` here as i believe we will always get a response. we can then throw an exception with a more meaningful message, i.e., based on the `error().code()` - rather than just ""topic metadata is corrupted""",0,0.9731172323226929
79785576,1884,dguy,2016-09-21T08:44:40Z,looks like this can be a local now?,0,0.9884810447692871
79785702,1884,dguy,2016-09-21T08:45:29Z,"again, i'd make all the immutable locals `final` - it is a good habit to get into. so, `metricstags`, `metadata`, `metricconfig`, `reporters`, `channelbuilder`, `selector`",0,0.7893527746200562
79786661,1884,dguy,2016-09-21T08:50:25Z,"again, `final` for all locals. also, as per my previous comment on this. i think we should change `internaltopicconfig.toproperties(...)` to return `map ` and then we don't need to copy the props into another `map`",0,0.9837213158607483
79787573,1884,dguy,2016-09-21T08:55:18Z,i still think if this is not being used anywhere we should remove it. if we really want to keep it then we need a test for it.,0,0.9724515080451965
79787831,1884,dguy,2016-09-21T08:56:41Z,"""deleting topic {} from brokers ..."" ?",0,0.9826891422271729
79787999,1884,dguy,2016-09-21T08:57:38Z,we can make all of these locals `final`,0,0.985064685344696
79788308,1884,dguy,2016-09-21T08:59:11Z,"maybe we should make this a better name, like `readytimeout` ?",0,0.9771196246147156
79788383,1884,dguy,2016-09-21T08:59:40Z,"same here, maybe sth like: `requesttimeout`",0,0.9818301796913147
79788859,1884,dguy,2016-09-21T09:02:16Z,"probably need a more descriptive message, i.e., ""timed out waiting for node="" + brokernode + "" to become available""",0,0.9851304888725281
79789101,1884,dguy,2016-09-21T09:03:54Z,"i think this is more like: ""failed to get response from node="" + brokernode + "" within timeout""",0,0.9703843593597412
79789452,1884,dguy,2016-09-21T09:06:15Z,we can remove this as the callback isn't required. we can also remove the `callback` param from `sendrequest(..)` as we don't need it.,0,0.9883964657783508
79789680,1884,dguy,2016-09-21T09:07:42Z,"private? is only used in this class, so there is no need to make it public. also, as per comment below, we can probably remove the `callback` arg as we don't really need it, i.e., we can just pass `null` for the callback.",0,0.9871804118156433
79790026,1884,dguy,2016-09-21T09:10:00Z,see my comment above in `internaltopicmanager`; we can probably just return the matching `metadataresponse.topicmetadata` instance here. as far as i know it will never be null. if we don't find one then we should probably throw an exception,0,0.9861366748809814
79790100,1884,dguy,2016-09-21T09:10:25Z,`final` locals...,0,0.980290412902832
79790238,1884,dguy,2016-09-21T09:11:16Z,`final` param and locals,0,0.9744935631752014
79790517,1884,dguy,2016-09-21T09:13:01Z,"`props.put(consumerconfig.key_deserializer_class_config, serdes.string().deserializer().getclass())` same on next line",0,0.9802142381668091
79790921,1884,dguy,2016-09-21T09:15:01Z,nit: `new kafkaconsumer<>(props);`,0,0.9783875942230225
79791157,1884,dguy,2016-09-21T09:16:14Z,"nit: formatting i.e., `for (string topicnameinlist : topics.keyset())`",0,0.9856115579605103
80079829,1884,hjafarpour,2016-09-22T16:21:32Z,changed it to medium.,0,0.9838401675224304
80080356,1884,hjafarpour,2016-09-22T16:24:26Z,removed it.,0,0.9677461981773376
80080581,1884,hjafarpour,2016-09-22T16:25:36Z,"removed it, please close the pr.",0,0.9841890931129456
80081058,1884,hjafarpour,2016-09-22T16:28:15Z,"good point, made the change accordingly!",1,0.9818503260612488
80081221,1884,hjafarpour,2016-09-22T16:29:01Z,they are final now :),1,0.9218431711196899
80082570,1884,hjafarpour,2016-09-22T16:36:00Z,"made the change, include error code in the message.",0,0.9794263243675232
80082828,1884,hjafarpour,2016-09-22T16:37:24Z,"yes, after the previous changes it only is used in one method. changed it to local.",0,0.9879849553108215
80083158,1884,hjafarpour,2016-09-22T16:39:06Z,all are final now :),1,0.9098458886146545
80083950,1884,hjafarpour,2016-09-22T16:43:10Z,the method is being used in quite a few tests too. if i change it i should change those tests too. do you want me to go ahead and make the change?,0,0.973370373249054
80084032,1884,hjafarpour,2016-09-22T16:43:33Z,removed it.,0,0.9677461981773376
80084885,1884,hjafarpour,2016-09-22T16:48:09Z,made the change!,1,0.6668845415115356
80200474,1884,dguy,2016-09-23T08:21:18Z,can remove this as it is no longer used,0,0.9835213422775269
80200580,1884,dguy,2016-09-23T08:22:06Z,`final` params?,0,0.984053909778595
80204324,1884,dguy,2016-09-23T08:47:49Z,"i think we can remove this constructor now. it is only used in the constructor of `mockinternaltopicmanager`. so, we could change the `mockinternaltopicmanager` constructor to also take a `streamsconfig` as a param. the `streamsconfig` could be minimal, i.e, just `application_id_config` and `bootstrap_servers_config` would need to be set. then in `mockinternaltopicmanager` constructor we just do: `super(new streamskafkaclient(streamsconfig), 0, 0)` and then we can remove this constructor as it is not needed. also means we can mark `streamskafkaclient` on line 39 as `final`",0,0.9618276953697205
80204544,1884,dguy,2016-09-23T08:48:56Z,is there a mapping from the `short` code to a string somewhere?,0,0.9863400459289551
80204699,1884,dguy,2016-09-23T08:49:56Z,can remove this todo as we need these 2 config properties. all the others have been removed.,0,0.9885377883911133
80205835,1884,dguy,2016-09-23T08:57:19Z,can remove this as it is not used.,0,0.9811743497848511
80206000,1884,dguy,2016-09-23T08:58:35Z,`final`,0,0.9729287028312683
80206022,1884,dguy,2016-09-23T08:58:43Z,`final`,0,0.9729287028312683
80207103,1884,dguy,2016-09-23T09:06:04Z,`final`,0,0.9729287028312683
80207117,1884,dguy,2016-09-23T09:06:12Z,`final`,0,0.9729287028312683
80207158,1884,dguy,2016-09-23T09:06:30Z,`final`,0,0.9729287028312683
80207228,1884,dguy,2016-09-23T09:07:00Z,`final`,0,0.9729287028312683
80207325,1884,dguy,2016-09-23T09:07:37Z,`collections.singletonlist(topic)`,0,0.9844856262207031
80213799,1884,dguy,2016-09-23T09:48:38Z,"it would be great if you do, but we can probably do it as another pr if you'd prefer. up to you",1,0.8747999668121338
80285978,1884,hjafarpour,2016-09-23T17:10:59Z,removed it.,0,0.9677461981773376
80286072,1884,hjafarpour,2016-09-23T17:11:32Z,removed it.,0,0.9677461981773376
80288512,1884,hjafarpour,2016-09-23T17:25:49Z,"couldn't find it in the docs. in the code we have ""org.apache.kafka.common.protocol.errors"". i can also print message() or exceptionname() instead of the code. adding the message().",0,0.8752574324607849
80288656,1884,hjafarpour,2016-09-23T17:26:32Z,removed it.,0,0.9677461981773376
80295804,1884,dguy,2016-09-23T18:03:55Z,do we need to add the `jmxreporter` here? the `todo` suggest we should be doing something differernt,0,0.9885727167129517
80505313,1884,hjafarpour,2016-09-26T15:42:06Z,"in kafkastreams.java jmx_prefix is defined private: private static final string jmx_prefix = ""kafka.streams""; i could either make it public and use it here or define a new field here. which one would you suggest?",0,0.9887102246284485
80983996,1884,guozhangwang,2016-09-28T18:19:59Z,do we still need this since we already have `testcompile project(':core')` in line 704 which should bring in zkclient jars transitively?,0,0.9893519282341003
80986713,1884,guozhangwang,2016-09-28T18:32:04Z,"nit: instead of declaring a new doc variable, could we just refer to `commonclientconfigs.xxx_doc` in the `.define`?",0,0.9896489381790161
80987096,1884,guozhangwang,2016-09-28T18:33:35Z,we could use a smaller default value as this is only used for admin requests that are mostly small.,0,0.9881904125213623
80987442,1884,guozhangwang,2016-09-28T18:35:14Z,`final`,0,0.9729287028312683
80987926,1884,guozhangwang,2016-09-28T18:37:27Z,are these two props `cleanup_policy_prop` and `retention_ms` used anywhere any more?,0,0.9875026345252991
80990290,1884,guozhangwang,2016-09-28T18:48:09Z,also should we remove `zookeeper_connect_config` above as well?,0,0.9885678291320801
80990884,1884,guozhangwang,2016-09-28T18:50:49Z,"in there future we will have an `adminclient` as part of completing kip-4 which is used for all such admin requests, and that can be used in kstream, kconnect, replicator, mm, etc. and whoever is about to implementing it would be suggested to borrow from this class. so i think it is ok to keep it as is for internals, and replacing it with the `adminclient` in the future.",0,0.9745716452598572
80992348,1884,guozhangwang,2016-09-28T18:57:47Z,"currently the embedded client: producer, consumer, and admin, have their own metrics and reporters, and we are only correlating them with the `clientid` in the tags. it is better to be improved with hierarchical metrics moving forward. for now i think we can just follow this way but change the prefix in `jmxreporter` from `kafka.streams` to `kafka.admin`?",0,0.9779863953590393
80992958,1884,guozhangwang,2016-09-28T19:00:21Z,the comment is a bit misleading: `polls the request for a given number of iterations to receive the response.` isn't it `keep polling until the corresponding response is received`?,-1,0.8484795093536377
80996029,1884,guozhangwang,2016-09-28T19:16:18Z,"if the broker node is not ready, should we consider picking a different broker instead of tie-ing up one thread doing the while loop here?",0,0.9775240421295166
80996757,1884,guozhangwang,2016-09-28T19:20:27Z,"is it a good behavior that we are simply dropping all other responses on the floor while waiting for the corresponding response? i think today we will not encounter such issues since we always send one request, and block on its response and then send another one. but this is less efficient since with n topics to create we have to go n round trips now, suppose moving forward we will do that in a more batched manner where multiple in-flight requests exist, then i this will be an issue. so instead of checking if the response, could we use the `requestcompletionhandler` interface with sth. similar to consumer where we poll until the handler set the `future` indicating it is received and processed?",0,0.9160121083259583
80996887,1884,guozhangwang,2016-09-28T19:21:07Z,"using another temporary consumer is very inefficient, could we just use `listoffsetrequest` with the admin client here?",-1,0.588901937007904
81010527,1884,guozhangwang,2016-09-28T20:33:33Z,"related to the comment below: since only one request is sent at a time, the `leastloadednode` function is not taking any load into consideration actually; so i think we could just iterate over the nodes and find one that is ready, and if all destination nodes are not ready, backoff based on the configured value and retry again.",0,0.9869468212127686
81013284,1884,dguy,2016-09-28T20:46:42Z,will sending `listoffsetrequest` result in creating the topic when `auto.topic.create` is true?,0,0.9897526502609253
81014530,1884,guozhangwang,2016-09-28T20:52:50Z,"sorry i meant `metadatarequest`, not `listoffsetrequest`. if you specify the topics to be the empty list (i.e. `all_topics_request`), then the broker will not create any topics even with `auto.topic.create` is true.",-1,0.9777359962463379
81044949,1884,mjsax,2016-09-29T00:22:36Z,"this class is still there. i did not follow the whole discussion, but i agree with that we might want to remove this class... what is the reason for keeping it?",0,0.9084786772727966
81047430,1884,guozhangwang,2016-09-29T00:47:43Z,"in `streampartitionassignor`, there is a while loop checking that the metadata has been refreshed with the right number of partitions: [code block] which is error-prone. could we remove that logic and check that the topic metadata has propagated to to the broker with the same `streamskafkaclient.topicexists(topic.name()`, i.e.: [code block]",0,0.986909806728363
81047544,1884,guozhangwang,2016-09-29T00:48:38Z,just fyi and i found the original while-loop may be the culprit of the recent unit test hanging issue.,0,0.9869083166122437
81155529,1884,enothereska,2016-09-29T14:52:59Z,so we still need to connect to zookeeper directly to do this verification? we can't get rid of the zk dependency in tests?,0,0.9794636964797974
81163558,1884,dguy,2016-09-29T15:25:40Z,it is a combination of that and auto topic creation,0,0.9861321449279785
84377963,1884,guozhangwang,2016-10-20T21:18:21Z,"can we merge these two functions `filterexistingtopics` and `gettopicstobedeleted` into a single one, or just in-line this logic in the `makeready` function as this seems specific in the internaltopicmanager, not in the kafkaclient.",0,0.9876362681388855
84378019,1884,guozhangwang,2016-10-20T21:18:43Z,this function seems not used any more.,0,0.8884263038635254
84378082,1884,guozhangwang,2016-10-20T21:19:06Z,ditto below.,0,0.9339895248413086
84378389,1884,guozhangwang,2016-10-20T21:21:11Z,this can be private.,0,0.9870530962944031
84378437,1884,guozhangwang,2016-10-20T21:21:27Z,not used any more.,-1,0.6698982119560242
84378526,1884,guozhangwang,2016-10-20T21:22:03Z,not used any more.,-1,0.6698982119560242
84378580,1884,guozhangwang,2016-10-20T21:22:22Z,the function name needs to be updated to `createtopics`.,0,0.9830058217048645
84379587,1884,guozhangwang,2016-10-20T21:28:19Z,"do we want to use the same value for `networkclient.poll()` timeout, and as well as the timeout value of `create/deletetopic` requests? in addition the `max_wait_time_ms` is 30 seconds which is even lower than the default value of timeout, so it is likely that the `client.poll()` will not return even when `max_wait_time_ms` has elapsed.",0,0.9871864318847656
84737925,1884,hjafarpour,2016-10-24T17:24:12Z,pushed a new version with the updates you mentioned.,0,0.9823322892189026
94757625,1884,ijuma,2017-01-05T12:12:49Z,we should not add this file back. we removed it intentionally.,0,0.6715178489685059
94757650,1884,ijuma,2017-01-05T12:13:06Z,we should not add this file back. we removed it intentionally.,0,0.6715178489685059
94757707,1884,ijuma,2017-01-05T12:13:39Z,is this dependency still needed? the comment seemed to imply that it wasn't.,0,0.9322790503501892
94758189,1884,ijuma,2017-01-05T12:17:50Z,"instead of instantiating `systemtime`, `time.system` should be used. same applies for other instances where we are creating `systemtime` instances.",0,0.9885631799697876
95036491,1884,guozhangwang,2017-01-06T23:04:12Z,i think `jackson` is not needed either since it was only for json parsing.,0,0.9885730743408203
95036696,1884,guozhangwang,2017-01-06T23:06:15Z,you mean we should just inline this class inside `streampartitionassignor`? personally i feel that class is already quite large and the functionalities in this class is self-contained.,0,0.8853411078453064
95036764,1884,guozhangwang,2017-01-06T23:06:53Z,can be private.,0,0.9845724105834961
95036888,1884,guozhangwang,2017-01-06T23:08:00Z,better add a log entry here since otherwise the error message in `streamsexception` will never be shown anywhere.,0,0.9856477975845337
95037077,1884,guozhangwang,2017-01-06T23:09:48Z,can we just inline this function in the other `makeready` since its only caller is the other function?,0,0.9889549016952515
95037147,1884,guozhangwang,2017-01-06T23:10:18Z,can be private.,0,0.9845724105834961
95037232,1884,guozhangwang,2017-01-06T23:11:02Z,"why not catch exceptions thrown here as well? also we should move it as well as the metadata fetching requests (line 60 - 63) inside the retry block as well since each time we retry, the metadata may have changed, right?",0,0.9879195690155029
95037434,1884,guozhangwang,2017-01-06T23:13:04Z,nit: this line not needed.,0,0.9796985387802124
95038339,1884,guozhangwang,2017-01-06T23:22:14Z,"i think this is not a good pattern, since afaik unlike the other clients the only `throwable` is actually `ioexception` (your error message also indicates that doesn't it :p `kafkastreamclient`), and it is only thrown from the metricsreporter.close(), capturing all throwable may hide some issues. instead, we can just let `internaltopicmanager.close()` to capture and log if there is any `ioexception` and not throw it all the way here.",0,0.9545638561248779
95038406,1884,guozhangwang,2017-01-06T23:22:46Z,could you reply to this comment as well?,0,0.9851886034011841
95038495,1884,guozhangwang,2017-01-06T23:23:42Z,btw i think this class will eventually be merged into o.a.k.common admin package when kip-4 is completed. cc,0,0.9760260581970215
95039652,1884,hjafarpour,2017-01-06T23:35:28Z,deleted the file!,0,0.9087204933166504
95039666,1884,hjafarpour,2017-01-06T23:35:37Z,deleted the file.,0,0.892288088798523
95039719,1884,hjafarpour,2017-01-06T23:35:59Z,"removed the line ""compile libs.jacksondatabind"".",0,0.9858657121658325
95039868,1884,hjafarpour,2017-01-06T23:37:29Z,replaced it with time.system.,0,0.9842250347137451
95040218,1884,hjafarpour,2017-01-06T23:41:29Z,done!,0,0.514024555683136
95040389,1884,hjafarpour,2017-01-06T23:43:19Z,good point! moved all in the try/catch block.,1,0.9869804978370667
95040644,1884,ijuma,2017-01-06T23:46:09Z,", yeah, we will have to refactor it to make it more generic, but good to have non-test code using the protocol. :)",1,0.9811561107635498
95040864,1884,hjafarpour,2017-01-06T23:48:44Z,added a log message.,0,0.9869759678840637
95041682,1884,hjafarpour,2017-01-06T23:57:25Z,handling the io exception in internaltopicmanager.close() now.,0,0.9885172843933105
95678659,1884,xvrl,2017-01-11T21:42:16Z,"this breaks backwards compatibility. until now streams did not delete existing topics. until streams offers a way to configure partition count and min.isr for internal topics, it should never attempt to delete topics. even then it might be dangerous to delete existing topics without warning.",0,0.8275474905967712
95980233,1884,enothereska,2017-01-13T11:34:33Z,i noticed this path is gone from the new code.,0,0.9694418907165527
96026577,1884,guozhangwang,2017-01-13T16:38:25Z,"i thought wrote it down on the kip wiki but seems he's not, we discussed about this issue while proposing kip-90. the problem is that even in the case that existing number of partitions is less than expected, we can not safely add partitions and reuse the existing ones for repartition topics or changelog topics, due to hashing.",0,0.9566670656204224
96035255,1884,mjsax,2017-01-13T17:27:38Z,this is an issue that we did miss. :(,-1,0.9905605912208557
203197427,5379,stanislavkozlovski,2018-07-17T22:08:12Z,"`scrammessages`'s value regex is `""[\\x01-\\x7f&&[^,]]+""`. i tried using it but could not get my tests to pass. to be frank, i don't understand it at all. specifically the `&&[^,]` part. [a link] says but i doubt that that is the case, otherwise i think scram would not work as well. is this some feature in the java regex engine i'm not familiar with?",0,0.7520338892936707
203203016,5379,stanislavkozlovski,2018-07-17T22:34:53Z,"i kind of want to have this in a more general space where every saslclient will have this code. an idea could be extend the saslclient interface and provide this default method, or move it to some utils resource. i'm not sure if it is worth the effort.",0,0.7539165019989014
204061226,5379,rondagostino,2018-07-20T14:23:35Z,"is the returned map supposed to be modifiable or unmodifiable? the default value (set via collections.emptymap) is unmodifiable. but if someone sets the map it isn't copied, so whether it will be modifiable or unmodifiable is non-deterministic. i think it would be best to state in the javadoc that the returned map is always unmodifiable, and when setting the map the input map should be copied and wrapped so as to be unmodifiable.",0,0.9842260479927063
204063618,5379,rondagostino,2018-07-20T14:30:45Z,"i would be careful to state that ""you can also add custom unsecured sasl extensions when using the default, builtin{ authenticatecallbackhandler} implementation using..."" because it is really the authenticatecallbackhandler instance that determines what kinds of callbacks are supported rather than this class itself.",0,0.986404538154602
204066800,5379,rondagostino,2018-07-20T14:40:10Z,"the token and the extensions must not be added until commit() is called as per the jaas specification. i would add a field ""extensionsrequiringcommit"" to mirror how the token is handled between the login() and commit() methods. also, note that this loginmodule supports calling commit() when the subject is shared with another instance of this class associated with a separate logincontext and that other instance has not yet had its logout() method called (see the last paragraph of the javadoc for details). you will need to support this for the extensions as well as for the token. you can mirror the existing code for the token and treat the extensions the same way. failure to do this will result in the extensions being deleted from the subject when the original logincontext has its logout() method called.",0,0.9848412871360779
204068531,5379,rondagostino,2018-07-20T14:45:35Z,"also, i am wondering if maybe we shouldn't simply attach a map to the public credentials but should instead attach something more precise and fit-for-purpose. the reason is because once we attach a map we can't ever use a map on the public credentials again; if we wanted to attach something else in the future it could not implement map. map is very broad and limits flexibility in the future. i am wondering if we should make the saslextensions class part of the public api and make it immutable. then we can attach an instance of that class specifically rather than just a map and we don't constrain ourselves going forward. what do you think? saslextensionscallback would return a saslextensions instance instead of a map if we decide to do this, and it also removes the confusion about the modifiability/immutabililty of what saslextensionscallback actually returns -- it will always be immutable.",0,0.8656564354896545
204070121,5379,rondagostino,2018-07-20T14:50:10Z,copy the map and store it immutably?,0,0.9858996272087097
204071530,5379,rondagostino,2018-07-20T14:54:20Z,don't need both properties and saslextension -- probably just saslextensions.,0,0.9807385802268982
204073705,5379,rondagostino,2018-07-20T15:00:49Z,please update javadoc for the class to also state that the instance of { authenticatecallbackhandler} can optionally handle an instance of { saslextensionstokencallback} to return any extensions generated by the { login()} event on the { logincontext}.,0,0.9877997636795044
204074321,5379,rondagostino,2018-07-20T15:02:43Z,typically catch exception rather than throwable since error generally should not be caught as it denots an event that the code can't really do anything about.,0,0.9796581268310547
204074903,5379,rondagostino,2018-07-20T15:04:34Z,is there a reason to return the callback? i would think the calling code is interested in the extensions themselves rather than the callback.,0,0.9859043955802917
204075829,5379,rondagostino,2018-07-20T15:07:37Z,please update javadoc to state that this class also recognizes { saslextensionscallback} and retrieves any sasl extensions that were created when the { oauthbearerloginmodule} logged in by looking for an instance of { map} in the { subject}'s public credentials. (or an instance of saslextensions rather than a map if we decide to make saslextensions part of the public api),0,0.9874637126922607
204076627,5379,rondagostino,2018-07-20T15:10:19Z,"can you name this in the same way as handlecallback(oauthbearertokencallback) -- i.e. handlecallback(saslextensionscallback)? unless there is a reason to do it differently? maybe you are foreshadowing a move of the method onto the oauthbearerloginmodule class at some point? if so, then maybe make the method static, name it handlecallback(), and make the handlecallback(oauthbearertokencallback) symmetric by also accepting a subject parameter? i think there is value in making the two methods look very much the same except for the type of callback they accept, so whichever you decide let's make them look the same as much as possible.",0,0.9856627583503723
204080059,5379,rondagostino,2018-07-20T15:21:26Z,"it is possible that the extensions could be set and then the process() method either returns an error response to the client or throws an exception. it probably isn't too much of an issue if this happens, but best to set the extensions at the same point where tokenfornegotiatedproperty is set, so probably should add the extensions as a new parameter on the process() call.",0,0.9860572814941406
204082009,5379,rondagostino,2018-07-20T15:27:35Z,"probably good to state above ""a { callbackhandler} that recognizes { oauthbearertokencallback} to return an unsecured oauth 2 bearer token and { saslextensionscallback} to return sasl extensions.""",0,0.9475824236869812
204088230,5379,stanislavkozlovski,2018-07-20T15:47:49Z,should be unmodifiable come to think of it. updated docs and code,0,0.981549859046936
204088701,5379,stanislavkozlovski,2018-07-20T15:49:24Z,agreed,0,0.9622963666915894
204091548,5379,stanislavkozlovski,2018-07-20T15:59:31Z,that would be the best approach i think. i also found this way non-ideal but decided to stick with the implementation as with `scramextensions`,0,0.9372235536575317
204093826,5379,stanislavkozlovski,2018-07-20T16:07:19Z,i see. thanks for the clarification,1,0.9529672861099243
204099967,5379,stanislavkozlovski,2018-07-20T16:29:38Z,"you're right, even the method name implies you get the extensions",0,0.9724540114402771
204100861,5379,stanislavkozlovski,2018-07-20T16:33:10Z,i wanted to document the code via more explicit names,0,0.9826276898384094
204101263,5379,stanislavkozlovski,2018-07-20T16:34:38Z,good catch,1,0.9703027606010437
204110927,5379,rajinisivaram,2018-07-20T17:11:42Z,"yes, it makes sense. we currently use `map` for delegation tokens extension for scram. since we are only adding custom extensions to oauth in this kip, perhaps we should add `saslextensionscallback` and `saslextensionscallbackhandler` in `org.apache.kafka.common.security.auth` and use it only for `oauth` for now. for scram, we should probably stick to the `map` for now, but we could have the interfaces extend the public interface. what do you think?",0,0.9774930477142334
204136508,5379,rondagostino,2018-07-20T18:43:20Z,"agreed, we can focus on oauthbearer for now, take the right steps (adding 2 classes to the public api instead of just the callback class), and start to leverage the added public api classes in other mechanisms (i.e. scram-related) if/when the time seems right. i am less familiar with the scram-related code, so i defer to whatever/whenever you feel is best.",0,0.9753678441047668
204138659,5379,stanislavkozlovski,2018-07-20T18:51:36Z,why should we not change scram? was the delegation token publicly accessible and that would break? i feel like we should change it outright if we can,0,0.6854438781738281
204139145,5379,rondagostino,2018-07-20T18:53:16Z,"this is the only place where the separator field is used, and i'm not clear on the semantics of this method. i think maybe the separator field can be dropped and eliminate that parameter from the constructor that takes a map?",0,0.971181333065033
204140072,5379,rondagostino,2018-07-20T18:56:56Z,make unmodifiable via collections.emptymap(),0,0.9803088903427124
204140395,5379,rondagostino,2018-07-20T18:58:19Z,javadoc on public api classes and their methods is very helpful,1,0.6452943682670593
204140849,5379,rondagostino,2018-07-20T19:00:23Z,should this constructor accept the same parameters as utils.parsemap()?,0,0.9884412288665771
204141019,5379,rondagostino,2018-07-20T19:01:03Z,probably remove separator parameter (and the field) as mentioned below,0,0.9870604276657104
204141410,5379,rondagostino,2018-07-20T19:02:49Z,might want to add an extensionentries() method that returns a map.entry,0,0.9882735013961792
204142058,5379,rondagostino,2018-07-20T19:05:23Z,"probably no need to make a copy since the map is unmodifiable; javadoc can say it returns an unmodifiable map view of the extensions. this raises the question of whether all of the map-related methods isempty(), extensionnames(), extensionentries(), and extensionvalue() are actually needed. if returning the map is cheap -- which it would be -- then all of those methods feel like clutter rather than good api additions. what do you think?",0,0.9650822877883911
204142539,5379,rondagostino,2018-07-20T19:07:43Z,i'm not sure this method needs to exist. if someone want to parse a string and get a map they can either call utils.parsemap() directly or they can construct an instance of this class and call extensionsmap() on it.,0,0.9500485062599182
204142913,5379,rondagostino,2018-07-20T19:09:31Z,i think this class should accept and return instances of saslextensions rather than a map now that saslextensions is part of the public api.,0,0.9877304434776306
204143400,5379,rondagostino,2018-07-20T19:11:45Z,is there a reason why we shouldn't always use saslextensions rather than map?,0,0.9640094637870789
204143672,5379,rajinisivaram,2018-07-20T19:13:00Z,"for this kip, i think we should do one of these: 1. implement custom extensions for oauthbearer alone, but add common callback classes to enable reuse for other mechanisms in future. this means leaving scram alone. 2. support custom extensions for both scram and oauthbearer, changing the delegation token mechanism to use the custom extensions code path treating `token` as a property in the map. i don't think we should do a half-change for scram, changing a public contract without actually providing a good reason to do so (i.e. change the way extensions are propagated without supporting custom extensions). does that make sense?",0,0.9695602059364319
204144544,5379,rondagostino,2018-07-20T19:16:39Z,i think this will end up being `extensions == mycommitedextensions` ?,0,0.9863302111625671
204144759,5379,rondagostino,2018-07-20T19:17:38Z,same -- use saslextensions instead of map?,0,0.9888166189193726
204157244,5379,stanislavkozlovski,2018-07-20T20:11:28Z,nope - [a link],0,0.982451856136322
204157659,5379,stanislavkozlovski,2018-07-20T20:13:12Z,actually - no. my bad,-1,0.9872835874557495
204158880,5379,stanislavkozlovski,2018-07-20T20:18:23Z,fair enough - i figured to have it there for the sake of completeness,0,0.8807986378669739
204159227,5379,stanislavkozlovski,2018-07-20T20:19:54Z,"is it bad to have it, even if unused in code (only tested)?",-1,0.7966172099113464
204159567,5379,rondagostino,2018-07-20T20:21:20Z,"yeah, the use of == instead of .equals() is certainly unusual, but it is necessary in this case because we need to make sure we remove our instance as opposed to an instance put there via another logincontext. i did not comment it when i did it for the token but should have given that it is unusual.",0,0.8184586763381958
204160970,5379,stanislavkozlovski,2018-07-20T20:27:27Z,i find they're still useful to keep. it's always good to abstract away the implementation behind an interface in my opinion,1,0.5570956468582153
204164892,5379,rondagostino,2018-07-20T20:45:33Z,"good question. the biggest mistake i made in doing this oauthbearer implementation was trying to do too much. the community reigned me in over time :-) my guess would be to keep things as simple and minimalistic as possible; there is less that can go wrong, less to debate over/review/test/fix, and ultimately a shorter time to when the code actually gets merged. at least that's the lesson i took from the experience.",1,0.9638491868972778
204165198,5379,stanislavkozlovski,2018-07-20T20:47:07Z,agreed and done,0,0.9656398296356201
204165223,5379,stanislavkozlovski,2018-07-20T20:47:15Z,done,0,0.9764507412910461
204165380,5379,stanislavkozlovski,2018-07-20T20:48:02Z,that's true in general. i honestly believe this is a useful constructor to have though,0,0.6211146712303162
204165803,5379,stanislavkozlovski,2018-07-20T20:50:01Z,is there a need to explicitly make it unmodifiable since `extensionsmap()` returns an unmodifiable version? come to think of it - maybe the other constructors shouldn't make it unmodifiable as well,0,0.9752655625343323
204498442,5379,rondagostino,2018-07-23T17:55:21Z,"should be ""check whether your callback **handler** is explicitly...""",0,0.9830467104911804
204499789,5379,rondagostino,2018-07-23T17:59:35Z,"need to also state: ""the { oauthbearerloginmodule} instance also asks its configured { authenticatecallbackhandler} implementation to handle an instance of { saslextensionscallback} and return an instance of { saslextensions}. the configured callback handler does not need to handle this callback, though -- any { unsupportedcallbackexception} that is thrown is ignored, and no sasl extensions will be associated with the login.""",0,0.9873716831207275
204500558,5379,rondagostino,2018-07-23T18:02:11Z,"this method doesn't actually attach the token -- it identifies the token that should be attached if/when commit() is called. the method needs a better name. maybe ""identifytoken()""?",0,0.9848619699478149
204500716,5379,rondagostino,2018-07-23T18:02:31Z,same here -- need a better method name (and also update javadoc) to reflect the fact that it is identifying the extensions that should be attached if/when commit() is called.,0,0.9872683882713318
204501651,5379,rondagostino,2018-07-23T18:05:39Z,should be == so we know it is literally the instance we committed,0,0.9808202981948853
204502047,5379,rondagostino,2018-07-23T18:07:11Z,this check is unnecessary; extensionsrequiringcommit cannot be null if tokenrequiringcommit is non-null.,0,0.9788075685501099
204505373,5379,rondagostino,2018-07-23T18:17:50Z,"this isn't actually parsing the custom extensions; it is retrieving the ones that have already been parsed and stored somewhere. it needs a better name. maybe ""retrieveextensions()""?",0,0.9803682565689087
204506803,5379,rondagostino,2018-07-23T18:22:20Z,"we need to make sure the ""auth"" key isn't defined here since that is generated from the token's compact serialization. should also add to the javadoc above that all token keys that meet the regex criteria are valid except ""auth"".",0,0.9888305068016052
204507438,5379,rondagostino,2018-07-23T18:24:12Z,attaches the first saslextensions (not map anymore),0,0.9893452525138855
204507634,5379,rondagostino,2018-07-23T18:24:52Z,can add static modifier since it doesn't refer to anything in the instance,0,0.9880181550979614
204509972,5379,rondagostino,2018-07-23T18:32:13Z,stylistically it is better to write it as `this.saslextensions = validateextensions(extensions)` (and of course make that method return the extensions passed in if an exception is not raised).,0,0.9885009527206421
204510197,5379,rondagostino,2018-07-23T18:32:52Z,"make it return the extensions as per above, and also throw an exception if the ""auth"" extension is specified.",0,0.9874918460845947
204512923,5379,rondagostino,2018-07-23T18:41:53Z,`this.saslextensions = validateextensions(new saslextensions(properties))`,0,0.9869417548179626
204513594,5379,rondagostino,2018-07-23T18:44:17Z,i actually think this method is no longer needed.,0,0.9702066779136658
204513736,5379,rondagostino,2018-07-23T18:44:43Z,can/should delete this method as per above.,0,0.9848971962928772
204514223,5379,rondagostino,2018-07-23T18:46:18Z,"is this constructor ever used? if not, probably best to eliminate it; if it is used, then it should invoke `extensionsmap = collections.emptymap()`",0,0.9876853227615356
204515380,5379,rondagostino,2018-07-23T18:49:54Z,this method is not needed since map() is an inexpensive call; anybody wanting an extension value can simply call `thesaslextensions.map().get(thename)`.,0,0.9876532554626465
204515582,5379,rondagostino,2018-07-23T18:50:28Z,same here -- unnecessary method due to the ability to invoke `thesaslextensions.map().keyset()`,0,0.9794435501098633
204515709,5379,rondagostino,2018-07-23T18:50:57Z,same here -- unnecessary method due to the ability to invoke `thesaslextensions.map().isempty()`,0,0.9760035276412964
204517898,5379,rondagostino,2018-07-23T18:58:09Z,"since the isgssapi variable is only used to determine if we should return, why not just this? `if (saslconfigs.gssapi_mechanism.equals(mechanism)) return; // extensions are not supported for gssapi`",0,0.9843361377716064
204518784,5379,rondagostino,2018-07-23T19:01:10Z,"""auth"" is not allowed.",0,0.9023621082305908
204532330,5379,stanislavkozlovski,2018-07-23T19:50:05Z,could you elaborate on why this should be the case? i tend to agree but cannot explicitly define why that's better - maybe it's just more obvious?,0,0.9317121505737305
204534985,5379,stanislavkozlovski,2018-07-23T20:00:08Z,should i? what do we win by that - it's private.,0,0.9223154783248901
204535795,5379,stanislavkozlovski,2018-07-23T20:03:04Z,sure,0,0.9371067881584167
204537047,5379,stanislavkozlovski,2018-07-23T20:07:42Z,"no, it's not. i kept it since i did not call `super(map)` in `scramextensions` which should not have been the case",0,0.9769728183746338
204542803,5379,stanislavkozlovski,2018-07-23T20:27:04Z,"i agree with the others but for this most common use case i propose we keep the method name. it is shorter and more concise to write. also reads better than `map().get(thename)`. glancing at `extensionvalue` you immediately understand what we're taking - in the other way, it's still obvious but not as much",0,0.9486213326454163
204545192,5379,stanislavkozlovski,2018-07-23T20:35:00Z,done,0,0.9764507412910461
204557034,5379,rajinisivaram,2018-07-23T21:18:22Z,`should be attached` => `may be added`,0,0.9854663610458374
204557800,5379,rajinisivaram,2018-07-23T21:21:10Z,why was this change made? i think the single `if` statement is better than returning here.,0,0.9806097149848938
204558311,5379,rajinisivaram,2018-07-23T21:23:16Z,"same as before - check the mechanism in the `if` statement below. also, i think we could check for scram mechanism in the check above and check for oauthbearer here.",0,0.9884020686149597
204562743,5379,rajinisivaram,2018-07-23T21:40:24Z,make this `private final`?,0,0.9876678586006165
204563236,5379,rajinisivaram,2018-07-23T21:42:27Z,personally i think we s should create a copy of the map.,0,0.9814762473106384
204563539,5379,rajinisivaram,2018-07-23T21:43:45Z,"personally, i would get rid of this and use `extensionvalue` and `extensionnames`. otherwise, as said below, we should remove `extensionvalue`.",0,0.9876366257667542
204564358,5379,rajinisivaram,2018-07-23T21:46:58Z,"i thought we weren't supporting `saslextensionscallback` for scram. we should either update `scramsaslclient` to process `saslextensions` and add tests for that or not deprecate this now. in any case, i am not sure why the javadoc was removed.",0,0.932402491569519
204565761,5379,rajinisivaram,2018-07-23T21:52:51Z,make `final`?,0,0.9864610433578491
204567218,5379,stanislavkozlovski,2018-07-23T21:59:13Z,doesn't `new hashmap<>(extensionsmap)` do exactly that?,0,0.982204258441925
204567896,5379,stanislavkozlovski,2018-07-23T22:02:02Z,"it would then require its initialized on the spot or in the constructor. the appropriate callback handler initializes it using `#extensions(...)`, so making it `final` wouldn't work",0,0.9845924973487854
204569668,5379,stanislavkozlovski,2018-07-23T22:10:29Z,"`oauthbearerclientinitialresponse` uses this to iterate over all values and build the extensions string using `utils.mkstring`. if we removed `map()`, we would need to iterate through `extensionnames`, fetch and validate each value one by one. we would also need to rebuild the map in `#extensionsmessage()` so that we could call `utils.mkstring`. this is all more complex to write and slower to execute, thus i believe we should keep `map()`. i do not understand what is inherently wrong with having an `extensionvalue` method. it keeps it consistent with `scramextensions`' usage, does not bloat the api (it's a single method) and offers a more concise and readable way to fetch a value from the extensions. can you elaborate why you believe we should remove `extensionvalue()` ?",0,0.9746135473251343
204570041,5379,stanislavkozlovski,2018-07-23T22:12:32Z,it's `protected` so `scramextensions` can have access to it. i made it `final` now,0,0.9844450354576111
204570220,5379,stanislavkozlovski,2018-07-23T22:13:25Z,"come to think of it, i'll outright remove `extensionnames` and use `map().keyset()`. did not realize `scramextensions` is not a public class",0,0.9764131903648376
204571187,5379,stanislavkozlovski,2018-07-23T22:18:34Z,removing the javadoc was a mistake. i will look into making `scramsaslclient` work with `saslextensions`. last time i tried some tests kept failing for a reason i could not debug even after significant effort. if it happens to be the case again i'll simply remove the deprecated tag,0,0.7004483342170715
204575201,5379,stanislavkozlovski,2018-07-23T22:39:32Z,personal preference. i find this more readable than a bigger if check. changed back to one `if` and now checking for the correct mechanism in each callback,0,0.9311808347702026
204575952,5379,stanislavkozlovski,2018-07-23T22:43:28Z,is this the correct way to check for the mechanism? i'm wondering why the previous code only checked for `!saslconfigs.gssapi_mechanism.equals(mechanism)` and not other mechanisms as well,0,0.9670692086219788
204583187,5379,rondagostino,2018-07-23T23:24:58Z,i agree with ; since we have map() there is no need to provide any shorthand methods for functionality that the return value of map() provides.,0,0.9778130054473877
204583275,5379,rondagostino,2018-07-23T23:25:33Z,probably a good idea to add tostring() as well.,0,0.6524461507797241
204584539,5379,rondagostino,2018-07-23T23:33:27Z,"the saslclient callback handler for the oauthbearer mechanism needs to handle oauthbearertokencallback as well as saslextensionscallback (with the last one optional, but the first one is definitely mandatory). if we are going to put this code here for oauthbearer then the only way the code is going to ever be invoked in a successful runtime scenario is if 1) we also add code to handle oauthbearertokencallback; and 2) somehow this class is set as the saslclient callback handler. (2) will happen if the config explicitly specifies this class, or, alternatively, we can delete the oauthbearersaslclientcallbackhandler class and make this class the default saslclient callback handler for the oauthbearer mechanism (that decision is made at line 330 of org.apache.kafka.common.network.saslchannelbuilder; that line would have to change). i'm okay with either migrating to a fully-functional (for oauthbearer) saslclientcallbackhandler class or deleting these lines; keeping them without also handling oauthbearertokencallback doesn't make sense, though.",0,0.9759795665740967
204585957,5379,rondagostino,2018-07-23T23:41:47Z,"sure. we want to remove the instance that we put there, so we use == instead of .equals(). the .equals() method may identify another instance rather than the one we added. frankly i don't think it would be a problem due to the existence of the `break` statement below, but if that `break` statement were to be removed for some reason then we would iterate through the entire collection and remove everything that satisfied .equals() -- and that could be multiple instances. so using `==` makes the semantics very clear and acts as an insurance policy at the same time.",0,0.8755279183387756
204586766,5379,rondagostino,2018-07-23T23:46:27Z,this needs to be `getpubliccredentials()` rather than `getpubliccredentials(saslextensions.class)` because the former returns the actual public credentials (see [a link] whereas the latter returns a new set that doesn't propagate changes through (see [a link].,0,0.9876712560653687
204588760,5379,rondagostino,2018-07-23T23:59:28Z,need to invoke `extensions = null` here as well.,0,0.9674094915390015
204589027,5379,rondagostino,2018-07-24T00:01:18Z,"need to state that the extension name must match th required regex but cannot be the reserved value ""auth"".",0,0.9787565469741821
204589338,5379,rondagostino,2018-07-24T00:03:42Z,probably a good idea to wrap in a try {} catch (kafkaexception e) {} block as is done above for the oauthbearertokencallback.,0,0.7732610702514648
204589592,5379,rondagostino,2018-07-24T00:05:17Z,"should be `extensions.put(extensionname, extensionvalue)`",0,0.9876783490180969
204595693,5379,stanislavkozlovski,2018-07-24T00:51:10Z,"i do not know what it should return, though",-1,0.5630683302879333
204595909,5379,stanislavkozlovski,2018-07-24T00:52:52Z,"oops, yes. this should not be here at all",-1,0.9681265950202942
204596760,5379,stanislavkozlovski,2018-07-24T01:00:26Z,that is a big gotcha! thanks!,1,0.9912870526313782
204597201,5379,stanislavkozlovski,2018-07-24T01:04:00Z,and just swallow the exception? i guess it boils down to: do we want to stop authentication on invalid extension value or just not use extensions?,0,0.9682165384292603
204599621,5379,rondagostino,2018-07-24T01:23:20Z,no need to check instanceof and cast it since `==` will return false if it isn't an instanceof. see line 331-338 above for what this should look like.,0,0.9869881868362427
204599894,5379,rondagostino,2018-07-24T01:25:53Z,is there a reason why this is protected and not private?,0,0.9468333125114441
204599996,5379,rondagostino,2018-07-24T01:26:29Z,`extensionsmap.tostring()` seems appropriate,0,0.9845805764198303
204600596,5379,rondagostino,2018-07-24T01:31:44Z,lines 344-347 are unnecessary; the statement `if (mycommittedextensions == credential)` will be correct regardless. see lines 332-333 above.,0,0.9879103899002075
204601020,5379,rondagostino,2018-07-24T01:35:15Z,probably should use `{ oauthbearerclientinitialresponse.auth_key}` instead of `{ oauthbearerclientinitialresponse.auth_key}`,0,0.987403392791748
204601155,5379,rondagostino,2018-07-24T01:36:22Z,"no, don't swallow, propagate it wrapped in an ioexception as is done a few lines up.",0,0.9850444793701172
204601217,5379,rondagostino,2018-07-24T01:36:48Z,`{` instead of `{`,0,0.9833083152770996
204601696,5379,rondagostino,2018-07-24T01:40:46Z,duplicate line,0,0.9678511619567871
204602098,5379,rondagostino,2018-07-24T01:44:07Z,why delete these comments?,0,0.8774963617324829
204602841,5379,rondagostino,2018-07-24T01:50:04Z,"i think what you want to do here is accept an array of saslextensions objects; if an array element is null then the handler would throw unsupportedcallbackexception on that iteration, otherwise it returns the element. this test is making sure the simultaneous login/logout functionality doesn't get confused. basically follow what is going on with the tokens and do the same thing with the saslextensions. you might need separate indexes for tokens and saslextensions (i.e. `tokenindex` instead of `index`, and then add `extensionsindex`)",0,0.9809849262237549
204603396,5379,rondagostino,2018-07-24T01:54:34Z,"same thing here; create an array of saslextensions mocks, one element of which should be null, etc.",0,0.9821791052818298
204603442,5379,rondagostino,2018-07-24T01:54:57Z,"same thing here; create an array of saslextensions mocks, one element of which should be null, etc.",0,0.9821791052818298
204603529,5379,rondagostino,2018-07-24T01:55:36Z,"same thing here; create an array of saslextensions mocks, one element of which should be null, etc.",0,0.9821791052818298
204603724,5379,rondagostino,2018-07-24T01:57:11Z,this test becomes unnecessary after weaving saslextensions into the above tests.,0,0.9731572866439819
204604012,5379,rondagostino,2018-07-24T01:59:30Z,"create an array of saslextensions mocks, one element of which should be null, etc.",0,0.9737279415130615
204604217,5379,rondagostino,2018-07-24T02:01:00Z,this test becomes unnecessary after weaving saslextensions into the above tests as long as you include at least one null element in the array for each one.,0,0.9834668040275574
204604435,5379,rondagostino,2018-07-24T02:02:51Z,why delete these 2 lines? can you just call `response.extensions().map().get()` instead of `response.propertyvalue()`?,0,0.9891497492790222
204604726,5379,rondagostino,2018-07-24T02:05:33Z,why delete this test? can you just call `response.extensions().map().get()` instead of `response.propertyvalue()`?,0,0.989240825176239
204605136,5379,rondagostino,2018-07-24T02:09:00Z,"indicate that ""auth"" is reserved and cannot be used.",0,0.9652601480484009
204672879,5379,rajinisivaram,2018-07-24T08:49:05Z,"sorry, my mistake.",-1,0.9877002239227295
204673218,5379,rajinisivaram,2018-07-24T08:50:14Z,"sorry, i was looking at the `unmodifiablemap` and didn't see the copy.",-1,0.9849811792373657
204673925,5379,rajinisivaram,2018-07-24T08:52:31Z,we should make this `private`.,0,0.9865784049034119
204674806,5379,rajinisivaram,2018-07-24T08:55:08Z,`scrammechanism.isscram(mechanism)`,0,0.9784249067306519
204676556,5379,rajinisivaram,2018-07-24T09:00:47Z,"in this line and the similar one for retrieving tokens, could we says `an internal error occurred while doing xxx`? also, perhaps `log.error(""error occurred while doing xxx"", e)`.",0,0.9865127801895142
204680030,5379,rajinisivaram,2018-07-24T09:11:57Z,looks like duplicate code. couldn't we just use one static `oauthbearerclientinitialresponse.validateextensions(map )` method for validation?,0,0.9848251938819885
204789092,5379,stanislavkozlovski,2018-07-24T14:54:13Z,i wrote a similar test (copied this one) to this that didn't make the pr. i must have deleted the comments from the wrong test in the end,0,0.9191607236862183
204795761,5379,stanislavkozlovski,2018-07-24T15:10:39Z,"no, we'd need this. the null element won't test out this backwards-compatible behavior",0,0.9826420545578003
204818374,5379,stanislavkozlovski,2018-07-24T16:09:58Z,i'll add the functionality and have one of the commit/login tests use it. i vote we keep the two tests i wrote - i don't see anything wrong with unit testing functionality in a more fine-grained way,0,0.9331918358802795
204819005,5379,stanislavkozlovski,2018-07-24T16:11:55Z,"yes. my bad, sorry",-1,0.9891662001609802
204821362,5379,stanislavkozlovski,2018-07-24T16:18:23Z,yes we can. this will result in a bit more complicated code in `oauthbearerunsecuredlogincallbackhandler#handleextensionscallback()` since it needs to unprefix the extensions first,0,0.9835379719734192
204907936,5379,rondagostino,2018-07-24T20:54:55Z,can mirror the way it is done for tokens just call `getpubliccredentials()` instead of `getpubliccredentials(saslextensions.class)`. this also eliminates the need to keep calling the method to calculate a new set -- the original set will always be accurate.,0,0.9873888492584229
205113394,5379,rondagostino,2018-07-25T13:44:17Z,can remove this line after making the change mentioned in line 127 above,0,0.9881129860877991
205114012,5379,rondagostino,2018-07-25T13:45:52Z,can remove this line after making the change mentioned in line 127 above,0,0.9881129860877991
205114191,5379,rondagostino,2018-07-25T13:46:17Z,can remove this line after making the change mentioned in line 127 above,0,0.9881129860877991
205114596,5379,rondagostino,2018-07-25T13:47:15Z,can remove this line after making the change mentioned in line 127 above,0,0.9881129860877991
205114906,5379,rondagostino,2018-07-25T13:48:03Z,can remove this line after making the change mentioned in line 127 above,0,0.9881129860877991
205115117,5379,rondagostino,2018-07-25T13:48:34Z,can remove this line after making the change mentioned in line 127 above,0,0.9881129860877991
205115297,5379,rondagostino,2018-07-25T13:49:00Z,can remove this line after making the change mentioned in line 127 above,0,0.9881129860877991
205115775,5379,rondagostino,2018-07-25T13:50:16Z,same as above -- can mirror the way it is done for tokens just call getpubliccredentials() instead of getpubliccredentials(saslextensions.class). this also eliminates the need to keep calling the method to calculate a new set -- the original set will always be accurate.,0,0.9863472580909729
205116317,5379,rondagostino,2018-07-25T13:51:35Z,"saslextensions array length should be the same as token array length -- 2, not 3.",0,0.9876059293746948
205116655,5379,rondagostino,2018-07-25T13:52:19Z,can remove this line after making the change mentioned in line 230 above,0,0.9878119826316833
205116789,5379,rondagostino,2018-07-25T13:52:38Z,can remove this line after making the change mentioned in line 230 above,0,0.9878119826316833
205116910,5379,rondagostino,2018-07-25T13:52:57Z,can remove this line after making the change mentioned in line 230 above,0,0.9878119826316833
205117003,5379,rondagostino,2018-07-25T13:53:12Z,can remove this line after making the change mentioned in line 230 above,0,0.9878119826316833
205117091,5379,rondagostino,2018-07-25T13:53:28Z,can remove this line after making the change mentioned in line 230 above,0,0.9878119826316833
205117236,5379,rondagostino,2018-07-25T13:53:49Z,can remove this line after making the change mentioned in line 230 above,0,0.9878119826316833
205117560,5379,rondagostino,2018-07-25T13:54:33Z,same as above -- can mirror the way it is done for tokens just call getpubliccredentials() instead of getpubliccredentials(saslextensions.class). this also eliminates the need to keep calling the method to calculate a new set -- the original set will always be accurate.,0,0.9863472580909729
205118094,5379,rondagostino,2018-07-25T13:56:01Z,can remove this line after making the change mentioned in line 296 above,0,0.9877674579620361
205118194,5379,rondagostino,2018-07-25T13:56:16Z,can remove this line after making the change mentioned in line 296 above,0,0.9877674579620361
205118319,5379,rondagostino,2018-07-25T13:56:38Z,can remove this line after making the change mentioned in line 296 above,0,0.9877674579620361
205118397,5379,rondagostino,2018-07-25T13:56:50Z,can remove this line after making the change mentioned in line 296 above,0,0.9877674579620361
205118520,5379,rondagostino,2018-07-25T13:57:08Z,can remove this line after making the change mentioned in line 296 above,0,0.9877674579620361
205118748,5379,rondagostino,2018-07-25T13:57:43Z,same as above -- can mirror the way it is done for tokens just call getpubliccredentials() instead of getpubliccredentials(saslextensions.class). this also eliminates the need to keep calling the method to calculate a new set -- the original set will always be accurate.,0,0.9863472580909729
205119069,5379,rondagostino,2018-07-25T13:58:29Z,can remove this line after making the change mentioned in line 353 above,0,0.9878694415092468
205119183,5379,rondagostino,2018-07-25T13:58:45Z,can remove this line after making the change mentioned in line 353 above,0,0.9878694415092468
205119367,5379,rondagostino,2018-07-25T13:59:11Z,can remove this line after making the change mentioned in line 353 above,0,0.9878694415092468
205119483,5379,rondagostino,2018-07-25T13:59:29Z,can remove this line after making the change mentioned in line 353 above,0,0.9878694415092468
205119824,5379,rondagostino,2018-07-25T14:00:16Z,can remove this line after making the change mentioned in line 353 above,0,0.9878694415092468
205119994,5379,rondagostino,2018-07-25T14:00:41Z,can remove this line after making the change mentioned in line 353 above,0,0.9878694415092468
205120125,5379,rondagostino,2018-07-25T14:00:59Z,can remove this line after making the change mentioned in line 353 above,0,0.9878694415092468
205120889,5379,rondagostino,2018-07-25T14:02:54Z,i believe this test adds no value and should be eliminated because the case is covered above.,0,0.9592942595481873
205122848,5379,rondagostino,2018-07-25T14:08:10Z,this test is checking the same thing that was checked via passing in raise_unsupported_cb_exception_flag (null) at line 133 and checking for empty_extensions at lines 191 and 200. this test should be deleted.,0,0.985444962978363
205125175,5379,rondagostino,2018-07-25T14:14:12Z,`collections.emptymap()` instead of `new hashmap<>()`,0,0.9867814183235168
205125573,5379,rondagostino,2018-07-25T14:15:07Z,"oops, delete this unintended change",-1,0.8441168069839478
205178909,5379,stanislavkozlovski,2018-07-25T16:33:59Z,"hm, that is strange. i initially went with this approach (obviously sprinkling `getpubliccredentials()` before every assert is bad) but hit some problem. i assumed that the public credentials had another value in them and changed the test with what you just reviewed. the test passed afterwards so i didn't go into investigating what the problem was. now that i removed the calls, test still pass. i'm not sure what i initially missed there",-1,0.9473893642425537
205185439,5379,stanislavkozlovski,2018-07-25T16:55:30Z,"sorry about my initial comment of ""no, we'd need this. the null element won't test out this backwards-compatible behavior"". i unfortunately commented prematurely before completely understanding your suggestion. i acknowledge that this is verified in the above tests. it's just that from what i've read from tdd books, the overall approach experts recommend is to rely on single, small tests that test concrete functionality. this way, when a problem occurs you immediately know what the cause is - `commitpopulatesextensions` - oh, my extensions weren't populated. where as if you get an error in test `login1commit1login2abort2login3commit3logout3` you need to investigate the test well and figure out where the problem is. while such big tests are always useful, i believe a test suite comprised of more smaller tests is better. tests comprised of more methods serve as better documentation. you can then just read the method names and get a general feeling of what the tested subject should do. please share your thoughts on this",-1,0.9862530827522278
205185773,5379,stanislavkozlovski,2018-07-25T16:56:38Z,"take a look at my comment below for test `commitdoesnotthrowonunsupportedextensionscallback`. i do not feel as strongly about this test as i feel on the one below, but i also tentatively think it doesn't hurt to have one more test",-1,0.6451302766799927
205197478,5379,rondagostino,2018-07-25T17:32:48Z,"still need this adjusted: saslextensions array length should be the same as token array length -- 2, not 3.",0,0.989403486251831
205198355,5379,rondagostino,2018-07-25T17:35:34Z,"i agree with your point below about lots of simple tests being better than one big one. let's eliminate the null value here, replace it with a mock, and rely on your test below to verify that unhandledcallbackexception is ignored.",0,0.9688745737075806
205198824,5379,rondagostino,2018-07-25T17:37:01Z,"yes, let's eliminate this one and keep the one below.",0,0.9828316569328308
205199240,5379,rondagostino,2018-07-25T17:38:17Z,good point -- i agree. let's keep this test and eliminate the null value in `login1commit1login2abort2login3commit3logout3`.,1,0.9102990627288818
207815285,5379,rajinisivaram,2018-08-06T08:47:03Z,can you move the link to the next line and include the full name including package since that class has not been imported in this class: `{ org.apache.kafka.common.security.oauthbearer.internals.oauthbearerclientinitialresponse#auth_key}`,0,0.9852511882781982
207818595,5379,rajinisivaram,2018-08-06T08:58:44Z,"was like this earlier, but will be good to update anyway. `string.format` not required. could use: `log.info(""login failed {} : {} (uri={}"",....`",0,0.928543746471405
207819149,5379,rajinisivaram,2018-08-06T09:00:41Z,"`log.info(""callbackhandler {} does not support..."", callbackhandler.getclass().getname())`?",0,0.9873586297035217
207819502,5379,rajinisivaram,2018-08-06T09:02:03Z,we could have a constant like `empty_extensions` for this case?,0,0.9889922142028809
207820729,5379,rajinisivaram,2018-08-06T09:06:27Z,"now that we can use java8, we could use `removeif` here and in the block above for tokens? [code block]",0,0.9877555966377258
207822201,5379,rajinisivaram,2018-08-06T09:12:06Z,`{ oauthbearerclientinitialresponse.auth_key}` => `{ oauthbearerclientinitialresponse#auth_key}`,0,0.9818280339241028
207822476,5379,rajinisivaram,2018-08-06T09:13:06Z,`get` => `containskey`?,0,0.989033579826355
207824202,5379,rajinisivaram,2018-08-06T09:19:09Z,`oauthbearerclientinitialresponse.auth_key` => oauthbearerclientinitialresponse#auth_key,0,0.9816840291023254
207824332,5379,rajinisivaram,2018-08-06T09:19:34Z,`oauthbearerclientinitialresponse.auth_key` => `oauthbearerclientinitialresponse#auth_key`,0,0.9800260066986084
207827945,5379,rajinisivaram,2018-08-06T09:31:55Z,could just use `collections.emptymap()` here since type can be inferred?,0,0.9890122413635254
207830135,5379,rajinisivaram,2018-08-06T09:39:45Z,`static final`?,0,0.9873687624931335
207841511,5379,rajinisivaram,2018-08-06T10:20:11Z,`values` => `value`?,0,0.9875972867012024
207842331,5379,rajinisivaram,2018-08-06T10:23:43Z,not used?,0,0.9662325978279114
207842366,5379,rajinisivaram,2018-08-06T10:23:51Z,not used?,0,0.9662325978279114
207859716,5379,stanislavkozlovski,2018-08-06T11:32:50Z,that is very cool,1,0.9840976595878601
38921717,191,ijuma,2015-09-08T12:59:25Z,"we should probably use 2.7.1, right?",0,0.9829283356666565
38921790,191,ijuma,2015-09-08T13:00:12Z,indenting doesn't look right in the new `allow` lines.,0,0.8276236653327942
38923719,191,ijuma,2015-09-08T13:20:24Z,is the current plan not to support `auth-int` and `auth-conf` qops?,0,0.979304313659668
38924187,191,ijuma,2015-09-08T13:25:00Z,what is this change for? `maxfdlimit` seems to be a deprecated flag ([a link],0,0.9813656806945801
38924482,191,ijuma,2015-09-08T13:27:45Z,"instead of having one method per security protocol, why not just take the security protocol as a parameter? then 3 methods would become one. the implementation seems exactly the same apart from the security protocol passed to `boundport`.",0,0.9866994619369507
38924900,191,ijuma,2015-09-08T13:31:31Z,i agree that this is useful. i think there are a number of places where we use `milliseconds()` where we should really be using a method like this one (i noticed that recently). it may be worth thinking about the naming so that the differences are clear. maybe `milliseconds()` should be removed in favour of `currentwalltime()` introduced below?,0,0.8971646428108215
38925126,191,ijuma,2015-09-08T13:33:25Z,not sure whether we should be returning `java.util.date` as it's a somewhat deprecated class as of java 8. maybe we can return a long and the caller can decide to create a `java.util.date` or anything else?,0,0.9803874492645264
39592806,191,junrao,2015-09-16T04:25:38Z,"could we document the handshake protocol in the comment? it seems that for each token, we first send a 4-byte size, followed by the bytes in the token itself?",0,0.9886999726295471
39592812,191,junrao,2015-09-16T04:25:48Z,it seems that we can just use one level of if/else.,0,0.9845479130744934
39592816,191,junrao,2015-09-16T04:25:56Z,could we just use a bytebuffer instead of a networksend?,0,0.9880656003952026
39592823,191,junrao,2015-09-16T04:26:07Z,could we get that through the config property instead of a jvm system property?,0,0.9875614643096924
40359478,191,Parth-Brahmbhatt,2015-09-24T19:08:40Z,i think this could just be if(!securityprotocol.values().contains(securityprotocol)),0,0.9853765368461609
40359495,191,Parth-Brahmbhatt,2015-09-24T19:08:47Z,shouldn't this come from a config?,0,0.954502522945404
40359539,191,Parth-Brahmbhatt,2015-09-24T19:09:12Z,is this needed?,0,0.9837570190429688
40359628,191,Parth-Brahmbhatt,2015-09-24T19:09:57Z,anyways to avoid this vendor spicific thing? can we just make this a config that defaults to sun.security.krb5.config?,0,0.9838973879814148
40362188,191,Parth-Brahmbhatt,2015-09-24T19:33:44Z,"let's also add ""socketchannel.socket().getinetaddress().gethostname() must match the hostname in principal/hostname""",0,0.9886893630027771
40375211,191,Parth-Brahmbhatt,2015-09-24T21:24:39Z,probably better to just create a method that returns the principal name and host. might be easier to extract all of it using a simple pattern matcher instead of going through bunch of indexofs and substrings.,0,0.9767782688140869
40375463,191,Parth-Brahmbhatt,2015-09-24T21:27:06Z,i am guessing this is all part of gss api magic but a link to doc or some explanation on what we are doing here might help with future maintenance.,0,0.9751987457275391
40575583,191,ijuma,2015-09-28T16:52:14Z,that would not be right because of `securityprotocol.trace` (the fact that trace exists is the reason why we do the check in the first place).,0,0.9734956622123718
40575758,191,ijuma,2015-09-28T16:53:55Z,`sun.security.krb5.config` is also vendor-specific and it won't work in java 9 (see [a link] is there no way to avoid this?,0,0.9835830330848694
40669700,191,ijuma,2015-09-29T13:22:29Z,i think it would be more readable if `listeners` were a `seq` and we can build the `string` at the end with `mkstring`,0,0.9853643774986267
41590473,191,harshach,2015-10-09T01:48:04Z,enabling qop on sasl proven to cause lot of perf issues . it was discussed before hence the reason i went with proposal ssl+sasl.,0,0.9553800225257874
41590525,191,harshach,2015-10-09T01:49:06Z,the reason to use networksend is to have length encoded token . i can use bytebuffer have it encoded with length. let me know if you prefer that.,0,0.9870340824127197
41627145,191,ijuma,2015-10-09T13:03:41Z,i removed it in my pr.,0,0.9791466593742371
41627200,191,ijuma,2015-10-09T13:04:24Z,"ok, thanks. should the name of this be `sasl_plaintext` and `sslsasl` should be `sasl_ssl`? i guess this is a bit subjective, but seems a bit clearer to me.",1,0.9078857898712158
41628653,191,ijuma,2015-10-09T13:22:05Z,i removed this in my pr as it's not used anywhere.,0,0.9469026923179626
41628772,191,ijuma,2015-10-09T13:23:38Z,"i filed kafka-2607 to modify the `time` interface. in the meantime, maybe we can `nanoseconds` and `milliseconds` instead of introducing these methods? i can make the change if you agree.",0,0.9859471321105957
41628927,191,ijuma,2015-10-09T13:25:12Z,do we have anything in kafka that does something similar to this?,0,0.9771416783332825
41629059,191,ijuma,2015-10-09T13:26:18Z,i changed this in my pr.,0,0.9756150245666504
41629081,191,ijuma,2015-10-09T13:26:33Z,i removed this change in my pr.,0,0.9787862300872803
41719366,191,junrao,2015-10-12T02:00:42Z,2 components -> 3 components ?,0,0.9839631915092468
41719367,191,junrao,2015-10-12T02:00:43Z,with out => without,0,0.9594383239746094
41719374,191,junrao,2015-10-12T02:00:50Z,would it be better to name this to sth like ticket_renew_window_factor?,0,0.9872809052467346
41719381,191,junrao,2015-10-12T02:01:01Z,should that be made configurable?,0,0.9859403371810913
41719400,191,junrao,2015-10-12T02:01:11Z,could we use utils.newthread() so that we can give it a proper name and register the uncaught exception handler?,0,0.9894806146621704
41719401,191,junrao,2015-10-12T02:01:15Z,should we test equals and after?,0,0.9844257831573486
41719402,191,junrao,2015-10-12T02:01:20Z,not be => not be able to,-1,0.5371188521385193
41719404,191,junrao,2015-10-12T02:01:24Z,newuntil => newuntil,0,0.9807918667793274
41719407,191,junrao,2015-10-12T02:01:32Z,"since we just want to exit, should we change break to return?",0,0.9766452312469482
41719410,191,junrao,2015-10-12T02:01:39Z,would it be better to get kafka.init from kafka_jaas.conf file instead of another system property?,0,0.987410843372345
41719414,191,junrao,2015-10-12T02:01:47Z,"since we are waiting for this thread to finish during shutdown, it seem that it shouldn't be a daemon thread?",0,0.9613876342773438
41719415,191,junrao,2015-10-12T02:02:07Z,it seems that t is never null. so perhaps it's simpler to just start the thread after t is created.,0,0.9720920324325562
41719416,191,junrao,2015-10-12T02:02:19Z,is this test needed? it seems that logincontextname can never be null.,0,0.984406590461731
41719421,191,junrao,2015-10-12T02:02:26Z,"could we make ""java.security.auth.login.config"" a constant and reuse?",0,0.9893065094947815
41719433,191,junrao,2015-10-12T02:03:00Z,"i am wondering how well this works when the broker is enabled to also authenticate to zk through sasl. will the global configuration be set twice (once here and another time potentially in zookeeper client)? will that affect the login logic? , do you know?",0,0.8358982801437378
41719435,191,junrao,2015-10-12T02:03:07Z,it seems that we need to set the login time during the initial login as well.,0,0.986229658126831
41719438,191,junrao,2015-10-12T02:03:13Z,it seems that we should setlastlogin() in setlogin() instead of here.,0,0.9868425726890564
41719441,191,junrao,2015-10-12T02:03:20Z,it seems that both logincontext and mode can just be a local variable.,0,0.9878764152526855
41719446,191,junrao,2015-10-12T02:03:39Z,do we need to make servicename configurable? could that just be hardcoded as kafka?,0,0.9859029054641724
41719449,191,junrao,2015-10-12T02:03:44Z,it doesn't seem that the client needs principalbuilder.,0,0.9519117474555969
41719453,191,junrao,2015-10-12T02:03:51Z,it seems that we need to pass in the config properties that may be specified in the jaas config file?,0,0.987834095954895
41719460,191,junrao,2015-10-12T02:04:04Z,"we need to turn off op_write when sasl state is complete, right?",0,0.987786054611206
41719461,191,junrao,2015-10-12T02:04:09Z,would it be enough to just check saslstate?,0,0.9878190755844116
41719464,191,junrao,2015-10-12T02:04:27Z,could you add some comments on when and what types of callbacks could be called?,0,0.9876662492752075
41719465,191,junrao,2015-10-12T02:04:31Z,this is a no op.,0,0.6088977456092834
41722182,191,junrao,2015-10-12T04:31:32Z,could you add a comment on why we need to exclude this?,0,0.9845492839813232
41722186,191,junrao,2015-10-12T04:31:45Z,should we specify those through kafka config file or just the jaas config file? it seems that the latter is more natural since it consolidates all sasl related stuff in one file?,0,0.9879202842712402
41722188,191,junrao,2015-10-12T04:31:56Z,need to add the new param configs.,0,0.9681947827339172
41722190,191,junrao,2015-10-12T04:32:03Z,is the test transportlayer.ready() necessary?,0,0.9845516085624695
41722191,191,junrao,2015-10-12T04:32:08Z,why does this need to be public?,0,0.9494311809539795
41722196,191,junrao,2015-10-12T04:32:19Z,do we need to pass in the config properties that may be specified in the jaas config file?,0,0.98802649974823
41722202,191,junrao,2015-10-12T04:32:25Z,do we need to set op_read? it seems it's always on.,0,0.9867384433746338
41722205,191,junrao,2015-10-12T04:32:30Z,we need to turn off op_write when saslserver is complete.,0,0.9864848256111145
41731553,191,ijuma,2015-10-12T07:54:25Z,"i agree that it's not needed in its current state, but it makes sense with the code as it was before, that is: [code block] which version do we prefer?",0,0.9801382422447205
41735085,191,ijuma,2015-10-12T08:45:58Z,"it doesn't, i'll change this back.",0,0.9646815061569214
41752308,191,ijuma,2015-10-12T12:47:41Z,fixed locally.,0,0.983333170413971
41752351,191,ijuma,2015-10-12T12:48:16Z,"that's right, changed it locally.",0,0.9840787649154663
41752705,191,ijuma,2015-10-12T12:53:31Z,done this locally.,0,0.9827788472175598
41752835,191,ijuma,2015-10-12T12:55:01Z,"i don't understand why we are doing this. we call this method if `authid.equals(authzid)` and set it to the value of `ac.getauthorizationid`, so it looks like a no-op?",0,0.9107872247695923
41752875,191,ijuma,2015-10-12T12:55:31Z,removed locally.,0,0.9676378965377808
41753910,191,ijuma,2015-10-12T13:08:19Z,"agreed. and we should handle parsing errors properly (at the moment we are ignoring the case where `indexof` returns -1). i haven't done this yet, but i added it to my list.",0,0.9748627543449402
41754232,191,ijuma,2015-10-12T13:12:02Z,fixed locally.,0,0.983333170413971
41754241,191,ijuma,2015-10-12T13:12:09Z,fixed locally.,0,0.983333170413971
41754749,191,ijuma,2015-10-12T13:17:33Z,maybe we can use `kerberosname` for this?,0,0.988463819026947
41755037,191,ijuma,2015-10-12T13:21:11Z,done locally.,0,0.9826404452323914
41755928,191,ijuma,2015-10-12T13:31:32Z,changed it locally (and in one other similar place).,0,0.9843557476997375
41756215,191,ijuma,2015-10-12T13:34:58Z,"there is the following in the constructor, so the thread can be null. [code block]",0,0.9876120686531067
41756262,191,ijuma,2015-10-12T13:35:32Z,changed it locally.,0,0.9812965989112854
41756269,191,ijuma,2015-10-12T13:35:39Z,changed it locally.,0,0.9812965989112854
41756390,191,ijuma,2015-10-12T13:37:05Z,"i think so, changed it locally.",0,0.9845123291015625
41756657,191,ijuma,2015-10-12T13:39:56Z,changed it locally.,0,0.9812965989112854
41756681,191,ijuma,2015-10-12T13:40:09Z,changed it locally.,0,0.9812965989112854
41759052,191,ijuma,2015-10-12T14:05:12Z,done locally.,0,0.9826404452323914
41815169,191,harshach,2015-10-13T00:13:09Z,i've a config property in sasl will replace that with this.,0,0.9887385368347168
41815315,191,harshach,2015-10-13T00:15:47Z,yes. will change that.,0,0.973990261554718
41815592,191,harshach,2015-10-13T00:20:18Z,"no its not needed. user needs to add another section kafka_jaas.conf with ""client"" section. here is the vagrant setup that i've for kafka kerberos. example here [a link]",0,0.9854921698570251
41817433,191,harshach,2015-10-13T00:57:11Z,this is not hardcoded. users need to come up with servicename and its equivalent to the principal name of the kafkaserver.,0,0.9876291751861572
41817530,191,harshach,2015-10-13T00:58:37Z,"didn't understand , are you saying we should pass jaas config file as part of client config properties?",0,0.9614052772521973
41817534,191,harshach,2015-10-13T00:58:46Z,yes. will fix it.,0,0.9663767218589783
41817553,191,harshach,2015-10-13T00:59:04Z,yes that should be enough.,0,0.9680718779563904
41817601,191,harshach,2015-10-13T01:00:11Z,jaas config special file in that it needs a different syntax like sections that we define. so it should only need to have login details like keytab files not kafka specific configs.,0,0.9889717698097229
41817692,191,harshach,2015-10-13T01:02:26Z,don't understand. what you mean by config properties in jaas config file. jaas should only contain sections and it has specific syntax to them we shouldn't be treating it as generic config file.,0,0.9276196360588074
41817707,191,harshach,2015-10-13T01:02:40Z,will take it out.,0,0.9783112406730652
41820027,191,junrao,2015-10-13T01:54:20Z,do we need the stringbuilder?,0,0.9875089526176453
41820042,191,junrao,2015-10-13T01:54:40Z,"could you add some examples of the rules and keberos names? in particular, how match, frompattern, topattern, etc are used to convert keberos names to user names?",0,0.9887703657150269
41820061,191,junrao,2015-10-13T01:54:51Z,it's a bit weird that # of params doesn't match numofcomponents. could you add a comment?,-1,0.9844467043876648
41820068,191,junrao,2015-10-13T01:55:03Z,should we get this from a system property or from the jaas conf file?,0,0.9883490800857544
41820075,191,junrao,2015-10-13T01:55:14Z,would it be better to pass in timeout through the constructor?,0,0.9851247072219849
41820084,191,junrao,2015-10-13T01:55:22Z,"what does it mean to have a negative interval? also, do we need to support interval? it seems that we have no use case to run a command periodically.",0,0.9346795678138733
41822597,191,harshach,2015-10-13T02:55:10Z,we initializing lasttime to negative of interval and in run method we are checking lasttime + interval > time.currentelapsedtime()) so it guarantees at least one execution of runcommand.,0,0.9873127341270447
41823048,191,harshach,2015-10-13T03:07:50Z,we've shellcommandexecutor in the same file that takes in timeout from constructor. let me know if you want to change this for shell as well.,0,0.9881781935691833
41833260,191,ijuma,2015-10-13T07:13:33Z,i fixed this in my pr that harsha merged some minutes before you made this comment.,0,0.9710133671760559
41875295,191,ijuma,2015-10-13T14:46:55Z,i agree that it's clearer to receive the parameter via the constructor instead of assigning it directly in the subclass (it also avoids initialisation ordering issues). i've changed this locally with a few other `shell` changes.,0,0.98208087682724
41879955,191,ijuma,2015-10-13T15:16:57Z,"as far as i can see, we don't need to support interval. i have removed it locally as it simplifies the class.",0,0.9830135703086853
41881028,191,ijuma,2015-10-13T15:23:37Z,"harsha changed this to be: `transportlayer.removeinterestops(selectionkey.op_write);` i think this also addresses the ""turn off op_write"" comment.",0,0.9861401319503784
41881164,191,ijuma,2015-10-13T15:24:25Z,"harsha address this, i believe.",0,0.905238687992096
41881443,191,ijuma,2015-10-13T15:26:12Z,changed it locally.,0,0.9812965989112854
41883325,191,ijuma,2015-10-13T15:37:52Z,"that's right, changed it locally. with the current code, this doesn't make much of a difference in practice, but it could lead to bugs in the future.",0,0.9547544121742249
41884709,191,ijuma,2015-10-13T15:47:19Z,"there was this code in the constructor before the `login` call: `this.lastlogin = time.currentelapsedtime() - this.mintimebeforerelogin;` i've changed it to: `this.lastlogin = time.currentelapsedtime()` `mintimebeforerelogin` is only relevant for the relogin case. however, we are still setting the `lastlogin` time before we actually execute `logincontext.login` (in both the first and subsequent logins). do you think we should be updating that value after the `logincontext.login` call?",0,0.985978901386261
41884856,191,ijuma,2015-10-13T15:48:21Z,harsha has done this.,0,0.9348987340927124
41884906,191,ijuma,2015-10-13T15:48:42Z,it looks like we don't.,0,0.7494223117828369
41885077,191,ijuma,2015-10-13T15:49:55Z,we now create the appropriate one (plaintext or ssl) based on whether it's sslsasl or plaintextsasl.,0,0.9887570738792419
41886074,191,ijuma,2015-10-13T15:56:39Z,i removed this as it wasn't being used.,0,0.9485085010528564
41886456,191,ijuma,2015-10-13T15:59:25Z,"i don't understand what you mean, could you elaborate please?",-1,0.7897530198097229
41886529,191,ijuma,2015-10-13T15:59:57Z,this was fixed by harsha.,0,0.9798429608345032
41886544,191,ijuma,2015-10-13T16:00:05Z,i fixed this.,0,0.9792455434799194
41886627,191,ijuma,2015-10-13T16:00:34Z,i removed this.,0,0.9756972789764404
41886671,191,ijuma,2015-10-13T16:00:51Z,harsha did this.,0,0.9564526081085205
41887608,191,ijuma,2015-10-13T16:07:42Z,checked with jun and this is fine.,0,0.9134575724601746
41889019,191,ijuma,2015-10-13T16:18:02Z,"these new methods are only used in the `login` class, so i will move them there and make them private for now.",0,0.9891425967216492
41889636,191,ijuma,2015-10-13T16:22:52Z,will propose sasl_plain and sasl_ssl in a pr (checked with jun).,0,0.9890165328979492
41890445,191,ijuma,2015-10-13T16:30:14Z,harsha did this.,0,0.9564526081085205
41890652,191,ijuma,2015-10-13T16:31:39Z,harsha removed the check.,0,0.9751326441764832
41890663,191,ijuma,2015-10-13T16:31:50Z,harsha did this.,0,0.9564526081085205
41898819,191,ijuma,2015-10-13T17:38:35Z,i moved `transportlayer.removeinterestops(selectionkey.op_write);` from `case complete` to here in my latest pr.,0,0.9850591421127319
41907669,191,ijuma,2015-10-13T18:46:29Z,"i will add a comment explaining the `oid` line, which is particularly bizarre.",-1,0.7148452997207642
41922109,191,fpj,2015-10-13T20:43:32Z,"this class is surprisingly similar to org.apache.zookeeper.login, have we copied from the same source? ;-)",1,0.9453228712081909
41928675,191,rajinisivaram,2015-10-13T21:32:51Z,"sasl/plain is typically used to refer to sasl with mechanism plain. and sasl/plain is usually used with ssl as transport layer. since the protocols here are referring to the transport layer and the plain transport layer is called plaintext, it would be less confusing to have sasl_plaintext and sasl_ssl.",0,0.9855449795722961
41929181,191,rajinisivaram,2015-10-13T21:37:21Z,"can the mechanism be made a configuration option? i haven't looked through the code yet to see if the implementation relies on this mechanism, but it will be good if it was configurable.",0,0.9816076755523682
41929415,191,rajinisivaram,2015-10-13T21:39:25Z,same question as for client - can the sasl mechanism be made configurable?,0,0.9891019463539124
41929710,191,rajinisivaram,2015-10-13T21:42:15Z,"is there a reason why this isn't simply using `configuration.getconfiguration()` to get the default configuration since it is using the standard java property to get the jaas config file anyway? i think `javaloginconfig` is provided by the sun provider, dont think it is available with all vendors.",0,0.9716668725013733
41930386,191,ijuma,2015-10-13T21:47:53Z,"ok, i can change my pr to use that instead. to check: is the proposed name better than what we have at the moment (sslsasl and plaintextsasl).",0,0.9802619218826294
41930669,191,ijuma,2015-10-13T21:49:59Z,i think it would be good if we could do that in a separate pr. which other mechanisms are important for you?,0,0.9494028091430664
41931374,191,rajinisivaram,2015-10-13T21:55:36Z,i do prefer sasl_plaintext and sasl_ssl since it is clearer (more readable) than sslsasl and plaintextsasl.,0,0.9611239433288574
41931566,191,ijuma,2015-10-13T21:57:05Z,"ok, great.",1,0.9649714827537537
41937626,191,rajinisivaram,2015-10-13T23:00:31Z,"the one we are keen on is plain. we will be using sasl with ssl, so plain gives us the simplest secure authentication without having to distribute certificates for mutual client auth. yes, a separate pr makes sense so that this one can be committed soon. i will raise another jira.",0,0.599000096321106
41948372,191,junrao,2015-10-14T02:03:31Z,"since this tests both the producer and consumer, probably this can be called saslintegrationtest. also, could we parameterize the test to test sasl_ssl port too?",0,0.9888995885848999
41948393,191,junrao,2015-10-14T02:03:58Z,perhaps it's clearer to also specify the param name for the third value (false).,0,0.9850660562515259
41948396,191,junrao,2015-10-14T02:04:04Z,"since we only use 1 consumer, do we need to create multiple consumers during setup?",0,0.9813418388366699
41948402,191,junrao,2015-10-14T02:04:10Z,probably better to use foreach instead map.,0,0.9770765900611877
41948404,191,junrao,2015-10-14T02:04:14Z,could we rename this to consumeandverifyrecords?,0,0.9875310063362122
41948407,191,junrao,2015-10-14T02:04:21Z,should we verify the content of the consumed messages too?,0,0.9870065450668335
41948415,191,junrao,2015-10-14T02:04:29Z,"it seems that saslconsumertest.scala covers what's being tested in this file. so, perhaps we don't need this test.",0,0.9860791563987732
41948446,191,junrao,2015-10-14T02:05:07Z,"could we make sun.security.jgss.native a property in the broker/client config file? in general, it seems that other than the jaas config file, it's better to specify other properties from config file instead of system properties.",0,0.9893168807029724
41948452,191,junrao,2015-10-14T02:05:21Z,"it seems that we need to turn off op_write after completing the send of each token. otherwise, the server will be busy looping over the selector while waiting for the next token to be received.",0,0.9671369194984436
41979803,191,ijuma,2015-10-14T10:59:00Z,"i don't think so. i am adding the following comment to the codebase that should explain it: // as described in [a link] // ""to enable java gss to delegate to the native gss library and its list of native mechanisms, // set the system property ""sun.security.jgss.native"" to true"" // ""in addition, when performing operations as a particular subject, for example, subject.doas(...) // or subject.doasprivileged(...), the to-be-used gsscredential should be added to subject's // private credential set. otherwise, the gss operations will fail since no credential is found.""",0,0.9570471048355103
41995662,191,junrao,2015-10-14T13:56:11Z,"it is probably not enough to just turn off op_write at sasl completion time. after completely sending a challenge token, the client needs to turn off op_write. otherwise, while waiting to receive the next token from the server, the client will be busy checking in the selector.",0,0.9582280516624451
42009871,191,ijuma,2015-10-14T15:35:04Z,"looking at the documentation, this only needs to be called if the value passed to `setauthorizedid` is different than the value of `getauthorizationid` which is not the case here. having said that, hadoop does the same thing so i'll leave it in case it's needed due to non-compliant implementations (unless others disagree).",0,0.9882910847663879
42062496,191,harshach,2015-10-14T22:30:08Z,yes. i'll fix it.,0,0.9752037525177002
42062570,191,harshach,2015-10-14T22:30:57Z,it will be helpful in case of doas which we are not supporting int this case. but will be added in future. leaving as it is would be better.,0,0.955935537815094
42062645,191,harshach,2015-10-14T22:31:37Z,yes. did take it from zookeeper.,0,0.9809298515319824
42063676,191,harshach,2015-10-14T22:43:28Z,yes will make it configurable we can implement additional callbacks and digest implementation as part of another pr.,0,0.9882751703262329
42117788,191,ijuma,2015-10-15T12:33:14Z,is it right that we always set it to authorized here (instead of checking if authenticationid and authorizationid are the same like in the client)?,0,0.9883925318717957
42119040,191,ijuma,2015-10-15T12:47:05Z,i changed it to do as you say and it seems to work fine. will include it in my next pr so that harsha can integrate it if he agrees.,0,0.7721558213233948
42119247,191,ijuma,2015-10-15T12:49:12Z,"what is the reason that we log here, but don't throw an exception?",0,0.9751116037368774
42126516,191,ijuma,2015-10-15T13:55:38Z,"ok, looking deeper into this, there is a difference: if someone else had called `setconfiguration`, `getconfiguration` would return that while here we override the value of configuration with the jaas file. neither option is ideal, but that's because of the global nature of this setting. i think just using `getconfiguration` is probably better, but i thought i'd mention it here for completeness.",0,0.9489412903785706
42127823,191,ijuma,2015-10-15T14:05:24Z,", do you know a way of doing this without using proprietary classes?",0,0.9786427021026611
42134970,191,rajinisivaram,2015-10-15T14:59:25Z,"sorry, i don't know of a standard way of doing this,",-1,0.988436222076416
42186791,191,ijuma,2015-10-15T22:03:44Z,", what is the reason that we refresh tgt ourselves instead of using `renewtgt=true` in the jaas file?",0,0.9784650802612305
42187629,191,rajinisivaram,2015-10-15T22:12:12Z,why is servicename a property inside jaas config? could this be made one of the kafka sasl configuration properties instead? presumably it is used only by kafka code and hence doesn't belong in jaas.conf? ibm jdk kerberos module throws an exception because it doesn't recognize this property.,0,0.977946400642395
42198931,191,harshach,2015-10-16T00:42:28Z,renewtgt=true doesn't mean it does the renewal on its own. if its a keytab you don't set it to renewtgt but if its kinit and the tgt in cache than we need to do the renewal.,0,0.9841775894165039
42199039,191,harshach,2015-10-16T00:44:03Z,"servicename always been used in jaas config and it has to match the keytab prinicpal name . since keytab is configured in the jaas config and it makes sense to keep it there. and all other projects from zookeeper, hdfs to everywhere else uses servicename in jaas config. i don't want to make that as an exception.",0,0.9269675612449646
42200491,191,ijuma,2015-10-16T01:13:49Z,"ok, i read from the following that it did: particularly this part ""with this feature, if krb5loginmodule obtains an expired ticket from the ticket cache, then the tgt will be automatically renewed and be added to subject of the caller who requested the ticket"" [a link] you are saying that this doesn't actually happen and we have to provide the implementation that does the actual renewal?",0,0.9483057260513306
42230500,191,ijuma,2015-10-16T10:55:40Z,"if all those projects use this property and the ibm jdk fails when it sees it, are they doing something to make it work with the ibm jdk? i looked at the zookeeper codebase and i couldn't find any code that retrieves a `servicename` from a jaas configuration file: [a link]",0,0.9792739152908325
42259558,191,rajinisivaram,2015-10-16T16:08:24Z,shouldn't this be a daemon thread? otherwise it would prevent client applications from terminating.,0,0.9618939757347107
42261859,191,junrao,2015-10-16T16:31:51Z,"it seems that we need the logic to turn off op_write here too. suppose that the client tries to send a token, but couldn't completely flush the writes. we get in here and completely flush the output buffer. now, if the op_write is not turned off, the selector will be woken up all the time before the client receives the next token from the broker.",0,0.9847477078437805
42261864,191,junrao,2015-10-16T16:31:56Z,"this seems to have the same issue as in saslclient in that we need the logic to turn off op_write here too. suppose that the server tries to send a token, but couldn't completely flush the writes. we get in here and completely flush the output buffer. now, if the op_write is not turned off, the selector will be woken up all the time before the server receives the next token from the client.",0,0.9806534647941589
42262890,191,ijuma,2015-10-16T16:42:30Z,"to make sure i understand, if we completely flush here, we continue executing the method. there are a few code paths where we call `sendsasltoken` which will turn off `op_write`. however, if we are in the intermediate state and we read to the `netinbuffer` but it's not complete, we could end up returning with the op_write on even though it should be off. is that the case you are outlining?",0,0.9842547178268433
42263662,191,junrao,2015-10-16T16:50:07Z,"that's right. if we are still waiting for a new token to be completely received, we will need to turn off op_write.",0,0.9878496527671814
42343337,191,ijuma,2015-10-19T07:52:15Z,i believe this is fixed in my next pr.,0,0.8115311861038208
42343338,191,ijuma,2015-10-19T07:52:19Z,i believe this is fixed in my next pr.,0,0.8115311861038208
42343484,191,ijuma,2015-10-19T07:54:15Z,"suggested that it shouldn't be because we wait for it to terminate on `shutdown`. and if consumers are closed, then it won't prevent client applications from terminating. but it may cause this problem when consumers are not closed, so i am tempted to change it back to a daemon thread. what are your thoughts jun?",-1,0.657602846622467
42366614,191,ijuma,2015-10-19T12:53:41Z,i added a comment explaining this in my latest pr.,0,0.9811097383499146
42366668,191,ijuma,2015-10-19T12:54:17Z,"i added a todo about this, we probably need to solve it in a subsequent release.",0,0.9822738766670227
42366763,191,ijuma,2015-10-19T12:55:21Z,", this is not actually used at the moment. can you please point me to where it should be used and i can quickly address it?",0,0.9789007902145386
573093783,10070,rondagostino,2021-02-09T17:42:50Z,"should the second check appear within the first `if` as it does below in `touch()`? and assuming yes, maybe refactor that common logic out into a `private void removefromactiveandunfenced(brokerheartbeatstate broker)` method?",0,0.9890794157981873
573094685,10070,rondagostino,2021-02-09T17:44:04Z,`public void remove(...)`?,0,0.972873866558075
573095059,10070,rondagostino,2021-02-09T17:44:38Z,`boolean hasvalidsession(...)`?,0,0.9845539927482605
573095621,10070,rondagostino,2021-02-09T17:45:26Z,`public void touch(...)`?,0,0.976767361164093
573098075,10070,rondagostino,2021-02-09T17:48:45Z,"this seems to imply that it is impossible for a broker to be doing a controlled shutdown and be fenced. i guess that means any controlled shutdown gets cancelled? a comment explaining the implications would be helpful. actually, from further down in `shouldshutdown()` it appears it can shutdown immediately if it is fenced -- so i think it's about leaders moving away? again, a comment would help.",0,0.9466529488563538
573113436,10070,rondagostino,2021-02-09T18:03:42Z,"at first i was confused as to why these two operations were necessary, then i realized it is because the instance is mutable and its places in the ordered list and `treeset` are going to change. a comment here would be helpful to make this apparent (i know there is a comment in the list and set declarations, but a reminder here would be helpful nonetheless).",0,0.9721274375915527
573115965,10070,rondagostino,2021-02-09T18:07:27Z,"`public void beginbrokershutdown(...)`? javadoc would be helpful, especially to explain what `deferred` is about. or, if `private` rather than `public`, at least a comment.",0,0.9849409461021423
573116733,10070,rondagostino,2021-02-09T18:08:34Z,what is supposed to happen if it is already shutting down and this is invoked? will it matter if `deferred` is different in the second call?,0,0.9796974062919617
573117364,10070,rondagostino,2021-02-09T18:09:30Z,`public` or `private`? same with methods below.,0,0.9882727265357971
573122112,10070,rondagostino,2021-02-09T18:16:01Z,"is this the case because fenced implies leadership is already moving away? if so, a comment to that effect (or some additional wording in the log line) would be helpful.",0,0.9861987829208374
573123473,10070,rondagostino,2021-02-09T18:17:45Z,you seem to sometime use `shutdown` and other times use `shutdown` -- not sure if that is on purpose or there is a lack of consistency?,0,0.9409815669059753
573125162,10070,rondagostino,2021-02-09T18:20:10Z,`currlowestactiveoffset` a better name?,0,0.9839290380477905
573146291,10070,rondagostino,2021-02-09T18:50:32Z,what's the difference between `beginbrokershutdown()` and `updateshutdownoffset()`? why would the offset at which it can shutdown change? a comment would be helpful.,0,0.9881442785263062
573234880,10070,cmccabe,2021-02-09T20:57:26Z,"hmm, are you suggesting that it should be public? i'd rather not make this public because it's only accessed from within the controller package",0,0.9806270003318787
573235167,10070,cmccabe,2021-02-09T20:57:55Z,"hmm, i'm not sure i understand the question....",-1,0.9459760189056396
573235373,10070,cmccabe,2021-02-09T20:58:15Z,"hmm, are you suggesting that it should be public? i'd rather not make this public because it's only accessed from within the controller package",0,0.9806270003318787
573236986,10070,cmccabe,2021-02-09T21:01:06Z,"thanks... that is a good catch. yes, it's a bit more efficient if the statements are nested. i will refactor this out into a separate function.",1,0.982313871383667
573238990,10070,cmccabe,2021-02-09T21:04:59Z,"good question. a fenced broker will not have leaders, so there should be no leaders to move away. more specifically, if any fenced broker tries to enter controlled shutdown, it will be shut down immediately. i'll add a comment.",1,0.676655650138855
573239810,10070,rondagostino,2021-02-09T21:06:23Z,"ok, i was just checking. these are all fine then.",0,0.9286985397338867
573240204,10070,rondagostino,2021-02-09T21:07:00Z,"sorry, was asking if it should be public -- but i assume not. was just checking. it's fine now.",-1,0.9732992053031921
573254808,10070,cmccabe,2021-02-09T21:29:21Z,if it's already shutting down nothing happens,0,0.9325480461120605
573254866,10070,cmccabe,2021-02-09T21:29:28Z,package-private is ok,0,0.9809420108795166
573256321,10070,cmccabe,2021-02-09T21:32:00Z,"in general it doesn't make sense to wait for controlled shutdown if the broker is already fenced, because in that case its leaders have already been moved away. i will add a comment.",0,0.920996367931366
573256612,10070,cmccabe,2021-02-09T21:32:32Z,i wanted to standardize on shutdown. i will fix the inconsistency.,0,0.9645953178405762
573256853,10070,cmccabe,2021-02-09T21:33:00Z,i'll switch to `lowestactiveoffset`,0,0.9873508810997009
573342973,10070,junrao,2021-02-10T00:08:53Z,typo hwne,0,0.9875491857528687
573345382,10070,junrao,2021-02-10T00:15:25Z,the returned map is not keyed on partition.,0,0.9827554821968079
573345428,10070,junrao,2021-02-10T00:15:31Z,the returned map is not keyed on partition.,0,0.9827554821968079
573931818,10070,junrao,2021-02-10T17:32:46Z,do we also need to update the metric for processing time?,0,0.9844474792480469
573934771,10070,junrao,2021-02-10T17:36:55Z,could we move those private methods after all the internal classes?,0,0.987657904624939
573952836,10070,junrao,2021-02-10T18:01:33Z,the return type is not a tuple.,0,0.9721879363059998
574130720,10070,junrao,2021-02-10T22:42:20Z,could we log lastkey too?,0,0.9891497492790222
574142240,10070,junrao,2021-02-10T23:00:23Z,is this used only for test?,0,0.9843161702156067
574147362,10070,junrao,2021-02-10T23:09:32Z,could we add a bit comment explaining logmanagers and batches?,0,0.98708176612854
574158801,10070,junrao,2021-02-10T23:34:34Z,could we add a comment for maxreadoffset? is it the committed offset?,0,0.9896169900894165
574162564,10070,junrao,2021-02-10T23:37:53Z,"we already replay the message when it's first appended to the log and here we replay the same message again after commit. this could temporarily revert the state. for example, the latest (uncommitted) config could be overwritten by a previously committed config.",0,0.9810159802436829
574202545,10070,junrao,2021-02-11T01:33:46Z,this can throw stalebrokerepochexception. it would be useful for kafkaeventqueue.run() to log the event associated with the exception.,0,0.9889103174209595
574204032,10070,junrao,2021-02-11T01:39:11Z,"in the zk case, we use the zk version to do conditional updates. in raft, could we associated each partitionstate with the offset in the raft log and use that as partitionepoch for conditional updates? this way, we don't need to explicitly maintain a separate partitionepoch field and the epoch is automatically bumped up for any change to the partition record, not just for leader and isr.",0,0.9875587224960327
574204838,10070,junrao,2021-02-11T01:42:24Z,i thought the raft leader epoch is an int since we store only int as leader epoch in the log?,0,0.9858231544494629
574208116,10070,junrao,2021-02-11T01:51:20Z,"currently, the follower never removes the leader out of isr. so, perhaps we should just throw an exception if this is not the case.",0,0.9813869595527649
574209960,10070,junrao,2021-02-11T01:56:44Z,"this is in response to a heartbeat request. so, it should generate a response in controllerresult?",0,0.9887240529060364
574213985,10070,junrao,2021-02-11T02:13:48Z,some of the replay (e.g. unregister_broker_record) could throw exceptions. we probably need to turn the exception into an error response. are we handling that already?,0,0.9796271324157715
574216140,10070,junrao,2021-02-11T02:23:07Z,we probably should name this sth like removefromisrandmaybechooseleader.,0,0.9852377772331238
574216583,10070,junrao,2021-02-11T02:25:19Z,we need to choose at least a live replica.,0,0.978617787361145
574765157,10070,junrao,2021-02-11T19:22:01Z,is that temporary?,0,0.9407995343208313
574773300,10070,junrao,2021-02-11T19:35:06Z,"in the zk based code, we also take live brokers into consideration when selecting a new leader.",0,0.9856711030006409
574843007,10070,junrao,2021-02-11T21:35:53Z,"hmm, not all partitions with isr containing the shutting down need to change the leader.",0,0.9684461355209351
574845213,10070,junrao,2021-02-11T21:39:46Z,we already did this check and the one below in the caller through `clustercontrol.checkbrokerepoch`.,0,0.9887372255325317
574846943,10070,junrao,2021-02-11T21:43:04Z,this seems unnecessary.,-1,0.6145328283309937
574869742,10070,junrao,2021-02-11T22:26:32Z,"if we want to log the shutting down the broker, it seems it's more consistent if we always log it. now, it seems we log it only when leaders need to be moved.",0,0.9789261221885681
574872303,10070,junrao,2021-02-11T22:31:36Z,"it seems that we if the request wants to shut down, we should always remove the shutting down broker from isr, just like moving the leader off the shutting down broker?",0,0.9849825501441956
575409674,10070,junrao,2021-02-12T18:00:36Z,"when a broker is unfenced, some of the partitions without leader could have a new leader now. so, it seems that we need to trigger a leader election here.",0,0.9715824723243713
575433620,10070,junrao,2021-02-12T18:26:12Z,"this call generates a leader change record before the following fencedbroker record. ordering wise, it seems that we should record the fencedbroker first. also, i am wondering what's the best place to trigger leader election and removing from isr due to fenced broker. there are multiple cases when a broker can be fenced (e.g. broker controlled shutdown, broker fenced due to no heartbeat). instead of of doing leader election and isr removal in all those cases, another option is to tigger them in a single place when a fencedbroker record is replayed.",0,0.9741695523262024
575435491,10070,junrao,2021-02-12T18:28:10Z,"since we use isrchangerecord for changing the leader too, could we name it to sth more general?",0,0.988255500793457
575451381,10070,junrao,2021-02-12T18:47:30Z,"should we also trigger leader elections here? also, should we allow broker decommission when it still has replicas?",0,0.9855673313140869
575459759,10070,junrao,2021-02-12T19:03:12Z,"this should tigger leader election too, right?",0,0.8695949912071228
575475691,10070,junrao,2021-02-12T19:35:05Z,"is the intention of `shouldshutdown` to wait until the metadata of the shutting down broker is received by other brokers? if so, not sure why `beginbrokershutdown` sets `broker.shutdownoffset` to either max_long or 0. also, if `shouldshutdown` returns false, when do we get another opportunity to mark the shutting down broker as fenced?",0,0.9824851751327515
575478386,10070,junrao,2021-02-12T19:40:05Z,"in the zk based logic, on receiving a controlled shutdown request, the controller tries to move the leaders off the broker. if this is successful, the controller sends a successful return for the broker to proceed with shutdown. here, it seems that the controller will initially return shouldshutdown as false to the broker if there are leaders moved off the broker and require the broker to heartbeat again to be able to shut down.",0,0.9821332097053528
575480618,10070,junrao,2021-02-12T19:44:40Z,i thought we want to allow topics to be created even when there is not enough live brokers now?,0,0.976241409778595
575514366,10070,junrao,2021-02-12T20:55:11Z,do we need to use `this`? ditto below.,0,0.947348952293396
575516660,10070,junrao,2021-02-12T20:59:54Z,"hmm, should we return the future from `appendwriteevent` ?",0,0.9859158992767334
575525508,10070,junrao,2021-02-12T21:20:15Z,"sometimes, we update the in-memory state after the record is appended to the log. here, it seems that we do the reverse. should we make that consistent?",0,0.9869316220283508
575527291,10070,junrao,2021-02-12T21:24:36Z,it seems the broker can shut down immediately if this is false?,0,0.9590256810188293
575535738,10070,junrao,2021-02-12T21:45:14Z,could we just update `partitions` in place?,0,0.9890187978744507
575541127,10070,junrao,2021-02-12T21:58:46Z,what triggers this on a hard controller failure?,0,0.9580798745155334
575542308,10070,junrao,2021-02-12T22:01:47Z,should we trigger the logic for leader election/isr removal since there could be unhandled fencedbroker records when the new controller takes over?,0,0.9877248406410217
575546009,10070,junrao,2021-02-12T22:11:02Z,should this be changed to unregisterbroker to match the kip?,0,0.9842804670333862
575547292,10070,junrao,2021-02-12T22:14:39Z,should we call this sth like waitforshutdowncomplete to match `beginshutdown`?,0,0.9861922860145569
575548758,10070,junrao,2021-02-12T22:18:13Z,is this still needed with raft metadata?,0,0.9888039231300354
575548839,10070,junrao,2021-02-12T22:18:24Z,this class seems unused.,0,0.8756392002105713
575549084,10070,junrao,2021-02-12T22:19:01Z,this class seems unused.,0,0.8756392002105713
575549246,10070,junrao,2021-02-12T22:19:28Z,inaccurate comment.,-1,0.9299831390380859
575549741,10070,junrao,2021-02-12T22:20:43Z,could we add some comment for this class?,0,0.9869508147239685
575552471,10070,junrao,2021-02-12T22:25:10Z,it might be useful to log both the old and the new value.,0,0.9852257370948792
575554284,10070,junrao,2021-02-12T22:28:11Z,are we deprecating the state-change log and the controller log that we had before?,0,0.9858453273773193
577117523,10070,cmccabe,2021-02-16T20:31:01Z,"yes, it is. i will move it to the test directory.",0,0.9849495887756348
577125115,10070,cmccabe,2021-02-16T20:45:16Z,this code is only executed by the followers. it is true that the leader already applied these log messages but these nodes are not the leader.,0,0.9838435053825378
577127231,10070,cmccabe,2021-02-16T20:48:46Z,`handleeventexception` handles logging exceptions thrown by events.,0,0.9882736206054688
577135430,10070,cmccabe,2021-02-16T21:02:02Z,"yes, i think that could work for partition epoch. let's do that once we have the initial code in, though...",0,0.9805454015731812
577136289,10070,cmccabe,2021-02-16T21:03:31Z,"it is an int and will be in 2.8, but i think that's a mistake (as discussed in the mailing list) and we should plan to make this 64 bit in the near future to avoid overflow issues. so the controller code treats it as a long... cc",0,0.9439036846160889
577143791,10070,cmccabe,2021-02-16T21:17:09Z,ok. we can make this an invalid request then.,0,0.9812177419662476
577146421,10070,cmccabe,2021-02-16T21:21:53Z,"hmm, this comment shows up for me as being left in the `decommissionbroker` function, which is called in response to the decomission broker rpc, not the heartbeat rpc. maybe this is a github ui issue? did you mean to leave this comment for a different function?",0,0.9708752632141113
577147155,10070,rondagostino,2021-02-16T21:23:19Z,i believe after this we need to invoke something to cover the case where a topic has this broker as its only isr member: [code block] the implementation might look like this: [code block],0,0.9420779943466187
577148107,10070,cmccabe,2021-02-16T21:25:13Z,if an exception is thrown here we will end up in `handleeventexception`. since the exception won't be a subclass of `apiexception` we will resign as controller and return an `unknownserverexception`.,0,0.976266622543335
577148212,10070,rondagostino,2021-02-16T21:25:26Z,i believe we should surround this section of code with the following to be sure we never drop the last isr member: [code block],0,0.9787131547927856
577163457,10070,cmccabe,2021-02-16T21:52:59Z,i changed it to `removefromisrandleaderships`,0,0.9787171483039856
577167409,10070,cmccabe,2021-02-16T21:58:24Z,"good point, will fix",1,0.9481878876686096
577167941,10070,cmccabe,2021-02-16T21:59:17Z,this has to be handled by the individual brokers. it's not persisted anywhere currently (currently it is not stored in zk i believe),0,0.9845661520957947
577176042,10070,cmccabe,2021-02-16T22:14:05Z,"in this function we are iterating only over the partitions that the given broker is a leader for. ( we obtained the iterator from `brokerstoisrs#iterator(brokerid=brokerid, leadersonly=true)` )",0,0.9868192672729492
577178197,10070,cmccabe,2021-02-16T22:18:19Z,ok,0,0.9667208194732666
577187004,10070,cmccabe,2021-02-16T22:34:34Z,"i will improve the logging a bit here. i agree that we should log when a broker is told it can shut down or be (un) fenced, since those are major events.",0,0.9683241844177246
577188202,10070,cmccabe,2021-02-16T22:36:59Z,"it seemed safer to leave it in the isr until it's ready to shut down for good. also, if we take it out, it might just get re-added if it catches up... ?",0,0.9456601738929749
577214559,10070,cmccabe,2021-02-16T23:36:58Z,"good point. the appropriate place to handle this will be in the broker heartbeat handling code, since that is where the active controller unfences brokers.",1,0.9459999203681946
577217605,10070,cmccabe,2021-02-16T23:44:42Z,"hmm... it should be ok to remove the leaderships first. kip-500 controlled shutdown works this way, for example... the shutting-down broker is not actually fenced at all until all the other brokers have removed it as a leader. also, wouldn't it be a bit weird to be in a state where a broker is still marked as the leader for some partition, but doesn't show up in the list of brokers given in the metadataresponse? that would happen if we put the fencing record first. i don't think clients or brokers would handle this well. replaying a record cannot trigger the creation of any additional records. this would not work since the standby controllers can't create records, after all... only the active controller. i have created a `handlebrokerfenced` function in `replicationcontrolmanager` which does most of what needs to be done for fencing, though... aside from creating the actual fencing record.",0,0.6617425084114075
577259797,10070,junrao,2021-02-17T01:23:48Z,sounds good. could we add a comment to make that clear?,1,0.9160723090171814
577262652,10070,junrao,2021-02-17T01:31:42Z,it seems that we are logging at the debug level. i am wondering if we should log at warn as before in zk based appoach. [code block],0,0.9810066223144531
577263866,10070,junrao,2021-02-17T01:35:14Z,"i thought the issue was that if changing leaderepoch to long requires a log format change for user data, it has significant performance impact such as down conversion.",0,0.9637523293495178
577268593,10070,junrao,2021-02-17T01:48:41Z,"sorry, i meant `decommissionbroker`. it seems that decommissionbroker request should we a response too, right?",-1,0.9845699667930603
577278241,10070,junrao,2021-02-17T02:16:16Z,"well, in zk based approach, in response to a controlled shutdown, the controller changes isr and the leader. here, it seems that `result.response().isfenced()` is not always true if the broker heartbeat indicates the intention to shut down?",0,0.9867030382156372
577865782,10070,cmccabe,2021-02-17T18:57:08Z,"i normally do group private methods after internal classes, but in this case, it seemed better to keep them together. otherwise you'd have to jump around a lot when reading the code. what do you think?",0,0.9032126069068909
577866850,10070,cmccabe,2021-02-17T18:58:41Z,added,0,0.9735139608383179
577868843,10070,cmccabe,2021-02-17T19:01:51Z,"we can get here just because the user made an invalid rpc, so i don't know if warn is appropriate. i'll change it to info for now.",0,0.9820041060447693
577879960,10070,junrao,2021-02-17T19:19:29Z,sounds good too.,1,0.9367080330848694
577894071,10070,cmccabe,2021-02-17T19:42:26Z,"note: this has been changed to unregisterbroker as per the mailing list discussion. it's ok to have a future that returns void. that just means you either get success, or an error (there is no other result). which is consistent with unregisterbrokerresponse.json, etc.",0,0.985974133014679
577895640,10070,cmccabe,2021-02-17T19:45:07Z,hmm... we only fence the broker once controlled shutdown has completed. if we fenced it immediately that would be disruptive to clients since they wouldn't be able to continue fetching from it until the leaderships have moved. basically immediate fencing is the non-controlled shutdown path....,0,0.6580049395561218
577914392,10070,cmccabe,2021-02-17T20:16:22Z,i have renamed it to `partitionchangerecord`,0,0.9881687760353088
577915565,10070,cmccabe,2021-02-17T20:18:09Z,"good catch. yes, this should be moving leaders. i fixed this in the latest version of the pr. yes, this is allowed.",1,0.979580819606781
577916179,10070,cmccabe,2021-02-17T20:19:10Z,"i restructured this code a bit. but yes, it does move leaders if needed (it's clearer in the new version i think)",0,0.9791521430015564
577916633,10070,cmccabe,2021-02-17T20:19:56Z,"this got refactored, hopefully the new version is clearer. the new version avoids the max_long / 0 hack and other ugliness that was in the initial version.",0,0.6939295530319214
577916988,10070,cmccabe,2021-02-17T20:20:33Z,that is correct. the broker must send another heartbeat before it is allowed to shut down.,0,0.9843007922172546
577918400,10070,cmccabe,2021-02-17T20:23:00Z,"good point. since we don't have much time for 2.8, i will add a todo for now.",1,0.9460920095443726
577919102,10070,cmccabe,2021-02-17T20:24:17Z,good catch.,1,0.9640093445777893
577919831,10070,cmccabe,2021-02-17T20:25:33Z,"the heartbeat manager is special because it stores soft state which is not in the metadata log (when each broker last heartbeated, for example).",0,0.9869987368583679
577920156,10070,cmccabe,2021-02-17T20:26:04Z,"this got refactored. hopefully it is clearer now. yes, a broker can shut down immediately in some cases",0,0.9339785575866699
577920610,10070,cmccabe,2021-02-17T20:26:52Z,since this is stored in a `timelinehashmap` it must be treated as immutable. we can't modify the past.,0,0.9794848561286926
577921275,10070,cmccabe,2021-02-17T20:27:54Z,this comes out of the raft layer and is invoked when the raft election has succeeded and produced a new leader node.,0,0.9879361987113953
577922334,10070,cmccabe,2021-02-17T20:29:46Z,"the standby controller must replay all the committed records before becoming active. so, there is no unfinished work to be done at this point.",0,0.9839973449707031
577922831,10070,cmccabe,2021-02-17T20:30:39Z,"the name close comes from `autocloseable`, which makes some of the tests nicer to write (because we can use the java try-with-resources syntax).",0,0.9842677712440491
577929118,10070,cmccabe,2021-02-17T20:41:57Z,"i don't think the state change log can scale to the number of partitions we need. it gets too verbose. also, this information is available in the metadata log itself.",0,0.6686382293701172
577929403,10070,cmccabe,2021-02-17T20:42:29Z,"thanks, . in the latest version, i do not remove brokers from singleton isrs.",1,0.9271650910377502
577961646,10070,rondagostino,2021-02-17T21:36:39Z,`mockcontrollermetrics` is a test class?,0,0.987920880317688
577971959,10070,rondagostino,2021-02-17T21:54:59Z,"maybe it would be better to check for null and exit out if it is unset -- otherwise we see this, which is not ideal: [code block]",0,0.9664146900177002
577993008,10070,junrao,2021-02-17T22:34:45Z,"in the old controller, eventqueuetimems is used to measure the amount of time an event is sitting in the queue before being processed. there is a separate timer metric per controller state that measures the processing time per event type.",0,0.9851084351539612
578003900,10070,junrao,2021-02-17T22:58:11Z,it seems that using long for leaderepoch in the log requires a bigger discussion. could we use int for now?,0,0.9807195067405701
578014387,10070,junrao,2021-02-17T23:22:16Z,"if a broker wants to shut down and is only included in isr, we still want to remove the broker from isr before allowing it to shutdown. otherwise, a new published record needs to wait for the session timeout before it can be committed.",0,0.9833663702011108
578015133,10070,junrao,2021-02-17T23:24:13Z,what about the case when request.wantfence() is true?,0,0.9870643615722656
578019439,10070,junrao,2021-02-17T23:35:12Z,"(1) in zk-based approach, we do leader election a bit differently for controlled shutdown. if we can't select a leader from the remaining isr, we just leave the current leader as it is. this gives the shutting down broker a chance to retry controlled shutdown until the timeout. (2) in zk-based approach, we also remove the broker from isr for other partitions whose leader is not on the shutting down broker. that's true and is an existing problem. one way to address this is to include partitionepoch in the follower fetch request. the leader could then reject a follower request if the partitionepoch doesn't match. this can be done in a followup pr.",0,0.9665214419364929
578026068,10070,junrao,2021-02-17T23:52:30Z,could we add a todo for handling the preferred leader election?,0,0.9858220219612122
578028795,10070,junrao,2021-02-17T23:59:48Z,should this be named unregisterbroker?,0,0.9819376468658447
578047059,10070,junrao,2021-02-18T00:51:31Z,is this check already implied since we are iterating `brokerstoisrs`?,0,0.9875922799110413
578054305,10070,junrao,2021-02-18T01:08:09Z,is there any benefit/enough to only allow the broker to shutdown when all brokers have caught up to controlledshutdownoffset? the zk-based criteria is that a broker is allowed to shut down as long as all leaders have been moved off the shutting down broker.,0,0.9820879101753235
578062730,10070,junrao,2021-02-18T01:31:49Z,we are generating an unregisterbrokerrecord.,0,0.965268075466156
578065045,10070,junrao,2021-02-18T01:36:55Z,are all records generated in a single controllerwriteevent appended to the metadata log atomically?,0,0.9891504645347595
578067236,10070,junrao,2021-02-18T01:43:22Z,"hmm, the comment seems to be the same as shouldshutdown.",0,0.9713141322135925
578071150,10070,junrao,2021-02-18T01:55:21Z,testfindstalebrokers ?,0,0.9839184284210205
578076422,10070,junrao,2021-02-18T02:09:31Z,could we make it private?,0,0.9865685701370239
578079100,10070,junrao,2021-02-18T02:17:13Z,testunregister?,0,0.98624587059021
578080050,10070,junrao,2021-02-18T02:19:53Z,testplacereplicas ?,0,0.987276017665863
578603931,10070,cmccabe,2021-02-18T17:19:36Z,"good point. i will fix it so that eventqueuetimems has its original meaning. for now, i have added a metric called eventqueueprocessingtimems which deals with processing time. i do want to do the per-state tracking but i don't think we have time right now",1,0.8367252349853516
578606545,10070,junrao,2021-02-18T17:23:17Z,an empty topic name currently results in an invalid_request error.,0,0.9312229156494141
578613805,10070,junrao,2021-02-18T17:32:32Z,an empty broker currently results in an invalid_request error.,0,0.9432768225669861
578619727,10070,cmccabe,2021-02-18T17:40:46Z,"ok, that makes sense. i will remove it from all non-singleton isrs as well as removing it from all leaderships.",0,0.9843781590461731
578621621,10070,cmccabe,2021-02-18T17:43:39Z,"good question. the broker doesn't currently request fencing once it is unfenced. but for completeness, it is simple to support this and it makes the code more intuitive, so i'll add it.",1,0.9492219090461731
578625531,10070,cmccabe,2021-02-18T17:49:18Z,"as i mentioned above, i changed it so that it now removes the broker from all non-singleton isrs, as well as removing it from leaderships. it seems like the remaining behavioral difference is that the new code will, if no other leader can be chosen, set the leader to -1 (offline). if we don't do this, controlled shutdown easily gets stuck if there are any partitions with replication factor = 1. maybe we can tune this a bit later? i like the idea of including the partition epoch in the follower fetch request.",0,0.6914203763008118
578627766,10070,cmccabe,2021-02-18T17:52:32Z,"hmm, i thought this already handles preferred leader election (there are only two options, preferred and unclean, so far...)",0,0.9040232300758362
578628736,10070,cmccabe,2021-02-18T17:53:57Z,good catch. this has been superseded by `replicationcontrolmanager#unregsiterbroker`.,1,0.9821179509162903
578629900,10070,cmccabe,2021-02-18T17:55:39Z,"we're iterating over the partitions with no leader, which may or may not have the newly activated broker in their isr.",0,0.9858160018920898
578630655,10070,cmccabe,2021-02-18T17:56:43Z,"basically it lets us know that the other brokers have successfully taken over as leader (where needed) which avoids having a period of unavailability, ideally",0,0.9758875966072083
578648887,10070,cmccabe,2021-02-18T18:23:21Z,fixed,0,0.975196123123169
578664492,10070,junrao,2021-02-18T18:47:22Z,do we allow a heartbeat request to set both the fence and wantshutdown flag?,0,0.986630380153656
578667056,10070,junrao,2021-02-18T18:51:14Z,"it's fine to revisit that later. the tradeoff is that if we wait, it slightly increases the probability of availability since another replica could join isr.",0,0.9818235635757446
578669898,10070,junrao,2021-02-18T18:55:42Z,"i think we need to handle preferred leader election in a special way. for example, if the assigned replicas are 1,2,3, isr is 2,3 and the current leader is 3, when doing preferred leader election, we want to keep the leader as 3 instead of changing it to 2.",0,0.9795234203338623
578693886,10070,junrao,2021-02-18T19:35:29Z,"this can be revisited later. when finalizing a feature, should be consider other controller's supported features too?",0,0.9878116250038147
578696957,10070,junrao,2021-02-18T19:40:18Z,this class seems never used?,0,0.9705289602279663
578699530,10070,junrao,2021-02-18T19:44:45Z,could we add some comments for this class?,0,0.9869049191474915
578700824,10070,junrao,2021-02-18T19:46:48Z,"to make this more intuitive, perhaps we could add a method isactive in quorumcontroller?",0,0.985270619392395
578722110,10070,junrao,2021-02-18T20:23:39Z,"hmm, why is a replication factor of 1 invalid?",0,0.9314307570457458
578817527,10070,cmccabe,2021-02-18T23:24:41Z,a resource with type broker and an empty name represents a cluster configuration that applies to all brokers. i'll add a comment,0,0.9873873591423035
578817611,10070,cmccabe,2021-02-18T23:24:57Z,"yes, it can set both",0,0.983817458152771
578850598,10070,cmccabe,2021-02-19T00:54:40Z,"hmm... right now, we don't have a good way of finding out what features the other controllers support. maybe we will have to think more about this when we support rolling upgrade in kip-500.",0,0.5323724150657654
578850804,10070,cmccabe,2021-02-19T00:55:21Z,it's used in unit tests,0,0.9879776239395142
578851481,10070,junrao,2021-02-19T00:57:07Z,"yes, that's the problem. from a consistency perspective, it seems that we should use the supported features from either all controller nodes or none.",0,0.9751402735710144
578857828,10070,cmccabe,2021-02-19T01:15:22Z,"there are no unfenced brokers (as you mentioned earlier, we should change this so that it places on the fenced broker). i will add a todo",0,0.9835312366485596
578876029,10070,junrao,2021-02-19T02:10:09Z,could we add some comments to this class?,0,0.9872408509254456
578877349,10070,junrao,2021-02-19T02:14:23Z,"well, currently the contract is just that if every broker picks the preferred replica (i.e. 1st replica), the leaders will be balanced among brokers. if not, all other replicas are equivalent. moving leaders among non-preferred replicas just creates churns without benefiting the balance.",0,0.9762542247772217
578878282,10070,junrao,2021-02-19T02:17:34Z,"as jason pointed out, in zk based approach, the controller bumps up the leader epoch for removing replica from isr too. also, since the broker is no longer receiving the leaderandisr requests, we need some logic for the broker to ignore the new partition record (for follower fetching) once it starts the controlled shutdown process.",0,0.9853613972663879
579374802,10070,cmccabe,2021-02-19T18:04:52Z,"this is resolved in the latest version of the code, where we disable metadata updates on the shutting down broker before starting controlled shutdown, and bump the leader epoch of all partitions.",0,0.9890350699424744
579378306,10070,cmccabe,2021-02-19T18:10:42Z,"i changed this so that the leader epoch is bumped if and only if there is a leader present in the partitionchange record. (it is possible to bump the epoch without changing the leader by including the same leader again in the record.) we now use this during controlled shutdown to unconditionally bump the leader epochs. otherwise, we only bump the leader epochs if the leader changed.",0,0.9846087694168091
579403297,10070,junrao,2021-02-19T18:50:24Z,"hmm, does integer.min_value have any special meaning? if so, could we use a more intuitive constant?",0,0.9825908541679382
579406849,10070,junrao,2021-02-19T18:56:29Z,"hmm, if the leader is already -1 and we can't change isr, there is no need to generate a new partitionchangerecord just to bump up the leader epoch. it won't help controlled shutdown since there is already no leader.",0,0.9714207649230957
579410463,10070,junrao,2021-02-19T19:01:26Z,"currently, for controller initiated isr change (controlled shutdown or hard failure), we always bump up the leader epoch. also, the name alwaysbumpleaderepoch is a bit weird since the code in handlenodedeactivated() doesn't directly bump up leader epoch.",-1,0.9435687065124512
579411851,10070,junrao,2021-02-19T19:03:59Z,"currently, for leader initiated alterisr request, the controller doesn't bump up the leader epoch. if we change that, it will slightly increase unavailability since all clients have to refresh the metadata in this case.",0,0.9878888726234436
579414289,10070,junrao,2021-02-19T19:08:23Z,"if we do this, does `brokermetadatalistener.close() `still need to call `beginshutdown()`.",0,0.9879846572875977
579421318,10070,junrao,2021-02-19T19:21:16Z,"hmm, it seems that we should only do `newleader != partitioninfo.preferredreplica()` if this is a preferred leader election.",0,0.9761198163032532
579438984,10070,junrao,2021-02-19T19:54:01Z,"hmm, merge bumps up the leaderepoch. it seems that this needs to be persisted in the metadata log?",0,0.9751933217048645
579458466,10070,cmccabe,2021-02-19T20:31:19Z,no special meaning. it's just a constant that can't be a valid leader. we could use -2 if that seems nicer.,0,0.951399028301239
579462462,10070,cmccabe,2021-02-19T20:38:40Z,hmm... i don't completely understand why we would want to bump the leader epoch when the controller removes a non-leader broker b but not when an alterisrrequest removes a non-leader broker b from the isr. it seems like we should either bump in both scenarios or neither. is the fact that we bump in the first scenario just an artifact of the fact that otherwise we could not send out a leader and isr request that had a new epoch and thereby caused a change?,0,0.8213779330253601
579463797,10070,cmccabe,2021-02-19T20:41:39Z,"hmm... replicationcontrolmanager should not allow this to happen during an alter isr request. there is some code that checks if the alter isr request is attempting to remove the current leader from the isr, and returns an error if so. so the leader should not be changed by an alter isr request and therefore the leader epoch will not be. [code block]",0,0.9685783386230469
579464755,10070,cmccabe,2021-02-19T20:43:43Z,it does need to be because there are some paths through the code that don't go through here. in general calling `beginshutdown` or `close` multiple times is harmless-- only the first time has an effect.,0,0.9769262671470642
579496903,10070,junrao,2021-02-19T21:52:36Z,"yes, the alterisr doesn't change leader, but generates a partitionchangerecord. on replaying this record, the code following code bumps on leaderepoch? ` partitioncontrolinfo newpartitioninfo = prevpartitioninfo.merge(record);`",0,0.9855534434318542
579497748,10070,junrao,2021-02-19T21:54:30Z,"ok, maybe the check can be `record.leader()< -1`?",0,0.988090991973877
579522201,10070,cmccabe,2021-02-19T22:47:15Z,"even in an unclean leader election, we don't want to change the leader unless we need to.",0,0.7119116187095642
579522827,10070,cmccabe,2021-02-19T22:48:43Z,"the leader epoch is managed implicitly -- every time a partitionchangerecord appears, the epoch is bumped if the leader is not no_leader_change.",0,0.9875197410583496
579536414,10070,junrao,2021-02-19T23:28:15Z,"hmm, we should set the leader to no_leader_change, right?",0,0.9778549671173096
579538752,10070,junrao,2021-02-19T23:37:14Z,could you file a separate jira to follow up on partitionepoch post 2.8?,0,0.9887961149215698
579547098,10070,cmccabe,2021-02-20T00:07:59Z,that is the default so we don't need to set it unless we're changing it,0,0.9862880706787109
579547404,10070,cmccabe,2021-02-20T00:09:24Z,filed kafka-12349,0,0.9820225834846497
579547731,10070,cmccabe,2021-02-20T00:10:42Z,merge only bumps the epoch if the leader was set. [code block],0,0.9888455271720886
579547825,10070,cmccabe,2021-02-20T00:11:10Z,"as per our discussion outside github, let's just use the old behavior for now.",0,0.9865554571151733
579547910,10070,cmccabe,2021-02-20T00:11:40Z,i added a constant. i think it looks a little nicer...,1,0.8176849484443665
579553251,10070,junrao,2021-02-20T00:35:14Z,"we have no_leader_change as the default for the serialized data. however, the active controller replays the partitionchangerecord created in memory, which defaults leader to no_leader_change, right?",0,0.9866496920585632
579564268,10070,cmccabe,2021-02-20T01:15:01Z,let's revisit this after 2.8,0,0.9841977953910828
579564579,10070,cmccabe,2021-02-20T01:16:31Z,right now the answer is yes. eventually we plan on supporting multiple batches.,0,0.9769046306610107
579564654,10070,cmccabe,2021-02-20T01:17:04Z,"i do think we should harmonize this, but i think it would be better to do that when we get rid of metalogshim. we've had a plan to get rid of the shim layer for a while but we just didn't have time to do it this week. so let's plan to do it then, if that makes sense",0,0.8691383004188538
579565540,10070,cmccabe,2021-02-20T01:21:30Z,ack. i fixed this,0,0.9641587138175964
580411938,10070,junrao,2021-02-22T16:54:21Z,do we have a jira to track this?,0,0.9833652377128601
136670512,3765,junrao,2017-09-01T21:42:22Z,could you carry over the comments in replicastatemachine about the possible state changes and the corresponding actions? ditto for the new partitionstatemachine.,0,0.9622498154640198
136672966,3765,junrao,2017-09-01T22:00:28Z,"i am actually not sure if we need to read the partition state from zk in this case. the transition to newreplica is only used in 2 places: (1) starting a new replica in partition reassignment, (2) when a new topic is created. in (1), if there is a leader, it will already be cached by the controller. in (2), currently, it seems it's guaranteed there is not a leader at this point. a subsequent transition to onlinepartition in onnewpartitioncreation() will do the leader election part. so, it seems that we can (a) just read the cached leader info, (b) call brokerrequestbatch.addleaderandisrrequestforbrokers if leader is available and doesn't equal to current replica, (c) move the replica to newreplica state unless the leader equals to the current replica, (d) we probably also want to log an error if the new replica happens to be the leader.",0,0.9529303908348083
136675513,3765,junrao,2017-09-01T22:24:23Z,it will be useful to document the response since it is a bit complicated.,0,0.9671918749809265
136678656,3765,junrao,2017-09-01T22:59:27Z,"it seems that it may be possible for the response to have a sequence of connectionloss, followed by a sequence of ok when the session was disconnected and then reconnected again. so, we may want to just do filter instead of takewhile.",0,0.9856520891189575
136679343,3765,junrao,2017-09-01T23:07:29Z,it will be useful to explicitly define the return type in each of the public methods to make it clear.,0,0.9876796007156372
136679765,3765,junrao,2017-09-01T23:13:11Z,"hmm, will kafkacontrollerzkutils.gettopicpartitionstates ever throw an exception?",0,0.9829155206680298
136872413,3765,junrao,2017-09-04T21:52:57Z,"it seems that we only need to check the topic config if the isr is empty after replicaid is removed from isr, not before.",0,0.9851348996162415
136872700,3765,junrao,2017-09-04T22:00:02Z,"for those partitions whose isr can't be shrunk due to making isr empty, we simply keep the current isr. so, it seems in this case, we can just do an optimization by not sending the leaderandisrrequest for those partition since neither the leader nor the isr will change.",0,0.9860312938690186
136873950,3765,junrao,2017-09-04T22:29:21Z,"hmm, do we need the logic here? it seems that we are refreshing the topic partition state when retrying doremovereplicasfromisr. so, reading the topic partition state here seems redundant.",0,0.9635117650032043
136874953,3765,junrao,2017-09-04T22:57:06Z,we will need to handle nonode error here by creating the missing parent path if needed.,0,0.9768378734588623
136875070,3765,junrao,2017-09-04T23:00:51Z,check the error code?,0,0.9808262586593628
136875311,3765,junrao,2017-09-04T23:06:24Z,it seems that we should do this in a while loop since we do conditional update to the leaderandisr path in zk and need to retry on badversion.,0,0.9704760909080505
136875649,3765,junrao,2017-09-04T23:15:27Z,"partitionswithuncleanleaderelectionstate includes partitions that don't need unclean leader election. so, the name seems a bit miss-leading.",0,0.8170632123947144
136876376,3765,junrao,2017-09-04T23:35:34Z,"ideally, we want to select the preferred replica if it's alive, in-sync and not shutting down as controlledshutdownleaderselector does.",0,0.9856430888175964
136876429,3765,junrao,2017-09-04T23:36:33Z,unused import,0,0.9649426341056824
136876599,3765,junrao,2017-09-04T23:40:15Z,"if a create operation retries due to code.connectionloss, it's possible for the retry to receive a nodeexist error since the previous create may have succeeded. perhaps on nodeexist error during retry, we can read the value back and only return nodeexist error if the value is different from that to be created.",0,0.9859864711761475
136876729,3765,junrao,2017-09-04T23:44:05Z,do we need to add some general handling for errors like noauth?,0,0.9764734506607056
136903037,3765,onurkaraman,2017-09-05T06:23:29Z,yeah i noticed this as well. i mainly just wanted to keep the existing behavior the same and worry about tweaking the existing behavior in later patches. the only reason i can come up with for this zk lookup is to notice if another controller takes over while this current controller is in the process of doing this transition.,0,0.9425219893455505
136904968,3765,onurkaraman,2017-09-05T06:39:48Z,"it seems that in this scenario today, the leadership changes to leaderandisr.noleader (-1), the leader epoch increments, and the zkversion increments too. we send leaderandisrrequests to the full replica set (not just isr) and also send updatemetadatarequests to the whole cluster with this updated leaderandisr with leader = -1, isr = old isr with the single replica, the incremented leader epoch, and the incremented zkversion. in fact, whenever we send a leaderandisrrequest, we also broadcast updatemetdatarequests to the whole cluster. are you suggesting we do neither of these things? skipping these steps means that: 1. non-isr replicas will not be aware of the incremented leader epoch and zkversions. 2. the cluster will not receive the updated metadata.",0,0.9716113805770874
136905187,3765,onurkaraman,2017-09-05T06:41:27Z,"it's possible since it internally calls zookeeperclient.waituntilconnected, which can throw exceptions (zookeeperclientauthfailedexception and zookeeperclientexpiredexception).",0,0.9898256659507751
136906744,3765,onurkaraman,2017-09-05T06:53:16Z,it attempts to mimic the existing behavior in replicationutils.checkleaderandisrzkdata (which is called from replicationutils.updateleaderandisr). strictly speaking i don't think this logic is required. i think it just attempts to make progress on a version conflict (for instance if the partition leader concurrently updated isr) instead of starting over.,0,0.971197783946991
137011097,3765,junrao,2017-09-05T14:53:43Z,"hmm, since we are fixing the issue with zk session expiration, there shouldn't be more than 1 controller accessing zk at the same time. in general, i agree that we don't want to make major changes to partition/replicastatemachine while refactoring zk accesses. however, if this simplifies how we use zk, it may be worth doing.",0,0.9732932448387146
137011133,3765,junrao,2017-09-05T14:53:51Z,"ah, ok. so, we did change the leader in this case.",0,0.9839884638786316
137011245,3765,junrao,2017-09-05T14:54:07Z,"hmm, for both zookeeperclientauthfailedexception and zookeeperclientexpiredexception, we probably don't want to retry forever in removereplicasfromisr(). it seems that we should just log an error and move on.",0,0.9678264856338501
137011321,3765,junrao,2017-09-05T14:54:22Z,"ok, that logic is just to handle the possibility that a previous write has succeeded on a connectionlossexception. it would be useful to document that.",0,0.981084406375885
137052511,3765,onurkaraman,2017-09-05T16:58:18Z,it's not terribly clear but that's actually the behavior in the pr.,0,0.95680171251297
137159386,3765,onurkaraman,2017-09-06T02:34:25Z,this falls in the category of suggestions that differ in current behavior. again i'm not sure if we want to overload this pr with more than just porting existing behavior.,0,0.730055570602417
137159912,3765,onurkaraman,2017-09-06T02:40:39Z,"in the case of `kafkacontrollerzkutils.createtopicpartitionstates`, we're creating the state znode for the first time, in which case the following parent znodes almost definitely will not exist: * /brokers/topics/\ /partitions * /brokers/topics/\ /partitions/\ * /brokers/topics/\ /partitions/\ /state so perhaps in this case, we should push the creation of these parent znodes into `kafkacontrollerzkutils.createtopicpartitionstates`.",0,0.9824858903884888
137160199,3765,onurkaraman,2017-09-06T02:43:52Z,"yeah as stated in one of my earlier pr comments, no effort has been put into partitionstatemachinev2 yet to do error handling and retries. the idea was to first validate that the overall strategy would work in replicastatemachinev2 and then apply error handling and retries to partitionstatemachinev2.",0,0.9781433343887329
137167391,3765,onurkaraman,2017-09-06T04:07:12Z,there was one typo in gettopicpartitionstatesfromzk: `val candidateisr = leaderisrandcontrollerepoch.leaderandisr.isr.filternot(_ != replicaid)` should be: `val candidateisr = leaderisrandcontrollerepoch.leaderandisr.isr.filter(_ != replicaid)` but otherwise we actually do the topic config checks only on the partitions whose isr is empty after removal. note that the `candidateleaderandisrs` returned is used to find `partitionswithemptyisr` which is what we pass into `leaderandisrbasedonlogconfigs`.,0,0.9857149720191956
137349319,3765,junrao,2017-09-06T18:18:11Z,"yes, that sounds good.",1,0.7929078340530396
138211018,3765,junrao,2017-09-11T22:39:08Z,"it seems that we will need to set acl based on whether zk security is enabled or not, like what zkutils.defaultacls() does.",0,0.9865459203720093
138212390,3765,junrao,2017-09-11T22:47:47Z,this method can be private.,0,0.9879018068313599
138451688,3765,junrao,2017-09-12T20:06:03Z,perhaps we should also log an error for any other error code?,0,0.98223876953125
138454615,3765,junrao,2017-09-12T20:19:12Z,"hmm, there is a bit of inconsistency here in how we deal with exceptions from zk calls. in general, it seems that exceptions (e.g. authorization error, session closed, etc) are not retriable. so, we probably should return them in a failed partition map as what we do in getlogconfigs().",0,0.9507091641426086
138478606,3765,junrao,2017-09-12T22:03:50Z,"i think we can simplify this logic a bit. badversion can happen because of updates from another client (e.g., leader) or retries from a connection loss. technically, for the latter, we can do a read and avoid updating the path again if the new value is already in place. however, it seems that it's simpler to just return any partition with badversion as updatestoretry and the let the caller retry. the caller already has the logic to read the latest value from zk on retry. since connection loss is rare, doing an extra write when it happens is probably ok.",0,0.9354386925697327
138480660,3765,junrao,2017-09-12T22:14:37Z,"hmm, it seems any other error is not really retriable and should be returned in a failed partition map.",0,0.911143958568573
138489383,3765,junrao,2017-09-12T23:09:11Z,"""controller %d epoch %d initiated state change for partition %s from %s to %s failed"" => ""controller %d epoch %d failed to change state for partition %s from %s to %s"" ?",0,0.9760647416114807
138490985,3765,junrao,2017-09-12T23:20:44Z,"hmm, it seems the convention should be that any exception is a non-retriable error and we will just log an error on those partitions, and then move on w/o retry.",0,0.9821509122848511
138495827,3765,junrao,2017-09-12T23:55:43Z,"we want to pick the preferred replica if possible. isr in general is not ordered. so, we want to go through assigned_replicas in order as controlledshutdownleaderselector does.",0,0.9877884984016418
138496088,3765,junrao,2017-09-12T23:57:37Z,would the code be easier to read if we just return failed partitions to electleaderforpartitions() and log the error there?,0,0.9858405590057373
138499176,3765,junrao,2017-09-13T00:23:11Z,same comment here. would the code be easier to read if we just return failed partitions to removereplicasfromisr() and log the error there?,0,0.9883728623390198
138501599,3765,junrao,2017-09-13T00:46:26Z,it's a bit inconsistent to return currentleaderandisrs since it includes candidateleaderandisrs. it seems it's easier to understand if we return 4 disjoint sets. the first two parts could then be named partitionswithoutreplicainisr and partitionswithreplicainisr,0,0.928463339805603
138502217,3765,junrao,2017-09-13T00:52:27Z,it seems that we should extract the topic set before passing into kafkacontrollerzkutils.getlogconfigs()?,0,0.9884381890296936
138502301,3765,junrao,2017-09-13T00:53:17Z,could topics be a set?,0,0.9844036102294922
138505415,3765,junrao,2017-09-13T01:22:10Z,"the method name is a bit confusing. it sounds like that we are just reading the partition state from zk, but we actually also remove the isr here. so, we probably want to use a more accurate method name. also, would it be better to change the isr in leaderandisrbasedonlogconfigs() instead of here?",-1,0.6185644865036011
138505545,3765,junrao,2017-09-13T01:23:35Z,"hmm, do we need those wrappers? could be just change controllerevent directly?",0,0.9882508516311646
138675875,3765,onurkaraman,2017-09-13T16:46:26Z,"anything with a v2 suffix is just temporary. it's there to make the diff easier to read. once we agree on the changes, i'll remove the suffix and make the new code replace the old.",0,0.9827002882957458
138677309,3765,onurkaraman,2017-09-13T16:52:16Z,this had also crossed my mind but decided to just try to replicate existing behavior in the first pass. however i agree that doing so simplifies the logic here quite a bit and agree that the change should be made in this pr.,0,0.8733590245246887
138684045,3765,onurkaraman,2017-09-13T17:20:35Z,"the behavior in the pr just tries to imitate `zkutils.conditionalupdatepersistentpath` which marks the update success as false when it receives any exception other than badversion. `zkutils.conditionalupdatepersistentpath` is called by `replicationutils.updateleaderandisr` which is called by `kafkacontroller.removereplicafromisr`. that update success value is what determines if we should retry in the while loop of `kafkacontroller.removereplicafromisr`. that being said, the existing behavior isn't necessarily right.",0,0.9817443490028381
138807407,3765,onurkaraman,2017-09-14T06:35:39Z,suppose we collect all failed partitions and return it to `electleaderforpartitions`. how will `electleaderforpartitions` log relevant information? i think you'd basically have to return error messages or exceptions back to `electleaderforpartitions`. so the end result would just consolidate all the calls to `logfailedstatechange` into one place. is this what you had in mind?,0,0.9835260510444641
139002874,3765,junrao,2017-09-14T20:28:40Z,"yes, i was thinking of returning partition -> error_code map to the caller.",0,0.9878981709480286
139269156,3765,junrao,2017-09-15T23:39:22Z,should we do that in every test?,0,0.9751662015914917
139270862,3765,junrao,2017-09-16T00:01:44Z,"it will be useful to add a test for the controlled shutdown case, which involves setting controllercontext.shuttingdownbrokerids and making the state transition to online.",0,0.9876787066459656
139271124,3765,junrao,2017-09-16T00:05:51Z,could we consolidate all the logfailedstatechange() calls here?,0,0.9895660877227783
139271360,3765,junrao,2017-09-16T00:08:47Z,could this be private?,0,0.9868327379226685
139271478,3765,junrao,2017-09-16T00:10:43Z,could we add a comment on the return value?,0,0.9876145124435425
139271708,3765,junrao,2017-09-16T00:14:25Z,it seems that we should return failedupdates to the caller so that we can log the error.,0,0.9861308932304382
139272320,3765,junrao,2017-09-16T00:25:57Z,could we consolidate all the logfailedstatechange() calls here?,0,0.9895660877227783
139272482,3765,junrao,2017-09-16T00:29:45Z,"hmm, not sure that i really understand this comment. also, could we document the return value?",0,0.850570797920227
139273133,3765,junrao,2017-09-16T00:43:56Z,"i think this part of the logic could be simplified a bit from the original implementation. if isr only contains replicaid, it seems that we can just always leave the last replica in isr independent of the uncleanleaderelection config. this is because the leader will be set to noleader. so, no new data could be written to this partition and replicaid will remain in sync.",0,0.9848757386207581
139273316,3765,junrao,2017-09-16T00:48:15Z,leaderandisrs.keys.map(_.topic).toseq => leaderandisrs.keys.map(_.topic).toset ?,0,0.9866775274276733
139298824,3765,onurkaraman,2017-09-17T00:54:22Z,"it doesn't seem like we should relax the easymock strictness in general. i only had to do it because i had issues specifying expectations on some scala methods with defaults (specifically, the isnew param for `mockcontrollerbrokerrequestbatch.addleaderandisrrequestforbrokers`).",0,0.9374385476112366
139298830,3765,onurkaraman,2017-09-17T00:55:08Z,your above earlier comment suggests we can get rid of this method entirely. so problem solved!,0,0.6436605453491211
139298835,3765,onurkaraman,2017-09-17T00:55:31Z,done.,0,0.9759407639503479
139298837,3765,onurkaraman,2017-09-17T00:55:38Z,agreed.,0,0.9702104926109314
139298838,3765,onurkaraman,2017-09-17T00:55:46Z,done.,0,0.9759407639503479
139298862,3765,onurkaraman,2017-09-17T00:56:46Z,done.,0,0.9759407639503479
139298884,3765,onurkaraman,2017-09-17T00:58:58Z,"this ends up getting surprisingly ugly due to the option[int] return values of `partitionleaderelectionalgorithms` as well as the leader election helper methods, specifically `leaderforoffline` which also does its own logging.",-1,0.9434646964073181
139298901,3765,onurkaraman,2017-09-17T01:00:52Z,i agree that it should be logged. it's just a bit tricky to cleanly consolidate all of the logging in partitionstatemachinev2. i'll give it another try in a follow-up update to this pr.,0,0.9393344521522522
139299269,3765,onurkaraman,2017-09-17T01:37:07Z,done.,0,0.9759407639503479
139316087,3765,junrao,2017-09-17T17:20:41Z,"structure-wise, it's probably better to do line 234 to 238 in electleaderforpartitions()?",0,0.9853551387786865
139316113,3765,junrao,2017-09-17T17:22:09Z,could we add a comment on what will fail if this is not added?,0,0.9812464118003845
139317183,3765,onurkaraman,2017-09-17T18:07:56Z,"we could, but in doing so, we'd have to return more state to `electleaderforpartitions`. currently, `doelectleaderforpartitions` returns `(seq[topicandpartition], seq[topicandpartition], map[topicandpartition, exception])` where the successes are just that first `seq[topicandpartition]`. if we delegate the work to `electleaderforpartitions`, we'd have to pass back not only the successful partitions, but their leaderandisr as well as the intended recipients of that partition's share of leaderandisrrequest. the code could end up messier as a result.",0,0.9742843508720398
139318096,3765,onurkaraman,2017-09-17T18:48:30Z,"sure. alternatively, one option is to just get rid of scala default arguments in controllerbrokerrequestbatch. if we actually want to keep something resembling default arguments, we can just do it the java way. split the methods with default arguments into two: 1. one with all of the arguments 2. one without the default argument that fills in the default value for the user. i'm fine with either commenting why or converting to java-style default arguments.",0,0.9739037752151489
139323536,3765,junrao,2017-09-17T22:57:40Z,"ok, we can leave it as it is then.",0,0.9846941232681274
139323553,3765,junrao,2017-09-17T22:58:00Z,perhaps we can just do 2?,0,0.9819533824920654
140394457,3765,junrao,2017-09-22T01:14:39Z,"could we change p to case (tp, _) to get rid of ._1 for better readability? ditto in a few other places.",0,0.7365455031394958
140394568,3765,junrao,2017-09-22T01:15:53Z,this comment is probably not longer valid?,0,0.9214168190956116
140394943,3765,junrao,2017-09-22T01:19:44Z,could we explicitly define the return type for all methods in the class?,0,0.9884048700332642
143092927,3765,junrao,2017-10-06T01:14:59Z,"it's possible that the controllereventthread has just taken an event out of the queue before eventmanager.clearandput(expire) is called. so, it seems that we need to wait for controllereventthread to return back to idle state before creating a new zk session. otherwise, controllereventthread may use the newly create zk session to process an event that happens before the session expiration.",0,0.9875677824020386
143096688,3765,junrao,2017-10-06T01:57:13Z,perhaps it's better to close kafkacontrollerzkutils before shutting down the controller to avoid it blocked on any zk operation.,0,0.984183669090271
143225895,3765,junrao,2017-10-06T15:47:52Z,"hmm, not sure that we really need to read the controllerid from zk again. it seems that we could just always set activecontrollerid to -1, call oncontrollerresignation(), and then call elect.",0,0.9721118807792664
143226529,3765,junrao,2017-10-06T15:50:36Z,i am wondering if we could just remove line 1242 to 1251 and alway try to create the controller path in zk.,0,0.95136559009552
143230568,3765,junrao,2017-10-06T16:07:42Z,unused import org.i0itec.zkclient.izkstatelistener and org.apache.zookeeper.watcher.event.keeperstate,0,0.9876677393913269
143231117,3765,junrao,2017-10-06T16:10:22Z,"over time, other components will be using this class, should we name this sth more general that's not tied to controller?",0,0.9879010915756226
143232047,3765,junrao,2017-10-06T16:14:59Z,this line seems unnecessary since it's done in the previous line.,0,0.9256893396377563
143232631,3765,junrao,2017-10-06T16:17:57Z,could replicastatemachine.handlestatechanges() take a set of replicas instead of a sequence?,0,0.9890705347061157
143234078,3765,junrao,2017-10-06T16:24:49Z,we probably don't intent to check code.ok again?,0,0.9643620848655701
143237031,3765,junrao,2017-10-06T16:38:57Z,"it's possible that the controller is still working on an event when expire() is called. in this case, it seems that we want to wait until the controller returns to idle state before we create a new zk session. otherwise, the controller may process an old event using the new session.",0,0.9873722791671753
143255144,3765,onurkaraman,2017-10-06T17:47:49Z,good catch. this must've been some leftover code while refactoring.,1,0.9759013652801514
143255167,3765,onurkaraman,2017-10-06T17:47:57Z,good catch.,1,0.9640093445777893
143262946,3765,junrao,2017-10-06T18:22:32Z,controllerstate.topicchange is incorrect.,0,0.6959449648857117
143263715,3765,junrao,2017-10-06T18:26:03Z,is v2 needed?,0,0.9856069087982178
143292558,3765,junrao,2017-10-06T20:56:33Z,is v2 needed?,0,0.9856069087982178
143316120,3765,onurkaraman,2017-10-07T00:20:06Z,"from an offline discussion, i think we agreed to leave this logic as is and change it in a later patch.",0,0.9813485741615295
143316125,3765,onurkaraman,2017-10-07T00:20:11Z,"from an offline discussion, i think we agreed to leave this logic as is and change it in a later patch.",0,0.9813485741615295
143318695,3765,onurkaraman,2017-10-07T01:17:23Z,good catch.,1,0.9640093445777893
143318696,3765,onurkaraman,2017-10-07T01:17:26Z,good catch.,1,0.9640093445777893
143318830,3765,onurkaraman,2017-10-07T01:21:51Z,"that's the current behavior and i think it's right. partitionmodifications is the event used for adding partitions to a topic. if you look at the other controllerstate states, it's the most accurate option.",0,0.9831956028938293
143319274,3765,onurkaraman,2017-10-07T01:38:52Z,"i was hoping to do a later ""cleanup"" pr that would contain: 1. renaming kafkacontrollerzkutils 2. removing state change logger entirely 3. doing your above suggestion of removing the ith tuple element notation ex: x._1",0,0.9793683290481567
143598970,3765,junrao,2017-10-09T23:14:27Z,"instead of exposing countdownlatch directly, perhaps it's better to add a waituntilprocessed() method in expireevent and call countdownlatch.await() there?",0,0.9877914190292358
143601978,3765,junrao,2017-10-09T23:38:37Z,i am not sure why replicas needs to be a seq instead of a set. it seems that all callers are converting a set to a seq.,0,0.7762566208839417
143604811,3765,junrao,2017-10-10T00:03:03Z,could we use case inside map to avoid unnamed reference _._2? ditto in the line below.,0,0.6870167851448059
143605920,3765,junrao,2017-10-10T00:12:17Z,"this matches the existing code. however, in this case, it seems that we probably want to throw an exception instead of proceeding w/o a new controller epoch.",0,0.9867773652076721
143607644,3765,junrao,2017-10-10T00:28:05Z,should we just pass the locally created brokerrequestbatch to both the replicastatemachine and partitionstatemachine?,0,0.9887059926986694
143611081,3765,junrao,2017-10-10T01:01:22Z,"this will be called when a topic is deleted. so, we probably want to make this a no-op instead of throwing an exception.",0,0.9804675579071045
143611266,3765,junrao,2017-10-10T01:03:36Z,"this will be called when the partition reassignment completes. so, we probably want to make this a no-op instead of throwing an exception.",0,0.9827213883399963
143611398,3765,junrao,2017-10-10T01:04:56Z,"this will be called when the preferred leader election completes. so, we probably want to make this a no-op instead of throwing an exception.",0,0.9763839840888977
143612243,3765,junrao,2017-10-10T01:14:49Z,could we use case inside filter to avoid unnamed reference p._2?,0,0.9892888069152832
143612493,3765,junrao,2017-10-10T01:17:19Z,could we use case inside partition to avoid unnamed reference _._2? there are a few other places like that.,0,0.9887104630470276
143612617,3765,junrao,2017-10-10T01:18:49Z,it seems that failedupdates.tomap can just be failedupdates.,0,0.9806679487228394
143612849,3765,junrao,2017-10-10T01:21:12Z,could we use case to avoid unnamed reference _._2? there are a few other places like that in this file.,0,0.9892885684967041
143613461,3765,junrao,2017-10-10T01:28:23Z,"could we explicitly define the return type in this and the following private method? otherwise, it's a bit hard to follow the logic.",0,0.7695927023887634
143613534,3765,junrao,2017-10-10T01:29:06Z,"the class is a bit harder to read now with the new zk wrapper. to make that a bit easier, could we add a comment to describe the return type and this method does? it may be worth doing that on a few other methods in this class as well.",0,0.9669267535209656
143614244,3765,junrao,2017-10-10T01:37:17Z,add a new line above. could we explicitly define the return type of this method?,0,0.9890949130058289
143614282,3765,junrao,2017-10-10T01:37:44Z,could we explicitly define the return type explicitly of this method and describe a bit the return type and the method? ditto for the method below.,0,0.96062833070755
143614860,3765,junrao,2017-10-10T01:44:35Z,could we add a comment to describe the return value?,0,0.9872277975082397
143614998,3765,junrao,2017-10-10T01:46:20Z,could we add a comment to describe the return value?,0,0.9872277975082397
143615041,3765,junrao,2017-10-10T01:46:52Z,could we explicitly specify the return type of this method?,0,0.9881062507629395
143615065,3765,junrao,2017-10-10T01:47:09Z,could we explicitly specify the return type of this method?,0,0.9881062507629395
143615317,3765,junrao,2017-10-10T01:50:48Z,"we probably want to wait for zookeeperclient to be connected within the connection timeout. otherwise, fail the restart of the broker.",0,0.8395359516143799
143621204,3765,onurkaraman,2017-10-10T03:04:22Z,sounds good. i'll make the change.,1,0.9293341040611267
143864242,3765,onurkaraman,2017-10-10T21:59:18Z,this is definitely something i've had in mind for a while now and i've mentioned it in the redesign doc. we agreed offline to do this change in a follow-up patch to minimize regressions.,0,0.8901791572570801
143867505,3765,onurkaraman,2017-10-10T22:16:03Z,"that's not quite right. topicdeletionmanager's `completedeletetopic` first unregisters the partitionmodificationshandler before deleting the topic znode. in addition to looking at the code, i did a topic deletion and didn't find any errors in any of the logs. i think there are 3 options here: 1. change unimplemented methods to be no-ops on a case-by-case basis. 2. change all of the controller's unimplemented handle methods to be no-ops. 3. change the traits themselves to make these methods no-ops by default. you'd only override if you need to. i am leaning towards option 3 since it'll make the code more concise but am okay with any option.",0,0.9384388327598572
143869274,3765,onurkaraman,2017-10-10T22:25:19Z,that's a good point. see my above comment describing several ways we can address this.,1,0.9569352269172668
143870540,3765,onurkaraman,2017-10-10T22:32:38Z,that's a good point. see my above comment describing several ways we can address this.,1,0.9569352269172668
143871821,3765,junrao,2017-10-10T22:39:53Z,"option 3 sounds reasonable. the thing with unregistering a watcher is that it only gets reflected during the next read. so, it may not happen immediately.",0,0.979422390460968
143880980,3765,onurkaraman,2017-10-10T23:42:31Z,"watches are tricky with zookeeper. the key point is that zookeeperclient handler unregistration is not the same thing as watcher removal. prior to zookeeper 3.5, there actually [a link]. watchers can only get removed after they get triggered. however, from the zookeeperclient's perspective, handler unregistration is local and immediate. it's possible for the zookeeper ensemble to send you a notification for a watcher after you've unregistered that watcher's corresponding handler, but it won't have any effect. zookeeperclient maintains local mappings from paths to registered handlers and updates these mappings immediately upon handler registration and unregistration. when zookeeperclient receives a watcher notification, its zookeeperclientwatcher first looks up a handler in its local mappings and only if one exists does it actually trigger the corresponding handle method.",0,0.8877448439598083
143885696,3765,junrao,2017-10-11T00:17:20Z,"ok, then, it's probably covered in this case.",0,0.9855414032936096
143898041,3765,onurkaraman,2017-10-11T02:18:37Z,"this is already exactly what happens. the zookeeperclient constructor calls `waituntilconnected(connectiontimeoutms, timeunit.milliseconds)`.",0,0.9896196722984314
143908207,3765,onurkaraman,2017-10-11T04:07:48Z,made the change in the latest update.,0,0.9761654138565063
144068415,3765,junrao,2017-10-11T16:43:53Z,it seems this should really be called onreconnectiontimeout?,0,0.9877663850784302
144133096,3765,junrao,2017-10-11T20:54:11Z,i am not sure if we need to explicitly have this callback. it seems that this can just be fold into the logic of waiting for the connection to be ready during initial connect and reconnect?,0,0.8886121511459351
144136815,3765,junrao,2017-10-11T21:08:57Z,we probably want to mention that the new leaders will be written to zk.,0,0.9870694875717163
144136971,3765,junrao,2017-10-11T21:09:28Z,identation,0,0.9879372715950012
144150290,3765,junrao,2017-10-11T22:13:41Z,this is redundant given what's in line 115.,0,0.9622012376785278
144151962,3765,junrao,2017-10-11T22:23:45Z,we probably want to document that new isr will be written to zk.,0,0.9882877469062805
144160128,3765,onurkaraman,2017-10-11T23:12:25Z,that indentation's actually what intellij suggested to me.,0,0.9857963919639587
144165799,3765,junrao,2017-10-11T23:54:29Z,this seems unnecessary since we log in the first statement in replicastatemachine.startup() already.,0,0.9765695929527283
144165817,3765,junrao,2017-10-11T23:54:44Z,this seems unnecessary since we log in the first statement in partitionstatemachine.startup() already.,0,0.9789561629295349
144177295,3765,onurkaraman,2017-10-12T01:41:48Z,done.,0,0.9759407639503479
144177305,3765,onurkaraman,2017-10-12T01:41:53Z,done.,0,0.9759407639503479
144482045,3765,onurkaraman,2017-10-13T07:27:27Z,"`statechangehandler.onauthfailure` only gets used in our zookeeperclient's custom zookeeperclientwatcher: [code block] `statechangehandler.onauthfailure` would only get called when the raw zookeeper client transitioned from the connecting state to the auth_failed state as shown in the state transition diagram below: [a link] there are three scenarios that could have caused you to be in the connecting state in the first place: 1. initial zookeeperclient instantiation 2. transient disconnect from the zookeeper ensemble 3. zookeeperclientwatcher initializing a new session after session expiration if you get rid of `statechangehandler.onauthfailure`, then only 1 and 3 will react to the auth failure on their own: * for scenario 1, assuming you want to keep the thrown zookeeperclientauthfailedexception, then 1 will throw that exception in waituntilconnected. * for scenario 3, eventually the connection timeout will be hit and the `statechangehandler.onconnectiontimeout` will get called. * however for scenario 2, without `statechangehandler.onauthfailure`, a reaction to the auth failure for 2 can only occur if the user calls waituntilconnected or if they observe the return code from any requests that were in-flight or sent after the auth failure. so you now risk a scenario where the application is just sitting around indefinitely with a client in the auth_failed state.",0,0.9841700792312622
144585764,3765,ijuma,2017-10-13T15:29:17Z,"out of curiosity, what is the reasoning for the `listener` -> `handler` rename?",0,0.9769957661628723
144588126,3765,ijuma,2017-10-13T15:38:31Z,"btw, there are some really long lines in this pr. our convention is that lines should not be longer than the github review window.",0,0.9713975191116333
144624196,3765,junrao,2017-10-13T18:18:07Z,"hmm, in case 2, wouldn't the zk session expire eventually?",0,0.9845811724662781
144668085,3765,junrao,2017-10-13T22:18:38Z,"we probably want to delete the log dir event first and then register the handler. otherwise, we may be processing those events triggered by deletion unnecessarily. ditto for deleteisrchange.",-1,0.6489682197570801
144669429,3765,junrao,2017-10-13T22:29:17Z,it seems that it's better to batch the call to handlestatechanges across all replicas like before?,0,0.985029399394989
144669526,3765,junrao,2017-10-13T22:30:08Z,"we only need to do this on newtopics, right?",0,0.9712597131729126
144676732,3765,onurkaraman,2017-10-13T23:42:37Z,good catch.,1,0.9640093445777893
144677353,3765,onurkaraman,2017-10-13T23:50:05Z,done.,0,0.9759407639503479
144680808,3765,onurkaraman,2017-10-14T00:45:15Z,"the diagram seems to indicate that you can either hit auth failure or session expiration, but not both.",0,0.9872345328330994
144681072,3765,junrao,2017-10-14T00:51:03Z,"hmm, that could be true. perhaps we could keep it and just log an error for now.",0,0.985079288482666
144681238,3765,onurkaraman,2017-10-14T00:54:51Z,"1. it's more concise. 2. it's also easier to read and verbalize, for me at least. 3. it let me keep both version of the classes side-by-side as a reference. 4. they pretty much mean the same thing in programming.",0,0.9036415219306946
145007795,3765,junrao,2017-10-17T01:13:16Z,instead of duplicating the comment. we could just refer it to the one in handle(requests: seq[asyncrequest])?,0,0.9889857769012451
145007985,3765,junrao,2017-10-17T01:15:05Z,"registerznodechildchangehandler(znodechildchangehandler: znodechildchangehandler) calls this method. so, it's better to put the detailed comments here and let the former refer it here.",0,0.986793577671051
145008953,3765,junrao,2017-10-17T01:26:05Z,"it seems that in all state transitions, it's useful to know the assigned replica list, the leader and the isr. perhaps, we can just do a generic logging at the end of the method?",0,0.9865320324897766
145010777,3765,junrao,2017-10-17T01:44:39Z,i had a comment on this before. should onconnectiontimeout() be onreconnectiontimeout?,0,0.9875072240829468
145206369,3765,junrao,2017-10-17T17:57:40Z,could we explicitly define the return type of this method?,0,0.9876431226730347
145206447,3765,junrao,2017-10-17T17:57:56Z,could we explicitly define the return type of this method?,0,0.9876431226730347
145212540,3765,onurkaraman,2017-10-17T18:19:03Z,"now that we've decoupled handler registration from watcher registration, there's really no benefit to having `registerznodechangehandlers` and `registerznodechildchangehandlers` since these are now purely local operations and equivalent to registering one-at-a-time. i'm going to remove these methods.",0,0.9673283696174622
145215526,3765,onurkaraman,2017-10-17T18:29:16Z,"hmm not sure if this would actually work. some of these concepts don't even exist in certain states. - newpartition has no leader or isr. - nonexistentpartition has no replicas, leader, or isr.",0,0.7961738705635071
145215623,3765,onurkaraman,2017-10-17T18:29:38Z,sure.,0,0.9536533951759338
145215655,3765,onurkaraman,2017-10-17T18:29:47Z,makes sense.,0,0.9637326002120972
145227489,3765,junrao,2017-10-17T19:12:45Z,"ok. maybe in the case where we transition to onlinepartition, we can just log the whole leaderandisr instead of just the leader.",0,0.9870815873146057
145250912,3765,onurkaraman,2017-10-17T20:45:25Z,done,0,0.9764507412910461
145250947,3765,onurkaraman,2017-10-17T20:45:34Z,done.,0,0.9759407639503479
145250967,3765,onurkaraman,2017-10-17T20:45:40Z,done.,0,0.9759407639503479
145483014,3765,tedyu,2017-10-18T17:20:24Z,dowork() doesn't use putlock. is it possible that an event retrieved by dowork() is supposed to be cleared by this call ?,0,0.986584484577179
145488953,3765,tedyu,2017-10-18T17:42:14Z,updatestoretry is not used.,0,0.9634483456611633
145489072,3765,tedyu,2017-10-18T17:42:39Z,partitionsleadbybroker -> partitionsledbybroker,0,0.9878647923469543
145664130,3765,ijuma,2017-10-19T10:46:03Z,"i think it's a good point that we should document the expected behaviour even if there's no bug. , can we please do that in a follow-up?",0,0.8629109859466553
145664835,3765,ijuma,2017-10-19T10:49:39Z,fixed in [a link],0,0.98800128698349
145664852,3765,ijuma,2017-10-19T10:49:45Z,fixed in [a link],0,0.98800128698349
145820562,3765,junrao,2017-10-19T20:52:58Z,"the purpose of putlock is to make sure no other callers can put anything to the queue in the middle of a clearandput() call. it's ok for a reader to have taken an event out of the queue just before the queue is cleared since in kafkacontroller.expire(), we wait until the last event in the queue is processed before creating a new zk session. we can probably document this to make it clear.",0,0.9867522716522217
1104737066,13240,Hangleton,2023-02-13T16:38:01Z,"the sequence of validation chosen here reflects what is used on the fetch request path: - if topic ids are used and the given topic id cannot be resolved (and no fallback name is provided), send back `unknown_topic_id`; - if the topic name is valid but that name is not authorized, send `topic_authorization_failed`; - if the topic name is authorized but not present in the metadata cache (in which case, that topic will not have been resolved via its id because in this case, we expect it to be in the cache), send `unknown_topic_or_partition`.",0,0.985771656036377
1104738082,13240,Hangleton,2023-02-13T16:38:36Z,note: topic id must not be null for a request/response version >= 9 to be serialized. `zero_uuid` means no topic id specified.,0,0.9876812696456909
1104738961,13240,Hangleton,2023-02-13T16:39:12Z,note: topic id must not be null for a request/response version >= 9 to be serialized. `zero_uuid` means no topic id specified.,0,0.9876812696456909
1104740902,13240,Hangleton,2023-02-13T16:40:29Z,"note 1: if the `topicname` is not null, we should also check if it resolves to the same uuid as we have cached locally.",0,0.9874479174613953
1104760648,13240,Hangleton,2023-02-13T16:53:38Z,note 2: we could fail partially - just for the given topic entry - rather than the entire response.,0,0.9786571860313416
1105846605,13240,dajac,2023-02-14T13:48:17Z,"there is very likely a bug here. in this case, `topic.name` is `null` and the response builder uses a hashmap keyed by topic name. therefore, all the topics with an unknown topic id will end up together.",0,0.9726056456565857
1105854122,13240,dajac,2023-02-14T13:54:34Z,"we are calling `resolvetopicname` three times. i think that it would be better to iterate once over the topics to resolve the topic ids and build the list of topic names (if one was found) while doing this. then, we can check the authorization and do the rest.",0,0.9840436577796936
1105855843,13240,dajac,2023-02-14T13:55:54Z,i suppose that this check is not necessary if we are using topic ids. we already know that the name resolved based on the topic id is valid.,0,0.9863638281822205
1105985661,13240,Hangleton,2023-02-14T15:31:23Z,"apologies, you are right. this hints that perhaps we should reconstruct the list of `offsetcommitrequesttopic` and use it internally to avoid any such mistake?",0,0.8277677297592163
1105987099,13240,Hangleton,2023-02-14T15:32:31Z,"you are right, yes. let's make this explicit in the code.",0,0.9693770408630371
1106229439,13240,Hangleton,2023-02-14T18:36:47Z,"i replaced this approach with a single iteration over the list of topic data, resolving and populating the topic name in place (line 455). i am concerned though because this involved mutating the request's body. but i am also concerned about the cost of creating a new arraybuffer, sequence or another data structure to pre-filter. without falling into premature optimization, what do you think about in-place mutation? i think the problem here is that we have the instantiation of the `offsetcommitrequest` decoupled from the resolution of topic ids. it makes sense since the former corresponds to the request deserialization while the latter corresponds to added semantics unconveyed by the request itself. in responsibility chains on server request handlers, one pattern sometimes adopted is to decorate a request with extraneous information which fall beyond the scope of ser/de. i wonder if topic id resolution could happen before passing it to the business request handler.",-1,0.7191101908683777
1113132735,13240,dajac,2023-02-21T14:21:42Z,nit: we probably don't need to duplicate `data` here. i understand why you are doing it but in practice we assume that `data` is owned by the builder once it is given to it.,0,0.9851890802383423
1113142734,13240,dajac,2023-02-21T14:29:30Z,nit: invalidrequestexception would be more appropriate.,0,0.9872698783874512
1113146018,13240,dajac,2023-02-21T14:32:07Z,i just realized that this is only used in tests. i wonder if we should just get rid of it and use the auto-generated classes in tests as well.,0,0.818467378616333
1113149061,13240,dajac,2023-02-21T14:34:29Z,nit: you could replace this by the following: [code block],0,0.9882783889770508
1113151869,13240,dajac,2023-02-21T14:36:46Z,nit: ditto.,0,0.6388124823570251
1113153482,13240,dajac,2023-02-21T14:37:59Z,nit: we could remove this empty line.,0,0.9868703484535217
1113156030,13240,dajac,2023-02-21T14:39:58Z,"i think that there is a bug here for the case where multiple topic ids are unknown in a single request. for those, the topic name will be null so they will be aggregated in the same offsetcommitresponsetopic and that one will have the topic id of the first unknown topic id seen.",0,0.9792928695678711
1113156632,13240,dajac,2023-02-21T14:40:25Z,nit: i think that we could remove this comment. it does not bring much.,-1,0.7464984655380249
1113157135,13240,dajac,2023-02-21T14:40:49Z,the kip also specifies new errors for this version. could we mention them here?,0,0.9889025092124939
1113160687,13240,dajac,2023-02-21T14:43:33Z,"at l1361 in this file, we construct `topicpartition` based on the response data but we don't resolve the topic id. i think that we should add the resolution there as well, no? we probably need to extend tests to better cover this as well. regarding `unknown_topic_id`, would it make sense to place it after `unknown_topic_or_partition` as they are quite similar?",0,0.9826138615608215
1113164928,13240,dajac,2023-02-21T14:46:18Z,"i would prefer to inline `resolvetopicname` and avoid allocating an `option` which does not bring much here. in the mean time, i would directly construct the list of topic names for the authorizer at l461. this way, we could save re-iterating over the topics and the `filter`. what do you think? moreover, the kip states that an `invalid_request` should be return if both a topic id and a topic name are provided. we could also handle this here.",0,0.9844223260879517
1113175049,13240,dajac,2023-02-21T14:52:56Z,"this issue is still present. yeah, we definitely need to update the response builder to support this. one way would be to change the semantic of `addpartitions` to directly add to the response when it is called and to only put the topic in the hashmap when `addpartition` is used.",0,0.9777604937553406
1113176828,13240,dajac,2023-02-21T14:54:08Z,it would be great if we could extend the tests here. i think that we need to use multiple unresolvable topic ids in the same request and also check the different versions. i am not sure if we could extend this one or if we should add other ones.,0,0.8041403293609619
1113178848,13240,dajac,2023-02-21T14:55:25Z,"what's the reason for this change? if we refactor this, it may be better to directly go with the auto-generated data structures.",0,0.9836927056312561
1113183283,13240,dajac,2023-02-21T14:58:39Z,we also need tests to check if the response is handled correctly.,0,0.9838119149208069
1113220631,13240,dajac,2023-02-21T15:26:05Z,nit: could we add `.` at the end?,0,0.9876481294631958
1113220793,13240,dajac,2023-02-21T15:26:12Z,nit: could we add `.` at the end?,0,0.9876481294631958
1116196039,13240,Hangleton,2023-02-23T20:10:09Z,"sure, i used the auto-generated class in the unit test for the `offsetcommitrequest`. i moved this method to the unit test class as it is used from other unit tests in for the consumer coordinator, from where using the full-fledged request object would be less convenient.",0,0.9868037104606628
1116198012,13240,Hangleton,2023-02-23T20:12:23Z,"you are right, thanks for finding this bug (again!). i followed the approach you suggest here in the builder of the `offsetcommitresponse`, please let me know if the semantics make sense.",1,0.945986270904541
1116200049,13240,Hangleton,2023-02-23T20:14:13Z,"that is right, thanks for pointing out. the resolution of topic name has been added to the response handler. if the topic is not defined, or the response topic is invalid because it contains neither an id or name, or contains both, that topic is ignored. the offset commit invocation is however not failed.",0,0.5156522989273071
1116202452,13240,Hangleton,2023-02-23T20:16:23Z,"thanks, i built the list of resolved topics and pass it to the authorizer, inlining name resolution. if a topic has both a name and id defined, the broker fails fast the request and returns an `invalid_request`. is this what you had in mind? should we send more information to the client in that case?",1,0.7933643460273743
1116203414,13240,Hangleton,2023-02-23T20:17:14Z,"sure, i added another unresolvable topic to the request/response. i will add more cases covering more of the possible code paths.",0,0.9850483536720276
1116204122,13240,Hangleton,2023-02-23T20:17:54Z,"sure, i reverted this refactoring and use the response class instead.",0,0.9898363947868347
1116205901,13240,Hangleton,2023-02-23T20:19:26Z,"that is right, i added tests which invoke the sync and async offset commit method.",0,0.989018440246582
1119248386,13240,dajac,2023-02-27T19:58:06Z,"i discussed offline with a few committers and the consensus is that having both the topic name and the topic id in the same version is not the right way. they share the same concerns that we discussed last week. could you update the pr to only have topicid from version 9? we can also remove the nullableversions for the name and set the versions to 0-8. i suppose that both fields could be ignorable. regarding the admin client, which does not support topic ids, it cannot use version 9 at the moment. we need to handle this in the builder (we can set the maximum allowed version). sorry for this late change.",0,0.9295095205307007
1119798298,13240,Hangleton,2023-02-28T09:40:06Z,"hi david, thanks for the follow-up and clarifying. this is all good, i am working on adapting the pr. thanks!",1,0.9876478910446167
1121486904,13240,dajac,2023-03-01T10:29:55Z,"now that we can rely on the version, we should use it here and simplify all this logic.",0,0.9783066511154175
1121487731,13240,dajac,2023-03-01T10:30:29Z,it would be better to rely on the version of the request instead of the topic name here.,0,0.9847890138626099
1121488495,13240,dajac,2023-03-01T10:31:00Z,i would move this up and do it in the first iteration.,0,0.9825094938278198
1121489116,13240,dajac,2023-03-01T10:31:23Z,you could use `resolvedtopics` instead of `offsetcommitrequest.data.topics` here.,0,0.9848963022232056
1121494379,13240,dajac,2023-03-01T10:35:07Z,i think that we could remove those checks now.,0,0.9855668544769287
1121496085,13240,dajac,2023-03-01T10:36:34Z,i think that we could just set both the name and the id all the time as the fields are ignorable. the serialization framework will do the right thing based on the version. we could also remove `version` from the arguments.,0,0.98609459400177
1121499577,13240,dajac,2023-03-01T10:39:12Z,we could get this in the base class and always set both of them. the serialization framework knows what to do.,0,0.9840008020401001
1121501980,13240,dajac,2023-03-01T10:41:03Z,"is this change related to the pr? if not, i would rather do it in a separate pr.",0,0.9739062190055847
1121502171,13240,dajac,2023-03-01T10:41:14Z,same question here.,0,0.9746769666671753
1121506569,13240,dajac,2023-03-01T10:44:43Z,"i am not a fan of all those attributes in test. one or two are fine if they are really re-used on all the tests. otherwise, it may be better to check define what you need in tests. i would also use `topicidpartition` when relevant so you can basically group the name, id, and partition together.",-1,0.9588335156440735
1121510354,13240,dajac,2023-03-01T10:47:36Z,is this really needed?,0,0.9841893315315247
1121710275,13240,Hangleton,2023-03-01T13:14:50Z,note: is this ok to break message round trip between < 9 and >= 9?,0,0.9826556444168091
1121724366,13240,Hangleton,2023-03-01T13:24:49Z,"adding the version to the response seems to be an anti-pattern as i haven't seen any other similar use in other responses. semantically it should be ok because the response instance is supposed to be built against a given version. if another approach is advisable, i will remove it.",0,0.974700391292572
1121724819,13240,Hangleton,2023-03-01T13:25:09Z,will add javadoc.,0,0.9864652156829834
1122096890,13240,Hangleton,2023-03-01T17:33:31Z,there is still a problem here if `topicname` and `topicid` are both undefined in which case we should do what was done before and add to the response without caching.,0,0.9780650734901428
1122097709,13240,Hangleton,2023-03-01T17:34:20Z,move the `topicresolver` in the `metadatacache` or create it without copying the map of topic ids as this is costly.,0,0.9546911716461182
1122175488,13240,Hangleton,2023-03-01T18:52:25Z,"this case shouldn't be reachable because once we have proceeded with constructing the response via `addpartition` all topic ids are supposed to have been resolved successfully. here, we choose to add the topic to the response with the error code `unknown_topic_id` if no error is already set. any existing error is not overwritten.",0,0.9818300008773804
1122188628,13240,Hangleton,2023-03-01T19:06:41Z,"at this point, topic ids should be always resolvable. however if some aren't, we should fallback to adding the topic ""as is"" to the response to avoid caching `zero_uuid` with risk of overwrites.",0,0.9851222038269043
1122265994,13240,Hangleton,2023-03-01T20:27:38Z,adding more tests to this class.,0,0.9821125268936157
1122271424,13240,Hangleton,2023-03-01T20:34:15Z,note - this duplicated invocation of the `builder` constructor is to allow the resolution of the parameter type as either `uuid` or `string`. not graceful but...,0,0.9574954509735107
1122830477,13240,Hangleton,2023-03-02T09:41:36Z,"thinking about it, it seems unnecessary to adopt a different classification for v >= 9 since topic names should always be resolved when calling `addpartition`. will remove all this logic and simplify.",0,0.9429587125778198
1124559198,13240,Hangleton,2023-03-03T14:48:12Z,not strictly needed. we can remove the condition and the logger as well.,0,0.9889699220657349
1125501983,13240,dajac,2023-03-04T16:59:02Z,should we add tests to cover this new logic?,0,0.9795658588409424
1125687390,13240,Hangleton,2023-03-05T15:35:04Z,sure! added the tests. thanks.,1,0.9746395945549011
1126511918,13240,Hangleton,2023-03-06T14:38:48Z,"hmm, we probably don't want to include a topic without id in the response version 9 here.",0,0.969916820526123
1128110858,13240,dajac,2023-03-07T16:01:47Z,nit: we usually don't leave such comment in our code base.,0,0.9084979891777039
1128111731,13240,dajac,2023-03-07T16:02:18Z,nit: should we use a boolean?,0,0.9828985929489136
1128113386,13240,dajac,2023-03-07T16:03:22Z,nit: i usually prefer to use `zero_uuid.equals(...` as it is safe for null values.,0,0.9508065581321716
1128117144,13240,dajac,2023-03-07T16:05:47Z,nit: we usually don't break long lines like this. i personally prefer the following: [code block] you can find other ways in the code base.,0,0.8595912456512451
1128122177,13240,dajac,2023-03-07T16:08:47Z,"is this really true? as we keep the `topicresolver` used to construct the request, all topics should be there. this case could happen if the server returns an unexpected topic id that was not in the request and that is not in the `topicresolver`. do i get this right?",0,0.9856195449829102
1128123974,13240,dajac,2023-03-07T16:09:50Z,"for my understanding, are we going to propagate this error back to the end user?",0,0.9768014550209045
1128126364,13240,dajac,2023-03-07T16:11:15Z,we don't really use those in our code base at the moment. we usually just mention those characteristics in the java doc.,0,0.9741520881652832
1128126821,13240,dajac,2023-03-07T16:11:31Z,should this be an invalidstateexception?,0,0.9692301154136658
1128128673,13240,dajac,2023-03-07T16:12:33Z,i am not really happy with this name but i could not find a better one yet. my concern is that this class is really about resolving topic ids/names and not really topics per say. have you considered any alternatives?,-1,0.9788609147071838
1128130754,13240,dajac,2023-03-07T16:13:43Z,is this constructor still used?,0,0.9857690930366516
1128132186,13240,dajac,2023-03-07T16:14:32Z,"nit: when we break the line like this, we usually align the arguments on the first one. otherwise, you can use the style that i mentioned earlier.",0,0.9854570031166077
1128133377,13240,dajac,2023-03-07T16:15:16Z,nit: should we also add the other ones?,0,0.9788770079612732
1128136075,13240,dajac,2023-03-07T16:16:52Z,did you check how we did this for the fetchrequest?,0,0.9870367050170898
1128141284,13240,dajac,2023-03-07T16:19:55Z,i am not sure about passing the `topicresolver` here. my understanding is that we are doing this because topic ids are lost when we call the group coordinator. wouldn't it better to update the group coordinator to preserve those topic ids? we may be able to handle this in the groupcoordinatoradaptor or we could switch to using topicidpartitions. we could also consider doing this in a separate pr as this one is already quite large.,0,0.920049786567688
1128148229,13240,dajac,2023-03-07T16:24:11Z,this does not look good. it would be better to place those helpers in `offsetcommitrequesttest` for instance or to keep them where they are used.,-1,0.49661651253700256
1128149528,13240,dajac,2023-03-07T16:24:56Z,nit: you can omit the `()` after `topics` as we usually don't put them for getters in scala. there are a few other cases in the pr.,0,0.9881740808486938
1128151493,13240,dajac,2023-03-07T16:26:10Z,i think that there is a race condition here. you have no guarantee that both maps are consistent with each others.,0,0.9495682120323181
1128154143,13240,dajac,2023-03-07T16:27:47Z,should we just throw an illegale state exception if we end up having a topic without id? ignoring it seems to be risky.,-1,0.5974743366241455
1128157560,13240,dajac,2023-03-07T16:29:43Z,i wonder if using optional is necessary here given that we always use `ornull` and `ordefault`. what do you think?,0,0.938281774520874
1129066723,13240,dajac,2023-03-08T07:41:32Z,i had a deeper look into this and it seems that we could get the version with `this.response.requestheader().apiversion()`. could you check if this would work?,0,0.9740193486213684
1129167871,13240,Hangleton,2023-03-08T09:26:49Z,"i agree with you and am not satisfied either with `topicresolver` but could not find a better name. `topicidresolver` would be misleading because this class treats topic ids and names symmetrically. one of the closest entity with similar purposes as this is in [a link] where `topicidinfo` is used to refer to the bidirectional mapping. the suffix `info` could be used here as well although it is not strictly aligned with other uses of that suffix such as in [a link]. interestingly another entity for which may have had to be assigned a generic name is [a link]. using another name to refer to the dual name/id reference such as `topicrefresolver` introduces yet another noun (_reference_) not used elsewhere in the codebase and which can be confusing. so, i am not sure about what could be a better name but maybe `topicinforesolver` or `topicidinforesolver` or `topicidinfo` or `topicidresolver` may sound better albeit still ambiguous and partially incorrect?",0,0.9105185866355896
1129194029,13240,dajac,2023-03-08T09:51:18Z,another way would be to implement a minimal and generic bimap that we could use here. would it be an option?,0,0.9866684675216675
1129266598,13240,Hangleton,2023-03-08T11:03:53Z,"with the synchronous api in the consumer, the error is not surfaced (only `true`/`false`). however, i added the missing tests to exercise the asynchronous api for this use case, and it did expose the `unknowntopicidexception` to the user. since it violates the api contract which exclusively relies on topic names, i raised the error `unknown_topic_or_partition` when an `unknown_topic_id` is returned in the offset commit response. do you think this is sensible? i added the corresponding unit tests for the consumer coordinator.",0,0.9804429411888123
1129267206,13240,Hangleton,2023-03-08T11:04:35Z,"yes, that is right. apologies, this is a fundamental misunderstanding/overlook.",-1,0.9412078261375427
1129272424,13240,Hangleton,2023-03-08T11:10:09Z,"i would tend to have a preference for a business type which conveys semantics versus a generic data structure, but that is not very important here especially since the entity exposing the bidirectional mapping is relatively short-lived when used in the code. one advantage of a generic ds is that it can be reused for other purposes. another thing is that there is no functionality provided outside that of a bimap and since no extension is foreseen, there is no need to expose a specialized type. very happy to expose it as a bimap. i could not find an existing implementation in the codebase or its dependencies, although there is a bidirectional multimap defined within restricted scope [a link].",1,0.9664993286132812
1129283573,13240,Hangleton,2023-03-08T11:22:44Z,"it was only used in tests, so best to have it removed.",0,0.9845349788665771
1129311477,13240,Hangleton,2023-03-08T11:51:54Z,"yes, this works. thanks for the call-out.",1,0.8524946570396423
1129371713,13240,Hangleton,2023-03-08T12:41:39Z,oops...,-1,0.9871377944946289
1129407685,13240,Hangleton,2023-03-08T13:11:41Z,"yes, there is a code smell here.",0,0.9830590486526489
1129452978,13240,Hangleton,2023-03-08T13:46:03Z,"i see what you mean. i moved this logic in the callback of the future which merges the results from the coordinator with those created by the request handling method. i thought about extending the support id in internal layers (group coordinator) in a pr of its own. so, eventually, the coordinator will return results populated with topic ids when applicable. added [a link] to track this work, if that is ok?",0,0.9670940041542053
1129482786,13240,Hangleton,2023-03-08T14:05:41Z,"modified the pr so that the server now sends an `unknown_server_error` when this happens, in the code moved to the future handler in `kafkaapis`. would this behaviour be acceptable?",0,0.987379789352417
1129710408,13240,Hangleton,2023-03-08T16:22:25Z,maybe `topicidandnamebimap`?,0,0.9877228736877441
1130670740,13240,dajac,2023-03-09T08:54:40Z,"i actually wonder if we should do it the other way around. we could do kafka-14793 first, merge it, and update this one accordingly. without kafka-14793, the contract of the not really respected and it feels a bit weird to work around it here instead of fixing the real issue. is kafka-14793 complicated? what do you think?",-1,0.969853937625885
1130671265,13240,dajac,2023-03-09T08:55:06Z,both names are fine for me. i leave it up to you.,0,0.8485405445098877
1130866578,13240,Hangleton,2023-03-09T11:36:23Z,"hi david, thanks for the insight. i think you are right that implementing support of topic ids in the functional layer before exposing it in the api makes sense as it provides the guarantee that offsets and metadata belong to the partitions of the right topic in case of homonyms. now, one question is how deep we go in the integration of ids in this layer. would you consider changing the data model authored by the group coordinator down to the `offsetcommitvalue ` as prescribed by kip 848?",1,0.9619266986846924
1130942769,13240,dajac,2023-03-09T12:18:21Z,the offsetcommitvalue part is not possible at the moment because we don’t have a way to downgrade. my colleague works on a proposal for this. we could start by either migrating from using topicpartition to using topicidpartition or handling this in the groupcoordinatoradaptor layer. the former is likely simpler.,0,0.9788550734519958
1131047710,13240,Hangleton,2023-03-09T13:41:44Z,"thanks for the answer. if i understand correctly, we would then have a resolution of topic ids from topic-name-based persisted data, so this may not prevent offsets from a topic to be provided as those of another topic with the same name (defined at different point in time in the server)? the resolution can be done in the group coordinator layer, assuming it has access to the topic id resolved upstream by the request handler. because we want to preserve the same mapping used when request processing started, we need to ensure the right ids are used within the adaptor's `groupcoordinator#commitoffsets` method(). since the mapping returned from the metadata cache depends on the snapshot used at the time the mapping is requested, if the adaptor retrieves it from the metadata cache internally, at a different time from the request handler, there is no guarantee the metadata is the same hence that the topic ids registered with the broker are the same. this means that the topic ids need to be propagated from the request handler (`kafkaapis`) to the coordinator adaptor somehow. without a change in the method and contract implemented by the coordinator, these ids could be transferred via the `offsetcommitrequestdata` dto directly, which means a change in the api schema would be required prior to the change. alternatively, we may want to change the interface of the coordinator and change the signature of the offset commit method to allow for the propagation of topic ids. i may be missing the entire thing though?",1,0.9184647798538208
1131114261,13240,dajac,2023-03-09T14:33:59Z,"how about doing the following? we change the signature of `groupcoordinator.handlecommitoffsets` to the following: [code block] note the change from `topicpartition` to `topicidpartition` for `offsetmetadata` and `responsecallback`. then, we have to adapt the implementation of `handlecommitoffsets` to get the `topicpartition` from the `topicidpartition` where required. we can keep `pendingoffsetcommits` and `offsets` keyed by `topicpartition` for now in `groupmetadatamanager`. this allows the preservation of the topic ids provided to the groupcoordinator but it does not provide any stronger guarantee for the offsets yet (as you pointed out). with this approach, we don't depend on the resolver at all.",0,0.9850000143051147
1131139080,13240,Hangleton,2023-03-09T14:49:42Z,"sounds good. thanks for your guidance. as you mentioned, this pr is already quite large, so if you agree, i will go ahead and implement this change first, in a pr of its own. thanks!",1,0.989211916923523
1131241761,13240,dajac,2023-03-09T15:56:05Z,sounds good to me. thanks!,1,0.9863046407699585
1168410473,13240,dajac,2023-04-17T09:17:52Z,"it looks like `topicidandnames` is only used if version >= 9. should we move it that else branch? moreover, it seems that we don't need the bimap anymore here. should we just get the mapping that we need and revert the bimap think in the `metadatacache`?",0,0.985823392868042
1168412474,13240,dajac,2023-04-17T09:19:41Z,"just to be sure. the addition of `true` is the only real change here, right?",0,0.9837622046470642
1168414850,13240,dajac,2023-04-17T09:21:50Z,i think that `topicid` is optional so we could just set it here.,0,0.9876706600189209
1168415581,13240,dajac,2023-04-17T09:22:24Z,"is using `true` all the time correct here? i suppose that it should be `false` if `version` < 9, no?",0,0.9870309233665466
1168416665,13240,dajac,2023-04-17T09:23:22Z,nit: i think that we could set it all the time here as well.,0,0.9656988978385925
1168423960,13240,dajac,2023-04-17T09:29:54Z,"should this test be parameterized as well? with this change, it seems that we don't have any tests exercising the validation with topic names now.",0,0.9706827402114868
1168430856,13240,dajac,2023-04-17T09:35:45Z,nit: `true` should be derived from the `version`.,0,0.988469660282135
1168433830,13240,dajac,2023-04-17T09:38:23Z,"changing the code structure like this is really annoying during reviews. it explodes the diff for no reasons and distracts the reviewing from the more important changes. it would be better to keep those for separate prs. in this case, we could just add the `true` and the `topicid` to the previous code.",-1,0.9830154776573181
1168454144,13240,dajac,2023-04-17T09:56:31Z,would you mind if we keep to keep those code refactoring in the tests for separate pr(s)? this pr is already extremely large and i would like to focus on getting the new code right. all those non-related changes are additional (unnecessary) distractions for now.,0,0.9443885684013367
1168456953,13240,dajac,2023-04-17T09:59:08Z,i think that you could pass config overrides to `createconsumer` directly.,0,0.9890382289886475
1168464261,13240,dajac,2023-04-17T10:05:22Z,i think that consumers created with `createconsumer` are closed automatically by the super class.,0,0.9884816408157349
1168468628,13240,dajac,2023-04-17T10:09:03Z,nit: this could be private.,0,0.9871900677680969
1168468929,13240,dajac,2023-04-17T10:09:20Z,nit: `topicnames.map(topic => {` -> `topicnames.map { topic => `,0,0.986362874507904
1168469544,13240,dajac,2023-04-17T10:09:58Z,do we really need to use `nameandid` here? this does not seem necessary.,0,0.9514152407646179
1168470063,13240,dajac,2023-04-17T10:10:28Z,"nit: you could get `topicids` with `gettopicids(""topic1"", ""topic2"", ""topic3"")`.",0,0.9866045117378235
1168472971,13240,dajac,2023-04-17T10:13:06Z,i would rather prefer to use the request/response data objects here.,0,0.9779238104820251
1168473224,13240,dajac,2023-04-17T10:13:22Z,could we parameterize the test instead of doing this?,0,0.9852278232574463
1168473647,13240,dajac,2023-04-17T10:13:46Z,i wonder if we already have integration tests for the consumer covering this. do we?,0,0.8969532251358032
1168474784,13240,dajac,2023-04-17T10:14:55Z,this test does not seem to be at the right place. it seems to me that `offsetcommitrequesttest` is more focused on testing the offsetcommitrequest api.,0,0.9144564270973206
1168475048,13240,dajac,2023-04-17T10:15:09Z,nit: let's make all the private methods private.,0,0.9864076375961304
1168475457,13240,dajac,2023-04-17T10:15:32Z,nit: could we revert this change and just add the boolean?,0,0.9843736886978149
1168671042,13240,dajac,2023-04-17T13:11:41Z,nit: indentation seems to be off here.,0,0.981717586517334
1168675481,13240,dajac,2023-04-17T13:14:40Z,nit: `topicidorzero`?,0,0.9833865761756897
1168676628,13240,dajac,2023-04-17T13:15:01Z,nit: `topicnameornull` and get rid of the `optional`?,0,0.9876279830932617
1168677142,13240,dajac,2023-04-17T13:15:24Z,nit: should we remove ` `?,0,0.9823519587516785
1168678603,13240,dajac,2023-04-17T13:16:32Z,nit: should we replace `ofnullable` by a simple `if/else` statement? allocating an optional does not seem necessary here.,0,0.9785743951797485
1168679689,13240,dajac,2023-04-17T13:17:09Z,nit: this one is already in the list (l47).,0,0.9860138893127441
1168688432,13240,dajac,2023-04-17T13:23:02Z,"nit: could we try to combine those? `private static topicidpartition t1p = new new topicidpartition(uuid.randomuuid(), 0, topic1)`?",0,0.987800121307373
1168689266,13240,dajac,2023-04-17T13:23:38Z,nit: `topicidandnamebimapping`?,0,0.9873972535133362
1168693500,13240,dajac,2023-04-17T13:26:00Z,nit: this empty line could be removed.,0,0.9853678345680237
1168694559,13240,dajac,2023-04-17T13:26:28Z,nit: this empty line could be removed.,0,0.9853678345680237
1168696909,13240,dajac,2023-04-17T13:28:15Z,"if the outcome of the test is different in this case, isn't it a bit weird to combine them in the same unit test?",-1,0.6946394443511963
1168703280,13240,dajac,2023-04-17T13:33:05Z,this goes a bit too far in my opinion. we usually prefer to have simpler parameterized tests. could we simplify this somehow and bring stuck back in the main unit test?,-1,0.5258866548538208
1168735466,13240,dajac,2023-04-17T13:52:19Z,"this one made me think that we are probably not doing the right thing in the implementation. in this particular case, if we have only one committed offset and we don't have a response for it because the topic id is wrong, i think that `commitoffsetssync` should not succeed because we actually don't know if the offset was committed or not. what do you think? one way around this would be to verify that we have received a response for each topic-partitions.",0,0.752830445766449
1168742716,13240,dajac,2023-04-17T13:57:02Z,i am not sure to follow why we need this `consumer` here. couldn't we just have a matcher which verifies what we want/need?,-1,0.5717790126800537
1168815694,13240,dajac,2023-04-17T14:36:03Z,"this seems to be a quite complicated way to group `offsetcommitrequestpartition` or `offsetcommitresponsepartition` by `topicidpartition`, no? i would just write two methods to do just this.",0,0.9373247027397156
1185002319,13240,clolov,2023-05-04T13:17:25Z,i believe t1p is abstracted because it is being used in 175 other places in this test class for test setup and assertions.,0,0.9833872318267822
1185137613,13240,clolov,2023-05-04T14:51:40Z,"sorry, could you elaborate, because i am not certain i follow? `gettopicids(...)` will return a map but only if the topics requested have been created first. are you suggesting that since all tests create these three topics we move the creation to the setup method and then we use `gettopicids` everywhere else?",-1,0.9840519428253174
1185779424,13240,Hangleton,2023-05-05T07:29:21Z,"that is right. christo, maybe you can create two separate tests for these cases and factor in common code in a method?",0,0.7680642008781433
1185861417,13240,clolov,2023-05-05T09:04:20Z,"yup, i will get to this today",1,0.8315418362617493
1197974839,13240,clolov,2023-05-18T15:36:59Z,"to be honest i would prefer if we leave it like this. if we parameterise it, this means we have to change `sendoffsetcommitrequest`. if we change `sendoffsetcommitrequest` then we need to come up with a different source for `testoffsetcommitwithunknowntopicid`. alternatively i can parameterise this test, but i would end up wrapping a single version in a seq. is the reason you want it parameterised here so that it breaks it down when running the tests in intellij?",0,0.8888627290725708
1197988726,13240,clolov,2023-05-18T15:49:27Z,from my reading of the code this consumer is a captor. we validate some of the things in this method and we validate the overall captured value elsewhere in individual tests. i am not too certain how this can be simplified to just a matcher to be honest.,0,0.6353111267089844
1203965540,13240,Hangleton,2023-05-24T11:46:23Z,"i think david probably hints at consolidating both in one defining object to ease future updates of topic-partition to topic ids. i updated the test class as per david's comment, i am happy to revert if this brings too many loc changes.",1,0.9331523180007935
1203992806,13240,Hangleton,2023-05-24T12:03:45Z,"i think i see what you mean, it is rather heavy-weight and lacks single scope which is preferable for unit tests. updating accordingly.",0,0.9464251399040222
1204079800,13240,Hangleton,2023-05-24T12:54:16Z,did the change to provide higher cohesion to the tests. i split the initial test method in two separated test methods.,0,0.9768033027648926
1204087015,13240,Hangleton,2023-05-24T12:58:43Z,that is true.,0,0.976017415523529
1204151150,13240,Hangleton,2023-05-24T13:34:57Z,"sure, i removed the method `createtopics` and use `gettopicids` instead.",0,0.9890432357788086
1204162396,13240,Hangleton,2023-05-24T13:40:14Z,"yes, i think the idea of parameterizing the test by version of request is it is faster to identify version-specific failures.",0,0.9821848273277283
1204312762,13240,Hangleton,2023-05-24T14:52:34Z,added a commit to build the dtos directly. this removes the contingency on correctness of the test code which built these dtos.,0,0.9871216416358948
1204356253,13240,Hangleton,2023-05-24T15:12:20Z,"you are right, this is exercised in `offsetfetchrequesttest`, `plaintextconsumertest`, `groupcoordinatorintegrationtest` and `authorizerintegrationtest`. so, i removed this test to avoid duplication.",0,0.9823164343833923
1204361177,13240,Hangleton,2023-05-24T15:14:16Z,added parameterization as david suggested.,0,0.9861387610435486
1204376110,13240,Hangleton,2023-05-24T15:20:43Z,"agreed, i thought to put it there because the underlying rpc is used, but you are right, it is a different client-level api.",0,0.9692131876945496
1204403475,13240,Hangleton,2023-05-24T15:33:49Z,i removed the test since this method is already exercised in `org.apache.kafka.clients.admin.kafkaadminclienttest#testoffsetcommitnumretries`.,0,0.9891023635864258
1205089112,13240,Hangleton,2023-05-25T07:11:05Z,"just to clarify, do you mean the commit offsets method should return false when at least 1 over n > 1 could not be committed due to topic id mismatch, or when n == 1 could not be committed for the same reason?",0,0.9802550673484802
1205119564,13240,Hangleton,2023-05-25T07:40:48Z,"sure, that makes sense to get rid of the consumer, since it is mixing test design pattern and overlaps the responsibilities of the matcher as you pointed out.",0,0.984021008014679
1226607855,13240,dajac,2023-06-12T12:41:20Z,"as a second thought, i wonder if we should complete the future with an exception here. being defensive would help us to catch bugs early one. what do you think?",-1,0.5571448802947998
1226610273,13240,dajac,2023-06-12T12:43:20Z,should we remove this one for now as it is not implemented yet?,0,0.9735157489776611
1226612028,13240,dajac,2023-06-12T12:44:42Z,should we remove stale_member_epoch and unknown_member_id for now?,0,0.9865500926971436
1226632779,13240,dajac,2023-06-12T13:00:26Z,"my understanding is that we don't retry when `commitoffsetsasync` is used. is it correct? if it is, it may be better to split the test in two. it is really misleading otherwise.",0,0.6859667897224426
1226634411,13240,dajac,2023-06-12T13:01:50Z,nit: it may be better to name this one `prepare....`.,0,0.9806443452835083
1226634534,13240,dajac,2023-06-12T13:01:56Z,nit: it may be better to name this one `prepare....`.,0,0.9806443452835083
1226636149,13240,dajac,2023-06-12T13:03:07Z,nit: i would inline this in the respective tests because it seems not related to what this method does.,0,0.9815407991409302
1226638371,13240,dajac,2023-06-12T13:04:55Z,is this used anywhere?,0,0.9868593215942383
1226638660,13240,dajac,2023-06-12T13:05:09Z,is this used anywhere?,0,0.9868593215942383
1226647441,13240,dajac,2023-06-12T13:12:15Z,"i think that the method should return false if any mismatched topic id. if i commit foo-topic-id and bar-topic-id, the method should not succeed if we don't get a response for any of them, right?",0,0.9768006801605225
1226648857,13240,dajac,2023-06-12T13:13:25Z,this case is not correct as well in my opinion. the caller should get an exception in this case.,0,0.8581807017326355
1226673880,13240,dajac,2023-06-12T13:32:08Z,nit: topicnameandid?,0,0.9865713715553284
1226675517,13240,dajac,2023-06-12T13:33:23Z,it is a bit weird to have this class defined here but i cannot think of a better place for now. thoughts?,-1,0.9873778223991394
1226676007,13240,dajac,2023-06-12T13:33:43Z,nit: this seems to be misaligned.,-1,0.5431126356124878
88262234,2140,ijuma,2016-11-16T15:45:33Z,is it intentional that this is `logbuffer` instead of `log_buffer`? same for the `tostring` implementation.,0,0.98447185754776
88262970,2140,ijuma,2016-11-16T15:48:36Z,should this method be renamed as well?,0,0.9862093329429626
88285663,2140,hachikuji,2016-11-16T17:25:22Z,ack. there are probably a few of these. i'll do another pass and try to find others.,0,0.9565936326980591
89426622,2140,junrao,2016-11-24T02:13:36Z,should we assert record.magic() > 0?,0,0.9877512454986572
89426686,2140,junrao,2016-11-24T02:14:27Z,"to be consistent, perhaps this.size and this.channel should just be size and channel?",0,0.9805876612663269
89426710,2140,junrao,2016-11-24T02:14:45Z,"it seems that some of the changes are lost during rebase? for example, there was code in memoryrecords for setting the buffer limit according to length, and cast position to int instead of creating a long object.",0,0.9834575653076172
89426721,2140,junrao,2016-11-24T02:14:55Z,"this seems to be an existing issue. for uncompressed messages, do we double count messagesread since we already increased the count in line 98?",0,0.9525653719902039
89426736,2140,junrao,2016-11-24T02:15:05Z,this and line 144 don't seem to be correct. it seems that we should add the number of entries in retainedentries?,0,0.970643937587738
89426742,2140,junrao,2016-11-24T02:15:10Z,should we add slice.limit or slice.position?,0,0.9860718846321106
89426755,2140,junrao,2016-11-24T02:15:19Z,it seems that this is only used in test now?,0,0.9849460124969482
89680530,2140,junrao,2016-11-27T00:17:36Z,"in line 337, we get the deep iterator by constructing a logbufferiterator with shallow set to false. to be consistent, it seems that if we want to get a shallow iterator, we should construct a logbufferiterator with shallow set to true instead of call a separate static method?",0,0.9879035353660583
89680531,2140,junrao,2016-11-27T00:17:43Z,is this comment at the right place? the following code doesn't directly allocate any buffer.,0,0.9833750128746033
89680539,2140,junrao,2016-11-27T00:17:57Z,"since logentries is a deque, perhaps it's clearer if we explicitly use addlast() ?",0,0.9868637323379517
89680541,2140,junrao,2016-11-27T00:18:03Z,recordsiterator.deeprecordsiterator is no longer valid.,0,0.9239022135734558
89698576,2140,junrao,2016-11-27T20:26:51Z,"instead of having shallowentries() and deepentries(), would it be better to combine them into a logentries(boolean isshallow)? this will make it consistent with how we get an iterator for records through abstractlogbuffer.records(boolean isshallow).",0,0.987301230430603
89698580,2140,junrao,2016-11-27T20:26:55Z,this can be private.,0,0.9870530962944031
89698584,2140,junrao,2016-11-27T20:27:07Z,"hmm, this seems like an existing issue. it seems that we should subtract the wrapper header and the record overhead from position() to get the compressed data size?",0,0.9531417489051819
89698589,2140,junrao,2016-11-27T20:27:17Z,could this be private since it seems to be only used within the class?,0,0.9861488342285156
89698592,2140,junrao,2016-11-27T20:27:35Z,"it seems that logentry.writeheader() is only used inside this class. perhaps we could just move the code from logentry to here as a private method. once we do that, it seems that we could also make putlong() and putint() private in this class.",0,0.9879062175750732
89698597,2140,junrao,2016-11-27T20:27:41Z,it seems that we could just eliminate this line?,0,0.9784491062164307
89931628,2140,junrao,2016-11-29T02:43:47Z,"with this change, it seems that we can make bufferpool.deallocate(bytebuffer buffer, int size) private?",0,0.9893261194229126
89931638,2140,junrao,2016-11-29T02:43:52Z,should we just remove the commented out code?,0,0.9823216199874878
89931661,2140,junrao,2016-11-29T02:44:09Z,perhaps we can make the comment clearer by saying that this can happen when there is no full log entry in the log buffer.,0,0.9850226044654846
89931696,2140,junrao,2016-11-29T02:44:35Z,would it be necessary to cache the record instance and reuse? it seems that a few methods like size() and setcreatetime() are calling record().,0,0.988032341003418
89931716,2140,junrao,2016-11-29T02:44:46Z,this maybe a bit confusing since our default compression type to the user is none. could we let the callers use gzip directly?,0,0.5731498003005981
89931730,2140,junrao,2016-11-29T02:44:52Z,$targettimestamp can only be used in scala.,0,0.9877384901046753
89931765,2140,junrao,2016-11-29T02:45:09Z,could we just always load records lazily and get rid of eagerloadrecords? not sure if we lose any performance by doing that.,0,0.8962217569351196
89931793,2140,junrao,2016-11-29T02:45:18Z,"to be consistent, should we change record to message?",0,0.9875708818435669
89931855,2140,junrao,2016-11-29T02:45:53Z,could we rename shallowentries/deepentries to shallowlogentryiterator/deeplogentryiterator so that it's clear that we are not buffering all entries in the call?,0,0.9886041879653931
89931924,2140,junrao,2016-11-29T02:46:37Z,"the contract for loginputstream seems to be that a null value from calling nextentry() indicates normal completion of the iterator and any ioexception indicates an error. so perhaps we should capture eofexception in dataloginputstream since it's only expected there, and convert it to a null return value in nextentry(). then, here, we can just check null for ending the iterator like other places.",0,0.9880139827728271
89931932,2140,junrao,2016-11-29T02:46:43Z,do we want to add a separator between records?,0,0.9870844483375549
89931956,2140,junrao,2016-11-29T02:46:53Z,perhaps we could add a comment here that this class deals with the write path to memorylogbuffer while memorylogbuffer only deals with the read path?,0,0.9887913465499878
89931968,2140,junrao,2016-11-29T02:47:03Z,could this method just call appendunchecked() to avoid code duplication?,0,0.9875605702400208
89931980,2140,junrao,2016-11-29T02:47:09Z,it seems that estimatedbyteswritten() and numrecordswritten() can be private?,0,0.9888951778411865
89931983,2140,junrao,2016-11-29T02:47:11Z,bufferstream.buffer() can just be buffer().,0,0.9886485934257507
89932016,2140,junrao,2016-11-29T02:47:36Z,"this also seems to be an existing issue. until memorylogbufferbuilder is closed, buffer().position() is not necessarily accurate since the compressor may not have flushed compressed data to the output stream. currently, recordaccumulator.drain() calls this method before closing memorylogbufferbuilder. so, if builtlogbuffer != null, perhaps it's better to use estimatedbyteswritten()?",0,0.9829587340354919
89932051,2140,junrao,2016-11-29T02:47:59Z,"this also seems to be an existing problem. it seems that when generating those internal messages (tombstone, groups, etc), we assume the message timestamp type is always create_time. however, the offset topic could be configured with log_append_time.",0,0.9817414879798889
89932067,2140,junrao,2016-11-29T02:48:08Z,it seems that we could get rid of ensurematchingmagic since no caller is setting it?,0,0.987863302230835
90155476,2140,junrao,2016-11-30T01:52:30Z,"for compressed messageset, perhaps it's more consistent if we always return the lastoffset as offsetofmaxtimestamp regardless of the timestamp type? we only need that for timestamp indexing. indexing at the shallow offset level is good enough and will make the indexing logic consistent between the leader replica and the follower replica (which doesn't do decompression during log append).",0,0.9833871722221375
90155523,2140,junrao,2016-11-30T01:52:58Z,"to be future proof, should we pass in the timestamp in this record instead of no_timestamp?",0,0.9886804819107056
90155541,2140,junrao,2016-11-30T01:53:10Z,"since this is only used in memorylogbufferbuilder, perhaps it can be a private method there?",0,0.9881761074066162
90155548,2140,junrao,2016-11-30T01:53:14Z,it seems that this method can be private?,0,0.9863656759262085
90155558,2140,junrao,2016-11-30T01:53:18Z,it seems that this method can be private?,0,0.9863656759262085
90155589,2140,junrao,2016-11-30T01:53:35Z,"info.offsetofmaxtimestamp returns the deep offset of the message with max timestamp. to be consistent with the other code path, if compression is enabled, it seems that we want to return the shallow offset? it maybe clearer to also rename validationandoffsetassignresult.offsetofmaxtimestamp to sth like shallowoffsetofmaxtimestamp.",0,0.9845395684242249
90155602,2140,junrao,2016-11-30T01:53:42Z,it seems that toformatversion() is only used in test now?,0,0.9830101728439331
90155611,2140,junrao,2016-11-30T01:53:46Z,it seems that converttobuffer() is no longer used?,0,0.9779832363128662
90155619,2140,junrao,2016-11-30T01:53:50Z,unused import kafka.api.fetchresponsepartitiondata,0,0.9876826405525208
90155632,2140,junrao,2016-11-30T01:53:58Z,"""message set size"" is bit ambiguous. perhaps we should say ""number of messages""?",0,0.969474732875824
90155643,2140,junrao,2016-11-30T01:54:08Z,"not sure what's ""byte offset"".",0,0.6275541186332703
90155656,2140,junrao,2016-11-30T01:54:15Z,"hmm, why do we have to change the expected size?",0,0.9646123051643372
90155674,2140,junrao,2016-11-30T01:54:24Z,is there a reason that we only test non-compressed message conversion now?,0,0.9772676825523376
90361346,2140,hachikuji,2016-12-01T00:35:21Z,"hmm.. there was actually a reason for this. the static `shallowiterator` returns the more specific logentry type, which would not be possible if `shallow` is passed as an argument. having the more specific type in shallow iteration lets you do some operations to the shallow entries that are not possible with the deep entries (such as setting offsets or timestamps in-place).",0,0.9837268590927124
90363088,2140,hachikuji,2016-12-01T00:50:56Z,ack. i'll fix this and the one below and update the test cases.,0,0.9687755107879639
90377352,2140,hachikuji,2016-12-01T03:27:16Z,"to be honest, i'm not really sure why this comment is needed. it seems obvious that the key and value sizes in the inner messages are based on the uncompressed data (how could they be otherwise if we compress the inner message set as a whole?).",-1,0.6694729328155518
90377503,2140,hachikuji,2016-12-01T03:29:28Z,"thanks, i like this idea.",1,0.978744626045227
90378055,2140,hachikuji,2016-12-01T03:36:43Z,how about `shallowiterator` and `deepiterator`?,0,0.9871121048927307
90378753,2140,hachikuji,2016-12-01T03:45:52Z,"related to my comment above. the reason to separate them is so that we can return a more specific type in the shallow iterator. for `memorylogbuffer`, `shallowentries` returns `bytebufferlogentry`, which gives you hooks for writing over the offset and the timestamp. these methods do not make sense for the inner entries, so it is not desirable to add them to the general `logentry` interface. similarly, with `filelogbuffer`, we get shallow instances of type `filechannellogbuffer`, which provides its own custom hooks. the other thing i like about having the explicit names is that it makes the iteration type clear in the calling code (i don't have to remember whether `true` or `false` means shallow). for consistency, we could change `records(boolean isshallow)` to support two variants. i added this method mainly for testing, but still it would be nice to have a consistent approach.",0,0.9846920371055603
90378909,2140,hachikuji,2016-12-01T03:48:01Z,"as a matter of fact, the `shallow` option is unused for `records()`, so maybe i will change this to have it only return the deep records.",0,0.9866207838058472
90381994,2140,hachikuji,2016-12-01T04:34:16Z,"thanks for the suggestion. i modified `logentry.writeheader` to work with the `dataoutputstream`. after doing so, i found that i no longer needed `putlong` and `putint`.",1,0.9008511900901794
90382244,2140,hachikuji,2016-12-01T04:38:04Z,apologies... i often comment this out in testing and forget about it.,-1,0.9787458777427673
90382891,2140,hachikuji,2016-12-01T04:47:58Z,i think we can. the only cost is that we have to allow for the possibility of an exception thrown from `logentry.record()` instead of `loginputstream.nextentry()` (which already deals with io errors).,0,0.983371913433075
90383775,2140,hachikuji,2016-12-01T05:02:32Z,"hmm.. i think the test was broken or at least incomplete since `message.toformatversion` only did shallow conversion. when i implemented this in the client code, i forbid shallow-only conversion because it results in bugs like we found in `logcleaner`. we'll probably end up dropping this code after we remove `message.toformatversion` as suggested above.",0,0.895708441734314
90383989,2140,hachikuji,2016-12-01T05:06:19Z,"it puzzled me for a while when writing this code why the size was coming out different only for snappy, but it turns out that we've overridden the block size in the client code, instead of using the default as was done for the server code.",0,0.6402702927589417
90486643,2140,ijuma,2016-12-01T16:43:09Z,"also, in java, having named methods is clearer than using booleans since one cannot use named arguments. however, it can be a bit confusing to have both options.",0,0.6582227349281311
90487017,2140,ijuma,2016-12-01T16:44:50Z,`shallowiterator` and `deepiterator` sounds good to me.,1,0.7625553011894226
90487806,2140,ijuma,2016-12-01T16:48:26Z,good catch. we probably don't want the change the buffer size in the server to be the same as the client. we may consider changing the client to be the same as the server. see kafka-3704 for details.,1,0.9416791796684265
90805334,2140,guozhangwang,2016-12-05T05:23:18Z,did we get rid of the re-allocation logic as a whole? otherwise we cannot remove this additional check i think.,0,0.9854440093040466
90805786,2140,guozhangwang,2016-12-05T05:31:37Z,"is this private function better than previously in-lined, since it is private anyways?",0,0.983988344669342
90806087,2140,guozhangwang,2016-12-05T05:36:06Z,"if we only deallocate the initial buffer, if re-allocation happens does that mean we will effectively have ""memory leaks""?",0,0.9771252870559692
90810199,2140,guozhangwang,2016-12-05T06:42:19Z,data -> memory?,0,0.9850919842720032
90810687,2140,guozhangwang,2016-12-05T06:49:42Z,is there any rationale for this magic number?,0,0.9761514067649841
90813219,2140,guozhangwang,2016-12-05T07:22:36Z,"i'm following myself about renaming here: we could consider rename to recordentryinputstream, with t extends recordentry.",0,0.9858534336090088
90814254,2140,guozhangwang,2016-12-05T07:36:51Z,this is not introduced in this patch: since we get the exact number of bytes returned from `log.append` could we use that in the trace logging?,0,0.9893829226493835
90815062,2140,guozhangwang,2016-12-05T07:46:44Z,where is this function used?,0,0.9864886403083801
90978864,2140,hachikuji,2016-12-05T23:18:12Z,"this ended up a little ugly whichever way i cut it. i think i prefer the current location because it keeps the message format encapsulated in `record` a bit better, but it comes at the cost of leaking the write optimization which is only used in `memoryrecordsbuilder`. i could go either way here, so let me know if you feel strongly about moving it into `memoryrecordsbuilder`. for now, i'll add a javadoc which explains the usage better.",0,0.6100882291793823
90979896,2140,guozhangwang,2016-12-05T23:24:38Z,i have a comment on this function and it seems squashed. my question was since it is a private function do we really need this rather than having it in-lined?,-1,0.6875959038734436
90979998,2140,guozhangwang,2016-12-05T23:25:18Z,nit: data -> space?,0,0.9858568906784058
90980061,2140,guozhangwang,2016-12-05T23:25:42Z,what is the rationale for this magic number for compressed set?,0,0.9813801646232605
90981109,2140,guozhangwang,2016-12-05T23:32:53Z,we use `maxrecordsize` here and `maxmessagesize` in the other extended class.,0,0.9880680441856384
90981197,2140,guozhangwang,2016-12-05T23:33:27Z,+1.,0,0.8624979853630066
90986644,2140,guozhangwang,2016-12-06T00:12:47Z,"we are using `logentry` here for the message set wrapper, and in other places `logentry` is used for the internal message. we may need to update the javadoc on `logentry` accordingly in different extensions of `loginputstream` and `records` clarify if its `nextentry` and `iterator` returns shallow or deep iterations.",0,0.9890707731246948
90986838,2140,guozhangwang,2016-12-06T00:14:24Z,"this actually returns the message set as a `record`, right?",0,0.9879319071769714
90986917,2140,guozhangwang,2016-12-06T00:15:09Z,nit: also add the `filerecords` reference here?,0,0.9901127815246582
90987096,2140,guozhangwang,2016-12-06T00:16:37Z,nit: indicate that this needs shallow iterations on the entries.,0,0.9827237129211426
90987112,2140,guozhangwang,2016-12-06T00:16:45Z,nit: indicate that this needs deep iterations on the entries.,0,0.9865933060646057
90987175,2140,guozhangwang,2016-12-06T00:17:18Z,"this statement is a bit misleading, how about ""to the format indicated by the given magic value"".",-1,0.7016691565513611
90987669,2140,guozhangwang,2016-12-06T00:21:56Z,nit: unnecessary new lines.,-1,0.7274752855300903
90988043,2140,guozhangwang,2016-12-06T00:24:42Z,we can reuse record_overhead_v0 and record_overhead_v1 here.,0,0.9895275235176086
90988718,2140,guozhangwang,2016-12-06T00:30:03Z,"update the comment as well for `public`. also i'm wondering if we could rename `wrapperxx` just to `xx` and add comments indicating that they are only used for old formatted messages with magic number > 0, and also add a check in constructor that the `magic()` field is consistent with its values: if it is larger than 0 these two fields should never be null; if it is 0 then these two fields should always be null etc.",0,0.9850872755050659
90989533,2140,guozhangwang,2016-12-06T00:36:26Z,is this function only used for unit tests?,0,0.9835198521614075
90989804,2140,guozhangwang,2016-12-06T00:38:51Z,is this function only used in tests?,0,0.9825688600540161
90989898,2140,guozhangwang,2016-12-06T00:39:40Z,why we keep its reverse function as private static in `record` while making it in utils?,0,0.9783564209938049
90990467,2140,guozhangwang,2016-12-06T00:44:19Z,read from -> write to?,0,0.9829109311103821
90991673,2140,guozhangwang,2016-12-06T00:54:36Z,why we can use `integer.max_value` for deep iteration?,0,0.9883119463920593
90991785,2140,guozhangwang,2016-12-06T00:55:33Z,do we still need to override this function from `abstractrecords` since we already override its calling `shallowiterator`?,0,0.9840187430381775
90992078,2140,guozhangwang,2016-12-06T00:58:01Z,ditto above. we use `maxmessagesize` and `maxrecordsize` interleavingly.,0,0.9850761294364929
90992562,2140,guozhangwang,2016-12-06T01:02:27Z,hmm... not sure i understand this: if compression is not use we will simply ignore the `shallow` flag and always go shallow??,-1,0.8418777585029602
90994228,2140,guozhangwang,2016-12-06T01:17:26Z,could you elaborate a bit why shallow iterator allows extensible `logentry` while deep iterator does not?,0,0.9866194128990173
90994615,2140,guozhangwang,2016-12-06T01:21:28Z,why we need to re-construct the `logentry` if its magic number is larger than 0? could we just set its corresponding record's timestamp directly?,0,0.9837385416030884
90995329,2140,guozhangwang,2016-12-06T01:28:44Z,good idea :),1,0.9881216287612915
90995731,2140,guozhangwang,2016-12-06T01:32:38Z,those java docs need to be updated with the new class names. ditto everywhere else.,0,0.9590948224067688
90996571,2140,guozhangwang,2016-12-06T01:41:11Z,nit: group kafka imports?,0,0.9798582792282104
90997090,2140,guozhangwang,2016-12-06T01:45:58Z,"i think we do not need to make `builderwithentries` public since this is the only caller here, and it is followed by a `build()` call immediately, so we can still use `withlogentries`.",0,0.9879833459854126
90997888,2140,guozhangwang,2016-12-06T01:53:42Z,"it is not introduced in this patch: i think its more clear to use two vals here, one named `trimedrecords` and one named `validrecords`.",0,0.9880573749542236
90998010,2140,guozhangwang,2016-12-06T01:55:10Z,where is this object used?,0,0.9862123727798462
90998487,2140,guozhangwang,2016-12-06T02:00:39Z,"a meta clarification question: for all these classes, are we planning to get rid of them all at the same time when the old consumer is removed?",0,0.9782922863960266
90999554,2140,guozhangwang,2016-12-06T02:12:13Z,looks good :),1,0.9887879490852356
90999912,2140,guozhangwang,2016-12-06T02:16:23Z,private?,0,0.9682251811027527
91007176,2140,hachikuji,2016-12-06T03:45:33Z,hmm... i may have misunderstood how this worked. i'll add it back.,0,0.5663687586784363
91008613,2140,hachikuji,2016-12-06T04:05:02Z,"""data"" is correct, but i'll clarify the comment since it does read a little awkwardly. we're trying to say that the client should raise an error if the size of the message exceeds the bytes returned in the response.",0,0.9718098044395447
91008790,2140,hachikuji,2016-12-06T04:07:51Z,it was copied from the server code: [a link] i think perhaps the 1024 comes from the minimum block size for snappy encoding. i can add a comment about that part at least.,0,0.9855363965034485
91009212,2140,hachikuji,2016-12-06T04:13:44Z,it's used in this file. it may not show in the diff because i moved it from `filemessageset` (which was deleted).,0,0.9880611896514893
91009296,2140,hachikuji,2016-12-06T04:15:00Z,inside `logmanager.asyncdelete`.,0,0.9875867366790771
91009688,2140,hachikuji,2016-12-06T04:20:18Z,it's the maximum size of a record entry to read. i think the only place we use it is in `dumplogsegments`.,0,0.9863531589508057
91010122,2140,hachikuji,2016-12-06T04:27:05Z,"the main reason for extension of `logentry` is to enable optimization tricks like overwriting the offsets in place (see `bytebufferlogentry`) or reading the magic byte without loading the record data (see `filechannellogentry`). these tricks are generally only possible for the shallow records. you can't modify the deep records in place since they have been decompressed, nor can you optimize which parts of the record to read (you have to read the whole thing). for the deep records, there's not much you can do aside from read the data, so extension seemed unnecessary.",0,0.9735668301582336
91010212,2140,hachikuji,2016-12-06T04:28:14Z,"haha, depends on whether it's compressed or not, right?",0,0.7738466858863831
91010306,2140,hachikuji,2016-12-06T04:29:41Z,i have a comment in `loginputstream` which attempts to make the distinction clear. let me know if more explanation is needed.,0,0.9862859845161438
91011143,2140,hachikuji,2016-12-06T04:41:47Z,"the wrapper values can be null if either the magic is 0 or if the record is uncompressed. i'll add an assertion for this, but i'd prefer to keep the current names since it's otherwise harder to explain.",0,0.9734328389167786
91011764,2140,hachikuji,2016-12-06T04:51:21Z,"it was necessary before because of the optimization in `filechannellogentry.magic()`, but since i've factored that into `logentry`, i was able to remove it.",0,0.988021194934845
91011883,2140,hachikuji,2016-12-06T04:52:59Z,"if compression is not used, there are no deep entries.",0,0.9813258647918701
91012046,2140,hachikuji,2016-12-06T04:55:40Z,"i followed what the current code did. previously deep iteration was done here in `bytebuffermessageset.deepiterator`, which has no check for max message size.",0,0.9889634847640991
91012622,2140,hachikuji,2016-12-06T05:02:47Z,"hmm... seems worth exploring. we could add a `setwrappertimestamp(timestamptype, long)` or something like that, but i'm not sure it's a good idea to make those fields mutable.",0,0.8695923686027527
91012841,2140,hachikuji,2016-12-06T05:06:55Z,the public version of `builderwithentries` is used in `logvalidator` and `bytebuffermessageset`.,0,0.9883809089660645
91013183,2140,hachikuji,2016-12-06T05:12:28Z,"on second thought, doing so would change the behavior of this function.",0,0.9795323014259338
91013213,2140,hachikuji,2016-12-06T05:12:48Z,"yes, that is the hope. i've removed almost all other uses.",0,0.9064838886260986
91017536,2140,hachikuji,2016-12-06T06:12:35Z,"actually i had to remove these assertions. first, if the magic is 1, then we can't distinguish between a shallow uncompressed entry, and a deep entry, which would also not have its compression flag enabled. we could at least raise an error if magic is 0 and there is a provided wrapper timestamp., but we currently have test cases which allow us to create a record with only a valid crc (which means we can't check magic). we could probably be a little stricter: if there aren't enough bytes in the bytebuffer to read the record overhead, then obviously the record can't be valid, so maybe those test cases are kind of silly and should be removed.",0,0.9692654013633728
91149520,2140,guozhangwang,2016-12-06T19:11:31Z,"aha, i was thinking about the new format :) nvm.",1,0.9759994745254517
91149711,2140,guozhangwang,2016-12-06T19:12:25Z,"i was thinking if we can save one object creation, but it seems less worth optimizing since we are not re-creating the underlying buffer anyways. so it's your call.",0,0.9813472032546997
91826419,2140,junrao,2016-12-10T02:22:04Z,deepentries => deepiterator ?,0,0.9853905439376831
91826423,2140,junrao,2016-12-10T02:22:10Z,"is ""file-backed log buffer."" still needed?",0,0.9893845915794373
91826431,2140,junrao,2016-12-10T02:22:21Z,"hmm, why do start and end need to be long?",0,0.9520301222801208
91826435,2140,junrao,2016-12-10T02:22:28Z,"""log buffer"" probably need to be changed?",0,0.9875857830047607
91826438,2140,junrao,2016-12-10T02:22:35Z,it seems that position should be int?,0,0.9870772361755371
91826441,2140,junrao,2016-12-10T02:22:40Z,could we just cast channel.size() to int?,0,0.9890111684799194
91826447,2140,junrao,2016-12-10T02:22:45Z,shallowentries in this and the next two methods should be shallowiterator?,0,0.987757682800293
91826461,2140,junrao,2016-12-10T02:23:01Z,"is the reference to ""log buffer"" still valid?",0,0.987687885761261
91826468,2140,junrao,2016-12-10T02:23:08Z,"it seems that the follower could call this more than once. so, perhaps it's worth caching.",0,0.9667395353317261
91826477,2140,junrao,2016-12-10T02:23:21Z,it doesn't seem that last offset is being maintained here.,0,0.9632332921028137
91826488,2140,junrao,2016-12-10T02:23:46Z,"hmm, we are getting the last offset, which is not necessarily the offset for message with the max timestamp.",0,0.9844261407852173
91826489,2140,junrao,2016-12-10T02:23:52Z,this and the next method probably should be deepiterator() too?,0,0.9878244400024414
91826492,2140,junrao,2016-12-10T02:23:59Z,"i had the following comment earlier. is that valid? this also seems to be an existing issue. until memorylogbufferbuilder is closed, buffer().position() is not necessarily accurate since the compressor may not have flushed compressed data to the output stream. currently, recordaccumulator.drain() calls this method before closing memorylogbufferbuilder. so, if builtlogbuffer != null, perhaps it's better to use estimatedbyteswritten()?",0,0.9860442876815796
91826501,2140,junrao,2016-12-10T02:24:05Z,are the references to log buffer still valid?,0,0.9884109497070312
91826508,2140,junrao,2016-12-10T02:24:13Z,"to be consistent, should we change entries to records?",0,0.9863682389259338
91826512,2140,junrao,2016-12-10T02:24:18Z,should logentries be records?,0,0.9877597689628601
91830966,2140,ijuma,2016-12-10T07:53:07Z,"btw, it's a bit of a shame to lose the enhanced foreach syntax. is there a reason not to expose a `deepiterable()` method instead?",-1,0.9868713617324829
91880865,2140,becketqin,2016-12-12T04:10:01Z,kafka-4497 reported an issue regarding this. there was a few other issues in `bytebuffermessageset.filterinto()` logic. i provided a patch in #2242 . we should probably fix the logic here as well.,0,0.986657440662384
92014373,2140,hachikuji,2016-12-12T18:57:41Z,"yes, that makes sense. apologies for missing the comment before.",-1,0.8972893953323364
92020118,2140,hachikuji,2016-12-12T19:24:26Z,"ack. this goes back to logcleaner actually, but i'll go ahead and fix here.",0,0.9324626922607422
92072625,2140,junrao,2016-12-13T00:21:41Z,"a 4 byte size, an 8 byte offset => an 8 byte offset, a 4 byte size of the record",0,0.9875877499580383
92072954,2140,junrao,2016-12-13T00:24:22Z,"is the reference to ""log buffer"" still valid?",0,0.987687885761261
92072967,2140,junrao,2016-12-13T00:24:27Z,"is the reference to ""log buffer "" still valid?",0,0.987687885761261
92195306,2140,ijuma,2016-12-13T15:42:32Z,"it's a bit annoying that we create so much indirection (dataloginputstream -> bytebufferinputstream -> underlyinginputstream -> bytebuffer -> byte[]). in an ideal world, we would not bother with `inputstream` at all and would just operate at the `bytebuffer` level. however, the gzip case is hard to do that way.",-1,0.9731208086013794
92216997,2140,junrao,2016-12-13T17:09:21Z,do we need to change the position of buffer? perhaps we could instead just change the position in the slice passed to record().,0,0.9872128367424011
92217186,2140,junrao,2016-12-13T17:10:13Z,"""a 4 byte size,"" needs to be removed.",0,0.9845378398895264
92225885,2140,hachikuji,2016-12-13T17:50:35Z,"haha, yeah. one of the layers is sort of fake (`datainputstream` should be a mixin), but the point is still valid.",0,0.8361722826957703
92227525,2140,hachikuji,2016-12-13T17:58:31Z,"currently `record` expects the position of the `bytebuffer` to be at 0. i was tempted to change this assumption, but decided to leave it for now (it's a bit annoying to change all the accessors to assume relative positioning). we could accomplish the same result using `mark()` and `reset()` if that seems any better.",0,0.5374667048454285
563471404,2140,dengziming,2021-01-25T05:30:44Z,"should this be `math.min(length, size.get() - offset)`?",0,0.988470196723938
563909128,2140,junrao,2021-01-25T17:32:58Z,: thanks for the comment. this does seem like a bug. would you be interested in submitting a separate pr to have this fixed?,1,0.9090579152107239
179653282,4830,tedyu,2018-04-06T03:32:29Z,should this be kafka_1_1_iv0 ?,0,0.9860580563545227
179653551,4830,tedyu,2018-04-06T03:35:26Z,i think channelunmutingcallback would be better name,0,0.9267300963401794
179898815,4830,jonlee2,2018-04-06T23:49:03Z,"this was based on the comments in lines 31-36, which states ""when we change the protocol a second time while developing 0.10.0, we will add a new config value ""0.10.0-iv1"" and a corresponding case object kafka_0_10_0-iv1. we will change the config value ""0.10.0"" to map to the latest internal version object kafka_0_10_0-iv1."" following the example, i set 1.1 to the latest internal version, kafka_1_1_iv1.",0,0.9824587106704712
179919414,4830,lindong28,2018-04-07T15:22:58Z,`throttledelayms`?,0,0.9869431257247925
179919602,4830,lindong28,2018-04-07T15:30:06Z,"if connection state is connecting (i.e. connectiondelay = long.max_value) and throttledelay is 10 ms, should we poll this connection right after 10 ms, or should we wait until the state is connected?",0,0.9892424941062927
179919811,4830,lindong28,2018-04-07T15:38:07Z,would it be more intuitive and consistent to let `clusterconnectionstates.isready()` return false if the connection is throttled?,0,0.988394021987915
179919877,4830,lindong28,2018-04-07T15:40:51Z,maybe `throttledelayms`?,0,0.9864140152931213
179919904,4830,lindong28,2018-04-07T15:41:38Z,"maybe `polldelayms`? also, can you update the param in the java doc?",0,0.9895423650741577
179919911,4830,lindong28,2018-04-07T15:41:53Z,maybe `polldelayms`?,0,0.9845885634422302
179920062,4830,lindong28,2018-04-07T15:47:04Z,"according to the java doc of log.trace(), it says `this form avoids superfluous string concatenation when the logger is disabled for the trace level`. thus we probably don't need to explicitly check `log.istraceenabled`.",0,0.9868027567863464
179920083,4830,lindong28,2018-04-07T15:48:11Z,nits: it may be simpler to just do `if (nodeswithclientsidethrottlingenabled.contains(nodeid) && throttletimems > 0)`,0,0.9878206849098206
179920227,4830,lindong28,2018-04-07T15:53:25Z,we probably don't need to explicitly check log.isdebugenabled(...) because `log.debug` will automatically check this before doing string operation.,0,0.9883082509040833
179920433,4830,lindong28,2018-04-07T16:00:33Z,"it seem a bit unintuitive -- if a node's apiversionresponse's version is smaller than 2, why would the node be in `nodeswithclientsidethrottlingenabled` in the first place? it maybe more intuitive to remove this `else` branch and instead remove the node from `nodeswithclientsidethrottlingenabled` in `handleconnections()`. what do you think?",0,0.5583592653274536
179920578,4830,lindong28,2018-04-07T16:04:56Z,"in order to be consistent with other comments, it may be better to say `introduced apiversionsrequest v2 via kip-219`. also, can you move `""1.1"" -> kafka_1_1_iv1` to the last entry?",0,0.9883244037628174
179920783,4830,lindong28,2018-04-07T16:13:09Z,can `throttledchannel` be `val` instead of `var`?,0,0.9883135557174683
179920867,4830,lindong28,2018-04-07T16:17:45Z,it seems that the return value of `tryunmuate` is only needed for trace level logging. can we move the trace level logging into this method and make this method void to simplify the implementation?,0,0.9894728064537048
179920958,4830,lindong28,2018-04-07T16:22:49Z,can `throttledchannel` be `val`?,0,0.9881300926208496
179920962,4830,lindong28,2018-04-07T16:22:56Z,can `throttledchannel` be `val`?,0,0.9881300926208496
179921259,4830,lindong28,2018-04-07T16:35:48Z,it is probably not necessary to check `throttletimems > 0` since `maybethrottle()` will check it anyway.,0,0.9855624437332153
179921295,4830,lindong28,2018-04-07T16:37:03Z,"it maybe more readable to keep the code style consistent by moving `quotas.request.maybethrottle(request, requestthrottletimems)` to a new line with `{` and `}`.",0,0.9893163442611694
179921553,4830,lindong28,2018-04-07T16:44:54Z,i think the word `maybe` in the original method name `mayberecordandthrottle` is mostly for `throttle`. it is probably more intuitive to name this method `getthrottletimems`.,0,0.985997200012207
179921638,4830,lindong28,2018-04-07T16:48:10Z,it seems a bit redundant to check `quotasenabled` in both `mayberecord` and `maybethrottle`. it is probably more intuitive to check `quotasenabled` only in `mayberecord` such that `throttletimems` will be 0 if `quotasenabled` is false. then `maybethrottle` can act solely based on `throttletimems`.,0,0.9430388808250427
179921729,4830,lindong28,2018-04-07T16:51:06Z,"nits: it may be more readable to use math.max(bandwidththrottletimems, requestthrottletimems) to be consistent with other code and also to show that these two variables are treated equally.",0,0.9869927167892456
180278955,4830,jonlee2,2018-04-10T02:01:50Z,done,0,0.9764507412910461
180286163,4830,jonlee2,2018-04-10T03:09:53Z,done,0,0.9764507412910461
180286169,4830,jonlee2,2018-04-10T03:09:57Z,done,0,0.9764507412910461
180286176,4830,jonlee2,2018-04-10T03:10:00Z,good point. i think throttledelay should make sense only when connected (either checking_api_versions or ready). updated the code to explicitly check the connection state to determine which delay to return.,1,0.9350507855415344
180286183,4830,jonlee2,2018-04-10T03:10:06Z,done. i also updated clusterconnectionstates.hasreadynodes() to take the throttling state into account. please review that change as well.,0,0.9815605878829956
180286188,4830,jonlee2,2018-04-10T03:10:08Z,done,0,0.9764507412910461
180286192,4830,jonlee2,2018-04-10T03:10:10Z,done,0,0.9764507412910461
180286207,4830,jonlee2,2018-04-10T03:10:20Z,done,0,0.9764507412910461
180286219,4830,jonlee2,2018-04-10T03:10:26Z,"based on your next comment, i think it still makes sense to call this mayberecord() (or mayberecordandgetthrottletimems?) because recording only happens when quotasenabled == true. and also rename maybethrottle() to throttle(). i made those changes. what do you think?",0,0.9777822494506836
180286234,4830,jonlee2,2018-04-10T03:10:32Z,"makes sense assuming that maybethrottle() always uses throttle time returned by mayberecord(), which is the case.",0,0.985374927520752
180286244,4830,jonlee2,2018-04-10T03:10:34Z,done,0,0.9764507412910461
180286350,4830,jonlee2,2018-04-10T03:11:33Z,done,0,0.9764507412910461
180286480,4830,jonlee2,2018-04-10T03:12:56Z,this variant takes 3+ arguments after the format string and the comment says that it incurs a small overhead. looks like the same check is used for other places where 3+ arguments are taken. will keep unless you have other concerns.,0,0.9862832427024841
180286492,4830,jonlee2,2018-04-10T03:13:04Z,done,0,0.9764507412910461
180286561,4830,jonlee2,2018-04-10T03:13:38Z,"for this, i removed the check because it take 1 or 2 args.",0,0.9877532124519348
180286995,4830,jonlee2,2018-04-10T03:15:53Z,"it was to cover corner cases where a broker restarted with a lower version (like rollback). i am not entirely sure how this can be in handleconnections(), though. it looks like just initiating api version fetch. can you elaborate?",0,0.9601011276245117
180287026,4830,jonlee2,2018-04-10T03:15:59Z,done,0,0.9764507412910461
180287053,4830,jonlee2,2018-04-10T03:16:05Z,done,0,0.9764507412910461
180287077,4830,jonlee2,2018-04-10T03:16:10Z,done,0,0.9764507412910461
180287095,4830,jonlee2,2018-04-10T03:16:14Z,done,0,0.9764507412910461
180287122,4830,jonlee2,2018-04-10T03:16:20Z,done,0,0.9764507412910461
180671354,4830,lindong28,2018-04-11T08:22:18Z,is this method used only in test? it maybe unnecessary to add a method to a interface solely for test purpose.,0,0.9634434580802917
180673624,4830,lindong28,2018-04-11T08:30:23Z,`isthrottled()` is only called once in non-test code (i.e. `clusterconnectionstates.isready(...)`). it maybe simpler to just call `throttledelayms(...) > 0` in `isready()`. (similar to the code in `hasreadynodes()`),0,0.9871384501457214
180675326,4830,lindong28,2018-04-11T08:36:50Z,how about just call `isready()` here? i understand that existing code does not re-use the isready(). it maybe better to improve it.,0,0.9797705411911011
180678877,4830,lindong28,2018-04-11T08:49:44Z,it seems that we can remove `isconnected(..)` and replace it with `isready(...)` in `polldelayms(...)`. `isconnected()` will be different from `isready()` only when state is `checking_api_versions`. but we are sending apiversionrequest to broker in `handleinitiateapiversionrequests()` anyway without checking whether the connection is throttled. alternatively we can update `handleinitiateapiversionrequests()` so that it does not send `apiversionrequest` if the connection is throttled. personally i would not do this because i don't think the first version apiversionrequest would overload the broker and thus the extra code/logic in client-side implementation is probably not worthwhile.,0,0.9831474423408508
180679073,4830,lindong28,2018-04-11T08:50:31Z,"`throttledeadlinems` maybe be a bit ambiguous in how it is used -- does it mean the connection should be throttled or un-throttled after this deadline? how about `throttleuntiltimems`, `muteuntiltimems` or `earliestsendtimems`?",0,0.9862309098243713
180679291,4830,lindong28,2018-04-11T08:51:20Z,we probably don't need this method if we don't need `clusterconnectionstates.isconnected()`.,0,0.9854173064231873
180682137,4830,lindong28,2018-04-11T09:00:59Z,we can probably just use `now` without calling `time.milliseconds()` here.,0,0.9886806011199951
180682340,4830,lindong28,2018-04-11T09:01:36Z,we can probably call `time.milliseconds` only once and share it with the existing `now = time.milliseconds()`.,0,0.988280177116394
180683981,4830,lindong28,2018-04-11T09:07:30Z,yeah `mayberecordandgetthrottletimems()` sounds better.,0,0.9278539419174194
180813450,4830,lindong28,2018-04-11T16:14:40Z,"previously the way we throttle a request is pretty extensible: we first throttle based on byte rate, and if that passes, then we throttle based on produce rate. if in the future we have another throttle mechanism, e.g. based on cpu, we can easily stack this on top of byte-rate-based and request-rate-based throttling mechanism. the way this patch implements throttling is kind of hard to extend (or appears to be difficult to read) due to the following reasons: - the number of throttling mechanisms is hard-coded to be 2 in throttlechannel.tryunmute() - instead of being able to distribute throttling mechanism in multiple places, now we have to determine the throttle time of all mechanism in one place (e.g. here) and use the one that has the largest throttle time. this will work for now. but it will be hard to extend and seems not-so-readable. - we pass around option[throttledchannel] and treats `none` separately from `some()`. it will be cleaner to just pass one non-option object. i am wondering if the following high-level solution would be better: in class `kafkachannel` we use an integer to keep track of the number of existing mechanisms that are throttling this channel. for example, if this request exceeds the byte-based quota, we increment this integer by one and enqueue an object into a delayed queue. after the corresponding throttle time is passed, we dequeue this object and decrement the value of this integer in the `kafkachannel`. if the value is 0 after it is decremented, we unmute the channel. this solution may be cleaner in the following sense: - we no longer needs to pass option[throttledchannel]. - we can implement byte-based and request-based throttling mechanism in the same manner as the existing kafka implementation without having to put them together. - the solution is more extensible since it does not assume there are exactly two throttling mechanisms. what do you think?",0,0.8904402852058411
182270273,4830,jonlee2,2018-04-17T23:21:30Z,done,0,0.9764507412910461
182270329,4830,jonlee2,2018-04-17T23:21:47Z,done,0,0.9764507412910461
182270349,4830,jonlee2,2018-04-17T23:21:58Z,done,0,0.9764507412910461
182270366,4830,jonlee2,2018-04-17T23:22:04Z,done,0,0.9764507412910461
182270438,4830,jonlee2,2018-04-17T23:22:32Z,renamed to throttleuntiltimems.,0,0.9877535700798035
182271668,4830,jonlee2,2018-04-17T23:31:08Z,"now that isready() checks for throttling status, i don't think it can be used directly for polldelayms(). polldelayms() needs to check if the state is ready and *throttled*. i can directly check if the state is ready, instead of isconnected(). will that work?",0,0.9766254425048828
182271745,4830,jonlee2,2018-04-17T23:31:44Z,see the comment above. i'll remove once we agree on what to do for polldelayms().,0,0.9859867691993713
182271764,4830,jonlee2,2018-04-17T23:31:52Z,done,0,0.9764507412910461
182271781,4830,jonlee2,2018-04-17T23:31:59Z,done,0,0.9764507412910461
182271956,4830,jonlee2,2018-04-17T23:33:16Z,"we discussed this offline and agreed to keep the current logic for using the max. as for option[throttledchannel], i used kafkachannel to keep the ref count as suggested and got rid of the use of option[throttledchannel].",0,0.9781011343002319
183115763,4830,lindong28,2018-04-20T17:15:27Z,"the java doc seems to be inconsistent with the implementation. if the connection has been established and the throttle delay is 0, we actually return `long.max_value` instead of 0. also, can this java doc follow the style of the existing java doc for `connectiondelay`. for example, `returns the number of milliseconds to wait, based on the connection state and the throttle time, before attempting to send data.`",0,0.985897421836853
183115843,4830,lindong28,2018-04-20T17:15:45Z,the java doc seems to be inconsistent with the implementation.,0,0.9065606594085693
183145676,4830,lindong28,2018-04-20T19:16:12Z,"it seems that `decrementunmuterefcountandget` and `unmute` are always used together. would it be simpler to just modify the existing method `unmute` to be `maybeunmute`, which internally will decrement the reference count and umute the channel if the reference count is 0?",0,0.9876179695129395
183146203,4830,lindong28,2018-04-20T19:18:35Z,"would it be simpler to just modify the existing method `mute` to be `maybemute`, which internally will increment the reference count and mute the channel if the reference count is 1 after it is incremented?",0,0.9870849251747131
183147589,4830,lindong28,2018-04-20T19:24:59Z,should this be debug level logging?,0,0.9883329272270203
183150790,4830,lindong28,2018-04-20T19:40:01Z,"it maybe subjective. i am more inclined not to use super.*. can we keep the existing java method style, where we check `quotasenabled` in `mayberecordandgetthrottletimems`, and call `recordandgetthrottletimems` if `quotasenabled` is true. `mayberecordandgetthrottletimems` can be defined in both `clientrequestquotamanager` and `clientquotamanager`. `recordandgetthrottletimems` will be defined only in `clientquotamanager`.",0,0.7422303557395935
183152661,4830,lindong28,2018-04-20T19:49:15Z,"this method is in `clientrequestquotamanager` but not in `clientquotamanager`. and it kind of overlaps with `throttle` and `mayberecordandgetthrottletimems`. so the simplification of removing callback in kafkaapis.java comes at the cost of added methods and inconsistency in `clientrequestquotamanager` and `clientquotamanager`. i am usually conservative and prefer to keep the existing code style unless the code style is clearly superior. in this case there is pros and cons in the new code style. and since difference people may have different opinion, it may cause back-and-forth change in open source development. later the second reviewer can comment on this.",0,0.5131059885025024
183153259,4830,lindong28,2018-04-20T19:52:02Z,"previously the throttletimems in fetchresponse is `bandwidththrottletimems + requestthrottletimems`. now it is changed to `max(bandwidththrottletimems, requestthrottletimems)`.",0,0.9889539480209351
183153543,4830,lindong28,2018-04-20T19:53:30Z,"previously the throttletimems in produceresponse is `bandwidththrottletimems + requestthrottletimems`. now it is changed to `max(bandwidththrottletimems, requestthrottletimems)`.",0,0.9890256524085999
183155316,4830,lindong28,2018-04-20T20:00:37Z,i am wondering if there is specific reason for the previous method signature.,0,0.9102451205253601
183588951,4830,jonlee2,2018-04-24T02:20:45Z,we need to return max since we are not stacking throttling anymore.,0,0.9577755331993103
183588956,4830,jonlee2,2018-04-24T02:20:49Z,we need to return max since we are not stacking throttling anymore.,0,0.9577755331993103
183588969,4830,jonlee2,2018-04-24T02:20:54Z,this is because we don't need to pass this as a callback anymore.,0,0.9785869717597961
183603418,4830,jonlee2,2018-04-24T04:43:04Z,done,0,0.9764507412910461
183603427,4830,jonlee2,2018-04-24T04:43:11Z,done,0,0.9764507412910461
183603515,4830,jonlee2,2018-04-24T04:43:59Z,i actually removed mayberecordthrottle() from clientrequestquotamanager. it is now consistent with clientquotamanager.,0,0.989166796207428
183603548,4830,jonlee2,2018-04-24T04:44:21Z,done. thanks for catching this.,1,0.9056273698806763
183603566,4830,jonlee2,2018-04-24T04:44:33Z,updated,0,0.9681491851806641
183604255,4830,jonlee2,2018-04-24T04:50:13Z,"i thought about it and i actually prefer to keep it this way. the reason why is that the ref count is used by socketserver only and thus i want socketserver to be the only one that updates the count. in other words, whatever layer that uses this ref count should update it within that layer. if we expose this to selector, i am concerned that there may be some misuse. what do you think?",-1,0.7365303039550781
183604277,4830,jonlee2,2018-04-24T04:50:29Z,please see the comment above.,0,0.9808663129806519
183916192,4830,lindong28,2018-04-25T00:19:45Z,nits: can we use math.max(...)?,0,0.9819889068603516
183917654,4830,lindong28,2018-04-25T00:33:09Z,it may be slightly better to share the code with the existing `setexpectedapiversionsresponse()`.,0,0.987117350101471
183918381,4830,lindong28,2018-04-25T00:39:55Z,do we need this change?,0,0.9829642176628113
183919344,4830,lindong28,2018-04-25T00:48:28Z,"typo requoest. also, should the throttle time for request rate quota to be larger than 0, since the request rate quota is 0.01?",0,0.9892409443855286
183919358,4830,lindong28,2018-04-25T00:48:39Z,typo requoest,0,0.988736093044281
183940157,4830,jonlee2,2018-04-25T04:27:12Z,done,0,0.9764507412910461
183940161,4830,jonlee2,2018-04-25T04:27:15Z,refactored the code to maximize code reuse.,0,0.9862372875213623
183940170,4830,jonlee2,2018-04-25T04:27:24Z,forgot to remove. updated.,0,0.8954328298568726
183940176,4830,jonlee2,2018-04-25T04:27:28Z,"fixed. the test is instrumented so that both quotas are violated, but throttle time is recorded for the max of the two only. that's why throttle time metrics for request quota is supposed to be 0.",0,0.9851279854774475
183940180,4830,jonlee2,2018-04-25T04:27:31Z,fixed,0,0.975196123123169
184196347,4830,rajinisivaram,2018-04-25T20:30:58Z,"there are a lot of comments like this that refer to kip-219. typically, we don't include kip numbers and jiras in comments for code changes. it is preferable to have comments that are self contained so that developers don't have to find the kip to follow the code.",0,0.973349928855896
184196826,4830,rajinisivaram,2018-04-25T20:32:58Z,"had a comment on the kip discuss thread about the approach to update only apiversions version. can you respond on the thread, please?",0,0.9876498579978943
184197543,4830,rajinisivaram,2018-04-25T20:35:47Z,"i haven't gone through the pr in detail, but i think this callback is invoked on a different thread when throttle time expires. `selector` is not thread-safe and we expect methods on the selector to be invoked from a single thread.",0,0.9678613543510437
184199595,4830,rajinisivaram,2018-04-25T20:43:28Z,"i am not sure about this. since quotas are calculated differently, not sure `max` gives the same result as the throttle times calculated separately as it was done earlier.",0,0.5684099793434143
184753260,4830,jonlee2,2018-04-27T17:25:02Z,"i removed kip-219 references, except for apiversion.scala.",0,0.9846316576004028
184753299,4830,jonlee2,2018-04-27T17:25:10Z,"yes, i replied to the vote thread for seeking comments. could you also respond to that thread since you were one of the original voters?",0,0.9840680956840515
184753337,4830,jonlee2,2018-04-27T17:25:17Z,"thank you for catching this. this is an important point. i made the following changes to address this. - removed the callback from socketserver to the api layer - when throttling starts and ends, the api layer will put responses using new responseactions to the request channel queue to notify socket server of start/end throttling - when socketserver receives responses with these new actions, it will update reference count and try to unmute the channel with these changes, reference count handling and mute/unmute channel will be handled in the same thread.",1,0.9766635298728943
184754840,4830,jonlee2,2018-04-27T17:30:50Z,"with this kip, a response needs to be sent out with a throttle time value before actually starting throttling, and thus we need to determine how long we should mute the channel first before sending out the response. in other words, if multiple quotas are violated, we can't really wait till throttling for one quota is over before computing throttle time for next quota. under this scenario, i thought using the max is reasonable. it will be same as before if only one quota is violated. if multiple quotas are violated, using max may not give the same throttle time in some cases but i am not sure what will be a better alternative. i am not entirely sure about how throttle times can be ""calculated separately"" with this kip. are you suggesting that on multiple quota violations, say, produce and request, we throttle for produce violation only and deal with any remaining request quota violation the next time the client sends another produce request after the initial throttling? but this is also different from the way it was and can be inefficient (in case we keep picking smaller throttle time).",0,0.8607306480407715
184950779,4830,rajinisivaram,2018-04-30T10:10:15Z,"no, i am not suggesting that we do only one at a time. i think we need to see if we can do a better calculation than `max` to combine the two (or potentially many in future).",0,0.9296784996986389
185120383,4830,jonlee2,2018-04-30T21:49:07Z,"i still think using max is reasonable. in my understanding, that is the minimum amount of time we need to throttle anyway for the traffic at the time of quota violation. there may be other connections using the same client id/user while the throttling is going on, but that will only add more load and thus will not improve the throttle time. i also discussed with and he agreed. would you let me know if you have any specific suggestions?",0,0.927129328250885
186307847,4830,lindong28,2018-05-07T00:06:29Z,nits: can we replace `throttledeadlinems` with `throttleuntiltimems` for consistency?,0,0.9900667667388916
186308119,4830,lindong28,2018-05-07T00:14:46Z,nits: can we align the second line of parameters with the first line in the same manner as `sendinternalmetadatarequest()`?,0,0.9898751378059387
186308382,4830,lindong28,2018-05-07T00:21:40Z,"according to the java doc of org.slf4j.logger.trace, `this form avoids superfluous string concatenation when the logger is disabled for the trace level. however, this variant incurs the hidden (and relatively small) cost of creating an object[] before invoking the method`. so it is probably ok to skip checking `log.istraceenabled`. it will also be more consistent with the existing invocation of `log.trace()` in kafka.",0,0.9830668568611145
186308601,4830,lindong28,2018-05-07T00:28:08Z,"since this integer is decremented when `tryunmutechannel()` is called, would it be a bit more intuitive to name it `muterefcount()`? if so, we may want to also rename methods such as `incrementunmuterefcount()`, `decrementunmuterefcountandget()`, `getunmuterefcount()` and `incrementchannelunmuterefcount()`.",0,0.9868371486663818
186309712,4830,lindong28,2018-05-07T00:55:33Z,"for the same reason that this patch adds the throttletimems field to the leaderandisrresponse, should we also add this field to stopreplicaresponse?",0,0.9888590574264526
186313712,4830,lindong28,2018-05-07T02:03:46Z,"broker's handling of fetchrequest becomes stateful after kip-227 added support for incremental fetch response. it means that the state in broker will be inconsistent with the state in client if we replace a non-empty fetchresponse with an empty response. more specifically, in `cachedpartitions.updateresponsedata()`, state (e.g. highwatermark) will be updated if a partition is assumed to be included in the fetchresponse. in order to solve this problem, we probably need to change the implementation related to kip-227. currently `cachedpartitions.updateresponsedata()` will 1) determine the partitions to be included and 2) update the state for those partitions that are included. we probably need to split this into two separate functions. the the state for those partitions should be updated only if the fetchresponse is not throttled. another problem is that `clientsensors.quotasensor.record` has already been called in `recordandgetthrottletimems()` at this point. it means that we have already assumed that the resource is used to send the fetchresponse at this point. it will cause under-utilization if we only sends an empty fetchresponse after updating the quotasensor. the main motivation of this kip is to address problem caused by producerequest. fetchrequest is small and probably not a concern. if we don't have a simpler way to handle the above two problems, i would recommend not to touch the handlefetchrequest() logic in this patch, i.e. broker still sends the non-empty fetchresponse after the throttle time has passed.",0,0.9836408495903015
187203528,4830,jonlee2,2018-05-09T23:23:32Z,"per discussion with , i reverted the changes i made to cluster action responses.",0,0.9857719540596008
187203579,4830,jonlee2,2018-05-09T23:23:56Z,done,0,0.9764507412910461
187203589,4830,jonlee2,2018-05-09T23:24:01Z,done,0,0.9764507412910461
187203602,4830,jonlee2,2018-05-09T23:24:09Z,done,0,0.9764507412910461
187203618,4830,jonlee2,2018-05-09T23:24:15Z,done,0,0.9764507412910461
187204068,4830,jonlee2,2018-05-09T23:27:20Z,"thanks for catching this. i made the following changes to address these points: 1. added getresponsesize() to fetchcontext to get the response size (for calculating throttle time) without updating the internal states 2. in case of fetch throttling, unrecord the recorded usage value by recording a negative value of the same quantity. i added comments stating more details about these changes.",1,0.9590960741043091
187911027,4830,rajinisivaram,2018-05-14T10:59:10Z,"`atomicinteger` suggests that this field is updated from multiple threads. since we rely on this to be updated and accessed only from a single thread, it would be better to make it an `int` (like the other fields in this class). also, it is confusing to have a field `muted` and another `muterefcount` and separate methods to go with each. can we combine these two? possibly even just have `mute/unmute` methods in `kakachannel` and make the reference count internal rather than managed by `socketserver`?",0,0.8362143635749817
187913359,4830,rajinisivaram,2018-05-14T11:09:53Z,this response as well as others without a throttle time don't need version bump.,0,0.9839047789573669
187913661,4830,rajinisivaram,2018-05-14T11:11:03Z,i think it would be better to add a `throttletimems()` method to `abstractresponse` that returns throttle time for responses which contain the time and zero for others.,0,0.9866586327552795
187914030,4830,rajinisivaram,2018-05-14T11:12:40Z,should just return zero for this response as well as other responses which don't contain throttle time.,0,0.9804129004478455
187924822,4830,rajinisivaram,2018-05-14T11:54:47Z,we don't usually use `get` prefix for getters.,0,0.9754660129547119
187925371,4830,rajinisivaram,2018-05-14T11:56:57Z,hmm.. this is not ideal. metrics are externally visible entities that are used for monitoring. recording and unrecording can be confusing. but agree that it is hard to fix. we should at least record using the same time (will also avoid an extra `system.currenttimemillis()` per fetch request).,0,0.8668345808982849
187925735,4830,rajinisivaram,2018-05-14T11:58:28Z,"this is the request quota manager, so it is always request processing time.",0,0.9882920384407043
188146295,4830,jonlee2,2018-05-15T01:53:39Z,done,0,0.9764507412910461
188146303,4830,jonlee2,2018-05-15T01:53:44Z,done,0,0.9764507412910461
188146314,4830,jonlee2,2018-05-15T01:53:49Z,done,0,0.9764507412910461
188146336,4830,jonlee2,2018-05-15T01:53:56Z,done,0,0.9764507412910461
188146689,4830,jonlee2,2018-05-15T01:56:58Z,"i agree that it is not ideal, but the current implementation couples the reporting and quota checking a little too tightly. i used the same time for both record/unrecord as suggested.",0,0.9236560463905334
188149319,4830,jonlee2,2018-05-15T02:21:38Z,"i changed atomicinteger to int. as for your other comments, the ref count is used by socketserver and thus i think it should be updated by socketserver only. i am concerned that the ref count combined with the existing kafkachannel mute/unmute may cause some issues when misused by other kafkachannel users. for example, what if someone calls mute() twice? the second mute() is supposed to be a no-op, but if we decide to increase the ref count as part of mute(), it is not actually a no-op. also, socketserver still needs to call some method to increase the count when startthrottlingaction is received, so it won't be completely transparent. another point is that unmute() will be effectively tryunmute() because it only unmutes when the ref count is 0. with these reasons, i initially decided to separate the ref count from the existing mute/unmut logic. but i do agree that it is confusing to have both in kafkachannel. having said that, would it make more sense if i maintain the ref count in socketserver (by using a per-processor map from channel id to ref count) instead of kafkachannel? what do you think?",-1,0.9201840758323669
188299694,4830,rajinisivaram,2018-05-15T14:04:47Z,"the problem with mute is that we already have too many different ways of controlling and tracking it, making the code really confusing. there is `kafkachannel.muted`, `kafkachannel.muterefcount`, `kafkachannel.isinmutablestate()`, `selector.explicitlymutedchannels` and the actual interest ops of the selection key in the transport layer. i don't think we want a per-processor map containing channel ids in `socketserver` since managing two lists of channels is just more work and could result in inconsistencies. the particular problem with `kafkachannel.muterefcount` is that if you are looking at `kafkachannel`, then that field and the methods that go with it make no sense since you can have `muted=true, refcount=0`. would it be possible to convert `kafkachannel.muted` to `kafkachannel.mutestate` with enum states like `not_muted`, `muted`, `response_pending`, `throttled`, `throttled_response_pending` or something along those lines with clear state transitions?",0,0.7085776329040527
188508062,4830,jonlee2,2018-05-16T05:42:19Z,thank you for the suggestion. makes a good sense. i replaced kafkachannel.muted with kafkachannel.mutestate and remove the ref count. transition of the mutestate of each channel will be controlled by mute-related events reported by socketserver (details mentioned in the comments).,1,0.9569554328918457
188706191,4830,tedyu,2018-05-16T17:21:10Z,what if mute state becomes channelmutestate.muted after the above call ? should unmute still be carried out ?,0,0.9827306866645813
188729990,4830,jonlee2,2018-05-16T18:35:52Z,"yes. this is a noop response case, so if the mute state transitions to muted after the above call (meaning that there's no throttling in progress), we should unmute the channel.",0,0.9852644801139832
189442592,4830,lindong28,2018-05-19T19:17:08Z,nits: return the number ...,0,0.9866207838058472
189442599,4830,lindong28,2018-05-19T19:17:19Z,nits: return the number ...,0,0.9866207838058472
189442674,4830,lindong28,2018-05-19T19:21:24Z,can you make it private?,0,0.9873910546302795
189442716,4830,lindong28,2018-05-19T19:23:11Z,nits: personally i feel the string can be in the same line.,0,0.967631459236145
189448493,4830,lindong28,2018-05-20T01:10:34Z,"it seems that we will mute a channel after receiving request from client, and maybe unmute a channel after sending the response to client. so should the first two entries be renamed to `request_received` and `response_sent` (with updated docs) respectively?",0,0.9882040023803711
189448703,4830,lindong28,2018-05-20T01:27:00Z,is this change in the leaderandisrresponse needed?,0,0.9865168333053589
189448829,4830,lindong28,2018-05-20T01:36:54Z,is this change needed?,0,0.9830894470214844
189448832,4830,lindong28,2018-05-20T01:37:28Z,is this change needed?,0,0.9830894470214844
189448835,4830,lindong28,2018-05-20T01:37:43Z,is this change needed?,0,0.9830894470214844
189448844,4830,lindong28,2018-05-20T01:38:49Z,is this change needed?,0,0.9830894470214844
189448845,4830,lindong28,2018-05-20T01:39:00Z,is this change needed?,0,0.9830894470214844
189448878,4830,lindong28,2018-05-20T01:41:22Z,nits: it maybe slightly simpler to skip the `if ` statement,0,0.9814015030860901
189448885,4830,lindong28,2018-05-20T01:41:27Z,nits: it maybe slightly simpler to skip the `if ` statement,0,0.9814015030860901
189448890,4830,lindong28,2018-05-20T01:41:48Z,nits: it maybe slightly simpler to skip the `if ` statement,0,0.9814015030860901
189448893,4830,lindong28,2018-05-20T01:41:52Z,nits: it maybe slightly simpler to skip the `if ` statement,0,0.9814015030860901
189449055,4830,lindong28,2018-05-20T01:57:35Z,nits: `${quotatype}` can be replaced with `$quotatype`,0,0.988811731338501
189449166,4830,lindong28,2018-05-20T02:09:07Z,"since we only unrecord quota sensor if the request is throttled, it may be better to skip checking `quotasenabled` (or throw exception if quotasenabled = false) and rename this method to `unrecordquotasensor`.",0,0.9887619614601135
189449289,4830,lindong28,2018-05-20T02:20:40Z,it could be `val`.,0,0.9876360297203064
189449309,4830,lindong28,2018-05-20T02:22:42Z,nits: it seems that we typically put the the body of the if statement in a new line?,0,0.9841041564941406
189449419,4830,lindong28,2018-05-20T02:34:35Z,`shouldbeincludedinresponse ` name may be a bit confusing because it does not tell whether this method can change state or not. can we name it `maybeupdateresponsedata`?,0,0.8560787439346313
189449460,4830,lindong28,2018-05-20T02:39:48Z,"can we make this class private? and would it be better to add `type resp_map_iter = iterator[util.map.entry[topicpartition, fetchresponse.partitiondata]]` in fetchsession object, and replace the first parameter with `val iter: resp_map_iter`. this seems to be more consistent with the existing code patter and make it more obvious that the new class is a wrapper around the original iterator.",0,0.9889440536499023
189450020,4830,lindong28,2018-05-20T03:11:43Z,would it make the code a bit more readable by initializing unconvertedfetchresponse to an empty map here. by doing this we initialize unconvertedfetchresponse in roughly the same place and createresponse() does not need to do `if (throttletimems > 0)`.,0,0.9888386726379395
189450100,4830,lindong28,2018-05-20T03:18:04Z,nits: can we move `2.0-iv0` to be after `2.0`?,0,0.9895780682563782
189474811,4830,jonlee2,2018-05-20T23:55:52Z,done,0,0.9764507412910461
189474816,4830,jonlee2,2018-05-20T23:55:58Z,done,0,0.9764507412910461
189474821,4830,jonlee2,2018-05-20T23:56:02Z,done,0,0.9764507412910461
189474823,4830,jonlee2,2018-05-20T23:56:06Z,done,0,0.9764507412910461
189474841,4830,jonlee2,2018-05-20T23:56:53Z,"hmm.. i thought i already removed it here and other cluster action responses, but obviously not. done.",0,0.9305866956710815
189474845,4830,jonlee2,2018-05-20T23:56:59Z,done,0,0.9764507412910461
189474848,4830,jonlee2,2018-05-20T23:57:05Z,done,0,0.9764507412910461
189474850,4830,jonlee2,2018-05-20T23:57:11Z,done,0,0.9764507412910461
189474855,4830,jonlee2,2018-05-20T23:57:17Z,done,0,0.9764507412910461
189474857,4830,jonlee2,2018-05-20T23:57:22Z,done,0,0.9764507412910461
189474864,4830,jonlee2,2018-05-20T23:57:29Z,done,0,0.9764507412910461
189474865,4830,jonlee2,2018-05-20T23:57:35Z,done,0,0.9764507412910461
189474868,4830,jonlee2,2018-05-20T23:57:41Z,done,0,0.9764507412910461
189474869,4830,jonlee2,2018-05-20T23:57:48Z,done,0,0.9764507412910461
189474873,4830,jonlee2,2018-05-20T23:57:57Z,done,0,0.9764507412910461
189474877,4830,jonlee2,2018-05-20T23:58:03Z,done,0,0.9764507412910461
189474880,4830,jonlee2,2018-05-20T23:58:10Z,done,0,0.9764507412910461
189474885,4830,jonlee2,2018-05-20T23:58:15Z,done,0,0.9764507412910461
189474890,4830,jonlee2,2018-05-20T23:58:22Z,done,0,0.9764507412910461
189474891,4830,jonlee2,2018-05-20T23:58:27Z,done,0,0.9764507412910461
189475769,4830,jonlee2,2018-05-21T00:23:40Z,done,0,0.9764507412910461
189476185,4830,jonlee2,2018-05-21T00:34:28Z,"request/response in this enum and the previous one refer to request/response between socketserver and the api layer, not between the client and socketserver. one reason why i chose this way was because we don't send out a response to the client when acks = 0. but you are right that we try unmuting after sending out to the response to the client, so i updated as suggested. i still use response_sent for acks=0 case, but i think it should not be confusing (mentioned that in the comments).",0,0.943239688873291
462738230,9103,abbccdda,2020-07-30T05:07:29Z,you commented on the previous pr about the style here. the reasoning is that this is a more common style than having period at the end in our codebase.,0,0.9836860299110413
463919020,9103,abbccdda,2020-08-01T04:11:47Z,moved to `alterconfigsutil`,0,0.986708402633667
464029227,9103,abbccdda,2020-08-02T04:18:20Z,moved to `alterconfigsutil`,0,0.986708402633667
464029411,9103,abbccdda,2020-08-02T04:21:07Z,"this is the new test, the rest of changes in this file are just side cleanups.",0,0.9832927584648132
464241946,9103,dajac,2020-08-03T07:34:55Z,could we use optional for these two as they are not always provided?,0,0.9861140847206116
464242434,9103,dajac,2020-08-03T07:36:02Z,nit: i would actually keep the callback as the last argument as it is a bit more natural to have the callback last.,0,0.9710131883621216
464244756,9103,dajac,2020-08-03T07:41:05Z,nit: empty line could be removed.,0,0.9837834239006042
464245796,9103,dajac,2020-08-03T07:43:25Z,"i personally prefer the previous indentation which is, i believe, more common in our code base. or do we plan to adopt a new formatting?",0,0.8965956568717957
464246880,9103,dajac,2020-08-03T07:45:52Z,nit: could we move it after `clientinformation` to keep the order inline with the order in the constructor?,0,0.9900879263877869
464247255,9103,dajac,2020-08-03T07:46:42Z,shall we use optional here as well?,0,0.9859191179275513
464247740,9103,dajac,2020-08-03T07:47:47Z,"actually, we will also use it for quota. i think that we could say that both `initialprincipalname` and `initialclientid` will be used for logging and quota purposes.",0,0.9881606101989746
464248637,9103,dajac,2020-08-03T07:49:43Z,"as 2.7 has not be release yet, we don't need to introduce a new version. we can reuse `kafka_2_7_iv0`.",0,0.9831546545028687
464248862,9103,dajac,2020-08-03T07:50:12Z,shall we use option here?,0,0.9869371056556702
464249275,9103,dajac,2020-08-03T07:51:05Z,nit: that was already present before your change but could we remove the extra space before the colon?,0,0.9879604578018188
464255551,9103,dajac,2020-08-03T08:04:21Z,the usage of the square brackets and the colon looks weird here. the audit log does not look like a sentence anymore. i wonder if we could go with something like this instead: `principal = a on behalf of principal = b is allowed...`. we could also put the initial principal name only if it is set.,-1,0.975557267665863
464260158,9103,dajac,2020-08-03T08:14:21Z,nit: remove extra space before `authorizedresources`.,0,0.9875662326812744
464271174,9103,dajac,2020-08-03T08:36:17Z,* i presume that this does not work if we use the same listener for bother the control plane and the data plane. * i also wonder if it is a good thing to have this extension here as it applies to all the authorization in the api layer. i think that we should be cautious and only do this for forwarded requests.,-1,0.5755781531333923
464271735,9103,dajac,2020-08-03T08:37:25Z,i presume that this does not work if the broker uses the same listener for the control plane and the data plane.,0,0.940514326095581
464274377,9103,dajac,2020-08-03T08:42:43Z,"nit: `as admin client doesn't know how to find the controller` is not relevant anymore. what about the following: `when ibp is smaller than xyz, forwarding is not supported therefore requests are handled directly`?",0,0.954023003578186
464276809,9103,dajac,2020-08-03T08:47:21Z,"it looks like that we will propagate the `not_controller` error back to the client. is it intentional? as clients don't send this request to the controller (and new ones won't get the controller id anymore), it sounds weird to return them this error. we could perhaps return another generic error.",-1,0.9703961610794067
464277479,9103,dajac,2020-08-03T08:48:34Z,have we considered using scala functions as callbacks? it would be more aligned with the other callbacks that we have in scala and also would avoid having to define classes for each handler that support forwarding. what do you think?,0,0.9837599992752075
464292019,9103,dajac,2020-08-03T09:15:10Z,"for my understanding, i suppose that we don't verify that redirection is enabled here to ensure that the controller can accept forwarded requests as soon as one broker in the cluster is configured with ibp 2.7. am i getting this right?",0,0.9797021746635437
464567004,9103,abbccdda,2020-08-03T17:44:56Z,it is not necessary as we don't check nulls for these fields.,0,0.9708406925201416
464569040,9103,abbccdda,2020-08-03T17:48:54Z,"not necessary, as explained.",0,0.9603689908981323
464570322,9103,abbccdda,2020-08-03T17:51:19Z,"i don't think we need initial client id for audit logging, is there some other logging you have in mind?",0,0.9841791987419128
464582897,9103,abbccdda,2020-08-03T18:16:19Z,will requests only flow to data plane if they use the same listener?,0,0.9837695360183716
464583310,9103,abbccdda,2020-08-03T18:17:08Z,not this is propagating to the sender broker.,0,0.9435507655143738
464584005,9103,abbccdda,2020-08-03T18:18:30Z,"yes, the purpose is to always handle a forwarding request even if ibp is not 2.7 yet. this is because some brokers may already upgrade their ibp and they start sending forwarding requests, which is totally legitimate.",0,0.9807414412498474
464585176,9103,abbccdda,2020-08-03T18:20:47Z,sg!,0,0.7951187491416931
465272340,9103,dajac,2020-08-04T19:16:28Z,"yeah, i was actually thinking about the request log. i thought that it may be useful to print them out there as well: [a link]",0,0.9748217463493347
465273597,9103,dajac,2020-08-04T19:18:54Z,"sorry, i was not clear. if the control plane listener is not configured, control requests will go to the data plane listener. based on your last commits, it seems that you have figured that out.",-1,0.9850175976753235
465273903,9103,dajac,2020-08-04T19:19:35Z,ack. i have missed the handling of `not_controller` in the `brokertocontrollerchannelmanager`.,-1,0.8782031536102295
465274018,9103,dajac,2020-08-04T19:19:49Z,ack. this is what i thought.,0,0.8508598208427429
465275440,9103,dajac,2020-08-04T19:22:33Z,"actually, we check nulls for these two in `isforwardingrequest` method. i don't feel strongly about this but i usually better to use optional when such values are not always present.",0,0.8435253500938416
465908873,9103,dajac,2020-08-05T18:05:16Z,"i wonder if this is correct. usually, we use `cluster_action` action with the `cluster` resource. for instance, this is how we authorize control requests: [code block] i thought that we would do the same in this case. don't we?",0,0.9242992401123047
466582281,9103,abbccdda,2020-08-06T17:45:49Z,"i'm not sure either, cc",0,0.5447478294372559
466714423,9103,abbccdda,2020-08-06T22:14:07Z,"actually i think you are right, will change here.",0,0.9299950003623962
467214507,9103,cmccabe,2020-08-07T18:54:46Z,"can we get rid of whitespace-only changes like this, or at least move them to another pr?",0,0.9882036447525024
467215647,9103,abbccdda,2020-08-07T18:56:53Z,let me check around.,0,0.9802005290985107
473158779,9103,abbccdda,2020-08-19T16:26:12Z,add equality check for the sake of easymock verification,0,0.9872968196868896
475710400,9103,cmccabe,2020-08-24T15:43:18Z,need to include: [code block],0,0.9838882088661194
475712573,9103,cmccabe,2020-08-24T15:46:38Z,"how about: ""a broker failed to authorize itself to another component of the system. this indicates an internal error on the broker cluster security setup"". this isn't specific to forwarding... there might be other reasons why a broker would need to authorize itself and fail",0,0.956669807434082
475714230,9103,cmccabe,2020-08-24T15:49:13Z,in general we don't define equals or hashcode on these builders. why are we defining it here?,0,0.9411500692367554
475725389,9103,cmccabe,2020-08-24T16:06:10Z,just as a note the alter isr pr may also have an object like this. so maybe we want a name which is more specific to redirection.,0,0.9868914484977722
476860796,9103,abbccdda,2020-08-25T23:33:02Z,the purpose is for the mock tests to compare the expected builder in `kafkaapistest`,0,0.9878919124603271
476864248,9103,abbccdda,2020-08-25T23:36:10Z,"interesting, why does the `authorizationexception` have no `serialversionuid`? is it because we never use that error code explicitly?",0,0.9673135876655579
489875283,9103,abbccdda,2020-09-17T01:59:50Z,i'm still trying to decide how to make sure we could turn off the redirection in 2.7. having a separate ibp for 3.0 may not work.,-1,0.6982214450836182
493160927,9103,hachikuji,2020-09-23T02:31:05Z,"nit: might be useful to document the expectation that `resources` is a subset of the key set of `configs`. the signature surprised me a little bit. as an aside, this kind of convenience conversion seems more appropriate for `incrementalalterconfigsrequest.builder` rather than a static class.",0,0.920054018497467
493165520,9103,hachikuji,2020-09-23T02:48:53Z,typically responses are immutable after construction. it seems kind of a brittle pattern to rely on being able to mutate the response we receive from the other broker. for example we inherit the throttle time which is a bit weird. are we saving that much by not creating a new response?,-1,0.938295304775238
493168061,9103,hachikuji,2020-09-23T02:58:59Z,"in general, the forwarded request may have a different version than the client request. i'm wondering if we should keep the version the same in case there are semantic differences. as an example, a newer version of the api may introduce unexpected error codes. unless we have logic to convert those error codes, then we might break compatibility unexpectedly.",0,0.9094369411468506
493168697,9103,hachikuji,2020-09-23T03:01:28Z,get rid of this todo. we do not need to remove ibp internal versions.,0,0.9793126583099365
493169192,9103,hachikuji,2020-09-23T03:03:34Z,"nit: why don't we add a case class and make this optional. for example: [code block] in addition to reducing parameters, that makes the expectation that both are provided explicit.",0,0.9836854934692383
493169273,9103,hachikuji,2020-09-23T03:03:54Z,nit: space after `if`,0,0.9857501983642578
493169694,9103,hachikuji,2020-09-23T03:05:42Z,can you explain why this change is needed?,0,0.9838811159133911
493170132,9103,hachikuji,2020-09-23T03:07:28Z,the comment doesn't seem to make sense here. seems like the logic doesn't have anything to do with the controller?,-1,0.5435665249824524
493170494,9103,hachikuji,2020-09-23T03:09:02Z,this function has 3 callbacks... it would be nice if we could figure out how to pass through the `forwardrequesthandler` directly.,0,0.9355515241622925
493170831,9103,hachikuji,2020-09-23T03:10:24Z,nit: this is misaligned,-1,0.5125582814216614
493171357,9103,hachikuji,2020-09-23T03:12:42Z,"we can't guarantee that this broker will still be the controller when we call `process` or that the broker we're forwarding to will still be the controller when it receives the request. in these cases, we need to return some retriable error to the client. can you help me understand how this is implemented?",0,0.9795680046081543
493171799,9103,hachikuji,2020-09-23T03:14:28Z,"nit: this is subjective, but this style is a bit ugly. i would prefer the following: [code block] that makes it easier visually to separate the return type and the function logic (again, in my opinion).",-1,0.9799514412879944
493172457,9103,hachikuji,2020-09-23T03:17:08Z,nit: seems `handle` doesn't really need to be part of `forwardrequesthandler`. instead we could pull it out: [code block] the advantage of this is that it allows us to pull the type out of `kafkaapis` without inheriting all of the dependencies that are needed by `handle`.,0,0.9830490350723267
493173723,9103,hachikuji,2020-09-23T03:22:14Z,it would be helpful to have a comment explaining this. it does not seem obvious.,0,0.9693478941917419
493174084,9103,hachikuji,2020-09-23T03:23:45Z,"good to see the unit tests in here. i think we also need at least a couple integration tests. for example, could we add something to `createtopicsrequesttest` to ensure that forwarding works as expected?",0,0.5296604633331299
493206068,9103,abbccdda,2020-09-23T05:28:51Z,the primary reason is that we would trigger the disallowed import if we do it in the request builder: [code block] let me check if we could make exceptions here,0,0.9873945713043213
493209974,9103,abbccdda,2020-09-23T05:41:23Z,"but in case we release ak 2.7, wouldn't this flag give user the confidence to upgrade to, which we don't want to happen?",0,0.9778982996940613
493518004,9103,rajinisivaram,2020-09-23T12:15:37Z,nit: `ssl` => `ssl`,0,0.9875533580780029
493518728,9103,rajinisivaram,2020-09-23T12:16:25Z,does this get reset somewhere or will we keep adding `/`?,0,0.9798592329025269
493519587,9103,rajinisivaram,2020-09-23T12:17:26Z,`ssl` => `ssl`,0,0.9857980608940125
493520160,9103,rajinisivaram,2020-09-23T12:18:05Z,"this means update was requested, but not necessarily that file has changed?",0,0.9862996935844421
493520165,9103,rajinisivaram,2020-09-23T12:18:05Z,"this means update was requested, but not necessarily that file has changed?",0,0.9862996935844421
493522186,9103,rajinisivaram,2020-09-23T12:20:21Z,can't we put this logic in `dynamicbrokerconfig`?,0,0.9839093089103699
493742677,9103,hachikuji,2020-09-23T16:50:32Z,i'm not sure i follow. do you not want redirection to be part of 2.7?,0,0.6880109310150146
493751026,9103,abbccdda,2020-09-23T17:03:58Z,"the rational is to trigger a reload of ssl store file by the zk notification. came out this idea to augment the path to [code block] when a reload is requested on the receiver broker, and by propagating such a path other brokers would see a difference and thus reload their corresponding store files as well. in the meantime, we need to trim the path back to single slash after handling the notification: [code block]",0,0.9846072793006897
493752855,9103,abbccdda,2020-09-23T17:07:06Z,"the logic is needed when there is an alterconfigrequest targeting at a specific broker. since the non-controller node will no longer handle alterconfigs, it is possible to see a redirected changing request with a broker.id different than the controller broker.id.",0,0.9895901083946228
493771144,9103,abbccdda,2020-09-23T17:37:09Z,"yes, we would trim it in `trimsslstorepaths`",0,0.9891392588615417
493771267,9103,abbccdda,2020-09-23T17:37:24Z,yea,1,0.6565009951591492
493773324,9103,abbccdda,2020-09-23T17:41:05Z,"i feel it's more explicit to do it in here, as zk notification is the only target case.",0,0.979678750038147
493782410,9103,abbccdda,2020-09-23T17:56:03Z,i guess we could get rid of it and do the merge in caller level.,0,0.9873298406600952
493795436,9103,abbccdda,2020-09-23T18:17:46Z,"it's a bit hard since we are passing requestbuilder all the way to networkclient, so if we want a designated version to build the request, that may involve some non-trivial changes.",0,0.555612325668335
493823776,9103,hachikuji,2020-09-23T18:56:42Z,"as discussed offline, we can pass the expected version down to the builder. the abstract builder already supports an explicit range of versions. in any case, it doesn't seem like we have a choice. by the way, one potential edge case here is that the broker receiving the request has upgraded to a later version than the controller. this would be possible in the middle of a rolling upgrade. i don't think there's an easy way to handle this. we could return unsupported_version to the client, but that would be surprising since the client chose a supported api based on apiversions and is not aware of the controller redirection. one idea to address this problem is to gate version upgrades to redirectable apis by the ibp. basically all of these apis have become inter-broker apis through redirection so they need the safeguard of the ibp. feels like we might have to do this.",0,0.9212528467178345
504286524,9103,hachikuji,2020-10-13T22:08:10Z,nit: why don't we call it `requestdata` to be consistent with the name used in the api spec?,0,0.9851706624031067
504287723,9103,hachikuji,2020-10-13T22:10:46Z,nit: i think it might be better to pull this out of the request class. the direction we're moving is toward dumber request/response classes. eventually `enveloperequest` will go away and we'll just use `enveloperequestdata`.,0,0.9644923806190491
504288659,9103,hachikuji,2020-10-13T22:12:59Z,not sure why we need this change. i think the convention is to include `none` in error counts.,0,0.9061073660850525
504293144,9103,hachikuji,2020-10-13T22:24:33Z,i'm wondering if we really need the ibp to leak into the common library. it should really only be a broker concern. seems like the only point is so that we can continue to use the factory methods defined below from the broker code. is that right? could we instead move the factories to the broker?,0,0.8978102207183838
504295024,9103,hachikuji,2020-10-13T22:29:23Z,"in a similar vein, i think it's better to not include serialization logic in the response object. it tends to hide some of the details like byte buffer allocation that we might want to control at another level.",0,0.9742894768714905
504295874,9103,hachikuji,2020-10-13T22:31:40Z,same here. we can return `bytebuffer` and leave parsing to higher layers.,0,0.9886813163757324
504298663,9103,hachikuji,2020-10-13T22:39:21Z,"it is strange to couple the serialization of the principal with the version of the envelope request. this might help us in the case of default principal builder, but users with their own custom builder are on their own, right? i think it is better to be consistent and always leave versioning to the principal builder.",0,0.9444677829742432
504298879,9103,hachikuji,2020-10-13T22:39:55Z,nit: maybe print `forwardingprincipal` only if it is defined,0,0.98885577917099
504300234,9103,hachikuji,2020-10-13T22:43:56Z,do we have a use case for this yet? i don't see that it gets used anywhere.,0,0.9423695206642151
504327985,9103,abbccdda,2020-10-14T00:12:51Z,i guess there are some inconsistency between different rpcs as i spotted cases excluding none. i would initiate a separate jira for the cleaning and revert the change here.,0,0.9688848853111267
504345664,9103,abbccdda,2020-10-14T01:19:44Z,"not yet, could be removed.",0,0.975406289100647
504408633,9103,abbccdda,2020-10-14T05:23:43Z,"the tricky thing here is that if we handle the api version constraints on the broker side, it means we need to either make changes directly to the returned apiversionsresponse or spawn a new instance with applied constraints. that means leaking of the internal architecture of apiversionsresponse to the broker level and redundant conversions imho. the current approach makes sure the broker level logic is clean with only the necessity of passing the ibp number.",0,0.9185876846313477
505765664,9103,hachikuji,2020-10-15T18:47:39Z,what is the benefit of using a different error code instead of `cluster_authorization_failure`?,0,0.9802127480506897
505768901,9103,hachikuji,2020-10-15T18:53:21Z,"i believe we need to set `requiresdelayedallocation` for this api. typically we will release the underlying buffer allocated for a request when `requestchannel.request` is constructed. however, since we are using ""zerocopy,"" we need to hold onto the `bytebuffer` reference until the api has been handled.",0,0.987500011920929
505798234,9103,hachikuji,2020-10-15T19:47:58Z,"it seems like we're trying to reuse this handler from the previous patch, but i'm not sure it still makes as much sense. a simpler structure might be something like the following: [code block]",0,0.9335694909095764
505842904,9103,abbccdda,2020-10-15T20:56:55Z,"`cluster_authorization_failure` normally indicates a client side security configuration error. we intentionally define a separate error code to let admin know that there is some security config trouble with the brokers, not the clients.",0,0.973889946937561
505852939,9103,abbccdda,2020-10-15T21:08:41Z,i think we do have that logic enforced by setting `zerocopy` to true for request data field in the rpc json.,0,0.9880240559577942
509528009,9103,hachikuji,2020-10-21T18:01:43Z,not sure i follow. all current inter-broker apis are gated by `clusteraction` and will return `cluster_authorization_failure` if the principal does not have access. there is no distinction between clients and brokers. it's not clear to me why we need something different here.,0,0.9356566071510315
509533968,9103,hachikuji,2020-10-21T18:06:33Z,"rather than assuming highest supported version, we should include the version in the serialized data. the simple thing would be to write the version first, then write the payload.",0,0.9869990944862366
509537587,9103,hachikuji,2020-10-21T18:09:44Z,nit: can we move this back to where the request parsing logic is. otherwise it becomes a bit hidden.,0,0.9867868423461914
509538545,9103,hachikuji,2020-10-21T18:10:43Z,"nit: add braces to all of these methods. even though they are not required, braces make it easier to see the scope",0,0.9818353652954102
509540617,9103,hachikuji,2020-10-21T18:12:56Z,nit: use `match`,0,0.9888428449630737
509541377,9103,hachikuji,2020-10-21T18:13:43Z,nit: use `match`,0,0.9888428449630737
509545893,9103,hachikuji,2020-10-21T18:19:31Z,nit: this is misaligned. it might be better to pull the body here into a separate method (e.g. `parseenveloperequest`),0,0.9695478081703186
509550124,9103,hachikuji,2020-10-21T18:24:02Z,"we should have a check at the beginning of `handle` to restrict the ""forwardable"" apis.",0,0.9883991479873657
509550802,9103,hachikuji,2020-10-21T18:24:48Z,"we use 'forward' and 'redirect' interchangeably throughout the pr, but the names do suggest different behavior. in my mind 'redirection' suggests that we are telling the client to go somewhere else, while 'forward' suggests that the broker is passing the request through to its destination. so maybe we can stick with 'forward' consistently (e.g. `isforwardingenabled`)?",0,0.9802425503730774
509553533,9103,hachikuji,2020-10-21T18:28:14Z,"as mentioned above, you can see the rest of the cases in this class where we check cluster_action and they all return `cluster_authorization_failure`.",0,0.9890278577804565
509555177,9103,hachikuji,2020-10-21T18:29:41Z,nit: you can just use `channel.principalserde.asscala`,0,0.9795880317687988
509562013,9103,hachikuji,2020-10-21T18:35:40Z,"we want to avoid this serialization since it introduces the possibility for the request to be altered by the forwarding broker. the `requestchannel.request` object retains the reference to the original buffer, which we can use here, but we need to tell the channel to delay releasing the buffer using `apikeys.requiresdelayedallocation` for all of the ""forwardable"" apis.",0,0.9878687262535095
509565018,9103,hachikuji,2020-10-21T18:38:58Z,use `defineinternal`,0,0.9856770038604736
509565555,9103,hachikuji,2020-10-21T18:39:36Z,how about `enable.metadata.quorum`?,0,0.9890897870063782
509645115,9103,abbccdda,2020-10-21T20:09:07Z,had a try but it seems java optional doesn't have an `asscala` option,0,0.9731422662734985
509670268,9103,abbccdda,2020-10-21T20:31:29Z,sounds good.,1,0.9202015399932861
510533897,9103,hachikuji,2020-10-23T00:37:04Z,you probably need the following: [code block],0,0.9859694242477417
510536894,9103,hachikuji,2020-10-23T00:49:41Z,"i was thinking a little bit about this and trying to decide if the envelope request should have a more literal representation of the client ip address. the way it is working right now, it looks like the following: 1) use `socket.getinetaddress` to populate `requestcontext.clientaddress`. 2) use `inetaddress.gethostname` to populate the `clienthostname` field in the envelope request. this will do a reverse dns lookup based on the ip address from 1). 3) now we send `clienthostname` over the wire. it gets unpacked here by doing a dns lookup to get to the `inetaddress` object. so it seems we should be skipping the dns translation and just using the ip address from 1). the `inetaddress` class gives us `getaddress` and `gethostaddress`. the first provides the raw byte representation of the ip address, while the latter provides a textual representation. i am thinking we should use `getaddress` and let this field be represented as bytes. what do you think?",0,0.9228808879852295
510540720,9103,hachikuji,2020-10-23T01:06:42Z,"can we move some of the checks from `maybeforward` here? this is the flow i'm thinking about: 1. first check authorization => cluster_authorization_failure 2. verify forwarding is enabled => invalid_request 3. verify the api is forwardable => invalid_request if all of these pass, then the request continues down the normal handling path.",0,0.9881354570388794
510552124,9103,hachikuji,2020-10-23T01:56:06Z,"quotas are one aspect of this work that need more consideration. what we don't want is for the inter-broker channel to get affected by the individual client throttle, which is what will happen with the current patch. what i'd suggest for now is that we allow the broker to track client quotas and pass back the throttle value in the underlying response, but we set the envelope throttle time to 0 and ensure that the inter-broker channel does not get throttled. for this, i think we we will need to change the logic in `kafkaapis.sendresponsemaybethrottle`. if it is a forwarded request, we still need to check `mayberecordandgetthrottletimems`, but we can skip the call to `clientquotamanager.throttle`. when the response is received on the forwarding broker, we will need to apply the throttle, which i think the patch already handles. one challenging aspect is how this will affect quota metrics. currently quota/throttling metrics are relatively simple because they are recorded separately by each broker. however, here the controller is the one that is tracking the throttling for the client across multiple inbound connections from multiple brokers. this means that the broker that is applying a throttle for a forwarded request may not have actually observed a quota violation. other than causing some reporting confusion, i am not sure whether there are any other consequences to this. cc",0,0.9280698299407959
510554587,9103,hachikuji,2020-10-23T02:06:38Z,"one challenge we have here is that there are two levels of errors. the current patch seems to conflate the two, which makes it confusing. i think we need a structure which allows us to separate the errors possible at the envelope level and those possible at the request level. what i'm thinking is this: 1. for cluster auth and principal serde errors, we should return the envelope error and null response body. 2. for everything else, we return envelope error none and just pass through whatever error is in the response. does that make sense?",0,0.8789475560188293
510568706,9103,abbccdda,2020-10-23T03:06:57Z,"the question would be how the forwarding broker should do the error handling for auth & principal serde exceptions. to me we should get a vanilla error response with `unknown_server_error` and get back to the original client? besides that, i think we could add a differentiation here to avoid passing the serde-type errors to the client.",0,0.9851503968238831
511007228,9103,abbccdda,2020-10-23T16:39:28Z,"for pt2, if the forwarding is not enabled on the active controller, but it has the capability, should we just serve the request?",0,0.9892809987068176
511012913,9103,abbccdda,2020-10-23T16:49:50Z,so the proposal is simply for saving the unnecessary dns translation? not sure if representing as bytes would also serve the security purpose as well.,0,0.9822198152542114
511872018,9103,rajinisivaram,2020-10-26T10:52:19Z,"i guess the only quota that is affected for the rpcs we currently forward is request quotas. totally agree that we shouldn't throttle inter-broker connections. there are a few other things to consider here: 1) every forwarded request uses network thread and request handler time on two brokers. are we saying that we can ignore the time spent on the forwarding broker because that is negligible? in a deployment with ssl on the external listener and plaintext on the inter-broker listener, there may be more network thread time used on the forwarding broker rather than the controller. do we record these, but use the controller throttle time for throttling? 2) are we changing the semantics of quotas? for example, if a client sends a request1 to leastloadednode a which mutes the connection and then sends request2 to leastloadednode b that happens to be the controller, we would mute that connection too. another client with the same principal would get muted on b, but not a because a's quota hasn't been violated. i think this should be ok, though a bit confusing. 3) are these measures good enough to protect the controller? this is the one that needs some more thought. request quotas are configured to allocate a percentage of thread usage to each principal. our quotas aren't very good at protecting against dos attacks, but they help to limit usage for normal clients using the apis. so if we can make sure the implementation for forwarded requests can handle this case, it would be good enough. in the old world, a client doing a lot of config updates would have just distributed the load across brokers as each node was throttled. now, we distribute the iniital request across brokers as controller decides to throttle. total rate for these requests across the cluster is dramatically reduced because all load is now on the controller. but from the controller broker's point of view, we are now allowing more requests through for the same quota from every client because a client can forward through `n` brokers. may have more context on whether these request types actually hit request quotas in real deployments.",0,0.9460607171058655
513608319,9103,hachikuji,2020-10-28T16:56:18Z,"hmm.. it looks like we do not serialize the response header, but i think we probably should. today it only includes the correlationid, but who knows how it will evolve in the future? since we do serialize the request header, it seems better to be consistent.",0,0.9657248854637146
513612935,9103,hachikuji,2020-10-28T17:02:38Z,"since this is a public api, it's worth documenting that these apis should raise a consistent error, such as `serializationexception`, in case of an error.",0,0.9868972897529602
513613435,9103,hachikuji,2020-10-28T17:03:23Z,nit: for the the purpose of inter-broker forwarding,0,0.9804420471191406
513614262,9103,hachikuji,2020-10-28T17:04:30Z,we may as well add a check here for the version so that we get a useful error in case we receive a version that we do not support.,0,0.9836910963058472
513615916,9103,hachikuji,2020-10-28T17:06:37Z,nit: use upper-case `tokenauthenticated` for consistency with other fields,0,0.9888468980789185
513616503,9103,hachikuji,2020-10-28T17:07:26Z,might be worth mentioning `org.apache.kafka.common.security.authenticator.defaultkafkaprincipalbuilder` explicitly.,0,0.983608067035675
513617300,9103,hachikuji,2020-10-28T17:08:33Z,perhaps add a little more detail?,0,0.9787901043891907
513619656,9103,hachikuji,2020-10-28T17:11:52Z,"since principals should be small, it is tempting to just use simple byte arrays for this interface. this is typically simpler for users and gives us a stronger boundary between plugin and broker code.",0,0.9764539003372192
513635843,9103,hachikuji,2020-10-28T17:34:28Z,"it looks like these changes made it to 2.7. we need to revert them before the release or it will not be safe to remove them. the danger is that we might use these tag ids for another purpose in the future, which will break the request parsing.",0,0.9331075549125671
513645474,9103,hachikuji,2020-10-28T17:48:22Z,i guess this shows an inconsistency between the envelope and the other inter-broker apis. the throttle time field is only useful if we actually expect the forwarding broker to respect it and backoff. i wonder if we should just be consistent for now and leave this out.,0,0.9351418018341064
513646769,9103,hachikuji,2020-10-28T17:50:11Z,"would it make sense to add a default rule? if the api is forwardable, then we can assert it requires delayed deallocation.",0,0.9875675439834595
513647237,9103,hachikuji,2020-10-28T17:50:49Z,"in fact, the schema doc says that the response header should be included.",0,0.9884985089302063
513648122,9103,hachikuji,2020-10-28T17:52:10Z,it's not clear to me why we need to do this now since we are not enabling forwarding yet.,0,0.6792225241661072
513659883,9103,hachikuji,2020-10-28T18:09:37Z,"hmm.. the request logging will not be too useful if we cannot see what is in the embedded request and response. i think we should print the envelope structures separately. longer term, we should figure out how to incorporate the envelope into [a link]",0,0.9638572931289673
513662914,9103,hachikuji,2020-10-28T18:14:32Z,not sure why this was resolved. i don't see the check. basically the first thing we should do in `handle` is check whether we have an envelope request and if it is authorized.,0,0.9352769255638123
513667101,9103,hachikuji,2020-10-28T18:21:14Z,"unless the internal config is present, i think we should treat the envelope as non-existing. once we are ready to enable it in the ibp, then we will accept the envelope request even if the local ibp is not high enough.",0,0.9863619804382324
513743473,9103,abbccdda,2020-10-28T20:35:38Z,i think it's ok to remove this flag for now.,0,0.9739747643470764
513750141,9103,abbccdda,2020-10-28T20:48:19Z,"i was under the impression that byte buffer provides more information such as a read position and capacity/limits, which makes the deserialization easier. if given a byte[], i'm afraid they need to convert to byte buffer internally eventually.",0,0.7578242421150208
513757978,9103,abbccdda,2020-10-28T21:02:19Z,"sounds good, will remove the throttle time field from the envelope",1,0.6557714939117432
513759802,9103,abbccdda,2020-10-28T21:05:21Z,"sg, but i guess we need to keep it as is for now to try using the correct api version.",0,0.9866437315940857
513826471,9103,abbccdda,2020-10-28T23:44:21Z,"sg, will initiate a pr for that.",0,0.9852643013000488
515212449,9103,hachikuji,2020-10-30T16:11:00Z,"probably the first thing we should check is `isforwardingenabled`. if it is not, i suggest we close the connection, which is basically the broker's way of saying ""i don't know how to handle this.""",0,0.9566047787666321
515215364,9103,hachikuji,2020-10-30T16:16:02Z,can we add a description explaining what this is for?,0,0.9861171841621399
515219198,9103,hachikuji,2020-10-30T16:22:25Z,we should duplicate the buffer instead of modifying it directly.,0,0.9853336811065674
515219726,9103,hachikuji,2020-10-30T16:23:22Z,"we can leave this for a follow-up, but it would be nice if we could avoid this deserialization (and the subsequent re-serialization).",0,0.9781604409217834
515220480,9103,hachikuji,2020-10-30T16:24:37Z,probably useful to explain why we do this. a debug log message with the original error would be helpful as well.,0,0.9499700665473938
515229180,9103,hachikuji,2020-10-30T16:39:03Z,"i think this was one of my initial questions, but do we have a timeout for the request? looking at the current logic in `handleresponse`, it seems like we will just retry indefinitely. that is probably what we want for requests generated by the broker (e.g. `alterisr`), but it is not so useful for client requests since the client itself will eventually give up and send a new request.",0,0.9705809354782104
515230020,9103,hachikuji,2020-10-30T16:40:21Z,nit: can we create a helper for `request.envelopecontext.isempty`? perhaps we can write this as `!request.isforwarded`?,0,0.9844886064529419
515231023,9103,hachikuji,2020-10-30T16:42:03Z,"hmm.. i had assumed we would be using the same channel manager. can you explain why we need two? in the end, i think all of the requests get serialized on the controller, so i'm not sure we're buying much.",0,0.8154557347297668
515245665,9103,hachikuji,2020-10-30T17:04:46Z,"as far as i can tell, the `callback` here is unused. tracing this back to `kafkaapis`, the callback passed to `sendresponsemaybethrottle` also appears to be unused. i think we can remove it from both apis and simplify this a bit.",0,0.9883516430854797
515276738,9103,abbccdda,2020-10-30T17:48:18Z,"i agree we don't have a prioritization system on the controller yet, but in long term having two separate managers mean we don't block alterisr unnecessarily, which seems to be definitely a higher priority message. cc",0,0.9635877013206482
515377453,9103,abbccdda,2020-10-30T20:51:51Z,sg,0,0.9626029133796692
515388258,9103,abbccdda,2020-10-30T21:20:47Z,"yea, i think this could be done as a follow-up. filed: [a link]",0,0.9573375582695007
515389068,9103,abbccdda,2020-10-30T21:23:12Z,filed: [a link],0,0.9857317805290222
515395403,9103,abbccdda,2020-10-30T21:41:50Z,got a follow-up ticket as well: [a link],0,0.9811142086982727
515413173,9103,hachikuji,2020-10-30T22:44:52Z,can we use `closeconnection`. we do not want to even acknowledge that the api exists unless forwarding is enabled.,0,0.9781309962272644
515414500,9103,hachikuji,2020-10-30T22:50:24Z,nit: drop parenthesis for simple getter,0,0.9867729544639587
515417787,9103,hachikuji,2020-10-30T23:05:00Z,"this begs the question whether the api should even be advertised from non-privileged listeners if users cannot access it. i am thinking we can make this case similar to the behavior if forwarding is not enabled. here we can use this logic: [code block] similarly, we can change the check in `apiversion.apiversionsresponse` so that it skips the envelope api if the request is not from a privileged listener.",0,0.9797021150588989
515418503,9103,hachikuji,2020-10-30T23:08:15Z,not sure i follow the point about the correct api version.,-1,0.5260034203529358
515421189,9103,hachikuji,2020-10-30T23:21:24Z,"i think this logic still conflates the envelope error and the inner response error. we might catch an exception raised from `validateforwardrequest` or from the request handler in `kafkaapis.handle`. both paths flow through `kafkaapis.handleerror`, so we do not have a way to distinguish the two cases. this means that an uncaught error from the underlying request will get sent back to the forwarded broker as an error in the envelope, which will cause us to translate it to unknown_server_error. i think we should handle envelope errors explicitly through a separate method. we can define a method here such as `buildfailedenvelope` which can be used inside `validateforwardrequest`. then inside `buildresponse` here, we can always return `errors.none` as the envelope error.",0,0.9786443710327148
515421553,9103,abbccdda,2020-10-30T23:23:16Z,"it's a bit tricky to do it here since we rely on exception catching to skip all the rest of handling logic, not sure it is worth to add this special case and do `if-else` to incur a large code change.",-1,0.7714328169822693
515427912,9103,hachikuji,2020-10-30T23:57:37Z,"perhaps it is obvious, but this logic does not give us any tight guarantees that the request will actually be handled by the broker that is currently the controller. for example, a new controller might get elected between the check in `validateforwardrequest` and the handler here. that is probably fine at the moment, because the zk logic in `adminmanager` can execute on any broker. if we imagine instead how this will work with the kip-500 controller, i think the incoming request will get put on the controller's queue. by the time the request gets dequeued, we will be able to know for sure whether this node is the controller or not, so we will be able to have a much better guarantee. the only reason i bring this up is that we are currently assuming that the not_controller gets propagated in the envelope error field. we'll have to keep this in mind when we adapt this logic for the new controller.",0,0.9685399532318115
515428385,9103,hachikuji,2020-10-31T00:00:26Z,perhaps we could return a boolean to indicate whether the handling logic should execute. i think it is important to avoid exposing this api until we're ready for it.,0,0.9699244499206543
516344965,9103,hachikuji,2020-11-02T23:57:03Z,nit: seems this change was not needed,0,0.9674120545387268
516349664,9103,hachikuji,2020-11-03T00:06:25Z,"nit: i feel `failureexception` is redundant. can we just call it `principaldeserializationexception`? also, i am not sure about this extending `authorizationexception`. i would consider it more of an invalid request than an authorization failure, though the effect is the same. i think it's probably better to avoid categorizing it and just let it extend `apiexception`.",-1,0.8380919098854065
516356565,9103,hachikuji,2020-11-03T00:21:28Z,nit: every other property name uses a capital first letter,0,0.9821456074714661
516363883,9103,hachikuji,2020-11-03T00:37:20Z,"it is quite expensive to parameterize these test cases. i am not sure it is worthwhile. if forwarding works for one of these cases, why would the others be different? since we are not planning to enable this feature yet, i think unit tests in `kafkaapistest` and maybe one integration test are good enough.",0,0.7735329866409302
516364497,9103,hachikuji,2020-11-03T00:38:40Z,i think it would be simpler to short-cut return. [code block],0,0.9851658940315247
516365803,9103,hachikuji,2020-11-03T00:41:17Z,nit: `validatedforwardedrequest`,0,0.9856319427490234
516366191,9103,hachikuji,2020-11-03T00:42:10Z,"nit: we are doing more than building the response here, we are sending it. how about `sendfailedenveloperesponse`?",0,0.9836128950119019
516372020,9103,hachikuji,2020-11-03T00:54:27Z,"nit: instead of `original`, could we use `forwarded` in these names?",0,0.9894073605537415
516373262,9103,hachikuji,2020-11-03T00:56:55Z,nit: define return type,0,0.9886656999588013
516375303,9103,hachikuji,2020-11-03T01:00:58Z,can you add a javadoc for these methods and mention ` serializationexception`?,0,0.9897558093070984
516378459,9103,hachikuji,2020-11-03T01:09:12Z,"hmm, not sure i get your point. nothing is simpler than a byte array. the main question is whether we want to expose the actual request buffer to the plugin, especially since we still plan on using it afterwards. the plugin is treated as a trusted component in any case, so it might not make a big difference. probably we should optimize here for simplicity. that may or may not be true. if it is, users can just use `bytebuffer.wrap`.",0,0.9509989619255066
516381090,9103,hachikuji,2020-11-03T01:19:18Z,nit: `network` prefix is not needed since we are already in this package,0,0.9887308478355408
516933194,9103,hachikuji,2020-11-03T20:20:55Z,"this inherits all tests from `dynamicbrokerreconfigurationtest`, which doesn't look to be intended. can we just remove it? we can add it back once we get to testing the ssl path changes. for now i think the simple integration test for createtopics is good enough. (by the way, it's curious that `testtruststorealter` still passes even after we have removed the path update logic.)",0,0.9616789221763611
516933962,9103,hachikuji,2020-11-03T20:22:34Z,do we need this change anymore?,0,0.9753376245498657
516934696,9103,hachikuji,2020-11-03T20:24:08Z,i don't think we want to make this the default until we are ready to enable it. i would suggest we create a new `forwardrequesttest` which extends `baserequesttest`. then we can move the test case from `createtopicsrequesttest`.,0,0.9844299554824829
516938814,9103,hachikuji,2020-11-03T20:32:19Z,nit: is this change needed?,0,0.9800792336463928
516942223,9103,hachikuji,2020-11-03T20:39:33Z,is this change needed? i am not sure i follow the comment about the privileged listener. that shouldn't affect acls i think.,-1,0.6882777810096741
516950684,9103,abbccdda,2020-11-03T20:56:53Z,seems ok to remove,0,0.9797009229660034
516951766,9103,abbccdda,2020-11-03T20:59:06Z,"yea, that's weird, let's move to the next pr for a discussion.",-1,0.9866901636123657
37318079,132,hachikuji,2015-08-18T16:09:35Z,"4,2,0?",0,0.9782124161720276
37320190,132,hachikuji,2015-08-18T16:28:11Z,it might make this code a little easier to follow if you split the rack-aware and default assignments into separate functions. what do you think?,0,0.9832219481468201
37323035,132,hachikuji,2015-08-18T16:52:26Z,maybe getinversemap instead?,0,0.9855169653892517
37441970,132,allenxwang,2015-08-19T17:24:41Z,"it will be difficult to separate them out as they actually share quite a lot of common logic, specifically around choosing the leader of the partition. the code change may seem a lot but actually very little for the default assignment algorithm other than changing the name of `brokerlist` to `arrangedbrokerlist`. i can try separate out the logic of choosing followers into different functions for default vs. rack aware assignment and see how it looks like.",0,0.9479679465293884
37442156,132,allenxwang,2015-08-19T17:26:15Z,that's correct. will fix.,0,0.977308452129364
37442594,132,allenxwang,2015-08-19T17:30:10Z,sure.,0,0.9536533951759338
37448769,132,hachikuji,2015-08-19T18:19:45Z,"yep, there would probably be some redundancy, but at least the default path would be uncluttered with all the rack-aware logic. i don't think it's too bad as it is, but clearer separation would be nice if possible.",0,0.9384129047393799
49287039,132,joestein,2016-01-11T02:48:05Z,"can you add some negative testing please, folks do weird and odd things in their properties by accident and we want to guard against that too, etc",-1,0.7867698669433594
49287098,132,joestein,2016-01-11T02:50:07Z,"something about the scala of this makes me want to say it should be an implicit, that is a much bigger topic and change so i would say maybe not introduce that now but here is one of a lot of places we could without losing readability or performance reduce code. maybe even try it with this change as your converting type only in raclocator",0,0.8538106679916382
49287153,132,joestein,2016-01-11T02:52:34Z,rack-locator might be a bit confusing to the user when just coming and looking at the new command / api changes in a release. why not rack-aware or rack-placement-class (keep the simplaracklocator class as is) and then rack-placement-properties? or something of the sort?,0,0.8277708292007446
49287181,132,joestein,2016-01-11T02:53:34Z,what/why are we ignoring here? not looking at entire class just seeing the diff hard to say if this makes sense or not to ignore,0,0.5160402655601501
54477992,132,hachikuji,2016-02-29T21:08:46Z,nitpick: maybe should be rack_key_name for consistency?,0,0.9893723130226135
54478309,132,hachikuji,2016-02-29T21:10:57Z,"also, the comment doesn't add much. maybe you can just relocate under ""endpoint key name""?",0,0.9827019572257996
54489948,132,allenxwang,2016-02-29T22:26:45Z,"i don't think rack belongs to endpoint. it is the same level as ""endpoint"" as indicated in the json format of broker in zookeeper and updatemetadatarequest protocol. a broker can have multiple endpoints but only one rack.",0,0.9869269728660583
54490437,132,hachikuji,2016-02-29T22:30:12Z,"yep, you are right. guess it would make sense for it to go under broker key names then?",0,0.9575707316398621
54498311,132,allenxwang,2016-02-29T23:28:28Z,sounds good.,1,0.9202015399932861
54592298,132,granthenke,2016-03-01T16:26:46Z,do we need to support null? would empty string work well enough and avoid null checks throughout the code?,0,0.9822762608528137
54592311,132,granthenke,2016-03-01T16:26:50Z,related to my protocol question above. would defaulting to empty string work?,0,0.986365556716919
54592316,132,granthenke,2016-03-01T16:26:51Z,could use the constructor that doesn't take a rack.,0,0.9851224422454834
54592322,132,granthenke,2016-03-01T16:26:53Z,could use the constructor that doesn't take a rack.,0,0.9851224422454834
54592337,132,granthenke,2016-03-01T16:26:58Z,is brokerlist used here?,0,0.9883224368095398
54592349,132,granthenke,2016-03-01T16:27:03Z,seams i may need to use this in kip-4. which means it would need to live in the clients library under the common package. could this be a java enum there?,0,0.988704264163971
54592380,132,granthenke,2016-03-01T16:27:09Z,is this includerack boolean used anywhere?,0,0.9879728555679321
54592390,132,granthenke,2016-03-01T16:27:10Z,is this includerack boolean used anywhere?,0,0.9879728555679321
54592404,132,granthenke,2016-03-01T16:27:15Z,are there unsafe characters that could be in the rack string that would break the json read/write?,0,0.9009273052215576
54624794,132,hachikuji,2016-03-01T19:52:38Z,is this only public for testing? would protected or default also work?,0,0.9850400686264038
54627527,132,hachikuji,2016-03-01T20:10:36Z,"would ""safe"" be a better default? looks like the default is only used in test cases, so maybe it would be better to always require the argument?",0,0.9848478436470032
54645170,132,allenxwang,2016-03-01T22:13:58Z,"broker.sizeinbytes() and broker.writeto() was used for serialization and deserialization of updatemetdatarequest when i started the pr. that's why i have to add includerack parameter for version compatibility. it was recently changed to use the java code in kafka.common for this. but broker.readfrom and broker.writeto remain in the code. so i am not sure if they are still needed. if not, we can delete this part of code all together.",0,0.9723832011222839
54645719,132,allenxwang,2016-03-01T22:17:44Z,"i am not sure. this is only used when replica assignment is needed. if the only change in client library is to be able to access rack in topicmetadatarequest/response, then this can stay in scala in kafka.admin.",0,0.9800029993057251
54645900,132,allenxwang,2016-03-01T22:18:59Z,i would think any character is fine.,0,0.9267656207084656
54646069,132,granthenke,2016-03-01T22:20:14Z,topiccommand is taking this as a parameter when creating a topic. assuming the options is important. when createtopic calls go through the broker i will need to pass this option in the request.,0,0.9860060214996338
54646230,132,allenxwang,2016-03-01T22:21:21Z,"no, it is used in controllerchannelmanager and has to be public.",0,0.9825018644332886
54648019,132,allenxwang,2016-03-01T22:33:44Z,"""safe"" is only used in auto topic creation. in command line tools, we would like to be strict about using rack (to catch mis-configured rack) unless the user wants to disable it. this was discussed in kip process. the reason to make this argument optional is that in most cases, user would supply rack for all brokers or no rack for any broker which can be handled automatically in ""enforced"" mode. then createtopic can remain the same signature so that caller of this method does not need to be concerned about rack aware.",0,0.9838423728942871
54648159,132,allenxwang,2016-03-01T22:34:44Z,sure.,0,0.9536533951759338
54649101,132,allenxwang,2016-03-01T22:43:27Z,i discussed this in kip discussion. nullable_string was recommended in the discussion. i think it makes sense as rack itself is designed to be nullable (option[string]). it is legal to define rack as an empty string. there isn't really any null checks in the code as far as i can tell. null just means no rack is defined.,0,0.979912519454956
54649841,132,hachikuji,2016-03-01T22:49:22Z,"is that because we're depending on this constructor for version 1? i know we depend on choosing the right constructor in other request objects to get the right version, but i wonder if it would be better to have explicit static factory methods (e.g. `updatemetadatarequest.createv0()`)?",0,0.966498076915741
54649887,132,allenxwang,2016-03-01T22:49:41Z,it's not. i will remove it.,0,0.907489538192749
54650027,132,granthenke,2016-03-01T22:50:37Z,"i checked the java doc for `json.encode`. it says `this method does not properly handle non-ascii characters.` i am not sure how ""bad"" it fails. some basic limitations/validation on available rack characters and length might help prevent unforeseen issues. something similar to the limitations for a topic name maybe.",-1,0.6877126693725586
54663838,132,allenxwang,2016-03-02T00:57:52Z,"if topic creation is available from clients, then we need to pass rackawaremode in the request. in that case i agree this class should be in common package as enum. do you want me to make this change? does the protocol support enum?",0,0.9868723154067993
54664542,132,allenxwang,2016-03-02T01:06:12Z,"we depend on this constructor to create version 1 and 2 updatemetadatarequest, and possibly for future versions as well.",0,0.9885169267654419
54667264,132,hachikuji,2016-03-02T01:39:53Z,fair enough. i was only wondering if there was a way to keep the version better encapsulated (like all of the other requests). perhaps at least there should be a check on the version to make sure it is greater than 1? i might even enforce only version 1 and 2 since we'll almost certainly have to touch this code anyway if there is another version bump.,0,0.9731728434562683
54668363,132,hachikuji,2016-03-02T01:53:29Z,"makes sense, thanks.",1,0.8964961767196655
54807092,132,allenxwang,2016-03-02T22:53:29Z,"i will add the check for version. i believe 0 is still supported so 0, 1 and 2 should be allowed.",0,0.8923361897468567
54811738,132,hachikuji,2016-03-02T23:30:47Z,"actually it's probably fine as it is since we would raise an error in `protoutils.requestschema()`. i didn't notice that this also supports version 0, so would it make sense change controllerchannelmanager to use this constructor for all cases. (and apologies for all this nitpicking)",0,0.4903508126735687
54812799,132,ijuma,2016-03-02T23:39:22Z,"by the way, for a bit of history, i initially proposed having a single constructor with a version when i introduced this class. however, preferred having separate constructors with all, but the most recent version deprecated.",0,0.9443724155426025
54813357,132,hachikuji,2016-03-02T23:44:08Z,i think my preference would probably be to have static factory methods with the versions included in the name. using constructors is kind of annoying because you have to check the comment to make sure you get the right one.,-1,0.9791877865791321
54813814,132,ijuma,2016-03-02T23:48:37Z,"yeah, we should use more static factories and less overloaded constructors in kafka.",0,0.971906304359436
54815295,132,allenxwang,2016-03-03T00:02:35Z,"i don't really know what would be the valid characters or length limit for rack. looking at the implementation of json.encode() there is nothing suspicious how characters are handled. note that in some cases, rack can be a logical name and used for grouping brokers for fault tolerance. so any character is possible. apache cassandra does not seem to do any validation on rack name for their property file based configuration. if there is no specification or usual convention for the rack name, i suggest we leave it unchecked.",0,0.9534786343574524
54817202,132,allenxwang,2016-03-03T00:22:24Z,would you mind if i leave this code refactoring of constructors to you guys?,0,0.9809007048606873
54817893,132,ijuma,2016-03-03T00:28:21Z,fine by me.,0,0.9450744986534119
54817929,132,hachikuji,2016-03-03T00:28:39Z,ditto,0,0.8428916931152344
54838116,132,junrao,2016-03-03T05:41:11Z,could we fix the alignment?,0,0.986275315284729
54838129,132,junrao,2016-03-03T05:41:23Z,alignment,0,0.9783409237861633
54838137,132,junrao,2016-03-03T05:41:37Z,we should probably mark this as deprecated.,0,0.9639937281608582
54838143,132,junrao,2016-03-03T05:41:40Z,an -> a,0,0.9567945003509521
54838189,132,junrao,2016-03-03T05:42:43Z,"by leader, do you mean preferred leader? the first replica is not always the leader. perhaps it's clearer to just refer to them as 1st replica, the rest of replicas, etc.",0,0.9812590479850769
54838197,132,junrao,2016-03-03T05:42:53Z,would it be better to combine brokerlist and rackinfo and pass in a seq of brokermetadata that includes id and rack?,0,0.9882090091705322
54838204,132,junrao,2016-03-03T05:43:00Z,can reversemap(rack).toiterator just be list.toiterator?,0,0.9894254207611084
54838213,132,junrao,2016-03-03T05:43:13Z,could we use case instead of tuple to make it clearer? ditto below.,0,0.9246330857276917
54838217,132,junrao,2016-03-03T05:43:17Z,should we sort the broker list per rack?,0,0.9861313104629517
54922060,132,allenxwang,2016-03-03T18:16:50Z,"rackinfo here can be different from the actual broker-rack mapping. in case some brokers have rack and some brokers do not have rack, adminutils.getbrokersandrackinfo() will modify the mapping depending on how strict we want to be rack aware. it will also return empty map if user does not want rack aware. i think it is better to have higher level api (like createtopic()) to be influenced by the rack aware mode depending on the situation and user input and leave this assignment api free of that influence.",0,0.9807994365692139
54928901,132,junrao,2016-03-03T18:59:57Z,"we will still need a separate constructor for v1 of updatemetadatarequest since in controllerchannelmanager, we may need to send a v1 request depending on inter.broker.protocol.",0,0.9889391660690308
54928926,132,junrao,2016-03-03T19:00:07Z,"now that we are returning the assignment, it's a bit weird to print the assignment to stdout. perhaps we should let the caller do that.",-1,0.9767425656318665
54928999,132,junrao,2016-03-03T19:00:36Z,"it seems that readfrom and broker.writeto are only used in tests now since the serialization of updatemetadatarequest is based on the one in o.a.k. instead of maintaining the logic here, could we just remove readfrom and broker.writeto and the corresponding test code?",0,0.9897642135620117
54929005,132,junrao,2016-03-03T19:00:38Z,unused import,0,0.9649426341056824
54929073,132,junrao,2016-03-03T19:01:01Z,we will need to construct v1 and v2 request using different constructors. see comment in updatemetadatarequest.,0,0.9879945516586304
54929083,132,junrao,2016-03-03T19:01:05Z,unused import,0,0.9649426341056824
54929093,132,junrao,2016-03-03T19:01:10Z,unused import,0,0.9649426341056824
54929109,132,junrao,2016-03-03T19:01:19Z,could we add the new params in the comment above?,0,0.987557053565979
54929134,132,junrao,2016-03-03T19:01:27Z,this seems to be an expensive way to test auto topic creation since it needs to start a cluster. could we just test adminutils.assignreplicastobrokers() directly?,0,0.9105501174926758
54929143,132,junrao,2016-03-03T19:01:32Z,do we need to start zk for this test?,0,0.9830410480499268
54929192,132,junrao,2016-03-03T19:01:42Z,is this useful since none of the 3 verifications are enabled by default. ditto below.,0,0.9692196846008301
54929198,132,junrao,2016-03-03T19:01:45Z,unused import,0,0.9649426341056824
54929228,132,junrao,2016-03-03T19:01:50Z,"should those comments starting with ""ensure"" be here?",0,0.9839950799942017
54929246,132,junrao,2016-03-03T19:01:56Z,do we need to start zk in this test? it seems that we can just test adminutils.assignreplicastobrokers() directly?,0,0.9878524541854858
54929251,132,junrao,2016-03-03T19:02:00Z,similar to the above. do we need to start zk in this test? it seems that we can just test adminutils.assignreplicastobrokers() directly?,0,0.9888699054718018
54937233,132,allenxwang,2016-03-03T19:51:18Z,do you suggest using a case class to represent the tuple?,0,0.9860245585441589
54937680,132,granthenke,2016-03-03T19:54:04Z,i think just like you did in the map above is good: [code block],1,0.523088812828064
54954835,132,ijuma,2016-03-03T21:54:00Z,"the kip says: `case class broker(id: int, endpoints: map[securityprotocol, endpoint], rack: option[string] = none)` i prefer how you have it here, but we should update the kip.",0,0.9816505908966064
54955136,132,ijuma,2016-03-03T21:55:52Z,yes and the kip should be updated to remove the point about updating `broker.writeto`.,0,0.9882440567016602
54971611,132,allenxwang,2016-03-04T00:15:15Z,"i think we can use the same constructor for both v1 and v2 except for the version number. when the request is serialized, the rack in v1 request is ignored according to protocol. in other words, regardless v1 or v2, we can have rack in updatemetadatarequest.broker and have it handled differently only at serialization. see the updated test requestresponsetest where i added the test for v1 request to make sure it still works.",0,0.9879317879676819
54971962,132,allenxwang,2016-03-04T00:19:06Z,this may not be necessary. see my comment in controllerchannelmanager.,0,0.9871238470077515
54972661,132,junrao,2016-03-04T00:26:36Z,"yes, you are right.",0,0.9410759806632996
54974078,132,allenxwang,2016-03-04T00:41:59Z,the only caller is main(). i feel it is little bit over stretched to print from main or create another function just to print the result.,0,0.9446512460708618
54974433,132,allenxwang,2016-03-04T00:45:54Z,will update the kip,0,0.985630214214325
54974451,132,allenxwang,2016-03-04T00:46:04Z,will update the kip,0,0.985630214214325
54977110,132,allenxwang,2016-03-04T01:10:56Z,"we have unit tests for adminutils.assignreplicastobrokers() that does not require starting a server. however, since the logic that governs the rack aware mode is separate from adminutils.assignreplicastobrokers(), we need to have tests to make sure the right api is called from kafkaapi. the behavior we need to test is - if all brokers have rack, rack aware assignment will be generated - if some brokers have rack and some do not, it will be treated as none of the brokers have rack",0,0.9747449159622192
54978198,132,allenxwang,2016-03-04T01:24:05Z,there is a test case (testgetbrokersandracks) testing the behavior of what broker-rack mapping should be used under different rack aware mode.,0,0.9877504706382751
54980762,132,allenxwang,2016-03-04T01:54:08Z,it is a bug that by default the three verifications are disabled. i will fix it.,0,0.9597225189208984
54981583,132,allenxwang,2016-03-04T02:06:34Z,"it ensures that user can disable rack aware in the command line in topiccommand and the reassignpartitioncommand can generate the assignment which is rack aware, if user does not disable rack aware when running reassignpartitioncommand.",0,0.9892143607139587
54981885,132,allenxwang,2016-03-04T02:11:04Z,"this covers the situation where replica assignment is rack aware for alter operation. again, i added this test since user input in the command line can change how rack aware is enforced.",0,0.9892744421958923
54983632,132,allenxwang,2016-03-04T02:38:55Z,"given the comment from that the old constructor should be deprecated, i think it is better to use the new constructor.",0,0.9812817573547363
54996851,132,granthenke,2016-03-04T07:08:34Z,works for me,0,0.9517455101013184
54997151,132,granthenke,2016-03-04T07:13:12Z,the way protocols support enum is via some id field. examples can be seen in existing enums and my kip-4 prs: [permissiontype.java ]([a link],0,0.987433135509491
55029807,132,ijuma,2016-03-04T13:35:25Z,note that this constructor is only used in tests. does it even make sense to keep it?,0,0.9845098853111267
55030014,132,ijuma,2016-03-04T13:37:23Z,"this constructor is only used in tests, does it make sense to keep it? i guess the question is whether the request classes are api. as i understand, they are not, but i would like to get 's take.",0,0.9827690720558167
55031610,132,ijuma,2016-03-04T13:52:14Z,"can you please elaborate why you think it's not good to move the println to `main`? in fact, that is exactly what was done in the following pr that adds some tests to the reassign partitions command: [a link]",0,0.9850452542304993
55032389,132,ijuma,2016-03-04T14:00:22Z,"i think it would be good if we could elaborate a little more on the purpose of this property (with some brief examples, maybe).",0,0.9378097653388977
55033837,132,ijuma,2016-03-04T14:14:35Z,"we say that we register the v3 format including rack, but the code only adds the rack if `apiversion >= 3`. if we follow the same approach as what we did with v2, we should always add the rack as it will simply be ignored if `version < 3`, right?",0,0.9885584115982056
55033946,132,ijuma,2016-03-04T14:15:36Z,"also, the documentation here isn't accurate as we may register `v2` depending on the value of `apiversion`.",0,0.9691218137741089
55075041,132,allenxwang,2016-03-04T19:16:21Z,"do you really need to serialize rackawaremode from the client side? if you want to send a request to broker to create topic, the only thing related to rack aware is whether you want to disable it. and you can send a string for this purpose like the ''--disable-rackaware"" command line option, right?",0,0.9853430986404419
55075472,132,granthenke,2016-03-04T19:19:51Z,"why send a string and translate it in 2 places, with 2 pieces of logic, if instead i can have 1 common enum that lets me send a small byte and ensure translation is the same on both sides. my understanding is this is not a boolean choice but there are 3 values to pick from. i have not spent enough time digging into rackawaremode and if its really required, but if i need to use it to communicate to a broker it should be in the clients code.",0,0.9684814810752869
55076734,132,allenxwang,2016-03-04T19:29:16Z,it is more of a style issue. i noticed that most of the command class' `main` does not have println. the above pr refactored the `generatedassignement` function into two and there is no println in main. i am fine with this approach.,0,0.8413835167884827
55082237,132,ijuma,2016-03-04T20:09:58Z,"that's fine too. the main aim is to keep the method that returns a value without `println` so that it can be tested without polluting the logs, for example.",0,0.943214476108551
55082518,132,ijuma,2016-03-04T20:12:28Z,"are you suggesting that `safe` mode would not make sense in this context? if so, then i agree that this enum would not make sense in `common`.",0,0.9725890755653381
55083450,132,allenxwang,2016-03-04T20:20:07Z,i will update the document. i think it is safer not to register the rack when version < 3 and having rack in v2 violates the specification anyway which might be confusing to users.,0,0.950163722038269
55084318,132,ijuma,2016-03-04T20:27:37Z,"ok, i think this has been discussed before and i apologise for asking again. why do we need to write v2 at all? with the exception of 0.9.0.0, the parsing code reads any version and ignore fields that it doesn't know about, right? is it to make it possible to upgrade from 0.9.0.0 (even if that will break old clients anyway)?",-1,0.8156113624572754
55088095,132,junrao,2016-03-04T21:00:54Z,"i think the reason that we have to design the broker registration json in a backward compatible way is that the old consumer and admin tools still read the json directly. once we deprecate the old consumer and move the admin tools to the admin api, only the brokers need to read the json. then, potentially we can make non compatible json changes as long as the broker writes the json according to inter.broker.protocol. for example, we make want to clean up the redundant host field in the future. so, it is true that at this moment, we can always write the latest version of the json that the broker understands since the change is backward compatible. however, following the inter.protocol convention is probably what we want to do in the future. so, we may want to just start doing this now.",0,0.9685041904449463
55088361,132,allenxwang,2016-03-04T21:03:37Z,safe mode is currently only used for auto topic creation. it is not used for command line tools. i think it is better for you guys to do the necessary changes when implementing the client side code since i cannot verify the changes i make here will work for clients in the future. and it will be more efficient to do this later since there might be unforeseen problems or design changes arise when client code is implemented.,0,0.8943941593170166
55088556,132,granthenke,2016-03-04T21:05:20Z,i am okay with that.,0,0.9225295186042786
55095191,132,ijuma,2016-03-04T22:00:10Z,"thanks for explaining. if we want to do it this way, i think we need to add a comment explaining it because it's not obvious and it's inconsistent with how we did the v1 to v2 change. having said that, i am not sure if it's worth doing this now for the following reasons: - it will probably be a long time before we can actually drop support for the old consumer and admin tools in the broker (i think 3 non-bug fix releases is the absolute minimum, but it will probably be longer) - it's inconsistent with how the parser code works (for compatibility as you mentioned). without changing the parser code, older brokers will break if we suddenly remove fields. - it doesn't seem to buy us anything in terms of what gets stored (people will bump inter.broker.protocol as part of the upgrade and then v3 will be stored anyway) for the time when we want to delete fields. it seems to me that when we have a concrete plan to clean this up, we can add the necessary code for both writing and parsing. it will probably take a few releases before we can actually delete the fields, but that's probably ok.",0,0.4591124951839447
55098730,132,junrao,2016-03-04T22:27:05Z,": yes, we can probably just write the v3 json for now and clean things up later.",0,0.9312120676040649
55102385,132,allenxwang,2016-03-04T23:02:57Z,one thing i want to add is that we have to write v2 when protocol is 0.9.0.x because of kafka-3100. having rack in v2 version is probably fine but i don't see any benefit of doing that.,0,0.9654834866523743
55103536,132,ijuma,2016-03-04T23:16:52Z,"right, so that was my original question, this helps with people who want to upgrade brokers from 0.9.0.0 to 0.10.0.0, right? that's a fair argument and worth mentioning in the code. with this approach, only old clients have to go to 0.9.0.1 before the 0.10.0.0 upgrade. brokers can go straight from 0.9.0.0 to 0.10.0.0 (provided that they do the inter.broker.protocol dance).",0,0.9743061065673828
55106909,132,allenxwang,2016-03-05T00:00:19Z,ok. i like that approach too and it will simply my junit tests. i will borrow that in this pr. you still need to resolve the conflict through in the future.,1,0.9466423988342285
55107138,132,ijuma,2016-03-05T00:03:20Z,sounds good.,1,0.9202015399932861
55187222,132,ijuma,2016-03-07T10:47:20Z,", if we use something like the following, we can still handle the scenarios you describe, right? [code block] i am happy to try this out on a branch to see how it looks. thoughts?",1,0.9582480788230896
55188628,132,ijuma,2016-03-07T11:00:54Z,i think we should also update the text around: `there are 2 goals of replica assignment` either we need to add a third goal or we should make it clear that that description is for rack unaware and then explain what the goals are for the rack-aware case.,0,0.9826814532279968
55402888,132,allenxwang,2016-03-08T18:24:57Z,updated the doc. please take a look.,0,0.9769644737243652
55404378,132,ijuma,2016-03-08T18:33:53Z,"looks good, thanks.",1,0.9419525265693665
55487522,132,ijuma,2016-03-09T08:52:56Z,"""notes to clients"" maybe?",0,0.9818285703659058
55488300,132,ijuma,2016-03-09T09:00:44Z,"maybe: ""clients with a zookeeper dependency (old scala high-level consumer and mirrormaker if used with the old consumer) will not work with 0.10.0.x brokers. therefore, 0.9.0.0 clients should be upgraded to 0.9.0.1 before brokers are upgraded to 0.10.0.0.""?",0,0.9821949601173401
55532555,132,granthenke,2016-03-09T15:15:02Z,this is a big deal right? it breaks kafka's backwards compatibility guarantee. it should probably be moved from the performance impact section to the breaking section. is there anything else we can do to fix this? are we sure it does not break 0.8 clients? cc,0,0.9632003307342529
55534413,132,granthenke,2016-03-09T15:26:22Z,"i went back and looked. i see why its only an issue for 0.9.0.0. its because a change went in that throws an exception for any version > 2 ([a link], where in 0.8.x version isn't even used ([a link]. can we leverage the fact that we are only adding a field, therefore this is a ""compatible"" update that does not require a version bump? that way we stay at version 2, 0.9.0.0 ignores the rack field, and everything works? this should work because all of our json parsing just uses a map[a link] anyway.",0,0.973031759262085
55536850,132,ijuma,2016-03-09T15:41:09Z,", yes, it is a big deal. your suggestion was discussed in the kip thread, but said that we need to increase the version when we change the format. as i understand it, the idea is to move away from being limited to just adding fields once we stop supporting old clients (but that is a while away in my opinion). thinking more about this, we could also add a new version field and deprecate the old one (which can stay at `2` until we no longer support `0.9.0.0` many years from now) if we really care about having an incrementing version each time we change the format. thoughts?",0,0.6606482863426208
55538191,132,granthenke,2016-03-09T15:49:05Z,"i agree, we don't want to be limited to just adding fields, but when we are just adding fields a version bump may not be required. this patch assumes anything over version 1 will be compatible in the else statement, so even though our goal is being able to remove fields, this patch does not do that. i don't think adding another version makes sense, thats just adding another field to (old) version 2. we can just add the rack field and achieve the same goal.",0,0.957993745803833
55539640,132,ijuma,2016-03-09T15:57:16Z,"i don't agree that we achieve the same goal. from a storage format documentation perspective, it's easier to track format changes if there is a version associated with them (even when doing compatible changes like adding fields). it is still useful to know when a particular set of fields was added ((in this case it's just a single field, but in others there will be more). yet another way to handle that is to tie the format with `apiversion`. this can be done implicitly or explicitly.",0,0.9661991596221924
55541167,132,granthenke,2016-03-09T16:05:41Z,"i completely agree. versioning the the format is important. it acts as valuable documentation and (when used correctly) can help improve compatibility. let me be clear about my intentions. i am making no comment on the future of zookeeper json compatibility, just this change and its impact to the upcoming release. given that we still, even in this patch, don't support removing fields in future versions. changing the version for that reason is a moot point. therefore the only value the version has is documentation. if we weigh documentation and compatibility for 0.10 and choose documentation, then we can bump the version. if we think compatibility is the most important thing to maintain. that can be solved by keeping the version at 2.",1,0.554224967956543
55604952,132,junrao,2016-03-09T22:50:20Z,": yes, we could keep version 2 in json. but the the drawback is the following. if we want to support upgrading form 0.9.0.0 to any future releases post 0.10.0, we can't bump the version in json forever. given that (1) versioning the json in zk is useful and (2) the issue in 0.9.0.0 is a bug and relatively few people are using 0.9.0.0 yet, i think it's probably better to change the zk version now, but require people to upgrade from 0.9.0.1.",0,0.8912048935890198
55631206,132,granthenke,2016-03-10T03:57:23Z,"in future releases we expect to remove the old scala clients. this means only the brokers will talk directly to zookeeper and this should not longer be an issue. my understanding is the goal of 0.10.0 is to be a ""compatible"" release. future releases may remove other deprecated things and choose to be breaking. i think that's the best time to break here as well. i don't want to push the issue too much. in the end, i am okay with either choice. i just want to be sure we are consciously choosing to break and for good reason.",0,0.6797414422035217
55909377,132,junrao,2016-03-12T00:37:13Z,"this doesn't seem to be 100% safe in that we can potentially assign 2 replicas to the same broker. consider the following example. rack : a b a a broker: 0 1 2 3 at some point, we assign the 1st replica to broker 1. suppose that nextreplicashift is 0. we then assign 2nd replica to broker 2. when assigning the 3rd replica, we will be skipping 3 and 0 and assign broker 2 to the 3rd replica again. before we don't have this issue since when assigning replicas other than the 1st, we cycle through the brokers sequentially without skipping. the new logic allows skipping. so, it's possible for us to hit the same broker.",0,0.9542571902275085
55909620,132,junrao,2016-03-12T00:41:32Z,"i still think that this test and adminrackawaretest (except for testgetbrokermetadatas) can still be simplified. for example, if we restructure the code a bit by wrapping assignreplicastobrokers in another helper method that takes the following signature, then we should be able to test all kinds of rack/rackawaremode combinations w/o needing to start broker/zk, right? (brokermetadatas: seq[broker], rackawaremode: rackawaremode, npartitions: int, replicationfactor: int, fixedstartindex: int = -1, startpartitionid: int = -1)",0,0.9796953201293945
55909641,132,junrao,2016-03-12T00:41:38Z,"hmm, what does notenoughpartitions mean?",0,0.9701809883117676
55909658,132,junrao,2016-03-12T00:41:48Z,is filling the same value expensive? would it be more efficient to just iterate each size and do a check?,0,0.9763295650482178
55909701,132,junrao,2016-03-12T00:42:30Z,should we also verify that no two replicas from the same partition are assigned to the same broker?,0,0.9874008297920227
55909718,132,junrao,2016-03-12T00:42:41Z,is there anything special with 12 partitions?,0,0.9870288372039795
55910465,132,ijuma,2016-03-12T00:56:40Z,this is really cheap compared to other things we do in our tests and it gives better error messages.,0,0.5990090370178223
55911136,132,allenxwang,2016-03-12T01:07:54Z,"i don't think that will help from test's perspective. even if we add rackawaremode here, we still need to make sure that for auto topic creation and command line tools (where you can disable rack aware) the right rackawaremode is used. the tests that have dependency on broker/zk make sure no matter how underlying api is structured, the end result is correct. so i think there are values in the tests.",0,0.9735672473907471
55911374,132,allenxwang,2016-03-12T01:12:35Z,i will fix the confusing name. the test makes sure the algorithm works when the number of partition is not multiple of brokers.,0,0.9862859845161438
55911537,132,allenxwang,2016-03-12T01:15:43Z,"probably not. :) in general, these tests run very fast since all they do is operate on collections in memory. so i have not thought about reducing the number of tests.",1,0.9432595372200012
55915045,132,allenxwang,2016-03-12T03:23:17Z,that's a very good point. i will address this in my next update.,1,0.9808295965194702
55917767,132,allenxwang,2016-03-12T07:16:04Z,"thinking a little bit more on this, i think this situation is actually covered by the algorithm. in this case, there are three replicas and only two racks. once replicas are assigned to 1 and 2, we know that all racks have replicas for the partition and skipping behavior will stop.",0,0.9726452231407166
55922985,132,junrao,2016-03-12T15:49:24Z,"right, this example actually works. but the following won't. consider the following broker to rack mapping. rack : a b c a a broker: 0 1 2 3 4 let's say you want to have 4 replicas and the first replica is assigned to broker 2. then you assign 2nd replica to 3. then you skip broker 4 and 0 since both are on rack a and not all racks are filled yet. then you assign 3rd replica to 1. finally, you will assign 4th replica to broker 3 again.",0,0.971758246421814
55929323,132,allenxwang,2016-03-12T23:09:16Z,"yes, i will add that check.",0,0.982892632484436
55929568,132,allenxwang,2016-03-12T23:31:03Z,excellent example. added the logic to prevent assigning replica twice to the same broker for the same partition.,1,0.9007142782211304
55933791,132,ijuma,2016-03-13T08:37:22Z,"nitpick: we don't really need this `assertequals` or the `brokerlist` val since that is checking that `tobrokermetadata` works correctly, which is not the purpose of this test.",0,0.9841312766075134
55933813,132,ijuma,2016-03-13T08:39:50Z,this was probably an accidental reformatting by intellij.,0,0.9661824703216553
55933814,132,ijuma,2016-03-13T08:39:55Z,this was probably an accidental reformatting by intellij.,0,0.9661824703216553
56015924,132,junrao,2016-03-14T15:12:39Z,"only this test needs zk. could we pull this test to a different class and remove the zk dependency from this class? otherwise, each test will unnecessarily start a zk server, which will slow down the test.",0,0.927640438079834
56016010,132,junrao,2016-03-14T15:13:09Z,could we add an error message in assertequals? ditto in the assertequals below.,0,0.9434946179389954
56053157,132,allenxwang,2016-03-14T18:40:06Z,will do.,0,0.9548023343086243
56054757,132,allenxwang,2016-03-14T18:50:00Z,"i think there is value in checking this to make sure test set up is correct. otherwise if `tobrokermetadata` is changed, there are two possibilities: - test fails and it is difficult to debug why it fails - test passes but is actually weakened",0,0.9751213192939758
56095654,132,ijuma,2016-03-14T23:45:37Z,", we use `tobrokermetadata` in many other tests and we don't check its behaviour in the other cases, so it looks a bit inconsistent. in my opinion, if we want to be sure about its behaviour, we should write a test for it instead of checking its behaviour inside other tests. in any case, this is a very minor point and i'm fine if we leave as is.",0,0.669793426990509
220379749,5693,vvcephei,2018-09-25T22:47:11Z,"this change (and similar changes below) are to make sure the serdes we need for suppression are available. i sort of thought that we already merged a pr to do this, but perhaps it was only partial.",0,0.9824718832969666
220380552,5693,vvcephei,2018-09-25T22:51:38Z,"i realized belatedly that i missed this (internal) interface when i renamed ""maxkeys"" to ""maxrecords"" in part 1.",0,0.9133464097976685
220380693,5693,vvcephei,2018-09-25T22:52:29Z,this wraps the value so that the buffer can store the whole record context for later forwarding.,0,0.9880684018135071
220381174,5693,vvcephei,2018-09-25T22:55:02Z,"since we don't actually store the value serialized in the in-memory impl, we annotate the value with its size so we can maintain the current footprint of the buffer. alternatively, we could serialize it again on removal to idempotently re-compute its size, but this seemed cheaper.",0,0.9680014848709106
220383032,5693,vvcephei,2018-09-25T23:04:56Z,"this could be configurable in the future, but for now, we enforce the time limit in the following fashion: * start a timer when a key first enters the buffer * that key and its most recent value will be emitted when the time limit expires, regardless of how recently it has been updated the primary advantage of this implementation is that we guarantee that if you set a 5-minute limit, we delay emitting the key for no more than five minutes. if we instead re-set the timer on each update, you might never see a record that gets consistently updated more frequently than the time limit. my judgement was that this is the most intuitive default and starting point for the feature. if people want to configure it, we can easily add that option later.",0,0.9563921093940735
220383454,5693,vvcephei,2018-09-25T23:07:36Z,"as demonstrated by part 1, we don't always need the buffer, so i thought it best to avoid allocating it and scheduling the associated punctuator until we first discover we need to buffer something.",0,0.9796265959739685
220384765,5693,mjsax,2018-09-25T23:15:03Z,why do we need this in `process` -- seem like moving it to `init()` should be sufficient?,0,0.9822072982788086
220385505,5693,vvcephei,2018-09-25T23:19:53Z,"this was the punctuation concern brought up. i haven't optimized this yet because i wanted to discuss the available options first. i'm thinking: 1. store the min timestamp in the buffer to make this function cheap when there's nothing to do 2. schedule just one punctuator for all the buffers. this would require more coordination in the topology builder, and i'm not sure if it would actually yield any benefit. is iterating over buffers any better than iterating over an equal number of punctuators? 3. schedule the punctuator less frequently. this would improve performance for high-frequency topics, but not for medium to low frequency topics. on the downside, it would sacrifice resolution and make the tests a little tricky to reason about. 3a. we could probably make a reasonable approximation of the appropriate resolution based on the suppression time limit, like `min( max(1, suppressduration / 10), 30 seconds)`, or even tie it to the commit interval. 3b. to mitigate the testing problem, we could add a private mechanism to directly set the resolution. (not sure this is needed; would like to see how awkward it is in practice once we decide on some optimizations)",0,0.8503232598304749
220385584,5693,mjsax,2018-09-25T23:20:27Z,`suppress.gettimedefinition()` should return the same thing each time? should we put it into a member variable?,0,0.9207972884178162
220385995,5693,vvcephei,2018-09-25T23:22:55Z,"come to think of it, this is probably insufficient to catch the wrong serde (due to erasure). i probably need to relocate this error message to the actual call to de/serialize",0,0.8951048254966736
220386097,5693,vvcephei,2018-09-25T23:23:35Z,oops. i'll take these out.,-1,0.9660875797271729
220386172,5693,mjsax,2018-09-25T23:23:58Z,"i am wondering about this: as we compute the byte-size later, and already pay the cost to serialize the record, should we not store `byte[]/byte[]` in the buffer? of course, still will imply that we need to deserialize later, however, the keeping the actual deserialized objects around would haver more storage overhead and would not obey the buffer size imho. thoughts?",0,0.804166853427887
220386402,5693,mjsax,2018-09-25T23:25:24Z,we should resolve this before merging imho.,0,0.9832594394683838
220386480,5693,vvcephei,2018-09-25T23:25:55Z,"oh yeah, i was meaning to figure out the right exception to throw to achieve a nice shutdown (i think any runtime exception will do it, but is there a semantically best one?)",0,0.8509628772735596
220386796,5693,mjsax,2018-09-25T23:28:01Z,do we need this check?,0,0.9846360683441162
220387020,5693,vvcephei,2018-09-25T23:29:25Z,this is specifically for storing the keys sorted by timestamp in the buffer. i wasn't sure whether a more general or more specific name like `bufferkey` is better...,0,0.8932511210441589
220387145,5693,mjsax,2018-09-25T23:30:17Z,nit: remove `this`,0,0.9810076355934143
220387246,5693,vvcephei,2018-09-25T23:31:02Z,"aka, ordering of keys that share a timestamp is arbitrarily. if anyone cares, we can do ""better"" by requiring k to be comparable (but i don't think anyone should care, so i kept it simple)",0,0.9530728459358215
220387263,5693,mjsax,2018-09-25T23:31:07Z,should we check for `last == null` and set `last = null` ?,0,0.9878501296043396
220387414,5693,mjsax,2018-09-25T23:31:56Z,guess this should be removed?,0,0.981046736240387
220387906,5693,mjsax,2018-09-25T23:35:08Z,not sure about this. see my other comment. would be good to get input from and about this.,0,0.8500329256057739
220387946,5693,vvcephei,2018-09-25T23:35:24Z,aha. i was thinking of [a link] which just isn't merged (yet).,0,0.9578341245651245
220390443,5693,mjsax,2018-09-25T23:50:35Z,"imho, scheduling a `1ms` punctuation would cause quite some overhead. alsw, we only need this for ""time based"" eviction, not for buffer size (num records, num bytes), right? we should also know, *when* we need to evict earliest -- thus, it should be sufficient to schedule accordingly? i think, we can also exploit cancellation to scheduled punctuation to be more flexible. also note, that during runtime, we don't check for punctuation execution after each record, but do this only after n records are processed (with n being adjusted dynamically during runtime). we also need to consider, that we fire a lot of punctuations if we ""jump ahead"" in time what seems to be inefficient.",0,0.9731833338737488
220390754,5693,mjsax,2018-09-25T23:52:28Z,i agree with the described semantics.,0,0.9744599461555481
220390935,5693,mjsax,2018-09-25T23:53:39Z,"forgot to add this to my review: this seems to have large runtime overhead and imho, we should try to find a better way to handle this.",-1,0.8402947783470154
220391498,5693,mjsax,2018-09-25T23:57:09Z,do we need to use punctuations to enforce record/byte limit? might be better to check for record/byte limit on put and use punctuations only to evict time based?,0,0.9869324564933777
220402141,5693,vvcephei,2018-09-26T01:19:05Z,"ah, ok. i was hoping this is not how punctuations work (i'm ashamed to say i haven't looked at it yet). what i was hoping is that if i start at stream-time 0ms and then get a record at time 100ms, then my 1ms punctuator would be invoked just once, at time 100ms. i.e., i was thinking it would ""jump ahead"" (i thought i observed this, but maybe it was using the `topologytestdriver`). one alternative is to ""brew my own"" schedule exactly as i described, checking during `process` if there are any old-enough records. this could be done in the same loop that evicts if we're over capacity. this implementation would be very cheap. the tradeoff is that the punctuator will be fired on any advancement in stream time, whether or not that record actually reaches the buffer. but the hack i described would only ""tick"" when `process` is invoked. i *think* this would probably be satisfactory semantics.",-1,0.8237335085868835
220403434,5693,vvcephei,2018-09-26T01:29:19Z,"regarding: this is true, but it's slightly tricky (or at least it took me a while to realize it's not sufficient to trigger every `suppressduration` ms). i guess that each time we have a new min buffered timestamp `m`, we'd schedule a punctuation, we could cancel the previous punctuation and schedule a punctuation for `m + suppressduration` time from now. the punctuation schedule doesn't let you schedule in the form of ""`x` ms from now"", (i'm guessing it's epoch aligned like the windows), so we'd do a little math to compute a punctuation interval that would next fire at the correct time. i said ""each time we have a new min timestamp"". this can happen when we buffer new records or when we evict records. is this what you had in mind?",0,0.8284639120101929
220405269,5693,vvcephei,2018-09-26T01:44:03Z,"it's not so easy to tell when we really need to buffer records until we actually get some records. this is a consequence (maybe a downside) of my choice to use `timedefinition` to use the window-end time as ""now"" and the grace period as the `suppressduration`. because of this, within the buffering context, even with a `suppressduration` of 0, we might still need to buffer, as the effective timestamp is in the future. thinking through this, we could try instead using the window start as ""now"" and using the window size + grace period as the suppress duration, but offhand it seems this wouldn't work too well with sessionwindows (or other variable-sized windows). so instead what i chose to do is just do a lightweight check when i need the buffer and initialize it if it hasn't already been. i could even move the `if buffer == null` to right here, and jit branch prediction would ensure this lazy check is almost zero after buffer gets initialized. some alternatives: 1. discard the optimization and just always initialize it, in case i need it. 2. junk the (maybe unnecessarily) flexible `timedefinition` function and instead just use a ""time strategy"" enum that tells the processor whether it should use record time or window-end time: in the former case, if the duration is zero, we know we'll never need a buffer. if it's > zero, we'll probably need one. in the latter case, we'll probably need a buffer, regardless of the suppression duration. wdyt?",0,0.9538446664810181
220413716,5693,vvcephei,2018-09-26T02:54:39Z,"yeah, i think this is a reasonable thing to do. i've been going back and forth on it. the downside of storing it serialized is then we need to deserialize it to emit it. this is a moot point for the (planned) on-disk implementation, but for in-memory it saves some cpu and possibly some gc pressure not to round-trip it through a byte array. as is, we serialize it just once instead of serialize + deserialize. plus we currently discard the produced array immediately, so it's easy on the gc, whereas if we keep it, then we have 3 medium-to-long term objects: the incoming record, the serialized array, and the (deserialized) outgoing record. is this premature optimization? possibly. some other factors to consider: when we send to the changelog, we'll need to serialize it anyway. but i'm planning to send only on `flush` and to keep the changelog buffer compact with a linkedhashmap, so records that get updated or retracted several times within a commit interval would only get serialized once. plus, for this purpose, we still only need the `serialize` side; we could hang onto the produced array after computing the size long enough to send it to the changelogger. for changelogging purposes, we'd only need to deserialize when we recover on startup, not in steady-state operations, so i think it's still more economical to store the records as objects instead of serialized. it is true that there's really no tight correlation between the heap used by an object and the heap used by its serialized form. so at the moment, we're only roughly obeying the size limit. for primitive data, it's probably pretty close, though. i'm open to either way of doing it, but that was my thinking. what say you?",0,0.9184287786483765
220413812,5693,vvcephei,2018-09-26T02:55:41Z,"definitely. should it just be a `kafkaexception`, or something more specific?",0,0.9800959825515747
220415961,5693,vvcephei,2018-09-26T03:16:24Z,"good idea, setting it to null after i use it will make it available for gc. i can guard against null also, but fwiw, i'm not sure how that situation could arise. it's an `illegalstateexception` to invoke `delegate.remove` without an intervening call `delegate.next`. or to call it before `next`. `delegate.next` could return null, but in that case, we'd get an exception in line 69... which i should check for there.",0,0.8114526271820068
220416468,5693,vvcephei,2018-09-26T03:21:03Z,"probably not. i don't think this can happen unless this buffer is used across threads (which shouldn't happen), or unless we screw up the implementation in the future (which we could do in any number of ways, it doesn't mean we need guards everywhere). wdyt?",0,0.9546001553535461
220416859,5693,vvcephei,2018-09-26T03:24:51Z,i think you're spot on. i'll check it out.,0,0.9441365599632263
220424615,5693,vvcephei,2018-09-26T04:38:31Z,i think i like this better than my ideas 2 and 3 above. i'm on the fence about this vs just doing it as a part of `process`. i think we'll probably want to do idea 1 regardless.,1,0.8949372172355652
220435089,5693,mjsax,2018-09-26T06:06:25Z,"compare [a link] and the corresponding pr for more details about punctuation semantics. `topologytestdriver` should not work differently (if it does, it's a bug in the test driver -- behavior must be the same to allow for unit testing -- would be bad if it would behave differently). about the second point: yes, something like this. i did not think this through. maybe it's also ""good enough"" to have something more coarse grained for first release. going with ""manual punctuation"" with ""process"" might also be a good first approach -- might still be better than `1ms` punctuation from an overhead point of view (of course, depends on the throughput... 1ms == 1000 records/second/task...)",0,0.8229774832725525
220435537,5693,mjsax,2018-09-26T06:09:25Z,hard to say -- jit branch prediction might make my concern invalid -- it's just because it's on the hot code path. would be good to get input from and,0,0.8409391045570374
220435742,5693,mjsax,2018-09-26T06:10:44Z,"also, we should avoid pre-mature optimization...",0,0.9425632357597351
220436580,5693,mjsax,2018-09-26T06:16:03Z,"agree with all trade-offs you mention. for ktable caches, we also went to storing `byte[]` to obey the size config. also note, we don't need to deserialize all byte[] arrays, but only on eviction -- if we have a lot of suppression. many byte[] arrays would never the deserialized but overwritten. depending on throughput and number if unique keys, this might happen quickly enough to still be young gen. hard to say. again, more input from and would be helpful. and as above, pre-mature optimization should be avoided. could we do some prototyping and benchmarking of both approaches? not sure if there is enough time. also, it's an internal implementation and if performance becomes an issue, we ca also improve on it in 2.2.",0,0.8510701656341553
220436698,5693,mjsax,2018-09-26T06:16:42Z,i guess `streamexception` or maybe a new sub-class would be a good idea.,0,0.9553065299987793
220437021,5693,mjsax,2018-09-26T06:18:42Z,"i tend to think, that we don't need this guard because a bug that gives multi-threaded access seems to be very unlikely. but it's a personal opinion... my concern again is because this is the hot code path. but i am also ok to keep the check if somebody insists.",-1,0.6047452092170715
220437726,5693,mjsax,2018-09-26T06:22:08Z,"ack. see your point that `delegate` does the check for us. i was aware that it would imply incorrect api usage (ie, wrong call order or similar). just wanted to make sure we catch a bug like this -- but seems it would crash anyway even if we don't add a check for `null`.",0,0.8957805037498474
220585715,5693,vvcephei,2018-09-26T14:26:29Z,"ok, i think the in-`process` approach sounds simple and low-overhead, so i'll do that for starters, and we'll see what we think.",0,0.9794744253158569
220586765,5693,vvcephei,2018-09-26T14:28:52Z,"this is very true: i won't do anything with it right now, but wait for more input (and take care of the other things we discussed)",0,0.7434523701667786
220587434,5693,vvcephei,2018-09-26T14:30:28Z,i also think it's unlikely to be useful. i'll remove it.,0,0.7409448027610779
220675913,5693,bbejeck,2018-09-26T18:32:37Z,i also agree with the semantics for enforcing the time limit.,0,0.9820610284805298
220687788,5693,vvcephei,2018-09-26T19:08:12Z,"ok, i just confirmed that `treemap#entryset().iterator().next()` can never return `null`, but we could theoretically store a null value in the map, which could still throw an npe on this line. i'll guarded against it.",0,0.9854561686515808
220689349,5693,bbejeck,2018-09-26T19:13:22Z,"while i also agree with the trade-offs mentioned by , we can't say exactly what the better approach will be without testing. to me, the bigger savings potential would be in cpu but again we can't say without testing. but we do need to serialize for sending to the changelog, and even if we only send on `flush` and couple that with the fact that a `byte[]` coming in does not always get deserialized due to updates by key. so i'm starting to think to go with either approach will be a wash. so, for now, i'm leaning towards storing `byte[]` 1. that's what we currently use for `ktable`, while that by itself is not enough of a reason, imho we need to be careful about having different approaches for similar issues without a clear, demonstratable reason for doing so. 2. benchmarking will really give us the answers we are looking for, but time is something we don't have right now for getting this into 2.1 3. i could be wrong about this but i think the biggest users of suppression are going to have several updates per key, so as mentions, many of the `byte[] arrays` are going get overwritten.",0,0.5864543914794922
220695412,5693,bbejeck,2018-09-26T19:33:58Z,left over debugging?,0,0.9764361381530762
220695672,5693,bbejeck,2018-09-26T19:34:51Z,+1 for a sub-class of `streamexception`,0,0.92836993932724
220701301,5693,bbejeck,2018-09-26T19:54:12Z,i think doing it in `process` is a good start as well.,1,0.8324189782142639
220703951,5693,vvcephei,2018-09-26T20:02:12Z,"yeah, i noticed it late. it's gone now.",0,0.8624656200408936
220707349,5693,vvcephei,2018-09-26T20:13:40Z,"ok, it sounds like no one has a super strong performance intuition. i think 's point about uniformity is a good one. if anyone wants to insist on this, i'll change it right now. otherwise, if we're all comfortable making a performance-based decision, i think i'll propose to implement change-logging first and then do a comparative benchmark to make the final call.",0,0.5373110771179199
220777672,5693,vvcephei,2018-09-27T02:29:33Z,"i've been mulling this over... it seems like byte arrays is the more normal choice in the code base, so it should be the default until proven otherwise by a performance test. the fact that i made the opposite choice in development is irrelevant. so i'll go ahead and swap it out for byte arrays tomorrow.",0,0.9208386540412903
220953221,5693,bbejeck,2018-09-27T14:44:59Z,can we add two cases to `ktablesuppressprocessortest` to hit this branch? one for the `emit` case and another for the `shut_down`,0,0.9894962906837463
220954471,5693,bbejeck,2018-09-27T14:48:13Z,"we could use a test to hit this branch as well, but imho it's a lower priority than the others mentioned above.",0,0.9780819416046143
220989558,5693,vvcephei,2018-09-27T16:21:32Z,"this line is actually gone now. but if it were still there, i'd agree with you.",0,0.9747816324234009
221031086,5693,bbejeck,2018-09-27T18:31:04Z,"nit: this can be simplified to: `testutils.waitforcondition(() -> driver.state() == kafkastreams.state.error, timeout_ms, ""streams didn't shutdown in error state"");`",0,0.9873239994049072
221046943,5693,vvcephei,2018-09-27T19:21:55Z,"ah, right. i looked for something like that, but i was looking in `integrationtestutils`. thanks.",1,0.9369903802871704
221048082,5693,vvcephei,2018-09-27T19:26:00Z,"ok, i've updated it.",0,0.9838953614234924
221336195,5693,guozhangwang,2018-09-28T18:04:25Z,"could we merge #5521 (i think it is in pretty good shape) and rebase this pr on that? i felt a couple of the changes blew are a bit redundant, e.g. passing in the materializedinternal object as well as its serde fields.",0,0.9702425003051758
221346202,5693,guozhangwang,2018-09-28T18:41:04Z,"could we move this function to a single class, e.g. `windowedserdes` to avoid duplicates (we have the same function in `sessionwindowedkstreamimpl.java`). btw in #5521 i just inlined each call, but i think extracting it is also fine.",0,0.9608703851699829
221346600,5693,guozhangwang,2018-09-28T18:42:16Z,"why only passing the windows object (for its length) here, but not in other callers below?",0,0.9710813760757446
221347082,5693,guozhangwang,2018-09-28T18:44:00Z,this reminds me of the `lrucacheentry` class used for caching.. could we consolidate these two?,0,0.933363676071167
221348235,5693,guozhangwang,2018-09-28T18:48:15Z,"can we just use `org.apache.kafka.streams.processor.internals.stamped`? they seem very similar (feel free to rename the class if you like other names better: since it is internal classes, we can change it whenever we want.)",0,0.895276665687561
221350777,5693,guozhangwang,2018-09-28T18:57:17Z,do we assume we will only remove the head of the iterator? if not i'm not clear why we can simply set the mintimestamp as the next key's timestamp.,0,0.9791985750198364
221351979,5693,guozhangwang,2018-09-28T19:01:31Z,edit: it seems the above assumption is true from the other classes. in this case could we guard against the unexpected case if there are un-deleted entries before the current position?,0,0.9871290922164917
221352155,5693,guozhangwang,2018-09-28T19:02:14Z,nit: i'd suggest putting the size calculation of `contextualrecord` inside the `contextualrecord` class instead of in this class.,0,0.9868885278701782
221376160,5693,guozhangwang,2018-09-28T20:42:21Z,do we ever expect the passed in not-null valueserde is a `fullchangeserde` already? if not we should wrap it with `fullchangeserde` still.,0,0.9869322180747986
221377817,5693,guozhangwang,2018-09-28T20:49:51Z,"we've encountered some issues related to the ordering of this before: [a link] could you read that ticket and double check if flush-first-remove-later would not cause any issues for re-entrant puts on the same buffer (say, if we have a loop in the topology)?",0,0.9821080565452576
221378172,5693,guozhangwang,2018-09-28T20:51:25Z,"should we clear the buffer upon closing? maybe it does not make a difference on correctness, but would it worthy for performance?",0,0.9759523272514343
221380146,5693,vvcephei,2018-09-28T21:00:17Z,"the one in sessionwindowedkstreamimpl is actually different (wraps it with a sessionwindowedserde). fwiw, i think inlining it is actually preferable to extracting it to a ""common"" location if it's actually just going to have one use.",0,0.9849387407302856
221380482,5693,vvcephei,2018-09-28T21:01:45Z,this was an oversight. thanks for the catch!,1,0.9744060635566711
221381920,5693,vvcephei,2018-09-28T21:08:17Z,"it is similar, but the lrucacheentry tracks `isdirty` that would be confusing in this context, so i wouldn't use lrucacheentry here, but we could go the other way and make lrucacheentry wrap contextualrecord instead of storing the value + context itself. let me know if this sounds good to you... i'll go ahead and optimistically code it up.",0,0.5670344829559326
221382215,5693,vvcephei,2018-09-28T21:10:01Z,"yeah, this sounds good.",1,0.8345418572425842
221384089,5693,vvcephei,2018-09-28T21:19:35Z,"hmm. actually, stamped has unusual implementations of equals, hashcode, and compareto. they all disregard the stamped value and are only determined by the timestamp... so, stamped won't provide the semantics we need from timekey, and i'm afraid to change the equals/hashcode/compareto of stamped and messing up _its_ semantics... wdyt?",-1,0.8614643216133118
221384963,5693,vvcephei,2018-09-28T21:24:08Z,"aaah, yes. this min-timestamp update does depend on always removing the head of the iterator. i'll fix it. thanks.",1,0.9629116654396057
221386195,5693,vvcephei,2018-09-28T21:31:16Z,"this computation makes use of the fact that this reference is a `contextualrecord `, the value type is generic in contextualrecord. of course, this is the only usage of that class, so, i could just build the `byte[]` value type into contextualrecord. but i'm slightly in favor of keeping it as-is so we can use contextualrecord in other contexts where we need both the value (not serialized) and the context in the future. wdyt?",0,0.9757324457168579
221387849,5693,vvcephei,2018-09-28T21:39:38Z,"this would mean that they have configured the `default.value.serde` as a fullchangeserde, which is in the `internals` package. nevertheless, it doesn't hurt to guard it. will do.",0,0.9601290225982666
221389162,5693,guozhangwang,2018-09-28T21:46:57Z,"i meant to have `contextualrecord` contains its only computesize() function which caluclates the size of bytes ""except"" the value size, which can then be called by this function, and here we only need to calculate the key size and value size plus whatever returned from `contextualrecord#computesize`. anyways, it is a nit comment and i do not feel strong about it.",-1,0.9712163209915161
221389407,5693,guozhangwang,2018-09-28T21:48:17Z,"yeah i point is that is seems ""impossible"" that the passed in serde will be a `fullchangeserde` but just the inner serde used for `fullchangeserde`, so we should always wrap (either the default one from config, or the inherited one) with the `fullchangeserde`, right?",0,0.9440735578536987
221390374,5693,guozhangwang,2018-09-28T21:54:10Z,"do we need to require value ordering for `timekey` here? i thought it is not required as they are not following offset ordering to break ties anyways, right?",0,0.9827431440353394
221390459,5693,guozhangwang,2018-09-28T21:54:38Z,`make lrucacheentry wrap contextualrecord` yeah that sounds good.,1,0.5046948194503784
221390529,5693,guozhangwang,2018-09-28T21:55:07Z,ack.,0,0.7720441818237305
221391967,5693,vvcephei,2018-09-28T22:03:46Z,"interesting! that issue seems to be cache-specific: that two subsequent processors can be backed by the same cache (as in the join case). i don't think loops are generally allowed in the subtopology, are they? if so, this code would indeed result in an infinite loop or possibly a concurrent modification exception. i was concerned that the remove might be sent to the buffer's changelog record collector and maybe sent to the broker, and then some exception might happen before the forward, resulting in the record being forgotten upon restart. i looked at some other processors, and they tend to do (logged) store operations first and then forward last. but then again, normal operations are forwarding a value that's a direct consequence of processing the _current_ record, which wouldn't have been committed and would therefore get re-processed upon restart. but the buffer is forwarding some older record, which has already been committed. reprocessing the new record (which caused the eviction the first time) won't cause us to remember the old record, which we were supposed to emit. under eos, if we crash after the changelog update but before the forward, we'll be fine because the changelog update won't be visible (it'll be in an aborted transaction) on restart, so the buffer will go back to it's correct starting point for reprocessing the new record. if we can't be sure that streams subtopologies are acyclic, then i reckon we'd better swap these two lines and tell people they'd better use eos if they want to be protected from all crash corruption (which i think is true anyway). otherwise, if subtopologies are acyclic, then i think it's better to leave it as is. wdyt?",1,0.5915576219558716
221392110,5693,vvcephei,2018-09-28T22:04:40Z,"yeah, i wasn't sure. i'll go ahead and do it.",0,0.8885203003883362
221392505,5693,vvcephei,2018-09-28T22:07:08Z,"actually, let's defer this to part 4, where the buffer becomes a proper store, and has its own `close()` method.",0,0.988767683506012
221393704,5693,vvcephei,2018-09-28T22:15:25Z,"i don't _think_ that will work... `comparable` requires a total ordering and also specifies that `a.compareto(b) == 0` iff `a.equals(b)`, which in turn requires that `a.hashcode() == b.hashcode()`. but this would prevent us from inserting two different keys with the same time into our buffer map. it doesn't seem like `stamped` is suitable for map keys or set entries for this reason.",0,0.9635985493659973
221405676,5693,vvcephei,2018-09-28T23:59:18Z,"ok, this is done now.",0,0.9819017052650452
221408442,5693,vvcephei,2018-09-29T00:41:29Z,"ok, i put in a guard. i also refactored the interface to purely evict the head of the buffer while a condition holds, which cleans up the usage quite a bit. let me know what you think.",0,0.9739510416984558
221408530,5693,vvcephei,2018-09-29T00:43:01Z,"since the part of the contextualrecord that isn't the value is just the processorcontext, i just added a `sizebytes()` method there. wdyt?",0,0.9894924163818359
221408651,5693,vvcephei,2018-09-29T00:45:27Z,"oh, i gotcha. the type of valueserde is already a fullchangeserde. in the case of an inherited serde, it gets wrapped in the constructor. the types ensure that the constructor arg is not already a fullchangeserde.",0,0.9635027050971985
221412551,5693,vvcephei,2018-09-29T02:23:50Z,"yes, i think that's a good plan. i agree on the reduncancy, but i wanted to keep the serde-related perturbations to a minimum so we wouldn't distract from the pr.",1,0.5095725655555725
221478048,5693,mjsax,2018-09-30T23:44:40Z,just reviewed #5521 again -- left some more comments.,0,0.979431688785553
221478098,5693,mjsax,2018-09-30T23:47:24Z,"i actually think that forward before delete is correct. compare: [a link] and the corresponding pr, that we never finished.",0,0.9883632063865662
221492758,5693,mjsax,2018-10-01T04:15:54Z,nit: `castorwrap`,0,0.9820246696472168
221492805,5693,mjsax,2018-10-01T04:16:41Z,why this change? (just for my own education.),-1,0.5604653358459473
221493048,5693,mjsax,2018-10-01T04:19:29Z,could we extend `wraporcast` to add a `null` check and return `null` for this case and use it here to make code more readable?,0,0.9895585775375366
221493375,5693,mjsax,2018-10-01T04:24:31Z,"i think we need to call `put` only if `previouskey == null`? ie, we could merge l103 ad l105 into an if-then block? might be more readable?",0,0.9892648458480835
221493496,5693,mjsax,2018-10-01T04:26:03Z,"this check for `previouskey == null` could be merged with the check from above? (it's hot code path, so might be worth to unify.)",0,0.9859397411346436
221493640,5693,mjsax,2018-10-01T04:28:03Z,different thought: why do we need to call `remove` above explicitly? `put` would return the old/replace value anyway if there is any -- would avoid one tree-traversal?,0,0.9753705263137817
221493984,5693,mjsax,2018-10-01T04:32:40Z,"i don't see the advantage of using generics in `contextualrecord` is it's only used once with `byte[]` types. as generic types are lost after compilation, i would prefer to remove the generic if not needed (afaik, generics have some runtime overhead as the compiler needs to insert casts that are evaluate during runtime.)",0,0.9757053256034851
221494361,5693,mjsax,2018-10-01T04:38:14Z,"this value should only be `0` or `1` -- maybe use a boolean instead? also wondering, if we need this at all? have the gut feeling, that `last != null` and `nextcount != 0` is the same thing?",-1,0.9540672898292542
221494851,5693,mjsax,2018-10-01T04:45:43Z,"if `next()` is called twice in a row without `remove()` in between, `nextcount` could be larger than 1 and thus we should throw -- seems that the current code enforces a `next-remove-next-remove...` pattern? if yes, why?",0,0.9824718832969666
221494894,5693,mjsax,2018-10-01T04:46:12Z,should this be set to `1` instead of incrementing?,0,0.9856969118118286
221495017,5693,mjsax,2018-10-01T04:48:07Z,"see my other comments -- it's still unclear from the code that we want to enforce `next-remove-...` pattern -- might also be worth to add a javadoc to the iterator about correct usage, even if it's an internal class only.",0,0.9882071614265442
221496039,5693,mjsax,2018-10-01T05:02:37Z,"i am wondering, if `suppressdurationmillis` is a valid config? i had problem to understand this part in the original pr already. can you explain once more? (maybe it's an indicator that we should add a comment explaining the cases we are handling here?)",0,0.765916645526886
221496235,5693,mjsax,2018-10-01T05:05:34Z,`and` -> `or` or `and/or` ?,0,0.9867666363716125
221496719,5693,mjsax,2018-10-01T05:11:06Z,"should we inline this method? also, i am wondering if we could/should call this unconditionally? if `overcapacity()` is true, we might or might not expire records here (same if called unconditionally). if `overcapacity()` is false, but `buffer.mintimestamp() <= expirytime` is true, we would expire record (same if called unconditionally). if both are false, `drainexpriredrecords()` would not expire anything if called either, because it passed in the corresponding boolean predicate anyway? ie, i _think_ we can just remove the `if` condition and execute the `then` part always",0,0.9790984392166138
221496860,5693,mjsax,2018-10-01T05:13:00Z,nit: `next` -> `evictedrecord` or just `record` ?,0,0.9890381097793579
221497240,5693,mjsax,2018-10-01T05:17:31Z,nit: `deserializedkey` -> `key` and `key` -> `rawkey` ?,0,0.9901570081710815
221497342,5693,mjsax,2018-10-01T05:18:50Z,should we cast here and keep `bufferconfig bufferconfig` as member type?,0,0.988149106502533
221497656,5693,mjsax,2018-10-01T05:22:47Z,"while i think, it's semantically fine, it might be nice to get the same eviction behavior for a reprocessing use-case... i am also realizing, that `timekey` is actually always used with `bytes` -- thus, i would recommend to remove the generic type, and exploit that `bytes` implements `comparable` already.",0,0.906431257724762
221498033,5693,mjsax,2018-10-01T05:27:24Z,"`key` is always `bytes()`, thus, this output is not very useful. can we can hold on the deserialized for human readable output here?",0,0.918117880821228
221498255,5693,mjsax,2018-10-01T05:30:19Z,"each java object has a natural overhead -- might be worth to add this here? would need to search the internet how many bytes, however, we would have it for `processorrecordcontext` itself, as well as `topic`, `headers` (including it's nested `header` objects).",0,0.9889272451400757
221498409,5693,mjsax,2018-10-01T05:32:06Z,"a `string` also store the length (it's a `char[]` internally) -- should we add 4 more bytes here? also, has a `char[]` similar overhead than a regular object?",0,0.9888385534286499
221498827,5693,mjsax,2018-10-01T05:36:55Z,`value` is always `byte[]` -- can we get a handle on the deserializer to get human readable output here? (one more reason to avoid generic if not necessary -- those issues slip easily with missing type information).,0,0.9844028949737549
221498993,5693,mjsax,2018-10-01T05:39:01Z,"should we add 4 byte to store array size? also, do we have object overhead for an array type?",0,0.9888920187950134
221499058,5693,mjsax,2018-10-01T05:39:49Z,should we add object overhead for `context` itself? (might be included in `sizebytes()` if we update is accordingly thought),0,0.9894886612892151
221640642,5693,vvcephei,2018-10-01T14:55:34Z,"it's just evidence of my mental slowness... in the prior pr, guozhang pointed out that my calling `buffer.array()` was incorrect, since the backing array isn't guaranteed to be exactly within the bounds we allocated. i fixed it at the time by delegating to the `bytebufferserializer`, which handles this. later on i realized that there is a more efficient solution available. by pre-creating the backing array and wrapping it, we know that `buffer.array()` returns what we needed. no need for the more general handling logic in `bytebufferserializer`.",0,0.6775254607200623
221640973,5693,vvcephei,2018-10-01T14:56:22Z,i can and will.,0,0.9535917043685913
221642753,5693,vvcephei,2018-10-01T15:00:59Z,"i've added that check because `context.valueserde()` (called elsewhere) could return null. if it's ok with you, though, i prefer the current code right here. this code ensures that `valserde` is of the correct type (notice that no casting is necessary). in general, i think we should avoid casting unless we actually need it, as it makes regressions harder to catch.",0,0.974911093711853
221646019,5693,vvcephei,2018-10-01T15:09:46Z,"this is true about `put`, but we still need to choose a key to insert into `sortedmap`. if i don't declare the `nextkey` variable, i need to have a bunch of redundant code in the if and else blocks: [code block] imho, this is less readable than the linear version where we just reuse or construct the key in line 103.",0,0.9796774983406067
221646437,5693,vvcephei,2018-10-01T15:10:56Z,"but if, after looking at it, you prefer the branching version, i'll change it.",0,0.9812596440315247
221648943,5693,vvcephei,2018-10-01T15:17:41Z,"please see my comment above. i agree it's more efficient to have just one branch, but i do think this version is easier to follow. regardless, you have a fresher perspective. if you prefer the branching version above, i'm happy to change it.",1,0.9477396011352539
221650193,5693,vvcephei,2018-10-01T15:21:04Z,"ok, apparently the way to convince me is to point out three reasons... i'll switch it out for the branching version.",0,0.9581342339515686
221655192,5693,vvcephei,2018-10-01T15:34:50Z,i didn't consider this runtime overhead. i'll go ahead and inline the generic type.,0,0.9739149212837219
221655988,5693,vvcephei,2018-10-01T15:37:06Z,"it is ok to call next multiple times, but if you do, you can't subsequently call remove. i don't think that we can learn whether next has been called twice by looking at any of the other fields we're maintaining.",0,0.9829193353652954
221661624,5693,vvcephei,2018-10-01T15:52:56Z,"yes. this is an optimization to support maximal efficiency in: * removing some unknown number records, each of which is currently the minimum in the buffer when it gets removed * maintaining a correct value of `mintimestamp`. as far as we know right now, we will only ever need to remove the min records from the buffer. i.e., i don't think we need to iterate for a while and *then* remove. but we may need to remove more than one record, and we won't know if we need to remove the *next* record until after we remove *this* record. previously, i didn't have this guard, but in that case, we can't just set `mintimestamp` to the buffer time of the next record upon removing. because we don't know whether the record we just removed is the leftmost record in the tree without traversing it again. because of that, i had to avoid updating `mintimestamp` until you close the iterator (and therefore it had to be a `closeableiterator`). this means that the ktablesuppressprocessor couldn't just keep popping records while the mintimestamp was less than the desired boundary, it had to get the ""buffer time"" from the timekey and make its decision from that. all in all, it's way cleaner this way, with the expense of that one extra guard. i could go one step further and make it like a ""predicated, consuming iterator"", which just pops records out as long as the predicate condition is true. do you think this would be more straightforward?",0,0.9365910887718201
221661740,5693,vvcephei,2018-10-01T15:53:15Z,no; see the reply above.,0,0.9771484136581421
221662088,5693,vvcephei,2018-10-01T15:54:14Z,"from your later comments, it seems like you would say it would be more straightforward. i'll go ahead and simplify it.",0,0.9697738885879517
221667743,5693,vvcephei,2018-10-01T16:11:01Z,i think the complexity is due to my over-flexible time definition. i'll drop it and then we'll see if it's still non-obvious what's going on here.,0,0.9427903294563293
221690047,5693,mjsax,2018-10-01T17:22:54Z,i guess it's personal taste -- don't insist on a change.,0,0.9181609153747559
221690536,5693,mjsax,2018-10-01T17:24:31Z,"think, even without the branching, this `remove` and the `put` below should be merged.",0,0.9846748113632202
221690691,5693,vvcephei,2018-10-01T17:25:03Z,"ok, i've decided that this optimization is premature and complex, so i've gone ahead and simplified it. (i'll let you know when i push the update). i've also updated the timedefinition class to be less flexible (although it doesn't really simplify this particular method). fwiw, though i think that ""suppress for 0ms"" is a perfectly valid way to disable a suppression operation. note that this is also what we wind up with when you use final-results on a windowed stream with graceperiod set to 0ms, which also seems perfectly fine.",0,0.818862795829773
221691013,5693,vvcephei,2018-10-01T17:26:10Z,i added the missing punctuation instead.,0,0.9807097911834717
221691019,5693,mjsax,2018-10-01T17:26:11Z,this breaks the iterator contract and should be well documented,0,0.9862050414085388
221692098,5693,vvcephei,2018-10-01T17:29:27Z,"i wanted to save on setting up the iterator, but your comment made me realize we can and should do that with an initial `if (predicate.get())` inside `evictwhile`. i did this and removed the condition as you recommended.",0,0.9770936369895935
221692337,5693,vvcephei,2018-10-01T17:30:09Z,good point. i called it `toemit`.,1,0.9662427306175232
221693619,5693,vvcephei,2018-10-01T17:34:29Z,"this made me realize that i named them `impl` when i meant to name them `internal`. in other words, both `suppressedinternal` and `bufferconfiginternal` to indicate that these are the internal interfaces.",0,0.9839218854904175
221694264,5693,vvcephei,2018-10-01T17:36:43Z,i didn't notice that. that is handy.,1,0.7165837287902832
221696756,5693,vvcephei,2018-10-01T17:44:39Z,"i agree that this is an under-estimate, but i don't think there's much point in being exact. the overhead is dependent on the jvm implementation, so we'd have to detect the jvm and maintain a mapping for each different implementation. even then, we don't know how much extra memory we're using in the various garbage collectors, of which there are now three different implementations in the oracle jdk alone... i'd rather just make the best effort we reasonably can to live more-or-less within the desired boundary. for example, storing the `byte[]` value is much closer than storing the object. but beyond that, we get into diminishing returns for quickly increasing complexity.",0,0.923206090927124
221697255,5693,vvcephei,2018-10-01T17:46:16Z,"i believe arrays also store their types. but again, we are getting into jvm implementation details. there are too many jvm implementations for us to be expected to worry about this, imho.",-1,0.6050102710723877
221698960,5693,vvcephei,2018-10-01T17:51:38Z,"i didn't consider this overhead, and agree it would be good to get rid of it.",0,0.8900901079177856
221699155,5693,vvcephei,2018-10-01T17:52:12Z,"i don't think the record needs to know how to deserialize itself. since `tostring` is only for debugging, i'm fine printing out the `arrays.tostring` summary of the value. if we wanted to print out the value in a log message, we would format it more specifically (including a deserialization if desired). that said, i will go ahead and get rid of the generic type.",0,0.9726158976554871
221701912,5693,vvcephei,2018-10-01T18:00:46Z,as above.,0,0.978552520275116
221702092,5693,vvcephei,2018-10-01T18:01:16Z,"it would be the responsibility of the context to account for its own overhead, but see my comments above.",0,0.9819220304489136
221756263,5693,vvcephei,2018-10-01T21:04:23Z,"roger that. it's moot now, since i've removed this iterator entirely.",0,0.9796419143676758
221757521,5693,vvcephei,2018-10-01T21:09:03Z,"i think in sum, your points elevate it beyond personal taste. i've gone ahead and done the branching. after a little cleanup, it's not too shabby anyway.",0,0.8743645548820496
221792731,5693,vvcephei,2018-10-02T00:01:39Z,"i had to add these so that suppress doesn't ""forget"" the window end time when it round-trips the record.",0,0.9820566177368164
221793798,5693,mjsax,2018-10-02T00:08:26Z,ack. that's fair. the existing caches also use rough estimates only. (might be interesting how much we are off though... but this could be a follow up improvement.),0,0.8744120597839355
221794070,5693,mjsax,2018-10-02T00:10:24Z,"my point is, that even for debugging it's not useful to print `byte[]` -- my argument is, to either ""fix this"" or don't overwrite `tostring()` at all.",0,0.9292026162147522
221794878,5693,mjsax,2018-10-02T00:16:14Z,is this mentioned in the kip? it's a public api change.,0,0.9882394075393677
221795634,5693,mjsax,2018-10-02T00:21:39Z,not sure if this is the best way to tack it? requires public api change.,0,0.8982594609260559
221796847,5693,mjsax,2018-10-02T00:29:57Z,i guess we can remove this generics?,0,0.9880446791648865
221797359,5693,mjsax,2018-10-02T00:33:39Z,`nextkey.time()` -> `time`,0,0.9843580722808838
221797795,5693,mjsax,2018-10-02T00:37:11Z,"should we compute `buffertime` within `buffer()` -- no need to pass it in, as both `internalprocessorcontext` and `key` are available there, too?",0,0.9896049499511719
221797893,5693,mjsax,2018-10-02T00:38:08Z,so we need this here? no need to pass it into `enforceconstraints()` imho.,0,0.9868009090423584
221798063,5693,mjsax,2018-10-02T00:39:28Z,should this be `<` instead of `<=` ?,0,0.9856122732162476
221798280,5693,mjsax,2018-10-02T00:41:14Z,guess we can remove variable `key` (only used once).,0,0.9878625869750977
221798347,5693,mjsax,2018-10-02T00:41:45Z,`key1` -> `key` and `key.get()` -> `toemit.key.get()`,0,0.9846056699752808
221798908,5693,mjsax,2018-10-02T00:46:05Z,"similar argument as for `byte[]` value: of course, here we still get the `time` information, but the `bytes` `key` is useless.",0,0.9689973592758179
221800768,5693,mjsax,2018-10-02T01:00:20Z,why remove this comment? seems to be valid?,0,0.9567232728004456
221800971,5693,mjsax,2018-10-02T01:01:37Z,"the change makes sense -- test was bubby before, but we did not notice at it threw anyway?",0,0.9233496785163879
221801525,5693,mjsax,2018-10-02T01:06:01Z,what was the original intend of this part? and why don't we need it?,0,0.9779737591743469
221802094,5693,mjsax,2018-10-02T01:10:39Z,why `timestamp - 1l` ?,0,0.9802761077880859
221805529,5693,vvcephei,2018-10-02T01:38:54Z,"ah, no. when i did this before, i did it differently to keep it private. i thought this was a better way, but overlooked the public-ness of it. i'll go back to private mode.",0,0.8863853216171265
221805956,5693,vvcephei,2018-10-02T01:43:11Z,"ah, yeah, it was previously used also here, but it's not needed anymore. good catch.",1,0.9823001027107239
221805975,5693,vvcephei,2018-10-02T01:43:21Z,same here. thanks!,1,0.951789140701294
221806806,5693,vvcephei,2018-10-02T01:49:57Z,"it wouldn't be wrong, but i think `<=` is also right, and it's a tighter bound. let's say we have buffered an event with time 10 at stream time 10 and the suppressduration is 1. the expiry time is `10-1 = 9`. mintimestamp is 10, and `10 <= 9` is false, so we don't evict. then, we get an event with time 11 at stream time 11. now, the expiry time is `11-1=10`. mintimestamp is still 10, but now the check is `10 <= 10`, so we evict that first event. i think this matches up to the intention of saying ""suppress for 1 ms"".",0,0.9716947674751282
221807188,5693,vvcephei,2018-10-02T01:52:48Z,"it's not anymore. now, we buffer the new event before we enforce the buffer constraints, so we return the more intuitive most recent state of `""v1"", 1l, 2l` right away, instead of later on.",0,0.9854692816734314
221808272,5693,vvcephei,2018-10-02T02:01:52Z,"we didn't throw it away before, just emitted it later on. this is what the comment i removed was explaining.",0,0.9643370509147644
221808394,5693,vvcephei,2018-10-02T02:02:54Z,"when we enforced constraints before buffering, we needed one extra tick to flush everything out. now that we buffer first, everything happens more promptly, so we don't need this last cycle to witness all the results we're looking for.",0,0.9704222083091736
221808532,5693,vvcephei,2018-10-02T02:04:09Z,"it doesn't matter for anything, it just seemed weird to have window start == window end. the window end is the time that matters for this test, which is why i made it the baseline.",-1,0.952009916305542
221811667,5693,mjsax,2018-10-02T02:34:28Z,ack,0,0.9720376133918762
221812576,5693,mjsax,2018-10-02T02:44:07Z,"we set record timestamp to `timestamp` -- thus, the record will be put in window `[timestamp, timestamp+1)`, right? seems weird to use the wrong window imho. or do i miss something?",-1,0.9747410416603088
221813111,5693,vvcephei,2018-10-02T02:49:17Z,"ok, i wasn't thinking about it like this. it makes sense.",0,0.7802359461784363
221813409,5693,mjsax,2018-10-02T02:52:09Z,i see. the comment focus on the second `v1` -- i applied it to the third `v1`. seems the comment was ambiguous :),1,0.48843270540237427
221813838,5693,vvcephei,2018-10-02T02:56:43Z,good thing it's gone!,1,0.9836174249649048
221821211,5693,guozhangwang,2018-10-02T04:13:10Z,makes sense.,0,0.9637326002120972
231290134,5821,lindong28,2018-11-06T20:58:29Z,exception and its corresponding error code is part of public interface. can you update design doc as appropriate and reply to the email thread with this change?,0,0.9880684018135071
231292242,5821,lindong28,2018-11-06T21:05:09Z,"currently all epoch fields (e.g. controller epoch, leader epoch) uses int32. would it be more consistent and space efficient to use int32 for broker epoch as well? max int32 value is more than 2 billion which seems large enough for broker epoch. if we change the type of broker epoch from int64 to int32, can you also update the design doc and reply to the email thread?",0,0.9863583445549011
231294160,5821,lindong28,2018-11-06T21:11:32Z,"since we are modifying the schema here, it may be a good time to use the new way of specification as shown in fetchrequest for consistency. then we can use `struct.getorelse(...)` here. it is specifically preferred to make this refactor together with the change in this pr if the existing code footprint is small (e.g. `stopreplicarequest.java`).",0,0.9808706641197205
231294372,5821,lindong28,2018-11-06T21:12:14Z,nits: can you add an empty line between these two methods?,0,0.9882901906967163
231300243,5821,lindong28,2018-11-06T21:30:41Z,nits: it seems a bit more consistent with the existing style (e.g. `produce_response_v4 = produce_response_v3` in produceresponse.java) to do `leader_and_isr_response_v2 = leader_and_isr_response_v1`. it is probably more readable as well since we typically want to see how the new schema compares with the previous version.,0,0.9756389260292053
231304928,5821,lindong28,2018-11-06T21:45:58Z,"nits: for consistency with the exiting style, can we use `update_metadata_response_v5 = update_metadata_response_v4`?",0,0.9901061654090881
231306661,5821,lindong28,2018-11-06T21:51:11Z,"it seems that even if we do this filter, the broker may still go offline after this step and before controller sends the request to the broker. so we still need to have this filter logic later. could you explain the benefit of having this logic here?",0,0.9816624522209167
231319305,5821,lindong28,2018-11-06T22:33:29Z,would this be more consistent and readable to move this logic to the class `controlledshutdown`? this can also ensure that the `brokerepochscache` is accessed only by the controller event thread after controller is initialized.,0,0.9888189435005188
231323345,5821,lindong28,2018-11-06T22:48:40Z,nits: there is one extra space after `=`,0,0.9835278987884521
231329438,5821,lindong28,2018-11-06T23:13:47Z,"currently `brokerepoch` is a `var` and its internal state is also immutable. it is generally preferred to allow mutation in only one way. since `brokerepoch` has its initial value from `kafkaserver.startup()` and it can be updated multiple times in `registerbrokerandreelect`, would it make sense to define ` var brokerepoch: int` in `kafkacontroller` similar to the existing `brokerinfo` field. `kafkaserver.startup()` can get the initial value of the broker epoch as integer and passes it to the `kafkacontroller` constructor as `initialbrokerepoch`. this approach seems much simpler and we would not need the helper class `brokerepoch`.",0,0.9847027659416199
231332131,5821,lindong28,2018-11-06T23:26:01Z,"i am wondering if it will be more intuitive and cleaner to move the logic of checking broker epoch from replicamanager to kafkaapis. currently there is already logic such as `controller.isactive` in kafkaapis which is similar to the logic of checking broker epoch. and if we do that, we can keep replicamanager unchanged. kafkaapis can first compare the epoch from the stoprepliarequest with the epoch in `controller.brokerepoch` before invoking e.g. `replicamanager.stopreplicas(...)`. controller can have api such as `controller.isactivebrokerepoch(epoch)` to make the logic more explicit.",0,0.9543166160583496
231339976,5821,lindong28,2018-11-07T00:02:54Z,"nits: `zookeepr` has typo. would the message `s""$request does not need controller epoch check""` be more appropriate here?",0,0.9884719848632812
231343743,5821,lindong28,2018-11-07T00:23:49Z,"now we have three methods named `retryrequestsuntilconnected(...)`. i am wondering if it would be more readable to keep the number still as two, one for single request and the other for sequence of requests. one thing that may be confusing to the reader is that, `retryrequestsuntilconnected[req <: asyncrequest](requests: seq[req])` does not take `expectedcontrollerzkversion` as parameter and thus it is not clear what is the expected behavior with controller epoch check in this method.",0,0.9010185599327087
231344408,5821,lindong28,2018-11-07T00:27:31Z,"can we also throw `illegalstateexception` if `zkopresults` does not match the pattern `seq(zkopresult(checkop: checkop, checkopresult), zkopresult)`?",0,0.9878519773483276
231348543,5821,lindong28,2018-11-07T00:50:29Z,"now the patch is not longer using zookeeper transaction, will there be issue if e.g. controller znode is created but the controller epoch is not incremented?",0,0.9880913496017456
231352782,5821,hzxa21,2018-11-07T01:14:05Z,the reason why we use int64 for broker epoch is that the `czxid` we get back from zookeeper is of int64 type. i think it is not a good idea to convert it into int32 because we may lose the globally unique and monotonically increasing guarantee.,0,0.7892067432403564
231365666,5821,hzxa21,2018-11-07T02:45:38Z,"after introducing broker epoch, we need to fill in the broker epoch we want to use for the control request we send out. only brokers in `controllercontext.liveorshuttingdownbrokerids` will have a entry in the `controllercontext.brokerepochscache`. the benefit of this change is to ensure that we can always get back the broker epoch from the cache in controller context when constructing the control requests. we can instead add extra logic in `controllerchannelmanager.sendrequeststobrokers` to check the existence of the broker epoch when constructing the request but i think it is cleaner and easier to reason about the code with this change because we will not send out requests to brokers that are not in `controllercontext.liveorshuttingdownbrokerids` anyway. it is true that the broker can become offline and this will cause requestsendthread to fail to send out the request if controller doesn't process the broker change event before requestsendthread sending out the request to the offline broker. this change will not affect this behavior and does not aim to solve this race condition. this change only acts as a pre-filter to ensure we can always construct the control request with broker epoch. whether we can actually send out the request is a separate issue.",0,0.9698398113250732
231397289,5821,lindong28,2018-11-07T06:58:52Z,"sounds good. i am not sure when brokerid in the `brokerids` will be negative. since we don't expect any brokerid in `liveorshuttingdownbrokerids` to be negative, can we just do `brokerids.filter(controllercontext.liveorshuttingdownbrokerids.contains)` to simplify the code here? same for `addstopreplicarequestforbrokers()` and `addupdatemetadatarequestforbrokers()`.",1,0.9291566014289856
231397355,5821,lindong28,2018-11-07T06:59:11Z,yeah i forgot this reason. sounds good.,1,0.942468523979187
231609250,5821,hzxa21,2018-11-07T17:47:41Z,that is a good point. i think we can simplify it.,1,0.9621770977973938
231624498,5821,hzxa21,2018-11-07T18:28:48Z,thanks for the suggestion. it makes sense and i will move it.,1,0.9378782510757446
231629225,5821,hzxa21,2018-11-07T18:42:53Z,"currently `brokerepoch` can be updated in `kafkaserver.startup()` as well as `registerbrokerandreelect` in the controller, and it can be read by `replicamanager` in order to reject outdated control requests. if we store `brokerepoch` in `kafkacontroller`, it requires passing the `kafkacontroller` object to `replicamanager` just for reading `brokerepoch`. i think use a helper class is simpler in this case. what do you think?",0,0.9846926927566528
231629808,5821,hzxa21,2018-11-07T18:44:39Z,"miss your next comment. if we do the check in `kafkaapis`, then you are right. please ignore the comment i just wrote down.",-1,0.7151103615760803
231629969,5821,hzxa21,2018-11-07T18:45:06Z,makes sense. that is a good point.,1,0.9547039866447449
231713300,5821,hzxa21,2018-11-07T23:09:38Z,"i am a little bit confused about your concern. there is no controller epoch check in `retryrequestsuntilconnected[req <: asyncrequest](requests: seq[req])` because this is the raw method that only does send requests as well as receive responses, and the epoch check happens outside of this method when calling `wraprequestwithcontrollerepochcheck` and `unwrapresponsewithcontrollerepochcheck`. maybe i understand you wrong, i think there is little confusion here. do you suggest only have `retryrequestsuntilconnected[req <: asyncrequest](requests: seq[req], expectedcontrollerepochzkversion: int)` and `retryrequestsuntilconnected[req <: asyncrequest](request: req, expectedcontrollerepochzkversion: int)`?",-1,0.8213632702827454
231724344,5821,hzxa21,2018-11-08T00:02:31Z,it is fine because we are using the zookeeper multi op directly right now. it is essentially the same as using zk transaction so we still provide the same guarantee.,0,0.9781672954559326
232446499,5821,hzxa21,2018-11-10T08:53:01Z,done.,0,0.9759407639503479
232446521,5821,hzxa21,2018-11-10T08:54:07Z,sure. i have adopted the new pattern in all control requests.,0,0.9742344617843628
232446524,5821,hzxa21,2018-11-10T08:54:13Z,fixed.,0,0.9810503125190735
232446526,5821,hzxa21,2018-11-10T08:54:17Z,fixed.,0,0.9810503125190735
232446530,5821,hzxa21,2018-11-10T08:54:22Z,fixed.,0,0.9810503125190735
232446539,5821,hzxa21,2018-11-10T08:54:30Z,done.,0,0.9759407639503479
232446540,5821,hzxa21,2018-11-10T08:54:34Z,done.,0,0.9759407639503479
232446542,5821,hzxa21,2018-11-10T08:54:38Z,fixed.,0,0.9810503125190735
232446547,5821,hzxa21,2018-11-10T08:54:45Z,fixed.,0,0.9810503125190735
232446550,5821,hzxa21,2018-11-10T08:54:49Z,done.,0,0.9759407639503479
232446551,5821,hzxa21,2018-11-10T08:54:54Z,fixed.,0,0.9810503125190735
232446554,5821,hzxa21,2018-11-10T08:55:02Z,sure. done.,0,0.9161409735679626
232477712,5821,lindong28,2018-11-11T08:02:17Z,"the exception name is inconsistent with name specified in kip-380. i feel that it is better to use the `stale_controller_epoch` which suggests that the broker epoch in the request is smaller than the expected value. since we do not expect the epoch in the request to be larger than the expected value, it would be illegalstateexception if the epoch in the request is larger than the expected value.",0,0.9589065909385681
232477749,5821,lindong28,2018-11-11T08:04:01Z,nits: can we follow the existing code style and move `brokerepochmismatchexception::new` to a new line?,0,0.9893072247505188
232477941,5821,lindong28,2018-11-11T08:11:11Z,"unlike updatemetadatarequest, this field is named `live_leaders` rather than `live_brokers`.",0,0.9862005710601807
232478024,5821,lindong28,2018-11-11T08:13:45Z,nits: there is an unnecessary space.,0,0.8791595101356506
232479092,5821,lindong28,2018-11-11T08:50:14Z,nits: there is an unnecessary space.,0,0.8791595101356506
232479565,5821,lindong28,2018-11-11T09:07:05Z,"can we do `struct.setifexists(offline_replicas, offlinereplicas.toarray())` here? also, it seems that `setifexists(field.array def, object[] value)` and `setifexists(field.complexarray def, object[] value)` in `struct.java` should only set value if the field exists. can you help fix that?",0,0.9861066341400146
232479847,5821,lindong28,2018-11-11T09:15:25Z,nits: would it be simpler to just do `brokerids.filter(controllercontext.liveorshuttingdownbrokerids.contains)`? the extra variable name does not seem useful here.,0,0.9799521565437317
232480199,5821,lindong28,2018-11-11T09:25:44Z,"we currently uses `controllercontext.brokerepochscache` in `sendrequeststobrokers()` under the assumption that the `leaderandisrrequestmap`, `updatemetadatarequestpartitioninfomap` and `stopreplicarequestmap` only includes brokerid that is defined in `brokerepochscache`. however, the logic to guarantee this is in other methods such as `addupdatemetadatarequestforbrokers`. would it make the code more readable to put these logics closer together in `sendrequeststobrokers()`? we can make the logic even more explicit by filtering the brokerid using `brokerepochscache` rather than `controllercontext.liveorshuttingdownbrokerids` in `sendrequeststobrokers()`.",0,0.9852868318557739
232480419,5821,lindong28,2018-11-11T09:32:08Z,would it be more readable to have method `isbrokerepochstale`? `iscurrentorunknownbrokerepoch` is a bit verbose and it feels a bit weird to look for unknown broker epoch. `isbrokerepochstale` would better match the name of `stalebrokeepochexception`.,-1,0.8733735680580139
232480534,5821,lindong28,2018-11-11T09:34:41Z,would it be simpler to just name the method `brokerepoch`? the variable can be named `_brokerepoch` similar to `_lastcaughtuptimems` in `replica.scala`.,0,0.9899229407310486
232480834,5821,lindong28,2018-11-11T09:42:29Z,currently most variables (e.g. `livebrokersunderlying`) in `controllercontext` provide cached information. it will be a bit inconsistent and confusing if we just put the word `cache` for brokerepoch. can we just name it `brokerepochs`?,0,0.9653822779655457
232480935,5821,lindong28,2018-11-11T09:44:54Z,nits: can we rename `bid` to `brokerid`? `bid` is an english word and currently the existing code does not use `bid` as shortcut for broker id.,0,0.9894423484802246
232481318,5821,lindong28,2018-11-11T09:55:51Z,"the log message itself raises concerns for user/developer without explaining why it is at warning rather than error level. can we add comment that says why this is ok? and since we expect this to happen normally when broker is restarted quickly, i am not sure we need to log it at warning level. we can ask other reviewer to comment on this later.",0,0.9737739562988281
232481594,5821,lindong28,2018-11-11T10:04:18Z,the code can probably be more readable with less nested if/else by doing this: [code block] same for other methods.,0,0.9887661337852478
232481972,5821,lindong28,2018-11-11T10:17:56Z,"the code here is comparing the zkversion with epoch, which seems misleading. also, `expectedcontrollerzkversion < 0`, will `expectedcontrollerzkversion` be anything other than `matchanyversion`? if not, it seems better to explicitly check `expectedcontrollerzkversion == zkversion.matchanyversion`. and if they are not equal, we can throw illegalstateexception if `expectedcontrollerzkversion` is negative.",0,0.9468079805374146
232482145,5821,lindong28,2018-11-11T10:24:33Z,nits: it seems that intellij complains here. can you change it to `getsortedbrokerlist()`.,0,0.9358824491500854
232482175,5821,lindong28,2018-11-11T10:25:54Z,"do we expect `brokeridznode.decode(...).broker` to return null? if not, it may be simpler to just do `some(brokeridznode.decode(brokerid, getdataresponse.data).broker, getdataresponse.stat.getczxid)`.",0,0.9884195327758789
232482475,5821,lindong28,2018-11-11T10:36:38Z,nits: can you add space between `case class` to be consistent with the existing code style?,0,0.9903662204742432
232482769,5821,lindong28,2018-11-11T10:46:07Z,"right, that is what i would suggest to reduce the overloaded methods number from 3 to 2. now looking at it again, the current way also looks good.",1,0.5933861136436462
232516981,5821,hzxa21,2018-11-12T01:37:08Z,that is a good point. i have changed it back to `stale_broker_epoch`. i also move the broker epoch check helper function from `kafkacontroller` to `kafkaapis` and throw `illegalstateexception` when the broker sees the broker epoch in the request larger than the current epoch.,1,0.8820438981056213
232516997,5821,hzxa21,2018-11-12T01:37:19Z,sure. done.,0,0.9161409735679626
232517017,5821,hzxa21,2018-11-12T01:37:31Z,good catch. fixed.,1,0.9799823760986328
232517029,5821,hzxa21,2018-11-12T01:37:37Z,fixed.,0,0.9810503125190735
232517036,5821,hzxa21,2018-11-12T01:37:42Z,fixed.,0,0.9810503125190735
232517050,5821,hzxa21,2018-11-12T01:38:00Z,sure. fixed.,0,0.9482191205024719
232517068,5821,hzxa21,2018-11-12T01:38:20Z,yes. fixed.,0,0.9799623489379883
232517104,5821,hzxa21,2018-11-12T01:38:45Z,good suggestion. done.,1,0.9395747780799866
232517335,5821,hzxa21,2018-11-12T01:41:16Z,i have renamed it and moved this helper function to `kafkaapis` because it will only be called in `kafkaapis` and we will need to throw `illegalstateexception` when the epoch is larger than the expected one. i think it is more readable this way.,0,0.9776540398597717
232517345,5821,hzxa21,2018-11-12T01:41:21Z,fixed.,0,0.9810503125190735
232517357,5821,hzxa21,2018-11-12T01:41:28Z,sure. done.,0,0.9161409735679626
232517373,5821,hzxa21,2018-11-12T01:41:38Z,sure. done.,0,0.9161409735679626
232517606,5821,hzxa21,2018-11-12T01:44:49Z,"comments added. when the broker sees stale controller epoch in the request, we also log the message at warning level. so i think it is better to do the same thing for stale broke epoch to keep it more consistent.",0,0.9838682413101196
232517635,5821,hzxa21,2018-11-12T01:45:15Z,that is a good point. thanks for the suggestion. done.,1,0.981264591217041
232517651,5821,hzxa21,2018-11-12T01:45:23Z,"fixed. btw, i think it is better to throw `illegalargumentexception` if `expectedcontrollerzkversion` is negative.",0,0.9802842736244202
232517736,5821,hzxa21,2018-11-12T01:46:39Z,fixed.,0,0.9810503125190735
232517759,5821,hzxa21,2018-11-12T01:46:51Z,good catch. fixed.,1,0.9799823760986328
232517773,5821,hzxa21,2018-11-12T01:46:57Z,done.,0,0.9759407639503479
232555865,5821,lindong28,2018-11-12T07:37:31Z,"it will be practically very rare to have `broker` that is not found in `controllercontext.brokerepochs`. so this trace level logging is probably not useful. my understanding is that we only use trace level logging for something that is almost always triggered. if we do not have good use-case for this trace level logging, can we simplify the code change here by just adding one line (relative to the original code) to filter the key for `leaderandisrrequestmap`. more specifically, we can change the code from [code block] to [code block] same for `updatemetadatarequestpartitioninfomap` and `stopreplicarequestmap`.",0,0.9649809002876282
232557832,5821,lindong28,2018-11-12T07:47:19Z,nits: `not equal to current broker epoch` => `smaller than the current broker epoch`. same for other logs.,0,0.9832097291946411
232562259,5821,lindong28,2018-11-12T08:08:05Z,"according to the zookeeper client javadoc, the name in `createresponse` is expected to be `the name of the znode that was created`. also, it is mentioned that `on success, name and path are usually, equal, unless a sequential node has been created`. on the other hand, the javadoc for `createresult` says that, `a result from a create operation. this kind of result allows the path to be retrieved since the create might have been a sequential create`. we need to make sure that the `createresult.path` has the same value as the original value of the `name` in `createresponse` when a sequential node is created. the javadoc `createresult` suggests this is the case but the name of its variable, i.e. `path`, suggests they are different. can you double check this by creating a sequential znode?",0,0.9777041673660278
232566446,5821,lindong28,2018-11-12T08:27:51Z,"should we also update `controllercontext.brokerepochs` properly in `brokermodifications.process()`? to reduce the chance of missing such update in the future, it is probably good to make `brokerepochs` a private variable. and expose a single method in `controllercontext` to update `brokerepochs`, `livebrokersunderlying` and `livebrokeridsunderlying` together. this method can replace the existing method `livebrokers_=(brokers: set[broker])` in `controllercontext`.",0,0.984216034412384
232567122,5821,lindong28,2018-11-12T08:30:51Z,"thinking about this more, it may be better to do the following to explicit show that we want to keep only broker ids that are in `liveorshuttingdownbrokerids`. [code block]",0,0.9868064522743225
232764958,5821,hzxa21,2018-11-12T18:25:36Z,"both zookeeper `createrequest` and `createresponse` use the field `path` to represent the resulting path (can handle the sequential create case). i think what you think it is confusing is that when we are using zookeeper async create, the `processresult` methond in `stringcallback` has a `path` field to represent the path included in the request and has a `name` field to represent the resulting path. i double check zookeeper source code and zookeeper client (to be more specific, in `clientcnxn.java`). the logic to invoke the callback is: [code block] the 2nd argument in `processresult` is `path` and the 4th argument is `name`. this confirms that we use `rsp.getpath()` for the `name` in `processresult`.",0,0.919416606426239
232767009,5821,hzxa21,2018-11-12T18:32:10Z,"i actually think of what you have suggested at the very beginning and the reason i didn't do that is that the only place we can update the broker epoch is in brokerchange event. broker epoch will only change when the broker ephemeral znode gets deleted and re-created so that is why we use czxid (create transaction id). czxid will only change when we create the broker znode, not when we modify it, so in `brokermodification` event the czxid will not change. the only place we will capture the czxid change is in `brokerchange` evnet because we are listening on the children nodes change.",0,0.9713558554649353
232772273,5821,hzxa21,2018-11-12T18:49:51Z,agree. done.,0,0.9572290778160095
232772296,5821,hzxa21,2018-11-12T18:49:56Z,fixed.,0,0.9810503125190735
232782780,5821,lindong28,2018-11-12T19:25:52Z,sounds good. thanks for the explanation.,1,0.9667019248008728
232782818,5821,lindong28,2018-11-12T19:25:59Z,sounds good. thanks for the explanation.,1,0.9667019248008728
233259207,5821,junrao,2018-11-13T23:11:36Z,could we fix the javadoc above?,0,0.9887354969978333
233260194,5821,junrao,2018-11-13T23:15:47Z,"it would be useful to avoid _1/_2 for better readability. we could do foreach { case (broker, epoch) => ...}",0,0.9782606959342957
233278007,5821,junrao,2018-11-14T00:43:32Z,it would be useful to avoid _1/_2 for better readability.,0,0.9781854152679443
233278057,5821,junrao,2018-11-14T00:43:47Z,it would be useful to avoid _1 for better readability.,0,0.9795411229133606
233279558,5821,junrao,2018-11-14T00:52:38Z,"instead of bouncedbrokerids(broker.id), it might be clearer to do bouncedbrokerids.contains(broker.id).",0,0.9882712960243225
233281539,5821,junrao,2018-11-14T01:03:18Z,"hmm, could we just change livebrokersunderlying to a map[broker, long] instead of introducing a separate val?",0,0.9853972792625427
234024398,5821,junrao,2018-11-15T21:59:47Z,could this be debug?,0,0.9881190657615662
234025608,5821,junrao,2018-11-15T22:04:07Z,this probably should be info since we handle it as expected.,0,0.9853869676589966
234028770,5821,junrao,2018-11-15T22:15:45Z,"normally, when we call onbrokerfailure(), the passed in deadbrokers won't be in controllercontext.livebrokers, which is used by onbrokerfailure() through partitionstatemachine/replicastatemachine. with this change, this may not be true. will that have any impact?",0,0.9833033680915833
234029553,5821,junrao,2018-11-15T22:18:43Z,should we log the broker epoch in addition to the broker id?,0,0.9886232018470764
234033660,5821,junrao,2018-11-15T22:34:33Z,could we use case for e to avoid _1/_2?,0,0.9867405295372009
234055778,5821,junrao,2018-11-16T00:24:48Z,"this may be an existing problem. if a zk multi fails because of one of the operations, does that error get reflected in the rc in the top level response or in individual zkopresult?",0,0.9690496325492859
234057258,5821,junrao,2018-11-16T00:34:27Z,"do we need to add ()? in general, we only need () for methods with side effects.",0,0.9757989645004272
234059863,5821,junrao,2018-11-16T00:50:39Z,this logic needs to be done after the response.resultcode match block as before the patch since getafternodeexists() can return code.ok too.,0,0.9789531230926514
234061971,5821,junrao,2018-11-16T01:04:43Z,is it still useful to log in the above line since codeafterrecreate hasn't changed?,0,0.9882155656814575
234062220,5821,junrao,2018-11-16T01:06:25Z,typo abstarct,0,0.9835720658302307
234064469,5821,junrao,2018-11-16T01:21:21Z,perhaps those warn should be info since there is nothing for the user to act on this.,0,0.9872257113456726
234065021,5821,junrao,2018-11-16T01:25:20Z,epoch => brokerepochinrequest ?,0,0.9879084229469299
234065222,5821,junrao,2018-11-16T01:26:51Z,there is logging in zkclient.registerbroker(). we could just log the broker epoch there.,0,0.9896202683448792
234067161,5821,junrao,2018-11-16T01:40:40Z,are leader_and_isr_request_topic_state_v0 and leader_and_isr_request_partition_state_v1 still valid? perhaps it's simpler to just say we normalized partitions under each topic.,0,0.9864507913589478
234069244,5821,junrao,2018-11-16T01:54:52Z,this is unnecessary since shutdown() is blocking.,0,0.9301300048828125
234069643,5821,junrao,2018-11-16T01:56:25Z,"since the propagation of the zk event is async, we may need to put the checking logic in a waituntiltrue() block. ditto below.",0,0.9853137135505676
234069804,5821,junrao,2018-11-16T01:57:13Z,the comment seems out of place.,-1,0.6944746375083923
234070541,5821,junrao,2018-11-16T02:02:40Z,outdated comment?,0,0.5176096558570862
234070606,5821,junrao,2018-11-16T02:03:07Z,we are not sending stale epoch anymore?,0,0.8406872153282166
234070761,5821,junrao,2018-11-16T02:04:24Z,does this need to be volatile?,0,0.9769291281700134
234071333,5821,junrao,2018-11-16T02:08:28Z,the code in this method is quite similar to that in testcontrolrequestwithcorrectbrokerepoch(). should we merged them somehow?,0,0.988605797290802
234071751,5821,junrao,2018-11-16T02:11:44Z,should this be volatile?,0,0.9705401062965393
234073100,5821,junrao,2018-11-16T02:21:50Z,this is unnecessary. great test!,1,0.991195559501648
234073572,5821,junrao,2018-11-16T02:25:08Z,indentation,0,0.982236921787262
234073709,5821,junrao,2018-11-16T02:26:06Z,indentation,0,0.982236921787262
234144660,5821,hzxa21,2018-11-16T09:48:12Z,"this is a very good point. i think it is fine because the bounced broker will reject the control requests anyway because the cached broker epoch has not been updated yet. however, this brings up another question: do we actually need to call `onbrokerfailure()` for bounced brokers? after a second thought, i think the answer is no because the end goal of controller handling bounced brokers in brokerchange event is to make sure the quickly bounced brokers will be initialized correctly and the end partition/replica states will be the same with and without calling `onbrokerfailure` for the bounced brokers (if there are no new brokers and dead brokers). in this case, only calling `onbrokerstartup` is sufficient. invoking `onbrokerfailure` first is a correct and safe option but it comes with some overhead because we need to perform leader election and send out the stopreplica/leaderandisr/updatemetadata, which are not necessary. previously i thought that missing `onbrokerfailure` will cause correctness issue because we might miss some state clean up but looks like it is not the case. also note that if we use controlled shutdown to shutdown and restart the broker, the leadership election actually happens before processing the brokerchangeevent. tl;dr: to be more specific for your original question (why updating the live brokers first then invoke `onbrokerfailure` is fine), there are three places where we use the live brokers informartion in `onbrokerfailure`: 1. determine whether we need to transition partition states to offlinepartition: since at the time of the brokerchange event processing, the bounced brokers are alive so there will not be offline partitions. 2. determine which brokers we want to consider when performing leader election in `partitionstatemachine.triggeronlinepartitionstatechange()`: since the bounced brokers are online at that time so we should consider them. 3. determine which brokers we need to send out control requests and which brokers we need to include in the live brokers field in updatemetadatarequest: since the bounced brokers will not accept control requests anyway so the first point doesn't matter. for the second point, the bounced brokers are live so we don't want to exclude them in the updatemetadatarequest.",1,0.9079828262329102
234152612,5821,hzxa21,2018-11-16T10:13:25Z,"code from zookeeper (clientcnxn.java): [code block] this suggests that if we can get back the opresult from zookeeper (no connection_loss), rc represents the first error in the operations. so using the rc in the top level response after unwrapping the multi response is fine becuase the first error will also be the actual error for create/setdata/delete if we pass the controller epoch check. this also suggests that list[opresult] can be null in the callback and i don't handle this in our zookeeperclient so i will fix it.",0,0.9601878523826599
234307011,5821,lindong28,2018-11-16T18:36:20Z,"regarding info vs. warn, i usually follow the summary in [a link] which says that info level is for `generally useful information to log (service start/stop, configuration assumptions, etc)`, and warn level is for `anything that can potentially cause application oddities, but for which i am automatically recovering`. in this case the `brokerepoch < cachedbrokerepoch` can happen only under rare scenario when controlledshutdownrequest is re-sent due to disconnection between broker and controller. this is similar to the scenarios captured in `networkclient.processdisconnection(...)` which are currently logged in warn level. and it is unlike all other info level logging in kafka for normal broker start/stop. so it seems that warn level is appropriate here?",0,0.9771555662155151
236885202,5821,junrao,2018-11-27T23:14:43Z,"yes, the question is whether rare == odd. to me, odd should be unexpected. brokerepoch < cachedbrokerepoch is rare, but is not unexpected.",0,0.9534192681312561
236902108,5821,junrao,2018-11-28T00:36:16Z,": overall, i agree with your assessment that the onbrokerfailure() call seems redundant. the only thing is that it can force a leader epoch change. suppose that broker 1 is a bounced broker and is the current leader. if we skip onbrokerfailure(), the controller just keeps broker 1 as the leader w/o bumping the leader epoch. this means that the follower won't go through leader epoch based log truncation, which maybe needed since broker 1 may not have all the data in its local log after the bounce. so, perhaps we can't skip onbrokerfailure(). the next question is should the live broker list exclude the bounced brokers when we call onbrokerfailure(). it seems that we should since live broker list influences which broker is the new leader. if the bounced brokers are still in the live broker list and are the current leaders, those leaders' epoch won't change. so, in summary, it seems that we should still call onbrokerfailure() but excluding bounced brokers from live broker list first. we then add the bounced brokers to live broker list and call onbrokerstartup().",0,0.9288722276687622
236906085,5821,hzxa21,2018-11-28T00:57:13Z,"i agree. also after an offline discussion with dong, we agree that the benefit of optimizing for quickly bounced brokers is minor and since in normal scenario we will go through onbrokerfailure and then onbrokerstartup for the bounce brokers, it is better to do the same thing here ( invoke onbrokerfailure() and then update live brokers). thanks for the comment. i will update the pr accordingly.",1,0.8672380447387695
236907622,5821,junrao,2018-11-28T01:05:33Z,"thanks. since the code still uses the rc in the individual ops, it seems that we need to change it to check the top level rc?",1,0.9237154126167297
237354671,5821,hzxa21,2018-11-29T05:09:40Z,fixed.,0,0.9810503125190735
237354685,5821,hzxa21,2018-11-29T05:09:45Z,fixed.,0,0.9810503125190735
237354693,5821,hzxa21,2018-11-29T05:09:49Z,fixed.,0,0.9810503125190735
237354698,5821,hzxa21,2018-11-29T05:09:52Z,fixed.,0,0.9810503125190735
237354713,5821,hzxa21,2018-11-29T05:10:02Z,done.,0,0.9759407639503479
237354811,5821,hzxa21,2018-11-29T05:10:53Z,"good suggestion. i have changed livebrokeridsunderlying to a map[int, long] to avoid introducing the val.",1,0.9650599360466003
237355006,5821,hzxa21,2018-11-29T05:12:19Z,i think it is better to keep it info because the broker epoch information is as informative as the broker ids. we als log the broker ids in info log so we should keep it consistent.,0,0.9764394760131836
237355104,5821,hzxa21,2018-11-29T05:13:13Z,i think info is fine. i have changed it to info. thanks you guys for sharing the guideline.,1,0.9710412621498108
237355138,5821,hzxa21,2018-11-29T05:13:31Z,done.,0,0.9759407639503479
237355290,5821,hzxa21,2018-11-29T05:14:32Z,the broker epoch is already logged at the end of the broker change event: [a link],0,0.9877129793167114
237355315,5821,hzxa21,2018-11-29T05:14:43Z,sure. done.,0,0.9161409735679626
237357526,5821,hzxa21,2018-11-29T05:27:45Z,"we need to use the rc in the individual ops (check and create/delete/set) because we need to differentiate whether the error happened in the controller epoch znode zkversion check or in create/delete/set. the opresut for the check op will reflect whether it has succeeded or not. if it succeeds, the top level rc will reflect the error happened in create/delete/set and we do use top level rc when constrcuting the response for create/delete/set. if the check op fails, we will throw exception accordingly.",0,0.987127423286438
237357668,5821,hzxa21,2018-11-29T05:28:58Z,i don't think we need to add () here. the problem is we have () in the function definition which exists before this patch. i remove the () in the updated pr.,0,0.9727334380149841
237357712,5821,hzxa21,2018-11-29T05:29:19Z,good catch. thanks for pointing it out. fixed.,1,0.9862865805625916
237357743,5821,hzxa21,2018-11-29T05:29:33Z,no. my bad. i have removed the log.,-1,0.9869317412376404
237357752,5821,hzxa21,2018-11-29T05:29:38Z,fixed.,0,0.9810503125190735
237357777,5821,hzxa21,2018-11-29T05:29:48Z,sure. done.,0,0.9161409735679626
237357789,5821,hzxa21,2018-11-29T05:29:52Z,done.,0,0.9759407639503479
237357805,5821,hzxa21,2018-11-29T05:30:03Z,yes. done.,0,0.9706167578697205
237357830,5821,hzxa21,2018-11-29T05:30:15Z,thanks for the suggestion. done.,1,0.7343969941139221
237357840,5821,hzxa21,2018-11-29T05:30:23Z,removed.,0,0.9311882257461548
237357856,5821,hzxa21,2018-11-29T05:30:30Z,good point. fixed.,1,0.9722912311553955
237357868,5821,hzxa21,2018-11-29T05:30:35Z,removed.,0,0.9311882257461548
237357874,5821,hzxa21,2018-11-29T05:30:39Z,removed.,0,0.9311882257461548
237357953,5821,hzxa21,2018-11-29T05:31:19Z,fixed.,0,0.9810503125190735
237358000,5821,hzxa21,2018-11-29T05:31:37Z,yes. fixed.,0,0.9799623489379883
237358049,5821,hzxa21,2018-11-29T05:32:02Z,sure. i have merged them into a single function.,0,0.9775495529174805
237358057,5821,hzxa21,2018-11-29T05:32:07Z,yes. fixed.,0,0.9799623489379883
237358075,5821,hzxa21,2018-11-29T05:32:14Z,remove. thanks!,1,0.8925310373306274
237358087,5821,hzxa21,2018-11-29T05:32:17Z,fixed.,0,0.9810503125190735
237358092,5821,hzxa21,2018-11-29T05:32:21Z,fixed.,0,0.9810503125190735
237710891,5821,junrao,2018-11-30T00:33:25Z,could initialbrokerepoch be right after initialbrokerinfo?,0,0.9892643094062805
237716547,5821,junrao,2018-11-30T01:07:40Z,indentation,0,0.982236921787262
237718706,5821,junrao,2018-11-30T01:21:33Z,control request => controlled shutdown request,0,0.9860084652900696
237719353,5821,junrao,2018-11-30T01:26:07Z,the controller part is not right. non-controllers are registered through this api too.,0,0.8748550415039062
237719687,5821,junrao,2018-11-30T01:28:31Z,it seems that this logging is redundant since registerbroker() logs the same info already?,0,0.9719417691230774
237721321,5821,junrao,2018-11-30T01:40:07Z,perhaps it's better to return a map instead of a sequence of pairs?,0,0.9808543920516968
237723919,5821,junrao,2018-11-30T01:58:10Z,normalize => normalizes,0,0.9823159575462341
237724317,5821,junrao,2018-11-30T02:01:06Z,perhaps add a comment on how v1 differs from v0?,0,0.9840571284294128
237724569,5821,junrao,2018-11-30T02:02:47Z,normalize => normalizes,0,0.9823159575462341
237725390,5821,junrao,2018-11-30T02:08:58Z,unused import,0,0.9649426341056824
237725957,5821,junrao,2018-11-30T02:13:03Z,typo reuest,0,0.9873774647712708
237799160,5821,hzxa21,2018-11-30T09:42:03Z,sure. done.,0,0.9161409735679626
237799446,5821,hzxa21,2018-11-30T09:43:00Z,fixed.,0,0.9810503125190735
237799723,5821,hzxa21,2018-11-30T09:43:54Z,"i mean leaderandisr/updatemetadata/stopreplica requests here, not controlled shutdown request. i have updated the comment to avoid confusion.",0,0.9840916991233826
237799747,5821,hzxa21,2018-11-30T09:44:00Z,fixed.,0,0.9810503125190735
237799890,5821,hzxa21,2018-11-30T09:44:27Z,thanks for pointing out. i have removed the log here.,1,0.7539679408073425
237799946,5821,hzxa21,2018-11-30T09:44:39Z,agree. fixed.,0,0.9699246883392334
237799968,5821,hzxa21,2018-11-30T09:44:42Z,fixed.,0,0.9810503125190735
237799996,5821,hzxa21,2018-11-30T09:44:48Z,sure. added.,0,0.9579672813415527
237800040,5821,hzxa21,2018-11-30T09:44:53Z,fixed.,0,0.9810503125190735
237800071,5821,hzxa21,2018-11-30T09:44:58Z,removed.,0,0.9311882257461548
237800090,5821,hzxa21,2018-11-30T09:45:02Z,fixed.,0,0.9810503125190735
238013840,5821,junrao,2018-11-30T21:53:05Z,could we put return after param ?,0,0.9882073998451233
238013931,5821,junrao,2018-11-30T21:53:30Z,could we change the comment accordingly?,0,0.9864507913589478
238020317,5821,hzxa21,2018-11-30T22:20:31Z,sure. done.,0,0.9161409735679626
238020331,5821,hzxa21,2018-11-30T22:20:36Z,done.,0,0.9759407639503479
238021750,5821,junrao,2018-11-30T22:26:43Z,it seems that you fixed a different line?,0,0.9734817147254944
238069509,5821,hzxa21,2018-12-01T16:57:44Z,ah. my bad. i mislooked this one. fixed.,-1,0.9884639382362366
205630399,5428,guozhangwang,2018-07-26T23:23:28Z,this is a bug found in mockproducer: we should never throw producerfenced in send() call as it should only be returned in the future callback.,0,0.9190709590911865
205630643,5428,guozhangwang,2018-07-26T23:24:49Z,"this is the optimization on commit: we only execute commit when some processing has been done since last commit, either some records processed, or punctuation triggered. for standby task commit will be triggered only when some update has been applied to the state store.",0,0.9878090620040894
205630742,5428,guozhangwang,2018-07-26T23:25:28Z,this is the optimization we have done for partition stream time update.,0,0.9858179688453674
205912746,5428,guozhangwang,2018-07-27T22:19:59Z,this is not intended and will be removed when rebasing on part ii merged.,0,0.9827340245246887
207436880,5428,guozhangwang,2018-08-03T04:17:16Z,this test is invalid (see the above comment).,0,0.9317654371261597
207436995,5428,guozhangwang,2018-08-03T04:18:12Z,"if a producer is fenced, its producerfencedexception is wrapped in the kafkaexception.",0,0.9859691858291626
207437074,5428,guozhangwang,2018-08-03T04:18:47Z,this function should only be called once within each iteration after records enqueued.,0,0.9880865812301636
207437109,5428,guozhangwang,2018-08-03T04:19:08Z,inline this function since it only have one caller.,0,0.9881348609924316
207437286,5428,guozhangwang,2018-08-03T04:21:09Z,"this flaky test is found while working on the pr, so i'm piggy back the fix here. but itself is really independent of the pr, so if people wants to put it into a separate one i can also do that.",0,0.5481255650520325
208295539,5428,bbejeck,2018-08-07T16:16:47Z,i think we could simplify this block like so [code block] wdyt?,0,0.9873886108398438
208346664,5428,bbejeck,2018-08-07T18:54:08Z,"in trunk, the ordering of calls for the `producer` during a commit was broken up, but now they are all grouped together. it seems ok to do this and is cleaner to follow, i just wanted to double check the change of ordering doesn't matter. maybe we should run system tests to confirm?",0,0.9566373229026794
208347652,5428,bbejeck,2018-08-07T18:56:53Z,nit: we could return `commitneeded` and get rid of `else` and return `false` directly if no punctuation occurred.,0,0.9889962673187256
208347752,5428,bbejeck,2018-08-07T18:57:10Z,same as above,0,0.9772257208824158
208354835,5428,bbejeck,2018-08-07T19:20:47Z,nice addition!,1,0.9802557229995728
208727056,5428,guozhangwang,2018-08-08T20:37:54Z,"good point, i will run the system test accordingly.",1,0.9185634255409241
208728232,5428,guozhangwang,2018-08-08T20:41:28Z,yup! :),1,0.987835705280304
208741696,5428,mjsax,2018-08-08T21:27:14Z,should we check the root cause?,0,0.9848595261573792
208745329,5428,mjsax,2018-08-08T21:41:04Z,"isn't this a behavior change? iirc, we had a discussion to do this change, or to maybe make it configurable if we want to interleave processing with recovery.",0,0.9843693971633911
208745919,5428,mjsax,2018-08-08T21:43:28Z,should this be `timesincelastpoll >= maxpolltimems / 2` ?,0,0.9884946942329407
208747346,5428,mjsax,2018-08-08T21:49:19Z,"we set poll interval to integer.max_value by default. thus, if user does not change the default (most won't i assume), the condition will never be met. should we rather consider to set a different default value (note, there is already a jira for this)?",0,0.986186146736145
208749613,5428,mjsax,2018-08-08T21:58:16Z,isn't `timesincelastpoll < maxpolltimems` covered via `if (timesincelastpoll / 2 >= maxpolltimems) { break; }` and redundant?,0,0.983026921749115
208761166,5428,mjsax,2018-08-08T22:55:11Z,could we actually remove this guard? we don't call `time. milliseconds()` as below.,0,0.9856595993041992
208761888,5428,mjsax,2018-08-08T22:59:09Z,"why do we need this? wouldn't it be easier to remove `else` block and just call `return committed > 0;` after the `if`? if i understand correctly, we want to return `true` if committing happen, and currently, even if we commit we could return `false`",0,0.9850795269012451
208771114,5428,guozhangwang,2018-08-08T23:55:56Z,good point!,1,0.9838534593582153
208771638,5428,guozhangwang,2018-08-08T23:59:02Z,"ah good point! i was actually not intentionally changing the behavior, i will revert it back to the old manner.",1,0.9114949107170105
208772074,5428,guozhangwang,2018-08-09T00:01:52Z,"yes, that was my plan. i'm aware that this line is basically a no-op because max.poll is integer.max_value, and want to do it in another pr. if people feel that we should reverse the ordering, i.e. change the default value first, then do this pr, i'm fine too.",0,0.6051977872848511
208772154,5428,guozhangwang,2018-08-09T00:02:28Z,"gosh, my bad.",-1,0.9889869689941406
208772446,5428,guozhangwang,2018-08-09T00:04:17Z,"yes. in an old commit the code structure was a bit different and hence we may run over the check (assuming the maxpolltimems is not integer.max_value), but in this format we will always check for `timesincelastpoll >= maxpolltimems / 2` anyways in each loop, and hence we can remove this.",0,0.9820857048034668
208772726,5428,guozhangwang,2018-08-09T00:06:00Z,"the intention is to save calling `taskmanager.activetaskids(), taskmanager.standbytaskids()` etc and pass them as parameters. it may not really introduce significant differences, but no harm to still keep them?",0,0.9827612042427063
208772966,5428,guozhangwang,2018-08-09T00:07:45Z,"you're right, and actually i should changed the above line to `committed += taskmanager.commitall();`.",0,0.9658068418502808
208773153,5428,mjsax,2018-08-09T00:08:52Z,"i would personally prefer, to keep the condition in the `while` conditions instead of using `if() break` construct.",0,0.9839156270027161
208773238,5428,mjsax,2018-08-09T00:09:30Z,"i see. fine with my both ways -- as long as it's intentional and we know about it, it's ok.",0,0.8576482534408569
208997552,5428,guozhangwang,2018-08-09T16:33:28Z,this is also a flaky test that i discovered here.,0,0.7486028075218201
209042674,5428,mjsax,2018-08-09T18:56:36Z,fine with me to keep the guard. was just double checking.,0,0.9664859175682068
209293245,5428,vvcephei,2018-08-10T15:13:11Z,i didn't follow why we need this now. can you explain?,0,0.8910414576530457
209300543,5428,vvcephei,2018-08-10T15:36:16Z,"just checking my understanding: we are planning to replace this counter with a wall-clock timer in kip-353. i think that once we do that, we can actually move this logic into `isprocessable()` because the condition would no longer be dependent on the number of calls.",0,0.9794408082962036
209300893,5428,vvcephei,2018-08-10T15:37:31Z,"it seems like it might be worth actually putting your remark ""this function should only be called once within each iteration after records enqueued."" in a comment so we can remember during refactoring later.",0,0.9846166372299194
209310471,5428,vvcephei,2018-08-10T16:09:53Z,is this just because punctuations might result in context.forwards?,0,0.9775081276893616
209313656,5428,vvcephei,2018-08-10T16:20:51Z,"i believe that java (or the alu) will do exactly the same thing whether you say `maxpolltimems >> 1` or `maxpolltimems / 2`, but your human colleagues might appreciate the latter ;)",1,0.6143444180488586
209336733,5428,vvcephei,2018-08-10T17:47:21Z,"nice! now that the condition is no longer dependent on the number of invocations, i think you can move it into `isprocessable()` and not need to call this method outside of this class.",1,0.9886383414268494
209338385,5428,vvcephei,2018-08-10T17:53:27Z,"actually, we should re-set the timer whenever we process, right? imagine we have the following sequence: [code block]",0,0.9824174046516418
209339003,5428,vvcephei,2018-08-10T17:55:50Z,"i think there's a risk of forcing processing on the very first iteration if too much time passes between construction and processing (like if the startup protocol takes a while). maybe we can initialize it to `long.max_value` instead, which should cause us never to force processing the first time.",0,0.9708781838417053
209344830,5428,vvcephei,2018-08-10T18:16:44Z,"i take it this was the source of the flakiness. can you explain why, for my education?",0,0.5609768629074097
209405125,5428,guozhangwang,2018-08-10T23:23:23Z,"this is following the same pr that had: [a link] the point is that when a xxxconfig is created, by default it will print `logall` and hence swamped the logs (we can see the same lists to be printed multiple times whenever it is created). this function is to disable `log` for such cases.",0,0.9858751893043518
209405232,5428,guozhangwang,2018-08-10T23:24:16Z,actually it is because users can call `context.commit()` in either ` punctuate()` or `process()` calls.,0,0.9891127943992615
209405249,5428,guozhangwang,2018-08-10T23:24:32Z,ack :),1,0.8799719214439392
209405308,5428,guozhangwang,2018-08-10T23:25:07Z,"yup, good point.",1,0.970841109752655
209405511,5428,guozhangwang,2018-08-10T23:27:15Z,"that's a good catch, but if we move `isprocessable()` inside the iteration, it will mean that we will only enforce-process one record for every `max.idle.ms` right? my original thought is that once we've decided to enforce process, we'll enforce for that whole thread iteration.",0,0.8446165919303894
209405561,5428,guozhangwang,2018-08-10T23:27:49Z,"hmm, good point, i'll see what can be done here.",0,0.673112154006958
209405825,5428,guozhangwang,2018-08-10T23:30:47Z,"the flakiness is actually that for this dedup integration test, we should check that ""for each key, the last record is the expected value"", while previously we just check that ""we retrieve n records, and check that these n records are exactly the expected values"". however even with dedup based on caching, it may not be the case that we only produce n final records. this pr increases the likelihood that we do not only produce n final records, and hence i updated the check logic accordingly.",0,0.9792951345443726
209406887,5428,guozhangwang,2018-08-10T23:42:22Z,i will set the enforced process in the `inittopology` which will be triggered when the task transits to running state.,0,0.9882358312606812
209757140,5428,vvcephei,2018-08-13T21:00:25Z,ah! i misread this as turning `logall` *on* instead of *off*. now i get it :),1,0.9400704503059387
210646404,5428,bbejeck,2018-08-16T15:43:04Z,nit: can be package private,0,0.9868354797363281
210646473,5428,bbejeck,2018-08-16T15:43:19Z,nit: can be package private,0,0.9868354797363281
210689155,5428,bbejeck,2018-08-16T18:02:59Z,why did this go from 2 to 1? other than not passing an arg to `runonce` the test logic to this point hasn't changed,0,0.9769980907440186
211453536,5428,guozhangwang,2018-08-21T01:16:54Z,"the logic does have changed: in the old code we will commit twice on producer, one during the rebalance and one from the elapsed time. in the new code, the optimization i added will realize that nothing has been generated since the last commit, and hence we will skip committing in this case. thinking about it, this does have a side-effect though since for eos if commit was not called in a long time then txn will be aborted, and if producer does not talk to txn coordinator even longer it could be removed as well. but personally i think it is okay for such scenario to happen, since really no data was generated, and hence committing an empty txn does not really make sense, and we should rather increase the txn expiration time in this case. wdyt?",0,0.6785831451416016
211764912,5428,vvcephei,2018-08-21T21:23:35Z,"i guess that we always have a transaction open, not just when we have something to commit. it seems like one solution is to open a transaction only when we have data to process. although this might complicate things. alternatively, is there a way to periodically send a ""keep alive"" message to let the broker know we do still intend to use that transaction? it seems like either this or just abort/close the empty txn and re-open is better than a super-long expiration time. otherwise, why is there even an expiration time? is there any tradeoff between having one transaction open for a super long time, vs periodically closing empty transactions and starting new ones?",0,0.9077265858650208
211773323,5428,guozhangwang,2018-08-21T21:57:21Z,"completing a txn and starting a new one come with some cost, and hence is what we want to avoid generally. on the other hand, we do not yet have a mechanism for ""keep alive"": with that, i think keeping a long lived empty txn is okay, note that if the txn is not empty, then not committing it in time will increase the latency. hence i'm only trying to optimize the case when the txn is empty.",0,0.9421137571334839
211775968,5428,mjsax,2018-08-21T22:09:46Z,"i just talked to about this. not committing is actually fine. note, that begintx() is a client local state transition -- nothing is written to the log (there are no ""begin tx markers"") and the tc state is also not modified. this implies, that the transaction timeout is not started on begintx() -- the timeout only starts after the first record was written to the log. thus, we don't need ""keep alive heartbeats"" and don't need to tell users to increase the tx timeout for low traffic topics that might have longer periods with no data.",0,0.9239955544471741
212116777,5428,mjsax,2018-08-22T21:30:07Z,nit: `out-of-ordering` -> `out-of-order`,0,0.9855703115463257
212120236,5428,mjsax,2018-08-22T21:44:01Z,nit: can be limited to be package private,0,0.9865387678146362
212120925,5428,mjsax,2018-08-22T21:46:59Z,nit: `failed to commit streamtask {} due` -- to distinguish active and standbys as before.,0,0.9207783937454224
212121159,5428,mjsax,2018-08-22T21:47:55Z,why do we remove `tasktypename` for the log statement?,0,0.9822117686271667
212121272,5428,mjsax,2018-08-22T21:48:21Z,why do we remove `tasktypename` for the log statement?,0,0.9822117686271667
212121781,5428,mjsax,2018-08-22T21:50:33Z,"i think we should increase `committed` after `task.commit()` returns -- otherwise, we over count if committing fails?",0,0.9880040884017944
212121812,5428,mjsax,2018-08-22T21:50:42Z,"i think we should increase `committed` after `task.commit()` returns -- otherwise, we over count if committing fails?",0,0.9880040884017944
212122618,5428,mjsax,2018-08-22T21:54:04Z,nit: `lastenforcedprocess[ingtime[stamp]]` ?,0,0.9878820180892944
212122704,5428,mjsax,2018-08-22T21:54:20Z,nit: `enforedprocess[ing]`,0,0.9848803281784058
212123252,5428,mjsax,2018-08-22T21:56:36Z,should we change the order of the order? not sure atm if this has a semantic impact due to potential partial evaluation? just want to double check.,0,0.9812468886375427
212123631,5428,mjsax,2018-08-22T21:58:06Z,"also, it seems that we might want to rename `enforcedprocess` to `enforceprocessing` (without `d`) ?",0,0.9882882237434387
212123911,5428,mjsax,2018-08-22T21:59:11Z,this comments seems not to be addressed?,0,0.9533551335334778
212125423,5428,mjsax,2018-08-22T22:05:14Z,"both good points. basically, we should reset the timer when there is data for all input partitions. thus, we should check after poll() if we can reset the timer (ie, in `streamtask#addrecords()` each time all partitions have data)?",1,0.9691250920295715
212125967,5428,mjsax,2018-08-22T22:07:43Z,nit: formatting -> more `}` to next line,0,0.9824405312538147
212126272,5428,mjsax,2018-08-22T22:09:07Z,why do we not check `if(commitneeded)` any longer?,0,0.9705945253372192
212127138,5428,mjsax,2018-08-22T22:13:22Z,"it was broken apart because we checked if there is anything to commit in the first place (ie, do the check on one place)-- if we did not process any data, we don't need to commit. this check now happens outside of `streamtask` as pointed out by guozhang [a link] thus, regrouping makes sense. code is cleaner this way.",0,0.9622437357902527
212128396,5428,mjsax,2018-08-22T22:19:04Z,"meta comment: not sure if this is a good argument for inlining in general---code might be more readable if it's broken apart is smaller pieces and calling methods (with good names) actually self-documents the code. also, shorter methods are easier to understand. for this particular case, inlining is ok imho, as with `if (commitneeded)` check, we don't loose anything.",0,0.9261215329170227
212129095,5428,mjsax,2018-08-22T22:21:57Z,"hmmm... if there is nothing to commit, it might also be fine to ignore the user commit request? it's a tricky question what to do for this case. just follow what the user demands, or be smart? from a correctness point of view, it should not make a difference, would it? also, we set flag `commitrequested` for this case -- thus, it might be better to put this logic somewhere else? eg: `abstracttask` or overwrite in `streamtask`: [code block] (an alternative, that i like less would be to add a check if `commitrequested==true`)?",0,0.7350815534591675
212131579,5428,mjsax,2018-08-22T22:33:34Z,nit: remove `this`,0,0.9810076355934143
212133194,5428,mjsax,2018-08-22T22:41:50Z,nit: `maybeenforceprocess[ing]` ?,0,0.9832688570022583
212133245,5428,mjsax,2018-08-22T22:42:10Z,nit: `maybeenforceprocess[ing]`?,0,0.9832688570022583
212133339,5428,mjsax,2018-08-22T22:42:41Z,nit: `maybeenforceprocess[ing]`?,0,0.9832688570022583
212134225,5428,mjsax,2018-08-22T22:46:58Z,"why this? the condition checks for `activerunningtasks` -- why would we need to punctuate if there are not active tasks? also, should we `maybeupdatestandbytasks()` before we do `maybecommit()` to include the data that is processed by standbys in the commit?",0,0.9872843027114868
212135789,5428,mjsax,2018-08-22T22:55:13Z,this seems to contradict that we set `commitneeded` after punctuations (cf. my comments below).,0,0.9226214289665222
212136165,5428,mjsax,2018-08-22T22:57:17Z,"should we move this into the and `else` branch of `if (committimems >= 0 && lastcommitms + committimems < now)` -- if the condition is true, we call `taskmanager.commitall()` and thus `taskmanager.maybecommitactivetasks()` seems to be redundant here?",0,0.987514078617096
212386802,5428,guozhangwang,2018-08-23T17:09:26Z,good point!,1,0.9838534593582153
212387543,5428,guozhangwang,2018-08-23T17:12:06Z,"no specific reasons, i should add it back.",0,0.9787599444389343
212387559,5428,guozhangwang,2018-08-23T17:12:11Z,ditto.,0,0.859873354434967
212387745,5428,guozhangwang,2018-08-23T17:12:44Z,yes!,0,0.8127877116203308
212388642,5428,guozhangwang,2018-08-23T17:15:44Z,"the ordering thing: my old-school instinct is to put ""cheapest"" condition first for an `or` operator, but in modern compiler / cpu it really not matter at all :) renaming: ack.",1,0.8849453926086426
212389112,5428,guozhangwang,2018-08-23T17:17:20Z,my bad...,-1,0.987868070602417
212395430,5428,guozhangwang,2018-08-23T17:37:20Z,"we check this in the assignedtasks now: if no commit is needed, we skip the whole committing function, including commit offsets, flushing stores, etc.",0,0.9881116151809692
212398936,5428,guozhangwang,2018-08-23T17:47:42Z,"not sure i follow your comment here.. let me elaborate a bit on my logic: we have two commits in places: commitall (periodic) and maybecommit (for user requested): the latter checks [code block] while the former only checks: [code block] i.e. the logic for the latter is that ""only if user have requested, and it is indeed needed to commit"": for example, if we have actually committed from the commit interval, and then user requested it as well, the second will be omitted. i intentionally separated ""commitrequest"" (this is only set by user) and ""commitneeded"" (this is determined by the library) because this way looks cleaner to me.",0,0.9134711027145386
212399201,5428,guozhangwang,2018-08-23T17:48:27Z,i've removed this function as whole and only reset upon `addrecords` as you suggested.,0,0.9865145087242126
212399262,5428,guozhangwang,2018-08-23T17:48:38Z,ditto below.,0,0.9339895248413086
212400548,5428,guozhangwang,2018-08-23T17:52:24Z,"good catch. the deliberation was that even though ""there is no data processed"", not ""there is no active tasks"" as the original check is `state == running` :) note that although `taskmanager.hasactiverunningtasks()` returns true, we may still not process any data (i.e. `totalprocessed` == 0 and we break the loop immediately). but with the new condition, we will always execute `if (maybepunctuate() || maybecommit())` anyways, so we only need to do `maybeupdate` followed by a `maybecommit` again.",1,0.9786609411239624
212401916,5428,guozhangwang,2018-08-23T17:56:27Z,"actually thinking about this, i feel it is better to separate the standby tasks from active tasks in maybecommit as otherwise we are doomed to waste some cpus doing either one of them. will refactor the code a bit more.",0,0.899181604385376
212402352,5428,guozhangwang,2018-08-23T17:57:37Z,still not sure if i follow.. we do `maybepunctuate` before `maybecommit` so this should be fine?,0,0.8566809892654419
212402578,5428,guozhangwang,2018-08-23T17:58:25Z,"yes we can, as i mentioned i felt it is better to separate committing for standby tasks and for active tasks.",0,0.9761409759521484
212404222,5428,mjsax,2018-08-23T18:03:45Z,"so setting `commitneeded` is a conservative approach, because we don't know what the user did within punctuation call? might be better to set `commitneeded` if user calls `context.forward` or `state.put()` -- not sure how hard this would be -- would also be out-of-scope for this pr. if we think it might be worth it, we should create a jira for this optimization.",0,0.9004430770874023
212405498,5428,mjsax,2018-08-23T18:07:36Z,i think i miss understood the logic before. please ignore this comment.,-1,0.9695588946342468
212779553,5428,mjsax,2018-08-25T00:05:14Z,"nit: the naming always confuses me -- maybe we could rename this to `checkforusercommitrequest` or similar? the name should reflect that this method should be called to ""commit on user request only"" -- not for commit-interval purpose.",0,0.8554575443267822
212779739,5428,mjsax,2018-08-25T00:07:31Z,seems you missed this one :),1,0.9614615440368652
212779906,5428,mjsax,2018-08-25T00:09:27Z,wondering if this is redundant to [code block],0,0.9363448023796082
212780227,5428,mjsax,2018-08-25T00:14:15Z,thought on my last comment?,0,0.9657983779907227
212780732,5428,mjsax,2018-08-25T00:22:19Z,"it seem we rely on `computelatency()` above to advance `now` -- it seems ""dangerous"" to rely on a ""side effect"" for this. should we advance time explicitly here? or at least put a check if `now < lastpollms || now > timesincelastpoll` ?",0,0.9465464353561401
212780848,5428,mjsax,2018-08-25T00:24:17Z,nit: should we rename to `taskmanger.maybepunctuate()` as well as `assignedstreamtasks#maybepunctuate()` to align naming?,0,0.9893932342529297
212780939,5428,mjsax,2018-08-25T00:26:00Z,nit: add comment `// visible for testing`,0,0.9869434833526611
212781336,5428,mjsax,2018-08-25T00:33:14Z,"`taskmanager#commitall()` still commits both, active and standby tasks. what kind of separation do you mean? and even if we separate both, it seems to be orthogonal to my comment. if we commit all tasks because commit time elapses, we don't need to check for user requested commits any longer. atm, we might iterator over all tasks twice. first iteration is checking for user requested commits, and if commit interval is passed, we iterate over all tasks again. however, if we commit time passed, we commit all tasks anyway and thus can avoid checking for user requested commits (ie, we can put `int committed = taskmanager.maybecommitactivetasks();` into the `else` of `if (committimems >= 0 && lastcommitms + committimems < now)` ? or maybe i miss understood your comment?",0,0.9489531517028809
212781601,5428,mjsax,2018-08-25T00:38:36Z,"note, that we call `waituntilfinalkeyvaluerecordsreceived` now instead of `waituntilminkeyvaluerecordsreceived`. not sure why we need to update the commit interval? isn't `auto.commit=false` anyway? if not, should we set `auto.commit=false` instead of setting commit interval to ""infinite""?",0,0.9880918264389038
212781654,5428,mjsax,2018-08-25T00:39:41Z,nit: move `consumerproperties` to next line,0,0.987795352935791
212781954,5428,mjsax,2018-08-25T00:45:26Z,"simplify both lines to `finalaccumdata.putifabsent(kv.key, new arraylist<>()).add(kv);`",0,0.986735999584198
212781963,5428,mjsax,2018-08-25T00:45:35Z,as above,0,0.9783914685249329
212782085,5428,mjsax,2018-08-25T00:47:20Z,seem so to duplicate line above?,0,0.9789596199989319
212782144,5428,mjsax,2018-08-25T00:48:36Z,"what do you mean by ""respect"" -- don't understand the test name",0,0.5212830901145935
212782288,5428,mjsax,2018-08-25T00:51:28Z,"shouldn't commitrequest not be false by default? also, did you intent to call `task.requestcommit()` above?",0,0.9884437918663025
212782318,5428,mjsax,2018-08-25T00:52:23Z,i think we need to initialize this with `false`? (compare my comment in the tests above),0,0.980491042137146
212782384,5428,mjsax,2018-08-25T00:54:07Z,"if commit interval is 100ms, we might want to test the edge case 100 and 101 -- the test does not cover that we would force processing at 70l already.",0,0.9868505001068115
212782504,5428,mjsax,2018-08-25T00:56:48Z,"why 202l? i cannot inver from the test, to what time the timer get's reset?",0,0.9701786637306213
212782744,5428,mjsax,2018-08-25T01:02:32Z,why do we remove this test?,0,0.9499729871749878
213046088,5428,vvcephei,2018-08-27T17:10:02Z,"yeah, i can confirm that i just now got confused about the names. can we maybe call this (and up the chain) `commitifrequestedandneeded` or similar? specifically, the thing that confused me was differentiating the periodic commits on any dirty task vs. the on-demand commit driven by `processorcontext#commit`.",0,0.8671491742134094
213052103,5428,vvcephei,2018-08-27T17:30:25Z,"overall, the enforced-processing algorithm is unclear to me. * following on 's comment, it seems strange to set this right before we return true anyway. note that this is currently the only place we set `enforceprocessing` to true. * also, it still seems to me that `maxtaskidlems` should count from the last time we process at all, not the last time we forced processing (same basic scenario i pointed out last time). is this right?",0,0.7877625823020935
213140235,5428,guozhangwang,2018-08-27T22:55:46Z,"oops, my bad.",-1,0.9894394278526306
213140554,5428,guozhangwang,2018-08-27T22:57:20Z,ack.,0,0.7720441818237305
213141057,5428,guozhangwang,2018-08-27T22:59:59Z,"we still need to commit even if no records are processed: consider a topology which only contains a single source node, then no data processed at all, but we still want to commit so that we would not re-process them right?",0,0.9800185561180115
213152609,5428,guozhangwang,2018-08-28T00:15:02Z,"it is not: once `enforceprocessing` is set, we want to continue in that state until the next batch of records are enqueued and we not have all partitions buffered. note that once we set the flag we update `lastenforcedprocessingtime = now;` as well, but we do not want to disable enforce processing in the next run immediately.",0,0.9877244234085083
213152646,5428,guozhangwang,2018-08-28T00:15:30Z,"it is not: once `enforceprocessing` is set, we want to continue in that state until the next batch of records are enqueued and we not have all partitions buffered. note that once we set the flag we update `lastenforcedprocessingtime = now;` as well, but we do not want to disable enforce processing in the next run immediately.",0,0.9877244234085083
213153611,5428,guozhangwang,2018-08-28T00:24:58Z,"the motivation of advancing `now` in `computelatency` is to save on `milliseconds()` call. i admit it is not ideal, if we want to change it to a different way, say: passing `now` along the calls than using a variable at all, then i'd suggest we do it in a separate pr as this pr has been dragging too long. regarding the check: that is a good idea, but i guess you mean `now - lastpollms > timesincelastpoll` right? i will add that check.",0,0.886263370513916
213154023,5428,guozhangwang,2018-08-28T00:28:20Z,"i think `commit()` and `punctuate()` in taskmanager is okay, as they return the number of actual number of punctuation / commits triggered, while the `maybexx` returns true or false.",0,0.988135814666748
213154784,5428,guozhangwang,2018-08-28T00:34:22Z,"i left a general comment before, copying here: [code block] regarding your question: yes i think switching the checking for time-based commits and then user-requested commits for now makes sense, i will update the code accordingly.",0,0.9865483641624451
213155160,5428,guozhangwang,2018-08-28T00:37:36Z,"i think this is not needed, will remove this.",0,0.9793367385864258
213156091,5428,guozhangwang,2018-08-28T00:44:52Z,"note sure what do you mean? `task.needcommit()` sets the flag, `commitrequested()` checks the flag. do you suggest renaming `needcommit` to `requestcommit`?",0,0.9875532388687134
213156299,5428,guozhangwang,2018-08-28T00:46:21Z,"the default init value should be `false` anyways, but yeah i can make it explicit.",0,0.9878829121589661
213156684,5428,guozhangwang,2018-08-28T00:49:15Z,"note we are testing for max idle time as `now - lastenforcedprocessingtime > maxtaskidlems` so 101 is necessary, ditto for below `202`.",0,0.9850303530693054
213157946,5428,guozhangwang,2018-08-28T00:59:03Z,"here is the rationale of this logic: 1. once we decide to `enforceprocessing`, we will continue enforcing until we got new data enqueued and all the buffer become full, in this case we will in `normalprocessing` state. 2. but we will update the `lastenforcedprocessingtime` the last time we decide to start enforce processing. 3. we know that once we decide to enforce processing, we will always process immediately as there are indeed some data buffered already. so the logic above sets `lastenforcedprocessingtime` at the time we decide to ""turn it on"", and only ""turn it off"" during records enqueuing and all buffers contain some data. and hence we will first check `enforceprocessing`: if it is true we just continue enforce processing. lgty?",0,0.9658574461936951
213162972,5428,guozhangwang,2018-08-28T01:39:44Z,note that `putifabsent()` will return null if it does not contain the key previously. i can try to use `computeifabsent` though.,0,0.9887827038764954
213173389,5428,mjsax,2018-08-28T03:11:36Z,fair enough. thanks for pointing it out.,1,0.903846263885498
213173805,5428,mjsax,2018-08-28T03:15:49Z,"good point. now i am wondering, if we should set `lastenforcedprocessingtime = long.max_value`, too, when we set `enforceprocessing == false` when adding records to the buffers?",1,0.9332091808319092
213174290,5428,mjsax,2018-08-28T03:19:57Z,"renaming helps -- `needscommit` implies ""there is something to commit"" while `requestcommit` implies ""user request committing"" -- it's too different things and we need to keep naming separated to avoid confusion.",0,0.9767805337905884
213800151,5428,vvcephei,2018-08-29T19:09:54Z,"i see. thanks for explaining. it still seems like the `enforceprocessing` variable isn't strictly necessary, it just saves calls to `partitiongroup.allpartitionsbuffered()`, `partitiongroup.numbuffered()`, and the comparison `now - lastenforcedprocessingtime > maxtaskidlems`. these are all just cached field lookups, though, so i don't know if the performance boost is worth the algorithmic complexity. regarding `lastenforcedprocessingtime`, consider this scenario. [code block] two things to note here: 1. the expression should probably be `now - lastenforcedprocessingtime >= maxtaskidlems` (with `>=` instead of `>`), otherwise you'll wait at least one extra ms _beyond_ the purported ""max task idle time"". 2. in the scenario above, we said we want to wait *2 ms* before forcing processing, but we actually force processing *immediately*. to fix this, we should be comparing against `lastprocessingtime`, which we should set every time we process.",1,0.8882478475570679
213814276,5428,guozhangwang,2018-08-29T19:59:30Z,"good point, i will try to address this along with 's other comment:",1,0.5093860030174255
213815807,5428,vvcephei,2018-08-29T20:04:51Z,"thanks. one final thought about whether the `enforceprocessing` optimization is worth it. it might be a good idea to benchmark it without the optimization, since branch prediction *should* eliminate any overhead from the checks on rarely used branches.",1,0.949649453163147
214207271,5428,guozhangwang,2018-08-30T23:10:55Z,"this turns out to be harder than i thought. the tricky thing is that we originally want to 1) record the sensor only for the first time when we transit to ""enforced processing"" state, and 2) start the idleness timer only for the first time when we do not have all buffered but some buffered. i tried to even implement a streamtask state just like kafkastreams and streamthread, but that turns out to not be so elegant as well. so what i ended up now is this: we will record the sensor whenever we enforce processing, either for the first time or not, and hence we will only update idlestarttime once, and reset it whenever we have all buffered. lmk wdyt.",0,0.5833994746208191
215719543,5428,mjsax,2018-09-06T17:52:03Z,not sure if i understand this. why is a commit only required if we did not restore all records that were passed in? don't we need to commit if we did a restore and updated `lastoffset` ?,0,0.9068745970726013
215734428,5428,mjsax,2018-09-06T18:38:24Z,nit: should it be `>` instead of `>=` ?,0,0.9879544973373413
215734587,5428,mjsax,2018-09-06T18:38:58Z,nit: `not_known` -> `unknown` ?,0,0.983951210975647
215735099,5428,mjsax,2018-09-06T18:40:40Z,"nit: `fatal` is not a good name (was named like this before, no not introduced in this pr) -- this exception is not fatal but we can recover from it.",-1,0.6908372044563293
215737734,5428,mjsax,2018-09-06T18:49:08Z,"why not just: `timesincelastpoll = now - lastpollms` ? if we assume that `now` never goes backwards, i don't see the need for calling `math.max`? and if we need the `math.max` guard, why do we need both? or do i miss something?",0,0.9511011242866516
215738983,5428,mjsax,2018-09-06T18:53:09Z,"should we check for `timesincelastpoll < maxpolltimems / 2`, too? according to the comment above, if we break the while-loop, we want to half `numiterations`, too. ie, instead of checking in the `while` condition, add a check here and call `break` after reducing `numiterations`?",0,0.9887886643409729
215741170,5428,mjsax,2018-09-06T18:59:52Z,"nit: `lastcommitms + committimems < now` -> `now - lastcommitms > committimems` imho, easier to read this way.",0,0.9835995435714722
215741742,5428,mjsax,2018-09-06T19:01:48Z,why another `if`? i thought this would be an `else` to the condition above?,0,0.9773438572883606
215803459,5428,mjsax,2018-09-06T23:02:09Z,sounds good to me.,1,0.9596179723739624
216033050,5428,guozhangwang,2018-09-07T17:32:21Z,there was an early comment on the test code that suggests `>=`. personally i think it does not make a big difference at all.,-1,0.49917250871658325
216033754,5428,guozhangwang,2018-09-07T17:35:11Z,"again, this comes from a previous comment that it is safer to make sure `timesincelastpoll` does not go backwards, in case `now` is reduced.",0,0.9813080430030823
216037853,5428,guozhangwang,2018-09-07T17:49:27Z,good point!,1,0.9838534593582153
216039375,5428,guozhangwang,2018-09-07T17:54:27Z,"`!restorerecords.isempty()` means we have non-empty records that are applied inside `statemgr.updatestandbystates` call, note it does not remove records that are applied after the call.",0,0.9839437007904053
216067026,5428,vvcephei,2018-09-07T19:38:19Z,"i am to blame for this suggestion. i agree it doesn't make a big difference. the reasoning was that if it's the ""maximum idle time"", then you shouldn't idle longer than it, otherwise, it's not really a maximum.",-1,0.9124136567115784
216141583,5428,mjsax,2018-09-08T21:50:01Z,"i agree that it does not matter too much :) (that why it's a nit) however, i think that the maximum is inclusive, and only if we exceed it, we should force processing. from my understanding, ""maximum idle time"" is actually a lower bound (-> don't force processing until this time passed) because we cannot guarantee anyway to not exceed this threshold. i see your point why the name might be counter intuitive (even if i think the name is correct). if you interpret the name strictly, we would be allowed (or actually we would be required) to force processing before the time passed. this interpretation would make the parameter useless (ie, user tells us to idle max 5 minutes and we obey by forcing processing after 1 minute). to me, the right interpretation is, ""wait until this time passed and force processing asap if the time is exceeded"". chaning the name to `min.idle.time.ms` would be more precise, but i think it would be more confusing to users.",1,0.8841912746429443
216141611,5428,mjsax,2018-09-08T21:51:27Z,how could this happen? seems to be impossible to me.,-1,0.8122053742408752
216141645,5428,mjsax,2018-09-08T21:53:28Z,ack. i confused it with `remainingrecords`. all good :),1,0.9874734878540039
216399814,5428,guozhangwang,2018-09-10T17:05:51Z,"quoting your comment: [code block] the above change is for addressing this comment. again i'd admit it is not ideal to rely on the side effect of `computelatency()` to advance `now` but at the same time i want to avoid calling system time necessarily. if you feel strong about it, i can just go ahead and explicitly advance `now`, does it sound better to you?",0,0.9512813091278076
216400887,5428,guozhangwang,2018-09-10T17:09:01Z,"okay guys, i'm going to make a final call here to end the discussion: i'm staying with `max.idle..` since i feel it is easier to understand for users, and be aware that this is not strictly respected in practice unless it is set to `0`. also i'm staying with `>=` since again, it is easier to understand though not strictly sound mathematically.",0,0.9067386984825134
216403879,5428,mjsax,2018-09-10T17:17:35Z,:) fair enough.,1,0.9413658380508423
216404303,5428,mjsax,2018-09-10T17:18:48Z,i see. i did not make the connection to the other discussion. i think we can leave as-is.,0,0.9459957480430603
216520595,5428,guozhangwang,2018-09-11T01:14:46Z,"to make it clear, i 1) renamed the function, and 2) explicitly called it outside the `sensor.record` call.",0,0.9884676337242126
216550162,5428,mjsax,2018-09-11T05:37:09Z,"should we compute this, before we call `taskmanager.updatenewandrestoringtasks()` ? also, do we need to update `now` after `updatenewandrestoringtasks()` to compute `processlatency` correctly, below?",0,0.9895294308662415
216551625,5428,mjsax,2018-09-11T05:48:59Z,nit `stays at 2` seems to be correct -- it's `equalto(2)` below.,0,0.9837579131126404
216829644,5428,guozhangwang,2018-09-11T21:30:35Z,ack.,0,0.7720441818237305
216853354,5428,guozhangwang,2018-09-11T23:15:27Z,ack,0,0.9720376133918762
108246948,2743,hachikuji,2017-03-27T18:38:12Z,sorry for the drive-by comment. maybe this could be `partitionleaderepoch` so there's no potential confusion with the producer epoch?,-1,0.9865561723709106
108319243,2743,junrao,2017-03-28T01:50:05Z,"to follow the existing convention, partition_id and error_id should be partition and error_code?",0,0.9885481595993042
108319252,2743,junrao,2017-03-28T01:50:11Z,epochs => leader epochs ?,0,0.9836597442626953
108319291,2743,junrao,2017-03-28T01:50:33Z,"to follow the convention in other requests like fetchrequest, perhaps we can store map , where int is for leaderepoch?",0,0.9895697832107544
108319308,2743,junrao,2017-03-28T01:50:44Z,could we consolidate the log here and in line 173 into a single one? perhaps it's also useful to log the leo at this point.,0,0.986811101436615
108319315,2743,junrao,2017-03-28T01:50:50Z,"it seems that during log recovery, we should recover the leader epoch cache as well?",0,0.988457977771759
108319326,2743,junrao,2017-03-28T01:50:55Z,entry => batch,0,0.9825093746185303
108319349,2743,junrao,2017-03-28T01:51:11Z,"map { case (tp, state) => ...} ?",0,0.9868707656860352
108319571,2743,junrao,2017-03-28T01:53:41Z,"currently, in abstractfetcherthread, we try not to hold the partitionmaplock while making an rpc call. otherwise, if an rpc call takes long for some reason, the becomingleader/follower call will be delayed while waiting for the partitionmaplock. perhaps, we can structure the code like the following. [code block] in processleaderepochrequest(), we can do sth similar to processfetchrequest: send the leaderepochrequest w/o holding partitionmaplock; then hold onto partitionmaplock and do log truncation.",0,0.986431896686554
108319584,2743,junrao,2017-03-28T01:53:48Z,merge 218-220 into the state line in 217?,0,0.9788958430290222
108319612,2743,junrao,2017-03-28T01:54:02Z,"the reason for calling partitionmapcond.signalall() is to wake up the abstractreplicathread. if the method is only called within abstractreplicathread, we know the thread is awake when making the call. so, there is no need to call signalall().",0,0.9877051115036011
108319622,2743,junrao,2017-03-28T01:54:09Z,handlehandleoffsetforleaderepochrequest => handleoffsetforleaderepochrequest,0,0.9786686301231384
108319626,2743,junrao,2017-03-28T01:54:15Z,it seems that offsetsforleaderepoch.getresponsefor() should be a method in replicamanager?,0,0.9888290762901306
108319633,2743,junrao,2017-03-28T01:54:19Z,missing license header,0,0.7844788432121277
108319657,2743,junrao,2017-03-28T01:54:30Z,"we probably only want to resort to hw if the error is noleaderepoch. otherwise, we should probably just backoff a bit and then retry.",0,0.9767672419548035
108319674,2743,junrao,2017-03-28T01:54:40Z,"if epochoffset.endoffset() is unsupported_epoch_offset, which can happen during the transition phase, we should fall back to hw?",0,0.9877043962478638
108319712,2743,junrao,2017-03-28T01:55:10Z,"if epochoffset.endoffset() >= replica.logendoffset.messageoffset, perhaps we could avoid log truncation.",0,0.9889296889305115
108319722,2743,junrao,2017-03-28T01:55:17Z,perhaps we should change the file name to offsetcheckpointfile?,0,0.9888371229171753
108319742,2743,junrao,2017-03-28T01:55:31Z,"if epoch is < latestepoch(), it might be useful to log a warning. we probably also want to assert that offset is > the offset of the last epoch.",0,0.9883346557617188
108319753,2743,junrao,2017-03-28T01:55:36Z,is epochs.last() of o(1) cost? it will be called on every request.,0,0.9870709776878357
108319812,2743,junrao,2017-03-28T01:56:21Z,"we want to be a bit careful here, especially during the transition phase when some existing messages may not have a leader epoch. so, if requestedepoch is < the first epoch in epochs, we probably want to return unsupported_epoch_offset so that the follower can fall back to hw.",0,0.9753620624542236
108319839,2743,junrao,2017-03-28T01:56:39Z,"do we need retainmatchingoffset? it seems that in both log.truncateto() and log.truncatefullyandstartat(), we want the offset to be inclusive, i.e., an epoch with offset will be removed.",0,0.9881122708320618
108319862,2743,junrao,2017-03-28T01:56:53Z,"could we log the topic/partition too? also, does this need to be info? seems more like debug level. ditto below in clearoldest().",0,0.9592621326446533
108319865,2743,junrao,2017-03-28T01:56:55Z,is the comment accurate?,0,0.9815764427185059
108319919,2743,junrao,2017-03-28T01:57:20Z,not sure if we need retainmatchingoffset here either. it seems the caller always wants this to be inclusive.,0,0.9645578265190125
108379720,2743,benstopford,2017-03-28T09:52:12Z,"yes, i'm using a listbuffer: [a link]",0,0.9841004610061646
108408756,2743,benstopford,2017-03-28T12:41:13Z,have changed to: `offset >= the offset of the last epoch.` as epoch can increment on the leader when the offset does not change.,0,0.9881559610366821
108652909,2743,benstopford,2017-03-29T11:31:33Z,"i've pulled the logic up into abstractfetcherthread. what i've done is somewhat similar to your snippet, but it includes a lock around the truncation step. [code block]",0,0.9846712350845337
109215784,2743,junrao,2017-03-31T17:54:40Z,"it seems that $leaderepoch is the same as ${partitionstateinfo.leaderepoch}? perhaps we can change the logging to ""$topicpartition starts leader epoch $leaderepoch from offset ${getreplica().get.logendoffset.messageoffset}""?",0,0.988644003868103
109216215,2743,junrao,2017-03-31T17:56:39Z,"given the logging in partition.makeleader(), it seems that we don't need the logging here.",0,0.9837212562561035
109217691,2743,junrao,2017-03-31T18:03:39Z,indentation,0,0.982236921787262
109219494,2743,junrao,2017-03-31T18:12:35Z,"this needs to be logged before line 80? otherwise, the new epoch is already the last epoch.",0,0.986107349395752
109225083,2743,junrao,2017-03-31T18:38:38Z,"we only want to return the offset for the epoch if the replica is still the leader. we probably want to call replicamanager.getleaderreplicaiflocal(), catch exceptions like not_leader_for_partition and unknowntopicorpartitionexception and convert it to an error code like what's in replicamanager.readfromlocallog().",0,0.9869454503059387
109225474,2743,junrao,2017-03-31T18:40:24Z,"hmm, if requestedepoch == undefined_epoch, it seems that we should return undefined_epoch_offset so that the follower can fall back to hw.",0,0.985577404499054
109225572,2743,junrao,2017-03-31T18:40:50Z,inaccurate comment.,-1,0.9299831390380859
109225580,2743,junrao,2017-03-31T18:40:52Z,inaccurate comment.,-1,0.9299831390380859
109226958,2743,junrao,2017-03-31T18:48:03Z,it seems that we should call leaderepochcache.clear() in this case since all data is gone.,0,0.9863417744636536
109227964,2743,junrao,2017-03-31T18:53:24Z,"in this case, we are removing all data starting at startoffset. so, we want to call leaderepochcache.clearlatest instead. even if there is no log recovery, it will be useful to make sure that leaderepochcache is consistent with what's in the log. so, instead of doing it here, we could just call leaderepochcache.clearlatest(nextoffset) immediately after loadsegments().",0,0.9824861288070679
109229094,2743,junrao,2017-03-31T18:59:10Z,"legacy messages will have epoch < 0 and we don't want to flood the logging. so, we can probably only log a warning if epoch is >= 0?",0,0.9868883490562439
109230643,2743,junrao,2017-03-31T19:07:19Z,"not sure if it matters, but we probably want to define leaderepochcache before loadsegments() is called since log recovery needs access to leaderepochcache.",0,0.9854282736778259
109231519,2743,junrao,2017-03-31T19:12:46Z,"i think this also needs to be called during log recovery in logsegment.recover(). also, during this process, it's possible for an older epoch to be assigned again. to avoid the unnecessary logging in maybewarn, on way is for the caller can only call assign() from latestoffset().",0,0.9881958961486816
109256482,2743,junrao,2017-03-31T21:47:17Z,the comment seems inaccurate. deletesegment only clearoldest.,-1,0.611585259437561
109256659,2743,junrao,2017-03-31T21:48:39Z,could we add epochcache to the comment above?,0,0.988822340965271
109256943,2743,junrao,2017-03-31T21:50:55Z,clearearliest to match clearlatest?,0,0.988454282283783
109261174,2743,junrao,2017-03-31T22:26:58Z,no need for this logging?,0,0.9845492839813232
109261760,2743,junrao,2017-03-31T22:33:01Z,indentation,0,0.982236921787262
109262199,2743,junrao,2017-03-31T22:37:36Z,allpartitions no longer used.,0,0.8961217403411865
109263288,2743,junrao,2017-03-31T22:48:18Z,this can be private.,0,0.9870530962944031
109264654,2743,junrao,2017-03-31T23:02:45Z,consumerid not used.,0,0.9691050052642822
109265484,2743,junrao,2017-03-31T23:12:15Z,"we should probably add a new tag kafka_0_11_0_iv2 which corresponds to the introduction of leaderepoch request, and use it here.",0,0.9891826510429382
109265507,2743,junrao,2017-03-31T23:12:29Z,"""fetch from the leader"" can be a bit confusing. ""issue leaderepochrequest to the leader""?",0,0.5303522944450378
109265520,2743,junrao,2017-03-31T23:12:34Z,remove ?,0,0.9761508703231812
109268030,2743,junrao,2017-03-31T23:45:31Z,perhaps we can also change the line 945 from if(targetoffset > logendoffset) { to if(targetoffset >= logendoffset) {,0,0.9872549772262573
109269015,2743,junrao,2017-03-31T23:58:16Z,this is the case the leader returned an offset >= leo. it would be useful to log the topic/partition as well.,0,0.9873954653739929
109269023,2743,junrao,2017-03-31T23:58:20Z,it would be useful to log the topic as well.,0,0.9835378527641296
109269093,2743,junrao,2017-03-31T23:59:19Z,could we add override?,0,0.9883607625961304
109269313,2743,junrao,2017-04-01T00:02:35Z,this can be private.,0,0.9870530962944031
109269322,2743,junrao,2017-04-01T00:02:44Z,this can be private.,0,0.9870530962944031
109269876,2743,junrao,2017-04-01T00:11:25Z,it doesn't seem this method and the trait are used.,0,0.9670273065567017
109311609,2743,junrao,2017-04-02T15:27:22Z,"could we remove todo? if we just want to test corrupted messages, there is no need to set includepartitioninitialisation to true.",0,0.9887737035751343
109312409,2743,junrao,2017-04-02T15:58:38Z,this is because we bounce the leader epoch when the controller changes the isr too so that the latest isr can be updated in the broker's cache.,0,0.987937867641449
109312786,2743,junrao,2017-04-02T16:17:18Z,"hmm, there is a subtle question here, which is should the new epoch be added to epoch cache when the leader epoch advances or when there is actually a message added in the new epoch. the latter means that epoch will be more consistent after log recovery and be more consistent between the leader and the follower. so, perhaps it's better to do the latter. then the flow will be (1) we remember the latest epoch in partition.leaderepoch when receiving leaderandisrrequests, but not updating the leader epoch cache yet; (2) we pass partition.leaderepoch to log.append() and only update the leader epoch cache when there is a new message produced. this will also make the test a bit easier to understand since the epoch will always be consistent btw the leader and the follower.",0,0.9746418595314026
109313719,2743,junrao,2017-04-02T16:54:09Z,this can be done using testutils.waituntiltrue(() ?,0,0.9876167178153992
109313817,2743,junrao,2017-04-02T16:58:00Z,"since we have a large linger and batch size in the producer, does it matter whether we send those 100 messages in batches? it seems that all of them will be in the same batch after the flush() call.",0,0.9847639203071594
109314127,2743,junrao,2017-04-02T17:10:49Z,unused method.,0,0.9157376885414124
109314585,2743,junrao,2017-04-02T17:31:46Z,put two statements in different lines and remove ;,0,0.9792419075965881
109314603,2743,junrao,2017-04-02T17:32:27Z,remove ;,0,0.9549312591552734
109314622,2743,junrao,2017-04-02T17:33:15Z,remove ; in the above 2 statements. ditto in a few other places.,0,0.9545484185218811
109315673,2743,junrao,2017-04-02T18:11:09Z,"deletecorrespondingleaderepochs should only be set to true when we are deleting a prefix of the log segments. the only caller for that is def deletesegments(deletable: iterable[logsegment]). also, segment.nextoffset() needs scanning the log and can be a bit expensive. so, perhaps, we can call leaderepochcache.clearoldest() in deletesegments(deletable: iterable[logsegment]) with the recomputed logstartoffset, which is much cheaper.",0,0.9771807193756104
109316101,2743,benstopford,2017-04-02T18:27:47Z,"this was a pretty big change, but the final one of your first round of comments. committed now.",1,0.6441203951835632
109316191,2743,junrao,2017-04-02T18:32:06Z,"the error message seem inaccurate. here, we are just verifying the log for broker 0, not for broker 1.",0,0.7494405508041382
109316509,2743,junrao,2017-04-02T18:47:39Z,do we need testsender or could we just reuse replicafetcherblockingsend?,0,0.989043116569519
109320017,2743,junrao,2017-04-02T21:05:12Z,"when clearearliest() is called, it means that the first offset of the log starts at offset. so we want to (1) preserve an entry whose startoffset == offset; (2) if the last entry whose startoffset is < offset and the next entry's offset is > offset or is not present, we want to preserve that last entry and just set its startoffset to offset. we want to change the comment accordingly.",0,0.986530065536499
109320018,2743,junrao,2017-04-02T21:05:14Z,oldest => earliest?,0,0.9756494760513306
109320084,2743,junrao,2017-04-02T21:07:48Z,is this needed?,0,0.9837570190429688
109320101,2743,junrao,2017-04-02T21:08:16Z,should we use just use createproducer()?,0,0.9876276254653931
109320117,2743,junrao,2017-04-02T21:08:55Z,a few methods like that can be made private.,0,0.9864922165870667
109320127,2743,junrao,2017-04-02T21:09:21Z,"hmm, why do we need to create a new producer here? if so, should we close the old one first?",0,0.9654501676559448
109320169,2743,junrao,2017-04-02T21:11:39Z,this is because we have to first change leader to -1 and then change it again to the live replica.,0,0.9820868968963623
109320452,2743,junrao,2017-04-02T21:24:48Z,a few methods like that in this file can be private.,0,0.9879698753356934
109320567,2743,junrao,2017-04-02T21:29:44Z,is this needed? it seems that we create the dir when initializing log in loadsegments().,0,0.9891160130500793
109320709,2743,junrao,2017-04-02T21:34:25Z,the second param should be offset + 3 too?,0,0.9869286417961121
109321139,2743,junrao,2017-04-02T21:50:17Z,this can be private.,0,0.9870530962944031
109321508,2743,junrao,2017-04-02T22:04:12Z,"hmm, if we are only deleting one segment, shouldn't the first offset be 5 and we should preserve epochentry(1,5)?",0,0.9854955673217773
109321591,2743,junrao,2017-04-02T22:06:53Z,this is actually not truncating the first segment. ditto in line 1478.,0,0.9647768139839172
109321653,2743,junrao,2017-04-02T22:09:46Z,"hmm, we are already testing multiple lines in the previous test. is this testing multiple partitions in the same topic?",0,0.9816398024559021
109321773,2743,junrao,2017-04-02T22:14:26Z,should this be removed now that leader epoch is at the set level?,0,0.9858605861663818
109321789,2743,junrao,2017-04-02T22:15:07Z,unused import,0,0.9649426341056824
109321997,2743,junrao,2017-04-02T22:24:47Z,the code is for 3 times.,0,0.9854100942611694
109322753,2743,junrao,2017-04-02T22:54:58Z,the part of calling assign() during log recovery still needs to be addressed.,0,0.9851678609848022
109322961,2743,junrao,2017-04-02T23:02:18Z,"this probably can be done in a followup patch. if there is an error, we probably want to add a bit of delay to the partition before retrying the offsetsforleaderepoch request (like what we do when the fetch request has an error).",0,0.9881479144096375
109333196,2743,junrao,2017-04-03T02:45:44Z,should we uncomment this?,0,0.9306061863899231
109447563,2743,benstopford,2017-04-03T15:29:09Z,"(2) is a good point. thank you. have altered and added appropriate tests. in a bit of a rush, coding this in the airplane lounge.",1,0.9832751154899597
109447763,2743,benstopford,2017-04-03T15:29:50Z,i need this to get tests to pass locally. feel free to remove as i have a pr to change these running separately.,0,0.8317626118659973
109448157,2743,benstopford,2017-04-03T15:31:17Z,hmm. this is covering a chicken/egg situation around the initialisation of log (i.e. where we initialise leaderepochcache). needs changing.,0,0.9831952452659607
109547558,2743,junrao,2017-04-03T23:24:20Z,epochsbytopic => epochsbytopicpartition?,0,0.9850794076919556
109547577,2743,junrao,2017-04-03T23:24:27Z,this doesn't seem to be used.,0,0.7894418835639954
109547593,2743,junrao,2017-04-03T23:24:34Z,this doesn't seem to be used.,0,0.7894418835639954
109547736,2743,junrao,2017-04-03T23:25:33Z,-1l = > epochendoffset.undefined_offset ?,0,0.9887663722038269
109547743,2743,junrao,2017-04-03T23:25:39Z,the method is not used.,0,0.9494054913520813
109547807,2743,junrao,2017-04-03T23:26:02Z,"at this point, the log dir may not have been created. so, we probably need to make sure the log dir exists first.",0,0.982008695602417
109547834,2743,junrao,2017-04-03T23:26:16Z,we can set the deleteepoch flag to false here since we call clearlatest() after loading the log.,0,0.9893520474433899
109547857,2743,junrao,2017-04-03T23:26:26Z,could we move line 943 to after line 949?,0,0.9870476722717285
109547889,2743,junrao,2017-04-03T23:26:37Z,"could we remove the todo? also, could we move this line to before line 960?",0,0.9888835549354553
109548130,2743,junrao,2017-04-03T23:28:14Z,"hmm, if the broker is on a version before kafka_0_11_0_iv2 and we don't let the partition go through the initialization phase, then the followers won't be doing any truncation based on hw. we can probably always set the partition to need initialization. if the broker is on a version before kafka_0_11_0_iv2, in fetchepochsfromleader(), we don't do the actual leader epoch request, but simply set the response to unknown_offset. then the maybetruncate() logic will just fall back to hw.",0,0.9754643440246582
109548156,2743,junrao,2017-04-03T23:28:20Z,it would be useful to log the topic/partition as well.,0,0.9868310689926147
109548176,2743,junrao,2017-04-03T23:28:27Z,do maybewarn() in else?,0,0.9826367497444153
109548190,2743,junrao,2017-04-03T23:28:33Z,"it will be useful to log the topic/partition as well. also, could this just be debug level logging?",0,0.9869905114173889
109548206,2743,junrao,2017-04-03T23:28:42Z,"if earliestoffset() == offset, it seems that we don't need to do anything.",0,0.9856276512145996
109548223,2743,junrao,2017-04-03T23:28:49Z,"similar here, we want to find entries with entry.startoffset < offset.",0,0.9862838983535767
109548234,2743,junrao,2017-04-03T23:28:54Z,not sure if we need the if test here.,0,0.7837755084037781
109548266,2743,junrao,2017-04-03T23:29:09Z,"this should say ""epoch < latestepoch"". an partitionleaderepoch => a partitionleaderepoch",0,0.9883158802986145
109548287,2743,junrao,2017-04-03T23:29:19Z,it seems that we only append messages of format v2 and newer. so epoch is never expected to be <0 ?,0,0.9775465130805969
109548308,2743,junrao,2017-04-03T23:29:29Z,"hmm, it seems that only the first segment will be removed according to the retention policy?",0,0.9759197235107422
109548322,2743,junrao,2017-04-03T23:29:35Z,it's no longer doing this in batches.,0,0.5660395622253418
109548330,2743,junrao,2017-04-03T23:29:39Z,this can be private.,0,0.9870530962944031
109548343,2743,junrao,2017-04-03T23:29:47Z,put two statements in different lines and remove ; there are quite a few other places using ;.,0,0.9787147045135498
109651046,2743,benstopford,2017-04-04T12:42:53Z,"oh, it's used by one of the tests. authorizerintegrationtest. all the request/response classes have it.",0,0.9879096746444702
109651092,2743,benstopford,2017-04-04T12:43:09Z,as above,0,0.9783914685249329
109651463,2743,benstopford,2017-04-04T12:45:10Z,see authorizerintegrationtest,0,0.9854838252067566
109781747,2743,benstopford,2017-04-04T21:26:54Z,"i think this is ok, but can remove if you feel strongly.",0,0.944826066493988
109795882,2743,benstopford,2017-04-04T22:43:51Z,hmm. i think this actually correct. i would like a better way to express it but i can't see one. i'd encourage you to look at the tests in leaderepochfilecachetest to see if you disagree with any of them.,0,0.9139035940170288
109967050,2743,junrao,2017-04-05T16:41:06Z,"yes, i agree that it's needed.",0,0.9539570808410645
124910746,2743,lindong28,2017-06-29T20:55:49Z,it seems that the method's java doc is inconsistent with its behavior if requestedepoch is < the first epoch in epochs. i am wondering if we should update the java doc or comment in this code to explain this. i only realized it is intentional after reading this 's comment in this pull request.,0,0.6765117645263672
124923278,2743,junrao,2017-06-29T22:01:02Z,: we can clarify that in the comment. could you file a jira?,0,0.9804468154907227
124927503,2743,lindong28,2017-06-29T22:27:39Z,sure. i filed [a link] and assigned it to .,0,0.9786585569381714
1890534015,18240,jsancio,2024-12-18T16:37:36Z,can we try moving this to the internal module? anything public in this package can be used outside the `raft` module.,0,0.9894663691520691
1890534655,18240,jsancio,2024-12-18T16:38:08Z,can we explicitly mark private any method that is not used outside of this class?,0,0.9883058667182922
1890535623,18240,jsancio,2024-12-18T16:38:49Z,please write java doc for all public methods.,0,0.9868099689483643
1890542820,18240,jsancio,2024-12-18T16:43:51Z,`illegalargumentexception` seems like a better exception type.,0,0.9808117151260376
1890544866,18240,jsancio,2024-12-18T16:45:11Z,let's write java doc for all public methods.,0,0.988143265247345
1890552560,18240,jsancio,2024-12-18T16:50:45Z,"this is not a warning. this is a valid state or condition. we should be able to log this message at info level. it should be rare because there are backoff/timeout logic in candidate, follower and unattached which limit how quickly a replica transitions to prospective. what do you think?",0,0.9781458377838135
1890554341,18240,jsancio,2024-12-18T16:52:04Z,let's use the same word you used in the `nomineestate`: `isnomineestate()` and `nomineestateorthrow()`.,0,0.9866245985031128
1890660800,18240,ahuang98,2024-12-18T18:22:03Z,"|i see your point here, there's nothing 'incorrect' about this happening. but i'm wondering about the case where a controller quorum is left partially upgraded on accident. would having a warning log make this situation more discoverable?",0,0.8481889963150024
1890678659,18240,jsancio,2024-12-18T18:37:30Z,"yeah. this would be interesting to monitor but cluster are not really monitored by looking at the log. clusters are monitored by collecting and comparing metrics. this is an issue beyond kraft and should be solved holistically. kafka could have a metrics that fires if the api versions and supported features don't match across all of the replicas. this metric would require a kip to implement. having said that, we should keep this message but it should not be logged at warn. it should be logged at info.",0,0.8894141316413879
1894260795,18240,ahuang98,2024-12-20T18:28:20Z,"it might not be expected that a state has both leader and voted key state, but i think it's better not to lose the state if it does happen to exist. not an issue for backwards compatibility, older version would lose votedkey state but would have leader state and will reject standard votes correctly because of that.",0,0.9800068736076355
1895898210,18240,ahuang98,2024-12-23T15:52:47Z,"open to what you think, this definitely isn't necessary but i thought this could help reduce the complexity of handlevoteresponse (this is called in a 3rd level of conditional statements)",0,0.9797234535217285
1895926505,18240,ahuang98,2024-12-23T16:24:52Z,"found existing test which checks that observers with ids can vote - [a link] which was added in kafka-16526, so i've removed `voted` for now (vs translating to `unattachedvoted`)",0,0.9886025786399841
1896920647,18240,jsancio,2024-12-24T18:52:19Z,the type should be `candidatestate`. let's add the field `retries` back to the message. how about replacing `voterstates` with `epochstate` and implementing a `tostring` method for `epochstate`?,0,0.988420844078064
1896921039,18240,jsancio,2024-12-24T18:53:27Z,let's move this method so that it doesn't show in the diff.,0,0.9838793873786926
1896921206,18240,jsancio,2024-12-24T18:53:57Z,let's move this method so that it doesn't show in the diff.,0,0.9838793873786926
1896921449,18240,jsancio,2024-12-24T18:54:31Z,let's move this method so that it doesn't show in the diff.,0,0.9838793873786926
1896921655,18240,jsancio,2024-12-24T18:54:53Z,let's move this method so that it doesn't show in the diff.,0,0.9838793873786926
1896923862,18240,jsancio,2024-12-24T19:01:12Z,let's revert this change. we should make it clear that this pr is not changing the persisted `quorum-state`.,0,0.9683859944343567
1896926243,18240,jsancio,2024-12-24T19:07:42Z,nice code removal! thanks.,1,0.9875323176383972
1896926826,18240,jsancio,2024-12-24T19:09:03Z,"i got the impression that you don't use this in `src/main`. if so, let's remove it.",0,0.9851544499397278
1896930978,18240,jsancio,2024-12-24T19:21:53Z,"let's just remove this method and have the tests use `transitiontounattached(int, optionalint)`. also update the java doc to match the new signature and parameters.",0,0.9887475967407227
1896932468,18240,jsancio,2024-12-24T19:26:02Z,"let's remove this and update the callers to use `transtitiontounattached(int, optionalint)`.",0,0.9882623553276062
1896934629,18240,jsancio,2024-12-24T19:32:12Z,how about: [code block],0,0.9867309331893921
1896935574,18240,jsancio,2024-12-24T19:35:15Z,let's fix the indentation. in the raft module we using this formatting style: [code block],0,0.9855487942695618
1896936282,18240,jsancio,2024-12-24T19:37:26Z,let's fix this formatting. see my under examples on how we try to format code in the raft module.,0,0.9862256050109863
1896936776,18240,jsancio,2024-12-24T19:39:06Z,this code only have one caller. how about just manually inline it at the call site.,0,0.9867826700210571
1896939688,18240,jsancio,2024-12-24T19:47:01Z,same here. let's fix the indentation since you are already changing this part of the code.,0,0.9876699447631836
1896941400,18240,jsancio,2024-12-24T19:52:07Z,i think this is too relax. the previous code assumed that if `leaderid.ispresent()` then `!leaderendpoints.isempty()`. that should not change in this pr.,0,0.9516141414642334
1896944012,18240,jsancio,2024-12-24T20:00:05Z,when would raft hit this case?,0,0.978276789188385
1896944517,18240,jsancio,2024-12-24T20:01:45Z,"minor but you can just inline the expression: `quorum.isprospective()`. also, the call site that calls this knows the `nomineestate` so it can use that information to determine if the request is a prevote request. no need to query `quorumstate` for this information. for example, you can add `isprevote` to the `nomineestate` interface and update the signature of this method to `buildvoterequest(replicakey, boolean)`.",0,0.9793810248374939
1896952514,18240,jsancio,2024-12-24T20:29:38Z,this handle when the majority of the voters rejected the candidate. this needs to also handle when the majority of the voters reject the prospective candidate.,0,0.983670711517334
1896953461,18240,jsancio,2024-12-24T20:33:17Z,this code shouldn't check `isvoterejected` if it is handled in `handlevoterespose`. i left a comment about this in that method. this is an event driven programming model. the event that cause the majority of the voters to reject the prospective state is received in the vote response. and not when polling the prospective state.,0,0.9810855388641357
1896955782,18240,jsancio,2024-12-24T20:40:24Z,i see. retries is only preserved when the prospective transition from prospective to candidate. the retries are lost if it transitions to unattached. i think we should file a jira to remove this exponential backoff. i am convinced that it is starting to lose its value with this implementation and if we make the election timeout improvements you highlight in the kip,0,0.8396039605140686
1896957160,18240,jsancio,2024-12-24T20:44:47Z,let's also include the epoch election and add a `tostring` method to the `epochelection` type.,0,0.9886291027069092
1896957660,18240,jsancio,2024-12-24T20:46:39Z,let's write a comment explaining why this expression is needed.,0,0.9807707667350769
1896958513,18240,jsancio,2024-12-24T20:49:40Z,should this check that the epoch is not decreasing?,0,0.9812167286872864
1896958745,18240,jsancio,2024-12-24T20:50:28Z,let's fix this formatting. [code block],0,0.9880267381668091
1896958960,18240,jsancio,2024-12-24T20:51:19Z,this should check that the epoch is not decreasing.,0,0.979714572429657
1896959037,18240,jsancio,2024-12-24T20:51:36Z,fix formatting.,0,0.9854978322982788
1896960167,18240,jsancio,2024-12-24T20:55:06Z,how about this formatting: [code block],0,0.9860471487045288
1896961481,18240,jsancio,2024-12-24T21:00:19Z,let's add a java doc comment to this method.,0,0.98876953125
1896962158,18240,jsancio,2024-12-24T21:02:46Z,let's undo this change. it is good to keep the existing invariant to avoid persisting both `leaderid` and `votedkey`.,0,0.9384846091270447
1896962727,18240,jsancio,2024-12-24T21:04:56Z,let's add a `tostring` method to this type so that its value is included in log messages.,0,0.9889947772026062
1896962935,18240,jsancio,2024-12-24T21:05:52Z,this is a publicly visible change. let's update the kip if it doesn't include this change.,0,0.9873484373092651
1897006321,18240,ahuang98,2024-12-25T00:07:15Z,"this method is solely for the case of adding voted state to unattached in the same epoch (if higher epoch, we take the path of transitiontounattached) the transitiontounattached method has the following comment, i will duplicate it for this method too [code block]",0,0.9881616234779358
1897013977,18240,ahuang98,2024-12-25T00:36:05Z,"i think i had convinced myself this was arguably not an invariant since it is not enforced (and perhaps just an unintentional quality of kraft today). i know we chatted earlier about how kraftversion=2 should enforce that both votedkey and leaderid are persisted if they exist, which i agree with. i guess what we're not on the same page about is if we can start to persist all the information we have, now. i would argue it is fine to do now because it is backwards compatible, the additional info isn't necessary for correctness, and losing that additional information also doesn't affect correctness (e.g. currently, if unattached with leaderid grants a standard vote, it transition to unattachedvoted w/o leaderid. unattachedvoted w/o leaderid and unattachedvoted w/ leaderid behave the same way in rejecting votes. if unattached has both leaderid and votedkey in electionstate and then downgrades, it would only retain the votedkey and transition to unattachedvoted w/o leader, which is the same transition that would have been taken in the past for an unattached w/ leaderid that grants a vote)",0,0.7192498445510864
1897014715,18240,ahuang98,2024-12-25T00:39:01Z,"retaining both leaderid and votedkey also can help other replicas find the leader faster (though not needed for correctness) - unattachedvoted w/ leader will reject vote requests w/ a leaderid unattachedvoted w/o leader will reject vote request w/o a leaderid if we only persist one, then on startup a replica just doesn't have all the information it _could_ have",0,0.9802185297012329
1899044657,18240,ahuang98,2024-12-29T01:12:26Z,fixed. i added this because i thought it was an oversight not to check for empty endpoints given that we can initialize in unattachedstate when the leaderendpoints are not known. but i see now that `maybetransition` is only called in places where the leaderendpoints are expected to be populated,0,0.9779677391052246
1899071006,18240,ahuang98,2024-12-29T06:28:07Z,fixed,0,0.975196123123169
1899072269,18240,ahuang98,2024-12-29T06:41:32Z,we can use this jira to track - [a link],0,0.9874271154403687
1899074255,18240,ahuang98,2024-12-29T06:59:55Z,i could also remove `epoch` as one of the params (method can use state.currentepoch instead of parameter value). but i would prefer to keep `epoch` as a param so we can validate the method is being used correctly (without any unintentional epoch change).,0,0.9890311360359192
1899074463,18240,ahuang98,2024-12-29T07:01:25Z,"same as above, this is meant to be called only to transition from prospectivenotvoted in epoch x to prospectivevoted in epoch x",0,0.9880571365356445
1899076157,18240,ahuang98,2024-12-29T07:16:33Z,"this is called within the third level of a conditional statement, adding this back violates checkstyle's cyclomatic complexity check",0,0.9791324734687805
1899077542,18240,ahuang98,2024-12-29T07:27:49Z,"for now, i've kept the helper but increased its scope to handle the case when prospective loses the election. i've renamed it as `maybehandleelectionloss`",0,0.9734899997711182
1899341945,18240,ahuang98,2024-12-30T07:39:52Z,"the existing raft event simulation tests picked up on a new bug in pollresigned - if we simply replace the transitiontocandidate(currenttimems) with transitiontoprospective(currenttimems), a cordoned leader in epoch 5 could resign in epoch 5, transition to prospective in epoch 5 (with leaderid=localid), fail election and then attempt to become follower of itself in epoch 5. so far, these are the alternatives which seem reasonable to me: - resigned voter in epoch x should transition to prospective in epoch x+1 - cons: need to create a special code path just for this case to allow becoming prospective in epoch+1 (would also add trivial complexity for determining if votedkey or leaderid should be kept from prior transition). transitioning to prospective in epoch + 1 is almost as disruptive as transitioning directly to candidate since it involves an epoch bump - pro: probably the option which follows intentions of past logic most closely - resigned voter in epoch x should simply transition to unattached in epoch x+1 (current version) - con: resigned replica has to wait two election timeouts after resignation to become prospective - pro: simplified logic. unless this is the only replica eligible for leadership in the quorum (e.g. due to network partitioning), the impact of waiting two election timeouts after resignation is small - all other replicas should be starting their own elections within a single fetch timeout/election timeout - resigned voter in epoch x instead waits a smaller backofftimems before transitioning to unattached in epoch x+1 - con: scope creep - what should this backoff be? additional changes to resignedstate - pro: resigned voter waits less time before becoming eligible to start a new election.",0,0.8614853024482727
1899579689,18240,jsancio,2024-12-30T14:26:34Z,yes. this is correct. observers can vote for candidate (kip-853) and prospective (kip-996). this was changed as part of kip-853 as documented [a link].,0,0.9818978905677795
1899610803,18240,jsancio,2024-12-30T15:11:33Z,"got it. thanks. i see now that kraft doesn't check if both the leader and voted field are set during iniialization. during initialization, it does check the voted field first before checking the leader field. i think we should switch that order. if the leader and the leader endpoints are known, the replica should transition to follower immediately instead of needing to rediscover the leader. let's change this comment too as it is slightly inaccurate. there are many reason why the replica may not send the leader endpoints. using an old version for the rpc is not the only reason why the replica may send the leader id but not the leader endpoint: [code block]",1,0.9343874454498291
1899633981,18240,jsancio,2024-12-30T15:47:39Z,what is the exact error? let's add an unittest to one of the `kafkaraftclient*test` suite that shows the bug. let's add a check to `transtitiontofollower` that checks that `leaderid` is not equal to `localid`. it makes sense to me that after the resign state the replica should always increase its epoch. the replica resigned from leadership at epoch x so eventually the epoch will be at least x + 1. did you consider transitioning to candidate and relaxing the transition functions to allow both resigned and prospective to transition to candidate?,0,0.9779466390609741
1899726228,18240,ahuang98,2024-12-30T18:37:26Z,"discussed offline, transitiontounattached has existing logic for assigning election timeouts which we can borrow - we can just add an additional if clause that if we came from resignedstate, assign electiontimeout to resignedstate.electiontimeout which is effectively 0",0,0.9877086877822876
1899726857,18240,ahuang98,2024-12-30T18:38:54Z,discussed offline that this method is only used for adding voted state to unattached (in same epoch),0,0.9865574240684509
1899727021,18240,ahuang98,2024-12-30T18:39:15Z,discussed offline,0,0.9774469137191772
1899773951,18240,jsancio,2024-12-30T20:22:57Z,sounds good to keep the epoch parameter and validating it against the current epoch.,1,0.6613116264343262
1899778973,18240,jsancio,2024-12-30T20:34:54Z,let's add an else case and throw an illegal state exception.,0,0.9469269514083862
1899780274,18240,jsancio,2024-12-30T20:38:21Z,"how about passing the `nomineestate` object, checking the subtype of that object and casting to the appropriate subtype.",0,0.9859724044799805
1899782793,18240,jsancio,2024-12-30T20:44:33Z,how about just printing the entire `epochelection`? it may be useful to know the state of the entire voter set not just the rejecting voters.,0,0.9877172112464905
1899783114,18240,jsancio,2024-12-30T20:45:25Z,how about just printing the entire `epochelection`? it may be useful to know the state of the entire voter set not just the rejecting voters.,0,0.9877172112464905
1899783839,18240,jsancio,2024-12-30T20:47:12Z,"i think you can join these lines. if not, there should be a newline before `);`",0,0.6117401719093323
1899783973,18240,jsancio,2024-12-30T20:47:36Z,add a newline before `);`.,0,0.9690071940422058
1899785061,18240,jsancio,2024-12-30T20:50:11Z,remove this line. let's not have commented code.,0,0.891923725605011
1899785505,18240,jsancio,2024-12-30T20:51:24Z,let add a comment that summarizes our discussion and conclusion. it is good to document and explain this decision.,1,0.5206741690635681
1899790092,18240,jsancio,2024-12-30T21:03:06Z,"as we discussed offline, the resigned state also transitions to unattached with a greater epoch. let's document that. having said that, let's also update the comment at the top of this file that documents the transitions from resigned: let's also update the kip.",0,0.9846563935279846
1899791694,18240,jsancio,2024-12-30T21:07:39Z,missing new line between these two lines.,0,0.8045743703842163
1900259204,18240,jsancio,2024-12-31T20:30:38Z,let's keep the previous pattern of using static methods to construct `electionstate`. you can add `optional ` parameter to `withelectedleader`.,0,0.9886893630027771
1900264788,18240,jsancio,2024-12-31T20:55:16Z,"why do you need to call `maybefireleaaderchange`? based on the inputs and since prospective doesn't increase the epoch, i would assume that the leader and epoch doesn't change when transitioning to prospective.",0,0.9775400161743164
1900278415,18240,jsancio,2024-12-31T22:01:43Z,"`quorumstate` already logs all transitions. it logs the ""from"" and ""to"" state. not sure this add any information.",0,0.917460560798645
1900278536,18240,jsancio,2024-12-31T22:02:33Z,same here. quorumstate already logs all state transitions.,0,0.9888908863067627
1900279911,18240,jsancio,2024-12-31T22:09:59Z,"transitioning to prospective is not really a durable transition since no persisted data should have changed, right? you can see this is the case since the function `transitiontoprospective` doesn't take any inputs and it doesn't increase the epoch. in other words, the information that is persisted is information that quorum state already knows and has already been persisted.",0,0.9766744375228882
1900448685,18240,jsancio,2025-01-01T19:17:21Z,"you don't need this method, right? this method is declared by `epochstate`.",0,0.9882704019546509
1900449219,18240,jsancio,2025-01-01T19:22:56Z,can you remove this if it is not needed anymore?,0,0.9857842326164246
1900449269,18240,jsancio,2025-01-01T19:23:30Z,can you remove this if it is not needed?,0,0.9863578081130981
1900451851,18240,jsancio,2025-01-01T19:45:23Z,offline you mentioned that you added this because you didn't want to lose information when transitioning states. i agree with this goal but the voted key is lost when the replica transitions to the `leaderstate`. do you agree? if so can you file a jira to fix this after this pr.,0,0.9738562703132629
1900452510,18240,jsancio,2025-01-01T19:50:09Z,minor but let's just remove the `=` sign. [code block],0,0.9887918829917908
1900453595,18240,jsancio,2025-01-01T19:59:59Z,state transition changes are already logged at `info` level.,0,0.9896019101142883
1900455665,18240,jsancio,2025-01-01T20:18:33Z,"isn't this the same [code block] if so, you can remove the variable `retainvotedkey`. similar to the unattached implementation, let's document why this is done.",0,0.9883959293365479
1900458506,18240,jsancio,2025-01-01T20:42:39Z,"you should be able to remove the check for if it is the only voter by making that case transition to prospective instead. when the replica transitions to prospective, it already short-circuits that transition. when the replica transitions to prospective it checks if it can immediately transition to candidate.",0,0.9875712394714355
1900460957,18240,jsancio,2025-01-01T21:04:44Z,looks like this doesn't need to be public. looks like this method can be removed since it is not used.,0,0.9782896637916565
1900461371,18240,jsancio,2025-01-01T21:08:36Z,why not just print the map? [code block],0,0.98396897315979
1900540449,18240,ahuang98,2025-01-02T04:59:01Z,"it felt redundant to print the keys given that the replica ids are also contained in the values. since this is would only be used for debugging though, i'll take your suggestion and just print the entire map",0,0.7544655799865723
1900541138,18240,ahuang98,2025-01-02T05:01:16Z,"replicakey's tostring method contains the class name so i didn't want to be redundant - `string.format(""replicakey(id=%d, directoryid=%s)"", id, directoryid);`",0,0.9861283302307129
1900546362,18240,ahuang98,2025-01-02T05:17:15Z,like the following? [code block] is the intention of the additional parameter to make it clear this method should be called on nomineestate? this seems a bit redundant with the existing quorumstate helpers (e.g. iscandidate() and candidatestateorthrow()).,0,0.9821792244911194
1900571487,18240,ahuang98,2025-01-02T06:24:14Z,i'll also change prospective and unattached's election() to use the static methods.,0,0.9859666228294373
1900580715,18240,ahuang98,2025-01-02T06:46:34Z,replacing with code comments instead,0,0.9740603566169739
1900583997,18240,ahuang98,2025-01-02T06:54:06Z,:exploding_head:,-1,0.9716804623603821
1900614259,18240,ahuang98,2025-01-02T07:53:35Z,thanks! i'll add the logic for short-circuiting transitions for only-voters. this also allows our invariant - only prospective can transition to candidate - to remain simple w/o edge cases.,1,0.97322016954422
1900648700,18240,ahuang98,2025-01-02T08:43:45Z,are you perhaps confusing `epochelection` with `electionstate` (the latter is what epochstate has declared),0,0.9544535279273987
1900951176,18240,jsancio,2025-01-02T14:48:09Z,"if the quorum has a size of one and since the replica votes for itself when transitioning to prospective, `isvotegranted()` should always return true. if so, the replica doesn't need to check if it is the only voter. let's confirm we have a test for this in kafkaraftclienttest. if not, let's add a test. let's also confirm that we have a test for this in prospectivestatetest and candidatestatetest. if not, let's add tests for these cases.",0,0.979339063167572
1900954282,18240,jsancio,2025-01-02T14:51:23Z,why do you check that is not leader? in kraft a replica should never start as a leader. kraft throws and illegal state exception if it starts as leader. see line 545 above. [code block],0,0.978976309299469
1901113187,18240,jsancio,2025-01-02T17:43:07Z,yes. we discussed this offline.,0,0.9776909351348877
1901117479,18240,ahuang98,2025-01-02T17:48:39Z,discussed,0,0.974078357219696
1901142655,18240,ahuang98,2025-01-02T18:17:36Z,"discussed offline, technically the replica can transition to leader due to the above conditional. we can improve this conditional by directly checking if the replica is unattached or follower, and merge this conditional into the above conditional",0,0.9834438562393188
1901235462,18240,ahuang98,2025-01-02T20:27:29Z,"added four tests for this, starting at `testinitializeasonlyvoterwithemptyelectionstate` confirmed!",0,0.9820581078529358
1902113084,18240,ahuang98,2025-01-03T19:49:45Z,"i've organized quorumstatetest in the following way - misc tests were pulled to the front. all other tests are organized under banners (e.g. initialization tests, tests of transitions from state x)",0,0.9862874150276184
1902114352,18240,ahuang98,2025-01-03T19:51:26Z,the diff is misleading here. this test was just removed because i found it was a duplicate of `testinitializeasresignedleaderfromstatestore`,0,0.7836194634437561
1902116235,18240,ahuang98,2025-01-03T19:54:13Z,the hw drops to -1l after candidate transitions to leader - if you agree this is a bug i'll file a jira for this,0,0.9576888084411621
1915345255,18240,jsancio,2025-01-14T17:48:56Z,this feels like it needs a comment explaining what and why.,0,0.8194288015365601
1915429555,18240,ahuang98,2025-01-14T18:45:41Z,clobbered `unattachedstatewithvotetest.java` into `unattachedstatetest.java`. i didn't think it was necessary to have a separate file (both having votedkey state and leaderid state are tested in this one file). i wanted to prevent introducing a separate withvotetest for prospectivestate as well,0,0.9470536112785339
1916914867,18240,jsancio,2025-01-15T15:55:11Z,okay. i went through all of the possible combination of quorum state and this change seem to be backward compatible and correct.,0,0.9794225096702576
1917004191,18240,jsancio,2025-01-15T16:43:54Z,"please make sure that all of the constructors delegate to this constructor. there is at least one constructor (`this(optionalint, uuid)`) that doesn't delegate construction to this constructor. that may mean that the tests should not specify the voters through the constructor but instead use the `with...` methods. in general the `builder` constructor should be as small as possible and the user can override the configuration using the builder's methods before calling `build()`. i think that means that ideally we should delete this method or it should have this signature: `builder(replicakey)`.",0,0.9769476652145386
1917022963,18240,jsancio,2025-01-15T16:55:41Z,can we avoid this? can we let the caller makes this decision? it is technically possible for the replicas to support new rpc (protocols) but their voter configuration to be static.,0,0.9849062561988831
1917031492,18240,jsancio,2025-01-15T17:00:48Z,let's create a followup jira to remove this method.,0,0.9865072965621948
1917037427,18240,jsancio,2025-01-15T17:05:00Z,"we are very close to being able to remove this method, `initializedasleader`. do you want to do the honor and fix the last remaining test?",0,0.7608654499053955
1917046168,18240,jsancio,2025-01-15T17:11:28Z,please use `electionstae.withelecterdleader`.,0,0.9854511022567749
1917046679,18240,jsancio,2025-01-15T17:11:51Z,did you mean `votedkey`?,0,0.9855715036392212
1917055500,18240,jsancio,2025-01-15T17:16:05Z,this looks like a `static` method. it doesn't use any object fields or methods.,0,0.9858421683311462
1917062525,18240,jsancio,2025-01-15T17:19:48Z,can we use `isreconfigsupported()`? this will break when we add a new kraft.version.,0,0.988344669342041
1917064565,18240,jsancio,2025-01-15T17:21:20Z,should this version check that the `prevote` field is `false`?,0,0.9866827726364136
1917068135,18240,jsancio,2025-01-15T17:24:10Z,hmm. how about having `raftprotocol` implement `voterpcversion()`?,0,0.9875473976135254
1917072892,18240,jsancio,2025-01-15T17:27:47Z,this is too relax. it should return 0 only for kip_595_protocol and throw an illegal argument/state exception for the `else` case.,0,0.9330319166183472
1917074839,18240,jsancio,2025-01-15T17:29:18Z,do you want to update the exception messages to reference `withraftprotocol` instead?,0,0.9887220859527588
1917096432,18240,jsancio,2025-01-15T17:44:56Z,do you need this since you are using begin_quorum_epoch to propagate the leader and epoch.,0,0.9881560802459717
1917097458,18240,jsancio,2025-01-15T17:45:46Z,the prospective candidate is the same as the leader. was this done on purpose?,0,0.9832664728164673
1917114855,18240,jsancio,2025-01-15T17:57:18Z,is there a reason why you used 2 instead of 1 (like the other cases) for the leo?,0,0.9811143279075623
1917116456,18240,jsancio,2025-01-15T17:58:37Z,same here. why was the leo changed to 2 in this case?,0,0.984715461730957
1917117528,18240,jsancio,2025-01-15T17:59:30Z,same here. why was the leo changed to 2 in this case?,0,0.984715461730957
1917136327,18240,jsancio,2025-01-15T18:12:05Z,"i see. this actually depends on the kraft.version. for kraft.version 1 the local log will have an leo of 3 (leader change message, kraft version record and voter set record). for kraft.version 0 the local log will have an leo of 1, no?",0,0.9703741669654846
1917149169,18240,jsancio,2025-01-15T18:20:32Z,is it intentional that this response has a leader for the epoch but the other one does not?,0,0.9421637058258057
1917155747,18240,jsancio,2025-01-15T18:24:30Z,interesting that unattached waits for election timeout to transition to prospective while follower waits for fetch timeout to transition to prospective. it is okay for now but maybe they should both wait for fetch timeout since unattached now sends fetch requests.,0,0.8770253658294678
1917168666,18240,jsancio,2025-01-15T18:35:32Z,"you can just call `polluntilrequest` since it calls poll at least once, no?",0,0.988114595413208
1917177912,18240,jsancio,2025-01-15T18:43:51Z,the most informative comparison in case of a failures is: [code block],0,0.9833327531814575
1917185173,18240,jsancio,2025-01-15T18:49:48Z,does it need to sleep for 1 ms? why? is calling `poll` enough?,0,0.9480392932891846
1917187753,18240,jsancio,2025-01-15T18:52:02Z,in other tests you sleep for `electiontimeoutms * 2` why the difference?,0,0.9604040384292603
1917190771,18240,jsancio,2025-01-15T18:54:11Z,same here. is calling poll enough since the remaining time is 0?,0,0.9860462546348572
1917203942,18240,jsancio,2025-01-15T19:04:24Z,"technically possible but it is odd that the replica is using a static voter set, with kip_595_protocol and an elected leader or voted candidate that is not in the voter set. maybe it is less confusing if you limit these tests to kip_853_protocol. minor but technically the protocol configuration is not needed since the replica doesn't need to send or handle rpcs to become leader.",0,0.9650484323501587
1917213839,18240,jsancio,2025-01-15T19:13:37Z,is this used? i couldn't find a caller for this method.,0,0.9388916492462158
1917216983,18240,jsancio,2025-01-15T19:16:37Z,checking the leader is not enough. it should also check that the epoch match.,0,0.5198103785514832
1917220113,18240,jsancio,2025-01-15T19:19:21Z,"let remove the ""todo"". how about: [code block]",0,0.9875774383544922
1917231251,18240,jsancio,2025-01-15T19:29:13Z,how about this formatting: [code block],0,0.9860471487045288
1917235613,18240,jsancio,2025-01-15T19:33:19Z,okay. i think it is fair to file a bug but assign it to yourself or me.,0,0.9759465456008911
1917246184,18240,jsancio,2025-01-15T19:43:16Z,not sure if idempotent is the correct description. i would just call this test: `testconsecutivegrant`.,0,0.9838470816612244
1917246675,18240,jsancio,2025-01-15T19:43:47Z,not sure if idempotent is the correct description. i would just call this test: testconsecutivereject.,0,0.9876279830932617
1917255498,18240,jsancio,2025-01-15T19:52:23Z,what about the non-empty case?,0,0.9790111184120178
1917258238,18240,jsancio,2025-01-15T19:54:56Z,we should have done this in a different pr. it is difficult for me to see what has change and what has move so i have to review almost the entire file.,-1,0.6793413758277893
1917365519,18240,ahuang98,2025-01-15T21:36:42Z,i'll change the other variations of this method to do the same,0,0.9847532510757446
1917376912,18240,ahuang98,2025-01-15T21:46:22Z,"sorry, i wish github was a bit smarter with diffs :( it was difficult for me to figure out what coverage we were missing without the tests being more ordered (and i thought it would be difficult for you to tell what we might be missing as well) so i ended up deciding the re-order was worth it. we discussed this briefly before, but ideally each state will have its own file in the end - i decided not to make that change in this pr since it would make it even harder to tell what had changed.",-1,0.9893649816513062
1917380871,18240,ahuang98,2025-01-15T21:50:33Z,same with all the other `xyzrpcversion()` methods?,0,0.9888351559638977
1917398669,18240,jsancio,2025-01-15T22:08:40Z,you could but i didn't suggest it for the sake of keeping the diff smaller. you can file a jira to fix this if you want.,0,0.9848328232765198
1917398687,18240,ahuang98,2025-01-15T22:08:41Z,"yes, i had considered allocating a different node for local to make its voted candidate, but rationalized that the behavior won't change and that this is also a valid/common state for a follower to be in (votedcandidatekey=leaderid)",0,0.9842907190322876
1917401126,18240,jsancio,2025-01-15T22:11:13Z,i take it back. this implementation is fine if you want to keep it. maybe just make it `else if (raftprotocol.isreconfigsupported()) {`.,0,0.9828692078590393
1917404175,18240,jsancio,2025-01-15T22:14:51Z,"i think i miss spoke. how about moving this out of the constructors and adding a configuration method like `withstartingvoter(voterset, kraftversion)`. the implementation delegates to `withstaticvoters` or `withbootstrapsnapshot`.",-1,0.5031139850616455
1917419710,18240,ahuang98,2025-01-15T22:29:46Z,"hm, can't think of a reason. i'll standardize",0,0.9010828137397766
1917424027,18240,ahuang98,2025-01-15T22:35:05Z,"yep, i decided to just use an leo of 3 for both cases as to not overcomplicate since it's valid for othernodekey to have a larger leo than local anyways. the difference in leo after gaining leadership between kraftversion 0 and 1 is also highlighted and tested in other kafkaraftclienttests which focus more on fetch/offset validation. i'll just add the conditional since it's easy enough",0,0.9538765549659729
1917434854,18240,ahuang98,2025-01-15T22:48:44Z,"yes, it was just for variation (since both could be valid responses)",0,0.9860711693763733
1917454524,18240,ahuang98,2025-01-15T23:10:33Z,i think i wanted to be more explicit with what happens when - i'll replace `polluntilrequest()` with the necessary `poll()` calls,0,0.977992594242096
1917456559,18240,ahuang98,2025-01-15T23:13:38Z,yes!,0,0.8127877116203308
1917459804,18240,ahuang98,2025-01-15T23:17:02Z,"no strong reason, i'll standardize",0,0.8463221192359924
1917512126,18240,ahuang98,2025-01-16T00:38:50Z,"ah, this actually clears the mock send queue (otherwise the following check `raftrequest.outbound fetchrequest = context.assertsentfetchrequest();` fails due to unexpected number of requests in send queue) it works to remove the poll and clear the expected fetch later in the test, so i'll do that instead.",0,0.9867002964019775
1917518120,18240,jsancio,2025-01-16T00:48:53Z,"well, it is good to have self documented test (or code). you can make this connection clear by using the local log end offset if you expect the logs to match. e.g. `context.log.endoffset()`.",0,0.8731681704521179
1917525983,18240,jsancio,2025-01-16T01:01:45Z,missing newline between parenthesis: [code block],0,0.9619703888893127
1917526225,18240,jsancio,2025-01-16T01:02:10Z,missing newline between parenthesis: [code block],0,0.9619703888893127
1917526506,18240,ahuang98,2025-01-16T01:02:35Z,"i introduced this constructor to remove some of the redundancy and conditionals i was seeing with test parameterization. factoring in your next comment as well, maybe it makes more sense to remove this constructor and have a helper method do something similar instead in kafkaraftclientprevotetest.",0,0.9860095977783203
1917539718,18240,ahuang98,2025-01-16T01:25:06Z,i missed your last response with your suggestion about `withstartingvoter`. i'll leave this as is for now and we can discuss tomorrow,-1,0.5294954180717468
1918724919,18240,jsancio,2025-01-16T15:06:33Z,can we make this an annotation that suppresses that check?,0,0.9859659075737
1918748224,18240,jsancio,2025-01-16T15:20:38Z,given this implementation it is also correct to just store it as `endpoints leaderendpoints` and changing the constructor to accept an `endpoints` instead of an `optional `. it looks like in the raft module we never use `optional ` since `endpoints.empty()` is a valid value.,0,0.9879606366157532
1918750392,18240,jsancio,2025-01-16T15:22:06Z,this type doesn't write any log messages. we don't need to pass the log context to the object.,0,0.9869168996810913
1918761915,18240,jsancio,2025-01-16T15:29:05Z,i think we use this formatting in this case: [code block],0,0.9867429733276367
1918763846,18240,jsancio,2025-01-16T15:30:18Z,okay but i would like us to standardize on using `string.format`. i think his should be formatted as: [code block],0,0.9553003311157227
1918795087,18240,jsancio,2025-01-16T15:50:02Z,some code duplication can be removed with: [code block] or [code block],0,0.9877849817276001
1918812401,18240,jsancio,2025-01-16T16:01:09Z,"why would the replica send another request since it already sent a request [a link]? or is the issue that the replica change state from unattached (with voted) to follower [a link] and reset its connection and request manager? which means that it will send another fetch request when it becomes a follower? if this is the case, maybe the test structure you had earlier is better where you assert a fetch request is sent while in the unattached stated.",0,0.9855857491493225
1918822107,18240,jsancio,2025-01-16T16:07:41Z,let's use this formatting: [code block],0,0.9872985482215881
1918823415,18240,jsancio,2025-01-16T16:08:31Z,missing newline character. [code block],0,0.9558499455451965
1918831481,18240,jsancio,2025-01-16T16:13:56Z,let's use this formatting: [code block],0,0.9872985482215881
1918838919,18240,jsancio,2025-01-16T16:19:08Z,if just one of the voter doesn't support pre-vote this replica needs to transition to candidate. that because that voter that doesn't support pre-vote may be need to establish quorum with the majority. i would change this working to: [code block],0,0.9743196964263916
1918852989,18240,jsancio,2025-01-16T16:28:12Z,"fyi, this shows the issue you highlighted in the metrics test. the known hwm is lost when transitioning to leader. this is odd from the client's (users of raftclient) point of view. this semantic turns out to be correct because the new hwm established by the leader is guarantee to be greater than the previous hwm. this is true because the leader first commits the current epoch before establishing the new hwm.",0,0.9814620018005371
1918931718,18240,ahuang98,2025-01-16T17:24:19Z,it's needed for `unattachedorprospectivecangrantvote`,0,0.9853841662406921
1918935598,18240,ahuang98,2025-01-16T17:27:18Z,i'll convert,0,0.98455411195755
1918980033,18240,ahuang98,2025-01-16T18:02:58Z,"english is hard :face_with_tongue: i meant ""not the entire quorum"" vs ""entire quorum does not""",-1,0.8042286038398743
1918980139,18240,ahuang98,2025-01-16T18:03:04Z,i'll add more details to the jira - we can decide if it's worth changing this behavior,0,0.9787939786911011
1919002962,18240,ahuang98,2025-01-16T18:22:42Z,"locally, checkstyle seems to take issue w/ this particular check. i'll give it a shot and see if it builds w/ ci",0,0.9852108359336853
1919024139,18240,ahuang98,2025-01-16T18:40:17Z,"ci doesn't like the change either :( [code block] i recall spending some time trying to debug the issue, and the potential fix (suppressioncommentfilter) seemed a bit more work than it was worth javancss is mentioned in the existing jira for addressing these raft suppressions though - [a link]",-1,0.9738054871559143
1919031445,18240,jsancio,2025-01-16T18:45:36Z,got it. thanks.,1,0.9481641054153442
92508146,2244,mjsax,2016-12-14T22:49:16Z,nit: either `kafka streams` or `{ kafkastreams}` (more ofter farther down),0,0.9873160123825073
92508580,2244,mjsax,2016-12-14T22:51:46Z,nit: `{ org.apache.kafka.streams.state.readonlykeyvaluestore readonlykeyvaluestore}` applies to all links with package prefix,0,0.9844618439674377
92508710,2244,mjsax,2016-12-14T22:52:35Z,` ktable`,0,0.980719268321991
92509183,2244,mjsax,2016-12-14T22:55:15Z,"just a view, i.e., it is not materialized in a state store, on top",0,0.9831288456916809
92509708,2244,mjsax,2016-12-14T22:57:47Z,javadoc missing `replicatedtable` -> `globalktable`,0,0.9871615767478943
92509786,2244,mjsax,2016-12-14T22:58:12Z,`table` -> `globalktable`,0,0.9829688668251038
92510046,2244,mjsax,2016-12-14T22:59:34Z,"an exception? seems to align with `ktable` so not part of this pr -- but should we change this and just skip/drop those records? if we apply an aggregation to compute a ktable, we do the same, ie, just dropping those records. so there is an gap between aggregation and join -- even if for aggregation the input is a kstream... nevertheless, we should think about this (\cc )",0,0.9745047688484192
92514204,2244,mjsax,2016-12-14T23:27:03Z,nit. indention.,-1,0.5327291488647461
92514591,2244,mjsax,2016-12-14T23:30:05Z,nit `kstreamglobalktablejoin`,0,0.9825136065483093
92514897,2244,mjsax,2016-12-14T23:32:20Z,"can we unify this with inner class of `kstreamktablejoin` (ie, extract both inner classes and make top level class)? if not, maybe rename to `kstreamglobalktablejoinprocessor`.",0,0.9892191290855408
92515229,2244,mjsax,2016-12-14T23:34:50Z,nit: rename `thejoinprocessor ` ->`ktableglobalktablejoinprocessor`,0,0.9873238801956177
92515479,2244,mjsax,2016-12-14T23:36:32Z,nit: rename `thevaluegettersupplier` -> `ktableglobalktablejoinvaluegettersupplier`,0,0.9850100874900818
92516392,2244,mjsax,2016-12-14T23:44:07Z,i just compared with `ktablektablejoinprocessor` and the logic there is less nested thus easier to read. maybe we can break this down into smaller pieces similar to `ktablektablejoinprocessor`,0,0.9840190410614014
92517207,2244,mjsax,2016-12-14T23:50:10Z,"if we can reuse `ktablektableleftjoinprocessor` why not the inner join processor, too?",0,0.9886487126350403
92517353,2244,mjsax,2016-12-14T23:51:16Z,why renaming?,0,0.8867272138595581
92518822,2244,mjsax,2016-12-15T00:02:57Z,comment does not apply anymore -- nodegroup will never be null now (maybe empty though),0,0.984889030456543
92573799,2244,dguy,2016-12-15T09:41:02Z,"yeah, i think that is a discussion worth having.",0,0.642068088054657
92574547,2244,dguy,2016-12-15T09:45:15Z,"thanks, i'll remember that going forward. you are my javadoc hero ;-)",1,0.9921585321426392
92577752,2244,dguy,2016-12-15T10:03:30Z,looks like a mistake.,-1,0.9498830437660217
92578027,2244,dguy,2016-12-15T10:05:14Z,should be `topicgroupid` is null,0,0.9843095541000366
92583292,2244,dguy,2016-12-15T10:36:26Z,yep - thought i did that already.,0,0.9697609543800354
92712542,2244,mjsax,2016-12-15T22:18:49Z,nit: root -> statestore,0,0.9878657460212708
92712675,2244,mjsax,2016-12-15T22:19:21Z,nit: name -> viewname,0,0.9858449697494507
92713058,2244,mjsax,2016-12-15T22:21:49Z,should we check for `key == null` -- or is this checked before the call already? we should start using assertions... would avoid those questions. (\cc ),0,0.7418708801269531
92714906,2244,mjsax,2016-12-15T22:32:40Z,"state stores are added via an supplier -- a suppliers is not required here, but it might be confusing for users if there are different method signature -- i think we should align both. wdyt?",0,0.9881165027618408
92716639,2244,mjsax,2016-12-15T22:42:58Z,"i am just wondering what abstraction we want to provide at papi level -- we never discussed this in detail -- and it's not part of the kip either. we only talked about globalktable. for globalktable we have the requirement that it is always populated from a source topic. thus, this method mimics this -- but it this a papi concept? should we have a method like this? and if it is a papi concept, should global stores always be used like this? if yes, we might want to drop `addglobalstore(final statestore store)`. not sure about the answers. we should discuss this.",0,0.9152386784553528
92719445,2244,mjsax,2016-12-15T23:00:21Z,"i am still not sure about this design. actually, the global part shout use a singleton pattern. it is kinda weird that we have two `processortopology` ""types"" -- the global one and the regular one. as the kip is still under discussion, we might want to think about this once more. also from an papi vs dsl point of view -- i think, we need a better separation between both and not ""pollute"" papi with dsl concepts.",-1,0.9527103304862976
92719996,2244,mjsax,2016-12-15T23:03:55Z,should we implement singleton pattern here?,0,0.9873207807540894
92720200,2244,mjsax,2016-12-15T23:05:21Z,should we release the lock here?,0,0.9837315082550049
92720829,2244,mjsax,2016-12-15T23:09:57Z,why not `.endoffsets()`? could replace the whole method.,0,0.987251877784729
92723075,2244,mjsax,2016-12-15T23:26:58Z,not strictly required -- only suppresses the log message. is this intended?,0,0.986205518245697
92723476,2244,mjsax,2016-12-15T23:30:19Z,are checkpoint files delete somewhere else? or should be do this here?,0,0.9815202355384827
92726236,2244,mjsax,2016-12-15T23:52:21Z,"as the restore consumer is shared, can we make sure no parallel restore operation messes with global state thread here? applies to the whole class... also -- if we change partitions assignment -- would we need to restore a previous assignment or maybe better just extend the current assignment (instead or replacing it)? or does every ""user"" of the consumer restores its own assignment each time it uses the consumer (this might also imply that doing the assignment in `initialize` is wrong)? btw: how does state recovery work today? single threaded?",0,0.9802226424217224
92773817,2244,dguy,2016-12-16T08:59:13Z,hmm - i'm don't think viewname really describes it any better. the class is already named `keyvaluestorejoinview` - name seems appropriate,0,0.9650554060935974
92773828,2244,dguy,2016-12-16T08:59:20Z,as above,0,0.9783914685249329
92773952,2244,dguy,2016-12-16T09:00:20Z,this is what it is on the interface and is consistent with every other `statestore`,0,0.986262321472168
92774161,2244,dguy,2016-12-16T09:02:15Z,it is worth adding a null check here. though i will probably just return null rather than throwing exceptions etc. i'm not convinced that calling `get(null)` is worthy of raising an exception.,0,0.8858828544616699
92774515,2244,dguy,2016-12-16T09:05:28Z,i don't think we should use a suppler here. we want a single instance of a `statestore` and this shows that intent. a supplier indicates that there may be multiple instances.,0,0.9851491451263428
92774899,2244,dguy,2016-12-16T09:08:42Z,"this is in the kip. anyway, this method has been added so that the joins generated by `globalktables` can be queried etc. as they are just views on top of other `globalktables` they don't have their own source as such. also, from a users point of view - why shouldn't they be able to add a global store of whatever type they like? they might have a pre-populated table or something that they'd like available in all of there processors.",0,0.9840834736824036
92775816,2244,dguy,2016-12-16T09:15:00Z,"i'm not 100% happy with this either, but as you know, the dsl just builds on the papi and the concepts are already mixed. i don't like this, but this is where we are at the moment. i'd much prefer that `kstreambuilder` didn't extend `topologybuilder` - imo there should be another class, lets say `papibuilder` (name sucks), `topologybuilder` becomes package private. `kstreambuilder` and `papibuilder` are standalone classes, they don't inherit from `topologybuilder` they just use it to build the topology. then we have no mixing of dsl and papi concepts at the api layer. anyway, i don't want to do that as part of this task!",-1,0.7594083547592163
92776262,2244,dguy,2016-12-16T09:18:21Z,no. not a fan of singletons at all. we just create a single instance of it.,-1,0.8048794269561768
92777615,2244,dguy,2016-12-16T09:28:09Z,didn't know it existed!,-1,0.8987667560577393
92778385,2244,dguy,2016-12-16T09:33:36Z,it probably should be deleted after it is first loaded. at least that is what we do elsewhere.,0,0.9866986274719238
92780091,2244,dguy,2016-12-16T09:44:14Z,"this consumer is not the restore consumer. it is a consumer just for this thread so it isn't shared at all. there are no parallel operations on it. when the `statestores` are restored, in `globalstatemanagerimpl`, they each `assign` their own partitions, fetch the data up to the hw, then un-assign their partitions. during this process all of the `topicpartition` for global stores are collected and that is what is assigned here. this is the set of partitions we need to consume to keep all global stores up-to-date. yes, recovery of statestores is always single threaded.",0,0.9771977066993713
92882610,2244,mjsax,2016-12-16T20:42:27Z,agreed: this should definitely not be done in this pr! i am just afraid that this pr makes reworking and separating papi and dsl even harder.,-1,0.9873227477073669
92883151,2244,mjsax,2016-12-16T20:46:28Z,hmmm... weird naming. should we rename all?,-1,0.9855712652206421
92883382,2244,mjsax,2016-12-16T20:48:16Z,sounds opinion based :) what's the problem with singletons?,1,0.9307934045791626
92888694,2244,mjsax,2016-12-16T21:24:39Z,"i understand that argument. my point is more about api design -- we break an api pattern and thus reveal something to the user, that you can consider an implementation detail. the user does not care how ofter we do instantiate a store. if i write code for a store, and hand it in, i don't care about it -- i want to same api for regular and global stores. why should i care about the number of instantiation as a user? i personally dislike the whole handing in factories instead of stores from a user perspective completely -- even if i understand why it is necessary for streams. (flink for example has a very nice api for this and it's not a concern there.) as a user, i want to implement a store -- i don't want to bother with a store factory (i don't want to change this pattern because we have good reasons to enforce is, and one more wrapper for the store is an acceptable burden for the user imho). so we educate the user to implement factories and suddenly we change our mind and say -- ""not for global store"".",-1,0.9682612419128418
92889320,2244,mjsax,2016-12-16T21:29:12Z,"understood. but than, we should maybe only keep `addglobalstore(final statestore store)` and remove the second (this) `addglobalstore` method -- it's a dsl concept again -- i understand the ""i don't care, papi legacy"" argument, but everything we introduce in hard to remove later on. we could just add a global store, and do the wiring with a topic in kstreambuilder instead of topologybuilder?",0,0.8922371864318848
92890189,2244,dguy,2016-12-16T21:35:22Z,not in this pr,0,0.9438803195953369
93021658,2244,dguy,2016-12-19T12:24:23Z,everything in software development is opinion based! singletons are ok for simple objects with no dependencies. as soon as you start adding dependencies in to the mix you end up with tightly coupled code. that is hard to test.,0,0.5940187573432922
93022514,2244,dguy,2016-12-19T12:31:19Z,"we could do that if we make some of the fields in `topologybuilder` protected, i.e., so they can be accessed from `kstreambuilder`. i'm not a big fan of doing this, but i agree with your point about making things harder to remove later",0,0.7893926501274109
94648336,2244,mjsax,2017-01-04T19:28:48Z,"i had a discussion about when to set the state to running with and we agreed that it is better to change the state before we start the threads -- can't remember the details of our discussion though. however, i would keep it as is. maybe can elaborate on it.",0,0.944736123085022
94648979,2244,mjsax,2017-01-04T19:32:16Z,"joins with other globalktable got removed, right?",0,0.9853674173355103
94649387,2244,mjsax,2017-01-04T19:34:30Z,nit: better markup would be [code block],0,0.9705451130867004
94650151,2244,mjsax,2017-01-04T19:38:23Z,"weather [or] not seem like c&p error -- would you mind fixing the other typos in all javadocs, too?",0,0.9772411584854126
94650667,2244,mjsax,2017-01-04T19:41:14Z,"remove this paragraph -- we did removed it for other javadocs, too.",0,0.989616870880127
94650786,2244,mjsax,2017-01-04T19:41:51Z,as above,0,0.9783914685249329
94651214,2244,mjsax,2017-01-04T19:44:01Z,"i would prefer to use `gk` (like global key), `gv`, and `rv` (result value) instead of `k1`, `v1`, and `r` to have somewhat more meaningful names instead of numbering. (`rv` is used in other methods, too)",0,0.9866539835929871
94651248,2244,mjsax,2017-01-04T19:44:13Z,as above.,0,0.978552520275116
94675135,2244,mjsax,2017-01-04T22:05:41Z,"should we not do this in ``? if test fails and `` is never executed, next test run might fail.",0,0.9501314759254456
94676111,2244,mjsax,2017-01-04T22:11:28Z,"i think that join result should not depend of other values being null or not. line 102/103 might hit a race condition if global table get altered between both calls. thus we might end up with wrong results imho. not 100% sure, but i think it's worth thinking about it.",0,0.9235149025917053
94676192,2244,mjsax,2017-01-04T22:11:51Z,as above.,0,0.978552520275116
94679715,2244,mjsax,2017-01-04T22:33:41Z,"this test is only sufficient for stream-globaltable join imho, but not for table-globalktable join for which we need to test `null` tombstone input record for ktable input. furthermore, i think we need a test that updates globalktable in the background while processing -- this might be a separate test though (it's about the race condition i mentioned that we should test for).",0,0.9872679114341736
94686399,2244,mjsax,2017-01-04T23:18:45Z,does this test anything that is not already covered by `globalktableintegrationtest` -- or the other way round?,0,0.9877206683158875
94688157,2244,mjsax,2017-01-04T23:32:34Z,"the test behavior is ok, but i think the name is wrong. -> `shouldnotforwardifoldvalueisnull` we should also have one more test, that test if `null` is emitted if `oldvalue != null`",0,0.9017066955566406
94688915,2244,mjsax,2017-01-04T23:38:53Z,i think we should expect `a.newvalue == null` because input `oldvalue != null` -- we cannot know if globaltable was updated in between and thus previous oldvalue might have joined.,0,0.9872072339057922
94689054,2244,mjsax,2017-01-04T23:40:09Z,"imho, this test is redundant with my suggested version of `shouldnotforwardifdeleteandoldkeynotinotherstoreandsendoldvalues`",0,0.9283934831619263
94689208,2244,mjsax,2017-01-04T23:41:40Z,"from my understanding, if old and new value is `null` nothing should be forwarded -- independent of the content of globalktable.",0,0.9819427132606506
94689292,2244,mjsax,2017-01-04T23:42:27Z,i guess similar comments as above apply -- skipping this class for now.,0,0.9836823344230652
94689865,2244,mjsax,2017-01-04T23:47:10Z,we should use `lockexception` instead of `streamsexception` imho.,0,0.9893639087677002
94690456,2244,mjsax,2017-01-04T23:52:15Z,why not just one test for `shouldinitializestatestores` and `shouldreturninitializedstorenames` ? both test the same method.,0,0.9854568839073181
94690596,2244,mjsax,2017-01-04T23:53:24Z,"remove try-catch and fail and add `(expected = illegalargumentexception.class)` (same below) or could `statemanager.initialize(context);` throw `illegalargumentexception`, too?",0,0.9802339673042297
94691732,2244,mjsax,2017-01-05T00:03:39Z,:),1,0.8757086992263794
94692341,2244,mjsax,2017-01-05T00:09:17Z,"nit: ""kaboom!"" ;)",1,0.9763592481613159
94692983,2244,mjsax,2017-01-05T00:15:15Z,should we apply a test timeout to check if `join()` got stuck because it did not stop running on `close()` ?,0,0.9800856709480286
94693136,2244,mjsax,2017-01-05T00:16:40Z,unify `shouldstoprunningwhenclosedbyuser` and `shouldclosestatestoresonclose` ? both do test `close()`,0,0.9867970943450928
94695940,2244,mjsax,2017-01-05T00:43:44Z,isn't this test covering `shouldupdatestatewithreceivedrecordsforpartition` ?,0,0.9862110018730164
94696136,2244,mjsax,2017-01-05T00:45:47Z,unify `shouldflushstorewhenflushintervalhaslapsed` and `shouldnotflushoffsetswhenflushintervalhasnotlapsed` ?,0,0.9867991805076599
94727438,2244,dguy,2017-01-05T08:17:54Z,sure - i'll put it back. didn't really make sense to me to set the state to running before the threads have started. but whatever,0,0.9597170948982239
94728105,2244,dguy,2017-01-05T08:24:48Z,next test wont fail as it will use a different state directory.,0,0.9247373938560486
94729425,2244,dguy,2017-01-05T08:37:42Z,"we should have both tests. they cover some of the same things, but this is much easier to write and debug issues. it runs much quicker. however, it doesn't cover the more end-to-end scenario that the integration tests cover.",0,0.9538586735725403
94730687,2244,dguy,2017-01-05T08:49:00Z,"i don't agree with the name you have suggested, but i also think the name of the test is not completely correct",0,0.6797711849212646
94734155,2244,dguy,2017-01-05T09:15:44Z,"yep. i was thinking that a direct key mapping could result in the join, but that was incorrect.",0,0.9769102334976196
94735025,2244,dguy,2017-01-05T09:22:02Z,"sure, but `lockexception` didn't exist when i wrote this!",0,0.9672834277153015
94735566,2244,dguy,2017-01-05T09:25:54Z,"yes, you could test them both in the same method. however, i prefer to have single focused tests where the test names describe what is happening. there is nothing wrong with having multiple tests for the same method and params, in-fact i'd encourage it.",0,0.9317183494567871
94735880,2244,dguy,2017-01-05T09:28:02Z,"it doesn't now, but it, or something, it uses might in the future. i prefer this approach for these sort of scenarios as it guarantees that the exception was raised from the code i am trying to test",0,0.8417510986328125
94736396,2244,dguy,2017-01-05T09:31:37Z,nope - they are testing different things that happen on close. i prefer it this way as it is easier to just read the test names to see what should be happening rather than have to read through the assertions.,0,0.8613595962524414
94736604,2244,dguy,2017-01-05T09:33:14Z,not quite - this is checking the multiple topic case. the other is just checking a single topic,0,0.9625378847122192
94736696,2244,dguy,2017-01-05T09:33:57Z,see my other comments. this is how i'd prefer to see the tests written,0,0.9813069105148315
94739678,2244,dguy,2017-01-05T09:53:44Z,"the `null` tombstone cases are already covered by `ktableglobalktablejointest` and `ktablektableleftjointest` - i don't think they need to be covered here again. i'm not sure about the background thread. yes there could be a race condition (i've updated the code as suggested below), but i'm not 100% sure how we could/should handle it.",0,0.919245719909668
94823111,2244,mjsax,2017-01-05T18:27:56Z,"if you apply this argument, you can never use `(expected = ...)` as it would apply to all tests using this pattern. wouldn't it?",0,0.978847086429596
94823260,2244,mjsax,2017-01-05T18:28:47Z,"yes. but if multi-topic works, single topic works, too. or not?",0,0.9790462255477905
94829084,2244,mjsax,2017-01-05T19:00:26Z,i just thought about this once more. to me it seems that the race condition is because of sending oldvalues. why do we actually need this? or could we just disable sending old values?,0,0.8243517875671387
94832919,2244,mjsax,2017-01-05T19:22:06Z,"what is the different from this test to `shouldnotsendanythingifchangeisnullnullandkeymapstonullinothertable`? furhtermore, why do you setup a new `ktableglobalktableleftjoin` ? if i did not miss anything, it is the same setup as the global member `join` variable.",0,0.9840861558914185
94919202,2244,dguy,2017-01-06T09:23:13Z,yeah they do look the same. brain fade!,0,0.676529586315155
94919538,2244,dguy,2017-01-06T09:26:11Z,"it is a question of how you write tests. i write tests and code starting from the simplest things and working out from that. so the test for the single topic comes first, and then the test for multiple topics. in this case the test for multiple topics might be enough, but maybe it isn't, maybe the code assume there is always >1 topic? it is good to have both",1,0.7832998633384705
94920231,2244,dguy,2017-01-06T09:32:06Z,"no, i disagree. most tests i'd use `(expected = ....)` in would either have a single method call in them, so you know that is the only method that can throw the exception. or, it would be a `new blah(..)` followed by testing the single method. of course the `new ..` could throw an exception, but hopefully most ctors are side-effect free.",0,0.8888652324676514
94930979,2244,enothereska,2017-01-06T11:01:39Z,"""weather"" typo",0,0.9825154542922974
94931159,2244,enothereska,2017-01-06T11:03:28Z,would be good to be consistent at least with the ktable.,0,0.8763329982757568
94931291,2244,enothereska,2017-01-06T11:04:46Z,currently we always materialize though.,0,0.9811069965362549
94939282,2244,dguy,2017-01-06T12:29:21Z,hmmm - maybe we don't need to get the old value from the other table at all. as in `ktablektableleftjoin` we get the current value from the other table and then if `sendoldvalues` we join `change.oldvalue` with the value from the other table. thoughts?,0,0.9801068305969238
94950774,2244,enothereska,2017-01-06T14:16:25Z,i agree with both of you.,0,0.8958673477172852
94980385,2244,mjsax,2017-01-06T17:04:46Z,"i would not send old value whatsoever -- because of async updates of globalktable we cannot guarantee any semantical meaning -- we might miss multiple update from globalktable and thus, me might send an ""old value"" that was never emitted as ""new value"" before.",0,0.9708976149559021
94981984,2244,dguy,2017-01-06T17:14:29Z,"i've been looking a bit more and i'm still not certain what the correct thing to do in this situation is. we need to send an old value for the subtractors of the aggregators/reducers, but the old value may not be the same value as previously seen. an example that doesn't work properly. [code block] if i initialize g1 with: (1, green) (2, blue) (3, yellow) (4 red) then send to t1 (1, 1) (2, 1) (3, 1) and flush state i get (green, 3) all good so far. however if i then send to g1 (1, orange) and then to t1 (1, 4) and flush state i get (green, 3) (orange, -1) (red, 1) which is obviously incorrect. the oldvalue of green never gets sent so the count for green doesn't reduce by 1, rather the oldvalue is orange, hence orange with a count of -1. hmmmm!",0,0.8158944845199585
95020150,2244,mjsax,2017-01-06T21:06:45Z,"that is exactly what i had in mind with my previous comment... i just thought we might be able to not send the old value at all -- but your example shows that we need to send it. one way to fix it, is to remember the old value on the triggering ktable side (i guess we need another store for this...). thus, instead of looking up old value in globalktable, we look it up the the new store. not sure if there is a better way to do it.",0,0.9249761700630188
95133661,2244,dguy,2017-01-09T10:49:03Z,would appreciate your thoughts on this.,1,0.551830530166626
95287565,2244,guozhangwang,2017-01-10T01:57:06Z,not sure if this interface is usefeul with `processorstatemanager`? should it be in the extended `globalstatemanager` only?,0,0.9836974740028381
95287972,2244,guozhangwang,2017-01-10T02:01:50Z,why we want to maintain an interface of `globalstatemaintainer`? is it because of mocking in unit tests? otherwise its only impl is `globalstateupdatetask`.,0,0.9702736735343933
95288306,2244,guozhangwang,2017-01-10T02:05:03Z,"my gut feeling is that we do not need to mimic a `processortopology` and `internalprocessorcontext` interface for this task, as it is a very special task whose topology will just be a list of source topics and a list of state stores, making them as generic interfaces would just introduce one-time classes like `globalprocessorcontext` in which lots of its functions will not be required at all. instead we can just e.g. pass into it a list of source topics, a map between topics to state stores, etc and let it run its only loop for fetching + updating stores, etc.",-1,0.6039689183235168
95288621,2244,guozhangwang,2017-01-10T02:09:14Z,"the usage of `sourcenodeandserializer` is a bit awkward to me here: we have wrapped the source node in order to get its corresponding deserializer in this class, and we again keep a map from topic name to this deserializer; so why don't we just use a map from topics to deserializer directly?",-1,0.872345507144928
95319354,2244,dguy,2017-01-10T08:42:06Z,it is used by `processorcontextimpl` it is needed on the interface,0,0.9883812069892883
95319810,2244,dguy,2017-01-10T08:44:51Z,"using interfaces is good oo design practice. it facilitates loose coupling, flexibility, better design of roles. yes, it also helps with testing.",1,0.936295211315155
95324378,2244,dguy,2017-01-10T09:16:20Z,"because we need both the sourcenode and the deserializer when we receive data from the topic. i.e., we need to deserialize the data and the `sourcenode` to process it",0,0.9798975586891174
95327582,2244,dguy,2017-01-10T09:35:35Z,"i disagree. firstly it isn't mimicing a `processortoplogy` - it is one! we have various classes in place already that do the the work needed to keep the table up-to-date, i.e, `soucenode` and `ktablesourceprocessor`. they need a `processcontext`. if we don't go down this path then we will be duplicating the code in those classes as we need to do the same thing. further `globalprocessorcontext` is as one-time as `standbycontextimpl`. i don't see any difference here. i also abstracted out all of the common `processorcontext` methods to `abstractprocessorcontext` to avoid having to avoid duplication and implementing of some unnecessary methods.",0,0.6390354633331299
95420343,2244,guozhangwang,2017-01-10T17:56:25Z,"this is a meta comment about `change<>`, not sure if my thoughts are correct: currently we propagate the need to send old values in any aggregate operators back-wards all the way to source nodes: if a ktable aggregate operator is observed it will be propagated to all its ancestors; with materialized results of ktable-ktable join, this propagation can be stopped at such operations. in this case, ktablektablexxjoin do not need to expect a `change<>` at all as it will never need the old value any more. i'm not sure if we can immediately change its type from `change ` to `v`, but i think technically it should be the case.",0,0.93187415599823
95420796,2244,guozhangwang,2017-01-10T17:58:32Z,nit: rename to `globalcontextimpl` to be consistent?,0,0.988944947719574
95422432,2244,guozhangwang,2017-01-10T18:07:24Z,"it is a subjective thing, but i usually find such oo design most useful when the interface is public and the impl has some separate functions to be used in other internal classes (e.g. the refactoring are doing to separate topologybuilder user-facing apis from its internal functions used by `streamthread`, etc). while this class is pure internal we can always just extend / override for testing.",0,0.9745035171508789
95424323,2244,guozhangwang,2017-01-10T18:16:58Z,"okay, make sense.",0,0.9631136059761047
95425307,2244,guozhangwang,2017-01-10T18:22:24Z,"instead of adding this interface, could we let `processorcontextimpl` to contain two `statemanagers`, while `standbycontextimpl` and `globalcontextimpl` each contain one? i know it is an internal interface so maybe it's not that important at all, but just wanted to throw my ideas here.",0,0.9645901322364807
95425732,2244,guozhangwang,2017-01-10T18:24:39Z,this is not about this pr: in #1446 we are removing specific cache sensors since we are adding sensors for generic purposes already. there will be some major conflicts between these two.,0,0.8125551342964172
95428000,2244,enothereska,2017-01-10T18:36:30Z,"there will be a conflict, but hopefully not major.",0,0.8937745690345764
95428041,2244,dguy,2017-01-10T18:36:39Z,yep :-(,-1,0.9729856848716736
95428151,2244,dguy,2017-01-10T18:37:14Z,sure,0,0.9371067881584167
95429909,2244,dguy,2017-01-10T18:45:57Z,i'm not sure i follow. not immediately clear to me how `ktablektablexxjoin` can't expect a `change<>`. that is what is will be sent from the previous `ktablexxxprocessor`,0,0.9111315608024597
95455229,2244,dguy,2017-01-10T20:57:11Z,if we did that i think we'd need another `statemanager` implementation. as we wouldn't want the one used by `processorcontextimpl` to go through the initialization and restoration of global stores.,0,0.9830933809280396
95455897,2244,dguy,2017-01-10T21:01:01Z,we'll have to agree to disagree on this one!,0,0.7273702621459961
95475213,2244,mjsax,2017-01-10T22:44:29Z,created [a link] for this.,0,0.985977292060852
85607023,2074,vahidhashemian,2016-10-28T20:44:23Z,"this is where the bug was introduced. if `state` is `none`, there is a possibility that the old consumer based group does not have any active members; so we need to check whether new consumer is used or not, and then proceed accordingly.",0,0.9822612404823303
85607062,2074,hachikuji,2016-10-28T20:44:33Z,was there a kip for this that i missed?,0,0.8186920881271362
85607674,2074,vahidhashemian,2016-10-28T20:48:28Z,"thanks for bringing this up. i wasn't totally sure what to process is for changing the protocol, and whether i'm actually correct to assume that the protocol has to be changed for this jira. i haven't opened a kip yet, if you think that's eventually going to be needed for i'd be happy to create one. thanks in advance for clarifying this.",1,0.9701971411705017
85608617,2074,hachikuji,2016-10-28T20:54:01Z,"yeah, protocol changes definitely need a kip. probably makes sense then to split the bug fix into a separate patch.",0,0.9837993383407593
85608849,2074,vahidhashemian,2016-10-28T20:55:44Z,"thanks. i'll submit the bug fix separately, and then work on creating a kip.",1,0.9423694610595703
86647580,2074,vahidhashemian,2016-11-04T23:11:13Z,"i was hoping you could take a look at an issue i'm running into if and when you get a chance. while kip-88 is open for discussion i spent some time creating some unit tests for this pr. this particular unit test simply mocks two consumers that consume from the same 1-partition topic and belong to the same consumer group. a similar unit test on old consumers exists earlier in the same file and runs fine. there are also other unit tests above using the new consumer that run fine but they mock only one consumer. the problem i'm running into is this line that mocks the second consumer and takes a long time to run (i believe for the consumer to join the group that eventually times out) and the consumer group gets corrupted somehow. when i debug and check the status of the group down in the `waituntiltrue` check, sometimes it is `empty`, or `dead`, or even `stable` with only one of the consumers and it never gets into the expected state (`stable` with two members). where it gets stuck in a loop i think is [a link] (after [a link]. i'm not sure if i'm doing something wrong with the unit test or if i'm hitting some bug. i thought you might know by just looking at it. thanks.",-1,0.6897097826004028
92458550,2074,hachikuji,2016-12-14T18:34:17Z,nit: the `offsetfetchrequest` suffix seems redundant. how about this `offsetfetchrequest.forallpartitions()`?,0,0.9884047508239746
92458890,2074,hachikuji,2016-12-14T18:36:11Z,"don't we need a null check in the loop above? also, should we return a null array in the response if the requested partitions are null?",0,0.9881340861320496
92459503,2074,hachikuji,2016-12-14T18:39:37Z,one thing i'm realizing is that this schema gives us no way to indicate that a group doesn't exist when you fetch all partitions. that may be ok since we usually know ahead of time whether or not a group _should_ exist (e.g. by using listgroups).,0,0.9698215126991272
92460753,2074,hachikuji,2016-12-14T18:46:06Z,seems like we could do these two lines with a `map` and `getorelse` combo.,0,0.9857601523399353
92461437,2074,hachikuji,2016-12-14T18:49:42Z,this is a little hard to follow. maybe we could create two vals and do the append at the end?,0,0.5655757188796997
92461907,2074,hachikuji,2016-12-14T18:52:02Z,can we cover the error case also for a request for all partitions?,0,0.9890303015708923
92462186,2074,hachikuji,2016-12-14T18:53:15Z,"maybe we can just say ""versions 1 and above""?",0,0.985709547996521
92462799,2074,hachikuji,2016-12-14T18:56:21Z,is the version check necessary?,0,0.9868072867393494
92463197,2074,hachikuji,2016-12-14T18:58:13Z,maybe we could wrap the `some` at the end to remove one level of nesting?,0,0.9884117245674133
92463905,2074,hachikuji,2016-12-14T19:02:05Z,hmm... i don't think we should be accessing the group directly at this layer. it's probably better to either overload `groupcoordinator.handlefetchoffsets` or expose a new method.,0,0.9746600985527039
92468547,2074,vahidhashemian,2016-12-14T19:24:18Z,"sure, that sounds reasonable. i'll update the method name.",0,0.9667425751686096
92477069,2074,hachikuji,2016-12-14T20:01:48Z,"thinking about this a little more.. there is an edge case around coordinator failover. we may lookup the coordinator for some group, find that it is broker a, and then send the offsetfetch for all partitions. before the request arrives, it could happen that broker b becomes the coordinator (it may have already begun the transition even before we did the initial coordinator lookup), but we won't have a way to detect it. this will cause us to mistakenly report that there are no offsets for the group.",0,0.8355604410171509
92478985,2074,vahidhashemian,2016-12-14T20:11:55Z,"yes, i missed that. thanks. i'll try to fix it in the next update.",1,0.9652799367904663
92495078,2074,vahidhashemian,2016-12-14T21:39:40Z,"could you please clarify your first comment above? with this change, i can still see the `error: consumer group '...' does not exist.` message if 1) the consumer group is never created. 2) the consumer group is created but its offsets are all expired. regarding the second comment, are you referring to double `findcoordinator(...)` calls in this use case (through [a link] and [a link]? if so, one improvement would be to somehow preserve the `coordinator` value found in `describeconsumergroup(...)` for use in `listgroupoffsets(...)`. please advise if i misunderstood the issue. thanks.",0,0.9820742011070251
92501254,2074,hachikuji,2016-12-14T22:10:14Z,"the basic issue is that the error codes are in the partition data of the response schema. if we have no partitions to return, then we cannot return any errors either. this is fine for most cases because we should already know if the group exists or not. however, there are (at least) two problematic edge cases: 1. the case i mentioned above. to use the offsetfetch api, we must first lookup the coordinator for the group. it could happen that when we do so, we happen to get a stale coordinator. this is possible because it takes some time for metadata changes to propagate to all the brokers. 2. when the coordinator first is started, it must read through the `__consumer_offsets` topic to populate the offset cache. usually we return a `coordinator_not_available` error in this situation which lets the consumer know it needs to retry a bit later. so if we happen to send an offset fetch for all partitions in either of these cases, then we could mistakenly believe that there are no offsets for the group.",0,0.9682032465934753
92674520,2074,vahidhashemian,2016-12-15T18:52:08Z,"thanks for explaining the issue. if i'm not mistaken, the first edge case (stale coordinator) could occur with the current code too ([a link] that leads to [a link]. so the main issue is that with the current protocol we cannot report error codes when there is no partition in the response. to me the options are 1. making further changes to the protocol to address this issue too. 2. rethinking how to solve the problem of kafka-3853 (with another option than proposed in kip-88). 3. accepting that limitation for now and continue with the current solution. is there another option? which option do you recommend we take?",1,0.8284223675727844
92679066,2074,vahidhashemian,2016-12-15T19:14:10Z,sounds good. i'll refactor the whole block a little bit.,1,0.9176633954048157
92679685,2074,hachikuji,2016-12-15T19:17:13Z,"adding an `error_code` at the top level in the response object seems like the cleanest solution. this error code could be used to communicate group-related errors, which is arguably a bit nicer than writing those errors into all the individual partition data. it's a bit painful to reopen a kip that has passed, but i don't think we can ignore this problem. perhaps send a comment to the kip-88 discussion thread explaining the problem and what you think the best option to fix it is?",-1,0.7051253914833069
92680619,2074,vahidhashemian,2016-12-15T19:21:36Z,sounds good. i'll do that. thanks for your feedback and advice.,1,0.980080246925354
92697405,2074,vahidhashemian,2016-12-15T20:51:52Z,one more question before i re-open the kip. the issue doesn't seem to be a side-effect of the suggested protocol change in kip-88 (we are not modifying the response in kip-88) and it would surface whenever there is no partition in the response. do you think it can be addressed in a separate kip? or i am missing something here?,0,0.9808216094970703
92702988,2074,hachikuji,2016-12-15T21:25:16Z,"i think it is a consequence of the changes to the request from this kip though, right? before we would always have at least one partition in the request, so we always had somewhere to pack an error code in the response. now that's no longer true.",0,0.932863712310791
92706549,2074,vahidhashemian,2016-12-15T21:43:42Z,"ok. i see. thanks. so before, it was guaranteed that whatever partition is in the request will be in the response. with the new protocol we could end up getting back an empty list if the group has no offset data. what about passing an empty array in the request with current protocol? wouldn't this cause the same problem?",1,0.9446293711662292
92707749,2074,hachikuji,2016-12-15T21:50:10Z,"that is true, but the impact is different. if you request offsets for an empty list of partitions, the correct response, regardless of the state of the group or the coordinator, is to return an empty partition list.",0,0.9805323481559753
92710994,2074,vahidhashemian,2016-12-15T22:08:45Z,this makes it clear ( hopefully :) ). thanks a lot. i'll work on that email and updating the kip.,1,0.9897525310516357
92729320,2074,vahidhashemian,2016-12-16T00:21:06Z,"a quick follow-up question: is it possible for the current api to return an offset fetch response with various error codes associated with the partitions? i'm trying to think if we can remove the internal ""error_code"" from the schema. thanks.",1,0.8930596709251404
92730823,2074,hachikuji,2016-12-16T00:35:52Z,"i was wondering about this also. unfortunately, it seems we can't remove the per-partition error code since we do authorization on the topics separately.",0,0.8191778659820557
92861504,2074,vahidhashemian,2016-12-16T18:30:06Z,"i guess not, since in previous versions it's not possible to pass in a null array. thanks.",1,0.9466244578361511
92876208,2074,vahidhashemian,2016-12-16T19:58:21Z,"sure. i think i'll expose a new method (something like `groupcoordinator.getpartitions(groupid)`), since the partitions have to go through authorization check and, after a quick look, i don't see a clean way of overloading `handlefetchoffsets` for this purpose that fits well with how `kafkaapis.handleoffsetfetchrequest` is implemented. unless we want to refactor that method more extensively.",0,0.974486768245697
94959538,2074,ijuma,2017-01-06T15:14:34Z,this should be `kafka_0_10_2_iv0`.,0,0.9875720739364624
94994319,2074,vahidhashemian,2017-01-06T18:30:04Z,thanks for catching this. i'll fix it shortly.,1,0.8759343028068542
95102027,2074,ewencp,2017-01-09T04:36:55Z,"is this still supposed to be included? it's not in the kip (i can't remember if it existed in a previous version.) if it is supposed to be included, presumably it'd be an override of an interface method from `consumer`?",0,0.9861694574356079
95103021,2074,ewencp,2017-01-09T05:08:34Z,style nit: normally we'd use braces around blocks unless they're a single line,0,0.9850012063980103
95103761,2074,ewencp,2017-01-09T05:30:01Z,"aren't you still missing setting the error code field on the struct in this case though? the pattern that seems to be used elsewhere, e.g. in `metadataresponse`, is to make the constructor that takes the version contain all the fields as arguments as well as the version. then all the decoded fields are kept as member variables and written regardless of whether that version contains them, but only written to the struct conditionally. for example, `metadataresponse` has some code that looks like this in its constructor: [code block] (after having constructed the `struct` with the correct schema). i think if the current code is working, it's just lucking out on `none`'s error code being `0` or something. i wouldn't think it would work as is since the field doesn't have a default value defined.",0,0.9847230911254883
95104096,2074,ewencp,2017-01-09T05:38:53Z,"shouldn't some of these change to remove the topic partition data since the v2 version will just include an empty list in that case? also, might be worth checking in on the patch(es) for [a link] to see how this will be impacted. i'd imagine you actually want to test both versions.",0,0.9855164885520935
95104149,2074,ewencp,2017-01-09T05:40:32Z,"since the is specific to v2+, the constructor used doesn't even really need the `responsedata` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `offsetfetchresponse`.",0,0.9885644316673279
95106780,2074,ewencp,2017-01-09T06:43:47Z,comment can be cleaned up,0,0.986609160900116
95106900,2074,ewencp,2017-01-09T06:46:14Z,"also, i noticed when reviewing this that `offsetfetchrequest.handleerror` doesn't use the request version when constructing the `offsetfetchresponse`. this seems broken, but even more so now that the format differs between versions. (strictly speaking i think it was already broken and a strict client could have potentially caught the issue.)",0,0.9301924109458923
95108544,2074,ewencp,2017-01-09T07:10:51Z,"i think you need to be careful about listing unauthorized topics. if `offsetfetchrequest.isallpartitions()` is `true`, then you shouldn't reveal the existence of unauthorized topics. see `handletopicmetadatarequest` for an example of what i mean.",0,0.9795820713043213
95235045,2074,vahidhashemian,2017-01-09T20:06:14Z,thanks for catching this. this method is not required anymore as it's part of rejected alternatives 1 and 2. i'll remove it.,1,0.9404060244560242
95239706,2074,vahidhashemian,2017-01-09T20:32:26Z,that's fair. i can modify the condition of the `if` block before this `switch` statement to skip building `responsedata` for version 2 and beyond.,0,0.9821081757545471
95273042,2074,vahidhashemian,2017-01-09T23:43:03Z,you're right. i'll try to follow a similar pattern for `offsetfetchresponse` in the next update.,0,0.9776198863983154
95294702,2074,vahidhashemian,2017-01-10T03:25:11Z,"i'll update the expected responses as you suggested. regarding supporting both versions it seems that work would conflict with what is being implemented for kip-97. not sure what's the best way to handle it, wait for that to merge first, or move forward with this as is (assuming the latest api version), and then update as part of or after kip-97.",0,0.9532918334007263
95297660,2074,ewencp,2017-01-10T04:10:35Z,"yeah, tbh i wasn't sure either since i hadn't reviewed those patches yet and wasn't sure of the state. i mentioned this to today as well. his thought was that since [a link] (which is actually only 1 of a couple of patches for kip-97) is quite large, it might make sense to get it merged first. we're pretty sure this is the only kip that will potentially be affected by it. has also taken a pass at that one, so if we merge it and you need guidance on updating the patch, he can probably give direction pretty easily. i just checked and there are some minor merge conflicts, but nothing too crazy, so my guess would be that it'd only be a bit more work to layer on the extra bit of compatibility work.",0,0.8009850978851318
95298064,2074,vahidhashemian,2017-01-10T04:17:08Z,sounds good to me. i'll work on the rest of items you found in the meantime that pr gets merged. then we can revisit this piece.,1,0.9621796011924744
95298512,2074,vahidhashemian,2017-01-10T04:24:36Z,another good catch. will try to address this it in the next update.,1,0.9185095429420471
95431126,2074,vahidhashemian,2017-01-10T18:51:35Z,you're right. i'll try to fix this in the next update.,0,0.9376529455184937
95485200,2074,hachikuji,2017-01-10T23:54:00Z,kind of annoying that the response doesn't give us an instance of `errors` directly.,-1,0.9726718664169312
95485372,2074,hachikuji,2017-01-10T23:55:28Z,comment is out of date.,0,0.6755028367042542
95488199,2074,hachikuji,2017-01-11T00:17:09Z,nit: not really sure we need two separate constants even though they are separate fields in the struct.,0,0.9140563011169434
95488264,2074,hachikuji,2017-01-11T00:17:48Z,perhaps useful to break down which of these are partition errors?,0,0.9818675518035889
95489296,2074,hachikuji,2017-01-11T00:26:36Z,"this will be a little annoying to handle when we incorporate the client compatibility kip since we'll have to check for the presence of these errors at both levels. one option might be to enhance the parsing of the response to check for the presence of one of the top-level errors in the partition data. if it is there, we could insert it at the top level as well. currently i think we just put `errors.none` at the top level for old versions.",-1,0.7601091861724854
95491518,2074,hachikuji,2017-01-11T00:45:18Z,"couldn't we push this logic into the response constructor? perhaps if the version is equal to 1, we take the top level error code and insert it into the partition data?",0,0.9849851131439209
95497258,2074,vahidhashemian,2017-01-11T01:40:34Z,i'll add a method to `offsetfetchresponse` that returns the actual `errors` value.,0,0.9882498979568481
95497341,2074,vahidhashemian,2017-01-11T01:41:27Z,no problem. i'll use the same constant.,0,0.9620782136917114
95498385,2074,vahidhashemian,2017-01-11T01:52:46Z,"sure, i also used a constant below this comment to define and use that in the code.",0,0.9892822504043579
95501741,2074,vahidhashemian,2017-01-11T02:24:15Z,sure. and i think it would be safe to insert one top level error in case there are more than one.,0,0.9668435454368591
95650676,2074,vahidhashemian,2017-01-11T19:20:32Z,"i think i'm missing something here. we are already iterating over all partitions here (for version 1) and injecting the proper error code. if we want to do the injection in `offsetfetchresponse` constructor, we need to iteration over them again, which wouldn't be very efficient. could you please clarify? thanks.",0,0.7027802467346191
95652522,2074,hachikuji,2017-01-11T19:29:38Z,"mainly what i'm trying to achieve is keeping version handling logic out of `groupcoordinator` as much as possible. so what i had in mind is a constructor or a factory which accepts a top-level error code and a list of the partitions. in the case of the old version, we take the top-level error code and override the partition-level errors. in the case of the new version, we can ignore the partition data and just return the top-level error code.",0,0.9680842757225037
95659959,2074,vahidhashemian,2017-01-11T20:04:47Z,thanks for clarifying. so the signature of this `groupcoordinator` method would likely need to be modified to return a `offsetfetchresponse` instance.,1,0.8077831864356995
95660614,2074,hachikuji,2017-01-11T20:07:41Z,true. i'm not sure that's better or worse. it doesn't seem too bad given that we already return `offsetfetchresponse.partitiondata` though.,0,0.9008284211158752
95669374,2074,vahidhashemian,2017-01-11T20:52:43Z,"yes, the only thing is after building the offset response here we'll have to later add response data for unauthorized topics.",0,0.9391008019447327
95672186,2074,hachikuji,2017-01-11T21:08:28Z,"good point... one option that comes to mind is to use exceptions to propagate top-level errors. this would rely on `offsetfetchrequest.geterrorresponse` to build the response. but we don't do that for any of the other coordinator apis, so i'd rather not make this case exceptional. so how about this: in addition to returning the top-level error code directly in the tuple, we also use it to fill the partition-level error code. then we don't need to pass the version into `groupcoordinator` at all and we can let the handler in `kafkaapis` decide how to do the serialization. basically if the top-level error code is not none, then ignore the partitions.",1,0.6237092018127441
95672359,2074,hachikuji,2017-01-11T21:09:24Z,can we use `errors` instead of `short` in the return type?,0,0.9873791337013245
95673432,2074,hachikuji,2017-01-11T21:15:04Z,"or perhaps even simpler: we could always return the error code and an empty map, and we could let `kafkaapis` expand the error code into the partition data when required by the fetch version?",0,0.988338828086853
95677478,2074,vahidhashemian,2017-01-11T21:36:08Z,thanks. i also like your last suggestion.,1,0.9504223465919495
95700427,2074,hachikuji,2017-01-11T23:58:36Z,could we just use `errors` throughout? you can always get the code from `errors` if you really need it.,0,0.988404393196106
95719434,2074,hachikuji,2017-01-12T03:17:37Z,i wonder if we ought to just assume that the error goes at the top-level. it's a little weird to receive a partition-specific error code here and then assume that it should be used for _all_ partitions.,-1,0.9671502709388733
95719458,2074,hachikuji,2017-01-12T03:18:01Z,"this is `errorcodethrown`, right?",0,0.9850262999534607
95719646,2074,hachikuji,2017-01-12T03:20:34Z,maybe we can remove this and force the use of `error()`?,0,0.9858761429786682
95721130,2074,hachikuji,2017-01-12T03:43:01Z,nit: braces for multi-line branches,0,0.9878392219543457
95721250,2074,hachikuji,2017-01-12T03:43:54Z,nit: i think this could be replaced by `offsets.get(topicpartition).map(_.offset)`,0,0.982582688331604
95721791,2074,hachikuji,2017-01-12T03:51:41Z,nit: right-hand side could be replaced by `new topicandpartition(offset._1)`,0,0.9879070520401001
95722080,2074,hachikuji,2017-01-12T03:56:23Z,"a little easier to follow this if you deconstruct the tuple (i.e. use `case (topicpartition, partitiondata)`.",0,0.9850384593009949
95722163,2074,hachikuji,2017-01-12T03:57:36Z,"where do we check errors in the response? if we push the error checking into `listgroupoffsets`, maybe this api could return `map[topicpartition, long]` as you would probably expect.",0,0.9886670112609863
95722389,2074,hachikuji,2017-01-12T04:00:57Z,same as comment above: maybe we always treat this as a top-level error?,0,0.9664290547370911
95722449,2074,hachikuji,2017-01-12T04:01:54Z,nit: the `case` is unneeded.,0,0.9836037158966064
95722624,2074,hachikuji,2017-01-12T04:04:27Z,"nit: slightly more natural if `errors` is the first entry? also, we don't need `apiversion` anymore, right?",0,0.9861300587654114
95722933,2074,hachikuji,2017-01-12T04:08:46Z,we need to synchronize on the group to access its state.,0,0.9784149527549744
95723097,2074,hachikuji,2017-01-12T04:10:06Z,not sure about the name. how about `partitionswithcachedoffsets`?,0,0.9442340135574341
95723245,2074,hachikuji,2017-01-12T04:12:45Z,"alternatively, we could allow `handlefetchoffsets` to return all offsets for the group, and we could filter out the partitions that the principal is not authorized to access. that seems a little bit better than exposing a new method in `groupcoordinator`.",0,0.9808056354522705
95723440,2074,hachikuji,2017-01-12T04:15:42Z,"if there should be a member, perhaps we should assert it?",0,0.9788691401481628
95723511,2074,hachikuji,2017-01-12T04:17:00Z,"nit: easy to miss the `&&` with this alignment. perhaps this could go on the previous line? also we can use `contains`. for example: `state.contains(""dead"")` instead of `state == some(""dead"")`.",0,0.9787116646766663
95723657,2074,hachikuji,2017-01-12T04:19:41Z,nit: replace with `contains`,0,0.9869393110275269
95723677,2074,hachikuji,2017-01-12T04:20:05Z,nit: we could use `count` here.,0,0.988376796245575
95723736,2074,hachikuji,2017-01-12T04:21:01Z,maybe this should be in a `finally`? similar below,0,0.9858443737030029
95724623,2074,hachikuji,2017-01-12T04:36:09Z,"you can use `==` instead of `equals` for all of these. as it is, intellij is complaining that the types are unrelated.",0,0.7218773365020752
95725601,2074,hachikuji,2017-01-12T04:54:05Z,nit: pretty sure we shouldn't need this if we're throwing an exception above. more of these below.,0,0.9705936312675476
95847224,2074,vahidhashemian,2017-01-12T17:55:09Z,so you mean if there is a top-level error code it should not be partition error? i'm okay with that. in that case the second check on this line would be redundant. please advise if i misunderstood. thanks.,1,0.8885708451271057
95849478,2074,vahidhashemian,2017-01-12T18:06:20Z,and perhaps later we should remove this method from other `response` classes.,0,0.9878202676773071
95854631,2074,vahidhashemian,2017-01-12T18:32:55Z,sounds good. i had missed the error check after the latest api change. thanks.,1,0.982435941696167
95855842,2074,hachikuji,2017-01-12T18:39:06Z,"haha, i'm not sure whether we're saying the same thing. my suggestion was to blindly treat the exception as a top-level error. in other words, take the error code from the exception and use it as the top-level error code for new versions, and as the partition-level error code for old versions.",-1,0.7724239826202393
95855851,2074,vahidhashemian,2017-01-12T18:39:08Z,"right, and with the change to return type of `listgroupoffsets` this will become `offsets.get(topicpatition)`. thanks.",1,0.9152734875679016
95859684,2074,hachikuji,2017-01-12T18:57:39Z,definitely. this is one of my favorite gripes. using more specific types whenever possible allows the compiler to do more work for us.,1,0.9390403628349304
95869619,2074,vahidhashemian,2017-01-12T19:45:04Z,so even the older versions will have an error code at the top level? this would change it to [code block],0,0.9831253886222839
95875608,2074,vahidhashemian,2017-01-12T20:17:31Z,"sure, this is a better approach. thanks.",1,0.9607420563697815
95886293,2074,vahidhashemian,2017-01-12T21:16:06Z,`contains` seems to be not supported in scala 2.10. and builds are failing locally for me because of that. don't we still support 2.10? is there a way to get around it?,-1,0.768585205078125
95891116,2074,vahidhashemian,2017-01-12T21:41:53Z,"sure, i'm using eclipse and it doesn't complain about `equals`.",0,0.9752062559127808
95912504,2074,hachikuji,2017-01-12T23:54:49Z,don't worry about it if it's not supported.,0,0.8101155757904053
95913606,2074,vahidhashemian,2017-01-13T00:04:00Z,"well, this actually breaks the unit test, because we don't want to run the `try` block only once. we want to keep trying until the group stabilizes. if we move the `close` to `finally` we close the command after the first try and run into an error on the next try.",0,0.9083717465400696
95937690,2074,vahidhashemian,2017-01-13T04:51:32Z,"so if we want to just check the top level error for any error in the response for partition level errors we lose the specific partitions that are erroneous. also, if there are different partition level error types present we'll report only one. this just limits the error reporting but shouldn't affect the functionality. i hope i did not misunderstand your point.",0,0.9230242967605591
95937720,2074,vahidhashemian,2017-01-13T04:52:12Z,"also, do you happen to know why out of the 5 possible errors we just check only 3 here?",0,0.9833155870437622
95938741,2074,hachikuji,2017-01-13T05:09:43Z,maybe we should enforce a minimum version number when querying all partitions? you can look at `listoffsetrequest` for an example of this.,0,0.9886493682861328
95939088,2074,hachikuji,2017-01-13T05:16:00Z,nit: add a space before the `:`.,0,0.9866259098052979
95939338,2074,hachikuji,2017-01-13T05:20:11Z,wonder if there's any harm retaining the top-level error regardless of the version. seems more consistent with how we handle the case of constructing from a `struct`.,0,0.8854636549949646
95939575,2074,hachikuji,2017-01-13T05:23:09Z,probably worth a comment explaining why we do this.,0,0.9561072587966919
95939801,2074,hachikuji,2017-01-13T05:25:39Z,"related to above comment. this method only makes sense for version 2, so maybe we should remove `version` and use 2 directly.",0,0.9877419471740723
95939909,2074,hachikuji,2017-01-13T05:27:50Z,do we need to check the partition errors also?,0,0.9846581220626831
95939988,2074,hachikuji,2017-01-13T05:29:04Z,nit: space after comma.,0,0.9863386750221252
95940177,2074,hachikuji,2017-01-13T05:31:54Z,you could also use `new topicandpartition(topicpartition)`,0,0.9866442084312439
95940449,2074,hachikuji,2017-01-13T05:36:09Z,"instead of using `null` as the sentinel, we could use an `option`.",0,0.9884657859802246
95940542,2074,hachikuji,2017-01-13T05:37:41Z,another option would be to push the handling of all offsets into `getoffsets`. one small advantage is that you would only need to acquire the lock once instead of twice.,0,0.9867126941680908
95942547,2074,hachikuji,2017-01-13T06:11:25Z,you could do these assignments at once: [code block] we use this pattern just below.,0,0.988807737827301
95942666,2074,hachikuji,2017-01-13T06:13:31Z,"seems like this and the other call to `handlefetchoffsets` below needs to go to the `else` case after the check for version 0. for version 0, we pull offsets from zookeeper. i'm wondering if your first approach, which collected all partitions from the coordinator first, may have been a little cleaner. another option to consider, perhaps you could do the post-filtering for the `isallpartitions` case separately, and continue doing pre-filtering when we are provided the partition list.",0,0.974040150642395
95942941,2074,hachikuji,2017-01-13T06:17:07Z,"i was thinking we could handle both of these cases in the same constructor. the constructor would take a single error code and the list of requested partitions. if the version is greater than or equal to 2, the partitions are ignored; otherwise, the error code is written into the partition errors.",0,0.986556351184845
96034941,2074,vahidhashemian,2017-01-13T17:25:50Z,i think it should be okay to do that. will update.,0,0.9328886270523071
96036429,2074,vahidhashemian,2017-01-13T17:34:41Z,will there be any partition error? in the case of all offsets unauthorized partitions are excluded and there won't be any unknown topic partition. do you think we should throw an exception if there is any?,0,0.9852262139320374
96042948,2074,hachikuji,2017-01-13T18:12:16Z,seems safer (and more future-proof) to check and throw an exception.,0,0.9594370126724243
96043181,2074,vahidhashemian,2017-01-13T18:13:33Z,great idea because `getoffsets` already gives us what we want ([a link].,1,0.9662318825721741
96057467,2074,vahidhashemian,2017-01-13T19:29:20Z,good idea. thanks.,1,0.9704252481460571
96058029,2074,vahidhashemian,2017-01-13T19:32:19Z,"would it also work if one assignment depends on the other one? `partitions` uses `groupoffsets`. also, it may not read easily since there is a big type definition for `groupoffsets`.",0,0.9860331416130066
96059742,2074,hachikuji,2017-01-13T19:40:46Z,does type inference not work? i was thinking something like this: [code block],0,0.9471560716629028
96060015,2074,hachikuji,2017-01-13T19:42:08Z,nit: unneeded parenthesis.,0,0.9577634930610657
96062247,2074,vahidhashemian,2017-01-13T19:53:46Z,"yes, it works perfectly. sorry for the premature question!",-1,0.9911262392997742
96085672,2074,vahidhashemian,2017-01-13T22:21:35Z,still not too sure about this. did you want to move this error check up in the first `if` block?,-1,0.5146558880805969
96088422,2074,hachikuji,2017-01-13T22:41:45Z,i'm not sure i see the problem. would we ever see this at the top level?,-1,0.6882013082504272
96089207,2074,hachikuji,2017-01-13T22:46:58Z,"actually i guess we could make this a little simpler. we know we need version 2, so maybe we can use it directly and remove `minversion`?",0,0.9790270328521729
96089229,2074,vahidhashemian,2017-01-13T22:47:07Z,"i'm referring to [a link], and i'm not sure if it implied modifying this method too.",0,0.7554097771644592
96089343,2074,vahidhashemian,2017-01-13T22:48:03Z,"sure, i thought about it too, but thought to keep it in sync with `listoffsetrequest`. i'll update.",0,0.9846316576004028
96090049,2074,hachikuji,2017-01-13T22:53:44Z,"i was mainly concerned that we'd need to check errors in both places, but i think we're good now since we ensure that top-level error codes will always appear at the top level (even for older versions).",0,0.8450021743774414
96090198,2074,hachikuji,2017-01-13T22:54:55Z,"yeah, we're still feeling out the best patterns for handling older versions.",0,0.9576659798622131
96090442,2074,vahidhashemian,2017-01-13T22:56:45Z,"great, thanks for clarifying.",1,0.9748167395591736
96091324,2074,hachikuji,2017-01-13T23:04:02Z,could we mention that we do this so that the client can depend on the top-level error code regardless of the offset fetch version?,0,0.9888623356819153
96091481,2074,hachikuji,2017-01-13T23:05:30Z,do we need another field if the errors are already contained in `partitiondata`?,0,0.9850543737411499
96092241,2074,hachikuji,2017-01-13T23:10:41Z,"talked to about this, and i don't think we need to bump the internal version number since the brokers do not use offset fetches themselves.",0,0.9856913685798645
96092616,2074,vahidhashemian,2017-01-13T23:13:53Z,i added this to keep track of partition errors that is needed by `adminclient` [a link]. unless it's okay to process `partitiondata` on the fly?,0,0.9893060326576233
96092684,2074,vahidhashemian,2017-01-13T23:14:22Z,sounds good. i'll remove the internal version.,1,0.9509521722793579
96092918,2074,hachikuji,2017-01-13T23:16:39Z,"seems just as efficient to me, especially since we only throw the first error.",0,0.8902987241744995
96093935,2074,vahidhashemian,2017-01-13T23:24:50Z,"sure, then i think we perhaps need to at least have another `errors` member for that first partition error. so we don't have to process `partitiondata` multiple times for checking the existence and actually retrieving the error (in `haspartitionerrors` and `partitionerrors`).",0,0.9883133172988892
96094359,2074,hachikuji,2017-01-13T23:28:38Z,"i think this is close, but it's a bit annoying that we have to call `handlefetchoffsets` in two places, right? wouldn't it be better to delay the check for `isallpartitions` and the filtering until after the call to `handlefetchoffsets` below. that gives us a clean separation of the kafka and zookeeper offset handling. so maybe the logic can be something like this: 1. filter unauthorized partitions 2. check if this is version 0 a. fetch from zk for version 0 b. check from kafka for versions 1 and above. after receiving the fetched offsets, check if `isallpartitions` is set. if so, additionally filter out the fetched offsets for topics we are not authorized for. does that make sense?",-1,0.571106493473053
96094652,2074,hachikuji,2017-01-13T23:31:17Z,hmm.. it just doesn't seem worth optimizing for. processing the partition data means what? looping over it and checking if error is none? does it matter if we do that twice? we could also just leave off the `haspartitionerrors` and do a single iteration and raise the error on the first exception.,0,0.8299130201339722
96095174,2074,vahidhashemian,2017-01-13T23:36:50Z,would something like this work? [code block],0,0.9865165948867798
96095469,2074,hachikuji,2017-01-13T23:40:03Z,"sure, that would work. maybe `getfirstpartitionerror` is a clearer name? or you could bundle the exception throwing as well into a single `maybethrowfirstpartitionerror`? either way is fine with me, but i'd prefer not to additional fields without a clear case that they're needed.",0,0.9726558327674866
96096333,2074,vahidhashemian,2017-01-13T23:48:54Z,"if i understand this correctly, for version 1 and above, to receive the fetched offsets we already need to check `isallpartitions` to determine if `none` or `some(partitions)` should be passed to `handlefetchoffsets`.",0,0.9890093207359314
96096521,2074,hachikuji,2017-01-13T23:50:38Z,"yeah, that's fair. the point is that it should happen in the kafka branch of that `if` and not before.",0,0.9453782439231873
96097187,2074,vahidhashemian,2017-01-13T23:58:29Z,i think we need to call `isallpartitions` upfront anyway because we need to make sure `offsetfetchrequest.partitions` is not null before starting to filter.,0,0.9877840876579285
96097302,2074,hachikuji,2017-01-13T23:59:40Z,ack,0,0.9720376133918762
96099907,2074,vahidhashemian,2017-01-14T00:28:49Z,i hope this is now closer to what you described.,0,0.6946125030517578
138698389,3849,becketqin,2017-09-13T18:15:47Z,it seems better to say producer.send() instead of send.,0,0.9839731454849243
138699047,3849,becketqin,2017-09-13T18:18:06Z,we are passing `now` everywhere else. maybe we can just keep the argument name the same.,0,0.9862333536148071
138726608,3849,tedyu,2017-09-13T20:14:46Z,should <= be used ?,0,0.9852936863899231
138726989,3849,tedyu,2017-09-13T20:16:27Z,deliverytimeoutms should be mentioned,0,0.9862522482872009
138787782,3849,becketqin,2017-09-14T03:06:17Z,should we validate the delivery.timeout.ms is greater than request.timeout.ms?,0,0.9874603748321533
138789918,3849,becketqin,2017-09-14T03:31:27Z,it is probably cleaner to have an explicit `expired` state.,0,0.9872205853462219
138791125,3849,becketqin,2017-09-14T03:46:07Z,"the logic here probably needs more comments. we may have the following three cases that the state of a batch has been updated before the produceresponse returns: 1. a transaction abortion happens. the state of the batches would have been updated to `aborted`. 2. the producer is closed forcefully. the state of the batches would have been updated to `aborted`. 3. the batch is expired when it is in-flight. the state of the batch would have been updated to `expired`. in the other cases, we should throw illegalstateexception.",0,0.9696497917175293
138791482,3849,becketqin,2017-09-14T03:50:16Z,"the batches still needs to be expired in order if `max.in.flight.requests.per.connection` is set to 1. so we probably still want to check if the partition is muted or not. that said, if we guarantee that when `recordaccumulator.expiredbatches()` returns non-empty list, all the earlier batches have already been expired, we can remove the muted check here. btw, i did not see the logic of expiring an in-flight batch in the current patch. am i missing something?",0,0.8331881165504456
138791524,3849,becketqin,2017-09-14T03:50:53Z,isfull is no longer used.,0,0.8941224813461304
138977901,3849,sutambe,2017-09-14T18:40:05Z,agreed,0,0.9622963666915894
139014083,3849,sutambe,2017-09-14T21:19:24Z,"the actual argument is `now`. however, i like the formal argument name to be `createtime` because it's an immutable value while constructing a batch. `now`, is by definition, changing.",0,0.9678390026092529
139014648,3849,sutambe,2017-09-14T21:22:07Z,i did some digging around. an expired batch's final state is `failed`. i don't feel great about adding yet another `finalstate`. we already have `aborted` and `failed`. the `producerbatch.done` will get even more complicated.,-1,0.9512621164321899
139246402,3849,sutambe,2017-09-15T20:45:56Z,please review the updated method documentation.,0,0.9779024124145508
139768240,3849,tedyu,2017-09-19T17:53:22Z,this variable can be dropped.,0,0.9858949184417725
139842619,3849,tedyu,2017-09-19T23:24:22Z,in not -> is not,0,0.9036109447479248
139843016,3849,tedyu,2017-09-19T23:27:37Z,the check 'if (deliverytimeoutms <= (now - this.createdms))' inside maybeexpire() would be true. looks like another method can be created inside producerbatch which expires the batch.,0,0.9886119961738586
139851577,3849,sutambe,2017-09-20T00:34:32Z,`maybeexpire` has a side-effect of setting `errormessage` internally. hence calling it again in `if`.,0,0.9796522259712219
139852241,3849,tedyu,2017-09-20T00:40:18Z,understand. that part can be refactored - goal is to reduce unnecessary comparison.,0,0.9720371961593628
139852661,3849,sutambe,2017-09-20T00:43:47Z,those test don't even compile or run on my machine. what's up with those tests?,0,0.7271562218666077
139853479,3849,apurvam,2017-09-20T00:51:42Z,they can't construct a kafka producer with the changes made in this pr.,0,0.9677314758300781
139871039,3849,becketqin,2017-09-20T04:01:43Z,is this comment accurate? the new state is not necessarily succeeded.,0,0.9304124712944031
139871499,3849,becketqin,2017-09-20T04:04:58Z,"maybe it's not a big deal but just want to call out that this is a behavior change. currently the producer will throw exception when transition from failed state to another state due to some reason other than expiration. if we change this logic, we may miss those cases which are not failed by expiration but still got state update twice. it may not be that important if we do not have programming bugs. personally i think it is better to clearly define the states of the batches even if additional complexity is necessary. the comments should probably also cover the force close case for completeness.",0,0.9271915555000305
139873674,3849,becketqin,2017-09-20T04:33:40Z,"some typos in this comments. ""expire the batch if no outcome is known within delivery.timeout.ms""",0,0.9826036095619202
139874459,3849,becketqin,2017-09-20T04:44:01Z,does this have to be a per partition map? intuitively we just need a `treeset ` with a comparator?,0,0.9836933016777039
139874583,3849,becketqin,2017-09-20T04:45:39Z,"assuming `nflightbatches` is a treeset suggested above, this code can be simplified to: [code block]",0,0.9881592988967896
139874633,3849,becketqin,2017-09-20T04:46:09Z,`tp` is not used anymore.,0,0.959738552570343
139874861,3849,becketqin,2017-09-20T04:49:12Z,no longer used.,0,0.6586141586303711
139874980,3849,becketqin,2017-09-20T04:50:43Z,this logic would become `inflightrequests.remove(batch)` when a `treeset` is used for this.,0,0.989464282989502
139875140,3849,becketqin,2017-09-20T04:52:44Z,this would be just `inflightbatches.add(batch)`,0,0.986809492111206
139875288,3849,becketqin,2017-09-20T04:54:13Z,we usually just use `earliestdeliverytimeout` in kafka.,0,0.9880238175392151
139875598,3849,becketqin,2017-09-20T04:58:47Z,it seems we don't need the `deliverytimeoutms` in the sender. it is only used as an argument passed to the accumulator. but the accumulator already has the config.,0,0.9872773289680481
139876175,3849,becketqin,2017-09-20T05:06:51Z,it seems an existing issue. when we expire the batches here. the memory of those batches will be deallocated. it seems that we will deallocate the same batch again when the produceresponse returns?,0,0.9773773550987244
140056222,3849,becketqin,2017-09-20T18:37:07Z,"apparently the my understanding of `treeset` is not accurate. it uses the comparator to decide whether the entries are the same or not. we can use a treemap > then. we may also want to bucket the timestamp a little bit, say one second to avoid huge amount of sets created for each ms in the `treemap`.",0,0.9253817796707153
140087965,3849,tedyu,2017-09-20T20:45:59Z,"i was thinking about this too. using millisecond as unit for map key is not prudent. after the switch to second as unit, we may need to check the two adjacent buckets keyed by ts-1 (sec) and ts+1 (sec).",0,0.9709417819976807
140133571,3849,becketqin,2017-09-21T01:50:36Z,this test has nothing to do with linger.ms anymore...,0,0.6298429369926453
140133681,3849,becketqin,2017-09-21T01:51:43Z,similar to above we should rename this.,0,0.9851263761520386
140133773,3849,becketqin,2017-09-21T01:52:35Z,typo: timeout,0,0.9834038615226746
140133809,3849,becketqin,2017-09-21T01:53:02Z,typo: timeout,0,0.9834038615226746
140136188,3849,becketqin,2017-09-21T02:19:02Z,"should we still expire the batches when they are expired instead of expiring all the bucket? having a second granularity bucket does not prevent us from doing that, right?",0,0.961760401725769
140303384,3849,sutambe,2017-09-21T17:11:05Z,"as we discussed, `treeset` does not cut it. the naming is consistent. a `treeset` is a set. it's just that equality criterion is different.",0,0.9760068655014038
140304267,3849,sutambe,2017-09-21T17:14:47Z,it's there now,0,0.9796222448348999
140367934,3849,hachikuji,2017-09-21T21:47:38Z,"hmm.. might not be too important, but it doesn't seem necessary to include the retry backoff in this check. if the user sets retries=0, then the backoff shouldn't matter.",0,0.966339111328125
140370206,3849,hachikuji,2017-09-21T21:58:50Z,"we are using the creation time of the batch to check for expiration. that will tend to expire some records which were added to the batch after creation earlier than the delivery timeout (by as much as linger.ms). alternatively, we could use the time that the batch was closed, which will tend to expire records later than the delivery timeout (by as much as linger.ms), but maybe expiring late is bit safer than expiring early? this is equivalent to saying that the delivery timeout excludes linger time.",0,0.9789876937866211
140371334,3849,hachikuji,2017-09-21T22:05:06Z,"checking my understanding. with this change, it should no longer be possible to expire a batch before linger.ms has completed and the batch has been closed. if so, do we still need the logic to abort appends on expiration? (it might be safer to have it anyway, just checking if it is still needed for correctness)",0,0.9739365577697754
140373989,3849,hachikuji,2017-09-21T22:21:29Z,"after we reset `earliestdeliverytimeoutms`, it seems that we do not take into account the expiration times of in-flight batches.",0,0.980076253414154
140375038,3849,hachikuji,2017-09-21T22:29:00Z,do we have any microbenchmarks that show this (potential) optimization is justified?,0,0.9840420484542847
140377235,3849,hachikuji,2017-09-21T22:44:15Z,why do we need this check? a comment would be helpful.,0,0.9821100831031799
140392052,3849,sutambe,2017-09-22T00:47:58Z,batch close may be arbitrrily delayed in some cases. see 's explanation: [a link],0,0.9832157492637634
140394635,3849,sutambe,2017-09-22T01:16:46Z,fixed. take a look.,0,0.9764225482940674
140395587,3849,sutambe,2017-09-22T01:26:49Z,`recordaccumulator.maybeupdateearliestdeliverytimeout`,0,0.9801605343818665
140560836,3849,apurvam,2017-09-22T18:10:06Z,"shouldn't we also be removing the batches from the inflight set when the batch is completed (failed or successfully)? i might be missing something, but i don't see that code here.",0,0.95256507396698
140571976,3849,sutambe,2017-09-22T18:59:40Z,"right. cleanup of `soontoexpireinflightbatches` happens in two places (1) if a batch gets reenqueued and (2) when `sender` looks for `expiredbatches`. in the second case, we cleanup the batches whose final state is known (success or failure) and there by ""removing"" them.",0,0.9882938861846924
140590998,3849,hachikuji,2017-09-22T20:35:40Z,"as far as i can tell, it shouldn't be possible to abort a batch after it has been completed. is this correct? if so, i think it might be better to continue to raise `illegalstateexception`. it's preferable to keep the allowable state transitions as narrowly defined as possible since it ensures faster failure for unexpected paths.",0,0.9794909358024597
140591599,3849,hachikuji,2017-09-22T20:38:58Z,this is still not used,0,0.9702825546264648
140591635,3849,hachikuji,2017-09-22T20:39:10Z,still not used,0,0.9544306993484497
140592411,3849,hachikuji,2017-09-22T20:43:10Z,"nit: ""for quick **access** to the oldest batch""?",0,0.9814272522926331
140594775,3849,hachikuji,2017-09-22T20:55:31Z,"if you are not implementing this, can you please remove it?",0,0.9752825498580933
140596621,3849,hachikuji,2017-09-22T21:05:43Z,the name is a little misleading given its proximity to similarly named fields. maybe something like `nextexpirationtimestampms` would be clearer?,0,0.8705011010169983
140597138,3849,hachikuji,2017-09-22T21:08:29Z,thanks. i synced with jun and it seems reasonable. it would help to document somewhere why we use create time.,1,0.9464632868766785
140603555,3849,hachikuji,2017-09-22T21:45:41Z,i think the answer to this question is that it is possible to expire while the batch is still being built because closing the batch can be arbitrarily delayed by inflight fetches.,0,0.9811673760414124
140604152,3849,hachikuji,2017-09-22T21:49:42Z,please respond to this. is it necessary to include retry_backoff in this check?,0,0.9865686893463135
140604457,3849,hachikuji,2017-09-22T21:51:32Z,do we want to mention the other case where a record is expired early because it was added to a batch which was already nearing expiration?,0,0.9847299456596375
140606225,3849,hachikuji,2017-09-22T22:04:24Z,"the logic for updating this field seems to assume that the batch at the front of the deque will always be the next to expire, but i'm not sure that is true in the case of retries.",0,0.9669276475906372
140608227,3849,hachikuji,2017-09-22T22:21:05Z,"to be honest, this lazy expiration seems like overkill. it should be a rare case where we actually have entries in `soontoexpireinflightbatches` because of the other optimization to only add to it when the delivery timeout will expire prior to the request timeout. and if the producer is in a situation where batches are being expired, then the performance of removal for a particular batch is probably not a major concern. maybe some benchmarking would show whether it is a worthwhile optimization.",0,0.5880625247955322
140608868,3849,hachikuji,2017-09-22T22:26:51Z,inadvertent commit i assume.,0,0.9068387150764465
140609030,3849,hachikuji,2017-09-22T22:28:14Z,"if we're just returning `true` for `matches`, we don't need to provide a `requestmatcher` at all.",0,0.986973762512207
140614799,3849,sutambe,2017-09-22T23:24:16Z,i think `retrybackoff` can be dropped. perhaps we can do two tests based on whether `retries` is set or not.,0,0.9879146814346313
140617891,3849,tedyu,2017-09-22T23:59:57Z,i don't see bucketing,0,0.9509695768356323
140619943,3849,becketqin,2017-09-23T00:30:02Z,"i agree in most case we probably do not need this. it is probably only useful for large producers (e.g. mirror maker which has thousands of partitions to send). there may still be value to have this: 1. since delivery.timeout.ms and request.timeout.ms are both user configurations. it would be good to guard against some configurations. (e.g. request.timeout.ms=delivery.timeout.ms, linger.ms=0). 2. it seems that in some scenarios this would help. for example, when the brokers are being rolling bounced, there will be a lot of retried batches. those batches may have `remainingdeliverytimeoutms` < `request.timeout.ms`. we may have even more than one batches per partition to insert if max.in.flight.request is greater than 1. a benchmark would be useful. but in general i think it is safer to have this optimization given it does not increase too much complexity.",0,0.8768224120140076
140625298,3849,becketqin,2017-09-23T04:01:04Z,i had a comment earlier that it seems we should still expire the batch at exact createtime + deliverytimeoutms even if we bucket them by seconds.,0,0.9865224957466125
140625337,3849,becketqin,2017-09-23T04:04:48Z,"i agree with that using retry backoff is a little weird here. `retries` means that ""at most retry that many times within delivery.timeout.ms"". so even if `retries` is greater than 0, it does not mean there must be a retry. so we should probably just check the `delivery.tiemout.ms` is at least `linger.ms` + `request.timeout.ms`.",-1,0.8992093205451965
140625355,3849,becketqin,2017-09-23T04:06:58Z,i also think we should mention the scenario that a record is added to a batch that is about to expire.,0,0.9854071140289307
140625458,3849,becketqin,2017-09-23T04:14:29Z,can we update the java doc to explain the return value?,0,0.9892330169677734
140625583,3849,becketqin,2017-09-23T04:24:43Z,personally i still think a clear expired state would be clearer. we can let batch.done() method take a finalstate argument instead of inferring the state from the exception.,0,0.9712907671928406
140625869,3849,becketqin,2017-09-23T04:46:59Z,"good point. it would work if max.in.flight.requests.per.connection=1, or when we enable idempotence. but otherwise the first batch may not be the first to expire. since we do not even have callback order guarantee in that case, maybe it is fine? but we should definitely document this.",1,0.8230375051498413
140626273,3849,becketqin,2017-09-23T05:15:12Z,this test will pass whether line 76 throws illegalstateexception or not. should we add a fail() statement after line 76?,0,0.9811950325965881
140626284,3849,becketqin,2017-09-23T05:16:11Z,is this needed? in what case could e be null?,0,0.9823195338249207
140626361,3849,becketqin,2017-09-23T05:21:32Z,we should change the test name to something like testbatchexpiration. and the test below to testbatchexpirationafterreenqueue.,0,0.9887089133262634
140626370,3849,becketqin,2017-09-23T05:22:08Z,the typo is still there.,0,0.9862344264984131
140626470,3849,becketqin,2017-09-23T05:23:40Z,"testsoontoexpire... (upper case ""to"")",0,0.9880422353744507
140626641,3849,becketqin,2017-09-23T05:25:13Z,do you mean it should not be included...,0,0.6908597946166992
140626811,3849,becketqin,2017-09-23T05:38:05Z,typo in the test name.,0,0.986150324344635
140626831,3849,becketqin,2017-09-23T05:39:42Z,request1 and request 2 are not used.,0,0.969537615776062
140626885,3849,becketqin,2017-09-23T05:43:03Z,should we check the completeness of request1?,0,0.9879818558692932
140626907,3849,becketqin,2017-09-23T05:44:46Z,we may need to call sender.run() one more time to ensure the message is not reenqueued. the reqenqueued message won't be sent out again in the same sender.run().,0,0.9852604269981384
140646338,3849,tedyu,2017-09-24T03:32:38Z,createtime -> creationtime,0,0.9852885603904724
140646367,3849,tedyu,2017-09-24T03:35:40Z,nit: 'else' can be dropped,0,0.9859641790390015
140671368,3849,sutambe,2017-09-24T23:48:00Z,restored the test as it was before.,0,0.9803379774093628
140864460,3849,sutambe,2017-09-25T18:47:43Z,just added a test to ensure that we don't do double deallocation. `sendertest.testnodoubledeallocation`,0,0.9840672016143799
140880631,3849,sutambe,2017-09-25T19:55:16Z,the batch is expired at exact time but not removed from the `soontoexpireinflightbatches`. based on some earlier comments grouping them to avoid pointer chasing?,0,0.9891512393951416
140881985,3849,becketqin,2017-09-25T20:00:59Z,"this method either throw exception or return true, which indicates there is no need to have a return value.",0,0.9876537919044495
140884890,3849,apurvam,2017-09-25T20:13:30Z,"hmm. this seems a bit off. what this means that in the 'normal' case when responses are successful and there is no backlog in the accumulator, we will hang on to batches (and not garbage collect them) until the delivery timeout. indeed, if you add the following at the end of sender tests where there are no more inflight requests (ie. all requests have completed and will never be retried) ` asserttrue(accumulator.soontoexpireinflightbatches().isempty());` all the tests fail. i think this should be fixed. we should clear the `soontoexpireinflightbatches` as soon as the batch is completely resolved (ie. failed or completed) so that we don't hang on to the reference unnecessarily.",-1,0.5474281907081604
140888794,3849,sutambe,2017-09-25T20:29:28Z,added the muted check back,0,0.9866331815719604
140910557,3849,becketqin,2017-09-25T22:00:14Z,the method never returns false. we can keep it as void if so.,0,0.9778698086738586
140914352,3849,becketqin,2017-09-25T22:20:07Z,should probably add an expire case?,0,0.9840278625488281
140918001,3849,becketqin,2017-09-25T22:41:20Z,the map is not used.,0,0.937800943851471
140918233,3849,becketqin,2017-09-25T22:42:40Z,should we assert the pool is not deallocated after the expiration but before the response returns?,0,0.9848500490188599
140918761,3849,becketqin,2017-09-25T22:46:05Z,how could the order be violated if we only append the first batch after the first one is expired?,0,0.9444811940193176
140919067,3849,becketqin,2017-09-25T22:47:55Z,the map is not used.,0,0.937800943851471
140919353,3849,becketqin,2017-09-25T22:49:39Z,nit: can we avoid reusing the argument name?,0,0.977605402469635
140927438,3849,becketqin,2017-09-25T23:46:36Z,"actually, it seems we may release the memory before the the response returns?",0,0.9865772724151611
140928325,3849,apurvam,2017-09-25T23:53:15Z,"as i mentioned in my other comment, the memory utilization itself is not the issue as much as the fact that we are retaining the reference to `producerbatch` for at least `deliverytimeoutms`. this probably won't cause too much memory pressure, but is still an undesirable behavior.",0,0.62969970703125
140935275,3849,becketqin,2017-09-26T00:53:48Z,"got it. good catch. yes, we should remove the completed batch.",1,0.9802928566932678
142276754,3849,sutambe,2017-10-02T22:55:37Z,return type restored to `void`,0,0.9864343404769897
142484042,3849,sutambe,2017-10-03T18:29:10Z,can some please clarify what suggestion is made here? remove completed batch from where?,0,0.9862209558486938
150616359,3849,sutambe,2017-11-13T17:56:25Z,fixed the test,0,0.984514057636261
151183810,3849,sutambe,2017-11-15T16:45:17Z,the new code seems to deallocate the batch right away. i'm not changing the behavior for now.,0,0.8089101910591125
151194892,3849,sutambe,2017-11-15T17:21:41Z,added,0,0.9735139608383179
151195752,3849,sutambe,2017-11-15T17:24:58Z,right,0,0.9538289308547974
151571211,3849,becketqin,2017-11-16T23:56:46Z,`verifyandgetdeliverytimeout()`?,0,0.986939549446106
151572566,3849,becketqin,2017-11-17T00:06:55Z,this check is a little flaky. what if deliverytimeoutms is `long.max_value - 1`?,-1,0.78038090467453
159586946,3849,becketqin,2018-01-04T06:27:34Z,still not used.,0,0.9119498133659363
159587416,3849,becketqin,2018-01-04T06:34:00Z,we don't need a priorityqueue for this because the batches in the recordaccumulator is already in order. so we just need to keep the draining order.,0,0.9852242469787598
159587789,3849,becketqin,2018-01-04T06:39:32Z,"if we always insert the batch to the inflightbatches queue and there is no bug, the batch to be removed should always be the first batch. can we assert on that?",0,0.989268958568573
159588151,3849,becketqin,2018-01-04T06:44:30Z,"the original reason we have this optimization is because we used to have a big sorted data structure. so avoiding inserting elements to it makes sense. given that now the batch order in the recordaccumulator is already guaranteed. it seems we can just put all the drained batches to the inflightbatches queue, which is simpler.",0,0.9744214415550232
159593877,3849,becketqin,2018-01-04T07:41:33Z,the while loop may break if the request size has reached. so there is no guarantee that it will iterate over all the partitions. one alternative is to find the nextbatchexpirytimems in the expirebatches.,0,0.9798129796981812
159594768,3849,becketqin,2018-01-04T07:50:21Z,it seems intuitively this should be the earliest batch in the entire record accumulator?,0,0.9860283732414246
159600209,3849,becketqin,2018-01-04T08:36:38Z,"it seems we may release the memory for the expired batches before the response is returned. this means the underneath bytebuffer is still referred by the producerbatch instance in the inflightrequests. i am not sure if this would cause any problem, but it seems a little dangerous.",0,0.7218942642211914
159602229,3849,becketqin,2018-01-04T08:50:18Z,is the response preparation needed in this case?,0,0.9840914607048035
67447081,1336,junrao,2016-06-17T00:34:31Z,"reporting both owner and member-id can be a bit confusing. also, for zk based consumer, we get the following output. the member-id part is repeated in the owner part. perhaps instead, we can report 3 fields: member-id, client-id, and client-ip. for kafka-based consumer, we can fill in all 3 fields. for zk-based consumer, we can just fill in member-id. we can leave the client-id and client-ip part empty since that are not stored explicitly. [code block]",0,0.7217046022415161
67447089,1336,junrao,2016-06-17T00:34:33Z,could all those scala.collection.mutable.map be just mutable.map?,0,0.9873560070991516
67447119,1336,junrao,2016-06-17T00:34:51Z,could we rename this to describemembertopicpartitions() to make it clear?,0,0.9866993427276611
67447129,1336,junrao,2016-06-17T00:35:00Z,"in this case, since the member has no associated partitions, do we need to pass in topic at all? could we just pass in none?",0,0.979520320892334
67566895,1336,vahidhashemian,2016-06-17T19:59:57Z,sure. will do in the next update.,0,0.9665749073028564
67566945,1336,vahidhashemian,2016-06-17T20:00:20Z,"yes, none should work too. will update the pr.",0,0.9721660614013672
67567026,1336,vahidhashemian,2016-06-17T20:00:57Z,i'll make this change too in the next update.,0,0.9828758835792542
67567292,1336,vahidhashemian,2016-06-17T20:03:09Z,"that's fair. i'll update the code to return the output in the format you suggested. i'm thinking of always returning an empty string for client id and ip for zk-based consumer (as you suggested), and returning ""none"" for member id when no active consumer exists for the group.",0,0.9752771258354187
67725952,1336,junrao,2016-06-20T17:00:35Z,"it doesn't seem that topic is being used. also, could we fix the indentation?",0,0.9823942184448242
67725986,1336,junrao,2016-06-20T17:00:48Z,"could we change getowner and getownerhost to getclientid and getmemberhost accordingly? also, i am not sure why we getmemberid, getowner and getownerhost need to be a function. could we just pass in an option and get rid of ""get""?",0,0.8633017539978027
67726057,1336,junrao,2016-06-20T17:01:15Z,could we change owner to client-id? could owner-host be member-host since not every member owns a partition?,0,0.987736701965332
67726065,1336,junrao,2016-06-20T17:01:19Z,"could we change owneropt and ownerhostopt to clientidopt and memberhostopt, respectively?",0,0.9881800413131714
67726085,1336,junrao,2016-06-20T17:01:27Z,"if topicpartition doesn't exist, should we really pass in offsetopt? it seems it's more intuitive to pass in none.",0,0.9615511894226074
67726141,1336,junrao,2016-06-20T17:01:51Z,"not sure why we need to use ephemeral owner here. it seems that topicpartition->owner gives us the mapping from topic partition to group member id directly. consumergroupdir + ""/ids gives us all members. from these two, we know members that don't own any partitions.",0,0.9761307239532471
67726172,1336,junrao,2016-06-20T17:02:03Z,"this is the case for members not owning any topic partitions, right? if so, could we just set topicpartitions and partitionoffsets to empty?",0,0.9849992394447327
67750840,1336,hachikuji,2016-06-20T19:27:44Z,it seems weird to let this function accept `none` for either of these fields (why would i ever try to get the leo if i don't have a topic or a partition?). maybe the function can accept an instance of `topicandpartition` and the caller can make sure they have an instance prior to calling?,-1,0.9557965993881226
67753873,1336,hachikuji,2016-06-20T19:47:38Z,basically the same comment as above: it's weird to have a function `describepartition` where the partition is optional. could we take the logic for handling that case out of this function?,-1,0.9818676710128784
67763714,1336,hachikuji,2016-06-20T20:50:42Z,minor: would it be helpful to echo the group back to the user in quotes (so that formatting errors are apparent)?,0,0.9881489872932434
67780260,1336,vahidhashemian,2016-06-20T22:42:58Z,you're right. i'll remove the `topic` parameter and fix indentation.,0,0.9780810475349426
67780312,1336,vahidhashemian,2016-06-20T22:43:19Z,"sure, i'll update in the next patch.",0,0.9796323180198669
67780332,1336,vahidhashemian,2016-06-20T22:43:27Z,sure.,0,0.9536533951759338
67780472,1336,vahidhashemian,2016-06-20T22:44:31Z,"yup, and i'm going to switch the last two parameters so member related parameters are next to each other. i hope that's fine.",1,0.7818427085876465
67780508,1336,vahidhashemian,2016-06-20T22:44:48Z,"right, will change to `none`.",0,0.9842725992202759
67781246,1336,vahidhashemian,2016-06-20T22:51:20Z,"i think i had tried that combination before to extract the info. the issue is when i try `get /consumers/group1/owners/test/0` the output looks like this: `cgroup1_kafka-1466461259713-759adaaa-0`. however, when i try `ls /consumers/group1/ids` the output is like `[cgroup1_kafka-1466462141465-ff19e1a5, cgroup1_kafka-1466461259713-759adaaa]`. it seems the first call returns a client id, and the second one a list of member ids, and that's why the outputs do not quite match (`cgroup1_kafka-1466461259713-759adaaa-0 != cgroup1_kafka-1466461259713-759adaaa`). that's why i did not use this approach as i wasn't sure if there is anything further i can assume to connect the two outputs. if there is, please let me know.",0,0.9730605483055115
67784301,1336,vahidhashemian,2016-06-20T23:18:06Z,that's correct and makes sense. will do.,0,0.9052741527557373
67787649,1336,vahidhashemian,2016-06-20T23:52:01Z,i understand the concern. will make some changes to fix the issue.,0,0.8444762229919434
67787692,1336,vahidhashemian,2016-06-20T23:52:27Z,i'll try to fix this as suggested.,0,0.9806897044181824
67788112,1336,vahidhashemian,2016-06-20T23:56:46Z,that's a good suggestion. will update this one and the one a few lines below to return the group name as part of the output message.,1,0.7863041758537292
71457060,1336,hachikuji,2016-07-20T02:28:50Z,minor: maybe we could just debug log the stack trace?,0,0.9854508638381958
71457421,1336,hachikuji,2016-07-20T02:34:23Z,nit: maybe something like `partitionassignmentstate` would be more accurate?,0,0.9839427471160889
71457470,1336,hachikuji,2016-07-20T02:35:35Z,"another small nit: the ""opt"" suffix is kind of annoying. could we drop it?",-1,0.9871454238891602
71457574,1336,hachikuji,2016-07-20T02:37:37Z,maybe we could change this to something like this: [code block] that might make testing easier.,0,0.9820780158042908
71458065,1336,hachikuji,2016-07-20T02:45:11Z,or maybe we keep the current name and just change the argument type since this is `outputwriter`.,0,0.9884190559387207
71458303,1336,hachikuji,2016-07-20T02:49:45Z,i'm wondering if we can collapse these bottom 3 methods into a single `printassignment(assignment: array[consumergroupassignment])`. doesn't seem like we're saving that much with the abstract for loop.,-1,0.499912291765213
71458830,1336,hachikuji,2016-07-20T02:58:36Z,nit: the name `describegroup` no longer seems quite right. maybe `assignmentstate` would be more accurate since that's what the method returns.,0,0.9766865968704224
71459346,1336,hachikuji,2016-07-20T03:07:25Z,maybe `describegroup` could be `collectgroupassignment` and this method could be `collectmemberassignment`?,0,0.9876689314842224
71459524,1336,hachikuji,2016-07-20T03:10:07Z,suggestion: `getalltopicpartitions`?,0,0.9871542453765869
71459607,1336,hachikuji,2016-07-20T03:11:43Z,is this used anywhere?,0,0.9868593215942383
71459749,1336,hachikuji,2016-07-20T03:14:11Z,"actually i see that we print some context-specific error messages, so maybe we need to allow the message to come through. but perhaps we could pass the exception in an optional argument so that we can have a common place to log the stacktrace.",0,0.9858778715133667
71580318,1336,vahidhashemian,2016-07-20T18:28:28Z,i believe this is being handled in [a link]. if it's okay i would let it come through that pr. one of the two prs would have to be rebased depending on which one goes in first.,0,0.8755834698677063
71581180,1336,vahidhashemian,2016-07-20T18:32:45Z,both sound good. will update in the next commit.,1,0.939163863658905
71592461,1336,vahidhashemian,2016-07-20T19:38:48Z,"sure, i'll make necessary changes for this.",0,0.9698792695999146
71592754,1336,vahidhashemian,2016-07-20T19:40:44Z,"that's fair. would it make sense to use `assignments`/`assignments` to imply all assignments, and `assignment`/`assignment` to imply a single assignment row?",0,0.9781836867332458
71593221,1336,vahidhashemian,2016-07-20T19:43:45Z,sure. i was wondering if we should use a `get` prefix (e.g. `getgroupassignment`) to indicate there is some return value. but i don't see that respected as a convention everywhere in the code.,0,0.9726393818855286
71593255,1336,vahidhashemian,2016-07-20T19:43:57Z,sounds good.,1,0.9202015399932861
71593302,1336,vahidhashemian,2016-07-20T19:44:19Z,no. thanks for catching this. will be removed.,1,0.7439779043197632
71604687,1336,hachikuji,2016-07-20T20:54:15Z,not sure i understand the question. i was thinking that a single `printassignment` method could accept the complete assignment for the full group. then printing assignment rows or whatever is just an implementation detail. does that make sense or not?,0,0.8205881118774414
71606434,1336,vahidhashemian,2016-07-20T21:04:26Z,"i agree with merging those three methods. i was just curious about naming convention for the method and the variables used to implement them. maybe [a link] helps, where i use `assignments` as the full list of assignments, and then each individual member is an `assignment`. i thought i could use this convention across the board. this is very minor and not a big deal though if it's confusing.",0,0.8415461182594299
71608339,1336,hachikuji,2016-07-20T21:16:23Z,"ah i see. maybe we could use `groupassignment` and `memberassignment`? as long as it's clear in its context, either way seems ok to me.",0,0.9685264229774475
71609719,1336,vahidhashemian,2016-07-20T21:25:15Z,"yeah, that works too, and would probably be more descriptive. thanks.",1,0.9465845823287964
72295665,1336,hachikuji,2016-07-26T17:19:46Z,"minor: if we use debug(), do we need to extract the stack trace? maybe you could do something like this: [code block]",0,0.985027551651001
72296396,1336,hachikuji,2016-07-26T17:23:50Z,"it's a little weird to have describe() return the partition state. in the test case below using the mock of `outputwriter`, could you replace the assertions on the result of describe() with `easymock.expect()` assertions?",-1,0.9794137477874756
72317288,1336,hachikuji,2016-07-26T19:14:02Z,seems like the only thing this method is contributing is the computation of lag. maybe we could replace it with a method like this: [code block] what do you think?,0,0.9316677451133728
72317749,1336,hachikuji,2016-07-26T19:16:39Z,"based on the usage below, would `printmessage` be a more accurate name?",0,0.9855998754501343
72318145,1336,hachikuji,2016-07-26T19:19:00Z,would it make sense to default `excludeinternaltopics` to true?,0,0.9818800687789917
72321388,1336,vahidhashemian,2016-07-26T19:37:48Z,"this is what i originally wanted to do, but struggled with how to verify the actual result (what would be printed as a result of `describe()` call) against how i call `easymock.expect(...)`, which is something like `easymock.expect(outputwritermock.printerror(""the consumer group 'missing.group' does not exist""))` for the first unit test (`testdescribenonexistinggroup`). how do i make sure that a call to `consumergroupcommand.describe()` would actually make the call identified in `easymock.expect`?",0,0.9641841053962708
72321525,1336,vahidhashemian,2016-07-26T19:38:35Z,"sure, i'll make this change.",0,0.9640205502510071
72324174,1336,vahidhashemian,2016-07-26T19:53:35Z,"yup, that makes sense.",0,0.8522243499755859
72324734,1336,vahidhashemian,2016-07-26T19:56:57Z,"yes, it would be more appropriate. i'll change it. thanks.",1,0.9422607421875
72325636,1336,vahidhashemian,2016-07-26T20:02:19Z,i guess it would. there is an existing method before this one (`getconsumerspertopic`) that also takes `excludeinternaltopics` and assumes no default value for it. i wanted to make the new method consistent with that one.,0,0.9783097505569458
72375727,1336,hachikuji,2016-07-27T03:29:00Z,"that's kind of unfortunate. so here's another idea (feel free to dismiss it if it doesn't make sense). maybe having `describe()` return the assignment is actually heading in the right direction. what if we get rid of `outputwriter` and move the printing logic into the main method. then the `consumergroupservice` becomes more functional (and testable). for `list()`, you can have it return the list of groups instead of printing them. the trickier one seems to be `delete()`. maybe you can leave it as it is.",-1,0.9783079028129578
72523263,1336,vahidhashemian,2016-07-27T21:03:42Z,"sure, i'll try that. having `describe()` return the assignment would make testing much easier.",0,0.9535327553749084
72666749,1336,hachikuji,2016-07-28T17:38:28Z,this is looking promising. maybe we could rename `list` to `listgroups` and `describe` to `describeassignment`?,0,0.6098697185516357
72688365,1336,vahidhashemian,2016-07-28T19:40:09Z,sounds good. wouldn't `describegroup` (singular) be more self-explanatory than `describeassignment`?,1,0.9431813955307007
72688649,1336,hachikuji,2016-07-28T19:41:51Z,"yeah, that sounds good to me.",1,0.9363479018211365
72688751,1336,vahidhashemian,2016-07-28T19:42:32Z,and we could also rename `delete` to `deletegroups`?,0,0.9893277287483215
72691457,1336,hachikuji,2016-07-28T19:58:55Z,makes sense to me.,0,0.9610221982002258
72722638,1336,vahidhashemian,2016-07-28T23:43:33Z,i was wondering what your opinion is about the response above to your comment. this pr has gone through a few more rounds of reviews thanks to and this currently is the only outstanding item. thanks in advance for looking into this.,1,0.9101687073707581
72728458,1336,hachikuji,2016-07-29T00:53:38Z,looks like we would print this twice: once here and once in main. i'm wondering if we could remove `consumergroupoutputwriter` from this class and do all the output in main. maybe we just need to move the empty check that you have below in main?,0,0.9844844341278076
72839362,1336,vahidhashemian,2016-07-29T18:28:54Z,"thanks for catching this. i'll fix in the next update. and we can remove `consumergroupoutputwriter` from that class, as you suggested.",1,0.9425688982009888
83920039,1336,hachikuji,2016-10-18T18:28:43Z,"is this needed for a consumer group? i think protocol type will always be ""consumer.""",0,0.9861202239990234
83920161,1336,hachikuji,2016-10-18T18:29:15Z,"for consumer groups, the protocol is really the assignment strategy.",0,0.9825232028961182
83921286,1336,hachikuji,2016-10-18T18:34:09Z,"as far as i can tell, the return type of this method doesn't need to be mutable. maybe something like this would be a little nicer? [code block] (note i used `keys` instead of `keyset` since we throw away the set anyway.)",0,0.9859214425086975
83922730,1336,hachikuji,2016-10-18T18:41:08Z,would it make a big difference if this method accepted `topicpartition` instead of `topicandpartition` since it seems that's what we need anyway?,0,0.983073890209198
83923001,1336,hachikuji,2016-10-18T18:42:34Z,is this intentional? same for the couple doc changes below.,0,0.9871876239776611
83924024,1336,hachikuji,2016-10-18T18:47:48Z,"since we didn't end up needing this for testing, maybe we can just get rid of it and keep its methods one level up?",0,0.9737928509712219
83924432,1336,hachikuji,2016-10-18T18:49:47Z,"nit: since you're using `map`, we don't need this check.",0,0.9845492839813232
83924865,1336,hachikuji,2016-10-18T18:51:46Z,could we let this function handle the empty assignment case as well?,0,0.9885402321815491
83925389,1336,hachikuji,2016-10-18T18:54:23Z,"i'm not actually sure this message is still correct. in kafka-2720, we introduced an `empty` state for the group, which basically persists until all the offsets for the group have expired. in this case, the assignment will be empty, but it will not be rebalancing.",0,0.9295161366462708
83925578,1336,hachikuji,2016-10-18T18:55:21Z,should this be `private`?,0,0.9862090945243835
83926233,1336,hachikuji,2016-10-18T18:58:31Z,similar to other comment: maybe we could use `topicpartition` here.,0,0.9852986335754395
83926524,1336,hachikuji,2016-10-18T18:59:55Z,why not use `map`?,0,0.9778637290000916
83932002,1336,hachikuji,2016-10-18T19:28:41Z,seems like this is another case where we don't actually need a mutable collection if we use `flatmap`.,0,0.973018229007721
83933934,1336,hachikuji,2016-10-18T19:39:34Z,"it seems the node of the partition owner includes the threadid. the pattern is always ""{consumerid}-{threadid}"", so checking the prefix of the partition owner would always get us the right id. maybe it's a little nicer to use that than the ephemeral owner?",0,0.9814749956130981
83934306,1336,hachikuji,2016-10-18T19:41:21Z,"maybe change this to `map`, then i think `flatmap` as suggested above would work nicely.",0,0.9813830256462097
83934935,1336,hachikuji,2016-10-18T19:44:51Z,this looks odd. we create an option just so we can call `map`? could we replace this with: [code block] same for the loop below.,-1,0.9264482259750366
83935126,1336,hachikuji,2016-10-18T19:45:44Z,using `map` would be nicer?,0,0.9853445887565613
83948295,1336,vahidhashemian,2016-10-18T20:52:35Z,"yes, it'll be `consumer`, but there is a check [a link] to verify that the protocol type os valid. if we remove this, i think that check has to be removed too. should i still go ahead and remove it?",0,0.9884073138237
83948616,1336,vahidhashemian,2016-10-18T20:54:22Z,"sure, i'll rename this field to `assignmentstrategy`.",0,0.9842482209205627
83952330,1336,vahidhashemian,2016-10-18T21:14:02Z,makes sense. thank you for the suggestion. i'll update the method.,1,0.9447111487388611
83955679,1336,vahidhashemian,2016-10-18T21:33:13Z,you're right. would it be ok to change this message to `consumer group ... has no active member or is rebalancing`?,0,0.9593909978866577
83957107,1336,hachikuji,2016-10-18T21:42:04Z,"i would probably move that check into `describegroup`. now that i'm thinking about it, we should probably either rename `describegroup` to `describeconsumergroup`, or we should let `describegroup` return a generic `groupsummary` while `describeconsumergroup` returns `consumergroupsummary`.",0,0.9876291751861572
83957355,1336,hachikuji,2016-10-18T21:43:17Z,it would be more ideal if we could tell the user which is the case. maybe we need to propagate the state of the group down to this method.,0,0.9817261099815369
83960147,1336,vahidhashemian,2016-10-18T22:00:51Z,"thanks. with the first suggestion, there already is a `describeconsumergroup` method. unless you prefer this suggestion (using a different method name) i'll go ahead with your second suggestion.",1,0.9153771996498108
83963057,1336,vahidhashemian,2016-10-18T22:20:09Z,"upon further consideration, i think i'm going to adopt your first suggestion, because i need the current `describegroup` method to return the coordinator as part of its output; so i can report the coordinator's broker id. i'm going to use the method name `getconsumergroupsummary` instead.",0,0.9837590456008911
83973106,1336,vahidhashemian,2016-10-18T23:35:51Z,"yup, will try to do this in the next patch.",0,0.9446353912353516
83973553,1336,vahidhashemian,2016-10-18T23:39:43Z,"this `case class` is used in other classes in the same file. since it's defined outside the scope of those classes `private` wouldn't work, but `protected` would. i hope i didn't misunderstood your point.",0,0.9550393223762512
83974748,1336,vahidhashemian,2016-10-18T23:49:50Z,"sure, sounds good.",1,0.8748131990432739
83974783,1336,vahidhashemian,2016-10-18T23:50:11Z,thanks for catching this.,1,0.5643005967140198
83975322,1336,vahidhashemian,2016-10-18T23:55:12Z,"we could, but we would need to pass more arguments now that we want to distinguish between empty group and rebalancing group. plus, in the case of an empty assignment we are using the `printerror` method, instead of actually printing assignments. do you still think we should change it?",0,0.9865711331367493
84141950,1336,vahidhashemian,2016-10-19T18:55:49Z,i'll try to make use of `flatmap`.,0,0.9873319268226624
84143779,1336,vahidhashemian,2016-10-19T19:05:03Z,sure i'll try to use that (by ignoring the threadid part) instead of ephemeral owner.,0,0.9830337166786194
84150277,1336,vahidhashemian,2016-10-19T19:39:35Z,this section will be removed now that we decided to use the owner info directly.,0,0.9879893064498901
84157718,1336,vahidhashemian,2016-10-19T20:17:48Z,i'll give it a try in the next patch.,0,0.9728180170059204
84164530,1336,vahidhashemian,2016-10-19T20:53:37Z,"to be honest, it's been so long that i don't recall why i made these changes. but when i try the current command, i can't tell what the meaning of ""new consumer being the default"" is. it seems to me that we need to either provide `--zookeeper` or `--bootstrap-server`; it's not like if we use `--new-consumer` we don't have to provide `--bootstrap-server`. the only restriction around `--new-consumer` seems to be that it cannot be used along with `--zookeeper`. the descriptions in parenthesis are not very clear to me. but it might be just me. your thoughts?",0,0.5865650773048401
84167217,1336,hachikuji,2016-10-19T21:07:13Z,"i agree it's not super clear. maybe we should just avoid saying it's required since it saves us from needing to qualify? you can try to fix this if you want, but i'd be ok just leaving it as it is since it seems orthogonal to the rest of this.",0,0.9422749280929565
84173733,1336,vahidhashemian,2016-10-19T21:42:52Z,"sure, i'll revert these changes. i'm ok with leaving the ""required"" text in since other tools have it too, but we need to better qualify them, as you mentioned. i may work on it separately later.",0,0.9790440201759338
84191293,1336,hachikuji,2016-10-19T23:53:22Z,"if we had `consumergroupsummary` include a list of `consumersummary` objects instead of `membersummary`, would we still need this function?",0,0.9897059202194214
84192091,1336,hachikuji,2016-10-20T00:00:45Z,seems like this method isn't giving us much anymore. maybe it's ok to use `println` directly?,0,0.6430115103721619
84192990,1336,hachikuji,2016-10-20T00:10:00Z,it's a little weird to locate this in `kafka.coordinator` since the coordinator is technically agnostic to group internals. the best alternative i can think of is maybe to put it in tools with `adminclient`. what do you think?,-1,0.9823687672615051
84193326,1336,hachikuji,2016-10-20T00:13:17Z,"nitpick: since it's a simple statement, maybe parenthesis in `map` would be a little nicer than braces?",0,0.9842483401298523
84193423,1336,hachikuji,2016-10-20T00:14:14Z,nitpick: we usually don't put a space before the ':'.,0,0.9742520451545715
84193800,1336,hachikuji,2016-10-20T00:18:18Z,nitpick: i think parenthesis are a little nicer for simple one-liners like this.,1,0.6766131520271301
84194583,1336,hachikuji,2016-10-20T00:26:11Z,there are few other places in the patch where we could also change this.,0,0.9856616854667664
84194947,1336,vahidhashemian,2016-10-20T00:30:38Z,i'm not sure if i follow. could you please elaborate a bit?,-1,0.5393986701965332
84195024,1336,hachikuji,2016-10-20T00:31:31Z,"since the zookeeper service has no notion of consumer state, should we return `option[string]` instead?",0,0.9889856576919556
84195092,1336,vahidhashemian,2016-10-20T00:32:12Z,"sure, it makes sense. i'll move it.",0,0.9487340450286865
84195261,1336,vahidhashemian,2016-10-20T00:34:17Z,i'll remove the space. there are a few other occurrences in this file that i'll fix too.,0,0.9866766929626465
84195305,1336,hachikuji,2016-10-20T00:34:51Z,"currently `consumergroupsummary` has a field for the group members, which are represented as instances of `membersummary`. i'm wondering if it would make sense to use `consumersummary` instead. then we might only need a single method returning `consumergroupsummary`.",0,0.9868791699409485
84195485,1336,hachikuji,2016-10-20T00:36:58Z,"if we use normal `map` instead of `flatmap`, does this need to be a `seq` anymore?",0,0.9868640303611755
84195843,1336,hachikuji,2016-10-20T00:41:19Z,could this one be a `flatmap` like the one just above?,0,0.9859160780906677
84195844,1336,vahidhashemian,2016-10-20T00:41:20Z,"no, it doesn't. thanks for catching it.",1,0.7317524552345276
84196169,1336,hachikuji,2016-10-20T00:44:54Z,looks like we're missing the 's' at the start of the string. another few of these below.,0,0.9793892502784729
84196393,1336,hachikuji,2016-10-20T00:47:07Z,nitpick: i think the braces are unnecessary if it is a simple variable.,0,0.9727922081947327
84196615,1336,vahidhashemian,2016-10-20T00:49:59Z,"thanks, i noticed there were a few more.",1,0.5122022032737732
84196895,1336,hachikuji,2016-10-20T00:53:01Z,looks like another case where we might be able to change the `foreach` to a `map` with a `toarray` at the end.,0,0.9867578148841858
84197069,1336,hachikuji,2016-10-20T00:55:32Z,nitpick: maybe we could destructure on assignment? [code block],0,0.9887281656265259
84197288,1336,vahidhashemian,2016-10-20T00:58:28Z,"do you mean merging `getconsumergroupsummary` and `describeconsumergroup` into one method that returns a `consumergroupsummary` object? if so, i thought about it when i was making the recent changes, and noticed that `getconsumergroupsummary` is being used in a few other places. that's why i hesitated to make the unnecessary change. but i guess they could be merged and all calls to `getconsumergroupsummary` would become calls to `describeconsumergroup`. please correct me if i'm misunderstood. thanks.",0,0.9650492668151855
84197311,1336,hachikuji,2016-10-20T00:58:45Z,"nitpick: should 'member' be plural? also, a little surprising we don't have a variable for the groupid. maybe we could add one above to make these messages a little easier to read.",0,0.974412739276886
84197388,1336,hachikuji,2016-10-20T00:59:50Z,"yeah, that's what i meant. don't bother if it's a ton of additional work, but seems like a nice cleanup.",1,0.7278920412063599
84198268,1336,vahidhashemian,2016-10-20T01:08:24Z,good suggestion.,1,0.9429097771644592
84198564,1336,vahidhashemian,2016-10-20T01:12:50Z,"no problem, i'll give it try in the next patch.",0,0.9463486671447754
84349940,1336,hachikuji,2016-10-20T18:42:27Z,"nit: shouldn't need parenthesis for most of these getters, i think. there are a bunch of these around the patch.",0,0.9770851135253906
84350479,1336,hachikuji,2016-10-20T18:45:11Z,nit: might be nice to add a `require` to validate that the group assignment is not empty.,0,0.9623681306838989
84352489,1336,hachikuji,2016-10-20T18:55:19Z,this check needs to be updated since `state` is now an `optional`.,0,0.9875155687332153
84352847,1336,hachikuji,2016-10-20T18:57:03Z,this should probably be `foreach` since we don't need any the return type.,0,0.9882481694221497
84363117,1336,hachikuji,2016-10-20T19:55:17Z,nit: no need for `new`.,0,0.9833356142044067
84363280,1336,hachikuji,2016-10-20T19:56:14Z,nit: maybe this could be [code block],0,0.9835151433944702
84363729,1336,hachikuji,2016-10-20T19:58:46Z,nit: maybe this could be a `foreach`?,0,0.9804343581199646
84364647,1336,hachikuji,2016-10-20T20:04:04Z,nit: no need for `new`,0,0.9832777380943298
84364950,1336,hachikuji,2016-10-20T20:06:07Z,nit: unneeded `tolist`.,0,0.9844954609870911
84365278,1336,hachikuji,2016-10-20T20:08:04Z,nit: unneeded import,0,0.9820513725280762
84365476,1336,hachikuji,2016-10-20T20:09:08Z,could this be `consumers`. the `summaries` suffix seems a tad verbose.,0,0.7640059590339661
84366002,1336,hachikuji,2016-10-20T20:12:08Z,"nit: since we've converted most of these to use string interpolation, maybe we could do the same here? i noticed a couple others.",0,0.9785047769546509
84369348,1336,vahidhashemian,2016-10-20T20:30:13Z,"sure, sounds fair.",0,0.7039673924446106
84369482,1336,vahidhashemian,2016-10-20T20:30:56Z,i'll try to remove them. i see that their occurrences are beyond what's in this patch.,0,0.9142088890075684
84379640,1336,vahidhashemian,2016-10-20T21:28:38Z,you're right. thanks. i'll fix this in the next patch.,1,0.9549732208251953
84388805,1336,vahidhashemian,2016-10-20T22:28:24Z,not sure if i follow this one?,0,0.7239853143692017
84390074,1336,vahidhashemian,2016-10-20T22:38:02Z,never mind. i think you mean something like [code block],0,0.9233716726303101
84391557,1336,hachikuji,2016-10-20T22:49:38Z,"yeah, something like that. kind of hard to tell sometimes when you're trying to get a little too cute, but using `map` and `foreach` seems to generally be preferred over an explicit check for `isdefined` or `isempty`.",0,0.8853756189346313
84391755,1336,hachikuji,2016-10-20T22:51:12Z,"the general rule is to omit the parenthesis if the function does not mutate any state. no need to catch all such cases, it just stood out a bit on this line.",0,0.9852235317230225
84513550,1336,hachikuji,2016-10-21T16:45:27Z,"i may have missed it, but how do we know this `get` is safe? should we match using the option instead?",0,0.5898348093032837
84520691,1336,vahidhashemian,2016-10-21T17:53:51Z,"i believe for the zookeeper-based consumers the `describegroup` returns either `none` for `assignments` or some array (and the array cannot be empty because as soon as a group starts there is an assignment row). therefore, this line would not be reached in that case. and for java based consumer groups as far as i can tell `state` always has some value, and it cannot be `none`. so this line would be safe to call. having said that i'm ok with checking `state` here instead of `state.get`. one more question. i tried creating a new topic and starting an old consumer consuming from that topic belonging to a new consumer group. when i tried `describe` with this patch i get this output for a few seconds, and then the error vanishes as the initializations are done. are we ok with this behavior? [code block]",0,0.844297468662262
84525026,1336,vahidhashemian,2016-10-21T18:36:18Z,this is the refactored code for `state` check. please let me know if you see issues with it. thanks.,1,0.9355164766311646
84536951,1336,hachikuji,2016-10-21T20:15:14Z,nit: you can use `nonempty`.,0,0.9891614317893982
84536970,1336,hachikuji,2016-10-21T20:15:23Z,"couple naming suggestions: 1. `member-id` -> `consumer-id` 2. `member-host` -> `host` what do you think? also, it seems neither of these options are available for the old consumer. maybe it would reduce the noise if we leave them out of the output in that case? not sure if there's a clean way to do that though.",0,0.9816646575927734
84539540,1336,vahidhashemian,2016-10-21T20:33:45Z,"i can make the name changes. regarding availability for old consumer, it's actually `member_host` and `client_id` (the last two) that will be blank in the output. i think i can leverage the `node` variable (that i introduced to report the coordinator broker id for new consumer option) and based on that decide whether the last two column should be printed or no. i'll submit an update shortly and you can take a look and let me know what you think. thanks.",1,0.8998216390609741
84542689,1336,vahidhashemian,2016-10-21T20:54:10Z,i don't feel very happy about this repeating check. to me it was either this or totally separate print statements for old and new consumers in the `match` block of line 114 above. what do you think?,-1,0.9744486212730408
84543875,1336,hachikuji,2016-10-21T21:00:56Z,it might be a little less annoying if you put the result in a val (e.g. `usenewconsumer`). maybe you could even pass `opts.useoldconsumer` into this function to avoid the need to check the coordinator.,0,0.6809207201004028
84544537,1336,vahidhashemian,2016-10-21T21:05:24Z,"btw, i'm thinking printing ""-"" instead of """" when data is not available or does not apply would look better and more readable (especially when there are multiple rows with blank columns). compare [code block] with [code block]",0,0.9674352407455444
84545114,1336,hachikuji,2016-10-21T21:09:20Z,good idea.,1,0.9657697081565857
84545242,1336,vahidhashemian,2016-10-21T21:10:22Z,passing `opts.useoldconsumer` sounds good; but that doesn't avoid the need for this repeating `if` block. or i misunderstood?,0,0.9332484006881714
84545937,1336,hachikuji,2016-10-21T21:15:37Z,"yeah, you still need it. seems not too bad to me. you could move it outside the loop, but then you'd need to repeat the loop in both arms of the `if`, which seems worse.",-1,0.9223122596740723
84546160,1336,vahidhashemian,2016-10-21T21:17:00Z,"right, i'll keep it as is then. thanks.",1,0.9350993633270264
84551578,1336,hachikuji,2016-10-21T21:58:36Z,"really sorry to keep adding comments... did we print this before? it seems unnecessary given that we require the group to be passed on the command line. one downside to having this line and the one below is that it's a little tougher to parse the output. on the other hand, having a way to get the coordinator seems useful for debugging. i wonder if it would make sense to add that to the `--list` option in a separate patch. what do you think?",-1,0.9894385933876038
84552130,1336,vahidhashemian,2016-10-21T22:03:39Z,that's fine with me. i added these two lines (along with [a link] and [a link] because there was a request on the corresponding jira asking for some clarification on the printed output. i'm fine with removing them and have the `--list` option report the coordinator broker id. should i also leave out the other two lines i linked to above?,0,0.9812560677528381
84553085,1336,hachikuji,2016-10-21T22:12:24Z,"looked back at the jira. maybe you could print the warning messages to stderr? i also saw jun's comment about printing the coordinator. it's a little odd to print it as a column in the table as you suggested (since it will be the same for all members), but that might be a better choice. i'd be ok with either doing that or adding it to the `--list` option separately. the latter might be a little nicer since this already has a lot of columns and i think we should have the coordinator information already when using `--list`.",0,0.9263902306556702
84553913,1336,vahidhashemian,2016-10-21T22:18:00Z,"i also think using `--list` to report the coordinator id is better for the same reasons you mentioned. i'll submit another update shortly, and open a jira for reporting the coordinator.",0,0.9792962670326233
108825282,2744,junrao,2017-03-30T01:39:13Z,"hmm, not sure if this is accurate to capture the network thread utilization. what we are recording is essentially the responsesendtime, which includes the time for waiting for the socket to be writable. that portion of the time actually doesn't tie up the network threads and shouldn't be accounted for in the request time. also, this seems to only cover the network thread time for sending responses, not for reading requests (which could be significant for produce requests). i was thinking that we may need to do the following. in selector.pollselectionkeys(), we will measure the time spent for reading/writing each kafkachannel and propagate the time back to the caller. then, we can account for both request/response time in network threads in socketserver.",0,0.9473779201507568
108825299,2744,junrao,2017-03-30T01:39:22Z,quotathreadpercentdefault => quotarequestpercentdefault ?,0,0.9850335717201233
108825310,2744,junrao,2017-03-30T01:39:26Z,it seems that toint is redundant.,0,0.8778741359710693
108825313,2744,junrao,2017-03-30T01:39:29Z,it seems that tolong is redundant.,0,0.8123461604118347
108825331,2744,junrao,2017-03-30T01:39:39Z,do we need to make this protected? it doesn't seems to be customized in the subclass and it doesn't seem that we can change it to anything other than rate().,0,0.9826001524925232
108825337,2744,junrao,2017-03-30T01:39:42Z,unused import,0,0.9649426341056824
108825350,2744,junrao,2017-03-30T01:39:48Z,utilizationthrottletimems => requestthrottletimems?,0,0.9882303476333618
108825356,2744,junrao,2017-03-30T01:39:52Z,remove space after trace( ?,0,0.9697183966636658
108825402,2744,junrao,2017-03-30T01:40:17Z,"hmm, i am wondering if we really need to subtract bandwidththrottletimsms from the throttle time. while the response is delayed for bandwidththrottletimsms, some time has passed, which should bring down the value of the metric when we check the request quota. then, naturally, this request will be delayed less for request quota violation.",0,0.9104721546173096
108826148,2744,junrao,2017-03-30T01:49:43Z,we throttle leaderandisrrequest if it's unauthorized. should we do the same thing here?,0,0.8977300524711609
108916491,2744,rajinisivaram,2017-03-30T12:49:37Z,done.,0,0.9759407639503479
108916544,2744,rajinisivaram,2017-03-30T12:49:54Z,removed.,0,0.9311882257461548
108916572,2744,rajinisivaram,2017-03-30T12:50:00Z,removed.,0,0.9311882257461548
108916610,2744,rajinisivaram,2017-03-30T12:50:13Z,reverted.,0,0.8778582215309143
108916623,2744,rajinisivaram,2017-03-30T12:50:18Z,removed.,0,0.9311882257461548
108917372,2744,rajinisivaram,2017-03-30T12:53:19Z,in this case `authorizeclusteraction` method throws an exception and the response is sent from the exception handler in `handle`. all responses sent from the exception handler are throttled.,0,0.9887646436691284
108917401,2744,rajinisivaram,2017-03-30T12:53:29Z,done.,0,0.9759407639503479
108917419,2744,rajinisivaram,2017-03-30T12:53:34Z,done.,0,0.9759407639503479
108917772,2744,rajinisivaram,2017-03-30T12:55:10Z,"yes, i wasn't sure which way to go. either way, i think the throttle times will correct themselves over time. i have removed the subtraction.",0,0.8952904939651489
108919055,2744,rajinisivaram,2017-03-30T13:00:59Z,"thank you, i have reworked the code for recording network thread time as you suggested. at the moment, ssl/sasl handshake time is included in the time for the first request. is that reasonable? i can clear the time after authentication if it is confusing.",1,0.6323969960212708
108923119,2744,rajinisivaram,2017-03-30T13:19:36Z,"sorry, had to revert that since `toint` was required for newer versions of scala.",-1,0.986096203327179
109046976,2744,junrao,2017-03-30T21:53:07Z,"could we add a comment somewhere so that people know that if they want to add a non-internal request in the future, they would need to include the throttle time field?",0,0.9870477318763733
109047035,2744,junrao,2017-03-30T21:53:31Z,this takes care of the time spent on receiving requests. we will need to do the same thing to track the time on sending responses.,0,0.9820829629898071
109049180,2744,junrao,2017-03-30T22:05:52Z,"the approach in the patch works. but one issue is that the implementor of all future requests will have to deal with throttling the responses directly. another approach is to do the throttling early in handle(). if a request needs to be delayed, we first throttle it and then hand it over to the specific request handler. this way, we just need to implement the request throttling logic in one place and all future requests don't have to be aware of it. we probably need to mark whether a request is at the cluster level so that we can throttle unauthorized internal requests too. also, not sure if there is an easier way for the request handler thread to pick up the requests after throttling is done. if there is, this may be a simpler approach?",0,0.974959135055542
109049691,2744,junrao,2017-03-30T22:08:59Z,that seems fine for now. perhaps we could add a comment in case we need to revisit in the future?,0,0.9418774247169495
109146033,2744,rajinisivaram,2017-03-31T12:09:54Z,i have added unit test in `apikeystest` that checks that all responses except those explicitly excluded contain a field named `throttle_time_ms`. there is a comment in the test as well to ensure that new requests either contain the field or are manually added to the test's exclusion list.,0,0.9893519282341003
109146742,2744,rajinisivaram,2017-03-31T12:15:02Z,"the time is accumulated in `selector` and includes the full time spent for each channel in `pollselectionkeys`. for each request, the accumulated time is used and the value is reset. this time includes the time for write of the previous response and the time for read of the current request. i have added a comment in the code.",0,0.9868159890174866
109149032,2744,rajinisivaram,2017-03-31T12:30:54Z,"thank you for the review. it will be nice to handle throttling in a single place. however, handling of all new requests need to be aware of throttling, so that they add the throttling time to the response. the bigger issue is the exclusions. we need to authorize in a central place for `clusteraction`. and worse, we need to handle `produce` differently since we don't want to throttle until after the request is processed and the memory can be released. we probably want to throttle later for `fetch` as well since we are relying on the bandwidth throttle time to reduce the request throttle time. we will need to record two more timestamps to take into account time spent before throttle in some cases and after throttle in others. and as you mentioned, we still want the request to be processed after throttling on the request handler thread. taking all that into account, i am not sure it is worthwhile to restructure the code to centralize the throttling logic. i have updated `requestquotatest` to ensure that unauthorized requests of all types are throttled. and also to check that all requests not explicitly excluded are throttled and return throttle time in response. this should catch any missing throttling in new requests. let me know if this is sufficient or whether i should try out the centralized approach.",1,0.8881529569625854
109149244,2744,rajinisivaram,2017-03-31T12:32:32Z,added comment in `socketserver`.,0,0.9881474375724792
109189436,2744,rajinisivaram,2017-03-31T15:42:41Z,"after writing the comment above, i realized that it sounds rather odd. so i have updated the code to record network thread time when request metrics are updated, so that receive+send are recorded together. this does also ensure that the last network time on each connection is recorded and it would work even if requests on a connection use different clientids. throttling is still performed only on subsequent requests.",-1,0.6120970845222473
110187347,2744,ijuma,2017-04-06T15:08:36Z,why is this an `atomiclong` instead of a plain long?,0,0.962711751461029
110188076,2744,ijuma,2017-04-06T15:11:24Z,"hmm, it seems a bit unfortunate that we need to do a `system.nanotime` per selection key. have we done any measurements on the overhead?",-1,0.9167216420173645
110188616,2744,ijuma,2017-04-06T15:13:33Z,i think we'd want to override `parseresponse` for `api_versions` only.,0,0.9888745546340942
110189171,2744,ijuma,2017-04-06T15:15:19Z,i wonder if there's a way to add this to `responseheader` in a compatible way. it seems a bit annoying to have to add that to every response.,-1,0.9796578288078308
110189630,2744,ijuma,2017-04-06T15:17:01Z,"since we use `ms`, should we not be using `ns` instead of `nanos`?",0,0.9875117540359497
110190164,2744,ijuma,2017-04-06T15:19:12Z,"nit: the logic inside this catch has become a bit complicated. can we perhaps extract methods? also, something i was thinking about recently is that methods like `geterrorresponse` could throw an exception due to bugs. it would be nice for us not to leak connections in such cases.",0,0.7172744870185852
110190689,2744,ijuma,2017-04-06T15:20:48Z,"if we could somehow add the throttle time in the response header, it would be easier to handle it in a generic way for the typical cases.",0,0.9836453199386597
110422348,2744,rajinisivaram,2017-04-07T15:52:11Z,"there are a few requests which don't have throttle time (controlledshutdown, stopreplica etc. used for inter-broker and not by producer/consumer). so it made sense to add throttle time to individual requests. error codes seem to be handled this way. but my main concern was compatibility. even if we looked at request version to determine the response header version, there is still the issue of `apiversionsresponse` which needs to be handled. according to kip-35, `apiversionresponse.errorcode is guaranteed to be the first int16 of the response for all future versions of apiversionrequest`. i didn't want to break that assumption.",0,0.9142850041389465
110422668,2744,rajinisivaram,2017-04-07T15:53:33Z,i couldn't see any way around it. i will kick off system test runs to see the impact.,0,0.7795494198799133
110422700,2744,rajinisivaram,2017-04-07T15:53:42Z,done.,0,0.9759407639503479
110423058,2744,rajinisivaram,2017-04-07T15:55:21Z,"both `ns` and `nanos` are already used in the code. i chose `nanos` everywhere in the pr since it stands out better from `ms`, especially since i was changing some measurements from millis to nanos. but i am ok with switching to `ns` if that is preferable.",0,0.9816941618919373
110423731,2744,rajinisivaram,2017-04-07T15:58:29Z,"have moved to a method. i think errors are propagated and logged. we won't close acks=0 connections if `geterrorresponse` threw an exception, but perhaps that is ok since that would still not be a leaked connection?",0,0.9853889346122742
110425748,2744,rajinisivaram,2017-04-07T16:08:22Z,because the value is updated on the network thread and read-and-reset on the request handler thread. i have added a comment.,0,0.987224817276001
110442824,2744,junrao,2017-04-07T17:39:04Z,our system test currently doesn't do perf validation well. it would be useful to just run producerperformance and consumerperformance and see if there is any noticeable degradation.,0,0.9814977645874023
110478783,2744,rajinisivaram,2017-04-07T20:42:21Z,i ran `producerperformance` and `consumerperformance` on my laptop and didn't see any noticeable difference. this is the throughput in mb/s (average of three runs): test (message size) | trunk | with pr -------------------------|--------------|------------ producer (100 bytes) | 158.68 | 160.18 producer (1000 bytes) | 355.43 | 350.36 consumer (100 bytes) | 376.20 | 378.52 consumer (1000 bytes) | 559.45 | 559.45,0,0.8780256509780884
112594508,2744,junrao,2017-04-21T01:43:24Z,"perhaps we should only fall back to version 0 of the request if the error is unsupported_version? for other kinds of error, just disconnect?",0,0.975967526435852
112594514,2744,junrao,2017-04-21T01:43:29Z,"instead of returning atomiclong, could we just reset to 0 and return a long?",0,0.9863545298576355
112594523,2744,junrao,2017-04-21T01:43:37Z,"hmm, not sure why we need this. it seems that the client should always use the requested version to parse the response of api_versions?",0,0.9527641534805298
112594538,2744,junrao,2017-04-21T01:43:44Z,"this makes things a bit more complicated. i was thinking of the following. in updaterequestmetrics(), we remember networkthreadtime as previousnetworkthreadtime. in kafkaapis, we can just add previousnetworkthreadtime to the throttler. that way we don't need this callback. will that be better?",0,0.8840670585632324
112594555,2744,junrao,2017-04-21T01:43:54Z,it seems that we should update the instance level localcompletetimenanos instead of a local one?,0,0.988520085811615
112594610,2744,junrao,2017-04-21T01:44:36Z,apikey in the comment needs to be changed accordingly.,0,0.9831932783126831
112594983,2744,junrao,2017-04-21T01:49:17Z,will subsequently used => will subsequently be used,0,0.9860025644302368
112726629,2744,rajinisivaram,2017-04-21T16:23:31Z,done.,0,0.9759407639503479
112726925,2744,rajinisivaram,2017-04-21T16:24:55Z,atomiclong is returned so that the the value can be updated from the i/o thread when a request is complete without propagating `kafkachannel` to the request handling code.,0,0.989315390586853
112727184,2744,rajinisivaram,2017-04-21T16:26:18Z,"if client sends apiversionsrequest with a higher version that client supports, broker responds with a version 0 response that indicates unsupported version.",0,0.9866887927055359
112729035,2744,rajinisivaram,2017-04-21T16:36:20Z,"hmm... network thread time needs to be accumulated against the (user, client-id) and needs to include the time for the sending the response. the callback avoids having to propagate (user, client-id).",0,0.9782448410987854
112729071,2744,rajinisivaram,2017-04-21T16:36:30Z,done.,0,0.9759407639503479
112729097,2744,rajinisivaram,2017-04-21T16:36:38Z,done.,0,0.9759407639503479
112729130,2744,rajinisivaram,2017-04-21T16:36:46Z,done.,0,0.9759407639503479
112791899,2744,junrao,2017-04-21T23:13:34Z,could we consistently add newthrottletimefield() as the first field?,0,0.9871643781661987
112791907,2744,junrao,2017-04-21T23:13:41Z,"offset_for_leader_epoch_response is an inter broker request. so, we shouldn't add a throttle field.",0,0.9868855476379395
112791941,2744,junrao,2017-04-21T23:14:08Z,"it might be useful to report all the time still as ms, but up to micro sec level accuracy now that we track with nanosec.",0,0.9806535840034485
112791964,2744,junrao,2017-04-21T23:14:21Z,"for request quota, since we are collecting request time in nanosecs already, it will be useful to create a rate with nanosec as the time unit. this will make the measurement more accurate.",0,0.9787279963493347
112791985,2744,junrao,2017-04-21T23:14:32Z,"hmm, in this case, we probably only want to throttle if the exception is related to authorization. for any other exceptions, we should send an error immediately?",0,0.9742034673690796
112791992,2744,junrao,2017-04-21T23:14:40Z,"hmm, this can be a bit tricky. fetch requests from the follower are considered internal and shouldn't be throttled.",0,0.5247662663459778
112792013,2744,junrao,2017-04-21T23:14:57Z,"hmm, when there is no data, the consumer will wait for the timeout. so, not sure if this is enough to trigger the throttling. we probably need to either set a low maxwait in consumer config and set the quota to be really low.",0,0.8654335737228394
112792018,2744,junrao,2017-04-21T23:15:02Z,"hmm, not sure where the test is.",0,0.5174345970153809
112792036,2744,junrao,2017-04-21T23:15:18Z,"why is the replicaid 5000? that indicates it's from a follower. also, i am wondering if 100 maxwait is enough to trigger throttling.",0,0.9551440477371216
112792083,2744,junrao,2017-04-21T23:15:48Z,"got it. an alternative is to call networkthreadtimenanos() in socketserver.processnewresponses() and processcompletedsends(). then we can just reset and return the value, which is easier to understand?",0,0.9854741096496582
112792089,2744,junrao,2017-04-21T23:15:53Z,thanks for the explanation. could we add that as comment in the code?,1,0.7117745280265808
112792094,2744,junrao,2017-04-21T23:15:56Z,got it. this is fine then.,0,0.8827566504478455
112908803,2744,rajinisivaram,2017-04-24T10:06:26Z,"according to kip-35, the java clients don't rely on this, but just in case some other clients do, i have left `error_code` as the first field for `apiversionsresponse`.",0,0.9853464365005493
112908831,2744,rajinisivaram,2017-04-24T10:06:36Z,fixed.,0,0.9810503125190735
112909448,2744,rajinisivaram,2017-04-24T10:09:51Z,the yammer metrics `histogram` class that tracks time only takes long and not double. hence the millisecond value is used.,0,0.9849242568016052
112910225,2744,rajinisivaram,2017-04-24T10:14:24Z,"for request quota, values are recorded as double, so even though they use millisecond as unit to be consistent, they have higher precision. isn't that sufficient?",0,0.9857450127601624
112910635,2744,rajinisivaram,2017-04-24T10:16:49Z,"yes, `authorizeclusteraction` takes care of throttling for unauthorized request and all other paths including error path goes through this `sendresponseexemptthrottle` which does not perform throttling.",0,0.9840850830078125
112910724,2744,rajinisivaram,2017-04-24T10:17:22Z,"oops, you are right. fixed.",1,0.630637526512146
112911096,2744,rajinisivaram,2017-04-24T10:19:27Z,consumers in this test are configured with `fetch.max.wait.ms=0`. the quota is set very small as well to trigger throttling.,0,0.9888827204704285
112911132,2744,rajinisivaram,2017-04-24T10:19:36Z,"oops, fixed.",0,0.8505692481994629
112911223,2744,rajinisivaram,2017-04-24T10:20:09Z,copy-paste error. fixed and set maxwait to zero.,0,0.9638903141021729
112911309,2744,rajinisivaram,2017-04-24T10:20:38Z,done.,0,0.9759407639503479
112911522,2744,ijuma,2017-04-24T10:21:59Z,i think the atomiclong comment should be moved to the field.,0,0.9867450594902039
112912615,2744,ijuma,2017-04-24T10:28:34Z,is there a reason why we don't replace the 4 lines above with: [code block],0,0.982529878616333
112917077,2744,rajinisivaram,2017-04-24T10:55:44Z,done.,0,0.9759407639503479
112917164,2744,rajinisivaram,2017-04-24T10:56:08Z,"thank you, done.",1,0.7101117372512817
112965720,2744,junrao,2017-04-24T14:46:06Z,"ok, could we add a comment that error_code has to be the first field in apiresponse?",0,0.9883450269699097
112965772,2744,junrao,2017-04-24T14:46:20Z,i was actually referring to line 169 where we log the time components in trace logging. it's useful to see more precise time there since sometimes the time may take less than 1ms.,0,0.9846829771995544
112965811,2744,junrao,2017-04-24T14:46:30Z,thanks. that should be enough then.,1,0.7617903351783752
112969979,2744,junrao,2017-04-24T15:00:57Z,"here, we throttle independent of the exception type. perhaps, it's better to only engage in throttling if the exception is clusterauthorizationexception?",0,0.9812731742858887
113048200,2744,rajinisivaram,2017-04-24T20:30:53Z,fixed to throttle only for `clusterauthorizationexception` for broker-only requests.,0,0.986240804195404
113595344,2744,junrao,2017-04-27T00:51:18Z,this is an inter-broker request as well and clusteraction should be true.,0,0.9885961413383484
113596378,2744,junrao,2017-04-27T01:02:52Z,"this is an inter-broker request. so, no throttling needed.",0,0.9852977395057678
113597310,2744,junrao,2017-04-27T01:13:52Z,perhaps it's better to pass the networkthread time to request.updatemetrics() and call the recordnetworkthreadtimecallback there?,0,0.9882716536521912
113597451,2744,junrao,2017-04-27T01:15:46Z,"hmm, we probably don't want to call recordnetworkthreadtimenanos here since it will be called in processcompletesends() again. instead, it seems that we want to call recordnetworkthreadtimenanos() in all places where we call request.updaterequestmetrics().",0,0.9860040545463562
113598851,2744,junrao,2017-04-27T01:31:19Z,it's actually read and reset by the broker's network thread.,0,0.9862632751464844
113599869,2744,junrao,2017-04-27T01:42:13Z,"for the trace logging in line 177, could we report all the time still as ms, but up to micro sec level accuracy?",0,0.988887369632721
113600212,2744,junrao,2017-04-27T01:45:55Z,"given this, should we just remove line 65?",0,0.9857189059257507
113694991,2744,ijuma,2017-04-27T13:29:57Z,"sorry for the delay on this one. so, one way to do this would be the following: 1. add two fields to responseheader _if_ the request version is higher than the version before this pr: error_code, throttle_time_ms (in this order) 2. remove any top-level error_code in the new version of all affected responses 3. remove throttle_time_ms from fetchresponse and produceresponse in the new version 4. throttle_time_ms is always 0 for requests that are never throttled as part of this, we would also solve the issue that we currently have no way to return generic errors via the protocol. since we are bumping the protocol version for so many requests, it seems like it would be a good opportunity to fix both issues at the same time. is there a reason why this is a bad idea or would not work?",-1,0.9871360063552856
113730628,2744,ijuma,2017-04-27T15:38:43Z,"discussed this with . the main challenge with this option is having the top level error field for every response. this would probably affect a lot of code: 1. we would need to handle this top level error code everywhere. 2. a bunch of protocols that currently have a top level error code would no longer have them, so a bunch of code would have to be updated as well. so, it doesn't seem appropriate to do this as part of this kip.",0,0.683148980140686
113731419,2744,rajinisivaram,2017-04-27T15:42:10Z,thank you for looking into this.,1,0.5488899946212769
113735595,2744,junrao,2017-04-27T15:58:07Z,could we make this and a few other methods in the class private?,0,0.9882156848907471
113736431,2744,junrao,2017-04-27T16:01:12Z,"hmm, is the test added? i don't see the code for submittest that checks the throttling field in the response.",0,0.9820804595947266
114028254,2744,rajinisivaram,2017-04-28T22:05:14Z,fixed.,0,0.9810503125190735
114028270,2744,rajinisivaram,2017-04-28T22:05:25Z,fixed.,0,0.9810503125190735
114028303,2744,rajinisivaram,2017-04-28T22:05:39Z,fixed.,0,0.9810503125190735
114028317,2744,rajinisivaram,2017-04-28T22:05:47Z,done.,0,0.9759407639503479
114028402,2744,rajinisivaram,2017-04-28T22:06:32Z,"yes, you are right. replaced with `long` and updated comment.",0,0.9748380184173584
114028417,2744,rajinisivaram,2017-04-28T22:06:39Z,done.,0,0.9759407639503479
114028438,2744,rajinisivaram,2017-04-28T22:06:52Z,done.,0,0.9759407639503479
114028518,2744,rajinisivaram,2017-04-28T22:07:28Z,"sorry, had forgotten the tests, fixed now.",-1,0.9847556948661804
114028539,2744,rajinisivaram,2017-04-28T22:07:37Z,done.,0,0.9759407639503479
511148601,9487,wcarlson5,2020-10-23T20:48:43Z,this will call closetoerror but i am testing if that has a problem. so far it does not,0,0.9565296173095703
511149017,9487,wcarlson5,2020-10-23T20:49:47Z,moved into stream thread because of a concurrent operation exception that appeared,0,0.9850356578826904
512320447,9487,wcarlson5,2020-10-26T23:03:45Z,method was a few lines too long,0,0.943703293800354
514527605,9487,lct45,2020-10-29T19:57:51Z,is this spacing on purpose?,0,0.9819825887680054
514531597,9487,lct45,2020-10-29T20:03:00Z,is this section going to be re-added after the other thread handling stuff gets figured out?,0,0.9838645458221436
514535353,9487,lct45,2020-10-29T20:07:44Z,supposed to be here?,0,0.9723954796791077
514535737,9487,lct45,2020-10-29T20:08:33Z,two new lines in a row,0,0.9753912687301636
514536366,9487,lct45,2020-10-29T20:09:41Z,extra line,0,0.9743177890777588
514536509,9487,lct45,2020-10-29T20:09:56Z,extra line (:,0,0.9716169238090515
514538306,9487,lct45,2020-10-29T20:13:34Z,extra line,0,0.9743177890777588
514540200,9487,lct45,2020-10-29T20:17:02Z,line!,0,0.7899169921875
514566700,9487,wcarlson5,2020-10-29T21:05:19Z,it will. i don't know if we should merge as comment or just add it later,0,0.973760724067688
514567028,9487,wcarlson5,2020-10-29T21:05:43Z,same as the other use in ks,0,0.9860288500785828
516994424,9487,vvcephei,2020-11-03T22:32:35Z,"[code block] in l389, we say that we throw an exception if the handler is null, which sounds like a more reasonable api to me.",0,0.9824755191802979
516995632,9487,vvcephei,2020-11-03T22:35:32Z,what's up with the `` on this line? i don't think i've seen that before.,0,0.858396589756012
516996830,9487,vvcephei,2020-11-03T22:38:42Z,"it's normally kinda weird to merge commented-out code. i'd either delete it or instead have a todo, like `// todo kafka-xxxx: add case replace_stream_thread once kip-? is implemented`, where `kafka-xxxx` is a follow-up ticket you create to implement this feature.",-1,0.9609023332595825
516998180,9487,vvcephei,2020-11-03T22:41:56Z,"[code block] just a little extra information, so we don't always have to pull up this code block to remember what exact response action this message corresponds to.",0,0.9843095541000366
517009538,9487,vvcephei,2020-11-03T23:11:46Z,[code block] didn't follow the prior message. is this what you meant?,0,0.9699562191963196
517009778,9487,vvcephei,2020-11-03T23:12:30Z,[code block] similar confusion here...,-1,0.6557585000991821
517012283,9487,vvcephei,2020-11-03T23:20:08Z,"this doesn't look like an ""error"". at best it's a ""warn"" log, but only if we think that this combination definitely looks like a misconfiguration. even then, why wouldn't we check for the misconfiguration in kafkastreams, since both the new and old handlers would be set over there?",0,0.9388132691383362
517012839,9487,vvcephei,2020-11-03T23:21:52Z,[code block] this looked a bit off...,0,0.681897759437561
517013547,9487,vvcephei,2020-11-03T23:24:09Z,it doesn't look like this needs to be shared outside of this thread. it seems like it just needs to be shared between the streamthread and its consumer?,0,0.8539047241210938
517464968,9487,cadonna,2020-11-04T16:19:46Z,could you please also add the needed changes to system test `streams_upgrade_test.py::streamsupgradetest.test_version_probing_upgrade` to this pr.,0,0.9807283282279968
517474129,9487,cadonna,2020-11-04T16:32:17Z,"i guess this should be 2.8.0, shouldn't it?",0,0.9697343111038208
517481718,9487,wcarlson5,2020-11-04T16:43:03Z,i don't remember putting it there so it was probably a mistake,-1,0.6497936248779297
517485257,9487,wcarlson5,2020-11-04T16:48:10Z,that works,0,0.9757509231567383
517486135,9487,cadonna,2020-11-04T16:49:27Z,i would also remove the commented-out code.,0,0.9868742823600769
517505173,9487,cadonna,2020-11-04T17:18:01Z,wouldn't it also be possible to start a shutdown thread here which closes the client without timeout? i think the other shutdown thread in close is rather useless (or i do simply not get its value).,-1,0.564938485622406
517507950,9487,cadonna,2020-11-04T17:22:26Z,"imo, it would be better to extract code to methods instead of removing some lines.",0,0.9866486191749573
517543638,9487,ableegoldman,2020-11-04T18:22:10Z,can you also leave a comment here reminding us to fix the version probing system test whenever this protocol number is bumped? since we apparently always forget,0,0.9814310073852539
517576758,9487,wcarlson5,2020-11-04T19:20:51Z,i think it is simpler to check in the stream thread because we don't in kafkastreams if the handlers have been set so we would have to check the stream thread a global thread so it would be much easier to just check in the thread. i do agree that it should be bumped down to warn through.,0,0.9675431847572327
517621757,9487,wcarlson5,2020-11-04T20:47:05Z,you are right it seems that it is not necessary,0,0.9350305795669556
517627843,9487,wcarlson5,2020-11-04T20:59:16Z,"thanks for the reminder. i think i i under stood the test ad incrementing to the next version, as the version is now 9",1,0.9510864019393921
517909467,9487,cadonna,2020-11-05T09:32:23Z,is this comment correct? in this code path we do not check that all threads have been stopped.,0,0.9790166020393372
517910538,9487,cadonna,2020-11-05T09:34:07Z,could you also remove the commented-out code here.,0,0.9875739216804504
517916345,9487,cadonna,2020-11-05T09:43:22Z,the name is a bit ambiguous. i would go for `streamsuncaughtexceptionhandlerintegrationtest`,0,0.8824637532234192
517993498,9487,cadonna,2020-11-05T11:51:47Z,"what is the benefit of using a latch versus simply sleeping here? actually, you should use `streamstestutils.startkafkastreamsandwaitforrunningstate()` to avoid flakiness coming from the kafka streams client not being in state running before the verifications.",0,0.9853491187095642
517995934,9487,cadonna,2020-11-05T11:55:58Z,[code block] an application is actually a group of kafka streams clients (or instances).,0,0.9864417314529419
518008710,9487,cadonna,2020-11-05T12:19:08Z,you could wait for this flag to become true with `testutils.waitforcondition()` before you verify the other criteria.,0,0.9891948699951172
518010780,9487,cadonna,2020-11-05T12:23:05Z,why do clean the state twice?,0,0.7807225584983826
518014119,9487,cadonna,2020-11-05T12:29:10Z,why do you need to set all these properties?,0,0.9679861664772034
518021251,9487,cadonna,2020-11-05T12:41:57Z,i would remove these comments.,0,0.9788574576377869
518033723,9487,cadonna,2020-11-05T13:03:05Z,"i had a hard time to understand this. we write just one record to the topic, but we end up processing two records. this is true, because we use two stream threads and there is no commit between the processing of the record of the first stream thread and the processing of the second stream thread. why do you use two stream threads here?",-1,0.8872092962265015
518035301,9487,cadonna,2020-11-05T13:05:41Z,most of the above comments also apply to the other tests.,0,0.985988438129425
518039024,9487,cadonna,2020-11-05T13:11:58Z,"why are those fields all package-private instead of private? we usually define string constants as `private static final string idempotent_topic = ""idempotenttopic""`.",0,0.9847620725631714
518042865,9487,cadonna,2020-11-05T13:18:06Z,i do not understand the motivation behind this topic. could you clarify?,-1,0.8431287407875061
518044472,9487,cadonna,2020-11-05T13:20:37Z,unit tests for this case are missing.,0,0.9373760223388672
518263368,9487,wcarlson5,2020-11-05T18:14:44Z,yes,0,0.9564858078956604
518263937,9487,wcarlson5,2020-11-05T18:15:40Z,it might be but i do not think that it is necessary,0,0.9414443373680115
518264927,9487,wcarlson5,2020-11-05T18:17:21Z,i don't think we actually need it either way so i will just remove it,0,0.9482372403144836
518265803,9487,wcarlson5,2020-11-05T18:18:47Z,sure,0,0.9371067881584167
518267956,9487,wcarlson5,2020-11-05T18:22:27Z,"thats a good idea, i didn't see that option",1,0.8781186938285828
518269493,9487,cadonna,2020-11-05T18:25:11Z,"why not? it would be much cleaner. we would close all stuff like admin client and the metrics, remove the client metrics and set the state to not_running which is not necessarily done with timeout zero (probably not because of the death lock). additionally, we would get an nice info debug saying `streams client stopped completely` instead of `streams client cannot stop completely within the timeout`. ;-)",1,0.6449155807495117
518271215,9487,wcarlson5,2020-11-05T18:28:06Z,good idea,1,0.9742737412452698
518271918,9487,wcarlson5,2020-11-05T18:29:17Z,we probably don't need all of them. i will trim them down,0,0.9503525495529175
518274359,9487,wcarlson5,2020-11-05T18:33:24Z,i use 2 threads there to make sure the old behavior is being followed. just one thread dies and then the next thread is tries. the second thread makes sure that the new path is not closing the client unintentionally.,0,0.9768952131271362
518283539,9487,cadonna,2020-11-05T18:49:19Z,my last comment is not true! sorry! everything alright!,-1,0.9850867986679077
518326776,9487,wcarlson5,2020-11-05T19:55:10Z,actually the latch ensures the rebalance gets processed,0,0.9870280027389526
518335631,9487,wcarlson5,2020-11-05T20:11:16Z,it can be removed,0,0.9870566129684448
518371511,9487,wcarlson5,2020-11-05T21:17:19Z,added unit test,0,0.9818024039268494
518371722,9487,wcarlson5,2020-11-05T21:17:33Z,good questions,1,0.9326164722442627
518478117,9487,ableegoldman,2020-11-06T01:55:29Z,"i had a little trouble following the `handler` class. some trivial things -- eg the handler in the streamthread is named `streamsuncaughtexceptionhandler` but it's actually _not_ a `streamsuncaughtexceptionhandler`. also the usage of the return value; iiuc it's supposed to indicate whether to use the new handler or fall back on the old one. to me it sounds like if `handle` returns `true` that means we should handle it, ie we should _not_ rethrow the exception, but this looks like the opposite of what we do now. honestly either interpretation is ok with me, as long as it's documented somewhere do we really need the `handler` in the first place though? it's already pretty confusing that we have to deal with two types of handlers (old and new) so i'd prefer not to add a third unless it's really necessary. it seems like we can just inline the logic of whether to invoke the new handler or rethrow the exception, which would also clear up the confusion around the meaning of the return value. but i might be missing something here -- wdyt?",0,0.6286370754241943
518479524,9487,ableegoldman,2020-11-06T01:59:50Z,seems like we can just pass in a runnable with `kafkastreams::closetoerror` instead of adding a whole `shutdownerrorhook` functional interface,0,0.9786502122879028
518483194,9487,ableegoldman,2020-11-06T02:12:42Z,should this be logged at error?,0,0.9772555232048035
518484271,9487,ableegoldman,2020-11-06T02:16:48Z,"looks like we call `setstate(error)` three times in this method, is that intentional?",0,0.9752030372619629
518485280,9487,ableegoldman,2020-11-06T02:20:24Z,"it probably doesn't matter too much since `handlerebalancecomplete` doesn't do anything that important at the mometn, but it seems like we should call it before shutting down, not after.",0,0.9191488027572632
518485749,9487,ableegoldman,2020-11-06T02:22:02Z,this should probably stay `final` so we don't accidentally change it ever,0,0.9777554869651794
518488577,9487,ableegoldman,2020-11-06T02:32:29Z,"this cast makes me kind of uncomfortable...either the `assignmenterrorcode` that we have in the assignmentinfo is conceptually the same as the one we're adding to the subscriptioninfo (in which case it should be the same type), or it's not the same, in which case we should use a different variable to track it. personally i think it's probably simpler to keep them the same, and just add an `int` errorcode field to the subscription instead of a `byte` shutdownrequested field. but it's your choice",-1,0.9827896356582642
518489261,9487,ableegoldman,2020-11-06T02:35:01Z,"i think we should mirror the `errorcode` in the assignmentinfo here, both in terms of naming and type. if we're going to use the same assignorerror for both, then they should really be the same. and we may want to send other kinds of error codes in the subscription going forward: better to just encode a single `int` than a separate `byte` for every logical error code. i don't think we'll notice the extra three bytes since subscriptions aren't sent that frequently",0,0.9669240117073059
518837250,9487,wcarlson5,2020-11-06T15:46:47Z,we could do the logic inline how ever this does make it slightly simpler. also we only expose the `streamsuncaughtexceptionhandler` to the user and had a problem with the wrapping that again with the same type. so we introduced a wrapper class. if we renamed it from `handler` to `streamsuncaughtexceptionhandlerwrapper` would that make it more clear?,0,0.9851972460746765
518838421,9487,wcarlson5,2020-11-06T15:48:45Z,in the normal close method the corresponding log is also info. as multiple thread will be calling this at once i would rather not flood the logs with error unnecessarily.,0,0.8253194689750671
518838586,9487,wcarlson5,2020-11-06T15:49:01Z,"no, i hadn't seen that",0,0.854172945022583
518840121,9487,wcarlson5,2020-11-06T15:51:21Z,"we can do that, it doesn't seem make difference which order it is called. however if it is not called it will get stuck continually rebalancing. we return because setting the state to partitions assigned will cause an error",0,0.9539018273353577
518840602,9487,wcarlson5,2020-11-06T15:52:00Z,i was changing it intentionally but i think i can get away with not,0,0.7099826335906982
518842747,9487,wcarlson5,2020-11-06T15:55:21Z,yes we can,0,0.9763602614402771
518850419,9487,wcarlson5,2020-11-06T16:08:05Z,"i think i agree on the name, i am not sure about the type. we should be able to fit thousands of different error code into the byte so we should not run out of space. the reason the errorcode. is an integer in the first place is because there is not `atomicbyte` that i know of.",0,0.8433274626731873
518913514,9487,ableegoldman,2020-11-06T17:57:36Z,"gotcha. in that case maybe we shouldn't log anything here at all? or just reword it to clarify that this is expected (eg `""skipping shutdown since we are already in error""`) since ""can not transition..."" kind of sounds like something went wrong",-1,0.8588186502456665
518938852,9487,wcarlson5,2020-11-06T18:47:09Z,"that is a good idea, ill change the log",1,0.6863947510719299
520077048,9487,ableegoldman,2020-11-09T19:47:31Z,"i'm not really worried that we'd run out of space, i just think it sends a signal that the assignment and subscription error codes are semantically distinct and don't refer to the same underlying concept. so it seems better to go with the simpler approach than over-optimize to save an occasional three bytes",0,0.5490360856056213
520104884,9487,wcarlson5,2020-11-09T20:38:03Z,"[a link] i originally had it at int32, but suggested int16, now it is int8. would you be good with int16 or do you think int32 is the way?",0,0.9836218953132629
522596527,9487,ableegoldman,2020-11-13T03:51:22Z,this wording is a little difficult to parse,0,0.9196747541427612
522597486,9487,ableegoldman,2020-11-13T03:55:34Z,"just curious, what's the motivation for doing it like this vs just immediately throwing the exception?",0,0.8428424000740051
522598008,9487,ableegoldman,2020-11-13T03:57:50Z,nit: parameters unaligned,0,0.9866214990615845
522598142,9487,ableegoldman,2020-11-13T03:58:34Z,that's a lot of line breaks :upside-down_face:,-1,0.9751673340797424
522598707,9487,ableegoldman,2020-11-13T04:00:50Z,is everything after this line the same as the code in the regular `close()`? might be a good idea to move it to a separate method so we don't accidentally forget to update one of them if we ever need to make changes to how we close,0,0.9717062711715698
522613334,9487,ableegoldman,2020-11-13T04:26:45Z,"it seems like we shouldn't both handle the exception in the catch block and shut down the client in the finally block. if the new handler is used, then we've already shut down the client or possibly started to shut down the whole application. it's tricky, though, because if the old handler was used then we _do_ want to make sure that the global thread is all cleaned up before rethrowing the exception. seems like we need some way to detect whether we're using the old or the new handler after all. but i think you can do it without too many changes, since basically the rule is ""if they set a new handler at all or didn't set either handler, then use the new one"". so maybe you can just make the `streamsuncaughtexceptionhandler` a local field instead of the `consumer<>`, and leave it as `null` to indicate that the old handler should be used and therefore this shutdown logic should be invoked. otherwise just call the new handler directly. or something like that...you'd know this code better than me, wdyt?",0,0.8142552971839905
522616515,9487,ableegoldman,2020-11-13T04:30:37Z,"hmm...this one seems like it should be a fatal error, so is it safe to just pass it along to the user and let them potentially just keep replacing the thread? (i know that option doesn't exist yet, but it will). there are some instances where we interpret errors as permanently fatal and choose to shut down the entire application, eg some errors during assignment. should we do the same here? cc or for more context on this error",0,0.7072215676307678
522622229,9487,ableegoldman,2020-11-13T04:37:49Z,i think we should add the `errorcode` parameter to the existing constructor rather than add a new one. it shouldn't be possible to construct a version 9 subscription that doesn't have an `errorcode`,0,0.9876093864440918
522622882,9487,ableegoldman,2020-11-13T04:38:35Z,"nice, thanks for the comment. btw anytime we bump this protocol version we should add the corresponding unit tests, eg `subscriptioninfotest#shouldencodeanddecodeversion8()`",1,0.9788281321525574
522626697,9487,ableegoldman,2020-11-13T04:43:11Z,"does the comment relate to the `` suppression? either way this probably makes more sense as a comment on the pr than in the code. given how bad we are about updating comments, i'd try to avoid anything that describes a change and reserve code comments for describing what's currently going on (or better yet, ""why"")",-1,0.6078327298164368
522627296,9487,ableegoldman,2020-11-13T04:43:39Z,"same here, what is the comment referring to? also what does it mean for a test to be deprecated :thinking_face:",0,0.9734044671058655
522635059,9487,ableegoldman,2020-11-13T04:49:40Z,ditto here,0,0.8146205544471741
522639947,9487,ableegoldman,2020-11-13T04:55:41Z,"is the latch ever being counted down anywhere? you might want to take a look at some of the test utils, there's a lot of useful stuff so you don't have to implement everything from scratch. if you just want to make sure that the client gets to `closed` within 15s then i'd recommend `testutils#waitforcondition`",0,0.98042231798172
522641072,9487,ableegoldman,2020-11-13T04:57:10Z,is this the only property that changed? might be clearer if you just override what you need to here,0,0.9842631220817566
522650704,9487,ableegoldman,2020-11-13T05:09:14Z,"we should probably use an actual handler here to make sure it works with the globalthread. actually maybe we should add a few unit tests here to make sure that it closes down and rethrows when the old handler is used, but handles the exception internally when the new handler is used, etc",0,0.9870249032974243
522654080,9487,ableegoldman,2020-11-13T05:13:23Z,why set the exception handler in this test and no others?,0,0.9597411751747131
523028163,9487,cadonna,2020-11-13T15:35:28Z,"nit: usually we indent 4 spaces, not 8.",0,0.9844093918800354
523034271,9487,cadonna,2020-11-13T15:45:11Z,"are you sure this is the correct method to call? as far as i understand the the javadocs and the decompiled code, this method does not return the handler you can set on a `thread` with `setuncaughtexceptionhandler()`.",0,0.989474892616272
523041454,9487,cadonna,2020-11-13T15:56:14Z,"i guess, you wanted to do this [code block]",0,0.9844974279403687
523041842,9487,cadonna,2020-11-13T15:56:53Z,please use a more meaningful parameter name.,0,0.9814724922180176
523044111,9487,cadonna,2020-11-13T16:00:23Z,"i still have a question here. since the stream thread is alive when it calls `close()` there will not be a deadlock anymore. so, why do we call `close()` with duration zero?",0,0.9738278985023499
523069611,9487,wcarlson5,2020-11-13T16:40:19Z,changed to ` in order to get the thread uses use thread.currentthread()` does that work better?,0,0.988628089427948
523070844,9487,wcarlson5,2020-11-13T16:42:18Z,we have to do the casting in order to throw the exception. otherwise the compiler complains about checked vs unchecked exceptions,0,0.9627647995948792
523072781,9487,wcarlson5,2020-11-13T16:45:31Z,yes good catch,1,0.9606567025184631
523073595,9487,wcarlson5,2020-11-13T16:46:49Z,that is a lot of line breaks,-1,0.8960930109024048
523079456,9487,wcarlson5,2020-11-13T16:56:05Z,everything except the state we leave it in. we can move most of it to a helper,0,0.983389675617218
523079965,9487,wcarlson5,2020-11-13T16:56:55Z,we should be able to change it to `close()`,0,0.9861781597137451
523080590,9487,cadonna,2020-11-13T16:57:57Z,"the name is a bit confusing. the best i could come up is `handlestreamsuncaughtexceptionbydefault()`, but i am sure there is a better name.",-1,0.7415707111358643
523089743,9487,vvcephei,2020-11-13T17:06:49Z,"if that's the case, then we really should just set a flag on kafkastreams to indicate whether that handler has been set.",0,0.984549880027771
523090161,9487,wcarlson5,2020-11-13T17:07:04Z,there is a logic to use the old handler if the conditions you laid out are true. the odd series of casts of exception types in `handlestreamsuncaughtexceptiondefaultwrapper` are what makes this happen. this is a bit tricky but i think we want to close the client either way. as we don't have plans to replace the global thread and shutting down the application is best effort. we talked about this a while back and we decided the global handler was mainly for information and the return type we would try to follow but we need to make sure we at least close the client.,0,0.8452559113502502
523095231,9487,wcarlson5,2020-11-13T17:10:31Z,i think this is fine for now. when we add replace thread as an option we can include overrides when handling the response that prevent the thread from being restarted in certain error cases.,0,0.9598914980888367
523103147,9487,wcarlson5,2020-11-13T17:21:13Z,when we remove the old handler we either need to remove the test or remove the suppression. that is what i am hoping the comment will do,0,0.9724145531654358
523109393,9487,wcarlson5,2020-11-13T17:28:41Z,"i'll add that to the comment, and add a test",0,0.9861904382705688
523136568,9487,wcarlson5,2020-11-13T18:14:59Z,how about `defaultstreamsuncaughtexceptionhandler`?,0,0.9884170889854431
523138325,9487,wcarlson5,2020-11-13T18:17:29Z,we can just set a flag through to be safe,0,0.984818160533905
523141998,9487,wcarlson5,2020-11-13T18:21:29Z,same as above,0,0.9772257208824158
523230140,9487,wcarlson5,2020-11-13T21:01:25Z,"so the problem that i am facing is that many tests are set up to work with the old handler. i was able to adapt most to use the new handler but not all. some, like a few eos tests, require one thread to die at a time. so i either suppress the deprecation or tag the test as deprecated, thus indicating it should be removed when the old handler is. another problem is that a few tests rely on the threads dying one at a time or they test behavior in this case but they do not set an old handler. so i can either 1) set an old handler and mark for deletion or 2) adapt for the new out come. for the ones i could, i changed to the new flow but i could not do that with all of them. how would you suggest updating these tests?",-1,0.5997565388679504
523277374,9487,wcarlson5,2020-11-13T23:04:52Z,because otherwise the task migrated exception sends it into a endless rebalance,0,0.9477730989456177
523280093,9487,wcarlson5,2020-11-13T23:14:47Z,that is useful thanks. i went with `waitforapplicationstate`,1,0.9166339635848999
523280707,9487,wcarlson5,2020-11-13T23:17:00Z,agree,0,0.9757640957832336
523288678,9487,wcarlson5,2020-11-13T23:49:17Z,for the same reason i had to add to the other cases as the close from the new handler will not finish otherwise,0,0.970382034778595
523296833,9487,ableegoldman,2020-11-14T00:16:51Z,is there an extra `uses` in there or am i not looking at this sentence from the right angle?,0,0.9463231563568115
523302976,9487,ableegoldman,2020-11-14T00:47:17Z,"ah ok i thought we executed this cleanup logic in the globalstreamthread's `shutdown` method but now i see that's not true. sorry for the confusion there. i do see some minor outstanding issues here, mainly around the state diagram. let's say the user opts to `shutdown_client` in the new handler: the intended semantics are to end up in `not_running` but i think what would happen is that from the global thread we would immediately call `kafkastreams#close` , which kicks off a shutdown thread to wait for all threads to join and then sets the state to `not_running`. then when the handler returns, it would transition the global thread to `pending_shutdown` and then finally to `dead`. and during the transition to `dead`, we would actually end up transitioning the kafkastreams instance to `error`, rather than `not_running` as intended. so probably, we just need to update the `onchange` method in kafkastreams. this also reminds me of another thing, we need to update the fsm diagram and allowed transitions in kafkastreams to reflect the new semantics we decided on for error (which iirc is basically just to make it a terminal state). does that sound right to you?",-1,0.9757031798362732
523303062,9487,ableegoldman,2020-11-14T00:47:52Z,"i suspect the tests didn't catch this because we would still transition out of error to pending_shutdown and finally not_running in this case. but really, we shouldn't transition to error in the first place",0,0.8132449388504028
523311219,9487,ableegoldman,2020-11-14T01:05:18Z,"what happens if we try to read the error code of an earlier subscription version? i genuinely don't know what the generated code does, but we should make sure it doesn't throw an npe or something. could you add a unit test for this case?",0,0.9338805079460144
523319677,9487,ableegoldman,2020-11-14T01:15:05Z,"i think any test that's trying to verify some unrelated behavior and just using the ""one thread dies at a time"" paradigm as a tool to do so should not be deleted. i'm sure in most if not all cases, there's some way to modify the test to verify that specific behavior either using the new handler or multiple apps or rewriting it altogether. but, there are a lot of tests that do this and a lot of them are pretty tricky, so i wouldn't want to stall this pr on waiting for all of these tests to be updated/adapted. i think we should file tickets for all of these tests and just try to pick up one or two of them every so often. maybe that's being overly optimistic about our inclination to pick up small tasks even over a long period, but it's better than losing track of them altogether. wdyt?",0,0.7668668031692505
523322776,9487,ableegoldman,2020-11-14T01:18:45Z,but taskmigratedexception should never be thrown all the way up to the exception handler. is that what you're seeing?,0,0.9848885536193848
523327104,9487,wcarlson5,2020-11-14T01:23:46Z,i appreciate the benefit of the doubt :) but you are right there is an extra `uses`,1,0.9881176352500916
523327338,9487,ableegoldman,2020-11-14T01:24:03Z,"well it's not exactly a default, technically this method is always used to decide which handler to invoke (which may or may not invoke a default handler). any of these would be fine by me but i'll throw one more idea out there: `invokeoldornewuncaughtexceptionhandler`",0,0.9633696675300598
523334335,9487,wcarlson5,2020-11-14T01:32:21Z,"i don't think it will actually transition to `error` because the handler will call close before the global thread is dead, which will transition to peding_shutdown, there is no transition to error from either pending_shutdown or not_running. the fsm will be part of the add thread work as it doesn't really make sense to remove the change to error until we can add threads",0,0.9543501734733582
523334732,9487,wcarlson5,2020-11-14T01:35:22Z,i agree we shouldn't remove the valid test cases. maybe the ones that are more complicated i can just set an idempotent old handler and mark as deprecated and we can file tickets to update. either we work them down or when we go to remove the old handler they will fail and we need to fix them then.,0,0.9647013545036316
523337226,9487,wcarlson5,2020-11-14T01:52:07Z,not quite. if i remove the handler and just run it there is an illegal state exception which runs endlessly until the handler can exit the loop. it looks like the thread hadn't started all the way before the taskmigratedexcpetion is thrown `info state transition from starting to pending_shutdown (org.apache.kafka.streams.processor.internals.streamthread:223) [`,0,0.9370564222335815
523337785,9487,wcarlson5,2020-11-14T01:56:35Z,good idea. it does not seem to do anything. but good to have a test for it,1,0.9826342463493347
523372464,9487,ableegoldman,2020-11-14T04:08:25Z,"ah ok so there's some other illegalstateexception that would get swallowed if we just used `e -> {}` like in the other tests, so we need to explicitly rethrow it? that seems fine, although it makes me think that we should go ahead and use a ""real"" handler in _all_ of the tests, not just this one. otherwise there could be some bug which causes an unexpected exception, but the test would just swallow it and silently pass. can we just use the default handler wrapper for all of these tests so they reflect realistic scenarios?",0,0.9576936364173889
523375614,9487,ableegoldman,2020-11-14T04:45:56Z,"oh you're totally right, sorry for letting my paranoia start spreading conspiracy theories here :slightly_smiling_face: given all this i'd still claim that the fsm is in need to being cleaned up a bit (or a lot), but if you'd prefer to hold off on that until the add thread work then i'm all good here. thanks for humoring me and explaining the state of things. i just wanted/want to make sure we don't overlook anything, since there's a lot going on. for example in the current code, if the global thread dies with the old handler still in use then we'll transition to error. however the user still has to be responsible for closing the client themselves, and it will ultimately transition from error to not_running. whereas if we transition to error as the result of a shutdown_application error code, the user should not try to invoke close themselves, and the error state will be terminal. that's pretty confusing eg for users who use a state listener and wait for the transition to error to call close(). we should make sure that error has the same semantics across the board by the end of all this work. anyways i'm just thinking out loud here, to reiterate i'm perfectly happy to merge this as-is. but for reasons like the above, i think it's important to tackle the fsm in the next pr and make sure it all gets sorted out by the next ak release",-1,0.7155429720878601
524433881,9487,wcarlson5,2020-11-16T17:11:38Z,it's actually not always used. it is only used until a new handler is set in which it is over written. once that happens we don't want the old handler to be set so we do not wrap a user provided handler with this method,0,0.9823614954948425
524435241,9487,wcarlson5,2020-11-16T17:13:23Z,"the default is in kafkastreams, but i see your point. we can make all of them rethrow then we will not have to worry about swallowing",0,0.8159537315368652
524437940,9487,wcarlson5,2020-11-16T17:17:31Z,"+1 to sorting out fsm before next release, i have a ticket to track the work. i started to change it and it ballooned out to be much more expansive than i thought. this pr is already complicated enough, so we can add is later.",1,0.6667096018791199
524447256,9487,vvcephei,2020-11-16T17:30:29Z,i think i'd personally still prefer the non-blocking version. it seems better to avoid blocking indefinitely when a thread is trying to shut itself down due to some unknown exception (or error).,0,0.9624332785606384
524448160,9487,vvcephei,2020-11-16T17:31:54Z,"likewise, here, it seems better to do a non-blocking close.",0,0.9758132696151733
524475389,9487,vvcephei,2020-11-16T18:14:59Z,"personally, as long as users have the information available to understand the nature of the error, it's fine to let them make their own decision about how to handle it. maybe another team is in the middle of a broker upgrade, for example, and the owner of this app would like to just keep trying until the broker team gets it together.",0,0.9410513639450073
524478717,9487,vvcephei,2020-11-16T18:20:34Z,i think i'd like to re-raise sophie's concern here. it doesn't compute for me why we are casting an int to a byte here..,0,0.875352144241333
524487609,9487,wcarlson5,2020-11-16T18:35:22Z,"that is probably fine. we can really get into it when we add the replace option, as now all calls to the handler are fatal.",0,0.9575114846229553
524490211,9487,wcarlson5,2020-11-16T18:39:34Z,"it doesn't really matter to me, though i think that non blocking is probably preferable.",0,0.9369200468063354
524540416,9487,wcarlson5,2020-11-16T20:06:47Z,i guess i must have misunderstood your earlier comment. i thought you wanted it to stay a byte so that is why i pushed back. but if you have no objections i will just change it,0,0.7058857679367065
524814932,9487,ableegoldman,2020-11-17T00:56:33Z,"that's a fair point about broker upgrades, but don't we require the brokers to be upgraded to a version that supports eos _before_ turning on eos-beta? anyways i was wondering if there was something special about this exception such that ignoring it could violate eos or corrupt the state of the program. i'll ping the eos experts to assuage my concerns",0,0.8877882957458496
524817135,9487,ableegoldman,2020-11-17T01:03:03Z,"can you clarify? i thought we would still be in danger of deadlock if we use the blocking `close()`, since `close()` will not return until every thread has joined but the streamthread that called `close()` would be stuck in this blocking call and thus never stop/join",0,0.9798163175582886
524819063,9487,ableegoldman,2020-11-17T01:08:55Z,"just to clarify i think it's ok to leave this as-is for now, since as walker said all handler options are fatal at this point",0,0.7552698850631714
524824649,9487,ableegoldman,2020-11-17T01:25:57Z,"mm ok actually i think this should be fine. i was thinking of the handler as just ""swallowing"" the exception, but in reality the user would still let the current thread die and just spin up a new one in its place. and then the new one would hit this unsupportedversionexception and so on, until the brokers are upgraded. so there shouldn't be any way to get into a bad state",0,0.838128924369812
525161434,9487,cadonna,2020-11-17T13:41:49Z,"ok, i think you are right. i focused too much on [code block] without considering that before the stream threads are shutdown which makes them not running. in the meantime, i understood a bit better the motivation of the shutdown thread in `close()`. the shutdown thread ensures that the timeout is still consiered in case `close()` is called by a stream thread. i think we should revisit it. but that is outside the scope of this pr. to unblock this pr, i am fine with `close(duration.zero)`, but i have the feeling we could do better.",0,0.7657451629638672
525169791,9487,cadonna,2020-11-17T13:52:01Z,there is something wrong in this sentence.,-1,0.6656712889671326
525170922,9487,cadonna,2020-11-17T13:53:37Z,`oldhanlder` -> `oldhandler`,0,0.9824204444885254
525194549,9487,cadonna,2020-11-17T14:26:06Z,nit: remove line,0,0.9622171521186829
525442248,9487,wcarlson5,2020-11-17T19:41:19Z,oops,-1,0.8822687864303589
525444958,9487,wcarlson5,2020-11-17T19:43:34Z,need to remove `use`,0,0.9802058935165405
525636554,9487,ableegoldman,2020-11-18T01:32:09Z,i think it makes more sense to transition to error in this case than to not_running. but let's put this on file with the other fsm-related work planned for following prs,0,0.9809154272079468
525640088,9487,ableegoldman,2020-11-18T01:43:12Z,"why do we shut down the global thread only after all stream threads have completed their shutdown? seems like it would be more efficient to send the shutdown signal to everyone first, and then wait for all the threads to join. can you try this out in the followup pr?",0,0.9795026779174805
525650632,9487,ableegoldman,2020-11-18T02:14:15Z,"i just realized that this is going to be a problem with the way the error state is being used. if we `closetoerror` then we transition to error and shut down, however `error -> pending_shutdown` is still an allowed transition so there's nothing to prevent the shutdown from being triggered again when a user calls `close()`. and note that a lot of users most likely have a state listener at the moment which does exactly that, ie when it sees a transition to error it immediately invokes close (because that's what you should do with the current semantics) just another thing that i think we can fix with some minor rewiring of the fsm.",0,0.95562344789505
525658639,9487,ableegoldman,2020-11-18T02:23:10Z,"hm ok this might be a problem. since this is thrown from another catch block and not from the try block, it won't be caught by the catch block below and will slip through the exception handler.",0,0.8488173484802246
525663640,9487,ableegoldman,2020-11-18T02:28:30Z,we should remember to update the wording here when we add the replace_thread functionality,0,0.9879400730133057
525678234,9487,wcarlson5,2020-11-18T02:44:07Z,you are right i think. i just copied from the normal close method because i knew it worked. in a follow up we can maybe change both of these. do you think that there should be a ak ticket to track it?,0,0.8220158815383911
525680874,9487,wcarlson5,2020-11-18T02:46:55Z,i am on the fence about this. i do think its would be consistent to be not running but also it did shutdown cleanly. we made this choice when error still meant all threads had died and that is not true now. in the end i just went with what we had in the kip rather than try to change it. though i could be swayed to leave this in error.,0,0.6465513706207275
525681642,9487,wcarlson5,2020-11-18T02:47:48Z,this is currently the plan to remove that transition. it is pretty much the only change we plan to make to the fsm.,0,0.8490009903907776
525686843,9487,wcarlson5,2020-11-18T02:53:20Z,like in stream thread we can just add a call to the handler,0,0.9863095283508301
525692960,9487,ableegoldman,2020-11-18T02:59:37Z,"eh, i wouldn't bother with an ak ticket if this will be tackled in the next pr. i'll just make a list of all the minor followup work somewhere to keep track",0,0.952568531036377
525701691,9487,ableegoldman,2020-11-18T03:06:40Z,"that's fair. i guess i was thinking less about the inherent meaning of error vs not_running, and more about not behaving differently in this special case. ie if there _are_ still streamthreads running when a user selects shutdown_application, then we ultimately transition to error. so it strikes me as a bit odd to transition to not_running just because we didn't happen to have any threads left.",-1,0.876676619052887
525734417,9487,ableegoldman,2020-11-18T03:30:18Z,"wdyt about having both not_running and error go through pending_shutdown, rather than just transitioning directly and permanently to error? at a high level i think it just makes sense for error and not_running to be symmetric. also any benefit to having an intermediate pending_shutdown for the not_running case presumably applies to the error case as well. eg, it indicates whether streams has completed its shutdown or not: users know that an app in pending_shutdown should never be killed, its only safe to do so once it reaches not_running. we should provide the same functionality and only transition to error after the shutdown is complete",0,0.9306961297988892
526211409,9487,wcarlson5,2020-11-18T16:08:54Z,"i do think that error should not have direct transition. however i don't like using `pending_shutdown` , mostly because we can already distinguish between the two states and it would be best to inform right away. also it could be a problem if we went to set error and some how it went from pending_shutdown to not_running. i am in favor of adding something like `pending_error` just to be more precise.",-1,0.5054507851600647
526477258,9487,ableegoldman,2020-11-18T22:53:15Z,sounds reasonable,0,0.958084762096405
665553313,10851,vlsi,2021-07-07T17:00:34Z,i guess it would be better to move the assignment to the field declaration to avoid duplication among constructors.,0,0.9815915822982788
665561377,10851,vlsi,2021-07-07T17:12:31Z,can you please clarify why `treemap ` is used here? would `map ` suffice?,0,0.988186240196228
669473299,10851,cadonna,2021-07-14T10:05:18Z,i was wondering whether we can simply standby assignment if `configs.numstandbyreplicas == 0`. here or as first step in the method body of `assignstandbyreplicatasks()`. in this way we can remove `noopstandbytaskassignor`.,0,0.9849709868431091
669496452,10851,cadonna,2021-07-14T10:41:19Z,"as far as i can see, this map is only used in `clienttagawarestandbytaskassignor` and it is only used to iterate over pairs (taskid, uuid). that can also be accomplished by iterating over the client states and for each client state iterate over the assigned active tasks. i do not think that we need to modify the signature of `assignactivestatefultasks()`. or am i missing something?",0,0.9774501323699951
669500118,10851,cadonna,2021-07-14T10:47:36Z,i think it should be `sortedmap` instead of `treemap`. i also saw that we sometimes missed to use `sortedmap` instead of `treemap` in some signatures. it needs to be a sorted map because the assignments should be stable otherwise it could happen that we compute different assignments for the same input which could lead to unnecessary state migrations.,0,0.9848939776420593
669504412,10851,cadonna,2021-07-14T10:54:30Z,why do we need this internal class? wouldn't it be simpler to structure the code with methods directly under `clienttagawarestandbytaskassignor`?,0,0.9865267872810364
669849371,10851,lkokhreidze,2021-07-14T18:20:28Z,"thanks for the feedback bruno. i reasoned that, since internal states like `clientspertagvalue`, `standbytaskclientsbytaskload`, etc., have to be allocated per invocation of `assignstandbytasks` method, it felt easier and more readable to create one single internal object rather than invalidating local caches in `clienttagawarestandbytaskassignor`.",1,0.9493553042411804
669851397,10851,lkokhreidze,2021-07-14T18:23:36Z,"i tried to avoid unnecessary iterations. with that we would have to do separate iteration in the `clienttagawarestandbytaskassignor`, which felt redundant, since `assignactivestatefultasks` can return necessary mapping since it has to iterate over client states either way.",0,0.9705290794372559
669853519,10851,lkokhreidze,2021-07-14T18:26:40Z,i didn't give it much thought to be honest. `treemap` for the `clientstates` was already used in the `highavailabilitytaskassignor` and went with the same signature here. i think it makes sense to change the contract to be a `sortedmap`. will do that.,0,0.9038052558898926
669865915,10851,lkokhreidze,2021-07-14T18:45:48Z,sure! done. personal preference. having all the strategies of standby task assignment implementations in a single class makes unit testing a bit easier. but i do agree that removing one extra class is indeed good idea.,1,0.9625157713890076
670294370,10851,cadonna,2021-07-15T09:27:04Z,"yes, the `treemap` in the signatures has been already there before this pr. thank you for fixing this!",1,0.9800466299057007
670309425,10851,cadonna,2021-07-15T09:47:08Z,"as far as i can see, we would iterate only over the active tasks in both cases. the difference is that in case we have one loop and in the other we have two nested loops. in the nested loop case, the code in the innermost loop is executed the same number of times as in the one loop case. that is, as many times as the number of active tasks. in general, i would not change too much code for a performance improvement before we hit a performance issue. you know, as donald e. knuth stated ""premature optimization is the root of all evil"". :slightly_smiling_face:",-1,0.939689040184021
670332282,10851,cadonna,2021-07-15T10:18:49Z,"method `assignstandbytasks()` is only invoked once per assignment, as far as i can see. i do not see the need to avoid invalidating caches. or am i missing somethings?",0,0.9849991202354431
670333813,10851,cadonna,2021-07-15T10:20:54Z,"i would prefer to have an interface instead of an abstract class. in the past, it turned out to be cleaner and easier maintainable even if we need to duplicate the `configs` field in the implementations of this interface.",0,0.9796767830848694
670336504,10851,cadonna,2021-07-15T10:24:46Z,i think a factory method as used [a link] should suffice instead of an entire class.,0,0.9856568574905396
671829899,10851,lkokhreidze,2021-07-18T11:47:01Z,"that is correct. currently, `standbytaskassignor` implementations are created once per `taskassignor#assign` method call, and `assignstandbytasks` is called only once. i just didn't want to assume how and how many times `assignstandbytasks` is called as i didn't want to leak the implementation details to the caller. however, if you feel strongly that it's better to have the implementation in the `clienttagawarestandbytaskassignor`, i can refactor the code. since it's internal contract of the assignment, maybe it's okay.",0,0.9707250595092773
672023300,10851,lkokhreidze,2021-07-19T06:38:07Z,"fair enough, done.",0,0.9126564860343933
672023438,10851,lkokhreidze,2021-07-19T06:38:26Z,done,0,0.9764507412910461
672023741,10851,lkokhreidze,2021-07-19T06:39:04Z,moved factory method in `standbytaskassignor` interface itself. hope it addresses your comment.,1,0.6374696493148804
685807795,10851,cadonna,2021-08-10T08:31:19Z,"i see your point, but i do also not see the need for an internal state for which we need to avoid invalidation. variables `numstandbyreplicas` and `numstandbyreplicas` are configs that can be stored as member fields of `clienttagawarestandbytaskassignor` or passed along to the methods that need them. variables `tagkeytotagvaluesmapping`, `clientspertagvalue`, `standbytaskclientsbytaskload`, and `clientstates` can also be passed to the methods that need them. avoiding state makes reasoning about code simpler and here it seems possible to avoid state. see `highavailabilitytaskassignor`, it does not have any state.",0,0.9711810946464539
685816278,10851,cadonna,2021-08-10T08:42:05Z,"i would prefer to make this interface independent of its implementations. if you put the factory method here, the interface is not independent anymore. i would prefer a factory method named `createstandbytaskassignor()` in `highavailabilitytaskassignor` similar to the existing factory method `createtaskassignor()` in `streamspartitionassignor`.",0,0.9818259477615356
685822324,10851,cadonna,2021-08-10T08:49:41Z,"minor: you could extend interface `taskassignor` and remove `assignstandbytasks()` from this interface since `assign()` in `taskassignor` has almost the same signature. the difference is parameters `configs` and `alltaskids`. you will need `configs` if you will not keep the config as a member variable as mentioned in my other comment. you will not need `alltaskids`, but that would be ok, i guess.",0,0.9763595461845398
685824044,10851,cadonna,2021-08-10T08:51:51Z,"i guess the initialization in the constructor on line 79 is only temporary. this will change in one of the next prs. nevertheless, i agree that it would also be fine to move the initialization to the field declaration for now. i would even propose to pass the client tags to the constructor, since those are kind of constants coming from the config.",0,0.9763293266296387
685865965,10851,cadonna,2021-08-10T09:48:09Z,i would prefer to just add two parameters -- `source` and `destination` -- to the `isvalidmovement()` method in `standbytaskassignor` and get rid of this class.,0,0.9882568717002869
685867438,10851,cadonna,2021-08-10T09:50:08Z,the task id is never used. could we remove it?,0,0.987580418586731
685871631,10851,cadonna,2021-08-10T09:56:06Z,could you move the second condition to the `canmove` assignment on line 166? i think the condition is logically a part of `canmove`.,0,0.9890139698982239
685872701,10851,cadonna,2021-08-10T09:57:39Z,nit: i think `isallowedtaskmovement()` reflects better the meaning of this method.,0,0.9718215465545654
685877129,10851,cadonna,2021-08-10T10:03:55Z,would it be possible to integrate the tag constraint as part of the constraint on the priority queue?,0,0.9877026677131653
693133897,10851,lkokhreidze,2021-08-20T18:14:16Z,"it's already part of the poll constraint of the priority queue. example: [code block] i don't think it will be doable with constructor constraint, because we need to update constraint on each poll.",0,0.984102189540863
693150166,10851,lkokhreidze,2021-08-20T18:44:21Z,good point about client tags being constant. added it as constructor parameter.,1,0.9420070052146912
693163634,10851,lkokhreidze,2021-08-20T19:09:26Z,addressed with 9841d25,0,0.985545814037323
695463229,10851,lkokhreidze,2021-08-25T07:11:43Z,this method is needed in `clienttagawarestandbytaskassignor` and `defaultstandbytaskassignor`. was thinking to create `standbytaskassignmentutils` and extract this logic in there. wdyt ?,0,0.9889994263648987
695630930,10851,cadonna,2021-08-25T10:49:00Z,"yes, i think that makes sense. in this way you can also directly test the method. btw, you can simply pass `statefultaskids` to this method instead of `statefultaskswithclients`. the keys in `statefultaskswithclients` should be the task ids in `statefultaskids` and the values in `statefultaskswithclients` are never used.",0,0.9861820936203003
695640768,10851,cadonna,2021-08-25T11:03:15Z,isn't this the same as: [code block],0,0.9659965634346008
695642889,10851,cadonna,2021-08-25T11:06:10Z,isn't this the same as: [code block],0,0.9659965634346008
695669488,10851,cadonna,2021-08-25T11:41:52Z,why is the map from tag key to tag values computed for each active task? they should not change during the assignment and we can just compute it once in `assign()`. do you agree?,0,0.9868100881576538
695690393,10851,cadonna,2021-08-25T12:12:07Z,"imo, the code is easier readable if you name the variables consistently like `tagvaluetoclients` and `tagkeytotagvalues` or `clientsfortagvalue` and `tagvaluesfortagkey`. i prefer the former because it better visualises the mapping, but that is a matter of taste, i guess.",0,0.8780419230461121
695717497,10851,lkokhreidze,2021-08-25T12:48:31Z,"good catch. i missed it during refactoring, you're correct.",1,0.9754457473754883
695735723,10851,lkokhreidze,2021-08-25T13:10:03Z,done,0,0.9764507412910461
695735854,10851,lkokhreidze,2021-08-25T13:10:15Z,pushed changes,0,0.9836722016334534
695735942,10851,lkokhreidze,2021-08-25T13:10:21Z,fixed,0,0.975196123123169
695736026,10851,lkokhreidze,2021-08-25T13:10:27Z,fixed,0,0.975196123123169
700864299,10851,cadonna,2021-09-02T08:25:40Z,"although we never use the returned value from a standby task assignor, i would return `false` since a standby task assignment will never require a follow-up probing rebalance.",0,0.9867314696311951
700905553,10851,cadonna,2021-09-02T09:18:37Z,map `statefultaskswithclients` is only used to iterate over its entries. i think it would be better to use the following nested loops and remove `statefultaskswithclients`: [code block],0,0.9872567653656006
700910355,10851,cadonna,2021-09-02T09:25:03Z,i do not understand why you re-add `clientsonalreadyusedtagdimensions`. those clients were not modified and not polled for sure due to line 140.,0,0.892769992351532
700917243,10851,cadonna,2021-09-02T09:33:57Z,"i think this map does not work for distinct tag keys that have overlapping tag values. for example, `key1` contains one of `{value1, value2}` and `key2` contains one of `{value2, value3}`.",0,0.9836331009864807
701068792,10851,cadonna,2021-09-02T13:12:40Z,"are you sure, because i cannot confirm the failure of the test on my side?",0,0.9791735410690308
701137236,10851,lkokhreidze,2021-09-02T14:26:05Z,"yeah, sorry. you're right. this is not needed.",-1,0.9864639043807983
701141903,10851,lkokhreidze,2021-09-02T14:30:51Z,"sorry, can you elaborate more on this? currently, when deciding the distribution, algorithm takes into account both, tag key, as well as tag value. so it will treat `key1: value2` and `key2: value2` as different dimensions. do you think it's something that has to be addressed?",-1,0.9840694069862366
701142976,10851,lkokhreidze,2021-09-02T14:32:05Z,pushed the changes.,0,0.9763523936271667
701143273,10851,lkokhreidze,2021-09-02T14:32:26Z,i've removed this line and pushed the changes.,0,0.9840179085731506
720193502,10851,cadonna,2021-10-01T12:12:59Z,"let's assume you have two clients. `clientx` has tags `keya:value1` and `keyb:value2` and `clienty` has tags `keya:value2` and `keyb:value3`. notice that `keya` and `keyb` share `value2`. with your code, we will end up with a `tagvaluetoclients` map that looks like this: [code block] now, let's assume that an active task is assigned to `clientx`. it would be totally fine if we assign the standby task to `clienty` since each tag key of both clients do not share a value. however, your algorithm does not allow it, because on line 198 it also adds `clienty` to the clients that are not allowed to get the standby. the reason is that `tagvaluetoclients` only looks for clients that contain value `value2` and not for clients that contain it as a value for `keya`. the following test fails because of this: [code block]",0,0.8242579698562622
720196549,10851,cadonna,2021-10-01T12:17:41Z,could you please use `tagvaluetoclients` and `tagkeytovalues` here as in the rest of the class?,0,0.9888277053833008
720214125,10851,cadonna,2021-10-01T12:46:53Z,"currently the code iterates over the active tasks and assigns all standby tasks for each active task. if the standby tasks cannot all be assigned, we might end up with all standby tasks assigned for some active task but none for others. what do you think about to assign one standby task for all active task and then assign the second standby task for all active task, and so on. in this way, it is more likely that at all active tasks have at least one standby task assigned. i am aware that the default standby assignor has the same drawback.",0,0.9545639753341675
741840561,10851,lkokhreidze,2021-11-03T11:18:42Z,"thanks, good catch.",1,0.968795657157898
741896976,10851,lkokhreidze,2021-11-03T12:41:17Z,"makes sense . should i update default standby task assignor, or prefer to leave it out of scope of this pr?",0,0.9865297079086304
741897677,10851,lkokhreidze,2021-11-03T12:42:16Z,solved by storing tuple of tag key and value as map key instead of just tag value.,0,0.9874945282936096
741923941,10851,lkokhreidze,2021-11-03T13:15:03Z,"also wondering if it's better to do this as a separate task altogether. since, as you've mentioned, it's the same behaviour as with default standby task assignor. but if you feel it's better to do it in current pr, happy to do so.",0,0.778291642665863
765909088,10851,cadonna,2021-12-09T15:39:09Z,for each standby of a single active task the set `clientsonalreadyusedtagdimensions` is computed from scratch. i think this is not necessary since the clients on already used tag dimensions that we found for the first standby are still valid for the second standby and the clients on already used tag dimensions found for the second standby are still valid for the third standby and so on. this is true because we only add clients to the set `usedclients` but we never remove any. i think we can compute `clientsonalreadyusedtagdimensions` incrementally for each standby of a single active task instead of computing it from scratch each time.,0,0.97328782081604
766104130,10851,cadonna,2021-12-09T19:48:26Z,"something does not work as expected in this algorithm. according to this doc, the assignor should fall back to distributing tasks on least-loaded clients. however, the following test case fails: [code block] the standby task for active task 0_0 can be put on client uuid_2 and the standby task for active task 0_1 can be put on client uuid_1 without breaking rack awareness constraints. standby tasks for active tasks 0_2 and 1_0 cannot be put on any client without breaking rack awareness, so they should be distributed on least-loaded clients. however, that does apparently not happen, because client uuid_3 and uuid_4 are not assigned any standby.",0,0.965793251991272
789057202,10851,lkokhreidze,2022-01-20T18:46:16Z,fixed with e3aff39c7687a358cc8672accd5bbf6a27193a04. algorithm will try to achieve partial rack awareness as there are different `cluster` tag dimensions.,0,0.9862924814224243
789057904,10851,lkokhreidze,2022-01-20T18:47:15Z,fixed with e3aff39. now we only create `clientsonalreadyusedtagdimensions` once and populate it for the each standby task assignment instead of re-creating it.,0,0.9886181354522705
789060382,10851,lkokhreidze,2022-01-20T18:50:46Z,"hi would appreciate your feedback on this. as of now, algorithm ignores a case when client has reached capacity and it will try to assign the standby task to it as long as it satisfies the rack awareness. there's a even test for it `shoulddistributeclientsondifferentzonetagsevenwhenclientsreachedcapacity`. for me it makes sense that rack awareness, if configured, takes precedence in this case. added log to inform the user, just want to make sure if you think this is a valid approach. it is not a lot of work to take capacity into account, so we can redo algorithm if you think that makes more sense.",1,0.6180791258811951
789687365,10851,lkokhreidze,2022-01-21T14:09:22Z,"i reworked things a bit, check out this comment [a link]",0,0.9768379926681519
789687883,10851,lkokhreidze,2022-01-21T14:10:01Z,"no longer relevant, i reworked things a bit, check out this comment [a link]",0,0.9615606665611267
795434808,10851,lkokhreidze,2022-01-31T08:32:34Z,"answering why do we need this: i think with client tag aware standby task assignment, there's a much higher chance that we will overload some clients without this check. i think it's better to not to overload the clients and instead log the warning so users can do the needful of increasing the capacity in order to satisfy the rack awareness.",0,0.9611997008323669
805156426,10851,showuon,2022-02-12T12:31:47Z,could we add some java doc to this assign to briefly mention about the algorithm used in the assignor? thanks.,1,0.8636446595191956
805156641,10851,showuon,2022-02-12T12:34:04Z,"i know there was no any java doc for the default least load assignor. but do you think we can add some comments to it, just like in `clienttagawarestandbytaskassignor`? i believe not everyone knows default assignor algorithm is least loaded assignor.",0,0.8971431851387024
805157124,10851,showuon,2022-02-12T12:40:02Z,i'm wondering could we keep the original constructor and pass empty map into the new one? so that we don't have to make changes to the old caller. that is: [code block] wdyt?,0,0.9819918870925903
805199777,10851,cadonna,2022-02-12T20:12:02Z,"i see what you want to do. however, the capacity is the number of consumers on the streams client, i.e., the number of stream threads running on the streams client. with this check, you only allow to assign standby tasks to clients that have less tasks assigned as stream threads running. that is actually rather an unlikely case. normally, you have more tasks assigned to a streams client than the number of stream threads running on the client. i would keep it simple and ignore the balance for now.",0,0.9654213786125183
805203233,10851,cadonna,2022-02-12T20:51:21Z,would it be possible to decrement the numbers in `taskstoremainingstandbys` to maintain the remaining standbys to distribute instead of using `pendingstandbytasktonumberremainingstandbys`?,0,0.9890563488006592
805571500,10851,showuon,2022-02-14T07:43:02Z,maybe add a comment here to mention we need to make sure the sourceclient tag matches to destinationclient tag if rack tag is enabled...something like that.,0,0.9841145277023315
805641183,10851,showuon,2022-02-14T09:19:10Z,is it normal when this happened? should we do anything to it? or at least log something here?,0,0.974259614944458
805642565,10851,lkokhreidze,2022-02-14T09:20:51Z,"thanks for the feedback. no objections from my side. the reason why i avoided that was to make sure that client tags are always passed. to emphasise that it's mandatory parameter when constructing the `clientstate` object. please note that we have made `clientstate#clienttags` immutable; so there're no setters for the client tags. but if you feel like it's better to default to empty map, happy to change it. will wait for your response on this.",1,0.9026381373405457
805646942,10851,showuon,2022-02-14T09:25:59Z,"the variable name `polledclient` is unreadable. i think the variable is the client not having the same tag key/value, right? could we give it a more meaningful name, ex: `clientuuidnotonusedtagdimension`, or other better one if you have.",0,0.9876647591590881
805656409,10851,showuon,2022-02-14T09:36:51Z,"when reaching this point, we have tried our best to assign standby tasks with rack awareness to all clients. i think we should have a debug log here, to log some current status, like current assignment, `pendingstandbytasktonumberremainingstandbys`, `pendingstandbytasktoclientid`, and mention we're going to distribute the remaining tasks with least loaded assignor...etc, for better troubleshooting.",0,0.9642856121063232
805659384,10851,showuon,2022-02-14T09:40:16Z,"tbh, i don't understand this method well before i read into the implementation. i think the method is trying to assign standby tasks to those clients without using the same tag key/value, right? if so, maybe we can change the name to `assignstandbytaskstoclientswithoutsametag`, or others you can think of. wdyt?",0,0.9352989196777344
805663941,10851,showuon,2022-02-14T09:45:26Z,"looks like the `findclientsonusedtagdimensions` method keeps finding duplicated `usedclients`. that is, if we have 10 `numremainingstandbys`, we'll run `findclientsonusedtagdimensions` with 1 `usedclients` at first. and then, add one more, to have 2 `usedclients` at 2nd run, and add one to 3, 4, 5, ... 10. is my understanding correct? if so, could we improve it?",0,0.9719916582107544
805668921,10851,showuon,2022-02-14T09:50:57Z,"this is an internal class, so i think it won't be changed/used many times. i think change to my previous suggestion is better. thanks.",1,0.9112465977668762
805782141,10851,lkokhreidze,2022-02-14T12:13:21Z,i think having a warn log is a good call. we can add validation rules (if necessary) when doing last part of this kip - updating streams configuration.,1,0.6491313576698303
805830410,10851,lkokhreidze,2022-02-14T13:16:51Z,good call. i don't know how i missed that...,1,0.951440691947937
807660376,10851,lkokhreidze,2022-02-16T08:24:19Z,thanks! renamed to `clientonnotusedtagdimensions` to be consistent with the rest of the codebase. since we refer to client uuids as just `client` in the codebase. hope this works.,1,0.9838727116584778
807663879,10851,lkokhreidze,2022-02-16T08:28:41Z,makes sense. renamed to `assignstandbytaskstoclientswithdifferenttags`. hope this works too.,1,0.9396832585334778
807738730,10851,lkokhreidze,2022-02-16T09:50:45Z,refactored javadocs a bit. moved some content from class level javadoc to the `assign` method. hope this works.,1,0.8882487416267395
807810480,10851,lkokhreidze,2022-02-16T11:07:20Z,good call. improved the code in a latest commit.,1,0.9807333946228027
809711301,10851,showuon,2022-02-18T06:35:57Z,ok,0,0.9667208194732666
809773328,10851,showuon,2022-02-18T08:29:41Z,nit: the algorithm will fall back to the least-loaded clients without **taking** rack awareness constraints into consideration.,0,0.9800584316253662
809797947,10851,showuon,2022-02-18T09:02:01Z,"i checked the use of `tagkeytovalues`. it is only used for total value count of each key. is that right? if so, could we just store the `map tagkeytovaluecount` only?",0,0.9877966046333313
809798766,10851,showuon,2022-02-18T09:03:03Z,"sorry, i didn't understand the reason why we can't filter out clients located on that tag when `alltagvalues.size() <= countofusedclients`. could you help explain to me? thanks.",-1,0.9777926206588745
809972865,10851,showuon,2022-02-18T12:54:02Z,nit: ` clienttagawarestandbytaskassignor` (no need the package name),0,0.9877390265464783
809980650,10851,showuon,2022-02-18T13:04:58Z,nit: close this bracket in the same line. that is: `private standbytaskassignmentutils() {}`,0,0.987139880657196
809983790,10851,showuon,2022-02-18T13:09:18Z,nit: indent issue. could we add comment in front of `empty_rack_aware_assignment_tags`?,0,0.9828693270683289
809984233,10851,showuon,2022-02-18T13:09:53Z,same as above.,0,0.9746477603912354
810003432,10851,lkokhreidze,2022-02-18T13:35:38Z,"can do, but also `set` makes it easier to handle duplicate values as we are looking for distinct count values here. not sure if refactoring is worth it though.",0,0.9702512621879578
810019916,10851,lkokhreidze,2022-02-18T13:54:59Z,"consider the following example [code block] with the above we have following number of unique tag values: [code block] now lets say we have standby replica count as `2` and we want to active task is located on `client 1` `usedclients=1` (because of the active task) ### 1st standby assignment during 1st standby takes assignment, we will exclude clients on following dimensions: [code block] used clients will get incremented since we can allocate the client on different `zone` and `cluster`. `usedclients=2` ### 2nd standby assignment we will have to exclude `zone: eu-central-1a and (eu-central-1b || eu-central-1c)` tag values. we can do that, because after we exclude clients on the new tag, we still have clients on the one free tag value we can assign the next standby to. we can't exclude `cluster` because we have already used two clients, and we just have two unique values for the `cluster` tag, so it's impossible to get the ideal distribution with this configuration and number of instances. so we can only achieve partial distribution. so idea of this check is to ignore tags where we have less unique values than the clients we have already used. if we don't have this check, for the 2nd standby task assignment we would have excluded all the clients located on `k8s-cluster1` and `k8s-cluster2`, and there wouldn't be any client left to assign the standby task to. we would fall back to the least loaded client, but there will be no guarantee that least loaded client assignment would honor partial rack awareness. hope this makes sense.",0,0.978344202041626
810020380,10851,lkokhreidze,2022-02-18T13:55:34Z,i added `shoulddothepartialrackawareness` test to verify this behaviour.,0,0.9878675937652588
810462108,10851,showuon,2022-02-19T07:58:08Z,"nit: could we be consistent with other tests that make the uuid_seq in order? it makes me a little confused when reading this test. that is, [code block]",0,0.8666384816169739
810462515,10851,showuon,2022-02-19T08:02:43Z,"i can understand what you tried to assert here. but i think we should also assert that the standby tasks count in each client is as what we expected, because under current verification, we only focus on the tasks distributed with rack awareness. however, there is still possibility that standby tasks don't distribute evenly, right? the following tests should also update. thanks.",1,0.893424928188324
810462817,10851,showuon,2022-02-19T08:06:49Z,"a ha, you're right! we only need the distinct count values. no need to refactor it then. thanks for the explanation.",1,0.9839815497398376
810464460,10851,showuon,2022-02-19T08:27:03Z,"in 1st standby assignment: usedclients=2 i think this used client should be 5 or 6, right? but i got your idea. thanks for the explanation. makes sense to me.",1,0.966589629650116
810465176,10851,showuon,2022-02-19T08:35:58Z,"i'm thinking, we can make it much clear by adding comments, though i know this is hard to explain in simple words. how do you think we add comments like this: // if we have used more clients than all the tag's unique values, // we can't filter out clients located on that tag, because it'll excluded all the clients. // please check clienttagawarestandbytaskassignortest#shoulddothepartialrackawareness test for more info. and we can make more description in `shoulddothepartialrackawareness` test.",0,0.9214603304862976
810485747,10851,showuon,2022-02-19T12:29:59Z,"we can add comments here like: // we need 2 standby tasks (+ 1 active task) to distribute, but we only have 2 cluster tag, so we will won't exclude all clients when 2nd standby tasks assignment, and will try to distribute the 2nd standby tasks with taking partial rack tag into consideration. wdyt?",0,0.983551561832428
810487017,10851,showuon,2022-02-19T12:43:36Z,"after your explanation of partial rack awareness, i can understand the distribution will be `uuid_5, uuid_6`. but i don't know why it's possible with the result `uuid_5, uuid_3`? i thought after 1st standby task assignment, we'll exclude `cluster_1` and `zone_1` tags clients. so the remaining clients will be `uuid_5, uuid_6`. therefore, the only possible results will be `uuid_5, uuid_6`. is my understanding correct? anything i missed? thanks.",0,0.9575931429862976
810487139,10851,showuon,2022-02-19T12:44:46Z,"and i think we should add some comments here, to have a simple explanation like we i did above to explain why we have these results. thanks.",1,0.9305184483528137
810857967,10851,lkokhreidze,2022-02-21T07:59:25Z,"`uuid_5` is essentially ""ideal"" distribution because it has both different cluster and zone compared to an active task. however, when we assign 2nd standby, we can only choose client on different `zone`. `cluster` tag is excluded as we don't have enough unique values to exclude the `cluster`. so for the 3rd standby task, both `cluster1` and `cluster2` are valid. that means that clients with `uuid_3` (`cluster1`, `zone3`) and `uuid_6` (`cluster2`, `zone3`) are valid destinations. on the high level, idea is that, if any of the values of the `cluster` tag goes offline, no matter on which `cluster` we distribute the 2nd standby `cluster1` or `cluster2`, we either way will loose two clients at the same time. so from availability perspective it doesn't make difference where the 2nd standby will be assigned. one may argue that it would be better to always distribute to a different tags compared to an active task, but this will complicate algorithm even further, so i guess it's better to keep it simpler in a first iteration. hope this makes sense, i will add more info as a comment.",0,0.9743173122406006
810894883,10851,lkokhreidze,2022-02-21T08:48:51Z,added more explanation in `shoulddothepartialrackawareness` test.,0,0.9864749312400818
811551306,10851,showuon,2022-02-22T03:33:07Z,nice tests!,1,0.9847846031188965
811556641,10851,showuon,2022-02-22T03:50:06Z,"nit: we can directly break the while when `numremainingstandbys == 0`, so that we don't need to run the redundant `findclientsonusedclienttagdimensions` in the last run. ex: [code block]",0,0.9885037541389465
811559765,10851,showuon,2022-02-22T03:59:48Z,"thanks for the explanation for partial rack awareness assignment. i think that algorithm makes sense. however, i don't think the implementation matches what you described. you said in the `shoulddothepartialrackawareness` test, in 2nd standby assignment for task_0_0, we will only consider `zone`, but in current implementation, we will also consider `cluster`. that is, when entering the `while (numremainingstandbys > 0) {` loop, the `clientsonalreadyusedtagdimensions` already excluded the `cluster_1` and `zone_1`. and in the 1st standby assignment, `uuid_5` will be chosen, we'll exclude `zone_2` only, and not exclude `cluster_2`. so , the only client left is `uuid_6`. that's the current design, isn't it? i don't see where we only consider `zone` in 2nd assignment. could you help elaborate more? thank you.",1,0.7973119020462036
811645496,10851,lkokhreidze,2022-02-22T07:30:21Z,"ah, you're absolutely right! i'm very sorry for the confusion. it's been a while and got lost myself. i will update comments to reflect this. do you think it makes sense to leave the implementation as is, or we should re-work it based on what i described before? either is fine with me.",-1,0.9646002054214478
811651144,10851,showuon,2022-02-22T07:39:28Z,i think we should re-work the `assignstandbytaskstoclientswithdifferenttags` method to match what you described. that makes more sense. thanks.,1,0.95826655626297
811652014,10851,lkokhreidze,2022-02-22T07:40:50Z,will get it done asap.,0,0.9783481955528259
811918321,10851,lkokhreidze,2022-02-22T12:58:07Z,updated implementation in [a link],0,0.9869980812072754
811964104,10851,cadonna,2022-02-22T13:48:33Z,wouldn't this be equivalent and maybe a bit more concise? [code block],0,0.9845625758171082
811981794,10851,cadonna,2022-02-22T14:06:40Z,"that is quite challenging to understand. after reading it a couple of times i understood that if we've used a number of clients that is equal to or greater than the number of unique values of the tag, we cannot guarantee that each standby is on a different tag value than the active and other standbys. so the rack-awareness becomes partial. is that correct? could you reformulate it, so that it states that the rack-awareness guarantee does not hold anymore. and why ""more clients than all tag's unique values""? when the number of used clients is equal to the unique tag values, we are already in the partial rack-awareness situation, right? maybe you should give here an example as in the mentioned test. i find referencing the test is a bit cumbersome, because if the test gets renamed this comment becomes useless.",0,0.6737662553787231
812018771,10851,cadonna,2022-02-22T14:41:55Z,"i could not find where you decrement the number of remaining standbys. if you get a value from this map and put it into an `int` variable, you do not have a reference to the `integer` value in the map anymore. this might become a problem in `standbytaskassignmentutils#pollclientandmaybeassignremainingstandbytasks()`.",0,0.970556914806366
812081768,10851,lkokhreidze,2022-02-22T15:41:22Z,"thanks bruno, i'll add the example to the comment.",1,0.9136583805084229
812519265,10851,showuon,2022-02-23T02:42:38Z,nit: lastusedclient -> lastusedclient,0,0.9827246069908142
812525667,10851,showuon,2022-02-23T03:03:49Z,"since we will remove tags, i think we can rename to `updateclieintsonalreadyusedtagentries`. wdyt?",0,0.9879330992698669
812527382,10851,showuon,2022-02-23T03:09:25Z,nice catch! and maybe we should add a test to address this.,1,0.9911772012710571
812527749,10851,showuon,2022-02-23T03:10:30Z,good suggestion!,1,0.9854104518890381
812626201,10851,cadonna,2022-02-23T07:48:45Z,"yes, a test is absolutely necessary!",0,0.5871574282646179
812720897,10851,lkokhreidze,2022-02-23T09:54:23Z,pushed the changes. i added detailed explanation with an example. also tests have the similar example. hopefully this change makes logic more clear.,0,0.8917702436447144
812722151,10851,lkokhreidze,2022-02-23T09:55:49Z,"updated tests for the `standbytaskassignmentutils#pollclientandmaybeassignandupdateremainingstandbytasks` and also added separate test for the `clienttagawarestandbytaskassignor`. for the `clienttagawarestandbytaskassignor` i decided to make few things package private to be able to test this logic. as otherwise, there was no easy way to test if `taskstoremainingstandbys` was getting updated properly. hope this is okay.",1,0.913902997970581
812884587,10851,showuon,2022-02-23T13:22:03Z,nit: additional space between `the` and `2nd`,0,0.9867203235626221
817629787,10851,cadonna,2022-03-02T12:08:36Z,"i think info log would also be ok here. i imagine users that are wondering why their standbys are not distributed as they would expect. with this information they can at least try to fix it on the config level. this log message should only happen at rebalance time, which should usually be rather seldom. if we decide to put the log message on info level, you should also change a bit the wording and not use variable names in it. maybe some hints what the users can do to fix this would also be nice. is it possible to separate the concerns of this log message and the one on line 135? something along the lines of here the rack-aware standby assignment did not work due the tag config and on line 135 the assignment did not work due to too low number of instances. we can then put both on warn or info (do not forget to also check the related log message in the default standby assignor).",1,0.5454311370849609
817650626,10851,cadonna,2022-03-02T12:37:25Z,this can be done in a follow-up pr: i am not a big fan of `// visible for testing` because it often means that we missed to extract code to separate classes. here i would definitely extract this code to a factory class.,-1,0.786404013633728
38823999,195,junrao,2015-09-06T17:45:05Z,it seems that it will be cleaner if we split this into getacls and getaclsfromzk. the former will just read from the cache and the latter always read from zk. only the zk listener will use the latter.,0,0.9852134585380554
38824003,195,junrao,2015-09-06T17:45:32Z,"hmm, this may not work well if two acl changes happen quickly. the second one will override the the resource of the previous one. if a broker hasn't finished processing the previous change, it will miss it after the override. i thought we wanted to use the same approach as in configchangelistener where the updates are written as a sequential zk node.",0,0.9223847985267639
38824005,195,junrao,2015-09-06T17:45:44Z,could we document the format of values used in the new zk paths in the comment?,0,0.988925039768219
38824017,195,junrao,2015-09-06T17:46:19Z,"hmm, do we need this? it's simpler if we always rely on zk watchers to propagate the changes. zkclient will handle all the reconnects for us. if we lose a session, we probably have to read the aclchangedzkpath in case we missed a zk notification.",0,0.9869333505630493
38925968,195,ijuma,2015-09-08T13:40:40Z,"you can use `_` if you want a value to be initialised to the default one (eg `null`, `false`, `0`, etc.)",0,0.9882856607437134
38926011,195,ijuma,2015-09-08T13:41:01Z,type annotation is redundant in cases like this.,0,0.9679768085479736
38926146,195,ijuma,2015-09-08T13:42:22Z,"a less verbose and more idiomatic way to write this: `import scala.collection._` ... `private val aclcache = mutable.map.empty[resource, set[acl]]`",0,0.9741000533103943
38926413,195,ijuma,2015-09-08T13:44:50Z,"what if `str` is not a `string`? that case is not being handled. nicer code can be written if you use the scala version of the map (ie `config`). then `get` will return an `option` and you can use methods like `filter`, `map`, etc. that applies to the other code that is reading from the config.",0,0.9855263233184814
38926589,195,ijuma,2015-09-08T13:46:19Z,unnecessary type annotation,0,0.8329030275344849
38926656,195,ijuma,2015-09-08T13:46:52Z,"in scala, one should use `==` not `equals`.",0,0.9834046959877014
38926768,195,ijuma,2015-09-08T13:47:41Z,"instead of doing this, you should replace the for comprehension with `find`.",0,0.9861635565757751
38926812,195,ijuma,2015-09-08T13:47:57Z,"no `var` needed, `inreadlock` returns a value.",0,0.9881068468093872
38926927,195,ijuma,2015-09-08T13:49:10Z,`acljson.map(acl.fromjson).getorelse(set.empty)`,0,0.9865012764930725
39098212,195,Parth-Brahmbhatt,2015-09-09T21:22:02Z,done.,0,0.9759407639503479
39098585,195,Parth-Brahmbhatt,2015-09-09T21:25:46Z,"i am confused. i thought you said a watch notification will never be missed or it will only be missed when a reconnection happens which is handled by zkclient, which is why we don't need the sync thread. if client-a updated the /kafka-acl-chaged and set its data to ""topic-1"" (this should go throught zkquorum) and then client-b updated the /kafka-acl-changed and set its data to ""topic-2"" are you saying we will only get notification for ""topic-2"" depending on how fast the change occurs? doesn't that violate the first guarantee which led us to delete the hourly sync? i would like to point out that in the watch notification we are just relying on data sent as part of notification and not really reading /acl-changed one more time.",-1,0.8791219592094421
39099520,195,Parth-Brahmbhatt,2015-09-09T21:33:56Z,done.,0,0.9759407639503479
39099854,195,Parth-Brahmbhatt,2015-09-09T21:37:13Z,done.,0,0.9759407639503479
39100044,195,Parth-Brahmbhatt,2015-09-09T21:39:00Z,removed the whole scheduler.,0,0.9665027856826782
39100138,195,Parth-Brahmbhatt,2015-09-09T21:39:47Z,"as soon as i add that import all the other places that expect set starts complaining that ""set[x] can not be converted to set[x]"" which i am guessing is just scala compiler complaining that they expect the unmutable scala set but with the new import now they are all assumed to be mutable set. did i mention scala is amazing :-).",1,0.9800886511802673
39100385,195,Parth-Brahmbhatt,2015-09-09T21:41:58Z,fixed.,0,0.9810503125190735
39100572,195,Parth-Brahmbhatt,2015-09-09T21:43:37Z,done.,0,0.9759407639503479
39103033,195,Parth-Brahmbhatt,2015-09-09T22:06:08Z,"apart from returning true , given i also want to log the debug statement as a side effect, the version with find looks less redable imo.",0,0.9804753661155701
39103099,195,Parth-Brahmbhatt,2015-09-09T22:06:51Z,function is deleted given jun has recommended to assume that zkclient will handle reconnects and guarantee all the watchers are always delivered.,0,0.9890778064727783
39103189,195,Parth-Brahmbhatt,2015-09-09T22:07:41Z,done.,0,0.9759407639503479
39104580,195,Parth-Brahmbhatt,2015-09-09T22:21:52Z,removed and added listener for reconnection handler.,0,0.9882681965827942
39105224,195,Parth-Brahmbhatt,2015-09-09T22:29:24Z,handled the case where its not string by just adding another case.,0,0.9866673350334167
39107202,195,junrao,2015-09-09T22:55:07Z,"parth, zk watchers are actually one-timer watchers ([a link] when a watcher fires, the client has to register the watcher again (typically through a read) to get notification for future changes. between the time that a watcher fires and the client does a read, multiple changes could have happened. the read will return the latest value and leave a watcher there. so, in general, there is no guarantee that every change triggers the firing of a watcher. in particular, if you update the value of a zk path multiple times in between, only the latest value will be seen by the reader. one way to capture all changes is to follow how we propagate the config changes (configchangelistener). whenever we change an acl, we write the acl under /kafka-acl and also write a sequential zk node under /kafka-acl-changed. the value of the sequential zk node indicates the resource for which the acl has changed. the sequential zk nodes are guaranteed to be unique and have a number suffix that's ever growing. the acl manager registers a child change listener on /kafka-acl-changed and remembers the last number suffix that it has processed. when the watcher fires, the acl manager reads all child nodes under /kafka-acl-changed (the read may pick up multiple acl changes) and process new nodes after the last remembered number suffix. the processing will involve reading the latest acl associated with the corresponding resource. since every sequential node is unique, the acl manager won't miss any acl change. on initialization, the acl manager will first register the watcher and read all existing acls. finally, we need a way to garbage collect old sequential nodes. this can be done by just removing sequential nodes that are say, more than 15 mins old (assuming every broker would have picked up the acl changes by then).",0,0.9562901854515076
39112549,195,Parth-Brahmbhatt,2015-09-10T00:08:18Z,thanks for the explanation and it makes perfect sense. will update the pr.,1,0.925186812877655
39349577,195,junrao,2015-09-13T17:06:25Z,typo immeditatly,0,0.9733372926712036
39349578,195,junrao,2015-09-13T17:06:32Z,need to either remove those pirintlns or convert them to logging.,0,0.9747159481048584
39349582,195,junrao,2015-09-13T17:06:39Z,perhaps we can include path and notifications in the error message.,0,0.9880452752113342
39349583,195,junrao,2015-09-13T17:06:47Z,we probably should rename this to /kafka-acl-changes.,0,0.9839228987693787
39349584,195,junrao,2015-09-13T17:06:50Z,"perhaps rename this to ""acl_changes_""?",0,0.9826013445854187
39349586,195,junrao,2015-09-13T17:07:03Z,probably rename this as javaconfigs. then we can define the scala one as configs.,0,0.9860317707061768
39349587,195,junrao,2015-09-13T17:07:08Z,perhaps it's better to explicitly assign the initial values than using _.,0,0.9812412858009338
39349588,195,junrao,2015-09-13T17:07:13Z,"to be consistent, use set.empty[kafkaprincipal] instead of set.empty?",0,0.987231433391571
39349592,195,junrao,2015-09-13T17:07:27Z,perhaps we can allow zkconnectiontimeout and zksessiontimeout to be configured explicitly for simpleauthorizer and default to those in kafkaconfig if not specified.,0,0.9888561367988586
39349604,195,junrao,2015-09-13T17:08:01Z,"i had a comment in the jira. it seems that in socketserver, when creating the session object, it's better to create a kafkaprincipal instead of using kafkachannel.principal(). the type in kafkaprincipal should always be user and the name should be kafkachannel.principal().getname(). then, we can just get the kafkaprincipal from session and don't need to create a new one.",0,0.9842096567153931
39349608,195,junrao,2015-09-13T17:08:24Z,"this is useful for things like auditing. perhaps we can log this in the end together with the decision on wether the operation is granted on not. also, could we put that into a separate authorization log4j logger (take a look at the request logger in log4j.properties)? that way, if people want auditing, they can just enable the authorization logger.",0,0.9761943817138672
39349609,195,junrao,2015-09-13T17:08:29Z,should this be removed?,0,0.9809368252754211
39349610,195,junrao,2015-09-13T17:08:32Z,can this be private?,0,0.9878947138786316
39349611,195,junrao,2015-09-13T17:08:35Z,can this be private?,0,0.9878947138786316
39349613,195,junrao,2015-09-13T17:08:38Z,can this be private?,0,0.9878947138786316
39349614,195,junrao,2015-09-13T17:08:39Z,can this be private?,0,0.9878947138786316
39349615,195,junrao,2015-09-13T17:08:46Z,this needs to be removed.,0,0.9592932462692261
39349616,195,junrao,2015-09-13T17:08:54Z,"since these two are accessed from different threads, do they need to be volatile?",0,0.9837321639060974
39349633,195,junrao,2015-09-13T17:10:50Z,"ideally, we want to reuse this class in dynamicconfigmanager. if that's too much to do in this jira, could you file a follow-up jira to address this?",0,0.9862517714500427
39439189,195,Parth-Brahmbhatt,2015-09-14T19:58:22Z,i like the idea of changing type of principal in session as kafkaprincipal. i dont agree with the type being always user as different authentication schemes may want to change that and different authorizer implementations may actually use the values differently. does that sound ok?,1,0.7995791435241699
39445926,195,Parth-Brahmbhatt,2015-09-14T20:56:26Z,fixed,0,0.975196123123169
39445928,195,Parth-Brahmbhatt,2015-09-14T20:56:27Z,was planning to do the same. filed kafka-2547,0,0.9753349423408508
39445934,195,Parth-Brahmbhatt,2015-09-14T20:56:30Z,removed debug statement.,0,0.9780594706535339
39445938,195,Parth-Brahmbhatt,2015-09-14T20:56:32Z,done.,0,0.9759407639503479
39445952,195,Parth-Brahmbhatt,2015-09-14T20:56:37Z,done,0,0.9764507412910461
39445961,195,Parth-Brahmbhatt,2015-09-14T20:56:39Z,done,0,0.9764507412910461
39445971,195,Parth-Brahmbhatt,2015-09-14T20:56:41Z,done.,0,0.9759407639503479
39445975,195,Parth-Brahmbhatt,2015-09-14T20:56:43Z,done.,0,0.9759407639503479
39445980,195,Parth-Brahmbhatt,2015-09-14T20:56:45Z,done.,0,0.9759407639503479
39445984,195,Parth-Brahmbhatt,2015-09-14T20:56:47Z,done,0,0.9764507412910461
39446002,195,Parth-Brahmbhatt,2015-09-14T20:56:55Z,"any time we allow or deny we already log the decision and the reasoning behind it, the trace is actually just to mark the entry point. modified log4j but i have set the default level at warn which will disable audit logging by default. let me know if you want it to be enabled by default.",0,0.9887642860412598
39446007,195,Parth-Brahmbhatt,2015-09-14T20:56:58Z,done.,0,0.9759407639503479
39446014,195,Parth-Brahmbhatt,2015-09-14T20:57:01Z,done,0,0.9764507412910461
39446020,195,Parth-Brahmbhatt,2015-09-14T20:57:03Z,done,0,0.9764507412910461
39446024,195,Parth-Brahmbhatt,2015-09-14T20:57:05Z,done,0,0.9764507412910461
39446032,195,Parth-Brahmbhatt,2015-09-14T20:57:06Z,done,0,0.9764507412910461
39446038,195,Parth-Brahmbhatt,2015-09-14T20:57:09Z,done,0,0.9764507412910461
39446049,195,Parth-Brahmbhatt,2015-09-14T20:57:14Z,done,0,0.9764507412910461
39468051,195,junrao,2015-09-15T02:06:53Z,"since we return early in a few places, it seems that not all accesses are logged.",0,0.9777550101280212
39468196,195,junrao,2015-09-15T02:10:07Z,"hmm, how do we get the type from the authentication layer? currently, authenticator only returns a principal, which just has a name?",0,0.987245500087738
39538158,195,Parth-Brahmbhatt,2015-09-15T17:19:17Z,"i rechecked to assure it is logged in all cases (superuser, no acls, deny acl match(as part of matching function), allow acl match(as part of matching function), no acl found). if we want it to be logged at the end, i can change the logic so it does not return in middle. may be its just me, i think the current way looks cleaner.",0,0.9679051041603088
39543626,195,Parth-Brahmbhatt,2015-09-15T18:00:01Z,"i was saying we change the type in authenticator interface to kafkaprincipal. then each authenticator implementation can add its own type (ssl can set principaltype=certificate, and kerberos based sasl can set type= user) as long as the authorizer they use can handle different types they will be fine. this will specifically useful when there are multiple listeners. i guess we can just do what you are suggesting for now and if we encounter a real use case we can change the type in authenticator at that time. i have made the changes you suggested for now.",0,0.8767944574356079
39591781,195,junrao,2015-09-16T03:54:26Z,"getacls should be getaclsfromzk, right? could we add a unit test to test the initial loading?",0,0.9886918067932129
39630946,195,ijuma,2015-09-16T13:48:46Z,why not import `javaconverters._` along with other imports at the top of the file and then simply do `changes.asjava` here and delete all local imports?,0,0.9871720671653748
39631044,195,ijuma,2015-09-16T13:49:34Z,we normally include `()` for side-effecting changes.,0,0.9875060319900513
39631152,195,ijuma,2015-09-16T13:50:24Z,it's generally better to do `notifications.nonempty` because it's o(1) even if the underlying implementation has a o(n) `size` (like scala.list).,0,0.987174928188324
39632552,195,ijuma,2015-09-16T14:00:47Z,early return inside a closure (and a for comprehension desugars to `foreach`) actually involves throwing a `nonlocalreturncontrol` exception. you don't think the following is more readable? [code block],0,0.9868828654289246
39633336,195,ijuma,2015-09-16T14:06:56Z,`unit.` should not be part of package name.,0,0.983807384967804
39633374,195,ijuma,2015-09-16T14:07:14Z,`unit` should not be part of package name,0,0.9862052798271179
39683091,195,Parth-Brahmbhatt,2015-09-16T20:48:48Z,done. sorry about missing this in first place. added the test for load cache.,-1,0.9874070286750793
39683115,195,Parth-Brahmbhatt,2015-09-16T20:48:54Z,done.,0,0.9759407639503479
39683121,195,Parth-Brahmbhatt,2015-09-16T20:48:56Z,done,0,0.9764507412910461
39683126,195,Parth-Brahmbhatt,2015-09-16T20:48:58Z,done,0,0.9764507412910461
39683134,195,Parth-Brahmbhatt,2015-09-16T20:49:03Z,may be i am missing it but where do you see the side effect?,0,0.800758421421051
39683137,195,Parth-Brahmbhatt,2015-09-16T20:49:07Z,done.,0,0.9759407639503479
39683204,195,Parth-Brahmbhatt,2015-09-16T20:49:40Z,added a consistent audit log message in addition to the other logging statements.,0,0.9863765835762024
39683466,195,Parth-Brahmbhatt,2015-09-16T20:51:45Z,"the original version is more readable to me, may be its just my java brain. i have assumed scala idioms make it more redable with your approach so changed it as you suggested. still had to use a return inside the map as acl is not an option but type acl.",0,0.9848228693008423
39684697,195,ijuma,2015-09-16T21:02:19Z,"`milliseconds()` returns a different result every time, so it's a side-effecting method (it gets data from the system clock typically). side-effect free methods always return the same result given the same arguments, so a method that takes no parameters and doesn't return a constant result is a side-effecting method.",0,0.9834305047988892
39769987,195,Parth-Brahmbhatt,2015-09-17T16:55:54Z,my understanding of what side effect is different than what you described. i have added the () anyways given i don't really think it affects readability one way or another.,0,0.6859898567199707
39771350,195,ijuma,2015-09-17T17:08:07Z,it is true that the terminology would be clearer if we used pure versus impure functions. thanks for making the change anyway.,1,0.9512518644332886
39778562,195,Parth-Brahmbhatt,2015-09-17T18:06:46Z,"i actually had to remove the bracket for compilation to succeed. with the beackets i get ""/users/pbrahmbhatt/repo/kafka/core/src/main/scala/kafka/common/zknodechangenotificationlistener.scala:80: long does not take parameters val now = time.milliseconds()""",0,0.9859753251075745
39779399,195,ijuma,2015-09-17T18:13:07Z,sorry for this. the reason is that the scala version of `time` has a method called `milliseconds` so you can't use `()` at the end. the java version of `time` doesn't have this issue.,-1,0.9877711534500122
39812216,195,junrao,2015-09-17T23:45:04Z,"it seems that we don't need both imports on javaconversions? import scala.collection.javaconversions._ seems enough. also, i think the previous version you had to just do the import inside processallnotifications() is better since it makes it clear where the implicits are used.",0,0.9678437113761902
39812243,195,junrao,2015-09-17T23:45:18Z,": i actually find the ""for-loop"" version that parth wrote earlier easier to understand. map() is supposed to convert one collection to another and it seems it's weird to return from inside a map().",-1,0.963364839553833
39812253,195,junrao,2015-09-17T23:45:25Z,why are we looping through resourcenames twice?,0,0.9544312357902527
39812263,195,junrao,2015-09-17T23:45:32Z,could we put addacls() and waituntiltrue() in a private method and reuse?,0,0.9888203740119934
39812389,195,ijuma,2015-09-17T23:47:33Z,i agree that this version looks worse. it's not what i suggested. :) a `getorelse` after the map is what i would do. do you still prefer the previous version in that case?,1,0.9700655341148376
39812505,195,ijuma,2015-09-17T23:49:14Z,", why not simply use import javaconverters._? it's the recommended way since it was introduced years ago. the main advantage is that it is both explicit (one has to use `asscala` or `asjava`) and you don't need scoped imports everywhere (which are quite verbose).",0,0.9778264760971069
39813672,195,ijuma,2015-09-18T00:08:46Z,"to elaborate a bit, `return` is discouraged in scala because it's not composable which makes it harder to refactor code safely. once `return` is used, it is no longer safe to extract code into reusable functions. another problem with `return` is that it uses exceptions for control flow once used inside closures (which are everywhere in scala) as it is the only way to implement the specified behaviour in the jvm. unfortunately, return is used quite a lot in this pr. i'd be willing to submit a pr to this branch that removed all usages of `return` for comparison if there is interest.",0,0.5338168740272522
39813673,195,junrao,2015-09-18T00:08:46Z,using explicit javaconverters will be fine.,0,0.9789671301841736
39813766,195,junrao,2015-09-18T00:10:24Z,could you post the exact syntax you had in mind?,0,0.9870473146438599
39814098,195,ijuma,2015-09-18T00:16:15Z,[code block] or [code block] the latter is more concise although we don't use it much in kafka yet.,0,0.9842469692230225
39862295,195,junrao,2015-09-18T14:46:40Z,"it would be better to move this inside processallnotifications() so that we know exactly where the implicits are used. alternatively, we can use the explicit conversion through javaconverters as isamel suggested.",0,0.9871981739997864
39862320,195,junrao,2015-09-18T14:46:48Z,could we just return boolean here?,0,0.9882023930549622
39862560,195,junrao,2015-09-18T14:48:44Z,"it seems that if filteredacls is empty, we want to remove the corresponding acl path. could we add a unit test for that? also, we probably only need to update zk if filteredacls is different from existingacls.",0,0.988509476184845
39862611,195,junrao,2015-09-18T14:49:15Z,"could we make this more general to sth like the following? then we can remove all individual usage of waituntiltrue(). // return the new acl set after applying the changes to the original acl. changeaclandverify(originalacl: set[acl], addedacl: set[acl], removedacl: set[acl]): set[acl]",0,0.9874842762947083
39862755,195,ijuma,2015-09-18T14:50:22Z,is this used anywhere?,0,0.9868593215942383
39863387,195,ijuma,2015-09-18T14:55:29Z,`exists` is probably better than `find` here as you are not using the value. maybe something like [code block],0,0.9840187430381775
39863729,195,ijuma,2015-09-18T14:58:33Z,"a number of typing annotations that could be removed as they are easily inferred (`string`, `set[acl]`, `acl`). it's ok to keep them if you think they help readability (as opposed to just java habits ;)).",0,0.9859450459480286
39864202,195,ijuma,2015-09-18T15:02:28Z,"remove type annotation on the left-hand side? also, you can replace `hashmap` with `map` which is the static factory method.",0,0.9890087246894836
39864888,195,ijuma,2015-09-18T15:08:31Z,`aclcache.values.flatmap(_.filter(_.principal == principal)).toset` should do the same as all of the lines above. the following is a bit more readable though: `aclcache.values.flatmap(aclset => aclset.filter(_.principal == principal)).toset`,0,0.9830033183097839
39884655,195,Parth-Brahmbhatt,2015-09-18T18:15:57Z,done,0,0.9764507412910461
39884657,195,Parth-Brahmbhatt,2015-09-18T18:16:00Z,done.,0,0.9759407639503479
39885138,195,Parth-Brahmbhatt,2015-09-18T18:20:36Z,we were not deleting the zookeeper path until an explicit call to remove(resource was made). i have changed that and added unit test. to read the zookeeper path i made the method toresourcepath public.,0,0.9873786568641663
39885146,195,Parth-Brahmbhatt,2015-09-18T18:20:41Z,done,0,0.9764507412910461
39885153,195,Parth-Brahmbhatt,2015-09-18T18:20:47Z,in the initialize we register this zkclient so in case a reconnection happens zkclient will invoke this method and as part handling a new session it will process any missed notifications during the reconnection.,0,0.9892738461494446
39885157,195,Parth-Brahmbhatt,2015-09-18T18:20:49Z,done.,0,0.9759407639503479
39885181,195,Parth-Brahmbhatt,2015-09-18T18:21:03Z,"java habits, nothing really to do with readability :-). guess it's going to take me sometime before i stop doing this.",1,0.9161487817764282
39885186,195,Parth-Brahmbhatt,2015-09-18T18:21:08Z,removed the type. trying to convert to map actually gives compilation error.,0,0.8585006594657898
39885345,195,Parth-Brahmbhatt,2015-09-18T18:22:42Z,"i actually realized one thing, given acl class itself does not have resource as acls are suppose to be attached to a resource, this method is pretty useless unless it returns a map[resource, set[acl]]. i have made the changes to both the interface and the implementation to reflect that.",0,0.8125993609428406
39893276,195,junrao,2015-09-18T19:42:14Z,empty set => empty map,0,0.9830101728439331
39893280,195,junrao,2015-09-18T19:42:17Z,space after if,0,0.9781984090805054
39893304,195,junrao,2015-09-18T19:42:36Z,has a valid point. it doesn't seem reconnection is ever used? the handling of the reconnection logic is all in handlenewsession().,0,0.9870004057884216
39893656,195,Parth-Brahmbhatt,2015-09-18T19:46:58Z,sorry i though he was referring to zkstatechangelistener object itself. removed.,-1,0.9863989353179932
39893666,195,Parth-Brahmbhatt,2015-09-18T19:47:01Z,done.,0,0.9759407639503479
39893669,195,Parth-Brahmbhatt,2015-09-18T19:47:03Z,done.,0,0.9759407639503479
39931619,195,junrao,2015-09-20T16:30:51Z,"startup() implies this class will have internal threads, but it doesn't. would it be better to rename this to init()?",0,0.9870855212211609
39931623,195,junrao,2015-09-20T16:31:00Z,"to be consistent with the line in 86, set.empty => set.empty[kafkaprincipal]?",0,0.9882892370223999
39931626,195,junrao,2015-09-20T16:31:27Z,"the ordering can be a bit subtle here. in order not to miss a session expiration event, we should probably use the following ordering. zkclient = zkutils.createzkclient(zkurl, zkconnectiontimeoutms, zksessiontimeoutms) zkutils.makesurepersistentpathexists(zkclient, simpleaclauthorizer.aclzkpath) [code block]",0,0.9811480641365051
39931632,195,junrao,2015-09-20T16:31:36Z,"we should add the acl to aclcache, right? could we add a unit test to cover this?",0,0.9878487586975098
39931641,195,junrao,2015-09-20T16:32:10Z,"it seems that we expect notificationmessage to be non-empty. so, perhaps we can change the type of processnotifications to be just string and in zknodechangenotificationlistener.processnotifications(), log a warning (with the path) if the data read from zk is empty.",0,0.9885256886482239
39931644,195,junrao,2015-09-20T16:32:21Z,"simpleaclauthorizer should be authorizer? also, we should add a loadcache() tests where all the nodes in /acl_changes are gone.",0,0.9900369644165039
40006553,195,Parth-Brahmbhatt,2015-09-21T18:24:46Z,done.,0,0.9759407639503479
40006570,195,Parth-Brahmbhatt,2015-09-21T18:24:52Z,done.,0,0.9759407639503479
40006588,195,Parth-Brahmbhatt,2015-09-21T18:25:01Z,done.,0,0.9759407639503479
40006914,195,Parth-Brahmbhatt,2015-09-21T18:27:34Z,"originally i did that but i figured given we havent added add,remove apis in reality add/remove calls will be made from cli so modifying cache did not make much sense. also it seemed cleaner to just have a single path (notification) that updated the cache and also made it easy to test. i have made changes to update the cache as you suggested but i don't see given the same state can be modified by 2 components there is any easy way to add unit test to ensure which component actually made the state change.",0,0.9194488525390625
40006927,195,Parth-Brahmbhatt,2015-09-21T18:27:42Z,done.,0,0.9759407639503479
40006945,195,Parth-Brahmbhatt,2015-09-21T18:27:51Z,done.,0,0.9759407639503479
40020498,195,junrao,2015-09-21T20:20:35Z,"this can just be private def loadcache() { ... } there are a few other places that we can get rid of "": unit ="".",0,0.9869881868362427
40020520,195,junrao,2015-09-21T20:20:49Z,"we shouldn't be accumulating in acls, right?",0,0.9711477160453796
40020555,195,junrao,2015-09-21T20:21:04Z,could we set up two resources with acl to cover the new issue identified in loadcache()?,0,0.9887840747833252
40020567,195,junrao,2015-09-21T20:21:09Z,space after if,0,0.9781984090805054
40022804,195,Parth-Brahmbhatt,2015-09-21T20:40:13Z,done.,0,0.9759407639503479
40022808,195,Parth-Brahmbhatt,2015-09-21T20:40:14Z,done,0,0.9764507412910461
40022814,195,Parth-Brahmbhatt,2015-09-21T20:40:18Z,"yes, done.",0,0.9761238098144531
40022826,195,Parth-Brahmbhatt,2015-09-21T20:40:24Z,done.,0,0.9759407639503479
40027139,195,junrao,2015-09-21T21:16:44Z,"remove "": unit =""",0,0.9571208357810974
40027169,195,junrao,2015-09-21T21:17:02Z,"if a method has no return value, we need to define it as the following w/o =. otherwise, it will pick up the value in the last statement as the return value. ditto in a few other places. def loadcache() { }",0,0.980061948299408
40028686,195,Parth-Brahmbhatt,2015-09-21T21:28:35Z,done.,0,0.9759407639503479
40028689,195,Parth-Brahmbhatt,2015-09-21T21:28:37Z,done.,0,0.9759407639503479
40035419,195,junrao,2015-09-21T22:35:14Z,remove =,0,0.9517606496810913
40035425,195,junrao,2015-09-21T22:35:20Z,remove =,0,0.9517606496810913
40035432,195,junrao,2015-09-21T22:35:25Z,remove =,0,0.9517606496810913
40035437,195,junrao,2015-09-21T22:35:29Z,remove =,0,0.9517606496810913
40035443,195,junrao,2015-09-21T22:35:33Z,remove =,0,0.9517606496810913
40035455,195,junrao,2015-09-21T22:35:40Z,testprocessnotification(),0,0.9873528480529785
40035464,195,junrao,2015-09-21T22:35:47Z,def testtopicacl() {,0,0.9829058647155762
40035473,195,junrao,2015-09-21T22:35:52Z,def testdenytakesprecedence() {,0,0.9852574467658997
40035480,195,junrao,2015-09-21T22:35:55Z,def testallowallaccess() {,0,0.984938383102417
40035489,195,junrao,2015-09-21T22:36:01Z,def testsuperuserhasaccess() {,0,0.9837130308151245
40035496,195,junrao,2015-09-21T22:36:05Z,def testnoaclfound() {,0,0.9837905764579773
40035506,195,junrao,2015-09-21T22:36:13Z,def testnoaclfoundoverride() {,0,0.9847779273986816
40035514,195,junrao,2015-09-21T22:36:19Z,def testaclmanagementapis() {,0,0.9821377992630005
40035523,195,junrao,2015-09-21T22:36:24Z,def testloadcache() {,0,0.9838505387306213
113242905,2910,ijuma,2017-04-25T16:19:38Z,seems like passing `isolationlevel` explicitly is a good idea anyway. maybe we don't need this comment.,0,0.9282821416854858
113243316,2910,ijuma,2017-04-25T16:21:24Z,"if we don't use `buffer` in this path, do we still want to allocate it eagerly?",0,0.9834760427474976
113244042,2910,ijuma,2017-04-25T16:24:27Z,you could use `map` instead of pattern matching.,0,0.9883931279182434
113244445,2910,ijuma,2017-04-25T16:26:03Z,maybe this block should be in a separate method.,0,0.9839045405387878
113244887,2910,ijuma,2017-04-25T16:27:41Z,nit: just use `filechannel.open` directly?,0,0.9894974231719971
113244991,2910,ijuma,2017-04-25T16:28:05Z,how do we go about deciding whether to use schema classes or writing to the buffer directly?,0,0.983105480670929
113246179,2910,ijuma,2017-04-25T16:32:39Z,"a general comment about default values: we should consider carefully when to use them as they are a common source of bugs. when we use them, the compiler no longer ensures that we think about what the value should be.",0,0.9643068909645081
113247921,2910,hachikuji,2017-04-25T16:39:33Z,ack. was thinking the same thing when i was looking over this.,0,0.8020630478858948
113248857,2910,hachikuji,2017-04-25T16:43:30Z,"sure, we can push allocation into the other branch. this is technically a bug fix, by the way, since `log.read` can return `memoryrecords.empty`.",0,0.9813013076782227
113249530,2910,hachikuji,2017-04-25T16:46:28Z,"yeah, it was a tough call. there's only a handful of use cases for `isfromclient = false`, and the default is the more restrictive option, so i thought it was reasonable.",-1,0.5512427091598511
113253193,2910,hachikuji,2017-04-25T17:01:32Z,"kind of a subjective call, but since we scan the abort index when handling fetches and the schema is so simple, i thought we could skip the need to go through the `struct` object when reading and writing.",0,0.9802936315536499
113829442,2910,junrao,2017-04-28T00:08:43Z,"during append, perhaps it's useful to assert that abortedtxn are inserted in ascending lastoffset order?",0,0.9876447319984436
113830001,2910,junrao,2017-04-28T00:13:54Z,"we don't set the position of channel after channel.truncate(), which seems ok. for consistency, we probably want to do the same in filerecords.truncateto()?",0,0.9878163933753967
113830270,2910,junrao,2017-04-28T00:16:40Z,"it seems that we can just allocate a single buffer and reuse, instead of reallocating?",0,0.9863405227661133
113831097,2910,junrao,2017-04-28T00:25:40Z,we throw an exception in the iterator below. should we do the same thing here?,0,0.980840265750885
113832544,2910,junrao,2017-04-28T00:42:38Z,could we add some comments on what's stored in this index?,0,0.9875284433364868
113833158,2910,junrao,2017-04-28T00:49:14Z,it would be useful to document whether firstoffset and lastoffset are inclusive or exclusive.,0,0.9855253100395203
113834767,2910,junrao,2017-04-28T01:05:00Z,it seems that we are missing the logic to fence off the request based on coordinatorepoch?,0,0.9417178630828857
113834965,2910,junrao,2017-04-28T01:07:18Z,we can probably use requesttimeoutms.,0,0.9881666302680969
113836150,2910,junrao,2017-04-28T01:21:01Z,could we document the new field in the java doc above?,0,0.9891859889030457
113838187,2910,junrao,2017-04-28T01:47:43Z,could we add the new field to the comment above? ditto for line 485.,0,0.904259979724884
113838217,2910,junrao,2017-04-28T01:48:05Z,"now that we have a few different types of epoch, could we change epoch to producerepoch?",0,0.9870147705078125
113972136,2910,junrao,2017-04-28T16:44:41Z,"could we add a method in recordbatch to indicate whether the batch is a controlled batch or not? also, it seems that we use a special sequence number to indicate whether a batch is controlled or not. would it be better to use another bit in the attribute for that?",0,0.9891433119773865
114010900,2910,junrao,2017-04-28T20:14:09Z,epoch => producerepoch? ditto in line 54.,0,0.9227333664894104
114013479,2910,junrao,2017-04-28T20:29:42Z,"there can only be one opening transaction from a pid, right? if so, does startedtxns need to be a set?",0,0.9874322414398193
114016660,2910,junrao,2017-04-28T20:48:04Z,"hmm, it seems because of this, we could be sending multiple responses for the same writetxnmarkersrequest, which won't be right?",0,0.9798873662948608
114018063,2910,junrao,2017-04-28T20:56:00Z,the spec says the value of the control record contains the coordinatorepoch.,0,0.9883356094360352
114018154,2910,junrao,2017-04-28T20:56:28Z,could we be calculate the buffer size more precisely?,0,0.9859451651573181
114035995,2910,junrao,2017-04-28T23:22:43Z,"hmm, when this is called on the leader side, we haven't assigned the offset for the record yet. it seems that this means the offset returned in appendinfo.completedtransactions will be incorrect when we try to use it?",0,0.9828264117240906
114036286,2910,junrao,2017-04-28T23:25:54Z,"when firstoffset is set to controlrecord.offset, it seems that lastoffset could be smaller than firstoffset. should we guard that?",0,0.9883320927619934
114038106,2910,junrao,2017-04-28T23:50:45Z,do we need to call this here given that we are calling the same method in onhighwatermarkincremented()?,0,0.9846605658531189
114039345,2910,junrao,2017-04-29T00:09:55Z,could we add isolationlevel to the comment above?,0,0.988402783870697
114039715,2910,junrao,2017-04-29T00:16:26Z,"we probably want to use the offset in fetchinfo instead of startoffset, which can be larger than startoffset?",0,0.9884616136550903
114040200,2910,junrao,2017-04-29T00:25:52Z,should we call updatefirstunstableoffset() in truncateto() too?,0,0.9893240332603455
114362367,2910,hachikuji,2017-05-02T16:29:01Z,i think we already do. it is in the call to `buildandrecoverpidmap`.,0,0.9881536364555359
114367045,2910,hachikuji,2017-05-02T16:48:37Z,the responses are accumulated and only sent after all callbacks have been received. i can change the name to clarify this.,0,0.9871101379394531
114367825,2910,hachikuji,2017-05-02T16:52:00Z,hmm.. yes that sounds right.,0,0.9131820201873779
114400313,2910,hachikuji,2017-05-02T19:11:25Z,i've fixed this. we always use the offset of the control record as the last offset.,0,0.9861517548561096
114460760,2910,junrao,2017-05-03T01:33:01Z,"getting the position requires index lookup and may be a bit expensive. do we really need to maintain position? it seems that when using firstunstableoffset, we only need the offset, not the position?",0,0.9266877174377441
114461895,2910,junrao,2017-05-03T01:49:48Z,"hmm, log.firstunstableoffset is only advanced after the completemarker has been fully replicated, which suggests that log.firstunstableoffset is always going to be < highwatermark?",0,0.986223042011261
114614159,2910,hachikuji,2017-05-03T18:08:06Z,"i realized that we need all started transactions in order to ensure that the lso is updated correctly. we take all the started transactions from an append, add them to a sorted collection, and then remove the completed transactions in order of completion. this ensures that the lso is always correct.",0,0.9794776439666748
114662697,2910,junrao,2017-05-03T21:54:11Z,could we add a comment whether fetchoffset and upperboundoffset are inclusive or exclusive?,0,0.9876404404640198
114678287,2910,junrao,2017-05-03T23:45:30Z,"when we call roll(), the base offset of the new segment could actually be larger than logendoffset. so, in that case, the snapshot offset may not match the base offset of the next segment. since in flush(), we delete snapshots based on the baseoffset of the active segment, we may delete the last snapshot by accident. one way to fix this is to call producerstatemanager.updatemapendoffset(newoffset) before taking the snapshot.",0,0.9842654466629028
114679141,2910,junrao,2017-05-03T23:53:23Z,"hmm, the comment in line 72 says completed txns are sorted by last offset, which seems to be what we want?",0,0.9858660697937012
114680532,2910,junrao,2017-05-04T00:05:19Z,the warn in line 312 now needs to include the tnx index.,0,0.9887789487838745
114681599,2910,junrao,2017-05-04T00:15:57Z,"this can be done later. but reloading the snapshot when recovering every segment can be expensive. since segments are recovered in order, it seems that we just need to load the snapshot on recovering the first segment.",0,0.9686681628227234
114683318,2910,junrao,2017-05-04T00:35:04Z,"hmm, in theory, it seems that we could have an abort marker with no open records before it?",0,0.9622846841812134
114685936,2910,junrao,2017-05-04T01:05:34Z,"hmm, instead of using hard-coded read_uncommitted, shouldn't we use the isolation_level in the fetcher?",0,0.9772031307220459
114688209,2910,junrao,2017-05-04T01:37:56Z,"hmm, not sure about the comment on hw. with kip-101, typically the truncation point is >= the local hw.",0,0.9271876811981201
114882654,2910,hachikuji,2017-05-04T20:42:54Z,"ah, good catch. forgot to update this after the transactional client patch was merged.",1,0.9560077786445618
114899888,2910,hachikuji,2017-05-04T22:13:47Z,"sorting by the first offset is what we want. this is used to find the first unstable offset which will always be the minimum first offset of all transactions. i couldn't find the comment you were referring to since the patch was updated. if it still exists, can you point me to it?",0,0.9859721660614014
114900931,2910,hachikuji,2017-05-04T22:20:48Z,"hmm... good point. i had thought it was necessary since the first unstable offset could be lower than the high watermark, but we wouldn't be able to advance it any further from this write because any appended transaction markers could not have been replicated yet.",1,0.8211573958396912
114904376,2910,junrao,2017-05-04T22:44:15Z,"hmm, this logic may not be quite right for the follower. the follower could append batches for different pids in a single append call, if we reject all batches because a single batch is duplicated, the follower will miss records from other pids. in theory, duplicates should never happen in the follower. if duplicates somehow already leaked into the leader, it's kind of hard to not take the duplicates in the follower since the follower's log is supposed to be identical with the leader. so, perhaps we can only return on duplicates if the append is on the leader. if duplicates are detect in the follower, just log a warning but proceed with the append?",0,0.8031967878341675
114906482,2910,junrao,2017-05-04T22:59:59Z,"it's a bit inconsistent that we serialize the value here, but the key inside appendcontrolrecord(). perhaps it's better to serialize the value inside appendcontrolrecord() too?",0,0.9515256285667419
114916532,2910,junrao,2017-05-05T00:32:48Z,fetching up the the => fetching up to the,0,0.9863194227218628
114918036,2910,hachikuji,2017-05-05T00:52:14Z,"the intent was to return a duplicate only if `isfromclient` is set (which would never be the case for the follower), but it looks like i left that out. i'll fix in the next commit.",0,0.9876011610031128
114918859,2910,hachikuji,2017-05-05T01:04:36Z,"i was trying to keep `appendcontrolrecord` generic for future control record types. that said, it seems reasonable to add an `appendendtxnmarker` which handles serialization of both the key and value.",0,0.9857487082481384
115065007,2910,junrao,2017-05-05T18:51:10Z,do we need to get position from segment.append()? we could also just get the size of the segment before appending.,0,0.9887967109680176
115079600,2910,junrao,2017-05-05T20:17:21Z,it seems that undecidedfirstoffset should never be < unreplicatedfirstoffset?,0,0.7363484501838684
115080853,2910,junrao,2017-05-05T20:24:56Z,do we need to do this under lock since we are updating the state in producerstatemanager?,0,0.9766037464141846
115082326,2910,junrao,2017-05-05T20:33:58Z,are the callers all properly synchronized on log.lock?,0,0.9884727597236633
115088857,2910,junrao,2017-05-05T21:14:23Z,epoch => producerepoch ?,0,0.983860969543457
115090409,2910,junrao,2017-05-05T21:24:45Z,should we print out an error in the else clause?,0,0.9742504358291626
115094046,2910,hachikuji,2017-05-05T21:50:01Z,"i think it is possible. you may have something like this: w1, w2, c2, c1 (where w1 is a write from producer 1, and c1 is a commit from producer 1). say the high watermark has reached c1 (which means the transaction from producer 1 is not yet visible). in this case, the first undecided offset will be w1 while the first unreplicated offset will be w2.",0,0.9828148484230042
115097120,2910,hachikuji,2017-05-05T22:15:31Z,i added some code to print the unknown type id in the else case. let me know if that seems reasonable.,0,0.9864081144332886
115099271,2910,hachikuji,2017-05-05T22:35:37Z,"the example was a little wrong. the proper scenario is this: w1, w2, c2 say the high watermark is at c2. the first undecided offset will be w1, but the first unreplicated offset will be w2. once the high watermark reaches c2+1, the first undecided offset will still be w1 and the first unreplicated offset will be empty.",0,0.9759119153022766
634023546,10579,satishd,2021-05-18T04:06:08Z,`config` definition will be moved to `kafkaconfig` later when default rlmm is integrated with the broker.,0,0.9892696738243103
640140543,10579,junrao,2021-05-26T21:40:19Z,"if the producer/consumer are configured incorrectly, we want to fail faster instead of retrying.",0,0.9498564600944519
640140766,10579,junrao,2021-05-26T21:40:51Z,"since producermanager and consumermanager are updated in a separate thread without holding lock, do they need to be volatile?",0,0.9863196015357971
640142495,10579,junrao,2021-05-26T21:44:24Z,should we pass in time through the constructor?,0,0.9857410192489624
640147224,10579,junrao,2021-05-26T21:54:14Z,do we need this since it's in the caller already?,0,0.9872213006019592
640148086,10579,junrao,2021-05-26T21:55:54Z,waiting for each event to be consumed reduces throughput. could we handle the expected metadata load with this?,0,0.9830068349838257
640154886,10579,junrao,2021-05-26T22:08:46Z,remotelogmetadatacontext => remotelogmetadata?,0,0.9868791699409485
640157247,10579,junrao,2021-05-26T22:12:05Z,no need to cast to kafkaexception.,0,0.9812169075012207
640158657,10579,junrao,2021-05-26T22:15:25Z,sending one event at a time reduces the batching benefit in the producer. could this handle the expected metadata load?,0,0.9856955409049988
640158995,10579,junrao,2021-05-26T22:16:09Z,could we add a comment for this class?,0,0.9873014688491821
640979693,10579,junrao,2021-05-27T21:28:06Z,typo ard,0,0.9856752753257751
640996146,10579,junrao,2021-05-27T21:56:15Z,"hmm, shouldn't we start with assignedmetapartitions?",0,0.9759277105331421
640997181,10579,junrao,2021-05-27T21:57:24Z,"hmm, assignedmetapartitions may not change if assignedtopicpartitions changes. should we still update assignedtopicpartitions in that case?",0,0.9858759045600891
641001043,10579,junrao,2021-05-27T22:04:49Z,from which offset does the consumer start fetching?,0,0.9865208864212036
641029590,10579,junrao,2021-05-27T23:10:00Z,should we only process events corresponding to assignpartitions?,0,0.9850903749465942
641030221,10579,junrao,2021-05-27T23:11:42Z,"if a partition is moved to a different broker, we will need to bootstrap the remote state for the partition by consuming from the beginning of the remote metadata partition. how is that handled?",0,0.987281858921051
641031767,10579,junrao,2021-05-27T23:15:58Z,the tostring() method could change over time. perhaps it's safer to compute a customized hashcode for topicidpartition here.,0,0.9844314455986023
641034498,10579,junrao,2021-05-27T23:24:16Z,"bootstrap_servers_config should be prefixed with remote_log_metadata_client_prefix, right?",0,0.9894024133682251
641035399,10579,junrao,2021-05-27T23:26:54Z,do we need this? it seems that it's easier to just duplicate the property for producer and consumer.,0,0.9741290211677551
641093708,10579,junrao,2021-05-28T01:17:10Z,what's the purpose of waiting for consumption up to partitiontotargetendoffsets?,0,0.9837908148765564
642095193,10579,satishd,2021-05-30T15:53:03Z,making volatile makes sense to me.,0,0.7409204244613647
642095217,10579,satishd,2021-05-30T15:53:14Z,done.,0,0.9759407639503479
642095239,10579,satishd,2021-05-30T15:53:34Z,removed the check as you suggsted.,0,0.9856587052345276
642095245,10579,satishd,2021-05-30T15:53:40Z,this method is invoked from multiple threads for different topic partitions. this will not be a bottleneck as each partition's segments will be uploaded in a sequential manner.,0,0.9866711497306824
642095258,10579,satishd,2021-05-30T15:53:47Z,it is needed as the method is declared with throws kafkaexception. i am also fine with removing it as it is a rte.,0,0.9662094116210938
642095262,10579,satishd,2021-05-30T15:53:51Z,multiple events are published by multiple threads and batching will occur in the producer.,0,0.9875039458274841
642095305,10579,satishd,2021-05-30T15:54:06Z,i will add that.,0,0.9787295460700989
642095309,10579,satishd,2021-05-30T15:54:11Z,are you saying it should be initialized with `updatedassignedmetapartitions = new hashset<>(assignedmetapartitions);`. this is not needed as we are recomputing that set based on updatedreassignedpartitions.,0,0.9878276586532593
642095314,10579,satishd,2021-05-30T15:54:14Z,"nice catch, updated.",1,0.9543980360031128
642095350,10579,satishd,2021-05-30T15:54:28Z,we have not yet added the code to store the consumed offset and start from those offsets whenever the consumer starts fetching from those partitions. we plan to add that in a subsequent pr.,0,0.9870221018791199
642095355,10579,satishd,2021-05-30T15:54:33Z,"right, i will add that check.",0,0.9813953042030334
642095359,10579,satishd,2021-05-30T15:54:36Z,this is not addressed in this pr. i planned to have a followup pr for these changes. i may use a different consumer for the newly subscribed partitions to build the state.,0,0.978661298751831
642095367,10579,satishd,2021-05-30T15:54:44Z,"remote_log_metadata_client_prefix is just a prefix for generating client-ids for producer and consumer. if you are talking about the remote log metadata property prefix, it is assumed that the caller would have already removed those prefixes and sent the config. these prefixes are defined [a link]",0,0.9877246022224426
642095371,10579,satishd,2021-05-30T15:54:47Z,"this is to avoid duplicate entries for both the producer and consumer. we added that in the kip earlier. if duplicating is the way we use at other places if any, i am fine with that.",0,0.9748750925064087
642095384,10579,satishd,2021-05-30T15:54:49Z,this is leftover code for other changes that i was working on for handling partition moving to a new broker in another branch. i will remove it.,0,0.9849101901054382
642095431,10579,satishd,2021-05-30T15:55:05Z,good point. i will add that.,1,0.9245243668556213
643693257,10579,kowshik,2021-06-02T06:40:28Z,s/set in close state/closed,0,0.9840838313102722
643693431,10579,kowshik,2021-06-02T06:40:47Z,s/metadatapartitionno/metadatapartition,0,0.986974835395813
643694704,10579,kowshik,2021-06-02T06:43:10Z,it appears you could eliminate the additional `topicidpartition` parameter and instead use the value returned by `remotelogmetadata.topicidpartition()` api.,0,0.9887157082557678
643695433,10579,kowshik,2021-06-02T06:44:35Z,it appears this class does not have unit tests currently. is there a plan to add unit tests?,0,0.9807568788528442
643698596,10579,kowshik,2021-06-02T06:50:35Z,could you pls add a comment for this class?,0,0.9883184432983398
643698781,10579,kowshik,2021-06-02T06:50:55Z,s/millis/ms,0,0.9829016923904419
643705660,10579,kowshik,2021-06-02T07:02:30Z,i had the same question. it appears better to just duplicate the properties.,0,0.9830096364021301
643707051,10579,kowshik,2021-06-02T07:04:58Z,"it seems that we have internal topics specified in `org.apache.kafka.common.internals.topic` class. don't we want this new internal topic to be defined in the `topic` class, together with other internal topics?",0,0.9796055555343628
643709758,10579,kowshik,2021-06-02T07:09:25Z,"hmm, why do you need this exclusion to be true?",0,0.940229594707489
643715269,10579,kowshik,2021-06-02T07:17:49Z,"is this the timeout for how long you'd want the client to wait to consume the message that it produces to `__remote_log_metadata` topic? if yes, then don't we want this timeout to be unlimited i.e. we wait as long as it takes to consume the published event?",0,0.985065758228302
643716426,10579,kowshik,2021-06-02T07:19:37Z,"`consumerprops` and `producerprops` are of type `map`, therefore the `.tostring()` is probably not readable. so you'd need to convert these into a comma-separated list sth like `k1=v1,k2=v2,...kn=vn`.",0,0.9866883158683777
643725247,10579,kowshik,2021-06-02T07:32:18Z,"for readability, it'll be useful to place the positive case under `if` and negative case under `else`, such as: [code block]",0,0.9858249425888062
643726313,10579,kowshik,2021-06-02T07:33:51Z,could you pls document the state does this boolean represents?,0,0.989556610584259
643728635,10579,kowshik,2021-06-02T07:37:21Z,could you pls mention what state does this boolean represent?,0,0.9888779520988464
643730668,10579,kowshik,2021-06-02T07:40:20Z,is it useful to assert that `record.key()` is empty before the key is ignored below?,0,0.9893671870231628
643731568,10579,kowshik,2021-06-02T07:41:36Z,"hmm, should you be setting `close` to true here? (it depends on the meaning of `close`, which i don't fully understand....)",0,0.8145759105682373
643736256,10579,kowshik,2021-06-02T07:48:14Z,"it appears that once this logic is implemented, there is probably no need to wait for `maybewaitforpartitionsassignment`. the reason is that whenever a partition is assigned, we will bootstrap the remote state by consuming from the beginning.",0,0.986014723777771
643738304,10579,kowshik,2021-06-02T07:51:00Z,"do you really need this explicit lock? it seems you could just use `wait()` and `notify()` apis on the `consumertask` object instead, combined with `synchronized` keyword.",0,0.990213930606842
643740157,10579,kowshik,2021-06-02T07:53:28Z,s/noofmetadatatopicpartitions/nummetadatatopicpartitions,0,0.9825687408447266
643740418,10579,kowshik,2021-06-02T07:53:46Z,s/partitionno/partition,0,0.9879856705665588
643740610,10579,kowshik,2021-06-02T07:54:02Z,s/no of.../num of... also it feels overkill to me to log this message for each call.,-1,0.9792613983154297
643742067,10579,kowshik,2021-06-02T07:55:59Z,"is topic necessary here, when uuid and partition is already sufficient input for the hash?",0,0.988205075263977
643745043,10579,kowshik,2021-06-02T08:00:02Z,it seems these 2 attributes can be marked final if you call `map.clear()` in `close()` instead of replacing the reference.,0,0.9884522557258606
643746007,10579,kowshik,2021-06-02T08:01:17Z,s/logs/log ?,0,0.9874086380004883
643749217,10579,kowshik,2021-06-02T08:05:53Z,i agree with the question here. this can become more expensive than it seems. the alternative is to pursue an asynchronous notification model to improve the throughput.,0,0.9720731377601624
643754935,10579,kowshik,2021-06-02T08:14:07Z,could you pls add a comment on what state does `close` represent?,0,0.9879698753356934
648927106,10579,satishd,2021-06-10T07:36:25Z,"as we discussed offline, we see the benefit of keeping several common client config like security to be shared across producer and consumer props avoiding any copy/paste mistakes. user has an option not to use common client configs and use the respective producer and consumer configs.",0,0.9681257009506226
649387317,10579,satishd,2021-06-10T17:30:15Z,i plan to add this once rlmm is called from remote log layer classes. i wanted this change to be self contained for now.,0,0.9733545780181885
649387744,10579,satishd,2021-06-10T17:30:37Z,we do not want this to be completely blocked as we want to release the remote log thread after a specific timeout in case of any intermittent issues so that other partitions tiring can proceed.,0,0.9242230653762817
649387805,10579,satishd,2021-06-10T17:30:40Z,"we are using hashmap for these instances and it prints k,v format. are you suggesting that this map implementation may change as it is of type map and need to put the right tostring. we can change the reference type to hashmap for clarity if needed.",0,0.9879211187362671
649388017,10579,satishd,2021-06-10T17:30:51Z,i do not think that check is really needed here.,0,0.7592268586158752
649388066,10579,satishd,2021-06-10T17:30:53Z,"it indicates whether the closing process has been started or not. if it is set as true, consumer will stop consuming messages and it will not allow partition assignments to be updated. updated the java doc of close.",0,0.9881889820098877
649388122,10579,satishd,2021-06-10T17:30:57Z,i wanted to have a separate lock instance specifically for the assignments and the respective processing. it gives better clarity and separations even if we add any other logic by taking lock on this instance.,0,0.9723333716392517
649388430,10579,satishd,2021-06-10T17:31:13Z,good point. we can skip topic as topic-id is sufficient here.,1,0.9503219723701477
649388497,10579,satishd,2021-06-10T17:31:16Z,i went with assigning empty map as map.clear() needs to go through all the entries and dereference them. another way is to leave the map as it is and set the cose state and do not allow any operation when it is closed but it will have a check for each call.,0,0.9888144135475159
649390143,10579,satishd,2021-06-10T17:32:50Z,done,0,0.9764507412910461
649390214,10579,satishd,2021-06-10T17:32:56Z,done,0,0.9764507412910461
649390292,10579,satishd,2021-06-10T17:33:03Z,done,0,0.9764507412910461
649390516,10579,satishd,2021-06-10T17:33:26Z,done.,0,0.9759407639503479
649390677,10579,satishd,2021-06-10T17:33:41Z,done,0,0.9764507412910461
650456266,10579,satishd,2021-06-13T01:49:18Z,done,0,0.9764507412910461
656734732,10579,ccding,2021-06-23T03:38:22Z,can we avoid making the variable name the same as the function name?,0,0.9791027903556824
656735781,10579,ccding,2021-06-23T03:42:06Z,"why is the variable name `partitions`, while the one above for `addassignmentsforpartitions` is `allpartitions`? also why one is `set` and the other is `hashset`?",0,0.985787034034729
656737032,10579,ccding,2021-06-23T03:46:28Z,i think in the codebase we use `ms` more often than using `millis`,0,0.9882053136825562
656737294,10579,ccding,2021-06-23T03:47:23Z,should this be fixed or configurable in `rlmmconfig`?,0,0.9882335662841797
656737888,10579,ccding,2021-06-23T03:49:16Z,`id` -> `if`,0,0.9857843518257141
656738264,10579,ccding,2021-06-23T03:50:38Z,"we may want a better variable name here. e.g., `isclosing` or `closed` or something else.",0,0.9878615140914917
656740556,10579,ccding,2021-06-23T03:57:00Z,"multiple threads are reading and writing `close`, which is not thread safe",0,0.9745215177536011
656740892,10579,ccding,2021-06-23T03:58:12Z,"why is this set to 30, rather than another number like 10, 50, 100?",0,0.9430414438247681
656741851,10579,ccding,2021-06-23T04:01:33Z,is the check necessary?,0,0.9834083318710327
656743129,10579,ccding,2021-06-23T04:06:13Z,can you explain what this variable means?,0,0.9854598641395569
656744938,10579,ccding,2021-06-23T04:12:18Z,also here. why are the variable names different? one is `updatedpartitions` and the other is `partitions`,0,0.9878514409065247
656747158,10579,ccding,2021-06-23T04:19:48Z,what is the cost of consuming from the beginning if the remote metadata partition grows huge?,0,0.9595200419425964
656748094,10579,ccding,2021-06-23T04:22:44Z,"the function name is a little confusing with variable names in the same class, e.g., `assignpartitions`, `assignedtopicpartitions`. i am not sure if it would be better to rename `assignedpartition` to `isassignedpartition`.",0,0.6243101954460144
656748535,10579,ccding,2021-06-23T04:24:11Z,not good to use the same name for a variable and a function.,-1,0.816005527973175
656749199,10579,ccding,2021-06-23T04:26:28Z,greater than or equal to?,0,0.9654918909072876
656749604,10579,ccding,2021-06-23T04:27:45Z,will the exception be caught by your own catch in line 74? maybe move it out of the `try` block?,0,0.9860503077507019
656751271,10579,ccding,2021-06-23T04:32:53Z,out of curiosity: why we don't do the check within the `new kafkaexception(...)` call,0,0.8637799620628357
656751707,10579,ccding,2021-06-23T04:34:24Z,is the check necessary?,0,0.9834083318710327
656752286,10579,ccding,2021-06-23T04:36:07Z,new line at the end of the file,0,0.9864020943641663
656761165,10579,ccding,2021-06-23T05:03:18Z,"function names `addremotelogsegmentmetadata`, `updateremotelogsegmentmetadata`, and `putremotepartitiondeletemetadata` don't seem very consistent. is there a way to improve it?",0,0.9725874662399292
656764820,10579,ccding,2021-06-23T05:13:51Z,"here has a race condition. it is possible `close=false` before calling `ensureinitializedandnotclosed()` and the `close()` function call by another thread has completed before calling `remotepartitionmetadatastore.listremotelogsegments(topicidpartition, leaderepoch)`. i think we should always grab a read lock before calling `ensureinitializedandnotclosed();`, or do some other fancy things.",0,0.9674643874168396
657655419,10579,satishd,2021-06-24T06:16:27Z,"`close/closing` is already volatile and its state is immediately reflected in other threads. in `close()` method, the consumer is invoked with `wakeup()`, and the other thread may receive `wakeupexception` if it is executing `poll()` or earlier than that. if it is after `poll` then the next check of `close/closing` allows to come out and finally close the consumer. `updateassignmentsforpartitions` and `close()` methods can not be called concurrently as it is alreadyhandled by `topicbasedremotelogmetadatamanager`.",0,0.9818388223648071
657655825,10579,satishd,2021-06-24T06:17:20Z,"when the code was refactored, it went with the caller method arg names. thanks for catching these.",1,0.9394491314888
657655966,10579,satishd,2021-06-24T06:17:37Z,"what about `must be less than the partition count`, conveys the intent clearly.",0,0.9806766510009766
657656102,10579,satishd,2021-06-24T06:17:55Z,"if you are asking about the earlier catch block, that will not cover the exceptions like receiving from broker etc. the earlier catch block is applicable only until the record is added to the accumulator.",0,0.9880517721176147
657657314,10579,satishd,2021-06-24T06:20:42Z,i did not add the checks for these methods as they will not be invoked in parallel when close is called. but i agree to have the guards here with read lock.,0,0.9776304364204407
657670757,10579,satishd,2021-06-24T06:47:34Z,this is a temporary change. i plan to have a config with a default value.,0,0.9628427028656006
657671527,10579,satishd,2021-06-24T06:48:51Z,what about `ispartitionassigned`?,0,0.9856467843055725
657674359,10579,satishd,2021-06-24T06:53:57Z,"javadocs explain the behaviorr in detail. `addremotelogsegmentmetadata` - adds a new entry. `updateremotelogsegmentmetadata ` - updates an existing entry. `putremotepartitiondeletemetadata ` - adds or updates an existing entry, put is generally used for that purpose. if this is not so clear, another option can be `addorupdateremotepartitiondeletemetadata`.",0,0.9880561828613281
657683814,10579,satishd,2021-06-24T07:10:29Z,"as we discussed offlime, this may not become a bottleneck but we will make respective rlmm apis asynchronous so that the apis are extensible and implementors can provide async behavior.filed [a link] to track this issue.",0,0.9886133670806885
658361692,10579,satishd,2021-06-24T23:58:23Z,i plan to have a config with a default value in a follow-up pr.,0,0.9822555780410767
660802584,10579,junrao,2021-06-29T16:58:25Z,"hmm, why is this a daemon thread? it seems that we want to coordinate the shutdown of the thread.",0,0.9623441696166992
660810740,10579,junrao,2021-06-29T17:10:21Z,"hmm, should we throw an exception in this case so that the caller knows the operation has failed?",0,0.9727439284324646
660812883,10579,junrao,2021-06-29T17:13:31Z,"similar to the above, should we throw an exception in this case so that the caller knows the operation has failed?",0,0.9834823608398438
660836440,10579,junrao,2021-06-29T17:45:05Z,we need to unblock the wait if we are closing the consumer.,0,0.958179235458374
660975970,10579,junrao,2021-06-29T21:28:57Z,"is this necessary since immediately after this check, the consumer task could be closed. ditto in other places.",0,0.9782581925392151
660980922,10579,junrao,2021-06-29T21:37:50Z,"is this necessary? once producer is closed, send() will throw an exception.",0,0.9865720272064209
660990345,10579,junrao,2021-06-29T21:54:51Z,how is this different from remotelogmetadatacache? it seems that it's just a wrapper over remotelogmetadatacache?,0,0.9694656729698181
660991871,10579,junrao,2021-06-29T21:58:01Z,could we add a comment for this class?,0,0.9873014688491821
661000698,10579,junrao,2021-06-29T22:17:24Z,why do we need to initialize in a separate thread?,0,0.9750736355781555
661002879,10579,junrao,2021-06-29T22:22:17Z,"since we have a lock, could we just make closing a boolean?",0,0.9865111112594604
661629252,10579,junrao,2021-06-30T16:20:30Z,millis => ms to be consistent with other places. ditto in a few other places.,0,0.9569754004478455
661641738,10579,junrao,2021-06-30T16:36:54Z,is this needed since we log all configs when creating kafkaconfig already?,0,0.988060712814331
661642633,10579,junrao,2021-06-30T16:38:10Z,"other plugins on the broker may also need a bootstrap_server config. to distinguish them, it would be useful to add a prefix that's specific to remote storage.",0,0.9885141253471375
661672097,10579,junrao,2021-06-30T17:20:36Z,"it seems that we need to automatically create metadata topic in rlmm implementation, not just in tests.",0,0.9854883551597595
661673976,10579,junrao,2021-06-30T17:23:08Z,120s seems quite long. do we need to wait that long?,0,0.9568665623664856
661687251,10579,junrao,2021-06-30T17:42:56Z,typo nto,0,0.9861962795257568
661687392,10579,junrao,2021-06-30T17:43:09Z,this sentence doesn't read well.,-1,0.8800436854362488
661693600,10579,junrao,2021-06-30T17:52:25Z,this should be for consumer?,0,0.9855561852455139
661698279,10579,junrao,2021-06-30T17:59:31Z,why are we testing against -1 here but 0 above?,0,0.9410191774368286
663808257,10579,satishd,2021-07-05T10:06:16Z,"good catch, updated it.",1,0.9761127829551697
663809083,10579,satishd,2021-07-05T10:07:34Z,there are two implementations about this class for both `remotelogmetadatacache` and `topicbasedremotelogmetadatamanager`. there are common tests in `remotelogsegmentlifecycletest `that we want to run for both of them.,0,0.9862191081047058
663809683,10579,satishd,2021-07-05T10:08:27Z,it was required to be retried until the topic is successfully created. i added the logic to check for topic creation too.,0,0.9840887784957886
663811753,10579,satishd,2021-07-05T10:11:33Z,i was planning to add that later as mentioned earlier. i updated with the required changes in latest commit.,0,0.9801321625709534
663813208,10579,satishd,2021-07-05T10:13:40Z,updated with a comment in the code.,0,0.9841492772102356
663818344,10579,satishd,2021-07-05T10:21:39Z,updated with a comment.,0,0.9838215112686157
663819484,10579,satishd,2021-07-05T10:23:26Z,"i guess 60s may be sufficient, updated with that.",0,0.9755833148956299
663821465,10579,satishd,2021-07-05T10:26:46Z,`closing` is accessed in `initializeresources` and we do not need to take a lock there. i would like to keep this as `atomicboolean` which addresses that and it is easy to understand the semantics.,0,0.9731627106666565
664630725,10579,ccding,2021-07-06T14:53:56Z,is it possible two threads call `close()` concurrently?,0,0.9882517457008362
664632598,10579,ccding,2021-07-06T14:55:56Z,our of curiosity: why we have `l` here but not [a link],0,0.9502314329147339
664866782,10579,junrao,2021-07-06T20:45:42Z,the test for closing seem unnecessary since closing can't change while synchronized on assignpartitionslock.,0,0.9562757015228271
664868563,10579,junrao,2021-07-06T20:49:01Z,"is remotelogsegmentlifecyclemanager used for tests only? if so, could we move it under tests?",0,0.9887415766716003
664905089,10579,junrao,2021-07-06T22:00:41Z,"i am still not sure why we need to initialize in a separate thread. if we can't create the metadata topic or instantiate the producer/consumer due to wrong configurations, we want to fail fast by throwing an error to shut down the broker.",-1,0.7324056625366211
664907494,10579,junrao,2021-07-06T22:06:20Z,should we verify that the number of partitions in the existing topic matches the configuration?,0,0.9869351387023926
664908297,10579,junrao,2021-07-06T22:08:11Z,"hmm, we don't want to retry forever. if there is a configuration error, we want to fail fast.",0,0.7360019087791443
664911197,10579,junrao,2021-07-06T22:14:50Z,"hmm, why is this needed since initializeresources() does this already?",0,0.9713553190231323
664912870,10579,junrao,2021-07-06T22:19:02Z,it seems producer credentials are closer for the admin client.,0,0.9778515696525574
664913921,10579,junrao,2021-07-06T22:21:34Z,is this comment addressed?,0,0.9840131998062134
664914536,10579,junrao,2021-07-06T22:22:55Z,createmetadatatopic() is no longer used.,0,0.9500513672828674
664970217,10579,satishd,2021-07-07T01:11:27Z,`remotelogsegmentlifecyclemanager` is already under tests.,0,0.987356424331665
664976317,10579,satishd,2021-07-07T01:32:10Z,"this loop can run after `assignpartitionslock.wait()` call which might have been notified from `close()` method, we should have a `closing` check to get out of the loop. we can have a more aggressive check to return from here when `closing` is true, i will add that.",0,0.9869322180747986
664980913,10579,satishd,2021-07-07T01:46:58Z,`close()` will not be called concurrently here.,0,0.9803580045700073
664983511,10579,satishd,2021-07-07T01:53:00Z,"i prefer adding l for longs, which i missed at other declaration. afaik, that does not cause any issues as it gets automatically converted via a widening conversion to a `long`. the compiler takes care of not allowing numbers that may get truncated from `int` to `long` widening. thanks for catching it, i will make it consistent by adding it.",1,0.8801242113113403
665259927,10579,satishd,2021-07-07T10:50:18Z,"the reason why we need to initialize in a different thread here is that rlmm will be created and `configure()` will be called before the broker starts accepting the requests. so, we can not call topic creation requests in the same thread as the brokers are not yet up. another way to do this is to have this topic as an internal topic and it will be auto created whenever it is accessed. afaik, creating producer and consumer instances can be done without the brokers up and running and they will not trigger a request to auto creation of remote log metadata topic. consumer assignment will send a metadata request which will trigger auto creation of topics. this assignment on consumer is done only when rlmm receives callback thorough the broker about leader and isr updates from the controller. this is what we had in pre-2.7 implementation but we saw an intermittent deadlock issue but i do not see that happening on trunk. in the current pr, i will make the existing producer manager and consumer manager in configure() and have the topic creation done in the tests. i will have a quick follow-up pr with internal topic changes and remove the topic creation code from tests.",0,0.9786064624786377
665299398,10579,satishd,2021-07-07T11:54:00Z,"`remotelogmetadatamanager.configure(map configs)` is always invoked with stripping the rlmm prefix. ""bootstrap.servers"" property is sent as part of the configs here and any registered rlmm plugin will receive this property.",0,0.9885848164558411
665531236,10579,satishd,2021-07-07T16:29:41Z,i made the mentioned changes for this pr in the latest commit.,0,0.983555018901825
665544995,10579,kamalcph,2021-07-07T16:48:33Z,this condition should be inverted.,0,0.9784243106842041
665555878,10579,satishd,2021-07-07T17:04:26Z,"good catch, we do not really need this check here as it is already guarded in `topicbasedremotelogmetadatamanager`.",1,0.708156168460846
666372073,10579,junrao,2021-07-08T17:03:35Z,": to create a topic, you don't need a particular broker to be up. you just need to be able to access the bootstrap brokers. auto creating this topic on access is a bit weird since it's not truly an internal topic and it is just an implementation detail of rlmm. so, it makes more sense for topic-based rlmm to create it.",-1,0.9332388639450073
666697373,10579,satishd,2021-07-09T06:15:00Z,"as i mentioned earlier, rlmm is created before broker starts accepting the requests. so, when rlmm is getting initialized and tries to create a topic in the same thread, then none of the brokers(including the brokers related to the bootstrap-servers config) will be available for taking any admin client requests for topic creation. that is why i was doing this in a different thread as it allows the broker/controller to comeup and accept the admin client request for topic creation.",0,0.9791126251220703
667102624,10579,junrao,2021-07-09T17:21:12Z,": my understanding is that when we enable remote storage, we will do that through a rolling upgrade. so, at any given time, there is at most a single broker being down. therefore, as long as the bootstrap broker list contains more than one broker, operations like creating topics can still be done while a single broker is starting.",0,0.9432723522186279
667427888,10579,satishd,2021-07-11T06:04:21Z,": that is a good point. but that is valid only for upgrade scenario. there are two scenarios here. 1) upgrade path 2) fresh install/deploy with the release containing this feature. what you said makes sense for upgrade path. but ""bootstrap.servers"" list is configured with the local broker endpoint only in which rlmm is getting initialized. so, if we try to initialize rlmm in the same thread, it wont be able to connect to the local broker as it is not yet started to accept the broker api requests. one way to address this is to give `bootstrap.servers` with more than one broker's endpoint. this will also put a limitation to create a cluster with one broker instance for test/demo environments. when users install/deploy a fresh environment with the release containing this feature, there should not be a restriction to do rolling restarts with the configuration enabled. please let me know if i am missing anything here.",1,0.9327369332313538
670800796,10579,junrao,2021-07-15T20:58:17Z,should halt the jvm in this case? ditto below when the partition count doesn't match.,0,0.8187201023101807
670820515,10579,junrao,2021-07-15T21:34:47Z,"since bootstrap_servers is used for the internal producer/consumer, should bootstrap_servers be defined with a prefix of remote_log_metadata_common_client_prefix, remote_log_metadata_common_client_prefix or remote_log_metadata_consumer_prefix?",0,0.9888184666633606
670823373,10579,junrao,2021-07-15T21:40:10Z,does pendingassignpartitions need to be synchronizedset since it's accessed under a lock?,0,0.9877210259437561
670947570,10579,satishd,2021-07-16T03:59:51Z,"yes, we are already doing that [a link] whenever this class is accessed with/for remote log metadata operations.",0,0.9893484115600586
671094510,10579,satishd,2021-07-16T09:13:18Z,it is needed because `pendingassignpartitions` is updated in both `onpartitionleadershipchanges` and `onstoppartitions` methods which can happen concurrently as both of them take read lock.,0,0.9897101521492004
671367565,10579,satishd,2021-07-16T16:04:32Z,"no, it is not needed to be sent with any prefix(like common_client, producer or consumer) because ""bootstrap.servers"" property is sent for any registered rlmm plugin but not only limited to the default rlmm. i will update the kip with these details.",0,0.9882323145866394
671381765,10579,junrao,2021-07-16T16:27:07Z,"since producermanager is initialized asynchronously, how do we deal with the case when the producermanager is not ready when an event needs to be published?",0,0.9798546433448792
671383087,10579,junrao,2021-07-16T16:29:09Z,"hmm, ""bootstrap.servers"" makes sense for a topic based rlmm since it depends on kafka. why do we require ""bootstrap.servers"" in other rlmm implementations?",0,0.9741108417510986
671415369,10579,satishd,2021-07-16T17:25:57Z,"that is a good point. we plan to improve the semantics here. earlier, we plan to introduce retriableexception for rlmm and rsm so that callers can have an option to know whether they can retry or not. in the case of initialization is not yet complete, retriableexception can be thrown caller can retry based on backoff. rlmm can send non retriable exception if it is in closing state and there will not be any retries. another way to handle this is to take these events and store them in in-memory queue and return future. these futures will be considered successful if initialization is successful and the events are published to the topic. i plan to address these in a followup pr while these apis are integrated with rlm, filed [a link]",1,0.7013017535209656
671419080,10579,satishd,2021-07-16T17:32:24Z,i am not sure about usecases with other rlmm but it allows them to connect to the broker.,0,0.9561347365379333
671516460,10579,junrao,2021-07-16T20:46:16Z,"what about client security related properties? it's weird that we pick up ""bootstrap.servers"" from one prefix, but the corresponding security properties under a different prefix. if we do provide the security related properties in the same prefix, they seem to be duplicated from those under prefix remote_log_metadata_common_client_prefix, remote_log_metadata_common_client_prefix or remote_log_metadata_consumer_prefix.",-1,0.9777503609657288
125019733,3325,dguy,2017-06-30T11:38:49Z,this is unused,0,0.9750969409942627
125019734,3325,dguy,2017-06-30T11:38:50Z,this is unused too. we should have a test for this.,0,0.9649949073791504
125019810,3325,dguy,2017-06-30T11:39:29Z,this is in a public package so we should provide some javadoc,0,0.980410635471344
125020051,3325,dguy,2017-06-30T11:41:18Z,same as above - needs javadoc. i guess it is intended for users? we should at least have some tests that use it.,0,0.9841572642326355
125020092,3325,dguy,2017-06-30T11:41:40Z,nit: extra space between `abstract` and `class`,0,0.9871346354484558
125020150,3325,dguy,2017-06-30T11:42:07Z,javadoc,0,0.9841633439064026
125020184,3325,dguy,2017-06-30T11:42:20Z,javadoc,0,0.9841633439064026
125020664,3325,dguy,2017-06-30T11:45:39Z,this should probably default to `noopstaterestorelistener` otherwise i think it is going `nullpointerexception` if the user doesn't add a listener,0,0.983379065990448
125020841,3325,dguy,2017-06-30T11:46:45Z,i think we should probably do a null check here and throw. setting the listener to null doesn't seem valid to me,0,0.5350408554077148
125021380,3325,dguy,2017-06-30T11:49:56Z,rather than setting this to `null` if it isn't an instance of `batchingstaterestorecallback` perhaps you could set it to an instance of an internal class that implements `batchingstaterestorecallback`. the benefit being that the `null` check is then only done once here and not also in `restoreall`,0,0.9877724051475525
125021406,3325,dguy,2017-06-30T11:50:09Z,see comment above in ctor,0,0.9863633513450623
125021525,3325,dguy,2017-06-30T11:50:57Z,unit tests for this class?,0,0.9859781265258789
125022092,3325,dguy,2017-06-30T11:54:42Z,again i think we could use an internal implementation (probably the same one) for `batchingstaterestorecallback`. so here we always have a `batchingstaterestorecallback` and we can get rid of the `if(...){...}else{...}` and the extra `if(!restorerecords.isempty)` i think that would make the code easier to follow.,0,0.9785557985305786
125022610,3325,dguy,2017-06-30T11:58:16Z,pass this in as a ctor param rather than constructing it? the `staterestorecallback` is only used to create the `compositerestorelistener`,0,0.9889063835144043
125036770,3325,dguy,2017-06-30T13:20:23Z,do we need to synchronize access to `staterestorelistener`? it can be set by a user thread and used by the `streamthread`,0,0.9897763729095459
125037238,3325,dguy,2017-06-30T13:22:33Z,nit: `private`,0,0.9811372756958008
125037487,3325,dguy,2017-06-30T13:23:46Z,nit: keep fields with the same access level together,0,0.987829327583313
125040681,3325,dguy,2017-06-30T13:38:20Z,nit: `collections.singletonlist(...)` or `utils.mklist(..)`,0,0.98701012134552
128017007,3325,bbejeck,2017-07-18T15:51:41Z,"ack, removed not needed as it's passed through to `streamthread`",0,0.9875895380973816
128018122,3325,bbejeck,2017-07-18T15:55:41Z,"don't think so, the `staterestorelistener` set by user is passed through to the `streamthread`. javadoc in `staterestorelistener` states that it expects operations to be stateless.",0,0.9875774383544922
128018683,3325,bbejeck,2017-07-18T15:57:34Z,"ack, added integration test",0,0.9849607348442078
128018746,3325,bbejeck,2017-07-18T15:57:47Z,ack,0,0.9720376133918762
128018769,3325,bbejeck,2017-07-18T15:57:51Z,ack,0,0.9720376133918762
128236093,3325,dguy,2017-07-19T12:53:08Z,nit: my preference is to mark all method params as `final`,0,0.98440021276474
128250446,3325,dguy,2017-07-19T13:47:18Z,`final` and there is an extra space,0,0.9836951494216919
128251187,3325,dguy,2017-07-19T13:50:01Z,nit: extra line,0,0.970479428768158
128251819,3325,dguy,2017-07-19T13:52:27Z,i think we should probably add a unit test in `rocksdbstoretest` to prove that this works.,0,0.9858767986297607
128253384,3325,dguy,2017-07-19T13:58:04Z,"i'd prefer to see these broken down into multiple smaller tests, i.e, you are effectively testing 4 different methods in each test. ideally a unit test is only testing a single method.",0,0.971083402633667
128254391,3325,dguy,2017-07-19T14:01:35Z,nit: `final` + next line and might as well do the previous while you are at it ;-),1,0.7542263269424438
128256200,3325,dguy,2017-07-19T14:07:39Z,"could we extract these 3 lines into a method, say `verifycallbackstatescalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok",0,0.9256247878074646
128303773,3325,bbejeck,2017-07-19T16:51:49Z,ack - agreed,0,0.9827871322631836
128303812,3325,bbejeck,2017-07-19T16:51:55Z,ack,0,0.9720376133918762
128414835,3325,guozhangwang,2017-07-20T02:48:34Z,"the javadoc may read a bit hard for end users since 1) `internal threads assignment` is not known to them at all, 2) `conclusion of restoring a statestore` is also a mess up. from their pov (not familiar with concept of task, etc) we can just state that `... set the listener which is triggered whenever a state is being restored in order to resume processing..`.",-1,0.867384135723114
128415004,3325,guozhangwang,2017-07-20T02:50:14Z,"same as above, do not need to mention ""all internal threads"". just emphasize it is triggered whenever a state is being restored is fine.",0,0.9632569551467896
128415203,3325,guozhangwang,2017-07-20T02:52:04Z,"nit: `not supported, please use...`",0,0.672606885433197
128415747,3325,guozhangwang,2017-07-20T02:58:16Z,i think we can use the following as part of javadoc: [code block] as a reference see `kafkaproducer` and `producer` in clients.,0,0.9882766604423523
128415932,3325,guozhangwang,2017-07-20T03:00:12Z,i did not catch it in the kip wiki but.. the class names are a bit inconsistent here: [code block] better be either [code block] or [code block] wdyt?,0,0.7417663931846619
128415948,3325,guozhangwang,2017-07-20T03:00:30Z,"ditto as above, we can refer to the javadocs of the base interface here.",0,0.9883488416671753
128416068,3325,guozhangwang,2017-07-20T03:01:46Z,"seems in the library, if it is determined a `batchingstaterestorecallback` at runtime we then would never call the `restore` function ever. is this true and will be future forever? if yes we should state it in the java doc.",0,0.9852994680404663
128416128,3325,guozhangwang,2017-07-20T03:02:26Z,does this need to be in `o.a.k.streams.state` or this package? i'm just wondering..,0,0.9557511806488037
128416252,3325,guozhangwang,2017-07-20T03:03:55Z,"better state ""when calling `setstate...` in \ kafkastreams, the passed instance is expected to be stateless since.."" because not everyone understand what does ""... for reporting all state store recovery.."" means, stating from the api point of view would be easier to understand. ditto elsewhere.",0,0.8059943914413452
128416789,3325,guozhangwang,2017-07-20T03:10:02Z,`in this case the size of the batch is whatever the value of the max_poll_records is set to.` is this really the case?? it is an upper bound but not necessary the exact value right?,0,0.9833739995956421
128603596,3325,bbejeck,2017-07-20T19:00:07Z,ack,0,0.9720376133918762
128603630,3325,bbejeck,2017-07-20T19:00:15Z,ack,0,0.9720376133918762
128607545,3325,bbejeck,2017-07-20T19:18:41Z,"agreed, i think the second option is best.",0,0.9423355460166931
128607578,3325,bbejeck,2017-07-20T19:18:51Z,ack,0,0.9720376133918762
128607619,3325,bbejeck,2017-07-20T19:19:00Z,ack,0,0.9720376133918762
128607645,3325,bbejeck,2017-07-20T19:19:09Z,ack,0,0.9720376133918762
128607671,3325,bbejeck,2017-07-20T19:19:16Z,ack,0,0.9720376133918762
128607701,3325,bbejeck,2017-07-20T19:19:25Z,ack,0,0.9720376133918762
128607714,3325,bbejeck,2017-07-20T19:19:30Z,ack,0,0.9720376133918762
128611709,3325,bbejeck,2017-07-20T19:37:21Z,"maybe, we could also move `statestore`, `statestoresupplier`, `statestorecallback` as well. let's see what others think.",0,0.984681248664856
128612612,3325,bbejeck,2017-07-20T19:41:59Z,ack,0,0.9720376133918762
128614536,3325,bbejeck,2017-07-20T19:51:06Z,ack,0,0.9720376133918762
128642317,3325,guozhangwang,2017-07-20T22:05:53Z,"if we start from scratch then maybe these would be better be in `state`, but they have been added to `processor` and moving them would be incompatible changes. so i'm more concerning about the newly added classes.",0,0.976219892501831
128642627,3325,guozhangwang,2017-07-20T22:07:36Z,maybe the parameter descriptions are not needed as well? ditto elsewhere.,0,0.7150447964668274
128643629,3325,guozhangwang,2017-07-20T22:13:58Z,we can define two static variables of `noopstaterestorelistener` and `noopstaterestorecallback` instead of creating a new instance multiple times.,0,0.9881554841995239
128646844,3325,guozhangwang,2017-07-20T22:34:54Z,"for `reportingstorelistener`, better rename it to `globalstorelistener` as it is the instance-level listener, but it is not necessarily used for reporting only.",0,0.9880848526954651
128647685,3325,guozhangwang,2017-07-20T22:40:22Z,also code structure wise i'm wondering if it is easier to keep the per-store callback/listener and the global listener in two separate classes than keeping them in this `composite` class? then we can do: [code block] i feel this null-check would be more performant than the no-op function call?,0,0.9855518341064453
128648024,3325,guozhangwang,2017-07-20T22:42:40Z,"as mentioned above, i'm wondering if it is better to not use the `set` function of global listener in this composite class but keep it in a separate class? also since the global listener could be accessed by concurrent threads of the instance, does it need to be synchronized?",0,0.9821970462799072
128648103,3325,bbejeck,2017-07-20T22:43:09Z,ok fair enough i can move it over. my only concern is that it could be slightly confusing.,0,0.9059914350509644
128648481,3325,guozhangwang,2017-07-20T22:45:19Z,hmm... should we ever expect the passed in callback to ever be `null`? if it is really null then no data will ever be restored right?,0,0.8783405423164368
128649545,3325,guozhangwang,2017-07-20T22:52:52Z,"instead of using this separate class and do the `instanceof` check on each call (which maybe expensive), maybe we could just have a `wrappedbatchingstaterestorecallback` which only takes the non-batching `staterestorecallback` in constructor and then in `restoreall` always do the for-loop, and in places that we need it (seems we only have two callers) we can do sth. like [code block] just once.",0,0.9811353087425232
128651168,3325,guozhangwang,2017-07-20T23:04:14Z,"i'm thinking that we can simply this logic a bit: 1) in line 124 above, when `needsrestoring.put(topicpartition, restorer);` call `restorer.restorestarted`. 2) then we can remove the `restorestarted` boolean in `storerestorer` and also the line here.",0,0.9685069918632507
128652257,3325,guozhangwang,2017-07-20T23:12:47Z,"this logic seems a bit complex to me, and also if we return at line 229 `restorebatchcompleted` is not called as well. is this correct? how about: [code block]",0,0.7976970076560974
128652963,3325,guozhangwang,2017-07-20T23:17:34Z,"following my comments above, we can rename to `setglobalstaterestorelistener` to make it clear.",0,0.9868359565734863
128653176,3325,guozhangwang,2017-07-20T23:19:29Z,these two functions can be merged into one? [code block] see my other comments on the `storechangelogreader.java` class.,0,0.9880478382110596
128653276,3325,guozhangwang,2017-07-20T23:20:19Z,ditto above: `setglobalstaterestorelistener`,0,0.9806752800941467
128653708,3325,guozhangwang,2017-07-20T23:23:42Z,"one caveat of letting users to set it via code is that, we cannot forbid users to call this function after calling `streams.start()`, in which case the behavior would be bad. also people can set it multiple times which is also not suggested. i'm now thinking maybe we should enforce users to set this global listener via configs? cc wdyt.",0,0.9313764572143555
128654031,3325,guozhangwang,2017-07-20T23:26:02Z,"`prepareforbulkload` will always be true here, right?",0,0.988229513168335
128654227,3325,guozhangwang,2017-07-20T23:27:35Z,"i do not think we need this variable at all, since as mentioned above when initiating it will always be true, and that is the only place this variable is ever read.",0,0.972386360168457
128654443,3325,guozhangwang,2017-07-20T23:29:00Z,we do not need to set `open = true` here again.,0,0.9851085543632507
128655290,3325,guozhangwang,2017-07-20T23:36:26Z,"personally i'm not a big fan of this integration test, since i felt that the its coverage has already been subsumed by unit tests. we should only consider integration tests for some end-to-end behavior that involves multiple modules to interact with each other, otherwise unit tests should be used per-module.",-1,0.9243603348731995
128656227,3325,guozhangwang,2017-07-20T23:44:14Z,actually i was really just asking for people's opinions :) the cons are that these classes will be in different packages which may looks a bit weird.,1,0.9425726532936096
128700639,3325,dguy,2017-07-21T07:33:05Z,if we put it in config then they lose the ability to use capture any objects/state etc in their application. we could always only allow the listener to be set when kafkastreams is in the `created` state and throw an exception if it isn't.,0,0.9852758646011353
128779376,3325,bbejeck,2017-07-21T14:44:10Z,:thumbs_up:,0,0.8380307555198669
128800005,3325,bbejeck,2017-07-21T16:05:22Z,ack,0,0.9720376133918762
128800078,3325,mjsax,2017-07-21T16:05:43Z,"in javadoc this markup is not needed 1. between the text and the parameter list, it will insert some space automatically 2. ` ` is just use to start new paragraphs (but javadoc is not html, there is no closing ` `)",0,0.9866780042648315
128800519,3325,mjsax,2017-07-21T16:08:08Z,"we could do a small kip and move the classes (preserving the old ones as deprecated). overall, i don't have a strong opinion.",-1,0.9072171449661255
128800688,3325,mjsax,2017-07-21T16:09:03Z,nit: why `code` but not `link` ?,0,0.9853277802467346
128800950,3325,mjsax,2017-07-21T16:10:23Z,nit: `.` missing at end of sentence,0,0.9586949944496155
128800998,3325,mjsax,2017-07-21T16:10:41Z,nit: remove unnecessary blank.,0,0.9772768020629883
128802000,3325,bbejeck,2017-07-21T16:16:03Z,ack on the name. i think we should keep `composite` class as it keeps implementation details out of the `staterestorer` class which doesn't need to know the details of restoring notification. as for synchronizing we can do that from within the `composite` class as well. although we specify in the javadoc it's expected the `globbalstorelistener` is stateless and implementors will need to provide synchronization if needed. if you insist i can remove the composite class and/or synchronize the calls on the `globalstorelistener`,0,0.9724668264389038
128802185,3325,bbejeck,2017-07-21T16:17:00Z,ack,0,0.9720376133918762
128807922,3325,bbejeck,2017-07-21T16:46:35Z,"ack, but i thinking some more we should replace the default value with `objects.requirenonnull`",0,0.9699571132659912
128809089,3325,bbejeck,2017-07-21T16:52:30Z,updated the set method to reflect the new name. comments on the `composite` class and synchronization same as above.,0,0.9865310788154602
128815139,3325,bbejeck,2017-07-21T17:22:11Z,ack,0,0.9720376133918762
128829007,3325,guozhangwang,2017-07-21T18:22:36Z,"re synchronization: enforcing users to do sync themselves inside the function is fine, i did not see `implementors will need to provide synchronization if needed` so there may be a mis-understanding. could you make that statement more clear in javadocs? re separating classes: one motivation i had is that, currently we did one ""instanceof"" for each call, and if the global listener is not set we still call a `no-op` listener; this does not seem optimized for me. instead we can do a `null` check or even a boolean flag indicating if a global listener is ever set already. that would be more performant? if you can do that inside this composite class i think we could keep it centralized.",0,0.9104304909706116
128843230,3325,bbejeck,2017-07-21T19:27:35Z,"ack, good catch.",1,0.9815772175788879
128847495,3325,bbejeck,2017-07-21T19:49:37Z,ack,0,0.9720376133918762
128849307,3325,bbejeck,2017-07-21T19:59:39Z,ack,0,0.9720376133918762
129029991,3325,bbejeck,2017-07-24T13:10:02Z,leaving as is based on offline-conversation,0,0.9607647657394409
129030050,3325,bbejeck,2017-07-24T13:10:17Z,ditto from above,0,0.9211898446083069
129030086,3325,bbejeck,2017-07-24T13:10:26Z,ditto from above,0,0.9211898446083069
129030265,3325,bbejeck,2017-07-24T13:11:13Z,"ok, i'll take it out.",0,0.9815280437469482
129090134,3325,bbejeck,2017-07-24T16:45:27Z,ack,0,0.9720376133918762
129090501,3325,bbejeck,2017-07-24T16:46:54Z,"oversight on my part, changing.",0,0.8892527222633362
129091268,3325,bbejeck,2017-07-24T16:50:16Z,ack,0,0.9720376133918762
129606674,3325,mjsax,2017-07-26T15:27:05Z,nit `{ staterestorerlistener}`,0,0.9856428503990173
129608628,3325,mjsax,2017-07-26T15:33:46Z,can't this `extend abstractnotifyingrestorecallback` to save all the boiler plate from below?,0,0.9813857674598694
129617878,3325,mjsax,2017-07-26T16:05:20Z,"can we introduce a global ""one parameter per line"" code style? i think it would help to make diffs cleaner. we can do this incrementally. if yes, please do for all newly introduced code of this pr. also, should be add `final` all over the place?",0,0.9615111351013184
129618333,3325,mjsax,2017-07-26T16:07:06Z,"nit: parameter descriptions are no sentences, thus no `.` at the end (on many other places, too). if we say they are sentences, they it should start with upper case `[t]he topicpartition`",0,0.9859809875488281
129620426,3325,mjsax,2017-07-26T16:13:55Z,as above?,0,0.9795584082603455
129623215,3325,mjsax,2017-07-26T16:24:35Z,can you elaborate?,0,0.9856976270675659
129624489,3325,mjsax,2017-07-26T16:28:29Z,we should not `expect` here and use `fail` within try-catch,0,0.9632547497749329
129626342,3325,mjsax,2017-07-26T16:35:25Z,as above.,0,0.978552520275116
129629040,3325,bbejeck,2017-07-26T16:44:40Z,ack,0,0.9720376133918762
129664724,3325,bbejeck,2017-07-26T18:54:03Z,ack,0,0.9720376133918762
129667712,3325,bbejeck,2017-07-26T19:05:08Z,"actually this class won't be used anymore, so removed.",0,0.9799739122390747
129670240,3325,bbejeck,2017-07-26T19:15:34Z,"sure thing, can you add to the steams guidelines?",0,0.9834370613098145
129677466,3325,bbejeck,2017-07-26T19:46:19Z,"will still have one no-op method, but i guess it's worth it as it does reduce the boilerplate some.",0,0.886283814907074
129692869,3325,bbejeck,2017-07-26T20:52:12Z,"there was some confusion over the number of times we open and close the `rocksdbstatestore` for handling optimized bulk loads, once that was clarified the comments pertaining to setting `prepareforbulkload` and `open` didn't need to be addressed.",0,0.9806923270225525
129963670,3325,guozhangwang,2017-07-27T21:26:05Z,nit: rename this function to `restorestarted` to be consistent with other names. such will help other code readers to understand these functions are for the same code granularity and semantics.,0,0.9850839972496033
129964281,3325,guozhangwang,2017-07-27T21:28:46Z,is this comment missed somehow? i think line 42 above could be `storerestorelistener = no_op_state_restore_listener`.,0,0.9881221652030945
129964947,3325,guozhangwang,2017-07-27T21:32:21Z,nit: space after `//` and we do not need capitalize the in-function comments.,0,0.9880309700965881
129965165,3325,guozhangwang,2017-07-27T21:33:28Z,ditto for in-function and simple top function comments.,0,0.9755355715751648
129965459,3325,guozhangwang,2017-07-27T21:34:51Z,nit: new lines are generally not recommended to break object type declaration with object name. for this specific line i think we can still make them in one line.,0,0.9853430986404419
129965596,3325,guozhangwang,2017-07-27T21:35:38Z,ditto: newline after keywords are generally not recommended.,0,0.974977970123291
129965850,3325,guozhangwang,2017-07-27T21:37:04Z,ditto for new line rules. could you make a pass over all the newlines and see if they can be improved?,0,0.7748762965202332
129966240,3325,guozhangwang,2017-07-27T21:39:04Z,we can use the `wrappedbatchingstaterestorecallback` here?,0,0.9882070422172546
129966522,3325,guozhangwang,2017-07-27T21:40:35Z,`org.apache.kafka.streams.processor.internals.noopstaterestorelistener` can be used here?,0,0.9866517782211304
129970463,3325,bbejeck,2017-07-27T22:01:09Z,ack,0,0.9720376133918762
129970523,3325,bbejeck,2017-07-27T22:01:27Z,"ack, must have overlooked",0,0.9044368863105774
129970837,3325,bbejeck,2017-07-27T22:03:18Z,ack,0,0.9720376133918762
129970870,3325,bbejeck,2017-07-27T22:03:26Z,ack,0,0.9720376133918762
129970957,3325,bbejeck,2017-07-27T22:03:53Z,"ack, need to adjust intellij settings",0,0.9684700965881348
129971207,3325,bbejeck,2017-07-27T22:05:25Z,"ack, same as above",0,0.9843222498893738
129971290,3325,bbejeck,2017-07-27T22:05:57Z,ack,0,0.9720376133918762
129974506,3325,bbejeck,2017-07-27T22:26:26Z,ack,0,0.9720376133918762
129974595,3325,bbejeck,2017-07-27T22:26:54Z,ack,0,0.9720376133918762
589867244,10218,junrao,2021-03-09T01:16:23Z,"it's a bit weird to include this in the client module. since this is implemented in java, we could potentially create a new java module for it (like the raft module). this reduces the size of the client jar and also avoids the inter-dependencies between java and scala. also, is this for testing? if so, it needs to be in the test directory.",-1,0.9858267903327942
589867914,10218,junrao,2021-03-09T01:17:56Z,"is this for testing? if so, it needs to be in the test directory.",0,0.9883784651756287
590723978,10218,junrao,2021-03-09T21:14:18Z,typo imemory,0,0.9863858222961426
590739158,10218,junrao,2021-03-09T21:40:00Z,"hmm, it's possible for a segment to transition to delete_segment_started here. should those segments still be added?",0,0.9868265390396118
590740461,10218,junrao,2021-03-09T21:42:19Z,"once a segment is in delete_segment_started state, the corresponding segment could be gone any time after that. so, it seems that we should remove the segment from leaderepochtooffsettoid once it's in delete_segment_started?",0,0.9888293147087097
590742564,10218,junrao,2021-03-09T21:46:15Z,could we just get the segment list from `idtosegmentmetadata.values()`?,0,0.9893463253974915
590744034,10218,junrao,2021-03-09T21:48:28Z,highestlogoffset => highestsegmentstartoffset ?,0,0.9847628474235535
590745670,10218,junrao,2021-03-09T21:50:53Z,could we add a comment to this class?,0,0.9873136878013611
590748558,10218,junrao,2021-03-09T21:55:55Z,we are not returning null here.,0,0.8478468656539917
591585302,10218,satishd,2021-03-10T14:49:20Z,the plan was to use the related classes in the default rlmm implementation and move any class which is relevant only for tests to test dir later. i am +1 to have this as a separate module. i will update with those changes.,0,0.9686983227729797
591588474,10218,satishd,2021-03-10T14:52:49Z,"this behavior was kept to be the same as local log cleanup behavior, in which leader epoch is truncated only after local log is moved/deleted. ideally, it is good not to consider the segments available that are being deleted as you said.",0,0.9790209531784058
591595247,10218,satishd,2021-03-10T15:00:08Z,there may be few segments with state as `copy_segment_started` and they will be part of `remotelogsegmentidinprogress` only but not `idtosegmentmetadata`. that is why we need to add them to the list.,0,0.9889174699783325
591603442,10218,satishd,2021-03-10T15:09:34Z,"no, it is not highestsegmentstartoffset but it is the highest log offset for the given leader epoch. nice catch! we need to give the max endoffset of all the segments for the given leader epoch.",1,0.9828163981437683
591905906,10218,kowshik,2021-03-10T22:05:03Z,this c'tor can be removed in exchange for the default generated c'tor.,0,0.9886183738708496
591912017,10218,kowshik,2021-03-10T22:15:55Z,it seems like we allow for an entry already existing with the same id to be replaced with a different entry. would that happen in practice?,0,0.9832566380500793
591915104,10218,kowshik,2021-03-10T22:21:41Z,"can `offsettoid` be empty if it is not null? i understand it is right to check for emptiness here, but i was just curious to learn if it could happen in practice.",0,0.9129322171211243
591919624,10218,kowshik,2021-03-10T22:30:10Z,"looking at the implementation, it appears we maintain some rules on when a `remotelogsegmentid` exists in one of these data structures versus all of them. it would be useful to briefly document those rules, and mention invariants (if any). for example, when an upload is in progress it is not (yet) added to this map.",0,0.9875682592391968
591921511,10218,kowshik,2021-03-10T22:33:57Z,can `metadata` be a better variable name over `rlsm`?,0,0.9891592860221863
592012860,10218,kowshik,2021-03-11T02:02:41Z,should we move this log message before l51? so that the message conveying the intent is logged first before any possible errors.,0,0.9885051846504211
592015659,10218,kowshik,2021-03-11T02:11:02Z,hmm... it seems like the only allowed state in `rlsmupdate` is `copy_segment_finished`. should we validate for that instead?,0,0.9704567790031433
592016707,10218,kowshik,2021-03-11T02:13:35Z,s/resource/entry ?,0,0.9848647117614746
592022166,10218,kowshik,2021-03-11T02:28:08Z,"it seems like we want to add more protections here. 1. if `remotepartitiondeletemetadata.state()` is `delete_partition_finished`, then should there have been a prior entry with `delete_partition_started` or `delete_partition_marked`? 2. imagine there exists an entry in `partitiontoremotelogmetadatacache` while the partition is also being deleted. is that a valid state, or if not should we assert against it?",0,0.9859236478805542
592022431,10218,kowshik,2021-03-11T02:28:56Z,sorry i don't understand what does this comment refer to?,-1,0.9864053130149841
592024533,10218,kowshik,2021-03-11T02:35:18Z,"hmm, any reason to not implement these methods? is it that they don't serve any purpose in the in-memory implementation?",0,0.9425498843193054
592070871,10218,satishd,2021-03-11T05:10:50Z,this can happen in race condition when this method is queried while it was getting added in `addremotelogsegmentmetadata`. it may not happen in practice but it is good to have these checks.,0,0.8299025297164917
592071729,10218,satishd,2021-03-11T05:13:59Z,"right, it is not applicable for inmemory implementation.",0,0.9249091744422913
592074962,10218,satishd,2021-03-11T05:24:46Z,"""no resource metadata found for partition: ""?",0,0.9448058605194092
592075662,10218,satishd,2021-03-11T05:26:51Z,it may not occur in practice.,0,0.9432559609413147
592096637,10218,satishd,2021-03-11T06:28:40Z,"it allows any state other than `copy_segment_started`, that is why we are checking only for this state.",0,0.9889742136001587
592123658,10218,kowshik,2021-03-11T07:32:25Z,is it useful to add a check against it?,0,0.987686276435852
592124191,10218,kowshik,2021-03-11T07:33:38Z,sure,0,0.9371067881584167
592173915,10218,satishd,2021-03-11T08:56:03Z,"other states include `copy_segment_finished`, `delete_segment_started`, and `delete_segment_finished`.",0,0.9891728162765503
592248245,10218,satishd,2021-03-11T10:37:36Z,"i meant there will be an external trigger based on delete partition marker, that is responsible for deleting the segments in a partition and updating the metadata. i will remove it as it looks to create confusion.",0,0.9830414056777954
592437366,10218,satishd,2021-03-11T15:05:20Z,1 -> added more assertions. 2 -> is a valid case.,0,0.9862939119338989
592577341,10218,satishd,2021-03-11T17:55:01Z,"sure, will add comments.",0,0.9775452613830566
594509836,10218,junrao,2021-03-15T16:51:52Z,delete_partition_marked is not part of remotelogsegmentstate.,0,0.9801067113876343
594510134,10218,junrao,2021-03-15T16:52:11Z,this seems to be an internal implementation and is not part of the public api? ditto for the same method in remotepartitiondeletestate.,0,0.9719381928443909
594550095,10218,junrao,2021-03-15T17:41:48Z,"this method updates idtosegmentmetadata, which seems redundant since it's done in line 107 already.",0,0.9869709014892578
594554053,10218,junrao,2021-03-15T17:47:01Z,"it's possible that after this, there is no segment associated with a leader epoch. should we remove the entry with that leader epoch from leaderepochtooffsettoid?",0,0.9882718920707703
594560602,10218,junrao,2021-03-15T17:55:35Z,it's kind of inefficient to have to iterate through the whole segment list. could we make leaderepochtooffsettoid an ordered map and then do highentry on that?,0,0.6292999982833862
594562408,10218,junrao,2021-03-15T17:57:34Z,highestlogoffset => highestoffsetforepoch?,0,0.9843934178352356
594564204,10218,junrao,2021-03-15T17:59:44Z,"it seems that there is a semantic difference between this method and the next one. while this one exposes all segments (including in progress ones), the latter only exposes segments that are completed. it would be useful to document this clearly in the public api.",0,0.9845026135444641
594567815,10218,junrao,2021-03-15T18:04:22Z,"hmm, it seems that we add the in-progress segment to idtosegmentmetadata in addtoinprogress? it would be useful to add a comment for idtosegmentmetadata.",0,0.9858582615852356
594577274,10218,junrao,2021-03-15T18:17:25Z,"for the local log, we first schedule the segment for async deletion and then take it out of leaderepochcache. so, the equivalent of that for remote storage seems to require taking the segment out of leaderepochcache once the segment deletion is initiated.",0,0.9876685738563538
594578101,10218,junrao,2021-03-15T18:18:32Z,inmemory => in-memory,0,0.986120343208313
595492577,10218,kowshik,2021-03-16T19:49:18Z,"1. will it be useful to place the implementation of this validation in a separate module, so that it can be reused with `rlmmwithtopicstorage` in the future? 2. suggestion from the standpoint of code readability/efficiency: would it make sense to replace the `if-else` logic by looking up from a `map< remotelogsegmentstate, set< remotelogsegmentstate>>` where key is the source state and value is a set of allowed target states?",0,0.986365795135498
595493561,10218,kowshik,2021-03-16T19:50:55Z,i have the same suggestions from `remotelogsegmentstate` for this as well. please refer to this comment: [a link],0,0.9856614470481873
595500039,10218,kowshik,2021-03-16T20:00:45Z,really minor comment/discussion: any reason to call this prefixed with `add` as `addremotelogsegmentmetadata` vs calling the deletion one prefixed with `put` as `putremotepartitiondeletemetadata` i.e. instead can these 2 methods both start with the same prefix either `add` or `put`?,0,0.9567537307739258
595505146,10218,kowshik,2021-03-16T20:09:07Z,"we may want to think more about the locking semantics for this class and `remotelogmetadatacache`. are we sure there would _not_ be use cases where we need to serialize mutations across the individually thread-safe attributes? if the answer is no, then using a fine-grained `object` lock makes more sense because we can use it to guard critical sections. should we evaluate this upfront? cc",0,0.983507513999939
595506748,10218,kowshik,2021-03-16T20:11:49Z,in the comment: s/putremotelogsegmentmetadata/addremotelogsegmentmetadata,0,0.9866375923156738
595954157,10218,satishd,2021-03-17T12:05:42Z,this is not really an internal implementation but it validates the state transition and it is the same for any implementation.,0,0.9872937202453613
596032415,10218,satishd,2021-03-17T13:46:26Z,i will update the javadoc of the apis to make this clear.,0,0.9844584465026855
596055570,10218,satishd,2021-03-17T14:12:17Z,good point! it will clear the values which are empty maps.,1,0.9888890981674194
596203582,10218,satishd,2021-03-17T16:48:25Z,`add` -> adding a new entry. `put` -> add or update. `putremotepartitiondeletemetadata` is used for both add or update the `remotepartitiondeletemetadata`.,0,0.9886246919631958
596204864,10218,satishd,2021-03-17T16:49:52Z,it was deliberate not to add locking semantics for now. we will add them once we have the respective changes using these classes.,0,0.9852970242500305
596247752,10218,satishd,2021-03-17T17:41:19Z,"1 -> imho, this validation method should be part of the state enum and it can be used by any implementation including default rlmm. 2 -> i would have preferred the suggested approach if there are many complex transitions but the transitions here are few and simple.",0,0.9846615195274353
598964030,10218,kowshik,2021-03-22T18:13:16Z,you can drop `it` and start with `indicates the state...`.,0,0.9889910221099854
598971940,10218,kowshik,2021-03-22T18:24:49Z,"imho, we can simplify this to say: [code block]",0,0.9859076142311096
598974632,10218,kowshik,2021-03-22T18:28:26Z,could we call this `idtoremotelogmetadatacache` to align with the naming of the other attribute thats called `idtopartitiondeletemetadata` ?,0,0.9887351393699646
598981046,10218,kowshik,2021-03-22T18:37:34Z,can this be checked inside `remotelogmetadatacache.addtoinprogress()` instead of here?,0,0.9887479543685913
598982742,10218,kowshik,2021-03-22T18:40:00Z,it seems to me that `srcstate` is never null in practice. where does this check come into play in practice?,0,0.970796525478363
598984916,10218,kowshik,2021-03-22T18:43:16Z,this is defined to be not thread safe unlike the other maps. is there any reason?,0,0.935348629951477
598990605,10218,kowshik,2021-03-22T18:51:29Z,can we add a 1-line doc for this similar to other attributes below?,0,0.9894577264785767
599000060,10218,kowshik,2021-03-22T19:05:29Z,"before we insert into the map/set, we should check if the provided `remotelogsegmentmetadata.state()` is `copy_segment_started`.",0,0.989572286605835
599001851,10218,kowshik,2021-03-22T19:08:20Z,"in this method, we allow for existing entries in `idtosegmentmetadata` to be replaced, even if the state of the existing and new entries are the same. is that intentional?",0,0.981442391872406
599003846,10218,kowshik,2021-03-22T19:11:32Z,"hmm, the entry for `existingmetadata` gets overwritten in the call to `addremotelogsegmentmetadata` in l110. should we be accounting for the same here?",0,0.9873714447021484
599006691,10218,kowshik,2021-03-22T19:16:01Z,"similar to above comment, why not check this inside `remotelogmetadatacache.updateremotelogsegmentmetadata()`?",0,0.9877460598945618
599008337,10218,kowshik,2021-03-22T19:18:33Z,typos: 1. s/wwe/we 2. s/gettign/getting,0,0.9806540608406067
599009374,10218,kowshik,2021-03-22T19:20:12Z,"can we improve the local variable names? for example `segidfootp0s0e100`, `segmetfootp0s0e100` etc. is not easy to read. we can use simpler names.",0,0.9790522456169128
599013040,10218,kowshik,2021-03-22T19:26:18Z,"the implementation compromises on the ordering, since it converts the iterator to a set. is that intentional?",0,0.95707106590271
599014824,10218,kowshik,2021-03-22T19:29:04Z,"this particular test checks a number of things together in one test. instead, could sections (1) to (4) from below each be defined as a separate unit test? especially since each section seems to operate on a different segment, so it seems logically independent.",0,0.9788621664047241
599016901,10218,kowshik,2021-03-22T19:32:49Z,could we add test(s) for `highestlogoffset` api?,0,0.9890956282615662
599018475,10218,kowshik,2021-03-22T19:35:22Z,could we assert just before this line that `seg3s350` is not empty? this will simplify the `seg3s350.orelse(null)` argument to `seg3s350.get()`. (same comment applies for other places in this test),0,0.9887588024139404
599021005,10218,kowshik,2021-03-22T19:39:17Z,"should we alter the other arguments too, for example `broker_id` and `eventtimestamp`? it appears that we expect `remotelogmetadatacache` to [a link], and this may include the other fields as well.",0,0.9887033104896545
599021666,10218,kowshik,2021-03-22T19:40:23Z,can we remove this c'tor in exchange for the default generated c'tor?,0,0.987928569316864
599024909,10218,kowshik,2021-03-22T19:45:33Z,"as per the interface we [a link] the caller to ensure unique id, but is it useful to add a guard that disallows replacing existing values?)",0,0.9879968762397766
599026440,10218,kowshik,2021-03-22T19:47:57Z,"we could add a c'tor overload to [a link] that takes a `throwable` as argument, it would the need to pass 2 args here.",0,0.989336371421814
599027282,10218,kowshik,2021-03-22T19:49:15Z,probably better to say `...must be greater than or equal to...` ?,0,0.9516390562057495
599029284,10218,kowshik,2021-03-22T19:52:27Z,"hmm, do we need to explicitly check if `endposition` < `segment.length`?",0,0.9869041442871094
599029805,10218,kowshik,2021-03-22T19:53:16Z,is this intentionally left empty?,0,0.8968757390975952
606249948,10218,satishd,2021-04-02T13:59:30Z,"it takes `math.min(endposition, segment.length)`. so, no need to have that check.",0,0.9858720898628235
606249998,10218,satishd,2021-04-02T13:59:36Z,right.,0,0.9566289782524109
606250883,10218,satishd,2021-04-02T14:01:49Z,"yes, it can happen to generate an event with the same state incase of retries.",0,0.9858288764953613
606251255,10218,satishd,2021-04-02T14:02:48Z,good catch. this is addressed in the latest commit.,1,0.976601779460907
606253220,10218,satishd,2021-04-02T14:07:45Z,"i thought earlier about having different methods, but it checks `listallsegments/listsegment(leaderepoch)` apis that return earlier segments. but i will have a separate test for that and extract as suggested.",0,0.9878881573677063
606253804,10218,satishd,2021-04-02T14:09:07Z,we can add that.,0,0.9848741888999939
606257469,10218,satishd,2021-04-02T14:17:46Z,"sure, i will add that.",0,0.9600632190704346
606343187,10218,junrao,2021-04-02T17:40:10Z,indicate => indicates ditto in a few other places.,0,0.9708867073059082
606348092,10218,junrao,2021-04-02T17:52:27Z,"the following table is a bit hard to read for developers. since this is not meant for a public interface, could we make it more readable for developers?",-1,0.5495703816413879
606348477,10218,junrao,2021-04-02T17:53:24Z,i guess this is an internal class. will this be exposed in javadoc since currently it includes **/org/apache/kafka/server/log/remote/storage/* ?,0,0.988559901714325
607191843,10218,junrao,2021-04-05T16:41:07Z,could we include remotelogsegmentmetadata in the exception message?,0,0.9894250631332397
607196509,10218,junrao,2021-04-05T16:49:33Z,should we include metadataupdate in the message of the exception?,0,0.9882259964942932
607205642,10218,junrao,2021-04-05T17:05:49Z,this comment is confusing since there is no update here.,-1,0.9110236167907715
607211862,10218,junrao,2021-04-05T17:17:23Z,"hmm, during unclean leader election, some of the old segments may need to be added to unreferenced segment id list but may not have the exact offset of the new segment. how are those segments handled here?",0,0.9695121645927429
607225040,10218,junrao,2021-04-05T17:40:58Z,it's weird to reference offsettoid here since it's in a separate class.,-1,0.9828826785087585
607226551,10218,junrao,2021-04-05T17:43:59Z,is the test for remotelogsegmentstate.copy_segment_finished necessary since it seems that only segments with remotelogsegmentstate.copy_segment_finished exist in offsettoid.,0,0.9897356033325195
607241348,10218,junrao,2021-04-05T18:10:59Z,updatehighestlogoffset => maybeupdatehighestlogoffset ?,0,0.9852419495582581
607247458,10218,junrao,2021-04-05T18:22:28Z,when are entries in leaderepochentries removed?,0,0.9852810502052307
607249504,10218,junrao,2021-04-05T18:26:13Z,"since existingstate can be null, we want to handle it properly.",0,0.9866286516189575
607250466,10218,junrao,2021-04-05T18:27:51Z,should we requirenonnull for topicidpartition here too?,0,0.9888189435005188
607255605,10218,junrao,2021-04-05T18:37:31Z,this is an existing issue. but is `>` in line 37 expected?,0,0.9836471676826477
607256604,10218,junrao,2021-04-05T18:39:31Z,is this constructor needed?,0,0.987058699131012
607546803,10218,satishd,2021-04-06T06:19:42Z,no. javadoc is generated for clients module with the package `/org/apache/kafka/server/log/remote/storage/ `. but this class is in `remote-storage` module.,0,0.9891515970230103
607546852,10218,satishd,2021-04-06T06:19:45Z,"sure, i will make it as simple ascii text.",0,0.9735751748085022
607551710,10218,satishd,2021-04-06T06:27:06Z,it prints null. i may be missing something here. what needs to be handled here?,0,0.9290741086006165
607556778,10218,satishd,2021-04-06T06:33:21Z,looks like autoformatter changed it.,0,0.9850562214851379
607559905,10218,satishd,2021-04-06T06:38:20Z,"good point, this check is no more needed.",1,0.8457748293876648
607561788,10218,satishd,2021-04-06T06:40:35Z,not really needed for now.,0,0.7283292412757874
607562925,10218,satishd,2021-04-06T06:41:59Z,updated the comment.,0,0.9832668304443359
607580027,10218,satishd,2021-04-06T07:07:24Z,"yes, in the case of unclean leader election, the leader will remove the old segments for the respective leader epochs. the removal process involves removing the actual segment and updating the respective metadata of the segments.",0,0.9868812561035156
607597875,10218,satishd,2021-04-06T07:30:13Z,one way to do that is to clear the entry when the respective `remotelogleaderepochstate` is empty. that means all the segments reached `delete_segment_finished` state. this is not currently addressed. i plan to look into it when we integrate these apis with remotelogmanager by exploring other options too.,0,0.9858068227767944
607959239,10218,kowshik,2021-04-06T15:34:20Z,nit: remove empty ``,0,0.9838460683822632
607959314,10218,kowshik,2021-04-06T15:34:24Z,nit: remove empty ``,0,0.9838460683822632
607972558,10218,kowshik,2021-04-06T15:50:20Z,should we call this map as `idtoleaderepochstate` or `idtoepochstate` similar to the naming for the other map?,0,0.9883257150650024
608025473,10218,kowshik,2021-04-06T16:58:53Z,"same comment as before: [a link] can srcstate be null in practice? if not, this can be defined as an instance method.",0,0.9872846007347107
608820288,10218,satishd,2021-04-07T16:40:30Z,the key is not really `id` but `epoch num`. what about `remotelogleaderepochstateentries` or `leaderepochtostate` or any other better name?,0,0.9870629906654358
608822419,10218,satishd,2021-04-07T16:43:31Z,"yes, it can be null. it is called from [a link]",0,0.9882446527481079
609073411,10218,junrao,2021-04-07T21:13:57Z,it would be useful to add a comment on whether the methods in this class are thread-safe or not.,0,0.9872905611991882
609083684,10218,junrao,2021-04-07T21:32:55Z,it seems that it's inconsistent that we update highest log offset here but not in handlesegmentwithcopysegmentstartedstate(). could we comment on whether highestlogoffset reflects the segments that have reached copy_segment_finished or not?,0,0.957004964351654
609089991,10218,junrao,2021-04-07T21:45:33Z,it would be useful to document the meaning of the following table.,0,0.9844257831573486
609093303,10218,junrao,2021-04-07T21:52:28Z,could we make it clear this is for offset range?,0,0.9877562522888184
609095034,10218,junrao,2021-04-07T21:56:11Z,"at this point, rlmm hasn't cleared all its internal state yet.",0,0.9731236696243286
609097289,10218,junrao,2021-04-07T22:00:24Z,is this logging needed? does it need to be in info level?,0,0.9880954027175903
609100380,10218,junrao,2021-04-07T22:05:53Z,could we make it clear this is for offset range?,0,0.9877562522888184
609103486,10218,junrao,2021-04-07T22:11:25Z,is this logging needed? ditto below.,0,0.9796625971794128
609104878,10218,junrao,2021-04-07T22:14:31Z,it's kind of weird that the segment with epoch 0 is already deleted and yet we still expect the highest offset for epoch 0 to be returned.,-1,0.9849696159362793
609107657,10218,junrao,2021-04-07T22:21:00Z,listremotelogsegments(0) => listremotelogsegments(1),0,0.9864527583122253
609351020,10218,satishd,2021-04-08T06:32:43Z,we may have this as debug level by default. it will be helpful to see for which entry the test is failed.,0,0.9840483665466309
609352593,10218,satishd,2021-04-08T06:35:08Z,we may have this as debug level by default. it will be helpful to see for which `epochoffset` the test is failed.,0,0.9864555597305298
609369185,10218,satishd,2021-04-08T06:57:19Z,"sure, i will add the doc. they are currently not thread safe. but we want to address them when we integrate these apis.",0,0.9848970174789429
609369253,10218,satishd,2021-04-08T06:57:24Z,"after thinking through this more, we need to update this only when the segment reaches copy_segment_finished. this is effectively used to find out up to which offset the segments are already copied. i will remove the call here and keep the call only in handlesegmentwithcopysegmentfinishedstate. wdyt?",0,0.9879001379013062
609369434,10218,satishd,2021-04-08T06:57:37Z,added a note.,0,0.9841687083244324
609369536,10218,satishd,2021-04-08T06:57:42Z,done,0,0.9764507412910461
609369903,10218,satishd,2021-04-08T06:58:06Z,updated.,0,0.9759359955787659
609372137,10218,satishd,2021-04-08T07:01:06Z,`highestlogoffset` can contain the deleted segments. `highestlogoffset` means the highest offset up to which the segments have been copied. pl take a look at the [a link].,0,0.9883434176445007
609372257,10218,satishd,2021-04-08T07:01:14Z,done,0,0.9764507412910461
609387061,10218,satishd,2021-04-08T07:20:04Z,updated.,0,0.9759359955787659
609882620,10218,junrao,2021-04-08T16:29:27Z,this is redundant.,0,0.8111133575439453
609891200,10218,junrao,2021-04-08T16:38:55Z,could we move this to debug level then?,0,0.9877092838287354
609895193,10218,junrao,2021-04-08T16:44:18Z,could we add a todo comment here so that we don't forget about it?,0,0.985335111618042
609896011,10218,junrao,2021-04-08T16:45:25Z,sounds good. could you make the change in the pr?,1,0.9295649528503418
609998576,10218,kowshik,2021-04-08T18:45:30Z,`leaderepochtostate` sounds good.,1,0.7980126142501831
610286497,10218,kowshik,2021-04-09T02:14:20Z,here is a slightly simpler version: [code block],0,0.9842981100082397
610293058,10218,kowshik,2021-04-09T02:26:22Z,"hmm here we assume that `id` should be present in the provided `idtosegmentmetadata`. due to programming error, or other reasons, the caller may not be able to ensure this. would it be safer if we instead threw whenever `id` is absent in `idtosegmentmetadata` to catch that case?",0,0.9836073517799377
610298531,10218,kowshik,2021-04-09T02:37:36Z,"the add call won't replace an existing element with the same `remotelogsegmentid`. is that expected? for example, what happens if `addcopyinprogresssegment` is called twice but this line doesn't replace the existing entry?",0,0.987916111946106
610302012,10218,kowshik,2021-04-09T02:44:27Z,"nit: add one whitespace at the end after ""...state""",0,0.9855139255523682
610305248,10218,kowshik,2021-04-09T02:50:25Z,is this method expected to be idempotent? note: this comment is related to my other comment: [a link],0,0.9854571223258972
610454559,10218,satishd,2021-04-09T08:42:52Z,"imho, existing code looks easy to read/comprehend, and no multiple calls to hasnext(). how about the below code after removing inline variables in the existing code? [code block]",0,0.9630889892578125
610462859,10218,satishd,2021-04-09T08:55:44Z,it already replaces the existing entry [a link].,0,0.986611008644104
610464252,10218,satishd,2021-04-09T08:57:54Z,addressed in the above [a link].,0,0.9865338802337646
610491754,10218,kowshik,2021-04-09T09:40:59Z,sounds good,1,0.9535238742828369
610494457,10218,kowshik,2021-04-09T09:45:34Z,"ok, i think this is fine then.",0,0.951734721660614
610494694,10218,kowshik,2021-04-09T09:45:53Z,sounds good,1,0.9535238742828369
610517070,10218,satishd,2021-04-09T10:23:25Z,"good point, i will add a check for that.",1,0.8352528214454651
610809710,10218,junrao,2021-04-09T17:53:19Z,typo epty,0,0.9835634231567383
610940157,10218,satishd,2021-04-09T22:50:50Z,"yes, it is done.",0,0.977464497089386
610940434,10218,satishd,2021-04-09T22:51:56Z,"yes, i updated the pr.",0,0.9843499660491943
610944855,10218,satishd,2021-04-09T23:07:59Z,fixed.,0,0.9810503125190735
611267145,10218,kowshik,2021-04-12T00:13:25Z,typo: the title of the last column should be `delete_segment_finished`.,0,0.9872279167175293
611305646,10218,satishd,2021-04-12T03:25:13Z,"thanks, addressed it in the latest commit.",0,0.5676320195198059
1335136107,14432,vamossagar12,2023-09-24T07:16:06Z,i have taken the liberty and updated the log line to use an argument based loggers instead of the string concatenation based pattern that existed before.,0,0.9804450273513794
1338285360,14432,vamossagar12,2023-09-27T08:53:33Z,this is not necessarily needed but added to avoid situations when a non static member tries to send a member epoch -2.,0,0.9873067140579224
1338844884,14432,kirktrue,2023-09-27T16:04:11Z,"this is for the case where the static member is leaving temporarily, right? would it be possible to add more detail to these error messages to aid in troubleshooting/debugging on the client when this condition is hit?",0,0.9864119291305542
1338849515,14432,kirktrue,2023-09-27T16:07:34Z,nice! can we add the group id to the 'static member' log message?,1,0.9879592657089233
1338895795,14432,vamossagar12,2023-09-27T16:34:12Z,"yes, that's correct. i have added some debugging information (like groupid etc). let me know if that makes sense.",0,0.9842708706855774
1338895972,14432,vamossagar12,2023-09-27T16:34:19Z,done.,0,0.9759407639503479
1338900198,14432,vamossagar12,2023-09-27T16:37:16Z,"also, `memberid can't be empty.` string is used in other places as well (when member epoch is > 0 or equal to -1. should we look to change those as well?",0,0.9875438213348389
1344754813,14432,kirktrue,2023-10-03T21:19:41Z,"it's just my preference, so if there's precedent for how you have it, i wouldn't hold up this pr in an effort to change the other places. thanks!",1,0.9691753387451172
1345450086,14432,vamossagar12,2023-10-04T08:57:24Z,"makes sense. i think i updated that one comment. but yeah the rest of the loggers, i won't be touching them, as that would be noisy to review.",0,0.9583009481430054
1348694911,14432,dajac,2023-10-06T13:02:39Z,nit: indentation should be 4 spaces.,0,0.9849249720573425
1348699907,14432,dajac,2023-10-06T13:07:25Z,i suppose that this must be a `timelinehashmap`.,0,0.9846898317337036
1348700266,14432,dajac,2023-10-06T13:07:46Z,nit: indentation should be four spaces.,0,0.9847731590270996
1348701917,14432,dajac,2023-10-06T13:09:15Z,the state should not be updated like this. all the updates are handled in the `replay()` methods.,0,0.9690960645675659
1348845154,14432,dajac,2023-10-06T15:03:46Z,could we add custom message to all the exceptions raise in this method?,0,0.9889103174209595
1348855163,14432,dajac,2023-10-06T15:11:38Z,i wonder if we really need the second part of the condition here. what was your thinking about it?,0,0.8146529793739319
1348858332,14432,dajac,2023-10-06T15:14:12Z,this is a bit weird because you pass `existingmember` to the builder and then you still have to override other fields. would it be better to do `new consumergroupmember.builder(existingmember)` and then override the fields? i think that we only need to set the new member id. nit: the indentation should be four spaces.,-1,0.9625938534736633
1348858959,14432,dajac,2023-10-06T15:14:33Z,"as said previously, the state should not be updated here but in replay.",0,0.9658270478248596
1348859279,14432,dajac,2023-10-06T15:14:48Z,nit: indentation.,0,0.9866654276847839
1348861003,14432,dajac,2023-10-06T15:15:53Z,i wonder if we could log something here as well when a static member is replaced.,0,0.9065335988998413
1348864154,14432,dajac,2023-10-06T15:18:25Z,this does not seem correct because we will write a record whenever the member is not updated and we have an instance id. i think that it would be better to capture the fact that we have a new static member in the condition at l801.,0,0.975460946559906
1348866036,14432,dajac,2023-10-06T15:19:51Z,"i just thought about something else. when a static member is replaced, we need to write records to erase the state of the previous member.",0,0.9775605201721191
1348872341,14432,dajac,2023-10-06T15:24:47Z,i would rather prefer to have a separate method for the static leave group.,0,0.9490020871162415
1348872557,14432,dajac,2023-10-06T15:24:57Z,nit: indentation.,0,0.9866654276847839
1348873017,14432,dajac,2023-10-06T15:25:14Z,nit: should we introduce a constant for -2 as well?,0,0.9859172701835632
1348874306,14432,dajac,2023-10-06T15:26:16Z,we don't need to use getormaybecreatestaticmember here as we only want to look up the member by its id.,0,0.9852498173713684
1348875180,14432,dajac,2023-10-06T15:26:59Z,"in there, we need to update the static id mapping in updatemember and removemember, i think.",0,0.9893251657485962
1354486658,14432,vamossagar12,2023-10-11T09:00:09Z,done.,0,0.9759407639503479
1354487016,14432,vamossagar12,2023-10-11T09:00:16Z,done.,0,0.9759407639503479
1354488025,14432,vamossagar12,2023-10-11T09:00:44Z,"makes sense, i have removed this direct update of states and moved it to `replay()`",0,0.9864227175712585
1354491971,14432,vamossagar12,2023-10-11T09:02:44Z,actually this is no longer required. have removed it.,0,0.9777845144271851
1354492275,14432,vamossagar12,2023-10-11T09:02:53Z,ack.,0,0.7720441818237305
1354505609,14432,vamossagar12,2023-10-11T09:06:55Z,yes that was a miss. i have added relevant tombstone records for the replaced static member and also cancelled it's timers.,0,0.9689606428146362
1354506320,14432,vamossagar12,2023-10-11T09:07:07Z,added.,0,0.9763525128364563
1354506847,14432,vamossagar12,2023-10-11T09:07:17Z,done,0,0.9764507412910461
1354507878,14432,vamossagar12,2023-10-11T09:07:33Z,done,0,0.9764507412910461
1354516913,14432,vamossagar12,2023-10-11T09:10:20Z,this method is no longer being used. i added custom messages in the other method which is now being called.,0,0.9808855652809143
1354518973,14432,vamossagar12,2023-10-11T09:10:51Z,"yes, that didn't quite make sense. it's not needed anymore. fixed indent as well.",0,0.7718580961227417
1354520295,14432,vamossagar12,2023-10-11T09:11:12Z,this bit of code has changed now.,0,0.9659203886985779
1362101057,14432,dajac,2023-10-17T13:19:21Z,nit: we tend to use a single line for getters. eg. ` the member id corresponding to the given instance id or null if it does not exist`.,0,0.9876732230186462
1362102003,14432,dajac,2023-10-17T13:20:03Z,nit: we don't prefix getters with `get`. let's add javadoc as well.,0,0.9877743124961853
1362105275,14432,dajac,2023-10-17T13:22:21Z,nit: would it make sense to have a method like the others? i would also do this before calling `maybeupdategroupstate`.,0,0.987004816532135
1362105499,14432,dajac,2023-10-17T13:22:30Z,ditto.,0,0.859873354434967
1362106636,14432,dajac,2023-10-17T13:23:12Z,let's add unit tests for the new or changed methods to the corresponding file.,0,0.9877946376800537
1362197123,14432,dajac,2023-10-17T14:13:31Z,i think that the old member will be in `members` so the computed target assignment is incorrect. we need to remove it with `removemember` and we also need to set the target assignment of the new member from the old one.,0,0.9817203283309937
1362197956,14432,dajac,2023-10-17T14:14:04Z,we have similar code somewhere else. could we add a method for this and reuse it?,0,0.9881470799446106
1362198218,14432,dajac,2023-10-17T14:14:15Z,same for this one. it would be great to have a method.,1,0.9365077614784241
1362200665,14432,dajac,2023-10-17T14:15:44Z,"i am not sold on this. is it too difficult to reuse the main logic? there are a few issues with this approach. for instance, the member's assignment is not reconciled like we do in the main logic. another one is that the subscription metadata must be updated as well if the subscriptions have changed.",0,0.9359958171844482
1362215540,14432,dajac,2023-10-17T14:23:59Z,i don't fully get this one. could you please elaborate?,-1,0.6368765830993652
1363301832,14432,vamossagar12,2023-10-18T06:22:35Z,"the main reason for extracting this out was that while using the main logic, there always always a group epoch bump even when a new static member replaces an older one. when i debugged it further, it seems to be because of this logic [a link] . more specifically, the issue at hand is that `subscriptionmetadata` has partition racks info while the currently stored metadata doesn't have it. this is with regards to the test `teststaticmembergetsbackassignmentuponrejoin`. i wasn't totally sure if this is an issue with the test itself but since this led to a group epoch bump, i thought we shouldn't do it. actually when i think about it now, maybe it makes sense to have a group epoch bump in this case as well. while it might go against no rebalance during static member rejoin but the reason for rejoin is a change in subscription metadata and not a static member re-join. the latter seemed harder to replicate via tests though because it always bumped up the group epoch due to the above mentioned issue. please let me know your thoughts.",0,0.9539171457290649
1363322519,14432,vamossagar12,2023-10-18T06:35:12Z,"i missed the `removemembers` part. thanks for pointing it out. regarding i assumed, this [a link] should take care of it. was my assumption wrong?",-1,0.6301248073577881
1363327084,14432,vamossagar12,2023-10-18T06:38:42Z,"this is mainly needed for the static member rejoin case. let's say a static member with instance id `id` departed. when it departs, we would write a member epoch value of -2 against it. now, if a new static member joins with the same instance id `id` and a member epoch value of 0, then without this condition, the rejoin would always fail with `fencedmemberepochexception`. this condition was added to avoid the same.",0,0.9876545071601868
1363408245,14432,dajac,2023-10-18T07:51:33Z,"well, at the moment, a new target assignment will be computed for the new static member and that block of code will indeed create the record for it. what i meant is that the new static member should actually reuse the target assignment of the previous member (vs computing a new one). then we only need to recompute the assignment if there is a group epoch bump.",0,0.9839015603065491
1363414003,14432,dajac,2023-10-18T07:55:20Z,hum... i am not sure to fully follow. the subscription metadata should not be different if the subscriptions and the metadata image have not changed. does the new static member has the same subs as the previous one in your case?,-1,0.9779360294342041
1363419939,14432,dajac,2023-10-18T07:58:37Z,"i see. would it make sense to put this condition first in the method, before `if (receivedmemberepoch > member.memberepoch())`? i got confused by the fact that it is within the if branch.",0,0.9769226312637329
1370523697,14432,vamossagar12,2023-10-24T16:47:34Z,"yeah, that makes sense as well. i placed it inside the if condition because this condition at hand shows up only when received epoch > current member epoch. but it should be ok to have it outside as you said. i have made the change.",0,0.9755316972732544
1370523927,14432,vamossagar12,2023-10-24T16:47:47Z,done.,0,0.9759407639503479
1370524066,14432,vamossagar12,2023-10-24T16:47:54Z,done.,0,0.9759407639503479
1370531600,14432,vamossagar12,2023-10-24T16:52:34Z,"i got around the issue by explicitly setting the rack info in the subscription metadata like [a link]. i guess so far this wasn't apparent because all the tests expected a group epoch bump happening. in this case, we didn't want a group epoch bump and hence i could notice the discrepancy.",0,0.955642819404602
1370532536,14432,vamossagar12,2023-10-24T16:53:25Z,that makes sense and thanks for the explanation. i have now changed the code to remove the existing static member and add the new static member. rest of the state would remain as is.,1,0.9062538146972656
1370532706,14432,vamossagar12,2023-10-24T16:53:34Z,done.,0,0.9759407639503479
1370533114,14432,vamossagar12,2023-10-24T16:54:00Z,done.,0,0.9759407639503479
1370533226,14432,vamossagar12,2023-10-24T16:54:07Z,done.,0,0.9759407639503479
1370538866,14432,vamossagar12,2023-10-24T16:55:35Z,"also, regarding given that now we will have a group epoch bump whenever a static member re-joins with a different subscription, should this be mentioned in the kip? as we noticed, this is a deviation from how the static member rejoining with a different subscription case as of today. wdyt?",0,0.9875713586807251
1370539621,14432,vamossagar12,2023-10-24T16:55:51Z,done.,0,0.9759407639503479
1370539793,14432,vamossagar12,2023-10-24T16:55:59Z,done.,0,0.9759407639503479
1370542261,14432,vamossagar12,2023-10-24T16:58:01Z,", i realised that even in the static member re-joining case, while the group epoch doesn't bump, the partitions would be in pending assignment state. i believe, eventually the member would get it's assignments. in that case, this state seems correct to me. wdyt?",0,0.9605786204338074
1377556564,14432,dajac,2023-10-31T13:05:28Z,"i wonder if we could simplify it even more. for instance, would it be possible to have something like the following: [code block]",0,0.8242678642272949
1377557816,14432,dajac,2023-10-31T13:06:15Z,if we rely on `member` and `updatedmember` then we don't need this because `!updatedmember.equals(member)` will catch the new member.,0,0.9820668697357178
1377567890,14432,dajac,2023-10-31T13:14:15Z,i don't fully understand how this would work because the members and the target assignment are not set.,0,0.6594647765159607
1377571172,14432,dajac,2023-10-31T13:16:47Z,"when the `targetassignmentbuilder` builds the spec for the assignor, it must use the target assignment of the previous static member for the new static member. how do we ensure this? we may have to update the `targetassignmentbuilder` to understand that a static member is replaced.",0,0.9867329001426697
1377572235,14432,dajac,2023-10-31T13:17:39Z,"don't we need to also force the step 3.? if we don't do it, we don't write the current assignment record for the new member and we don't reconcile him.",0,0.9257586002349854
1377575023,14432,dajac,2023-10-31T13:19:44Z,nit: removememberandcanceltimers? the logic is not tight to static members. i would also directly pass the groupid and the memberid as this is all it needs.,0,0.9852950572967529
1377614473,14432,dajac,2023-10-31T13:46:48Z,"this is actually executed twice. once here and once in `consumergroupstaticmembergroupleave`. i also wonder if we need to full validation here. i suppose that ensuring that the member id is correct would be enough, no?",0,0.9534565806388855
1377615301,14432,dajac,2023-10-31T13:47:21Z,nit: we check this twice. once here and once earlier to lookup the member. could we combine them?,0,0.9818978905677795
1377616732,14432,dajac,2023-10-31T13:48:07Z,"nit: `""[groupid {}] static member {} with member id {} left the consumer group.""`? i would also use a similar logging structure for the other log messages.",0,0.9882607460021973
1377617256,14432,dajac,2023-10-31T13:48:25Z,nit: let's align the description of the params.,0,0.9856774806976318
1377617520,14432,dajac,2023-10-31T13:48:35Z,nit: `member`?,0,0.9832280874252319
1377619412,14432,dajac,2023-10-31T13:49:40Z,nit: the `addall` does not seem necessary here. could we avoid it?,0,0.9825106263160706
1377621712,14432,dajac,2023-10-31T13:50:48Z,nit: we can reduce the space between the name and the desc.,0,0.9871499538421631
1377623260,14432,dajac,2023-10-31T13:51:46Z,"nit: let's use `""memberid can't be empty.""` to be consistent with the previous errors.",0,0.9869866967201233
1377624326,14432,dajac,2023-10-31T13:52:27Z,i think that the instance id cannot be null and cannot be empty as well. then let's use `instanceid can't be null or empty.`,0,0.9876875281333923
1377625954,14432,dajac,2023-10-31T13:53:36Z,could we add something to the exception?,0,0.9860631823539734
1383610866,14432,vamossagar12,2023-11-06T16:27:59Z,i have updated the logic in line with your suggestion.,0,0.9830302596092224
1383611138,14432,vamossagar12,2023-11-06T16:28:11Z,"yes, that makes sense.",0,0.9645439386367798
1383612141,14432,vamossagar12,2023-11-06T16:28:57Z,i have added members and target assignment.,0,0.98637855052948
1383612935,14432,vamossagar12,2023-11-06T16:29:33Z,i think i got it now. i added some state tracking to the `targetassignmentbuilder` so that it doesn't compute assignments for a replacing static member.,0,0.9836269617080688
1383615616,14432,vamossagar12,2023-11-06T16:30:58Z,"yes, i am now building the replacing static member with the same set of assignments (target/pending). this forces it directly to have the current assignment record for the new member.",0,0.9860286116600037
1383616531,14432,vamossagar12,2023-11-06T16:31:09Z,done.,0,0.9759407639503479
1383617107,14432,vamossagar12,2023-11-06T16:31:17Z,removed.,0,0.9311882257461548
1383617522,14432,vamossagar12,2023-11-06T16:31:25Z,done.,0,0.9759407639503479
1383617966,14432,vamossagar12,2023-11-06T16:31:31Z,done.,0,0.9759407639503479
1383618637,14432,vamossagar12,2023-11-06T16:31:41Z,done.,0,0.9759407639503479
1383620879,14432,vamossagar12,2023-11-06T16:32:19Z,added.,0,0.9763525128364563
1397018204,14432,dajac,2023-11-17T10:00:25Z,i would just use `instanceid can't be null.` here. i think that we should also verify that the instance id is not empty.,0,0.9865508079528809
1397269098,14432,dajac,2023-11-17T13:01:00Z,nit: it seems that we could declare this one only when we use it at l948.,0,0.9877068400382996
1397287511,14432,dajac,2023-11-17T13:14:27Z,i still find this logic quite complex to follow. i wonder if we could be a little more explicit. i think that the complexity comes from `throwifstaticmembervalidationfails` which hide quite a lot of the logic. i wonder if something as follow would be better. i am not sure... what do you think? [code block] note that i just wrote this without testing it so the code is likely not 100% correct :).,-1,0.6700607538223267
1397290332,14432,dajac,2023-11-17T13:16:47Z,i would say `[groupid {}] static member {} with instance id {} joins the consumer group.`,0,0.9888144135475159
1397291443,14432,dajac,2023-11-17T13:17:55Z,"i was thinking about this a little more and i actually wonder if we need this after all. if we don't see it, i think that the reconciliation will kick in and compute the current assignment. what do you think?",0,0.6924260258674622
1397321543,14432,dajac,2023-11-17T13:35:23Z,is the condition really correct? it seems to me that we must remove the previous member whenever staticmemberreplaced is true. how about the following? [code block],0,0.9873523712158203
1397322222,14432,dajac,2023-11-17T13:35:48Z,nit: let's keep this log message where it was.,0,0.9851027727127075
1397350631,14432,dajac,2023-11-17T13:54:43Z,how about the following? [code block],0,0.9880566596984863
1397353174,14432,dajac,2023-11-17T13:56:52Z,"instead of doing this, could we just pass the mapping from the consumergroup?",0,0.9865779876708984
1397356292,14432,dajac,2023-11-17T13:59:21Z,"it is a tad annoying that we have to build this mapping here because we usually only need it for one member. instead of doing this, i wonder if we could lookup the member id from the instance id mapping and then get the target assignment of the member id. the mapping will contain the previous member or nothing.",-1,0.9778608679771423
1397360473,14432,dajac,2023-11-17T14:02:39Z,should we remove this as the member is not there anymore?,0,0.971883237361908
1397363828,14432,dajac,2023-11-17T14:05:27Z,nit: let's put this comment before `consumergroupmember member2updatedepoch = ...`.,0,0.982501208782196
1397366414,14432,dajac,2023-11-17T14:06:46Z,"if i recall correctly, we automatically do this in `consumergroupheartbeat()`.",0,0.9863085150718689
1397366873,14432,dajac,2023-11-17T14:06:58Z,nit: `member...`.,0,0.9743186831474304
1397367189,14432,dajac,2023-11-17T14:07:11Z,nit: `member...` and `.` at the end.,0,0.985438346862793
1397368692,14432,dajac,2023-11-17T14:08:31Z,i suppose that this is not required as it don't be called.,0,0.9772595167160034
1397369747,14432,dajac,2023-11-17T14:09:29Z,nit: let's remove this empty line.,0,0.9799637198448181
1397373074,14432,dajac,2023-11-17T14:11:28Z,nit: we can remove this empty line.,0,0.9862961769104004
1397376607,14432,dajac,2023-11-17T14:14:25Z,should we also verify that the timers are cancelled correctly?,0,0.9855055212974548
1397378393,14432,dajac,2023-11-17T14:15:52Z,"do we test all possible error cases? thinking of fenced instance id, unknown member id, fenced member epoch, etc.",0,0.9877294898033142
1397379496,14432,dajac,2023-11-17T14:16:50Z,"this is true if the member leaves with -2. if it leaves with -1, it should be removed immediately. should we test this as well?",0,0.9877703189849854
1397382111,14432,dajac,2023-11-17T14:18:37Z,i wonder if we could add a few more tests. thinking about the following ones: * the leaving static member should disappear if the new one does not rejoin with the session timeout. * the new data structures should be updated correctly on replay.,0,0.9508622884750366
1397383047,14432,dajac,2023-11-17T14:19:27Z,"should we simplify a bit this test? we only need on member in the group to verify what we want here. we could also use one topic only, etc.",0,0.984437882900238
1397383490,14432,dajac,2023-11-17T14:19:50Z,we could also simplify this one.,0,0.9833040237426758
1397383760,14432,dajac,2023-11-17T14:20:04Z,this one as well.,0,0.9802976846694946
1399522392,14432,vamossagar12,2023-11-20T17:22:47Z,sure. `instance id should not be empty` check is already happening [a link],0,0.9842643141746521
1402215662,14432,vamossagar12,2023-11-22T15:12:10Z,"actually, `groupepoch == targetassignmentepoch` is not needed. i was just trying to ensure that the group epoch and target member epoch are the same which is what will happen when static member is replaced. so, in a way it's redundant. i will remove it.",0,0.9774134755134583
1402217667,14432,vamossagar12,2023-11-22T15:13:39Z,"if i don't set `setassignedpartitions`, then the replacing static member doesn't get it's assignments back. the pending assignments bit, i added just to ensure all assignments from previous member are assigned to the new member. the reason that happens is that it lands up [a link] and if there are no partitions assigned, it gets back empty assignments.",0,0.9818878769874573
1404037483,14432,dajac,2023-11-24T07:50:21Z,i would rather use `instanceid can't be null.` here in order to be consistent with the other error messages.,0,0.9834744334220886
1404037631,14432,dajac,2023-11-24T07:50:33Z,i suppose that we could remove this one now. could we?,0,0.9849812984466553
1404037934,14432,dajac,2023-11-24T07:50:54Z,is it still necessary with the last implementation?,0,0.9831758737564087
1404038516,14432,dajac,2023-11-24T07:51:40Z,nit: `leave` -> `leave`.,0,0.9563992023468018
1404039007,14432,dajac,2023-11-24T07:52:16Z,should we also log something in this case?,0,0.986497700214386
1404039730,14432,dajac,2023-11-24T07:53:14Z,nit: i would put `member` as the first argument to be consistent with the other helpers.,0,0.9881845712661743
1404042879,14432,dajac,2023-11-24T07:57:03Z,"* could we move those helpers next to `throwifmemberepochisinvalid`? could we also add some javadoc to each of them? * i wonder if we could also find better names for the params because it is not clear whether `memberid` and `instanceid` are the ones of the existing member or the ones received in the request. we could perhaps use `receivedmemberid`, etc. what do you think? this also applies to the other helpers.",0,0.9767727255821228
1404047713,14432,dajac,2023-11-24T08:02:56Z,i wonder if we could follow the structure of the other log messages here: `[groupid {}] static member {} with instance id {}....`.,0,0.9026682376861572
1404047826,14432,dajac,2023-11-24T08:03:06Z,should we also log something here?,0,0.9864739179611206
1404050011,14432,dajac,2023-11-24T08:05:46Z,nit: `.` at the end.,0,0.9830498099327087
1404050141,14432,dajac,2023-11-24T08:05:56Z,nit: `.` at the end.,0,0.9830498099327087
1404051525,14432,dajac,2023-11-24T08:07:38Z,"nit: could we also use `records = ` here? with this, we could remove `new arraylist<>()` when `records` is declared, i think.",0,0.988375186920166
1404058043,14432,dajac,2023-11-24T08:15:26Z,nit: let's revert this change as it is not necessary.,0,0.9520771503448486
1404062478,14432,dajac,2023-11-24T08:20:30Z,"i am not sure to follow this one. my understanding is that we populate `staticmembers` only when `addorupdatemember` is called. in the main flow, we basically call this only once with the new or updated member. let's imagine that a new static member joins. we will add its static id with its member id to `staticmembers`. therefore here, we basically get back its member id and end up with no assignment. did i get this right? i think that this could work but we would need to pass the `staticmembers` mapping from the `consumergroup` to the builder, like we pass the members. if we have this, we could use it here to find the previous member with the static id if the member is new and has a static id.",0,0.903634786605835
1404070683,14432,dajac,2023-11-24T08:29:42Z,nit: `instance id {} is unknown.`?,0,0.9861694574356079
1404071502,14432,dajac,2023-11-24T08:30:30Z,nit: `static member {} with instance id {} cannot join the group because the instance id is owned by member {}.`?,0,0.9848190546035767
1404072143,14432,dajac,2023-11-24T08:31:17Z,nit: `static member {} with instance id {} was fenced by member {}.`?,0,0.9870060682296753
1404124114,14432,dajac,2023-11-24T09:22:48Z,"to close on this one, it is indeed correct to set the assigned partitions here. without it, the reconciler checks if the partitions in the target assignment are still owned and they are effectively still owned until the previous member is removed. this only happens when the records are processed.",0,0.987310528755188
1404125908,14432,dajac,2023-11-24T09:24:32Z,i think that we could also `setpartitionspendingrevocation` to empty because we know that the member has revoked all its partitions when it leaves.,0,0.9881166219711304
1404157968,14432,dajac,2023-11-24T09:52:34Z,"this should not be here. i think that you mix in two different things. `addgroupmember` is basically what is used to build what will be passed to `withmembers` and `withtargetassignment` whereas `updatemembersubscription` is for `addorupdatemember`. therefore, the test does not reproduce how we use it.",0,0.977994978427887
1404158564,14432,dajac,2023-11-24T09:53:07Z,this one is incorrect as well because the newly added member is not added via `withmembers`.,0,0.9319729208946228
1404163349,14432,dajac,2023-11-24T09:57:41Z,nit: indentation seems off here. i think that it should be 4 spaces earlier.,0,0.9840729832649231
1404164525,14432,dajac,2023-11-24T09:58:45Z,nit: indentation is incorrect.,0,0.7883909940719604
1404165368,14432,dajac,2023-11-24T09:59:30Z,nit: indentation.,0,0.9866654276847839
1404167570,14432,dajac,2023-11-24T10:01:35Z,let's replace `-2` with the relevant constant. there are other cases in this file.,0,0.9882373213768005
1404168570,14432,dajac,2023-11-24T10:02:31Z,nit: temporarily leave?,0,0.8153434991836548
1404172073,14432,dajac,2023-11-24T10:05:48Z,we already have `testconsumerheartbeatrequestvalidation` so i wonder if we could just add the new case there. what do you think?,0,0.9746787548065186
1404172650,14432,dajac,2023-11-24T10:06:25Z,nit: indentation.,0,0.9866654276847839
1405732004,14432,vamossagar12,2023-11-27T07:18:31Z,no it is not. removed it.,0,0.9444813132286072
1405732141,14432,vamossagar12,2023-11-27T07:18:43Z,added a log line,0,0.9872604608535767
1405732647,14432,vamossagar12,2023-11-27T07:19:24Z,"done, moved the methods next to `throwifmemberepochisinvalid`, added javadocs and updated the argument names.",0,0.9889533519744873
1405733434,14432,vamossagar12,2023-11-27T07:20:28Z,done.,0,0.9759407639503479
1405737202,14432,vamossagar12,2023-11-27T07:25:42Z,"yes, your understanding is correct. i see what you are saying about how this won't work when a new static member joins. i have updated the group to expose the current set of static members in the group.",0,0.9787400960922241
1405737404,14432,vamossagar12,2023-11-27T07:26:02Z,thank you for the confirmation.,1,0.5763148069381714
1405738152,14432,vamossagar12,2023-11-27T07:27:02Z,"i see. thanks for the explanation, i hadn't understood the usage of these methods correctly. i have removed these unwanted calls to `updatemembersubscription`",1,0.9716842174530029
1405739030,14432,vamossagar12,2023-11-27T07:28:09Z,ok.. i am slightly confused by this comment. the new member is being added using `addgroupmember` which internally invokes `withmembers`. i had an unwanted call to `updatemembersubscription` which i have removed. probably i am missing something here.,-1,0.8430531620979309
1405785516,14432,dajac,2023-11-27T08:13:45Z,i think that we should call `updatemembersubscription` instead of calling `addgroupmember` here because `updatemembersubscription` is what is used to eventually call `addorupdatemember`.,0,0.9889683127403259
1331125886,14408,dajac,2023-09-20T07:24:58Z,nit: you could use `foreach` which is a bit more concise.,0,0.9857473969459534
1331127964,14408,dajac,2023-09-20T07:26:29Z,"nit: let's put `delete-group` on a new line as well. could you also ensure that the format conforms to the existing code? e.g. where the closing parenthesis is, the indentation (4 spaces), etc.",0,0.9882354736328125
1331129777,14408,dajac,2023-09-20T07:27:57Z,it may be better to use `join` instead of `get`. i think that you would be able to remove the try..catch if you use `join`.,0,0.9854893088340759
1331132885,14408,dajac,2023-09-20T07:30:11Z,"let's assume that one of the write operation fails with `coordinator_load_in_progress`, this would result in failing `allfutures` even though some write operations may have been successful. it seems to me that we should handle exceptions for each write operation future before we combine them, no?",0,0.9678210020065308
1331133058,14408,dajac,2023-09-20T07:30:21Z,nit: indentation.,0,0.9866654276847839
1331134867,14408,dajac,2023-09-20T07:31:13Z,nit: indentation. there are other cases in this pr. i won't mention them all.,0,0.9839410185813904
1331141079,14408,dajac,2023-09-20T07:36:09Z,"i have a few comments regarding this piece of code: 1. i think that we should write the tombstones for the offsets before the ones for the group. 2. it is a bit strange to return a coordinatorresult from `deletealloffsets` and to ignore it. it would be better to pass the list of records to the method and to let the method populate it if the deletion is accepted. i would also remove the response as we don't need it. 3. the `validgroupids` is a bit weird. how about iterating over the group ids here? then, you can call the various methods from the manages to validate, delete offsets and finally delete the group. if there is an error, you can directly populate the response with it.",-1,0.9248325824737549
1331143758,14408,dajac,2023-09-20T07:37:23Z,"`newgroupmetadatatombstonerecord` only works for generic groups. for consumer groups, we need to write other tombstones.",0,0.9864429235458374
1331145296,14408,dajac,2023-09-20T07:38:32Z,we should not write the record if subscribedtotopic is true because it will effectively delete the offset.,0,0.9769942164421082
1331146404,14408,dajac,2023-09-20T07:39:23Z,"as i said earlier, i think that returning coordinatorresult is not appropriate here because we don't need a response in this case. we basically build for the response to ignore it right after.",0,0.9420826435089111
1331958841,14408,dongnuo123,2023-09-20T17:19:03Z,"yeah, it makes sense. i'm not sure what to return if there's an exception in the write operation, since we can't set an error code for a `deletablegroupresultcollection`.",0,0.950737714767456
1331960774,14408,dongnuo123,2023-09-20T17:20:56Z,done,0,0.9764507412910461
1331961151,14408,dongnuo123,2023-09-20T17:21:20Z,done,0,0.9764507412910461
1331961609,14408,dongnuo123,2023-09-20T17:21:49Z,done,0,0.9764507412910461
1331969154,14408,dongnuo123,2023-09-20T17:29:14Z,"i rearranged this part. now we loop over the group ids and process them one by one -- validate, populate record list with offset tombstones, add group tombstone, and add response.",0,0.988063633441925
1331969312,14408,dongnuo123,2023-09-20T17:29:25Z,done,0,0.9764507412910461
1332009903,14408,dongnuo123,2023-09-20T18:08:40Z,fixed.,0,0.9810503125190735
1332010169,14408,dongnuo123,2023-09-20T18:08:59Z,fixed,0,0.975196123123169
1332010328,14408,dongnuo123,2023-09-20T18:09:11Z,fixed,0,0.975196123123169
1332057781,14408,dajac,2023-09-20T18:59:25Z,`deletablegroupresultcollection` contains `deletablegroupresult` which has an error code. therefore i think that we should create a `deletablegroupresult` per group id in the `grouplist` when there is an exception.,0,0.9873313307762146
1332069169,14408,dajac,2023-09-20T19:11:34Z,i think that we need to generate the above records here. * newtargetassignmentepochtombstonerecord * newgroupsubscriptionmetadatatombstonerecord * newgroupepochtombstonerecord,0,0.9795119762420654
1332072625,14408,dajac,2023-09-20T19:15:21Z,do we need this coordinatorresult?,0,0.988654613494873
1332073736,14408,dajac,2023-09-20T19:16:28Z,"this is the same as newgroupepochtombstonerecord, no?",0,0.9875613451004028
1332632377,14408,dajac,2023-09-21T07:53:22Z,"nit: i wonder if we should use `topicpartitionfor` here. with this, we could directly have the topicpartition as the key in the map and we would not need to create `new topicpartition(topic.group_metadata_topic_name, partition)` later on. what do you think?",0,0.9469959735870361
1332633082,14408,dajac,2023-09-21T07:53:58Z,nit: we could specify the size of the array when we allocate it.,0,0.9881029725074768
1332637192,14408,dajac,2023-09-21T07:56:43Z,nit: you could do the following to avoid having to put the list again into the map. [code block],0,0.9868029952049255
1332637739,14408,dajac,2023-09-21T07:57:13Z,nit: `res.addall(future.join())` to reduce the code?,0,0.9886735081672668
1332656181,14408,dajac,2023-09-21T08:12:15Z,"it is interesting to point out that, in the current implementation, all these errors are swallowed. this is definitely not ideal because it tells to the user that the deletion is successful even if was not. should we apply the same error handling to the deletegroups?",0,0.9229519963264465
1332661430,14408,dajac,2023-09-21T08:16:25Z,nit: we can remove this empty line.,0,0.9862961769104004
1332661944,14408,dajac,2023-09-21T08:16:51Z,"nit: `deletealloffsets`? i also wonder if the context is required. if not, we could remove it.",0,0.9337930083274841
1332664716,14408,dajac,2023-09-21T08:18:59Z,the coordinatorresult is a bit annoying here. how about passing `records` to the method as well? then we could construct the response here. we could also remove the context if it is not needed. how about naming it `deletegroup` to be consistent with `deleteoffsets`?,-1,0.9736931324005127
1332665059,14408,dajac,2023-09-21T08:19:14Z,nit: we could remove this empty line?,0,0.984818696975708
1332667219,14408,dajac,2023-09-21T08:20:58Z,"i have a question regarding the error handling. could `groupdelete` thrown an exception? if it can, we would need to handle records a bit differently because we don't want to delete the offsets if the group cannot be delete. the operation should be atomic.",0,0.982921838760376
1332667737,14408,dajac,2023-09-21T08:21:23Z,nit: the indentation is incorrect.,0,0.8303346633911133
1332670356,14408,dajac,2023-09-21T08:22:52Z,nit: let's remove this empty line and add javadoc to the method.,0,0.9876708984375
1332672724,14408,dajac,2023-09-21T08:23:41Z,nit: indentation is incorrect.,0,0.7883909940719604
1332679503,14408,dajac,2023-09-21T08:28:21Z,"let's do the validation before allocating response, records, etc. we don't have to allocate them if the request is invalid. `group` could also be `final`.",0,0.9882730841636658
1332679648,14408,dajac,2023-09-21T08:28:28Z,nit: final?,0,0.9591788649559021
1332680359,14408,dajac,2023-09-21T08:29:01Z,"i think that the try..catch is not needed here because we handle the exceptions in the group coordinator service, no?",0,0.9780450463294983
1332682319,14408,dajac,2023-09-21T08:30:30Z,nit: `response = ` is not needed here as `settopics` mutates the response directly.,0,0.9847384691238403
1332689518,14408,dajac,2023-09-21T08:35:32Z,i wonder if we need to verify if there is actually an offset for the topic/partition. we don't need to write a tombstone if there is not. what do you think?,0,0.9371568560600281
1332692288,14408,dajac,2023-09-21T08:37:43Z,i think that a consumer group will actually never transition to dead. we could actually remove this state.,0,0.980216920375824
1332692487,14408,dajac,2023-09-21T08:37:52Z,ditto.,0,0.859873354434967
1332693494,14408,dajac,2023-09-21T08:38:40Z,i wonder if using a switch would be better here. what do you think?,0,0.7765976786613464
1332694686,14408,dajac,2023-09-21T08:39:31Z,this does not seem correct to me because this exception does not apply to consumer groups.,0,0.7595730423927307
1332695102,14408,dajac,2023-09-21T08:39:47Z,"as mentioned earlier, we have to generate other tombstones.",0,0.9824648499488831
1332697684,14408,dajac,2023-09-21T08:41:20Z,throwing an exception does not seem to be the right approach to me because we still want to delete the group and the exception will stop the process. my understanding is that we could just skip generating the tombstone if the generation <= 0.,0,0.8386417627334595
1333162337,14408,dajac,2023-09-21T14:32:57Z,"actually, what i said is wrong here. i think that we should generate the tombstone in any cases to ensure that the group is removed from the timeline hashmap.",0,0.7125657796859741
1333326880,14408,rreddy-22,2023-09-21T16:24:11Z,"nit: can we add a tab space and capitalize ""the"" -> topic the topic name.",0,0.985385537147522
1333327696,14408,rreddy-22,2023-09-21T16:24:52Z,"also i thought we had decided to use topicids instead of topic names throughout the new protocol, are we using topic names for this api?",0,0.9857101440429688
1333329945,14408,rreddy-22,2023-09-21T16:26:53Z,"nit: same with this, tab spaces to align both param descriptions",0,0.9887688159942627
1333331492,14408,rreddy-22,2023-09-21T16:28:22Z,nit: extra line,0,0.970479428768158
1333348886,14408,rreddy-22,2023-09-21T16:42:49Z,nit: period is missing,0,0.9658688902854919
1333554676,14408,jeffkbkim,2023-09-21T20:11:58Z,"let's say that for some of the topic partitions, the deletegroups write operations were successful. for others, let's say that there was a timeout. this would return a request timeout to the clients indicating that the request failed. i think this is fine, but it could be confusing to the user. what are your thoughts?",0,0.9383630156517029
1333558630,14408,jeffkbkim,2023-09-21T20:16:28Z,we can use collections.singletonlist(),0,0.9876787066459656
1333583218,14408,jeffkbkim,2023-09-21T20:45:18Z,this can be null right? if there are no offsets for the given group id,0,0.9854612946510315
1333600423,14408,jeffkbkim,2023-09-21T21:01:38Z,"nit: handles ""a"" maybe we can reword this to ""deletes offsets as part of a deletegroups request.""",0,0.9888920187950134
1333601100,14408,jeffkbkim,2023-09-21T21:02:28Z,"nit: `(partition, __) ->`",0,0.9848951697349548
1333615622,14408,jeffkbkim,2023-09-21T21:20:16Z,should it be `offsetsbytopic.get(topic.name())`?,0,0.9876320362091064
1333615893,14408,jeffkbkim,2023-09-21T21:20:40Z,should this be `containskey(partition.partitionindex())`?,0,0.9889718890190125
1334471084,14408,dajac,2023-09-22T14:37:24Z,i made the same comment earlier and updated the code to handle exceptions for each write operation.,0,0.9864913821220398
1334519906,14408,dajac,2023-09-22T15:15:50Z,offsets apis still use topic names...,0,0.9871042370796204
1336162536,14408,rreddy-22,2023-09-25T16:56:06Z,got it okie!,1,0.9100071787834167
1336165006,14408,rreddy-22,2023-09-25T16:58:32Z,nit: can we add new lines between the tests,0,0.9875767230987549
1336165306,14408,rreddy-22,2023-09-25T16:58:52Z,nit: line,0,0.9684032201766968
1336168777,14408,rreddy-22,2023-09-25T17:02:31Z,nit: line,0,0.9684032201766968
1336348269,14408,jeffkbkim,2023-09-25T20:18:12Z,i wonder if creategrouptombstonerecords() makes more sense,0,0.9008711576461792
1336363313,14408,jeffkbkim,2023-09-25T20:36:10Z,"nit: ""deletegroups"" request. this should reflect the actual apikeys#delete_groups name",0,0.9892772436141968
1336441437,14408,jeffkbkim,2023-09-25T22:24:33Z,"can we add a test with three __consumer_offsets topic partitions where one finishes immediately, another takes a while, and the last coordinator throws an exception?",0,0.988239049911499
1336446270,14408,jeffkbkim,2023-09-25T22:33:21Z,"nit: testdeletegroups also, can we verify the number of method invocations and also test that we append records correctly for multiple groups?",0,0.9888581037521362
1336446500,14408,jeffkbkim,2023-09-25T22:33:44Z,nit: testdeletegroupsinvalidgroupid can we also add a valid group id and verify the first stores invalid group id error and the second stores none?,0,0.9896870255470276
1336449678,14408,jeffkbkim,2023-09-25T22:38:58Z,should this be a static method?,0,0.9846155047416687
1336451305,14408,jeffkbkim,2023-09-25T22:42:01Z,we can inline this to l380,0,0.9863998889923096
1336461743,14408,jeffkbkim,2023-09-25T23:01:52Z,this can be removed,0,0.9870893359184265
1336461886,14408,jeffkbkim,2023-09-25T23:02:11Z,we can do `consumergroup::validategroupdelete` for this along with the other invocations in the test,0,0.9862260222434998
1336465543,14408,jeffkbkim,2023-09-25T23:10:02Z,should we add empty test case? also for testvalidategroupdelete,0,0.9899416565895081
1339019021,14408,jeffkbkim,2023-09-27T18:13:35Z,should these be deletegroup?,0,0.9867312908172607
1339020329,14408,jeffkbkim,2023-09-27T18:14:44Z,whether,0,0.958652675151825
1339025948,14408,jeffkbkim,2023-09-27T18:19:28Z,"should this be ""delete-groups""?",0,0.9834255576133728
1339176820,14408,jeffkbkim,2023-09-27T20:29:44Z,"validations are done in `{ groupcoordinatorshard#deletegroups(requestcontext, list)}`",0,0.9887935519218445
1339182547,14408,jeffkbkim,2023-09-27T20:34:35Z,ditto on link can we add a comment on why we don't expect an exception to be thrown here?,0,0.9662059545516968
1339194498,14408,jeffkbkim,2023-09-27T20:45:50Z,the id of the group to be deleted.,0,0.9824798107147217
1339198942,14408,jeffkbkim,2023-09-27T20:50:06Z,"in the existing implementation, we transition to dead if the group is empty so that even if the write operation fails we delete the group in the next purge cycle. we don't need to do this here since if the write operation fails we revert to the previous state and return an error so the client knows that the operation failed. is this correct?",0,0.9833803176879883
1339201386,14408,jeffkbkim,2023-09-27T20:52:23Z,the current implementation logs how many groups and offsets were removed. should we add something similar? [code block],0,0.9883185625076294
1339216413,14408,jeffkbkim,2023-09-27T21:06:07Z,can we move this check outside of the foreach block? we perform this check for every partition of the topic,0,0.9880286455154419
1339228792,14408,jeffkbkim,2023-09-27T21:17:29Z,don't we also need to check whether the stable group is using the consumerprotocol.protocol_type? from [code block],0,0.9890294075012207
1339232259,14408,jeffkbkim,2023-09-27T21:21:07Z,"should this be ""delete-offsets""?",0,0.9859874844551086
1339234027,14408,jeffkbkim,2023-09-27T21:22:59Z,do we need this?,0,0.983482837677002
1339235261,14408,jeffkbkim,2023-09-27T21:24:20Z,can we follow the same line break as in l1101-1102? same for result2,0,0.9888467192649841
1339255544,14408,jeffkbkim,2023-09-27T21:46:00Z,"in general, it's not a good practice to use thread.sleep in tests. also, i don't think this tests what we actually want to test. we want to confirm that the final future is not completed until this operation completes. so i propose: 1. have this thread wait 2. confirm future did not complete 3. unblock this thread 4. confirm future completes something like the following: [code block]",-1,0.5097077488899231
1340712345,14408,dajac,2023-09-28T22:14:06Z,nit: could we refactor `geterrorresponse` to use this new method as well? should we also add a unit test for this one?,0,0.9897502064704895
1340712743,14408,dajac,2023-09-28T22:14:53Z,i wonder if we should rather pass the list of records as an argument in order to avoid having to copy the records afterwards. have you considered this?,0,0.9401366710662842
1340716345,14408,dajac,2023-09-28T22:22:06Z,nit: should we set the expected size here?,0,0.9825969338417053
1340716744,14408,dajac,2023-09-28T22:22:57Z,"good question. in my opinion, this log line is useful for the expiration case. i am not sure if it really is in this one.",1,0.8992383480072021
1340717283,14408,dajac,2023-09-28T22:24:01Z,nit: let's remove this empty line.,0,0.9799637198448181
1340717524,14408,dajac,2023-09-28T22:24:31Z,nit: should we just add this to the document of the groupid field?,0,0.9861307740211487
1340720235,14408,dajac,2023-09-28T22:29:11Z,"do we ever transition to dead? if not, i wonder if we should just remove this and remove the dead state. what do you think?",0,0.9191880822181702
1340720555,14408,dajac,2023-09-28T22:29:51Z,nit: i wonder if using a switch would be better here. have you considered it?,0,0.7567381858825684
1340720632,14408,dajac,2023-09-28T22:30:01Z,nit: ditto for the switch.,0,0.8321301341056824
1340744802,14408,dajac,2023-09-28T23:20:18Z,nit: could we put `setgroupid` on a new line as well?,0,0.988888680934906
1340745968,14408,dajac,2023-09-28T23:23:13Z,nit: the `null` here is not ideal. could we put a string instead? or you could also use coordinator_load_in_progress.exception().,0,0.979197084903717
1340747829,14408,dajac,2023-09-28T23:27:23Z,"i am not sure to understand what you are trying to achieve here. could you elaborate? if you want to delay the completion of the future, the best would be to create a completablefuture, use thenreturn(future), and then complete the future at l1149.",0,0.5980809330940247
1340749921,14408,dajac,2023-09-28T23:33:00Z,is there a reason why you don't use when().thenanswer(...)?,0,0.9573010802268982
1340750286,14408,dajac,2023-09-28T23:33:55Z,could we also use `groupids` to generate the list here?,0,0.9883421063423157
1340750616,14408,dajac,2023-09-28T23:34:52Z,ditto for those two.,0,0.8882253170013428
1340750923,14408,dajac,2023-09-28T23:35:44Z,nit: could we put an empty line before this one? i find the code a bit hard to read because all the lines are all together.,0,0.9186751842498779
1340752025,14408,dajac,2023-09-28T23:38:51Z,"small nit: it may be a bit easier to read if we create the expected response as follow? what do you think? if you find it better, we could also update the other test cases. [code block]",0,0.9805896282196045
1340752304,14408,dajac,2023-09-28T23:39:37Z,should we at minimum verify the group ids here?,0,0.9843868613243103
1340753404,14408,dajac,2023-09-28T23:42:35Z,"in the groupmetadatamanagertestcontext, we actually moved this to the replay method. see [a link]. it may be better to do the same here. what do you think?",0,0.9826808571815491
1340753611,14408,dajac,2023-09-28T23:43:06Z,nit: indentation should be 4 spaces.,0,0.9849249720573425
1340753971,14408,dajac,2023-09-28T23:44:05Z,should we move this method to the test context?,0,0.9857429265975952
1340754157,14408,dajac,2023-09-28T23:44:38Z,we could also apply my formatting suggestion here.,0,0.9849177002906799
1340754965,14408,dajac,2023-09-28T23:46:50Z,"this block is really hard to parse. [code block] would it be better like this? otherwise, i would use a regular if statement.",-1,0.6639028191566467
1340756205,14408,dajac,2023-09-28T23:50:13Z,what does `invalidoffset` mean here?,0,0.9741244912147522
1340756359,14408,dajac,2023-09-28T23:50:43Z,ditto.,0,0.859873354434967
1340757038,14408,dajac,2023-09-28T23:52:20Z,could we use `grouptype` instead? then you could use a switch based on the enum.,0,0.9885425567626953
1340757258,14408,dajac,2023-09-28T23:52:59Z,nit: could we put an empty line here?,0,0.9824777245521545
1340783686,14408,jeffkbkim,2023-09-29T01:11:23Z,"the current [a link] transitions groups to dead once a group is empty && offsets are gone. the current behavior for generic groups is the above, and i copied the same behavior for consumer groups. then once the group is dead, it will be considered for expiration in the next cycle.",0,0.986767590045929
1340783926,14408,jeffkbkim,2023-09-29T01:12:09Z,should we at least log the number of groups that were deleted from the deletegroups request?,0,0.9867988228797913
1340788752,14408,jeffkbkim,2023-09-29T01:27:40Z,"this was my suggestion. your suggestion is much simpler, thanks!",1,0.9675584435462952
1341653044,14408,dajac,2023-09-29T17:49:06Z,"i am not sure to understand why we need to do this. couldn't we just delete the group when it is empty and offsets are gone instead of transitioning to dead and then deleting it? my understanding is that we use dead in the old code because we can't remove the group from the map before the change is committed to the log. during this time, the group is in the dead state. in our world, the group is remove from the map immediately and the change is reverted if the write fails.",0,0.6697328090667725
1341917129,14408,yangy0000,2023-09-30T06:16:35Z,error handling codes in lines 555-586 and 797-816 are very similar. an alternative implementation is create a util method: [code block] within deletegroups : [code block] within deleteoffsets: [code block],0,0.9815585017204285
1341918630,14408,yangy0000,2023-09-30T06:34:17Z,nit: the else braces can be simplified to [code block],0,0.9888131022453308
1341919233,14408,yangy0000,2023-09-30T06:42:12Z,"no check on ""issubscribedtotopic"" in here? is this expected?",0,0.9851540923118591
1342599402,14408,dajac,2023-10-02T12:02:33Z,nit: given that there is only one test. i would rather move everything into that test.,0,0.9477277994155884
1342610382,14408,dajac,2023-10-02T12:13:55Z,"i am +1 for bringing the definition of `offsetsbypartition` within the `else` clause. however, we have to keep using `topic.partitions().foreach(` to iterate over the partitions. however, i don't like `if(offsetsbypartition ==null) {continue};`. how about using `offsetsbypartition != null`?",0,0.9389017224311829
1342611067,14408,dajac,2023-10-02T12:14:42Z,"no, we don't need it here because the group is completely removed in this case.",0,0.9727399945259094
1342627317,14408,dajac,2023-10-02T12:31:57Z,i wonder if we should rather log this within the shard in order to have it logged per shard (with the shard context). what do you think?,0,0.9545737504959106
1342628078,14408,dajac,2023-10-02T12:32:46Z,nit: how about `return allfutures.thenapply...`?,0,0.9867540001869202
1342632075,14408,dajac,2023-10-02T12:36:58Z,"nit: would it make sense to use? we don't really need `response` except here. ``` return new coordinatorresult<>( records, new offsetdeleteresponsedata().settopics(responsetopiccollection) );",0,0.9861245155334473
1342635373,14408,dajac,2023-10-02T12:40:21Z,nit: could we use `state() != empty`? this would be more robust.,0,0.9842531085014343
1342640395,14408,dajac,2023-10-02T12:45:34Z,i wonder if we should test all the exceptions that we re-map. i did something similar in `testconsumergroupheartbeatwithexception`. what do you think?,0,0.9084572792053223
1342641976,14408,dajac,2023-10-02T12:47:11Z,ditto about the error mapping verification.,0,0.9313716888427734
1342642294,14408,dajac,2023-10-02T12:47:29Z,can't we use `assertequals`?,0,0.9862406849861145
1342643914,14408,dajac,2023-10-02T12:48:59Z,it would be better to use the other way in order to remain consistent with the other tests. is this possible?,0,0.9829223155975342
1342645279,14408,dajac,2023-10-02T12:50:17Z,nit: expectederror?,0,0.9866265654563904
1342647294,14408,dajac,2023-10-02T12:51:42Z,"nit: should we define an helper method in the context (e.g. hasoffset(groupid, topic, partition))? i would also bring `error == errors.none` back on the previous line because it fits there.",0,0.9883061051368713
1342851207,14408,yangy0000,2023-10-02T15:33:32Z,any chance deletealloffsets will get invoked before the group is completely removed?,0,0.9850561618804932
1343253093,14408,jeffkbkim,2023-10-02T23:24:28Z,was this addressed?,0,0.9827174544334412
1343255509,14408,jeffkbkim,2023-10-02T23:30:33Z,"also, we can remove the `v`",0,0.9872542023658752
1343257434,14408,jeffkbkim,2023-10-02T23:34:56Z,nit: an,0,0.9631584286689758
1343258721,14408,jeffkbkim,2023-10-02T23:38:09Z,"""at this point, we have already validated the group id so we know that the group exists and that no exception will be thrown."" how's this?",0,0.9800020456314087
1343258959,14408,jeffkbkim,2023-10-02T23:38:35Z,"nit: can we change all usages of ""id"" to ""id""?",0,0.9877238273620605
1343259306,14408,jeffkbkim,2023-10-02T23:39:31Z,we can move these into the test as well,0,0.9846409559249878
1343259404,14408,jeffkbkim,2023-10-02T23:39:45Z,"we can remove the ""v""",0,0.9873505234718323
1343260319,14408,jeffkbkim,2023-10-02T23:41:35Z,what's the benefit of using final variables here?,0,0.9799537658691406
1343262352,14408,jeffkbkim,2023-10-02T23:46:19Z,we can use [code block],0,0.9886272549629211
1343263220,14408,jeffkbkim,2023-10-02T23:48:18Z,nit: newline,0,0.9799820184707642
1343263632,14408,jeffkbkim,2023-10-02T23:49:12Z,?,0,0.9320514798164368
1343266197,14408,jeffkbkim,2023-10-02T23:54:55Z,can we use [code block] and remove the helper method?,0,0.9889722466468811
1343267277,14408,jeffkbkim,2023-10-02T23:57:24Z,can we assert true that the future is done?,0,0.9813566207885742
1343267559,14408,jeffkbkim,2023-10-02T23:57:57Z,can we use [code block] and remove the helper?,0,0.9890596866607666
1343269222,14408,jeffkbkim,2023-10-03T00:01:47Z,can we change all of the `dosomething...when...` to `when().dosomething`?,0,0.9884250164031982
1344182771,14408,dajac,2023-10-03T14:14:31Z,"i think that we should be careful with this. the change is not 100% equivalent to the previous implementation here because the error message is not set for all errors whereas it was only set of a sub set before. while i agree that we could do better, i would suggest to tackle this in a separate pr.",0,0.946263313293457
1344185641,14408,dajac,2023-10-03T14:16:09Z,"nit: if we keep it, the method could be static and we usually don't prefix methods with `get`. `normalizeexception` maybe an alternative name.",0,0.9880101084709167
1344186369,14408,dajac,2023-10-03T14:16:40Z,why do we need an atomicinteger here?,0,0.9653195142745972
1344187568,14408,dajac,2023-10-03T14:17:30Z,nit: `... removed.`.,0,0.8727570176124573
1344188289,14408,dajac,2023-10-03T14:17:57Z,"i guess that they don't hurt, isn't it?",0,0.8384435176849365
1344189933,14408,dajac,2023-10-03T14:19:04Z,"if you look at the usage in `[a link]`, all offsets are removed before deleting the group.",0,0.9877710342407227
1344192203,14408,dajac,2023-10-03T14:20:23Z,i agree. i mentioned this a few times a well.,0,0.8827937245368958
1344192583,14408,dajac,2023-10-03T14:20:34Z,ditto.,0,0.859873354434967
1344192793,14408,dajac,2023-10-03T14:20:41Z,ditto.,0,0.859873354434967
1344192915,14408,dajac,2023-10-03T14:20:45Z,ditto.,0,0.859873354434967
1344193032,14408,dajac,2023-10-03T14:20:50Z,ditto.,0,0.859873354434967
1344498860,14408,dongnuo123,2023-10-03T17:44:07Z,"if we use int, we'll get error `variable used in lambda expression should be final or effectively final`. lambda expressions do not allow any external variable operation within itself. i can add a small comment here.",0,0.9868636131286621
1344502310,14408,dongnuo123,2023-10-03T17:47:11Z,when(method).dosomething requires method to return a non-void value. i can add a comment here for explanation.,0,0.98831707239151
1344523685,14408,dongnuo123,2023-10-03T18:06:47Z,rolled back,0,0.9550579190254211
1344524665,14408,dongnuo123,2023-10-03T18:07:42Z,comment added,0,0.9845704436302185
1344524782,14408,dongnuo123,2023-10-03T18:07:49Z,comment added,0,0.9845704436302185
1344524966,14408,dongnuo123,2023-10-03T18:07:59Z,comment added,0,0.9845704436302185
1344525094,14408,dongnuo123,2023-10-03T18:08:08Z,comment added,0,0.9845704436302185
1344554094,14408,dajac,2023-10-03T18:34:48Z,ack. i wonder if we should use `for (string groupid : groupids) ....` then. what do you think?,0,0.5309704542160034
464705276,9100,hachikuji,2020-08-03T23:00:19Z,probably reasonable to handle it the same way other inter-broker rpcs are handled.,0,0.9800604581832886
464708303,9100,hachikuji,2020-08-03T23:10:04Z,"good question. might be fair to assume the controller is correct and use stale_broker_epoch. once kip-500 is all done, it would be totally fair since the controller will be guaranteed to have the latest state. the other question is what the broker should do if it sees stale_broker_epoch...",1,0.7203577756881714
464709341,9100,hachikuji,2020-08-03T23:13:24Z,"hmm.. this adds a delay of 2.5s to every isr change, which is a bit annoying. i guess the point is to allow batching? i think a better approach might be to send requests immediately on arrival, but set a limit on the maximum number of in-flight requests (maybe just 1) and let the changes accumulate when there is a request in-flight. then we can still get a big batching benefit when there are a large number of isr changes that need to be sent in a hurry.",-1,0.7520537972450256
464710258,9100,hachikuji,2020-08-03T23:16:19Z,hmm.. not sure it's worth doing these validations up-front. these checks could fail between the time that the event is enqueued and the time it is processed.,-1,0.7635267972946167
464716040,9100,mumrah,2020-08-03T23:35:25Z,that makes sense. i'll change that (this was pulled in from the previous isr notification code in replicamanager),0,0.9878562092781067
464717171,9100,mumrah,2020-08-03T23:39:05Z,"the main rationale for validating in the request handler is so we can return meaningful partition-level errors to the broker (fenced leader, not leader or follower, etc). although, i'm not sure the broker could do anything useful with these errors since it probably has stale metadata in these cases. the kip calls out four partition-level errors. do we actually need them?",0,0.9813140630722046
464718819,9100,hachikuji,2020-08-03T23:44:49Z,"to be clear, i'm not questioning the need for the validation, just the fact that it is done before enqueueing the event instead of when the event is processed.",0,0.9710758924484253
465029352,9100,mumrah,2020-08-04T12:56:33Z,"ah, i see what you mean. initially, i was concerned about blocking for too long while waiting for a response, but it looks like there is precedent for this pattern for some requests (reassignment, leader election, controlled shutdown). i'll move this validation and the callback down into the event processor method",0,0.9521740078926086
465708837,9100,cmccabe,2020-08-05T13:00:48Z,"it seems like we need to set the `insyncreplicaids` here, since we don't do it in `shrinkisr`.",0,0.9702238440513611
465711962,9100,cmccabe,2020-08-05T13:06:08Z,this is also a concurrency bug since you can't access stuff like the controllercontext except from the controller thread itself (it would be multi-threaded access without a lock),0,0.8184399008750916
465712943,9100,cmccabe,2020-08-05T13:07:48Z,this also needs to call `networkclient#wake` in case we are blocking inside `networkclient#poll`,0,0.9857782125473022
465715770,9100,cmccabe,2020-08-05T13:12:19Z,"it would be good to find a better name for this. when i read ""alterisrchannelmanager"" i assumed it had its own separate channel, rather than using the controllerchannelmanager.",0,0.9376022219657898
465743922,9100,mumrah,2020-08-05T13:54:54Z,good to know about `controllercontext` :thumbs_up:,1,0.936400830745697
465746162,9100,mumrah,2020-08-05T13:58:00Z,"it might be simpler just to use alterisrrequestdata and alterisrresponsedata throughout this code (rather than converting to `map[topicpartition, leaderandisr]` and `map[topicpartition, errors]`)",0,0.987436056137085
465748120,9100,mumrah,2020-08-05T14:00:36Z,"i think we need to send leaderandisr for all the given partitions whether we updated the isr or not. in cases where we failed due, the leaders likely have stale metadata. this way we can proactively send them the latest state.",0,0.9850519895553589
465748504,9100,mumrah,2020-08-05T14:01:11Z,"yea, maybe just ""alterisrmanager""?",0,0.9712159633636475
465749546,9100,mumrah,2020-08-05T14:02:38Z,should probably get rid of this and change the method to [code block],0,0.9857915639877319
465750445,9100,mumrah,2020-08-05T14:03:55Z,remove this,0,0.9735968708992004
465750632,9100,mumrah,2020-08-05T14:04:10Z,newline,0,0.9834905862808228
465888182,9100,abbccdda,2020-08-05T17:28:23Z,nit: could move these operations to the `alterisrrequest` as helpers.,0,0.9880609512329102
469372344,9100,hachikuji,2020-08-12T16:03:52Z,"with kip-500, i imagine we could end up with other cases where we end up using optimistic concurrency control. does it make sense to make this error a little more generic? maybe `invalid_update_version` or something like that..",0,0.9680436253547668
469373339,9100,hachikuji,2020-08-12T16:05:24Z,nit: maybe drop the parameters if they do not need to be documented,0,0.986085057258606
469379488,9100,hachikuji,2020-08-12T16:14:57Z,nit: info feels a bit high for a message like this,0,0.6963552236557007
469382729,9100,hachikuji,2020-08-12T16:20:13Z,we might need to be careful about performance here since this would get called on every follower fetch.,0,0.9593610763549805
469383572,9100,hachikuji,2020-08-12T16:21:34Z,"the usage is a bit surprising given the ""pending"" name. i wonder if it would be clearer if we used a type of `option[set[int]]` so that we could use `none` when there is no pending isr change. one more thing. it's worth double-checking the threading assumptions here. it looks like `updateassignmentandisr` is only called while holding the write side of `leaderisrupdatelock`. on the other hand, i don't see any lock held in `updatefollowerfetchstate`. it's worth stepping through that logic to make sure that we do not depend on `insyncreplicaids` and `pendinginsyncreplicaids` getting set atomically.",0,0.7940126061439514
469385374,9100,hachikuji,2020-08-12T16:24:32Z,"i think the answer is no. the pending isr set is not guaranteed, so we cannot depend on it to enforce min.isr.",0,0.983633816242218
469388095,9100,hachikuji,2020-08-12T16:29:06Z,"related to the other comment, but we need to be careful with the min.isr check below. i think it is correct to wait for `effectiveinsyncreplicaids` before acknowledging the produce request, but we should probably use the size of `insyncreplicaids` in the min.isr check since that is the only set we can guarantee.",0,0.982796311378479
469399037,9100,hachikuji,2020-08-12T16:47:34Z,"there is a ""classic"" edge case in kafka which goes as follows: 1. leader is 1, isr is [1, 2, 3] 2. broker 3 begins controlled shutdown. while awaiting shutdown, it continues fetching. 3. controller bumps epoch and shrinks isr to [1, 2] and notifies replicas 4. before controlled shutdown completes and 3 stops fetching, the leader adds it back to the isr. this bug was fixed by kip-320 which added epoch validation to the fetch api. after shrinking the isr in step 3, the controller will send `leaderandisr` with the updated epoch to [1, 2] and `stopreplica` to [3]. so 3 will not send any fetches with the updated epoch, which means it's impossible for the leader to add 3 back after observing the shrink to [1, 2]. i just want to make sure whether above is correct and whether `alterisr` changes it in any way. i think the answer is no as long as isr expansion is _only_ done in response to a fetch request, but it's worth double-checking.",0,0.9713401198387146
469406972,9100,hachikuji,2020-08-12T17:00:32Z,i think it's worth adding a comment in the cases we rely on `effectiveinsyncreplicaids` to explain why.,0,0.978471577167511
469412587,9100,hachikuji,2020-08-12T17:10:15Z,"i think the implementation here is actually different than what was in the model. consider the following case: 1) initial state: isr=[1, 2], pendingisr=[1, 2] 2) leader expands isr. isr=[1, 2], pendingisr=[1, 2, 3] 3) leader shrinks isr. isr=[1, 2], pendingisr=[1, 2] we don't know which of the updates in 2) or 3) will be accepted, but after 3), we will not assume that broker 3 could be in the isr, which could lead to a correctness violation if the update in 2) is accepted by the controller. in the model, we always assumed the maximal isr across _any_ potential update to protect from this edge case. maybe in the end it is simpler to not allow multiple in-flight updates.",0,0.9777896404266357
469413205,9100,hachikuji,2020-08-12T17:11:21Z,nit: remove parenthesis for simpler getters like `code`. a few more of these,0,0.9867183566093445
469413455,9100,hachikuji,2020-08-12T17:11:47Z,missing license header in this file.,0,0.5731533169746399
469414718,9100,hachikuji,2020-08-12T17:13:57Z,"nit: avoid loaded terminology like ""blackout"" (see [a link] do we actually need this or `isrchangepropagationinterval` below?",0,0.9621466398239136
469415543,9100,hachikuji,2020-08-12T17:15:14Z,we should use `time`,0,0.9865615963935852
469417613,9100,hachikuji,2020-08-12T17:18:30Z,probably need to reduce the log level here and below.,0,0.9729719161987305
469419452,9100,hachikuji,2020-08-12T17:21:31Z,"i think the basic approach here is to ignore successful responses and wait for the `leaderandisr` update. i am wondering how we should handle the case when the update failed. say for example that our update fails with the invalid_version error. inside `partition`, we will still have the pendingisr set. do we need to clear it? how about other errors?",0,0.9693356156349182
469421031,9100,hachikuji,2020-08-12T17:24:17Z,nit: more useful as a debug if we add request details to the message,0,0.9703327417373657
469421800,9100,hachikuji,2020-08-12T17:25:29Z,the broker epoch is not a constant. it gets reinitialized whenever the broker has to create a new session.,0,0.962726891040802
469423834,9100,hachikuji,2020-08-12T17:28:57Z,"the term ""pending"" again is a little unclear. perhaps ""unsentisrupdates"" would make the usage clearer.",0,0.9650170803070068
469425898,9100,hachikuji,2020-08-12T17:32:22Z,removal from this set won't prevent `brokertocontrollerrequestthread` from retrying in-flight requests. i'm considering whether we should have a way to cancel requests that we are still awaiting.,0,0.9800436496734619
469460462,9100,mumrah,2020-08-12T18:33:11Z,"we don't, these were copied over from the replicamanager's isr propagation logic. i'll clean this up",0,0.9853832721710205
469467881,9100,mumrah,2020-08-12T18:46:27Z,"i'm currently looking at the effective isr to find new out of sync replicas. this can include new isr members which haven't made it into the ""true"" isr via leaderandisr yet (like broker=3 in your example). maybe we should only consider removing isr members iff they are in the true isr. iow changing from [code block] to [code block] also, i wonder if the batching that's happening in alterisrchannelmanager violates the model. it sends the request asynchronously with a small delay, so multiple isr changes can be batched into one alterisr.",0,0.9330936670303345
469516375,9100,abbccdda,2020-08-12T20:20:11Z,nit: new line,0,0.96523118019104
470053173,9100,mumrah,2020-08-13T15:51:39Z,"yea, lots of these will be lowered, was just doing this during development",0,0.9316182136535645
470063833,9100,mumrah,2020-08-13T16:08:16Z,"i don't think alterisr changes anything since we're now just sending the async isr update where we were previously directly updating zk. looking at the usages, `updatefollowerfetchstate` is only called following a read (`partition#readrecords`). these reads only happen on fetch requests and from the alter log dirs fetcher. i'm not sure about the alter log dirs flow, but as long as it sends the leader epoch, it should be safe.",0,0.9824827909469604
470673412,9100,mumrah,2020-08-14T14:51:00Z,fixed this by adding getbrokerepoch to kafkazkclient,0,0.9888216257095337
470675300,9100,mumrah,2020-08-14T14:54:10Z,"with the latest changes to prevent multiple in-flight requests, i don't think this should happen for a given partition. even if it did, the retried in-flight request from brokertocontrollerrequestthread would fail on the controller with an old version. i'm wondering if we even need this clearpending behavior. since i changed the alterisr request to fire at most after 50ms, it's a narrow window between enqueueing an isr update and receiving a leaderandisr.",0,0.8828415870666504
470678123,9100,mumrah,2020-08-14T14:58:58Z,"since we are now only allowing one in-flight alterisr, i changed the semantics of pendinginsyncreplicaids to be the maximal ""effective"" isr. this way we don't need to compute it each time.",0,0.9843368530273438
473515635,9100,abbccdda,2020-08-20T01:36:09Z,"should we move the startup logic to `kafkaserver`? note the channel is shared between different modules, so it makes sense to start and close inside the server.",0,0.989349365234375
474106591,9100,mumrah,2020-08-20T16:17:31Z,"i found a race during the system tests when a follower is shutting down. the controller handles the shut down before it handles an alterisr. if the proposed isr includes the now-offline replica, the controller refuses to update that isr change and returns an error for that partition. it then sends out the current leaderandisr. the problem is that the broker ignores this leaderandisr since it has the same leader epoch. this is easy enough to fix, we can bump the leader epoch in the controller (and zk) before sending it out. however, there's still the case of failing to update zk. i think we should probably treat this the same way as an offline replica. if we simply return an error in alterisr response and let the leader reset the pending isr state, the leader will just retry with stale metadata and the update will fail again. i think in all these error cases we must bump the leader epoch to force the leader to accept the new leaderandisr. thoughts?",0,0.955353319644928
474930329,9100,mumrah,2020-08-21T20:15:17Z,it's a little tricky since leaderandisr isn't visible to alterisrrequest.,0,0.8098496198654175
474934833,9100,mumrah,2020-08-21T20:20:56Z,"update: after some discussion and looking over failed system tests, we ended up with the following error handling: * replica_not_available and invalid_replica_assignment will clear the pending isr to let the leader retry. this covers a case where a leader tries to add a replica to the isr which is offline because it (the follower) just finished shutdown. * invalid_update_version will not clear the pending isr since the broker has stale metadata. * fenced_leader_epoch, not_leader_or_follower, unknown_topic_or_partition will _not_ clear the pending state and therefor will not retry. we presume here that the controller is correct and the leader has old metadata. by not clearing the pending isr, the leader will await leaderandisr before attempting any further isr changes * other unspecified errors: clear the pending state and let the leader retry. not sure what cases could cause other errors, but it is probably better to be in a retry loop than to be completely stuck",0,0.973793625831604
474959176,9100,mumrah,2020-08-21T20:50:34Z,continued in [a link],0,0.9862625598907471
475625111,9100,mumrah,2020-08-24T13:53:27Z,this error message should be less specific,0,0.9673598408699036
475626573,9100,mumrah,2020-08-24T13:54:36Z,"need to revert this stuff, didn't mean to commit",-1,0.5901800990104675
475627290,9100,mumrah,2020-08-24T13:55:09Z,rename to alterisrmanager,0,0.9851437211036682
475629593,9100,mumrah,2020-08-24T13:57:02Z,expand on this comment to discuss the maximal isr,0,0.985373854637146
475630695,9100,mumrah,2020-08-24T13:57:55Z,fix comment to refer to correct variable,0,0.9877795577049255
475632719,9100,mumrah,2020-08-24T13:59:34Z,newline,0,0.9834905862808228
477616910,9100,hachikuji,2020-08-26T22:08:38Z,we may as well add flexible version support for the request and response.,0,0.9860982894897461
477618083,9100,hachikuji,2020-08-26T22:11:44Z,"nit: i think `alterisrresponsetopics` should be singular (similarly for other arrays in both of these schemas). also, i wonder if it's reasonable to leave off the `alterisr` prefix. we could access it as `alterisrresponse.topicdata` or something like that.",0,0.9777252674102783
477618646,9100,hachikuji,2020-08-26T22:13:13Z,nit: unneeded newline,0,0.9818490743637085
477620548,9100,hachikuji,2020-08-26T22:18:02Z,do we need this message? it seems the one on line 537 below has more detail already. it would be useful to include the zkversion in the message on 537 as well.,0,0.9837896227836609
477625772,9100,hachikuji,2020-08-26T22:32:18Z,"i am wondering if we can split this into two separate methods: - `effectiveisr`: takes into account any pending changes which may or may not have happened (i could probably also be convinced to call this `maximalisr`) - `confirmedisr`: the latest known value from zookeeper (or the controller) that makes the code easier to follow since we wouldn't have to interpret this flag. some high-level comments might be helpful as well. for example, it's useful to mention somewhere that the high watermark is always treated with respect to the effective isr.",0,0.9798812866210938
477629764,9100,hachikuji,2020-08-26T22:41:43Z,can we move this check earlier in the flow so that we can skip acquiring the write lock if there is an inflight alterisr? maybe it can be part of `needsexpandisr` and `needsshrinkisr` for example.,0,0.9899411797523499
477748433,9100,hachikuji,2020-08-27T00:16:03Z,"i have been thinking a little bit about the semantics of min.isr. basically i am wondering if should be treated as a guarantee on the state of the isr at the time the high watermark is reached (i.e. how many replicas are in the isr), or instead should it be a guarantee on the state of progress of replication (i.e. some number of replicas have reached a given offset)? we may not have ever formally decided this, but here we are taking a stance that it is the latter because we are using the effective (uncommitted) isr. one of the consequences of this view is that a leader may continue to accept appends satisfying min.isr even if the true isr never reaches min.isr. for example, imagine we have the following state: replicas: (1, 2, 3) isr: (1) leader: 1 suppose that replica 2 has caught up to the leader, but the leader is unable to expand the isr because the controller is unavailable or unreachable. with the logic here, we will nevertheless continue to satisfy acks=all requests with a min.isr of 2. i am not sure there is much choice about it to be honest. if instead we used only the ""confirmed"" isr, then we would have sort of an opposite problem. for example, consider this state: replicas: (1, 2, 3) isr: (1, 2) leader: 1 suppose the leader wants to remove 2 from the isr. the alterisr is received by the controller and the state is updated, but the controller fails to send the corresponding leaderandisr. then committing on the basis of the confirmed isr would lead to a similar problem. here is the current documentation for the config: [code block] even though it is named in terms of the isr, the documentation only discusses acks from other replicas, so it seems like the implementation here is consistent even if potentially surprising in some cases.",0,0.9175251126289368
477785759,9100,hachikuji,2020-08-27T00:35:59Z,maybe trace would be better? this could get verbose while we have an inflight alterisr.,0,0.9864756464958191
477786630,9100,hachikuji,2020-08-27T00:36:26Z,i still think we need a better name for `pendinginsyncreplicaids` since it is misleading in this case. maybe we could call it `overrideinsyncreplicaids` or something like that?,0,0.9805220365524292
477787350,9100,hachikuji,2020-08-27T00:36:50Z,nit: maybe `sendalterisrrequest`?,0,0.9877681136131287
477811336,9100,hachikuji,2020-08-27T00:49:30Z,"hmm.. i am not sure it is safe to reset `pendinginsyncreplicaids` in any case except `invalid_update_version`. for example, imagine the following sequence: 1. broker sends alterisr 2. controller writes new isr and crashes before sending response 3. broker hits session expiration 4. broker retries alterisr on new controller with old broker epoch 5. controller responds with stale_broker_epoch in this case, the isr was updated, but the broker is going to revert to the old state. i think the _only_ time we can reset `pendinginsyncreplicaids` is when we know the change could not have been applied.",0,0.8825972080230713
477817624,9100,hachikuji,2020-08-27T00:52:47Z,"the conversion logic is a tad annoying, but it makes the rest of the code nicer. i'm ok with it. that said, could we use scala conventions, e.g.: [code block]",-1,0.7813003659248352
477832161,9100,hachikuji,2020-08-27T01:00:46Z,don't forget the todo!,1,0.7068103551864624
477876231,9100,hachikuji,2020-08-27T01:32:23Z,"should we try to make `alterisr` an idempotent operation? i think currently if we retry an update that was successfully applied, then we will see invalid_version. in general, i'm a bit concerned about the number of errors that are possible through this api and how the leader is supposed to handle them. i am thinking it might make our lives easier if we return some additional information in the response about what the current state really is. let's say that we always try to add the full state tuple to the response: (leaderid, epoch, isr, zkversion). then we can go through a simple process of reconciliation? - am i still the leader? - do i have the latest epoch? - has the zkversion been bumped? - did the isr change get applied? basically i'm looking for a reliable way to determine whether we should continue retrying the request and whether it is safe to clear the pending replica set. at the same time, i'm feeling a bit on-the-fence about relying exclusively on leaderandisr for state changes. if we need to return the current state in the response anyway to properly handle errors, then perhaps we may as well allow the state to be updated as well? this would actually be closer to the flow that we have today, which is the following: 1. leader changes state in zookeeper and updates current isr directly. 2. after some delay, it posts the isr update to isr_change_notifications. 3. controller picks up the notification and sends updatemetadata to all the brokers. notice that the controller does not send leaderandisr to the followers in this flow. what we could do is something more like the following: 1. leader sends alterisr to controller. 2. controller applies the change and returns the updated state. 3. leader receives the response and applies the state change. 4. after some delay, the controller sends updatemetadata to the brokers with the change. if we did this, then we wouldn't need to have the controller bump the epoch when handling alterisr. just as we do today, we can reserve epoch bumps for controller-initiated changes. then we might be able to simplify the error handling to the following: - if the epoch is the same and we are still the leader, then apply the update - if the epoch is higher, leave pendingisr set and do not bother retrying - otherwise just keep retrying what do you think?",-1,0.9630446434020996
477889557,9100,hachikuji,2020-08-27T01:43:00Z,probably not a useful log message,0,0.8748766779899597
477892802,9100,hachikuji,2020-08-27T01:45:16Z,not sure about this. do we really want to put zk in the path to sending to the controller?,0,0.8427937030792236
477902972,9100,hachikuji,2020-08-27T01:52:41Z,this should be fixed,0,0.9762791395187378
477904479,9100,hachikuji,2020-08-27T01:53:43Z,"as far as i can tell, we don't have any logic which tells us whether there is an inflight request. i am considering whether we should as a mechanism for batching/flow control. it might be simpler if we just allow one inflight request. while we are waiting for it to return, we can collect additional pending updates. in case we need to retry the request, we could coalesce the new updates into the request. note that currently `brokertocontrollerchannelmanagerimpl` currently sets max inflight requests to 1 anyway.",0,0.9830322265625
477911757,9100,hachikuji,2020-08-27T01:59:01Z,"we seem to be losing some of the value of having a top-level error code here. as far as i can tell, the following top-level errors should be possible: 1. not_controller: should be retried (handled in `brokertocontrollerchannelmanagerimpl`) 2. stale_broker_epoch: should be retried (could we do that here?) 3. cluster_authorization_failed: probably should be fatal (can we handle that here?) seems like it might simplify the error handling if we can handle them at a corresponding granularity.",0,0.8535391092300415
477912314,9100,hachikuji,2020-08-27T01:59:22Z,nit: misaligned,-1,0.7865947484970093
477916564,9100,hachikuji,2020-08-27T02:02:29Z,any particular reason to change the order here?,0,0.9780314564704895
477918557,9100,hachikuji,2020-08-27T02:03:54Z,we should probably have a try/catch in here somewhere for the unhandled errors to make sure that the callback always gets applied.,0,0.982957124710083
477920314,9100,hachikuji,2020-08-27T02:05:17Z,maybe debug is more suitable?,0,0.9836477637290955
477921396,9100,hachikuji,2020-08-27T02:06:04Z,could be debug perhaps?,0,0.9880461692810059
478067221,9100,mumrah,2020-08-27T03:55:53Z,"i think that sounds pretty reasonable. would we need any kind of timeout at this layer, or just rely on the underlying channel to provide timeouts?",0,0.9555997252464294
478069145,9100,mumrah,2020-08-27T03:57:52Z,"i wasn't too happy about this. is there another way to get the current broker epoch? as i understand it, the broker epoch can change during the lifecycle of a broker.",-1,0.9388436079025269
486521810,9100,mumrah,2020-09-10T17:43:05Z,"i think this sounds good, explict over implicit and all that. if we have two methods like this, should we then make `insyncreplicaids` a private member?",0,0.6810796856880188
486535166,9100,mumrah,2020-09-10T18:05:57Z,"yea, good idea. i'll leave the check here since we actually acquire and release the lock when checking if we should expand/shrink. it's possible that pendinginsyncreplicaids is cleared by a leaderandisr before we acquire the write lock to do the update",1,0.879736065864563
486535868,9100,mumrah,2020-09-10T18:07:08Z,how about `uncommittedinsyncreplicaids`?,0,0.9842823147773743
486535964,9100,mumrah,2020-09-10T18:07:20Z,"nope, will revert",0,0.9322203397750854
489569400,9100,hachikuji,2020-09-16T16:29:34Z,"i know we've gone back and forth on including some of these fields. this is one i'm inclined to get rid of since we already include ""brokerid"" at the top level and `alterisr` can only be sent by leaders.",0,0.9709517955780029
489571330,9100,hachikuji,2020-09-16T16:32:40Z,nit: shall we call this `leaderid` in line with `brokerid` in the request?,0,0.9878238439559937
489572418,9100,hachikuji,2020-09-16T16:34:32Z,"can we revert this change? i think the trace logging is intended, if a bit odd.",0,0.9859808683395386
489572745,9100,hachikuji,2020-09-16T16:35:06Z,we probably need another version since we bumped the fetch protocol version yesterday.,0,0.9856770038604736
489577394,9100,hachikuji,2020-09-16T16:42:48Z,"nit: we use ""maximal"" and ""effective"" interchangeably in this pr. maybe we can choose one term and use it consistently. i do sort of like ""maximal"" since it is more suggestive of the semantics.",0,0.9255145192146301
489579590,9100,hachikuji,2020-09-16T16:46:31Z,nit: maybe `hasinflightalterisr` so that it's clearer what the return value indicates?,0,0.9866255521774292
489580384,9100,hachikuji,2020-09-16T16:47:54Z,nit: maybe we could rename `curinsyncreplicaids` to `cureffectiveisr`,0,0.9804573655128479
489582879,9100,hachikuji,2020-09-16T16:52:06Z,nit: probably need to reword mention of `leaderandisr` since the `alterisr` response is now used.,0,0.9886503219604492
489593301,9100,hachikuji,2020-09-16T17:09:49Z,nit: maybe we can check in-flight requests first (same in `needsexpandisr`). otherwise it's a little odd that `getoutofsyncreplicas` may be based on the maximal isr while we have an in-flight.,0,0.9707686305046082
489593650,9100,hachikuji,2020-09-16T17:10:29Z,nit: redundant comment,0,0.8968497514724731
489594684,9100,hachikuji,2020-09-16T17:12:13Z,nit: you can take the topic partition out of this message since it is already included in `logident`. same on line 1262 below.,0,0.9886188507080078
489604587,9100,hachikuji,2020-09-16T17:29:38Z,"the problem is that it is a sort of worst-case isr and not the intended isr update itself. tough to come up with a good name to describe that. just for the sake of having an alternative, what if we used case classes to represent the current isr state and pending update? for example: [code block] then we can get rid of `effectiveisr`, `insyncreplicaids`, and `pendinginsyncreplicaids`.",-1,0.7868941426277161
489606127,9100,hachikuji,2020-09-16T17:32:22Z,"nit: ""... doesn't know about this **topic** or partition""?",-1,0.8784301280975342
489607165,9100,hachikuji,2020-09-16T17:34:25Z,"hmm... why do we reset `pendinginsyncreplicaids` if we are retrying? unless we are guaranteed that the update failed, then i think we need to continue assuming the worst-case isr. maybe we could just could call `enqueueisrupdate` again to explicitly retry?",0,0.9676836729049683
489608511,9100,hachikuji,2020-09-16T17:36:44Z,"nit: we don't need topic partition here, but it would be nice if we could include the intended update.",0,0.9348356127738953
489608740,9100,hachikuji,2020-09-16T17:37:10Z,"nit: as long as we're updating this, can we use `$` substitutions? also can we mention that this update came from `alterisr`?",0,0.9892921447753906
489609866,9100,hachikuji,2020-09-16T17:39:09Z,"maybe helpful if these messages indicate that this `leaderandisr` can from an `alterisr` response. also, it may be useful to include the current (stale) leader epoch.",0,0.9868571162223816
489610509,9100,hachikuji,2020-09-16T17:40:19Z,"nit: similarly, we can include current `zkversion`",0,0.988650918006897
489612385,9100,hachikuji,2020-09-16T17:43:38Z,nit: maybe we could shorten this name to just `enqueue` since the fact that it is an isr update is already implied by the argument and the name of the trait itself.,0,0.9828962683677673
489614105,9100,hachikuji,2020-09-16T17:46:39Z,nit: usually we write this as `foreach { topic =>`. avoids the extra parenthesis.,0,0.9849627017974854
489614732,9100,hachikuji,2020-09-16T17:47:43Z,nit: maybe split this into two separate methods?,0,0.9737396240234375
489617709,9100,hachikuji,2020-09-16T17:52:57Z,the use of a queue is a tad odd here. we could use `listbuffer`? also nit: use type inference.,-1,0.6207997798919678
489619376,9100,hachikuji,2020-09-16T17:55:53Z,still not super keen on this propagation delay. at least it would be nice if we did not have to wakeup the thread every 50ms when there's nothing to do. this is potentially something we can save for a follow-up since coming up with a good solution might require some experimentation and analysis.,0,0.5859289169311523
489619767,9100,hachikuji,2020-09-16T17:56:37Z,nit: use type inference,0,0.987276017665863
489621121,9100,hachikuji,2020-09-16T17:59:00Z,nit: can we include the broker epoch that was sent in this message?,0,0.9895133376121521
489621168,9100,hachikuji,2020-09-16T17:59:06Z,"hmm.. where does this exception get caught? since it is in the response handler, i guess that `networkclient` just eats it. perhaps we should just continue retrying so that the problem remains visible in the logs.",0,0.969761312007904
489621815,9100,hachikuji,2020-09-16T18:00:08Z,nit: this message would be more useful if we include the response. perhaps it would be better to log each partition update separately?,0,0.9799684286117554
489622001,9100,hachikuji,2020-09-16T18:00:29Z,nit: unneeded parenthesis,0,0.978289783000946
489623549,9100,hachikuji,2020-09-16T18:03:18Z,maybe we could log a warning and let the partition remain in `unsentisrupdates` so that it is retried until we get a response?,0,0.9880934357643127
489623929,9100,hachikuji,2020-09-16T18:04:01Z,nit: may as well convert to `errors` since we do so below anyway,0,0.986902117729187
489624854,9100,hachikuji,2020-09-16T18:05:34Z,i think authorization should probably be the first thing we do.,0,0.9822679758071899
489625184,9100,hachikuji,2020-09-16T18:06:09Z,nit: remove these lines,0,0.976764976978302
489625611,9100,hachikuji,2020-09-16T18:07:02Z,do we still need this change? i think we are trying to keep the current approach where the controller bumps the leader epoch for any controller-initiated change.,0,0.9816270470619202
489625836,9100,hachikuji,2020-09-16T18:07:25Z,i guess we don't need this anymore.,0,0.7409684658050537
489703810,9100,mumrah,2020-09-16T19:27:49Z,"i think this has been a long-standing bad assumption on my part in this pr. i've been (mis)treating `pendinginsyncreplicaids` as a mechanism for initiating a retry along with its other semantics. you're right though, explicitly re-sending the isr is definitely better.",-1,0.5656905174255371
489720971,9100,mumrah,2020-09-16T20:00:38Z,"yup, my mistake, shouldn't have been committed",-1,0.9601553082466125
489721316,9100,mumrah,2020-09-16T20:01:18Z,"""maximal"" works for me :thumbs_up:",0,0.6606888771057129
489730265,9100,mumrah,2020-09-16T20:19:09Z,"ah, missed one ;)",1,0.9353527426719666
489740479,9100,mumrah,2020-09-16T20:39:05Z,currently we impose a 2.5s delay for the old zk based isr propagation method. we could probably increase this 50ms up to a few hundred without any ill-effects. we still benefit from fact that we assume the maximal isr immediately. how about 200ms? longer term we can look into having a single thread invocation that sits in a while loop trying to consume from a linkedblockingqueue or maybe even a synchronousqueue. but agreed we should leave this for later.,0,0.9579993486404419
489744561,9100,mumrah,2020-09-16T20:47:19Z,how about we raise this to an error log with the exception?,0,0.9787200689315796
489745539,9100,mumrah,2020-09-16T20:49:17Z,should we drop it to trace in that case?,0,0.9838088154792786
489747101,9100,mumrah,2020-09-16T20:52:28Z,good idea. another case not covered is if partitions are included in the response but weren't sent out. these will be ignored as things currently stand -- maybe that's ok,1,0.538912832736969
489753946,9100,mumrah,2020-09-16T21:05:59Z,this is actually a really good point. i filed a jira to fix this in other places in kafkaapis [a link],1,0.9706107378005981
489756083,9100,mumrah,2020-09-16T21:10:09Z,"no, we don't need this anymore. this was added so a leaderandisr could update the partition state without a leader epoch bump, but we don't have that flow anymore so we can revert this.",0,0.9792255163192749
490464756,9100,hachikuji,2020-09-17T18:20:10Z,nit: `hasinflight`?,0,0.9872960448265076
490465180,9100,hachikuji,2020-09-17T18:20:54Z,nit: it's surprising to have a side effect like this in a function like this. i think it would be better to include this logging at the caller when we are considering a specific change. that way we can also include in the log message information about the change that we were intending to make.,0,0.9173269271850586
490469252,9100,hachikuji,2020-09-17T18:28:13Z,another possibility is that the replica is pending removal in which case another `alterisr` will be needed. i think it might be more intuitive to make this check: [code block],0,0.9845867156982422
490488626,9100,hachikuji,2020-09-17T19:03:35Z,i think we can refactor this a little bit to avoid some duplication and inconsistency. we have the following logic above when updating follower state: [code block] this is a little inconsistent because here we are checking `isrstate.isr`. i'd suggest splitting this method into something like the following: [code block] then we can change the logic in `maybeexpandisr` to the following: [code block],0,0.9734611511230469
490492340,9100,hachikuji,2020-09-17T19:10:10Z,seems like we do not have a check for inflight alterisr after the write lock has been acquired.,0,0.9580470323562622
490492780,9100,hachikuji,2020-09-17T19:10:50Z,"this is related to my comment above for the isr expansion case, but it is a bit confusing to use maximal isr when the expectation is that we will not shrink as long as we have a pending update inflight. would it be better to check for inflights and document that this method will return an empty set as long as there is a pending alterisr request?",0,0.8539078235626221
490494777,9100,hachikuji,2020-09-17T19:14:38Z,it might be a little more intuitive to change the order here. something like this: [code block],0,0.9749098420143127
490494975,9100,hachikuji,2020-09-17T19:14:57Z,nit: can probably rework this as `exists` [code block],0,0.989538311958313
490527627,9100,hachikuji,2020-09-17T20:00:06Z,"since `invalid_update_version` is one of the expected errors at this level, can we add a separate case for it? for unexpected errors, we might want to log at warn level.",0,0.9877647757530212
490528339,9100,hachikuji,2020-09-17T20:01:27Z,shall we include some details about the failed request?,0,0.9830081462860107
490528744,9100,hachikuji,2020-09-17T20:02:13Z,nit: rewrite with `$`,0,0.987013041973114
490529253,9100,hachikuji,2020-09-17T20:03:19Z,i think `warn` might be too high here. we should expect to see some of these even if the cluster is working properly. how about debug?,0,0.9674780964851379
490530496,9100,hachikuji,2020-09-17T20:05:35Z,nit: can we avoid using `_1` and `_2`? it's a lot easier to follow if they are named.,0,0.9686302542686462
490531814,9100,hachikuji,2020-09-17T20:08:12Z,nit: use type inference. it's conventional to write this as [code block],0,0.9875039458274841
490532481,9100,hachikuji,2020-09-17T20:09:31Z,nit: i think we can get rid of this. the logging in `controllerchannelmanager.sendupdatemetadatarequests` is probably good enough.,0,0.8438847064971924
490534060,9100,hachikuji,2020-09-17T20:12:36Z,"nit: it's subjective, so feel free to ignore, but i find this a little easier to read if we handle the error cases first. so.. [code block] basically we're discarding the error cases so that the successful path continues flowing downward and we're avoiding extra nesting. like i said, it's subjective.",0,0.6148645281791687
490534274,9100,hachikuji,2020-09-17T20:13:00Z,nit: unneeded newline,0,0.9818490743637085
490534954,9100,hachikuji,2020-09-17T20:14:26Z,nit: not sure it makes sense to include this change any longer,-1,0.9013871550559998
490536839,9100,hachikuji,2020-09-17T20:17:56Z,"i wonder if we should be exposing this. would it be enough to have a `def insyncreplicaids = isrstate.isr`? one thing we need to be a little careful of is the fact that we now have a volatile variable with multiple fields. so if you try to access two fields through the `isrstate` reference, you could see inconsistent data.",0,0.8574988842010498
490539522,9100,hachikuji,2020-09-17T20:23:10Z,need to address the todos in this class.,0,0.9648281931877136
490540789,9100,hachikuji,2020-09-17T20:25:23Z,"i may have missed it, but do we have tests which verify error handling? i see tests which verify requests get sent, but at a quick glance i didn't see tests of responses.",0,0.8071311116218567
490541557,9100,hachikuji,2020-09-17T20:26:45Z,nit: sort of conventional to use a name like `mockalterisrmanager`,0,0.9834310412406921
490542749,9100,mumrah,2020-09-17T20:29:02Z,yea i was thinking we should move the isr to a separate public accessor. i'll change this,0,0.9557439088821411
490561028,9100,mumrah,2020-09-17T21:04:05Z,"makes sense, that will also satisfy your other comment about not checking for inflight requests within the write lock",0,0.9868130683898926
490562630,9100,mumrah,2020-09-17T21:07:24Z,"also, yes it's confusing to refer to `maximalisr` here even though it should always equal the committed isr at this point (assuming we check for inflight first).",0,0.5108187794685364
490594335,9100,mumrah,2020-09-17T22:21:46Z,yea checking the maximal set isn't needed anymore since adding the sealed trait. i'll just update this to simply call `maybeexpandisr` which will do the check you propose here,0,0.9812701940536499
494480847,9100,hachikuji,2020-09-24T17:13:35Z,"consider the following scenario: 1) broker sends alterisr 2) the update succeeds but the response is lost 3) broker retries alterisr currently the leader will be stuck after 3) because it has no way to get the latest leaderandisr state if the first attempt fails. to handle this, i think we need to add an idempotence check here. after we have validated the leader epoch, if the intended state matches the current state, then we can just return the current state.",0,0.9769362807273865
494483808,9100,hachikuji,2020-09-24T17:18:40Z,"it might make more sense to handle this case similarly to fenced_leader_epoch. retrying won't help since we know our version will be rejected come to think of it, this would be kind of a strange error to hit in the current implementation which only allows one request inflight at a time. for controller-initiated changes, we'd expect to hit fenced_leader_epoch. anyway, i think it's still worth keeping the error.",0,0.9421637654304504
494486578,9100,hachikuji,2020-09-24T17:23:03Z,"is there any way that we could end up retrying after the pending isr state had already been reset? i know we have `alterisrmanager.clearpending`, but that only removes the partition from the unsent queue. how do we handle inflight `alterisr` requests after the state has been reset. seems like it might be worth adding a check here to validate whether the request is still needed.",0,0.982550323009491
494520245,9100,mumrah,2020-09-24T18:21:33Z,"i was trying to think some kind of race with a zombie leader trying to update the isr, however this would get fenced by the leader epoch. this should be pretty easy to add",0,0.9294793605804443
494523773,9100,mumrah,2020-09-24T18:26:13Z,"true, we could see a new isr from controller initiated changes via leaderandisr while our request is in-flight. we have a check for this on successful responses, but we should also check here. since our request failed, we don't have a leaderepoch to check against so i think the best we can do is see if `isrstate` is still pending before re-sending the request",0,0.9741382002830505
494660084,9100,hachikuji,2020-09-24T23:13:45Z,"nit (for follow-up): fix grammar ""since due""",0,0.9854726195335388
494660983,9100,hachikuji,2020-09-24T23:16:38Z,"nit: conventionally we prefer ""retriable""",0,0.9564562439918518
494661344,9100,hachikuji,2020-09-24T23:17:43Z,it might be worth mentioning that this could happen in the case of a retry after a successful update.,0,0.9818379878997803
494661583,9100,hachikuji,2020-09-24T23:18:19Z,nit: leave off parenthesis after `exception`,0,0.9856980443000793
99288458,2472,norwood,2017-02-03T07:44:06Z,should probably make this ` `,0,0.9772320985794067
99288467,2472,norwood,2017-02-03T07:44:07Z,if you are going to do this check then why not make `newtopics` a `set`? if we'd rather do this check here then we can use `collection` instead,0,0.9854545593261719
99288478,2472,norwood,2017-02-03T07:44:16Z,should include a `listtopics` that takes a `collection ` of topics to query,0,0.9837073683738708
99288485,2472,norwood,2017-02-03T07:44:20Z,is it possible that this masks errors in `partitionmetadata`? e.g. if we have a topic level error and an error on a specific partition.,0,0.9803871512413025
99406097,2472,cmccabe,2017-02-03T19:30:13Z,agree,0,0.9757640957832336
99406308,2472,cmccabe,2017-02-03T19:31:20Z,i didn't make it a set because i didn't want to have to worry about hashcode and equals. i think you're right; it should just be a collection.,0,0.9097220301628113
99406744,2472,cmccabe,2017-02-03T19:33:33Z,"hmm, i'm not sure i follow. all the errors in the rpc response are faithfully reproduced in the return values... what else can we do to improve it?",0,0.8791912198066711
99407725,2472,norwood,2017-02-03T19:38:50Z,"you have a `continue` in this block. my question is related to if you end up with a `topicmetadata` that looks like: [code block] also, in writing this up, i realize that in line 487 you are checking `topic.error()` instead of `partition.error()`",0,0.9784824252128601
99410119,2472,cmccabe,2017-02-03T19:51:06Z,i added a function which allows you to get information for one topic,0,0.9691847562789917
99687358,2472,norwood,2017-02-06T21:23:13Z,"i still really think that we should have a `listtopics(set topics, enumset flags)`, e.g. one thing i've had to do is write code that is basically waits until i have seen our topics replicated/etc. it would be nice to not have to get all if i dont have to, and also nice to batch for me :) sample code [code block]",1,0.8893014192581177
112326031,2472,ijuma,2017-04-19T22:10:04Z,"this package doesn't currently contain public api classes. if we want `clients` to be a public package, we need to move all the classes that are there at the moment to `clients.internals`.",0,0.9882118105888367
112326124,2472,ijuma,2017-04-19T22:10:41Z,"as per our conversation today, maybe we should say that this will implement `completionstage` once we require java 8. also, i think we should just expose an interface to users and have the implementation under an internal package. we can then only expose methods that users should use (`complete` and `completeexceptionally` should never be used by users, for example).",0,0.9850127696990967
112326754,2472,ijuma,2017-04-19T22:14:38Z,we need to complete this.,0,0.96319180727005
112326863,2472,ijuma,2017-04-19T22:15:23Z,is it intentional that we mention `kafkaadminclient` here? the idea behind a `create` method like this is to avoid mentioning an implementation.,0,0.965370237827301
112327164,2472,ijuma,2017-04-19T22:17:26Z,we should flesh out the documentation for these methods. important details about what success means should be mentioned (in the same way we did for `deletetopics`).,0,0.9807557463645935
112327310,2472,ijuma,2017-04-19T22:18:30Z,i think this is unused.,0,0.86815345287323
112327572,2472,ijuma,2017-04-19T22:20:22Z,this default doesn't seem to make sense for the `adminclient`.,0,0.8561297059059143
112327616,2472,ijuma,2017-04-19T22:20:39Z,i wonder if we should be sharing these values in `commonclientconfigs`.,0,0.819536566734314
112327840,2472,ijuma,2017-04-19T22:22:20Z,seems like we sometimes have a constant field for `doc` and sometimes we don't. we should choose a pattern and stick to it.,0,0.9705826640129089
112328054,2472,ijuma,2017-04-19T22:23:49Z,i wonder if we should be using such magic values for public classes. it that using `null` to indicate an unset value is a bit safer and there's some indication by the type system.,0,0.7714252471923828
112328352,2472,ijuma,2017-04-19T22:24:42Z,we can use a rule to avoid repeating this in every test? same for other tests.,0,0.9863399267196655
112328439,2472,ijuma,2017-04-19T22:25:29Z,we typically use `*integrationtest` to indicate integration tests and simply `*test` for unit tests.,0,0.9881515502929688
112328490,2472,ijuma,2017-04-19T22:25:50Z,nit: this method seems unnecessary.,0,0.5755233764648438
112328573,2472,ijuma,2017-04-19T22:26:23Z,we can use `testutils.waituntiltrue` to simplify this a little?,0,0.9879574179649353
112328632,2472,ijuma,2017-04-19T22:26:50Z,this is not a junit assert method.,0,0.9637871980667114
112328873,2472,ijuma,2017-04-19T22:28:16Z,i was thinking we should put this class in an `internals` package.,0,0.9851962327957153
112329026,2472,ijuma,2017-04-19T22:29:20Z,this block formatting is a bit weird and we don't usually use it in kafka.,-1,0.981916069984436
112329873,2472,ijuma,2017-04-19T22:35:14Z,we close the selector in `networkclient` and `channelbuilder` in the `selector`. do we really need to close them separately?,0,0.9883318543434143
112336265,2472,cmccabe,2017-04-19T23:22:51Z,"yeah, implementing `completionstage` is probably a good idea, once we have jdk8 support. i don't see what's so bad about users calling `complete` or `completeexceptionally`. it just means that if the `kafkaadminclient` attempts to call those methods, the future will already be completed and it will have no effect. that seems pretty harmless?",-1,0.5797914862632751
112336354,2472,cmccabe,2017-04-19T23:23:32Z,"oops, let me replace that with something descriptive.",-1,0.9133602976799011
112336940,2472,cmccabe,2017-04-19T23:28:12Z,"ok, i will remove the reference to `kafkaadminclient`.",0,0.9857020378112793
112337328,2472,cmccabe,2017-04-19T23:31:36Z,it's used by the metadata object. although the rate-limiting is not implemented by the adminclient for normal requests yet.,0,0.9890811443328857
112337741,2472,cmccabe,2017-04-19T23:35:00Z,"ok. i suppose i'll just have the constant, then, even if it just maps back to `commonclientconfigs`.",0,0.9861002564430237
112338241,2472,ijuma,2017-04-19T23:38:55Z,those methods are racy and that's why they are not present in completionstage or scala futures. is there a use case where it's useful for users to call these methods? the scenario you outlined does not seem harmless since it seems like a clear user error to cause the adminclient values to be ignored.,0,0.7671640515327454
112338335,2472,cmccabe,2017-04-19T23:39:46Z,"i agree that the text doesn't make sense, since we don't care about `max.poll.ms` here. i'll set 2 minutes (a high default is good here to avoid test failures and so forth.)",0,0.9104877710342407
112338407,2472,ijuma,2017-04-19T23:40:18Z,i'm referring to the doc field...,0,0.9490736126899719
112338643,2472,cmccabe,2017-04-19T23:41:58Z,"i'm not sure there's a huge amount of utility in sharing this particular config value with the producer and consumer-- it is a different application, after all. we should probably shorten the idle time a bit",0,0.749880313873291
112339193,2472,cmccabe,2017-04-19T23:47:10Z,fair enough. i'll change it to use integer.,0,0.9631059765815735
112340310,2472,cmccabe,2017-04-19T23:57:41Z,"that seems like a lot of churn. does it make sense to do it in a separate jira, either beforehand or after this one?",-1,0.5467761754989624
112340400,2472,cmccabe,2017-04-19T23:58:33Z,"hmm, you mean the javadoc indentation?",0,0.9811883568763733
112340956,2472,cmccabe,2017-04-20T00:03:32Z,"i didn't realize that networkclient closed the selector... but i looked at the code again, and indeed it does. so we don't need to worry about that in `kafkaadminclient#close`. however, we do need to handle the case where the various constructors throw exceptions (pretty much all of them can.) for example, the selector constructor could fail and leave our channelbuilder dangling, and etc.",0,0.9715626835823059
112358759,2472,cmccabe,2017-04-20T03:26:35Z,i removed the tracking of the selector in kafkaadminclient. i kept the close in the factory function so that error handling is bulletproof...,0,0.7639186978340149
112358902,2472,cmccabe,2017-04-20T03:28:22Z,"hmm, retry_backoff_ms_doc is used later down... unless i'm looking at the wrong thing...",-1,0.5132030248641968
112359050,2472,cmccabe,2017-04-20T03:30:11Z,"so, the unfortunate thing about moving this into a separate namespace is that it means a bunch of other methods need to be public. the api surface and potential for api breaks increases a lot because stuff like constructors for all the public helper classes kafkaadminclient uses needs to be public. java doesn't yet have any concept of package-private like scala does. i wonder if it might be better to just put an annotation or comment saying that kafkaadminclient is public on the class.",-1,0.9762446880340576
112362257,2472,cmccabe,2017-04-20T04:10:56Z,"one use-case i can think of is cancelling a future. in `completablefuture` this is essentially equivalent to a call to `completablefuture#completeexceptionally(new cancellationexception(...))` cancellation isn't an optional operation for us since it's part of java's original `java.util.concurrent.future` api, which we need to implement. i agree that it's a bit nicer conceptually to separate the ""listen for stuff happening"" api from the ""signal that stuff has happened"" api. it makes sense that scala did this with `scala.concurrent.future`. java's `completablefuture` muddies the waters a bit by combining them into one concrete class. i don't know if this is something that is really likely to trip users up, though...",0,0.8301019668579102
112444553,2472,ijuma,2017-04-20T12:54:01Z,"yes, we should do the move separately if we think making `clients` public is the way forward (instead of having a separate package for shared classes). this class doesn't seem specific to `clients` though so maybe we should move it to `common`?",0,0.9862332344055176
112444774,2472,ijuma,2017-04-20T12:55:05Z,"`cancel` is exposed via the `future` interface, so it doesn't seem like we need to expose `completeexceptionally` even if we use it internally for that?",0,0.9707642793655396
112445364,2472,ijuma,2017-04-20T12:57:48Z,i wonder if there's a better name for this than `kafkafuture`. can't think of anything that's not already taken. but maybe you have some ideas. :),1,0.9713843464851379
112445599,2472,ijuma,2017-04-20T12:59:03Z,we should probably make these interfaces and move them to top level in their own package. maybe `clients.function` or `common.function` (java uses `java.util.functions`).,0,0.9881033301353455
112446037,2472,ijuma,2017-04-20T13:01:08Z,"nit: make this final. also, it seems like not all tests have been updated to use rule.",0,0.9718620777130127
112446276,2472,ijuma,2017-04-20T13:02:18Z,"if we want `vals` to always have two values, then we should just make the method take two parameters?",0,0.9855067729949951
112446649,2472,ijuma,2017-04-20T13:04:07Z,"hmm, not sure about this. can we not avoid using reflection for this?",0,0.7031117677688599
112447470,2472,ijuma,2017-04-20T13:07:59Z,"i think that was changed in a subsequent commit. before the define was doing `commonclientconfigs.retry_backoff_ms_doc`. on that point, it makes it harder to review if history is rewritten (i.e. additional changes are squashed into the existing commit). i have no way to tell what changed. :) can you please just add separate commits instead?",1,0.9580721855163574
112449184,2472,ijuma,2017-04-20T13:15:17Z,yes. there is huge amounts of whitespace. i suspect it's that way because there's an attempt at having alignment across all methods. but the value of that doesn't seem worth it.,-1,0.545701801776886
112449330,2472,ijuma,2017-04-20T13:15:50Z,nit: remove `get` from this and other similar methods.,0,0.979001522064209
112449528,2472,ijuma,2017-04-20T13:16:44Z,"why not use `utils.closequietly`? we can change the signature to take an `autocloseable` instead of `closeable`, if that's the issue.",0,0.9867122173309326
112449930,2472,ijuma,2017-04-20T13:18:35Z,"hmm, we should probably have a config for metric reporters and add the jmxreporter by default like other clients.",0,0.9859311580657959
112450736,2472,ijuma,2017-04-20T13:22:13Z,should this be `admin-client`? or is the idea that the prefix should be whatever comes before the first `-`?,0,0.98673415184021
112451618,2472,ijuma,2017-04-20T13:24:26Z,we should probably use `kafkathread` here. naming convention should be consistent with other client threads. for the producer we do: [code block],0,0.9867788553237915
112452024,2472,ijuma,2017-04-20T13:26:06Z,"generally, it's good to have consistent terminology to avoid confusion. the kafka code typically just says `requests` instead of `rpcs`.",0,0.9082444906234741
112453789,2472,ijuma,2017-04-20T13:33:24Z,"starting a new comment thread about the closing we do here since github is not allowing me to add a comment to the existing one. since this is an issue for all clients, maybe we should ensure that the constructors close things in case of exceptions in the constructor?",0,0.9856408834457397
112491693,2472,cmccabe,2017-04-20T15:57:23Z,"yeah, i'll just add separate commits",0,0.9871279001235962
112514535,2472,cmccabe,2017-04-20T17:36:00Z,i moved it to `org.apache.kafka.common`.,0,0.986026406288147
112514652,2472,cmccabe,2017-04-20T17:36:22Z,"ok, i have split them. we'll see how this looks.",0,0.9774919152259827
112516162,2472,cmccabe,2017-04-20T17:41:01Z,"hmm, i'm not sure if there's anything better. i think `kafkafuture` is short and clearly expresses the concept that it's our `future` class.",0,0.5923675298690796
112516461,2472,cmccabe,2017-04-20T17:42:30Z,"well, they are abstract classes so that we can add more methods without breaking compatibility in java 7. remember that user code has to implement these. as to making them top-level... i'm not sure. they are stopgap classes until we can use the real classes from java 8...",0,0.877094030380249
112517345,2472,cmccabe,2017-04-20T17:46:35Z,"it's not that it always has two parameters, it is that it always has an even number of parameters. it's used to create a map from key1, value1, key2, value2, key3, value3, ...",0,0.9674721956253052
112520218,2472,cmccabe,2017-04-20T17:58:35Z,"i don't feel strongly about it either way. it gets used in selector.java to build the metric group name as follows: `string metricgrpname = metricgrpprefix + ""-metrics"";` i'm not aware of any convention that says we can't have a hyphen here, so i guess i'll put it in...",-1,0.9128718972206116
112523477,2472,cmccabe,2017-04-20T18:12:15Z,"ok, i'll reduce the indentation where i can.",0,0.9850971102714539
112527847,2472,cmccabe,2017-04-20T18:29:54Z,"the constructor is private and can't be called from outside this class. even the create methods are package-private and only used by the public interface in adminclient and by unit tests. putting a lot of logic in the constructor doesn't work very well because the logic needs to be different for the unit tests (which don't use networkclient, selector, or channelbuilder, for example)",0,0.9462372660636902
112655250,2472,ijuma,2017-04-21T10:02:07Z,seems better to update the `import-control.xml` file.,0,0.9859234094619751
112972103,2472,ijuma,2017-04-24T15:07:55Z,"will we eventually retry the request, return an error to the user or something else?",0,0.9743372201919556
113934868,2472,ijuma,2017-04-28T13:52:13Z,we should add a class comment stating that this tests the internal scala adminclient that will be replaced by the java one eventually.,0,0.9887176752090454
113935275,2472,ijuma,2017-04-28T13:53:58Z,this should probably use `messagewithfallback`.,0,0.9885101914405823
113943073,2472,ijuma,2017-04-28T14:29:05Z,nit: `public` not needed.,0,0.9848511815071106
113943764,2472,ijuma,2017-04-28T14:31:56Z,"hmm, should we not just throw an error here? something would have to be very wrong for this to happen.",-1,0.6361525654792786
113944479,2472,ijuma,2017-04-28T14:35:12Z,this seems more informative than what's in the abstract class.,0,0.9678796529769897
113944854,2472,ijuma,2017-04-28T14:36:56Z,nit: `!isempty` instead of `length() > 0`.,0,0.9711079001426697
113945142,2472,ijuma,2017-04-28T14:38:14Z,this comment doesn't seem accurate.,-1,0.8209608197212219
113948024,2472,ijuma,2017-04-28T14:49:27Z,`commonclientconfigs.metrics_num_samples_doc` should just be `metrics_num_samples_doc`.,0,0.9875642657279968
113948175,2472,ijuma,2017-04-28T14:50:05Z,we should either do this for all of the configs or none.,0,0.985054612159729
113948212,2472,ijuma,2017-04-28T14:50:15Z,the doc configs should be private.,0,0.9866607189178467
113948629,2472,ijuma,2017-04-28T14:52:01Z,seems like we're missing `metrics_recording_level_config`.,0,0.946010172367096
113950116,2472,ijuma,2017-04-28T14:58:27Z,the consumer default is 64k while the producer default is 32k. was it intentional that you picked the same default as the producer?,0,0.9796767830848694
113950557,2472,ijuma,2017-04-28T15:00:27Z,this comment needs to be updated since you reduced the max_idle value to 5 minutes.,0,0.9855700135231018
113965338,2472,ijuma,2017-04-28T16:08:22Z,do we need something like the producer's `max_request_size_config` or are we ok to just rely on the broker if someone creates a batch that is too large somehow?,0,0.9746924638748169
113967006,2472,ijuma,2017-04-28T16:16:37Z,nit: maybe this should simply be `testclose()`?,0,0.9856885671615601
113967166,2472,ijuma,2017-04-28T16:17:33Z,seems like we always create an adminclient and close it at the end. maybe we can do that in `setup` and `teardown`? that way we don't leak resources if the test fails.,0,0.9788292646408081
113967578,2472,ijuma,2017-04-28T16:19:43Z,"it would be good to run these tests with security enabled. maybe a variant with sasl_ssl would do the job. it's reasonably straightforward, see `saslsslconsumertest`.",0,0.9552930593490601
113970289,2472,ijuma,2017-04-28T16:34:24Z,"oh, the result type of `createtopic` and `createtopics` is the same? that makes the non batch method less useful, no? may as well let the user use `collections.singleton` (with a static import)`.",0,0.9877519607543945
114015243,2472,cmccabe,2017-04-28T20:39:23Z,"since `kafkafuture#completedfuture` returns a completed future, we need access to the `kafkafutureimpl#complete` method. normally, `org.apache.kafka.common.kafkafuture` accessing `org.apache.kafka.common.internal.kafkafuture` would be blocked. this exception allows it to be called.",0,0.9881161451339722
114015511,2472,cmccabe,2017-04-28T20:41:00Z,"hmm. i was following the example of `producer.java`, whose javadoc has a link to `kafkaproducer.java`. i will add a little more javadoc to the `adminclient.java` class, though.",0,0.9821634292602539
114016199,2472,cmccabe,2017-04-28T20:45:37Z,"we don't know what request the response corresponds to, because its correlation id is invalid. of course, requests that don't receive a response will time out after enough time.",0,0.9220088720321655
114016438,2472,cmccabe,2017-04-28T20:47:06Z,"it's kind of awkward because other futures might have been completed successfully at this point. assuming that there is a bug where the server is responding with an incorrect topic name, this will be caught by means of the sanity check at the bottom that fails futures which haven't been completed by the response.",-1,0.9062355160713196
114022797,2472,cmccabe,2017-04-28T21:26:19Z,"i didn't think about it that much. i suppose 64k might be a better default, though, since some messages have large responses (larger than those the producer normally gets, at least).",0,0.9681336283683777
114023074,2472,cmccabe,2017-04-28T21:28:06Z,i don't think that we need a config like that here. the size of messages should come naturally out of the batch size which the client chooses. the rpc system will catch it if it gets too big (although there are probably other performance problems when admin requests get that big).,0,0.9774616360664368
114024595,2472,cmccabe,2017-04-28T21:38:18Z,good idea. i will add a close to an cleanup function.,1,0.9538825154304504
114024764,2472,cmccabe,2017-04-28T21:39:29Z,let's revisit this later once we have more experience with use-cases,0,0.9800278544425964
114024818,2472,cmccabe,2017-04-28T21:39:54Z,i updated this to 64k.,0,0.9849914908409119
114025089,2472,cmccabe,2017-04-28T21:41:54Z,good idea. i added some javadoc here and also on the scala adminclient with that info,1,0.980998694896698
114025911,2472,cmccabe,2017-04-28T21:47:28Z,"hmm, good catch. i think it makes more sense to add the fallback logic into `errors#exception`, though. if null is passed to that method, it should return an exception with the default message for that error code.",1,0.9685271382331848
114026050,2472,cmccabe,2017-04-28T21:48:31Z,"note: i did add an entry to the `import-control.xml` for the `org.apache.kafka.clients.admin` namespace, which was previously missing. that entry is useful for allowing imports between classes in the same package. but it doesn't affect this issue in `org.apache.kafka.common`.",0,0.9844909310340881
114029206,2472,ijuma,2017-04-28T22:13:01Z,"when is later though, the feature freeze is pretty soon. as you know, in api design, adding methods is easy, removing them is hard. our experience so far in the consumer is that the batch version is enough so it seems to make sense to start that way. also, are we adding the unstable annotation to this class?",0,0.9425422549247742
114029207,2472,ijuma,2017-04-28T22:13:02Z,"when is later though, the feature freeze is pretty soon. as you know, in api design, adding methods is easy, removing them is hard. our experience so far in the consumer is that the batch version is enough so it seems to make sense to start that way. also, are we adding the unstable annotation to this class?",0,0.9425422549247742
114037965,2472,cmccabe,2017-04-28T23:48:49Z,"i suppose it is easier to add new methods than to remove them. i will remove the singular methods for now, and add the \ annotation to the api classes.",0,0.986384928226471
114044708,2472,ijuma,2017-04-29T03:06:43Z,"we should just allow `common` to access `common.internals`, there's no good reason not to allow that. it's a simple addition: in general, `import-control.xml` is the right place to make these changes, i don't think we should be using suppressions for this.",0,0.9525067806243896
114044716,2472,ijuma,2017-04-29T03:08:18Z,"`producer` and `consumer` are a bit weird because the implementation classes are what people typically use (due to the constructor). for the adminclient, the abstract class is what people will be exposed to most probably.",-1,0.9448860883712769
114044732,2472,ijuma,2017-04-29T03:09:21Z,i would have thought that we would fail all the requests for that connection.,0,0.7399518489837646
387427500,8218,mjsax,2020-03-04T03:11:27Z,"this is not really relevant for this pr, but we need to add it for kip-447 eventually, thus i just include it in this pr.",0,0.9843435287475586
387427638,8218,mjsax,2020-03-04T03:12:04Z,we moved this to `taskmanager`,0,0.9879264831542969
387427823,8218,mjsax,2020-03-04T03:12:59Z,"on `suspend()` and `preparecommit()` we don't commit yet, but return the offsets that need to be committed",0,0.987381637096405
387427911,8218,mjsax,2020-03-04T03:13:24Z,we don't commit and thus don't throw any longer,0,0.6027746200561523
387428416,8218,mjsax,2020-03-04T03:15:41Z,"frankly, not sure if this is correct any longer. what do we want to record with this sensor exactly? flushing can be expensive and we might want to record it as part of committing -- but i am not sure.",0,0.5072399973869324
387428786,8218,mjsax,2020-03-04T03:17:11Z,"i am not happy with this rewrite (but as i know that john did some changes in this class in another pr, i just did this hack her for now -- needs some cleanup after a rebase)",-1,0.9845015406608582
387429067,8218,mjsax,2020-03-04T03:18:27Z,"we could also do a second loop over all tasks, _after_ calling `commit(..)` below -- not sure if this is ok as-is?",0,0.9875476360321045
387430556,8218,mjsax,2020-03-04T03:25:43Z,moved both tests to `taskmanagertest`,0,0.9879675507545471
387430633,8218,mjsax,2020-03-04T03:26:02Z,move all 4 tests to `taskmanagertest`,0,0.9869836568832397
387983590,8218,abbccdda,2020-03-04T22:54:42Z,did you already update the kip for the new config?,0,0.9883081316947937
387984270,8218,abbccdda,2020-03-04T22:56:19Z,what's the benefit of building this as a static helper?,0,0.9774238467216492
387994001,8218,mjsax,2020-03-04T23:23:13Z,we need to allow committing in `suspended` state now as we first suspend all tasks and than commit. cf. `taskmanager#handlerevocation()`,0,0.9876518249511719
387994269,8218,mjsax,2020-03-04T23:23:59Z,minor improvement: we include writing the checkpoint and the caller can indicate if it should be written or not.,0,0.9804728627204895
387994697,8218,mjsax,2020-03-04T23:25:15Z,this issues was introduced in the pr that introduced `streamsproducer` -- we forgot to close them. fixing this on the side.,0,0.9854729771614075
387995044,8218,mjsax,2020-03-04T23:26:10Z,"we call `closeclean` below -- just fixing the comment here for now (\cc ) note that we don't commit offsets for this case any longer -- previously, committing offsets ""might"" have been done with `closeclean()` (even if i believe that the task would be marked as ""commitneeded == false""). we don't let the taskmanager commit offsets here, as it should not be required.",0,0.9823855757713318
387995875,8218,mjsax,2020-03-04T23:28:26Z,similar to above: this issue was introduced in the `streamsproducer` pr. we nee to close the producer when we remove it.,0,0.9882530570030212
387995961,8218,mjsax,2020-03-04T23:28:44Z,as above,0,0.9783914685249329
387996132,8218,mjsax,2020-03-04T23:29:16Z,not sure why we use an iterator here. simplifying the code with a `for`-loop,0,0.9012576341629028
387996797,8218,mjsax,2020-03-04T23:31:16Z,"we need to commit explicitly in ttd now to mimic the taskmanger. hence, we need access to the `consumer` and `streamsproducer`",0,0.987177848815918
388015857,8218,abbccdda,2020-03-05T00:33:39Z,why do we start to suppress warnings?,0,0.9096230268478394
388016523,8218,abbccdda,2020-03-05T00:35:52Z,"sounds good, just mark that depending on john's fix, we probably don't need to handle this.",0,0.5978871583938599
388018015,8218,abbccdda,2020-03-05T00:41:10Z,add a comment describing the new return statement.,0,0.9842872619628906
388019423,8218,abbccdda,2020-03-05T00:45:58Z,i would prefer a second loop to guarantee a consistent reflection on the task committed state.,0,0.9787614345550537
388019820,8218,abbccdda,2020-03-05T00:47:32Z,"in eos beta, we should be able to send out a batch commit instead of individual ones?",0,0.9886466860771179
388022132,8218,abbccdda,2020-03-05T00:55:25Z,i don't think we need to test `assertfalse(task.commitneeded()` as its outcome is controlled by `task.markcommitted`. so we only need to do it once.,0,0.9867311716079712
388022419,8218,abbccdda,2020-03-05T00:56:24Z,why do we no longer have the mock verification?,0,0.881838321685791
388026690,8218,abbccdda,2020-03-05T01:11:22Z,should we do `expectlastcall` here?,0,0.9866053462028503
388028665,8218,abbccdda,2020-03-05T01:18:20Z,we should also verify the thrown cause,0,0.9848848581314087
388028820,8218,abbccdda,2020-03-05T01:18:46Z,"same here, for verifying the thrown cause",0,0.9868757724761963
388029164,8218,abbccdda,2020-03-05T01:20:06Z,"what's the reasoning her for only wrapping the consumer offset commit case here, not for eos case?",0,0.9701959490776062
388029471,8218,abbccdda,2020-03-05T01:21:10Z,always feels better for one less parameter :),1,0.9662256836891174
388029958,8218,abbccdda,2020-03-05T01:22:58Z,makes sense to me.,0,0.9610221982002258
388030250,8218,abbccdda,2020-03-05T01:23:57Z,checkmark for proving the 6 tests are all migrated.,0,0.9896211624145508
388030837,8218,abbccdda,2020-03-05T01:25:58Z,probably need to change after rebase,0,0.9788737297058105
389051551,8218,mjsax,2020-03-06T17:50:27Z,"we should have done this from the beginning on... (it's just a ""side fix"")",0,0.7882558703422546
389052130,8218,mjsax,2020-03-06T17:51:29Z,we will need this later (ie follow up pr) and it reduced code duplication,0,0.9837733507156372
389052956,8218,mjsax,2020-03-06T17:53:26Z,correct. unifying the commit logic as done is this pr allows us to do this in a follow up pr that actually enable producer per thread -- the whole purpose of this pr is to prepare/refactor for this.,0,0.9832693338394165
389053599,8218,mjsax,2020-03-06T17:54:52Z,"you mean exception handling? for the producer all exception handling is done within `streamsproducer` (note that `threadproducer` above is a `streamsproducer`, not a `kafkaproducer`)",0,0.9894709587097168
389054695,8218,mjsax,2020-03-06T17:57:11Z,"we remove `recordcollector#commit()` method in this pr and thus we remove the expected call to commit at the beginning of this test -- thus, there is nothing to be verified any longer and we don't call `commit()` with `preparecommit()` any longer.",0,0.9842283725738525
390712211,8218,mjsax,2020-03-11T02:20:42Z,"this is an open question: we don't want to remove this sensor however it was unclear to me how to handle this metric after we split ""task committing"" into three steps (preparecommit; taskmanager#commit; postcommit).",0,0.9733144640922546
390712571,8218,mjsax,2020-03-11T02:22:13Z,simplification to avoid passing in `eosenabled` and reducing constructor parameter list -- we just piggy back on the `application.id` that shall be `null` for non-eos.,0,0.9846989512443542
390712665,8218,mjsax,2020-03-11T02:22:35Z,avoid redundant logging.,0,0.9543545842170715
390712770,8218,mjsax,2020-03-11T02:23:06Z,side cleanup: all those method can actually be package private.,0,0.9899256229400635
390712971,8218,mjsax,2020-03-11T02:23:55Z,removing this state -- this is an open question if i did this correctly. \cc,0,0.9641351103782654
390714027,8218,mjsax,2020-03-11T02:27:59Z,"after we addressed the question how we want to do metrics, we can update this tests",0,0.9842516779899597
390714488,8218,mjsax,2020-03-11T02:29:59Z,because we make app method in `streamsproducer` package private but need access to `commit()` we add `testdriverproducer` to get access.,0,0.9892739653587341
390714741,8218,mjsax,2020-03-11T02:31:09Z,just added to give public access to `committransaction()` to ttd (it's more elegant than making `streamsproducer#committransaction` public imho),0,0.9852074384689331
390727409,8218,abbccdda,2020-03-11T03:27:07Z,nit: we could log thread-id here for easier log search.,0,0.9846135377883911
391162808,8218,vvcephei,2020-03-11T18:01:56Z,"it seems a bit roundabout to have to remember we should send a `null` `application.id` as the constructor argument to indicate that eos is enabled. what's wrong with saying ""eos is enabled"" when you want eos to be enabled?",-1,0.6593452095985413
391233773,8218,abbccdda,2020-03-11T20:05:06Z,could we internalize this state check inside the task to simplify the logic here?,0,0.986973226070404
391234248,8218,abbccdda,2020-03-11T20:05:36Z,"similarly here, this state check could be internalized.",0,0.9887987971305847
391236509,8218,abbccdda,2020-03-11T20:07:57Z,nit: let's order the functions as [code block],0,0.9874258041381836
391237078,8218,abbccdda,2020-03-11T20:08:36Z,prepare to uncleanly close a task that we may not own.,-1,0.7097476124763489
391241528,8218,abbccdda,2020-03-11T20:13:52Z,"having a `prepareclosedirty` makes the calling of `closedirty` a bit cumbersome as we always need to call `prepareclosedirty` first. to simplify or just do a reminder, i have two suggestions: 1. internally create a task state called prepare_close or just a boolean like `closedirtyprepared` as the state check, so that closedirty will throw illegal state if the flag is false 2. following #1, instead of throw, if we don't see the prepareclose is being called, the `closedirty` will invoke `prepareclosedirty` first internally.",0,0.9483925700187683
391243910,8218,abbccdda,2020-03-11T20:17:03Z,"for my own education, why we do `and` here instead of just checking `commitrequested`?",0,0.9768220782279968
391244729,8218,abbccdda,2020-03-11T20:18:43Z,:thumbs_up:,0,0.8380307555198669
391260243,8218,abbccdda,2020-03-11T20:50:44Z,"comment here for no better place: standby task always returns an empty `committableoffsetsandmetadata`, then why do we still need to check `commitneeded` for it? shouldn't it always set to false?",0,0.7801733613014221
391261158,8218,abbccdda,2020-03-11T20:52:34Z,`logcontext ` is not used.,0,0.9749168753623962
391261929,8218,abbccdda,2020-03-11T20:54:06Z,should we attempt to add more fine-grained metrics for 3 stages then?,0,0.980660617351532
391265711,8218,abbccdda,2020-03-11T21:01:37Z,could we add a `` for this method? also we should comment about the different indications when we return an empty map vs null.,0,0.9887802600860596
391267109,8218,abbccdda,2020-03-11T21:04:39Z,remove `if`,0,0.9814930558204651
391286988,8218,abbccdda,2020-03-11T21:47:16Z,i feel a bit weird here as we don't need `preparecloseclean` anymore. this api usage is a little complicated upon when we should do it and we don't.,-1,0.9786288738250732
391287132,8218,abbccdda,2020-03-11T21:47:37Z,similarly for `closedirty` and `prepareclosedirty`,0,0.9842423796653748
391289786,8218,abbccdda,2020-03-11T21:54:04Z,nit; 228 - 229 could be merged.,0,0.9826880097389221
391291102,8218,abbccdda,2020-03-11T21:57:16Z,"also the above step #4 is no longer correct, the commit is done on taskmanager now.",0,0.9882574677467346
391295221,8218,abbccdda,2020-03-11T22:08:20Z,do we need to keep a task once it is failed to clean close? why couldn't we just close it dirty immediately after we see the exception?,0,0.7935392260551453
391296895,8218,abbccdda,2020-03-11T22:11:16Z,why do we need to move these tests?,0,0.9582385420799255
391298785,8218,abbccdda,2020-03-11T22:13:39Z,looks like we lack test coverage for timeoutexception and kafkaexception cases,0,0.7798775434494019
391301678,8218,abbccdda,2020-03-11T22:17:34Z,we don't have unit test coverage for this exception case,0,0.9728329181671143
391302227,8218,abbccdda,2020-03-11T22:18:14Z,we lack unit test coverage for this case,0,0.9412830471992493
391303712,8218,abbccdda,2020-03-11T22:20:40Z,"could we verify the assignment stack and lost stack separately, by doing `handleassignment` verify first before calling `handlelost`",0,0.9894008040428162
391337786,8218,mjsax,2020-03-12T00:07:25Z,the `threadid` is already added to the log prefix when the `log` object is created in `streamsthread`,0,0.9879514575004578
391338238,8218,mjsax,2020-03-12T00:09:08Z,not sure if i can follow. we don't check `commitneeded` in `postcommit()`? can you elaborate?,0,0.9627604484558105
391338530,8218,mjsax,2020-03-12T00:10:18Z,"frankly, i have no good idea atm... also, if we change metrics, we need to update the kip and it's getting more complicated. if possible, i would prefer to not change any metric, but not sure if it is possible...",-1,0.9757645726203918
391338712,8218,mjsax,2020-03-12T00:10:57Z,"yeah, this pr does not yet add all required test...",0,0.9161561727523804
391339213,8218,mjsax,2020-03-12T00:13:04Z,"why do we need to document this in the method javadoc? it's an internal method? internal comment outdate quickly if code is changed and comments are not updated accordingly (what happens 99% of the time). hence, i would prefer to limit comments if possible. in doubt, we should document at `task` level anyway.",0,0.9806163311004639
391339463,8218,mjsax,2020-03-12T00:13:57Z,you see -- that is may point from above... the code should be written in a way that explains itself... updating comments always slips...,-1,0.6014992594718933
391340439,8218,mjsax,2020-03-12T00:17:53Z,i am actually wondering about point (5) -- why do we need to checkpoint the state manager if we wipe out the store later anyway for the unclean eos case?,0,0.6472905278205872
391342962,8218,mjsax,2020-03-12T00:28:08Z,"i actually had a similar though, but was not sure if it's worth it. would like to hear from what they think? if we do this, we might want to do it for ""commit"" and ""suspend"", too. for suspend() adding a state suspend_prepared is not helpful as suspend() does different things depending on the previous state. (for commit and close an additional state would work). for consistency reasons, an internal flag might be better though. not sure ate if calling ""prepare"" automatically would actually be correct for all cases?",0,0.9326582551002502
391344437,8218,mjsax,2020-03-12T00:33:24Z,"`preparecloseclean()` already does a state check and returns `emptymap` if state is `created`. the point of this check is, that we don't add anything to the `consumedoffsetsandmetadatapertask` map -- this is important for the corner case for which all tasks are in state created and thus no transaction was initialized. for this case we cannot call `producer.addoffsetstotranscation()` and must skip this step entirely. note, that we have a corresponding check below to not call `commitoffsetsortransaction` if the map is empty.",0,0.9810077548027039
391344863,8218,mjsax,2020-03-12T00:35:23Z,we need to call `preparecloseclean` (as done in l196 above) _before_ we call `commitoffsetsortransaction` (l215 above).,0,0.9891157746315002
391344936,8218,mjsax,2020-03-12T00:35:38Z,some comment as above.,0,0.9843559861183167
391344967,8218,mjsax,2020-03-12T00:35:44Z,i know...,0,0.9421771168708801
391345982,8218,mjsax,2020-03-12T00:40:13Z,"to avoid the overhead to commit offset that are already committed, ie, the previous commit committed offset 5 and now we would commit offset 5 again.",0,0.9875888228416443
391346285,8218,mjsax,2020-03-12T00:41:22Z,i think it's easier to read if it's split.,0,0.9663568139076233
391347114,8218,mjsax,2020-03-12T00:44:22Z,"i try to keep ""order"" and group test methods to keep an overview if test coverage is complete. [code block]",0,0.9836681485176086
391348100,8218,mjsax,2020-03-12T00:48:34Z,"not sure if i can follow? the comments just mark which setup calls belongs to which test call, nothing more. all setup is done upfront before we call the actually methods under test.",0,0.9738447666168213
391348586,8218,mjsax,2020-03-12T00:50:19Z,good catch.,1,0.9640093445777893
391361243,8218,mjsax,2020-03-12T01:47:39Z,good idea!,1,0.9889351725578308
391809790,8218,guozhangwang,2020-03-12T18:22:32Z,nit: add a check that taskid exists in `taskproducers` to make sure we do not return null.,0,0.9882302284240723
391812242,8218,guozhangwang,2020-03-12T18:27:10Z,subjectively i'd +1 that adding one more parameter to avoid piggy-backing on the applicationid is better.,0,0.9642822742462158
391829473,8218,guozhangwang,2020-03-12T18:59:20Z,"actually on a second thought, i'm wondering if the following inside taskmanager is cleaner: [code block] instead of: [code block] my gut feeling is that it is cleaner to not access the task creator for its created stream-producers (and hence here we need to change the task-producer map to streamsproducers), but just access each task's record collector and call its `commit` --- today we already have a `streamtask#recordcollector` method.",-1,0.6449413895606995
391829854,8218,guozhangwang,2020-03-12T19:00:10Z,"please see my other comment above --- i think it is cleaner to just call `foreach(active-task) task.recordcollector.commit` inside the task-manager; and inside recordcollectorimpl we check that eosenabled is always true, otherwise illegal-state thrown. in the next pr where we have the thread-producer, we could then only create a single `recordcollector` object that is shared among all active tasks and wraps the thread-producer, and then the caller `taskmanager` code then can just get one active task and call its record-collector's commit function knowing that is sufficient to actually commit for all tasks since everyone is using the same record-collector. wdyt?",0,0.9634127020835876
391838078,8218,guozhangwang,2020-03-12T19:16:48Z,"this is a meta comment: i think we can consolidate `preparecommit` and `prepareclose` and `preparesuspend` here by introducing the clean parameters to the function, since their logic are very similar (for the part that they diffs a bit, it can be pushed to post logic), and on task-manager during commit: 1) for each task -> task.preparecommit(true) 2) commit 3) for each task -> task.postcommit(true) during close: if (clean) 1) for each task -> task.preparecommit(true) 2) commit() 3) for each task -> task.postcommit(true) else 1) for each task -> task.preparecommit(false) // do not commit 3) for each task -> task.postcommit(false) 4) tasks.close(flag) and the same for suspension.",0,0.9707094430923462
391838707,8218,guozhangwang,2020-03-12T19:18:06Z,"i actually think that we can remove this debug-level per-task commit metrics, since we already have the info-level per-thread commit metric and this one does not provide much more additional information?",0,0.9865721464157104
391974508,8218,mjsax,2020-03-13T00:39:06Z,"i think it's unclean to let the recordcollector commit (note that this pr removes `recordcollector` not at side refactoring but on purpose) -- to me the recordcollector has the responsibility to bridge the gap between the runtime code (that is typed), and the producer that uses ` ` (ie, it serialized the data and manages errors from `send`) -- why would a **_collector_** know anything about committing (for which it also needs a handle to the consumer)? about accessing the `activetaskcreator`: we could also expose the `streamsproducer` via the `recordcollector` though (or directly via the task)? that would be cleaner i guess.",0,0.8900535702705383
391993410,8218,mjsax,2020-03-13T02:06:16Z,it's a personal preference i guess. but seems you don't like it. will revert it.,-1,0.9461419582366943
392017955,8218,guozhangwang,2020-03-13T03:50:05Z,"this is not introduced in this pr, but: while thinking about it, i realized for restoring state we do not need to rely on eosdisabled to checkpoint, in fact we can always checkpoint during restoring here.",0,0.9676091074943542
392783249,8218,mjsax,2020-03-16T04:59:42Z,will do this in a follow up pr.,0,0.9821309447288513
392783415,8218,mjsax,2020-03-16T05:00:28Z,ack,0,0.9720376133918762
392783859,8218,mjsax,2020-03-16T05:02:44Z,covered via `shouldcommitnextoffsetfromqueueifavailable` and `shouldcommitconsumerpositionifrecordqueueisempty`,0,0.9842460751533508
392784308,8218,mjsax,2020-03-16T05:05:18Z,we can address this in a follow up pr.,0,0.9871663451194763
392794910,8218,mjsax,2020-03-16T05:56:23Z,added test `shouldthrowwhenhandlingclosingtasksonproducercloseerror`,0,0.9866668581962585
393132558,8218,abbccdda,2020-03-16T16:00:20Z,we need a unit test for this function.,0,0.986417293548584
393136595,8218,abbccdda,2020-03-16T16:06:09Z,"we could just do one log in front: `log.info(""prepare suspending {}"", state());`",0,0.9854568839073181
393139575,8218,abbccdda,2020-03-16T16:10:32Z,do we have unit test to check the checkpoint status after `postcommit()`?,0,0.9888659119606018
393180380,8218,abbccdda,2020-03-16T17:06:41Z,"i couldn't fully follow this idea, just playing devil advocates here, if we think meta code comments actually hinder the readability of internal class, why not just remove all the internal function meta comments, as they would get outdated anyway? for me the return type comment is still valuable for understandability. if the comment gets outdated, we should just update it. cc if the idea here makes sense, or we could get a consensus on what needs to be done in internal class comments, and what's not.",-1,0.8410144448280334
393183310,8218,abbccdda,2020-03-16T17:11:13Z,nit: { could be reduced.,0,0.9769903421401978
393195455,8218,abbccdda,2020-03-16T17:31:51Z,"yea, a todo is also ok.",0,0.9602764248847961
393336160,8218,guozhangwang,2020-03-16T22:07:16Z,"`for the next pr` (all other comments with this tag means no changes required for this pr): my understanding is that we would make the thread-producer also a `streamsproducer` instead of a `kafkaproducer` which would be used to `committransaction` under `eosbeta`, is that right?",0,0.9835687279701233
393336618,8218,guozhangwang,2020-03-16T22:08:31Z,"nit: we can have a wrapped streamsproducer#close / metrics, and then #kafkaproducer would be for testing-only.",0,0.9876761436462402
393336934,8218,guozhangwang,2020-03-16T22:09:16Z,"after syncing offline about this, i think i'm convinced now that moving this logic into taskmanager is better.",0,0.9080342054367065
393339067,8218,guozhangwang,2020-03-16T22:14:56Z,"i think we should just let the preparexx function to return the map of partitions -> partition-timestamp to indicate if it should be included in the map of committing offsets, so that we do not need to leak the state into task-manager here. also we only need to call `mainconsumer.position` once for all tasks -- please see my other comment above. also: we should not try to commit state if we are in restoring but only flushing store and writing checkpoints (i think this is already the behavior in trunk), since the partitions are paused from the main-consumer before restoration is done --- maybe it is partly causing some unit test flakiness.",0,0.9814547896385193
393339213,8218,guozhangwang,2020-03-16T22:15:23Z,sg. i think in this pr we still can do the change to let `preparexx` to return the map of partitions -> partition-timestamp to indicate whether this task should be included in committing.,0,0.9846979379653931
393341972,8218,guozhangwang,2020-03-16T22:23:14Z,"in either eos-alpha or eos-beta or non-eos, we can just loop over all the ""committable partitions"" and call `mainconsumer#position` once, so this function can be extracted out of the task as a per-task call. more specifically, in the preparexx calls, we know based on the state of the task and clean flag whether or not we should commit the source topic offsets for this task, so we can let the preparexx function to return `map partitiontimes` encoding the extracted timestamps for each partition instead of void --- when we decided not to commit we return an empty map. and then inside taskmanager we just use the `mainconsumer` to call position once and then pass that to the `commitoffsetsortransaction` call.",0,0.9827340245246887
393344611,8218,guozhangwang,2020-03-16T22:28:40Z,nit: we can do `if / else if / else` here still and move the `closetasksensor.record(); / transitionto(state.closed);` to avoid duplication.,0,0.9890314936637878
393345037,8218,guozhangwang,2020-03-16T22:29:26Z,"ditto here, i think if / else if / else is more readable.",0,0.9396148324012756
393350516,8218,mjsax,2020-03-16T22:43:50Z,"well, we log ""skip"" for state created and we throw for invalid states. note sure how to do this?",0,0.987640917301178
393350827,8218,mjsax,2020-03-16T22:44:47Z,"yes, `shouldrespectcommitneeded()` check this already.",0,0.9872969388961792
393371781,8218,guozhangwang,2020-03-16T23:47:56Z,"`for the next pr`: as i mentioned in the last commit i feel `preparesuspend` and `prepareclose` can be consolidated with `preparecommit` but in the next pr these logic would be changed again for eos-beta so maybe we cannot do that any more, so i'm fine with keeping as-is and we can revisit to see if we can really do this refactoring or not in the next pr when we did the eos-beta.",0,0.9512625336647034
393373023,8218,guozhangwang,2020-03-16T23:52:01Z,yes we are unnecessarily checkpointing here --- the reason is that eos flag was original striped out of task and only processor-state-manager knows about it; now since we get this eos flag back to task (sigh.. :) we can add this additional check.,0,0.9457579255104065
393374466,8218,guozhangwang,2020-03-16T23:57:18Z,"i would suggest not restricting ourselves to some specific rules about comments :) personally i tried to avoid the `one line comment explaining one line code` type of comments inside a function since it should be obvious, rather i'd add some comments for a block or several blocks if i fear it maybe hard to read by itself. i think you guys should just make your best judgement here. and for internal functions, i agree that we do not necessarily need to write java-docs, and this one, for example, i wrote the java-doc as part of the tech debt cleanup just to remind what operations must be considered here inside closing / suspending etc so that later on when we change the function itself by other contributors, they would use it as a reference to check if they mistakenly missed some steps or re-ordered some steps. however if we are going to split this function into multiple, instead of just re-structuring the function as a whole, then although i have my preference i'd leave to you guys if you want to add the javadoc for both pre/post of you feel now it is too obvious to bother :)",1,0.9733171463012695
393377256,8218,guozhangwang,2020-03-17T00:07:51Z,"`for the next pr`: i see the reason i return the checkpoint is that we are now extracting the committing out of the task and i need to remember if we need to checkpoint and if yes which offsets after we've flushed and before we checkpoint, but since the state of the task would not change before / after the commit during close. more specifically we only have three cases: 1) to not write checkpoint, 2) write checkpoints for written offsets (changelogs) only, 3) write checkpoint for written and consumed offsets. and no matter which case it is during the `preclose`, it would always be the same in the `post`, so why do we need to return it to task-manager, book-keep there, and then after commit to pass it back to tasks?",0,0.9642925262451172
393378779,8218,guozhangwang,2020-03-17T00:14:27Z,nit: we should emphasize that prepareclose and close calls should be implemented idempotent since we may call it multiple times if a task close clean first and then fail and then close dirty.,0,0.9821707010269165
393384266,8218,guozhangwang,2020-03-17T00:37:48Z,"`for the next pr`: i think we can save prepareclose (or more accurately, merge prepareclose and close together again) if we make a state diagram change that only suspended state can transit to closed state, i.e. at task-manager level whenever we want to close a task we call its `suspend` function first, which would, depending on its state, be a no-op, or flushing, or closing topology etc, and then after that the task is always in suspended state, and then we call ""commit"" if necessary, and then we call close (a minor thing is that today when the state is in suspended we would omit committing inside task, and we need to lift this restriction; and also the transition actions to transit to suspended need to rely on the clean flag, hence we need `suspend(clean-flag)`). and we can further merge preparesuspend and suspend as well by just making the checkpointing logic as part of post-commit instead of post-suspend, since as i mentioned above you only have three cases: 1) do not need to checkpoint: if you are in created. 2) checkpoint written and consumed offsets: if you are in running, in which you need to commit offsets as well. 3) checkpoint only store offsets: if you are in restoring, and in which case you do not need to commit offsets. in fact, if we are not in the running state yet, the `consumedoffsets` as well as `recordcollector#offsets()` are always going to be empty, so it is always safe to call `statemgr.checkpoint(checkpointableoffsets())` and not condition on the state and call `statemgr.checkpoint(emptyset())`. and if we now allow committing in suspended state as part of closing (i.e. suspend -> commit -> close), similar rules apply: if we are suspending from a restoring state, then in `postcommit` while we ``statemgr.checkpoint(checkpointableoffsets())` the `checkpointableoffsets` would always be empty; if we are suspending from a running state it would contain some offsets.",0,0.970151960849762
393385438,8218,guozhangwang,2020-03-17T00:41:49Z,"see my other comments: we should not commit in created, restoring and suspended state, and it's better just to let the preparexx function to indicate if there's anything to commit based on its state internally than letting task-manager to branch on the task state -- more specifically, here the prepareclose call should not return the map of checkpoints but the map of partition -> partition-timestamps (if empty it means nothing to commit), since the checkpoint map are not needed at task-manager at all and post commit, if the offsets should be empty it would still be empty.",0,0.9845432639122009
393387491,8218,guozhangwang,2020-03-17T00:50:23Z,"same here: not only created, but also restoring and suspended tasks should not be included in `consumedoffsetsandmetadatapertask` and we should not let the task-manager to peek its state.",0,0.9824260473251343
393387840,8218,guozhangwang,2020-03-17T00:51:31Z,"""as above"" :)",1,0.8785417079925537
393389583,8218,mjsax,2020-03-17T00:58:53Z,correct. for eos-beta there will be one `streamsproducer` that is shared over all tasks.,0,0.985651969909668
393389903,8218,mjsax,2020-03-17T01:00:30Z,"we could, but the idea was that `activetaskcreator` creates the producer via `new kafkaproducer()` and thus it should call `kafkaproducer#close()`, too, and not delegate it to `streamsproducer`. thoughts?",0,0.9875218272209167
393392898,8218,mjsax,2020-03-17T01:12:55Z,"well, we can, but we get an empty ""than block"" what is weird: [code block]",-1,0.9847419261932373
393418010,8218,mjsax,2020-03-17T02:58:33Z,"within `maybecommitactivetasksperuserrequested` we know that we are in state `running` and thus, no need to check what `committableoffsetsandmetadata()` returns but we can ""blindly"" commit.",0,0.9874019026756287
393792511,8218,abbccdda,2020-03-17T16:05:29Z,"by `next pr`, you mean the one after we finish the eos-beta commit feature right?",0,0.9874332547187805
393884343,8218,guozhangwang,2020-03-17T18:25:59Z,i mean the next pr when we add the eos-beta feature --- please see the first comment i have with this tag.,0,0.9837649464607239
393885815,8218,guozhangwang,2020-03-17T18:28:21Z,"hmm, i think moving forward we would create and maintain both the single thread-producer and task-producers as streamsproducer objects right?",0,0.9805755615234375
393887170,8218,guozhangwang,2020-03-17T18:30:28Z,"i'd say we can always log a debug there saying ""doing nothing in this function since we are in this state"" :) the main concern i had, is that if in the future we want to add more steps in addition to `recording sensor` etc, we may forget adding it in one place or the other. removing duplicated code helps us to be less vulnerable.",1,0.7622175812721252
393898999,8218,mjsax,2020-03-17T18:50:49Z,sgtm,0,0.9783707857131958
393905732,8218,guozhangwang,2020-03-17T19:03:16Z,thanks for the cleanup!,1,0.9163866639137268
393906971,8218,guozhangwang,2020-03-17T19:05:38Z,why we have to transit to suspended before prepare-closing? originally we want to check that created state can still trigger close.,0,0.9825259447097778
393907754,8218,guozhangwang,2020-03-17T19:07:06Z,not introduced in this pr: could we add test checking closed state should not commit as well? also checking suspended state close-call is no-op.,0,0.9871784448623657
393911532,8218,guozhangwang,2020-03-17T19:14:37Z,"why making `committransaction` is less elegant? i thought that was fine since `streamsproducer` is inside the internals package anyways? in fact, in ttd we have access to internaltopologybuilder accessing it functions (we used to also have a wrapper of internaltopologybuilder which we removed later) so i thought that was the agreed pattern.",0,0.9789530038833618
393917156,8218,guozhangwang,2020-03-17T19:25:38Z,"this is a meta comment: since we moved the commit logic out of the tasks into task-manager already, we should add the check that: 1) inside the task manager, if the commit failed with fatal errors, the corresponding follow-up steps (postcommit, suspend, closeclean) should be skipped, and the exception is thrown out of the task-manager to thread 2) if commit failed with fenced errors, follow-up steps are also skipped (tasks state should be un-changed) and the task-migration exception is thrown out of the task-manager.",0,0.9840923547744751
393963708,8218,mjsax,2020-03-17T20:53:23Z,ack. we can remove this.,0,0.9629122018814087
393964723,8218,mjsax,2020-03-17T20:55:19Z,ack,0,0.9720376133918762
393966087,8218,mjsax,2020-03-17T20:57:46Z,but in `close()` if state is suspended we might still wipe out the state store -- it's not a no-op,0,0.9737715125083923
393968843,8218,mjsax,2020-03-17T21:03:00Z,"it's obviously subjective -- personally, even if something is internal, we should not just declare stuff as `public` but try to keep it to a minimum to follow the idea of encapsulation (not always possible). if you want me to remove this class and make the method `public` i can do it in a follow up pr. not sure if we have an agreed pattern, though.",0,0.7387288212776184
393979041,8218,guozhangwang,2020-03-17T21:23:47Z,"cool, in that sense let's just keep it then -- do not add it in one pr and remove it immediately in the next.",1,0.951740562915802
56714551,1095,granthenke,2016-03-18T20:05:32Z,"not sure if this is the best way to do this. i need a different constructor for requesting a `null` list because `null` matches both the list and struct constructors with the same ""specificity"". i am open to ideas for a better way to support requesting no topic metadata.",0,0.8038945198059082
56716409,1095,gwenshap,2016-03-18T20:20:17Z,"you mean other.rack? also, i'm wondering whether we want to consider a node to be a different node when the rack changed. i guess it depends on how it is used - except it isn't used...",0,0.919337272644043
56716786,1095,granthenke,2016-03-18T20:23:02Z,good catch. i just maintained equals meaning all fields match. i suspect thats the safest path to go right now.,1,0.9611923098564148
56717383,1095,gwenshap,2016-03-18T20:27:12Z,"i noticed you keep using broker_v0 anywhere except metadata, and i think thats the plan going forward as well. if my understanding is correct, broker_v1 is not really a ""newer"" broker definition (which implies that eventually we'll move everything to use that) but rather a broker definition specific for metadata request or just a more detailed broker definition. maybe rename to something less misleading?",0,0.9580872058868408
56717758,1095,gwenshap,2016-03-18T20:29:50Z,and on similar topic (but should be separate jira) - the protocol has few different places with broker definitions - maybe more consolidation is possible?,0,0.9860193729400635
56717859,1095,granthenke,2016-03-18T20:30:38Z,"yes, my understanding is these ""sub-schemas"" are supposed to tie directly to single api/protocol to allow them to change independently. i think the fact that a broker_v0 was shared was a mistake. i had left the old one being shared just to minimize change. i can break-out and rename a bit to prevent an accidental sharing in the future.",0,0.8870391845703125
56718714,1095,granthenke,2016-03-18T20:37:26Z,"i am of the impression that we are not consolidating so that the wire protocols can change independently. however, we want to represent that in java or scala object is up to the parser. this decouples protocol from implementation. though even in implementation we have chosen to duplicate in the past too.",0,0.9520553350448608
56768466,1095,ijuma,2016-03-20T17:47:15Z,would it make sense to use a bitset for these booleans?,0,0.982330322265625
56892437,1095,granthenke,2016-03-21T20:38:10Z,"yeah, that could save a byte for each topic. i will mention it during the wire protocol discussion on the next kip call, since this needs to be reviewed/voted.",0,0.9861297011375427
57952993,1095,hachikuji,2016-03-30T19:57:34Z,"i've been wondering if it would be better to use static factory methods instead of relying on constructors. in that case, you could use something like `metadatarequest.alltopics()` or something like that.",0,0.9755753874778748
57953330,1095,granthenke,2016-03-30T19:59:43Z,"good suggestion. i like the builder pattern as well. the implementation can be a bit verbose in java, but it can do validation at build time and prevent the telescoping constructor problem. it may also be able to provide simplified api compatibility.",1,0.9809344410896301
57967577,1095,hachikuji,2016-03-30T21:31:43Z,"i also like the builder pattern. it reads nicely and you don't have to care about argument order. on the other hand, it's also easier to forget necessary arguments and it feels kind of silly when the number of arguments is small. one nice thing about factory methods is that you can give them convenient names (e.g. metadatarequest.alltopicsv1()). both options are probably better than using the constructors, but i don't think it would be too bad to stick with the current convention for this patch. another option would be to include an explicit flag in the constructor. for example: [code block] we could then have the other constructor which accepts the topic list use the ""empty means empty"" semantics, and users would have to call this method to get all topics.",1,0.8684209585189819
58056988,1095,granthenke,2016-03-31T13:55:48Z,"i do like the idea of a flag to make it explicit. the challenge that poses is compatibility. i think any existing constructor needs to continue to function the way it used to. so empty list would need to continue to signify ""all topics"", at least for existing constructors.",1,0.9173353314399719
58058004,1095,ijuma,2016-03-31T14:02:16Z,"request classes are not api so i am not sure why it has to be like that? the official position is that we generate javadoc for classes that are api: [a link] (yes, i know it's confusing, i hope to change that so internal classes are all in internal packages).",0,0.7900121212005615
58060325,1095,granthenke,2016-03-31T14:15:24Z,i didn't realize compatibility wasn't a concern on these classes. then we can do whatever we would like here.,0,0.9643130898475647
58221673,1095,granthenke,2016-04-01T15:24:57Z,i updated the constructor to take an `alltopics` boolean. i think the changes required to do so may also solve [a link]. it worked nicely with `metadata.needmetadataforalltopics` in the `networkclient`.,0,0.97988361120224
58239805,1095,SinghAsDev,2016-04-01T17:36:14Z,"in current proposal, we are saying a null indicates all topics. would it be possible to use that here as well?",0,0.9859775304794312
58240259,1095,granthenke,2016-04-01T17:39:41Z,"the proposal is to use null on the wire protocol, not in the api. in the discussions it was mentioned that being more explicit in the api was favored. beyond that, if you specify `metadatarequest(null)` java wont know which constructor to use between `metadatarequest(list topics)` and `metadatarequest(struct struct)`.",0,0.9870779514312744
58243837,1095,SinghAsDev,2016-04-01T18:04:58Z,"got it, thanks for the explanation .",1,0.772841215133667
58245304,1095,granthenke,2016-04-01T18:14:51Z,thanks for the review !,1,0.9476193785667419
58536600,1095,ijuma,2016-04-05T13:26:17Z,just noting that this is no longer relevant given the current implementation (for other people reading the pr).,0,0.9508469104766846
60636130,1095,gwenshap,2016-04-21T18:55:09Z,don't we usually add new arguments at the end?,0,0.9731951951980591
60638297,1095,gwenshap,2016-04-21T19:08:35Z,do we need to validate if this is nullable before writing?,0,0.979630708694458
60638460,1095,gwenshap,2016-04-21T19:09:40Z,do we want to throw an exception with appropriate message if item if null but shouldn't be?,0,0.9826104044914246
60638661,1095,gwenshap,2016-04-21T19:11:02Z,"not sure if it matters, but we will get the exact same hash for empty and null arrays?",0,0.9779636263847351
60641282,1095,granthenke,2016-04-21T19:28:51Z,"since this was in internals and i needed to update all usages regardless, i located ""related"" parameters close to each other. i can move to the end if you prefer.",0,0.9879292249679565
60642147,1095,granthenke,2016-04-21T19:35:12Z,i think all of the other types assume validate will be called before calling write and that the written object would be the one returned by the validate call. here is a code snippet from `schema.write(...)`: [code block],0,0.9872877597808838
60642638,1095,granthenke,2016-04-21T19:39:10Z,it fails further down during the cast the same way it would before nulls were allowed. that exception is caught and re-thrown as a schemaexception. this behavior is validated by `protocolserializationtest.testnulls`.,0,0.9850198030471802
60645983,1095,granthenke,2016-04-21T20:02:39Z,"good point. we don't have `hashcode` or `equals` defined for `schema`, `field` or `type`...perhaps we should.",1,0.8751723170280457
60660381,1095,gwenshap,2016-04-21T21:45:10Z,"yeah, i saw that. i'm suggesting a separate schemaexception with message specific for nulls, to make troubleshooting/debugging a bit easier. not a big deal though.",0,0.9085983633995056
60660437,1095,gwenshap,2016-04-21T21:45:34Z,want to create a followup jira?,0,0.9779514074325562
60660863,1095,granthenke,2016-04-21T21:48:48Z,created [a link] to track that.,0,0.9837906956672668
60661081,1095,ijuma,2016-04-21T21:50:27Z,"personally, i'd introduce a `arrayof.nullable` static factory method as i think that would be more readable than the `true` here (since we don't have named arguments in java).",0,0.9876233339309692
60661303,1095,gwenshap,2016-04-21T21:52:16Z,i don't think we can do a fall-through here? since v1 error response is not a valid v0 response?,0,0.963120698928833
60661511,1095,granthenke,2016-04-21T21:53:47Z,i can do that. it should probably be done for all types that don't accept null. i opened [a link] to track that.,0,0.9862711429595947
60662604,1095,gwenshap,2016-04-21T22:03:00Z,"i am bit confused about the use of controller node vs controllerid. the protocol requires sending controllerid, which is what we have in most places. but you also find the actual node and provide an api (which isn't used anywhere? not even in tests?) to get the node. wondering what was the the plan here.",-1,0.936637818813324
60672248,1095,gwenshap,2016-04-21T23:41:16Z,thanks!,1,0.9308210611343384
60672977,1095,gwenshap,2016-04-21T23:49:55Z,i'm wondering if we can push down the work of figuring out if a topic is internal to topicmetadata constructor. it will clean up the api and topicmetadata has all the information it needs to find out.,0,0.9593690633773804
60673350,1095,gwenshap,2016-04-21T23:54:39Z,"mind adding a comment here, something along the lines of: ""in version 0, we returned an error when brokers with replicas were unavailable, while in higher versions we simply didn't include the broker in the list we returned"" (or is it vice-versa? anyway, its non-obvious and need a comment imo)",0,0.9746741652488708
60673675,1095,SinghAsDev,2016-04-21T23:58:50Z,nit: i think broker or broker_info or broker_metadata would be better.,0,0.9488115310668945
60673775,1095,gwenshap,2016-04-22T00:00:03Z,not 100% sure about changes to this test. random cleanup or related to kip-4?,0,0.8627777099609375
60673904,1095,SinghAsDev,2016-04-22T00:01:23Z,should we mention effect of a null string as rack here?,0,0.9850436449050903
60673918,1095,gwenshap,2016-04-22T00:01:35Z,aren't we adding a test for the results with errorunavailableendpoints = false?,0,0.9167254567146301
60673941,1095,gwenshap,2016-04-22T00:01:52Z,love it!,1,0.9899575114250183
60674080,1095,gwenshap,2016-04-22T00:03:44Z,"ok, i saw we are testing both request versions below. i still find it a bit weird it is missing from the cache tests, since it is added functionality for the cache - but up to you.",-1,0.9028725624084473
60674146,1095,gwenshap,2016-04-22T00:04:31Z,do you want to also validate that v0 request with null still returns all topics?,0,0.9887444972991943
60674190,1095,gwenshap,2016-04-22T00:05:11Z,i also don't see us checking for v1 all-topics explicitly. do you want to add something?,0,0.9660503268241882
60674223,1095,gwenshap,2016-04-22T00:05:38Z,not sure how this is related.,-1,0.7361006736755371
60674299,1095,gwenshap,2016-04-22T00:06:13Z,its fine. just checking :),1,0.9844085574150085
60674310,1095,gwenshap,2016-04-22T00:06:26Z,got it. thanks.,1,0.9481641054153442
60674321,1095,gwenshap,2016-04-22T00:06:34Z,thanks!,1,0.9308210611343384
60674337,1095,gwenshap,2016-04-22T00:06:52Z,+1,0,0.696722686290741
60674619,1095,SinghAsDev,2016-04-22T00:10:09Z,"just thinking it loud here, it seems we follow getter convention here, we really do not have a common convention across the codebase. however, it is not too bad, as this is not end-user. i think user facing classes/interfaces do not follow getter convention though.",0,0.5964167714118958
60675033,1095,SinghAsDev,2016-04-22T00:15:12Z,shouldn't we check something like `topics != null && !topics.isempty()` or maybe we just want to rename the method to indicate we are indeed checking for topics to be non-null.,0,0.9296058416366577
60675649,1095,SinghAsDev,2016-04-22T00:23:11Z,"would it make sense to be consistent with other key names? have something like ""controller_id"".",0,0.9885993003845215
60676104,1095,gwenshap,2016-04-22T00:29:20Z,kafka-3603 seems to be for something else?,0,0.9665593504905701
60676663,1095,SinghAsDev,2016-04-22T00:36:36Z,+1,0,0.696722686290741
60676892,1095,SinghAsDev,2016-04-22T00:40:19Z,nit: maybe we can leave this file out if there are no other changes?,0,0.9804739952087402
60755927,1095,ijuma,2016-04-22T15:19:50Z,this should be `byte` instead of `byte`.,0,0.9867188334465027
60756062,1095,ijuma,2016-04-22T15:20:48Z,"what is the reasoning for accepting any non-zero value as `true`? it seems more error-prone imo. if any value outside of `0` or `1` are used, it's probably a mistake.",-1,0.5711385607719421
60756385,1095,ijuma,2016-04-22T15:22:59Z,do we want to ignore or it would it be better to validate it (ie `topics` must be empty or null for that case).,0,0.9818915724754333
60757857,1095,ijuma,2016-04-22T15:31:46Z,"you can just return the controller here and then you don't need the `controller` variable or break (in scala, i don't like to use `return`, but if one is using `break` already, then it's at a similar level imo).",0,0.9874480366706848
60758124,1095,ijuma,2016-04-22T15:33:37Z,"if possible, jun generally suggests that we have one constructor per version with older version constructors deprecated. seems like we could do that here right? the older version would not have `controllerid`.",0,0.9891262054443359
60758473,1095,ijuma,2016-04-22T15:35:40Z,"i think it would be useful to add a comment here and when we set other new fields (`rack_key_name`, `is_internal_key_name`, etc.) saying stating the version they were added in (we do that in other request/response classes).",0,0.984254002571106
60758863,1095,ijuma,2016-04-22T15:38:05Z,"hmm, if we don't have that field, then we don't know if it's internal or not, right?",0,0.9247006773948669
60761238,1095,granthenke,2016-04-22T15:53:41Z,i had maintained the old constructor for compatibility in an older version of the patch. but in previous reviews i was told i did not need to maintain it: [a link],0,0.9760971069335938
60761858,1095,granthenke,2016-04-22T15:57:30Z,i am okay with that.,0,0.9225295186042786
60762586,1095,granthenke,2016-04-22T16:01:17Z,this is left over from changes required when leveraging zookeeper to track deletes. i left it because it looks like its closer to what was actually trying to be mocked based on the comment. i can keep it or leave it.,0,0.9430265426635742
60762636,1095,granthenke,2016-04-22T16:01:35Z,sure i will add some more test cases.,0,0.9597837924957275
60762667,1095,granthenke,2016-04-22T16:01:52Z,i can add those tests here too.,0,0.9857498407363892
60762756,1095,granthenke,2016-04-22T16:02:28Z,this is left over from changes required when leveraging zookeeper to track deletes. i left it because it looks like its closer to what was actually trying to be mocked based on the comment. i can keep it or leave it.,0,0.9430265426635742
60762885,1095,granthenke,2016-04-22T16:03:00Z,will add the comment.,0,0.9836607575416565
60762972,1095,granthenke,2016-04-22T16:03:33Z,thats an interesting idea. let me take a look and report back.,1,0.8494593501091003
60763255,1095,granthenke,2016-04-22T16:05:26Z,"this is challenging because we use the same class for both v0 and v1 responses. in the common case if you have the new version of the class you would be using v1 protocol, but thats not always true. in the case of new fields i tried to pick a safe default. since v0 is not aware of internal topics i defaulted to false. do you have thoughts on a better approach?",0,0.5987268686294556
60763550,1095,ijuma,2016-04-22T16:07:18Z,"sorry for the confusion. if we don't need to use the older version, we can remove it. however, if we still need to use it, then it's better to keep a constructor for the older version instead of having a version parameter. that's based on jun's previous reviews, i actually prefer the current approach as we don't need to call deprecated constructors. anyway, if gwen is fine with this, maybe we can leave as is.",-1,0.983928918838501
60763729,1095,ijuma,2016-04-22T16:08:38Z,do we need to check `false` twice?,0,0.981238067150116
60763932,1095,ijuma,2016-04-22T16:10:07Z,shall we add a topic where the boolean is `true`?,0,0.9862870573997498
60764088,1095,ijuma,2016-04-22T16:11:07Z,should we just pass `null` instead of empty list (like in `requestresponsetest`)?,0,0.9875200986862183
60764126,1095,granthenke,2016-04-22T16:11:23Z,"whenever a broker id is used on the wire protocol, logically this class looks up the broker by id in the brokers list and represents it to the user as a node. this is very similar logic to how replicas ids are handled in this class. i am not saying its my favorite, but i chose to maintain the existing pattern. the controller node is not used yet, but in kip-4 it may be used to route messages.",0,0.9645851254463196
60764164,1095,ijuma,2016-04-22T16:11:39Z,nitpick: no need for braces.,0,0.9815727472305298
60764416,1095,ijuma,2016-04-22T16:13:41Z,not sure about that. the request classes shouldn't really have any logic imo. they should just be a way to serialize/deserialize to the kafka protocol. we could have a util method somewhere that does this. or at least a static factory method (instead of constructor) in the request classes as a pragmatic compromise.,0,0.9188764691352844
60764750,1095,granthenke,2016-04-22T16:16:09Z,"its a bit of a gray area. we introduced the boolean to be explicit and be the single deciding factor for all topics. if we have this validation, its actually the topics list that really matters again and we essentially have 2 toggles to enable all topics. when validating would we require null & true to get all topics and fail in all other cases in order to match closely to the wire protocols behavior?",0,0.7489197254180908
60764789,1095,granthenke,2016-04-22T16:16:25Z,will fix.,0,0.9742533564567566
60764921,1095,ijuma,2016-04-22T16:17:34Z,"we are using this `tostring` in a number of log statement, not sure the rack information is that relevant (the fact that `tostring` is used for both debug and more user-facing string is a pain). , you cleaned up the logs, what do you think?",0,0.5351431369781494
60765137,1095,ijuma,2016-04-22T16:19:07Z,"ok, maybe add a comment in this case as it's not obvious.",0,0.9749876856803894
60765466,1095,granthenke,2016-04-22T16:21:18Z,"i implemented it this way to match the existing behavior of stopreplica requests delete_partitions boolean. that way this type could be used there as well without a version bump, and all the ""booleans"" would behave the same. i planned to update stopreplicarequest after this patch based on the decisions here. here is the relevant code: [a link]",0,0.9815970659255981
60765571,1095,granthenke,2016-04-22T16:22:00Z,this class uses get for all other methods so i followed that.,0,0.9868590831756592
60765672,1095,granthenke,2016-04-22T16:22:56Z,"apologies, copy and paste error. its [a link].",-1,0.8453420996665955
60765811,1095,granthenke,2016-04-22T16:24:02Z,what message would you suggest?,0,0.983322262763977
60766018,1095,granthenke,2016-04-22T16:25:38Z,the idea is that this is the broker used with the metadata response. all objects tied to the metadata response are prefixed with metadata. there are other broker objects in this file that i would not want to be confused.,0,0.9807299375534058
60766035,1095,granthenke,2016-04-22T16:25:43Z,will do.,0,0.9548023343086243
60766571,1095,granthenke,2016-04-22T16:29:49Z,these constructors are generally only used in the broker. i like passing in the version because then one constructor can handle all versions and the broker is guaranteed to send the correct version back without a bunch of if/switch logic. there could be a case in the future where a separate constructor is required to maintain compatibility. but if i can avoid many constructors i would prefer it.,0,0.7662299871444702
60766711,1095,granthenke,2016-04-22T16:31:05Z,sure. will remove.,0,0.9785355925559998
60766886,1095,ijuma,2016-04-22T16:32:03Z,"`boolean` is a keyword, that's why.",0,0.9759741425514221
60766905,1095,granthenke,2016-04-22T16:32:18Z,no. will fix.,0,0.9214997887611389
60767008,1095,granthenke,2016-04-22T16:33:08Z,sure we can.,0,0.9182438850402832
60767033,1095,ijuma,2016-04-22T16:33:23Z,"i know what you mean, i did the same in a previous pr, but jun made me change it. ;) as i said, let's see what gwen thinks.",1,0.942093551158905
60767100,1095,granthenke,2016-04-22T16:33:56Z,i can do that. i will include explanation in the version comments suggested earlier.,0,0.9751337766647339
60767154,1095,granthenke,2016-04-22T16:34:22Z,i think it depends on the choice in earlier comments here: [a link],0,0.9832395911216736
60767558,1095,granthenke,2016-04-22T16:37:27Z,"this is related to this discussion too: [a link] right now some these classes have quite a bit of logic and don't expose the ""raw"" information. i agree that it would be nice to have some layering here where the logic is handled/exposed elsewhere. i don't want to impose to much change on existing logic in this patch though either.",0,0.9106401801109314
60767635,1095,granthenke,2016-04-22T16:38:04Z,that too.,0,0.9571985006332397
60769396,1095,ijuma,2016-04-22T16:52:26Z,"this is a bit different. there are 3 levels, in a sense: 1. wire protocol 2. wrapping the wire protocol into domain model classes 3. having business logic like what topics are internal in the request classes (or calling helper methods for that from within the request classes) as we discussed previous , i think we should really do `1`, but we do `2` in a number of places. this suggestion is `3`. in any case, i'm ok if we do it in a static factory method as a starting point (and we can move it elsewhere in the future in a separate pr maybe).",0,0.8192301392555237
60770343,1095,SinghAsDev,2016-04-22T16:59:21Z,"ok, thanks for the explanation.",0,0.6235677003860474
60770562,1095,SinghAsDev,2016-04-22T17:00:59Z,"something that would capture the following, need not be this verbose though.",0,0.9589354395866394
60770887,1095,ijuma,2016-04-22T17:03:39Z,"generally, i'm against adding unused methods until we actually need to use them. i agree that this may make sense here from a consistency perspective, but even then i would lean towards not having it. if we do have it, then we should use it from a test, at least.",0,0.9128653407096863
60771090,1095,SinghAsDev,2016-04-22T17:05:24Z,"yea, i was just curious about reasoning, not specifically for the method.",0,0.8413116335868835
60771140,1095,ijuma,2016-04-22T17:05:55Z,legacy code is annoying. ;),-1,0.9746285080909729
60776015,1095,ijuma,2016-04-22T17:42:03Z,"the idea is to avoid mistakes. so, if someone gets the boolean logic inverted and passes some topics, then the validation would find that.",0,0.9752278923988342
60776076,1095,ijuma,2016-04-22T17:42:34Z,"by the way, i agree that this is a bit subjective.",0,0.7076643705368042
60776472,1095,granthenke,2016-04-22T17:45:18Z,i will play around with some options and run it by you.,0,0.9820377826690674
60776680,1095,granthenke,2016-04-22T17:46:41Z,that information is useful for rack configuration on the broker. i am not sure if it needs to be in the protocol documentation for the metadata response.,0,0.9769440293312073
60776722,1095,ijuma,2016-04-22T17:46:58Z,"this method is the main hotspot when it comes to the performance of metadata requests, so we need to be careful about adding additional logic here. i should have added a comment saying that, maybe you could do that. under the assumption that unavailable nodes are rare, it seems like this change is safe.",0,0.969407320022583
60776919,1095,ijuma,2016-04-22T17:48:21Z,why don't we return `option[int]` here?,0,0.9796059727668762
60776992,1095,ijuma,2016-04-22T17:48:51Z,is there a reason why we don't check that the value is the same as `no_controller_id`?,0,0.9757072329521179
60777018,1095,granthenke,2016-04-22T17:49:00Z,"this is used in `metadatarequesttest.testcontrollerid`. i will look at keeping it around or not. if i do, i will make sure hascontroller is tested too.",0,0.9859579205513
60777028,1095,ijuma,2016-04-22T17:49:05Z,formatting nit: this could be on the previous line.,0,0.9894411563873291
60777369,1095,ijuma,2016-04-22T17:51:32Z,i agree that these changes (and also in the other file) are weird to include here.,-1,0.973887026309967
60777637,1095,ijuma,2016-04-22T17:53:39Z,seems unnecessary since the superclass already defines it?,0,0.8875871896743774
60778171,1095,gwenshap,2016-04-22T17:57:17Z,"i actually like the deprecated constructors because we get explicit compile warnings when we bump versions and don't accidentally forget to update some of the places where they are called. if you are not convinced that having warnings to help with bumps is useful, i won't make you change it ;)",1,0.9445670247077942
60786052,1095,gwenshap,2016-04-22T18:51:22Z,"has the full scope of kip-4 though, if he knows it will be used, it is best to add it now (since the whole point was to add the lower-level apis now)",0,0.9843698740005493
60787278,1095,ijuma,2016-04-22T18:59:32Z,"this is an internal class, so methods can be added at any time though. the point was to update the wire protocol now as far as i know.",0,0.9877288341522217
60788788,1095,gwenshap,2016-04-22T19:09:55Z,"i don't think it is internal? it isn't in an ""internals"" package... it is a public class in ""common"". afaik, this makes it public? obviously it isn't as widely used as kafkaproducer, but my understanding was that anything not in a package called ""internals"" is public?",0,0.9297933578491211
60789535,1095,ijuma,2016-04-22T19:14:58Z,"today the only public classes are the ones we generate javadoc for (this was confirmed by jay and neha). we don't generate the javadoc for the request classes. as you know, i think this is very confusing and i want to change it so that we use internals packages across the board.",0,0.49769526720046997
60801036,1095,ijuma,2016-04-22T20:49:31Z,this is doing the same thing as the `controllerid` line. i think you meant to get the controller id from `metadataresponse`.,0,0.9897308349609375
60801175,1095,ijuma,2016-04-22T20:50:37Z,don't you mean to use `controllerserver2` and `metadataresponse2`?,0,0.98580002784729
60801224,1095,ijuma,2016-04-22T20:51:00Z,"typo, `what's`.",0,0.98244309425354
60801286,1095,ijuma,2016-04-22T20:51:25Z,nitpicks: `()` not needed in `brokers` and `rack`.,0,0.986918032169342
60801527,1095,ijuma,2016-04-22T20:53:21Z,there's a few other examples in this file.,0,0.9861830472946167
60801878,1095,ijuma,2016-04-22T20:55:59Z,can we rely on the ordering of the metadata in the response and of the partition metadata?,0,0.9875871539115906
60802099,1095,ijuma,2016-04-22T20:57:50Z,"nitpick: for cases like this, i think it's more readable to have the opening brace after `=>`. for cases where the opening brace can replace the opening parenthesis, it makes sense to position the brace like this case. a bit subjective though.",0,0.9567598104476929
60802287,1095,ijuma,2016-04-22T20:58:51Z,same question for a couple of other cases like this below.,0,0.9819677472114563
60802721,1095,ijuma,2016-04-22T21:02:08Z,how do we know that there are always 3 brokers? i guess the intent is that subclasses will use this in `generateconfigs` but that seems easy to miss. we could define this as a def and let the subclasses define it. or we could implement `generateconfigs` here and call an abstract method `generateconfig(brokerid)` or something.,0,0.9745765328407288
60802854,1095,ijuma,2016-04-22T21:03:19Z,the 3 methods above seem to be used in many tests. would it make sense to have a utility class or trait that people can mix-in?,0,0.9806004166603088
60802895,1095,ijuma,2016-04-22T21:03:40Z,nitpick: `correlationid += 1`,0,0.985945999622345
60802936,1095,ijuma,2016-04-22T21:04:09Z,this seems to be unused?,0,0.9607248902320862
60809216,1095,gwenshap,2016-04-22T22:03:27Z,"got it. thanks for clarifying. if we can modify it at any time, there's really no point in including ""may need"" features.",1,0.8916629552841187
60939173,1095,granthenke,2016-04-25T16:01:04Z,"it is unused, i just need to call parse to ensure it parses correctly and moves the buffer forward. i can remove the val assignment though.",0,0.9885086417198181
60940329,1095,granthenke,2016-04-25T16:08:16Z,"there is definitely a better way to share this test code across other tests. i would like to do this cleanup, but would you mind if i open a separate jira to track that and do it shortly after this patch?",0,0.945881187915802
60940596,1095,ijuma,2016-04-25T16:09:48Z,"sounds good to me. also, please add a comment as side-effects like that are not obvious.",1,0.9426555633544922
60940760,1095,ijuma,2016-04-25T16:10:53Z,sure.,0,0.9536533951759338
60943982,1095,granthenke,2016-04-25T16:30:16Z,i moved the configuration to the baserequesttest and provided a way to override the properties in the subclass.,0,0.9882978796958923
60944350,1095,granthenke,2016-04-25T16:32:36Z,since i am asking for only 1 topic and that topic has only 1 partition it shouldn't matter here.,0,0.9343549609184265
60946083,1095,granthenke,2016-04-25T16:44:19Z,since any negative value is invalid i map it to none.,0,0.9442043304443359
60946121,1095,granthenke,2016-04-25T16:44:37Z,yeah i should return the option here and use `metadataresponse.no_controller_id` kafkaapis.,0,0.9851827025413513
60946477,1095,granthenke,2016-04-25T16:46:54Z,i will add the comment.,0,0.9831137657165527
60948003,1095,granthenke,2016-04-25T16:55:56Z,i have added comments that they only exist in v1+,0,0.9868561625480652
60948570,1095,granthenke,2016-04-25T16:59:26Z,"i think it actually ends up being a bit of ""crying wolf"" since the brokers would be required to use the old constructors to support the old versions. we would throw, and likely suppress, the deprecation warnings in that case. i think unit tests are the best way to verify this behavior. i will work on increasing the version coverage on this patch and consider updating other apis at a later time.",0,0.8851110339164734
60951090,1095,granthenke,2016-04-25T17:15:52Z,i would like to leave it for use in unit tests and also with the expectation that it will be used shortly. i will remove any method that is not being used or tested.,0,0.9778255820274353
60963008,1095,granthenke,2016-04-25T18:26:59Z,this can fall through because the constructor supports version 0 and 1. the version is passed as the last parameter. this is related to the discussion here: [a link],0,0.9872411489486694
60963844,1095,gwenshap,2016-04-25T18:31:45Z,sounds good!,1,0.984022855758667
60963946,1095,ijuma,2016-04-25T18:32:19Z,"the issue with this approach is that we accept instead of failing when we receive invalid values. in some cases, this can lead to bugs being missed.",0,0.9060046076774597
61162466,1095,ijuma,2016-04-26T20:54:58Z,we can call `isalltopics` on `request` and remove the comment about `null`,0,0.9877603650093079
61163654,1095,ijuma,2016-04-26T21:01:33Z,"i think it's important to be clear about the expected usage of methods like this. either we return a new instance or we mutate the passed instance. given how `properties` are generally used, isn't it better to just not return `properties`?",0,0.9773065447807312
61163744,1095,ijuma,2016-04-26T21:02:09Z,shall we add a helpful message via `getorelse`?,0,0.98691725730896
61164103,1095,ijuma,2016-04-26T21:04:35Z,the second argument to `assertequals` could be `controllerid` right?,0,0.9872040152549744
61164205,1095,ijuma,2016-04-26T21:05:17Z,"this is kind of weird, we should probably get the broker id from the config (ie `controllerserver.config.brokerid`) or add a method to `kafkaserver` that returns the broker id.",-1,0.982212245464325
61164585,1095,ijuma,2016-04-26T21:07:39Z,it's a bit weird that we assert that failover happened and then we wait until failover happens. shouldn't the `waituntiltrue` be before anything else?,-1,0.9764071702957153
61165412,1095,ijuma,2016-04-26T21:13:00Z,we should also include an assert for the field we can use to know that a replica is down.,0,0.9853661060333252
61178157,1095,granthenke,2016-04-26T22:50:00Z,this is because the failover is basically immediate when looking up the servers directly via: [code block] but propagating that state to the metadatacache and therefore the metadataresponse could take a bit of time and requires the `testutils.waituntiltrue`,0,0.9829151630401611
61178707,1095,granthenke,2016-04-26T22:55:27Z,will add a check to confirm the downed broker is not in the brokers list,0,0.9831538796424866
61178731,1095,granthenke,2016-04-26T22:55:41Z,will change to config,0,0.9862122535705566
61182686,1095,ijuma,2016-04-26T23:36:29Z,thanks for the explanation.,0,0.5256959199905396
341684130,7629,mjsax,2019-11-01T17:53:06Z,"`application`? the operator are named, not the application?",0,0.9874467253684998
341686787,7629,mjsax,2019-11-01T17:59:30Z,"should this be a paragraph, ie, wrapped with ` ... ` tags? same below.",0,0.9881730675697327
341687086,7629,mjsax,2019-11-01T18:00:12Z,"this is not the upgrade section, hence, i would remove the reference to `2.4` and the word `now`.",0,0.9865002036094666
341687746,7629,mjsax,2019-11-01T18:01:54Z,"`prefixed` -> the ""suffix"" is ""prefixed"" -- quite hard to read. also, are the details of the `number-suffix` format relevant?",0,0.969332218170166
341689152,7629,mjsax,2019-11-01T18:05:23Z,"we should be a little bit more clear. at papi level, there are `processors` and `statestores` and people need to name the explicitly. at the dsl, we have operators, and an operator may compile down to multiple `processors, `statestores`, and `repartition-topic`, and all those are name automatically, and there is a relationship between the processor-name and the store/changelog topic name and repartition topic names.",0,0.9820152521133423
341695265,7629,mjsax,2019-11-01T18:20:38Z,nit: remove version reference,0,0.9701876044273376
341695374,7629,mjsax,2019-11-01T18:20:56Z,nit: remove `now`,0,0.9815248250961304
341696372,7629,mjsax,2019-11-01T18:23:29Z,"should this be formatted with ""single line per operator"" to make it easier to read (and to align with the formatting of the other code snippets?",0,0.9820783734321594
341696731,7629,mjsax,2019-11-01T18:24:23Z,"does this render correctly? i think, ` ` does not remove ""indenting whitespaces"" and thus this would render the indention...",0,0.977209746837616
341707445,7629,mjsax,2019-11-01T18:52:05Z,nit: ` before ` ?,0,0.9512854218482971
341707858,7629,mjsax,2019-11-01T18:53:20Z,"`with the joined, streamjoined, or grouped classed`",0,0.9811821579933167
341708595,7629,mjsax,2019-11-01T18:55:01Z,`even though you've added processors before your state store` -> `with or without the filter operation`,0,0.9827827215194702
341709276,7629,mjsax,2019-11-01T18:56:52Z,"nit: `:` should be on line above `topolog:` -- otherwise it will be rendered as `topolog :` (ie, with a ws in between)",0,0.983354389667511
341709757,7629,mjsax,2019-11-01T18:58:08Z,"for `kstream-ktable` joins, it's still `joined`, right? so we need to add one line to the column?",0,0.9884355068206787
341710210,7629,mjsax,2019-11-01T18:59:16Z,for aggregations and ktables-ktable joins right? to distinguish the `kstream-kstream` join case?,0,0.9894521236419678
341881771,7629,ableegoldman,2019-11-04T00:02:03Z,"how about ""naming operators in a streams dsl application""?",0,0.9882599115371704
341881852,7629,ableegoldman,2019-11-04T00:03:23Z,nit: remove comma after 'dsl',0,0.9891766905784607
341882038,7629,ableegoldman,2019-11-04T00:07:16Z,"i agree it's not necessary to mention the details here, but i do think it's appropriate to briefly explain where the compatibility or ""name shifting"" issue comes from in the `changing names` section below",0,0.9699817895889282
341882125,7629,ableegoldman,2019-11-04T00:08:57Z,"have you considered any alternative names for this section/trade-off? ""cognitive issues"" seems to have a weird connotation, what about just `readability` or `readability problems`?",-1,0.9431213736534119
341882260,7629,ableegoldman,2019-11-04T00:11:22Z,"are you referring to repartition topics, or users failing to name their topics meaningfully? we should definitive make it clear they are encouraged to name things meaningfully, and it seems weird to expect users to choose meaningful names for their operators but not for their topics",-1,0.9480993747711182
341882442,7629,ableegoldman,2019-11-04T00:15:10Z,"i personally find it more readable when everything is in its own section, eg the section beginning ""but there's another reason..."" was moved to the `changing names` section whose topic it's actually referring to. but feel free to leave as-is if you or anyone else disagrees",0,0.9415097236633301
341882738,7629,ableegoldman,2019-11-04T00:20:47Z,"i'm finding the comment about **most** processors existing in memory only a bit confusing -- maybe just use the term ""stateless"" instead? also, i think it's a bit misleading to say that ""because most are stateless, this shifting presents no issue"" -- maybe rephrase to something like ""many processors are stateless and therefore exist in memory only, so this name shifting on topology change presents no issue to applications built entirely of such operators."" ?",0,0.6879377365112305
341883192,7629,ableegoldman,2019-11-04T00:29:55Z,"""give the state store a constant user-defined name instead of relying...""",0,0.9846807718276978
341883257,7629,ableegoldman,2019-11-04T00:31:12Z,nit: replace `--` with `such as`,0,0.9860628247261047
341883357,7629,ableegoldman,2019-11-04T00:33:07Z,"nit: `transient` --> `stateless` ? i think it's good to be consistent in our terminology throughout the docs -- it might be obvious to us that ""stateless"", ""in-memory"", and ""transient"" all refer to the same thing, but i think users will find this confusing.",0,0.9457438588142395
342141293,7629,bbejeck,2019-11-04T16:24:57Z,ack,0,0.9720376133918762
342150101,7629,bbejeck,2019-11-04T16:41:15Z,ack,0,0.9720376133918762
342151782,7629,bbejeck,2019-11-04T16:44:25Z,"i'll clean this up some, but i'd prefer to leave this here to set the stage for the `changing names` section.",0,0.9834420084953308
342186088,7629,bbejeck,2019-11-04T17:54:38Z,ack,0,0.9720376133918762
342269064,7629,bbejeck,2019-11-04T21:04:28Z,ack,0,0.9720376133918762
342270140,7629,bbejeck,2019-11-04T21:07:09Z,ack,0,0.9720376133918762
342270257,7629,bbejeck,2019-11-04T21:07:28Z,ack,0,0.9720376133918762
342271483,7629,bbejeck,2019-11-04T21:10:33Z,ack,0,0.9720376133918762
342271670,7629,bbejeck,2019-11-04T21:11:03Z,"that's what i wanted, but is the indentation not correct?",0,0.9735814929008484
342271794,7629,bbejeck,2019-11-04T21:11:24Z,ack,0,0.9720376133918762
342271936,7629,bbejeck,2019-11-04T21:11:45Z,ack,0,0.9720376133918762
342272114,7629,bbejeck,2019-11-04T21:12:11Z,ack,0,0.9720376133918762
342272560,7629,bbejeck,2019-11-04T21:13:14Z,ack,0,0.9720376133918762
342272791,7629,bbejeck,2019-11-04T21:13:51Z,ack,0,0.9720376133918762
342273114,7629,bbejeck,2019-11-04T21:14:45Z,ack,0,0.9720376133918762
342273794,7629,bbejeck,2019-11-04T21:16:27Z,my point here is that most users won't have control over topic names. they'll build a streams application to work with existing topics.,0,0.955898642539978
342274069,7629,bbejeck,2019-11-04T21:17:07Z,ack,0,0.9720376133918762
342274140,7629,bbejeck,2019-11-04T21:17:17Z,ack,0,0.9720376133918762
342274425,7629,bbejeck,2019-11-04T21:18:03Z,ack,0,0.9720376133918762
342274497,7629,bbejeck,2019-11-04T21:18:14Z,ack,0,0.9720376133918762
342274660,7629,bbejeck,2019-11-04T21:18:39Z,ack,0,0.9720376133918762
342275213,7629,bbejeck,2019-11-04T21:19:53Z,ack,0,0.9720376133918762
342275977,7629,bbejeck,2019-11-04T21:21:43Z,ack,0,0.9720376133918762
342276210,7629,bbejeck,2019-11-04T21:22:18Z,ack,0,0.9720376133918762
342276356,7629,bbejeck,2019-11-04T21:22:41Z,ack,0,0.9720376133918762
342276577,7629,bbejeck,2019-11-04T21:23:13Z,ack,0,0.9720376133918762
342658799,7629,bbejeck,2019-11-05T16:24:07Z,"i think it fits where i had it originally, but you are correct about it being in the same section as well. if i kept it in the original location, i should at least repeat the information in the `changing names` section. but i opted to take your suggestion and just move it there altogether",0,0.9723960757255554
342659633,7629,bbejeck,2019-11-05T16:25:33Z,ack,0,0.9720376133918762
342659990,7629,bbejeck,2019-11-05T16:26:08Z,ack,0,0.9720376133918762
342662764,7629,bbejeck,2019-11-05T16:30:36Z,ack,0,0.9720376133918762
342664122,7629,bbejeck,2019-11-05T16:32:41Z,ack,0,0.9720376133918762
342664196,7629,bbejeck,2019-11-05T16:32:50Z,ack,0,0.9720376133918762
342665851,7629,bbejeck,2019-11-05T16:35:39Z,ack,0,0.9720376133918762
342667608,7629,bbejeck,2019-11-05T16:38:49Z,ack,0,0.9720376133918762
342668807,7629,bbejeck,2019-11-05T16:41:02Z,ack,0,0.9720376133918762
342669710,7629,bbejeck,2019-11-05T16:42:28Z,ack,0,0.9720376133918762
342670496,7629,bbejeck,2019-11-05T16:43:43Z,ack,0,0.9720376133918762
342676589,7629,bbejeck,2019-11-05T16:54:24Z,"ack, i used something similar",0,0.9771885871887207
342676930,7629,bbejeck,2019-11-05T16:55:01Z,ack,0,0.9720376133918762
342678646,7629,bbejeck,2019-11-05T16:58:12Z,ack,0,0.9720376133918762
342680311,7629,bbejeck,2019-11-05T17:01:20Z,ack,0,0.9720376133918762
342682536,7629,bbejeck,2019-11-05T17:05:33Z,ack,0,0.9720376133918762
342683837,7629,bbejeck,2019-11-05T17:08:03Z,ack,0,0.9720376133918762
342684647,7629,bbejeck,2019-11-05T17:09:43Z,ack,0,0.9720376133918762
342685100,7629,bbejeck,2019-11-05T17:10:34Z,ack,0,0.9720376133918762
342686001,7629,bbejeck,2019-11-05T17:12:14Z,ack,0,0.9720376133918762
342686440,7629,bbejeck,2019-11-05T17:13:06Z,ack,0,0.9720376133918762
342687361,7629,bbejeck,2019-11-05T17:14:50Z,ack,0,0.9720376133918762
342687629,7629,bbejeck,2019-11-05T17:15:23Z,ack,0,0.9720376133918762
342688024,7629,bbejeck,2019-11-05T17:16:06Z,ack,0,0.9720376133918762
342688356,7629,bbejeck,2019-11-05T17:16:40Z,ack,0,0.9720376133918762
342689620,7629,bbejeck,2019-11-05T17:19:10Z,ack with a slight tweek,0,0.9348213076591492
342690110,7629,bbejeck,2019-11-05T17:20:11Z,good point,1,0.9578153491020203
342690641,7629,bbejeck,2019-11-05T17:21:20Z,ack,0,0.9720376133918762
342690865,7629,bbejeck,2019-11-05T17:21:42Z,ack,0,0.9720376133918762
342691755,7629,bbejeck,2019-11-05T17:23:21Z,good catch!,1,0.9899783134460449
342693339,7629,bbejeck,2019-11-05T17:26:23Z,ack,0,0.9720376133918762
342694351,7629,bbejeck,2019-11-05T17:28:30Z,"i'd prefer to keep this as is, but if you have a strong opinion on this, i'll make the change.",0,0.9631685614585876
342696400,7629,bbejeck,2019-11-05T17:32:41Z,ack,0,0.9720376133918762
342787455,7629,ableegoldman,2019-11-05T20:43:20Z,"q: what do you mean by `the generated processor-name state store`? and which topic names, changelog or input/output? i'm not sure i follow this sentence",0,0.9186210036277771
342819399,7629,ableegoldman,2019-11-05T21:58:57Z,"prop: i still find this sentence confusing but if others disagree i'll hold my peace...but how about something like ""...this name shifting presents no issue for many topologies"" or ""for any stateless topologies"" ?",-1,0.9653322696685791
342852018,7629,ableegoldman,2019-11-05T23:34:27Z,"prop: sentence reads a bit awkward, how about `...the state store (and changelog topic) names...` or `...the state store names (and changelog topics as well) have changed` ?",-1,0.628618597984314
342854854,7629,ableegoldman,2019-11-05T23:44:54Z,"req: does it make sense for this section to go after the ""testing a streams application"" section? i would keep it together with the other dsl operators prop: do you think we should include a quick line about why you'd want to name things here? just wondering if we should protect against people who won't want to read the full manual, and won't realize that naming is essential for compatibility",0,0.9711955189704895
344388199,7629,bbejeck,2019-11-08T22:16:06Z,"i think it's a bit subjective. imho it should come after all the other operations are described as this is a ""meta-operation"". at any rate, i've moved it up closer, so it's the first item in the list after describing the other operations. i'm inclined to leave this as-is, it's just one click, and users can read the first paragraph.",0,0.533819317817688
344393729,7629,bbejeck,2019-11-08T22:36:56Z,clarified some (i think). if it's still unclear i'll just remove it altogether.,0,0.9820303320884705
344401859,7629,bbejeck,2019-11-08T23:12:02Z,updated,0,0.9681491851806641
344403668,7629,bbejeck,2019-11-08T23:20:50Z,ack,0,0.9720376133918762
344404824,7629,ableegoldman,2019-11-08T23:27:03Z,fair enough,0,0.9163533449172974
344405137,7629,ableegoldman,2019-11-08T23:28:37Z,:thumbs_up: this is a good point to drive home,1,0.9786142706871033
344406892,7629,ableegoldman,2019-11-08T23:38:02Z,"hm. is this roughly what you mean here: ""the processor name generated for a state store (and hence changelog topic name) will also be used in generating the repartition topic name"" or something to that affect? or even replacing `generated processor-name state store` with `state store's generated processor name` or `generated processor-name of a state store`?",0,0.9781267642974854
344474564,7629,mjsax,2019-11-10T06:22:20Z,"this example has a similar issue: [a link] note that the first block of the code example has a larger indention as the last two lines. if you compare with the docs files, the first block has whitespace: [a link] the last two lines don't have and render correctly: [a link] the example i picked uses ` ` tag but i think ` ` work the same way.",0,0.9825693368911743
344474629,7629,mjsax,2019-11-10T06:25:06Z,nit: remove whitespace in ` repartition...`,0,0.9844380021095276
344474691,7629,mjsax,2019-11-10T06:27:05Z,"-> `processor names, state store names (and hence changelog topics names), and repartition topic names` if you don't repeat `names` (note plural) it's hard to read -- and not `-` in `processor names`.",0,0.9459072351455688
344474755,7629,mjsax,2019-11-10T06:29:58Z,"why `but`? maybe better, `note, that the names of state stores and changelog/repartition topics are ""stateful"" while processor names are ""stateless"".` i would not use ` ` but put into quote -- a name is not really stateful, but i understand what you want to say. again, no `-` in `processor names`",0,0.9789459109306335
344474790,7629,mjsax,2019-11-10T06:31:45Z,"i think, ` ` tag has similar indentation issue as ` ` tag -- compare my other comment. (there are more ` ` tags below -- won't comment on them but please fix all)",0,0.9834120273590088
344474827,7629,mjsax,2019-11-10T06:33:58Z,missing ` ` tag,0,0.9684562087059021
344474843,7629,mjsax,2019-11-10T06:34:20Z,missing ` ` tag,0,0.9684562087059021
344474850,7629,mjsax,2019-11-10T06:34:31Z,missing ` ` tag,0,0.9684562087059021
344474854,7629,mjsax,2019-11-10T06:34:36Z,missing ` ` tag,0,0.9684562087059021
344474856,7629,mjsax,2019-11-10T06:34:44Z,missing ` ` tag,0,0.9684562087059021
344474861,7629,mjsax,2019-11-10T06:35:07Z,missing ` ` tag (there seems to be more below; please fix),0,0.9863003492355347
345833885,7629,bbejeck,2019-11-13T15:43:14Z,ack,0,0.9720376133918762
345833978,7629,bbejeck,2019-11-13T15:43:23Z,ack,0,0.9720376133918762
345834082,7629,bbejeck,2019-11-13T15:43:33Z,ack,0,0.9720376133918762
345834190,7629,bbejeck,2019-11-13T15:43:43Z,ack,0,0.9720376133918762
345834273,7629,bbejeck,2019-11-13T15:43:51Z,ack,0,0.9720376133918762
345834384,7629,bbejeck,2019-11-13T15:44:01Z,ack,0,0.9720376133918762
418108095,8589,abbccdda,2020-04-30T15:45:14Z,could we pass the members into the context?,0,0.9865819215774536
420339593,8589,abbccdda,2020-05-05T19:03:29Z,remove print statements,0,0.9642800688743591
420340211,8589,abbccdda,2020-05-05T19:04:30Z,"curious why we are still continuing in this case, as the member lookup already fails.",0,0.9591103196144104
420341894,8589,abbccdda,2020-05-05T19:07:17Z,could we just make members to be `optional >` so that we don't need a separate removeall parameter?,0,0.9872481226921082
420344946,8589,abbccdda,2020-05-05T19:12:50Z,style error here. i would recommend doing a self style check like: `./gradlew checkstylemain checkstyletest spotbugsmain spotbugstest spotbugsscoverage compiletestjava` otherwise we still need to fix those failures after we do jenkins build.,0,0.9625292420387268
420568190,8589,feyman2016,2020-05-06T06:23:45Z,"thanks for the advice, will fix it in the next commit.",1,0.7108948230743408
420806232,8589,feyman2016,2020-05-06T13:50:14Z,"sure. taking a step further, can we just keep the the type `set ` for `members` unchanged and treat it as `removeall` if the `members` is empty set?",0,0.9867331385612488
420824271,8589,feyman2016,2020-05-06T14:13:08Z,"my initial thought was to put the `members` in the context, but hesitated to do so because the `consumergroupoperationcontext` seems to be for generic usage. so i just refer to `kafkaadminclient#getalterconsumergroupoffsetscall` and make the members as a separate input param. anyway, i'm glad to make the change if we think it's preferred to put the `members` in context.",0,0.601364016532898
420824572,8589,feyman2016,2020-05-06T14:13:32Z,fixed~,0,0.972282350063324
420848223,8589,feyman2016,2020-05-06T14:43:57Z,"thanks, will fix this .",1,0.6915374398231506
421216617,8589,feyman2016,2020-05-07T03:24:17Z,fixed,0,0.975196123123169
421216746,8589,feyman2016,2020-05-07T03:24:43Z,updated~,0,0.968959629535675
421216977,8589,feyman2016,2020-05-07T03:25:42Z,"i reran the self style check, but didn't capture any error. i assume the error would be the missed `final` in for loop, updated.",0,0.9880778193473816
424198050,8589,abbccdda,2020-05-13T06:23:08Z,nit: space before `:`,0,0.9653902649879456
424510483,8589,abbccdda,2020-05-13T15:04:03Z,"yes, i feel this is more consistent for internal calls not to do a second round of interpretation for which `members` set to use.",0,0.9780313372612
424512993,8589,abbccdda,2020-05-13T15:07:20Z,nit: remove extra line,0,0.9814272522926331
424516058,8589,abbccdda,2020-05-13T15:11:24Z,should be collection.emptylist(),0,0.9857857823371887
424517564,8589,abbccdda,2020-05-13T15:13:24Z,"why do we blindly put `allmembers`? i believe we base on context to interpret, but like discussed earlier, this is easy to make mistake, we should rely on one source for members.",0,0.8761433959007263
424518540,8589,abbccdda,2020-05-13T15:14:40Z,"and to be clear, i'm not suggesting we have to put stuff into the context, just always passing in the intended removal list and do not depend on `context.removeall` again inside internal function.",0,0.9859563112258911
424522056,8589,abbccdda,2020-05-13T15:19:18Z,not necessary change,0,0.9635054469108582
424522792,8589,abbccdda,2020-05-13T15:20:13Z,nit: space after `empty_group_instance_id`,0,0.9882504940032959
424524146,8589,abbccdda,2020-05-13T15:22:05Z,could we specify the return type?,0,0.9885128736495972
424525171,8589,abbccdda,2020-05-13T15:23:22Z,"i don't think we really need this struct, could we just put `null` in `groupinstanceset`?",0,0.9705352783203125
424525436,8589,abbccdda,2020-05-13T15:23:44Z,nit: space,0,0.9737508893013
424525798,8589,abbccdda,2020-05-13T15:24:16Z,why do we suppress here?,0,0.8843992352485657
424527021,8589,abbccdda,2020-05-13T15:25:51Z,remained -> remaining,0,0.9648932218551636
424529767,8589,abbccdda,2020-05-13T15:29:16Z,do we also want to edit the `usage` info on top to mention the force delete option?,0,0.9880258440971375
428579361,8589,feyman2016,2020-05-21T10:47:11Z,"i think so, updated",0,0.9833531379699707
428580805,8589,feyman2016,2020-05-21T10:50:37Z,fixed~,0,0.972282350063324
428581576,8589,feyman2016,2020-05-21T10:52:32Z,fixed,0,0.975196123123169
428583883,8589,feyman2016,2020-05-21T10:58:19Z,"fixed, now we explicitly pass in the members to be deleted to the private `getremovemembersfromgroupcall`",0,0.9882517457008362
428585120,8589,feyman2016,2020-05-21T11:01:17Z,reverted,0,0.9771652221679688
428585373,8589,feyman2016,2020-05-21T11:01:53Z,fixed,0,0.975196123123169
428585617,8589,feyman2016,2020-05-21T11:02:29Z,refactored,0,0.9850403070449829
428586730,8589,feyman2016,2020-05-21T11:05:08Z,"i feel like this is more informative, so didn't update it, but yeah, i can update if we really not prefer this~",0,0.4688047766685486
428587018,8589,feyman2016,2020-05-21T11:05:49Z,fixed,0,0.975196123123169
428588172,8589,feyman2016,2020-05-21T11:08:27Z,fixed,0,0.975196123123169
428589350,8589,feyman2016,2020-05-21T11:11:16Z,"didn't change the exception handling logic here, just extract the thread creation logic to reuse~",0,0.9850783348083496
428745517,8589,abbccdda,2020-05-21T15:51:55Z,i think we should catch `exception` here: [a link],0,0.9872397780418396
428748938,8589,abbccdda,2020-05-21T15:56:31Z,"this indentation is a bit weird, let's just merge l3625-3626",-1,0.984907865524292
428751049,8589,abbccdda,2020-05-21T16:00:08Z,let's get back the original indentation.,0,0.9856798648834229
428752600,8589,abbccdda,2020-05-21T16:02:44Z,nit: we could merge l3666-3667,0,0.9862972497940063
428753012,8589,abbccdda,2020-05-21T16:03:26Z,nit: we could name it `members` now,0,0.9825525283813477
428756738,8589,abbccdda,2020-05-21T16:09:52Z,i could see this doesn't hold true for a plain static member removal. let's discuss why skipping the individual member check in `removemembersfromconsumergroupresult` makes sense over there.,0,0.9832325577735901
428757676,8589,abbccdda,2020-05-21T16:11:25Z,collections.emptyset() makes more sense since it is immutable.,0,0.9840317368507385
428758681,8589,abbccdda,2020-05-21T16:13:16Z,"in `removeall()` mode, why could we skip the individual member removal results? i guess although we don't need to verify against the original member list (because they don't exist for `removeall`), going throw the sub error list is still valuable to make sure there is no unexpected failure.",0,0.9851834774017334
428758798,8589,abbccdda,2020-05-21T16:13:27Z,remove print statement.,0,0.9302109479904175
428762047,8589,abbccdda,2020-05-21T16:19:03Z,"this test looks good, but it seems that we didn't test the case where some members get deleted successfully while some are not?",0,0.5667906999588013
428763784,8589,abbccdda,2020-05-21T16:22:10Z,"should we check the member removal result here before proceeding? if that call failed, the whole operation should fail with error message containing the result imho.",0,0.9813073873519897
428764977,8589,abbccdda,2020-05-21T16:24:15Z,fair enough,0,0.9163533449172974
428767771,8589,abbccdda,2020-05-21T16:28:56Z,does this check duplicate l1103? also i think it makes sense to check all the members' clientid as they should all equal to `testclientid`,0,0.9869650602340698
428769255,8589,abbccdda,2020-05-21T16:31:25Z,"i prefer `testinstanceidone = ""test_instance_id_1""` and `testinstanceidtwo = ""test_instance_id_2""`",0,0.9758613705635071
428770028,8589,abbccdda,2020-05-21T16:32:48Z,size - 1,0,0.9782378673553467
428770176,8589,abbccdda,2020-05-21T16:33:09Z,we could remove this comment for now,0,0.9854495525360107
428770601,8589,abbccdda,2020-05-21T16:33:50Z,nit: format i'm pretty surprised this wasn't caught in my previous template. let me check how to cover this in style test as well.,0,0.8541710376739502
428771346,8589,abbccdda,2020-05-21T16:35:08Z,"what does `"""" + ` mean?",0,0.9686517119407654
428772089,8589,abbccdda,2020-05-21T16:36:25Z,nit: parameters are not aligned.,0,0.9252215623855591
428772936,8589,abbccdda,2020-05-21T16:37:52Z,"like said earlier, i think we could just return `return new streamsresetter().run(parameters, cleanupconfig) == 0`",0,0.9868466258049011
428773173,8589,abbccdda,2020-05-21T16:38:16Z,"we could add meta comment for the return value here, and instead of returning an exit code, i feel a boolean is suffice to indicate whether the clean operation was successful or not.",0,0.9875882267951965
429070319,8589,feyman2016,2020-05-22T06:43:25Z,"indeed, updated as suggested",0,0.9866011738777161
429070411,8589,feyman2016,2020-05-22T06:43:39Z,updated,0,0.9681491851806641
429071232,8589,feyman2016,2020-05-22T06:46:07Z,fixed,0,0.975196123123169
429082038,8589,feyman2016,2020-05-22T07:16:49Z,"without the `"""" +` to convert the value to string, we will get exception like: it is because `streams_consumer_timeout = 2000l`, `""""+` is widely used in this test, just follow it here without any change to not enlarge the scope of this pr, i can help to create a jira to enhance it if we think this workaround is not quite intuitive~ [code block]",0,0.9613820314407349
429082487,8589,feyman2016,2020-05-22T07:18:01Z,"thanks, but i wonder what does the **template** refer to here?",0,0.797711193561554
429083564,8589,feyman2016,2020-05-22T07:20:46Z,"removed, but curious about the reason :)",1,0.752313494682312
429083611,8589,feyman2016,2020-05-22T07:20:54Z,fixed,0,0.975196123123169
429083674,8589,feyman2016,2020-05-22T07:21:04Z,fixed,0,0.975196123123169
429083960,8589,feyman2016,2020-05-22T07:21:45Z,"thanks, all members' clientid are checked now",1,0.7644020915031433
429084219,8589,feyman2016,2020-05-22T07:22:22Z,"agreed, fixed",0,0.9692434072494507
429084559,8589,feyman2016,2020-05-22T07:23:04Z,good catch! added the test for partial failure,1,0.99169921875
429084786,8589,feyman2016,2020-05-22T07:23:40Z,"make sense, fixed",0,0.9557672739028931
429086933,8589,feyman2016,2020-05-22T07:28:59Z,"yeah, just as you surmised, but you are right, we should scan the removal results as well. slightly updated, followed the convention of `non-removeall` scenario, just return with the first exception",0,0.980946958065033
429087051,8589,feyman2016,2020-05-22T07:29:17Z,"yeah, fixed",0,0.9676406979560852
429087133,8589,feyman2016,2020-05-22T07:29:27Z,updated,0,0.9681491851806641
429087216,8589,feyman2016,2020-05-22T07:29:38Z,fixed,0,0.975196123123169
429087282,8589,feyman2016,2020-05-22T07:29:48Z,fixed,0,0.975196123123169
429087492,8589,feyman2016,2020-05-22T07:30:17Z,"make sense, fixed~",0,0.9334884285926819
429133442,8589,feyman2016,2020-05-22T09:11:18Z,fixed,0,0.975196123123169
429145185,8589,feyman2016,2020-05-22T09:35:24Z,"for removing static members, this still true because we put memberid as `""""` in the request, and the server will also response with the same request field. (verified `groupcoordinator#handleleavegroup`) for removing dynamic members, we need this change to know the memberid for the caller. i suppose the `individual check` here is just to check the response against the members to be removed(for `removeall` scenario)? previously i thought of putting all members got from `kafkaadminclient#getmembersfromgroup` in the removemembersfromconsumergroupresult for checking, but in `removeall` scenario, we get members as `memberidentity` which cannot be converted back to `membertoremove`, so i'm hesitate to do in this way",0,0.9803352355957031
429276600,8589,feyman2016,2020-05-22T14:22:23Z,wrap to let the failed member info available for caller like `streamsresetter`. only capture the first found member error like in the non `removeall` scenario.,0,0.9845989942550659
429329313,8589,abbccdda,2020-05-22T15:57:04Z,nit: extra semi-colon,0,0.9828954935073853
429333199,8589,abbccdda,2020-05-22T16:11:06Z,"let's put the exception in the cause so that we could verify the cause in `kafkaadminclienttest`, as: [code block]",0,0.9883699417114258
429333355,8589,abbccdda,2020-05-22T16:11:21Z,"nit: we could set `""0""` to `joingrouprequest.unknown_member_id` if we don't want to test it out. having all members use the same member.id is a bit weird.",-1,0.9833367466926575
429333999,8589,abbccdda,2020-05-22T16:12:30Z,nit: space after `*`. also i feel we could make the context more concrete by: [code block],0,0.9627012610435486
429338025,8589,abbccdda,2020-05-22T16:20:11Z,"i see, this is indeed weird, please file a jira so that we could clean in a follow-up pr if others feel the same way.",-1,0.985433042049408
429404004,8589,abbccdda,2020-05-22T18:50:06Z,this is no longer used.,0,0.8691840171813965
429504184,8589,feyman2016,2020-05-23T01:57:09Z,"cool, updated",1,0.9637916088104248
429504532,8589,feyman2016,2020-05-23T02:01:24Z,no existing help method to assert the cause of exception throw by `all()`. also i think it's more straight forward in this way.,0,0.981478214263916
429504600,8589,feyman2016,2020-05-23T02:02:25Z,removed,0,0.9654131531715393
429504705,8589,feyman2016,2020-05-23T02:04:05Z,"indeed, updated",0,0.9859524965286255
429504725,8589,feyman2016,2020-05-23T02:04:26Z,"yeah, updated",0,0.9818292856216431
429507189,8589,feyman2016,2020-05-23T02:44:53Z,"created [a link] for tracking, thanks!",1,0.9670791625976562
430828662,8589,mjsax,2020-05-27T02:51:46Z,why do we need this part? seems sufficient to end the test here?,0,0.9797220230102539
430828933,8589,mjsax,2020-05-27T02:52:49Z,"with `cleanglobal` and `--force` the consumer group could be empty when `cleanglobal` returns, right? hence, we should do this assertion without timeout or retries?",0,0.9872055053710938
430830840,8589,mjsax,2020-05-27T03:00:33Z,"if `option.members()` is empty, it implies that we do a `removeall()` -- hence, should we pass in `members` into the `removemembersfromconsumergroupresult` instead of `options.members()` ?",0,0.9878125786781311
430831033,8589,mjsax,2020-05-27T03:01:24Z,nit: fix formatting: [code block],0,0.989231526851654
430832010,8589,mjsax,2020-05-27T03:05:21Z,not sure if i understand the change. also not sure if i can follow the comments. can you elaborate?,0,0.5375207662582397
430832423,8589,mjsax,2020-05-27T03:07:09Z,"as we have different semantics for an empty collection (it was ""remove nothing"" originally, and we change it to ""remove all""), i am wondering if we should do a check if `members` is empty or not and throw an exception if empty? or at least log a warning that empty implies ""remove all"" now?",0,0.9087925553321838
430833520,8589,mjsax,2020-05-27T03:12:09Z,not sure why the `removeall()` case needs to be handled differently? can you elaborate?,0,0.9629015922546387
430833928,8589,mjsax,2020-05-27T03:13:55Z,"why that? i understand that we expect that users don't know the memberid if the so a ""remove all""; however, i don't see why we need to disallow this call? can you elaborate?",0,0.9614163637161255
430834203,8589,mjsax,2020-05-27T03:15:16Z,nit: formatting [code block],0,0.9882078766822815
430835656,8589,mjsax,2020-05-27T03:21:36Z,nit: formatting: move `new newtopic(...)` to next line,0,0.9878041744232178
431247169,8589,feyman2016,2020-05-27T15:48:10Z,"this is to verify that after the `successfully force removal of active members`, the stream application re-run can send exactly the same records again to the output topics",0,0.9876111149787903
431266629,8589,feyman2016,2020-05-27T16:11:11Z,"--- if option.members() is empty, it implies that we do a removeall() => yes, that is correct. --- hence, should we pass in members into the removemembersfromconsumergroupresult instead of options.members() => the members is of type `list ` and `memberidentity` contains field: `memberid` which supports the removal of dynamic members, while `options.members()` is of type: `set `, membertoremove only supports static member removal specification, in removemembersfromconsumergroupresult we treat similarly like in `removemembersfromconsumergroupoptions`, empty `members` implies `removeall`, we handle it in this way because we think in `non removeall` scenario we would only remove static members, while in `removeall` scenario we may remove both static and dynamic members.",0,0.979112982749939
431302352,8589,feyman2016,2020-05-27T17:02:53Z,"because in non `removeall` scenario, we have put the members to be deleted in the `removemembersfromconsumergroupresult#memberinfos`, while in the `removeall` scenario, we don't do so(members to be deleted are decided in the private method: `kafkaadminclient#getmembersfromgroup` of `kafkaadminclient`).",0,0.9849376082420349
431305795,8589,feyman2016,2020-05-27T17:08:53Z,"since in the `removeall` scenario, we don't save the members to be deleted in `removemembersfromconsumergroupresult`, so i think calling `memberresult` doesn't seem applicative.",0,0.944186806678772
431312462,8589,feyman2016,2020-05-27T17:20:23Z,fixed,0,0.975196123123169
431313074,8589,feyman2016,2020-05-27T17:21:25Z,make sense. it will throw exception if empty members provided now.,0,0.9885340332984924
431313236,8589,feyman2016,2020-05-27T17:21:43Z,fixed,0,0.975196123123169
431313242,8589,feyman2016,2020-05-27T17:21:44Z,fixed,0,0.975196123123169
431322560,8589,mjsax,2020-05-27T17:37:06Z,"seems redundant as tested somewhere else. and the purpose of the test is to verify `--force` itself. this additional checks have nothing to do with `--force` imho. it seems best to keep test to a ""minimum"".",0,0.9752920866012573
431323350,8589,mjsax,2020-05-27T17:38:31Z,thanks for clarifying.,0,0.5212144255638123
431327264,8589,mjsax,2020-05-27T17:45:07Z,"well, while `memberinfo` is empty for the `removeall` case, i am still wondering if the code for `removeall` would not work for the other case, too?",0,0.9752110838890076
431329158,8589,mjsax,2020-05-27T17:48:14Z,i see. makes sense.,0,0.9567835927009583
431341731,8589,feyman2016,2020-05-27T18:04:07Z,"yes, updated",0,0.9841416478157043
431345466,8589,feyman2016,2020-05-27T18:10:45Z,"i'm not sure i understand the question, could you elaborate more?",-1,0.7854568958282471
431352788,8589,feyman2016,2020-05-27T18:23:50Z,"yeah, i totally agree with: `it seems best to keep test to a ""minimum"".` not sure if my understanding is correct, but i still think the tests for `resetter` should compare the first run and re-run results, from the test's perspective, it cannot assume that `--force` option won't do something underneath that make the re-run produce different results. but i'm ok to remove the re-run part if we do think it's redundant.",0,0.8793900609016418
431354284,8589,mjsax,2020-05-27T18:26:19Z,"can we just do for both cases? [code block] the ""issue"" with using `memberinfos` is, that for the removeall() case it's empty and we cannot use it. however, `membererrors` should have an entry for all members for both cases?",0,0.9885954260826111
431355573,8589,mjsax,2020-05-27T18:28:43Z,fair enough. let's leave it as-is.,0,0.95215904712677
431372024,8589,feyman2016,2020-05-27T18:58:10Z,"i'm afraid not because, in the non `removeall` scenario, caller specify the members(`memberinfos`) to be deleted, and according to `maybecompleteexceptionally`, the `memberinfos` is used because it might sometimes happen that certain member in `memberinfos` cannot be found in `membererrors `, that's the reason i didn't use the `removeall` logic for all cases.",-1,0.7644861340522766
431373621,8589,mjsax,2020-05-27T19:00:58Z,thanks for explaining!,1,0.9328235387802124
199933294,5322,vvcephei,2018-07-03T19:59:28Z,"i think we did it this way on purpose, so we wouldn't automatically assume that later versions would have this data. but now that i'm looking at it again, it seems like this boolean expression will become silly. also, the risk of breakage is low. if we choose not to include this stuff in later versions, it'll be pretty obvious that we have to put an upper bound on this condition. so i think this change is good.",1,0.6110749840736389
199934416,5322,vvcephei,2018-07-03T20:04:10Z,"i don't think we need to move this field. when you use it, you return immediately after assigning it, so you could just make it a local variable in that block for return. then the uninitialized field won't be in scope for everything else in this method.",0,0.9839358329772949
199935554,5322,vvcephei,2018-07-03T20:08:46Z,"maybe we can introduce a method to build this assignment and save some vertical space in this super-long method. then you could just return it, such as `return errorassignment(clientsmetadata, errorcode)`. in fact, we could ditch this variable entirely, and just return directly in all three spots we currently set it.",0,0.9875889420509338
199938505,5322,vvcephei,2018-07-03T20:20:24Z,"it seems like it would be nice also to have a constant for the ""no error"" value (0). i'm wondering if namespacing the error codes would be beneficial. minimally, we could prefix the constant like ""err_unknown_partition"". or we could use an enum: [code block] then, we could encode with `out.writeint(errcode.getcode());` and decode with `assignmentinfo.errcode = error.fromcode(in.readint());` just an idea... what do you think?",0,0.8982879519462585
199939219,5322,vvcephei,2018-07-03T20:23:17Z,i guess we'll need one of these for version 4.,0,0.9821000099182129
199940084,5322,vvcephei,2018-07-03T20:26:38Z,"it seems like this new constructor only supports the ""error assignment"" code path. can we just inline it? i admittedly didn't quite follow why we need this version check now.",0,0.9383603930473328
199952165,5322,guozhangwang,2018-07-03T21:15:58Z,"this is a meta comment: i'd suggest having a separate check at the very beginning of `assign()`, after `step zero`, that for each entry value in `topicgroups = taskmanager.builder().topicgroups()`, if each of its `topicsinfo#sourcetopics` are either in `topicsinfo#repartitionsourcetopics` or can be found in `metadata`. if the check fails we immediately falls back into the error case of 1) log an error, and 2) set dummy assignment to all the clients with error code. then in line 419 here we do not need this `do-while` loop, instead we should follow the sub-topology id ordering to assign num.partitions for repartition topics, and if it cannot be decided we will throw an runtime exception since it is not expected any more. in addition we can remove `not_available` as well.",0,0.9785916805267334
199953001,5322,guozhangwang,2018-07-03T21:19:16Z,"+1, we can add an enum inside streamspartitionassignor which can be extended in the future. also for this error case the name `unknown_partition` is a bit confusing, i'd suggest we name it `incomplete_source_topic_metadata`. and upon receiving this error code we should log an error that `some of the source topics ( + source topic lists) are not known yet during rebalance, please make sure they have been pre-created before starting the streams application.`",0,0.9675868153572083
199953116,5322,guozhangwang,2018-07-03T21:19:44Z,"as mentioned in the jira ticket, we should log an error that `some of the source topics ( + source topic lists) are not known yet during rebalance, please make sure they have been pre-created before starting the streams application.`",0,0.9871357083320618
199953424,5322,guozhangwang,2018-07-03T21:20:57Z,nit: add empty line.,0,0.9813096523284912
199955030,5322,guozhangwang,2018-07-03T21:27:16Z,"this is another meta comment, not related to this line: in `copartitionedtopicsvalidator` we should also update the logic accordingly, first of the [code block] should never happen, since we would already fail before if the metadata is not complete, and the `not_available` case should not happen either (see my other comment). also note that there is a related bug fix pr for this jira long time ago about when the ensurecopartitioning should be called: [a link] with this general change: [code block] should not happen either since all topic's num.partitions should be determined by then.",0,0.9779744148254395
199955216,5322,guozhangwang,2018-07-03T21:28:03Z,"nit: add empty line between functions, ditto below.",0,0.9815946817398071
199956438,5322,guozhangwang,2018-07-03T21:33:15Z,"again this is another meta comment: the member decoding and handling leader's propagated assignment is in `onassignment`, in which the we decode `assignmentinfo` from `assignment#userdata`. in that function we should check the returned error code in `assignmentinfo`, and if it is not none we should ""gracefully"" shutdown than just throwing a runtime exception: for example, we can set a flag indicating we need to error out, and then in `onpartitionsassigned` callback we can check this flag and then decide to shutdown if necessary.",0,0.9763349294662476
199971943,5322,tedyu,2018-07-03T23:01:43Z,"for onpartitionsassigned, did you mean the method in streamthread ? the method takes collection . does this mean the flag should be added to topicpartition ?",0,0.98912513256073
199972239,5322,tedyu,2018-07-03T23:04:07Z,"still need to figure out how to follow the sub-topology id ordering. for now, i keep the do-while loop.",0,0.9799278974533081
200792196,5322,guozhangwang,2018-07-06T23:32:18Z,"the way `streamthread` class and `streamspartitionassginor` communicates today is bit weird: in order to break mutual dependency and keep the code cleaner, what we did is to pass in mutually needed modules as internal configs via the `streamsconfig`, which `streamspartitionassignor` will call `configure` on. the process works the following: 1. when streamthread creates the consumer, it adds more objects into the properties map to the consumer. 2. consumer client would create the instantiated `streamspartitionassignor`, which will then call `configure` with the passed in properties. the reason is because of the way consumers instantiate their coordinator's `assignor` object today. 2.a) for example, streamthread passed in the `taskmanager` object as `streamsconfig.internalconfig.task_manager_for_partition_assignor`. the streamspartitionassignor would then call its update functions to update the assigned tasks, which stream thread would then try to access in its own class. another example is we pass in the version prob flag as an `atomicboolean` to be set / reset between these two classes as `streamsconfig.internalconfig.version_probing_flag`. so what i meant for a `flag` is to suggest doing the similar thing like the `atomicboolean prob-flag`, in which `streamspartitionassignor` can set in its `onassignment` function. the `onpartitionassigned` function called within `streamthread` can then check this flag. for more details you can reference the current implementation pattern of the version probing flag",-1,0.9552763104438782
200792492,5322,guozhangwang,2018-07-06T23:35:44Z,"one way to break the while loop, is to rely on the [code block] note the `integer` key is indeed the sub-topology id here, and since we sort the sub-topology by their ids, starting with `1`, the first sub-topology 1 should have no internal topics as its source topic. so we can start by this key ordering, to first determine any of the repartition topic's num.partitions as their sink topics of sub-topology 1, and then based on them as for the source topics of sub-topology 2, we can determine sub-topology 2's sink repartition topic's numb.partitions, and so on.",0,0.9777660369873047
201814927,5322,guozhangwang,2018-07-11T19:36:10Z,it is simpler to just have an `encodeversionfour` which does not change anything than `encodeversionthree` but just put the different version. note that within this release cycle we may introduce other format changes as well (so eventually the `encodeversionfour` may be implemented differently anyways).,0,0.9862090945243835
201815805,5322,guozhangwang,2018-07-11T19:39:33Z,"nit: rename to `__assignment.error.code__` and `assignment_error_code`? another comment: thinking about this a bit more, maybe we can subsume the `version_probing_flag` with the `assignment_error_code`, as upon receiving the error code the member should be handling it separately on the error code, sometimes re-join the group with a down-graded encoding version, some time to shutdown, etc. with that we can generalize the handling logic.",0,0.9764837622642517
201816222,5322,guozhangwang,2018-07-11T19:41:19Z,"for trouble shooting only: maybe we can still check that `!partitions.isempty()`, and if yes log an fatal and throw runtime exception? if we had a bug that still causes `partitions.size() == 0`, then the line 83 below would silently skip assigning the maxnumpartitions update, which would be very hard to capture during debugging.",0,0.8172286748886108
201818695,5322,guozhangwang,2018-07-11T19:50:35Z,"i think it is to not call `return` after that since line 272 below will return null and hence return anyways, plus it will log the final debug entry as well. also note that in the only other caller we do [code block] i.e. we need to set `thread.setstatelistener(null);` since otherwise there may be deadlock issues. we need to do the same here.",0,0.9870377779006958
201819967,5322,guozhangwang,2018-07-11T19:55:16Z,cc wdyt?,0,0.9808274507522583
201820822,5322,guozhangwang,2018-07-11T19:58:04Z,nit: comment line misaligned,0,0.8462771773338318
201821078,5322,guozhangwang,2018-07-11T19:59:02Z,"see my other comment: it's better just duplicate the logic of handling version 3 and version 4 information for now, as we may add new info for version 4 soon which would make the handling logic different.",0,0.9844150543212891
201824357,5322,guozhangwang,2018-07-11T20:12:12Z,"same as above, let's add a fatal error and throw a runtime exception like illegalstateexception.",0,0.9761558771133423
201824624,5322,guozhangwang,2018-07-11T20:13:10Z,this seems not used.,0,0.9038482904434204
201825636,5322,guozhangwang,2018-07-11T20:16:53Z,nit: empty line.,0,0.8843977451324463
201825651,5322,guozhangwang,2018-07-11T20:16:55Z,nit: align parameters.,0,0.9836226105690002
201825785,5322,guozhangwang,2018-07-11T20:17:27Z,we can remove the code block line 82-85 above since it will be called here.,0,0.9888863563537598
201826312,5322,guozhangwang,2018-07-11T20:19:19Z,"ditto, i'd suggest just duplicating the code since we may add more logic for version 4 anyways.",0,0.9752464890480042
201826496,5322,guozhangwang,2018-07-11T20:19:57Z,nit: latestsupportedversion,0,0.9885886907577515
201826570,5322,guozhangwang,2018-07-11T20:20:13Z,nit: align parameters.,0,0.9836226105690002
201826760,5322,guozhangwang,2018-07-11T20:20:55Z,ditto. let's just add an `encodeversionfour` with duplicated logic except the version.,0,0.9711653590202332
201843313,5322,tedyu,2018-07-11T21:21:47Z,"version probing is a boolean flag. assignment error code is int. if we unify these two, we need to encode version probing. btw version probing doesn't imply assignment error.",0,0.9879750609397888
201850915,5322,tedyu,2018-07-11T21:49:45Z,unfortunately no. the `this` call goes to line 100 where this is no such check.,-1,0.5613359212875366
201851272,5322,tedyu,2018-07-11T21:51:16Z,addition to version 4 can be added at the end of `encodeversionfour`,0,0.9875124096870422
201851485,5322,tedyu,2018-07-11T21:52:12Z,i did that first - resulting in duplicate local variable.,0,0.9851465821266174
202841909,5322,guozhangwang,2018-07-16T22:15:37Z,"yes, my intention is to use another error code value (seems you've already done it as `version_probing`) to replace the flag, and then after onassignment is called we would check the error code and if it is not `none` react accordingly, it may be simply shutdown and stop-the-world, or other actions like down-grade.",0,0.9567194581031799
202842440,5322,guozhangwang,2018-07-16T22:18:13Z,i see --- we can define latestsupportedversion before the switch not as a `final` int then?,0,0.9895619750022888
202855945,5322,guozhangwang,2018-07-16T23:29:29Z,"if we are adding this function in `kafkastreams` then we do need a kip.. but i was thinking if we can just add this in `streamthread`, which is an internal class and hence doing so does not need a kip. we can, instead, add a `kafkastreamswrapper` (it is similar to `topologywrapper` and `topologytestdriverwrapper` to allow unit test code to access their internal private fields) which can access the threads and globalthread, and then adds this function in this class to manipulate them. also note that streamthread already has a state change listener `final class streamstatelistener implements streamthread.statelistener` so our `statelistenerstub` should not completely replace its logic. instead we can extend that listener to `statelistenerstub` which does the state change tracing in additional to the necessary logic.",0,0.9778391122817993
202856322,5322,guozhangwang,2018-07-16T23:31:58Z,"this condition seems not right: we should not shutdown if the error was `version_probing`, right? i.e we should firstly check if the error was `none`, and if not, switch branch on the actual error code to handle them accordingly.",0,0.9552989602088928
202856380,5322,guozhangwang,2018-07-16T23:32:17Z,"similarly, here we would only create tasks if the error was `none`.",0,0.9856325387954712
202856437,5322,guozhangwang,2018-07-16T23:32:39Z,case 2 is missing.,0,0.9481071829795837
202856560,5322,guozhangwang,2018-07-16T23:33:24Z,ping again.,0,0.9783717393875122
202857024,5322,guozhangwang,2018-07-16T23:36:20Z,"as we are merging the two scenarios to use the error code, we should let the leader to set the error code in the version probing case as well as setting the `receivedassignmentmetadataversion` in the assignment. and then we only need to do the logic in line 796 above, and do not need to set it in line 827 any more.",0,0.9872090816497803
202857302,5322,guozhangwang,2018-07-16T23:38:05Z,we should not use a `topologyexception` here any more since `topologyexception` should be used for dsl statement parsing only. instead we could just throw an illegalstateexception since it should never be expected (i.e. if the metadata is indeed not known we should error out with the error assignment earlier and never reach this line).,0,0.9682357907295227
202857594,5322,guozhangwang,2018-07-16T23:39:56Z,adding a parameter `version` for `encodeversionthree` is very confusing to other readers. i'd suggest completely duplicate the code in `encodeversionfour` and remove this parameter in `encodeversionthree`.,-1,0.7627466917037964
202857927,5322,guozhangwang,2018-07-16T23:42:01Z,"thanks for adding this integration test! it looks reasonable, but we'd generally adding integration java test under `org.apache.kafka.streams.integration`, not `org.apache.kafka.streams.scala` (the latter is only for the scala api only).",1,0.9846225380897522
202858371,5322,guozhangwang,2018-07-16T23:44:49Z,"and also the title `testshouldcountclicksperregionwithmissingtopic` is confusing, it should be `shouldshutdownwithmissingtopic` right? and note this class is for `streamtotablejoinscalaintegrationtestimplicitserdes`, so not the right class to add this test. i'd suggest adding a new test class under the above mentioned package for this test case, like `assignmenterrorhandlingintegrationtest`, and this test case be `shouldautoshutdownonincompletemetadata`.",0,0.9355097413063049
202864203,5322,tedyu,2018-07-17T00:23:59Z,pardon. can you explain in a bit more detail ? i am not sure how leader sets the error code for version probing if not done on line 827.,-1,0.8723986148834229
202867018,5322,tedyu,2018-07-17T00:45:35Z,"i took a look at streams/src/test/java/org/apache/kafka/streams/integration/streamtablejoinintegrationtest.java where cluster is not involved. if i move the new test there, a lot of scala code for setting up the testing environment would be repeated. it seems more intuitive if the new integration test is added in this test class in terms of code reuse.",0,0.9758573174476624
202868232,5322,tedyu,2018-07-17T00:55:42Z,please confirm: threads and state fields of kafkastreams can be changed to protected. otherwise the new method in kafkastreamswrapper still cannot access them.,0,0.9890553951263428
202901382,5322,guozhangwang,2018-07-17T05:56:17Z,"yes, they can.",0,0.9724380970001221
202901958,5322,guozhangwang,2018-07-17T06:00:28Z,"currently the version probing works as the following: 1. when leader receives the subscription info encoded with a higher version that it can understand (e.g. the leader is on version 3, while one of the subscription received is encode with version 4), it will send back an empty assignment with the assignment encoded with version 3, and also `latestsupportedversion` set to 3. 2. when the member receives the assignment, it checks if `latestsupportedversion` is smaller than the version it used for encoding the sent subscription (i.e. the above logic). if it is smaller, then it means that leader cannot understand, in this case, version 4. it will then set the flag and then re-subscribe but with a down-graded encoding format of version 3. now with your pr, we can let leader to clearly communicate this error via the error code, and upon receiving the assignment, if the error code is `version_probing`, then the member can immediately know what happens, and hence can simplify the above logic. does that make sense? also cc",0,0.9846944212913513
202902176,5322,guozhangwang,2018-07-17T06:01:51Z,"i understand the code duplication, but still adding a test case that has nothing to do with `streamtotablejoinscalaintegrationtestimplicitserdes` is not recommended. i'd still suggest making a new class and duplicate the setup code a bit.",0,0.9854288697242737
202932846,5322,tedyu,2018-07-17T08:22:31Z,"in the example given above, the gap in subscription info versions between leader and the member is 1. is the expectation that when the gap is > 1, at least one round trip is reduced for version probing compared to the existing implementation ? the version probing error code currently is hard coded and not correlated with the actual gap. i wonder if the optimization can be done in another jira.",0,0.9059362411499023
203204145,5322,mjsax,2018-07-17T22:41:10Z,"iirc, the idea was to be as explicit as possible and list out the versions, in case a future version does not encode `partitionsbyhoststate` any longer. the risk of the change is small though. i am ok with it.",0,0.9375070929527283
203204413,5322,mjsax,2018-07-17T22:42:43Z,nit: code formatting and missing `final`: [code block],0,0.9888771176338196
203204472,5322,mjsax,2018-07-17T22:42:57Z,nit: add `final`,0,0.9880309700965881
203204612,5322,mjsax,2018-07-17T22:43:41Z,nit: use `{}` instead of string concatenation,0,0.9891504645347595
203204975,5322,mjsax,2018-07-17T22:45:43Z,not sure if calling `shutdown()` directly is the best way? shouldn't we just `return` and break the loop in `streamthread#runloop()` ?,0,0.9618328809738159
203205168,5322,mjsax,2018-07-17T22:46:38Z,nit: use `{}` instead of string concatenation,0,0.9891504645347595
203205249,5322,mjsax,2018-07-17T22:47:08Z,nit: add `final`,0,0.9880309700965881
203205508,5322,mjsax,2018-07-17T22:48:23Z,why remove `final` ?,0,0.958608090877533
203205842,5322,mjsax,2018-07-17T22:49:59Z,"`processversionthreeassignment` -> `processversionfourassignment` if both are identical, it's ok to call `processversionthreeassignment()` from within `processversionfourassignment()` imho, but adding a `processversionfourassignment()` seems to be cleaner to me.",0,0.9781955480575562
203206140,5322,mjsax,2018-07-17T22:51:46Z,`final` ?,0,0.9830428957939148
203206482,5322,mjsax,2018-07-17T22:53:30Z,do we need this new constructor? can the existing one not just be extended with `errorcode`?,0,0.9884971380233765
203206896,5322,mjsax,2018-07-17T22:55:50Z,nit: add `final`,0,0.9880309700965881
203206912,5322,mjsax,2018-07-17T22:55:55Z,nit: add `final`,0,0.9880309700965881
203206951,5322,mjsax,2018-07-17T22:56:07Z,nit: indention,0,0.7653846144676208
203207194,5322,mjsax,2018-07-17T22:57:30Z,why do you remove this test?,0,0.9573639035224915
203207828,5322,guozhangwang,2018-07-17T23:01:17Z,"hmm.. i'm not sure if this is the right fix, but maybe upgrading the test when we bump up version is also out side the scope of this pr itself. i'll let to take a look and decide how can we fix forward the upgrade-test.",0,0.9122517108917236
203208753,5322,mjsax,2018-07-17T23:06:40Z,"if we bump the version, we need to update this to 5 and 4 as already done. we should also make this more generic and test upgrades from 3 -> 4, 3 -> 5 and 4 -> 5. the current code does only go from latest version to future version. however, generalizing the test should be out of scope of this pr and just changing the expected numbers should be fine for this pr.",0,0.9717112183570862
203209970,5322,tedyu,2018-07-17T23:13:46Z,the type of the version probing flag has changed from boolean to integer. there is another subtest for checking the error code.,0,0.9876337051391602
203210372,5322,tedyu,2018-07-17T23:16:16Z,this was suggested by guozhang and i tend to agree with calling shutdown(),0,0.969595730304718
203216673,5322,mjsax,2018-07-17T23:55:19Z,"i understand that. thus, this test should be updated to `shouldthrowkafkaexceptionifversionprobingflagconfigisnotatomicinteger` -- it tests the data type, ie, the cast operation.",0,0.9821847081184387
203216813,5322,mjsax,2018-07-17T23:56:01Z,what is the reasoning behind this?,0,0.8992058038711548
203248963,5322,guozhangwang,2018-07-18T04:35:43Z,"copying my response from the email thread: [code block] currently i cannot think of a race condition that calling `shutdown` in the callback would introduce than calling shutdown in the main loop, but i'm not 100% sure, so i insisted on triggering a system test.",0,0.8676915764808655
203542445,5322,mjsax,2018-07-18T21:54:19Z,"this should never happen, right? thus, i am wondering if we should throw an `illegalstateexception` instead?",0,0.8122897744178772
203542534,5322,mjsax,2018-07-18T21:54:38Z,nit: add `{ }` to then-block,0,0.9886888861656189
203542781,5322,mjsax,2018-07-18T21:55:50Z,seems this slipped in the last update.,0,0.8900395035743713
203543587,5322,mjsax,2018-07-18T21:58:57Z,"ack. we might still want to add a `return` to make clear it's an early exit. of course, the `if` below evaluate to `false` anyway, however, it makes the code more readable imho.",0,0.9684764742851257
203544388,5322,mjsax,2018-07-18T22:02:10Z,nit: we usually omit `get` prefix for all getter method. please update to `code()` to align with common naming conventions.,0,0.9888148903846741
203544506,5322,mjsax,2018-07-18T22:02:35Z,comment can be omitted,0,0.9804635643959045
203547299,5322,mjsax,2018-07-18T22:15:20Z,"for future version this might work. however, if we upgrade from 2.0 to 2.1 with version bump from 3 -> 4, the old leader is on version 3 and cannot encode the version probing via the error flag. as we are stuck with older version 3 metadata, i am not sure if we gain a lot if we change the logic, as we still need the current code anyway.",0,0.9512582421302795
203547399,5322,mjsax,2018-07-18T22:15:50Z,nit: fix indention,0,0.9871826171875
203548013,5322,mjsax,2018-07-18T22:18:58Z,why do we move this up here? `topics` is only used when an exception is thrown (or did i miss anything)?,0,0.976288914680481
203548143,5322,mjsax,2018-07-18T22:19:35Z,did this slip?,0,0.8697061538696289
203548277,5322,mjsax,2018-07-18T22:20:13Z,any comments? i would like to keep the number of constructors small if possible.,0,0.9818335175514221
203548421,5322,mjsax,2018-07-18T22:20:52Z,nit: rename to `errorcode` ? we try to avoid abbriviations,0,0.9778003692626953
203548476,5322,mjsax,2018-07-18T22:21:06Z,nit: rename `errorcode()`,0,0.9871122241020203
203548586,5322,mjsax,2018-07-18T22:21:40Z,nit: add empty line,0,0.9846440553665161
203548969,5322,mjsax,2018-07-18T22:23:18Z,add `getversionfourbytelength()` ? or rename method to `getversionthreeandfourbytelength()` ?,0,0.9879042506217957
203549210,5322,mjsax,2018-07-18T22:24:16Z,nit: fix indention,0,0.9871826171875
203549314,5322,mjsax,2018-07-18T22:24:47Z,nit: add empty line,0,0.9846440553665161
203549359,5322,mjsax,2018-07-18T22:25:01Z,seems this slipped,0,0.9248175024986267
203549395,5322,mjsax,2018-07-18T22:25:11Z,seems this slipped,0,0.9248175024986267
203549533,5322,mjsax,2018-07-18T22:25:49Z,seems this slipped,0,0.9248175024986267
203549904,5322,mjsax,2018-07-18T22:27:14Z,should we change the test to expect an exception instead of removing it?,0,0.9790548086166382
203550235,5322,mjsax,2018-07-18T22:28:20Z,"as above: should we check that an exception is thrown? (we had ""infinite loop"" bugs in the past -- those tests seems to be valuable)",0,0.984214723110199
203550652,5322,mjsax,2018-07-18T22:29:45Z,seems this can be removed?,0,0.9869731068611145
203550712,5322,mjsax,2018-07-18T22:29:59Z,"seems, this can be removed?",0,0.9866837859153748
203555179,5322,mjsax,2018-07-18T22:49:12Z,why is this change required? it seems we forgot to update `assignmentinfo#equals()` and `assignmentinfo#hashcode()`...,0,0.9680536389350891
203555598,5322,mjsax,2018-07-18T22:51:27Z,how does this test relate to the change?,0,0.977797269821167
203555659,5322,mjsax,2018-07-18T22:51:52Z,as above? why do we change this test?,0,0.9721298813819885
203556910,5322,tedyu,2018-07-18T22:58:08Z,"right, this code shouldn't be reached.",0,0.9036945700645447
203557121,5322,tedyu,2018-07-18T22:59:13Z,there is no then-block - i guess you mean the if-block.,0,0.9830536246299744
203559036,5322,tedyu,2018-07-18T23:09:57Z,i want to mention versionprobingflag just in case some developer who knew the flag comes wondering what happened to the flag :-),1,0.9209535121917725
203559379,5322,mjsax,2018-07-18T23:11:30Z,"terminology is fun... it's and if-then-else statement -- there is no `then` keyword, but still and then-block -- interesting that you call it if-block :)",1,0.9818852543830872
203559593,5322,mjsax,2018-07-18T23:12:51Z,`git blame` is their friend :) -- that's why there is a commit history. allows us to keep the code base clean :),1,0.919481098651886
203563364,5322,tedyu,2018-07-18T23:34:18Z,right.,0,0.9566289782524109
203564178,5322,tedyu,2018-07-18T23:39:04Z,streamtotablejoinscalaintegrationtestbase is created for reusing cluster setup code between existing test and new integration test.,0,0.9891352653503418
203564273,5322,tedyu,2018-07-18T23:39:37Z,streamtotablejoinscalaintegrationtestimplicitserdes is changed to preserve non-cluster setup test code.,0,0.9887645244598389
203564445,5322,tedyu,2018-07-18T23:40:44Z,i see - yeah i call it if block.,0,0.9815908670425415
203807596,5322,mjsax,2018-07-19T17:21:41Z,"as mentioned in a previous comment, we need to update `hashcode()` and `equals()`.",0,0.9869623780250549
203829239,5322,mjsax,2018-07-19T18:31:54Z,"i understand your other test changes now. however, i am wondering why we add this test to the scala module in the first place? kafka streams is written in java, and we should write all tests in java, too. the scala module is just a thin language wrapper on top, and integration tests in the scala module should only test the scala/java integration, but not core functionality. this test belongs to `stream/src/test/java/org/apache/kafka/stream/integration` thus, my argument is not really about java vs scala, but putting test into the scala wrapper module scatters our test code across two modules and we should not do this.",0,0.9246050715446472
1137856849,13391,jolshan,2023-03-15T23:01:21Z,bug here -- we don't want to clear non-inflight nodes.,-1,0.7976296544075012
1137901882,13391,jolshan,2023-03-16T00:00:27Z,i have a fix i will push with the rest of the tests,0,0.9825106263160706
1142707455,13391,artemlivshits,2023-03-20T21:44:34Z,"looks like this could be called from multiple threads, do we need to add synchronization?",0,0.9879940748214722
1142722842,13391,artemlivshits,2023-03-20T22:07:29Z,"would it be possible to have a retry (say first request timed out, and then we send another one) and have more than one request?",0,0.986900269985199
1142729789,13391,artemlivshits,2023-03-20T22:17:58Z,we could use getorelseupdate.,0,0.9866248369216919
1142747856,13391,artemlivshits,2023-03-20T22:48:21Z,"if the request is already in flight, looks like we wouldn't be able to detect and reject a stale request here. is it needed for correctness? if yes, we need to fix that, if not, i'd propose to remove this logic and just properly handle stale epoch when it gets to transaction coordinator.",0,0.980338990688324
1142753293,13391,artemlivshits,2023-03-20T22:58:00Z,inflightnodes seem to be accessed only by the inter-broker send thread so synchronization is not actually needed.,0,0.9841863512992859
1142758001,13391,artemlivshits,2023-03-20T23:06:56Z,"shouldn't it get cleared automatically once it gets out of scope? if there is a tricky consideration, let's add a comment.",0,0.9801052212715149
1142762452,13391,artemlivshits,2023-03-20T23:15:37Z,"is this client going to be used only for addpartitionstotxnmanager or some other inter-broker communication (in the future) as well? if it the former, we should make name more specific.",0,0.9883409142494202
1142786061,13391,jolshan,2023-03-21T00:08:15Z,"i thought about that, but i was concerned about blocking on a single produce request too long. i though maybe the producer's retry mechanism would be enough to handle this.",-1,0.6898209452629089
1142787086,13391,jolshan,2023-03-21T00:10:10Z,i think it's ok to have new data when a request is inflight. the issue is that i have an invariant here that we can only have one queued item for a given txn id at a time. this is due to how the information is stored in the map. the only time we can receive two requests from the same txn id is when the producer restarts and the epoch is bumped. that is why i have this logic here.,0,0.9728227853775024
1142787356,13391,jolshan,2023-03-21T00:10:48Z,i guess i was considering more than one send thread :grinning_face_with_sweat: i guess we don't have that now.,-1,0.8198069930076599
1142788144,13391,jolshan,2023-03-21T00:12:38Z,we are reusing this for each transactional id and it remains in scope at this time.,0,0.9872888326644897
1142788313,13391,jolshan,2023-03-21T00:13:00Z,we can make it more specific.,0,0.9814759492874146
1144090231,13391,junrao,2023-03-21T23:38:45Z,does the todo still need to be addressed?,0,0.9837623238563538
1144092204,13391,junrao,2023-03-21T23:41:57Z,could we add a new line after?,0,0.9855892062187195
1144106075,13391,junrao,2023-03-22T00:13:25Z,could this be private?,0,0.9868327379226685
1145103445,13391,junrao,2023-03-22T16:26:10Z,"i am wondering why we need to do this in a request thread. for example, transactionmarkerrequestcompletionhandler already appends to the log in a separate thread.",0,0.9647331237792969
1145118797,13391,junrao,2023-03-22T16:36:44Z,we already have a transactionmarkerchannelmanager for txn coordinator to send requests to brokers. could we reuse that for sending requests from brokers to txn coordinators? we probably don't want too many separate threads for exchanging requests among brokers.,0,0.9813913106918335
1145376271,13391,jolshan,2023-03-22T20:30:39Z,we are sending from the partition leader to the txn coordinator. can we still use that same thread? i think the usage is different right?,0,0.9860894680023193
1145376651,13391,jolshan,2023-03-22T20:31:03Z,thought this should be done. perhaps he can explain better than me.,0,0.9189274907112122
1145453181,13391,junrao,2023-03-22T22:01:40Z,"that's true. however, if you look at transactionmarkerchannelmanager, the main api is `addmarkersforbroker`. so at that level, it's just sending some requests to another broker. in addpartitionstotxnmanager, its main api is `addtxndata`. again, it's just sending some requests to another broker. instead of creating more and more of those specialized broker-to-broker communication channels, it may be better to consolidate them into a single general framework.",0,0.9829553961753845
1145463265,13391,jolshan,2023-03-22T22:15:52Z,"i thought about this, but the trouble is how each request is built slightly differs. some of them pass the node they are sending to when sending adding the request (like this one) and some do the calculation right before (ie, controller channel manager) i can take a look at the transaction channel marker channel manager and see how it handles it. but i think the other benefit for this class is keeping all the add partitions logic together. perhaps there is a way to consolidate this, but also use the same thread/channel?",0,0.9345929026603699
1145487679,13391,junrao,2023-03-22T22:55:39Z,"yes, i was wondering if there is a way to reuse the thread and the channel for broker to broker communication for all low volume requests.",0,0.9685183763504028
1145533272,13391,jolshan,2023-03-22T23:54:53Z,i can look into this. do we also want to handle the callback on that same thread still?,0,0.9878786206245422
1145545834,13391,junrao,2023-03-23T00:21:10Z,"yes, that's what i was wondering. transactionmarkerchannelmanager writes the final commit to the log in the callback of sending the marker to the broker. i am wondering if we could just do the same here.",0,0.9411951899528503
1145549423,13391,jolshan,2023-03-23T00:30:05Z,"i think is the best to answer this. he was the one who said we should do this and although i vaguely remember the explanation, he will do a better job explaining.",0,0.7556840181350708
1146789680,13391,YiDing-Duke,2023-03-23T20:24:15Z,"if 1st request timeout, the second one cannot hit this stage unless 1st one is done due to connection muted?",0,0.9866302013397217
1146821982,13391,jolshan,2023-03-23T20:46:16Z,"yi is correct. i also think if we hit timeout, it is the epoch bump case i mentioned before.",0,0.9828979969024658
1146944915,13391,junrao,2023-03-23T22:36:19Z,"chatted with artem offline. his reasoning is for performance. it's better to do any io related operations in the request thread pool to prevent blocking the callback thread. this could be a bit better. if we do this, maybe we should also change transactionmarkerrequestcompletionhandler so that it writes the complete marker in the request thread instead of the callback thread. that could be done in a followup jira.",0,0.9357517957687378
1146951880,13391,jolshan,2023-03-23T22:49:09Z,(answer is above),0,0.9841685891151428
1147152053,13391,artemlivshits,2023-03-24T06:01:39Z,"this should be .offer -- we don't need to block if the request queue is full, and it's ok if we don't have a wakeup request in a full queue -- the queue would would contain a request (due to the fact that it's full) to wake up the poll.",0,0.979812502861023
1147156380,13391,artemlivshits,2023-03-24T06:10:23Z,"we could probably handle wakeuprequest in this function, so that the wakeup mechanism is encapsulated in requestchannel (i.e. check if we got a wakeup request from the requestqueue and poll the callbackqueue again in that case).",0,0.9888536930084229
1147689005,13391,junrao,2023-03-24T14:50:15Z,could we just reuse the actionqueue instead of introducing a new queue? actionqueue is drained by the request thread whenever it finishes processing the current event.,0,0.9888152480125427
1147787658,13391,jolshan,2023-03-24T16:05:36Z,will we still have the behavior of putting the callback at the front of the queue? it would go to the end of the action queue right?,0,0.9869222044944763
1147789029,13391,jolshan,2023-03-24T16:06:54Z,offer was throwing spotbugs errors since i didn't check the response. i can do that but it will be a little uglier.,-1,0.980582058429718
1147794328,13391,junrao,2023-03-24T16:11:55Z,"it would go to the end of the action queue. however, not every request adds entries to the action queue. so, the action queue is typically smaller than the request queue. also, request threads prioritize the action queue over the request queue.",0,0.9872708320617676
1147804661,13391,jolshan,2023-03-24T16:22:05Z,so it is the case that all the action entries are removed before the next request? for some reason i thought it just cleared one for each request. i can take a look.,0,0.9874662756919861
1147813111,13391,junrao,2023-03-24T16:28:59Z,it clears all entries it sees at the beginning. [code block],0,0.9883055686950684
1147857120,13391,jolshan,2023-03-24T17:09:05Z,thanks!,1,0.9308210611343384
1147991721,13391,artemlivshits,2023-03-24T19:43:30Z,"if a request hits a timeout the new request will come in the new connection, so the fact the old connection is muted wouldn't prevent the new request to come. the timeout processing on the client is just a timer, once it expires, it'll kill old connection, create a new one and re-send the batch. we won't bump the epoch on retry -- it'll override duplicate checking logic, so we'd have duplicates if we did, so the exact same batch (same epoch, same sequence) will come again on the new connection.",0,0.9785829782485962
1147999817,13391,artemlivshits,2023-03-24T19:53:33Z,i'd expect the synchronization would be added as part of making the class properly multithreaded.,0,0.9881487488746643
1148002291,13391,artemlivshits,2023-03-24T19:56:51Z,"should we move it to the proper scope then? (the indentation is hard to follow in the pr view, i assumed it's already in the proper scope)",0,0.9821901321411133
1148025113,13391,artemlivshits,2023-03-24T20:29:51Z,"oh, i see, we have only one request for a trasnactional.id, so we need to complete previous one in order to replace. see my other comments about retries.",0,0.9849934577941895
1148044044,13391,artemlivshits,2023-03-24T20:52:43Z,"we could try to re-purpose the action queue for this, but it currently has different semantics -- the error processing is different, for example (it's executed in the finally clause). what we want here is the semantics that we'd get if we just blocked the thread while we're contacting tc, but without blocking the thread. same error handling, same context, same metrics, etc. the basic implementation of the desired semantics is just a queue, but we could also preserve request context (see todos in kafkarequesthandler.scala) so that this functionality that would work for any requests that need to do non-blocking async calls.",0,0.9787967205047607
1148057123,13391,artemlivshits,2023-03-24T21:08:17Z,"i guess, if the request queue is full then it means that the request threads are all overloaded, so if we block the inter-broker channel thread it probably wouldn't matter much as the broker is already in pain. but on the other hand, it's kind of strange to not implement technically more correct behavior because we've got some spurious warnings.",-1,0.8872087001800537
1148060963,13391,artemlivshits,2023-03-24T21:14:41Z,"we should measure the time it took to process the request to tc and report it (either as ""remote time"" that we already have or as a new metric), otherwise it'll just roll into ""local time"" (time spent by this broker to handle the request).",0,0.9870498776435852
1148081688,13391,jolshan,2023-03-24T21:39:48Z,yeah. i planned to look at the request timing stuff next. thanks for the reminder :),1,0.9906383752822876
1148082243,13391,jolshan,2023-03-24T21:40:36Z,the build will fail with the warnings. but i can add the extra code so the build passes.,0,0.9781437516212463
1148084290,13391,jolshan,2023-03-24T21:42:44Z,"ah. i guess i was thinking of the client restarting. so you are saying in the case where the request times out before we send the request here, we can hit the error?",0,0.9828304052352905
1149586417,13391,jolshan,2023-03-27T17:34:15Z,i think we want to update in both cases -- and we want to distinguish the two.,0,0.9802120923995972
1149838206,13391,artemlivshits,2023-03-27T22:12:27Z,"yes, that's my understanding based on my reading of the code -- once a connection to a broker has at least one timed-out in-flight request, it's disconnected and all in-flight requests get a timeout error (which can be then retried by the producer on a new connection). [a link] it's also not guaranteed that the request that comes later here is the retry (i.e. the assumption that we can just fail the previous request because it must've timed out anyway is not true). should be unlikely with default settings, so we can probably just return some retriable error and document the caveat. alternatively (i would actually prefer that), we could just support multiple requests per transactional.id which would eliminate the need to handle this case here altogether: just add all new requests to the pending ""batch"" and let the tc handle different cases.",0,0.9533100724220276
1149847782,13391,jolshan,2023-03-27T22:28:23Z,i don't think we can add multiple to the batch because of how the callbacks are currently implemented. we would need to know which response goes to which callback. i thought about this a while and one callback is the the simplest way to do it.,0,0.9574129581451416
1149873099,13391,artemlivshits,2023-03-27T23:14:12Z,"ok, looks like the protocol is not designed to support multiple requests for one transactional.id. for same-epoch case, though, we'd get the same answer because we'd be asking the same question, so we could just keep multiple callbacks per trasnactional.id and call them all with the response, this way we don't have to guess which message is first and which is the retry.",0,0.9830238819122314
1149903116,13391,jolshan,2023-03-28T00:17:49Z,hmm -- would it be better to just replace the old one? i don't think we'd expect two responses. and we definitely don't want to write twice.,0,0.7664591670036316
1151026334,13391,artemlivshits,2023-03-28T18:44:14Z,we don't know which one is the old one -- the one that's there or the one that just arrived. we won't write twice -- at some point we'll check for duplicates and one of the requests would succeed and the other would get 'duplicate' error (which is effectively success). we had this situation anyway without verifying the transactions: 2 requests will just continue processing and eventually one would succeed and another would get a duplicate. we also have this situation when one request is already in-flight to tc.,0,0.9402751326560974
1151046857,13391,artemlivshits,2023-03-28T19:06:16Z,"(could have syntax errors as i didn't compile it) ``` val nodeandtransactiondata = nodestotransactions.getorelseupdate(node, new transactiondataandcallbacks( new addpartitionstotxntransactioncollection(1), mutable.map.empty)) val currenttransactiondata = nodeandtransactiondata.transactiondata.find(transactiondata.transactionalid))",0,0.9861791133880615
1151269827,13391,YiDing-Duke,2023-03-29T00:07:47Z,"i assume the duplicate and out of order check happens in producer id cache and before this stage. if that's true, in general, the next batches with the same epoch won't hit this stage and should be fenced with out of order retry error to client. there can be a special case where this is the very first batch write from new epoch so the producer id cache cannot block any batches into this stage.",0,0.9879245758056641
1152479391,13391,artemlivshits,2023-03-29T20:59:25Z,"duplicate check + store has to be atomic (cannot really discard a new request as a duplicate until the previous request succeeds, not can let it go through until the previous request fails), so it needs to happen under a lock. the purpose of this stage is to not let a request go into log if the transaction is not there, so it got to be either between the check and the store or before the check and the store, hopefully, it's the latter, because otherwise we'd have a long lock around inter-broker rpc. btw, there should be no out-of-order errors or fenced errors during normal retry processing -- the first try should go through and others would be bounced with ""duplicate"" error which is effectively a success. this way all tries would be effectively successful and the intermittent error would be transparently handled by kafka without bubbling up to the application.",0,0.9760169386863708
1152485888,13391,jolshan,2023-03-29T21:07:05Z,"it does not happen before this stage. but artem is right. if we do process the callback twice, i suppose the second one will see it as a duplicate and return fine. i think my concern is that we return a timeout response + the callback response, but i guess this sort of thing can happen normally? i guess my question is whether we still want to return both callbacks with the response to addpartitionstotxn, or if it is just sufficient to ignore the first one.",0,0.9170368909835815
1152509597,13391,jolshan,2023-03-29T21:37:29Z,will do in [a link],0,0.9881503582000732
1152543409,13391,jolshan,2023-03-29T22:21:23Z,actually -- i misread the original comment -- i thought this was about callback time. i'm wondering if we want to report this in a different way after all. it would be a bit confusing to report this as remote time since this is technically still on the broker. i'm also not sure how we would parse the separate metric. is the idea that we would somehow get the time to send and receive the response and subtract it from the local time? i don't even see the local time metric getting incremented at this level. one idea is to take the request time and subtract the time to do the callback. i'd have to see if this is even possible though.,-1,0.903900146484375
1152603124,13391,artemlivshits,2023-03-30T00:03:28Z,"actually, this is a higher level discussion that we should probably have on the kip thread, as it affects public metric semantics. i think it would be useful to have a separate metric, because it'll help with diagnosing extra latency in transactions that we're introducing with this rpc call. especially if we provide a feature flag to turn off this check for perf reasons -- we'd need to have some data to help the admin make a decision.",0,0.9586359262466431
1152615315,13391,artemlivshits,2023-03-30T00:26:37Z,synchronization?,0,0.9852050542831421
1152617531,13391,artemlivshits,2023-03-30T00:32:15Z,"if we'll have a thread pool of network threads, we'd need to synchronize this too. so we probably need to add a comment here.",0,0.9833753705024719
1152624055,13391,artemlivshits,2023-03-30T00:48:02Z,"the kip also mentions a race condition where the transaction may be aborted just after we've verified it, but before we got the reply, it doesn't seem like this pr addresses that, do we plan to do it in a different pr?",0,0.9799888134002686
1153539479,13391,jolshan,2023-03-30T16:56:29Z,thanks for the reminder -- i need to remember the details here.,1,0.8445262908935547
1153540952,13391,jolshan,2023-03-30T16:57:51Z,i don't recall having a pool of network threads. this would just be the one send thread for now i think.,0,0.9530561566352844
1154744670,13391,artemlivshits,2023-03-31T17:49:25Z,"currently we only have one thread and it might be the case forever, but from this code the threading model is not obvious and it would be useful to have a comment that we don't need synchronization for inflightnodes because inflightnodes is only accessed from methods that are called on the sender's thread.",0,0.9863828420639038
1157599255,13391,jolshan,2023-04-04T18:07:21Z,"i've changed the internal details a bit so i no longer have an identifier that the first check succeeded. we append to the log on callback. originally, i was going to update the psm entry to contain the first offset and then we would remove the entry on the end marker. however, now we don't write the offset until the first append. (we can check for the next ones, but not the first append). the later changes with the epochs will make this not necessary since we bump the epoch on the marker write. i'm trying to think how we can handle this in the old clients case on the first append -- if there are any indicators we can check.",0,0.9257397055625916
1157781323,13391,jolshan,2023-04-04T21:20:40Z,"one option here is to check the timestamp of the last time the entry was updated if there is no ""last txn"" information. on the first append, the timestamp should not change on the entry. (i believe it only changes on data appends and txn markers)",0,0.9824620485305786
1158766750,13391,jolshan,2023-04-05T16:40:42Z,i'm going to keep what i have for now -- we can revisit the action queue if we want later.,0,0.9685900807380676
1160343683,13391,artemlivshits,2023-04-07T00:02:30Z,"if we don't want to put too many things in one change, we could implement the race condition checks in a separate change -- even though we didn't fully fix the problem we didn't regress (in fact improved quite a bit). on the other hand, fixing localtime metric should be done in this change, because it worked before this change so if we don't fix it, it would be a regression. another approach (if it makes things simpler in any way) could be to split out the framework to run callbacks on request threads and add metrics there, then rebase this change on top of framework, so this change focuses on the transaction-specific stuff.",0,0.9720095992088318
1160355023,13391,artemlivshits,2023-04-07T00:38:32Z,"update comment to say ""requestchannel and request"".",0,0.9873607158660889
1160356274,13391,artemlivshits,2023-04-07T00:42:51Z,we should set it to null once we're done with the request (in a finally clause). this would avoid issues of a request living longer than needed because it's referenced in a thread local of some request thread.,0,0.9870882034301758
1160357216,13391,artemlivshits,2023-04-07T00:46:09Z,"this change uses only one callback, but as a generic framework, a request could run multiple rpcs during its processing, so we should do `currentrequest.set(request.originalrequest` (and clean it afterwards).",0,0.9888142943382263
1160357426,13391,artemlivshits,2023-04-07T00:46:50Z,maybe use `callback` instead of `request`.,0,0.986995279788971
1160363167,13391,artemlivshits,2023-04-07T01:04:07Z,"i think the metric could be updated when the response is sent in request.fun(), so it may actually see some value in request.originalrequest.callbackrequestdequetimenanos and no value in callbackrequestcompletetimenanos, in which case the processing time could be negative. also, if multiple callbacks are used during the request processing, we'd lose callback processing time for all but last callback (for this we could add a comment, to add this logic if we have multiple callbacks to handle).",0,0.8767037987709045
1160803600,13391,jolshan,2023-04-07T16:06:04Z,"are you saying network client sends the response + updates the metrics before we reach line 115, so we should put the complete message as part of the response? i'm not sure the best way to put that in the callback. i'll have to think about it.",0,0.744252622127533
1160807017,13391,jolshan,2023-04-07T16:12:00Z,i wasn't sure if we would have a new request here though. we could be handling this callback after the original request returned right?,0,0.939434289932251
1160817791,13391,jolshan,2023-04-07T16:30:14Z,we've opted to return a retriable error for the case where the second response is returned first.,0,0.9838647842407227
1160819448,13391,jolshan,2023-04-07T16:32:51Z,let's do the check before append in a followup -- here is the jira -- [a link],0,0.9879205226898193
1160830029,13391,jolshan,2023-04-07T16:51:33Z,ah i think i figured it out.,0,0.9446396827697754
1160831069,13391,jolshan,2023-04-07T16:53:25Z,ah i misunderstood your comment. i guess i'm just not sure what setting current request here does for us. why would we use currentrequest instead of original request? unless we wanted to schedule another callback :grinning_face_with_sweat:,-1,0.9822285771369934
1160849589,13391,artemlivshits,2023-04-07T17:27:55Z,"we might in the future. from the implementation perspective it may seem like we have ""the request"" and ""the callback"", but conceptually we should think in terms of a request that may run a few asynchronous operations and then continue processing, in which case we can have multiple callbacks in the context of the same request. so logically it's like this: -- request starts processing 1. do some processing on a broker request thread 2. do async operation (rpc, or maybe even async storage access in some distant future) 3. continue processing on a broker request thread. 4. do some async operation 5. continue processing on a broker request thread 6. do some async operation 7. finish processing on a broker request thread -- request is done in this case the steps 1, 3, 5, 7 would be accounted as local time and logically we just keep processing the same request, only instead of blocking the thread in steps 2, 4, 6, we wait without blocking the thread.",0,0.9553489685058594
1160872423,13391,jolshan,2023-04-07T18:10:20Z,"i think the issue is that the way that i implemented the metric is that we only have callback start and end. if we wanted to store results of multiple callbacks, we would need to change this. i'm tempted to tackle this sort of thing in a followup change to avoid overcomplicating this one.",-1,0.7387957572937012
1160875392,13391,artemlivshits,2023-04-07T18:15:07Z,"i think it's still good to keep the request.originalrequest.callbackrequestcompletetimenanos = some(time.nanoseconds()) here as well. looking at the code, request could end in many different ways, some could happen before callback completion, some may happen after callback completion. there are some error cases, like connection disconnects that may not go through the success path.",0,0.8995159864425659
1160879089,13391,artemlivshits,2023-04-07T18:22:06Z,"instead of doing this, i would put the request.callbackrequestcompletetimenanos = some(time.nanoseconds()) back after the callback.fun() call and just update the place where we update metrics to take the current time if callbackrequestcompletetimenanos is empty. then we don't need chase all the code paths that we could go through before updating the metrics.",0,0.9521010518074036
1160883532,13391,artemlivshits,2023-04-07T18:30:54Z,"1. isn't it backwards? the complete time should be larger than deque time. 2. if we do the following logic, then it should work regardless of whether we arrive here before setting callbackrequestcompletetimenanos or after setting callbackrequestcompletetimenanos. [code block]`",0,0.9876837134361267
1160892559,13391,artemlivshits,2023-04-07T18:49:23Z,"yeah, if we need to make larger change to complete the framework, then we should definitely do in a follow-up change, but i think in this case all we need to do is this: [code block] and then we've got ourselves a fully functional framework for supporting arbitrary number of async calls in a request processing :-).",1,0.645054042339325
1160895598,13391,jolshan,2023-04-07T18:55:52Z,ooops -- good call.,1,0.9776585102081299
1160896272,13391,jolshan,2023-04-07T18:57:08Z,"hmm -- so we should only update if callback is also defined. i'm also not sure about setting it twice, so we should only set after fun() if it is not already set.",0,0.9376280307769775
1160975587,13391,artemlivshits,2023-04-07T21:27:29Z,need to clear as well in the finally clause.,0,0.967085599899292
1160976550,13391,artemlivshits,2023-04-07T21:30:02Z,"not sure if the 'if' clause is required, prevcallbackstimenanos would be 0 if there was no prev callback.",0,0.9800697565078735
1160980316,13391,jolshan,2023-04-07T21:40:29Z,"i just wanted to avoid doing all this extra code if not needed. in my head, it made more sense to someone reading it.",-1,0.6392821669578552
1161050689,13391,artemlivshits,2023-04-08T02:40:25Z,"we don't need to pass the current request, this could be completely encapsulated within wrap. in fact, having a request argument here makes it look like that we could pass some arbitrary request, while here we need exactly the one that is currently processed on the thread.",0,0.9858204126358032
1161050986,13391,artemlivshits,2023-04-08T02:43:44Z,or currentrequest == null,0,0.9723387956619263
1161051019,13391,artemlivshits,2023-04-08T02:44:17Z,ok,0,0.9667208194732666
1161051461,13391,artemlivshits,2023-04-08T02:48:44Z,do we have a test that actually tests that we'd get a failure if we try to produce without adding the partition to transaction first?,0,0.9778786897659302
1161058187,13391,artemlivshits,2023-04-08T04:07:10Z,producerstatemanager.activeproducers.get(producerid).exists(entry => entry.currenttxnfirstoffset.ispresent),0,0.9870626330375671
1161058423,13391,artemlivshits,2023-04-08T04:09:33Z,leaderlogiflocal.exists(leaderlog => leaderlog.hasongoingtransaction(producerid)),0,0.9879117012023926
1161846085,13391,jolshan,2023-04-10T15:59:45Z,"my original concern was that if we just used the thread local, we would access it when the inner method is called. i guess i can just save a local variable when wrap is called and pass that value into the inner method.",0,0.9748116135597229
1161847053,13391,jolshan,2023-04-10T16:00:34Z,"depends what you mean here. if you mean a unit test -- yes. if you mean a integration test, no because the correct behavior is built into the producer.",0,0.9824808239936829
1161854813,13391,jolshan,2023-04-10T16:06:53Z,actually hmm -- i suppose this test is not present if you mean the exact path of returning the error and not producing to the log. i really did think i added such a test to replica manger test. i can try to add this path.,0,0.9672256708145142
1161874495,13391,jolshan,2023-04-10T16:31:12Z,"this is a java map, so that doesn't work. i can convert to scala, but not sure that is much better.",0,0.8291330933570862
1161896585,13391,jolshan,2023-04-10T16:58:16Z,we do have tests from the previous pr that return errors if the partition is not added to the txn. see [a link],0,0.9878473281860352
1161909242,13391,junrao,2023-04-10T17:14:34Z,our long term goal is to replace the scala code with java. could we write this new class and the corresponding test in java?,0,0.980299711227417
1161915489,13391,junrao,2023-04-10T17:22:40Z,"the above comment still says ""is still under developement"". is the latest version indeed stable? or should we change the comment accordingly?",0,0.9873402714729309
1161918638,13391,junrao,2023-04-10T17:26:46Z,the params of this method is getting a bit large. could we add the javadoc explaining each of the param?,0,0.9627337455749512
1161932999,13391,junrao,2023-04-10T17:45:39Z,coordinatornotavailable error is not listed in produceresponse. should we add it there and verify that it's handled as expected by existing clients?,0,0.9833564758300781
1161943463,13391,junrao,2023-04-10T17:58:16Z,does this need to be volatile?,0,0.9769291281700134
1161946467,13391,jolshan,2023-04-10T18:01:40Z,added a line to the replicamanager test to see that we return early on the error in the callback.,0,0.9872660636901855
1161971721,13391,junrao,2023-04-10T18:33:41Z,do we have a use case where the same callback needs to be handled multiple times by the request thread? how do we prevent that the callback is added an infinite number of time to the callback queue?,0,0.9777690172195435
1161978192,13391,junrao,2023-04-10T18:41:52Z,"so, `originalrequest.callbackrequestcompletetimenanos.isempty` is expected to be true? should we add a warning log if it's false?",0,0.9868913292884827
1161979607,13391,junrao,2023-04-10T18:43:46Z,"since we don't expect to see wakeuprequest here, should we add a warning log?",0,0.9830697774887085
1161982117,13391,junrao,2023-04-10T18:46:51Z,this seems to be a more general mechanism than actionqueue. could we move all existing actionqueue usage to callback queue and get rid of actionqueue? this could be done in a separate pr.,0,0.9863422513008118
1161984615,13391,junrao,2023-04-10T18:50:06Z,"incomplete sentence ""check if we have already"".",0,0.8848852515220642
1161987786,13391,junrao,2023-04-10T18:54:20Z,network_exception is not listed in produceresponse. should we add it there and verify that it's handled as expected by existing clients?,0,0.988723874092102
1161996676,13391,junrao,2023-04-10T19:05:43Z,addpartitionstotxncollection seems unused?,0,0.9866029024124146
1162000865,13391,junrao,2023-04-10T19:11:11Z,"since this can be skipped, should this be warn instead of error?",0,0.9842952489852905
1162001708,13391,junrao,2023-04-10T19:12:20Z,extra space before returned,0,0.9851924180984497
1162003823,13391,junrao,2023-04-10T19:15:09Z,"hmm, not quite sure that i follow. do you mean that we return invalid_record to be compatible for old clients?",0,0.9194771647453308
1162043968,13391,jolshan,2023-04-10T20:06:24Z,i will update the comment.,0,0.9823121428489685
1162044614,13391,jolshan,2023-04-10T20:07:21Z,it is retriable -- currently if the error is retriable we just retry. it seems like most retriable errors are not enumerated specifically.,0,0.9645152688026428
1162045206,13391,jolshan,2023-04-10T20:08:02Z,^ ditto comment about retriable errors.,0,0.8109906315803528
1162045551,13391,jolshan,2023-04-10T20:08:23Z,"we can make it volatile, but this is only really used in tests.",0,0.9833605289459229
1162046736,13391,jolshan,2023-04-10T20:09:36Z,artem requested this. see comment here. [a link] there is currently not a way to prevent infinite callbacks.,0,0.9837903380393982
1162047387,13391,jolshan,2023-04-10T20:10:12Z,it is not true if we returned a response. we also update the value there.,0,0.9814202189445496
1162047588,13391,jolshan,2023-04-10T20:10:25Z,we can add a warning log.,0,0.9877745509147644
1162049144,13391,jolshan,2023-04-10T20:12:25Z,"yes. sorry for the confusion. in the kip we mention invalid_txn_state for the new clients, but old clients use invalid_record for compatibility. i will update the comment.",-1,0.9887951612472534
1162109668,13391,jolshan,2023-04-10T21:38:30Z,let's do in a separate pr.,0,0.9856501221656799
1163283951,13391,junrao,2023-04-11T20:21:19Z,"hmm, not sure that i follow. in the false case, it seems that we just don't set `callbackrequestcompletetimenanos`? this is a bit weird since the callback is completed.",-1,0.950185239315033
1163284515,13391,junrao,2023-04-11T20:21:57Z,could we file a jira to track this in a followup?,0,0.9872550964355469
1163287233,13391,junrao,2023-04-11T20:23:51Z,could this be private? ditto for a few other helper methods in this file.,0,0.976754367351532
1163292661,13391,junrao,2023-04-11T20:28:22Z,"""the error map should remain empty."" what does this mean?",0,0.9511332511901855
1163294534,13391,junrao,2023-04-11T20:29:59Z,get rid of the new line since the following validation is related to this action?,0,0.9853248000144958
1163323491,13391,junrao,2023-04-11T20:55:26Z,"basesequence is redefined as val. so, this is unused.",0,0.9704620242118835
1163335886,13391,junrao,2023-04-11T21:08:11Z,do we need this? it doesn't seem the request handler thread is involved in the test.,0,0.9860724210739136
1163418845,13391,jolshan,2023-04-11T23:22:00Z,"it means that we didn't complete the request. if we returned an error response, we would populate the map. but if it just replaced the old data, we don't send a response.",0,0.9401505589485168
1163421308,13391,jolshan,2023-04-11T23:26:54Z,"there are two cases according to artem -- one where we send a response via network client and one where we don't (and we have more callbacks) in case a, we set in the network client and that is the end of handling of the request. this is also when the metric is updated. in case b, we don't set it there so we must do it here. i have the check to match the same sort of protocol we see in kafka apis where we check if the value is -1. maybe it's fine to set it twice in case a as we won't update the metrics again, but i did it for consistency.",0,0.9621248841285706
1163421979,13391,jolshan,2023-04-11T23:28:30Z,oops. i see we changed this logic. i will fix the comment.,-1,0.8239415884017944
1163429337,13391,jolshan,2023-04-11T23:44:47Z,"we still call the wrap method which checks if we are on the request handler thread. since we are not it will fail via illegal state exception. we we set the bypass, it just runs the callback.",0,0.9846051931381226
1163446164,13391,junrao,2023-04-12T00:23:43Z,"i am still a bit confused on this. case a - only 1 callback. in this case, callbackrequestcompletetimenanos is never set and is expected to be empty. case b - multiple callbacks. in this case, after the first callback, callbackrequestdequeuetimenanos is set. so, when the 2nd callback is processed, we set callbackrequestcompletetimenanos to empty before executing the callback. when we get here, callbackrequestcompletetimenanos is expected to be empty. so, it seems that in both case a and b, we expect callbackrequestcompletetimenanos to be empty?",0,0.5479509234428406
1163659843,13391,artemlivshits,2023-04-12T06:02:22Z,"basically, we should search for `apilocalcompletetimenanos` and update the callbackrequestcompletetimenanos in similar places. my understanding is that we can send the reply during request / callback and it may complete (concurrently) before we end the request / callback or after we end request / callback. in which case we want the end time to be the earliest of the two. usually, the way it's done is the start time is set at the start of the request / callback processing and the end time is set after, but if the end time is not set then the metric is reported, then we just report the current time.",0,0.9780043959617615
1163676408,13391,artemlivshits,2023-04-12T06:26:09Z,"right now, this framework just accounts for a single logical request that does a few non-blocking calls and continues serially after each call. we could probably add a check that prohibits adding a second .wrap during request / callback execution.",0,0.9885425567626953
1164335669,13391,jolshan,2023-04-12T15:55:15Z,"in case a, we set it in the network client -- it will not be empty. in case b, it is empty and we set it. then, when executing the next callback, we take this time and subtract it from the start of the new callback. this gives us total time of all.",0,0.981067419052124
1164392731,13391,junrao,2023-04-12T16:45:31Z,"thanks for the explanation. i understand it now. callbackrequestcompletetimenanos can be non-empty if the response is sent before the callback completes. currently, we update the metric when the sending of the response completes. so, a more accurate place to set callbackrequestcompletetimenanos in requestchannel is when the response send completes. an alternative approach is to delay the updating of the request time metrics until the callback completes. this simplifies the setting of callbackrequestcompletetimenanos since it only needs to be done in kafkarequesthandler and is more accurate since we don't need to cut off callbackrequestcompletetimenanos by response send complete time. both of these could be addressed in a followup jira.",1,0.8871572613716125
1164399008,13391,jolshan,2023-04-12T16:51:49Z,"i'm not sure i follow the first part since right now, we need to account for all the callback local times. unless we change to a cumulative callback total time where we periodically add to it, we will need to update either on the send or when the callback completes (if we don't send yet) i'm also not sure about waiting until the callback completes because that is after we send via the network client and that is no longer considered ""local time""",0,0.9163478016853333
1164424805,13391,junrao,2023-04-12T17:17:36Z,"for simplicity, let's just assume there is only one callback for now. currently, the code sets callbackrequestcompletetimenanos when the response is being sent. if the callback has been started, but not completed at that point, the measurement of the callback portion time is not accurate. if we delay the cut off of callbackrequestcompletetimenanos at the time when request time metric is updated (which currently is when the response send completes), we allow for more accurate measurement of the callback portion time. for your second question, yes, it's a bit weird to report the callback time as 'local' after the response is being sent. however, 'local' really reflects the amount of time a request handler thread is tied up for processing a request. from that perspective, it could also make sense. if we cut off the callback portion of the time by response send time, we could leave a portion of the request thread time unaccounted for?",0,0.9753740429878235
1164431328,13391,jolshan,2023-04-12T17:24:15Z,i asked to just assume one callback earlier but i was told we should just implement this now :grinning_face_with_sweat: (thread here [a link] i'm not sure i follow which scenario is inaccurate?,-1,0.9801558256149292
1164445859,13391,junrao,2023-04-12T17:33:50Z,"in the more general case, the callback is not guaranteed to be completed when the response is sent, right? in that case, the code in requestchannel cuts off callbackrequestcompletetimenanos at response send time. when the callback completes, kafkarequesthandler doesn't set callbackrequestcompletetimenanos since it's not empty. this means the measurement of callback time is not accurate, right?",0,0.9743449091911316
1164460056,13391,jolshan,2023-04-12T17:48:36Z,"given that we have only one case right now i guess i'm not sure we have a general case -- but in the current case, we complete the callback by sending the response. i guess i saw this protocol working as follows: a) we have one callback and send the response in which local time is correct b) we have multiple callbacks and the first few do not send the response. we updated after calling the callback. then the final one sends the response (case a) we always must return in the final callback because we only use this callback if we've already returned from handle. we must return via the callback in my understanding.",0,0.9399343729019165
1164476174,13391,junrao,2023-04-12T18:04:26Z,"yes, in the current usage where the last callback sends the response as the last thing, it doesn't make much difference. i was thinking that the callbacks in actionqueue are executed after the response is generated. if want to replace actionqueue with the callback queue, we need to handle the more general case.",0,0.9750503897666931
1164479606,13391,jolshan,2023-04-12T18:08:12Z,"yeah -- i guess the previous decisions were made without considering the action queue. i'm wondering if it is better to leave as is and change via a followup or simplify back to ""base case"" (ie, case a which is currently what we do)",0,0.9681020379066467
1164488222,13391,junrao,2023-04-12T18:16:22Z,"yes, we can leave the pr as it is. could we file a jira to revisit action queue? we can make any needed changes there.",0,0.9871926307678223
1164633122,13391,junrao,2023-04-12T20:41:15Z,it's probably used for to log the destination broker on which the request fails. ditto in other logging.,0,0.9054375290870667
1164638992,13391,jolshan,2023-04-12T20:48:13Z,i will switch to the destination node.,0,0.9850444793701172
61458168,1251,gwenshap,2016-04-28T16:23:35Z,nit: oracle's javadoc guide specifically says: [a link],0,0.9865391850471497
61458366,1251,gwenshap,2016-04-28T16:25:03Z,"""iff"" means ""if and only if"" and is correct in this context. i don't think it was a typo. if you find ""iff"" unclear, feel free to replace with ""if and only if""",0,0.9820067286491394
61458701,1251,gwenshap,2016-04-28T16:27:09Z,these are new public apis right? ( - correct me if i'm wrong).,0,0.9520024657249451
61459284,1251,gwenshap,2016-04-28T16:30:38Z,"it is a bit hard to tell from the diff, but did you add a new argument as the first in the list? is there a reason? we usually add new arguments at the end.",0,0.934385359287262
61459399,1251,gwenshap,2016-04-28T16:31:16Z,the nulls are getting a bit hard to read. do we want constants for no_apis and no_metadata?,-1,0.9072403907775879
61459449,1251,ijuma,2016-04-28T16:31:33Z,looks like only the consumer and producer packages are considered api: [a link],0,0.9835439324378967
61460110,1251,gwenshap,2016-04-28T16:36:22Z,thanks :),1,0.9818400740623474
61460735,1251,gwenshap,2016-04-28T16:40:12Z,"""trace"" maybe? this seems incredibly chatty even for debug.",-1,0.9124224185943604
68186750,1251,ijuma,2016-06-23T07:24:20Z,why was this removed?,0,0.9225016236305237
68190038,1251,ijuma,2016-06-23T07:52:43Z,"we probably want a `kafkaconsumer` and `kafkaproducer` test that expects a newer than supported broker. sounds like it needs to be a system test. it probably needs a request to be bumped up too before it works. hmm, actually, we should have system tests for broker versions that don't support `apiversionsrequest` (e.g. 0.9.0.1 and 0.8.2.1). in addition, it would be great if we could detect if something is missing from this list at unit/integration test time. any ideas on how to do that?",0,0.9094743728637695
68190553,1251,ijuma,2016-06-23T07:56:40Z,"i think it would be better for `ready` to be the state where one sends requests. this means that if the api version requests are not needed, we can automatically transition from `connected` to `ready`. thoughts? cc .",0,0.9798941016197205
71025620,1251,SinghAsDev,2016-07-15T19:06:20Z,"it should not be, fixed in next version.",0,0.9368886947631836
71026255,1251,SinghAsDev,2016-07-15T19:11:00Z,"added system test against trunk and older broker versions. the interesting tests like testing against unsupported broker versions, will probably have to wait till we have such versions. the list of apis used by client is similar to the practice of specifying used errors for a request. as you said, it will be nice to have this checked dynamically at test time, however nothing comes to my mind with which we can do that. will be happy to accommodate any suggestion on this.",1,0.9359261989593506
71026376,1251,SinghAsDev,2016-07-15T19:11:49Z,"i do not have a strong bias on this, will be happy to make the change if you really think it is a must.",0,0.6592305898666382
74093108,1251,dpkp,2016-08-09T16:25:49Z,"apologies for the late review, but i feel like it would be much clearer if the state transition were: `disconnected -> connecting -> checking_api_versions -> connected` it strikes me that the main reason you have the ready state is to manage `cansendmore`, but i can't actually find where `cansendmore` is called in the api version request flow. networkclient `dosend` skips the `cansendmore` check, i believe, so do we really need that extra layer of complexity? and so would it be possible to check for `this.requiredapiversions == null` directly here and set the next connectionstate to connected if null, or to checking_api_versions if not? then in the api version response handler the state could be updated to connected.",-1,0.4785851538181305
74093303,1251,dpkp,2016-08-09T16:26:46Z,why not use a future + callback handler? the inline check in `handlecompletedreceives` is a bit confusing / buried,0,0.6211875081062317
91202952,1251,cmccabe,2016-12-07T00:18:58Z,"hmm. ""java.util.collection"" could be something unsorted like a list. how about making this a map from apikey to apiversion so that we can compare it with the server response more efficiently?",0,0.9855918884277344
91203250,1251,cmccabe,2016-12-07T00:21:40Z,"hmm. i was initially confused by what the ""apis"" parameter did. can we call this ""requiredapiversions""? same comment for the other constructor overloads.",0,0.8915098309516907
91203437,1251,cmccabe,2016-12-07T00:23:19Z,"can we have ""if"" statements instead of the ternary operator?",0,0.986212968826294
92007667,1251,hachikuji,2016-12-12T18:25:33Z,nit: feels like overkill to have constants for `null` which are only used in the constructors.,-1,0.7801345586776733
92007933,1251,hachikuji,2016-12-12T18:26:55Z,might be helpful to add a brief comment here explaining the behavior if `requiredapiversions` is null.,0,0.9862281084060669
92008244,1251,hachikuji,2016-12-12T18:28:25Z,+1. this is a little hard to read.,-1,0.7860137820243835
92009315,1251,hachikuji,2016-12-12T18:33:31Z,"might be helpful to add a short comment explaining the new states and transitions. for example, if the version check fails, do we go to `disconnected`?",0,0.9853969216346741
92036463,1251,hachikuji,2016-12-12T20:48:34Z,"nit: this could be `else if`, right? also, i think we could do an `instanceof` check on the response body, and pass the cast result to `handleapiversionsresponse` instead of going through the `struct` instance.",0,0.9884877800941467
92036719,1251,hachikuji,2016-12-12T20:49:55Z,nit: `else if`.,0,0.9824743866920471
92038835,1251,hachikuji,2016-12-12T21:00:39Z,"i'm in favor of this suggestion, but maybe overloading `connected` would be misleading. perhaps the states could be `disconnected -> connecting -> checking_api_versions -> ready` instead?",0,0.9641513228416443
92042824,1251,hachikuji,2016-12-12T21:21:12Z,"does this need to be concurrent? `networkclient` itself is not thread-safe. also, i wonder if queue is the right data structure. would a `set` make more sense? are there any cases we'd add the same node more than once? now that i'm thinking about it... do we need this collection at all? it seems like it is identical to the set of nodes which are in the `connected` state. maybe we could just get that directly from `clusterconnectionstates`?",0,0.9187023043632507
92043237,1251,hachikuji,2016-12-12T21:23:30Z,nit: this change seems unneeded,0,0.847612202167511
92043284,1251,hachikuji,2016-12-12T21:23:50Z,nit: could be static.,0,0.9877622127532959
92043619,1251,hachikuji,2016-12-12T21:25:26Z,nit: why not let this be `list `? it's usually preferable to preserve type information as long as possible. same in `kafkaproducer` and the test cases.,0,0.9877480268478394
92044055,1251,hachikuji,2016-12-12T21:27:45Z,this looks like same code as in `kafkaconsumer`. perhaps we should move it to `utils`?,0,0.9881966710090637
92047117,1251,hachikuji,2016-12-12T21:43:40Z,"nit: seems we could use a singleton, maybe `apiversionsrequest.instance` or something like that?",0,0.9876567125320435
92048027,1251,hachikuji,2016-12-12T21:48:13Z,should we try to use `cansendrequest`?,0,0.9876803159713745
92049126,1251,hachikuji,2016-12-12T21:53:42Z,might this be simpler if we just have two methods: `cansendrequest(string node)` and `cansendapiversionrequest(string node)`?,0,0.9883118271827698
92049847,1251,hachikuji,2016-12-12T21:57:36Z,"these tests are a little obscure. i wonder if it would be a little clearer to 1) use only one api instead of a list, and 2) reference the versions directly using `protoutils`?",0,0.8901253342628479
92050099,1251,hachikuji,2016-12-12T21:58:38Z,kudos for adding the system test!,0,0.9532790780067444
92050177,1251,hachikuji,2016-12-12T21:59:03Z,nit: why remove the newline?,0,0.93974769115448
92050279,1251,hachikuji,2016-12-12T21:59:39Z,nit: why remove the newline?,0,0.93974769115448
92050477,1251,hachikuji,2016-12-12T22:00:40Z,"also, maybe we could call this `consumer_apis` and get rid of the comment, which doesn't add much value.",0,0.9838384389877319
92074335,1251,ijuma,2016-12-13T00:36:53Z,i think the ternary operator is probably ok if the connection state checks were extracted into a variable.,0,0.9878496527671814
92074732,1251,ijuma,2016-12-13T00:40:05Z,`else if` is not required here since the `if` always throws right? or do you just mean as a style thing it's clearer?,0,0.9817637801170349
92079250,1251,ijuma,2016-12-13T01:18:29Z,"yeah, that would be similar to `api_versions_response` in `apiversionsresponse`.",0,0.9878008365631104
92154634,1251,ijuma,2016-12-13T12:01:02Z,it seems a bit inconsistent that `connected` clears the internal list while other methods like `disconnected` don't. maybe we should call `clear()` from `poll`?,0,0.9092914462089539
92154840,1251,ijuma,2016-12-13T12:02:18Z,"we should add `latest_0_10_1` and `latest_0_10_0` too. since they support `apiversionsrequest`, i take it that the behaviour is more graceful?",0,0.988410472869873
92155097,1251,ijuma,2016-12-13T12:04:08Z,nit: maybe there should be no default for `should_fail` since we always pass a value.,0,0.9738024473190308
92155443,1251,ijuma,2016-12-13T12:06:18Z,seems like they can be final.,0,0.9790763854980469
92155793,1251,ijuma,2016-12-13T12:09:05Z,nit: missing space before `:`.,0,0.9180254340171814
92156071,1251,ijuma,2016-12-13T12:11:06Z,it would be good to include more information about the failure in the message.,0,0.9781900644302368
92156138,1251,ijuma,2016-12-13T12:11:28Z,do we want to validate that it failed for the right reason?,0,0.9543461203575134
92156687,1251,ijuma,2016-12-13T12:15:26Z,why are we duplicating all of this logic here? can we not reuse the existing serialization logic?,0,0.9343662858009338
92243074,1251,SinghAsDev,2016-12-13T19:11:41Z,sounds good.,1,0.9202015399932861
92243960,1251,SinghAsDev,2016-12-13T19:16:03Z,"i don't think it has to be sorted, though having a consistent order will make it easier to read in logs. also, i failed to see why changing this to a map is going to be more efficient. the checking is happening in `handleapiversionsresponse` and response already has a map of keys to supported versions.",0,0.9791014194488525
92244101,1251,SinghAsDev,2016-12-13T19:16:50Z,"after taking out `connected` state, this is no longer an issue.",0,0.9800925254821777
92259621,1251,SinghAsDev,2016-12-13T20:31:40Z,"we would need some kind of ds to keep track of api versions request that need to be sent during poll. if we were to use `clusterconnectionstates` to do this, we will either have to add a state between `checkingapiversions` and `ready` to indicate that api versions check is already in progress for a connection, or we will have to move trigger for sending api versions from poll to handleconnections. i am more in favor of having it the way it is right now, and have the api version requests be sent during polls. however, i do agree that the ds for this can be a set, and i will make that change.",0,0.7806286811828613
92265829,1251,SinghAsDev,2016-12-13T21:05:22Z,"`cansendrequest` also checks if connection state is `ready`, which won't be true here.",0,0.9898411631584167
92266604,1251,SinghAsDev,2016-12-13T21:09:25Z,good point.,1,0.9406068921089172
92270976,1251,SinghAsDev,2016-12-13T21:32:08Z,"if the version check fails, connection is closed. no reason to go in `disconnected` state, as their is no way broker would start supporting the version without having to terminate the connection.",0,0.9556933641433716
92279721,1251,SinghAsDev,2016-12-13T22:16:58Z,"not sure if those changes help, but making those changes anyway. let me know if you meant something else.",0,0.9717779755592346
92285072,1251,SinghAsDev,2016-12-13T22:49:22Z,"not sure, if you wanted me to add checks for exception messages, as it makes these tests a little brittle. i anyway, went ahead and added those checks. let me know if you think they don't add much.",0,0.9491785168647766
92286131,1251,SinghAsDev,2016-12-13T22:55:28Z,ahh.. left over from some debugging.,0,0.9763211607933044
92294978,1251,hachikuji,2016-12-13T23:56:13Z,"yeah, it's personal preference, so feel free to ignore. the `else if` makes the relation between the two cases stand out a bit more.",0,0.9362496733665466
92295136,1251,hachikuji,2016-12-13T23:57:39Z,i think this check and the one above are redundant. maybe we can remove the check for the api key?,0,0.9847833514213562
92296138,1251,hachikuji,2016-12-14T00:05:20Z,would be nice to have `node` somewhere in this name. maybe `nodesrequestingapiversions`?,0,0.9358751177787781
92296968,1251,hachikuji,2016-12-14T00:13:05Z,or maybe `nodesneedingapiversionsfetch`? might be closer to the usage.,0,0.9878925085067749
92297033,1251,hachikuji,2016-12-14T00:13:38Z,"if the node is in `apiversionsrequests`, then wouldn't the state already be `checking_api_versions`?",0,0.9884763956069946
92299342,1251,hachikuji,2016-12-14T00:33:07Z,nit: the check seems unnecessary.,0,0.8346425890922546
92303136,1251,hachikuji,2016-12-14T01:02:50Z,"i'm wondering if we can simplify this a little bit. once the connection has completed, it seems that both `selector.ischannelready()` and `inflightrequests.cansendmore()` should both be true. so instead of going through this intermediate collection before sending the `apiversionrequest`, perhaps we can just immediately send the request when we transition to `checking_api_versions`? i think that would let us get rid of the `apiversionsrequests` set. does that seem right?",0,0.9742814302444458
92303744,1251,SinghAsDev,2016-12-14T01:08:18Z,"yea that is one option that i was pointing to earlier. it has been so long that i do not remember why i chose this over sending, but one reason that comes to my mind is that handling all sends receives from poll seems like a good idea. however, i am open to change that.",0,0.657606840133667
92305344,1251,hachikuji,2016-12-14T01:22:43Z,"never mind. i talked with jun and ismael about this and ""connected"" currently does not imply ""ready.""",0,0.6692222356796265
92316606,1251,hachikuji,2016-12-14T03:24:29Z,nit: alignment,0,0.9832958579063416
92316756,1251,hachikuji,2016-12-14T03:27:07Z,nit: doesn't seem like this method adds much.,-1,0.802381694316864
92317190,1251,hachikuji,2016-12-14T03:33:42Z,i don't think we need this one.,0,0.8033573627471924
92318309,1251,hachikuji,2016-12-14T03:47:33Z,"not sure you saw my previous comment, but these two constants seem unneeded.",0,0.6023411750793457
92320200,1251,SinghAsDev,2016-12-14T04:18:28Z,"this was explicitly asked in one of the previous review comments, having bunch of nulls in a method call, makes it hard to read. if this is not a big concern, maybe we can leave it in as it makes code more readable? lmk.",0,0.9733878970146179
92433034,1251,hachikuji,2016-12-14T16:34:34Z,"sure, that's fair.",0,0.8953261375427246
92452791,1251,hachikuji,2016-12-14T18:07:07Z,seems this is unused. do we need it?,0,0.9804961085319519
92456223,1251,hachikuji,2016-12-14T18:23:38Z,"the second argument here is used to indicate when the request is a metadata request initiated by the `networkclient`. this lets us send metadata requests externally without having the `networkclient` intercept them (i think we were the ones who added this feature initially :winking_face: ). i think it would probably make sense to do the same for the `apiversionsrequest`. it seems a little safer and i can imagine using this api from the admin client in the future, for example.",0,0.9263088703155518
92496174,1251,SinghAsDev,2016-12-14T21:45:07Z,"i initially thought to do that, but it is very likely that someone would have raised that as not required in review. however, now that is is raised, happy to add it. if there are no more reviews, i will shortly update the pr here.",1,0.8115618824958801
92498039,1251,hachikuji,2016-12-14T21:53:51Z,could we use a single `isinternalrequest` flag combined with an `instanceof` check to distinguish the two cases?,0,0.9888675808906555
92501345,1251,SinghAsDev,2016-12-14T22:10:43Z,"one can argue against it, as now the same check has to be done at multiple places. if number of such internal requests grow beyond two, then probably it won't make sense to keep a flag for each of them. at that point it would be better to add a method like `boolean isinternalrequestoftype(apikeys apikey)`. makes sense?",0,0.9796229004859924
92503655,1251,hachikuji,2016-12-14T22:23:26Z,"we should probably have the `instanceof` checks anyway prior to casting the response object, so this just removes the need for an extra field. is there any downside?",0,0.9826340079307556
92505757,1251,SinghAsDev,2016-12-14T22:35:00Z,"not sure i am following you here. below is one of the places where `isinternalmetadatarequest` flag is used. [code block] are you suggesting that i change it to something like. [code block] if so, then we are talking about changing `metadataupdater` interface. do we really want to do that? do you see any other type of request being initiated by network client any time soon?",0,0.971144437789917
92510635,1251,hachikuji,2016-12-14T23:03:03Z,"yeah, that's exactly what i was thinking. it seems like a nice improvement to let the `metadataupdater` interface accept an instance of `metadataresponse` directly so that it doesn't have to deal with casting itself.",0,0.7789188027381897
92513323,1251,hachikuji,2016-12-14T23:20:59Z,nit: seems we no longer have much use for `handlemetadataresponse`. maybe we just move its body here?,0,0.9029174447059631
92515767,1251,ijuma,2016-12-14T23:39:14Z,"nit: `oldest` and `latest` are not symmetric. also, it's a bit odd that we use different names for the field names (basically `current` and `minimum`). finally, why do we use `int` instead of `apikeys`?",0,0.853550136089325
92515994,1251,ijuma,2016-12-14T23:40:55Z,"if you look at `producerrecord`, we use a slightly different convention for `tostring` (i know we are not consistent everywhere, but i'm trying to improve that).",0,0.9835633039474487
92516990,1251,ijuma,2016-12-14T23:48:30Z,`collections.singletonlist` can be used to make this more concise.,0,0.9876605272293091
92517073,1251,ijuma,2016-12-14T23:49:08Z,"i don't understand this name, why do we call it `used_api_key`?",0,0.7700043320655823
92517275,1251,ijuma,2016-12-14T23:50:41Z,i don't understand why we add +2 to `short.max_value` and then cast to `short` causing it to overflow?,0,0.9531686902046204
92517541,1251,ijuma,2016-12-14T23:52:41Z,don't we have some code that we can reuse for this? why are we manually serialising `apiversionresponse`?,0,0.9683587551116943
92517616,1251,ijuma,2016-12-14T23:53:18Z,we should have a timeout here so that we don't loop forever in case of a bug.,0,0.9791146516799927
92517670,1251,ijuma,2016-12-14T23:53:47Z,"are some of these fields supposed to be `final` (existing code, i know)?",0,0.9873387813568115
92517741,1251,ijuma,2016-12-14T23:54:17Z,nit: maybe this should be `createnetworkclient` and similar for the other method.,0,0.9857304096221924
92517776,1251,ijuma,2016-12-14T23:54:36Z,nit: should probably just be `expectedapiversions`.,0,0.9879388809204102
92517927,1251,ijuma,2016-12-14T23:55:49Z,we should have some shared code for serialising the response and response header instead of duplicating it in multiple places.,0,0.9858852624893188
92517976,1251,ijuma,2016-12-14T23:56:12Z,did you see this comment?,0,0.9804010987281799
92518023,1251,ijuma,2016-12-14T23:56:37Z,nit: extra empty line.,0,0.9629546403884888
92518167,1251,ijuma,2016-12-14T23:57:35Z,"hmm, i thought we'd have `latest_0_10_1` and `latest_0_10_0` instead of `latest_0_10` (which doesn't make sense because we have multiple feature releases in the `0_10` line.",0,0.982435941696167
92518242,1251,ijuma,2016-12-14T23:58:15Z,should we not check that we get a better error for the case where `apiversions` is available (i.e. `0.10.0.x`)?,0,0.9829208254814148
92528123,1251,hachikuji,2016-12-15T01:32:33Z,"yeah, maybe just remove the constant and use `apikeys.metadata` directly?",0,0.9892839789390564
92866560,1251,ijuma,2016-12-16T19:01:30Z,"on second thought, i'm ok to leave this as it is and we can leave this improvement as future work.",0,0.9108631610870361
92897920,1251,SinghAsDev,2016-12-16T22:35:34Z,"yea, this will require a bit of refactoring. current changes are inline with the way `protoutils` is written. leaving it as it is for now.",0,0.9871017932891846
92897966,1251,SinghAsDev,2016-12-16T22:35:51Z,good point!,1,0.9838534593582153
37427316,151,ijuma,2015-08-19T15:21:47Z,what is the right way to handle this? the random suffix is there because an exception will be thrown in `registermetric` if a broker is removed and then added again. the `selector` doesn't allow the caller to control that in its current form.,0,0.9835642576217651
37427419,151,ijuma,2015-08-19T15:22:27Z,is it ok to use the same config as `socketserver` for this?,0,0.985870361328125
37427623,151,ijuma,2015-08-19T15:23:51Z,"`config.controllersockettimeoutms` was previously being used for `blockingchannel.readtimeoutms`, is it correct to use it here in this way?",0,0.9877937436103821
37427682,151,ijuma,2015-08-19T15:24:19Z,is it ok to reuse the `socketserver` settings here?,0,0.9880421161651611
37427714,151,ijuma,2015-08-19T15:24:36Z,"`config.controllersockettimeoutms` was previously being used for `blockingchannel.readtimeoutms`, is it correct to use it here in this way?",0,0.9877937436103821
37427818,151,ijuma,2015-08-19T15:25:18Z,is it ok to use the `socketserver` config parameters here?,0,0.98795086145401
37470292,151,gwenshap,2015-08-19T21:25:21Z,i don't think you need maxbytes here... this was for limiting the message size from clients. we have networkreceive.unlimited if we want to leave this open.,0,0.9809815883636475
37470393,151,gwenshap,2015-08-19T21:26:05Z,can to expend on why would the broker get removed and re-added from here?,0,0.9699175953865051
37472395,151,ijuma,2015-08-19T21:44:00Z,"`controllerchannelmanager.removebroker` is called in `brokerchangelistener.handlechildchange`, the actual line is: `deadbrokerids.foreach(controllercontext.controllerchannelmanager.removebroker(_))`",0,0.9883549213409424
37474431,151,gwenshap,2015-08-19T22:02:49Z,"so, it looks like you have a selector for each controller->broker connection? i'd expect one selector for the controller and open and close connections for brokers. this way the selector string will include the broker id for the controller, but not for the brokers themselves. and we'll probably want to maintain metricsperconnection so we can track those separately. does that make sense?",0,0.9815199375152588
37476236,151,gwenshap,2015-08-19T22:23:50Z,"i think these utils are very generic, but also make the code a bit harder to read. it looks like the ""find"" we are waiting for is basically always a reply from a specific broker? in this case, maybe make the generic method private and provide a more specific wrapper?",0,0.955581784248352
37476467,151,ijuma,2015-08-19T22:26:34Z,"yes, i understand that one selector per controller would be better. i was trying to avoid a complete redesign of `controllerchannelmanager` though. it currently uses one `requestsendthread` per broker with a `blockingqueue` and `blockingchannel`. `controllerchannelmanager` has a public `sendrequest` method that adds to the relevant queue. `requestsendthread` takes from this queue. my understanding is that a given selector should be used from just one thread and hence the resulting code. please let me know if this is not correct. in an ideal world, we would redesign things to use one selector per controller, but it seemed riskier and i thought it would be better to do that in a separate change after the next release (since our main goal at this point is just to use `selector` for the tls/ssl support). what are your thoughts?",0,0.8838334083557129
37476513,151,gwenshap,2015-08-19T22:27:11Z,"yeah, i think it does exactly the same thing we used to do: block until we get a reply or get to the timeout time. iirc, the networkreceive code has some deprecated methods specifically to support the blocking channel timeouts. maybe this can be cleaned up now.",0,0.9847132563591003
37476689,151,gwenshap,2015-08-19T22:29:20Z,blockingchannel used to get the buffer sizes as parameters... shouldn't we keep the same behavior?,0,0.9586477875709534
37476724,151,ijuma,2015-08-19T22:29:48Z,"`blockingchannel` is still used by the old consumer, so i am not sure we can remove anything just yet. i'll double-check though.",0,0.9779272079467773
37476769,151,gwenshap,2015-08-19T22:30:30Z,"i think it is, since it keeps the same behavior.",0,0.9808082580566406
37476900,151,ijuma,2015-08-19T22:32:17Z,"we were passing `blockingchannel.usedefaultbuffersize` (which is `-1`) everywhere and the code in `blockingchannel` does: [code block] so, we were basically not setting anything.",0,0.9408093690872192
37477305,151,gwenshap,2015-08-19T22:36:56Z,"lets see if i got it. we have a communication thread per broker, and a selector per thread. if a broker dies, we close the thread and the selector. if the broker comes back, we can't create a new selector with the same name due to metrics. since the number of possible brokers is limited, can we just store the selector for each broker in a map and reuse / reconnect if the dead broker is revived? this should keep the metrics sane too.",0,0.9797090888023376
37477570,151,gwenshap,2015-08-19T22:39:45Z,"lol, we are cute :) i'd leave it at -1 then.",1,0.9936563372612
37477835,151,gwenshap,2015-08-19T22:42:36Z,"i'd also document that these are for creating blocking behavior on top of our async network classes, and to use only where blocking makes sense...",0,0.9810247421264648
37478175,151,ijuma,2015-08-19T22:47:28Z,"i can try to add some wrappers and see how it looks. to help me understand, what makes it hard to read? is it because of the long line with many parameters? this could be simplified quite a bit by using implicit value classes and passing the time implicitly as well. example follows: now: [code block] after the proposed change: [code block]",0,0.9782754182815552
37478292,151,ijuma,2015-08-19T22:49:29Z,"yes, that seems doable. i'll try that tomorrow and update the pr.",0,0.6563553214073181
37478390,151,ijuma,2015-08-19T22:50:46Z,good point about documenting the blocking aspect. will do.,1,0.8613844513893127
37478724,151,ijuma,2015-08-19T22:54:31Z,we can't pass -1 to `selector.connect` though as it will fail when it calls `socket.sendbuffersize`. maybe you are suggesting that i update `selector.connect` to behave as `blockingchannel` did when a negative value is passed in (basically not call `set*buffersize`)?,0,0.9873051047325134
37479192,151,gwenshap,2015-08-19T23:00:29Z,yep. basically move the constants and their behavior to the new network classes.,0,0.9838356971740723
37479252,151,ijuma,2015-08-19T23:01:11Z,sounds good.,1,0.9202015399932861
37479424,151,gwenshap,2015-08-19T23:03:33Z,"i actually find the very generic ""any predicate"" or ""any find on a collection"" challenging. i'm concerned that future contributors won't quite know what to do with those. i'm thinking that baking the specific ""find"" we actually have into a wrapper, will help. so: polluntilrecievingresponsefromconnection(selector, timeout, connection_id)",-1,0.8772239089012146
37567314,151,gwenshap,2015-08-20T18:53:17Z,nice :),1,0.9863845705986023
37606457,151,junrao,2015-08-21T04:49:32Z,"we need to block until the connection is established, right?",0,0.9813547730445862
37606471,151,junrao,2015-08-21T04:50:02Z,"we will need to handle disconnects (like what networkclient does) by checking selector.disconnected(). if a socket is disconnected, there is no need to wait for the timeout. we should just throw an ioexception back. ditto to the selector.poll() below.",0,0.9775247573852539
37606475,151,junrao,2015-08-21T04:50:16Z,"we haven't been using the s notation so far. to be consistent, perhaps it's better to use the string format thing for now and do a global replacement at some point if we feel that's better?",0,0.9792161583900452
37606486,151,junrao,2015-08-21T04:50:28Z,"since there is a selector per broker, we need to add a broker id tag for the metric tag.",0,0.9887520670890808
37614464,151,ijuma,2015-08-21T08:12:40Z,"i thought we did not as we will eventually block after the `send`, which happens a few lines below. have i misunderstood how the `selector` should be used in this case?",0,0.9622863531112671
37614569,151,ijuma,2015-08-21T08:14:11Z,"makes sense, will do.",0,0.9346156120300293
37614852,151,ijuma,2015-08-21T08:19:05Z,"i considered that, but we have over 800 instances of `format` in our codebase, so it would be quite a painful global replacement (with potential for introducing bugs). string interpolation is safer and performs better than `.format`, so i thought we could use it for new code where it made sense. we use it in a small number of places already. please let me know if you still think i should change it.",0,0.8901044726371765
37614934,151,ijuma,2015-08-21T08:20:33Z,"will do. i'm not really sure how these tags work to be honest, but i'll see if i can find an existing example. :)",1,0.9825387001037598
37626125,151,ijuma,2015-08-21T11:28:49Z,", i added the `broker-id` tag below. does it still make sense to include `broker.id` in the `metricgrpprefix` above?",0,0.9892499446868896
37651956,151,junrao,2015-08-21T16:34:42Z,"if you look at networkclient, the way that it uses selector is the following. before networkclient can send any request, it has to make sure the connector is connected and the channel is ready. if you don't follow this protocol, things can get weird. for example, in ssl, after we finish the handshake, we will turn off the interest bit for write. if the interest bit for write has already been turned on by a request sent before the handshake completes, the send may never complete. thinking a bit more about this. it seems to implement a blocking channel on the selector, we will need most of the connection state management logic in networkclient. the problem with using networkclient is that it's tied to metadata refresh, which is not needed. we can either add an option to turn off the metadata part in networkclient and use it to implement the blocking channel. alternatively, we can implement a blockingselector on top of selector, but has to copy some of the state management logic from networkclient over. not sure which one is better.",-1,0.9351336359977722
37651974,151,junrao,2015-08-21T16:34:54Z,"metricgrpprefix is just a prefix of the metrics group, which is a string. tags give metadata in key/value pairs, which is more informative.",0,0.9848666787147522
37653240,151,ijuma,2015-08-21T16:48:38Z,"ok, i see. i'll check if turning off metadata in `networkclient` can be done without too much complexity.",0,0.9777520298957825
38272677,151,ijuma,2015-08-30T15:23:09Z,will add javadoc.,0,0.9864652156829834
38272682,151,ijuma,2015-08-30T15:23:15Z,will add javadoc.,0,0.9864652156829834
38272693,151,ijuma,2015-08-30T15:23:58Z,will add `and version` at the end of the sentence.,0,0.9873142838478088
38272702,151,ijuma,2015-08-30T15:25:30Z,v1 was added during the development of 0.8.3 so we could change this to be like v0 if we think it's important.,0,0.9828242063522339
38272718,151,ijuma,2015-08-30T15:27:19Z,will add `scaladoc` to this class and methods.,0,0.9870826005935669
38279205,151,junrao,2015-08-31T01:03:19Z,"do we need to wait for the next poll() call? disconnect() will cancel the key, after which the key will never be selected again.",0,0.9521868228912354
38279208,151,junrao,2015-08-31T01:03:29Z,it seems that we also need to remove nodeid from clusterconnectionstates?,0,0.984562337398529
38279209,151,junrao,2015-08-31T01:03:35Z,need to add .,0,0.9175261855125427
38279211,151,junrao,2015-08-31T01:03:42Z,need to add .,0,0.9175261855125427
38279215,151,junrao,2015-08-31T01:03:47Z,need to add .,0,0.9175261855125427
38279216,151,junrao,2015-08-31T01:03:54Z,do we need to pass mode in? could we just get it from configs?,0,0.9877376556396484
38279217,151,junrao,2015-08-31T01:04:00Z,this field should be named live_leaders.,0,0.9844464659690857
38279219,151,junrao,2015-08-31T01:04:04Z,this can just be referencing leader_and_isr_request_partition_state_v0.,0,0.9899948835372925
38279226,151,junrao,2015-08-31T01:04:16Z,good catch. it's probably too late to change that though.,1,0.9728794097900391
38279229,151,junrao,2015-08-31T01:04:22Z,leaders is better named as liveleaders.,0,0.9736863970756531
38279232,151,junrao,2015-08-31T01:04:33Z,"it's probably better to create two constructors, one for each version. we can then mark the v0 constructor as deprecated and can remove it in the future.",0,0.9866424798965454
38279234,151,junrao,2015-08-31T01:04:38Z,both v0 and v1have host_key_name. perhaps we should check field security_protocol_type_key_name?,0,0.9896725416183472
38279239,151,junrao,2015-08-31T01:04:44Z,should we mock the other new method disconnect() too?,0,0.935373067855835
38279241,151,junrao,2015-08-31T01:04:49Z,response version should be 1.,0,0.9844095706939697
38279242,151,junrao,2015-08-31T01:04:51Z,response version should be 1.,0,0.9844095706939697
38279278,151,junrao,2015-08-31T01:07:21Z,we probably want maxinflightrequests to be 1 so that it's consistent with the current behavior in blockingchannel.,0,0.9877625703811646
38279285,151,junrao,2015-08-31T01:07:47Z,there are a few unused imports.,0,0.9822850227355957
38279287,151,junrao,2015-08-31T01:07:55Z,selector should now be networkclient. there are a few other mentions of selector below.,0,0.9874113202095032
38279289,151,junrao,2015-08-31T01:08:00Z,"$sockettimeoutexception should be $sockettimeoutms, right?",0,0.9889589548110962
38279291,151,junrao,2015-08-31T01:08:06Z,we probably want maxinflightrequests to be 1 so that it's consistent with the current behavior in blockingchannel.,0,0.9877625703811646
38279296,151,junrao,2015-08-31T01:08:14Z,do we need to do this? nodes are only used for sending metadatarequest and we are not doing that here.,0,0.8757247924804688
38279300,151,junrao,2015-08-31T01:08:36Z,"we probably want to move the blocking support to the client side. in the future, we likely will be writing the admin tools in java and it potentially will need to make blocking request calls too.",0,0.9860634207725525
38279310,151,junrao,2015-08-31T01:09:04Z,"if the connection didn't fail, is there any reason to back off? it seems that we should be calling networkclient.poll() with the timeout immediately.",0,0.9858437776565552
38279316,151,junrao,2015-08-31T01:09:31Z,"perhaps it's more convenient to include to logic to wait for the connection being ready here. this way, we are guaranteed that every time we send a request, the socket is ready. currently, in controllerchannelmanager, if we can't establish a socket connection, it seems that we can send a request before the channel is ready.",0,0.983881950378418
38292654,151,ijuma,2015-08-31T08:21:53Z,"i copied that documentation from `selector.disconnect`. there is the following code in `selector.poll`: [code block] and there is the following test in `networkclienttest`: [code block] so, that lead me to believe that a poll was needed to update the internal state of the `selector` and `networkclient`. the test above fails without the `poll` line (although it does use a `mockselector`, so the bug could be there). what are your thoughts based on this additional information?",0,0.9741266369819641
38292972,151,ijuma,2015-08-31T08:27:34Z,"i did think about setting the state to disconnected (which has a similar effect), but then i thought that this would be updated automatically via `poll` as per the comment added in the discussion around the javadoc for `kafkaclient.poll`. but maybe the right thing is to do update the state here as you suggest. do you think we should remove the id or set the state to `disconnected`?",0,0.9823895692825317
38296748,151,ijuma,2015-08-31T09:30:40Z,"the 4 places where this is used all pass this parameter explicitly (as `sslfactory.mode.{client,server}`). we could put a key into the configs map, but i think that would make things more opaque with no clear benefit. what do you think?",0,0.9867732524871826
38296826,151,ijuma,2015-08-31T09:32:11Z,"will fix. we also have `alive_brokers` elsewhere, should we be calling that `live_brokers` instead for consistency?",0,0.9851303100585938
38296887,151,ijuma,2015-08-31T09:33:21Z,"ok, will do. i wasn't sure what was our policy when it came to referencing schemas from other apis in the same class. good to know.",1,0.9337347745895386
38296946,151,ijuma,2015-08-31T09:34:04Z,will do.,0,0.9548023343086243
38296965,151,ijuma,2015-08-31T09:34:20Z,will do.,0,0.9548023343086243
38297159,151,ijuma,2015-08-31T09:37:48Z,"in v1, `host_key_name` is in the `end_points` struct though, so it should be fine either way as far as i can see. i'll change it to `security_protocol_type_key_name` as it's clearer though.",0,0.987170398235321
38297285,151,ijuma,2015-08-31T09:39:41Z,it was already there previously.,0,0.9875006675720215
38297303,151,ijuma,2015-08-31T09:39:56Z,"good catch, will fix.",1,0.9754865765571594
38297314,151,ijuma,2015-08-31T09:40:10Z,"good catch, will fix.",1,0.9754865765571594
38297556,151,ijuma,2015-08-31T09:44:08Z,"i think the behaviour should be consistent anyway as we block for each request. setting this to `1` will enforce it, so i'll change it.",0,0.9867439270019531
38297677,151,ijuma,2015-08-31T09:46:00Z,will fix.,0,0.9742533564567566
38297917,151,ijuma,2015-08-31T09:49:38Z,i'll change this to say `networkclient`/`selector`. i think the other `selector` mentions are fine.,0,0.9418420195579529
38297929,151,ijuma,2015-08-31T09:49:53Z,"good catch, will fix.",1,0.9754865765571594
38297986,151,ijuma,2015-08-31T09:50:55Z,"similar to the other instance of this, i think the behaviour is still correct, but i'll change it to be clearer/safer.",0,0.9667023420333862
38298281,151,ijuma,2015-08-31T09:56:12Z,"we don't strictly need it, but `kafkaclient.leastloadednode` would return `null` if we don't do this. as you say, we don't use that method so it would have no effect right now if we remove it. i did that because i thought it may help avoid surprises in the future, but i don't have a strong opinion on it. do you still think it should be removed?",0,0.8169696927070618
38299301,151,ijuma,2015-08-31T10:12:13Z,i checked this and i think 0 is correct for `leaderandisrresponse`. or am i missing something?,0,0.980166494846344
38299668,151,ijuma,2015-08-31T10:19:05Z,"i think you meant `controlledshutdownresponse`, i fixed that.",0,0.9872379302978516
38300557,151,ijuma,2015-08-31T10:33:47Z,"is this something we want to do now or when the need arises? i didn't want to add this to the clients jar because i thought it was just useful to help us transition the broker code without bigger changes. it seems like there may be more use cases, but isn't it better to wait until they are concrete before moving the code to the clients jar?",0,0.9687362909317017
38303535,151,ijuma,2015-08-31T11:31:47Z,"actually i can't make this change because `security_protocol_type_key_name` will never exist at this level. i could check for `endpoints_key_name`, but i think the current way is less error-prone (as endpoints could be empty due to a bug perhaps). so i'll leave it as is unless you disagree.",0,0.963940441608429
38303909,151,ijuma,2015-08-31T11:38:38Z,will fix.,0,0.9742533564567566
38303913,151,ijuma,2015-08-31T11:38:45Z,will fix.,0,0.9742533564567566
38303918,151,ijuma,2015-08-31T11:38:53Z,will fix.,0,0.9742533564567566
38304564,151,ijuma,2015-08-31T11:50:35Z,"perhaps. i'm not sure though. it's easy enough for the caller to call `blockingready` if that is desired, right? i didn't do that in `controllerchannelmanager` because the existing code already handles the exception that would be thrown if the initial connection fails: [code block] the existing code is not the prettiest, but i tried not to make too many changes at this point. i think we should consider redesigning the controller/broker communication to make better use of `networkclient` in the future.",0,0.9350584745407104
38306320,151,ijuma,2015-08-31T12:21:10Z,"i did this, but it's worth being aware of the downsides (and why i had avoided that in the first place): - we now have a number of warnings due to the fact that we call the deprecated constructor - the calling code is more complex as it needs to pass slightly different data to each constructor (we still support both versions from the calling code and previously it just had to pass a version) - a new deprecated inner class `brokerendpoint` had to be introduced for the v0 constructor",0,0.9316074252128601
38313413,151,ijuma,2015-08-31T13:54:32Z,"i'll remove `retrybackoff`. it's how i had it at first, but i was seeing some issues where `poll` was returning immediately which was causing the thread to spin and seemed to be causing more connection timeouts than usual. i now think that this was caused by a bug in the handling of the connection failures (which i fixed before reopening the pr).",0,0.9671440720558167
38332668,151,junrao,2015-08-31T16:58:29Z,"yes, that's how mockselector is implemented. in the real selector, my understanding is that if you disconnect a client, we cancel the key. the cancelled key will never be selected by the selector again. so, you would have to set the connection state in the same disconnect call. if that's the case, we probably need to change the behavior of mockselector.",0,0.9834000468254089
38332742,151,junrao,2015-08-31T16:59:17Z,"this is related to the comment above. if a client calls disconnect, it may not be interested in using this connection any more. so, we probably want to fresh the memory by removing the id from the connection state.",0,0.9869801998138428
38332766,151,junrao,2015-08-31T16:59:27Z,what you have is fine. i didn't realize that mode is implicit and not an explicit property.,0,0.9612511396408081
38332782,151,junrao,2015-08-31T16:59:34Z,what you had is fine.,0,0.9547333717346191
38332818,151,junrao,2015-08-31T16:59:55Z,"it's fine if we set the nodes explicitly. if so, we should do the same for the manualmetadataupdater used in controllerchannelmanager.",0,0.987628698348999
38332943,151,junrao,2015-08-31T17:01:04Z,"yes, the logic in controllerchannelmanager is not pretty. the issue that i see is that if connecttobroker() fails to establish a connection in time, we just disconnect. so, by the time you send a request, there is not guarantee that the connection is ready.",-1,0.6730222702026367
38335942,151,junrao,2015-08-31T17:31:06Z,we can keep the blocking logic in scala for now.,0,0.9880367517471313
38336063,151,ijuma,2015-08-31T17:32:10Z,"we do indeed, but at construction time because we use a `networkclient` for each broker connection, i paste the line below: `new manualmetadataupdater(seq(brokernode).asjava)`",0,0.9872176051139832
38336694,151,ijuma,2015-08-31T17:37:51Z,"yes, i understand. so, if the connection is not ready, an `illegalstateexception` will be thrown which will cause a disconnect (no-op) followed by another connect and then we will retry again after a 300ms sleep since `issendsuccessful === false`. this behaviour is very similar to what would happen with `blockingchannel` where a closedchannelexception would be thrown if `send` was called and the channel was not connected due to a failure. i can add a `blockingready` call before the `send` if you think that is better though.",0,0.947996973991394
38337234,151,ijuma,2015-08-31T17:42:47Z,"i see. i'll test the behaviour of the real selector just to be sure. in the likely case that it matches your description, i will do the following: - update `mockselector` - update `networkclienttest` - update `selector.disconnect` and `networkclient.disconnect` documentation - update implementation of `networkclient.disconnect` to update connection states - remove `networkclientblockingops.disconnectandpoll` as `disconnect` will be sufficient have i covered everything?",0,0.9836666584014893
38338561,151,junrao,2015-08-31T17:53:43Z,"yes, relying on illegalstateexception probably works, but it's kind of hacky. illegalstateexception is meant to capture all programming errors, and using it for error handling feels wrong.",-1,0.9751376509666443
38338732,151,junrao,2015-08-31T17:55:07Z,got it. i missed that you can pass in the nodes from the constructor.,0,0.5804515480995178
38338901,151,junrao,2015-08-31T17:56:31Z,that sounds good.,1,0.8649845719337463
38340333,151,ijuma,2015-08-31T18:08:22Z,"ok, i will add a `blockingready` before the send then.",0,0.9885009527206421
38400639,151,ijuma,2015-09-01T09:30:33Z,we have `liveleaders` in `leaderandisrrequest`. do we want to keep this as `alivebrokers` or would it be better to call it `liveborkers`?,0,0.984973669052124
38423086,151,ijuma,2015-09-01T14:16:52Z,i did this here instead of changing `blockingsendandreceive` to make it easier to maintain the previous behaviour of logging once a connection is established.,0,0.9878078103065491
38423154,151,ijuma,2015-09-01T14:17:33Z,"this method already existed in `networkclient`, i just added it to the interface.",0,0.9895920157432556
38423354,151,ijuma,2015-09-01T14:19:08Z,"i named this `close` instead of `disconnect` to match the relevant method in `selector`, but i'd be interested in feedback regarding the naming. also, it's not clear to me when `selector.disconnect` is actually useful.",0,0.987342357635498
38473289,151,junrao,2015-09-01T21:16:58Z,is that added?,0,0.9846867918968201
38473306,151,junrao,2015-09-01T21:17:04Z,this is not really an instance of invalidmetadataexception.,0,0.8979078531265259
38473310,151,junrao,2015-09-01T21:17:09Z,this is not really an instance of invalidmetadataexception.,0,0.8979078531265259
38473361,151,junrao,2015-09-01T21:17:30Z,"even though updatemetadatarequest_v0 has identical structure as leaderandisrrequest_v0, the set of brokers used are slightly different. in updatemetadatarequest_v0, we pass in all live brokers. in leaderandisrrequest_v0, we pass in all live brokers that are the leaders. so, we can keep the names as they are.",0,0.9860047698020935
38473426,151,junrao,2015-09-01T21:17:59Z,"in version 0, we should only allow passing in a single brokerendpoint.",0,0.9888353943824768
38473454,151,junrao,2015-09-01T21:18:06Z,"now that we have the broker tag, the group prefix can just be ""controller-channel"" or sth like that.",0,0.9880449175834656
38473470,151,junrao,2015-09-01T21:18:13Z,is the if statement needed since the test is already done in networkclient.blockingready()?,0,0.9839545488357544
38475260,151,ijuma,2015-09-01T21:35:08Z,is it a `retriableexception` or `apiexception` then?,0,0.9863895773887634
38475273,151,ijuma,2015-09-01T21:35:16Z,is it a `retriableexception` or `apiexception` then?,0,0.9863895773887634
38475371,151,ijuma,2015-09-01T21:36:00Z,will fix.,0,0.9742533564567566
38475773,151,ijuma,2015-09-01T21:40:14Z,ok. we don't need to include the controller id in the group prefix or as a tag?,0,0.9876763820648193
38476438,151,ijuma,2015-09-01T21:46:57Z,"it's done this way to only log the ""controller %d connected"" message if the connection is not already ready.",0,0.9858507513999939
38477988,151,junrao,2015-09-01T22:02:59Z,apiexception for both.,0,0.9889464974403381
38478139,151,junrao,2015-09-01T22:04:55Z,we don't need the broker id in group prefix. still need the broker id in the metrics tag.,0,0.9878069758415222
38478285,151,junrao,2015-09-01T22:07:00Z,ok. we can leave it as it is. thanks for the explanation.,1,0.900934636592865
38478450,151,ijuma,2015-09-01T22:09:06Z,"sorry, my question was about the controller id (i had understood the point about the broker id).",-1,0.9818011522293091
38478876,151,ijuma,2015-09-01T22:14:31Z,"are you sure about this? looking at the scala code, it does: read: `case 0 => for(i <- 0 until numalivebrokers) yield new broker(brokerendpoint.readfrom(buffer),securityprotocol.plaintext)` write: ``case 0 => alivebrokers.foreach(_.getbrokerendpoint(securityprotocol.plaintext).writeto(buffer))`",0,0.9854162335395813
38483970,151,ijuma,2015-09-01T23:18:34Z,"not yet, i was focusing on getting the behaviour right first. i'll add all the missing javadoc/scaladoc in my next commit.",0,0.9719559550285339
38498073,151,junrao,2015-09-02T04:29:17Z,"actually, my comment wasn't right. what you had is right since in v0, we pass in a set of brokerendpoint and v1, we pass in a set of broker.",0,0.9502202272415161
38521906,151,ijuma,2015-09-02T11:30:39Z,"yes, i understand the difference between brokers and leaders. the bit i was asking about is the `live` prefix (in `liveleaders`) versus the `alive` prefix (in `alivebrokers`). it seemed to me that `livebrokers` means the same and the prefix would be consistent. anyway, not a big deal, so fine to keep as is if you prefer.",0,0.937681257724762
38559331,151,junrao,2015-09-02T17:21:34Z,"yes, i agree that it's better to make the names consistent. so we can use live_brokers and live_leaders here and in protocols as well.",0,0.9727362394332886
114734810,2967,ijuma,2017-05-04T09:43:29Z,are the `private` -> `protected` changes still needed?,0,0.9884101152420044
114739200,2967,ijuma,2017-05-04T10:09:24Z,"for consistency, it may make sense for `wrapforoutput` to take a `bytebuffer` too.",0,0.9880639910697937
114740176,2967,ijuma,2017-05-04T10:15:34Z,"we could change `defaultrecord.readfrom` to take a `datainput` (instead of `datainputstream`), change `kafkalz4blockinputstream` to implement `datainput` and then only wrap if the returned value is not already a `datainput`. that would remove a layer of indirection and if it's possible to implement `readfully` more efficiently in `kafkalz4blockinputstream`, then it could be a win. if you have time, it may be worth a try.",0,0.9107492566108704
114742214,2967,ijuma,2017-05-04T10:27:46Z,"it wasn't clear to me why we needed both `thebuffer` and `decompressionbuffer`. it seems that we rely on the fact that `thebuffer` is only populated after the first `readblock` to implement `available` correctly. is that the only difference? if so, would it not be simpler to have a single buffer that is allocated for the first time in `readblock`?",0,0.9751108884811401
114742293,2967,ijuma,2017-05-04T10:28:16Z,`mark()` and `reset()` are synchronized and probably should not be.,0,0.984119713306427
114742552,2967,ijuma,2017-05-04T10:29:51Z,i think the default should be `current_magic_value`.,0,0.9889931082725525
114742615,2967,ijuma,2017-05-04T10:30:16Z,why did you remove `none` from this list? it seems useful to have the uncompressed baseline.,0,0.9833811521530151
114742753,2967,ijuma,2017-05-04T10:31:07Z,seems like more fields could be final in this class.,0,0.977867603302002
114743094,2967,ijuma,2017-05-04T10:33:53Z,you should probably use `abstractrecords.sizeinbytesupperbound`.,0,0.9887211918830872
114744092,2967,ijuma,2017-05-04T10:41:09Z,"to make the benchmark less dependent on implementation details, it would be better if it used `memoryrecords.readablerecords(...).batches()`. same for the other benchmark.",0,0.9864126443862915
114744933,2967,ijuma,2017-05-04T10:46:15Z,maybe this should be `recordbatchiterationbenchmark`?,0,0.987825334072113
114746255,2967,ijuma,2017-05-04T10:55:31Z,"we followed the same approach for snappy and lz4 to deal with the possibility that the libraries are not in the classpath because it's not supported in a given platform. however, we are using kafka classes for the block input stream and block output stream. as such, we can probably reference the constructor directly. we won't invoke the constructor unless lz4 is configured and it's ok to fail in that case. does that make sense?",0,0.9748272895812988
114746515,2967,ijuma,2017-05-04T10:57:30Z,why do we need this?,0,0.9493659734725952
114807909,2967,xvrl,2017-05-04T15:14:02Z,"we don't need them anymore, indeed",0,0.9104661345481873
114808828,2967,xvrl,2017-05-04T15:17:27Z,sure,0,0.9371067881584167
114808856,2967,xvrl,2017-05-04T15:17:33Z,"the benchmark is in the `org.apache.kafka.common.record` package. now that we don't rely on package protected classes anymore, we can move it to `org.apache.kafka.jmh` and remove this.",0,0.9878608584403992
114810971,2967,xvrl,2017-05-04T15:24:57Z,`thebuffer` is also pointed directly to the input buffer when a block is not compressed to avoid copying bytes.,0,0.9875911474227905
114811084,2967,xvrl,2017-05-04T15:25:21Z,"hmm, not sure why they were in the first place",0,0.7988094687461853
114812768,2967,ijuma,2017-05-04T15:31:22Z,"copy and paste, i bet.",0,0.7453786730766296
114812862,2967,ijuma,2017-05-04T15:31:42Z,sounds good.,1,0.9202015399932861
114814192,2967,ijuma,2017-05-04T15:36:30Z,"i had noticed that, but didn't think through how that could work if we had a single buffer variable. ok, seems simplest to have two buffers. can we add a comment explaining this?",0,0.9679904580116272
114824952,2967,xvrl,2017-05-04T16:19:55Z,"seems like this is not as straightforward as it seems. memoryrecordsbuilder relies on having access to the underlying bytebuffer held by the bytebufferoutputstream, which would break if the buffer is expanded in bytebufferoutputstream",0,0.95939701795578
114826480,2967,xvrl,2017-05-04T16:26:38Z,"makes sense, as far as i know lz4 falls back to a pure-java version anyway, so it should be safe regardless (unless there are other platform issues that are unrelated to native code)",0,0.9844574332237244
114826699,2967,xvrl,2017-05-04T16:27:43Z,"i'd prefer to do that in a follow-up pr in trunk, since i'd also like to backport this to 0.10.2.x",0,0.9863718152046204
114826741,2967,xvrl,2017-05-04T16:27:56Z,will do,0,0.9603245854377747
114828336,2967,xvrl,2017-05-04T16:35:40Z,"note however that we store the lz4safedecompressor as a static field, so loading the kafka class would also trigger loading the lz4 classes.",0,0.9883393049240112
114873529,2967,xvrl,2017-05-04T20:00:12Z,fixed,0,0.975196123123169
114873560,2967,xvrl,2017-05-04T20:00:19Z,fixed,0,0.975196123123169
114874156,2967,xvrl,2017-05-04T20:03:09Z,"when using `memoryrecords.readablerecords(...)` we don't technically test the compression.none ""compression"" method, but test a different code path, so it's not really comparable if you care about an upper bound on how fast decompression could be.",0,0.9733346700668335
114874228,2967,xvrl,2017-05-04T20:03:31Z,i added it back so we could at least see what it means in practice though,0,0.9838268160820007
114874277,2967,xvrl,2017-05-04T20:03:40Z,fixed,0,0.975196123123169
114874313,2967,xvrl,2017-05-04T20:03:52Z,good to know,1,0.9388749003410339
114874345,2967,xvrl,2017-05-04T20:04:02Z,changed.,0,0.9753402471542358
114876003,2967,xvrl,2017-05-04T20:12:03Z,"i was also thinking, if we avoided readfully altogether, we could avoid the eofexception penalty when reaching the end of the batch on legacy records and get a further 3x improvement for small legacy batches.",0,0.9822486639022827
114877226,2967,ijuma,2017-05-04T20:18:00Z,"it's not the same code path, but that's ok. the comparison i'm looking for is a bit like the one in the lz4 github page where it compares memcpy with lz4 decompression ([a link]",0,0.9598891139030457
114879573,2967,ijuma,2017-05-04T20:28:49Z,"hmm, `datainputstream.readfully` only throws an exception if we ask it to read past the end of the inputstream. so supposedly, if we fix the underlying inputstream, it's enough either way. the following pr does that: [a link]",0,0.9797098636627197
115125280,2967,hachikuji,2017-05-06T17:42:08Z,"nit: this looks a little weird. could we just do [code block] also, the name is a bit vague. maybe `record_header_size`?",-1,0.9852321147918701
115125399,2967,hachikuji,2017-05-06T17:47:46Z,this block seems to be the same code as below. perhaps we could move it into a `readfully` function in `utils` (we have a couple of these for working with `filechannel` already)?,0,0.9893978834152222
117260682,2967,ijuma,2017-05-18T14:20:03Z,"good point, can we please add a comment explaining the reason for the inconsistency?",0,0.6202072501182556
117292625,2967,ijuma,2017-05-18T16:19:57Z,"yeah, but `kafkalz4blockinputstream` itself should not be initialised until it's actually used. i made this change, used compressiontype.snappy.wrap* methods while lz4 was not in the classpath and it worked fine. the same exercise did not work for snappy because `snappyinputstream` was not in the classpath. anyway, we can keep it as it is if you prefer as the performance impact is low when compared to other things (8ns instead of 4ns per construction).",0,0.9578260779380798
117300016,2967,xvrl,2017-05-18T16:54:17Z,done,0,0.9764507412910461
117300539,2967,xvrl,2017-05-18T16:56:50Z,"ok, i've change it to construct the lz4 streams directly, and updated the comments accordingly.",0,0.9878756403923035
118957598,2967,ijuma,2017-05-29T15:38:55Z,is it safe to do this on the received buffer? `deeprecordsiterator` doesn't seem to duplicate the buffer before calling `compressiontype.wrapforoutput`.,0,0.9892759323120117
118962982,2967,ijuma,2017-05-29T16:25:02Z,"i'm not totally sure why we were previously using a `readunsigned` method and now we're not. for many of the other cases where we do this, it's easy to verify that the values we care about work either way. the ones that weren't totally clear to me were this and the block checksum cases. can you please elaborate why the change is safe in those two cases?",0,0.8718182444572449
118966334,2967,ijuma,2017-05-29T17:01:00Z,"hmm, so this bug meant that the `blocksize > maxblocksize` check was not working, right? also, did we just get lucky that the `blocksize == 0` check worked?",0,0.9535818696022034
118970809,2967,ijuma,2017-05-29T17:52:18Z,nit: is there a reason why we are modifying the existing block size instead of just setting the bad block size directly?,0,0.8353390097618103
119135013,2967,xvrl,2017-05-30T15:35:05Z,"from reading the code, `byteutils.readunsignedintle` is a misnomer and should probably be just be called `readintle`. unlike `readunsignedint`, which returns a long and applies the proper bit mask, `readunsignedintle` returns an integer and doesn't do anything other than shifting the bytes.",0,0.9810555577278137
119140839,2967,xvrl,2017-05-30T15:55:42Z,"`deeprecordsiterator` technically duplicates the buffer when calling [a link] and never reuses it, but i agree that could easily be missed or introduce odd bugs if that code were to be rewritten. i can add a `duplicate()` here just for safety.",0,0.9826252460479736
119141976,2967,ijuma,2017-05-30T15:59:58Z,sounds good.,1,0.9202015399932861
119146762,2967,xvrl,2017-05-30T16:18:08Z,"indeed, the size check wasn't working, but at the end of the day, we would just thrown a different exception in case the block size exceeded the max. regarding the zero size block, we were just lucky that we never set the `lz4_frame_incompressible_mask` flag in `kafkalz4blockoutputstream.writeendmark`. i checked the spec and it didn't seem to specify whether the flag should be set or not in that case, so better be safe.",0,0.8500492572784424
119157414,2967,xvrl,2017-05-30T17:02:15Z,"yes, to make sure it works in both cases when the incompressible flag is set and when it is not.",0,0.9815165996551514
119160775,2967,hachikuji,2017-05-30T17:15:48Z,should we rewind the buffer in case the position wasn't reset after the last use? (also nit: can we just call it `buffer`?),0,0.987963080406189
119161965,2967,hachikuji,2017-05-30T17:20:29Z,it's a little odd for this to live here given the interface is in `kafkalz4blockinputstream`. i'd suggest either moving it there or pulling the `buffersupplier` interface out of `kafkalz4blockinputstream`.,0,0.8286079168319702
119174351,2967,ijuma,2017-05-30T18:10:08Z,"yeah, my pr removes all of these in favour of existing constants: [a link]",0,0.9772953987121582
119174470,2967,ijuma,2017-05-30T18:10:32Z,you and i had the exact same thought: [a link],0,0.9739773869514465
119174697,2967,ijuma,2017-05-30T18:11:25Z,3 for 3: [a link],0,0.9784157872200012
119174941,2967,ijuma,2017-05-30T18:12:24Z,that's one issue. the other is that if there are two `kafkalz4blockinputstream` instances in the same thread: [a link],0,0.9840344190597534
119183125,2967,xvrl,2017-05-30T18:47:29Z,"technically we don't have to, kafkalz4blockinputstream resets position and limit every time anyway when preparing the buffer for consumption. agree that would be a concern if someone were to consume from two separate consumers in the same thread. happy to replace the buffer supplier implementation with the one you pointed to.",1,0.9482141733169556
119185468,2967,hachikuji,2017-05-30T18:57:10Z,"yeah, figured that was the case, but it makes the code a bit brittle to depend on that.",0,0.8296200037002563
107401674,2719,dguy,2017-03-22T12:36:06Z,i wonder if we should set this higher? is there any harm in setting it to `integer.max_value`?,0,0.7421388626098633
107402332,2719,dguy,2017-03-22T12:39:55Z,do you think we should maybe kill some more brokers? or is that going to be too non-deterministic in terms of test failures?,0,0.9081592559814453
107427012,2719,enothereska,2017-03-22T14:26:45Z,we probably can. the main problem i have right now is how to sidestep all the kafka corner cases when it comes to failures while still showing that streams is resilient. stay tuned.,0,0.8975589275360107
107454080,2719,enothereska,2017-03-22T15:57:22Z,ok,0,0.9667208194732666
107481625,2719,enothereska,2017-03-22T17:36:40Z,do these parameters make sense for a config that should not lose data? we are ok to have duplicates. do i need to do anything with `unclean.leader.election`?,0,0.9752932190895081
108192236,2719,dguy,2017-03-27T14:58:35Z,would be better to pass in an implementation of `time` and use `time.sleep(1000l)` here.,0,0.9847590327262878
108193858,2719,dguy,2017-03-27T15:04:12Z,we currently don't do anything about `min.insync.replicas` - should we?,0,0.9419949054718018
108194089,2719,dguy,2017-03-27T15:05:03Z,"nit: ""active tasks {}, standby tasks {}, suspended tasks {}, and suspended standby tasks {}""",0,0.9884344339370728
108194869,2719,dguy,2017-03-27T15:07:41Z,"`new streamsexception(""could not poll."", e)`",0,0.9817673563957214
108195049,2719,dguy,2017-03-27T15:08:16Z,"apart from a `streamsexception` i think the only other exception that `poll` is going to throw is `illegalstateexception` - should we just handle this in `sendrequest` and leave this as it was. even if there are more exceptions, i think it would be better to handle it in `sendrequest` and throw a `streamsexception` from there",0,0.9832067489624023
108196783,2719,dguy,2017-03-27T15:15:24Z,i guess you can remove this now?,0,0.9864447712898254
108197021,2719,dguy,2017-03-27T15:16:24Z,you can remove this now as you've set it as the default in `streamsconfig`,0,0.9883784651756287
108197175,2719,dguy,2017-03-27T15:16:59Z,same with this one,0,0.9828817844390869
108202868,2719,enothereska,2017-03-27T15:37:34Z,yes we should. any insights on what you have found useful for that? thanks.,1,0.8584921956062317
108203239,2719,enothereska,2017-03-27T15:38:57Z,"not quite, since in streamsconfig it is the internal streams producer. here it's another producer.",0,0.984492301940918
108262374,2719,norwood,2017-03-27T19:48:07Z,"something like `min(2, replicationfactor)` should be a good default. i'd also be concerned about this override for `brokers.size() < replicationfactor`. i think i'd prefer we fail here, rather than getting in to a misconfigured state. we have run in to issues where a user brings up a cluster and as kafka is doing its thing also brings up their streams app. so during startup we see 1 broker, then sometime down the line broker 2...n. this was causing us to precreate a bunch of our streams topics incorrectly (when we only saw one broker), and then on restart we would try to verify topics against actual configs and fail.",0,0.5070787072181702
108262836,2719,norwood,2017-03-27T19:50:09Z,i think `validatetopicpartitions` should also validate `replicationfactor`,0,0.9864930510520935
108263977,2719,mjsax,2017-03-27T19:55:21Z,we need a kip if we change any default values...,0,0.9755346775054932
108264259,2719,mjsax,2017-03-27T19:56:42Z,do we really want to do this? i would strongly prefer to throw an exception to the user!,0,0.7167114019393921
108264430,2719,mjsax,2017-03-27T19:57:23Z,i would not change this default value -- it's a hassle of anyone want to run a demo with local single broker setup.,0,0.8480106592178345
108264962,2719,mjsax,2017-03-27T19:59:40Z,ups. we really missed to close suspended tasks. really bad :( great catch eno!,-1,0.9497092366218567
108265404,2719,mjsax,2017-03-27T20:01:29Z,nit: add `final`,0,0.9880309700965881
108265542,2719,mjsax,2017-03-27T20:02:06Z,nit: add `final`,0,0.9880309700965881
108265707,2719,mjsax,2017-03-27T20:02:53Z,nit: add `final`,0,0.9880309700965881
108265721,2719,mjsax,2017-03-27T20:02:56Z,nit: add `final`,0,0.9880309700965881
108268924,2719,norwood,2017-03-27T20:16:25Z,"maybe a more dynamic default here, like with `acks=all=-1`? e.g. set `replicationfactor=-1` => `actualreplicationfactor=min(3, brokers.size())`",0,0.9863054752349854
108276754,2719,enothereska,2017-03-27T20:51:12Z,"the code actually uses min(#brokers, replication_factor), and prints a warning, but it still runs with, say, 1 broker.",0,0.9894644021987915
108276951,2719,enothereska,2017-03-27T20:51:55Z,"this is consistent with how things like schema registry, proactive support etc handle cases when the number of brokers is less than replication factor.",0,0.9849987626075745
108277094,2719,enothereska,2017-03-27T20:52:35Z,"do we? ? i thought we needed a kip to add new config values, not each time we tune them.",0,0.969897449016571
108277327,2719,enothereska,2017-03-27T20:53:28Z,"the goal here is to do the right thing when there are enough brokers, not to provide magic when there just aren't enough brokers (e.g., in a test environment). currently we do the wrong thing when there are enough brokers.",0,0.6015703678131104
108278624,2719,enothereska,2017-03-27T20:59:15Z,yeah this was fun :),1,0.9910266995429993
108281740,2719,guozhangwang,2017-03-27T21:14:49Z,"i'd suggest throwing an exception here with the motivation similar to above. we have seen similar issues with offset topic num.partitions which we do this ""min(broker.size, required num.broekrs)"" trick and it introduces much more confusions than user-friendly benefits. for unit tests we should just always override these configs.",0,0.9668980240821838
108282040,2719,guozhangwang,2017-03-27T21:16:24Z,let's write a quick kip for this (also including the default replication factor to 3 above)? i think they are mostly fixing a bug but would better making them well known in the community as well.,0,0.975023627281189
108282772,2719,guozhangwang,2017-03-27T21:20:17Z,"also i feel 1 second maybe too long in production? in practice brokers should be up / running much earlier than streams apps. for cases i still think it's better to fail fast and educate users retry creating their apps after the broker is fully up than trying to wait for, say 5 seconds and hopefully it will succeed.",0,0.7417884469032288
108283433,2719,guozhangwang,2017-03-27T21:23:29Z,these two functions are very similar: could we collapse them into one function `performontasks` and pass in a `list ` as an additional parameters?,0,0.9840001463890076
108283588,2719,guozhangwang,2017-03-27T21:24:15Z,ditto above.,0,0.9270309805870056
108283829,2719,guozhangwang,2017-03-27T21:25:22Z,why we want to wrap even a rte as a streamsexception here?,0,0.978492021560669
108283871,2719,guozhangwang,2017-03-27T21:25:38Z,same here.,0,0.9813250303268433
108288736,2719,mjsax,2017-03-27T21:49:35Z,"i think this dynamic change is quite dangerous -- if i specify replication 3 and cannot get it, i want an exception... thus, i would leave replication factor to 1 for demoing purpose -- if anyone goes to production she can set to whatever value is suitable -- or we make the parameter non-optional. i think it would be a hassle to have default value 3, and overwrite it with 1 in each example we do...",-1,0.9225732684135437
108289042,2719,mjsax,2017-03-27T21:51:10Z,we really need a bug fix release for this! \cc,-1,0.9591094255447388
108292755,2719,enothereska,2017-03-27T22:09:39Z,"if i understand you right, you want the default 3, with the option for a user to set it to 1, right? or you want no change at all to what we currently have (default 1, user can set higher). i don't like the current option since it leads to trouble in production. i'm ok with the first option.",-1,0.920806884765625
108292984,2719,enothereska,2017-03-27T22:11:04Z,i think a kip unnecessarily slows things down. why do we need to do a kip to correct an internal flaw? users are already expecting internal topics to be robust. i'd argue we're fixing a bug here.,-1,0.570859432220459
108293564,2719,norwood,2017-03-27T22:14:25Z,"yeah, my suggestion was to make the dynamism configurable. replication_factor_config= n where n >0 => i know what i want. streams should fail if it can't meet this contract replication_factor_config = -1 => streams is smart and can figure it out for me. this allows *me* to be as anal retentive as i want, but allows the defaults to work for demos/tests/etc.",1,0.6724802255630493
108301670,2719,mjsax,2017-03-27T23:06:09Z,"what should this be than? would we need another parameter ""default_replacation_factor"" and streams can choose between 1 and this value? not sure if this would not be too confusing.",0,0.957642674446106
108301836,2719,mjsax,2017-03-27T23:07:18Z,i am happy without a kip :) makes live easier for us. it's call. or any other committer.,1,0.9915798902511597
108302114,2719,norwood,2017-03-27T23:09:18Z,"my suggestion above was `min(3, brokers.size())` i dont like this cause it seems like magic, but it also addresses most peoples issues.",-1,0.8166852593421936
108302312,2719,mjsax,2017-03-27T23:10:37Z,"i would prefer to keep the current default 1 and mark the parameter importance as ""high"", indicating that one most likely wants to change the default if going to production. default values must not be ""production ready"" settings imho (cf. `state.dir`). default values should give the best ""out-of-the-box"" experience when getting started with you first ""word count"" -- ie., local single broker setting.",0,0.9823127388954163
108341596,2719,enothereska,2017-03-28T06:20:32Z,"ok, i cannot keep the default to 1. this is what led to several bugs. it's not great to expect users to set this parameter which streams should be maintaining correctly.",-1,0.8389846086502075
108359843,2719,ijuma,2017-03-28T08:19:41Z,", as you know, we have changed the behaviour for the offsets topic so that we default to the safe production setting and fail otherwise. that is based on experience, as said, and seems more relevant than some of the other examples given. the question then is how to make it easy for development. for the offsets topic, we set the value to 1 in the `server.properties` that is used in the quickstarts, etc. that won't work here. there are a few possible solutions that will be helpful for this and many other configs: 1. have a config where users can define whether the environment is prod or dev and change the defaults based on that. 2. provide methods so that a user can get a prod or dev config. for example, `streamsconfigs.production()` or `streamconfigs.development()`. 3. add an enum to the constructor of `streamconfigs` where users can define if the environment is production or development. i think i like `3` best. in any case, we don't need to block this pr on the long-term solution. still, it may be worth figuring out the end state and then a plan on how to get there.",0,0.9137741923332214
108364658,2719,enothereska,2017-03-28T08:44:11Z,cc,0,0.9684008955955505
108368495,2719,ijuma,2017-03-28T09:01:55Z,"we typically do kips for config changes that impact users. kip-106 is one such example. if you can make the case that this is an internal bug fix and has no compatibility impact, then no kip is needed. the replication factor one would seemingly have a compatibility impact.",0,0.9831189513206482
108471613,2719,enothereska,2017-03-28T16:35:58Z,this will now be done in a kip and different pr.,0,0.9845461845397949
108472487,2719,enothereska,2017-03-28T16:39:37Z,"i'm reducing the time, but passing in `time` is a bit of a pain here and other calls also use thread.sleep. would prefer to do a cleanup pass later.",-1,0.8352253437042236
108472921,2719,enothereska,2017-03-28T16:41:17Z,"i didn't get this, what should be `final`?",0,0.8646652698516846
108473345,2719,enothereska,2017-03-28T16:43:10Z,this class should hide all underlying network exceptions and wrap them with stream exception imo. this is consistent with other examples in this class. otherwise the upper layers would need to know all the details of the underlying classes.,0,0.9885181784629822
108473773,2719,enothereska,2017-03-28T16:44:56Z,what exactly? i don't get this.,-1,0.8259566426277161
108479165,2719,enothereska,2017-03-28T17:07:45Z,this will now require a kip. will do in separate pr.,0,0.9877045154571533
108479321,2719,enothereska,2017-03-28T17:08:29Z,this will now require a kip and will be done in separate pr.,0,0.9870225787162781
108479431,2719,enothereska,2017-03-28T17:09:01Z,this will now require a kip and will be done in a separate pr.,0,0.9872904419898987
108481016,2719,mjsax,2017-03-28T17:15:57Z,-> `} catch (final exception e) {`,0,0.983928918838501
108656204,2719,dguy,2017-03-29T11:52:48Z,can we pass in `time` and use `time.sleep(100l)` here?,0,0.9873085618019104
108656295,2719,dguy,2017-03-29T11:53:14Z,same as above,0,0.9772257208824158
108892220,2719,dguy,2017-03-30T10:31:20Z,i'm thinking it might be better to have a field in `streampartitionassignor` for time. it would default to `time.system` and then have a package private method for overriding it in tests. this way we wouldn't need to make the `time` field on `streamthread` public,0,0.9849547147750854
108892245,2719,dguy,2017-03-30T10:31:29Z,see comment above,0,0.981052577495575
108894798,2719,enothereska,2017-03-30T10:46:16Z,but couldn't that lead to cases when `streamthread` is given one type of time and `streampartitionassignor` another type of time? i'm not sure what that would mean. i think they should use the same time type.,0,0.9378013014793396
108895304,2719,dguy,2017-03-30T10:49:18Z,"in tests that could happen. i guess there are other `public final` fields (which i don't agree with), so whatever",0,0.9818815588951111
109059440,2719,guozhangwang,2017-03-30T23:13:34Z,i'd agree with damian to have this time object pass long the hierarchy than passing it from the thread directly to the internal topic manager. i would not worry too much about passing in different objects since both of them are internal topics so the only place we may directly pass the object is in unit tests.,0,0.8349799513816833
109060051,2719,guozhangwang,2017-03-30T23:18:48Z,"for suspended tasks, could the closure process be simpler? for example we have already closed the topology as well as committing the states, etc. ditto below.",0,0.9863796830177307
109073610,2719,mjsax,2017-03-31T01:39:01Z,"nit: i think the error message does not read well: `not enough brokers 2 for replication factor 3` better: `found only 2 brokers, but replication factor is 3. decrease replication factor for internal topics via streamsconfig parameter ""replication.factor"" or add brokers to your cluster.`",0,0.8353366851806641
109073704,2719,mjsax,2017-03-31T01:40:35Z,should we increase backup time if we keep retrying?,0,0.9794895648956299
109073754,2719,mjsax,2017-03-31T01:41:19Z,as above?,0,0.9795584082603455
109074329,2719,mjsax,2017-03-31T01:49:23Z,why do we need a `node` now but not before?,0,0.9773808717727661
109074528,2719,mjsax,2017-03-31T01:52:08Z,didn't we change the default values for both already?,0,0.9849004745483398
109074584,2719,mjsax,2017-03-31T01:52:51Z,add `final` to `properties props = new properties();` and method parameters. also all variables used farther down.,0,0.9879896640777588
109074646,2719,mjsax,2017-03-31T01:53:37Z,rename `props` to `producerprops` ;),0,0.8534712195396423
109074740,2719,mjsax,2017-03-31T01:54:38Z,not sure what's happening here. but `6` does still not seem to be large. why change it in the first place?,0,0.7700815200805664
109075186,2719,mjsax,2017-03-31T02:01:04Z,"we have replication factor 3 and min.in.sync.replicas 2 -- it might happen that if 2 brokers fail, a topic does not have enough in-sync-replicates anymore?",0,0.9815089702606201
109114808,2719,enothereska,2017-03-31T08:47:50Z,"i could add an extra method in streamtask.java to close the rest, not the topology. however, this only happens at shutdown, not sure it's worth it. so it could be simpler, but with more lines of code.",0,0.9778949618339539
109115463,2719,enothereska,2017-03-31T08:51:36Z,"traditionally we don't do anything clever with backoff times throughout the code. it can get complicated, e.g., by how much to increase in each step.",0,0.7854743003845215
109115631,2719,enothereska,2017-03-31T08:52:28Z,"because now in `makeready` we check the number of brokers in metadata, whereas before we didn't.",0,0.986735463142395
109117043,2719,enothereska,2017-03-31T09:01:02Z,we decided that changing the internal default values required a kip. for now just changing the test values in this pr.,0,0.9823577404022217
109117552,2719,enothereska,2017-03-31T09:03:53Z,"this is effectively the timeout of the test. with higher replication factor for the internal topics, and with acks to ""all"" i noticed that the test takes slightly longer to run, so upped this value.",0,0.9829879999160767
109117773,2719,enothereska,2017-03-31T09:04:50Z,"yeah that's fine. this just means that when there is no failure, keep 2 replicas in sync. when there are 2 failures, the system should still be up and running.",0,0.9720562100410461
109203917,2719,mjsax,2017-03-31T16:54:28Z,"depends on the use case: either add the same value each time, or double up. we this when waiting for locks to get released on rebalance already: [a link]",0,0.9858109951019287
109208623,2719,guozhangwang,2017-03-31T17:19:31Z,makes sense.,0,0.9637326002120972
109279169,2719,enothereska,2017-04-01T06:40:45Z,i'm not ready for this yet. we can revisit backoffs in all the streams code and see how the networking client code has done them. also we should tie these numbers to some sort of config users can set.,0,0.6469188928604126
649771532,10822,erdody,2021-06-11T07:56:17Z,nit: or empty **if** this worker ....,0,0.6585102677345276
649777408,10822,erdody,2021-06-11T08:05:50Z,"nit: this actually collects the state of all tasks, so it's only empty if there are no tasks, right?",0,0.9834519624710083
649778786,10822,erdody,2021-06-11T08:08:00Z,nit: can use a method reference,0,0.9879431128501892
649791058,10822,erdody,2021-06-11T08:26:54Z,"there are a few comments in different places explaining the special equality implementation in restartrequest. have we considered making this a map to make it explicit that we keep the latest per connector, have a more typical equals/hashcode and avoid all the warnings?",0,0.9873966574668884
649792398,10822,erdody,2021-06-11T08:28:48Z,"just out of curiosity, any particular reason why we want to process these in connectorname order? (instead of fifo)",0,0.8939608931541443
649797930,10822,erdody,2021-06-11T08:36:52Z,nit: use a message similar to the one you corrected in line 1030?,0,0.9851395487785339
649800302,10822,erdody,2021-06-11T08:40:27Z,"just wondering: could blocking the addition of new entries be a problem, considering that this method can take some time? would it be worth creating a copy of the collection to minimize the synchronized time?",0,0.9375851154327393
649803403,10822,erdody,2021-06-11T08:44:48Z,"nit: quotes around connectorname, like in the line below",0,0.9883952140808105
649806839,10822,erdody,2021-06-11T08:49:53Z,the return value is only used by tests. can we assert based on other methods calls instead?,0,0.989063560962677
651253521,10822,erdody,2021-06-14T20:26:32Z,nit: move up so you can share with 270?,0,0.9839404821395874
651262244,10822,erdody,2021-06-14T20:40:49Z,nit: `boolean.parseboolean()`,0,0.9857309460639954
651291606,10822,kpatelatwork,2021-06-14T21:30:52Z,done,0,0.9764507412910461
651291754,10822,kpatelatwork,2021-06-14T21:31:09Z,fixed,0,0.975196123123169
651291878,10822,kpatelatwork,2021-06-14T21:31:22Z,fixed,0,0.975196123123169
651292365,10822,kpatelatwork,2021-06-14T21:32:16Z,fixed,0,0.975196123123169
651292417,10822,kpatelatwork,2021-06-14T21:32:22Z,fixed,0,0.975196123123169
651293447,10822,kpatelatwork,2021-06-14T21:34:20Z,"i agree it is used by only tests but it made the tests more clear rather than relying on mock verify. i added a comment to the code to make this clear, please let me know if the new changes looks good.",0,0.8128825426101685
651296666,10822,kpatelatwork,2021-06-14T21:40:35Z,we can't make a copy because we are doing pollfirst and its removing it out of set ` while ((request = pendingrestartrequests.pollfirst()) != null) { ` the whole method synchronization was done deliberately to keep the code simple. one more point is that this just triggers the start of connector/tasks and real start happens in another thread so this should be pretty fast.,0,0.9670904278755188
651298044,10822,kpatelatwork,2021-06-14T21:43:12Z,"no particular reason, treeset was a navigableset implementation that came to my mind. but i like your above idea of using a map and simplifying the code, let me work on it.",1,0.6911789178848267
651300080,10822,kpatelatwork,2021-06-14T21:46:49Z,"good idea, fixed",1,0.9740139245986938
651323170,10822,kpatelatwork,2021-06-14T22:38:07Z,"fixed, could you please check to see if it looks good now?",0,0.9240887761116028
651323500,10822,kpatelatwork,2021-06-14T22:38:54Z,new implementation with iterator makes this explicit. could you please check to see if it looks good now?,0,0.9642747640609741
651508714,10822,erdody,2021-06-15T07:09:53Z,"the main problem is that you're testing the code you added for tests, not that the actual actions are executed. unless you're also have coverage to verify that there's correspondence between the different results and the actions that need to happen in each case.",0,0.9504621624946594
651509086,10822,erdody,2021-06-15T07:10:23Z,"afaics, since all accesses are synchronized, this doesn't need to be concurrent.",0,0.9868796467781067
651852657,10822,kpatelatwork,2021-06-15T14:32:29Z,fixed,0,0.975196123123169
651854001,10822,kpatelatwork,2021-06-15T14:33:51Z,i removed the return and fixed the tests just to power mock verify. anyway i have integration tests so i partially agree that the return values were just me being paranoid in testing.,-1,0.8910017013549805
652845546,10822,rhauch,2021-06-16T16:16:53Z,can we replace these two methods with the following? [code block],0,0.9892390966415405
652846118,10822,rhauch,2021-06-16T16:17:35Z,nit: [code block],0,0.9873168468475342
652848315,10822,rhauch,2021-06-16T16:20:31Z,"this method name is very similar to the `includetasks()` getter method. wdyt about changing to `istaskincluded(taskstatus status)` instead, to more clearly differentiate that it's not merely a getter? if so, then `includeconnector(...)` could be renamed to `isconnectorincluded(connectorstatus status)`, too.",0,0.9868708848953247
652850147,10822,rhauch,2021-06-16T16:22:43Z,nit: [code block],0,0.9873168468475342
652852357,10822,rhauch,2021-06-16T16:25:39Z,"if the `dorestartconnectorandtasks(..)` method fails, then we won't remove the restart request and the herder will never make progress. should we protect this call a bit more with a try-catch-finally block?",0,0.9577637314796448
652854145,10822,rhauch,2021-06-16T16:28:00Z,"another option might be to dequeue (from the map) the restart requests in a synchronized block, and then perform those restarts outside of the synchronized block. this would at least minimize the work being done within the synchronized block to be just iteration and removal, lessoning the likelihood of blocking new requests. wdyt?",0,0.9882379174232483
652858133,10822,rhauch,2021-06-16T16:33:15Z,"of course, another option is to use a concurrent queue rather than a map, and deduplicate the requests only upon processing. for example, this method could dequeue all of them to a collection, replacing any earlier request with a more recent one, and then restart all of the deduplicated requests (ideally in the same order in which they were received). i'm not sure this is actually simpler. or, did you consider using a concurrentmap to avoid synchronization? that may be the least complicated way to remove the synchronization and yet require very few changes to the existing logic.",0,0.9599542021751404
652858998,10822,rhauch,2021-06-16T16:34:22Z,let's avoid more than 1 adjacent blank line: [code block],0,0.9862241744995117
652860987,10822,rhauch,2021-06-16T16:37:08Z,"i assume the choice of info here was intentional. if not, at what log level do we really want this log message? if so or if we do want this at info level, then maybe we should modify the `restartrequest.tostring()` method to be a little more user friendly (e.g., `restart request for connector %s (...)`). and would it help to mention here that it's being enqueued? maybe: [code block]",0,0.9821418523788452
652872036,10822,rhauch,2021-06-16T16:52:13Z,nice! i didn't recall that `` exists. but we should not have a space between that annotation and the open parenthesis: [code block],1,0.9891209006309509
652875494,10822,rhauch,2021-06-16T16:55:46Z,"won't `string.valueof(boolean)` be used here, and thus we're unboxing the `boolean` instance here? if there is a default value, then will `includetasks` and `onlyfailed` both always be non-null, and if so then couldn't we just use `boolean.tostring()` here?",0,0.987133800983429
652877090,10822,rhauch,2021-06-16T16:57:28Z,maybe add a comment here: [code block],0,0.9861336350440979
652881239,10822,rhauch,2021-06-16T17:03:05Z,"nit: i wonder if these log messages would be a bit easier to search and filter if they were reworded slightly: [code block] if you agree, then maybe also make similar changes to the corresponding log messages in the `distributedherder`.",0,0.8696456551551819
652883217,10822,rhauch,2021-06-16T17:05:57Z,"should we use a constant for this? i see that it's not really a pattern in the existing code, but maybe we should still do that here.",0,0.9824569821357727
652884464,10822,rhauch,2021-06-16T17:07:48Z,"wdyt about being a bit more tolerant of missing keys? for example, we could use defaults here.",0,0.9687535166740417
652885234,10822,rhauch,2021-06-16T17:08:52Z,let's avoid more than one adjacent blank lines. [code block],0,0.9874831438064575
652886935,10822,rhauch,2021-06-16T17:10:25Z,"""both"" what?",0,0.9314287900924683
652887340,10822,rhauch,2021-06-16T17:10:45Z,"again, ""both"" what?",0,0.934607744216919
652888065,10822,rhauch,2021-06-16T17:11:27Z,can we be more explicit in the test method names about what this test does?,0,0.985802412033081
652888765,10822,rhauch,2021-06-16T17:12:32Z,what does this mean:,0,0.9651648998260498
652890167,10822,rhauch,2021-06-16T17:14:33Z,"iiuc, we are not actually testing that the connector and task instances are distributed across different worker nodes, though it is likely to happen given the light connector load on the connect cluster.",0,0.9857122302055359
652891026,10822,rhauch,2021-06-16T17:15:44Z,"how long does it take for all of the tests in this it to run, say locally? iiuc, we're setting up a new kafka cluster and connect cluster for every test. how difficult would it be to share the same kafka and connect cluster across most of the tests?",0,0.9488388299942017
652921473,10822,kpatelatwork,2021-06-16T17:55:54Z,"could you guide me if there a predictable way to spread the tasks then i can change the test? i found that when i gave numworkers>1 most of the time they were distributed that's how i found an npe bug and had to use in the api. i am using numworkers=1 in other test to have a deterministic number of task restarts, whenever i had numworkers>1 the tasks would get restarted more than what i expect due to rebalance on worker nodes coming up.",0,0.9764605760574341
652923058,10822,kpatelatwork,2021-06-16T17:57:09Z,its on average 7-11sec per test (the ones with 35 sec are due to waiting in noop cases) ![a link] let me see if i can find a way to share and if it reduces the time.,0,0.8553600907325745
653046083,10822,kpatelatwork,2021-06-16T20:53:16Z,"the name was bothering me also :), the method documentation says ""determine whether the connector with the given status is to be restarted."" wdyt about changing it to one of the below? 1. isconnectorrestartable 2. istaskrestartable or 1. shouldrestartconnector 2. shouldrestarttask",1,0.9145622253417969
653053764,10822,kpatelatwork,2021-06-16T21:06:14Z,"good point , i missed this behavior when i moved from navigablemap to a normal hashmap. let me fix it.",1,0.5178672671318054
653088343,10822,kpatelatwork,2021-06-16T22:07:20Z,fixed,0,0.975196123123169
653089179,10822,kpatelatwork,2021-06-16T22:09:03Z,fixed and changed all test names to be explicit,0,0.988352358341217
653089598,10822,kpatelatwork,2021-06-16T22:09:58Z,"thanks for noticing this, its my bad the ide method extract left the comment and i didn't notice.",-1,0.9706187844276428
653089924,10822,kpatelatwork,2021-06-16T22:10:42Z,fixed,0,0.975196123123169
653115877,10822,rhauch,2021-06-16T23:17:29Z,either work for me.,0,0.962102472782135
653116810,10822,rhauch,2021-06-16T23:20:07Z,"two things. first, these multi-worker its are not necessarily testing the requests getting forwarded to the leader, but that's really hard to do. second, it might be good to try to send the request to a worker that is not running any instances to be restarted. one way to do that is to run 1 more worker than the total number of `connector` and `task` instances for the connector being restarted. though i'm not sure this adds a lot of value given the others unit tests.",0,0.9094409942626953
653117252,10822,rhauch,2021-06-16T23:21:18Z,"yeah, that's already a good portion of the total time to run the connect unit and integration tests. it'd be great if we could avoid increasing the build times by that much.",0,0.5245920419692993
653117875,10822,kpatelatwork,2021-06-16T23:23:03Z,"good idea, i fixed it",1,0.9771928191184998
653118611,10822,kpatelatwork,2021-06-16T23:25:12Z,"good idea , i fixed it. i added a default constant in kafkaconfigbackingstore class, the only thing i was unsure of if i should use the same default constant in connectorsresource class api or not. they seem to be 2 different world and i didn't wanted to introduce a dependency between the classes as it would expose unwanted details so right now default=false is in 2 places. please let me know if you have a better idea to solve this or if it's ok to have it copied the default value in 2 places.",1,0.8047096729278564
653119839,10822,kpatelatwork,2021-06-16T23:28:46Z,"thanks, i went with shouldxxx and it's committed, the code looks much better now.",1,0.9518092274665833
653174069,10822,kpatelatwork,2021-06-17T02:10:54Z,"this was a good find, i just refactored the code, and this saved 2 min ![a link]",1,0.9498915076255798
653681672,10822,rhauch,2021-06-17T15:32:38Z,nit: would a delimiter here help? [code block],0,0.9882885217666626
653687374,10822,rhauch,2021-06-17T15:39:33Z,"this method is where the worker restarts connector and task instances assigned to it. lines 1153 and 1155, along with the `assignedidstorestart` are really the only evidence that this method does that. can we modify the comments and log messages in this method to make that more evident, and maybe add javadoc?",0,0.9858587384223938
653698313,10822,rhauch,2021-06-17T15:52:11Z,"can you confirm that the methods called in this block of logic handle failures? for example, the `worker.stopandawaitconnector(...)` method waits only up to 5 seconds, and we have no visibility into whether the connector was actually stopped in that time or we timed out. if we timed out, should we restart the connector, or should we abort this method and try again later? if we retry again later, it seems like it's okay to try stopping an already stopped connector, but it'd be good to double check that. same questions about stopping the tasks. we may need to modify the `stopandawait...(...)` methods to add a callback that will allow us to better track what was actually stopped. and where this method is called we may need to handle the case where this restart was not completed and re-enqueue it for restart.",0,0.9535748958587646
653701944,10822,rhauch,2021-06-17T15:56:20Z,"one thing about using a map is that we're always saving the last restart request, rather than the restart request that will (potentially) have the greatest impact. consider two restart requests are submitted at about the same time: 1. restartrequest 1 requests that everything is restarted (onlyfailed=false) for connector foo 2. restartrequest 2 requests that only failed instances are restarted (onlyfailed=true) for connector foo if this method saw restartrequest 2 before restartrequest 1, then everything would be restarted as expected. but if this method saw restartrequest 1 first, then only the failed tasks would be restarted. seems like we should keep the most impactful one: restartrequest 1 in this example. wdyt?",0,0.9767479300498962
653705258,10822,rhauch,2021-06-17T16:00:11Z,"excellent! iiuc, the tests are only using 2 differently-sized clusters (1 node and 4 nodes), which is good because it minimizes the startup time. can you confirm that statement is true? it seems like there are three total methods that take more than 30 seconds -- any reduction in duration on any of those three will have a very direct impact.",1,0.9912680387496948
653745712,10822,kpatelatwork,2021-06-17T16:49:20Z,"and i changed the implementation to dequeue from map and perform the restart outside the synchronized block, could you please review to see if it looks ok now?",0,0.9819931983947754
653749526,10822,kpatelatwork,2021-06-17T16:52:53Z,"this is an excellent suggestion, i just added this test based on the above discussion [a link] and now feel more confident that we are testing the distributed behavior of the feature. here is a sample response i copied from the above test output and we can see the call from the test was made on a worker not running the task or connector instance.",1,0.9515859484672546
653753526,10822,kpatelatwork,2021-06-17T16:56:42Z,"i agree and i fixed it as part of recent tests changes, ` private static final string connector_name_prefix = ""conn-""; `",0,0.968532145023346
653815012,10822,kkonstantine,2021-06-17T18:02:00Z,"seeing above, seems that this might as well be called `onrestart`. it's only naming but still would be nice to maintain consistency",0,0.9047350287437439
653819933,10822,kpatelatwork,2021-06-17T18:09:43Z,"i went with a different sleep duration and that cut the times by 1minute 15 sec ![a link] [a link] i chose 5sec because locally the test that sets up the cluster takes around 5 sec to do it and most test after they setup the cluster finishes in <300ms, request propagation and restart isn't taking long but thats my local machine and i chose to do 15 times the wait in case cloud or other developer machines are slow. could you please review to see if you agree with the fix as another idea is to reduce it to 1 sec?",0,0.8719598650932312
653854373,10822,kpatelatwork,2021-06-17T18:57:12Z,"i agree and implemented it, could you please review the below commit and see if it suffices? [a link]",0,0.94502192735672
654043932,10822,kpatelatwork,2021-06-17T23:19:44Z,+1 i just fixed them in both classes,0,0.7362006306648254
654060352,10822,kpatelatwork,2021-06-18T00:10:56Z,"i did confirm that both stop and await for task and connector does connector.cancel() and task.cancel() if it timed out. i added try/catch in start connector/tasks [a link] however, i am not sure about re-enqueue as it can lead to infinite tries, and adding retries may complicate things so need some guidance. could you please review to see if it looks a bit better now?",0,0.8801341652870178
654741212,10822,kpatelatwork,2021-06-19T03:30:22Z,the new times after checking that api response didn't return any restarting state is 13 sec and 10 sec out of it is in bringing up kafka cluster. ![a link],0,0.7505483031272888
654741381,10822,kpatelatwork,2021-06-19T03:32:23Z,added javadoc and cleaned some logs and there are logs in the called methods so didn't added new logs,0,0.9859334826469421
655408049,10822,kpatelatwork,2021-06-21T14:06:30Z,"we can add a retrycount in the restartrequest and start with a default of 5 and decrement it every time we re-enqueue. if the tick() happens every second then we can exhaust the retries pretty fast so we may need to add backoff with a delay before processing the request. adding retry logic to this pr can make the pr complex, i would vote for adding it in a separate pr.",0,0.9747270345687866
655658286,10822,rhauch,2021-06-21T19:45:48Z,"i would agree. we're not sure whether we need this behavior yet, so i'm +1 for keeping it simple in this pr and adding it in the future only if we discover a need for it.",1,0.6573177576065063
655660680,10822,rhauch,2021-06-21T19:49:52Z,let's mention the natural sort order.,0,0.9860541224479675
655678526,10822,rhauch,2021-06-21T20:21:36Z,"the `startconnector(...)` method _should_ handle most of the errors by calling the callback, but there are still a few potential errors that could happen before the worker actually tries starting the connector. do you think this try-catch is needed, though, since the try-catch where this `dorestartconnectorandtasks(...)` is called will catch and log any unexpected change? i guess keeping this will ensure we proceed with starting the tasks, rather than failing quickly.",0,0.9783846139907837
655683692,10822,rhauch,2021-06-21T20:30:35Z,"if we were to change `pendingrestartrequests` to a `concurrentmap`, then we could use the `compute(...)` functionality that actually would work even if we removed the synchronization. i wonder if this is a bit more readable (even though strictly speaking we don't need concurrent access). wdyt? [code block]",0,0.9542316198348999
655688374,10822,rhauch,2021-06-21T20:38:42Z,what do you think about returning `optional ` here (if every worker has at least one instance for the given connector) rather than throwing an exception?,0,0.9840837121009827
655749684,10822,kpatelatwork,2021-06-21T22:40:23Z,"i kinda agree with you but i had seen this code in below two links and it had try/catch around both starttask and startconnector . i added try/catch around starttask so if one tasks fails we can see if others atleasst succeed. the try/catch around startconnector was because i saw the pattern. but i am torn on this, if you think we should remove the try/catch on connector, i am open to removing the try/catch given its already caught at the higher layer, but imho we can keep the starttask try/catch. wdyt? [a link] [a link]",-1,0.5341362953186035
655755572,10822,kpatelatwork,2021-06-21T22:55:44Z,turns out a normal hashmap also has compute so i just used it.,0,0.9887154698371887
655755798,10822,kpatelatwork,2021-06-21T22:56:17Z,"i added some javadoc, could you please review and see if it looks good?",0,0.9315273761749268
655757673,10822,kpatelatwork,2021-06-21T23:01:30Z,i think it's a good idea but i saw that org.apache.kafka.connect.util.clusters.embeddedconnectcluster#endpointforresource method is using the same pattern and if i change it then i will have to change a lot of classes not related to this pr and ultimately in the test i will have to check for optional.present and do an assert. the situation for not finding a worker is rare and doing empty check and assert in all places will be a lot of copy/paste whereas throwing an exception here is centralizing this rare situation. do you think it's ok to leave it as is?,0,0.8509851098060608
655776106,10822,rhauch,2021-06-21T23:42:01Z,"yeah, i think it's actually fine the way it is: with the try-catrch around `startconnector(...)`, because that helps us catch any problem _at that point_ and allows us to continue starting the tasks. if we were to remove this try-catch around `startconnector(...)`, then any problem would cause us to return immediately from the method.",0,0.9178808927536011
655778416,10822,rhauch,2021-06-21T23:48:33Z,"well, the `embeddedconnectcluster` is technically not an official public api for connect, but lots of connector projects use it (as intended), meaning we have to be very clear about backward compatibility. it's probably fine to keep the same pattern.",0,0.9749413728713989
655781412,10822,rhauch,2021-06-21T23:57:06Z,"it might be good to clean up the method name a bit. since it's similar to the existing `endpointforresource(...)`, maybe just add a suffix ... maybe something like `endpointforresourcenotrunningconnector()`?",0,0.9753502607345581
655781662,10822,rhauch,2021-06-21T23:57:46Z,please add descriptions of the other parameters and the return value.,0,0.9859778881072998
655885518,10822,kkonstantine,2021-06-22T05:25:50Z,"i think we can avoid this alignment style. it leaves us with significantly less space to write lambdas, etc. (another indicator is that this style is not applied elsewhere in the file). two tab stops in the line below should be fine, even if the declaration above is where it is now.",0,0.9840052127838135
655887809,10822,kkonstantine,2021-06-22T05:31:37Z,"i don't think we have examples in connect where we refer to an argument in the name of a method. maybe we don't want to change this just yet with the opportunity of the changes introduced by this feature. another observation is that we don't use `get`, `set` and possibly `build`. but since it wouldn't be obvious if it's an action or an object maybe leaving `buildrestartplan` might be fine here. (`restartplan` would be the alternative)",0,0.9772293567657471
655891458,10822,kkonstantine,2021-06-22T05:41:30Z,maybe a good idea to say that this is a plan per connector (and not a global plan). i know the javadoc of the constructor says it already but good to be at the top level too.,1,0.5915784239768982
655892160,10822,kkonstantine,2021-06-22T05:43:08Z,nit: in the constructor we refer to member fields with `this.` during initialization (even if they are not shadowed) [code block],0,0.9890851378440857
655893949,10822,kkonstantine,2021-06-22T05:47:38Z,`shouldrestarttasks` or `shouldrestartanytasks` (same recommendation as above),0,0.9862896800041199
655893977,10822,kkonstantine,2021-06-22T05:47:42Z,since this is not an action but a recommendation i think it'd be better to call `shouldrestartconnector`,0,0.9831830263137817
655894996,10822,kkonstantine,2021-06-22T05:50:00Z,not sure we should say `restart` in the method name. the object is already a `restartplan` type. so that's a bit redundant i think. `connectorstateinfo` ?,0,0.9628608226776123
655896479,10822,kkonstantine,2021-06-22T05:53:29Z,below we have a method name called `restartconnectorandtasks` implying _any_ tasks. so maybe we can skip `any` in the name.,0,0.9892590641975403
655900253,10822,kkonstantine,2021-06-22T06:02:13Z,use of `final` doesn't seem to be consistent in this method. i'd suggest skipping its addition to local variables unless we need it in lambdas.,0,0.9677689671516418
655902961,10822,kkonstantine,2021-06-22T06:07:49Z,any reason not to use primitive types? [code block],0,0.9859448671340942
655904820,10822,kkonstantine,2021-06-22T06:11:50Z,do we have to call it snapshot? is `startsandstops` enough? [code block],0,0.9887583255767822
655905352,10822,kkonstantine,2021-06-22T06:13:02Z,i found the name a bit overloaded and added a suggestion below. you think we could make it a bit simpler?,0,0.9825793504714966
656348082,10822,kpatelatwork,2021-06-22T15:41:56Z,the defaults are used in code like below and using primitive would lead to an extra boxing,0,0.9846020936965942
656356700,10822,kpatelatwork,2021-06-22T15:50:11Z,"excellent suggestion, naming is indeed hard problem and i had the same feeling this is overloaded. i applied your suggestion.",1,0.9579542279243469
656356999,10822,kpatelatwork,2021-06-22T15:50:29Z,fixed,0,0.975196123123169
656357145,10822,kpatelatwork,2021-06-22T15:50:38Z,thanks for catching this,1,0.7543206810951233
656357635,10822,kpatelatwork,2021-06-22T15:51:09Z,thanks for catching this.,1,0.5643005967140198
656358121,10822,kpatelatwork,2021-06-22T15:51:45Z,renamed to buildrestartplan as per your suggestion.,0,0.9846497178077698
656358424,10822,kpatelatwork,2021-06-22T15:52:04Z,"good observation, i fixed it.",1,0.9550890326499939
656633158,10822,kpatelatwork,2021-06-22T22:49:51Z,fixed documentation and renamed the method.,0,0.98665452003479
656633775,10822,kpatelatwork,2021-06-22T22:51:29Z,"good idea, i renamed the method.",1,0.9621803760528564
656652231,10822,kpatelatwork,2021-06-22T23:39:56Z,fixed,0,0.975196123123169
656653569,10822,kpatelatwork,2021-06-22T23:42:54Z,i think we should keep it because in the caller code plan.connectorstateinfo() conveys its the current state but plan.restartconnectorinfo() conveys the intent that its the stateinfo with restart state. i know its not the best name :( cc: if he has any better suggestions for the name.,0,0.5951581597328186
656654293,10822,kpatelatwork,2021-06-22T23:44:45Z,"and i renamed the methods for shouldxxx suggestion. for removing any in the name, i think we should keep it in the name because plan.shouldrestarttasks() in caller code conveys the intent it would restart all tasks but plan.shouldrestartanytask conveys it would restart at least one task. i know its again not the best name. wdyt if we rename it to shouldrestartatleastonetask, it was too verbose that's why we had picked any?",0,0.9203349947929382
657118416,10822,rhauch,2021-06-23T13:46:50Z,"this is subtly different than a normal `connectorstateinfo`, so keeping the current name may be a bit more clear in the context where this method is used, even if it's less conventional.",0,0.9849331974983215
657148983,10822,kpatelatwork,2021-06-23T14:18:16Z,renamed to shouldrestarttasks,0,0.9822061061859131
660274546,10822,kkonstantine,2021-06-29T04:38:50Z,is there any reason we are not adding these new methods in the `taskstatus.listener` interface? in any case we should add javadoc to the base declaration (interface or class methods).,0,0.9868969321250916
660275673,10822,kkonstantine,2021-06-29T04:42:29Z,"nit: the ternary operator can be used (`?:`) as below, unless you're not a fan. [code block]",0,0.9855592250823975
660276986,10822,kkonstantine,2021-06-29T04:46:34Z,"a bit confusing that a second assignment follows if the `if` statement is true. i'd also call the variable `taskstate` (as opposed to `connectorstate` above) ternary can be used here as well: [code block] (as with any suggestion from github, please check it compiles and conforms to the style)",0,0.5443097949028015
660280566,10822,kkonstantine,2021-06-29T04:57:05Z,no problem.,0,0.9470120072364807
660281788,10822,kkonstantine,2021-06-29T05:00:50Z,something like? [code block] breaking this long statement doesn't make it much less long i guess.,0,0.8804961442947388
660283562,10822,kkonstantine,2021-06-29T05:06:17Z,"[code block] ? (seems a bit more common way to say it, but i don't have a strong opinion)",0,0.5645061731338501
660290194,10822,kkonstantine,2021-06-29T05:25:47Z,"i see we've been verbose in similar logic above before, but maybe we can improve on that a bit, at least in new code. here's another suggestion: [code block]",0,0.9763091206550598
660291164,10822,kkonstantine,2021-06-29T05:28:23Z,"following up on the comment above, here's how we could write this and avoid autoboxing/unboxing while using the more readable primitives. [code block]",0,0.9881094098091125
660291287,10822,kkonstantine,2021-06-29T05:28:45Z,similar suggestion as above,0,0.982819139957428
660291760,10822,kkonstantine,2021-06-29T05:29:56Z,i agree the conversion is on a frequently used path. but maybe it's the code below that can be re-written to avoid both autoboxing and unboxing (when it's not required),0,0.9832563400268555
660293584,10822,kkonstantine,2021-06-29T05:34:43Z,"this misuse might have originated because above, specifically for tasks, `null` is actually a valid value (tombstone/delete), which is not the case here.",0,0.8429714441299438
660295568,10822,kkonstantine,2021-06-29T05:40:09Z,since we print the warning inside `recordtorestartrequest` we can probably avoid the early return with: [code block],0,0.9884361028671265
660296712,10822,kkonstantine,2021-06-29T05:43:05Z,"btw, all other log statements are `log.error` elsewhere. should we remain consistent with that, instead of using `log.warn` just here? the issues seem similar above.",0,0.9842306971549988
660301592,10822,kkonstantine,2021-06-29T05:55:31Z,dependents in the implementation of `startandstoplatch` seems to overload the meaning of `null` with a check. but it actually doesn't seem to matter. the call is equivalent to passing an empty list. should we simplify that with something like: [code block] ?,0,0.9712850451469421
660301819,10822,kkonstantine,2021-06-29T05:56:03Z,see comment above on whether `null` matters.,0,0.9764904975891113
660303274,10822,kkonstantine,2021-06-29T05:59:36Z,"does it make sense to skip, given that it's called below? (i hope i'm not missing something)",0,0.9452457427978516
660309326,10822,kkonstantine,2021-06-29T06:13:53Z,nit: similar style as elsewhere in this file [code block],0,0.9875541925430298
660311654,10822,kkonstantine,2021-06-29T06:18:53Z,nit: type inference is nice ... [code block],1,0.9610987305641174
660315005,10822,kkonstantine,2021-06-29T06:25:58Z,i'd call it `plan` here.,0,0.9863800406455994
660315335,10822,kkonstantine,2021-06-29T06:26:38Z,safe to skip the declaration here. [code block],0,0.9854906797409058
660315588,10822,kkonstantine,2021-06-29T06:26:59Z,nit: extra [code block],0,0.9885453581809998
660320316,10822,kkonstantine,2021-06-29T06:36:25Z,same as the connector call above [code block],0,0.9875960350036621
660781818,10822,kpatelatwork,2021-06-29T16:29:13Z,fixed,0,0.975196123123169
660782579,10822,kpatelatwork,2021-06-29T16:30:10Z,i agree and i fixed it like you suggested.,0,0.9166596531867981
660834568,10822,kpatelatwork,2021-06-29T17:42:17Z,"the plan may or may not be present, that's why i was calling it maybeplan",0,0.9845027327537537
660836387,10822,kpatelatwork,2021-06-29T17:45:00Z,"we are logging an error if we are rejecting the request due to an invalid type, but in this particular case as we are defaulting the missing fields, that's why the warn.",0,0.9760273098945618
660864346,10822,kpatelatwork,2021-06-29T18:26:17Z,"i added the missing documentation. i didn't add the onrestart method to listener because it didn't felt it should be a part of the task lifecycle controlled by the worker. earlier the method was called recordrestart but based on a review comment, it was renamed it to onrestart, do you think we should rename it back to recordrestart. the original intent of this method was to just record the state change.",0,0.9808725118637085
660866556,10822,kpatelatwork,2021-06-29T18:29:36Z,fixed as per your suggestions.,0,0.9814205765724182
660867874,10822,kkonstantine,2021-06-29T18:31:31Z,did you compare it with other methods? my understanding is that `ondelete` is the same in that respect and exists on the `listener` as well. but i might have skimmed too quickly through the code,0,0.9774507880210876
660868474,10822,kkonstantine,2021-06-29T18:32:28Z,didn't notice. thanks. makes sense then,1,0.806875467300415
660870565,10822,kkonstantine,2021-06-29T18:35:40Z,"we might be too precise here. as we discussed elsewhere, baking the meaning of the type in every variable name might be too verbose. it's a plan, and the fact that is optional means that there might be one or it might not. that's how i'd read it. the other use of `maybeplan` below is harder to avoid. feel free to keep it consistent here with what you have below. again, my point is not to bake type meaning in the variable names. i feel this keeps things simpler.",0,0.6447369456291199
660925249,10822,kpatelatwork,2021-06-29T20:02:52Z,after your latest explanation it makes sense to rename it to keep it simple. thanks for guiding me. i have renamed it.,1,0.9565483927726746
660953271,10822,kpatelatwork,2021-06-29T20:48:53Z,you are right. do you mind if we do this work in a follow-up pr? the reason i ask is because if we add it to the listener then it becomes part of the interface and this would require me to retrofit the listener event into the old restarttask and restartconnector api for backward compatibility reasons and it can be big change to this already big pr.,0,0.7100698351860046
661028655,10822,kpatelatwork,2021-06-29T23:28:38Z,i moved it to the lisetner interface in [a link] could you please check to see if it looks good.,0,0.964918315410614
1579221285,15640,cadonna,2024-04-25T10:08:01Z,"why do you use a timer here? the `asynccommit()` does not throw any timeout exception, does it? if you need to pass the timer to the `commitevent` or further up the class hierarchy then you can create the timer in the constructor of `asynccommitevent` or even further up the class hierarchy.",0,0.9880117177963257
1579239807,15640,cadonna,2024-04-25T10:24:10Z,"why should those two fields ever be `null`? they seem necessary for the consumer to function correctly. if my statement is correct, the constructors should ensure that those fields are never `null`.",0,0.9812783598899841
1579264527,15640,cadonna,2024-04-25T10:45:03Z,"i have two questions here: 1. why is this code not in `completableevent`? 2. why do you not keep the timer in a object field? regarding 2, i have the feeling this pr contains code that already exist in the timer. you could have a method on `completableevent` that checks for the expiration without exposing the timer. something like `isexpired()` or `istimedout`.",0,0.9217545390129089
1579269984,15640,cadonna,2024-04-25T10:49:30Z,could you export this lines into a method `processapplicationevents()` or similar. i think it makes the code more readable.,0,0.9852555990219116
1579275627,15640,cadonna,2024-04-25T10:54:36Z,do we need this comment? i am not a big fan of inline comments in general. all the information about the behavior in the comment should be clear from the corresponding unit tests. i do not think we need the references to the legacy consumer. once the legacy consumer is gone we need to remove these references which is work that we can avoid by just not writing those comments.,-1,0.8048731088638306
1579283124,15640,cadonna,2024-04-25T11:00:50Z,i think that is clear from the code. we do not need the comment.,0,0.9795656204223633
1579292380,15640,cadonna,2024-04-25T11:09:42Z,"here i have a similar comment as with `asynccommitevent`, i would move the creation of the timer into the constructor of `consumerrebalancelistenercallbackneededevent`.",0,0.9884434342384338
1579314894,15640,cadonna,2024-04-25T11:30:24Z,same questions as above.,0,0.9764343500137329
1579322300,15640,cadonna,2024-04-25T11:36:39Z,"nit: imo, this is more readable, but feel free to leave it if you do not share my taste. [code block]",1,0.7235233187675476
1579324613,15640,cadonna,2024-04-25T11:38:47Z,wouldn't it be safer to not have a default here as a reminder for closing.,0,0.9000821113586426
1579733831,15640,kirktrue,2024-04-25T15:45:14Z,"yeah, i went back and forth on this a few times :winking_face: ultimately i wanted to force the caller to be explicit about its timeout intention, vs. having it implicitly ""hidden"" away in the event hierarchy. also, to create a `timer` in the event constructor, we'd have to pass in a `time` object (`time.timer(long.max_value)`), which seemed a bit obtuse, so :man_shrugging:",-1,0.8708217144012451
1579735209,15640,kirktrue,2024-04-25T15:46:22Z,"they're only `null` if there was an error in the constructor. the constructor's `finally` block calls `close()`, so we need to handle the case where the consumer wasn't fully constructed before it's closed.",0,0.9862388968467712
1579756071,15640,kirktrue,2024-04-25T16:01:51Z,"i'm happy to reword the comment and clean it up, but the lines that follow that comment are the raison d'être of this change. it's very subtle and easy to miss, hence the call-out.",1,0.9584783315658569
1579760563,15640,kirktrue,2024-04-25T16:05:28Z,i'll look into how to do this in a way that i don't find too ugly :winking_face:,-1,0.5779529809951782
1579864626,15640,kirktrue,2024-04-25T17:22:11Z,"`completableevent` is an interface, but i could see if i can put a static method in there to keep the logic in one place.",0,0.9880870580673218
1579865601,15640,kirktrue,2024-04-25T17:23:08Z,"yeah, i can see your point. tbh, i'm not sure if that's even needed still :thinking_face:",0,0.6214905381202698
1579884608,15640,kirktrue,2024-04-25T17:40:17Z,added a brief comment. ptal.,0,0.9874655604362488
1579884758,15640,kirktrue,2024-04-25T17:40:25Z,done.,0,0.9759407639503479
1579885684,15640,kirktrue,2024-04-25T17:41:16Z,split into a separate method to accommodate the reworded comment.,0,0.983366072177887
1579885847,15640,kirktrue,2024-04-25T17:41:24Z,removed.,0,0.9311882257461548
1579897029,15640,kirktrue,2024-04-25T17:51:50Z,"for point 1, i created a new method named `calculatedeadlinems` that moves this code into one place. for point 2, there is no `timer` in the event because `timer` is not thread safe, and events cross the application/background thread boundary. i did not want to expose the `timer` in the event to avoid its possible usage from the background thread.",0,0.9692707657814026
1579899408,15640,kirktrue,2024-04-25T17:54:02Z,"it turns out `close()` wasn't needed any more, so i just removed it :man_shrugging:",-1,0.8375684022903442
1579914824,15640,kirktrue,2024-04-25T18:04:46Z,i was able to refactor the code to eliminate the need for passing in a `timer`.,0,0.9878010749816895
1579915561,15640,kirktrue,2024-04-25T18:05:12Z,i was able to refactor the code and this is now sans `timer` again.,0,0.9887068271636963
1580785461,15640,cadonna,2024-04-26T09:53:28Z,nit: could you please move this parameter to the previous line?,0,0.9876902103424072
1580790248,15640,cadonna,2024-04-26T09:57:24Z,i think you do actually not need the timer in this method at all. you could pass a deadline to the event.,0,0.9871506690979004
1580879040,15640,cadonna,2024-04-26T11:13:20Z,the timer is not used anywhere else. maybe a deadline for this event would be simpler.,0,0.984271228313446
1580883395,15640,cadonna,2024-04-26T11:18:18Z,also here the timer is only used in the event. using a deadline would be simpler.,0,0.9870033860206604
1580884538,15640,cadonna,2024-04-26T11:19:34Z,the timer is only used by the event. maybe a deadline is simpler.,0,0.9830817580223083
1580885372,15640,cadonna,2024-04-26T11:20:30Z,the timer is only used in the event.,0,0.980861485004425
1583451774,15640,kirktrue,2024-04-29T17:28:47Z,"per the above, i added `completableevent.calculatedeadlinems()` to keep the code in a shared location.",0,0.9882612824440002
1583452334,15640,kirktrue,2024-04-29T17:29:14Z,"yep, i made the change to use the deadline directly (vs. a `timer`).",0,0.9884375929832458
1583452722,15640,kirktrue,2024-04-29T17:29:36Z,agreed. using the deadline directly instead of a `timer`.,0,0.9822798371315002
1583452937,15640,kirktrue,2024-04-29T17:29:46Z,changed.,0,0.9753402471542358
1583520696,15640,kirktrue,2024-04-29T18:20:21Z,removed use of `timer` in favor of calculating the deadline from the `time` and `timeout` directly.,0,0.9792927503585815
1583520759,15640,kirktrue,2024-04-29T18:20:26Z,removed use of `timer` in favor of calculating the deadline from the `time` and `timeout` directly.,0,0.9792927503585815
1585003046,15640,lianetm,2024-04-30T15:10:56Z,"couldn't we make that the same add operation removes the event whencomplete? seems tighter that the same operation that adds the event ensures that it's removed (if completes), and then it's simpler here, when we only need to care about maintaining the uncompleted (which seems like the core responsibility of the reaper). also that would mean that we don't rely on calls to reap to remove events that complete in time.",0,0.9392881989479065
1585004533,15640,lianetm,2024-04-30T15:11:39Z,"responsible for events that ""are being processed"" right?",0,0.9641993045806885
1585005659,15640,lianetm,2024-04-30T15:12:14Z,"typo ""we are""",0,0.9812828302383423
1585035057,15640,lianetm,2024-04-30T15:28:16Z,"what about renaming this to be explicit about what we process here? it gets confusing given that at this consumer level we're dealing with app events and background events. `processbackgroundevents` feels pretty clear, and i know there is already another one called liked that, but the other one is more about `awaitfutureprocessingbackgroundevents` , because it actually blocks for a time, only used from the unsubscribe, so maybe rename here and there?",-1,0.7261041402816772
1585083395,15640,lianetm,2024-04-30T15:44:39Z,"regarding the func doc, typo and clarification: the app thread enqueues the event in an **application event queue** (that the background thread consumes), right? in the doc we ended up mentioning the background and app thread both adding to the background event queue.",0,0.9883304834365845
1585091606,15640,lianetm,2024-04-30T15:49:20Z,"also, regarding: it does not need to if the consumer unsubscribing does not own any partition, so just for accuracy in the example i would suggest to extend it with ""...needs to be invoked for the partitions the consumer owns""",0,0.9808205366134644
1585152310,15640,lianetm,2024-04-30T16:17:07Z,"not introduced by this pr, but reviewing this processing i don't quite see the value in all [a link] , that are even repeated further down, just for a log, when in practice this are both the happy path that will have [a link] log from the unsubscribe. a one liner with `return consumerutils.getresult(future);` would achieve the same and make the func much simpler. (even if we end up using this from a func other than the unsubscribe, seems an overkill to have all this code for something we don't need now, or know if we we'll need some day)",-1,0.7852289080619812
1585179214,15640,philipnee,2024-04-30T16:35:22Z,any specific reason for using linkedlist implementation?,0,0.9849919676780701
1585390985,15640,lianetm,2024-04-30T19:17:17Z,"this logic is always needed whenever we `reapincomplete`, and is currently repeated when we call it from the asyncconsumer or here, so what about we move it into the `reapincomplete`, make it receive a list of all events and internally filter the ones that are `completableevent`?",0,0.9882447719573975
1585435927,15640,lianetm,2024-04-30T19:34:00Z,is there a reason for loosing the final on the offsets map?,0,0.9813403487205505
1585466853,15640,lianetm,2024-04-30T20:05:10Z,"the reaper actually calls `completeexceptionally` with a `cancellationexception` instead of calling `completablefuture#cancel(boolean)`. unless i'm missing a subtle semantic diff they should achieve the same, but still, adding a link to `cancel` here would not be accurate i would say.",0,0.8848460912704468
1585531596,15640,philipnee,2024-04-30T21:13:12Z,can we remove this? i think the test works without it.,0,0.987320065498352
1585537917,15640,philipnee,2024-04-30T21:20:55Z,the test should work without setting the current time to 0. so i think new mocktime(0) should be fine.,0,0.9659865498542786
1585558712,15640,philipnee,2024-04-30T21:46:34Z,ditto: we probably don't need the final but it would be good to be consistent.,1,0.5203136205673218
1586499310,15640,kirktrue,2024-05-01T16:46:20Z,"my first attempt at this resulted in a `concurrentmodificationexception`, since we're removing each entry from the very same list we're iterating over :thinking_face:",0,0.9523035883903503
1586524076,15640,kirktrue,2024-05-01T17:11:43Z,"unfortunately, the term ""processed"" is sufficiently ambiguous :disappointed_face: so we're _both_ right :winking_face: here, i'm referring to events that had been passed to the `eventprocessor`'s [a link] method. which, sadly, isn't even correct, because they're being `add()`-ed to the reaper _before_ they're passed to `eventprocessor.process()` :man_facepalming:",-1,0.9776933789253235
1586537358,15640,kirktrue,2024-05-01T17:24:31Z,i reworked the comments/documentation to avoid that altogether. ptal. thanks.,1,0.9696275591850281
1586539952,15640,kirktrue,2024-05-01T17:27:19Z,fixed.,0,0.9810503125190735
1586542049,15640,kirktrue,2024-05-01T17:29:36Z,i renamed `process()` as `processbackgroundevents()`. is that ok?,0,0.988602340221405
1586557142,15640,kirktrue,2024-05-01T17:43:16Z,"i made the documentation changes you requested and removed the logging to make the logic simpler. when you state that it seems like ""overkill to have all this code for something we don't need now, or know if we we'll need some day,"" i'm a bit confused :thinking_face: because unsubscribing may require invoking `consumerrebalancelistener` callbacks, we need a way to check and run those events that are coming from the background thread, right? i do agree that it's overkill to have this broken out as a separate method since it's only used for the `unsubscribe()` case. iirc, there was some talk of another use case for this, and it does make unit testing it easier.",-1,0.7502022981643677
1586559943,15640,kirktrue,2024-05-01T17:46:08Z,":grinning_squinting_face: yes, i went back and forth on this at least three times during development. i'll look at switching back to the approach you suggest.",0,0.9696584939956665
1586603709,15640,kirktrue,2024-05-01T18:20:32Z,pulled the logic to `reapincomplete()` as suggested.,0,0.9857951402664185
1586607598,15640,kirktrue,2024-05-01T18:23:21Z,added back `final` and changed back to `protected`. not sure how/why i changed those :thinking_face:,0,0.7582188844680786
1586620323,15640,kirktrue,2024-05-01T18:32:47Z,"good catch! i had been using `cancel()`, but noticed that the message in the exception the caller of `future.get()` later received was unhelpful. yes, `cancel()` calls `completeexceptionally(new cancellationexception())`, but i wanted the exception to include a (hopefully) meaningful message. anyhoo... i've updated the documentation to reflect that change.",1,0.9870283603668213
1586622390,15640,kirktrue,2024-05-01T18:34:25Z,"yes, because it has the `drainto()` method. however, this code is now gone, so it's moot :man_shrugging:",-1,0.8656211495399475
1586626516,15640,kirktrue,2024-05-01T18:37:25Z,done.,0,0.9759407639503479
1586626597,15640,kirktrue,2024-05-01T18:37:29Z,done.,0,0.9759407639503479
1586632167,15640,kirktrue,2024-05-01T18:40:25Z,"moved the `listoffsetsevent` up to the previous line. missed it on first read, sorry :thumbs_up:",-1,0.9892038702964783
1587519244,15640,cadonna,2024-05-02T11:59:47Z,"do you propose to remove completed events in `completableeventreaper#add`? if yes, to avoid the `concurrentmodifictionexception` , you could iterate over `tracked` with an iterator and remove completed events through the iterator: [code block]",0,0.9890103936195374
1587734052,15640,cadonna,2024-05-02T14:26:17Z,is this enough error handling?,0,0.9672525525093079
1587741997,15640,cadonna,2024-05-02T14:31:18Z,is this really unclear from the name `deadlinems`?,0,0.9521515965461731
1587841410,15640,cadonna,2024-05-02T15:30:00Z,"on a second thought, what is the issue with moving [code block] to `add()`? i guess, i am misunderstanding your comments.",-1,0.8960610628128052
1588986665,15640,cadonna,2024-05-03T09:49:48Z,you actually do not need a timer here. the event takes the deadline and also the reaper does not use the timer.,0,0.9821880459785461
1589007012,15640,cadonna,2024-05-03T10:07:31Z,"also here, i do not think you need this timer.",0,0.980975866317749
1589007924,15640,cadonna,2024-05-03T10:08:31Z,same here.,0,0.9813250303268433
1589011280,15640,cadonna,2024-05-03T10:12:05Z,not needed.,0,0.9606450200080872
1589011422,15640,cadonna,2024-05-03T10:12:15Z,not needed.,0,0.9606450200080872
1589016749,15640,cadonna,2024-05-03T10:17:44Z,couldn't you use a simple `collection` with a simple `arraylist` here?,0,0.9873288869857788
1589016846,15640,cadonna,2024-05-03T10:17:50Z,couldn't you use a simple `collection` with a simple `arraylist` here?,0,0.9873288869857788
1589061761,15640,cadonna,2024-05-03T11:05:52Z,tests for the new behavior added to `consumernetworkthread` are missing.,0,0.9608489274978638
1589073577,15640,cadonna,2024-05-03T11:19:32Z,do you not need to add some tests to verify the newly added reaper?,0,0.9862814545631409
1599232056,15640,kirktrue,2024-05-14T00:16:37Z,"there's some debate over that, for sure. however, this is the same error processing we've used before this change, so hopefully we can continue that debate separately?",0,0.9590927362442017
1599232355,15640,kirktrue,2024-05-14T00:17:17Z,"we've had some confusion in the past between timeouts and expiration, but i can remove it if you firmly want it removed.",0,0.9650049805641174
1599233659,15640,kirktrue,2024-05-14T00:19:47Z,the use of the `timer` is only for the test method itself. i'd argue the use of the `timer` makes the code a little more obvious than a plain `long` variable as the code switches between expiration timestamps and timeouts.,0,0.9796552658081055
1599235694,15640,kirktrue,2024-05-14T00:24:21Z,"yes. previous versions of `reapexpiredandcompleted()` required a `blockingqueue`. when the logic was changed to use a more general `collection`, i failed to update the test code. i will make the change as suggested.",0,0.9757223725318909
1599236609,15640,kirktrue,2024-05-14T00:25:57Z,done.,0,0.9759407639503479
1599236661,15640,kirktrue,2024-05-14T00:26:04Z,done.,0,0.9759407639503479
1599243250,15640,kirktrue,2024-05-14T00:40:27Z,i went ahead and made the change you suggested :thumbs_up:,0,0.9301953911781311
1599243369,15640,kirktrue,2024-05-14T00:40:36Z,removed.,0,0.9311882257461548
1599243426,15640,kirktrue,2024-05-14T00:40:42Z,also removed.,0,0.9810413718223572
1599243498,15640,kirktrue,2024-05-14T00:40:50Z,"removed here, too.",0,0.9822263717651367
1599243592,15640,kirktrue,2024-05-14T00:41:04Z,and from here as well :winking_face:,0,0.9322257041931152
1599244057,15640,kirktrue,2024-05-14T00:42:02Z,"i will add tests for the `consumernetworkthread`, but it will probably take some contortion :thinking_face:",0,0.85152268409729
1599244816,15640,kirktrue,2024-05-14T00:43:28Z,i will try my best to add tests to `asynckafkaconsumertest`. i'm hoping it's not quite as bad as i'm imagining it will be :frowning_face_with_open_mouth:,-1,0.9111441373825073
1599266953,15640,kirktrue,2024-05-14T01:27:07Z,"keep in mind that `add()` is called _for each event_ in the queue. if we remove completed events in `add()`, we're updating `tracked` each time, too. in the current approach, `tracked` is only updated once inside `reapexpiredandcompleted()`. i think i'm missing the benefit of moving it to `add()` :thinking_face:",0,0.9188653230667114
1599698758,15640,cadonna,2024-05-14T09:31:32Z,"usually if it takes some contortion to write unit tests, then there is usually a code smell somewhere. :thinking_face: unit tests do not only test code in execution, but often also help to design components that have loose coupling and high cohesion.",0,0.9589752554893494
1599699017,15640,cadonna,2024-05-14T09:31:43Z,see my comment above. i am sure you will find a good solution!,1,0.9781403541564941
1600781636,15640,kirktrue,2024-05-14T23:38:33Z,"oh, the code definitely has smells! :winking_face: i added a test to `consumernetworkthread`.",1,0.9535390138626099
1600781735,15640,kirktrue,2024-05-14T23:38:45Z,i added a test to `asynckafkaconsumertest`.,0,0.9891693592071533
1601414540,15640,cadonna,2024-05-15T10:56:53Z,why is this not a mock? you do not need to test the actual reaper here. you just need to verify that the reaper is called correctly in the correct situations. please do not use a spy. :folded_hands:,0,0.6221494674682617
1601422068,15640,cadonna,2024-05-15T11:02:46Z,"the reaper is not only called in `close()`. it is also called in `unsubscribe()` and `poll()`. i do not know how important it is that the reaper is called in `unsubscribe()` or if it is a collateral that we do not need to test. you know best. however, verifying the calls to the reaper in `poll()` seems important to me, doesn't it?",0,0.940242350101471
1601428828,15640,cadonna,2024-05-15T11:07:52Z,"if you used a mock for the reaper, something like this would be enough to verify the correct use of the reaper in `close()`. [code block]",0,0.988664448261261
1601430406,15640,cadonna,2024-05-15T11:09:01Z,"also here, why not a mock?",0,0.9344066977500916
1601431832,15640,cadonna,2024-05-15T11:10:14Z,with a mock also this test should get simpler.,0,0.9791207313537598
1601434014,15640,cadonna,2024-05-15T11:12:16Z,"i would write two distinct tests for `runonce()` and `cleanup()`. by using a mock, it should get simpler to separate the tests.",0,0.9873237609863281
1602381867,15640,kirktrue,2024-05-15T23:56:21Z,done,0,0.9764507412910461
1602381940,15640,kirktrue,2024-05-15T23:56:30Z,agreed. ptal.,0,0.9762913584709167
1602382027,15640,kirktrue,2024-05-15T23:56:39Z,"yes, ptal.",0,0.9800397157669067
1603682545,15640,lianetm,2024-05-16T16:22:52Z,the benefit i see is self-cleaning which reduces the scope/responsibilities of `tracked`. we don't really care about events that are created and complete successfully (so nice that they are just temporarily tracked and automatically disappear when they complete). then `reapexpiredandcompleted` it's simply about `reapexpired`,0,0.8766570687294006
1603740393,15640,lianetm,2024-05-16T17:05:16Z,just a suggestion but i would leave it to you as they may be impl details i'm missing ;),1,0.7616662383079529
1603994190,15640,kirktrue,2024-05-16T20:30:44Z,changed to mock.,0,0.8689741492271423
1603994499,15640,kirktrue,2024-05-16T20:31:07Z,"added tests for reaper invocation for `close()`, `poll()`, and `unsubscribe()`.",0,0.989081859588623
1603994732,15640,kirktrue,2024-05-16T20:31:20Z,done.,0,0.9759407639503479
1604239000,15640,kirktrue,2024-05-17T01:39:30Z,"& —please let me know if the following makes sense. i am trying to convince myself of this design as much as anyone else :grinning_face_with_smiling_eyes:... ------- the `consumernetworkthread.run()` method sits in a tight loop that calls `runonce()` on each pass. the ordering of operations inside `runonce()` is as follows: 1. call `processapplicationevents()`, for each event... a. call `completableeventreaper.add()` to add the event to `tracked` list b. call `applicationeventprocessor.process()` to call relevant request manager apis based on the event. many of the calls to the request manager apis will create and return `completablefuture`s 2. call `requestmanager.poll()` for each request manager 3. call `networkclientdelegate.add()` for each `unsentrequest` returned from step 2 4. call `networkclientdelegate.poll()` to process all the requests added in step 3. this will invoke handlers for received network responses, which will call `complete()`/`completeexceptionally()` to be called on any `completablefuture`s created in step 1b 5. call `reapexpiredapplicationevents()` (which calls `completableeventreaper.reap()`) to remove expired events and any `completablefuture`s completed in step 4 the design of `consumernetworkthread` is such that an event's `future` will _only_ `complete()` (success or failure) in step 4. any events eligible to be removed from `tracked` in step 1 would have already been removed in the previous loop's step 5. so it makes the most sense to me to leave the removal in `reap()` vs. `add()`.",0,0.8078803420066833
1608020071,15640,cadonna,2024-05-21T10:02:24Z,why did you remove this test without replacement?,0,0.9507737159729004
1608024280,15640,cadonna,2024-05-21T10:05:39Z,you control the time here. why do you not verify that `reap()` is called with the correct time?,0,0.9804926514625549
1608024737,15640,cadonna,2024-05-21T10:06:00Z,you control the time here. why do you not verify that `reap()` is called with the correct time?,0,0.9804926514625549
1608418633,15640,lianetm,2024-05-21T14:17:52Z,"do we expect the close to throw? if so, we should verify that (at the moment our test will just complete successfully if the close does not throw). if that's the expectation, maybe this simpler snippet would cover it all: [code block]",0,0.9808123111724854
1608453186,15640,lianetm,2024-05-21T14:38:42Z,"this is not a ""maybe"" anymore, so what about `autocommitsyncallconsumed`?",0,0.9763802289962769
1608487528,15640,lianetm,2024-05-21T14:59:16Z,don't we want >= here when identifying expired events? i would expect so (that's the semantic applied in the `timer` class [a link] for instance),0,0.9873283505439758
1608516652,15640,lianetm,2024-05-21T15:18:31Z,"this `processor` passed as argument is in the end always a reference to the `backgroundeventprocessor`, so could we simplify this, remove the arg and directly reference the var? it caught my attention when seeing how this is used, which seems a bit redundant with all calls having to provide the same `processbackgroundevents(backgroundeventprocessor, ...` which feels like an internal that the `processbackgroundevents` could know about.",0,0.9495925903320312
1608534184,15640,kirktrue,2024-05-21T15:30:00Z,good call. done!,1,0.9832528829574585
1608534408,15640,kirktrue,2024-05-21T15:30:11Z,"and done here, too.",0,0.9754508137702942
1608539565,15640,kirktrue,2024-05-21T15:33:44Z,resolving this as there has been further discussion for some time.,0,0.9759422540664673
1608540876,15640,kirktrue,2024-05-21T15:34:43Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9810858964920044
1608541319,15640,kirktrue,2024-05-21T15:35:03Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9810858964920044
1608541494,15640,kirktrue,2024-05-21T15:35:12Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9810858964920044
1608541856,15640,kirktrue,2024-05-21T15:35:25Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9810858964920044
1608542017,15640,kirktrue,2024-05-21T15:35:32Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9810858964920044
1608542270,15640,kirktrue,2024-05-21T15:35:43Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9810858964920044
1608542683,15640,kirktrue,2024-05-21T15:36:00Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9810858964920044
1608584519,15640,kirktrue,2024-05-21T16:00:40Z,reinstated.,0,0.969282865524292
1608595900,15640,kirktrue,2024-05-21T16:06:50Z,"this is an interesting point :thinking_face: if a user provides a timeout of 1000 milliseconds, is it expired at 1000 milliseconds or at 1001 milliseconds? regardless, i will change it to `>=` to be consistent.",0,0.9267758727073669
1608607062,15640,kirktrue,2024-05-21T16:15:26Z,there is a unit test that passes in a mocked event processor. let me look at refactoring this.,0,0.987171471118927
1608607604,15640,kirktrue,2024-05-21T16:15:53Z,changed to just `autocommitsync()`. is that ok?,0,0.9879702925682068
1608614638,15640,lianetm,2024-05-21T16:21:36Z,"yes, the flow makes sense to me. also fine with me to keep the reap handling completed and expired.",0,0.9778277277946472
1608730407,15640,kirktrue,2024-05-21T18:01:36Z,done.,0,0.9759407639503479
1608732398,15640,kirktrue,2024-05-21T18:03:30Z,done. that's much better :grinning_face_with_smiling_eyes:,1,0.9171184301376343
1608870767,15640,lianetm,2024-05-21T19:43:33Z,"how did we resolve this? i see the section got completely removed, verification not needed?",0,0.981096088886261
1608875582,15640,kirktrue,2024-05-21T19:48:33Z,"yes, it turns out that changes made elsewhere have obviated the need for this check.",0,0.97393798828125
1608897877,15640,lianetm,2024-05-21T20:10:37Z,"actually seems to me that we shouldn't have this test here (and maybe this is why removed it before?). as i see it, this unit test is testing something that is not the `consumernetworkthread`'s responsibility (and that's why it ends up being complicated, having to mimic the reaper behaviour and spying). it is testing that events are completed, and that's the reaper.reap responsibility, so seems to me we need to: 1. test that the `consumernetworkthread` calls the reaper with the full list of events -> done already in the [a link] 2. test that the `completableeventreaper.reap(collection events)` completes the events -> done in completableeventreapertest ([a link] and [a link] in the end, as it is, we end up asserting a behaviour we're mocking ourselves in the `doanswer`, so not much value i would say? agree with that we need coverage, but i would say that we have it, on my points 1 and 2, and this should be removed. makes sense?",0,0.7225605249404907
1608934073,15640,kirktrue,2024-05-21T20:48:04Z,"yes, the test was a little suspect in terms of its value-add, so i'd removed it. i was planning to file a jira to move several of the tests (including this one) from `consumernetworkthreadtest` to `applicationeventprocessortest`. then we could fix up some of the funkiness in this test as a separate task.",0,0.8751890063285828
1609312616,15640,cadonna,2024-05-22T06:09:52Z,"that is all fine! i was not arguing that we need to keep the test, but if i see a test removed without replacement, i suspect a mistake. which did apparently not happen in this case. next time comment on the pr why you removed the test.",1,0.5990921854972839
1609353060,15640,cadonna,2024-05-22T06:28:44Z,"do you still have the change locally, because here it does still not verify the correct time?",0,0.9735037684440613
