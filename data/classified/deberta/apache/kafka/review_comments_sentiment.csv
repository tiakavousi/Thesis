id,pr_number,user,created_at,body,deberta_sentiment_label,deberta_confidence
113856314,2929,onurkaraman,2017-04-28T05:53:31Z,can we contain the `javaconverters._` import to be within the specific method needing the conversion as is being done elsewhere in kafkacontroller? importing at the file-level can lead to a lot of surprises when reading the code.,0,0.9811257123947144
113856373,2929,onurkaraman,2017-04-28T05:54:07Z,remove. this import already exists.,0,0.9927809834480286
113856447,2929,onurkaraman,2017-04-28T05:55:07Z,"every other data structure in the controller uses the old topicandpartition. for consistency, can we use topicandpartition instead of topicpartition?",0,0.9946098327636719
113856721,2929,onurkaraman,2017-04-28T05:57:39Z,can just be: [code block],0,0.9912721514701843
113856779,2929,onurkaraman,2017-04-28T05:58:18Z,can just be: [code block],0,0.9912721514701843
113857148,2929,onurkaraman,2017-04-28T06:02:27Z,can we make this naming consistent with topicdeletionstopreplicaresult? we can either change the other class name or maybe change your new class to something like leaderandisrresult or leaderandisrresponseresult?,0,0.994498074054718
113973577,2929,lindong28,2017-04-28T16:51:48Z,i think it may be better to rename `topicdeletionstopreplicaresult` to `topicdeletionstopreplicaresponsereceived`. but i don't have a strong opinion on this. i can also rename `leaderandisrresponsereceived` to `leaderandisrresponseresult`. do you have a strong preference between the two?,0,0.9756900072097778
113973608,2929,lindong28,2017-04-28T16:51:59Z,sure. fixed now.,0,0.9459871053695679
113973627,2929,lindong28,2017-04-28T16:52:07Z,sure. fixed now.,0,0.9459871053695679
113975537,2929,lindong28,2017-04-28T17:02:05Z,i was thinking that we may want to use the java version for new code so that we can gradually migrate to the java version. i have change the code to use topicandpartition.,0,0.9888715147972107
113975948,2929,lindong28,2017-04-28T17:04:27Z,fixed now.,0,0.9943431615829468
113975960,2929,lindong28,2017-04-28T17:04:32Z,fixed now.,0,0.9943431615829468
113984161,2929,onurkaraman,2017-04-28T17:47:26Z,i'd prefer renaming `topicdeletionstopreplicaresult` to `topicdeletionstopreplicaresponsereceived`.,0,0.9921225905418396
114925916,2929,ijuma,2017-05-05T03:03:47Z,this rule doesn't apply to `javaconverters` since you need explicit `asscala` and `asjava` calls anyway. that rule was for `javaconversions` which did things automatically and has been deprecated.,0,0.992367684841156
114925955,2929,ijuma,2017-05-05T03:04:37Z,"yeah, we definitely want to migrate all the code to the java class. it probably makes sense to do the whole class in one go though.",0,0.9860275983810425
119011953,2929,becketqin,2017-05-30T04:52:54Z,why should we rename the class?,0,0.9904502034187317
119012138,2929,becketqin,2017-05-30T04:55:35Z,this was a public api so it seems worth keeping and maybe mark it as deprecated.,0,0.9905210733413696
119012234,2929,becketqin,2017-05-30T04:56:56Z,maybe add some java doc to describe the exception a little?,0,0.9914463758468628
119012458,2929,becketqin,2017-05-30T05:00:15Z,can we add java doc for metadata request v3?,0,0.9958789348602295
119012849,2929,becketqin,2017-05-30T05:06:29Z,java doc is missing.,0,0.961162269115448
119012994,2929,becketqin,2017-05-30T05:07:39Z,nit: name is a little different from the way zk_version was named.,0,0.983512818813324
119013074,2929,becketqin,2017-05-30T05:08:58Z,can just fall through.,0,0.98180091381073
120798287,2929,lindong28,2017-06-08T04:35:36Z,thanks for the information .,0,0.5617383122444153
120800388,2929,lindong28,2017-06-08T05:03:46Z,this patch adds the scala class `leaderandisrpartitionstate` and `metadatapartitionstate`. `metadatapartitioninfo` makes it more explicit that this is a java class that corresponds to `metadatapartitionstate`.,0,0.9944273233413696
120800491,2929,lindong28,2017-06-08T05:05:06Z,then i wouldn't bother to rename this class if it is public api.,0,0.9887455105781555
120800642,2929,lindong28,2017-06-08T05:06:43Z,sure. i added this comment: `miscellaneous disk-related ioexception occurred when handling a request`.,0,0.9842891097068787
120800786,2929,lindong28,2017-06-08T05:09:03Z,sure. added this comment: [code block],0,0.9898125529289246
120800846,2929,lindong28,2017-06-08T05:10:00Z,good catch. thanks. i replaced it with `is_new` both here and in the protocol.java.,1,0.9945113658905029
120800894,2929,lindong28,2017-06-08T05:10:51Z,i forgot this is java not scala. good point. fixed now.,1,0.9874202609062195
121294118,2929,becketqin,2017-06-11T23:12:45Z,"the comment seems a little convoluted. i think it can just be ""whether the replica should have existed on the broker or not.""",0,0.894387423992157
121294281,2929,becketqin,2017-06-11T23:20:33Z,"do we need to create `leader_and_isr_request_live_leader_v1`? it seems that we do not have a consistent convention on when to create a new internal field version. my preference is that we always bump up request/response version if either request or response version is bumped, because the version would be used for compatibility check. but for internal fields, we do not have to bump up version if there is no change.",0,0.9896989464759827
121294385,2929,becketqin,2017-06-11T23:26:10Z,"yes, this is a public api. renaming it requires a kip.",0,0.993584930896759
121294648,2929,becketqin,2017-06-11T23:40:16Z,"if the default value of isnew is false, for brokers which are running ibp version lower than 0.11.1, replicas may not be created if a broker has a disk failure? in leaderandisrrequest earlier than v5, it actually means `create the replica if it does not exist`. in this case, i think it might make sense to keep the same behavior on the broker when storage failure is detected. i.e. let the entire broker halt if ibp is lower than 0.11.0.",0,0.990514874458313
121294669,2929,becketqin,2017-06-11T23:40:52Z,"btw, can you also bump up `apiversions` as well?",0,0.9940276145935059
121294748,2929,becketqin,2017-06-11T23:44:31Z,good cleanup.,1,0.9451795220375061
121294952,2929,becketqin,2017-06-11T23:47:17Z,is this renaming necessary?,0,0.9921384453773499
121295031,2929,becketqin,2017-06-11T23:52:10Z,the hierarchy here is a little strange. it might be clearer to create a new `abstractpartitionstate` class and let the partitionstate in leaderandisrrequest and updatemetadatarequest inherit from it.,0,0.6168819665908813
121295155,2929,becketqin,2017-06-11T23:56:56Z,see comments about the `partitionstate` hierarchy.,0,0.9927465319633484
121295230,2929,becketqin,2017-06-12T00:00:23Z,no need to do this if the struct does not contain the offline_replicas field. a big if statement seems simpler.,0,0.9868702292442322
121295331,2929,becketqin,2017-06-12T00:05:39Z,is this change intended? can the parent directories on different disk have the same name?,0,0.9919631481170654
121295556,2929,becketqin,2017-06-12T00:16:13Z,it is weird to pass in both controller and a member of the controller. the eventmanager field is already private to controller package so it is accessible from here.,-1,0.9920929074287415
121295627,2929,becketqin,2017-06-12T00:18:48Z,could be replaced by [code block].,0,0.9944116473197937
121296146,2929,becketqin,2017-06-12T00:39:50Z,no need to have the brackets around `brokerid`,0,0.9939414262771606
121296370,2929,becketqin,2017-06-12T00:48:03Z,some of the logics in this class are the same as in `onbrokerfailure()` probably worth trying to abstract them out to a shared method to handle offline replicas.,0,0.987657904624939
121296397,2929,becketqin,2017-06-12T00:49:05Z,no need to have eventmanager passed in.,0,0.9954994320869446
121296413,2929,becketqin,2017-06-12T00:49:40Z,empty java doc.,0,0.9484756588935852
121296662,2929,becketqin,2017-06-12T00:59:18Z,ditto above.,0,0.9910715222358704
121296804,2929,becketqin,2017-06-12T01:04:53Z,ditto above.,0,0.9910715222358704
121297063,2929,becketqin,2017-06-12T01:13:10Z,is a mutable map enough here?,0,0.9913753867149353
121297514,2929,becketqin,2017-06-12T01:22:21Z,why arraybuffer?,0,0.9883210062980652
121297615,2929,becketqin,2017-06-12T01:25:06Z,would a mutable map work here?,0,0.9884854555130005
121297859,2929,becketqin,2017-06-12T01:31:27Z,"there should not be duplicates in the `livelogdirs`, right? so we can just remove the dir for `livelogdirs`.",0,0.9931672215461731
121298466,2929,becketqin,2017-06-12T01:44:00Z,i did not see the logic to handle io failures in log segments loading. am i missing something?,0,0.9468297958374023
121299795,2929,becketqin,2017-06-12T02:00:53Z,we should probably exit if broker id load or checkpoint fail.,0,0.9842880964279175
121305112,2929,becketqin,2017-06-12T03:19:54Z,"it seems that sometimes we are catching both ioexception and kafkastorageexception, sometimes we only catch kafkastorageexception. it might be better to only catch ioexception at the the direct thrown and convert them to kafkastorageexception. so in the caller methods we only need to catch kafkastorageexception.",0,0.9869853854179382
121305435,2929,becketqin,2017-06-12T03:25:16Z,this exception should probably extend from retriableexception instead of apiexception. a disk failure should not cause the client to throw exception to the users. the clients should just retry after the leadership moves to another healthy replica.,0,0.993858277797699
121313873,2929,lindong28,2017-06-12T05:50:36Z,sure. i have updated the comment as you suggested.,0,0.980867326259613
121313909,2929,lindong28,2017-06-12T05:50:58Z,sure. i updated the patch to removed `leader_and_isr_request_live_leader_v1`.,0,0.983089029788971
121314572,2929,lindong28,2017-06-12T05:58:35Z,"regarding the first comment, it seems safer to disable replica creation if any replica offline. i think it is probably more backward compatible to do so -- currently leaderandisrrequest will fail to create replica if any disk is offline. regarding the second comment, good point. i should have updated the controller code to specify the version for leaderandisrrequest and updatemetadatarequest based on the configured `interbrokerprotocolversion`. i have updated the patch to do this and added `kafka_0_11_1_iv0` in `apiversion`. thanks!",1,0.9903734922409058
121314687,2929,lindong28,2017-06-12T06:00:02Z,`metadataresponsepartitionstate` will be more consistent and clearer than `partitionmetadata` in describing the usage of this class. it is not necessary to change the class. i replaced the todo with a comment that says `this is used to describe metadataresponsepartitionstate`.,0,0.9888335466384888
121314881,2929,lindong28,2017-06-12T06:02:16Z,"sure. i think we can do that refactor. since this is not an important refactor, can we do this refactor later or even in separate patch to reduce the chance of conflicts with other commits? for now i replaced the todo with a comment that says `this is used to describe leaderandisrpartitioninfo`.",0,0.9107304811477661
121314992,2929,lindong28,2017-06-12T06:03:26Z,i think the current class name updatemetadatarequestpartitionstate is good enough. i have removed this todo.,0,0.923255205154419
121315115,2929,lindong28,2017-06-12T06:04:43Z,"the current code is simpler than having an extra `if` statement. i am wondering what is the benefit of the extra `if` statement. it seems to have negligible impact on performance, right?",0,0.9754832983016968
121315417,2929,lindong28,2017-06-12T06:08:39Z,"yes, it is intended. i think `dir.getparent` is exactly the same as `dir.getparentfile.getabsolutepath` according to their java doc. `dir.getparent` is a bit shorter. i think parent directories on different disk must have the different name since they are specified as a list of strings using `log.dirs` config. they must be different so that kafka can distinguish between them.",0,0.9900035262107849
121315565,2929,lindong28,2017-06-12T06:10:44Z,good point. previously i think my ide tells me it can not be accessed as `controller.eventmanager`. i have updated it to use `controller.eventmanager`.,1,0.9802591800689697
121315578,2929,lindong28,2017-06-12T06:10:53Z,good point. fixed now.,1,0.9872389435768127
121315647,2929,lindong28,2017-06-12T06:11:47Z,great point. i have moved the overlapping logic to a new method named `onreplicabecomeoffline(newofflinereplicas: set[partitionandreplica])`.,1,0.9877127408981323
121315661,2929,lindong28,2017-06-12T06:11:56Z,sure. fixed now.,0,0.9459871053695679
121316067,2929,lindong28,2017-06-12T06:15:48Z,this comment seems ok since it is similar to the comment of `brokerchangelistener` and `isrchangenotificationlistener` etc. i can improve it. is there any example listener class's comment you want me to follow?,0,0.7736061811447144
121316335,2929,lindong28,2017-06-12T06:18:22Z,"i agree. but all existing listener class (e.g. partitionreassignmentlistener) takes this as the second argument. it seems better to keep the same code style for `logdireventnotificationlistener`, or we can update all of them to remove the second argument `eventmanager`. which solution do you prefer?",0,0.9674564599990845
121316376,2929,lindong28,2017-06-12T06:18:37Z,it is removed now. thanks.,1,0.9582696557044983
121316420,2929,lindong28,2017-06-12T06:18:44Z,it is removed now. thanks.,1,0.9582696557044983
121316852,2929,lindong28,2017-06-12T06:22:20Z,"i think it can be changed to a mutable map since a volatile var map can usually be replaced by a mutable map and vise versa. does kafka code has a preference between the two? i have chosen to use volatile var here because the code may be simpler. for example, i can simply do `checkpoints = checkpoints.filterkeys(_.getabsolutepath != dir)` in `logcleanermanager.handlelogdirfailure(dir: string)`.",0,0.9876514673233032
121317056,2929,lindong28,2017-06-12T06:24:16Z,"i think it can be changed to a mutable map since a volatile var map can usually be replaced by a mutable map and vise versa. does kafka code has a preference between the two? i have chosen to use volatile var here because the code may be simpler. for example, i can simply do `recoverypointcheckpoints = recoverypointcheckpoints.filterkeys(file => file.getabsolutepath != dir)` in `logmanager.handlelogdirfailure(dir: string)`.",0,0.9879916310310364
121319054,2929,lindong28,2017-06-12T06:43:47Z,"previously i think it is ok not to handle failure in `loadlogs()` because the subsequent requests (e.g. fetchrequest, producerrequest, leaderandisrrequest) can trigger `handlelogdirfailure(...)`. handling log directory failure in `loadlogs()` could allow broker to fail faster if all log directories are offline at the cost of slightly more code. anyway, i have updated the code to handle io failure in log segments loading.",0,0.989728569984436
121319440,2929,lindong28,2017-06-12T06:47:22Z,we need to pass `logmanager.livelogdirs` to `logcleanermanager` by reference and be able to propagate the change in `logmanager.livelogdirs` to `logcleanermanager`. therefore we need to change its type to arraybuffer so that it is mutable. does this make sense?,0,0.9940202236175537
121319883,2929,lindong28,2017-06-12T06:51:16Z,note that `livelogdirs` has type `arraybuffer[file]` and `dir` has type `string`. it seems that `arraybuffer` only allows remove by position in the array. it does not have a method to remove element by value.,0,0.9928216338157654
121320013,2929,lindong28,2017-06-12T06:52:20Z,"can you explain why we should let broker exit if broker id load fail? my concern is that this will cause broker to exit if any log directory goes offline, which defeats the purpose of this kip.",0,0.8663667440414429
121320570,2929,lindong28,2017-06-12T06:57:39Z,"it is possible to catch ioexception at the the direct thrown and convert them to kafkastorageexception. but the code change required for those try/catch/indentation is probably much more than the code needed for the extra exception in the catch. also, it is probably easier to verify that we catch both ioexception and kafkastrageexception in the request handling code than making sure we have a try/catch around every code that touches io. does this make sense?",0,0.9893934726715088
121320850,2929,lindong28,2017-06-12T07:00:26Z,i think it is probably better to keep `kafkastorageexception` as `apiexception` similar to the definition of`replicanotavailableexception`. the client code should not see `kafkastorageexception` if any replica is offline due to disk failure. instead the client should see e.g. `leadernotavailableexception` which is `retriableexception`. `kafkastorageexception` will only be received by controller. does this make sense?,0,0.9843876361846924
121347432,2929,ijuma,2017-06-12T09:32:10Z,"since it's an inner class of `metadataresponse`, there is no need to also add `metadataresponse` as a prefix to the inner class name.",0,0.9947713017463684
121349573,2929,ijuma,2017-06-12T09:41:19Z,"the intent is for `kafkacontroller.eventmanager` to be visible for testing (there's a comment next to the field). maybe we need to change the tests to access it reflectively since it's understandable that people may miss the comment. the reasoning is that by passing the `kafkacontroller` everywhere, it makes it harder to understand and limit the responsibility of each class. it would be nicer if we passed more granular instances . for example, this class needs `eventmanager`, `config`, `topicdeletionmanager` and `controllerchannelmanager`. if we passed those instead, we get a picture of what the class needs immediately instead of having to read every line of code.",0,0.9817055463790894
121349800,2929,ijuma,2017-06-12T09:42:24Z,i explained in another similar comment why `eventmanager` is passed explicitly.,0,0.9902781844139099
121350268,2929,ijuma,2017-06-12T09:44:36Z,"the semantics are not the same if you simply replace a volatile map with a mutable one in the face of concurrency (i haven't looked at the code, but the volatile implies that multiple threads are in play here).",0,0.9848703742027283
121351052,2929,ijuma,2017-06-12T09:48:27Z,you can remove it by value by using `def -= (x: a): this.type`.,0,0.9946558475494385
121467556,2929,lindong28,2017-06-12T16:56:01Z,"it may be useful to rename this class such that, instead of doing `new metadataresponse.partitionmetadata(...)` in the code, we can do `import org.apache.kafka.common.requests.metadataresponse.partitionmetadata` and `new partitionmetadata(...)` e.g. in `metadatacache.java`. the latter is more concise. anyway, i have replaced this todo with just a comment.",0,0.9915037751197815
121468083,2929,lindong28,2017-06-12T16:58:09Z,"thanks for the explanation. do you prefer to include `eventmanager` explicitly in the constructor of `controllerbrokerrequestbatch`, or is it ok to reference `eventmanager` via `kafkacontroller`?",1,0.8683069348335266
121468423,2929,lindong28,2017-06-12T16:59:26Z,thanks. i think i will keep the existing approach of including `controllereventmanager` in the constructor of those listeners since it is needed in the test. we can refactor them in a separate patch if it is necessary.,1,0.9554026126861572
121469351,2929,lindong28,2017-06-12T17:03:14Z,yeah i understand the meaning of volatile. can you explain a bit more specifically the case in which one can not be replaced by the other? thank you.,1,0.8337224125862122
121483933,2929,lindong28,2017-06-12T18:02:17Z,you are right. i have updated the patch to use `livelogdirs -= new file(dir)`.,0,0.9846850633621216
121559449,2929,ijuma,2017-06-13T00:33:56Z,"if one uses a volatile var, it's possible to update multiple entries in the map without exposing the intermediate states. with mutable maps, that's typically not possible without some form of external locking. on the other hand, one can lose updates by using a volatile var. generally, it's clearer to use a concurrentmap if that is the intent.",0,0.986672043800354
121560258,2929,lindong28,2017-06-13T00:41:47Z,"thanks for the explanation . i have two follow-up questions. suppose we don't use a thread-safe map and choose to use an external lock to protect a non-thread safe map, then are these two approaches equivalent? and in this specific case, do you recommend me to replace the ` var map` with a `concurrentmap`?",1,0.976518452167511
121563032,2929,ijuma,2017-06-13T01:08:16Z,"if you have an external lock during updates in both cases (like in this example), then the volatile version has the advantage that you don't need a lock on reads. the disadvantage is that there is potentially more copying. in this particular case, you are using `filterkeys` which is just a view on the underlying map. that doesn't seem like a good idea. aside from that, i have to look at the changes more closely to have a worthwhile opinion on what should be done here.",0,0.8110125660896301
121759231,2929,becketqin,2017-06-13T18:27:55Z,doing that later is fine.,0,0.9817251563072205
121762930,2929,becketqin,2017-06-13T18:42:07Z,"i am not sure about why it is safer to disable replica creation on a broker with failed directory. does that mean a broker will not get assigned any new replica as long as it has one disk failed? does that require controller awareness? but the controller does not know about that if it runs old ibp, right?",0,0.9279395937919617
121763195,2929,becketqin,2017-06-13T18:43:15Z,we should probably just remove the ` controller` if there is no java doc for it.,0,0.9918964505195618
121765991,2929,becketqin,2017-06-13T18:53:54Z,"this code is only called at startup time. it is to protect against data messed up from different brokers. since the broker hasn't started yet, it is probably ok for the broker to shutdown. users can remove the log dir from the path and restart the broker in this case.",0,0.9894602298736572
121779680,2929,lindong28,2017-06-13T19:51:54Z,"note that this only matters when there is disk failure. let me try to explain it based in the following different scenarios: 1) all brokers are running old code. the choice of the default value doesn't matter in this case because the code in this patch won't be used. 2) brokers are rolling upgraded to use the new code but the ibp is still old. here is the concern with setting default value to true. suppose the broker is running new code and partition p1 is in an offline log directories of this broker. if controller is running old code and sends leaderandisrrequest asking this broker to be leader of p1, the broker will re-create partition p1 on a good log directory. the follower will truncate the log for p1 and the data will be lost. and kip-112 currently doesn't handle it the case that the offline disk is repaired and used again with p1 still in it. on the other hand, with default value set to false, broker will refuses to become leader for p1, controller will not handle re-elect leader for p1 because it is running old code. during this period partition will become unavailable because the producer/consumer will send request to this broker and receive notleadderforpartitionexception. however, this will only happen for a short period of time and the problem will be solved once the controller is moved to a broker which is running new code. thus in this case, it is safer to set default value to false. 3) all brokers are running new code but some brokers are still using old ibp. suppose controller sends leaderandisrrequest for a new partition p1 to a broker with offline log directory, the broker will refuse to create log for p1 and return error in leaderandisrresponse. since the controller is running new code, it will handle the error properly by re-electing leader for this partition. in the rare scenario that all brokers elected to be replicas for this partition have offline disk, the partition will be offline. but the chance of this happening is low and this will be addresses once the ibp is fully upgraded. 4) all brokers are running new code with the new ibp. in this case the leaderandisrrequest will explicitly specify the isnew field and the default value doesn't matter. does this make sense?",0,0.9792190194129944
121779812,2929,lindong28,2017-06-13T19:52:31Z,thanks ! i will also think about it more.,1,0.9867397546768188
121780457,2929,lindong28,2017-06-13T19:55:32Z,i think the purpose of kip-112 is to make sure that broker be able to serve replicas on the good log directory even if there is bad log directory. we can not achieve this goal and the availability will be reduced if broker can not startup due to disk failure. can you explain a bit more why it is a concern if broker id load fails in one log directory? does this cause data corruption?,0,0.9820199608802795
121784846,2929,lindong28,2017-06-13T20:15:35Z,yeah you are right. i have removed it from the patch.,0,0.9795611500740051
122559063,2929,lindong28,2017-06-17T02:39:55Z,"discussed with offline. we decide to assume isnew = false if ibp is old. there are two options here when ibp is old. one is to be behavior of the current patch, i.e. broker will not shutdown if there is offline replica, and if there is new replica is assign to a broker will offline log directory, its creation will fail and the replica will be offline even if it can be created on a good replica. the other solution is to simply let broker shutdown if there is offline log directory. this allows new partition/topic to be assigned to only live broker and they won't be offline immediately after creation. we choose the first solution because it can keep the replicas on good log directories online at the cost of having all new replicas on that broker offline. it is likely that the number of new replicas assigned to that broker will be much less than the number of replicas on the good log directories of that broker. also, if user does prefer the second solution, he/she can manually shutdown that broker so that new replica will be online. i have updated the notes in `upgrade.html` to explain this.",0,0.9768733978271484
122559075,2929,lindong28,2017-06-17T02:40:54Z,"discussed offline. i have updated the patch so that if there is ioexception when reading brokerid from metadata file, the corresponding log dir will be marked failure but the broker will not shutdown. on the other hand, after broker registers itself in the zookeeper, it will only try to checkpoint brokerid in the metadata files in the live log directory (i.e. `logmanager.livelogdirs`). most likely there won't be ioexception when writing to metadata files here. if there is, then broker will shutdown entirely.",0,0.9893107414245605
123092424,2929,becketqin,2017-06-20T20:53:29Z,"hmm, if that is the case, should the storage exception be converted to leadernotavailableexception when it is thrown for requests such as produce/fetch/listoffsets? also, in that case, does that mean the broker needs to hold on the response until the controller moves leadership? otherwise broker is essentially giving up leadership by itself without get the confirmation from the controller. another thing is that we need to make sure the error code returned matches what is reflected in the metadata response. i am not sure what is the best exception to return to the user in this case, but in general i would rather not reuse exceptions for different scenarios.",0,0.9427897930145264
123122372,2929,lindong28,2017-06-20T23:32:52Z,sure. i have made kafkastorageexception a retriable exception.,0,0.9883537292480469
123122415,2929,lindong28,2017-06-20T23:33:18Z,i have fixed the issue by using the `if` statement as suggested.,0,0.9936994314193726
123651559,2929,becketqin,2017-06-23T00:30:24Z,we should also add a 0.11.1 version pointing to kafka_0_11_1_iv0,0,0.995235025882721
123659570,2929,lindong28,2017-06-23T02:08:06Z,sure. i have updated the patch to address this issue. and the patch has been rebased onto the latest trunk.,0,0.9805325269699097
123817916,2929,becketqin,2017-06-23T18:38:02Z,do we need to create this field version?,0,0.9956886172294617
123832032,2929,becketqin,2017-06-23T19:54:25Z,"for these two cases, the broker needs to read data from internal topics asynchronously. it seems that in both case the broker will only log an error without notify the controller that they cannot serve as leaders for those two partitions.",0,0.9890931844711304
123836327,2929,becketqin,2017-06-23T20:20:01Z,looked a bit more. it seems that we are not handling the disk exceptions thrown from filerecords.readinto(). that method is also used by logcleaner. could you check?,0,0.9908517003059387
123840858,2929,becketqin,2017-06-23T20:45:37Z,the `truncateto` method can throw storage exceptions. if that storage exception happens in the `replicafetcherthread` it seems we are not handling that.,0,0.9935632944107056
123869098,2929,lindong28,2017-06-24T03:09:49Z,sorry. removed now.,-1,0.9940358400344849
123869183,2929,lindong28,2017-06-24T03:15:45Z,thanks for catching this. i have added `try/catch` for `truncateto`.,1,0.9712494015693665
123871120,2929,lindong28,2017-06-24T05:32:43Z,sure. i have updated the code to handle ioexception here.,0,0.9900166392326355
123884003,2929,becketqin,2017-06-24T19:40:12Z,this looks a little verbose. maybe it could just be `updatemetadatarequest.partitionstate`,0,0.9729844927787781
123884171,2929,becketqin,2017-06-24T19:49:55Z,"should this class be in updatemetadatarequest? this patch introduces/modifies some classes containing similar fields, can we clean them up? we had some discussion on that before and i though a follow up patch is also fine. could you create another ticket to track this? more specifically, if there are common fields, an abstract partition state class would probably help. if there are additional partition state in different requests, those partitionsstate class should ideally extends from the abstract class and sit together with the corresponding requests.",0,0.9830405116081238
123884367,2929,becketqin,2017-06-24T20:01:18Z,"we are already checking the `isreplicalocal(replicaid)` above, can this logic be merged into that if statement?",0,0.9944709539413452
124189370,2929,becketqin,2017-06-27T06:45:27Z,"typo, filel -> file",0,0.9931033849716187
124197932,2929,becketqin,2017-06-27T07:34:37Z,i have the same question here. is it just to make sure we do not *lose* the log that failed to be removed?,0,0.9792585968971252
124200168,2929,becketqin,2017-06-27T07:47:39Z,is this the same as`logmanager.livelogdirs`?,0,0.995643138885498
124413939,2929,becketqin,2017-06-27T22:35:56Z,"it seems that calling `replicamanager.handlelogdirfailure()` may cause deadlock here. say the broker is handling an leaderandisrrequest, it will first grab the `replicamanager.replicastatechangelock` and then grab the `abstractfetcherthread.partitionmaplock`. however, when handling disk failure in `replicafetcherthread.processpartitiondata()`, the locking order is reversed. one way to solve this is to add an abstract error handling method in abstractfetcherthread and invoke that out of the `partitionmaplock`.",0,0.9882510304450989
124416864,2929,becketqin,2017-06-27T22:55:08Z,logdirutils?,0,0.9936459064483643
124417294,2929,becketqin,2017-06-27T22:58:13Z,"it seems that in the existing code the broker will halt if `logmanager.cleanuplogs()` sees a disk exception here. but with the patch, it will just silently fail.",0,0.9900716543197632
124418494,2929,becketqin,2017-06-27T23:07:19Z,is this block needed?,0,0.9942356944084167
124429369,2929,lindong28,2017-06-28T00:32:18Z,sure. it is renamed now.,0,0.9856758117675781
124429977,2929,lindong28,2017-06-28T00:38:11Z,"sure. i can clean them up. in the interest of reducing conflicts with other patches, i refactor the code and clean it up in a follow up patch. i will create the ticket after this patch is committed.",0,0.9857785701751709
124430275,2929,lindong28,2017-06-28T00:41:32Z,the `isreplicalocal(replicaid)` used above is only called if `replicaid` is not in `assignedreplicamap`. i couldn't find a good way to merge them. do you have a good way to do it?,0,0.9913327097892761
124430429,2929,lindong28,2017-06-28T00:43:07Z,thanks. fixed now.,1,0.9681604504585266
124430768,2929,lindong28,2017-06-28T00:46:48Z,not exactly the same because `config.logdirs` is a list of string whereas `logmanager.livelogdirs` is a list of file. i have updated the code to avoid the `if` statement.,0,0.9907089471817017
124438217,2929,lindong28,2017-06-28T02:07:35Z,great catch! it is fixed now.,1,0.996932864189148
124439381,2929,lindong28,2017-06-28T02:19:21Z,good point. it is renamed now.,1,0.9734551906585693
124444527,2929,lindong28,2017-06-28T03:16:48Z,"thanks for catching this. this becomes a problem due to the use of `leaderepochcache` in kip-101. i have updated the patch to halt the system if `filenotfoundexception` is observed. while it is possible catch the ioexception thrown from this place and handle it, it will require a couple of try/catch/handle distributed across the code. and non-trivial change is needed to avoid deadlock because `replicafetcherthread.handleoffsetoutofrange()` may also trigger this code. i think the simplest approach is to just keep the existing code, i.e. halt the system if `filenotfoundexception` is thrown from here. i don't think it will affect the availability of jbod deployment because according to mayursh's comment, this `filenotfoundexception` is thrown if the broker is configured with raid. we can re-investigate this problem if this is also an issue when broker uses jbod.",1,0.9254907369613647
124445278,2929,lindong28,2017-06-28T03:25:41Z,yeah this is no longer needed in this test after a recent comment on jun 5. i will go through the core code after rebase but typically skip the test code if they pass. thanks for catching this! it is removed now.,1,0.9941816926002502
124479048,2929,becketqin,2017-06-28T08:19:26Z,"you are right, never mind.",1,0.7476779818534851
124685896,2929,junrao,2017-06-29T00:03:27Z,perhaps add a comment that summarizes what's changed in v1 of leaderandisr request?,0,0.9947958588600159
124686504,2929,junrao,2017-06-29T00:08:37Z,perhaps add a comment that summarizes what's changed in v4?,0,0.9941781759262085
124695356,2929,junrao,2017-06-29T01:37:04Z,could we avoid wrapping kafkastorageexception if e is already of kafkastorageexception?,0,0.992712140083313
124696536,2929,junrao,2017-06-29T01:51:10Z,"state change log is for logging actions to requests from the controller. since this method could be called from serving non-controller request, perhaps it's better to just log it in the server.log.",0,0.9935186505317688
124711510,2929,lindong28,2017-06-29T04:49:26Z,i will replace `deleterecursively(...)` with `org.apache.kafka.common.utils.utils.delete(...)` in the next commit.,0,0.9946182370185852
124931997,2929,junrao,2017-06-29T23:01:39Z,"could we do filter { case (tp, log) .. } and map ( case (tp, log) ...} so that it's a bit clearer what's being referenced?",0,0.9932599663734436
124932600,2929,junrao,2017-06-29T23:06:13Z,is this worth logging?,0,0.9914501309394836
124932609,2929,junrao,2017-06-29T23:06:21Z,is this worth logging?,0,0.9914501309394836
124934166,2929,junrao,2017-06-29T23:18:20Z,we probably want to limit the places with direct zkutils access. perhaps it's better to send zk notification in replicamanger.handlelogdirfailure()?,0,0.9926539659500122
124935126,2929,junrao,2017-06-29T23:25:38Z,does this need to be synchronized inside logcreationordeletionlock since livelogdirs could be changed concurrently? offlinelogdirs could be called from a different thread for metric reporting.,0,0.9929243326187134
124935421,2929,junrao,2017-06-29T23:28:00Z,will it be worth adding a per logdir metric so that we can find out which individual log dir is online/offline?,0,0.9921553730964661
124936765,2929,junrao,2017-06-29T23:37:56Z,"perhaps it's better to only capture ioexception here? for other exceptions, it's probably better to just fail the broker as before.",0,0.9859721660614014
124940850,2929,junrao,2017-06-30T00:13:52Z,"there are a few places like logmanager.truncateto() where we call logmanager.handlelogdirfailure() directly. it seems that they should all call replicamanager.handlelogdirfailure() instead since it does things like taking the partition off allpartitions and removing the partition from replicafetchermanager, which need to be done on an offline logdir.",0,0.990227222442627
124947219,2929,junrao,2017-06-30T01:21:12Z,"so, here, we are not communicating the truncation error back to the replica fetcher thread. ideally, if the truncation fails, we shouldn't let the replica fetcher proceed with the subsequent fetching.",0,0.9899656772613525
124948445,2929,junrao,2017-06-30T01:30:13Z,is .toseq needed?,0,0.9944517016410828
124948786,2929,junrao,2017-06-30T01:33:58Z,"for consistency, it seems that we need to handle ioexception in truncatefullyandstartat() and call handlelogdirfailure() too?",0,0.9912471175193787
125063695,2929,junrao,2017-06-30T15:15:48Z,"we requeue the logs that failed deletion mostly because of ioexception. so, i am not sure if we need to requeue removedlog now.",0,0.9693565368652344
125064418,2929,junrao,2017-06-30T15:18:51Z,could we add a comment to explain what isnew means?,0,0.9947688579559326
125069246,2929,junrao,2017-06-30T15:40:50Z,"in line 709, we convert an ioexception to kafkastorageexception in log.append. i am wondering if this is needed since the caller of append handles both ioexception and kafkastorageexception. also, in replicamanager, sometimes we catch kafkastorageexception and some other times we catch both ioexception and kafkastorageexception. it would useful to make that consistent. for example, we can make the convention that ioexception will be throw from java library and kafkastorageexception will be throw in the kafka code (but not wrapping ioexceptions from java). then the caller will catch both ioexception and kafkastorageexception",0,0.975328266620636
125073587,2929,junrao,2017-06-30T16:00:19Z,"hmm, not sure why we need the additional check here. if replicaid is not in assignedreplicamap, it probably shouldn't lead to a kafkastorageexception.",0,0.9200051426887512
125087026,2929,junrao,2017-06-30T17:13:36Z,we probably need to do the following optimization in delete() here? coreutils.swallow(forceunmap(mmap)),0,0.9944775700569153
125088146,2929,junrao,2017-06-30T17:19:41Z,unused import,0,0.9873000979423523
125094553,2929,junrao,2017-06-30T17:51:33Z,could we adjust the comment of the return value accordingly?,0,0.9938226938247681
125097858,2929,junrao,2017-06-30T18:05:59Z,partitionstate seems unused?,0,0.9830233454704285
125101226,2929,junrao,2017-06-30T18:21:56Z,"hmm, doloadgroupsandoffsets() just runs in a scheduler. should we call replicamanager.handlelogdirfailure() on ioexception too? if so, we probably want to do the same in txnmanager.",0,0.9838984608650208
125109233,2929,junrao,2017-06-30T19:02:30Z,"in controller failover, would it be worth to clean up all leftover sequence nodes in logdireventpath? those nodes won't be useful since the new controller will send a leaderandisrrequest to every broker on failover.",0,0.9891876578330994
125112249,2929,junrao,2017-06-30T19:19:03Z,"if a disk fail in the code path outside of the log cleaner, we should remove that dir from checkpoints too. is that logic added already?",0,0.9940219521522522
125120383,2929,lindong28,2017-06-30T20:05:00Z,thanks for catching this. i have updated the patch to say `leader_and_isr_request_v1 added a per-partition is_new field. this field specifies whether the replica should have existed on the broker or not`.,1,0.9682088494300842
125120952,2929,lindong28,2017-06-30T20:08:44Z,"sure. i added the following comment for `update_metadata_request_partition_state_v4`, `update_metadata_request_v4` and `metadata_response_v5`. `... added a per-partition offline_replicas field. this field specifies the list of replicas that are offline`",0,0.984086811542511
125121473,2929,lindong28,2017-06-30T20:12:07Z,sure. i fixed it with the follow code: [code block],0,0.9830127358436584
125121745,2929,lindong28,2017-06-30T20:13:47Z,previously i thought this is used for making partition state change. they are the same because previously all state change are triggered by controller request. i have changed the code to log it in the server.log.,0,0.9924384951591492
125123322,2929,lindong28,2017-06-30T20:23:17Z,"when `logcleaner` encounters ioexception when cleaning up the log, we want to mark the corresponding log directory as offline and inform controller of the log directory failure via zookeeper. note that this ioexception is not triggered by an external request and thus will not go through `replicamanager`. since we probably don't want to reference replicamanager via logmanager, `logmanager.handlelogdirfailure()` seems to be the only reasonable place to have this log of wrting to log directory notification znode. i couldn't find a better way to address this problem. do you have a better solution?",0,0.9894947409629822
125130310,2929,lindong28,2017-06-30T21:06:04Z,"another reason to put the logic of zookeeper notification in logmanger is that, currently logmanager is managing which logs are online or offline and thus is the source of truth of offline log directories. ideally we would like to put the logic of notification in the same place so that the notification is sent if and only if the offline log directories change.",0,0.9908272624015808
125136812,2929,lindong28,2017-06-30T21:52:18Z,"previously i think the chance of exception due to this race condition is so small (because disk failure should be rare) that we don't want to degrade performance by getting lock every time we read `livelogdirs`. for example, metrics reporting will access `abstractfetchermanager.fetcherthreadmap` and it seems fine so far. but strictly speaking, you are right that this can cause race condition and it is better to prevent this completely from any unknown consequence. so i made the following changes to address the problem: 1) use `_livelogdirs: arrayblockingqueue[file]` to record offline log directories. we don't have to worry about blocking operation because we will only remove log directory from it. i think this may be a little better than using `logcreationordeletionlock synchronized {}` every time we access `_livelogdirs` (e.g. `checkpointlogrecoveryoffsets()`, `checkpointlogstartoffsets` and metrics reporting) so that these access won't block `logmanager.createlog()` or `logmanager.asyncdelete()` 2) add `def livelogdirs: array[file] = _livelogdirs.asscala.toarray` so that we don't have to change test code to work with `arrayblockingqueue[file]`. 3) update various checkpoint() methods (e.g. `checkpointlogstartoffsetsindir(dir: file)`) so that they can handle the case that the directory in the input parameter gets removed from the checkpoint map right after the method begins.",0,0.9680812358856201
125137370,2929,junrao,2017-06-30T21:56:44Z,"we could probably pass in a onlogdirfailure callback to the logcleaner. an ioexception could be triggered in different places. however, independent of where it's triggered, we always want to react with the same process, which includes (marking the partition/replica as offline, remove partition from replicafetcher, notify the controller, etc). replicamanager seems to be the best place to consolidate that process.",0,0.9910445213317871
125138864,2929,lindong28,2017-06-30T22:07:56Z,"previously i don't think it is needed because if user wants to know which specific log directories are offline in addition to the offline log directory count, it probably means they want to fix the problem and they will login the machine anyway. in this case they can find the offline log directory name in the log. and user probably wants to fix the problem because the log itself gets deleted from the cluster because they need to see the exception trace to debug the problem. yes, it can make debug easier to have this metric. i have updated the patch with the following code: [code block]",0,0.9818436503410339
125139125,2929,lindong28,2017-06-30T22:10:15Z,sure. good point. i have updated the code to only catch `ioexception`.,1,0.9416135549545288
125142699,2929,lindong28,2017-06-30T22:44:00Z,"are you suggesting that `logmanager.handlelogdirfailure()` should invoke `replicamanager.handlelogdirfailure()` and `replicamanager` should be put in the constructor of the `logmanager`? this can be done. but i am worried that this creates circular dependency between `logmanager` and `replicamanager` and can make future development harder. in addition to the worry with this java class dependency, i also find hard to organize the methods. for example, say the broker receives a `producerequest`, triggers `replicamanager.appendtolocallog()`, which in turn calls `partition.appendrecordstoleader()` and fails with `ioexception`. note that we haven't touched `logmanger` in this path and thus `logmanger.handlelogdirfailure()` won't be called. now that the replicamanager catches an ioexception, ideally it should have its own method `handlelogdirfailure()` to deal with it, e.g. remove the corresponding topcpartition from `replicamanager.allpartitions` and `logmanager.logs`. then it become pretty straightforward to have `replicamanager.handlelogdirfailure()` to call `logmanager.handlelogdirfailure()`. but then it seems weird for `logmanager.handlelogdirfailure()` to invoke `replicamanager.handlelogdirfailure()` even though we can use some trick to make it work. do you have a solution to this circular invocation? currently if the ioexception is triggered by user's request, both `replicamanager.handlelogdirfailure` and `logmanager.handlelogdirfailure()` will be called so this is ok. if ioexception is triggered by e.g. `logcleaner`, only `logmanager.handlelogdirfailure()` will be triggered and some partition will still stay in `replicamanager.allpartitions`. as of now i don't find this to be a problem. because the next time any producerequest or fetchrequest tries to access a partition on that offline log directory, replicamanager will handle the log directory failure. also, i have updated the code so that `replicamanager.checkpointhighwatermarks()` will trigger `replicamanager.handlelogdirfailure()` if any partition in `allpartitions` is on an offline log directory. thus the period of inconsistency will be limited. does this address your concern?",-1,0.9304405450820923
125142923,2929,lindong28,2017-06-30T22:46:16Z,yeah i have concern with having `logmanager` call `replicamanager.handlelogdirfailure()`. we can continue the discussion in the other comment.,0,0.7905312180519104
125144710,2929,lindong28,2017-06-30T23:06:01Z,"yeah this can be improved. i removed this if statement and replaced this log with `info(s""stopping serving logs in dir $dir"")`.",0,0.9916566610336304
125144734,2929,lindong28,2017-06-30T23:06:16Z,no. i have removed this log.,0,0.9913769960403442
125144776,2929,junrao,2017-06-30T23:06:51Z,": my suggestion is that nobody should directly call logmanager.handlelogdirfailure() except for replicamanager.handlelogdirfailure(). the latter knows how to bring all parts to a consistent state with respect to ioexception, no matter where it's introduced. so, if a method hits an ioexception through replicamanager, we will just the ioexception bubble up to replicamanager and call replicamanager.handlelogdirfailure() there. if the ioexception is isolated logcleaner, we can somehow pass replicamanager.handlelogdirfailure() to logcleaner and let logcleaner call it. this way, any time a disk error is detected, it will be handled consistently no matter in which component the error is detected, which seems easier to reason about.",0,0.9810708165168762
125145180,2929,lindong28,2017-06-30T23:12:21Z,"sure. i have replaced this line with `val offlinetopicpartitions = logs.filter { case (tp, log) => log.dir.getparent == dir}.map { case (tp, log) => tp}`",0,0.9831697940826416
125145259,2929,lindong28,2017-06-30T23:13:35Z,hmm.. i couldn't remember why this is added in the first place.. removed now.,0,0.9144713282585144
125148715,2929,lindong28,2017-07-01T00:05:01Z,i see. do you think it is ok to have a method `logmanger.setlogfailurecallback()` that will be called in `kafkaserver.startup()` after the `replicamanager` is constructed? if yes then i will do it. we can not get not pass this callback to the constructor of `logmanager` because `logmanager` is instantiated before the `replicamanager`.,0,0.9906596541404724
125149426,2929,lindong28,2017-07-01T00:19:47Z,sure. i added the following java doc: [code block],0,0.9889125823974609
125149731,2929,lindong28,2017-07-01T00:27:04Z,ok. i have updated the code to remove this re-enqueue logic.,0,0.9932162165641785
125152135,2929,lindong28,2017-07-01T01:57:02Z,"we need this check to address the issue we have been discussing in the other threads, i.e. the partition may have been removed in `logmanager` but not in `replicamanager`. in this case, replicaid will be in the assignedreplicamap even though the replica is offline. this additional check will make sure that `getorcreatereplica()` will throw kafkastorageexception in this case. more specifically, here is the currently workflow if logcleaner encounters ioexception: - `logmanager.handlelogdirfailure()` will remove this log dir and partitions and inform controller via zookeeper. - controller sends leaderandisrrequest for all partitions on this broker - `partition.getorcreatereplica()` for partitions on the offline log directory will throw kafkastorageexception, which in turn triggers `replicamanager.handlelogdirfailure()` so that those partitions can be removed from `replicamanager` as well.",0,0.99090576171875
125152284,2929,lindong28,2017-07-01T02:07:26Z,yeah i would like to invoke `replicamanager.handlelogdirfailure()` whenever there is ioexception. but this is not done yet because `logmanager` is not able to reference `replicamanager` since it is instantiated before the `replicamanager`. we can address this problem by doing `logmanager.setonlogdirfailurecallback()` after the replicamanage is instantiated. i find this to be a big ugly though. what do you think?,-1,0.942039966583252
125152579,2929,lindong28,2017-07-01T02:25:56Z,"btw, here is the current workflow if `logmanger.handlelogdirfailure()` is called by `logcleaner`. - `logmanager.handlelogdirfailure()` will remove this log dir and partitions and inform controller via zookeeper. - controller sends leaderandisrrequest for all partitions on this broker - `partition.getorcreatereplica()` for partitions on the offline log directory will throw kafkastorageexception, which in turn triggers `replicamanager.handlelogdirfailure()` so that those partitions can be removed from `replicamanager` and the `replicafetchermanager`.",0,0.9897422790527344
125152647,2929,lindong28,2017-07-01T02:29:54Z,sure. i have updated the patch to catch ioexception here. previously i had a long discussion with and we think it is ok to handle ioexception that currently doesn't trigger `halt()` in a followup patch. the reasons are recorded in this pull request. that is why i didn't catch ioexception here.,0,0.9594011902809143
125153306,2929,lindong28,2017-07-01T03:12:25Z,"the line in 709 is there before this patch. that is no longer needed after kip-112. i kept it there to avoid changing the indention of that code block so that the code diff and the code review can be a bit simpler. i will remove that conversion after most all comments have been addressed. besides the motivation of avoid changing code indentation, the current patch only convert ioexception to kafkastorageexception if the method needs to handle that ioexception before throwing that again. i assume that we don't want to have try/catch around all java library to convert ioexception to kafkastorageexception for code simplicity. as a result our kafka method may potentially throw both ioexception and kafkastorageexception and that is why some code needs to catch both. regarding the consistency, are you suggesting that the code that currently catches only the `kafkastorageexception` should be updated to catch both `ioexception` and `kafkastorageexception` and treat them as `kafkastoragexception`?",0,0.9862576127052307
125153341,2929,lindong28,2017-07-01T03:15:02Z,good point. i didn't realize we had this method. i have updated the code as suggested.,1,0.9817020893096924
125153345,2929,lindong28,2017-07-01T03:15:33Z,thanks. fixed now.,1,0.9681604504585266
125153388,2929,lindong28,2017-07-01T03:18:58Z,ah i should have done this. thanks for noticing this. i have updated the patch with the following comment: [code block],1,0.9862268567085266
125153403,2929,lindong28,2017-07-01T03:20:24Z,my bad.. removed now.,-1,0.995307981967926
125153742,2929,lindong28,2017-07-01T03:43:25Z,good catch! i missed the fact that this method is run in a scheduler. sure. i have updated the patch to call relicamanager.handlelogdirfailure() in `doloadgroupsandoffsets()` when there is `ioexception`. i also reverted the change that was made to update the `responsemap` when there is `ioexception`. becket had similar comment and asked me to do the same in `transactionstatemanager`. i didn't do that because i am not sure i know `transactionstatemanager` good enough to handle ioexception in the best way. this is an existing problem with `transactionstatemanager` and probably other modules in kafka as well because they don't explicitly handle the scenario when the disk write operation fails. can we focus on the ioexception that currently causes `halt()` and leave the handling of ioexeption that are currently ignored (e.g. in `transactionstatemanager`) in follow up patch?,1,0.9869289398193359
125153969,2929,lindong28,2017-07-01T03:57:57Z,"no, that logic is not added. there are two reason i didn't do that. one reason is to avoid circular invocation. currently `logcleaner.handlelogdirfailure()` and `logcleanermanager.handlelogdirfailure()` will invoke `logmanager.handlelogdirfailure()`. it seems a bit ugly if we let `logmanager.handlelogdirfailure()` invoke `logcleanermanager.handlelogdirfailure()`. ideally the invoke between methods is a directed acyclic graph. the other reason is that it is not necessary to explicitly remove dir from `logcleanermanager.checkpoints` as long as `logmanager.handlelogdirfailure()` has already removed all partitions on the offline dir from `logmanager.logs`. note that all read or write operation on `logcleanermanager.checkpoints` is triggered by the partition in that log directory, which in turn comes from `logmanager.logs`. thus if all partitions on a dir is removed from `logmanager.logs`, it is guaranteed that this `dir` will no longer be used as key to access `logcleanermanager.checkpoints`. does this address the problem?",0,0.9514830708503723
125154247,2929,lindong28,2017-07-01T04:22:13Z,good point. i have added the following methods in `logdirutils` and invoked this at the beginning of `oncontrollerfailover()`. [code block],1,0.9539229869842529
125369462,2929,lindong28,2017-07-04T00:07:26Z,i realized that there is one way to do this without using `logmanger.setlogfailurecallback ()`. we can provide `kafkaserver` to the constructor of `logmanager`. then `logmanager.handlelogdirfailure()` can call `kafkaserver.replicamanager.handlelogdirfailure()`. the disadvantage is that this exposes a log of things to `logmanger`. does this sound reasonable?,0,0.9822123050689697
125761540,2929,junrao,2017-07-05T21:25:42Z,it may not be efficient to do the exists check in every iteration of topicpartition since the exists check requires a scan of allpartitions. perhaps we could figure out the topics to be removed by first getting the uniqe topics from newofflinepartitions and then do the exists check on allpartitions?,0,0.9892566800117493
125762622,2929,junrao,2017-07-05T21:31:15Z,perhaps it's better to rename createlog to getorcreatelog?,0,0.9898183941841125
125773929,2929,junrao,2017-07-05T22:34:28Z,"hmm, currently, the java producer from 0.11.0.0 will treat this new exception as an unknown exception and won't retry. since we may add new error code that may be retriable in the future, perhaps we should make unknownserverexception a retriable error? if so, we probably want to do that in a separate patch and patch the 0.11.0 and probably the 0.10.2 branch as well.",0,0.9824001789093018
125796722,2929,junrao,2017-07-06T01:52:09Z,": good point on the circular dependency on constructing those objects. another approach that i am thinking is to have a diskfailurechannel which contains an in-memory queue. diskfailurechannel can be passed into all components such as logmananger, logcleaner, replicamanager, etc where io errors can be generated. if an io error happens in a component, it just enqueues the disk name into the diskfailurechannel. we can have a separate thread (maybe in replicamanager) that reads from diskfailurechannel and acts on it (e.g., remove partitions in replicamanager, remove logs in logmanager, remove partitions from replica fetcher), etc. this way, all disk errors will be handled consistently. the only thing is that disk errors will be handled asynchronously. however, i am not sure if disk errors need to be processed synchronously.",1,0.8680535554885864
125804911,2929,lindong28,2017-07-06T03:30:34Z,"thanks for the suggestion! one concern with having this queue for disk failure events is that, in the event a log directory fails, every attempt to access any replica in that log directory will generate a disk failure event for the same log directory. a lot of events may be instantiated and put into this queue which wastes cpu and memory. i am also concerned that we can not bound the number of events generated for a single disk failure since we don't know when the os will schedule that thread to read event from this queue. maybe we don't need this `diskfailurechannel`. we can just schedule a thread in `replicamanager` to read from `logmanager.offlinelogdirs` and call `replicamanager.handlelogdirs(dir)` when there is new offline log dir. i understand that the goal of this alternative approach is to make sure that the state in `replicamanager` (e.g. `replicamanager.allpartitions`) is consistent with the state in `logmanager` (e.g. `logmanager.logs`). and i agree that we can achieve this goal by having an extra thread in `replicamanager`. but i am not sure that the benefit of this alternative approach is worth the extra thread. note that the disadvantages of the alternative approach is: 1) it requires an extra thread in `replicamanager` which makes kafka's java class a bit more complicated; and 2) the log failure event will be processed asynchronously which potentially delays the controller notification and leader election. and we can not bound the delay. can you help me understand why it is necessary to keep state in `replicamanager` and `logmanager` consistent all the time? the current approach in the patch guarantees eventual consistency, i.e. the `replicamanager.handlelogdirfailure()` will be called after controller notification is sent and the broker receives `leaderandisrrequest` from controller. it seems that nothing will go wrong during the period of inconsistency -- if anything goes wrong then we will have the same issue with the alternative approach. and the alternative approach makes state consistent by delaying the execution of `logmanager.handlelogdirfailure()`. i will implement the alternative approach using an extra thread if the consistency is more important than the extra complexity and the potential delay in log failure handling.",1,0.988911509513855
125806173,2929,lindong28,2017-07-06T03:47:24Z,good point. i replaced this with the following code: [code block],1,0.9780101180076599
125806333,2929,lindong28,2017-07-06T03:49:38Z,sure. i have renamed this method as `getorcreatelog()`,0,0.9882013201713562
125807634,2929,lindong28,2017-07-06T04:07:01Z,now i understand the question. i am not sure we should make `unknownserverexception` a retriable error because i am a bit concerned with having unnecessary retry if we do that. i think we can keep the current practice by making an error retriable only if we know it should be retriable. is there any reason that we should make `unknownserverexception` retriable? i understand that `kafkastorageexception` was previously non-retriable because it is send to client as `unknownserverexception`. but i couldn't find anything wrong with making it retriable now. it also doesn't break any contract between client and server because client is now receiving a new error (i.e. kafkastorageerror) from client's perspective. is there any concern with this approach?,0,0.9309380054473877
126026144,2929,junrao,2017-07-06T21:54:51Z,"the issue that i am thinking is the following. the 0.11.0 client jar doesn't have the error code for kafkastorageexception. if the 011.1 server sends a kafkastorageexception to the 0.11.0 client, the client will treat it as an unknownserverexception and won't retry. however, ideally, we want the 0.11.0 client to retry in this case.",0,0.9836081862449646
126036453,2929,junrao,2017-07-06T22:55:31Z,": my thoughts are the following. (1) when reacting to a disk failure, it would be useful to handle this in order, e.g., removing the partition from replicamanager, followed by removing the log from logmanager. if you only remove the log from logmanager w/o removing the partition from replicamanager, then a request may hit an unexpected exception when trying to access the log, which is not ideal. (2) the notification to zk could take a long time if zk is not performing. doing the zk notification in a background thread reduces the potential latency impact to the client request. (3) we may implement a more sophisticated disk failure detection module (e.g., proactively verifying crcs in the log) in the future. having a diskfailurechannel allows us to integrate such a module easier (such a module only needs to interact directly with diskfailurechannel, instead of replicamanager). i agree that adding a separate disk failure handling thread adds a bit complexity, but probably not too much. to avoid building up the queue, perhaps diskfailurechannel can just maintain a disk dir set instead of a queue.",0,0.9300193190574646
126036708,2929,lindong28,2017-07-06T22:57:26Z,"i see. this makes sense. one concern with making `unknownserverexception` a retriable exception is that client may retry unnecessarily. maybe we can reduce unnecessary retries by distinguishing between `unknownserverexception` and `unknownexception`. an exception is an `unknownexception` if the error code is not found defined, .e.g. 0.11.0 client receives the error code for `kafkastorageexception`. thus the client wouldn't have to retry if server sends the error code of the existing server unknown exception. and the client will only retry unnecessarily if its client's version is (temporarily) lower than server's version. does this sound ok? i can submit a separate patch for 0.11.0 and 0.10.2 branch.",0,0.9583828449249268
126038803,2929,ijuma,2017-07-06T23:11:22Z,"the downside of any of the suggested approaches is that it won't help already released versions. another option would be to use an existing retriableexception when dealing with older clients. this would require bumping the relevant protocol versions though. going forward, it may make sense to define a `retriableunknownexception` that the broker can use to force older clients to retry.",0,0.9635807275772095
126090944,2929,lindong28,2017-07-07T08:08:48Z,"i agree with your points. thanks so much for the detailed explanation. i have updated the patch to include `logdirfailurechannel` and an extra thread in `replicamanager`. the `logmanager.handlelogdirfailure()` will only be called by `replicamanager.handlelogdirfailure()`, which in turn will only be called by that thread. and the offline log dir name will be put into `logdirfailurechannel` if there is new offline dir. the new thread will block waiting for new offline log dir. i have also updated the patch to revert changes such as the zkutils in the logmanager constructor. i have reviewed the changes and the entire patches myself before uploading it. i think all comments have been addressed. can you take another look at the patch? thanks much for your time!",1,0.990860104560852
126091184,2929,lindong28,2017-07-07T08:10:28Z,i have updated the patch so that `logmanager.handlelogdirfailure()` will be called only by `replicamanager.handlelogdirfailure()`,0,0.9941498041152954
126091442,2929,lindong28,2017-07-07T08:12:13Z,i have updated the patch so that the partitions will be removed from the replica fetcher if truncation fails.,0,0.9948613047599792
126092808,2929,lindong28,2017-07-07T08:20:06Z,thanks for the suggestion. yes we can also name that new exception as `retriableunknownexception`. and `errors.forcode(code)` will return `retriableunknownexception` if the code is larger than maximum code of the defined error on the client side. my previous idea is to name the new exception as either `unknownexception` which will be retriable. the advantage is that the error will be more explicit about that it is -- a code that is not found in the client's library. the advantage of your solution is that we can re-use the new exception for any retriable exception. does this sound good to you?,1,0.9627214670181274
126236649,2929,junrao,2017-07-07T20:19:46Z,"hmm, if we bump up the protocol, wouldn't we have the same problem on the old client using the old protocol? i.e, if the broker hits a kafkastorageexception serving a request from the old client, we have to convert kafkastorageexception to sth that the old client can recognize.",0,0.9831843972206116
126243848,2929,lindong28,2017-07-07T20:57:01Z,"i guess i didn't understand ismael's suggestion w.r.t. the protocol version.. in my opinion, the long term approach is to have a new retriable exception, named as either `unknownexception` or `retriableunknownexception` such that an known error code will be translated to this exception on the client side. one short term solution we can do in this patch is to transform kafkastorageexception to the error code of notleaderforpartitionexception in produceresponse and fetchresopnse. this is hacky. but it should address this problem without causing any additional concern since producer/consumer shouldn't really care whether this is kafkastorageexception as long as it is retriable. what do you think of this short term solution?",-1,0.9528889060020447
126252343,2929,ijuma,2017-07-07T21:48:02Z,"yes, my suggestion was to bump the protocol so that we reuse an existing retriable exception for the old version and `kafkastorageexception` for the new version. and `retriableunknownexception` would be a way to avoid this hack in the future, but it doesn't help now.",0,0.9782388210296631
126256742,2929,lindong28,2017-07-07T22:18:36Z,"thanks much. this makes sense. i have updated the patch to include `unknownretriableexception`, bumped up the version of producerequest and fetchrequest, and converted kafkastorageexception to the error code of notleaderforpartitionexception for existing versions of produceresponse and fetchresponse.",1,0.9854355454444885
126448908,2929,junrao,2017-07-10T15:06:52Z,"hmm, this thread is interruptible. could we just make takenextlogfailureevent() block infinitely?",0,0.9405088424682617
126462482,2929,junrao,2017-07-10T15:51:34Z,"this is going to affect how the replicafetchthread works. before this patch, if the replicafetchthread hits an ioexception during truncate, the affected replica will remain in the truncating state and the truncation will be retried. with the patch, since the ioexception is not propagated back to replicafetchthread, the replicafetchthread just assumes that the truncation has succeeded and moves onto the next stage. we want to preserve the original behavior.",0,0.9893624186515808
127005161,2929,lindong28,2017-07-12T16:30:58Z,this line can be removed. it probably becomes redundant after a rebase.,0,0.99411940574646
127013042,2929,lindong28,2017-07-12T17:04:42Z,change java doc to the following ``` get the next offline log dir from logdirfailureevent queue. block waiting for up to the specified amount of time if there is no new offline log dir. ``,0,0.994205892086029
127014976,2929,lindong28,2017-07-12T17:13:00Z,this can be removed now since we have `logdirfailurechannel`.,0,0.9950834512710571
127038150,2929,lindong28,2017-07-12T18:41:58Z,"never mind. this is still needed. if there is offline log dir, `getorcreatepartition()` will create the partition object before `getorcreatereplica()` fails with exception. in this case we need this code to remove the partition which doesn't have a valid local replica.",0,0.9575667977333069
127068479,2929,junrao,2017-07-12T20:51:59Z,could we adjust the above comment to reflect initialofflinedirs?,0,0.9938482642173767
127068824,2929,junrao,2017-07-12T20:53:23Z,this probably should be named islogdirectoroffline?,0,0.989210844039917
127072655,2929,junrao,2017-07-12T21:09:18Z,_livelogdirs could change after the size check in line 77. should we tighten this up?,0,0.9943428039550781
127074402,2929,junrao,2017-07-12T21:17:20Z,should we swallow ioexception from the destroy() call?,0,0.9922358393669128
127075492,2929,junrao,2017-07-12T21:21:59Z,while load => while loading? ditto in line 292.,0,0.9907920360565186
127077430,2929,junrao,2017-07-12T21:30:38Z,should we call logdirfailurechannel.maybeaddlogfailureevent() on initialofflinedirs? we call logdirfailurechannel.maybeaddlogfailureevent() on log dirs that fail during loading.,0,0.9928775429725647
127078294,2929,junrao,2017-07-12T21:34:25Z,could we log the failed dir too?,0,0.9942591190338135
127078328,2929,junrao,2017-07-12T21:34:34Z,could we log the failed dir too?,0,0.9942591190338135
127084663,2929,junrao,2017-07-12T22:05:32Z,could we log the failed disk dir too?,0,0.9939814209938049
127084683,2929,junrao,2017-07-12T22:05:39Z,could we log the failed disk dir too?,0,0.9939814209938049
127236631,2929,junrao,2017-07-13T14:42:27Z,"should we add ""either""?",0,0.9892560243606567
127238635,2929,junrao,2017-07-13T14:49:02Z,"hmm, it doesn't seems that partition.deleterecordsonleader() can throw kafkastorageexception. it can throw ioexception though.",0,0.9673739075660706
127242028,2929,junrao,2017-07-13T15:00:27Z,perhaps it's simpler to just handle kafkastorageexception here instead of in line 579.,0,0.9796328544616699
127242867,2929,junrao,2017-07-13T15:03:26Z,perhaps it's simpler to just handle kafkastorageexception/ioexception here instead of in line 765?,0,0.9870882034301758
127247023,2929,junrao,2017-07-13T15:17:18Z,"hmm, shouldn't we pass in the isnew flag to the getorcreatereplica() call in line 182 too?",0,0.9821532368659973
127262313,2929,junrao,2017-07-13T16:15:26Z,"once a partition is removed from allpartitions, future produce/fetch request will get an unknowntopicpartitionexception, ideally, it seems that they should get a kafkastorageexception for consistency?",0,0.991826057434082
127267996,2929,junrao,2017-07-13T16:37:56Z,could we adjust the message a bit so that unknown_retriable can be distinguished from unknown? it would also be useful to add a comment on how it should be used differently from unknown.,0,0.9938920736312866
127268535,2929,junrao,2017-07-13T16:40:18Z,"hmm, i thought the plan is for uncaught exceptions still be unknown (i.e., not retriable), but if the server throws a new exception that's retriable, the server will send unknown_retriable to old clients.",0,0.9708923697471619
127270473,2929,junrao,2017-07-13T16:49:09Z,could we add some comment that describe the flow of how disk failure is handled here?,0,0.9940757751464844
127276896,2929,lindong28,2017-07-13T17:16:22Z,"i think it is probably not necessary to call this on initialofflinedirs. the purpose of calling `maybeaddlogfailureevent()` is to cleanup state (e.g. logmanager.logs) and notifying controller. for initialofflinedirs, the no state will be created for replicas in these offline log directories. and the broker hasn't registered itself in the zookeeper yet and thus controller will query this broker for state of all replicas afterwards -- thus no need to notify controller either. on the other hand, if any log directory fails during loading, it is possible that states have been created for some logs that directory but not others. in this case we need to call `maybeaddlogfailureevent()` to clean up the state.",0,0.9788201451301575
127280905,2929,lindong28,2017-07-13T17:32:33Z,"i think it is probably ok to keep the current code. it is true that a log failure may happen right after the check in line 77. in this case the the caller may try to access that log directory that just became offline. however, there is no way to prevent this from happening since it is always possible for a log directory to become offline immediately before (or while) the caller tries to access it. thus caller code always needs to handle the possibility that log directory was removed from the state (e.g. `logmanager.recoverypointcheckpoints`). currently the only regular callers of `livelogdirs()` are those checkpoint routines. the code has handled with e.g. `this.recoverypointcheckpoints.get(dir).foreach(...)` to avoid nullpointerexception. does this make sense?",0,0.8986397385597229
127281494,2929,lindong28,2017-07-13T17:35:08Z,"initially i think it may be more concise to re-use the existing metric name with the additional tag. sure, i will replace this with `islogdirectoroffline`.",0,0.9877859354019165
127282168,2929,lindong28,2017-07-13T17:37:54Z,sorry. it is bad that i forgot to update comment. i have updated it to `create and check validity of the given directories that are not in the given offline directories...` i will go over the patch and see if there are other comments that i should update.,-1,0.9948256015777588
127282599,2929,lindong28,2017-07-13T17:39:43Z,good point. i have updated the code as suggested.,1,0.9777362942695618
127283147,2929,lindong28,2017-07-13T17:41:39Z,thanks. i have fixed the typo now.,1,0.9457679390907288
127284560,2929,lindong28,2017-07-13T17:47:02Z,sure. i have also updated the corresponding comments in all checkpoint*() methods.,0,0.9878069758415222
127284651,2929,lindong28,2017-07-13T17:47:25Z,sure. fixed now.,0,0.9459871053695679
127284798,2929,lindong28,2017-07-13T17:48:01Z,sure. fixed now.,0,0.9459871053695679
127286069,2929,lindong28,2017-07-13T17:53:00Z,sure. fixed now.,0,0.9459871053695679
127289016,2929,lindong28,2017-07-13T18:04:32Z,i think this is ok. `isnew` flag is only matters for local replica. and the local replica of the leader broker must be in the insync replicas set and it will be created properly in line 173. maybe i can add a comment here. or do you like me to refactor the code a bit to call this method with the isnew flag?,0,0.5464333295822144
127291275,2929,lindong28,2017-07-13T18:14:03Z,yes that is the plan and it is actually implemented here. note that `errors.forexception(throwable t)` will return `errors.unknown` if the given exception is not listed in `errors.java`. and `errors.forcode(short code)` will return `errors.unknown_retriable` is the error code is out of the range of existing error codes listed in `errors.java`. our server code is not expected to call `errors.forcode(short code)` with a not-listed error code. the client may call `errors.forcode(short code)` with a not-listed error code if the client library version is smaller than the server library version and the server library has a new error code. in this case we want `errors.forcode(short code)` to return a retriable exception so that producer can re-send the message after metadata update. does this make sense?,0,0.9889965057373047
127294705,2929,lindong28,2017-07-13T18:27:30Z,sorry for the typo. it is removed now.,-1,0.9888155460357666
127300635,2929,lindong28,2017-07-13T18:50:23Z,yes you are right. previously i made a mistake that made me think that `arrayblockingqueue.take()` doesn't unblock after interruption. i have updated this to block infinitely.,0,0.9866683483123779
127301936,2929,lindong28,2017-07-13T18:55:37Z,good catch! you are right. i have updated the code to call `maybeaddlogfailureevent` and return kafkastorageexception if it is ioexception. i also updated the code not to catch kafkastorageexception.,1,0.9960456490516663
127305273,2929,lindong28,2017-07-13T19:08:56Z,sure. i have updated the patch as suggested.,0,0.9880368709564209
127307745,2929,lindong28,2017-07-13T19:20:02Z,sure. i have updated the code as suggested.,0,0.9847109913825989
127361245,2929,lindong28,2017-07-14T00:11:31Z,removed now.,0,0.9922707080841064
127361297,2929,lindong28,2017-07-14T00:12:02Z,fixed now.,0,0.9943431615829468
127376539,2929,lindong28,2017-07-14T03:02:30Z,"sure. i have renamed the variable `unknown` to `unknown_server_error` to distinguish it from `unknown_retriable`. i think it is reasonable because the corresponding exception is `unknownserverexception`. if we want to further differentiate the two, we also rename `unknown_retriable` to be `unknown_client_retriable` and rename `unknownretriableexception` to `unknownclientretriableexception`. what do you think? and i added the following comment for `unknown_retriable`. does that look ok? [code block]",0,0.8726867437362671
127377150,2929,lindong28,2017-07-14T03:10:28Z,sure i added the following comment. does this look ok? [code block],0,0.9868867993354797
127380697,2929,lindong28,2017-07-14T03:56:50Z,"good point. i have updated both the `logmanager.truncateto()` and `logmanager.truncatefullyandstartat()` so that these two method will call `maybeaddlogfailureevent()` and throw a kafkastorageexception if ioexception is caught. this preserves the previous behavior. based on your previous comments, i get that it is a bit ugly in when and where we should catch ioexception or kafkastorageexception. it is also not nice to have code that needs to decide whether we should throw the original kafkastoragexception or encapsulate the original ioexception into a kafkastorageexception. after thinking through this issue, i made the following changes to make the logic cleaner - `logdirfailurechannel` is now passed to the constructor of `log` and `logsegment` so that they can enqueue offline log dir when there is ioexception. - the patch guarantees if `maybeaddlogfailureevent()` is called before a new kafkastorageexception object is instantiated (except for very few scenarios where we know it is not needed). thus we do not need to call `maybeaddlogfailureevent()` when kafkastorageexception is caught. - we only need to call `maybeaddlogfailureevent()` when ioexception is caught. when ioexception is caught, we can either log the error and swallow the exception, or we can throw a new instance of kafkastorageexception so that the outside code can catch it and generate the proper error in the response.",1,0.8581895232200623
127380827,2929,lindong28,2017-07-14T03:58:34Z,actually i find it better to name the new error as unknownerrorcode. i will use it in the updated patch. i also moved the comment to `unknownerrorcodeexception.java`. do you think this name is better?,0,0.9729299545288086
127381549,2929,lindong28,2017-07-14T04:06:25Z,i still keep the code to catch `kafkastorageexception` since it may be useful if the underlying code re-throws kafkastorageexception in the future. it is a safe choice. but we no longer needs to call `maybeaddlogfailureevent` when kafkastorageexception is caught for the reasons explained in the other comment.,0,0.9781967997550964
127410791,2929,lindong28,2017-07-14T08:36:25Z,initially i thought it is ok and simpler to just return `unknowntopicpartitionexception` since the client only cares whether it needs to retry or not. but you are right that it is better and consistent to always return kafkastorageexception if client attempts to access a replica that is on an offline log directory. i have updated the patch with considerable change to achieve this consistency.,0,0.9778892993927002
127411380,2929,lindong28,2017-07-14T08:40:01Z,i added this comment to line 182: `we don't need to specify isnew flag since the local replica would have been created already`,0,0.9947071671485901
127600194,2929,lindong28,2017-07-16T06:53:27Z,"after more thought, i think it simpler to just specify the isnew flag so that future developer doesn't need to think about it. i have updated the patch to do so.",0,0.98633873462677
127772691,2929,junrao,2017-07-17T17:37:25Z,"for code like this, perhaps it's useful to add a comment since it's easy to forget about the original reason over time.",0,0.982094943523407
127794464,2929,junrao,2017-07-17T18:58:46Z,"hmm, now i am wondering if adding unknown_error_code is really a good idea. by adding this, the broker has to consider 3 different types of clients when adding a new retriable error: (1) clients that don't understand unknown_error_code; (2) clients that understand unknown_error_code, but don't understand the new specific error code (e.g., kafka_storage_error); (3) clients that understand the new specific error code. the broker has to send different error codes for those three different cases (1) send an existing retriable error (2) send unknown_error_code; (3) send the specific error code. we have to do this for each type of request that can receive the new error code. an alternative is the following. we don't introduce unknown_error_code. if the broker introduces a new retriable error, we bump up the request protocol. the broker (a) sends an existing retriable error for clients that don't understand the new specific error code; (b) sends the new specific error code otherwise. this seems simpler.",0,0.7981132864952087
127807824,2929,junrao,2017-07-17T19:53:39Z,"if would be useful to double check which requests other than produce/fetch can receive and care about kafka_storage_error. it seems that offsetcommit, offsetforleaderepoch, listoffsets and deleterecords could receive this. not sure if they all care about it though. a few new requests for eos could probably also hit this, which can be addressed in s a separate patch.",0,0.9809114933013916
127811509,2929,junrao,2017-07-17T20:09:05Z,islogdirectoroffline => islogdirectoryoffline,0,0.9889861345291138
127814413,2929,junrao,2017-07-17T20:21:06Z,islogdirectoroffline => islogdirectoryoffline,0,0.9889861345291138
127827127,2929,junrao,2017-07-17T21:12:09Z,the comment seems outdated now.,0,0.9640563130378723
127837300,2929,junrao,2017-07-17T21:59:10Z,"hmm, not sure what the convention is now in handling ioexception at the log/logmanager level. we could (1) turn all ioexception in log to kafkastorageexception and call logdirfailurechannel.maybeaddlogfailureevent(). then, in replicamanager, we don't need to deal with ioexception. (2) let the ioexception for log to bubble to replicamanager and call logdirfailurechannel.maybeaddlogfailureevent() in replicamanager. it seems that the patch does a mix of both (1) and (2). in logmanager.getorcreatelog(), it seems it's possible for an ioexception to be thrown. in log, we are turning all ioexceptions to kafkastorageexception. it seems that it's better to pick either (1) or (2) and do it consistently in all places?",0,0.8850786089897156
127838104,2929,junrao,2017-07-17T22:03:17Z,"hmm, could we get ioexception here? i thought now the convention is to catch all ioexception in the log level and convert it to kafkastorageexception?",0,0.9839022755622864
127842977,2929,junrao,2017-07-17T22:32:36Z,perhaps it's better to use eq (reference equality).,0,0.9807433485984802
127845994,2929,junrao,2017-07-17T22:49:50Z,this seems to break the convention of not calling maybeaddlogfailureevent on kafkastorageexception?,0,0.9896979928016663
127846644,2929,junrao,2017-07-17T22:53:47Z,"hmm, the callers of getlogendoffset() don't seem to expect an exception.",0,0.9551393985748291
127849554,2929,junrao,2017-07-17T23:13:16Z,we don't need to mention producerequest here since it's not an inter broker request.,0,0.9931055903434753
127850607,2929,junrao,2017-07-17T23:20:51Z,should we do this on any ioexception?,0,0.993048906326294
127858289,2929,junrao,2017-07-18T00:21:57Z,"the comment seems inaccurate. we are sending all replicas, not just live replicas in the leaderandisrrequest.",0,0.9439438581466675
127864124,2929,junrao,2017-07-18T01:19:49Z,it would be useful to replace leaderandisrpartitionstate and metadatapartitionstate with partitionstate and updatemetadatarequest.partitionstate. this can be done in a followup cleaning patch.,0,0.9935286641120911
127864321,2929,junrao,2017-07-18T01:22:09Z,unused import timeunit,0,0.9935372471809387
127864547,2929,junrao,2017-07-18T01:24:18Z,"unused imports seq, set.",0,0.9940768480300903
127864941,2929,junrao,2017-07-18T01:28:24Z,it seems that we should check if the notification is of logdirfailureevent in logdireventnotification.process()?,0,0.9924414157867432
127865003,2929,junrao,2017-07-18T01:29:10Z,unused import,0,0.9873000979423523
127865578,2929,junrao,2017-07-18T01:34:27Z,using a null replicamanager to represent an offline partition seems a bit hacky. could we just add a new offline flag in the constructor?,-1,0.5289714336395264
127865966,2929,junrao,2017-07-18T01:38:40Z,could we add a comment that leader_and_isr_response_v1 can receive the new kafkastorage error code?,0,0.9949106574058533
127866463,2929,junrao,2017-07-18T01:44:15Z,check whether is offline log directory => check whether there is offline log directory ?,0,0.9951856732368469
127867135,2929,junrao,2017-07-18T01:52:02Z,"hmm, a couple of thoughts on this. if the broker is still on an old inter-broker protocol, the controller won't be able to handle the failed disk dir event. so, the broker will be up with offline replicas, but new leaders can't be elected. perhaps it's better to just failed the broker in the old way if the inter-broker protocol is old? related to this, i am wondering if it's useful to add a config to turn off this new feature. this way, if there is a bug, the user has the option to switch to the old behavior.",0,0.9421448707580566
127867830,2929,junrao,2017-07-18T01:59:15Z,"in the following line in line 65, shouldn't we set the desired version to 4 if magic is on v2? super(apikeys.produce, (short) (magic == recordbatch.magic_value_v2 ? 3 : 2));",0,0.9952214360237122
127885491,2929,lindong28,2017-07-18T05:32:18Z,"thanks much for the quick review! i think the current approach is probably simpler. the broker only needs to know 2 types of the clients instead of three, i.e. one that knows unknownerrorcodeexception and one that doesn't. if the request of the client suggests that the client knows unknownerrorcodeexception, then the broker will simply send the origin error code. the client library will convert the error to unknownerrorcodeexception if the error code is not recognized. otherwise, the broker should convert the new error code to an existing error code before sending the response. note that we need at most one `if/else` in each response to check whether the client knows unknownerrorcodeexception given the request version. on the other hand, the alternative approach requires kafka to potentially have multiple `if/else` in each response to check whether the clients know each newly-added error code. the number of check will increase overtime as we add more and more new error code. thus the current approach seems simpler. what do you think?",1,0.9926270842552185
127885621,2929,lindong28,2017-07-18T05:33:53Z,ah.. fixed now.,0,0.8422622680664062
127885629,2929,lindong28,2017-07-18T05:34:00Z,fixed now.,0,0.9943431615829468
127886423,2929,lindong28,2017-07-18T05:41:53Z,sure. i added this comment: [code block],0,0.9895377159118652
127889378,2929,lindong28,2017-07-18T06:11:39Z,"yeah had similar comment as well but i find that the patch in its current form is simpler. this is because not all exceptions bubble to the replicamanager. for example, both replicafetchthread and logclean may attempt to truncate the log which doesn't go through replicamanager. and we may have more ioexeption from new methods in the future. thus (2) alone wouldn't work. alternatively we can do (1) only, e.g. find all operations that may cause ioexception, catch/call logdirfailurechannel.maybeaddlogfailureevent() and re-throw a kafkastorageexception. my concern with this approach is that we will need to identify all possible calls that may throw ioexception and make sure that ioexception does not bubble up to replicamanager because otherwise we will return unknownserverexception in the response. this is doable but it requires carefully review of the code which may be error-prone both now and in the future development. on the other hand, if we can catch ioexception in the replicamanager where we generate the error code for various response, we can ensure that if any request handling incurs ioexception, we will trigger `maybeaddlogfailureevent` and return the proper error code. thus the current mixed approach seems simpler and more reliable than the approach (1). does this explanation sound reasonable? while i understand that consistency is a good feature, is there specific benefits of doing (1) only?",0,0.9620792865753174
127890064,2929,lindong28,2017-07-18T06:17:58Z,good point. i fixed all of them.,1,0.987386167049408
127890791,2929,lindong28,2017-07-18T06:24:33Z,"no.. currently i didn't catch/try ioexception for methods like log.append(), logsegment.append() or offsetindex.append(). i feel that kafka' code will be cleaner and more reliable if we can catch ioexception in the methods which handle request and generate response. the only reason not all ioexception are caught in replicamanager or kafkaapi is that we have checkpoint file operation, replicafetcherthread or logcleaner which does io operation without requiring external request.",0,0.9813565015792847
127891075,2929,lindong28,2017-07-18T06:27:02Z,i see. i replaced the comment with this: `mark partition as offline in the cache if the local replica creation has failed due to offline log directory`,0,0.9934093952178955
127891341,2929,lindong28,2017-07-18T06:29:21Z,this is just for code simplicity of not having to duplicate the code of logging error and populating the response map. do you want me to separate them?,0,0.9932087063789368
127892176,2929,lindong28,2017-07-18T06:36:30Z,i think the behavior of throwing the exception is the same as returning none for `groupmetadatamanager`. i am not sure very what is the right behavior for `transactionstatemanager` if the corresponding partition is in offline log directory. previously i think it is reasonable to throw kafkastorageexception if the partition is offline. but i am not strong on this. i have changed it to return none instead.,0,0.9736250042915344
127892430,2929,lindong28,2017-07-18T06:38:32Z,"thanks. i see. i have removed producerequest, fetchrequest and metadatarequest from this comment.",1,0.8892239332199097
127894263,2929,lindong28,2017-07-18T06:51:19Z,"i have thought about catching ioexception here. after reading [a link] i am still not sure why we previously didn't halt the kafka on any ioexception here. there are also some ioexception that are explicitly thrown in this class that do not trigger halt. i couldn't find a reason not to catch ioexception either. i choose to be conservative by preserving the behavior by not doing this on all ioexception just in case we have a reason not to do so. would you like me to do this on any ioexception? alternatively, maybe we can discuss the handling of these specific ioexception in a followup patch?",0,0.9429572224617004
127894415,2929,lindong28,2017-07-18T06:52:19Z,good point. you are right. i removed the `live` here.,1,0.9669684767723083
127894505,2929,lindong28,2017-07-18T06:52:58Z,thanks!! i will do it in a followup patch.,1,0.9939733147621155
127894624,2929,lindong28,2017-07-18T06:53:46Z,ah it somehow escaped from my reviews.. removed now.,0,0.9829229116439819
127894717,2929,lindong28,2017-07-18T06:54:26Z,my bad.. removed now.,-1,0.995307981967926
127896162,2929,lindong28,2017-07-18T07:05:01Z,initially i think it is ok not to check it since there is only one type. it is similar to how we currently have a version field in the reassignment json file provided to `kafka-reassign-partitions.sh` but we currently don't check that version either. but it is also reasonable to check it. i have updated the code to throw illegalargumentexception is the event type value is not 1.,0,0.9282127618789673
127896355,2929,lindong28,2017-07-18T07:06:23Z,not sure why i missed these.. removed now.,0,0.7569012641906738
127897210,2929,lindong28,2017-07-18T07:12:18Z,"initially i wanted to avoid adding complexity to the constructor. sure, i have added isoffline flag to the constructor.",0,0.9865664839744568
127897438,2929,lindong28,2017-07-18T07:13:34Z,sure. i added this: `leaderandisrresponse v1 may receive kafka_storage_error in the response`,0,0.9855652451515198
127897524,2929,lindong28,2017-07-18T07:14:08Z,thanks for catching this. fixed now.,1,0.96614009141922
127898698,2929,lindong28,2017-07-18T07:21:48Z,"as long as the controller and the broker is running new code, the controller will be able to handle the failed disk dir event even if the inter-broker protocol is still old. more specifically, if there is log directory failure, the broker will write a sequential znode in zookeeper, the controller will send leaderandisrrequest, broker will specify error in the response, and the controller will trigger leader election. none of these steps require new inter-broker protocol. does this make sense? i am not sure we should add a config just to take care of the potential bug. ideally we don't want to add a config just for short-term use. the typical way of handling bug is to either hotfix the code or rollback to the last stable version. any kip or big code change may potentially have bug and it seems a big weird to add a config to handle the bug. adding this config is easy since all we need is to tell logdirfailurehandler to halt the broker when there is log directory failure. do you think it is necessary?",0,0.9865484833717346
127899953,2929,lindong28,2017-07-18T07:28:56Z,"no. this is the only improvement in my mind that i haven't made in this patch. i mentioned this in a comment after my last commit yesterday. as of this patch, producer will still send producerequest with version 3 if the message magic value is 2. this is because the newly-added produce version 4 is incompatible with 0.11 broker. as of now our producer determines the request version based on the minimum magic value in the data instead of using the apiversionsrequest to negotiate the this with the broker. this wasn't a problem in the latest kafka but this is causing problem for patches like kip-112 which wants to bump up producrequest version without bumping up the magic value. i don't think this is a critical problem for kip-112 since notleaderforpartitionexception in the response is a reasonable workaround. can i fix this issue in a followup patch later?",0,0.940509557723999
127902927,2929,lindong28,2017-07-18T07:44:43Z,sure. i will go over all existing request and see if they need to handle kafkastorageexception specifically.,0,0.983788013458252
127912013,2929,lindong28,2017-07-18T08:28:42Z,"another way i look at this is that, regardless of what the underlying code does, the outside code, i.e. those methods that determines the response, should catch all exception and determine the error in the response properly. this is similar to why we currently catch `throwable`. it is just that, instead of catching ioexception (as part of the throwable) and return unknownserverexception, it seems more reasonable to call `maybeaddlogdirfailure()` and return kafkastorageexception on ioexception.",0,0.9876742959022522
128041151,2929,junrao,2017-07-18T17:26:57Z,": ok, what you said about the approach in the patch makes sense. i was just wondering if we can achieve the same w/o introducing unknownerrorcode. the alternative that i suggested also just needs 1 if/else check. basically, you bump up the client request protocol, if the client is on the old protocol, the broker sends an existing retriable error code. otherwise, the broker sends the new specific error code. so, the logic is about the same as your patch, but we don't need to introduce unknown_error_code. this seems a bit simpler since we don't have to explain to the client developers the subtle difference btw unknown_error_code and unknown.",0,0.8897469639778137
128042260,2929,junrao,2017-07-18T17:30:51Z,": we don't necessarily have to go purely with (1) or (2). however, it would be useful to have a convention that we can follow in the future. could you summarize that convention? i seems that you are saying that all ioexception for client facing requests (but not inter broker requests) will be turned to kafkastorageexception in the log level?",0,0.9855851531028748
128042285,2929,junrao,2017-07-18T17:30:58Z,"hmm, we do convert ioexception to kafkastroageexception in log.append(), right?",0,0.9778257608413696
128042324,2929,junrao,2017-07-18T17:31:05Z,"fetchrequest is used by inter broker replication. so, we need to include it.",0,0.9949358701705933
128042447,2929,junrao,2017-07-18T17:31:35Z,"in the future, we may need to add new event type. then, when upgrading a broker, the controller may see a new event type that it doesn't understand yet. so, it would be useful for the logic in the controller to be resilient to that.",0,0.9888359904289246
128042652,2929,junrao,2017-07-18T17:32:21Z,"is that true? in controllerchannlemanager, if the inter broker protocol is before 0.11.1, the controller will send v0 of leaderandisrrequest and the response won't have kafkastorageerror, which means that the controller won't be able to move failed replicas to offline?",0,0.993649423122406
128044355,2929,lindong28,2017-07-18T17:38:37Z,"for offsetcommitrequest, i have updated the patch so that server will send `errors.not_coordinator` in the response if there is kafka_storage_error. this is similar to how broker currently converts not_leader_for_partition to not_coordinator when handling offsetcommitrequest. no change on the client side is needed. for offsetforleaderepoch, the server will send kafka_storage_error and the replica fetcher thread will retry if there is error -- it doesn't care which error it is. thus no change is needed. for listoffsets, the server will send kafka_storage_error and the client will convert this error to stalemetadataexception which extends invalidmetadataexception. thus no change is needed.",0,0.9756038784980774
128045320,2929,lindong28,2017-07-18T17:42:24Z,oops.. i added it back.,-1,0.8934034109115601
128048615,2929,lindong28,2017-07-18T17:54:31Z,"hmm.. not sure if i fully understand the alternative approach. let say we introduced two new retriable errors a and b for produceresponse in the future. a is added in version 5 and b is added in version 6. if we have unknown_error_code, then the response handling logic would look like this: [code block] on the other hand, if we don't have unknown_error_code, then the response handling logic would look like this, which increases over time as we have more and more new errors. [code block] thus it seems that unknown_error_code can make things a bit easier. does this make sense?",0,0.5551310181617737
128049363,2929,lindong28,2017-07-18T17:57:19Z,"right, this makes sense.",0,0.9821963310241699
128050930,2929,lindong28,2017-07-18T18:03:02Z,"i still think it is true.. in this case, controller will send leaderandisrrequest v0 which doesn't explicitly specify the isnew flag. the broker will assume isnew = false when it attempts to create the local replica. and if there is log directory fail, then broker either dies (if it is running the old code) or the broker will specify kafkastorageexception in the response (if it is running the new code). then the controller can move failed replicas offline. this works because leaderandisrresponse v0 already allows broker to specify per-partition error code. does this make sense?",0,0.9594679474830627
128057016,2929,lindong28,2017-07-18T18:26:44Z,my bad... i missed this. i have removed this ioexception handling here.,-1,0.994856595993042
128064844,2929,junrao,2017-07-18T18:58:50Z,got it. this is assuming that the new error code is a retriable error. how would the logic compare if the new error code is not retriable?,0,0.942677915096283
128067682,2929,junrao,2017-07-18T19:08:02Z,"got it. i forgot that we don't convert the error code in leaderandisrresponse. then the issue is mostly when you have a mix of brokers with old and new code. if the controller happens to be on the broker with the old code, it wouldn't react to disk failure events until the controller is upgraded. in a larger cluster, rolling upgrade could take some time and leaving the offline replicas unprocessed for long is probably not ideal. if we only apply the new logic when the inter.broker protocol is 0.11.1, then the above issue can be addressed since at that point, we expect every broker to be on the new code. a minor related issue is that the offlinereplicas won't be propagated properly until the controller's inter broker protocol is on 0.11.1. this will affect the metadata response. not sure if we can avoid this completely. it would be useful to at least document this.",0,0.8686313033103943
128076192,2929,lindong28,2017-07-18T19:45:28Z,"if the new error is not retriable, then the client will convert the unknown error code to unknownserverexception which is non-retriable. i think it is a reasonable solution before the client library is upgraded.",0,0.979670524597168
128076999,2929,lindong28,2017-07-18T19:48:56Z,both are good points. i will update the logdirfailurehandler so that it will halt the broker if the inter broker protocol is before 0.11.1.,1,0.9715754985809326
128078560,2929,lindong28,2017-07-18T19:55:33Z,"my previous convention is that: 1) ioexception should maybeaddlogdirfailureevent. 2) ioexception should either be logged or be re-thrown as kafkastorageexception. 3) kafkastorageexception should not trigger maybeaddlogdirfailureevent. previously i feel it is simpler to catch ioexception in the replicamanager similar to how we handle most other exceptions that happen during request processing. and i intend to avoid adding big try/catch because it typically makes code review harder. now i agree with you that it is a good idea to keep it consistent and try to catch ioexception before the replicamanager. i have updated the patch so that the replicamanger no longer needs to catch ioexception at all. ioexception is now caught in e.g. log, logmanager and checkpointfile. these ioexception will trigger maybeaddlogdirfailureevent() and be re-thrown as kafkstorageexception. i think this address the issue here.",0,0.9595596790313721
128079255,2929,lindong28,2017-07-18T19:58:32Z,i have updated the code so that replicamanager no longer needs to catch ioexception at all including here.,0,0.9938501119613647
128082294,2929,lindong28,2017-07-18T20:12:18Z,"i don't know why we don't halt the server on ioexception when reading or writing the checkpoint file. anyway, i have updated the patch to catch ioexception when reading/writing the checkpoint file, call maybeaddlogdirfailureevent(), and re-throw a kafkastorageexception. thus this issue is also addressed.",0,0.9857306480407715
128097699,2929,lindong28,2017-07-18T21:14:51Z,"ah, i probably misunderstood your previous question. if the new error code is non-retriable and client library already knows unknownerrorcodeexception, then the client library will treat the new error as a retraible error. it means that client may retry unnecessarily instead of failing fast. i think this is ok and better than having client failing immediately when it should retry.",1,0.77024906873703
128097968,2929,junrao,2017-07-18T21:15:58Z,"hmm, if a new error is not retriable, the server code will probably look like the following. [code block] so, you don't really save code if the new error is not retriable. another thing that bothers me a bit is that the logic for handling a retriable error is a bit different from that for handing a non-retriable error. in the alternative approach, at least any new error code is handled in the same way.",-1,0.6938844919204712
128106111,2929,lindong28,2017-07-18T21:53:32Z,"my use-case for unknownerrorcodeexception is based on the assumption that it is always ok for client to retry. the client should always have a reasonable timeout setting if it retries. thus if the original error is non-retriable, the client will block unnecessarily up to that timeout which is not that bad. also, for requests that don't want to retry on unknown error code, we can always update its response handling logic to skip retry if error == unknownerrorcodeexception. does this sound reasonable? if not, then i think we will have to add specific if/else for potentially a few requests for every new error in the future. i can remove the unknownerrorcodeexception if you prefer not to make the decision in this patch.",0,0.9541229605674744
128109393,2929,junrao,2017-07-18T22:10:42Z,the issue with retrying on any unknown error is that an app (e.g. mirrormaker) could set the retry to infinite and then it won't be aware of the error. adding a new if/else statement for every new error code is not necessary bad as long as the process is clear. adding unknownerrorcodeexception seems more complicated to me at this moment. perhaps we could remove it and reconsider it later if there is a need.,0,0.9091172218322754
128110294,2929,junrao,2017-07-18T22:14:52Z,"thanks. discussed this a bit with jason. it seems that we probably need to extend the current desired version logic to support the possibility of having multiple versions on the same magic (perhaps having a desired version range). so, we can do this in a followup jira. if you ping jason on that jira, he can help you with some suggestions.",1,0.9686340093612671
128133249,2929,lindong28,2017-07-19T01:13:44Z,"sure! after this pull request is closed, i will create tickets for all the todos mentioned in the discussion of this pull request. i will ping you and json for review later.",1,0.9573343992233276
128133400,2929,lindong28,2017-07-19T01:15:19Z,sure. i have removed the unknownerrorcodeexception in the latest patch.,0,0.9861552119255066
128367026,2929,junrao,2017-07-19T21:05:50Z,"islogdirectoryoffline => logdirectoryoffline ? the latter seems more consistent with underreplicated in partition. if we change the name, make sure that we change it consistently in the place where the metric is removed as well.",0,0.9856606721878052
128371038,2929,junrao,2017-07-19T21:22:57Z,should we catch ioexception in fetchoffsetsbytimestamp() in line 1041 too?,0,0.994022786617279
128376413,2929,junrao,2017-07-19T21:47:24Z,since all accesses to logsegment are through log/logcleaner/logmanager/logcleanermanager. perhaps we can just catch ioexceptions in those places instead of here?,0,0.99033522605896
128390730,2929,junrao,2017-07-19T23:09:30Z,cleanup => clean up,0,0.9174671769142151
128396923,2929,junrao,2017-07-19T23:55:28Z,use exit.halt() to be consistent with what's in replicamanager?,0,0.9951282739639282
128397663,2929,junrao,2017-07-20T00:01:48Z,do we still need to call maybeaddlogfailureevent() on kafkastorageexception?,0,0.9943907856941223
128397699,2929,junrao,2017-07-20T00:02:13Z,do we still need to call maybeaddlogfailureevent() on kafkastorageexception?,0,0.9943907856941223
128399202,2929,junrao,2017-07-20T00:14:21Z,could we add some comment at the beginning of the class on the process of adding a new server side exception going forward?,0,0.9945971965789795
128400026,2929,junrao,2017-07-20T00:21:10Z,ioexception is unused now.,0,0.9918277263641357
128401597,2929,junrao,2017-07-20T00:35:49Z,unused import,0,0.9873000979423523
128404639,2929,junrao,2017-07-20T01:01:30Z,poll(0) => poll(10) to prevent busy loop?,0,0.991095781326294
128404788,2929,junrao,2017-07-20T01:02:40Z,poll(0) => poll(10) to prevent busy loop?,0,0.991095781326294
128542365,2929,junrao,2017-07-20T15:06:26Z,the comment seems inaccurate now.,0,0.8769593238830566
128542947,2929,junrao,2017-07-20T15:08:22Z,could we just set the file to be unreadable and unwritable?,0,0.9888280630111694
128543296,2929,junrao,2017-07-20T15:09:22Z,should we assert the consumer sees at least 2 messages?,0,0.9906176924705505
128544125,2929,junrao,2017-07-20T15:12:14Z,"perhaps it's also useful to assert that logdireventnotificationpath is empty eventually. it may also be useful to verify the replica state for that replica in the controller is in offline state,",0,0.9926683306694031
128548154,2929,junrao,2017-07-20T15:25:34Z,perhaps it's better to use kafkaconfig.logdirsprop,0,0.9889111518859863
128550482,2929,junrao,2017-07-20T15:33:47Z,"to make this more robust, perhaps we need to disable the periodic metadata fresh in the producer?",0,0.9915418028831482
128551469,2929,junrao,2017-07-20T15:37:33Z,is sudo really needed?,0,0.9889320135116577
128552122,2929,junrao,2017-07-20T15:39:46Z,"this is for isr, not leader replica.",0,0.9931748509407043
128552194,2929,junrao,2017-07-20T15:40:00Z,leader => isr,0,0.9907859563827515
128559280,2929,junrao,2017-07-20T16:04:02Z,"""leader node"" doesn't cover the case when broker_type is follower.",0,0.9895464777946472
128559453,2929,junrao,2017-07-20T16:04:45Z,is sudo needed?,0,0.9949067234992981
128560468,2929,junrao,2017-07-20T16:08:41Z,is the test from line 161 to 174 necessary? it doesn't seem to be directly related to offline disks.,0,0.9873479604721069
128560625,2929,junrao,2017-07-20T16:09:19Z,topic2 actually has min.isr of 1.,0,0.9930452704429626
128561993,2929,junrao,2017-07-20T16:14:33Z,why is time-based log rolling needed here?,0,0.9910261034965515
128582900,2929,lindong28,2017-07-20T17:38:37Z,yeah.. i also prefer `logdirectoryoffline`. i changed it to `islogdirectoryoffline` because i didn't have a good reason not to use `islogdirectoryoffline` when asked previously. i have updated the patch to use `logdirectoryoffline`.,0,0.9759650826454163
128583248,2929,lindong28,2017-07-20T17:40:11Z,good catch. it is fixed now.,1,0.9943035840988159
128632191,2929,lindong28,2017-07-20T21:12:23Z,"you are right. i missed this.. i should have gone over all methods in log.scala. i just went over all the methods in log.java and made sure the following rule is satisfied for any method in this class: 1) if the method is used during log load phase, which should only happen before the broker registers itself in the zookeeper, this method doesn't have to convert ioexception to kafkastorageexception. 2) otherwise, if the method in incurs i/o operation and may be called by other classes after broker has registered itself (excluding shutdown()), this method should catch ioexception, add it to log dir failure channel, and re-throw kafkastorageexception 3) otherwise, the method either doesn't throw ioexception, or it is only called by internal methods in log that belong to one of the two above categories, we don't need to catch ioexception in this method. i still keep an unnecessary conversion from ioexception to kafkastorageexception in `log.roll()`. it is unnecessary because it is currently only called by methods in log.scala that will catch ioexception. i still keep it there since it is a public method and may be used in the future. it is a bit tedious to go over all method and make sure ioexception is caught `iff` it is needed. so i choose to lean towards over-catch it in log.scala. i can remove it if needed. i also added the comment `we don't convert ioexception to kafkastorageexception in this method because this method may be called before all logs are loaded` to some methods in log.scala so that future develop can be aware of this.",1,0.63164222240448
128634615,2929,lindong28,2017-07-20T21:24:12Z,good point. i have updated the code to the following with an extra comment. i think we don't have to catch ioexception for logging purpose here because the ioexception should specify the file name and be caught and logged by the caller. [code block],1,0.9535771012306213
128634780,2929,lindong28,2017-07-20T21:25:03Z,thanks for catching this. it is fixed now.,1,0.9730858206748962
128634986,2929,lindong28,2017-07-20T21:26:03Z,clearly i didn't review the patch careful enough.. sorry. it is fixed.,-1,0.9948659539222717
128635061,2929,lindong28,2017-07-20T21:26:24Z,i should have noticed this.. it is fixed now.,0,0.6093457937240601
128639223,2929,lindong28,2017-07-20T21:48:19Z,good point. i added the following comment: [code block] i also added the following comment in `kafkastorageexception.java`: [code block],1,0.979435920715332
128639576,2929,lindong28,2017-07-20T21:50:21Z,ah.. i just realized that i can not rely on intellij to show the unused import in gray color. it is fixed now.,0,0.5794672966003418
128639643,2929,lindong28,2017-07-20T21:50:52Z,it is fixed now... i need to be more careful.,0,0.7638682723045349
128640385,2929,lindong28,2017-07-20T21:54:56Z,i missed this. it is fixed now.,0,0.6575877070426941
128644708,2929,lindong28,2017-07-20T22:20:45Z,"i just tested it by setting the file to be unwritable. the testproduceafterlogdirfailure() with pass. however, `kafkaservertestharness.teardown()` will fail with `java.nio.file.accessdeniedexception` because it is not able to delete the log directory. it is possible to swallow the exception so that the test will pass. but that the temporary log directory will not be removed after the test and will accumulate over time on the test server. according to the information provided below, it seems that the log directory can only be removed with sudo access if it is set to be unwritable. thus it seems simpler to just use the current approach by replacing the log directory with a file. [code block]",0,0.9862960577011108
128644975,2929,lindong28,2017-07-20T22:22:24Z,i think it is not necessary to use poll(10). `waituntiltrue()` will sleep for 100 ms before trying to poll() again.,0,0.9894533157348633
128646300,2929,lindong28,2017-07-20T22:31:01Z,"are you suggesting to set `retry.backoff.ms` to long_max when we create the producer? i am not sure we should do that because we need metadata to be refresh after producer sees kafkastorageexceptoin in the produceresponse, so that we can verify that producer can produce message after leadership is moved by controller. actually i intentionally set the `retry.backoff.ms` to 100 ms so that the producer can refresh the metadata almost immediately after it sees kafkastorageexception in the response. `metadata.max.age.ms` is 5 minutes by default which should be longer than the time needed for this test. thus it seems that the test is already robust since producer should not automatically refresh metadata unless it sees exception in the produceresposne. does it sound reasonable?",0,0.9842766523361206
128652090,2929,lindong28,2017-07-20T23:11:14Z,i don't think we should.. the first message sent by the first produce has already been consumed by the first call of `poll()`. this is the second call of `poll()` and it is possible to consume only one message.,0,0.9732022285461426
128652222,2929,lindong28,2017-07-20T23:12:32Z,it is probably not necessary because `waituntiltrue()` will sleep for 100 ms before trying to poll() again.,0,0.9880527257919312
128654104,2929,lindong28,2017-07-20T23:26:38Z,good point. i have updated the test to assert both requirements.,1,0.976839005947113
128654285,2929,lindong28,2017-07-20T23:28:06Z,good point. i have updated the patch to use `kafkaconfig.logdirsprop`.,1,0.9786908626556396
128654830,2929,lindong28,2017-07-20T23:32:08Z,my bad. i have fixed this.,-1,0.9959768652915955
128654940,2929,lindong28,2017-07-20T23:33:03Z,thanks. it is fixed now.,1,0.9730711579322815
128655255,2929,lindong28,2017-07-20T23:36:10Z,"is this because after the broker has opened the file handler for a log segment, it can continue read/write to the log segment even after the log directory is removed or marked as unreadable. i set the log rolling to 3 sec so that the broker will need to create new log segment every 3 seconds. then the server will be able to discover log directory failure when it attempts to create file for a new log segment.",0,0.9902994632720947
128655516,2929,lindong28,2017-07-20T23:38:25Z,"thanks. i added a line that says ""and another topic with partitions=3, replication-factor=3, and min.insync.replicas=1""",1,0.966057300567627
128655798,2929,lindong28,2017-07-20T23:40:34Z,my bad.. i have updated it to say `broker %d should be in isr set`,-1,0.9951227307319641
128656024,2929,lindong28,2017-07-20T23:42:30Z,i think it may be useful. this is needed to verify that the broker can still server replicas on the good disks even if it has bad disks.,1,0.5182008743286133
128659071,2929,junrao,2017-07-21T00:08:19Z,i was referring to metadata.max.age.ms. we can leave it as it is since metadata.max.age.ms is 5 minutes by default.,0,0.9920033812522888
128659130,2929,junrao,2017-07-21T00:08:49Z,could we add a comment for that?,0,0.9951646327972412
128661501,2929,lindong28,2017-07-21T00:32:22Z,"in particular, i made the following code changes: 1) catch ioexception in log.fetchoffsetsbytimestamp() 2) catch ioexception in log.deletesegments() 3) catch ioexception in log.flush() 4) catch ioexception in log.delete() 5) catch ioexception in log.truncateto() 6) catch ioexception in log.truncatefullyandstartat() 7) catch ioexception in log.asyncdeletesegment() 8) removed ioexception catch code in logmanager.truncateto() 9) removed ioexception catch code in logmanager.truncatefullyandstartat() 10) removed ioexception catch code in logmanager.deletelogs() 11) removed ioexception catch code in logsegment.changefilesuffixes() 12) removed ioexception catch code in logsegment.delete()",0,0.9932782053947449
128676856,2929,lindong28,2017-07-21T03:21:13Z,yes.. i think it is needed. below is the error if this command is executed without sudo. [code block] i also tried to execute the command with and without sudo by logging into the vagrant node. here is what i found: [code block],0,0.9838722348213196
128677507,2929,lindong28,2017-07-21T03:29:19Z,ah... i realized that i can work without `sudo`. the `chmod a-rw /mnt/kafka-data-logs-1/ -r` can actually change the permission of this log directory. but it still returned error probably because this command attempts to read information of this log directory after it takes effect. i am able to avoid sudo by replacing the command with `chmod a-w /mnt/kafka-data-logs-2/ -r`.,0,0.8711182475090027
128678929,2929,lindong28,2017-07-21T03:48:41Z,sure. i added the following comment: [code block],0,0.9907938838005066
128679135,2929,lindong28,2017-07-21T03:51:24Z,yes. the sudo is needed in order to delete an unwritable log directory.,0,0.9936397671699524
128679816,2929,lindong28,2017-07-21T04:01:28Z,never mind.. i originally used `offlinelogdirectorycount` instead of the `logdirectoryoffline`. thanks for the suggestion!,1,0.9800296425819397
128680876,2929,lindong28,2017-07-21T04:16:46Z,i updated the code to use `kafkaconfig.logdirsprop` only if the dir count > 1. this is because some tests such as offsetcommittest.scala assumes that there is only one log directory and the will fetch the log directory based on `log.dir`. it seems simpler to keep these tests and only update the `testutils.createbrokerconfig()` to fill in the property based on the directory number. [code block],0,0.9933372735977173
128804228,2929,junrao,2017-07-21T16:26:51Z,"could we just use the existing def replicasinstate(topic: string, state: replicastate)?",0,0.9947798252105713
128805708,2929,junrao,2017-07-21T16:34:35Z,"this method is actually called in places after log loading. but in all other places, ioexceptions are handled by the callers. perhaps we can adjust the comment a bit.",0,0.9939771890640259
128806377,2929,junrao,2017-07-21T16:37:50Z,"ditto as the above since it can be called after loading. also, we should change ?",0,0.9950439929962158
128806610,2929,junrao,2017-07-21T16:39:12Z,ditto as the above since it can be called after loading.,0,0.9939284324645996
128807592,2929,junrao,2017-07-21T16:44:48Z,it seems that logdirfailurechannel can be removed now.,0,0.9923345446586609
128818124,2929,lindong28,2017-07-21T17:36:06Z,i missed this. thanks for catching this. it is fixed now.,1,0.9920680522918701
128818202,2929,lindong28,2017-07-21T17:36:29Z,sure. i have removed this method.,0,0.9915624260902405
128818227,2929,lindong28,2017-07-21T17:36:36Z,it is fixed now.,0,0.9371016621589661
128818243,2929,lindong28,2017-07-21T17:36:41Z,sure. it is fixed now.,0,0.7552802562713623
128818272,2929,lindong28,2017-07-21T17:36:46Z,it is fixed now.,0,0.9371016621589661
128828324,2929,becketqin,2017-07-21T18:19:52Z,we also added producerequest v4.,0,0.9960289001464844
128828858,2929,lindong28,2017-07-21T18:22:05Z,remove logdirfailurechannel from cleaner.,0,0.9929511547088623
128833298,2929,becketqin,2017-07-21T18:40:41Z,"not sure if this is in kip-113, but we should probably also consider assigning the partitions based on the actual logdir size instead/in addition to the number of partitions. we can have a follow up patch for this.",0,0.9819438457489014
128850166,2929,becketqin,2017-07-21T20:04:24Z,nit: onreplicabecomeoffline -> onreplicasbecomeoffline,0,0.9864047765731812
128850247,2929,becketqin,2017-07-21T20:04:43Z,effected -> affected,0,0.8500952124595642
128851186,2929,lindong28,2017-07-21T20:10:01Z,i will add code to catch and handle ioexception in `locklogdirs()`,0,0.9949807524681091
128887429,2929,becketqin,2017-07-22T02:49:22Z,there are a lot of similar try/catch logic in this class. maybe we can group them into a lambda like we did for inlock.,0,0.9861381649971008
128889008,2929,becketqin,2017-07-22T04:30:34Z,"in groupcoordinator and txncoordinator, we load the state using filerecords.readinto() and if ioexception occurs, currently we log it and let it go. i am not sure if this has been discussed before, but should we notify controller to reelect leader in this case? it does not have to be in this patch. we can do it separately. let's see what say.",0,0.9918751120567322
128889452,2929,becketqin,2017-07-22T04:50:50Z,can we add a comment explaining the logic here? i was confused first time see this logic.,-1,0.6170613169670105
128889819,2929,lindong28,2017-07-22T05:17:13Z,i am not sure whether we should add comment regarding the producerequest. said earlier that we only need to add comments regarding requested used between brokers. i guess we can do this in the other followup patch if needed.,0,0.8939849138259888
128889832,2929,lindong28,2017-07-22T05:18:33Z,yeah i think it is useful. it is probably better to do it in kip-113 so that we can finish this kip sooner :),1,0.9895231127738953
128889837,2929,lindong28,2017-07-22T05:18:53Z,thanks! fixed now.,1,0.9920086860656738
128889858,2929,lindong28,2017-07-22T05:19:33Z,sure. fixed now.,0,0.9459871053695679
128889862,2929,lindong28,2017-07-22T05:19:48Z,good point. it is fixed now.,1,0.9894931316375732
128889977,2929,lindong28,2017-07-22T05:27:59Z,"i think both groupcoordinator and txncoordinator will access log directory via methods in log, e.g. `log.read` in `groupmetadatamanager.loadgroupsandoffsets()`. thus ioexception will be caught and trigger `maybeaddlogfailureevent()`. i think this handling of ioexception is good enough for `groupcoordinator`. if this handling of ioexception is not good enough for `txncoordinator`, it is probably an existing problem and needs feedback from the developers who are more knowledgeable in transaction related logic. yeah let's do it in a followup patch if any fix is need for `txncoordinator`.",0,0.8827055096626282
128889980,2929,lindong28,2017-07-22T05:28:20Z,fixed now.,0,0.9943431615829468
128890112,2929,lindong28,2017-07-22T05:36:58Z,sure. i have updated the comment to clarify this better.,0,0.9887493848800659
128903577,2929,becketqin,2017-07-22T19:37:47Z,would it be better to put this method into coreutils?,0,0.9921596646308899
128903738,2929,lindong28,2017-07-22T19:45:05Z,i have thought about this. we can do it if we add another 1-2 parameters to this method. this is because both the object `logdirfailurechannel` and `dir` in the body of `maybehandleioexception` belong to `log`. thus the `maybehandleioexception()` in its current form can not be static. it seems to me that the code is simpler by putting it only in log. we can move it to coreutils with the extra parameter if you think that is better.,0,0.9709330201148987
452397898,9001,kowshik,2020-07-09T18:05:44Z,add doc,0,0.9940147995948792
452397966,9001,kowshik,2020-07-09T18:05:50Z,add doc,0,0.9940147995948792
452398154,9001,kowshik,2020-07-09T18:06:14Z,add doc,0,0.9940147995948792
452398464,9001,kowshik,2020-07-09T18:06:49Z,remove word 'should',0,0.9896913170814514
452399744,9001,kowshik,2020-07-09T18:09:17Z,add doc to entire class,0,0.9939608573913574
452400240,9001,kowshik,2020-07-09T18:10:10Z,add doc to entire class,0,0.9939608573913574
452400376,9001,kowshik,2020-07-09T18:10:27Z,attributes can be final,0,0.993846595287323
452401987,9001,kowshik,2020-07-09T18:13:20Z,1. add test code in `kafkaadminclienttest` 2. final variable names,0,0.9942259192466736
452402127,9001,kowshik,2020-07-09T18:13:36Z,add test code in `kafkaadminclienttest`,0,0.9952390193939209
452403561,9001,kowshik,2020-07-09T18:16:13Z,1 line gap before `cal`,0,0.99402916431427
452406393,9001,kowshik,2020-07-09T18:21:18Z,eliminate and use invalid_request,0,0.9918964505195618
452406721,9001,kowshik,2020-07-09T18:21:49Z,eliminate and use invalid_request,0,0.9918964505195618
452407219,9001,kowshik,2020-07-09T18:22:42Z,"space between "","" and ""key""",0,0.9910039901733398
452407255,9001,kowshik,2020-07-09T18:22:46Z,final,0,0.9173561930656433
452407329,9001,kowshik,2020-07-09T18:22:56Z,final,0,0.9173561930656433
452408614,9001,kowshik,2020-07-09T18:25:15Z,make variables final throught class add doc,0,0.9953967928886414
452410015,9001,kowshik,2020-07-09T18:27:45Z,fix apikeys,0,0.9476253390312195
452410620,9001,kowshik,2020-07-09T18:28:54Z,eliminate timeout?,0,0.9846003651618958
452413347,9001,kowshik,2020-07-09T18:34:02Z,add doc and explain various cases,0,0.9944289922714233
452413777,9001,kowshik,2020-07-09T18:34:54Z,call the variable as `nodecontents` ?,0,0.994759738445282
452418487,9001,kowshik,2020-07-09T18:44:00Z,perhaps add info about newfeatures and incompatiblebrokers.,0,0.990025520324707
452418679,9001,kowshik,2020-07-09T18:44:24Z,can improve by splitting into few lines,0,0.9919915795326233
452426595,9001,kowshik,2020-07-09T18:59:05Z,check braces (),0,0.993847668170929
452428079,9001,kowshik,2020-07-09T19:01:44Z,s/supported/supportedfeatures same for other one,0,0.9809914231300354
452428293,9001,kowshik,2020-07-09T19:02:07Z,"say ""if there are any feature incompatibilities found.""",0,0.9880557060241699
452428858,9001,kowshik,2020-07-09T19:03:22Z,add unit test add doc,0,0.9936203360557556
452432658,9001,kowshik,2020-07-09T19:10:56Z,shouldn't the code be waiting here?,0,0.9882699251174927
452435772,9001,kowshik,2020-07-09T19:16:57Z,add doc,0,0.9940147995948792
452435913,9001,kowshik,2020-07-09T19:17:15Z,remove these 2 lines,0,0.9921969175338745
452436233,9001,kowshik,2020-07-09T19:17:41Z,revert the file eventually,0,0.99261075258255
453842949,9001,abbccdda,2020-07-13T18:21:40Z,nit: get a ` { updatefinalizedfeaturesresult}` as well,0,0.9952344298362732
456123467,9001,abbccdda,2020-07-16T22:57:10Z,s/`as input a set of finalizedfeatureupdate`/`in a set of feature updates`,0,0.9872435927391052
456124708,9001,abbccdda,2020-07-16T23:00:50Z,"for the entire sentence, i assume you want to say something like [code block]",0,0.9865623116493225
456125212,9001,abbccdda,2020-07-16T23:02:31Z,"looking at `updatefinalizedfeaturesresult`, we don't have a per feature based error code returned. if this is the case, how could we know which feature is missing?",0,0.9915581941604614
456126450,9001,abbccdda,2020-07-16T23:06:05Z,"we should suggest in what circumstances a user may require sending the request directly to the controller, to me if there is a case where user wants stronger consistency.",0,0.9934034943580627
456150664,9001,abbccdda,2020-07-17T00:25:56Z,we should consider using optional for `finalizedfeaturesepoch` to indicate absence.,0,0.9941348433494568
456151287,9001,abbccdda,2020-07-17T00:27:57Z,"nit: one parameter each line, with the first parameter on the same line as constructor name.",0,0.9931045174598694
456151476,9001,abbccdda,2020-07-17T00:28:41Z,nit: seems not necessary,0,0.9905933737754822
456151635,9001,abbccdda,2020-07-17T00:29:16Z,`false otherwise` doesn't provide too much useful info.,0,0.9024901390075684
456603010,9001,abbccdda,2020-07-17T18:20:41Z,nit: we could just `return new updatefinalizedfeaturesrequestdata().setfinalizedfeatureupdates(items)`,0,0.9940341114997864
456849186,9001,abbccdda,2020-07-19T02:19:21Z,missing header,0,0.985005259513855
456855815,9001,abbccdda,2020-07-19T04:00:54Z,nit: put first parameter on this line.,0,0.9935683608055115
456855941,9001,abbccdda,2020-07-19T04:02:52Z,"the definition seems not aligned with the kip which states `updatefeatures`, do you think it's necessary to mention `finalized` in all the function signatures?",0,0.9919044375419617
456857080,9001,abbccdda,2020-07-19T04:19:26Z,"it looks weird to complete `callvialeastloadednode` in a controller response handler. i'm inclined to increase a bit on the code duplication, based on `if (options.sendrequesttocontroller())` to have two separate request traces like: [code block] and try to complete the same future.",-1,0.9842148423194885
456857730,9001,abbccdda,2020-07-19T04:29:50Z,"would be good to redundantly copy over the expected error codes from `admin.java` definition, similar to other response class such as `offsetcommitresponse`",0,0.9941006302833557
456858439,9001,abbccdda,2020-07-19T04:39:21Z,seems not necessary to have this helper as it doesn't reduce the code length.,0,0.9882004261016846
456858741,9001,abbccdda,2020-07-19T04:42:42Z,space,0,0.7991176247596741
456859001,9001,abbccdda,2020-07-19T04:45:45Z,"this is a bit unique, since we should commonly rely on the error code to propagate information instead of a message which has unbounded size. could you explain why we couldn't simply re-invent a new error code if existing ones are not sufficient?",0,0.9834817051887512
456859342,9001,abbccdda,2020-07-19T04:50:52Z,"we don't need to include the same error information twice, as the client side will recognize anyway.",0,0.9903401732444763
456859761,9001,abbccdda,2020-07-19T04:56:54Z,access should be private,0,0.9925642609596252
456859864,9001,abbccdda,2020-07-19T04:58:05Z,nit: the comment seems unnecessary on l3011,0,0.990542471408844
456859960,9001,abbccdda,2020-07-19T04:58:51Z,"commonly in scala we try to avoid using return, consider using `if-else` instead.",0,0.9866930842399597
456860187,9001,abbccdda,2020-07-19T05:01:31Z,`setting the allowdowngrade flag to true in the request`,0,0.9947668313980103
456862645,9001,abbccdda,2020-07-19T05:31:43Z,`apikeys.update_finalized_features api`,0,0.9951933026313782
456862745,9001,abbccdda,2020-07-19T05:33:11Z,we only need to mark testing only comment on the functions,0,0.9949055910110474
456863153,9001,abbccdda,2020-07-19T05:38:15Z,nit: mark the parameter as `logincompatibilities = true)`,0,0.9955759048461914
456863287,9001,abbccdda,2020-07-19T05:39:58Z,redundant {},-1,0.7091019749641418
456863554,9001,abbccdda,2020-07-19T05:42:50Z,redundant {},-1,0.7091019749641418
456863914,9001,abbccdda,2020-07-19T05:48:12Z,do we need this precision of exact wait time? could we just track the function start time and compare with current system time for expiration?,0,0.9899688363075256
456931477,9001,abbccdda,2020-07-19T17:03:30Z,"`for a new kafka cluster (i.e. it is deployed first time), we would like to start the cluster with all the possible supported features finalized immediately.` i think this comment is hard to understand if reader has zero context on the feature versioning. it would be good to include a short explanation on what does a `supported feature` mean, and what it means to be `finalized`. `the new cluster will almost never be started with an old ibp config thats less than kafka_2_7_iv0.` this sentence is positioned awkwardly. i would suggest we just propose `as a new cluster starting with ibp setting equal to or greater than kafka_2_7_iv0`",-1,0.6355961561203003
456931559,9001,abbccdda,2020-07-19T17:04:23Z,"`then here is how we it` could be removed: `assuming this is the case, then the controller...`",0,0.9928828477859497
456932817,9001,abbccdda,2020-07-19T17:17:40Z,"maybe a newbie question here: since the `supportedfeatures` could be mutated, why couldn't we just assume its min level marks the `defaultfeatureminversionlevels`? trying to understand the necessity for secondary bookkeeping. might be good to also put reasonings in the meta comment as well to clear confusion.",0,0.9770070314407349
456934831,9001,abbccdda,2020-07-19T17:38:27Z,"if this is broker required feature set, i feel we could name it something like `brokerrequiredversionrange`. `updated` sounds a bit blur for reader, as it couldn't infer the subject.",0,0.9743446111679077
456935073,9001,abbccdda,2020-07-19T17:40:37Z,what about the case where `existingversionrange.min() > updatedversionrange.max()` is true? for example: [code block] are we enabling version 3 as well?,0,0.9942873120307922
457072387,9001,abbccdda,2020-07-20T05:46:02Z,"is it ok for us to always do `updatefeatureznode`, since this call is idempotent?",0,0.9943585991859436
457075484,9001,abbccdda,2020-07-20T05:52:11Z,could the receiving broker analyze the request and decide to shut down itself? what's the gain we have by avoiding sending update metadata to incompatible brokers?,0,0.99085932970047
457076040,9001,abbccdda,2020-07-20T05:53:19Z,replace with `nonempty`,0,0.9939404726028442
457076787,9001,abbccdda,2020-07-20T05:54:49Z,"could we avoid blocking controller processing here, by putting the callback into a delayed queue or sth?",0,0.9922577142715454
457077246,9001,abbccdda,2020-07-20T05:55:46Z,`incompatiblefeatures`?,0,0.9911484718322754
457077954,9001,abbccdda,2020-07-20T05:57:18Z,"nit: i have seen that we use both `map{` and `map {`, could we try using only one format consistently within the current file?",0,0.9919517040252686
457802220,9001,kowshik,2020-07-21T02:40:49Z,done. updated the doc now.,0,0.9863505959510803
457806176,9001,kowshik,2020-07-21T02:56:06Z,done.,0,0.9897913336753845
457806399,9001,kowshik,2020-07-21T02:57:00Z,done.,0,0.9897913336753845
457806541,9001,kowshik,2020-07-21T02:57:43Z,"to your point, this information is available in the error message returned in the response. the feature updates are atomically applied to zk by the controller i.e it is all or none. we don't have a use case (yet) where we have to programmatically learn which feature updates are incorrect. instead an error message with details seems sufficient to us. please let me know how you feel about it, and if you feel that we are better off in returning per-feature-update error code. this was discussed in the [a link], search for the word ""transaction"".",0,0.869525671005249
457808548,9001,kowshik,2020-07-21T03:06:14Z,done.,0,0.9897913336753845
457809543,9001,kowshik,2020-07-21T03:10:05Z,done.,0,0.9897913336753845
457812340,9001,kowshik,2020-07-21T03:19:53Z,done. good point.,1,0.9824387431144714
457812690,9001,kowshik,2020-07-21T03:21:00Z,done.,0,0.9897913336753845
457812867,9001,kowshik,2020-07-21T03:21:44Z,done. removed.,0,0.9905270338058472
457813021,9001,kowshik,2020-07-21T03:22:17Z,done. removed.,0,0.9905270338058472
457813152,9001,kowshik,2020-07-21T03:22:53Z,done. good point.,1,0.9824387431144714
457815251,9001,kowshik,2020-07-21T03:32:07Z,done. good point.,1,0.9824387431144714
457821195,9001,kowshik,2020-07-21T03:56:30Z,it calls into couple other helper functions. let us keep it.,0,0.994146466255188
457821791,9001,kowshik,2020-07-21T03:58:56Z,done.,0,0.9897913336753845
457821925,9001,kowshik,2020-07-21T03:59:25Z,done.,0,0.9897913336753845
457823139,9001,kowshik,2020-07-21T04:04:34Z,"the purpose of the error message is to sometimes describe with finer details on what is the error (such as which feature update is incorrect). to your point, it seems there are existing response types that do allow for an error message, examples are: `createtopicsresponse`, `createpartitionsresponse`, `deleteaclsresponse` etc. there is ongoing related discussion under another pr review comment and we can continue the discussion there: [a link] .",0,0.9938032627105713
457872699,9001,kowshik,2020-07-21T06:46:14Z,done. updated the doc.,0,0.9869144558906555
457873376,9001,kowshik,2020-07-21T06:47:55Z,done.,0,0.9897913336753845
457876122,9001,kowshik,2020-07-21T06:54:17Z,"done. this case is also handled now. to your point, the case where `updated.max < existing.min` can never happen unless brokers get downgraded (after finalizing features at higher levels), and especially if the downgrade was done improperly (without applying feature tooling commands). it's a rare case. but even in that case, the broker will start crashing because of incompatibility in supported feature version max level, so the problem is found before it reaches this point.",0,0.9722262024879456
457879567,9001,kowshik,2020-07-21T07:02:03Z,not sure i understood. we will only update the `featureznode` if the status is not disabled currently (see the implementation below). what am i missing?,0,0.9139994382858276
457880383,9001,kowshik,2020-07-21T07:03:54Z,this handles the race condition described in the kip-584 [a link]. please refer to the kip for details. i have also added doc to this method.,0,0.9916133880615234
457883779,9001,kowshik,2020-07-21T07:11:03Z,done.,0,0.9897913336753845
457884903,9001,kowshik,2020-07-21T07:13:24Z,"i feel that there isn't a pressing reason to optimize this api path currently, and make it async. the api is not going to be frequently used, and an infrequent write to a zk node with low write contention feels like a relatively inexpensive case that we could block the controller on. please let me know how you feel.",0,0.6949073672294617
457885415,9001,kowshik,2020-07-21T07:14:28Z,done.,0,0.9897913336753845
457885467,9001,kowshik,2020-07-21T07:14:38Z,done. made the comment better. pls take a look.,0,0.6579742431640625
457890046,9001,kowshik,2020-07-21T07:23:55Z,"it is already explained in the class level doc. this is also explained in the kip-584 [a link]. this is needed because `defaultfeatureminversionlevels` is mainly for feature version deprecation. when we deprecate feature version levels, we first bump the `defaultfeatureminversionlevels` in a broker release (after making an announcement to community). this will automatically mean clients have to stop using the finalized min version levels that have been deprecated (because upon startup the controller will write the `defaultfeatureminversionlevels` to zk from within `kafkacontroller#setupfeatureversioning` method). once the write to zk happens, clients that are using the finalized features are forced to stop using the deprecated version levels. then, finally in the future when we remove the code for the deprecated version levels, that is when we will bump the min version for the supported feature in the broker. thereby we will completely drop support for a feature version altogether.",0,0.9881438612937927
457891034,9001,kowshik,2020-07-21T07:25:44Z,done.,0,0.9897913336753845
457892024,9001,kowshik,2020-07-21T07:27:45Z,done. calling it `incompatiblefeaturesinfo` now.,0,0.9919660091400146
457892374,9001,kowshik,2020-07-21T07:28:29Z,done.,0,0.9897913336753845
457892622,9001,kowshik,2020-07-21T07:28:55Z,done.,0,0.9897913336753845
457892858,9001,kowshik,2020-07-21T07:29:25Z,done.,0,0.9897913336753845
457897331,9001,kowshik,2020-07-21T07:37:49Z,"done. made it the way you suggested, pls take a look. overall either way looked fine to me but the one you suggested is a bit simpler.",1,0.7334311604499817
457903477,9001,kowshik,2020-07-21T07:48:51Z,done.,0,0.9897913336753845
457903582,9001,kowshik,2020-07-21T07:49:04Z,done.,0,0.9897913336753845
457904782,9001,kowshik,2020-07-21T07:51:11Z,done. removed.,0,0.9905270338058472
457905010,9001,kowshik,2020-07-21T07:51:34Z,done.,0,0.9897913336753845
457939241,9001,kowshik,2020-07-21T08:50:07Z,done.,0,0.9897913336753845
457981705,9001,kowshik,2020-07-21T10:01:43Z,done. i'm calling it `brokerdefaultversionrange` now.,0,0.9822966456413269
457985348,9001,kowshik,2020-07-21T10:08:39Z,"done. removed the word ""finalized""in the context of this api.",0,0.990727424621582
457986837,9001,kowshik,2020-07-21T10:11:25Z,done.,0,0.9897913336753845
458503099,9001,abbccdda,2020-07-22T02:52:48Z,nit: do `{ describefeaturesresult}`,0,0.9936668276786804
458985306,9001,abbccdda,2020-07-22T18:06:59Z,nit: new line,0,0.9900916814804077
458985676,9001,abbccdda,2020-07-22T18:07:40Z,could be simplified as `sendtocontroller`,0,0.9947275519371033
458986288,9001,abbccdda,2020-07-22T18:08:46Z,"why do we need this override, which seems to be exactly the same with super class?",0,0.9842446446418762
458987227,9001,abbccdda,2020-07-22T18:10:24Z,s/featurename/feature,0,0.9916828870773315
459002813,9001,abbccdda,2020-07-22T18:37:41Z,"the two `call` structs only have two differences: 1. used different node provider 2. one would handle not controller, one not so i would suggest a bit refactoring to reduce the code redundancy, by providing a helper as: [code block]",0,0.9939622282981873
459003818,9001,abbccdda,2020-07-22T18:39:25Z,"same here, why do we need this extension?",0,0.9909668564796448
459004097,9001,abbccdda,2020-07-22T18:39:54Z,"as discussed offline, we need to extend the result as per feature.",0,0.9941502213478088
459004701,9001,abbccdda,2020-07-22T18:40:56Z,couldn't we just use `isincompatiblewith`?,0,0.99382084608078
459005027,9001,abbccdda,2020-07-22T18:41:29Z,why do we jump from code 88 to 91?,0,0.9866865873336792
459006265,9001,abbccdda,2020-07-22T18:43:34Z,"make sense, after looking further i realized that we also did some data format conversion.",0,0.9836487770080566
459008772,9001,abbccdda,2020-07-22T18:47:48Z,do we also need to check `allowautodowngrade` here?,0,0.9954913258552551
459009582,9001,abbccdda,2020-07-22T18:49:09Z,we could consider either making `data` to be private or remove this unnecessary accessor. i would prefer making it private.,0,0.9917431473731995
459009753,9001,abbccdda,2020-07-22T18:49:24Z,same here for consistency.,0,0.9930863380432129
459010149,9001,abbccdda,2020-07-22T18:50:03Z,"spaces look weird, let's try to remove all `two space` cases in this file.",-1,0.9454643726348877
459014883,9001,abbccdda,2020-07-22T18:58:04Z,"my pt is that since we know the outcome (feature versioning will be disabled), we don't need to do one more lookup but just try to push the update. anyway, i think this is a nit.",0,0.9672471880912781
459183702,9001,abbccdda,2020-07-23T02:26:11Z,parameters could be on the same line to be consistent with l80,0,0.9900357723236084
459185058,9001,abbccdda,2020-07-23T02:32:59Z,"`testupdatefeatures` should be suffice, as we sometimes are not passing in a real error.",0,0.9899862408638
459185171,9001,abbccdda,2020-07-23T02:33:32Z,nit: prefer using `error == errors.none`,0,0.9934895038604736
459186000,9001,abbccdda,2020-07-23T02:37:26Z,`collections.emptylist()` should be suffice.,0,0.9937346577644348
459186249,9001,abbccdda,2020-07-23T02:38:39Z,we should have a matcher checking whether the sent request is pointing at the correct controller id.,0,0.993175208568573
459186371,9001,abbccdda,2020-07-23T02:39:08Z,"make it a variable, as `int controllerid = 1`",0,0.9954960346221924
459186681,9001,abbccdda,2020-07-23T02:40:44Z,`defaultfeaturemetadata` should be suffice. ak repo normally tries to avoid using `get` as func prefix.,0,0.9944129586219788
459186760,9001,abbccdda,2020-07-23T02:41:09Z,nit: could use `utils.mkmap` to simplify here.,0,0.9945220947265625
459188638,9001,abbccdda,2020-07-23T02:50:16Z,nit: `zkclient.getdataandversion(featureznode.path)._2` should be suffice,0,0.9954584836959839
459188844,9001,abbccdda,2020-07-23T02:51:18Z,s/znode/znode,0,0.9938831329345703
459188931,9001,abbccdda,2020-07-23T02:51:41Z,s/ is is / is,0,0.962790846824646
459189057,9001,abbccdda,2020-07-23T02:52:09Z,remove `in zk`,0,0.9948511719703674
459189198,9001,abbccdda,2020-07-23T02:52:55Z,nit: s/it's/its,0,0.9775762557983398
459189220,9001,abbccdda,2020-07-23T02:53:03Z,nit: s/it's/its,0,0.9775762557983398
459189352,9001,abbccdda,2020-07-23T02:53:49Z,remove `one and`,0,0.9944789409637451
459189517,9001,abbccdda,2020-07-23T02:54:36Z,remove `and their version levels` or restructure as `the information about finalized features' version levels`,0,0.9945240020751953
459189854,9001,abbccdda,2020-07-23T02:55:55Z,"could we just remove ` the feature versioning system (kip-584) is enabled, and`? it does not provide any useful information.",0,0.9867002964019775
459189970,9001,abbccdda,2020-07-23T02:56:23Z,s/this status/the enabled status,0,0.9883697032928467
459190247,9001,abbccdda,2020-07-23T02:57:49Z,we don't need to capitalize `broker` here,0,0.9915545582771301
459190329,9001,abbccdda,2020-07-23T02:58:15Z,same here,0,0.99204421043396
459190412,9001,abbccdda,2020-07-23T02:58:44Z,"s/`the reason to do this is that...`/`this process ensures we do not enable all the possible features immediately after an upgrade, which could be harmful to the application.`",0,0.9527921676635742
459190870,9001,abbccdda,2020-07-23T03:01:03Z,remove `then`,0,0.9936854243278503
459191665,9001,abbccdda,2020-07-23T03:05:05Z,{} could be removed.,0,0.9924609065055847
459192115,9001,abbccdda,2020-07-23T03:07:16Z,nit: would be easier to read if we always compare `existingversionrange` towards `brokerdefaultversionrange` instead of flipping in this statement.,0,0.9842586517333984
459192901,9001,abbccdda,2020-07-23T03:11:05Z,i think we need to override `equals` here.,0,0.9853508472442627
459192976,9001,abbccdda,2020-07-23T03:11:26Z,cache,0,0.9057924151420593
459193453,9001,abbccdda,2020-07-23T03:13:22Z,`no updatemetadatarequest will be sent to broker...`,0,0.9885791540145874
459193711,9001,abbccdda,2020-07-23T03:14:45Z,does `features` guarantee to be non-null?,0,0.993588924407959
459193767,9001,abbccdda,2020-07-23T03:15:02Z,format,0,0.7970684766769409
459194593,9001,abbccdda,2020-07-23T03:19:03Z,"yea, i'm a bit worried about such a blocking call here as we don't have a precedence for relying on zk connect timeout (18 seconds), besides the result doesn't matter to the controller (since client will do the retry). cc to see if they have a different opinion on this.",-1,0.9226407408714294
459195272,9001,abbccdda,2020-07-23T03:22:08Z,what `clients` are we referring to here?,0,0.9909588098526001
459195338,9001,abbccdda,2020-07-23T03:22:35Z,`the class is immutable in production`,0,0.99394291639328
459528132,9001,abbccdda,2020-07-23T15:16:34Z,is it necessary to quote `incompatible`?,0,0.9873221516609192
459538486,9001,abbccdda,2020-07-23T15:30:57Z,could you explain a bit why we no longer use singletons for feature cache?,0,0.992400050163269
459554866,9001,abbccdda,2020-07-23T15:54:51Z,we could explicitly mention this is `either or` result.,0,0.9906588792800903
459556307,9001,abbccdda,2020-07-23T15:56:45Z,could be initialized closer to l3005,0,0.9939361214637756
459562747,9001,abbccdda,2020-07-23T16:06:37Z,could we assert the expected version here?,0,0.9931904673576355
459563255,9001,abbccdda,2020-07-23T16:07:24Z,nit: new line,0,0.9900916814804077
459564526,9001,abbccdda,2020-07-23T16:09:36Z,...`withinvalidsmallvalue`,0,0.9914851784706116
459564664,9001,abbccdda,2020-07-23T16:09:48Z,...`withinvalidlargevalue`,0,0.9904268980026245
459565850,9001,abbccdda,2020-07-23T16:11:41Z,what's the purpose of this second test?,0,0.9899744391441345
459566826,9001,abbccdda,2020-07-23T16:13:14Z,nit: replace with `noncontrollerservers.head`,0,0.9952508211135864
459569818,9001,abbccdda,2020-07-23T16:17:56Z,this case seems not to be tested yet.,0,0.986451268196106
459570396,9001,abbccdda,2020-07-23T16:18:54Z,format,0,0.7970684766769409
459653525,9001,abbccdda,2020-07-23T18:41:59Z,format,0,0.7970684766769409
459655758,9001,abbccdda,2020-07-23T18:45:44Z,we could refactor out a helper in `updatefeaturesrequest` to create `featureupdatekey`,0,0.9944043159484863
459658554,9001,abbccdda,2020-07-23T18:50:45Z,"could we add some unit tests in `kafkaapistest.scala`, once the refactoring is finished?",0,0.9946233034133911
460365110,9001,kowshik,2020-07-25T04:51:52Z,done.,0,0.9897913336753845
460365185,9001,kowshik,2020-07-25T04:52:57Z,done.,0,0.9897913336753845
460365229,9001,kowshik,2020-07-25T04:53:47Z,done.,0,0.9897913336753845
460365305,9001,kowshik,2020-07-25T04:54:32Z,done. removed now. didn't realize it was present in super class too.,0,0.9496278762817383
460365462,9001,kowshik,2020-07-25T04:56:23Z,done. actually `feature` is removed from this class now.,0,0.9795127511024475
460369033,9001,kowshik,2020-07-25T05:44:35Z,done. good point.,1,0.9824387431144714
460369103,9001,kowshik,2020-07-25T05:45:25Z,done. removed now.,0,0.9910275340080261
460369423,9001,kowshik,2020-07-25T05:49:31Z,done. removed this method now.,0,0.9904967546463013
460369509,9001,kowshik,2020-07-25T05:50:19Z,done. not intentional. changed to 89 now.,0,0.9829258918762207
460369545,9001,kowshik,2020-07-25T05:50:51Z,done.,0,0.9897913336753845
460370082,9001,kowshik,2020-07-25T05:57:51Z,done. made the attribute private.,0,0.9901989698410034
460370089,9001,kowshik,2020-07-25T05:58:03Z,done. made the attribute private.,0,0.9901989698410034
460370162,9001,kowshik,2020-07-25T05:59:09Z,done.,0,0.9897913336753845
460371001,9001,kowshik,2020-07-25T06:10:14Z,done.,0,0.9897913336753845
460371104,9001,kowshik,2020-07-25T06:11:43Z,done.,0,0.9897913336753845
460371146,9001,kowshik,2020-07-25T06:12:24Z,done.,0,0.9897913336753845
460371283,9001,kowshik,2020-07-25T06:14:31Z,done.,0,0.9897913336753845
460371443,9001,kowshik,2020-07-25T06:16:22Z,done.,0,0.9897913336753845
460371572,9001,kowshik,2020-07-25T06:18:05Z,done.,0,0.9897913336753845
460373122,9001,kowshik,2020-07-25T06:38:13Z,"i have improved the matcher now, but how do i check the correct controller id?",0,0.9934476017951965
460373211,9001,kowshik,2020-07-25T06:39:17Z,`newversion` is more readable than `_2`.,0,0.9909605383872986
460373254,9001,kowshik,2020-07-25T06:39:52Z,done.,0,0.9897913336753845
460373296,9001,kowshik,2020-07-25T06:40:15Z,done.,0,0.9897913336753845
460373384,9001,kowshik,2020-07-25T06:41:31Z,done.,0,0.9897913336753845
460373389,9001,kowshik,2020-07-25T06:41:37Z,done.,0,0.9897913336753845
460373454,9001,kowshik,2020-07-25T06:42:14Z,done.,0,0.9897913336753845
460373463,9001,kowshik,2020-07-25T06:42:21Z,done.,0,0.9897913336753845
460373549,9001,kowshik,2020-07-25T06:43:36Z,done.,0,0.9897913336753845
460373561,9001,kowshik,2020-07-25T06:43:52Z,done.,0,0.9897913336753845
460373590,9001,kowshik,2020-07-25T06:44:08Z,done.,0,0.9897913336753845
460373616,9001,kowshik,2020-07-25T06:44:20Z,done.,0,0.9897913336753845
460373708,9001,kowshik,2020-07-25T06:45:15Z,done.,0,0.9897913336753845
460373729,9001,kowshik,2020-07-25T06:45:37Z,done.,0,0.9897913336753845
460373746,9001,kowshik,2020-07-25T06:45:51Z,done.,0,0.9897913336753845
460373809,9001,kowshik,2020-07-25T06:46:45Z,done.,0,0.9897913336753845
460374117,9001,kowshik,2020-07-25T06:50:59Z,"`featureznode` is a `case class`, and therefore the `equals` method is auto generated. let me know if i'm missing something. here is the doc: [a link]",0,0.993480920791626
460374136,9001,kowshik,2020-07-25T06:51:22Z,done.,0,0.9897913336753845
460374558,9001,kowshik,2020-07-25T06:57:15Z,"we can not just push the update, because, we have to decide if the node needs to be created or existing node should be updated. that is why we read the node first to understand if it exists or not, then we update the existing node only if the status does not match (this avoids a zk write in the most common cases).",0,0.9921191930770874
460374653,9001,kowshik,2020-07-25T06:58:43Z,done.,0,0.9897913336753845
460375004,9001,kowshik,2020-07-25T07:03:27Z,"yes, `broker.features` is just empty when there are no features set or none decoded from the `brokeridznode`.",0,0.9930118918418884
460375038,9001,kowshik,2020-07-25T07:04:01Z,done.,0,0.9897913336753845
460375251,9001,kowshik,2020-07-25T07:06:15Z,done. i was referring to external clients of kafka. have updated the doc now.,0,0.9897038340568542
460375270,9001,kowshik,2020-07-25T07:06:32Z,done.,0,0.9897913336753845
460375378,9001,kowshik,2020-07-25T07:08:11Z,done. removed quotes.,0,0.992066502571106
460375750,9001,kowshik,2020-07-25T07:13:11Z,"it became painful to write tests using singletons. particularly in `kafka.server.updatefeaturestest` we would like to simulate presence of multiple brokers and a controller within the same test process. then we would like to set incompatible features for some brokers, and compatible features for some others. using a singleton for feature cache made it impossible to set up such an environment for testing. that is why we no longer use a singleton, instead we instantiate the class once in `kafkaserver` and we use the object wherever needed.",-1,0.7594693899154663
460375901,9001,kowshik,2020-07-25T07:15:07Z,done.,0,0.9897913336753845
460375935,9001,kowshik,2020-07-25T07:15:25Z,done.,0,0.9897913336753845
460376009,9001,kowshik,2020-07-25T07:16:37Z,done.,0,0.9897913336753845
460376035,9001,kowshik,2020-07-25T07:16:42Z,done.,0,0.9897913336753845
460376322,9001,kowshik,2020-07-25T07:20:35Z,"it is explained in the test doc above, and, i have also added comments now. the purpose is to check that the zk watch on the featureznode was re-established by the broker, after the first update triggers a zk notification that populates the cache. the best way to check it is to update the node again and see if the notification is received by the broker again.",0,0.985042154788971
460376477,9001,kowshik,2020-07-25T07:22:27Z,done.,0,0.9897913336753845
460376521,9001,kowshik,2020-07-25T07:22:56Z,done.,0,0.9897913336753845
460376578,9001,kowshik,2020-07-25T07:23:54Z,done.,0,0.9897913336753845
461412713,9001,kowshik,2020-07-28T08:35:14Z,done.,0,0.9897913336753845
461413382,9001,kowshik,2020-07-28T08:36:21Z,done.,0,0.9897913336753845
461413992,9001,kowshik,2020-07-28T08:37:29Z,done.,0,0.9897913336753845
461416641,9001,kowshik,2020-07-28T08:42:00Z,done.,0,0.9897913336753845
461417458,9001,kowshik,2020-07-28T08:43:22Z,"sure, we can hear what others say.",0,0.9787670373916626
461418384,9001,kowshik,2020-07-28T08:44:51Z,will take a look.,0,0.9661961793899536
461418530,9001,kowshik,2020-07-28T08:45:03Z,this method has changed greatly and it has been moved to `kafkacontroller.scala`.,0,0.995427131652832
461418681,9001,kowshik,2020-07-28T08:45:17Z,this method has changed greatly and it has been moved to `kafkacontroller.scala`.,0,0.995427131652832
461421563,9001,kowshik,2020-07-28T08:49:51Z,"hmm, there seem to be very few call sites and therefore seems ok to inline it. let me know!",0,0.5331288576126099
461424717,9001,kowshik,2020-07-28T08:54:59Z,added a test now in `updatefeaturestest.scala`. look for `testsuccessfulfeatureupgradeandwithnoexistingfinalizedfeatures`.,0,0.9889748096466064
461771992,9001,abbccdda,2020-07-28T18:03:35Z,nit: s/name/names,0,0.9940144419670105
462453975,9001,abbccdda,2020-07-29T17:08:15Z,"note in the post-kip-500 world, this feature could still work, but the request must be redirected to the controller inherently on the broker side, instead of sending it directly. so in the comment, we may try to phrase it to convey the principal is that `the request must be handled by the controller` instead of `the admin client must send this request to the controller`.",0,0.9906653165817261
462456942,9001,abbccdda,2020-07-29T17:13:03Z,should this a per feature error or a top level error?,0,0.9535752534866333
462458761,9001,abbccdda,2020-07-29T17:15:56Z,"for top level exception such as cluster authorization exception, we could just define a top level error code instead of check-marking every feature with the redundant error code. i know we have been a bit inconsistent in such a case, but personally feel having layered error codes could make the response handling clear of whether it is per feature issue, or a high level issue.",0,0.9591367244720459
462458948,9001,abbccdda,2020-07-29T17:16:15Z,space,0,0.7991176247596741
462459015,9001,abbccdda,2020-07-29T17:16:21Z,same here,0,0.99204421043396
462459152,9001,abbccdda,2020-07-29T17:16:34Z,same here,0,0.99204421043396
462462109,9001,abbccdda,2020-07-29T17:21:30Z,`can be issued only to the controller.`/ `must be processed by the controller`,0,0.9906142950057983
462462268,9001,abbccdda,2020-07-29T17:21:47Z,`could be processed by any random broker`,0,0.9916627407073975
462462801,9001,abbccdda,2020-07-29T17:22:41Z,same here,0,0.99204421043396
462463977,9001,abbccdda,2020-07-29T17:24:33Z,"try to put first parameter on the same line as the constructor, and align the rest parameters.",0,0.9926375150680542
462465188,9001,abbccdda,2020-07-29T17:26:28Z,"this won't work well with string format, consider doing `orelse`",0,0.9887491464614868
462465387,9001,abbccdda,2020-07-29T17:26:50Z,new line,0,0.9904432892799377
462471038,9001,abbccdda,2020-07-29T17:36:28Z,"i suggest we build a static method in the `updatefeaturesrequest` class to avoid exposing the sub modules of feature data, such like: [code block]",0,0.9933453798294067
462472940,9001,abbccdda,2020-07-29T17:39:43Z,does this overlap with `completeunrealizedfutures` check? we could just keep one to reduce the checking complexity.,0,0.9922007918357849
462475689,9001,abbccdda,2020-07-29T17:44:02Z,"you are right, it seems not necessary.",0,0.9410966634750366
462477303,9001,abbccdda,2020-07-29T17:46:32Z,"do we need to make this a public error? it seems only be used internally, so could be made private if we don't have intention to let user catch.",0,0.9882546663284302
462480826,9001,abbccdda,2020-07-29T17:52:16Z,comment here since no better place: createapiversionsresponse on l198 could be made private,0,0.9927956461906433
462483315,9001,abbccdda,2020-07-29T17:56:31Z,nit: could be replaced with lambda,0,0.9942493438720703
462485886,9001,abbccdda,2020-07-29T18:00:41Z,should we also mention that this flag would fail the request when we are not actually doing a downgrade?,0,0.9859554767608643
462488078,9001,abbccdda,2020-07-29T18:04:41Z,"i'm actually wondering whether this is too strict in the perspective of a user. if they accidentally set a feature version larger than the cache, what they only care about is to be able to change the version to it. so it's a matter of whether we think this is a user error, or this could happen when user gets stale feature information from a broker while the downgrade already succeed eventually. if we want to keep this check, it makes sense to update the meta comments around `allowdowngrade` to inform user that the request could fail when the target version is actually higher than the current finalized feature.",0,0.9160414338111877
462489375,9001,abbccdda,2020-07-29T18:07:00Z,could be moved to the `updatefeaturesresponse`,0,0.9952443242073059
462492285,9001,abbccdda,2020-07-29T18:11:58Z,could we make `updates` as a pass-in parameter to avoid calling `maketestfeatureupdates` twice?,0,0.9944837689399719
462492825,9001,abbccdda,2020-07-29T18:12:58Z,nit: could use lambda,0,0.9930940866470337
462496091,9001,abbccdda,2020-07-29T18:18:17Z,"do we need to call `featurecache.waituntilepochorthrow(newnode, config.zkconnectiontimeoutms)` here to ensure the update is successful?",0,0.995357096195221
462498961,9001,abbccdda,2020-07-29T18:23:15Z,"i see, still wondering if we could just check whether `newfeatures` is equal to `existingfeatureznode.features`",0,0.9738465547561646
462500314,9001,abbccdda,2020-07-29T18:25:31Z,"are we good to proceed in this case? when there is no overlapping between broker default features and remote finalized features, is the current controller still eligible?",0,0.9948227405548096
462501301,9001,abbccdda,2020-07-29T18:27:19Z,"i see, what would happen to a currently live broker if it couldn't get any metadata update for a while, will it shut down itself?",0,0.9806696772575378
462502780,9001,abbccdda,2020-07-29T18:29:57Z,"i see, still i'm a bit worried future changes could break this assumption. not a bad idea to check `features != null`?",-1,0.9130014181137085
462504467,9001,abbccdda,2020-07-29T18:32:45Z,state the error explicitly here.,0,0.9780657887458801
462627189,9001,abbccdda,2020-07-29T22:30:26Z,"yea, i mean you could use `val newversion = zkclient.getdataandversion(featureznode.path)._2`, but it's up to you.",0,0.9925346374511719
462649895,9001,abbccdda,2020-07-29T23:38:21Z,is this case covered by the case on l1931? could we merge both?,0,0.9927136301994324
462650343,9001,abbccdda,2020-07-29T23:39:44Z,we should be consistent and remove `()` from `maxversionlevel`,0,0.9947921633720398
462651241,9001,abbccdda,2020-07-29T23:42:50Z,nit: new line,0,0.9900916814804077
462658154,9001,abbccdda,2020-07-30T00:05:36Z,"could you clarify the reasoning here? if structs are not the same, are we going to do a partial update?",0,0.9912151098251343
462714278,9001,abbccdda,2020-07-30T03:34:34Z,could we get a static method instead of initiating a new `finalizedversionrange` for a comparison every time?,0,0.9929695725440979
462715368,9001,abbccdda,2020-07-30T03:39:07Z,why don't we just use `system.currenttimemillis()` to avoid conversion between nano time?,0,0.9922226071357727
462715603,9001,abbccdda,2020-07-30T03:39:57Z,seems not covered yet,0,0.9863475561141968
462716040,9001,abbccdda,2020-07-30T03:41:34Z,could be moved to `updatefeaturesresponse` as a utility.,0,0.9946746826171875
462716875,9001,abbccdda,2020-07-30T03:44:56Z,"some methods in the `brokerfeatures` are not covered by this suite, such as `defaultminversionlevel`, `getdefaultfinalizedfeatures` and `hasincompatiblefeatures`, you could use code coverage tool to figure out any missing part.",0,0.9900761246681213
462717083,9001,abbccdda,2020-07-30T03:45:45Z,indentation is not right.,-1,0.6709336042404175
462718258,9001,abbccdda,2020-07-30T03:50:44Z,the meta comment for `finalizedfeaturecache` should be updated as it is now being accessed for both read and write,0,0.9957395792007446
462719027,9001,abbccdda,2020-07-30T03:54:08Z,nit: this could be extracted as a common struct.,0,0.9943893551826477
462719977,9001,abbccdda,2020-07-30T03:57:50Z,"could we only pass in `featurecache` to reduce the class coupling here? as we already have `brokerfeatures` as a private parameter, it shouldn't be too hard to set a helper to get supported features.",0,0.9920646548271179
463880076,9001,kowshik,2020-07-31T23:01:47Z,"sorry, i do not understand why should describefeatures (in post kip-500) be handled only by controller?",-1,0.9895959496498108
463912157,9001,kowshik,2020-08-01T02:54:07Z,it does not overlap. this checks for unexpected responses for features that we never intended to update. `completeunrealizedfutures` is for futures that we never got a response for from the server -- we need to complete such futures exceptionally.,0,0.9938031435012817
463912498,9001,kowshik,2020-08-01T02:57:46Z,this exception corresponds to `errors.feature_update_failed`. the caller of `adminclient#updatefeatures` can receive this exception whenever a feature update can not be written to zk (due to a zk issue). so this has to be a public error.,0,0.993282675743103
463915406,9001,kowshik,2020-08-01T03:23:44Z,"updated the doc. let's keep the check, if it happens then it's a user error. especially because this can not happen if the user is using the tooling that we are going to provide in ak.",0,0.9941481351852417
463915409,9001,kowshik,2020-08-01T03:23:50Z,done.,0,0.9897913336753845
463915553,9001,kowshik,2020-08-01T03:25:20Z,"no, that is not required. please refer to the documentation above under `note` for this method where i have explained why.",0,0.9941529631614685
463916219,9001,kowshik,2020-08-01T03:34:23Z,isn't that what i'm using currently?,0,0.9922147393226624
463916470,9001,kowshik,2020-08-01T03:37:35Z,like how? i don't understand. isn't that what i'm doing currently?,-1,0.864054799079895
463916610,9001,kowshik,2020-08-01T03:39:49Z,"if the broker has feature incompatibilities, then it should die as soon as it has received the zk update (it would die from within `finalizedfeaturechangelistener`).",0,0.9918866753578186
463916688,9001,kowshik,2020-08-01T03:40:25Z,done now.,0,0.9922559261322021
463934710,9001,kowshik,2020-08-01T07:31:07Z,"we should keep the existing check as it is. the reason is that if the existing node is `(disabled, {})` then here we would like to change it to `(enabled, features)`. therefore, we have to check the features as well as the `featureznodestatus`.",0,0.9933679699897766
463934948,9001,kowshik,2020-08-01T07:34:46Z,i do not understand the concern. which code path can possibly introduce `null` features attribute in `broker` object? it is impossible....,-1,0.7510414719581604
463935718,9001,kowshik,2020-08-01T07:44:14Z,"a value < 1 is indicative of a deletion request (a kind of downgrade request). it is for convenience of generating a special error message, that we handle the case here explicitly: `...less than 1 for feature...`.",0,0.9897245168685913
463936048,9001,kowshik,2020-08-01T07:48:44Z,done.,0,0.9897913336753845
463936098,9001,kowshik,2020-08-01T07:49:28Z,existing approach is equally readable too. i'd rather leave it this way.,0,0.9687447547912598
463936412,9001,kowshik,2020-08-01T07:54:05Z,"since the app depends on monotonically increasing elapsed time values, `system.nanotime()` is preferred. `system.currenttimemillis()` can change due to daylight saving time, users changing the time settings, leap seconds, and internet time sync etc.",0,0.9928181171417236
463937032,9001,kowshik,2020-08-01T08:02:25Z,"the `finalizedfeaturecache.getsupportedfeatures` api is not the right fit for the cache's public interface (it is quite unrelated to the other public apis of the cache). i'd rather not pollute the public api there, just for the sake of convenience.",0,0.913196861743927
463937184,9001,kowshik,2020-08-01T08:04:35Z,just 2 occurrences (one in this test and other in the next test). i'd leave it the way it is as the test is readable with values inlined in the test body.,0,0.9927493333816528
465565925,9001,kowshik,2020-08-05T08:36:36Z,"actually this is an error case now. have updated the code with the fix, and with good documentation.",0,0.7188177704811096
465570359,9001,kowshik,2020-08-05T08:44:21Z,"this does not seem to be required, since it is already achieved via `updatefeaturestest`. infact there we test using admin client, which is even better as it tests e2e client to server functionality. what do we gain by adding the additional tests in `kafkaapistest` ?",0,0.9887697696685791
465572011,9001,kowshik,2020-08-05T08:47:06Z,"i don't see that we consistently use a top level error code across other kafka apis, so i will leave it as it is. it feels ok for this api to not use it, as it does not make a significant difference.",0,0.8025099635124207
465572056,9001,kowshik,2020-08-05T08:47:12Z,answered below.,0,0.993208110332489
467279790,9001,junrao,2020-08-07T21:29:27Z,the kip wiki has allowdowngrade at the topic level. could we update that?,0,0.9954812526702881
467282147,9001,junrao,2020-08-07T21:32:28Z,the kip wiki doesn't include this field.,0,0.9747603535652161
467309169,9001,junrao,2020-08-07T22:15:43Z,"when we roll the cluster to bump up ibp, it seems that it's possible for status to be enabled and then disabled repeatedly? this can be a bit weird.",-1,0.6607795357704163
467315417,9001,junrao,2020-08-07T22:40:05Z,"when we roll the cluster to bump up ibp, it seems that it's possible for the min of finalized version to flip repeatedly? this can be a bit weird. also, it seems that we should set min version based on the largest min version across all brokers?",-1,0.8784856200218201
467319530,9001,junrao,2020-08-07T22:57:09Z,"hmm, do we need to do this? if there is an incompatible feature, the broker will realize that and can just shut itself down.",0,0.9496506452560425
467326580,9001,junrao,2020-08-07T23:29:11Z,"if update.maxversionlevel < defaultminversionlevel, we throw an illegalstateexception. should we catch it and convert it to an error code?",0,0.9909071922302246
467330197,9001,junrao,2020-08-07T23:48:02Z,"since we are doing the compatibility check for every broker, do we need to special case here just for the broker feature on the controller?",0,0.9934753775596619
467333895,9001,junrao,2020-08-08T00:08:33Z,"if the broker discovers that it's incompatible, should it just shut itself down?",0,0.9672276973724365
467341811,9001,junrao,2020-08-08T01:04:11Z,could you explain how the default min version is different from the min in supportedfeatures?,0,0.99428790807724
468000768,9001,junrao,2020-08-10T15:42:18Z,"the return type is different from the kip. which one is correct? since this is a public interface, in general, we don't want to expose anything other than truly necessary. this pr seems to expose a lot more public methods to the user. finalizedversionrange is in org.apache.kafka.common.feature. currently, all public interfaces are specified under javadoc in build.gradle. so, we need to either include that package in javadoc or move it to a public package.",0,0.991654634475708
468000872,9001,junrao,2020-08-10T15:42:28Z,the return type is different from the kip. which one is correct?,0,0.9921892881393433
468002060,9001,junrao,2020-08-10T15:44:20Z,the kip also exposes host() and port(). are they still needed?,0,0.9952816367149353
468005420,9001,junrao,2020-08-10T15:49:30Z,"the kip doesn't have describefeaturesoptions. if we are changing the kip, could we summarize the list of the things that are changed?",0,0.9934529066085815
468008294,9001,junrao,2020-08-10T15:53:53Z,"again, this method has a different signature from the kip.",0,0.9894890189170837
468009874,9001,junrao,2020-08-10T15:56:13Z,the kip doesn't have this method.,0,0.9798784255981445
468020800,9001,junrao,2020-08-10T16:14:00Z,handlenotcontrollererror() already throws an exception. should other errors like cluster_authorization_failed be treated in the same way?,0,0.9924141764640808
468084269,9001,kowshik,2020-08-10T18:04:56Z,i'm missing something. which lines on the kip-584 were you referring to? i didn't find any mention of the flag being at the topic level.,0,0.7056976556777954
468085443,9001,kowshik,2020-08-10T18:07:00Z,"yes, we changed to have an error code per feature update. i'll update the kip-584 write up.",0,0.9929723739624023
468089357,9001,kowshik,2020-08-10T18:14:32Z,"to be sure we are on same page, is this because of a controller failover during an ibp bump? it seems to me that this can happen mainly when ibp is being bumped from a value less than kafka_2_7_iv0 to a value greater than or equal to kafka_2_7_iv0 (assuming subsequent ibp bumps will be from kafka_2_7_iv0 to a higher value, so the node status will remain enabled). in general, i'm not sure how to avoid this node status flip until ibp bump has been completed cluster-wide.",0,0.9857107996940613
468097360,9001,kowshik,2020-08-10T18:29:32Z,"true, this is possible. good point. to be sure i understood, are you referring broadly to any future ibp bump? or specifically are you referring to the ibp bump from a value less than kafka_2_7_iv0 to a value greater than or equal to kafka_2_7_iv0? (since kafka_2_7_iv0 is the ibp where the feature versioning system gets activated) to answer your question, i'm not sure how to avoid the flip. it is to be noted that min version level changes are used only for feature version deprecation. due to the flipping values, it merely means some version levels would go a few times from deprecated -> available -> deprecated -> available...., until the ibp bump has been completed cluster-wide. i can't (yet) think of a case where the flip is dangerous, since: 1. we have this check: [a link] and 2. as best practice, we can recommend to not change a) minversion of supportedfeature as well as b) default minversionlevel within the same release. the reason being that we typically first deprecate a feature version level before we remove the code to drop support for it i.e. (b) usually has to happen before (a).",1,0.9213273525238037
468101982,9001,kowshik,2020-08-10T18:38:18Z,"good question. yes, the broker will shut itself down. but still there is a possible race condition that needs to be handled to prevent an incompatible broker from causing damage to cluster. the race condition is described in the kip-584 [a link]. please let me know your thoughts.",1,0.9436516165733337
468103224,9001,kowshik,2020-08-10T18:40:39Z,"yes, excellent point. i'll fix this.",1,0.9784133434295654
468109791,9001,kowshik,2020-08-10T18:52:51Z,"it's required because `defaultminversionlevel` does not exist for a feature that's not in the supported list. however, i'll change the code to make the check more obvious to the reader (currently it's not).",0,0.9952583909034729
468111300,9001,kowshik,2020-08-10T18:55:30Z,"good question. the existing behavior is that it shuts itself down, as triggered by this loc. the reason to do it is that an incompatible broker can potentially do harmful things to a cluster (because max version level upgrades are used for breaking changes): [a link]",1,0.8019033074378967
468111785,9001,kowshik,2020-08-10T18:56:28Z,"sure, i'll update the pr documenting it.",0,0.9917254447937012
471627837,9001,junrao,2020-08-17T17:13:02Z,ok. there are a couple of places that this pr is inconsistent with the kip. 1. the kip has 2 levels of arrays: []featureupdatekey and []featurekey. this pr only has one array. 2. the kip has a timeoutms field and this pr doesn't.,0,0.9829978942871094
471806378,9001,junrao,2020-08-17T22:20:32Z,"my understanding of the race condition is that the controller finalizes a feature while there is a pending broker registration in the controller event queue. when the controller starts to process the new broker registration, it will realize that its supported feature is not compatible. here, it's seems that we will still process this new broker registration and only avoid sending updatatemetadatarequest to it. i am not sure if this helps since we already acted on this incompatible broker registration and some damage may already be done. the same updatatemetadatarequest will still be sent to other brokers and its metadata will be available to the clients. an alternative way is to just skip the handling of new broker registration if it's detected as incompatible.",0,0.9005322456359863
494170995,9001,kowshik,2020-09-24T09:28:25Z,done. i have added a top-level error code now.,0,0.9906452894210815
494171030,9001,kowshik,2020-09-24T09:28:29Z,done.,0,0.9897913336753845
494171814,9001,kowshik,2020-09-24T09:29:49Z,"done. fixed the kip and the code, so that they align with each other now.",0,0.8598645329475403
494173396,9001,kowshik,2020-09-24T09:32:21Z,"done. i've updated the kip-584 write up, please refer to [a link] in the kip.",0,0.9458974003791809
494174446,9001,kowshik,2020-09-24T09:34:09Z,done. i've fixed this now to align with the kip.,0,0.9497200846672058
494179911,9001,kowshik,2020-09-24T09:42:55Z,done. i've updated the kip to use `optional ` as well.,0,0.9906402826309204
494180021,9001,kowshik,2020-09-24T09:43:06Z,done. i've removed those methods from the kip.,0,0.9894294142723083
494180167,9001,kowshik,2020-09-24T09:43:22Z,done. i've updated the kip to mention `describefeaturesoptions`.,0,0.9880747199058533
494180305,9001,kowshik,2020-09-24T09:43:36Z,"done. i've updated the kip to align with whats used here, so both are the same now.",0,0.919008731842041
494180601,9001,kowshik,2020-09-24T09:44:03Z,done. the kip has been updated to have this method now.,0,0.9906139373779297
494183456,9001,kowshik,2020-09-24T09:48:37Z,"done. fixed the code to not throw exception again when handling not_controller error. i'm not sure how could we treat it the same way. in the case of the not_controller error, the admin client code would retry the request once again when the exception is raised. but when cluster authorization fails, would a retry help?",0,0.9636484384536743
494519631,9001,kowshik,2020-09-24T18:20:37Z,done. i've changed the code such that we skip the broker registration if it's detected as incompatible.,0,0.9844175577163696
494542156,9001,kowshik,2020-09-24T18:54:14Z,done. this is fixed now.,0,0.6653279662132263
494569726,9001,kowshik,2020-09-24T19:46:20Z,done.,0,0.9897913336753845
494653251,9001,kowshik,2020-09-24T22:52:14Z,done.,0,0.9897913336753845
496093216,9001,junrao,2020-09-28T16:48:55Z,"space before ""name"".",0,0.9659112691879272
496099482,9001,junrao,2020-09-28T16:59:02Z,this is not included in the kip. should we update the kip?,0,0.9922605156898499
496104584,9001,junrao,2020-09-28T17:05:46Z,"since this is public facing, could we include the description in the kip?",0,0.9945631623268127
496118993,9001,junrao,2020-09-28T17:31:27Z,"since the user is not expected to instantiate this, should we make the constructor non-public?",0,0.9921318888664246
496120406,9001,junrao,2020-09-28T17:34:03Z,"since the user is not expected to instantiate this, should we make the constructor non-public?",0,0.9921318888664246
496122127,9001,junrao,2020-09-28T17:37:09Z,"this seems identical to supportedversionrange. should we just have one, sth like versionrange?",0,0.9912611842155457
496124713,9001,junrao,2020-09-28T17:41:52Z,are we adding the timeout option based on the kip discussion?,0,0.9927138686180115
496131186,9001,junrao,2020-09-28T17:52:57Z,"""at a those "" typo?",0,0.9767727255821228
496211011,9001,junrao,2020-09-28T20:24:46Z,"i guess after the first step, deprecated finalized versions are no longer advertised to the client, but they can still be used by existing connections?",0,0.9848324656486511
496213232,9001,junrao,2020-09-28T20:29:04Z,perhaps isfeatureversioningsupported is a better name?,0,0.9880629777908325
496227488,9001,junrao,2020-09-28T20:56:44Z,is it useful to expose firstactiveversion to the client?,0,0.9942124485969543
496253083,9001,junrao,2020-09-28T21:47:00Z,"could you define the default finalized features? also, default minimum version seems outdated now.",0,0.9909488558769226
496268711,9001,junrao,2020-09-28T22:22:21Z,perhaps it's better for the following code to use match instead if/else.,0,0.9861977696418762
496271143,9001,junrao,2020-09-28T22:29:17Z,setupfeatureversioning => maybesetupfeatureversioning ?,0,0.9945769309997559
496305291,9001,junrao,2020-09-29T00:20:56Z,map() is supposed to be used with no side effect. perhaps we could use match here.,0,0.9914889335632324
496306005,9001,junrao,2020-09-29T00:23:48Z,"do we need to return the stacktrace to the caller? since this is unexpected, perhaps we can log a warn?",0,0.9938253164291382
496306586,9001,junrao,2020-09-29T00:26:06Z,indentation,0,0.9911677837371826
496309833,9001,junrao,2020-09-29T00:38:35Z,featurecache => finalizedfeaturecache ?,0,0.9932981133460999
496311550,9001,junrao,2020-09-29T00:45:23Z,"i think the convention is that if there is a top level error, the second level will just be empty since there is not need to process them individually.",0,0.9760831594467163
496312688,9001,junrao,2020-09-29T00:50:09Z,-1 => -1l?,0,0.9833710193634033
496315493,9001,junrao,2020-09-29T01:00:56Z,this package is not part of the javadoc and thus is not part of the public interface.,0,0.9933384656906128
496317328,9001,junrao,2020-09-29T01:08:23Z,"since we are including the timeout in the updatefeature request, perhaps we could just use that timeout here.",0,0.9910325407981873
496318368,9001,junrao,2020-09-29T01:12:25Z,featurecache => finalizedfeaturecache?,0,0.9922311902046204
496319189,9001,junrao,2020-09-29T01:15:24Z,"should we just verify the range [first_active_version, max]?",0,0.9944385290145874
496321312,9001,abbccdda,2020-09-29T01:23:04Z,"yea, you are right, i think this comment belongs to updatefeatures",0,0.9613212943077087
496506413,9001,kowshik,2020-09-29T08:09:57Z,done.,0,0.9897913336753845
496509097,9001,kowshik,2020-09-29T08:12:24Z,done. updated the kip. please refer to [a link] section.,0,0.9692129492759705
496509282,9001,kowshik,2020-09-29T08:12:34Z,done. updated the kip. please refer to [a link] section.,0,0.9692129492759705
496511604,9001,kowshik,2020-09-29T08:14:42Z,"it is instantiated from `kafka.server.updatefeaturestest`, so have to keep the c'tor public.",0,0.9955549836158752
496511864,9001,kowshik,2020-09-29T08:14:55Z,"it is instantiated from `kafka.server.updatefeaturestest`, so have to keep the c'tor public.",0,0.9955549836158752
496523315,9001,kowshik,2020-09-29T08:25:21Z,"i considered this, however if we plan to expose `firstactiveversion` to the client, then, it is better to have 2 separate classes like we do now. this is because `firstactiveversion` will become an attribute only in `supportedversionrange` class.",0,0.9921332597732544
496523894,9001,kowshik,2020-09-29T08:25:52Z,"yes, it is already added. the base class: `abstractoptions` contains a `timeoutms` attribute and the value is set in the `updatefeaturesrequest`.",0,0.9942277669906616
496524072,9001,kowshik,2020-09-29T08:26:03Z,done.,0,0.9897913336753845
496524793,9001,kowshik,2020-09-29T08:26:44Z,"yes, correct. i have updated the doc mentioning the same.",0,0.9895251989364624
496524910,9001,kowshik,2020-09-29T08:26:50Z,done.,0,0.9897913336753845
496525949,9001,kowshik,2020-09-29T08:27:48Z,"this is a really good point. yes, i feel it is useful to expose it to the client via `apiversionsresponse`. i can change the kip suitably and then update the pr.",1,0.9924744963645935
496526254,9001,kowshik,2020-09-29T08:28:04Z,"done. i reworded a bit and i'm now no longer using ""default finalized features"" and ""default minimum version"" in the wordings.",0,0.9408847093582153
496527539,9001,kowshik,2020-09-29T08:29:14Z,done.,0,0.9897913336753845
496528169,9001,kowshik,2020-09-29T08:29:47Z,done.,0,0.9897913336753845
496528445,9001,kowshik,2020-09-29T08:30:00Z,done.,0,0.9897913336753845
496530810,9001,kowshik,2020-09-29T08:32:23Z,done. good point. i'm now logging just a warning and i've removed the stacktrace from the return value.,1,0.9676322340965271
496531037,9001,kowshik,2020-09-29T08:32:31Z,done.,0,0.9897913336753845
496534914,9001,kowshik,2020-09-29T08:36:03Z,done.,0,0.9897913336753845
496535534,9001,kowshik,2020-09-29T08:36:37Z,done. great point.,1,0.9926064014434814
496535646,9001,kowshik,2020-09-29T08:36:42Z,done.,0,0.9897913336753845
496538616,9001,kowshik,2020-09-29T08:39:26Z,done. i have now moved it to the package: `org.apache.kafka.clients.admin`.,0,0.968397319316864
496543685,9001,kowshik,2020-09-29T08:44:03Z,"i agree. but note that in this method, we do not process an `updatefeaturesrequest`. this method is only called during controller election to setup feature versioning. so, i have incorporated your suggestion at the point where we process the request, look for `def processfeatureupdateswithactivecontroller` in this file where now i set the zk write timeout to be `min(timeoutms, config.zkconnectiontimeoutms)`.",0,0.9498059153556824
496544239,9001,kowshik,2020-09-29T08:44:33Z,done.,0,0.9897913336753845
496550557,9001,kowshik,2020-09-29T08:54:04Z,"we need to keep the existing validation. here is a case where `minversionlevel < firstactiveversion` is true, but still there are no incompatibilities: [code block] for example, the above can happen during step 1 of feature verison level deprecation. imagine the following: * a supported feature exists with `supportedversionrange={minversion=1, firstactiveversion=4, maxversion=7}` * the above feature is finalized at `{minversionlevel=2, maxversionlevel=6}` in zk already. then imagine a new kafka release is deployed that raises `firstactiveversion` for the supported feature from 1 -> 4 (in order to deprecate versions: 1,2,3). in such a case, during kafka server startup (where we check for feature incompatibilities), we would run into the comparison cited above between the new `supportedversionrange` and existing `finalizedversionrange`. but it is not considered to be a case of incompatibility.",0,0.9920449256896973
496901588,9001,abbccdda,2020-09-29T17:06:45Z,"do we want to have a different name from `org.apache.kafka.common.feature.finalizedversionrange`, such as `finalizedversionlevels`? same case for `supportedversionrange`, personally i feel the same class name makes the navigation harder.",0,0.9513646364212036
496916316,9001,abbccdda,2020-09-29T17:30:34Z,"i think we could just make the `firstactiveversion = minversion` by default, to avoid the requirement for configuring firstactiveversion",0,0.9871947169303894
496917029,9001,abbccdda,2020-09-29T17:31:41Z,similar here to make `firstactiveversion = minversion` as default.,0,0.9940744042396545
496917907,9001,abbccdda,2020-09-29T17:33:09Z,"so we are saving the zk epoch in a long, which was supposed to be an int field?",0,0.9917179346084595
497255894,9001,kowshik,2020-09-30T05:46:08Z,"yes, but can i do it in a follow-up pr? the reason is if i were to refactor it now, this pr will bloat up.",0,0.9669249653816223
497256162,9001,kowshik,2020-09-30T05:47:01Z,done. i've provided an overloaded c'tor now in `org.apache.kafka.common.feature.supportedversionrange` that only takes `minversion` and `maxversion` as parameters.,0,0.9821481704711914
497256475,9001,kowshik,2020-09-30T05:48:03Z,"as mentioned in above response to a different comment, i've provided an overloaded c'tor now in `org.apache.kafka.common.feature.supportedversionrange` that only takes `minversion` and `maxversion` as parameters.",0,0.9950923919677734
497257420,9001,kowshik,2020-09-30T05:51:12Z,we would like to avoid overflow issues once zk is gone in the future. this change is being done based on colin's suggestion in the kip-584 voting thread: - [a link] is colin's comment - [a link] is my response,0,0.9936063289642334
497399425,9001,kowshik,2020-09-30T10:17:16Z,done. the `firstactiveversion` is now part of `apiversionsresponse`. i added it in the recent commit: a7f4860f5f8bb87cfb01452e208ff8f4e45bcd8b.,0,0.979956865310669
497793784,9001,junrao,2020-09-30T20:53:28Z,"hmm, why do we need to take the min? if the zk data is propagated quickly, waituntilepochorthrow() will just return early.",0,0.9773831367492676
497813798,9001,junrao,2020-09-30T21:34:06Z,"i was looking at existing classes fro the return value. for example, createaclsresult deliberately makes the constructor non-public.",0,0.9893693923950195
497848498,9001,junrao,2020-09-30T23:05:04Z,it's useful to return an error message too.,0,0.9928225874900818
497850391,9001,junrao,2020-09-30T23:11:02Z,could we use collections.emptymap()?,0,0.9944725632667542
497856858,9001,junrao,2020-09-30T23:32:11Z,"this can throw an exception due to feature mismatch. currently, this forces the controller to move but keeps the broker alive. should we force the broker to exit in this case?",0,0.9914088845252991
498072158,9001,kowshik,2020-10-01T08:29:43Z,"done. good point, removed the min now.",1,0.9758565425872803
498092489,9001,kowshik,2020-10-01T09:03:09Z,done. good catch. also i've modified `org.apache.kafka.clients.admin.{supported|finalized}versionrange` classes to make constructors non-public.,1,0.9893920421600342
498093400,9001,kowshik,2020-10-01T09:04:48Z,would the default error message suffice?: `unable to update finalized features due to an unexpected server error.`,0,0.9752306342124939
498094043,9001,kowshik,2020-10-01T09:05:53Z,done.,0,0.9897913336753845
498113308,9001,kowshik,2020-10-01T09:38:02Z,"done. good point. it looks appropriate to me that we exit the broker in this case. i've captured the exception and added a call to `exit.exit(1)`, is there a better way to do it?",1,0.9773526191711426
498420758,9001,junrao,2020-10-01T17:55:31Z,"thinking about this a bit more. it seems that the intention of firstactiveversion is to avoid deploying a wrong version of the broker that causes the deprecation of a finalized feature version unexpectedly. however, the same mistake can happen with firstactiveversion since the deprecation of a finalized feature version is based on firstactiveversion. so, i am not sure if firstactiveversion addresses a real problem. in general, we tend to deprecate a version very slowly in ak. so, if the mistake is to deploy a new release that actually deprecates a supported version. old clients are likely all gone. so, moving finalized min version to supported min version may not cause a big problem. we can just document that people should make sure old versions are no longer used before deploying new releases. if the mistake is to deploy an old version of the broker whose maxsupportedversion is < maxfinalizedversion, we will fail the broker. so, this mistake can be prevented.",0,0.8080269694328308
498495464,9001,kowshik,2020-10-01T20:27:42Z,": i'd like to discuss an example that cites a problem i'm concerned about. let's say we have some feature `f` whose: * supported version range is: `[minversion=1, maxversion=6]` * existing finalized version range in the cluster is: `[minversionlevel=1, maxversionlevel=6]` now, let us say a point in time arrives when we need to deprecate the feature version `1`. let us say we bump up supported `minversion` to `2` in a subsequent major kafka release. before this new release is deployed, let us assume the cluster operator knows 100% that old clients that were using the feature at version `1` are gone, so this is not a problem. **problem:** still, if we deploy this new release, the broker will consider the following as a feature version incompatibility. * supported version range is: `[minversion=2, maxversion=6]` * existing finalized version range in the cluster is: `[minversionlevel=1, maxversionlevel=6]` upon startup of a broker thats using the new release binary, the above combination will crash the broker since supported `minversion=2` is greater than `minversionlevel=1`. basically the versioning system thinks that there is now a broker that does not support `minversionlevel=1`, which does not adhere to the rules of the system. we currently do feature version incompatibility checks during kafkaserver startup sequence, [a link]. here is my thought: this is where `firstactiveversion` becomes useful. by bumping it up during a release (instead of the supported feature's `minversion`), we are able to get past this situation. when `firstactiveversion`is advanced in the code, and the cluster is deployed, the controller (and all brokers) know that the advancement acts a request to the controller to act upon the feature deprecation (by writing the advanced value to the `featureznode`). so, in this case we would release the broker with the supported feature version range: `[minversion=1, firstactiveversion=2, maxversion=6]`, and the broker release wouldn't fail (because the intent is clearly expressed to the versioning system). what are your thoughts on the above? is there a different way to solve it better that i'm missing, without compromising the versioning checks enforced by the system?",0,0.8484565019607544
498512579,9001,junrao,2020-10-01T21:04:51Z,": i was thinking what if we relax the current check by just making sure that maxversion of finalized is within the supported range. basically in your example, if supported minversion goes to 2, it's still allowed since it's less than maxversion of finalized. however, if supported minversion goes to 7, this fails the broker since it's more than maxversion of finalized. your concern for the relaxed check seems to be around deploying a wrong version of the broker by mistake. i am not sure if that's a big concern. if the wrong broker affects maxversion of finalized, the broker won't start. if the wrong broker affects minversion of finalized, if we deprecated slowly, it won't impact the existing clients.",0,0.8365217447280884
498574911,9001,kowshik,2020-10-02T00:38:05Z,"does the below feel right to you? the key thing seems to be that you feel it is rare to deprecate feature versions in ak. i agree with the same. so, i propose we just do not have to solve the deprecation problem in this pr, until we find a clear route that the ak community agrees with. in this pr i propose to revert the `firstactiveversion` change, leaving the rest of the things the way they are. in the future, we can develop a concrete solution for version deprecation i.e. the part on how to advance `minversion` of supported feature, may be (or may not be) using `firstactiveversion` or other ways (it is up for discussion, maybe in a separate kip). i have made this proposed change in the most recent commit: 4218f95904989028a469930d0c266362bf173ece. regarding your thought: there is a consequence to relaxing the current check: the controller can not effectively finalize `minversionlevel` for the feature, because, with a relaxed check we do not know whether all brokers in the cluster support a particular `minversion` when the controller finalizes the `minversionlevel` at a particular value. it seems useful to keep the concept of `minversionlevel` like the way it is now (i.e. it is the lowest version guaranteed to be supported by any broker in the cluster for a feature). and as i said above, in the future, we can decide on ways to mutate it safely (maybe through `firstactiveversion` or other means).",0,0.9608308672904968
498959506,9001,junrao,2020-10-02T17:39:15Z,"this this case, existingfeatureznode.features is expected to be empty? could we log a warn if this is not the case and always set finalized to empty?",0,0.9910524487495422
498960633,9001,junrao,2020-10-02T17:41:40Z,should we call updatefeatureznode() so that we can get the logging?,0,0.9950867295265198
498980025,9001,junrao,2020-10-02T18:19:31Z,"this test may not be enough. the issue is that when a controller fails over, it's possible that new brokers have joined the cluster during the failover. so, if existingfeatureznode is enabled, it may not be reflecting the state in those newly joined brokers. so, it seems that we need to do the validation for every broker during controller failover in that case.",0,0.9730227589607239
499034372,9001,junrao,2020-10-02T20:25:16Z,"""we do not know whether all brokers in the cluster support a particular minversion when the controller finalizes the minversionlevel at a particular value."" the controller knows the minsupportedversion for all brokers, right? what if we do the following? when finalizing a feature, the controllers uses the highest minsupportedversion across all brokers as finalizedminversion, as long as it's <= finalizedmaxversion. on broker restart, we also advance finalizedminversion if the new broker's minsupportedversion has advanced (assuming still <= finalizedmaxversion).",0,0.9908103942871094
499036138,9001,junrao,2020-10-02T20:29:54Z,could we make the constructor non-public?,0,0.9927474856376648
499036605,9001,junrao,2020-10-02T20:31:03Z,could we make the constructor non-public?,0,0.9927474856376648
499102118,9001,kowshik,2020-10-03T01:14:01Z,done.,0,0.9897913336753845
499102130,9001,kowshik,2020-10-03T01:14:05Z,done.,0,0.9897913336753845
499102146,9001,kowshik,2020-10-03T01:14:17Z,done.,0,0.9897913336753845
499102163,9001,kowshik,2020-10-03T01:14:24Z,done.,0,0.9897913336753845
499102176,9001,kowshik,2020-10-03T01:14:36Z,done. excellent catch.,1,0.9914828538894653
499102266,9001,kowshik,2020-10-03T01:15:32Z,"awesome. this is a very good point. the approach you proposed is very elegant, and we should shoot for it, when were giving the benefit of the doubt on deprecation to the broker binary version. ill update the kip with details and share with community for feedback. as soon as that is done, i'll follow up in separate pr implementing this logic.",1,0.9951700568199158
499739889,9001,junrao,2020-10-05T16:54:25Z,it's a bit weird that featureznode.status is defined as featureznodestatus.value. it seems that it should be defined as just featureznodestatus?,-1,0.9779177904129028
499740489,9001,junrao,2020-10-05T16:55:28Z,should we log the non-empty features too?,0,0.993626594543457
499753420,9001,junrao,2020-10-05T17:18:52Z,should we revert the changes here?,0,0.9875431060791016
499761963,9001,junrao,2020-10-05T17:34:20Z,"this is probably not enough since it only waits for the controller path to be created in zk, which happens before the processing of the finalized features.",0,0.9794448018074036
499775367,9001,junrao,2020-10-05T17:59:22Z,could we add feature to the javadoc above?,0,0.9945449829101562
499776675,9001,junrao,2020-10-05T18:01:47Z,should we use a version > 0?,0,0.991622269153595
499776894,9001,junrao,2020-10-05T18:02:14Z,typo thats,0,0.9873014688491821
499810462,9001,kowshik,2020-10-05T19:05:24Z,"done. i have improved it now introducing a type definition called `featureznodestatus` that points to `value`. iiuc you were referring to this loc, correct? [a link] here the enum: `featureznodestatus` is defined and used in the same file. i thought i'd add an `import` to fix it like the below, but it was a little unusual to add an `import` statement right above the class definition: [code block] with my recent change, in the future it should be possible to `import featureznodestatus._` within other files when referring to the enum value.",0,0.8081877827644348
499811265,9001,kowshik,2020-10-05T19:06:45Z,done.,0,0.9897913336753845
499811752,9001,kowshik,2020-10-05T19:07:42Z,done. nice catch!,1,0.9957658052444458
499812076,9001,kowshik,2020-10-05T19:08:21Z,done.,0,0.9897913336753845
499816373,9001,kowshik,2020-10-05T19:16:34Z,done. good point.,1,0.9824387431144714
499816619,9001,kowshik,2020-10-05T19:17:03Z,done.,0,0.9897913336753845
499847021,9001,kowshik,2020-10-05T20:16:35Z,done. please take a look at the fix. i've added logic to wait for processing on a dummy event just after waiting for controller election. i'm hoping this will make sure the controller failover logic is completed before the test proceeds further to make assertions.,0,0.7731359004974365
501418496,9001,chia7712,2020-10-08T02:53:08Z,"the error message says it can't be null but there is no null check. for another, this check can happen early (when creating [code block])",0,0.9917900562286377
501432770,9001,chia7712,2020-10-08T03:51:37Z,"should we add an empty-parameter variety for [code block]? that is similar to other methods, like [code block] and [code block].",0,0.9936049580574036
501489060,9001,chia7712,2020-10-08T06:58:43Z,the top-level error message is not propagated.,0,0.9858824014663696
501575432,9001,kowshik,2020-10-08T09:26:06Z,done. addressed in #9393.,0,0.9903049468994141
501575489,9001,kowshik,2020-10-08T09:26:11Z,done. addressed in #9393.,0,0.9903049468994141
501575519,9001,kowshik,2020-10-08T09:26:13Z,done. addressed in #9393.,0,0.9903049468994141
102111062,2476,becketqin,2017-02-21T00:13:51Z,the variable names seem a little misleading. are all partitions without leader information unauthorized?,0,0.722973108291626
102111239,2476,becketqin,2017-02-21T00:16:05Z,should we use the exception returned by the broker in this case?,0,0.9930608868598938
102113712,2476,becketqin,2017-02-21T00:48:53Z,"when `client.poll(future, remaining)` returns true, the future may either contains a value (succeeded) or an error (failed). if the future has an error, calling `future.value()` will throw exception. it seems better if we can return the full results to the users even if some of the requests failed so the users will be able to know which partitions has failed to purge.",0,0.9914255142211914
102114179,2476,becketqin,2017-02-21T00:55:27Z,"it seems a single `consumernetworkclient.poll(0)` cannot guarantee all the requests are sent out. also, the interface might be a little weird that after `purgedatabefore()` is returned the users have to keep calling future.client.poll() otherwise the futures will not be completed. i am wondering how would user use the asynchronous purge in this case? at very least we should document this clearly.",0,0.5828503370285034
102114578,2476,becketqin,2017-02-21T01:00:08Z,this could just be a string concatenation.,0,0.9823228716850281
102116849,2476,becketqin,2017-02-21T01:29:45Z,this seems a little over optimizing. any reason we care about invoking time.milliseconds here more than in line 441 and everywhere else?,0,0.8183044195175171
102117137,2476,becketqin,2017-02-21T01:33:37Z,should we log the partition information and which replica is unavailable here?,0,0.9937559366226196
102117519,2476,becketqin,2017-02-21T01:38:43Z,should this be in write lock?,0,0.9924448132514954
102118327,2476,becketqin,2017-02-21T01:47:26Z,is this comment accurate?,0,0.9903568625450134
102118888,2476,becketqin,2017-02-21T01:54:33Z,nit: could be `mapvalues`.,0,0.9940820336341858
102119889,2476,becketqin,2017-02-21T02:06:32Z,"methods with three tuples as return value may be a little hard to follow, may be we can create a case class. at very least we should document each field of the return value.",0,0.9823087453842163
102121248,2476,becketqin,2017-02-21T02:22:07Z,do we want to distinguish between no_log_start_offset v.s. log_start_offset = 0? is it clearer to define the no_log_start_offset as -1?,0,0.9936536550521851
102146034,2476,lindong28,2017-02-21T07:37:14Z,agree. i have updated the names.,0,0.986588180065155
102146077,2476,lindong28,2017-02-21T07:37:42Z,good point. i have updated code to use error from metadatarequest.,1,0.9789840579032898
102146450,2476,lindong28,2017-02-21T07:40:56Z,great point. i have updated the adminclient to create its own thread to do `client.poll(retrybackoffms)`. i find it necessary for adminclient to have its own thread in order to support both syn and async operation. i have also added `testlogstartoffsetafterasyncpurge()` to validate the asyn purge operation.,1,0.9860337376594543
102147486,2476,lindong28,2017-02-21T07:49:25Z,"this should not be a problem for `purgedatabefore()`, because those `futures` provided to the `compositefuture` has been constructed in such a way that they never raises exception. those future will call `future.complete(result)` in case of `onfailure`, where result indicates has the error information. i agree it would be make `compositefuture` more useful if this class handles the logic of converting error to result and return the full results to user as you suggested. but i don't have a good way to do it now because `compositefuture` doesn't know the type of the return value -- it currently use template `t`.",0,0.974740743637085
102147741,2476,lindong28,2017-02-21T07:51:19Z,is there any negative impact to use stringbuilder as compared to string concatenation? using stringbuilder here allows us to have the same code style as `tostring()` of other requests such as `producerequest` and `leaderandisrrequest`.,0,0.9876154661178589
102147786,2476,lindong28,2017-02-21T07:51:46Z,good point. i have updated the log message as you suggested.,1,0.9781045317649841
102147860,2476,lindong28,2017-02-21T07:52:34Z,i think it is not bad to remove one unnecessary call to `time.milliseconds`. i removed it since you don't like it.,1,0.5827003121376038
102148192,2476,lindong28,2017-02-21T07:55:22Z,i validated that we can not use `mapvalues()` here. this is because `mapvalues()` returns a map view which maps every key of this map to `f(this(key))`. the resulting map wraps the original map without copying any elements. as a result `status.ackspending = true` in the constructor of `delayedpurge` becomes no-op.,0,0.991768479347229
102148242,2476,lindong28,2017-02-21T07:55:47Z,good point. i have updated the code to make it more readable.,1,0.9782125353813171
102148307,2476,lindong28,2017-02-21T07:56:18Z,"i think we should use readlock since this method doesn't update leader or isr of the partition, right?",0,0.9894161820411682
102148443,2476,lindong28,2017-02-21T07:57:24Z,it was not accurate. i have updated the comment to replace `all replicas of this broker` to `in-sync replicas of this broker`,0,0.9781977534294128
102148589,2476,lindong28,2017-02-21T07:58:36Z,i don't think it is necessary to distinguish between no_log_start_offset v.s. log_start_offset = 0. is there any use-case for no_log_start_offset?,0,0.989179253578186
102260819,2476,becketqin,2017-02-21T17:01:27Z,"not much difference, just for readability (see below) we can keep them the same as other requests. [a link]",0,0.9839676022529602
102263429,2476,becketqin,2017-02-21T17:12:12Z,"yes, you are right. read lock here is fine.",0,0.9298863410949707
102265149,2476,becketqin,2017-02-21T17:19:34Z,"in general, we want to identify the state of the system as clear as possible. the follower should not take any action if the log_start_offset on the broker is no_log_start_offset. but if the follower sees the leader returning the starting offset = 0 while the actual starting offset on the leader is not, this introduces confusion.",0,0.9877808094024658
102267118,2476,becketqin,2017-02-21T17:27:24Z,the kip stated that the consumer will put value -1l as the log_begin_offset.,0,0.9953872561454773
102267688,2476,becketqin,2017-02-21T17:29:46Z,"nit: in consumer we use the term ""earliest"" instead of ""smallest"", maybe we can make the term consistent.",0,0.982286274433136
102269297,2476,becketqin,2017-02-21T17:37:30Z,maybe we should always use the latest version here?,0,0.9827682375907898
102269853,2476,becketqin,2017-02-21T17:39:51Z,latest version?,0,0.9937554597854614
102289505,2476,lindong28,2017-02-21T19:04:23Z,agree. i have updated the code to test all versions of fetchresponse.,0,0.9857625961303711
102289533,2476,lindong28,2017-02-21T19:04:33Z,sure. updated to use latest version here.,0,0.990622341632843
102289562,2476,lindong28,2017-02-21T19:04:42Z,sure. made the change.,0,0.9902408123016357
102289627,2476,lindong28,2017-02-21T19:04:58Z,nice catch. updated to use -1l here.,1,0.9905591011047363
103133485,2476,becketqin,2017-02-27T03:54:41Z,"the comment is a little confusing here. how about ""the offset before which the messages will be deleted.""",0,0.812336802482605
103134243,2476,becketqin,2017-02-27T04:09:47Z,sleeping here seems not ideal and may miss subsequent action invoked by the users. we probably want to have a long poll() and just wake up the networkthread when needed.,0,0.8989159464836121
103134387,2476,becketqin,2017-02-27T04:12:42Z,"since we have separate thread now, retry could be done without involving users, right?",0,0.989130973815918
103136031,2476,becketqin,2017-02-27T04:45:50Z,nit: can we just call it timebeforelocalpurge?,0,0.9659181833267212
103136983,2476,becketqin,2017-02-27T05:02:36Z,"if we want to make this optimization, we should do it in line 330 as well.",0,0.991446852684021
103138261,2476,becketqin,2017-02-27T05:26:55Z,the earliest offset allowed...,0,0.9938739538192749
103138990,2476,becketqin,2017-02-27T05:38:11Z,"the statement here is a little misleading. logstartoffset is not used to ""decide"" the log retention. the log retention is still based on time/size limit. the logstartoffset will be updated by retention. a manual update of logstartoffset may trigger the log deletion.",0,0.7568703889846802
103139730,2476,becketqin,2017-02-27T05:49:15Z,"hmm, why would truncation change the startlogoffset? shouldn't truncation always be above the startlogoffset?",0,0.9818373322486877
103140001,2476,becketqin,2017-02-27T05:53:11Z,"the update of logstartoffset should probably be synchronized and ensure no rewind will happen, otherwise a fetch request may see an incorrect logstartoffset.",0,0.9915220737457275
103140524,2476,becketqin,2017-02-27T06:00:58Z,"it seems we should be careful about when to delete the log segments. in the current code, when the leader deleted an old log segment. the low watermark will not increase immediately because the followers has not updated the logstartoffset yet. however, at this point if user tries to fetch from lw, they will receive an offset out of range exception, which is not expected. one solution would be letting the segment deletion to be based on the low watermark instead of logstartoffset. so we need to delay the log deletion until low watermark is updated. similarly the valid range of fetch request should be based on lw instead of logstartoffset. nit: there is an existing typo in line 729, which missed a ""t"" in ""deleteretentionmsbreachedsegments()"".",0,0.9782282114028931
103140662,2476,becketqin,2017-02-27T06:02:53Z,"should it be an error to truncate beyond the logstartoffset? logstartoffset should not decrease, right?",0,0.9840033650398254
103140993,2476,becketqin,2017-02-27T06:07:48Z,"it seems that we should also checkpoint low watermarks, right?",0,0.9904453754425049
103272179,2476,lindong28,2017-02-27T18:07:47Z,"when there is no pending requests, `consumernetworkclient.poll(...)` blocks for up to `retrybackoffms`. it means the thread does poll() in kind of busy looping manner if we don't sleep here. also, the thread holds the lock on `consumernetworkclient` while blocked on `selector.poll()` which means the user will be blocked waiting for lock in order to enqueue requests.",0,0.9916692972183228
103273306,2476,lindong28,2017-02-27T18:13:28Z,"yes we can, if we ask user to specify retries num and retry back off. current implementation assumes retries = 1. this seems like an optimization which may be added later?",0,0.992283284664154
103273330,2476,lindong28,2017-02-27T18:13:35Z,sure. fixed now.,0,0.9459871053695679
103273660,2476,lindong28,2017-02-27T18:15:11Z,"do you mean `debug(""produce to local log in %d ms"".format(time.milliseconds - stime))`? i thought this `time.milliseconds` will only be evaluated if debug level logging is enabled, no?",0,0.9940766096115112
103274743,2476,lindong28,2017-02-27T18:20:09Z,sure. fixed now.,0,0.9459871053695679
103275187,2476,lindong28,2017-02-27T18:22:19Z,fixed.,0,0.9905837774276733
103276622,2476,lindong28,2017-02-27T18:28:41Z,"i include this scenario because i couldn't provide that log truncation will always be above the logstartoffset. for example, we have had bug such that log may be truncated below high watermark in case of double failure.",0,0.9937483072280884
103276835,2476,lindong28,2017-02-27T18:29:37Z,sure. i changed it to `log deletion`.,0,0.9853790998458862
103288992,2476,lindong28,2017-02-27T19:23:42Z,good point. i just added `lock` around this.,1,0.971599817276001
103293344,2476,lindong28,2017-02-27T19:42:11Z,"sure, the typo is fixed. in the current implementation, if user seeks to earliest offset, he/she will seek to the `logstartoffset` of the leader regardless of what is the low watermark. user will not seek to lw since lw is not even exposed to the user. is there any concern with this approach?",0,0.9884418249130249
103295145,2476,becketqin,2017-02-27T19:49:35Z,"if poll() itself is not a busy looping internally, we will not have a busy loop (even though it look like so). however, in the current case, if retry back off is set to 0, we do have a busy poll(). holding a lock and blocking on selector.poll() is strange, maybe we should reconsider that. even if that is true, we can still have a queue outside of the consumernetworkclient and wake up the sender thread to poll from that queue.",0,0.6825175881385803
103295641,2476,lindong28,2017-02-27T19:51:32Z,if everything is implemented correctly then log start offset should not decrease. but in reality we have seen unlean leader election during double failure where the logendoffset is truncated beyond high watermark. it seems safer to preserve the existing behavior of `truncateto()` and allow logstartoffset to be reduced if such truncation does happen instead of throwing exception. note that such truncation will only happen as part of unclean leader election initiated by the brokers themselves.,0,0.9906067848205566
103295886,2476,lindong28,2017-02-27T19:52:40Z,"no, we intentionally only checkpoint logstartoffset. is there any reason to checkpoint lowwatermark?",0,0.993613064289093
103307226,2476,becketqin,2017-02-27T20:43:41Z,it will call `time.milliseconds` because it is an argument passed to the `debug()`.,0,0.994809627532959
103307455,2476,becketqin,2017-02-27T20:44:49Z,"if it is not an expected behavior, we should throw some exception instead of allowing the lw to decrease, right?",0,0.9815087914466858
103310427,2476,ijuma,2017-02-27T20:58:41Z,"i'm a bit confused about the discussion here, so i'll just explain how it works. :) whatever one passes as a parameter to `debug` is only evaluated if debug logging is enabled. at runtime, a `function0` is passed and the body of that function is the block of code passed as the parameter to `debug`. does that make sense?",1,0.9909716844558716
103362427,2476,becketqin,2017-02-28T02:16:09Z,"thanks for the clarification . you are right, i realized that after taking a closer look.",1,0.9745868444442749
103580604,2476,lindong28,2017-02-28T23:49:38Z,"discussed offline. given that existing apis such as `adminclient.listgroupoffsets(..)` and `kafkaconsumer.retrieveoffsetsbytimes(..)` would not retry and just expose the exception to user, it should be ok for `adminclient.purgedatabefore(...)` to do the same thing. if we think it is useful to retry for user, we probably want to discuss the new configs and do it in java adminclient as part of kip-117.",0,0.9903696179389954
103580824,2476,lindong28,2017-02-28T23:51:17Z,"discussed offline. given that `log.truncateto(...)` has explicitly consider the case that the targetoffset is smaller than base offset of the first log segment, it would be safer and simpler for us to assume that `log.truncateto(...)` can truncate to an offset smaller than logstartoffset.",0,0.9935697317123413
103580946,2476,lindong28,2017-02-28T23:52:03Z,"discussed offline. given that log.truncateto(...) has explicitly consider the case that the targetoffset is smaller than base offset of the first log segment, it would be safer and simpler for us to assume that log.truncateto(...) can truncate to an offset smaller than logstartoffset.",0,0.9935617446899414
103595573,2476,lindong28,2017-03-01T01:49:32Z,"i have updated the adminclient to remove the sleep operation. and the patch guarantees that if user thread attempts to send any request, it will get the lock on consumernetworkclient and enqueue the requests once the currehnt `client.poll(..)` exits. the user thread may still wait up to `maxretrybackoffms` in order to send the requests as of current implementation. this is because `consumernetworkclient.poll(...)` does not guarantee that it will unblock and send the request if there is available request to be send by `consumernetworkclient.send(...)`. the problem exists even if we have a queue outside of consumernetworkclient and use only one thread to call `consumernetworkclient.poll(...)` and `consumernetworkclient.send(...)`. having user thread wake up consumer may help reduce the chance of unnecessary block but doesn't prevent this from happening. ideally we want to be able to fix consumernetworkclient so that user's request should get sent immediately if there is no other inflight requests. but it turns out to be a non-trivial fix. the problem is that `consumernetworkclient.poll(...)` will hold the lock of `consumernetworkclient` while it is blocked on `nioselector.select(ms)`. if user calls `nioselector.wakeup()`, it may be lost if the sender thread is right before the `nioselector.select(ms)` while `nioselector.wakeup()` is called. if user attempt to get the lock of `consumernetworkclient` before calling `nioselector.wakeup()`, then it will block as well while trying to get the lock. we need to find a way for the `poll(...)` to release lock while it is waiting on `nioselector.select(ms)`. but i don't have an easy way to fix it.",0,0.990528404712677
103671647,2476,ijuma,2017-03-01T12:21:50Z,"i didn't see this mentioned in the kip. this is a user facing cli tool, so we should mention it there.",0,0.9850430488586426
103671752,2476,ijuma,2017-03-01T12:22:42Z,"we can only do this once there's agreement that the next release is 0.11.0. luckily, i started that discussion recently and people seem to be in favour. :)",1,0.9944174289703369
103671959,2476,ijuma,2017-03-01T12:23:50Z,"since 0.10.0, we do the `iv0` thing (e.g. `kafka_0_11_0_iv0`). the version string should be changed accordingly.",0,0.9944367408752441
103672175,2476,ijuma,2017-03-01T12:25:02Z,an empty synchronized block doesn't do anything. is this still in progress?,0,0.9246178269386292
103681117,2476,ijuma,2017-03-01T13:21:02Z,"just so that we are on the same page. until this method is available in the java adminclient, there is no public api for it (i.e. the scala `adminclient` is an internal class), right? so, the tool is the only way to do it if one doesn't want to deal with breakage later.",0,0.9911572933197021
103748555,2476,lindong28,2017-03-01T18:00:15Z,i included it as a way for myself and probably reviewers to test the patch. i was not sure if it needs to be included in the patch. let me propose it in the mailing thread and specify it in the kip. i am ok to remove it if others don't think it is necessary.,0,0.9470091462135315
103748701,2476,lindong28,2017-03-01T18:00:59Z,great. thanks for confirmation :),1,0.9967299699783325
103749257,2476,lindong28,2017-03-01T18:03:45Z,i see. i changed this to `kafka_0_11_0_iv0`.,0,0.9919346570968628
103750145,2476,lindong28,2017-03-01T18:08:14Z,"it is actually needed as a way for user thread to get the lock to enqueue requests once sender thread has finished its current `client.poll(...)`. even though it is empty, this synchronzed block is still useful because some other thread may have the lock here. this trick will no longer be needed after kafka-4820 is committed.",0,0.9933039546012878
103751509,2476,lindong28,2017-03-01T18:14:51Z,have we explicitly stated in the code or documentation that this class is internal and should not be used by users? becket is not aware of this as well. it seems that user can already construct scala adminclient directly and that is how i expect this api to be used.,0,0.9906525611877441
103792810,2476,ijuma,2017-03-01T21:25:42Z,"since this is going away, i won't comment further. :)",1,0.9925819635391235
103793255,2476,ijuma,2017-03-01T21:27:59Z,i see. sounds good to ask in the mailing list thread if people think it's useful.,1,0.842819333076477
103793302,2476,ijuma,2017-03-01T21:28:15Z,"if we keep this class, we need to update the comment.",0,0.99136883020401
103794835,2476,ijuma,2017-03-01T21:35:34Z,"by the way, i think the code as it is now is a bit dangerous. imagine that there are some changes and this field starts being used in info logging. it's not unlikely that a bug will be introduced. is this optimisation really worth doing?",-1,0.9339778423309326
103795078,2476,ijuma,2017-03-01T21:36:36Z,what is the reason for this change?,0,0.9925865530967712
103795243,2476,ijuma,2017-03-01T21:37:29Z,what is the reason for this change?,0,0.9925865530967712
103796063,2476,ijuma,2017-03-01T21:41:20Z,"the vast majority of kafka code is not public api. the somewhat unintuitive way that public api is defined at the moment is by what has javadoc published: [a link] apart from that, the old producers and consumers are also public api (until we remove them). the admin package is definitely internal and that's why there was no kip for the scala adminclient when it was added in 0.9.0.0 (or any of the changes since).",0,0.9905836582183838
104300596,2476,lindong28,2017-03-05T00:07:59Z,ok. the optimization is removed now.,0,0.9933549165725708
104300644,2476,lindong28,2017-03-05T00:09:59Z,discussed offline. the issue is resolved after we change the definition of lowwatermark to be the minimum logstartoffset of all live replicas.,0,0.9947811961174011
104300648,2476,lindong28,2017-03-05T00:10:22Z,discussed offline. we don't need to checkpoint lowwatermark.,0,0.9941603541374207
104300660,2476,lindong28,2017-03-05T00:11:23Z,i have updated the kip to include this script and email the mailing thread about this addition. there is no objection so far. i assume we can include this script in the patch.,0,0.9789001941680908
104300670,2476,lindong28,2017-03-05T00:12:10Z,the `synchronized` has been removed in the patch after rebasing the patch onto the trunk. kafka-4820 has been committed to the trunk.,0,0.9955539107322693
104300696,2476,lindong28,2017-03-05T00:14:58Z,i see. i think the method is available in two ways. user can use the script without having to deal with breakage later. and user can also uses our internal api and will need to deal with breakage later. linkedin kafka team will use the second solution and is ok to deal with breakage later.,0,0.9722331166267395
104300714,2476,lindong28,2017-03-05T00:16:25Z,"thanks. i have updated the comment to ""a command for purging data of given partitions to the specified offset.""",1,0.9353892207145691
104300777,2476,lindong28,2017-03-05T00:19:27Z,it is a side effect of making change and reverting change in the process of implementing this patch. i have changed it to the original order.,0,0.9868931770324707
104301004,2476,lindong28,2017-03-05T00:38:27Z,i thought `setup()` and `teardown()` will be executed once for every test method (e.g. testconsumeafterpurge) but the initialization of `consumers` in `trait integrationtestharness` will be executed only once per test class (e.g. adminclienttest). i am wrong. i have reverted this change.,0,0.8102424740791321
104834321,2476,junrao,2017-03-08T02:56:13Z,we probably want to add a comment that this is only used in the fetch requests from the followers.,0,0.9930993318557739
104834398,2476,junrao,2017-03-08T02:57:11Z,could we adjust the comment above accordingly?,0,0.9939846396446228
104834503,2476,junrao,2017-03-08T02:58:43Z,do we need to override this method to public?,0,0.9946534633636475
104834563,2476,junrao,2017-03-08T02:59:22Z,unused import,0,0.9873000979423523
104834590,2476,junrao,2017-03-08T02:59:42Z,"hmm, not sure about this. in general networkclient is not thread safe.",0,0.6682966947555542
104834673,2476,junrao,2017-03-08T03:00:18Z,it's kind of weird to use a consumernetworkclient to implement purgedatabefore() since this api has nothing to do with consumer.,-1,0.9827792048454285
104834719,2476,junrao,2017-03-08T03:01:01Z,unused import,0,0.9873000979423523
104834774,2476,junrao,2017-03-08T03:01:42Z,%s => %d for oldlowwatermark and newlowwatermark,0,0.9859673380851746
104834848,2476,junrao,2017-03-08T03:02:37Z,"hmm, should we take max here?",0,0.9640997648239136
104834900,2476,junrao,2017-03-08T03:03:15Z,"to be consistent with the logic in recovery, should we initialize this to baseoffset?",0,0.9947718977928162
104834928,2476,junrao,2017-03-08T03:03:39Z,could we add the new param to javadoc above and adjust the comment accordingly?,0,0.994809627532959
104834990,2476,junrao,2017-03-08T03:04:21Z,d% => %d,0,0.9385619759559631
104835046,2476,junrao,2017-03-08T03:05:03Z,unused import,0,0.9873000979423523
104835080,2476,junrao,2017-03-08T03:05:32Z,hasenough => lowwatermarkreached ?,0,0.9933295845985413
104835108,2476,junrao,2017-03-08T03:06:03Z,could we just reuse logflushoffsetcheckpointintervalmsprop instead of introducing a new config?,0,0.9930365681648254
104835196,2476,junrao,2017-03-08T03:07:03Z,should the comment be changed to all live replicas?,0,0.9933387637138367
104835279,2476,junrao,2017-03-08T03:08:04Z,"do we want to poll with 0 since it can burn cpu unnecessarily? also, instead of duplicating the code for waiting the consumer to be ready, could we factor it out to a private method and reuse?",0,0.9902605414390564
104835345,2476,junrao,2017-03-08T03:08:58Z,is there a need to test async? it seems the sync test is enough?,0,0.9949824810028076
104835380,2476,junrao,2017-03-08T03:09:23Z,"instead of the sleeping for a fixed amount of time, it would be better to do the checking in a waituntiltrue() method.",0,0.9914591312408447
104840525,2476,lindong28,2017-03-08T04:11:36Z,good point. maybe we should specify this in the explanation of the field instead of in the comment? i added following to the field's doc: the field is only used when request is sent by follower. for simplicity i didn't specify that the field will be set to -1 if the request is sent by consumer.,1,0.9303196668624878
104840843,2476,lindong28,2017-03-08T04:16:38Z,ah i should have updated the comment here. it is updated now.,0,0.985572874546051
104841044,2476,lindong28,2017-03-08T04:19:13Z,my bad. i have changed it back to protected.,-1,0.9952741861343384
104841196,2476,lindong28,2017-03-08T04:21:38Z,thanks. fixed now.,1,0.9681604504585266
104841282,2476,lindong28,2017-03-08T04:22:59Z,yeah `networkclient` is not thread-safe. but `consumernetworkclient` explicitly stated in its java doc that it is thread-safe.,0,0.9877669811248779
104841527,2476,lindong28,2017-03-08T04:26:14Z,"i agree this name is a bit weird. maybe we should either rename this class, or implement another `xxxnetworkclient` class to be used for sending requests by java adminclient in the future. as of now i don't have a simple solution for this. i think we can keep it as is and think more thoroughly in the java adminclient. what do you think?",-1,0.7480100989341736
104841631,2476,lindong28,2017-03-08T04:27:50Z,"sorry, i thought checkstyle will catch all unused import but i am wrong. it seems that checkstyle only does this check for java files. will check it manually in the future.",-1,0.9876351952552795
104841846,2476,lindong28,2017-03-08T04:30:57Z,thanks. fixed in both messages.,1,0.9401772022247314
104842139,2476,lindong28,2017-03-08T04:35:40Z,"if we truncate log using `truncatefullyandstartat` to an offset that is higher than the `logstartoffset`, i think we should keep the logstartoffset not changed instead of increasing it, right? it seems similar to the existing logic of updating `recoverypoint`, where we use `math.min`. another argument is that it is safer to assume a small logstartoffset.",0,0.9885728359222412
104842737,2476,lindong28,2017-03-08T04:43:59Z,"i think we still need to set this to -1 initially so that we can call `nextoffsetfromlog()` the first time we access `nextoffset()`. the longer answer: we can set initialize this to `baseoffset` in recovery because we will read all entries in `recovery()`. in the scenario that we do not call `recover()`, we need to initialize `nextoffset` to the `nextoffset` of the latest entry in the log segment file. to trigger this, we need to initialize `nextoffset` to -1 and call `nextoffsetfromlog()` the first time we access `nextoffset()`.",0,0.9901093244552612
104847614,2476,lindong28,2017-03-08T05:38:08Z,good point. it is updated now.,1,0.9816680550575256
104847763,2476,lindong28,2017-03-08T05:39:01Z,my bad. thanks for catching this! fixed now.,-1,0.9931898713111877
104847789,2476,lindong28,2017-03-08T05:39:14Z,fixed now.,0,0.9943431615829468
104848112,2476,lindong28,2017-03-08T05:40:57Z,sure. replaced `hasenough` with `lowwatermarkreached`.,0,0.9858437776565552
104849219,2476,lindong28,2017-03-08T05:49:11Z,"i am not sure. it seems safer to have a separate config. the current default value of `logflushoffsetcheckpointintervalms` is 60 seconds. but we probably want logflushstartoffsetcheckpointintervalms to be set to a lower value because if a broker fails after user purge data but before the logstartoffset is checkpointed, the offset may not be preserved. having separate configs allows user to tradeoff between disk write overhead and logstartoffset persistence. also, it is probably cheaper to checkpoint logstartoffset than checkpointing recoveroffset. we only need to checkpoint logstartoffset for a partition if its logstartoffset > baseoffset, which only happens when user has explicitly requested data purge. thus the actually amount of data written to the log-start-offset-checkpoint file is probably much less than the data written to recovery-point-offset-checkpoint. this means that we can set logflushstartoffsetcheckpointintervalms to a lower value without worrying too much about its overhead.",0,0.9309136271476746
104849362,2476,lindong28,2017-03-08T05:50:56Z,thanks! updated now.,1,0.9807042479515076
104849612,2476,lindong28,2017-03-08T05:53:58Z,it seems that we don't have to worry about cpu burn because `testutils.waituntiltrue()` will wait for 100l between calls to `poll(0)`. sure. i updated the patch to move this wait logic into a separate method.,0,0.9786180257797241
104851102,2476,lindong28,2017-03-08T06:09:38Z,it is no longer needed after we add a dedicated thread in adminclient to do `poll()`. removed now.,0,0.9947739243507385
104851560,2476,lindong28,2017-03-08T06:15:06Z,this test with offline brokers is needed when we define lw to min offset of all replicas. but it is not needed anymore after we change it to beh min offset of all live replicas. i simply removed this part.,0,0.9931049942970276
105036939,2476,lindong28,2017-03-08T22:11:18Z,thought about this more. i think we should just set `logstartoffset` to `newoffset`. the reason is that `truncatefullyandstartat(...)` is supposed to create a new log. thus `logstartoffset` should be the same as `baseoffset` of the first segment.,0,0.9768801927566528
105060654,2476,junrao,2017-03-09T00:29:07Z,"ok, we can leave it as it is.",0,0.9896450042724609
105060659,2476,junrao,2017-03-09T00:29:10Z,"yes, that makes sense.",0,0.9811934232711792
105060668,2476,junrao,2017-03-09T00:29:15Z,"yes, that works. it's just that if we initialize to baseoffset (which is what nextoffsetfromlog() will return on an empty segment), _nextoffset is always initialized properly and we probably can get rid of the if test in nextoffset().",0,0.9905034303665161
105067509,2476,lindong28,2017-03-09T01:20:50Z,"i am not sure we can get rid of the if test in `nextoffset()`. suppose we initialize `_nextoffset` to `baseoffset` and the segment is not empty, when should we call `nextoffsetfromlog()` in order to set `_nextoffset` to the correct value? currently we need the if test in `nextoffset()` to call `nextoffsetfromlog()` on the first invocation of `nextoffset()`. did i miss something?",0,0.9317152500152588
105333239,2476,junrao,2017-03-10T05:30:29Z,could this be private?,0,0.9816126227378845
105333267,2476,junrao,2017-03-10T05:30:54Z,thanks for the explanation. then this is fine.,1,0.9337871670722961
105567622,2476,lindong28,2017-03-12T20:11:43Z,yeah it should be private. i will change it.,0,0.9867961406707764
106523663,2476,becketqin,2017-03-16T20:31:18Z,should this be `leader_not_available` instead?,0,0.9903074502944946
106525699,2476,becketqin,2017-03-16T20:40:21Z,"do we want to wait until the networkthread to exit before closing the `consumernetworkclient`? otherwise there will be some exception thrown and logged, which seems no ideal.",0,0.9312003254890442
106527195,2476,becketqin,2017-03-16T20:47:31Z,can we use a macro instead?,0,0.9943085312843323
106549682,2476,becketqin,2017-03-16T22:47:38Z,the terminology lso is also used by kip-98 as last stable offset. just a note so that we do not introduce confustion.,0,0.9950101375579834
106550281,2476,becketqin,2017-03-16T22:51:38Z,what is lbo?,0,0.9925382733345032
106550413,2476,becketqin,2017-03-16T22:52:31Z,hw -> lw,0,0.9394782781600952
106550867,2476,becketqin,2017-03-16T22:55:53Z,would it be safer to set the initial value to -1l if it is only kept on the leader?,0,0.9884793162345886
106551121,2476,becketqin,2017-03-16T22:57:58Z,nit: we usually do not use the `_*` pattern in apache kafka.,0,0.9903045296669006
106551960,2476,becketqin,2017-03-16T23:03:44Z,attempt => attempting,0,0.9895436763763428
106560377,2476,becketqin,2017-03-17T00:09:41Z,shouldn't this be -1l?,0,0.9896097183227539
106568532,2476,becketqin,2017-03-17T01:29:44Z,we can probably make those methods protected.,0,0.991732120513916
106569363,2476,becketqin,2017-03-17T01:40:25Z,this number seems a little too large for deleterecordsrequest.,0,0.8189128041267395
106571166,2476,becketqin,2017-03-17T02:03:40Z,this could be [code block],0,0.9940861463546753
106586044,2476,lindong28,2017-03-17T05:24:34Z,thanks. good catch. fixed now.,1,0.9938369393348694
106587187,2476,lindong28,2017-03-17T05:40:53Z,"are you suggesting to wait for networkthread to exit before or after calling `client.close()`? if we call `client.close()` first, we can not prevent error from being logged because `selector.close()` will log error. if we wait for networkthread to exit first, then close() may become a blocking call which seems unnecessary. i agree with you that we do not want to throw exception here. but i am not sure why we should not log any error here. for example, `selector.close()` may log error if there is `ioexception`. i have updated the code to catch exception. does this address the problem?",0,0.9716865420341492
106587383,2476,lindong28,2017-03-17T05:43:42Z,sure. fixed now.,0,0.9459871053695679
106587470,2476,lindong28,2017-03-17T05:45:01Z,sure. replaced `lso` with `logstartoffset`.,0,0.9879580736160278
106587521,2476,lindong28,2017-03-17T05:45:44Z,good catch. thanks. it means logbeginoffset. replaced it with logstartoffset.,1,0.9945526719093323
106587539,2476,lindong28,2017-03-17T05:46:07Z,thanks. fixed now.,1,0.9681604504585266
106587752,2476,lindong28,2017-03-17T05:49:36Z,"i used `_*` here because we have methods `lastcaughtuptimems`, `logstartoffset` and `lowwatermark`. what would you suggest to name these variables?",0,0.9944325089454651
106587831,2476,lindong28,2017-03-17T05:50:30Z,sure. changed it to -1l.,0,0.9884089231491089
106587893,2476,lindong28,2017-03-17T05:51:13Z,fixed now.,0,0.9943431615829468
106587916,2476,lindong28,2017-03-17T05:51:32Z,good catch. fixed now.,1,0.9932025671005249
106588046,2476,lindong28,2017-03-17T05:53:18Z,good point. i changed it to 1.,1,0.9803020358085632
106588193,2476,lindong28,2017-03-17T05:55:28Z,cool. fixed now.,1,0.9903512597084045
106767687,2476,becketqin,2017-03-18T00:47:23Z,"it seems that if any exception is thrown from the network thread, the futures that have been returned will not be completed forever. ideally we will want to have those futures get an exception so that users do not wait on that indefinitely.",0,0.9855144023895264
106770832,2476,lindong28,2017-03-18T02:29:49Z,thanks for your review! i have fixed it in the last commit.,1,0.9895370006561279
106821825,2476,junrao,2017-03-19T23:00:48Z,should we update upgrade.html?,0,0.9957793951034546
106821828,2476,junrao,2017-03-19T23:00:59Z,should we rename offset to sth like fetchoffset so that it's clear how it's different from logstartoffset?,0,0.9937921166419983
106821831,2476,junrao,2017-03-19T23:01:08Z,should we follow the convention by nesting partitions inside topics?,0,0.993110179901123
106821839,2476,junrao,2017-03-19T23:01:25Z,"so, we are not calling maybeincrementleaderlw() when the old segments are deleted? this means that lw may not be accurate when there is only 1 replica?",0,0.9929256439208984
106821844,2476,junrao,2017-03-19T23:01:34Z,"hmm, it seems that we should be using the logstartoffset from the follower, not from the leader?",0,0.9817022085189819
106821857,2476,junrao,2017-03-19T23:01:55Z,"if we modify the log, we should probably coordinate this with the log cleaner. in logmanager.truncateto(), we first abort the ongoing cleaning, then truncate and finally resume the cleaning. we probably should do the same here.",0,0.9927170276641846
106821867,2476,junrao,2017-03-19T23:02:15Z,should we adjust the comment above accordingly?,0,0.9934157133102417
106821871,2476,junrao,2017-03-19T23:02:27Z,"hmm, the change doesn't seem right. the first value should be startoffset and the second value should be logstartoffset?",0,0.885083019733429
106821879,2476,junrao,2017-03-19T23:02:53Z,"is this comment still correct? i thought we check the delete offset is smaller than hw, which is less than log end offset?",0,0.9929665327072144
106821907,2476,junrao,2017-03-19T23:03:49Z,"is it important to track this metric, especially at partition level, given deleterecords is a rare operation?",0,0.9896738529205322
106821909,2476,junrao,2017-03-19T23:04:03Z,"hmm, could timestampoffset.offset be < localreplica.logstartoffset? it seems that the result returned from fetchoffsetfortimestamp() guarantees that timestampoffset.offset >= localreplica.logstartoffset?",0,0.9887552261352539
106821916,2476,junrao,2017-03-19T23:04:13Z,this is not a produce response.,0,0.9812760353088379
106821917,2476,junrao,2017-03-19T23:04:19Z,do we need this to be 10000? could we make it 60000?,0,0.9910240173339844
106821918,2476,junrao,2017-03-19T23:04:23Z,log begin offset => log start offset?,0,0.994511604309082
106821926,2476,junrao,2017-03-19T23:04:40Z,"it seems that logstartoffset is only needed in replicafetcherthread. instead of adding it in partitionfetchstate, perhaps it's simpler to just add it here by calling getlogstartoffset()?",0,0.9907282590866089
106821934,2476,junrao,2017-03-19T23:04:54Z,"if we do this, perhaps there is no need to pass in metadatacache through methods like becomeleaderorfollower() and maybeupdatemetadatacache()?",0,0.9898536801338196
106837370,2476,lindong28,2017-03-20T05:48:26Z,i am not sure we have that convention. this is the same pattern used by `reassignpartitionscommand`. i can change it if you think the other pattern is better.,0,0.9772794246673584
106837391,2476,lindong28,2017-03-20T05:49:00Z,i didn't change it in order to reduce the amount of code change and conflicts with other patches. i will change it as you suggested.,0,0.9912616014480591
106838059,2476,lindong28,2017-03-20T06:03:20Z,"it seems ok because when there is no follower, lw is only used in the `purgeresponse` to tell user whether purge has finished. in this case the `purgerequest` would have triggered `maybeincrementleaderlw`.",0,0.9847452044487
106838930,2476,lindong28,2017-03-20T06:20:34Z,good point. i have updated code so that `deletelogstartoffsetbreachedsegments` is called periodically by `logmanager` for non-compact topics and by `logcleaner` compact topics. `deleterecordsrequest` only needs to update `logstartoffset` of the `replica`.,1,0.9676253199577332
106839374,2476,lindong28,2017-03-20T06:27:55Z,sure. i updated the comment to say `return error on attempt to read beyond the log end offset or read below log start offset`. is this ok?,0,0.9858466982841492
106840055,2476,lindong28,2017-03-20T06:40:15Z,you are right. it is wrong after we add that check. i have removed this comment.,0,0.9327692985534668
106840295,2476,lindong28,2017-03-20T06:44:02Z,it is not important. i added it because we have similar per-partition metrics in `delayedproduce`. i realized that we don't per-partition metrics in `delayedfetch`. it is removed now.,0,0.9843330383300781
106840866,2476,lindong28,2017-03-20T06:52:31Z,good point. it is removed now.,1,0.9624016880989075
106840929,2476,lindong28,2017-03-20T06:53:38Z,my bad. i have corrected this comment now.,-1,0.9948281645774841
106841258,2476,lindong28,2017-03-20T06:59:03Z,"i like this to be smaller to reduce the chance that a logstartoffset updated by deleterecordsrequest is lost. this is useful e.g. if there is only one replica and the broker may crash. anyway, i will change it to 60 sec.",0,0.822651743888855
106841300,2476,lindong28,2017-03-20T06:59:37Z,sure. fixed now.,0,0.9459871053695679
106843753,2476,lindong28,2017-03-20T07:28:19Z,oops... good point! thanks! i fixed the bug by passing `followerlogstartoffset` to `updatelogreadresult` via `logreadresult`.,1,0.9956781268119812
106843969,2476,lindong28,2017-03-20T07:30:10Z,i think the original error message is probably wrong. why the range of log segments depend on an offset provided by the user?,0,0.9461795091629028
106844614,2476,lindong28,2017-03-20T07:37:08Z,`logstartoffset` is also needed in `replicamanager.readfromlocallog`. it seems reasonable to include it in the `fetchrequest.partitiondata` since `fetchrequest.partitiondata` is supposed to contain the same fields of `protocol.fetch_request_partition_v1`. does this make sense?,0,0.9931245446205139
106844878,2476,lindong28,2017-03-20T07:40:41Z,"sure. i have updated the code to remove `metadatacache` from parameters of methods `becomeleaderorfollower`, `maybeupdatemetadatacache` and `makefollowers`.",0,0.986116349697113
106845566,2476,lindong28,2017-03-20T07:50:07Z,hmm.. i wasn't aware i need to change upgrade.html. i will do it tomorrow.,0,0.8471646904945374
106956008,2476,lindong28,2017-03-20T16:58:20Z,"sorry, i missed the first `%d` in the message. i have corrected this now.",-1,0.9899589419364929
107039812,2476,junrao,2017-03-20T23:13:42Z,"ok, we can leave this as it is since the /admin/reassign_partitions path in zk already follows the same pattern.",0,0.9919307827949524
107039880,2476,junrao,2017-03-20T23:14:13Z,"if lw is only used for deleterecordresponse, do we need to store and maintain it in replica? could we just compute it on the fly when serving deleterecordrequests?",0,0.9927172660827637
107039905,2476,junrao,2017-03-20T23:14:24Z,"so, deleterecordsrequest can't be applied on a compacted topic? should we return an error code in the response in that case?",0,0.9904561638832092
107039943,2476,junrao,2017-03-20T23:14:38Z,i meant is there a need to include logstartoffset in partitionfetchstate in abstractfetcherthread.scala? it seems that only replicafetcherthread needs it.,0,0.9929847717285156
107049639,2476,lindong28,2017-03-21T00:29:02Z,ah i see your point now. you are right that we don't have to include it in `abstractfetcherthread`. i have removed it from `partitionfetchstate` in `abstractfetcherthread` and the code change in `consumerfetcherthread` and `abstractfetcherthread` is much smaller now. thanks!,1,0.9862093329429626
107052078,2476,lindong28,2017-03-21T00:51:33Z,"yes we can compute it on the fly when we need it in e.g. in `delayeddeleterecords`. is there reason to do it on the fly instead of maintaining it in the `replica`? is it because you think the patch would be simpler if we compute it on the fly? i think both solution has the same performance. but maintaining it in replica in the same way as `hw` may make lw easier to reason about and extend in the future. for example, the code is easier to extend if we want to use `lw` in the future as a way to determine the minimum offset available for consumption (currently the minimum offset available for consumption varies between replicas because different replicas may have different logstartoffset).",0,0.9870750308036804
107052828,2476,lindong28,2017-03-21T00:58:38Z,"btw, the reason `maybeincrementleaderlw()` is not called when the old segments are deleted is that the concept of `lw` and partition is at a higher level than `logmanager`, `logcleaner` and `log`. ideally those classes such as `logmanager` do not contain reference to the higher level class such as `partition`.",0,0.9926512837409973
107058922,2476,lindong28,2017-03-21T02:04:36Z,i have updated `upgrade.html` to change latest version from 0.10.3.0 to 0.11.0 and specify change in the fetchrequet and fetchresponse.,0,0.9946005344390869
107195440,2476,junrao,2017-03-21T15:56:32Z,"my concern is that if we store it, but don't make it accurate, then someone may start using it in the future without realizing that it's only accurate at deleterecordrequest time. so, it's better to either store it and make it accurate, or not store it and always compute it accurately when needed.",0,0.7444233894348145
107281864,2476,lindong28,2017-03-21T21:35:35Z,"i see. i just updated the patch to store `lowwatermark` in `partition` instead of `replica` and always call `maybeincrementleaderlw()` when we retrieve `lowwatermark`. i still maintain lowwatermark as state so that we only need to call `trycompletedelayedrequests` if lowwatermark has increased. other than that, the `lowwatermark` is essentially computed on the fly developer access it through `partition.updateandgetlowwatermarkiflocal()`. i added a comment that says: `lowwatermark should always be accessed through updateandgetlowwatermarkiflocal() because we may not update lowwatermark when log segment is deleted`.",0,0.9779535531997681
107512572,2476,lindong28,2017-03-22T19:42:46Z,i will add back this javascript template in the next commit. guozhang just told me that we are expected to have a local webserver in order to read this upgrade.html.,0,0.9945886135101318
107589219,2476,junrao,2017-03-23T05:10:16Z,"it still seems that it's a bit weird to maintain lowwatermarkiflocal just to see if the value has changed. another way to do that is in partition.updatereplicalogreadresult(), we compute lw before and after calling replica.updatelogreadresult. then, we will know if lw has changed. we can further optimize it by only computing the lw if the deleterecordpurgatory is not empty.",-1,0.8781521320343018
107589225,2476,junrao,2017-03-23T05:10:22Z,we are resetting log-start-offset to the base offset of first segment?,0,0.9940330386161804
107589236,2476,junrao,2017-03-23T05:10:29Z,"this logic seems a bit dangerous. there is no synchronization between nextoffset() and the updating of nextoffset in append(). so they can step on each other. since the deleting record logic never deletes the active segment, it seems that we could just use the base offset of the next segment as the next offset of the current segment. then we don't need to maintain nextoffset per segment?",-1,0.5745208859443665
107589241,2476,junrao,2017-03-23T05:10:34Z,"i had a comment on this earlier. if deleterecords() can't be applied on a compacted topic, should we send some error code in the response?",0,0.993320107460022
107748044,2476,lindong28,2017-03-23T18:26:29Z,that is a good idea. i have updated the patch to avoid maintaining lowwatermark as state of partition and compute it only on the fly. and `updatereplicalogreadresult` would only compute lw if deleterecordpurgatory is not empty.,1,0.9651151299476624
107750331,2476,lindong28,2017-03-23T18:35:39Z,"this is kind of similar to what we do with recoverypoints if its checkpoint file is unreadable. for example, if recoverypoints checkpoint file is unreadable but `.kafka_cleanshutdown` file exists, we will reset recoverypoint to `activesegment.nextoffset` after warning `resetting the recovery checkpoint to 0`. here we assume the log-start-offset in the checkpoint file is 0 if checkpoint file is not readable. on a second thought, i agree it is confusing because we will always set `logstartoffset` to at least base offset of the first second if its checkpoint file is unreadable. i will remove this statement.",0,0.8659013509750366
107752878,2476,lindong28,2017-03-23T18:45:42Z,"my apology, i missed your comment here. `deleterecordsrrequest` can actually be applied on a compacted topic. `deleterecordsrrequest` will increase the logstartoffset. when `logcleaner` calls `log.deleteoldsegments()`, those log segments which breach the logstartoffset will be deleted.",-1,0.7896237373352051
107753068,2476,lindong28,2017-03-23T18:46:29Z,"sorry, i missed your comment there previously. my bad. deleterecordsrrequest can actually be applied on a compacted topic. deleterecordsrrequest will increase the logstartoffset. when logcleaner calls log.deleteoldsegments(), those log segments which breach the logstartoffset will be deleted. thus we don't need to send error code in response.",-1,0.9906719923019409
107779887,2476,junrao,2017-03-23T20:48:59Z,"hmm, in logcleaner, we have the following code. only logs configured as compacted and deleted are deletable and will call deleteoldsegments(). [code block]",0,0.9843929409980774
107785265,2476,lindong28,2017-03-23T21:12:04Z,"after kip-71 is committed, log compaction and deletion can co-exist. strictly speaking deleterecordsrequest can be applied on a compacted topic: if a topic is compacted and deletable, its log segment can be deleted by logcleaner; if a topic is non-compacted and deletable, its log segment can be deleted by the `logmanager.cleanuplogs()` which runs periodically. are you suggesting that deleterecordsresponse should provide error immediately if the topic is not deletable? this is certainly a good point. i missed this part previously. i will update the patch to do it. thanks!",0,0.5642392635345459
107806053,2476,lindong28,2017-03-23T23:16:43Z,"i get your concern. i am not sure we could just use the base offset of the next segment, because `nextoffset()` is a method that exists prior to this kip and is actually used by `log` to initialized `nextoffsetmetadata` (i.e. `nextoffsetmetadata = new logoffsetmetadata(activesegment.nextoffset(), activesegment.baseoffset, activesegment.size.toint)`). thus we actually need `nextoffset` of the active log segment. i have updated the patch so that `nextoffset()` is a read-only operation and only returns the cached next offset. and i make sure that for non-empty segment that is read from disk, we will always call `updatenextoffsetfromlog()` before the first call to its `nextoffset()`. i think it should resolve the problem.",0,0.9598225355148315
107819630,2476,junrao,2017-03-24T01:24:55Z,"before this patch, we have nextoffset(), which computes the next offset by scanning the last portion of the log. this could be expensive, but is only used during the initial log loading. i was suggesting that we could just keep the logic as it is. in deletelogstartoffsetbreachedsegments(), we always use the baseoffset of the next segment to check if a segment should be deleted. if a segment doesn't have the next segment, we know it's the active segment and won't be deleted. this way, we never need to call nextoffset() in deletelogstartoffsetbreachedsegments().",0,0.9816429018974304
107820483,2476,lindong28,2017-03-24T01:35:40Z,"thanks for the quick comment . yes it is possible to do that, i.e. we keep the previous expensive implementation of `nextoffset()` which scans the last portion of the log, and implement `deletelogstartoffsetbreachedsegments()` in such a way that the deletion of a segment depends on the baseoffset of the next segment. i am just not very sure about advantage of that approach as compared to the approach in the current patch. in comparison, that approach keeps nextoffset() expensive, and requires more complex implementation of `deletelogstartoffsetbreachedsegments()` because it can no longer re-use `deleteoldsegments(predicate)` to delete partition. the benefit of the approach is that we don't need to maintain `nextoffset` as state in `logsegment`. i am ok with the suggested approach. let me do that then.",1,0.9710639715194702
107825145,2476,lindong28,2017-03-24T02:34:51Z,"after thinking about this more, i agree that it is safer to keep less state in the class unless `nextoffset()` is called frequently. thus i agree the suggested approach is simpler. thanks .",1,0.9837990999221802
108008403,2476,junrao,2017-03-24T22:07:24Z,we could use mapvalues() here?,0,0.9948306679725647
108008598,2476,junrao,2017-03-24T22:09:03Z,"thinking a bit more. it seems that a delayeddeleterecord could be added right after the if check. in the next updatereplicalogreadresult() call, lw may not advance any more. then the response will be delayed. perhaps, if (replicamanager.delayeddeleterecordspurgatory.delayed() > 0) , we could just always call trycompletedelayedrequests()?",0,0.9608874320983887
108008646,2476,junrao,2017-03-24T22:09:26Z,this is not very accurate. lw will increase with deleterecordsrequest or log deletion?,0,0.9526904225349426
108008660,2476,junrao,2017-03-24T22:09:33Z,should we initialize this to an unknownoffset?,0,0.9945553541183472
108009638,2476,lindong28,2017-03-24T22:18:10Z,"no we can not use `mapvalues()`. this is because `mapvalues()` returns a view and any write operation on that view will be ignored later, e.g. `status.ackspending = true` in `delayeddeleterecords`.",0,0.9912971258163452
108010888,2476,lindong28,2017-03-24T22:23:08Z,"yes i think it is correct. for example, if there is only one replica, deleterecordsrequest or log retention will immediately increase lw.",0,0.972606897354126
108011703,2476,lindong28,2017-03-24T22:28:46Z,there is no existing variable named unknownoffset. there is `logoffsetmetadata.unknownsegbaseoffset` but i am not sure we should use unknownsegbaseoffset for logstartoffset. so i created `log.unknownlogstartoffset = -1l`. does address the problem?,0,0.9936424493789673
108012358,2476,lindong28,2017-03-24T22:34:33Z,"if there is only one live replica for this partition, then lw will increase immediately to the specified offset and the response can be sent to the client. otherwise, say there is at least one live follower for this partition, lw will not increase now. lw will increase in the next updatereplicalogreadresult() call, and the response can be sent back then. does this work?",0,0.9934900999069214
108092052,2476,junrao,2017-03-27T05:16:52Z,"to follow the convention in fetch_response, should this be named fetch_request_partition_v5?",0,0.9952540397644043
108092057,2476,junrao,2017-03-27T05:17:01Z,could you include the changes from kip-98 too?,0,0.9941545128822327
108266895,2476,junrao,2017-03-27T20:08:06Z,"we don't read the logstartoffset from the checkpoint in this case, which is a bit inconsistent with how we load the log when the broker starts up. this seems ok for now since in the rare case when a follower loses the whole log (but still has the logstartoffset checkpoint), it can discover the logstartoffset from the leader quickly. not sure if we want to add a comment on this.",0,0.9616684317588806
108287834,2476,lindong28,2017-03-27T21:44:53Z,"i am not sure i understand the problem of inconsistency here. i think this `createlog()` will only be called when the replica doesn't exist on the broker, which means the broker should not have logstartoffset for this replica, right? are you considering the scenario that the replica is deleted (either through stopreplicarequet or manually deleted via `rm -rf`) but the logstartoffset is still there? in that case i think we should actually ignore the outdated logstartoffset in the checkpoint file and read the value from leader. because logstartoffset can be considered as logically deleted if log file is deleted. does this make sense?",0,0.875725507736206
108288220,2476,lindong28,2017-03-27T21:46:54Z,"i think it may be better for owners of kip-98 to add this in the upgrade note (e.g. in kafka-4816) because they know much more about the change in kip-98 than i do.. anyway, i can go over the kip-98 doc and add things that i think necessary.",0,0.9836952686309814
108291575,2476,ijuma,2017-03-27T22:02:38Z,", feel free to leave out the kip-98 change for now. i am about to file a jira for updating the upgrade notes for kip-98. this is not the only one.",0,0.9491451978683472
108301862,2476,lindong28,2017-03-27T23:07:34Z,thanks . then i won't include this in the patch.,1,0.7125886082649231
108301889,2476,lindong28,2017-03-27T23:07:45Z,sure. i will change it to be fetch_request_partition_v5.,0,0.9824491739273071
108305808,2476,lindong28,2017-03-27T23:38:42Z,"as of now, the base offset of the first segment of a compacted topic can be always 0. thus it seems ok to have its logstartoffset as 0. we can consider logstartoffset as the lower bound of the offset of the first message in the partition, but not necessarily the strict lower bound. i couldn't find any use-case that would be broken due to this definition.",0,0.9887019395828247
108326834,2476,becketqin,2017-03-28T03:17:00Z,"can we be more clear on this field. in the `fetchresponse` we have log_start_offset which have almost the same comment. maybe here we can say ""the smallest available offset across all live replicas.""",0,0.9908676147460938
108326881,2476,becketqin,2017-03-28T03:17:44Z,for the given topic => for the given partition.,0,0.9918475151062012
108329771,2476,junrao,2017-03-28T03:54:50Z,"i don't think it breaks anything. so, we can leave this as it is.",0,0.9545068740844727
108333754,2476,becketqin,2017-03-28T04:49:22Z,"there seems a very rare case that may result in message loss. assuming there is only one replica, consider the following sequence: 1. user deletes a topic, we are not deleting the log starting offset from the checkpoint file. 2. if the topic is created again with the same name and the partitions happen to be on the same broker. 3. user produced some messages and before the log starting offset is checkpointed, the broker went down. 4. now when the broker restarts, the old checkpointed log starting offset may be applied to the newly created topic, which may cause the messages that have been produced into the log to be unavailable to the users. this is a very rare corner case, though.",0,0.9851542115211487
108335119,2476,lindong28,2017-03-28T05:07:41Z,sure. updated now.,0,0.9892030358314514
108335175,2476,lindong28,2017-03-28T05:08:03Z,good catch. fixed now.,1,0.9932025671005249
108335392,2476,lindong28,2017-03-28T05:10:53Z,good point. i fixed the problem by always do `checkpointlogstartoffsetsindir(removedlog.dir.getparentfile)` when a partition is deleted. the overhead will probably be smaller than checkpointing the cleaner offset which we already do everytime we delete a partition.,1,0.9723629355430603
103840661,2614,junrao,2017-03-02T02:42:05Z,"we may add new compression codec in the future. using the bits from 15 downwards makes adding new compression codec a bit easier in the future. also, unused should be 5-15.",0,0.9940780401229858
103840673,2614,junrao,2017-03-02T02:42:15Z,"in the comment above the class and in the kip wiki, lastoffsetdelta is after attributes.",0,0.9946840405464172
103840681,2614,junrao,2017-03-02T02:42:21Z,the comment is no longer valid?,0,0.9908503890037537
103840693,2614,junrao,2017-03-02T02:42:29Z,"hmm, should we be passing in delta timestamp?",0,0.9779292941093445
103840712,2614,junrao,2017-03-02T02:42:36Z,the comment seems outdated. attributes are no longer used to indicate the presence of key and value.,0,0.9769178628921509
103840724,2614,junrao,2017-03-02T02:42:43Z,"could we spell out how this is calculated? also, does it include the length field?",0,0.9941441416740417
103840746,2614,junrao,2017-03-02T02:42:57Z,"if key is null, should we return -1, which is the current convention?. ditto for valuesize().",0,0.9912880063056946
103840757,2614,junrao,2017-03-02T02:43:04Z,"we compute crc from timestamp, instead of attributes.",0,0.9919431209564209
103840767,2614,junrao,2017-03-02T02:43:09Z,timestamp => timestampdelta? ditto in sizeinbytes() and sizeofbodyinbytes().,0,0.9930874705314636
103840780,2614,junrao,2017-03-02T02:43:15Z,probably non-idempotent/non-transactional to make it clear?,0,0.9849333167076111
103840821,2614,junrao,2017-03-02T02:43:40Z,"for up-converted message, timestamp will be -1. but shouldn't timestamptype be the timestamptype of the topic?",0,0.9929757118225098
103840897,2614,junrao,2017-03-02T02:44:17Z,"the comment above suggests that lastoffset() is the same as nextoffset(), which seems inaccurate.",0,0.946901261806488
103840910,2614,junrao,2017-03-02T02:44:25Z,shouldn't we return -1 if there is no key? ditto for valuesize().,0,0.9924867153167725
103840930,2614,junrao,2017-03-02T02:44:37Z,should that be hasvalue() to be consistent with haskey()?,0,0.9940767288208008
103840934,2614,junrao,2017-03-02T02:44:42Z,should this be fixed?,0,0.9882408976554871
103840949,2614,junrao,2017-03-02T02:44:51Z,should we return 0 or logentry.no_sequence?,0,0.9933300614356995
103840960,2614,junrao,2017-03-02T02:45:00Z,probably mention the magic in the error message.,0,0.9837254881858826
103840968,2614,junrao,2017-03-02T02:45:05Z,bytebufferlogentry => bytebufferoldlogentry ?,0,0.9936324954032898
103840980,2614,junrao,2017-03-02T02:45:10Z,integer => long? ditto in a few other places.,0,0.9913199543952942
103840998,2614,junrao,2017-03-02T02:45:19Z,it's a bit weird to assign lastoffset to firstoffset with old magic. perhaps adding a comment to explain why?,-1,0.9771225452423096
104274159,2614,ijuma,2017-03-04T01:44:08Z,"i think we should introduce a `byteutils` class and move all the relevant methods there. maybe we could do that in its own pr, which could be merged quickly independently of the message format changes?",0,0.9895610809326172
104276385,2614,hachikuji,2017-03-04T02:40:23Z,works for me.,0,0.987933337688446
104345921,2614,junrao,2017-03-06T05:29:26Z,1 => logentry.magic_value_v1? ditto in line 84 below.,0,0.9880785346031189
104345937,2614,junrao,2017-03-06T05:29:39Z,"so, the old consumer won't work on the eos message format? if so, should we pin the fetchrequest version in consumerfetcherthread to an older version?",0,0.9934008717536926
104345956,2614,junrao,2017-03-06T05:30:02Z,"since maxmessagesize now applies to record set, it would be useful to change the description in kafkaconfig and describe that change in the upgrade section of the documentation.",0,0.994269847869873
104345961,2614,junrao,2017-03-06T05:30:07Z,entry probably should now be named logrecord?,0,0.9925810098648071
104345969,2614,junrao,2017-03-06T05:30:18Z,"in validatemessagesandassignoffsets(), should we further validate that there is only 1 log entry in records in eos format?",0,0.9945991039276123
104345976,2614,junrao,2017-03-06T05:30:26Z,does this need to be fixed? could we reuse abstractrecords.estimatesizeinbytes() for estimating the size for all magic?,0,0.9938533306121826
104495063,2614,junrao,2017-03-06T19:07:12Z,"hmm, this adds some complexity and i am not sure about the benefit. first, when sending the first few batches of the data in the producer or when the leaders are not on all brokers, we don't have a connection to all brokers. so the minusedmagic may not be very accurate. could we just rely on the down conversion logic on the broker side and make it clearer in the documentation that eos feature should be turned on only when the whole cluster has been upgraded?",0,0.7622372508049011
104495083,2614,junrao,2017-03-06T19:07:17Z,does this array need to be nullable?,0,0.9913709163665771
104495161,2614,junrao,2017-03-06T19:07:35Z,"could you add some comment on what needs to be done if we change the version of the key in the future? for example, do we have to explicitly delete keys on the old version since it won't be compacted out by the new version of the key?",0,0.9945066571235657
104495190,2614,junrao,2017-03-06T19:07:44Z,should we support the write method here?,0,0.9939010143280029
104495211,2614,junrao,2017-03-06T19:07:49Z,the reference bytebufferloginputstream.bytebufferlogentry in the comment above is no longer valid.,0,0.9909225106239319
104495248,2614,junrao,2017-03-06T19:07:55Z,should we include laststableoffset?,0,0.9939655661582947
104495273,2614,junrao,2017-03-06T19:08:01Z,the error message seems to be the opposite.,0,0.9591087698936462
104495288,2614,junrao,2017-03-06T19:08:05Z,is the todo still valid?,0,0.9931023120880127
104495343,2614,junrao,2017-03-06T19:08:20Z,should timestamptype be hardcoded to createtime or should it use the topic level config? ditto for line 256 below.,0,0.9944136738777161
104495356,2614,junrao,2017-03-06T19:08:25Z,is 1024 guaranteed to be always large enough?,0,0.9886056780815125
104495396,2614,junrao,2017-03-06T19:08:38Z,"should we print out additional information related to eos format (e.g. pid, epoch, sequence) etc? should we support printing out the control message?",0,0.995233952999115
104495429,2614,junrao,2017-03-06T19:08:44Z,"now that we have increased the param limit in checkstyle, do we still need this?",0,0.9942764639854431
105383915,2614,ijuma,2017-03-10T12:01:24Z,we should add a note that this is an internal class since the package doesn't make that obvious.,0,0.9894676804542542
105384533,2614,ijuma,2017-03-10T12:06:49Z,"nit: `maxusablemagic = math.min(usablemagic, maxusablemagic)`?",0,0.992358386516571
105385120,2614,ijuma,2017-03-10T12:11:24Z,"i think this `switch` should be a separate method as it's the interesting logic that may need to be updated when we add more produce versions. maybe it should live in `producerequest`? and we should have a test that breaks when we add a new produce version to the protocol (if we don't already) so that we don't forget to update it (since the client would still work fine, it could go unnoticed).",0,0.98201984167099
105386294,2614,ijuma,2017-03-10T12:20:42Z,"hmm, would it be better to have a `nodeapiversions.usableversion` that takes a `desiredversion` as well? we could the collapse these two branches and there would be no need to call `ensureusable`.",0,0.9777504205703735
105386464,2614,ijuma,2017-03-10T12:21:54Z,"it's an existing issue, but realised that this comment is out of date.",0,0.9894300699234009
105387601,2614,ijuma,2017-03-10T12:30:43Z,"can we just simply call `get` on the map? also, maybe we should return `null` if there's no element (like `map.get`).",0,0.9906361699104309
105388069,2614,ijuma,2017-03-10T12:34:39Z,maybe we could move the logic that creates the appropriate `usableversion` into a static factory method (or constructor) in `usableversion`.,0,0.986985981464386
105390691,2614,ijuma,2017-03-10T12:54:19Z,"i found the term `default` a bit confusing here. this is `usableversion`, right? i guess you were trying to avoid repeating it since the class name is `usableversion`. could we just call it `value`?",0,0.9213474988937378
105390911,2614,ijuma,2017-03-10T12:55:59Z,"i think the field name should just be `apiversion`, no?",0,0.9907163977622986
105391297,2614,ijuma,2017-03-10T12:58:39Z,"this should be ""0.11.0-iv0"" and the rest should be updated accordingly.",0,0.9958550333976746
105392682,2614,ijuma,2017-03-10T13:08:27Z,"`create_time` is correct, see [a link]",0,0.9944556355476379
105394318,2614,ijuma,2017-03-10T13:19:26Z,"it makes sense to leave space for the compression type, but i'd hope we won't need more than 3 bits for it.",0,0.9879266619682312
105394549,2614,ijuma,2017-03-10T13:20:53Z,"would `basicrecord` or `simplerecord` be a better name? i think the key feature is that it just captures the essence of what a record is: timestamp, key, value (and potentially headers in the future?).",0,0.9838417768478394
105497417,2614,hachikuji,2017-03-10T21:55:38Z,"my guess is we'll have another message format bump before we run out of room for compression codecs, but i don't mind adding another bit if you think it's useful.",0,0.8988232016563416
105498031,2614,hachikuji,2017-03-10T21:58:44Z,"oh, i may have misunderstood. are you suggesting moving the transactional flag and timestamp type to the end of the second byte?",0,0.9395757913589478
105515378,2614,hachikuji,2017-03-11T00:20:03Z,"i do this validation inside `producerequest`. if there is more than one entry, we will raise `invalidrecordexception` before the request reaches `logvalidator`.",0,0.9946985244750977
105516191,2614,hachikuji,2017-03-11T00:29:01Z,"yes, i think we can.",0,0.9570568203926086
105516431,2614,hachikuji,2017-03-11T00:31:41Z,"if fetching in `read_uncommitted`, we do not compute the aborted transaction list. i thought `null` would be a good way to communicate this instead of an empty array, which would be ambiguous (are there no aborted transactions or did we just not compute them?).",0,0.9906874299049377
105516776,2614,hachikuji,2017-03-11T00:35:28Z,"discussed offline, but for posterity, down-conversion on the broker only helps when the broker supports the new produce request version. however, the client also needs to support older versions of the produce request, which must use older versions of the message format. the difficulty is that there is a delay between the time that the producer starts building the batch and the time that we send the request, and we may have chosen the message format based on out-dated metadata. in the worst case, we optimistically chose to use the new message format, but found that the broker didn't support it, so we need to down-convert on the client before sending.",0,0.9797234535217285
105698631,2614,hachikuji,2017-03-13T16:02:00Z,"yeah, let's do this for now. we can add support in a follow-up if desired.",0,0.984171450138092
105722433,2614,hachikuji,2017-03-13T17:33:41Z,i guess the todo should really go to the other constructor.,0,0.969666600227356
105724542,2614,hachikuji,2017-03-13T17:42:04Z,we'd need to increase a bit more to capture this one too. increasing to 12 dropped two others.,0,0.9889995455741882
105732368,2614,hachikuji,2017-03-13T18:11:01Z,i assume you are asking whether we can support this method directly using the `filechannel`? i have implemented this in the latest commit.,0,0.9944217801094055
105733027,2614,hachikuji,2017-03-13T18:13:44Z,"yeah, that's fair. let me see if we can move it to `producerequest`.",0,0.9807430505752563
105746262,2614,hachikuji,2017-03-13T19:09:50Z,"yes, that sounds good.",1,0.5444263219833374
105767662,2614,junrao,2017-03-13T20:48:30Z,"since we already have 3 bits for compression, so leaving this as it is will be fine.",0,0.9903693795204163
105767710,2614,junrao,2017-03-13T20:48:40Z,"i was trying to say it seems that we (should) never do writes through fileloginputstream? if so, perhaps the implementation can just throw unsupportedexception?",0,0.990220308303833
105770550,2614,hachikuji,2017-03-13T21:01:32Z,i guess the name is a little misleading. we're really reading here into the provided buffer. maybe the name should be `readinto`?,0,0.8512027263641357
105985925,2614,junrao,2017-03-14T18:09:16Z,"since we are including the exact key/value length, perhaps we should exclude the max key/value length in max_record_overhead?",0,0.9928816556930542
105985975,2614,junrao,2017-03-14T18:09:30Z,"perhaps name this to producerepoch to distinguish it from the partitionleaderepoch? if so, probably rename the variables in the class as well.",0,0.9939703941345215
105985994,2614,junrao,2017-03-14T18:09:37Z,should we pass in timestampdelta instead of timestamp?,0,0.9943158030509949
105987708,2614,hachikuji,2017-03-14T18:16:04Z,`simplerecord` works for me. i may have actually had this in the code at one time or another.,0,0.9927011728286743
106071613,2614,junrao,2017-03-15T02:02:41Z,it's a bit weird to call this maxusablemagic when we take the min. perhaps this and the method should be minusablemagic?,-1,0.9682665467262268
106071657,2614,junrao,2017-03-15T02:03:05Z,"hmm, the method doesn't do exactly what the comment says. if desiredversion is not usable, it doesn't seem to fall back to latest usable version. is the comment incorrect?",0,0.9803280234336853
106071664,2614,junrao,2017-03-15T02:03:10Z,maybe useful to include the min/max version in the error message?,0,0.9903506636619568
106071700,2614,junrao,2017-03-15T02:03:30Z,"this can be a bit tricky. it seems that maxusablemagic could change btw when size is computed in line 190 and in line 205. if the estimated size is not correct, we may not be able to append the record to the newly allocated recordsbuilder, which will cause the assertion in line 209 to fail.",0,0.8121852278709412
106071703,2614,junrao,2017-03-15T02:03:34Z,annotate this with ?,0,0.9927796721458435
106071718,2614,junrao,2017-03-15T02:03:46Z,legacyrecordbatch => abstractlegacyrecordbatch ?,0,0.9850761294364929
106071726,2614,junrao,2017-03-15T02:03:52Z,perhaps it's clearer to name this legacyrecord()?,0,0.989294171333313
106071817,2614,junrao,2017-03-15T02:04:48Z,"the comment in loginputstream says it only does shallow iteration. however, here we are doing deep iteration. so, perhaps the comment needs to be changed?",0,0.9887403845787048
106071826,2614,junrao,2017-03-15T02:04:52Z,log logentries => logentries,0,0.9914952516555786
106071834,2614,junrao,2017-03-15T02:04:56Z,due => due,0,0.9538972973823547
106071846,2614,junrao,2017-03-15T02:05:04Z,epoch => producerepoch here and in the comment?,0,0.9947537183761597
106071855,2614,junrao,2017-03-15T02:05:09Z,could we call this producerepoch to distinguish it from partitionleaderepoch?,0,0.9929119944572449
106071869,2614,junrao,2017-03-15T02:05:18Z,"hmm, is remaining() correct? it seems that limit() is right.",0,0.9754272699356079
106071874,2614,junrao,2017-03-15T02:05:25Z,"hmm, the last message has offset 3. so, shouldn't position be 4?",0,0.9815748929977417
106071891,2614,junrao,2017-03-15T02:05:39Z,"could we print out whether this is a control record? and if so, perhaps print out more details about the control record?",0,0.9944260120391846
106071917,2614,junrao,2017-03-15T02:05:54Z,could we print out leaderepoch as well. also epoch => producerepoch?,0,0.9954462647438049
106083563,2614,junrao,2017-03-15T04:21:17Z,"with this, it's possible to have no records added to the builder. does the builder support that at close() time?",0,0.9945650100708008
106086048,2614,junrao,2017-03-15T04:58:44Z,it seems that the validation has been done in line 203?,0,0.9946925044059753
106086067,2614,junrao,2017-03-15T04:58:56Z,"hmm, why do we need to do this check? the batch could be on magic 2? ditto on the ensurenotcontrolrecord() check below.",0,0.9762023091316223
106239779,2614,hachikuji,2017-03-15T18:00:26Z,"i agree it reads a little weird, but i'm not sure `minusablemagic` is accurate. the minimum usable magic would always be 0, but we are actually trying to get the maximum magic value that is supported across all brokers, which means taking the minimum of the max versions supported by all.",-1,0.9344704151153564
106243896,2614,hachikuji,2017-03-15T18:15:53Z,i'll clarify the comment. what i was trying to say is that `loginputstream` only handles one level of iteration (it itself does not descend into compressed payloads).,0,0.9918811917304993
106247667,2614,hachikuji,2017-03-15T18:30:11Z,"the `toarray` we're delegating to begins from `buffer.position()`, so `remaining()` seems correct. i'll add a test case to figure it out.",0,0.9933030605316162
106249688,2614,hachikuji,2017-03-15T18:37:57Z,"yes, we basically set the built records to `memoryrecords.empty` and reset the position in the underlying buffer.",0,0.993726372718811
106251349,2614,hachikuji,2017-03-15T18:44:06Z,this was intended to be temporary until we have the transactional portion of kip-98. i didn't want to get too far into that validation in this patch if possible. does that seem reasonable?,0,0.9922491312026978
106257259,2614,hachikuji,2017-03-15T19:08:53Z,good catch. it seems we need to use the same value throughout this logic. we always have the code to handle conversion later if we need it.,1,0.9856555461883545
106258412,2614,hachikuji,2017-03-15T19:13:49Z,"should have known not to try to slip something by jun! fixing this is actually a bit tricky since we need to retain the control record long enough to update the consumer's position. this requires a bit of refactoring in `fetcher`, which i had intended to do in a follow-up. i'll see if there's an easier workaround for now.",-1,0.9628909826278687
106321514,2614,junrao,2017-03-16T01:23:48Z,"it seems that we should either use (1) 0 and buffer.limit() or (2) buffer.position() and buffer.remaining(), but not mixing the two? for (2), typically the buffer is in the write mode. in the read mode, (1) is probably what we want?",0,0.9897486567497253
106322699,2614,ijuma,2017-03-16T01:35:51Z,seems like `offset` is ignored in the `else` case.,0,0.985489547252655
106322962,2614,ijuma,2017-03-16T01:38:41Z,"the reason why `0` is being passed is that `position` is called in the overloaded `toarray` method. so, this is actually doing `2` although it's not too clear.",0,0.9910549521446228
106324045,2614,junrao,2017-03-16T01:50:08Z,"could we also print out baseoffset. basetimestamp, partitionleaderepoch, basesequence?",0,0.9951985478401184
106342774,2614,hachikuji,2017-03-16T05:43:08Z,good catch,1,0.9915775060653687
106454133,2614,ijuma,2017-03-16T15:45:48Z,"shouldn't we document the behaviour in 0.11.0 first? we can add a note about the previous behaviour at the end, but if someone sees these docs, they should be interested in 0.11.0.",0,0.9935411214828491
106455746,2614,ijuma,2017-03-16T15:51:39Z,nit: would `struct.hasfield(transactional_id_key_name)` be a little better?,0,0.9869080781936646
106455926,2614,ijuma,2017-03-16T15:52:15Z,nit: would `struct.hasfield(transactional_id_key_name)` be a little better?,0,0.9869080781936646
106460700,2614,ijuma,2017-03-16T16:09:43Z,"could we call `usableversion.ensureusable(version)` here? also, maybe we can improve the exception message from that method to be as good as this one (i.e. include the supported versions).",0,0.992501974105835
106461149,2614,ijuma,2017-03-16T16:11:24Z,"can we mention the requested `apikey` in the exception? also, it would be good to document that the method throws an exception instead of just returning `null` if no `apiversion` can be found.",0,0.9945021867752075
106478107,2614,junrao,2017-03-16T17:17:01Z,perhaps save this in a constant and reuse?,0,0.9907006025314331
106478136,2614,junrao,2017-03-16T17:17:07Z,"hmm, is headers nullable? if so, should we use -1 to represent null for consistency?",0,0.9864193797111511
106478167,2614,junrao,2017-03-16T17:17:14Z,this should now be named writedefaultrecordheader()? there are a bunch of places like that.,0,0.9903184175491333
106478340,2614,junrao,2017-03-16T17:17:53Z,this should be appendlegacyrecord()? there are a few other places referencing oldlogrecord.,0,0.9915512800216675
106525941,2614,ijuma,2017-03-16T20:41:31Z,nit: `batch`.,0,0.9932641983032227
106528086,2614,ijuma,2017-03-16T20:51:27Z,"have we settled on using `magic` instead of `messageformatversion`? we may need to clean-up some scala code later. personally, i think `messageformatversion` is less `magic` (see what i did there). ;)",1,0.9828580617904663
106535449,2614,ijuma,2017-03-16T21:25:42Z,should some of this github response be included in the code comments?,0,0.9947547912597656
106536471,2614,ijuma,2017-03-16T21:30:15Z,"to avoid this cast, we can add an overrides for `downconvert` in `filerecords` and `memoryrecords` that make the type more specific (where we know it cannot fail).",0,0.9933640956878662
106537132,2614,ijuma,2017-03-16T21:33:25Z,i think that makes sense for what it's worth.,0,0.8718457818031311
106541553,2614,ijuma,2017-03-16T21:56:35Z,"we don't have to do this now, but i wonder if `recordbatch` could simply be an abstract class and we could remove this one. or we could wait until we move to java 8, keep the interface and use default methods.",0,0.9796363115310669
106542021,2614,ijuma,2017-03-16T21:59:19Z,you don't need to say `beginning in 0.11.0` since that's the case for everything in this list.,0,0.9915247559547424
106542403,2614,ijuma,2017-03-16T22:01:33Z,is it worth saying something about `batch.size`? it seems that is what ensures that the batch will be of an appropriate size.,0,0.9914954900741577
106543613,2614,ijuma,2017-03-16T22:09:03Z,can we simplify this in a similar way as we simplified `networkclient`?,0,0.9949630498886108
106546543,2614,ijuma,2017-03-16T22:26:41Z,typo: `unusuable`,0,0.9893103837966919
106546942,2614,ijuma,2017-03-16T22:29:16Z,is this just an optimisation or it's a correctness issue?,0,0.9887205958366394
106570149,2614,junrao,2017-03-17T01:50:37Z,"entry => batch ? also, the comment above still references entry.",0,0.994691789150238
106570158,2614,junrao,2017-03-17T01:50:45Z,logentries => recordbatch? there are a few other places like that in this file.,0,0.9935844540596008
106570162,2614,junrao,2017-03-17T01:50:51Z,convertlogentry => convertrecordbatch?,0,0.9954409599304199
106570181,2614,junrao,2017-03-17T01:51:05Z,we can only do this if headervalue.hasarray() is true? ditto for the crc computation in computechecksum() and in readfrom(). we can probably write a util for that.,0,0.9939413070678711
106570196,2614,junrao,2017-03-17T01:51:22Z,should we assert headerkey is not null?,0,0.9925758838653564
106570214,2614,junrao,2017-03-17T01:51:26Z,log_entry_overhead => record_batch_overhead ?,0,0.9931265115737915
106570219,2614,junrao,2017-03-17T01:51:31Z,"instead of ""magic v2"", referencing magic()?",0,0.9947587847709656
106570227,2614,junrao,2017-03-17T01:51:35Z,logentry => recordbatch ?,0,0.9944696426391602
106570233,2614,junrao,2017-03-17T01:51:40Z,1 => named constant?,0,0.9937189817428589
106570245,2614,junrao,2017-03-17T01:51:46Z,could you add a bit more explanation on why the crc is useless?,0,0.9862192273139954
106570254,2614,junrao,2017-03-17T01:51:50Z,buildeosrecord => builddefaultrecord?,0,0.9955560564994812
106570260,2614,junrao,2017-03-17T01:51:55Z,onelogentry => onerecordbatch ?,0,0.9917118549346924
106570281,2614,junrao,2017-03-17T01:52:09Z,"in validatemessagesandassignoffsets(), when validating the defaultrecordbatch, should we also validate the the message count matches the actual number of messages in the array and the header count matches the actual number of headers?",0,0.9950575828552246
106570283,2614,junrao,2017-03-17T01:52:15Z,"instead of 0, referencing the constant?",0,0.9918162226676941
106581113,2614,junrao,2017-03-17T04:15:14Z,"ok, perhaps add a todo comment for now?",0,0.9930521249771118
106581349,2614,junrao,2017-03-17T04:18:30Z,could we include an error message to indicate that this is unexpected? or could we throw an illegalstateexception instead?,0,0.9913229942321777
106892521,2614,ijuma,2017-03-20T12:53:15Z,the implementation of this method in `legacyrecord` is: [code block] i think you need something similar here.,0,0.9943535327911377
106895148,2614,ijuma,2017-03-20T13:05:52Z,nit: shouldn't we represent this as `records => [record]` instead of having `recordscount` as a separate line?,0,0.9822805523872375
106896027,2614,ijuma,2017-03-20T13:10:21Z,"in the documentation above, we use `length` while here we use `size`. it would be good to be consistent.",0,0.9897524118423462
106896581,2614,ijuma,2017-03-20T13:13:16Z,is it ever possible that we use `defaultrecordbatch` with `magic == 0`?,0,0.9928438067436218
106898316,2614,ijuma,2017-03-20T13:21:36Z,is this uint32 or int32? the code does both. :),1,0.9883931279182434
106899598,2614,ijuma,2017-03-20T13:28:02Z,we should have a private method for reading the last offset delta. we are using `readunsignedint` in `lastoffset` and `getint` here.,0,0.9949175119400024
106900105,2614,ijuma,2017-03-20T13:30:31Z,"this should be uint32, i believe.",0,0.9920545816421509
106913341,2614,ijuma,2017-03-20T14:26:05Z,"hmm, shouldn't we have more tests here? looking at the tests for the legacy records, some ideas: 1. tests like `simplerecordtest.*isvalid*`, but for `defaultrecordbatch`. 2. `legacyrecordtest.testchecksum` would be useful to have as well. 3. `simplerecord.buildeosrecord` should be renamed and moved here. 4. some tests involving compression? or is the idea that `memoryrecordstest` and `memoryrecordsbuildertest` cover those? it may be worth adding some javadoc to the test classes to give an idea of the what they're intended to test.",0,0.9673573970794678
106913783,2614,ijuma,2017-03-20T14:27:34Z,nit: logrecord -> record.,0,0.9923575520515442
106914828,2614,ijuma,2017-03-20T14:31:11Z,"i think we should rename this class `legacysimplerecordtest` (or something like that) and move the tests that are not for `legacyrecord` elsewhere. also, if there are tests that would make sense for `defaultrecord`, we should port them.",0,0.9863340258598328
106915417,2614,ijuma,2017-03-20T14:33:09Z,should this be in `memoryrecordsbuildertest` (or `memoryrecordstest`)?,0,0.994649350643158
106915947,2614,ijuma,2017-03-20T14:35:04Z,we should add a comment here.,0,0.9952344298362732
106916671,2614,ijuma,2017-03-20T14:37:33Z,nit: i would say exactly-once as not everyone is familiar with the eos terminology.,0,0.9883477091789246
106917876,2614,ijuma,2017-03-20T14:41:50Z,nit: would `struct.hasfield(transactional_id_key_name)` be a little better?,0,0.9869080781936646
106919175,2614,ijuma,2017-03-20T14:46:02Z,i think we should call the `validaterecords` method for all versions.,0,0.9864194989204407
106919335,2614,ijuma,2017-03-20T14:46:32Z,"if we do this check, should we not do it for other versions `magic_value_v1` too?",0,0.9933568835258484
106919624,2614,ijuma,2017-03-20T14:47:25Z,"instead of saying ""version 3 and above"", should we just say ""version $version""?",0,0.9904065728187561
106919757,2614,ijuma,2017-03-20T14:47:55Z,"i think we should call the `validaterecords` method for all versions. also, why do we only do it on `tostruct` instead of the constructor?",0,0.9875832200050354
106920410,2614,ijuma,2017-03-20T14:50:06Z,why was this moved to a separate line?,0,0.988281786441803
106922600,2614,ijuma,2017-03-20T14:57:51Z,"maybe replace `unexpected` by `unknown`? given the versioning, it is expected that new versions will be introduced eventually.",0,0.9897096753120422
106929150,2614,ijuma,2017-03-20T15:20:29Z,"if you use `standardcharsets.utf_8`, you don't need the try/catch.",0,0.9938218593597412
106929931,2614,ijuma,2017-03-20T15:22:48Z,is there a reason why we don't just call `crc32.crc32` here? was it while doing some experiments with other implementations?,0,0.9933736324310303
106933605,2614,ijuma,2017-03-20T15:36:00Z,"it's a bit odd that `legacyrecord` is referenced here. if this is the same for legacy and default, we should move it to a shared class. otherwise, it seems this logic should not live here any more.",-1,0.5662931203842163
106934435,2614,ijuma,2017-03-20T15:38:55Z,shouldn't this pass the headers as well?,0,0.9936268329620361
106934918,2614,ijuma,2017-03-20T15:40:29Z,i wonder if some of these constructors that are only used by tests should be static factory methods to avoid accidental usage from non-test code.,0,0.9416278004646301
106935553,2614,ijuma,2017-03-20T15:42:47Z,"the formatting of this method doesn't seem to follow our java convention (yes, i know, intellij) since the `return` is in the same line as the `if`. using `&&` is a concise alternative.",0,0.989946186542511
106967419,2614,hachikuji,2017-03-20T17:40:23Z,"an optimization i guess. we could construct a new `memoryrecords` with the stored buffer, but i didn't see a good reason to.",0,0.983802080154419
106967704,2614,hachikuji,2017-03-20T17:41:30Z,"lol, looks like my mind got stuck somewhere between typing ""unusual"" and ""unusable"".",1,0.9701442122459412
107003151,2614,hachikuji,2017-03-20T20:09:52Z,i could go either way... i ended up favoring `magic` mainly because it gives more concise variable and method names.,0,0.950055718421936
107003332,2614,hachikuji,2017-03-20T20:10:39Z,i debated on this... i'm inclined to leave it for later since this is internal.,0,0.9114750027656555
107022774,2614,ijuma,2017-03-20T21:34:16Z,"note that this is only true before kip-74. after kip-74, this should never happen.",0,0.9922633171081543
107026003,2614,ijuma,2017-03-20T21:50:52Z,shouldn't we use the buffer position here?,0,0.9920521974563599
107041677,2614,hachikuji,2017-03-20T23:27:01Z,good point,1,0.9818260669708252
107043636,2614,hachikuji,2017-03-20T23:42:06Z,hmm... we should check with magnus which case it was that he was accidentally using. was it the old produce request version with the new format?,0,0.9689970016479492
107044557,2614,hachikuji,2017-03-20T23:48:56Z,that's fair,0,0.9778157472610474
107044757,2614,ijuma,2017-03-20T23:50:19Z,is it right that `0` is used if there is none for this and `producerid`? the constants at the top of the file seem to indicate that it's `-1`?,0,0.993872880935669
107044853,2614,ijuma,2017-03-20T23:51:03Z,we should probably replace `message set` with `record batch` in the comments.,0,0.9938904047012329
107045184,2614,ijuma,2017-03-20T23:53:34Z,`log overhead` -> `batch overhead`?,0,0.9907770156860352
107045235,2614,ijuma,2017-03-20T23:53:59Z,`log entry` -> `record batch`,0,0.9929887652397156
107045406,2614,ijuma,2017-03-20T23:55:21Z,"wouldn't this be better as a top level interface? i think an inner interface would make sense if we called it `mutable` only. as it is, the name stands well on its own and it makes usage a bit less verbose.",0,0.9839091897010803
107047035,2614,ijuma,2017-03-21T00:08:17Z,the `shallow` should be removed. maybe we need to do a search and replace for that string.,0,0.9915094375610352
107048855,2614,ijuma,2017-03-21T00:22:43Z,that's a good point. maybe we should just add a comment saying that we don't validate older versions because some clients rely on that.,1,0.9377464652061462
107057682,2614,hachikuji,2017-03-21T01:50:20Z,i think we can remove these utilities. i didn't know about the methods already in `crc32` until i started updating that class.,0,0.9891579151153564
107057717,2614,hachikuji,2017-03-21T01:50:50Z,agreed,0,0.9598594307899475
107057751,2614,hachikuji,2017-03-21T01:51:12Z,you are my hero,1,0.9876188039779663
107059245,2614,hachikuji,2017-03-21T02:08:33Z,"after thinking about this, it might be better to move the attribute logic into the record classes. we'll duplicate a little code, but it seems better to keep the usage of record attributes encapsulated.",0,0.9875481128692627
107146211,2614,ijuma,2017-03-21T12:57:36Z,nit: formatting (same as other case).,0,0.9942871928215027
107146442,2614,ijuma,2017-03-21T12:59:00Z,"nit, if you are importing everything in `record`, then there's no reason to specify `recordbatch` on its own, right?",0,0.9728863835334778
107146675,2614,ijuma,2017-03-21T13:00:13Z,why are we not defaulting to `current` any more? same for the other method.,0,0.9890000224113464
107146794,2614,ijuma,2017-03-21T13:00:54Z,do we need to have a method like this for message format 1?,0,0.9950191974639893
107147049,2614,ijuma,2017-03-21T13:02:08Z,nit: `logentry` -> `record`?,0,0.992133617401123
107147536,2614,ijuma,2017-03-21T13:04:22Z,why don't we use `logentries` here and in other similar methods?,0,0.9875808954238892
107147613,2614,ijuma,2017-03-21T13:04:43Z,shall we call this `records`?,0,0.9939191341400146
107148607,2614,ijuma,2017-03-21T13:09:43Z,"unfortunately, there are a few magic values in these tests. how did you arrive at the correct values for the array fill and `segmentbytesprop`?",-1,0.6066363453865051
107148969,2614,ijuma,2017-03-21T13:11:14Z,"as you know, we have had a lot of issues with the cleaner in the past. and we don't have any system tests with compacted topics. do you feel like we have enough coverage for all message format versions?",0,0.9875901937484741
107149933,2614,ijuma,2017-03-21T13:15:44Z,it would be a bit clearer if we did: [code block],0,0.9897845387458801
107152276,2614,ijuma,2017-03-21T13:26:31Z,nit: entry -> record.,0,0.9936978220939636
107153794,2614,ijuma,2017-03-21T13:32:43Z,nice catch.,1,0.9716947674751282
107156070,2614,ijuma,2017-03-21T13:41:08Z,"if i understand correctly, you have two `flush` calls to ensure that we produce two batches, right? a few suggestions: 1. add a comment 2. rename the tests to make it clear that they're about record batches now, not records. 3. maybe we should do a `get` on the future in case it fails (in that case, we can probably remove the `flush()`).",0,0.9877306818962097
107157124,2614,ijuma,2017-03-21T13:45:19Z,"one more thing, we should consider changing the default to use the new format's overhead. at the moment it is: `val messagemaxbytes = 1000000 + messageset.logoverhead`.",0,0.9932029247283936
107157639,2614,ijuma,2017-03-21T13:47:20Z,"to avoid similar brittleness, would it be better to say something like `maxmessagesize - record_batch_overhead - 24` (the latter being the key size)?",0,0.9925857186317444
107159115,2614,ijuma,2017-03-21T13:52:44Z,should we be returning the current version in these stub returns?,0,0.9919058084487915
107160387,2614,ijuma,2017-03-21T13:57:21Z,"answering your question, this index is for the lz4 checksum value as the comment above says. maybe we should mention in the comment that it's not our message crc.",0,0.9934154748916626
107161317,2614,ijuma,2017-03-21T14:00:52Z,why do we need the `flush`? we are waiting until the future completes already?,0,0.9928643703460693
107161936,2614,ijuma,2017-03-21T14:03:08Z,`logentries` -> `records`.,0,0.9895442724227905
107162213,2614,ijuma,2017-03-21T14:04:15Z,is it intentional that we want to wait for a send to complete before doing the next send? is it related to how many batches we create?,0,0.9871276617050171
107162877,2614,ijuma,2017-03-21T14:06:35Z,how we get `12`? maybe worth adding a comment?,0,0.9938401579856873
107163216,2614,ijuma,2017-03-21T14:07:51Z,"hmm, can we not use a constant for the offset as we had before?",0,0.9781557321548462
107166963,2614,ijuma,2017-03-21T14:21:01Z,maybe we should have a shared constant for the magic offset since it's the same for all formats?,0,0.9829923510551453
107168486,2614,ijuma,2017-03-21T14:26:07Z,maybe we want to update this comment?,0,0.9913542866706848
107168520,2614,ijuma,2017-03-21T14:26:17Z,entry -> batch,0,0.9924272894859314
107168876,2614,ijuma,2017-03-21T14:27:23Z,i was wondering about the fact that `baseoffset` is not the same as `firstoffset` for compacted topics. do we care in cases like this?,0,0.9662273526191711
107169714,2614,ijuma,2017-03-21T14:30:03Z,seems like we need to update the scaladoc of this method. why are we now using `maxtimestamp` instead of the first timestamp?,0,0.9899271726608276
107170322,2614,ijuma,2017-03-21T14:32:15Z,logentry -> recordbatch,0,0.9926129579544067
107171955,2614,ijuma,2017-03-21T14:37:59Z,could some of this logic be moved to `fetchrequest` like we did for the `producerequest`? we could then also write a unit test to verify the behaviour (if we haven't already).,0,0.9924073815345764
107173311,2614,ijuma,2017-03-21T14:42:54Z,`logentryiteratormap` -> `recordbatchesiteratormap`,0,0.9924497604370117
107173784,2614,ijuma,2017-03-21T14:44:22Z,do we need to mention `recordbatch` explicitly here?,0,0.9926848411560059
107174475,2614,ijuma,2017-03-21T14:46:40Z,"should we change the message to mention batch size instead of message size? also, we may consider using `recordbatchtoolargeexception` (which already exists) although maybe later in case it may break things.",0,0.9933367967605591
107175231,2614,ijuma,2017-03-21T14:49:08Z,"nit: it may make sense to keep all the logic in one place. `shouldretainmessage` is only called from this method, so is there any reason not to just add the first check there as well?",0,0.9897895455360413
107177315,2614,ijuma,2017-03-21T14:55:27Z,"we stated in `recordbatch` that `baseoffset` remains the same after compaction. it would be good to specify the behaviour of other header fields like `lastoffset` and `maxtimestamp`. furthermore, we should make sure to test the specified behaviour for these cases (i.e. compaction removes the first/last item in the batch, compaction removed the item with the max timestamp). do we have these tests already?",0,0.9927553534507751
107180500,2614,ijuma,2017-03-21T15:05:51Z,nit: `s` is not needed and the line below.,0,0.9938210844993591
107181957,2614,ijuma,2017-03-21T15:10:49Z,haha,1,0.885028600692749
107183186,2614,ijuma,2017-03-21T15:15:06Z,`maybebatch` or we can just remove the val altogether.,0,0.9917819499969482
107183305,2614,ijuma,2017-03-21T15:15:30Z,logentry -> recordbatch,0,0.9926129579544067
107183565,2614,ijuma,2017-03-21T15:16:32Z,shallowlogentry -> recordbatch,0,0.9894552826881409
107183893,2614,ijuma,2017-03-21T15:17:43Z,entries -> batches,0,0.9918550252914429
107183937,2614,ijuma,2017-03-21T15:17:54Z,we can remove the comment.,0,0.9929031729698181
107184438,2614,ijuma,2017-03-21T15:19:43Z,"i don't understand this comment. what about compaction? also, we handle compressed and uncompressed the same now, so maybe there's no point in mentioning `uncompressed`?",0,0.601180911064148
107185244,2614,ijuma,2017-03-21T15:22:29Z,nit: space after `=`.,0,0.9807548522949219
107186719,2614,ijuma,2017-03-21T15:27:00Z,"it's a bit odd that we use all lowercase for the existing fields and camel-case for the new ones. would it make sense to use just one style (camel-case seems better, but not sure about compatibility guarantees)?",-1,0.8262041211128235
107187022,2614,ijuma,2017-03-21T15:28:05Z,"seems like we have no junit tests for `dumplogsegments` although the system tests do exercise it. i filed [a link] so that we can address this, but worth keeping in mind that manual verification is needed in the meantime.",0,0.9901289343833923
107193728,2614,ijuma,2017-03-21T15:50:46Z,"i removed this, the other `convert` method, `convertsize` and the tests that called these methods and the code compiled. seems like they are unused and can be removed. we must make sure that the conversion cases are still tested before removing the tests that call these methods.",0,0.9928126931190491
107198136,2614,ijuma,2017-03-21T16:05:51Z,would it be clearer if we called this `outerrecord` or something?,0,0.9847539663314819
107200862,2614,ijuma,2017-03-21T16:16:00Z,we don't need to wrap `iterator`. the following makes it compile: [code block] what do you think?,0,0.9936503767967224
107226762,2614,hachikuji,2017-03-21T17:47:22Z,guess that's the danger of using the optimize imports shortcut.,-1,0.6101962924003601
107264435,2614,hachikuji,2017-03-21T20:20:55Z,you are right. it seems unnecessary and the test works without it.,0,0.9488759636878967
107268478,2614,hachikuji,2017-03-21T20:37:34Z,"right. a lot of the testing around the max message size is obviously sensitive to how the messages are batched. if possible, i'd like to save refactoring of these test cases for a follow-up.",0,0.9827086329460144
107268800,2614,hachikuji,2017-03-21T20:38:59Z,i think we can use `recordbatch.max_record_overhead`,0,0.9902599453926086
107269975,2614,ijuma,2017-03-21T20:43:55Z,sounds good.,1,0.857205867767334
107270196,2614,hachikuji,2017-03-21T20:44:52Z,i'm not sure we need a dependence on the offset here. maybe we can just flips some arbitrary bits in the payload?,0,0.9481075406074524
107272979,2614,ijuma,2017-03-21T20:56:40Z,"ah, i understand what you did now. maybe add a comment?",0,0.9106769561767578
107279979,2614,hachikuji,2017-03-21T21:27:11Z,"i think the invariant we are trying to maintain is that the offsets added to the index are strictly increasing, so using the base offset in place of the first offset seems sufficient and avoids the decompression needed to find the actual first offset.",0,0.9820334315299988
107281528,2614,hachikuji,2017-03-21T21:34:02Z,"the behavior is not actually different. recall that this is ""shallow"" iteration in the old code. the timestamp we are accessing is actually the max timestamp when the record is viewed as a batch. in the uncompressed case, the ""batch"" has just a single record so the timestamp is the same as its max timestamp. in the compressed case, the timestamp is the max timestamp of all records in the batch. we preserve the old behavior and adopt the old compressed behavior for the new message format. i can update the comment to clarify this.",0,0.9921982884407043
107283016,2614,hachikuji,2017-03-21T21:40:57Z,"it is possible, but i am not sure conversion is something we want to hide too deeply. maybe we can consider this for a follow-up?",0,0.9690157771110535
107286163,2614,hachikuji,2017-03-21T21:56:43Z,"this is a good point. the current usage of `recordbatchtoolargeexception` is to indicate when a batch exceeds the log segment size, but this only really made sense for the old format without compression. it might be worthwhile considering in a follow-up whether we have need to reuse this error for other purposes. for now, i'll update the message.",1,0.9245710372924805
107290844,2614,hachikuji,2017-03-21T22:22:17Z,"see memoryrecordstest.filterto. the test is kind of a bear, but it covers a large number of cases. i'll update the doc for `lastoffset` and `maxtimestamp`.",0,0.9867510199546814
107292917,2614,hachikuji,2017-03-21T22:34:27Z,"yeah... debated on this. all lower-case is hard to read (e.g. ""partitionleaderepoch""), but i wasn't sure about compatibility.",-1,0.5364301204681396
107294949,2614,ijuma,2017-03-21T22:46:13Z,"ok, maybe we can consider using camel-case for the existing fields in a follow-up.",0,0.9894290566444397
107295245,2614,ijuma,2017-03-21T22:48:12Z,"follow-up is fine. generally, i think it's a good pattern to keep the logic in `kafkaapis` simple since it makes it harder to test.",1,0.5096848011016846
107296984,2614,hachikuji,2017-03-21T22:58:41Z,"yeah, that's a good idea.",1,0.9578582048416138
107297922,2614,hachikuji,2017-03-21T23:04:56Z,good call. seems better.,1,0.9909608960151672
107298677,2614,hachikuji,2017-03-21T23:09:57Z,"yes, i agree. there are probably ways we can do it so that we keep so visibility into the fact that the down-conversion is happening behind the scenes (maybe just comments).",0,0.9821059703826904
107316444,2614,ijuma,2017-03-22T01:37:53Z,"i was going to suggest removing this, but was unsure. happy that you did it anyway. :)",1,0.9969139099121094
107318058,2614,ijuma,2017-03-22T01:55:28Z,"my bad, you're right. thanks for updating the comment.",-1,0.9940528273582458
107327673,2614,ijuma,2017-03-22T03:43:37Z,"copied and pasted from the method comment, so we can delete it, i think.",0,0.9931337833404541
107328065,2614,ijuma,2017-03-22T03:48:46Z,was this never required? it seems like we don't do it any more.,0,0.9818447828292847
107334914,2614,junrao,2017-03-22T05:25:37Z,move this to previous line?,0,0.9943650960922241
107334929,2614,junrao,2017-03-22T05:25:48Z,logentries => recordbatch?,0,0.9951508045196533
107334933,2614,junrao,2017-03-22T05:25:51Z,the the => the,0,0.9925912618637085
107398114,2614,ijuma,2017-03-22T12:14:51Z,do you know why we had 2 builders?,0,0.9919942617416382
107412161,2614,ijuma,2017-03-22T13:29:38Z,did we decide on this one?,0,0.9900493621826172
107415960,2614,ijuma,2017-03-22T13:45:00Z,nice that we avoid the overhead of the streams here.,1,0.5208012461662292
107425811,2614,ijuma,2017-03-22T14:22:21Z,"yes, i agree that it's worth adding a brief comment explaining until we fix the issue.",0,0.9805346131324768
107441751,2614,ijuma,2017-03-22T15:15:15Z,"is it ok that we don't check the magic here, but we do for the append that takes a legacy record?",0,0.9905238747596741
107494215,2614,hachikuji,2017-03-22T18:23:25Z,looks like i forgot this one. i'll fix.,0,0.9596897959709167
107498549,2614,hachikuji,2017-03-22T18:39:56Z,"yeah, that's a good question. i'm not sure there's a good reason for the check in the `legacyrecord` case. i think initially we were doing something like copying the bytes directly, so it may have made more sense before.",0,0.8161149621009827
107499252,2614,hachikuji,2017-03-22T18:42:53Z,"oh, i guess we still do the memory copy in this case. the question is whether we should?",0,0.9800500273704529
107510450,2614,hachikuji,2017-03-22T19:32:49Z,i think we were verifying the auto-incrementing behavior. i will verify that we have both cases covered.,0,0.9902803301811218
107539054,2614,ijuma,2017-03-22T21:34:50Z,this method is only used by `bytebuffermessageset` (i.e. scala clients) so it seems ok to favour consistency over optimisation in this case.,0,0.9920620918273926
107768943,2614,ijuma,2017-03-23T19:58:09Z,why doesn't assertequals work here?,0,0.9591497778892517
107769018,2614,ijuma,2017-03-23T19:58:34Z,would it be worth adding some timestamp assertions as well?,0,0.9932870268821716
107773329,2614,ijuma,2017-03-23T20:19:57Z,"`non-compressed` should be removed, right?",0,0.991367757320404
107773377,2614,ijuma,2017-03-23T20:20:11Z,`verifyconvertedbatches`,0,0.9941588640213013
107774031,2614,hachikuji,2017-03-23T20:23:08Z,"we only convert messages when necessary. so if we down-convert a batch to version 1, and we have messages which are magic 0, we won't up-convert them to 1.",0,0.9916785955429077
107774243,2614,hachikuji,2017-03-23T20:24:03Z,ack. may as well.,0,0.9255433082580566
107839904,2614,junrao,2017-03-24T06:02:41Z,"actually, if crc only covers from attributes to the end, do we really need to switch partitionleaderepoch and crc?",0,0.9887604713439941
107886287,2614,ijuma,2017-03-24T11:52:21Z,"it's true that the change is not strictly needed. the reasoning for the switch is that this way the crc includes everything that follows it (same as for v0 and v1 formats). in v0 and v1, the offset and length are before the crc and are not included in the computation. in v2, the offset, length, partitionleaderepoch and magic are before the crc and not included in the computation. given that, do you think the benefit is worth the switch?",0,0.9842047095298767
107915842,2614,junrao,2017-03-24T14:33:18Z,"earlier, jason's proposal is to put crc to the very end after records and covers everything from magic. if we do that, the switch is not ideal, but makes sense. if crc is still at the front, then it seems leaving crc in its current location causes less confusion.",0,0.9845296144485474
107921226,2614,ijuma,2017-03-24T14:55:05Z,"if we leave the crc in the same position as in v0 and v1, would you still change the computation to be from attributes to the end? a couple of alternatives (each with pros/cons): 1. include magic in the crc computation, but not partitionleaderepoch (con: we'd have to call `checksum.update` twice instead of once). 2. compute the crc from magic to the end (as it was before), but with partitionleaderepoch always assumed to be -1. this makes the computation simple on the producer side, but it's a bit tricky after the partitionleaderepoch has been set. this is a bit similar to how tcp includes the checksum field in the checksum computation, but assumes it to be always 0 (to avoid the chicken and egg problem).",0,0.9523937702178955
107945087,2614,hachikuji,2017-03-24T16:30:20Z,"i think we can swap the crc and leader epoch fields in the current version, but keep the scope of the crc unchanged. in other words: [code block] it's a little odd that we change the scope of the crc in this format, but perhaps it's less odd than changing the location of the field entirely.",0,0.975293755531311
107954369,2614,hachikuji,2017-03-24T17:13:11Z,"this is a tough one. it's nice being consistent with the old format to some extent, but clients would still need to look at the magic byte first to figure out how to validate the crc, so maybe the consistency win is marginal. the main advantage of the format in the current patch is that it's clear at a glance what is covered by the crc, so it seems easier to explain.",-1,0.8167763948440552
107982462,2614,ijuma,2017-03-24T19:27:43Z,discussed offline and jun said he was ok with leaving as is.,0,0.9874233603477478
108027606,2614,lindong28,2017-03-25T04:13:03Z,bug: we should use `partitionresponseheader` instead of `partitionresponse` to get the response. i guess this is not discovered by any test because the current patch always has `last_stable_offset = -1l`?,0,0.9608592987060547
108040126,2614,ijuma,2017-03-25T16:48:09Z,thanks for catching this . this field won't be used until the transactional code lands. i submitted a pr with tests: [a link],1,0.9774243831634521
139199834,3874,ijuma,2017-09-15T16:59:14Z,i assume this is not intentional :),0,0.9880635142326355
139200069,3874,lindong28,2017-09-15T17:00:26Z,i made this to skip findbug and speedup test execution while i am still debugging my test :),0,0.9889300465583801
139200184,3874,lindong28,2017-09-15T17:00:59Z,the code is almost ready. i will let you know once it is done today.,0,0.7337807416915894
139200865,3874,tombentley,2017-09-15T17:04:32Z,"`renameddir` was instantiated in the line above, it can't possibly `== dir`. i think you mean `.equals()`",0,0.9911918044090271
139204236,3874,tombentley,2017-09-15T17:20:39Z,but if replication factor == 1 we've lost the log? from the description you give it sounds like we lose track of the state of the renaming because the only information to go on are the names of the files in the directory. could this be solved by having a transaction log file for the deletion in the same directory?,0,0.9932170510292053
139204483,3874,ijuma,2017-09-15T17:21:46Z,`==` in scala is _not_ reference equality.,0,0.9840387105941772
139206306,3874,tombentley,2017-09-15T17:29:35Z,why is this necessary? a comment to explain why would be useful.,0,0.9910373687744141
139206895,3874,tombentley,2017-09-15T17:32:07Z,doh! thank you.,1,0.9885204434394836
139276166,3874,lindong28,2017-09-16T02:26:05Z,thanks for the comment. the patch you saw was fully ready for review. the patch has been updated now with better code.,1,0.9711081385612488
139276169,3874,lindong28,2017-09-16T02:26:25Z,i will comment on this later.,0,0.9776753783226013
139527305,3874,junrao,2017-09-18T20:11:53Z,perhaps we can just get rid of the return value since it always returns errors.none?,0,0.9831848740577698
139529322,3874,junrao,2017-09-18T20:20:37Z,"i thought if destinationdir is any, we will also cancel any existing disk movement?",0,0.9939959049224854
139531084,3874,junrao,2017-09-18T20:27:42Z,there is one otherwise in 1) and another in 2). it's very not clear which is matched to which if.,0,0.9660950303077698
139532975,3874,junrao,2017-09-18T20:35:32Z,it seems that 1) and 2) are in reverse order of the code below.,0,0.9867320656776428
139534077,3874,junrao,2017-09-18T20:40:13Z,should logmanager.updatepreferredlogdir() only remember the preferred log dir if the log doesn't exist?,0,0.9945878982543945
139534824,3874,junrao,2017-09-18T20:43:15Z,should we handle the case when destinationdir is any?,0,0.9937781095504761
139536481,3874,junrao,2017-09-18T20:49:55Z,we use ( for .filter and { for .map. we probably want to be consistent.,0,0.9916035532951355
139539863,3874,junrao,2017-09-18T21:03:29Z,"probably simpler to say ""if the replica is not created or is offline"".",0,0.979107141494751
139554816,3874,junrao,2017-09-18T22:16:43Z,it seems that we can just combine the logging here and that in line 1398?,0,0.9921785593032837
139555164,3874,junrao,2017-09-18T22:18:40Z,"could we add a comment to explain futurelogs a bit? also, for consistency, should we rename logs to sth like primarylogs or currentlogs?",0,0.9950125813484192
139555761,3874,junrao,2017-09-18T22:22:13Z,we probably want to do foreach{ topicpartition => ...} to be consistent?,0,0.9922989010810852
139557211,3874,junrao,2017-09-18T22:31:11Z,perhaps offlinedirs could be a set?,0,0.9886026382446289
139558508,3874,junrao,2017-09-18T22:39:37Z,should we add isfuture to the param list in the comment above?,0,0.9955949187278748
139558693,3874,junrao,2017-09-18T22:40:43Z,"hmm, it seems that every time we truncate a log, we want to truncate the future log to the same offset? ditto for truncatefullyandstartat().",0,0.9652055501937866
139559651,3874,junrao,2017-09-18T22:46:53Z,should we add the missing param topicpartition and isfuture in the comment above?,0,0.9955086708068848
139560220,3874,junrao,2017-09-18T22:50:27Z,new params missing in the comment above.,0,0.9925408363342285
139562965,3874,junrao,2017-09-18T23:08:38Z,it seems that this should be an illegalstateexception since this is not expected?,0,0.9863320589065552
139563311,3874,junrao,2017-09-18T23:10:55Z,"if we check the preferredlogdir when it's added, it seems this should also be an illegalstateexception.",0,0.9908164739608765
139566414,3874,junrao,2017-09-18T23:33:03Z,typo direcotory,0,0.9505167603492737
139566677,3874,junrao,2017-09-18T23:35:00Z,"we probably want to use consistent naming in comments and variables(e.g., primary/secondary or current/future or sth else.)",0,0.9920831918716431
139567451,3874,junrao,2017-09-18T23:40:32Z,"could we move in the following sequence to avoid this corner case issue? 1. rename futurelog to log.completed. 2. rename currentlog to log.deleted. 3. rename log.completed to log. this way, if we fail at any step, we will have either log.completed or log to recover from. we probably also don't need the logic to rename back in the failure case. we just need some extra logic in loadlogs().",0,0.9867416024208069
139572154,3874,junrao,2017-09-19T00:16:49Z,should we include futurelogs in logsbytopicpartition too?,0,0.9950453042984009
139572695,3874,junrao,2017-09-19T00:22:02Z,could we use named variables instead of _._1 and _._2?,0,0.9935159683227539
139576864,3874,junrao,2017-09-19T01:03:50Z,"this doesn't seem to be a complete sentence. are we missing ""when"" before ""the future""?",0,0.9313575625419617
139578305,3874,junrao,2017-09-19T01:19:00Z,"the kip says using zero-copy to move data btw disks, but this is not. we probably can file a separate followup jira to revisit whether such an optimization is worth doing.",0,0.9919533133506775
139579858,3874,junrao,2017-09-19T01:35:23Z,"hmm, this doesn't look right. it seems that we want to use the future replica's latest epoch to build the leaderepochrequest.",0,0.6276938319206238
139582141,3874,junrao,2017-09-19T01:58:07Z,we probably want to use current/future replica instead of leader/follower.,0,0.989153265953064
139812138,3874,junrao,2017-09-19T20:42:26Z,replicafetchermanager probably needs to be changed accordingly?,0,0.9941779375076294
139834520,3874,junrao,2017-09-19T22:28:37Z,"after we do the swap, there is no checkpoint file for log cleaner. this means that we need to clean the compacted topic from the beginning, which is not ideal. one option is to copy the checkpoint to the destination log dir at the beginning of the data movement.",0,0.9654094576835632
139835264,3874,junrao,2017-09-19T22:33:34Z,"hmm, do we need this? it seems that any replica being moved across disks should be subject to throttling. the reason that we have this for inter-broker replication throttling is to avoid throttling replicas already in sync.",0,0.9711788892745972
139835968,3874,junrao,2017-09-19T22:37:48Z,typo betwee,0,0.9731950759887695
139836442,3874,junrao,2017-09-19T22:40:29Z,"we have another quota for log cleaning, which is also intra broker. to avoid confusion, would it be better to name this sth like ""replication.across.dirs.throttled.rate""?",0,0.992664635181427
139836798,3874,junrao,2017-09-19T22:42:41Z,"hmm, this wasn't in the kip. do we need this at the topic level?",0,0.9731298685073853
139843596,3874,junrao,2017-09-19T23:32:07Z,"to make it clear, would it be better to rename assignedreplicas to replicasassignedtofuturedir?",0,0.9945892095565796
139844894,3874,junrao,2017-09-19T23:42:00Z,does log need to be var?,0,0.9941111207008362
139846597,3874,junrao,2017-09-19T23:55:45Z,"hmm, why do we need to remove newofflinepartitions from replicaalterdirmanager?",0,0.9862502813339233
139849668,3874,junrao,2017-09-20T00:19:58Z,"hmm, the issue with this approach is that if one thread has no partition left and another thread has multiple partitions, we can't let the former to pick up the load from the latter. an alternative is to put all partitions in a queue and let alterreplicathreads pick up one partition at a time from the queue. this will improve the thread utilization.",0,0.9747640490531921
139851404,3874,lindong28,2017-09-20T00:32:57Z,sure. i will update the patch to get rid of the return value in this method.,0,0.986922025680542
139852351,3874,lindong28,2017-09-20T00:41:27Z,"ah i forgot this. i just checked the kip-113 wiki and it does say that broker will cancel existing movement if ""any"" is specified as the destination log directory. i am wondering if we should to make the cancellation operation more explicit by saying, if ""cancel"" is specified as the destination log directory, the existing movement of this replica should be canceled. the issue with the existing design in the wiki is that user can not distinguish between ""don't care"" and ""cancel existing movement"". what do you think?",0,0.801335871219635
139852501,3874,lindong28,2017-09-20T00:42:38Z,yeah it is more readable to reorder the comment. i will change it as suggested. thanks.,1,0.9750783443450928
139854278,3874,junrao,2017-09-20T00:59:03Z,"yes, explicitly modeling cancellation will be better. perhaps we can change alter_replica_dir_request to sth like the following. alterreplicadirrequest => [movedpartitions] [cancelledpartitions] movedpartitions => logdir [topic [partitions]] cancelledpartitions => [topic [partitions]] with that, i am not sure we still need to support any in logdir anymore.",0,0.9888380765914917
139854818,3874,lindong28,2017-09-20T01:04:35Z,"i have considered the suggested approach. i think the current approach may be simpler. - if we only remember the preferred log dir when the log doesn't exist, then in order to create the future log in the destination directory, the destination log directory needs to be passed to both `partition.getorcreatereplica(...)` and `logmanager.getorcreatelog()`, thus adding one more parameter to each method. - in addition, the suggested approach means that there will be two different ways that destination log directory is passed to logmanager, i.e. `logmanager.getorcreatelog(...)` and `logmanager.updatepreferredlogdir(...)`. this makes the logic a bit more complicated than the current patch. on the other hand, i think we only need to do `logmanager.updatepreferredlogdir()` if neither the current log nor the future log is in the user-specified log directory. i will update the patch to do it. what do you think?",0,0.9811768531799316
139855447,3874,lindong28,2017-09-20T01:11:06Z,my bad.. i have updated the comment as shown below: [code block],-1,0.9946154952049255
139855723,3874,lindong28,2017-09-20T01:14:06Z,"in the current patch, `any` will be read and filtered by `reassignpartitionscommand` such that broker will not see or handle `any` as the destination log directory. this may change if we want to allow user to cancel ongoing movement. i will reply to the other command after thinking through this.",0,0.9937100410461426
139855851,3874,lindong28,2017-09-20T01:14:55Z,sure. i have updated the patch to use `}` consistently.,0,0.9856861233711243
139855941,3874,lindong28,2017-09-20T01:15:47Z,good point. i have updated the comment as suggested.,1,0.970500111579895
139856155,3874,lindong28,2017-09-20T01:17:43Z,i think `replicaalterdirmanager` will only be able to fetch data from source log of a partition if the source log of the partition is on an offline log directory. thus newofflinepartitions should be removed from replicaalterdirmanager. does this make sense?,0,0.9896346926689148
139856530,3874,junrao,2017-09-20T01:21:52Z,"yes, that makes sense.",0,0.9811934232711792
139856926,3874,lindong28,2017-09-20T01:26:19Z,sure. i have updated the patch to combine these two statements and the statement in line 1401 into this: [code block],0,0.9894028902053833
139856929,3874,junrao,2017-09-20T01:26:21Z,got it. make sense. thanks.,1,0.9937415719032288
139858472,3874,lindong28,2017-09-20T01:42:28Z,sure. i have fixed this as suggested. i will pass over the entire patch later to see if this needs to be fixed in anywhere else.,0,0.9217545390129089
139858629,3874,lindong28,2017-09-20T01:44:04Z,sure. i have updated the patch to use set.,0,0.9890467524528503
139859230,3874,lindong28,2017-09-20T01:50:05Z,you are right. i have updated the patch to document `isfuture` for all methods in logmanager as appropriate.,0,0.9605271220207214
139859392,3874,lindong28,2017-09-20T01:51:53Z,sure. i have updated the patch to document parameters of this method.,0,0.9892742037773132
139859579,3874,lindong28,2017-09-20T01:53:57Z,sure. i have updated the patch to document all parameters of this method.,0,0.9889705181121826
139859792,3874,lindong28,2017-09-20T01:56:03Z,sure. i have updated the patch to use illegalstateexception here.,0,0.9915797710418701
139859805,3874,lindong28,2017-09-20T01:56:11Z,good point. i have updated the patch to use illegalstateexception here.,1,0.9681249260902405
139868382,3874,lindong28,2017-09-20T03:30:21Z,"good point regarding the cleaner checkpoint. i am wondering if it may be better to simply pause log cleaner for all those partitions that are being moved to other log directories. this approach may have two advantages over the suggested approach of saving copying the checkpoint file at the beginning of the data movement: - the broker performance is better than the suggested approach. with the suggested approach, broker needs to clean the data after the checkpoint twice. it is better to only do log cleaning after the partition has been moved to the destination log directory. - the implementation is simpler than the suggested approach. with the suggested approach, the offset for the same partition will be recorded twice in two log directories. and we will need to have more logic in logcleanermanager.allcleanercheckpoints() to differentiate between checkpoint of primary log and the checkpoint of the future log. and we probably need to take more care to keep the checkpoints across log directories consistent if e.g. log renames during swap phase failed. the only concern may be that the size of the compacted partition in the source log directory may be larger than if it is compacted. it is only a concern if replica movement takes a long time. and if this is the case, we probably already have problem with the size of the future log in the destination log directory anyway. what do you think?",1,0.9119095802307129
139870056,3874,lindong28,2017-09-20T03:51:41Z,"`any` is only used in the json file that is provided to the `reassignpartitionscommand`. this is necessary in the case that user only wants to specify log directory for one out of three replicas for a given partition. in that case the `log_dirs` field in the json file will be something like `[""any"", ""/path/to/logdir"", ""any""]`. also note that `reassignpartitionscommand` will filter out the `any` before it constructs alterreplicadirrequest. thus `any` will not be specified as log directory in alterreplicadirrequest and broker does not need to understand this constant. after more thinking, i think we probably don't need to provide a constant for user to cancel ongoing reassignment. there are two use-case for cancelling replica movement. one use-case is that user wants the replica to stay in the current log directory and he/she already knows the absolute path of the current log directory. in this case user can simply reassign partition again using the current log directory as the destination log directory. replicamanager will stop replica movement as appropriate. the other use-case is that user wants to save broker io by stop moving replica. in this case it is probably better to use quota to throttle replica movement. and user can also use either `kafka-log-dirs.sh` or `adminclient.describereplicalogdir` to read the current log directory (and lag) of the partitions that are being moved, and reassign replica again with the current log directory as the destination log directory. thus it seems that we don't need to support explicit cancellation. also, given that we are on a tight schedule to put this patch in 1.0 release, it may be better to try to reduce big changes to the patch unless it is necessary for the jbod feature.",0,0.9867689609527588
139875419,3874,lindong28,2017-09-20T04:56:06Z,thanks. i have updated the patch to fix it.,1,0.907547652721405
139875907,3874,lindong28,2017-09-20T05:03:18Z,good point. i have updated the patch to consistently use current/future in the comment everywhere in this patch. i verified this by searching for primary in the diff.,1,0.9795843362808228
139876330,3874,lindong28,2017-09-20T05:08:49Z,this method is only used in test. we can not naively include futurelogs in logsbytopicpartition because it returns a map with topicpartition as key. i have updated the patch to remove this method and replaced its use in test with logmanger.getlog().,0,0.9929346442222595
139876533,3874,lindong28,2017-09-20T05:11:11Z,sure. it is fixed now.,0,0.7552802562713623
139878127,3874,lindong28,2017-09-20T05:29:13Z,my bad. it is fixed now.,-1,0.9957629442214966
139878292,3874,lindong28,2017-09-20T05:31:07Z,yes. we should consider zero-copy. we probably don't have time to investigate it in this patch due to the 1.0 release deadline.,0,0.9863089323043823
139878466,3874,lindong28,2017-09-20T05:32:42Z,"ah, my bad.. it is fixed now.",-1,0.994892954826355
139879142,3874,lindong28,2017-09-20T05:39:57Z,i maybe wrong here because i have not read through the kip wiki of this epoch. the idea here is that replicaalterdirthread will always copy&past the epoch from the current replica to the future replica of this partition. thus it is safe to simply read the epoch and epoch offset from the current replica's cache. did i miss something here?,0,0.9086399078369141
139879604,3874,lindong28,2017-09-20T05:44:50Z,"yeah i have thought about this problem. the thing is that it requires change in the abstractfetchermanager to address this issue, or we need to create a new manager class for replicaalterdirthread. the code will be more complicated with either solution. currently the replica is assigned to threads using abstractfetchermanager.getfetcherid(...). suppose the hash function is good, it should roughly evenly balance the partition across the available replicaalterdirthread. maybe we can have a follow up jira to optimize this if the load imbalance across threads turn out to be an issue. does this sound ok?",0,0.9046230912208557
139879668,3874,lindong28,2017-09-20T05:45:30Z,my bad. thanks for catching this. it is fixed now.,-1,0.9933789968490601
139879987,3874,lindong28,2017-09-20T05:48:45Z,ah.. it is fixed now.,1,0.5189812183380127
139880505,3874,lindong28,2017-09-20T05:54:47Z,is `log.cleaner.io.max.bytes.per.second` the config for throttling log cleaning? i am not sure it is easy to be confused with `intra.broker.replication.throttled.rate`. the former uses `log.cleaner` in the name thus we know it is for log cleaner. the latter uses `replication` in the name and therefore we know it is for replication within the broker. did i miss something here?,0,0.962102472782135
139881125,3874,lindong28,2017-09-20T06:00:27Z,yeah it wasn't in the kip.. it seems useful and reasonable to include in this patch. i can document this sensor in the kip-113 wiki. i think it may be useful to have it as topic level for debug purpose. but i am not strong on this. i have updated the patch to only record it for `alltopicsstats`.,0,0.8287065029144287
139881570,3874,lindong28,2017-09-20T06:05:15Z,sure. i have renamed variables in this method and in reassignpartitions() as appropriate.,0,0.986454427242279
139882608,3874,lindong28,2017-09-20T06:14:48Z,it needs to be var because `partition.maybedeleteandswapfuturereplica()` needs to do `replica.log = futurereplica.log`. alternative we can replace the current replica with the future replica in partition.allreplicasmap. but that means we need to copy states such as lastfetchtimems from the current replica to the future replica. and it takes extra care to maintain this when we add new state in the replica in the future. thus i choose the current approach because it is simpler.,0,0.9891340136528015
139883108,3874,lindong28,2017-09-20T06:18:41Z,"i have replied to the other comment. i think we probably don't need to change alterreplicadirrequest or reassignpartitionscommand. replicamanager will not need to handle the case when destinationdir is any because alterreplicadirrequest is not expected to specify ""any"" as log directory.",0,0.9870845675468445
139884242,3874,lindong28,2017-09-20T06:28:16Z,sure. i added the following comment and renamed `logs` to `currentlogs`. [code block],0,0.9868322610855103
139885668,3874,lindong28,2017-09-20T06:40:07Z,"my gut feel is that the logic is harder to be correct if we add more suffix and more rename steps. for example, the following sequence of events may happen with the suggested approach: - futurelog is successfully renamed to log.completed. - currentlog can not be renamed due to log directory failure. - log.completed is renamed to log. if we do not rename it to log now, then when the broker starts with currentlog still offfline, broker will forget about currentlog and will need to rename log.completed to log - now broker restarts again with currentlog online. broker sees two copies of log for the same partition. it will be hard for broker to decide which one to use if the log has been truncated when currentlog is still offline. i think the current approach has simpler with less suffix. it will cause the replica to be deleted in very rare scenario. and even then the broker should be able to recover from this as long as rf > 1. if rf = 1, kafka can not ensure no data loss anyway due to disk failure.",0,0.9453652501106262
139891303,3874,lindong28,2017-09-20T07:15:24Z,"currently the the future replica will only be written by the replicaalterdirthread. and the current log will only be written by replicafetcherthread and kafkarequesthandler. the replicaalterdirthread is responsible for fetch data from current log to the future log in the same way that replicafetcherthread fetches data from leader to follower. the advantage of this design is that 1) the design is simpler because replicaalterdirthread uses essentially the same logic as replicafetcherthread; and 2) most new logic for intra-broker replication is handled by replicaalterdirthread and replicafetcherthread won't need to worry about the future log. in order to address this problem cleanly while still keep the pattern described above, i have updated the patch so that logmanager.truncateto() will always be called from partition.truncateto(). and the same for truncatefullyandstartat(). in partition.truncateto() will grab the read lock `partition.leaderisrupdatelock` before truncating the log. with the use of partition.leaderisrupdatelock, the current patch ensures that when `partition.maybedeleteandswapfuturereplica()` calls `logmanager.deleteandswapfuturelog`, it is guaranteed that `replica.logendoffset == futurereplica.logendoffset` and no thread can truncate or write the log because all write operation will need to grab `leaderisrupdatelock`. therefore, if the replicafetcherthread truncates the log to an offset smaller than the log end offset of the future log, it is guaranteed that replicaalterdirthread() will receives offsetoutofrangeexception and truncate the future log as well. does this make sense?",0,0.9772449135780334
139891823,3874,lindong28,2017-09-20T07:18:43Z,"just to double check, are you suggesting that we don't need `intrabrokerreplicationthrottledreplicasprop` and should assume that `intrabrokerreplicationthrottledrateprop` is applies to all replicas? i think it makes sense. i will update the patch after confirmation.",0,0.9834619760513306
140006970,3874,ijuma,2017-09-20T15:34:42Z,"seems like we made a bit of a mistake with the existing throttling configs in that they don't specify the unit. the log cleaner setting gets that right. also, it seems like `replication` should be reserved for data transfer between two replicas. are there two replicas here or is this just a case of copying data from one log dir to another?",0,0.986071765422821
140017132,3874,junrao,2017-09-20T16:08:15Z,"yes, that's not a bad idea. we could pause log cleaning during disk movement and copy the cleaning point after the movement completes.",0,0.8553109169006348
140017691,3874,junrao,2017-09-20T16:10:29Z,"yes, we could make it simple for now that the only way to cancel is to specify the source log dir in alterreplicadirrequest.",0,0.9930724501609802
140021307,3874,junrao,2017-09-20T16:24:44Z,"after a power failure, it's possible for the future replica to have more data than the current replica after recovery. new data could then be appended to the current replica before the future replica resumes replicating. you could have data like the following. current replica: offset: 0 1 2 epoch: 1 1 2 value : v1 v2 v4 future replica: offset: 0 1 2 epoch: 1 1 1 value : v1 v2 v3 to reconcile the replicas, you want to use future replica's latest epoch (i.e. 1) to find the offset of the last offset in that epoch in the current replica so that the future replica can get rid of v3 and copy v4 over.",0,0.983705997467041
140023208,3874,junrao,2017-09-20T16:32:18Z,"i was thinking that longer term, it may be better to have a single quota that covers all i/os within a broker (including log cleaner, moving data across disks, etc). in that case, a config name with ""intra.broker"" may be more appropriate. however, if we use that name for moving data across disks, it may make future naming a bit harder.",0,0.9828985929489136
140023952,3874,junrao,2017-09-20T16:35:04Z,"if we enable replication quota, the quota metric already tracks the byte rate across all moving partitions. so this seems redundant?",0,0.9876130223274231
140029825,3874,junrao,2017-09-20T16:58:12Z,"hmm, does it guarantee that? after the current replica truncates the data, new data could have been written to the current replica. when the future replica fetches from the current replica again, it may have seen the new data and therefore won't receive offsetoutofrangeexception. this will potentially lead to inconsistent data between the future and the current replica.",0,0.9847375750541687
140030015,3874,junrao,2017-09-20T16:58:55Z,"yes, that's my suggestion.",0,0.9873269200325012
140030170,3874,lindong28,2017-09-20T16:59:40Z,good point. i didn't consider the scenario that the future log may be ahead of the current log. i will updated the patch to use the latest epo of the future replica here.,1,0.9586399793624878
140031247,3874,lindong28,2017-09-20T17:04:23Z,thanks. i have updated the patch as suggested.,1,0.8549518585205078
140032664,3874,lindong28,2017-09-20T17:10:02Z,you are right. we no longer need this metric now that we will apply quota to all topic partitions. i have removed this metric from the patch.,0,0.9743673205375671
140034012,3874,junrao,2017-09-20T17:15:18Z,"yes, we can probably optimize this in the future if needed.",0,0.989573061466217
140038010,3874,junrao,2017-09-20T17:30:37Z,": in general, i agree the simpler the better. however, changing suffix in the future potentially will be even more complicated in order to support upgrade. so, it's worth thinking a bit more to see if we can get things right in the first place. for the approach that i described above. i was thinking that if any step fails, you stop and skip the rest of the steps. you only clean this up during log recovery on startup. for the scenario that you described, the sequencing will be the following. a) futurelog is successfully renamed to log.completed. b) currentlog can not be renamed due to log directory failure. c) currentlog will be marked offline and disk movement is stopped. d) broker is restarted and the log dir for currentlog is still offline. disk movement is still stopped and log.completed is untouched. e) broker is restarted and the log dir for currentlog is online. continue with step 2) and 3) above during log recovery. this is a bit more complicated than your approach, but seems safer and matches how we do swapping in log cleaner.",0,0.9019681811332703
140038900,3874,lindong28,2017-09-20T17:33:45Z,"it is two replicas here instead of simply copying data from one log dir to another because we are maintaining states such as epoch and high watermark in the future replica. i think it is a good idea to have a single config to throttle all i/os within a broker. given that this probably needs to deprecate the existing `log.cleaner.io.max.bytes.per.second` config, maybe we should do it in a separate kip and find a good name for it? regarding this patch, i think `intra.broker.replication.throttled.rate` is ok because this name says ""replication"" which means fetching data from one replica to another. i am also good with `across.dirs.replication.throttled.rate` (which is more consistent with `leader.replication.throttled.rate`). do you prefer me to change the name to `across.dirs.replication.throttled.rate`?",0,0.9208205342292786
140062197,3874,junrao,2017-09-20T18:59:37Z,how about log.dirs.balancing.io.max.bytes.per.second ?,0,0.9919729232788086
140063395,3874,junrao,2017-09-20T19:04:27Z,typo ofr,0,0.9924606680870056
140065045,3874,lindong28,2017-09-20T19:11:26Z,sure. i have updated the patch to rename this config and related variables as suggested.,0,0.9871921539306641
140086569,3874,junrao,2017-09-20T20:40:06Z,"should we remove the future replica too? otherwise, we may pick up the wrong futurereplica.logendoffset if logdir is changed again.",0,0.9896782636642456
140088276,3874,junrao,2017-09-20T20:47:14Z,"hmm, the logic seems to be the reverse of the comment.",0,0.9636368155479431
140090819,3874,junrao,2017-09-20T20:57:47Z,should we check if destinationdir is offline too and return an error if so?,0,0.993224561214447
140097808,3874,junrao,2017-09-20T21:27:55Z,we should be using futurereplica's hw instead of currentreplica.,0,0.9899933934211731
140107358,3874,junrao,2017-09-20T22:17:02Z,"hmm, if the replica is a future one, it seems that we don't read the hw from the checkpoint. this may impact the initial offset for replication in the future replica.",0,0.9915390610694885
140109134,3874,lindong28,2017-09-20T22:28:01Z,"great point.. i have been thinking about the right solution since your comment. i have addressed the problem with the following changes to the patch: - add methods truncateto() and truncatefullyandstartat() in partition.scala. both methods need to grab readlock of leaderisrupdatelock before truncating the log. - add method appendrecordstofuturereplica() in partition.scala. this method needs to grab inwritelock of leaderisrupdatelock first. if leo of the current replica >= leo of the future replica, this method will append data to the future log. otherwise, this method will throw offsetoutofrangeexception. this method ensures that, if the current replica is truncated after replicaalterdirthread fetches from the current replica but before replicaalterdirthread try to append data to the future replica, the data will not be appended. - abstractfetcherthread.processfetchrequest() will catch offsetoutofrangeexception thrown from processpartitiondata(). when this exception is caught, the future replica will be truncated with handleoffsetoutofrange and marked for truncation. and the future replica will be truncated again based on the epoch when replicaalterdirthread calls maybetruncate() next time. does this solution sound ok? i am not sure very sure whether we need to both do handleoffsetoutofrange() and mark the log for truncation. maybe we need only one of them?",1,0.9923548698425293
140110357,3874,junrao,2017-09-20T22:35:50Z,are we really removing the partition from the source checkpoint file as the comment says?,0,0.9927477240562439
140111701,3874,lindong28,2017-09-20T22:44:47Z,my solution has a flaw. let me think about how to fix it..,0,0.5965278744697571
140112065,3874,junrao,2017-09-20T22:47:32Z,should we remove future replicas for newofflinepartitions too?,0,0.9930436611175537
140115757,3874,junrao,2017-09-20T23:13:41Z,"hmm, i am not sure that we should do line 1080-1090 on every leaderandisr request especially the controller could re-send the same leaderandisr request. it seems that it's enough to just do this on the very first leaderandisr request (i.e., inside ""if (!hwthreadinitialized) {"").",0,0.9609226584434509
140122257,3874,lindong28,2017-09-21T00:03:31Z,"after more thinking, i made the following change to address the issue. - add method appendrecordstofuturereplica() in partition.scala. this method needs to grab inwritelock of leaderisrupdatelock to prevent race condition with log truncation on the current replica. after appending records to the future replica, this method will do the following. [code block] here is why this could address the issue. in order for the issue in this thread to happen, the following events need to happen: 1) replicaalterdirthread fetches some messages from the current replica 2) the current replica is truncated such that some data that was fetched above will be deleted from the current replica 3) new data is appended to the current replica after log truncation 4) replicaalterdirthread now appends the fetched data to the future replica. this causes inconsistency because it appends some data that was just truncated on the current replica. with the change made above, in step 4) the replicaalterdirthread will notice that the latest epoch of the current replica is larger than the latest epoch of the future replica while the offset of the first message with that epoch in the current replica is smaller than the offset of the last message in the fetched records. then the replicaalterdirthread can truncate the future replica to solve the problem. does this make sense?",0,0.9427365064620972
140122398,3874,lindong28,2017-09-21T00:04:44Z,thanks. it is fixed now.,1,0.9730711579322815
140122619,3874,lindong28,2017-09-21T00:06:29Z,thanks for catching this. it is fixed now.,1,0.9730858206748962
140122997,3874,junrao,2017-09-21T00:09:50Z,"i was thinking that one way to do this is that if the current replica truncates, we just remove the partition from the replicaalterdirthread and add it back again. this will force the initialization with proper truncation if needed.",0,0.9873219132423401
140123008,3874,lindong28,2017-09-21T00:09:58Z,thanks. you are right. i have updated the patch to fix this bug.,1,0.9848878383636475
140123222,3874,lindong28,2017-09-21T00:12:05Z,"i think alterreplicadir() already checks whether the destinationdir is offline at the beginning. if it is offline, it will return kafkastorageexception as error.",0,0.9889506697654724
140128580,3874,lindong28,2017-09-21T00:58:12Z,"my concern with doing it only on the first leaderandisrrequest is that this imposes two restrictions that it actually enforced now but may not be true in the future. one restriction is that controller needs to send all partitions in the first leaderandisrrequest to a broker. it is true as of now. but from design perspective broker should also be able to setup partition state properly if the partition is specified in the subsequent leaderandisrrequest. another restriction is that broker always need to shutdown after receiving stopreplicarequest with delete = false. otherwise, when broker receives leaderandisrrequest to be leader/follower for a partition, state of this partition may not be setup properly. this is also true for now. but it is just not very nice because ideally we should be able to send stopreplicarequest and leaderandisrrequest to stop/start a partition in a broker. i have updated the patch to address the problem by only doing line 1080 - 1090 for partitions that are online and not already created before the broker receives this leaderandisrrequest.",0,0.8034567832946777
140128968,3874,lindong28,2017-09-21T01:02:10Z,"newofflinepartitions will be removed from replicamanager.allpartitions. i think we probably don't need to remove the replica from partition.allreplicasmap if the partition object itself is going to be removed and garbage collected, right?",0,0.9919779300689697
140129564,3874,lindong28,2017-09-21T01:08:09Z,previously i think it is more accurate to just use the hw of the current replica. i have updated the patch to use hw of the future replica.,0,0.9917982816696167
140130152,3874,lindong28,2017-09-21T01:13:58Z,"yes i think so. it is same way as how logcleaner.updatecheckpoints() is used to remove partition from cleaner offset checkpoint file. logmanager.asyncdelete() will delete the log from logmanager.futurelogs before it calls `cleaner.updatecheckpoints`. the caller of altercheckpointdir(), in this case logmanager.deleteandswapfuturelog(), needs to update logmanager.currentlogs before it calls logmanager.deleteandswapfuturelog(). then `updatecheckpoints(sourcelogdir, none)` will remove the partition from source log directory and updatecheckpoints(destlogdir, option(topicpartition, offset)) will add the partition to the destination log directory.",0,0.9787243008613586
140130593,3874,lindong28,2017-09-21T01:18:53Z,"i think we actually read hw from the checkpoint if the replica is a future one. when the future replica is newly created, it is ok that we don't have hw for the future replica because the log for this future replica is empty. then `replicamanager.checkpointhighwatermarks()` will checkpoint hw for the future replica in the destination log directory. when broker restarts and load the log, partition.getorcreatereplica() will read the hw checkpoint in the destination log directory for future replica as well. does this make sense?",0,0.9820533990859985
140131155,3874,lindong28,2017-09-21T01:24:40Z,"it seems that all other issues have been addressed. i need to think more about this issue more. let me first fix the test, cleanup the patch and upload it.",0,0.9775121212005615
140131332,3874,junrao,2017-09-21T01:26:46Z,thanks for the explanation. makes sense.,1,0.9438415765762329
140131769,3874,junrao,2017-09-21T01:31:31Z,"ok, sounds good.",1,0.509122371673584
140131983,3874,junrao,2017-09-21T01:34:06Z,thanks. make sense. missed that isreplicalocal() covers future replica too.,1,0.9809550642967224
140163072,3874,lindong28,2017-09-21T07:04:14Z,"i think the suggested approach will work. i am just wondering if the following approach would be simpler: in logmanager.deleteandswapfuturelog(): 1. rename futurelog to be the current log 2. rename currentlog to be deleted. and here is how we handle log directory failure: 1) futurelog is successfully renamed to be the current log 2) currentlog can not be renamed due to log directory failure 3) the log in the source log directory will be marked offline. the log in the destination log directory will serve as the current log and this partition is still online. 4) broker is restarted and the source log directory is still offline. nothing needs to be done. the partition is online. 5) broker is restarted and the source log directory is online. but the destination log directory is online. in this case the log in the source log directory will be truncated based on the leader epoch and will be try to catch up with the leader. 6) broker is restarted and both source and destination log directory is offline. logmanager.loadlogs() will choose the one with the larger latestepoch as the current log. if these two replicas has the same leader epoch, then the one with the larger nextoffset will be chosen as the current log. the other log will be marked for deletion. the advantage of this solution is that we don't need to new suffix, and we don't need to have the logic of renaming a log directory back-and-forth. this solution takes advantage of the leaderepoch to resolve conflicts. do you think this would be a good solution?",1,0.6010389924049377
140326737,3874,junrao,2017-09-21T18:40:08Z,": what you suggested is simpler. my concerns are the following: (1) it can't truly protect the case when the same partition shows up in more than one log dir (say by human mistakes). (2) the approach of using leaderepoch only works when the message format has been upgraded. however, users may not upgrade the message format immediately after upgrading the code. picking the replica based on just the offset is less reliable.",0,0.9640985727310181
140330274,3874,lindong28,2017-09-21T18:54:37Z,"regarding (1), if the same partition appears on multiple log directories due to human either, i think log manager can still choose the one with the highest epoch (or nextoffset if epoch is the same) to address the problem. is my understanding right? regarding (2), i am wondering if it is reasonable to support intra-broker replica movement only if message format has been increased to support leader epoch. i personally think it is a good tradeoff to keep the kafka implementation simpler in the long term. it seems reasonable for a new feature to rely on a message format that has come before it. btw, in my solution to another issue you raised, i.e. inconsistency between the current and the future replica, i also used this trick of leader epoch to address the problem. the solution to that problem will probably be less clean if we can not reply on leader epoch. i will need to think more about how to address these two problems if we want to allow user to move replica within broker with older message format.",0,0.7596263885498047
140330487,3874,lindong28,2017-09-21T18:55:28Z,also note that kip-112 is only enabled if inter-broker-protocol is 1.0 or higher. i am wondering if the similar logic can be applied to determine whether kip-113 is fully supported.,0,0.9920549392700195
140347295,3874,junrao,2017-09-21T20:13:39Z,": for (1), if there is human error, the 2 replicas could correspond to the same topic created at different times. so, their leader epoch may not be directly comparable. it just feels safer if we have a more direct way to detect errors like this. for (2), note that inter-broker-protocol is separate from the message format. even when the message format is set, leader epoch only applies to newly produced messages.",0,0.9801289439201355
140361789,3874,junrao,2017-09-21T21:18:44Z,"hmm, i am not sure if we should lock the writes to the current replica while writing to the future replica. what you said earlier makes sense: we want the writes to the current and the future replica to be independent. another concern is that we are duplicating the logic for epoch checking in replicaalterdirsthread here. i was thinking that another way to do this is in partition.truncateto(), if the truncation is on a current replica, we simply remove it and add it back to the replicaalterdirmanager if it's there. the newly added partition will go through the initialization phase to do the truncation that's needed. this way, the writes to current and the future replica can still be independent.",0,0.7758724689483643
140364258,3874,junrao,2017-09-21T21:30:09Z,could we replace replicamgr.getpartition(topicpartition).get with partition?,0,0.9947524070739746
140365688,3874,junrao,2017-09-21T21:36:34Z,it's not very clear what's being deleted from the name. would it be better to name this replacecurrentwithfuturelog?,0,0.9822836518287659
140366268,3874,junrao,2017-09-21T21:39:25Z,it seems that we need to call replicaalterdirmanager.shutdownidlefetcherthreads() after a partition is removed?,0,0.9928528666496277
140369569,3874,junrao,2017-09-21T21:55:51Z,"there are various error loggings like that in line 220 with text ""error to broker .."". those lines are now shared between the replicafetcherthread and the replicaalterdirthread. so, we probably want to make the logging clearer.",0,0.9916446805000305
140370782,3874,junrao,2017-09-21T22:02:02Z,the reference to leader is not accurate here.,0,0.9436479806900024
140371771,3874,junrao,2017-09-21T22:07:07Z,"hmm, shouldn't we get the startoffset from the future replica?",0,0.9806061387062073
140375054,3874,junrao,2017-09-21T22:29:05Z,should we make this volatile now that it's updatable?,0,0.9921215772628784
140377631,3874,junrao,2017-09-21T22:47:03Z,we probably want to have a separate window size and window samples config for the intrabroker quota?,0,0.9929416179656982
140377671,3874,junrao,2017-09-21T22:47:19Z,intrabroker => logdirsbalancing?,0,0.9944037199020386
140379049,3874,junrao,2017-09-21T22:57:49Z,"to be consistent with the new throttling name, perhaps name this num.log.dirs.balancing.threads? if so, we want to change variable names, comments, and documentations accordingly.",0,0.9945113658905029
140379353,3874,junrao,2017-09-21T23:00:10Z,this is now unused.,0,0.993134617805481
140380696,3874,junrao,2017-09-21T23:09:43Z,"hmm, leaderepochcache is maintained when records are appended to the log. so, not sure if we need to call initializeleaderepochcache() when renaming.",0,0.9629951119422913
140380952,3874,junrao,2017-09-21T23:11:40Z,"if the dir name doesn't change, could we skip the steps below?",0,0.9923932552337646
140383875,3874,junrao,2017-09-21T23:34:10Z,could we add topicpartition too?,0,0.9949179887771606
140385799,3874,junrao,2017-09-21T23:51:11Z,we probably want to rename intra-broker-throttle to log-dirs-balancing-throttle?,0,0.9920392036437988
140385990,3874,junrao,2017-09-21T23:53:02Z,should we make it volatile?,0,0.9839943647384644
140387569,3874,junrao,2017-09-22T00:07:08Z,unused import,0,0.9873000979423523
140389918,3874,junrao,2017-09-22T00:26:11Z,is the comment still valid?,0,0.9935123324394226
140389959,3874,junrao,2017-09-22T00:26:37Z,should we do the assert in a waituntil loop?,0,0.9934499859809875
140390517,3874,junrao,2017-09-22T00:32:46Z,"the replica on broker 100 is just changing the log dir. waitforreassignmenttocomplete() only checks for the completion of cross broker replica movement, but not of cross log dirs movement. perhaps we should do this in a waituntil() loop?",0,0.9923648834228516
140595813,3874,lindong28,2017-09-22T21:01:15Z,"regarding (2), i am thinking that it may be reasonable to say we only support inter-broker replica movement only if message format is supports epoch. this is similar to saying that we only support time-based query if message format supports time index, and we only kafkaheader if the message format support kafka header. this may be worth doing if it can keep the kafka implementation simpler in the long term. also regarding (2), my understanding is that we can use leader epoch to choose the newer log directory in this case after message format has been upgraded to support leader epoch, even if there is still old messages in the log that doesn't have leader epoch. this is because the trick here only look at the epoch of the latest message for each log directory. if this is not true then my approach would not work. regarding (1), i realized the following shortcomings of the suggested approach while trying to implement it. let me compare the suggested approach with my approach in more detail below. to clarify, my approach is the following: 1) rename futurelog to be the current log 2) rename currentlog to be deleted. the approach you suggested is the following: 1) rename futurelog to log.completed. 2) rename currentlog to log.deleted. 3) rename log.completed to log. pros of the suggested approach: - it allows user to move replica between log directories of the same broker before user has upgraded to the message format that support leader epoch. (a short term benefit) - it matches how we do swapping in log cleaner (i am not very sure the benefit of following the existing swapping logic in log cleaner in this case though. can you explain a bit more?) - it can help us detect human error if the user mistakenly copied a directory with old data to a broker which already has directory for this partition on another log directory. cons of the suggested approach: - if we fail at the step 2 (rename currentlog to log.deleted), we will mark the partition offline even if we can use the partition in the destination log directory. this reduces availability of the partition. - if we fail at step 3 (rename log.completed to log), we will still delete the replica in the source log directory because it has been successfully renamed for deletion. this reduces the persistence of the partition. - extra logic is needed to keep completable logs in a separate map in logmanager so that we can include its size in the describelogdirsresponse. we also need extra metric tag for log whose directory has be renamed to log.completed. this adds complexity to kafka implementation in the long term. - it doesn't protect against more complicated errors, e.g. if user deletes new log directory before copying the old log directory, or if user deletes specific segment for the partition. overall i think the ability to detect some human error is nice to have. but human error detection is generally hard to do and we don't have a good definition for the scope of human error that can be detected. i am not sure if this is worth the cost in availability and code complexity. actually, if we do want to detect this specific human error, we can also modify the my approach to have broker refuse to start if the same partition appears in more than one directory. this will generate false positive only if source log directory fails exactly at the time the destination partition has caught up with the source partition, which should be pretty. since user knows the log directory that was offline, he/she can manually delete the partition in the source log directory correctly and restart the broker. the reply is a bit long. thanks for taking time to read and discuss this issue.",0,0.9552726149559021
140636915,3874,junrao,2017-09-23T16:22:58Z,": i like the modified version of your approach. basically fail the broker if we detect duplicated logs during restart. this makes the logic simpler. with this, we probably don't need to have the constraint on message format.",1,0.809095561504364
140643683,3874,lindong28,2017-09-23T23:16:22Z,"ah, i didn't realize you have replied to this thread. yeah i have considered this option. my concern with this approach is that truncation usually happens at the partition level or log level, but the management of replicaalterdirmanager and replicafetchermanager ideally should happen at the replicamanager level, which is higher than the level of partition and log. usually the level of caller should be higher than the level of caller to avoid deadlock and to make the code logic simpler to maintain and develop in the long term. in this specific case, if we add/remove partition from replicaalterdirmanager, a replicafetcherthread may need to get the following lock if truncation happens: abstractfetcherthread.partitionmaplock, partition.leaderisrupdatelock, replicamanager.replicastatechangelock, replicaalterdirmanager.maplock and replicaalterdirthread.maplock. this may cause deadlock if another kafkarequesthandler attempts to get the replicamanager.replicastatechangelock and then partition.leaderisrupdatelock. do you think the approach i suggested previously would work? do you have concern with having this approach depend on the leader epoch and thus the message format?",0,0.6995271444320679
140645077,3874,lindong28,2017-09-24T01:25:35Z,"yeah i have considered this option. my concern with this approach is that truncation usually happens at the partition level or log level, but the management of replicaalterdirmanager and replicafetchermanager ideally should happen at the replicamanager level, which is higher than the level of partition and log. usually the level of caller should be higher than the level of caller to avoid deadlock and to make the code logic simpler to maintain and develop in the long term. in this specific case, if we add/remove partition from replicaalterdirmanager, a replicafetcherthread may need to get the following lock if truncation happens: abstractfetcherthread.partitionmaplock, partition.leaderisrupdatelock, replicamanager.replicastatechangelock, replicaalterdirmanager.maplock and replicaalterdirthread.maplock. this may cause deadlock if another kafkarequesthandler attempts to get the replicamanager.replicastatechangelock and then partition.leaderisrupdatelock. regarding your concern with ""lock the writes to the current replica while writing to the future replica"", i think it probably won't hurt performance much. it will reduce the maximum throughput of writing to the current replica by at most half. but i assume that for most replica, the average throughput should be much less than 50% of the maximum throughput that a broker can write to a partition. furthermore, even if the throughput of this partition is very close to the maximum throughput, we actually want to reduce the throughput that a broker can write to the current replica before the future replica catches up. does this make sense? do you think the approach i suggested previously using leader epoch would work? do you have concern with having this approach depend on the leader epoch and thus the message format?",0,0.8988173007965088
140645086,3874,lindong28,2017-09-24T01:26:15Z,"regarding your concern with ""lock the writes to the current replica while writing to the future replica"", i think it probably won't hurt performance much. it will reduce the maximum throughput of writing to the current replica by at most half. but i assume that for most replica, the average throughput should be much less than 50% of the maximum throughput that a broker can write to a partition. furthermore, even if the throughput of this partition is very close to the maximum throughput, we actually want to reduce the throughput that a broker can write to the current replica before the future replica catches up. does this make sense? we can continue discussion under the new batch of comment you provided. thanks!",0,0.9413892030715942
140645139,3874,lindong28,2017-09-24T01:30:45Z,"my bad. previously i was very tight on the time and spent on most of the time on addressing the comments and have not spent enough time on reviewing the patch myself. now that i have time, i will review the patch myself twice and let you know once it is ready.",-1,0.9914469718933105
140645147,3874,lindong28,2017-09-24T01:31:10Z,the issue is fixed as suggested.,0,0.9831458330154419
140645440,3874,lindong28,2017-09-24T02:02:10Z,"i understand that ideally we want to shutdown idle threads. my concern with this approach is that it will let replicaalterdirthread depend on replicaalterdirmanager which introduce circular dependency and make it easier to have deadlock in the future. the only drawback of the current approach is that, there may be idle replicaalterdirthread until the broker receives the next leaderandisrrequest. during this period this replicaalterdirthread will call dowork() once every 1 second by default, which doesn't seem like a problem. thus i think the little performance overhead is better than complicating the kafka implementation. what do you think?",0,0.7830807566642761
140645451,3874,lindong28,2017-09-24T02:03:35Z,my bad. it is fixed now.,-1,0.9957629442214966
140645510,3874,lindong28,2017-09-24T02:06:24Z,previously i thought it is always more accurate to simply read the logstartoffset (and similarly hw) from the current replica. i forgot to go over the patch and correct this after your previous comment regarding the use of hw. i will go over the patch twice to make sure all these are corrected. it is fixed as suggested.,0,0.9712800979614258
140648350,3874,lindong28,2017-09-24T06:20:07Z,it is fixed now. i should be able to fix missing parameters like this in the next update.,0,0.8943936228752136
140651820,3874,lindong28,2017-09-24T09:39:56Z,good point. i have updated the name as suggested. thanks!,1,0.9954822063446045
140653814,3874,lindong28,2017-09-24T11:24:16Z,"i am not sure i understand the problem here. it seems that current error logging in abstractfetcherthread is technically correct. for example, the `error to broker` in line 220 is correct because `sourcebroker.id` still refers to the broker from which the data is fetched, for both replicafetcherthread and replicaalterdirthread. furthermore, the log4j error logging already identifies the class (either replicafetcherthread or replicaalterdirthread) for those log statements in the abstractfetcherthread, thus there is probably no need to identify in the logging message whether it is for replicafetcherthread or replicaalterdirthread. does this make sense?",0,0.6362060904502869
140653857,3874,lindong28,2017-09-24T11:25:59Z,good point! i have updated the patch to make it volatile.,1,0.9950575828552246
140653887,3874,lindong28,2017-09-24T11:27:44Z,it is fixed now. i will review the patch myself twice and try to catch all these things.,0,0.785746693611145
140654025,3874,lindong28,2017-09-24T11:34:18Z,"i don't have a good reason for adding a separate window size and window samples. i think the main difference between interbroker and logdirsbalancing quota is the throttle rate which can already be configured differently for these two quotas. is there any scenario where user may want to use different window size and window samples for interbroker and logdirsbalancing quota? if not, maybe we can do it when we need it in the future?",0,0.9757177829742432
140654292,3874,lindong28,2017-09-24T11:48:32Z,"replicaalterdir describes the action of these threads and classes, whereas logdirsbalancing identifies the purpose of this action of moving replica. i think replicaalterdir* is more useful and explicit for kafka developer to understand the what these replicaalterdirthread is doing. on the other hand, logdirsbalancing is probably more useful for user to understand the purpose of this new quota. if we were to unify the name, i think it is better to use replace logdirsbalancing with replicaalterdir. the reason is that it is a bit weird and vague to have method like adminclient.logdirsbalancing(map ). and both developer and user probably needs to translate logdirsbalancing to replicaalterdir in order to understand what the new thread, thread manager and request is doing. what do you think?",0,0.9165547490119934
140654314,3874,lindong28,2017-09-24T11:49:27Z,sorry.. it is fixed now.,-1,0.9942029118537903
140654337,3874,lindong28,2017-09-24T11:50:30Z,good point. i have updated the patch as suggested.,1,0.9724542498588562
140654392,3874,lindong28,2017-09-24T11:53:26Z,"i think we need to call initializeleaderepochcache() because the leaderepochcheckpointfile.checkpoint.file is determined and fixed in initializeleaderepochcache(). thus if we don't call initializeleaderepochcache() after the log directory is renamed, leaderepochcheckpointfile.write() will still try to write to a file in the old log directory which no longer exists.",0,0.9864352345466614
140654406,3874,lindong28,2017-09-24T11:54:17Z,"yes, you are right. i will rename these.",0,0.9676998853683472
140654424,3874,lindong28,2017-09-24T11:54:59Z,ah.. fixed now.,0,0.8422622680664062
140654487,3874,lindong28,2017-09-24T11:57:27Z,thanks. i have updated the comment to the following. i will review the patch end-to-end twice to try to make comments and the code consistent after the previous changes. `// when we execute an assignment that moves an existing replica to another log directory on the same broker`,1,0.9651349186897278
140654577,3874,lindong28,2017-09-24T12:02:24Z,you are right. it is fixed now.,1,0.6566940546035767
140654729,3874,lindong28,2017-09-24T12:10:00Z,you are right. strictly speaking we should use waituntil() here. i have updated the patch accordingly.,0,0.9625142216682434
140683628,3874,junrao,2017-09-25T03:34:28Z,": your suggested approach probably works in the common case. my concerns are the following. (1) log truncation is a relatively rare event. your approach tries to solve the problem by requiring writes to future log to hold on to the lock to the current log on every write. so, we add overhead in the common path to solve a rare event. intuitively, to solve a rare event, we also want to add overhead in the rare path. (2) your approach won't be able to distinguish leader epoch inconsistency due to log truncation or bugs in kafka. in the latter case, we probably want to error out instead of continuing. (3) the dealing with leader epoch is tricky to reason about and is already done during replica initialization in the replicaalterdirthread. if possible, it would be useful to limit the places that we deal with leader epoch directly. (4) in theory, even if a topic has the new message format, a truncation may bring the log to the point where there is only old message. (5) intuitively, the disk balancing feature seems independent of message format. so, it feels a bit weird to require that. as for the concerns that you mentioned on the suggested approach. i am not sure we need to hold partition.leaderisrupdatelock. that lock is only needed when the replica set changes. truncating an existing future replica doesn't change replica set though. we do want to make sure that the reinitialization in the future replica is synchronized properly with potential concurrent alterlogdir requests, as you pointed out. so, the following is a slightly modified approach. after the replicafetchthread truncates the log, it will do the following: (1) call a new method in replicaalterdirthread.addpartitionswithtruncation that takes a partition and a truncating offset. this method won't directly do truncation in the future replica. it simply sets the partition state to be truncating if the partition is still present in the partition map. when replicaalterdirthread sees this new state, it ignores any pending fetch response and truncates the future log to the truncating offset, and then resumes fetching. addpartitionswithtruncation() needs to hold partitionmaplock. however, since only replicafetchthread.truncation can call replicaalterdirthread.addpartitionswithtruncation, but not vice versa. there is no cycle to form a deadlock. this approach seems to address all the above concerns: (1) no additional overhead in the write path, which is common, (2), (3) no additional logic for dealing with leader epoch, (4) and (5) doesn't require new message format. neither approach deals with the case when a truncation only happens on the current replica, but not the future replica, and the broker dies. this can still lead to the case when the future replica's log can be ahead of the current replica. if the message format doesn't have the leader epoch, this may not be dealt with cleanly during future replica initialization. we could potentially just truncate the future replica to the log end offset of the current replica in that case during recovery.",0,0.9350830912590027
140683654,3874,junrao,2017-09-25T03:34:53Z,could we just add a scheduler thread that calls replicaalterdirmanager.shutdownidlefetcherthreads() periodically?,0,0.9938627481460571
140683674,3874,junrao,2017-09-25T03:35:14Z,"my point is that for replicaalterdirthread, the logging ""to broker"" doesn't convey much info since it always moves data within the same broker. when there is an error, it's more useful to know the source log dir from which the future replica is copying.",0,0.9853590726852417
140683704,3874,junrao,2017-09-25T03:35:49Z,"the window size and window samples impact how much load can be put during initialization. during initialization, we give a full window worth of quota. so, the larger the window, the more bytes can be put in initially. since interbroker quota may be configured based on network capacity whereas logdirsbalancing quota is mostly based on disk capacity, having separate window sizes between the two quotas allows the admin to control the initial load separately.",0,0.9923837780952454
140683719,3874,junrao,2017-09-25T03:36:06Z,"hmm, it seems that both the num.threads config and the disk movement quota will be set by the admin. so, it seems it makes sense to make them consistent. naming them both after replica alter dir will be fine too.",0,0.981941819190979
140683728,3874,junrao,2017-09-25T03:36:14Z,"ah, makes sense. could you add a comment about this?",0,0.981493353843689
140683945,3874,junrao,2017-09-25T03:39:55Z,"a related concern here is that we are paying the sort overhead on every fetch request. if there are lots of partitions, this could add non-trivial overhead. the queue approach where the replicaalterdirthread takes one partition at a time from the queue obviates the need for that. it's fine to optimize this in a followup patch though.",0,0.9862885475158691
140922489,3874,lindong28,2017-09-25T23:09:34Z,"i think your points 1-5 makes sense. my concern with the modified approach is that it requires replicafetcherthread to depend on the replicaalterdirthread in order to call fetching. addpartitionswithtruncation(). it seems a bit clumsy. i have another way of doing that by passing the truncation signal from replicafetcherthread to replicaalterdirthread via the affected partition. here is my modified approach: 1) partition.truncateto() and partition.truncatefullyandstartat() will grab write lock of leaderisrupdatelock. and partition.appendrecordstofuturereplica() will grab read lock of leaderisrupdatelock. thus we still ensure that the truncation of the current replica and the append operation of the future replica will be executed in order. 2) when the current replica of a partition is truncated, it will set partition.futurereplicaneedtruncation to true. 3) partition.appendrecordstofuturereplica() will first check whether partition.futurereplicaneedtruncation is true. if the flag is true, the method will set the flag to false and throw offsetoutofrangeexception. 4) if abstractfetcherthread.processfetchrequest() catches an ooor exception from processpartitiondata(), it will update partitionstate for this partition to set truncatinglog to true. then the future replica will be truncated based on the leader epoch later. this approach also seems to address all the above concerns: (1) no additional overhead in the write path, which is common, (2), (3) no additional logic for dealing with leader epoch, (4) and (5) doesn't require new message format. in comparison to the previous modified approach, the class dependency graph will be simpler and more intuitive. what do you think?",1,0.5087732076644897
140923612,3874,lindong28,2017-09-25T23:17:24Z,great! i will implement this version in the updated patch.,1,0.9951459765434265
140928340,3874,lindong28,2017-09-25T23:53:27Z,thanks for catching this. i have updated it patch to fix it.,1,0.9685006141662598
140928991,3874,lindong28,2017-09-25T23:57:55Z,good point. i have updated the patch to call replicaalterdirmanager.shutdownidlefetcherthreads() every 2.5 seconds.,1,0.961637020111084
140931539,3874,lindong28,2017-09-26T00:19:55Z,"i see. currently abstractfetcherthread can not get the log directory for partition in general because consumerfetcherthread, which also extends abstractfetcherthread, does not have log directory for partition. i think the existing implementation probably already provides log directory of the partition in the error log when this information is needed. the idea is that we need to know the log directory of the partition in the error log only if this is a log directory failure. but if this is the case, the original exception should have specified the log directory of the partition. does this sound reasonable?",0,0.9802680015563965
140931968,3874,lindong28,2017-09-26T00:23:48Z,i see. the default size of the full window is 11 seconds. i think the replica movement typically lasts much longer than 11 seconds and in general it is not a big deal to have a slow start. i am not sure it is worth two additional configs to optimize the initial performance of intra-broker replica movement. i don't have a strong opinion on this. do you prefer me to add two configs for this new quota?,0,0.8623217344284058
140932270,3874,lindong28,2017-09-26T00:26:57Z,sure. i added this comment: `re-initialize leader epoch cache so that leaderepochcheckpointfile.checkpoint can correctly reference the checkpoint file in renamed log directory`,0,0.9794461727142334
140936761,3874,lindong28,2017-09-26T01:07:01Z,sure. i have updated the patch to use replica alter dir consistently.,0,0.9902883768081665
140938334,3874,lindong28,2017-09-26T01:22:16Z,"good point. i have updated the patch with the following code. the new implementation should require only one pass of the partitionmap with o(n) time complexity, which is same as the time complexity of replicafetcherthread.buildfetchrequest().",1,0.9783962368965149
140938438,3874,lindong28,2017-09-26T01:23:13Z,here is the code. the idea is that we only need the maximum partition in the filtered partitionmap. [code block],0,0.994902491569519
140941543,3874,junrao,2017-09-26T01:55:06Z,": the modified approach sounds good overall. a few more questions on this. (a) do we need the leaderisrupdatelock in step 1? if we truncate the current replica first and then insert the truncation point in the future replica, eventually the future replica will be able to truncate to the right offset, right? (b) for step 2 and 3, we can set the truncation state through partition. but we could also just directly set the state in replicaalterdirthread, which seems simpler since it avoids a level of indirection. (c) not sure why we need to turn the truncation state to ooor exception. the handling of ooor may truncate to a different offset than the truncation offset. it seems it's clearer if we handle the truncation state directly.",1,0.9031294584274292
140942158,3874,junrao,2017-09-26T02:01:26Z,"yes, i'd prefer to add two new configs for the new quota since we already have separate window configs for the client and the replication quota.",0,0.9914212822914124
140952243,3874,lindong28,2017-09-26T03:54:06Z,sure. i will update the patch to add these two new configs.,0,0.9870012998580933
140993990,3874,lindong28,2017-09-26T08:53:21Z,"good point regarding (a). indeed, truncateto() and truncatefullyandstartat() can simply use the readlock instead of the writelock. readlock is needed to avoid race condition with maybereplacecurrentwithfuturereplica(). regarding (b), can you explain a bit more how replicafetcherthread can set state in replicaalterdirthread after log truncation? are you suggesting that replicafetcherthread constructor should take `replicaalterdirmanger.fetcherthreadmap` as input. then when log truncation happens for partition, it derives the corresponding replicaalterdirthread from `replicaalterdirmanger.fetcherthreadmap` by hashing the topic and partition, before calling `replicaalterthread. addpartitionswithtruncation ()`? it seems a bit weird to put `replicaalterdirmanger.fetcherthreadmap` in the constructor of each replicafetcherthread. what do you think? regarding (c), i agree we don't need to throw ooor if we can directly set the truncation state. i am just not sure how we can directly set the truncation state due the concern with (b) described above. also, in my suggested approach, the handling of this ooor will not reset offset using handleoffsetoutofrange. instead it will set partitionstate.truncatinglog to true so that the partition will be truncated based on the leader epoch later. i am going to update the patch soon so that you can see it.",1,0.8336710333824158
141366056,3874,junrao,2017-09-27T14:44:59Z,": i was thinking of adding a truncatepartition(map[topicpartition, long]) method in abstractfetcherthread and abstractfetchermanager. the latter will call the former. the method takes a truncation offset for each partition in the map. replicafetcherthread will have access to replicaalterdirmanager to call truncatepartition() when the current log is truncated. currently, abstractfetcherthread maintains partitionfetchstate for each partition, if the state is truncatinglog, it will issue leaderepochrequest, followed by log truncation. we can probably introduce a separate leaderepochstate. during initialization, a partition will go through leaderepoch state (where leader epoch request is issued) and then truncatinglog state (where log will be truncated). when truncatepartition() is called, abstractfetcherthread just sets the partition state to truncatinglog state. when abstractfetcherthread sees a partition in that state, it will just truncate the log to the specified truncating offset and then transition to the fetch state. for (a), i am not sure we even need a read lock on leaderisrupdatelock. in the case when a partition is already removed when abstractfetcherthread.truncatepartition() is called, we can simply ignore that partition.",0,0.974172830581665
141389315,3874,lindong28,2017-09-27T15:57:01Z,"regarding (b), it seems that leaderepochstate is not used in the suggested approach? i think the suggested approach would work. my only concern with this approach is that his approach will have replicafetcherthread depend on replicaalterdirthread, which is a bit unintuitive. on the other hand, my current approach is more complicated because it requires a new flag in parition, ooor exception from partition.truncateto(...), and handling of this ooor exception thrown from processpartitiondata(). i will implement the suggested approach if you think it is ok to have replicafetcherthread depend on replicaalterdirthread. can you confirm this? regarding (a), i think readlock is needed by truncateto() and truncatefullyandstartat() to avoid race condition with maybereplacecurrentwithfuturereplica(). for example, if truncateto() does not grab the read lock, it is possible that maybereplacecurrentwithfuturereplica() finds the leo of the future replica equals leo of the current replica, truncateto() truncates the current replica, and then maybereplacecurrentwithfuturereplica() replaces the current replica with the future replica, and the future replica has data that should have been truncated. does this make sense?",0,0.9492825865745544
141399349,3874,junrao,2017-09-27T16:33:14Z,": in comparison, the approach that lets replicafetcherthread reference replicaalterdirmanager seems a bit better. your explanation on the locking requirement makes sense. we are abusing the intent of leaderisrupdatelock now. so, we probably want to add some comments on that.",0,0.8610779643058777
141768963,3874,lindong28,2017-09-29T00:49:23Z,thanks for all the comments! i have updated the patch as suggested.,1,0.9891582727432251
142055101,3874,tedyu,2017-10-02T03:57:10Z,should we check whether getreplica(request.futurelocalreplicaid).get.log is none (in case we get read lock immediately after write lock is released) ? see code at line 197 above.,0,0.9951940178871155
142070001,3874,lindong28,2017-10-02T07:34:43Z,maybereplacecurrentwithfuturereplica() will not cause nosuchelementexception here because there the thread that calls maybereplacecurrentwithfuturereplica() for a given partition is guaranteed to be the same replicaalterdirthread that appends record to the future replica of this partition.,0,0.9945953488349915
142263275,3874,junrao,2017-10-02T21:41:00Z,unused import offsetoutofrangeexception.,0,0.9930078983306885
142266788,3874,junrao,2017-10-02T21:58:47Z,"hmm, not sure why we need to check partitionstates.contains() here since we already have the check in line 179.",0,0.8830921649932861
142267378,3874,junrao,2017-10-02T22:01:30Z,indentation,0,0.9911677837371826
142278626,3874,junrao,2017-10-02T23:08:27Z,"hmm, i am not sure that we should always let a partition go through the leader epoch logic when a partition is marked for truncation. there are two cases here. (1) if a partition is not in the fetching mode, we should let the replica go through the leader epoch logic and truncate based on the epoch response. after that, we will truncate again based on the marked truncation offset. (2) if a partition is in the fetching mode, we should just do the truncation based on the marked truncation offset w/o going through the leader epoch logic. we probably want to add some comments to document this. also, given this new method, the existing includelogtruncation flag can be a bit confusing. perhaps it's clearer to rename it to isrecovering?",0,0.8543109893798828
142283836,3874,junrao,2017-10-02T23:46:58Z,"the name appendtofollower is now a bit mis-leading since it can be used to append records for future replicas, which is not really a follower. perhaps it's better to rename the methods here and those in log as appendwithoffsetassignment() and appendwithoutoffsetassignment().",0,0.9818779230117798
142294260,3874,ijuma,2017-10-03T01:17:04Z,"we can use this in `logfuturedirname` and `logdeletedirname`. we can maybe add a `suffix` parameter and have `""""` as the default.",0,0.9946976900100708
142294466,3874,ijuma,2017-10-03T01:19:17Z,it seems like `if/else` could be about appending the third tag instead of duplicating all the logic.,0,0.9863805174827576
142294684,3874,lindong28,2017-10-03T01:21:36Z,"previously i had a method called `appendrecordstofuturereplica`. i merged it with `appendrecordstofollower` to reduce the number of methods. since this is misleading, i think it may be better to add method `appendrecordstofuturereplica`, which is more intuitive and more consistent with the name `appendrecordstoleader`. what do you think?",0,0.9808401465415955
142294773,3874,ijuma,2017-10-03T01:22:21Z,"we typically use dash-separated names for kafka metrics. should it be `is-future` then? also, i wonder if this name will be clear to people. i'll think a bit more, don't have any concrete suggestions, right now.",0,0.952268660068512
142294900,3874,lindong28,2017-10-03T01:23:46Z,"the reason is that replicadiralterthread may have removed topicpartition from the partitionstates in `processpartitiondata()` if the future replica has caught up with the current replica. in this case if we call `partitionstates.updateandmovetoend()`, this partition will be added back to the `partitionstates` by mistake.",0,0.9920651316642761
142294964,3874,lindong28,2017-10-03T01:24:06Z,my bad.. it is fixed now.,-1,0.995913565158844
142295005,3874,lindong28,2017-10-03T01:24:24Z,thanks much for the detailed review. it is fixed now.,1,0.9643048048019409
142295483,3874,ijuma,2017-10-03T01:28:49Z,"does this not need to be `volatile`? also, now that it's a `var`, we may want to make it private and only provide a public accessor.",0,0.990481436252594
142295625,3874,ijuma,2017-10-03T01:30:23Z,we should probably use `utils.atomicmovewithfallback`.,0,0.9935251474380493
142295728,3874,ijuma,2017-10-03T01:31:36Z,"seems like we should extract a method that just takes the suffix and generates the `uniqueid`, etc.",0,0.9874463081359863
142421245,3874,lindong28,2017-10-03T14:37:39Z,"one reason to let a partition go through leader epoch is that, if the leader replica is truncated to offset 10, append data up to offset 20, and truncated again to offset 15, first truncation offset 10 will be overwritten by the second truncation offset 20. in reality the window for this happening is probably small and we expect the truncation to happen almost immediately on the future replica after the leader is truncated. but ideally we would probably want to stay on the safe side and use leader epoch to make sure this does not cause any problem. another reason to apply leader epoch is to mimic what we are currently doing with the follower replica. currently whenever leader replica is truncated, it is guaranteed that there is leadership transfer, and the replica will be removed from the replicafetchermanager and added back in the follower. thus the follower will always apply leader epoch if leader is truncated. so it seems to make sense to always truncate the future replica using leader epoch whenever the current replica is truncated. does this make sense? also, is there any correct or performance concern if we always use leader epoch to truncate the future replica?",0,0.9841025471687317
142422846,3874,lindong28,2017-10-03T14:42:59Z,"good point. you are right, it should be volatile. i have updated the patch to make it private and added a public accessor for it.",1,0.9674235582351685
142423254,3874,lindong28,2017-10-03T14:44:26Z,yeah it should be is-future. i have updated the patch as suggested. thanks!,1,0.9881559610366821
142424683,3874,lindong28,2017-10-03T14:49:18Z,sure. i updated the patch with the following code: [code block],0,0.989543080329895
142427674,3874,lindong28,2017-10-03T14:59:18Z,"i have considered this api. `utils.atomicmovewithfallback` calls `files.move`. and according to the java doc of `files.move`, this method will fail if the target file exists, which is the case here when we replace the current replica with the future replica.",0,0.9928054213523865
142429205,3874,lindong28,2017-10-03T15:04:25Z,"sure. i have updated the patch to add a private method `logdirname(topicpartition: topicpartition, suffix: string)`. i still keep the method `logfuturedirname` and `logdeletedirname` because it seems easy to use by the caller. i can remove these two methods if you prefer.",0,0.9741761088371277
142429272,3874,ijuma,2017-10-03T15:04:36Z,"`files.move` does not fail if the target file already exists given the right `copyoptions`, which `atomicmovewithfallback` uses.",0,0.9941987991333008
142429768,3874,ijuma,2017-10-03T15:06:22Z,"in particular, `atomic_move` should work on linux. and on windows, we fallback to `replace_existing`.",0,0.9939157366752625
142430102,3874,ijuma,2017-10-03T15:07:34Z,"although, this is a directory, so not sure. maybe we should write a test to verify. either way, if `atomic_move` doesn't work, we should use `files.move` with `replace_existing`, which should work, i believe.",0,0.984336256980896
142431419,3874,lindong28,2017-10-03T15:12:09Z,sure. i have updated the patch to use this method in the newly-added private method.,0,0.9884365797042847
142432032,3874,lindong28,2017-10-03T15:14:15Z,i made a mistake previously. the `renamedir` will rename a directory but the destination direction does not exist. thanks for the explanation. i will try and test this approach.,1,0.9675081372261047
142433208,3874,ijuma,2017-10-03T15:18:11Z,sounds good. the main advantage of the `files` apis when compared to the legacy ones is that they provide error messages when things go wrong. that can be quite helpful.,1,0.9379964470863342
142482694,3874,lindong28,2017-10-03T18:24:12Z,i have updated the patch as suggested.,0,0.9947056174278259
142558743,3874,junrao,2017-10-04T00:34:06Z,good point. could you add a comment for that?,1,0.9603290557861328
142559035,3874,junrao,2017-10-04T00:37:14Z,: very good point on double truncation. one way to get around this is to maintain the smallest truncation offset if the partition is marked for truncation multiple times. my concern of depending on leader epoch is that it won't apply if the message format is old.,1,0.9720500111579895
142704994,3874,lindong28,2017-10-04T15:27:09Z,sure. actually the comment is already in the patch.,0,0.9911832809448242
142707839,3874,lindong28,2017-10-04T15:37:00Z,"good point. i have update the patch to use the smallest truncation offset. even if we use the smallest truncation offset, i think it is still safer to use leader epoch to truncate the future replica if leader epoch is available. this is because truncation offset is only recorded in the memory which may be lost if broker restarts. does this make sense?",1,0.9412718415260315
142721548,3874,lindong28,2017-10-04T16:24:54Z,i have rebased patch onto trunk. i will go through this patch end-to-end after we agree on how to truncate the future replica.,0,0.9946040511131287
142831425,3874,junrao,2017-10-05T01:26:53Z,": thinking a bit more. we can use leader epoch to handle truncation since if the leader epoch doesn't exist, we fall back to hw and the truncation point should always be no lower than that. so, this should be safe.",0,0.9497199058532715
142933529,3874,lindong28,2017-10-05T13:17:04Z,"great. thanks for taking time to think through this. since it is safe to use leader epoch and there is not performance concern with doing it, to simplify the implementation, i am going to update the patch to use only leader epoch or high watermark to truncate the future replica without recording the truncation offset. does this sound ok?",1,0.9930830001831055
143042586,3874,junrao,2017-10-05T20:04:43Z,extra empty line,0,0.9917312264442444
143044343,3874,junrao,2017-10-05T20:12:27Z,"in the common case, partitionandoffsets will have less entries than partitionstates. so, it will be more efficient to iterate partitionstates and do lookups in partitionandoffsets.",0,0.9920158386230469
143052139,3874,junrao,2017-10-05T20:45:12Z,"since this method is only called only by replicaalterdirmanager, perhaps it should be defined there?",0,0.9919369220733643
143060422,3874,junrao,2017-10-05T21:21:00Z,"in this case, the current replica won't have an leader epoch info after truncation. to deal with this better, it seems that it's better for a follower replica or a future replica to fall back to the initialized offset in the partitionstate in abstractfetcherthread, instead of hw, when leader epoch can't be found. we can initialize the offset in partitionstate to the truncation point in this case. in other cases, we can pass in hw to initialize the offset in partitionstate.",0,0.9904003739356995
143061641,3874,junrao,2017-10-05T21:27:09Z,"it maybe possible that the log end offset in the partition is less than leaderendoffset. in that case, we really want to start fetching from the log end offset instead of leaderendoffset. so, it seems it's safer for truncateto() to return the current log end offset after truncation and use that as the starting offset for fetching. ditto in replicaalterlogdirsthread.",0,0.9895442724227905
143065376,3874,junrao,2017-10-05T21:45:46Z,do we need the lock here? it seems that we just need to make sure the current replica is not being updated when maybedeleteandswapfuturereplica() is called.,0,0.9941698312759399
143067860,3874,junrao,2017-10-05T21:59:13Z,getreplicaorexception can throw an exception. we don't want to kill the replicaalterlogdirsthread because of this. it seems that we need to return resultwithpartitions?,0,0.9919447302818298
143068459,3874,junrao,2017-10-05T22:02:31Z,it seems lastpartitionopt is better than maxpartitionopt?,0,0.9860237836837769
143071316,3874,junrao,2017-10-05T22:19:12Z,alterlogdirs => alterreplicalogdirs ?,0,0.9921979308128357
143071753,3874,junrao,2017-10-05T22:21:21Z,"numalterlogdirsreplicationquotasamples => numalterreplicalogdirsquotasamples ? ditto for alterlogdirsreplicationquotawindowsizeseconds. in general, it would be useful to make the naming consistent.",0,0.9932844638824463
143072002,3874,junrao,2017-10-05T22:22:44Z,num.replica.alter.log.dirs.threads => num.alter.replica.log.dirs.threads ?,0,0.9914665222167969
143072168,3874,junrao,2017-10-05T22:23:44Z,alter.log.dirs.replication.quota.window.num => alter.replica.log.dirs.quota.window.num? ditto for alter.log.dirs.replication.quota.window.size.seconds.,0,0.992834210395813
143073815,3874,junrao,2017-10-05T22:33:36Z,shutdownidlereplicaalterlogdirsthread => shutdownidlealterreplicalogdirsthread ?,0,0.9806463718414307
143073900,3874,junrao,2017-10-05T22:33:58Z,replicaalterlogdirsmanager => alterreplicalogdirsmanager?,0,0.9937498569488525
143074047,3874,junrao,2017-10-05T22:34:43Z,"shutdown-idle-replica-alter-log-dirs-thread => shutdown-idle-alter-replica-log-dirs-thread? also, 2500l could probably just be 10000l since the idle threads don't have to be closed that quickly.",0,0.9902059435844421
143079118,3874,junrao,2017-10-05T23:09:46Z,"it seems that we if the source dir is offline, we want to avoid adding the partition to replicaalterlogdirsmanager?",0,0.9931297898292542
143084972,3874,junrao,2017-10-05T23:57:02Z,"since we are calling sourcelog.close() later, could we just call it here instead calling sourcelog.closehandlers()?",0,0.9929715991020203
143091621,3874,lindong28,2017-10-06T01:01:45Z,thanks. it is removed now.,1,0.9387795329093933
143091979,3874,lindong28,2017-10-06T01:05:13Z,"sorry, i missed the exception here. instead of returning resultwithpartitions, how about we keep it consistent with replicafetcherthread.fetchepochsfromleader(), which returns `tp -> new epochendoffset(errors.forexception(t), undefined_epoch_offset)` in the resulting map if the current replica for this topic partition is offline?",-1,0.9734880924224854
143092370,3874,lindong28,2017-10-06T01:09:14Z,it is called maxpartitionopt because this is the toipcpartition with largest topic (in alphabetical order) or the largest partition (if topic string is the same). this topic partition is not selected based on its order in partitionstates. `lastpartitionopt` seems to suggest it is the last partition that is put into the partitionstates. that is why i used `maxpartitionopt`. do you still prefer `lastpartitionopt`?,0,0.9913135170936584
143092809,3874,lindong28,2017-10-06T01:13:48Z,"i intentionally used alterlogdirs to reduce the length of the variable name and related config key name in other places. i think ""replica"" can be removed from the name because its type is `replicationquotamanager`, which already includes the word ""replication"". i will change it to `altereplicalogdirs` if you prefer. what do you think?",0,0.9832109212875366
143092968,3874,lindong28,2017-10-06T01:15:23Z,"i just think that ""numalterreplicalogdirsquotasamples"" is a bit verbose by having both ""replica"" and ""replication"". thus i removed ""replica"" from the name. i will change it to ""numalterreplicalogdirsquotasamples"" if you prefer.",0,0.9751570224761963
143093247,3874,lindong28,2017-10-06T01:18:38Z,"though the request is named ""alterreplicalogdirsrequest"", the thread is `replicaalterlogdirsthread`, which is more consistent with `replicafetcherthread`. because this config is used to determine the thread number, it seems more intuitive to name it `num.replica.alter.log.dirs.threads`. what do you think?",0,0.9853691458702087
143093359,3874,lindong28,2017-10-06T01:19:51Z,"i just think that ""alter.log.dirs.replication.quota.window.num"" is more consistent with the existing config ""replication.quota.window.num"". what do you think?",0,0.9717550873756409
143093452,3874,lindong28,2017-10-06T01:20:49Z,i think it is because the thread class is named `replicaalterlogdirsthread`. i can change it if you still prefer `shutdownidlealterreplicalogdirsthread`.,0,0.9895083904266357
143093676,3874,lindong28,2017-10-06T01:23:06Z,do you prefer to rename the manager class from `replicaalterlogdirsmanager` to `alterreplicalogdirsmanager`? previously i think `replicaalterlogdirsmanager` is more consistent with the existing class `replicafetcherthreadmanager`. same for the `replicaalterlogdirsthread`.,0,0.993405818939209
143174644,3874,lindong28,2017-10-06T12:11:34Z,"the reason this is defined in abstractfetchermanager is that, this method currently uses `fetcherthreadmap`, `maplock` and `getfetcherid`, which are currently private in abstractfetchermanager. i thought it is better to keep them private and only uses these variables in `abstractfetchermanager`. another reason is that we already have methods such as `abstractfetcherthread.fetchepochsfromleader()`, which are defined in `abstractfetcherthread` but only used in `replicafetcherthread`. i am not strong on this. do you prefer to change variables above to protected and move `markpartitionsfortruncation` to `replicaalterdirmanager`?",0,0.9745833277702332
143176721,3874,lindong28,2017-10-06T12:24:02Z,"i am not sure i fully understand your suggestion. i checked the current implementation of replicafetcherthread.handleoffsetoutofrange(). if log end offset in the partition is less than leaderendoffset, the current implementation will start fectching from `math.max(leaderstartoffset, replica.logendoffset.messageoffset)`. so it already does what you suggested, right?",0,0.6473897099494934
143178096,3874,lindong28,2017-10-06T12:32:43Z,"good point. it is not needed. in addition to the reason you mentioned, another reason is that appendrecordstofuturereplica() will be called by the same replicaalterlogdirsthread that calls maybedeleteandswapfuturereplica() for this partition. i will update the patch to remove this lock. thanks!",1,0.99433833360672
143178280,3874,lindong28,2017-10-06T12:33:55Z,"it is named `shutdown-idle-replica-alter-log-dirs-thread` because the thread class is replicaalterlogdirsthread. do you think we should change the name of the thread class and thread manger class? sure, i will update the patch to use 10000l as interval.",0,0.9935412406921387
143178857,3874,lindong28,2017-10-06T12:36:56Z,"yeah i think the current implementation already avoids adding the partition to replicaalterlogdirsmanager if the source dir is offline. if the source dir is offline, the `val replica = getreplicaorexception(topicpartition)` at line 604 will throw kafkastorageexception and this method will not call `replicaalterlogdirsmanager.addfetcherforpartitions` for this partition.",0,0.9847714304924011
143179842,3874,lindong28,2017-10-06T12:42:37Z,"i think we need to call sourcelog.closehandlers() instead of sourcelog.close(). if we call sourcelog.close() and if source log directory is offline, this method will throw kafkastorageexception without closing handler for this sourcelog. later when logmanager.handlelogdirfailure() is called for this source log directory, the handles of this sourcelog will not be closed because sourcelog has already been removed from `currentlogs`. on the other hand, if we sourcelog.closehandlers() and if the source log directory is offline, the handler of sourcelog will be closed before sourcelog.renamedir() throws kafkastorageexception. all handlers in the source log directory will be properly closed in this case. does this make sense?",0,0.9839472770690918
143179997,3874,lindong28,2017-10-06T12:43:33Z,good point. this makes sense. let me think more about how to handle this case properly.,1,0.9846475124359131
143258114,3874,junrao,2017-10-06T17:59:55Z,"the case that i am worried about is the following. suppose the follower replica has logendoffset of 5 and truncateto(10) is called. after that, we will be fetching from offset 10, which could be in the offset range of the leader. this means that we will be missing messages from offset 5 to 10 in the follower. fetching from offset 5 in this case will be safer.",-1,0.6409245729446411
143258987,3874,junrao,2017-10-06T18:03:26Z,"yes, that covers the common case. the case that i was concerned about is when the source replica is taken offline after getreplicaorexception() but before getpartition(topicpartition).get.getorcreatereplica(request.futurelocalreplicaid). in this case, are we creating a future replica on an offline partition?",0,0.992895781993866
143320042,3874,lindong28,2017-10-07T02:11:34Z,"replicamanager.handlelogdirfailure() is the only method that will take a replica offline. this method is synchronized with replicamanager.alterreplicalogdirs() using replicastatechangelock. thus if the handelogdirfailure() is executed after alterreplicalogdirs(), the future replica will be created first, and then both the current replica and the future replica will be taken offline. if the handelogdirfailure() is executed before alterreplicalogdirs(), the future replica will not be created on the offline partition. so the current implementation seems correct, right?",0,0.9877259135246277
143320196,3874,lindong28,2017-10-07T02:18:44Z,"in replicafetcherthread.handleoffsetoutofrange(), we will first check whether `leaderendoffset < replica.logendoffset.messageoffset`. the code block which you mentioned here is only executed if `leaderendoffset < replica.logendoffset.messageoffset`. in the case ""the follower replica has logendoffset of 5 and truncateto(10) is called"", i assume you are saying that `replica.logendoffset.messageoffset` is 5 and `leaderendoffset` is 10, then the code block here won't be executed. instead, the code block in the `else` branch will truncate the follower replica to offset `math.max(leaderstartoffset, replica.logendoffset.messageoffset)`, which will be offset 5 if the leaderstartoffset is smaller than the follower's leo. later replicafetcherthread will actually fetch starting from offset 5, which seems correct. did i miss something here?",0,0.9936980605125427
143355895,3874,lindong28,2017-10-08T14:15:27Z,"sorry for late reply on this issue. now i think about this more, i think the current patch handles this case well. i understand that if truncatefullyandstartat() is called for the current replica, the current patch will truncate the future replica to high watermark which does not have any effect. but truncatefullyandstartat() will also be called for the future replica later. if truncatefullyandstartat() is called for the current replica, then we know that futurereplica's logendoffset < ""currentreplica's logendoffset before truncation"" < ""currentreplica's logstartoffset after truncation"". this means that replicaalterdirthread will see offsetoutofrangeexception for futurereplica and call handleoffsetoutofrange for future replica. later truncatefullyandstartat() will be called for the future replica as well, which makes the result correct. do you think this make sense? if not, can you explain a bit more what will go wrong?",-1,0.9830735921859741
143356250,3874,lindong28,2017-10-08T14:29:43Z,this lock is removed.,0,0.9956249594688416
143356393,3874,lindong28,2017-10-08T14:36:43Z,"i have updated the patch to return `tp -> new epochendoffset(errors.forexception(t), undefined_epoch_offset)` if the replica is offline. hw will be used to truncate the future replica before the future replica is removed from replicaalterdirthread later.",0,0.9943841695785522
143356469,3874,lindong28,2017-10-08T14:40:19Z,thanks. i realized that the signature of this method could be simplified to `markpartitionsfortruncation(topicpartition: topicpartition)`. i have updated the patch to do the following to optimize the performance of this method. [code block],1,0.9646756052970886
143529807,3874,junrao,2017-10-09T17:22:58Z,": yes, it doesn't seem that this can happen here. so we can leave this as it is.",0,0.9890333414077759
143530433,3874,junrao,2017-10-09T17:25:52Z,": good point that we can rely on truncatefullyandstartat() being called on the future replica later since its offset will be out of range too. in that case, it seems that replicamgr.replicaalterlogdirsmanager.markpartitionsfortruncation() is a no op. do we need to call it here? however, the same issue may happen on truncateto(). consider the following case. the current replica needs to call partition.truncateto(leaderendoffset) since its logendoffset is > leaderendoffset, which can happen when an unclean leader election is triggered. we then call replicamgr.replicaalterlogdirsmanager.markpartitionsfortruncation(). if there is no leader epoch info (e.g., message format is still old), the future replica will default to truncating to its hw, which could be > the leaderendoffset of the current replica. by the time the future replica fetches again, more data could have been accumulated in the current replica and the future replica's offset could still be in range. however, some of the data in the future replica now are different from the current replica. in this case, it's better if the future replica defaults to the leaderendoffset of the current replica during truncation.",1,0.8736516237258911
143530570,3874,junrao,2017-10-09T17:26:26Z,"hmm, do we need to truncate based on hw for those partitions that are already marked as offline? it seems that it's simpler to just let handlepartitionswitherrors() deals with them before they are removed from replicaalterdirthread.",0,0.9912232160568237
143545091,3874,lindong28,2017-10-09T18:31:56Z,"yeah you are right, markpartitionsfortruncation() is not needed if currentreplica. truncatefullyandstartat() is called. i will remove the markpartitionsfortruncation() here. regarding the second issue, i agree that the inconsistency between the current and the future replica can happen if the remaining message's format is old. but it seems to me that the same inconsistency can happen between follower and leader as well if the message format is old. thus the inconsistency between the future and the current replica does not increase the problem we already have. and in the long term, all messages will have the new format and this won't be an issue. thus i am not sure the reduced change of inconsistency is worth additional code complexity. but i will update the patch as suggested if you think this is worth doing. what do you think?",0,0.9429045915603638
143546055,3874,lindong28,2017-10-09T18:36:29Z,"strictly speaking, we don't have to truncate the future replica is the current replica is offline. but it is probably more intuitive to return `epochendoffset(errors.forexception(t), undefined_epoch_offset)` here because the purpose of this method is `fetchepochsfromleader()`. the caller of this method, in this case abstractfetcherthread.maybetruncate(), should decide which to handlepartitionswitherror or truncate the replica. does this make sense?",0,0.9893674254417419
143592973,3874,junrao,2017-10-09T22:36:40Z,"ok, this is fine then.",0,0.9554449319839478
143592989,3874,junrao,2017-10-09T22:36:48Z,": i agree that the same issue may happen between the leader and the follower, which we can improve separately in the future. we probably don't want to introduce new issues here between the current and the future replica. i am not sure if my suggestion will add more complexity though. we already store the initial offset in abstractfetcherthread.partitionstates, but ignore it in maybetruncate(). it seems that it's more natural to fall back to this initial offset instead of hw. then, we just need to set the initial offset in markpartitionsfortruncation().",0,0.9477406740188599
143783274,3874,lindong28,2017-10-10T16:33:23Z,"the reason i think they are the same problem (not new issue) is that, the future replica is conceptually very similar to the follower replica. replicaalterlogdirsthread works in a very similar way as the replicafetcherthread. they currently share the same problem regarding the inconsistency. and if we have a solution for the follower replica, the solution should be applicable to the future replica as well. i personally think the future replica is just another follower replica on the same broker as leader. let's say we think the inconsistency in the future replica is a new problem and we want to fix it. i think re-using the offset in `abstractfetcherthread.partitionstates` for truncation will make the code a bit more complicated for the following reasons: - if we allow markpartitionsfortruncation() to change the offset in `partitionstates`, then replicafetcherthread (and replicaalterlogdirsthread) will need to handle this properly in processpartitiondata(). currently only one thread will update the offset in `partitionstates` and `fetchoffset` should always equals `replica.logendoffset.messageoffset` in `processpartitiondata()`. - as of now, the offset in `partitionstates` is always the leo of the follower (and future) replica. thus it is no-op if we truncate the follower replica to this offset in maybetruncate(). re-using this offset to store the truncation offset may make the code harder to maintain. it may be better to store the truncationoffsets in a separate map and use it in maybetruncate(...) as shown in [a link] thanks for all the discussion. given my explanation above, can you let me know which solution you prefer? besides, do you want me to change the name of configs and classes as you raised in the other comments?",0,0.9327069520950317
143793959,3874,junrao,2017-10-10T17:14:38Z,": a couple of things. first, when markpartitionsfortruncation(), the replica is now transitioning to a maybe truncating state (not ready for fetching). if there is a pending fetch response, we should just ignore it. i have a separate pr ([a link] that tries to tighten this up. second, once we have that. the implementation that i was thinking is the following. markpartitionsfortruncation() just marks the partition as maybe truncating and puts the initial offset in partitionstates. from that point on, the replica won't be used for fetching data until it transitions to the ready for fetch state. during the handling of maybetruncate() logic, we will try to decide the truncation point based on leader epoch if possible. otherwise, we will just fall back to the initial offset. so, implementation wise, i am not sure we really need a separate truncationoffsets map. so, my thinking is that such a change seems relatively small and safer than the current approach. as for the naming, i don't want have a strong preference. it's up to you to pick sth consistent.",0,0.9389302730560303
143807179,3874,lindong28,2017-10-10T18:03:08Z,this solution makes sense. i have updated the patch as suggested. it seems that all comments have been addressed. i will rebase the patch onto trunk and review it myself tomorrow. thanks!,1,0.9927842617034912
143874421,3874,junrao,2017-10-10T22:55:11Z,if we tighten the check in abstractfetcherthread like in [a link] we can still throw an exception here since it shouldn't be possible. that seems a more general fix since it covers the replicafetcherthread too.,0,0.9911643862724304
143876603,3874,junrao,2017-10-10T23:08:56Z,we probably want to throw an illegalstateexception if includelogtruncation is false since markpartitionsfortruncation() is not meant to be called in that case.,0,0.9873924851417542
143882150,3874,junrao,2017-10-10T23:52:27Z,partitionstoalterlogdirwithlogendoffset =>futurereplicasandinitialoffset ?,0,0.9940087795257568
143898257,3874,lindong28,2017-10-11T02:20:26Z,"good point. i have updated the patch as suggested, i.e. still throw exception here and check `isreadyforfetch` in `processfetchrequest()`. i can rebase the patch after your patch is committed.",1,0.962773859500885
143899061,3874,lindong28,2017-10-11T02:28:59Z,thanks for catching this. i have updated the patch as suggested.,1,0.9554246068000793
143900496,3874,lindong28,2017-10-11T02:43:07Z,"actually, since that state is not possible, i have updated the patch to replace runtimeexception with illegalstateexception.",0,0.9936860203742981
143900528,3874,lindong28,2017-10-11T02:43:31Z,sure. i have updated the patch to check for this illegal state.,0,0.9861528873443604
144160448,3874,junrao,2017-10-11T23:14:38Z,"how about we change the comment to the following? ""it's possible that a partition is removed and re-added or truncated when there is a pending fetch request. in this case, we only want to process the fetch response if the partition state is ready for fetch and the current offset is the same as the offset requested.""",0,0.9948673248291016
144160911,3874,junrao,2017-10-11T23:17:52Z,"we should throw the exception, right?",0,0.9731035232543945
144162641,3874,junrao,2017-10-11T23:30:32Z,"how about changing the comment slightly to the following? ""the read lock is needed to prevent the follower replica from being updated while replicaalterdirthread is executing maybedeleteandswapfuturereplica() to replace follower replica with the future replica.""",0,0.9949554800987244
144162836,3874,junrao,2017-10-11T23:32:12Z,"how about changing the comment slightly to the following? ""the read lock is needed to prevent the follower replica from being truncated while replicaalterdirthread is executing maybedeleteandswapfuturereplica() to replace follower replica with the future replica.""",0,0.9950461387634277
144162863,3874,junrao,2017-10-11T23:32:26Z,"how about changing the comment slightly to the following? ""the read lock is needed to prevent the follower replica from being truncated while replicaalterdirthread is executing maybedeleteandswapfuturereplica() to replace follower replica with the future replica.""",0,0.9950461387634277
144168236,3874,lindong28,2017-10-12T00:15:17Z,sure. i have updated the comment as suggested.,0,0.9883988499641418
144168256,3874,lindong28,2017-10-12T00:15:22Z,sure. i have updated the comment as suggested.,0,0.9883988499641418
144168262,3874,lindong28,2017-10-12T00:15:26Z,sure. i have updated the comment as suggested.,0,0.9883988499641418
144168272,3874,lindong28,2017-10-12T00:15:29Z,sure. i have updated the comment as suggested.,0,0.9883988499641418
144168299,3874,lindong28,2017-10-12T00:15:46Z,ah... my bad. thanks much for catching this.,-1,0.9953267574310303
144629332,3874,junrao,2017-10-13T18:40:47Z,"earlier, you had assertequals(nummessages, consumerrecords.size), which seems useful. is there a reason to remove this?",0,0.9935120940208435
144632221,3874,junrao,2017-10-13T18:54:22Z,"hmm, do we need the read lock here? replica/log can only be changed by leaderandisrrequest, stopreplicarequest, and alterreplicalogdirs, all of which are already protected under replicastatechangelock.",0,0.9757304191589355
144632346,3874,junrao,2017-10-13T18:54:57Z,"it seems that this case should never happen. so, should we throw illegalstateexception?",0,0.890146017074585
144632596,3874,junrao,2017-10-13T18:56:03Z,should performed => should be performed,0,0.9886717796325684
144665825,3874,junrao,2017-10-13T22:01:56Z,"hmm, it seems that sourcelog.close() can only throw kafkastorageexception because closehandlers() has already been called due to offline log dir. so, not sure why closehandlers() needs to be called again.",0,0.9505828022956848
144666248,3874,junrao,2017-10-13T22:05:13Z,is this comment correct? it seems that logsegment.close() does a superset of logsegment.closehandlers().,0,0.9941998720169067
144680990,3874,lindong28,2017-10-14T00:49:04Z,"thanks for the review. i think we need readlock here is that the log directory of the current replica is not changed by replicaaltherlogdirsthread when the kafkarequesthandler thread is checking whether it needs to create future replica (when it handles alterreplicalogdirsrequest). if we don't use read lock here, the following scenario can happen: 1) broker receives alterreplicalogdirsrequest 2) kafkarequesthandler calls maybecreatefuturereplica(). it finds that the log directory of the current replica is different from the user-specified destination log directory. so it creates future replica and will later try to add this partition replicaalterlogdirsmanager 3) replicaaltherlogdirsthread calls maybereplacecurrentwithfuturereplica(), updated the log directory of the current replica, removed the future replica from allreplicasmap, and removed this partition from replicaalterlogdirsmanager. 4) kafkarequesthandler will now add this partition to replicaalterlogdirsmanager. 5) now we have an inconsistent state where replicaalterlogdirsmanager has this partition but this partition does not have future replica. the replicaalterlogdirsthread will see replicanotavailableexception and fail. does this make sense?",1,0.9576890468597412
144681216,3874,lindong28,2017-10-14T00:54:15Z,"on a double thought, i realized that this could actually happen if the broker receives the same alterreplicalogdirsrequest multiple times, which could happen because reassignpartitionscommand will re-send alterreplicalogdirsrequest. does this make sense?",0,0.9829760789871216
144681244,3874,lindong28,2017-10-14T00:54:59Z,thanks. i will update the patch to fix it.,1,0.9116324186325073
144681370,3874,lindong28,2017-10-14T00:57:22Z,i think it is correct. i verified that close() does not set abstractindex.mmap to null. note that close() can not set mmap to null so that abstractindex.delete() can be executed by the scheduler thread.,0,0.8566269874572754
144681629,3874,lindong28,2017-10-14T01:03:50Z,"i think log.close() also does disk io operation, e.g. when it calls producerstatemanager.takesnapshot() or filerecords.flush(). therefore it could throw kafkastorageexception() if the ioexception occurs. i realized that we need maybehandleioexception() for log.close() to catch e.g. ioexception from producerstatemanager.takesnapshot(). i have updated the patch to do this.",0,0.9864597320556641
144681763,3874,lindong28,2017-10-14T01:06:46Z,"the reason is that testutils.consumetopicrecords() will throw exception if the consumerecords.size() is not exactly the nummessages(). do you prefer me to add back assertequals(nummessages, consumerrecords.size) so that this check is more explicit in the test?",0,0.9938710927963257
144913957,3874,junrao,2017-10-16T17:30:53Z,thanks for the explanation. this is fine then.,1,0.9364264011383057
144913975,3874,junrao,2017-10-16T17:30:58Z,"thanks, sound goods.",1,0.9007610082626343
144913998,3874,junrao,2017-10-16T17:31:04Z,"ok. then ""file handlers"" can be a bit confusing since we do close the channel associated with the log segment. how about changing the comment to the following? ""the memory mapped buffer for index files of this log will be left open until the log is deleted""",0,0.9856573939323425
144914073,3874,junrao,2017-10-16T17:31:23Z,"hmm, this is the case that the future replica exists, but not in the specified log dir. resending the same alterreplicalogdirsrequest won't lead to this case, right?",0,0.9825531244277954
144914169,3874,junrao,2017-10-16T17:31:52Z,"i guess the scenario that you are describing is that there is already an ongoing replica movement across disks at step 2. however, in that case, it seems that we will remove the partition from replicaalterlogdirsmanager and the future replica in line 591 and 592. after that point, replicaalterlogdirsthread can't call maybereplacecurrentwithfuturereplica() any more because the additional partition state check that we added in abstractfetcherthread, right?",0,0.9872646331787109
144995830,3874,lindong28,2017-10-16T23:30:42Z,"not sure i explained my thought clearly. i think here the case is that the future replica already exists in the specified log dir. more specifically, when the broker receives the same alterreplicalogdirsrequest again, it calls replicamanager.alterreplicalogdirs(). alterreplicalogdirs() should only add this partition to replicaalterlogdirsmanager if this future replica has not already been created. so alterreplicalogdirs() calls maybecreatefuturereplica(), and maybecreatefuturereplica() should return true iff the future replica is newly created. because it is possible that future replica already exists, we should not throw illegalstateexception. does this sound ok?",0,0.847534716129303
144995860,3874,lindong28,2017-10-16T23:30:59Z,sure. i have updated the comment and related method names as suggested.,0,0.9886817932128906
144996257,3874,lindong28,2017-10-16T23:34:00Z,"the scenario is that there is already an ongoing replica movement for this same partition to the same destination log directory, which can happen if broker receives the same alterreplicalogdirsrequest again. because the requested destination log directory of the alterreplicalogdirsrequest is same as the destination log directory of the ongoing movement, we will not remove the partition from replicaalterlogdirsmanager. does this make sense?",0,0.9928199648857117
144999197,3874,lindong28,2017-10-16T23:56:36Z,"actually, in the scenario that there is already an ongoing replica movement to a different destination log directory, the following may happen: - replicaaltherlogdirsthread calls maybereplacecurrentwithfuturereplica(), updated the log directory of the current replica and removed the future replica from allreplicasmap() - kafkarequesthandler calls alterreplicalogdirs(). because future replica has been removed, it will not remove this partition from replicaalterlogdirsmanager. then it will create the future replica for this partition and add fetcher for this partition. - then replicaaltherlogdirsthread will remove fetcher for this partition. this leads to an inconsistent state where we have future replica for this partition but this partition is not in replicaalterlogdirsmanager. the main issue is that, we do not have a lock that makes it an atomic operation to 1) add/remove partition from replicaalterlogdirsmanager and 2) add/remove future replica for the partition. protect maybecreatefuturereplica() with `leaderisrupdatelock` could reduce the chance of this race condition.",0,0.9931923747062683
145007121,3874,junrao,2017-10-17T01:06:10Z,": thanks for the info. makes sense. perhaps we should throw an illegalstateexception if future replica exists, but is on a log dir different from the input?",1,0.9763510227203369
145007148,3874,junrao,2017-10-17T01:06:34Z,": in the scenario that there is already an ongoing replica movement to a different destination log directory, i am not sure what you described can happen. maybereplacecurrentwithfuturereplica() is called inside processpartitiondata() and is protected by the abstractfetcherthread.partitionmaplock. so, while this is ongoing, no new partitions can be added to the fetcher. the other scenario that there is already an ongoing replica movement for this same partition to the same destination log directory does make sense. so, we can keep the readlock there.",0,0.98310387134552
145007951,3874,lindong28,2017-10-17T01:14:41Z,sure. i have updated the code to throw illegalstateexception if the current log dir of the future replica is different from the requested log dir. thanks!,1,0.9615136981010437
145008087,3874,lindong28,2017-10-17T01:16:16Z,thanks much for the discussion!,1,0.8470761775970459
1400867677,3874,Hongten,2023-11-21T16:32:47Z,"i have a question about the previous var. if the log dir name doesn't end with ""-future"", the `currentlogs` will put the topic partition as key and log as value, and return log. the simple logic like the below: [code block] if the `previous` is not null, then there is an `illegalstateexception` to be thrown. right?",0,0.9889948964118958
59305175,1215,becketqin,2016-04-12T00:37:28Z,"i have a question regarding the code here. on line 199 of this patch (line 192 of the original code), we check if the index file exists or not. however, right before this, we have already created the log segment which will create the index file if it does not exist. so it seems the test here will never be false?",0,0.9778504967689514
59380790,1215,ijuma,2016-04-12T14:02:16Z,was it intentional to remove the volatile annotation from this var?,0,0.9926403164863586
59381324,1215,ijuma,2016-04-12T14:05:03Z,"also, do we actually need to mutate the vars above in the subclasses? if not, they should remain `private[this]` as they were before. we have accessor methods (without the underscore).",0,0.9939491748809814
59381969,1215,ijuma,2016-04-12T14:08:30Z,"a tuple of 3 elements is not great for readability, i think it's time to introduce a case class for the method result.",0,0.8980043530464172
59382177,1215,ijuma,2016-04-12T14:09:43Z,unintentional indent.,-1,0.7368113398551941
59425499,1215,becketqin,2016-04-12T18:13:02Z,i was actually wondering why we need these variables? they are just a derived value based on `mmap.limit` and `mmap.position`. shouldn't we just define them as methods?,0,0.9766407608985901
59429145,1215,ijuma,2016-04-12T18:33:05Z,"it's a good question. i assumed they were there for performance reasons, but i haven't checked.",1,0.9838449358940125
59433036,1215,becketqin,2016-04-12T18:54:25Z,thought about this again. having the variables makes sense because we do not lock the mmap on read. that means the read can happen when the writing of an index entry is half-done. i'll keep the variables.,0,0.9761532545089722
60862080,1215,junrao,2016-04-25T04:38:00Z,typo abastract,0,0.987409770488739
60862083,1215,junrao,2016-04-25T04:38:04Z,key/value combination => key or value,0,0.9932230710983276
60862084,1215,junrao,2016-04-25T04:38:10Z,should we assert that exactly one of targetkey and targetkey is not empty?,0,0.9925038814544678
60862100,1215,junrao,2016-04-25T04:38:40Z,"when searching for offset, the passed in value is the absolute offset whereas the offsets in the index are relative. so, we use to translate the absolute offset to the relative one in indexslotfor(). that logic seems to be lost in the new code.",0,0.9848358035087585
60862105,1215,junrao,2016-04-25T04:38:48Z,the description starting from line 155 seems redundant. the description in line 150 and 151 explains this method pretty well.,0,0.9661003947257996
60862107,1215,junrao,2016-04-25T04:38:53Z,it seems it's more natural to return none in this case.,0,0.9765558838844299
60862130,1215,junrao,2016-04-25T04:39:07Z,passing in handleandmaybestop seems a bit more complicated than necessary. i am wondering if we can just reuse the iterator() code to be able to iterate messageandoffset from an arbitrary position. the caller can decide what to do.,0,0.8761242032051086
60862136,1215,junrao,2016-04-25T04:39:22Z,typo: mappying and timestamp,0,0.994392454624176
60862140,1215,junrao,2016-04-25T04:39:26Z,unused imports.,0,0.9867687821388245
60862143,1215,junrao,2016-04-25T04:39:33Z,the comment on line 172 is now outdated. perhaps we can just say all index files.,0,0.9924094676971436
60862149,1215,junrao,2016-04-25T04:39:45Z,that's a good point. it seems that we should check the existence of the index file before creating logsegment.,1,0.9496458172798157
60862151,1215,junrao,2016-04-25T04:39:56Z,"the warning log in line 205 always refers to indexfile, which is not necessarily correct now.",0,0.983740508556366
60862158,1215,junrao,2016-04-25T04:40:12Z,"hmm, it seems that we should insert the offset in segment i that has the largest timestamp. not sure why we want to insert the offset in the next segment.",0,0.9589707255363464
60862171,1215,junrao,2016-04-25T04:40:34Z,"hmm, does the seg.largesttimestamp always correspond to logendoffset?",0,0.9862224459648132
60862192,1215,junrao,2016-04-25T04:41:35Z,"the current getoffsetbefore() api is a bit awkward to use since it's tightly coupled with how we use the last modified time in each log segment. for example, it doesn't seem to make sense to return a sequence of offsets now that we have message level timestamp. so, it's probably simpler and better to leave the current implementation of getoffsetbefore() as it is. in log, logsegment, and timeindex, we expose a simple api that takes a timestamp and returns a single offset whose timestamp is >= than the input. in the future, we can design a new request that exposes this capability to the client.",0,0.8431041240692139
60862196,1215,junrao,2016-04-25T04:41:44Z,"hmm, i think we want to show both the actual size and the max size, not the ratio.",0,0.9583562016487122
60862197,1215,junrao,2016-04-25T04:41:50Z,could we just call entry.getvalue once?,0,0.9945547580718994
60862201,1215,junrao,2016-04-25T04:41:58Z,"hmm, is this right? the offset associated with the largest timestamp may not be the last offset in the time index.",0,0.9783115983009338
60862203,1215,junrao,2016-04-25T04:42:02Z,is lastoffset ever used?,0,0.9940882921218872
60862208,1215,junrao,2016-04-25T04:42:09Z,should we compute maxtimestampsofar before appending to the timeindex?,0,0.9942761063575745
60862210,1215,junrao,2016-04-25T04:42:13Z,typo retrun,0,0.9918357729911804
60862213,1215,junrao,2016-04-25T04:42:21Z,not sure why we need max here since we should always be able to find a timestamp >= lasttimeindexentry.timestamp.,0,0.9050350785255432
60862216,1215,junrao,2016-04-25T04:42:32Z,"not sure why we need ""the timestamp is the max timestamp before that offset.""",0,0.8969536423683167
60862218,1215,junrao,2016-04-25T04:42:34Z,typo timestmaps,0,0.9895023107528687
60862221,1215,junrao,2016-04-25T04:42:38Z,larger than => larger than or equal to,0,0.9780349731445312
60862225,1215,junrao,2016-04-25T04:42:45Z,store => stored,0,0.9900498390197754
60862228,1215,junrao,2016-04-25T04:42:46Z,typo monitonically,0,0.9861407279968262
60862233,1215,junrao,2016-04-25T04:43:05Z,is it worth maintaining _lasttimestamp and _lastoffset since they can be obtained from lastentry?,0,0.9937314391136169
60862237,1215,junrao,2016-04-25T04:43:17Z,"if there is no return value, the convention is not to use =. so, it will be def maybeappend() { }",0,0.9946223497390747
60862243,1215,junrao,2016-04-25T04:43:25Z,"do you mean ""timestamp can't be"" instead ""timestamp can be""?",0,0.9919018149375916
60862249,1215,junrao,2016-04-25T04:43:33Z,"timestampoffset(timestamp, offset) != lastentry seems a more expensive check. could we just check timestamp and _lasttimestamp?",0,0.9880188703536987
60862253,1215,junrao,2016-04-25T04:43:41Z,this check seems useless since _entries is calculated from mmap.position.,0,0.7666188478469849
60862264,1215,junrao,2016-04-25T04:44:04Z,"hmm, not sure why this logic here is different from that in offsetindex.truncateto. if we find an index entry that matches offset exactly, it seem that we should delete that slot from the time index too.",0,0.901869535446167
60862266,1215,junrao,2016-04-25T04:44:11Z,"the error message is only for timestamp, but the failure could be due to offset.",0,0.9873201847076416
60862269,1215,junrao,2016-04-25T04:44:15Z,should 35% be 33%?,0,0.9871848225593567
60862271,1215,junrao,2016-04-25T04:44:16Z,the each => each,0,0.9925845265388489
60923190,1215,junrao,2016-04-25T14:36:11Z,"we should insert the offset corresponding to maxtimestampsofar, right?",0,0.9929907321929932
60952050,1215,becketqin,2016-04-25T17:22:10Z,this logic has been moved to `parseindexentry()` in offsetindex and timeindex. this is to make `indexslotfor()` entry format agnostic.,0,0.9952996969223022
60956589,1215,becketqin,2016-04-25T17:50:02Z,good point. i think we can use the iterator for timestamp search. we probably still need to keep a separate scan function for offset search because the iterator does not give the position. but this will be only used by offset search so there is no function argument passed in.,1,0.9347484111785889
60967454,1215,becketqin,2016-04-25T18:52:36Z,"if we check the existence of the index files before creating log segment, would it be a little difficult to distinguish between 1) the upgrade case and 2) time index file is really missing? in (1), we want to just create an empty time index without rebuilding the time index. in (2), we want to rebuild the entire time index. i am wondering in which case will we miss a index? is it only when the index is deleted manually?",0,0.971583366394043
60968317,1215,becketqin,2016-04-25T18:57:47Z,"hmm, if we return none, what timestamp and offset response should we return to the user? we cannot simply use the log end offset or hw because it is possible the log end offset or hw has grown after the search. so it seems we should tell the caller that up until which offset we have searched?",0,0.992741048336029
60974231,1215,becketqin,2016-04-25T19:35:42Z,"the way we index the timestamp changed a little since the original proposal. the original proposal was that a timestamp entry `(t, offset)` means the message with timestamp `t` is at `offset`. now it means that before `offset`, the largest timestmap we have seen is `t`. so the offset does not point to the message with the largest timestamp any more. the benefit of the current way is that it is a little easier to build and maintain. so in this case, we are treating the entire log segment as a big message set and assuming the last modification time is the largest timestamp in this segment. so that means before the base offset of the next segment, the largest timestamp we see in this segment is the last modification time of the segment. that is why the last time index entry in each inactive segment always points to the base offset of the next segment.",0,0.9554238319396973
60974567,1215,becketqin,2016-04-25T19:37:52Z,there is no real logic change here. i just changed the printing code format to a shorter pattern.,0,0.987959623336792
60981807,1215,becketqin,2016-04-25T20:23:08Z,please see the previous reply. the offsets is no longer the offset of the message with maxtimestampsofar now.,0,0.995236337184906
60982883,1215,becketqin,2016-04-25T20:29:09Z,"if the starting position is the position from the last time index entry, it is not guaranteed that we can find a timestamp >= lasttimeindexentry.timestamp.",0,0.9891307353973389
60995200,1215,becketqin,2016-04-25T21:45:14Z,"i was trying to say that when the log segment tries to append a time index entry, it is not guaranteed the timestamp of that entry is strictly larger than the timestamp of previous entries. but the offset has to be strictly larger. we probably should also check the timestamp as well.",0,0.9903393387794495
60996355,1215,becketqin,2016-04-25T21:53:24Z,"this check is to avoid throwing exception in cases when we insert the last entry to the time index when the log segment is closed or rolled. in those cases, we may see attempt to insert a duplicate a time index entry whose offset is the same as the previous one. we can probably split it into two if statement.",0,0.9944796562194824
60996692,1215,becketqin,2016-04-25T21:55:58Z,actually the last check won't even be evaluated unless the previous two statement are true. not sure if performance is a concern here.,0,0.8017600774765015
60996885,1215,becketqin,2016-04-25T21:57:13Z,"_entries is a variable loaded from mmap.position when then index is created, but after that it is maintained separately. the original offset index has the check so i just left it unchanged.",0,0.9936896562576294
61005130,1215,becketqin,2016-04-25T23:04:06Z,"this is also related the to semantic meaning of the time index. because the offset in the index entry is the ""next"" offset. so if the truncated to index is the same offset in the index entry, we should keep the entry because the max timestamp corresponding to that time index entry are not truncated.",0,0.9933406710624695
61006403,1215,becketqin,2016-04-25T23:16:09Z,"if we compute the maxtimestampsofar before appending to the timeindex, we will require the lastoffset of the messages. if we do it in this way we only need the firstoffset.",0,0.9935417175292969
61188911,1215,Ishiihara,2016-04-27T00:49:44Z,the parentheses may not be needed here as this function does not have side effect. correct me if i am wrong.,0,0.9834191799163818
61188922,1215,Ishiihara,2016-04-27T00:49:50Z,maybe add another log after the file is successfully deleted.,0,0.9911085367202759
61188929,1215,Ishiihara,2016-04-27T00:49:56Z,are we always rounding up or rounding down? it would be nice to reflect that in the function name.,0,0.989109992980957
61188934,1215,Ishiihara,2016-04-27T00:50:01Z,assume all entries are valid and set the position to the last entry,0,0.9938411712646484
61188942,1215,Ishiihara,2016-04-27T00:50:05Z,how about using a different error message? e.g. entry size exceeds max index size.,0,0.9914781451225281
61189019,1215,Ishiihara,2016-04-27T00:51:03Z,may be remove forcefully?,0,0.9884395599365234
61189107,1215,Ishiihara,2016-04-27T00:52:21Z,how bout log in the error level?,0,0.9930182695388794
61326011,1215,Ishiihara,2016-04-27T20:03:02Z,the comments of the return value are inconsistent. largest_timestamp_checked_before_target_timestamp and largest_timestamp_checked.,0,0.9644866585731506
61326015,1215,Ishiihara,2016-04-27T20:03:04Z,this equivalent as -> this is equivalent to,0,0.9911980032920837
61674500,1215,becketqin,2016-04-30T20:20:34Z,"it seems this message is warning about a wrong maxindexsize argument, but not because there are too many entries. so the error message seems right. but we can probably add the current index size in the log.",0,0.9858977794647217
61674869,1215,becketqin,2016-04-30T20:48:16Z,"this is a pre-existing comments. i am not sure if it is really a ""forceful"" free. so i just leave it as is.",0,0.9666199088096619
61674895,1215,becketqin,2016-04-30T20:50:28Z,"not sure if it is needed. if something wrong happened, an exception should be thrown and we will see that in the log. otherwise it is removed successfully. so no exception = success?",0,0.9746882915496826
61676699,1215,Ishiihara,2016-04-30T23:10:43Z,it seems a bit nicer if we use string interpolation.,0,0.9781939387321472
61676701,1215,Ishiihara,2016-04-30T23:10:47Z,"again not a big deal, but we can use pattern matching to be more scala-like. [code block]",0,0.900790810585022
61676704,1215,Ishiihara,2016-04-30T23:10:54Z,nit: comment is not aligned with code below.,0,0.9234141111373901
61676705,1215,Ishiihara,2016-04-30T23:10:57Z,"not a bit deal, but we need to import `ioexception` to make the ide happy.",0,0.9008042216300964
61684116,1215,ijuma,2016-05-01T09:09:56Z,it is true that pattern matching is a more scala-like. the suggested code is missing a case entry if the first case doesn't match though.,0,0.9901331663131714
64971303,1215,junrao,2016-05-27T21:53:50Z,unused import ioexception,0,0.9845014214515686
64971332,1215,junrao,2016-05-27T21:54:10Z,"this interface is a bit awkward. since we expect either key or value to be set, another option is to have sth like the following. protected def indexslotfor(idx: bytebuffer, target: k, boolean istargetforkey):",-1,0.9804845452308655
64971340,1215,junrao,2016-05-27T21:54:17Z,the comment on return value is duplicated as the one in line 170.,0,0.9930550456047058
64971410,1215,junrao,2016-05-27T21:54:58Z,could we just return the base offset in this case?,0,0.9927793145179749
64971431,1215,junrao,2016-05-27T21:55:10Z,typo timestmap,0,0.9884244203567505
64971444,1215,junrao,2016-05-27T21:55:19Z,perhaps it's better to do the try/catch for each index file so that we know which one is corrupted?,0,0.9860867261886597
64971523,1215,junrao,2016-05-27T21:56:00Z,"hmm, for those segments w/o time index because they were created in 0.9, we will update the index with the last modified time. however, it seems that we didn't change maxtimestampsofar in the log segment after that since logsegmentsseq(i).loadlargesttimestamp() is called before updating the index?",0,0.98655766248703
64971535,1215,junrao,2016-05-27T21:56:11Z,"hmm, it seems that if assignoffsets is false, we won't set maxtimestampinmessageset properly? perhaps we should initialize maxtimestampinmessageset in analyzeandvalidatemessageset()?",0,0.9841448068618774
64971545,1215,junrao,2016-05-27T21:56:15Z,returnoffsets is unused,0,0.9944412112236023
64971577,1215,junrao,2016-05-27T21:56:30Z,does the timestamp in the last message necessarily have the largest timestamp?,0,0.9886264204978943
64971583,1215,junrao,2016-05-27T21:56:33Z,no need for unit.,0,0.9911168813705444
64971598,1215,junrao,2016-05-27T21:56:37Z,no need to have unit =. there are a few other places like that.,0,0.6098701357841492
64971603,1215,junrao,2016-05-27T21:56:39Z,typo retrun,0,0.9918357729911804
64971625,1215,junrao,2016-05-27T21:56:50Z,"hmm, in this case, should we return lastoffset + 1 in the segment and perhaps with a max timestamp?",0,0.987221896648407
64971644,1215,junrao,2016-05-27T21:56:58Z,"intuitively, if there is no message, should largesttimestamp be maxlong?",0,0.9817661046981812
64971662,1215,junrao,2016-05-27T21:57:06Z,perhaps we should move this comment to before line 125?,0,0.9889706373214722
64971685,1215,junrao,2016-05-27T21:57:18Z,"since there is no close() method in timeindex, we probably want to clarify that the logic of adding the last timestamp index entry is in logsegment.onbecomingactivesegment().",0,0.993444561958313
64971723,1215,junrao,2016-05-27T21:57:40Z,typo validatd,0,0.9929929971694946
64971763,1215,junrao,2016-05-27T21:58:00Z,it seems that maxtimestamp won't be set properly if messagetimestamptype is log_append_time?,0,0.9914022088050842
64971776,1215,junrao,2016-05-27T21:58:05Z,could we update the comment with respect to the return type?,0,0.9944964051246643
64971791,1215,junrao,2016-05-27T21:58:11Z,it would be useful to add a comment explaining the return type before the method.,0,0.9926704168319702
64971800,1215,junrao,2016-05-27T21:58:16Z,log timestamp => offset,0,0.9915558099746704
64971805,1215,junrao,2016-05-27T21:58:19Z,"hmm, not sure what this is for.",0,0.5835968255996704
64972732,1215,Ishiihara,2016-05-27T22:10:04Z,the ioexception is used in scaladoc.,0,0.9943894743919373
64998112,1215,becketqin,2016-05-29T06:05:53Z,"hmm, but the key and value type might be different, so only defining the target to be the type of key seems not enough. maybe it is less awkward if have sth like: `protected def indexslotfor(idx: bytebuffer, target: indexentry[k, v], searchbyentity: indexsearchentity):` the indexsearchentity is an enumeration that is either searchbykey or searchbyvalue.",0,0.8749011158943176
64998229,1215,becketqin,2016-05-29T06:20:56Z,"actually never mind. since we only search by key, so having key is probably good enough.",0,0.8532314300537109
64998294,1215,becketqin,2016-05-29T06:29:16Z,we do search by value when truncating the time index... so maybe we still need to pass in the index entry.,0,0.9890205264091492
64998628,1215,becketqin,2016-05-29T07:16:57Z,"if there is no message after the starting point, it means we have reached the log end. ideally we should return the offset that we started to search with, but we only have position in this method. so we return none here to let the caller know that we have reached the log end and the caller will return the offset corresponding to the physical starting position.",0,0.9938276410102844
64999284,1215,becketqin,2016-05-29T08:12:38Z,i added that according to the scala coding style guide. maybe we can do a refactoring separately if we want to. [a link],0,0.9938904047012329
64999465,1215,ijuma,2016-05-29T08:27:13Z,"yeah, kafka currently deviates from that convention. i prefer the scala coding style guide way, but there isn't a strong reason either way (one way is a little more consistent, but is more verbose). so, it probably makes sense to stick with kafka's way for now as it would create a lot of diffs to change.",0,0.9649659395217896
65019054,1215,becketqin,2016-05-30T02:53:53Z,"if `log.searchfortimestamp()` returns none, that means there is no message at or after the position we started to search with. it could happen when: 1. the log segment is empty 2. the log segment is truncated after we got the position from the offset index. for case (1) maybe we should just return (notimestamp, baseoffset). for case (2) maybe we should propagate the none to the caller so the caller can retry the search. this does not completely solve the problem that we may return an offset to the user that is later truncated, but would avoid it as much as possible. does that sound reasonable?",0,0.9853750467300415
65019819,1215,becketqin,2016-05-30T03:10:57Z,"previously we don't have a concept of largest timestamp for a log segment. implicitly the largest timestamp is the last modification time. so all the logic around timestamp is built based on last modification time. with kip-33 supposedly most of the previous logic that are depending on `lastmodified()` should now be using largest timestamp. maxtimestampsofar is only updated when it sees actual timestamp in a message (except for old inactive log segments where maxtimestampsofar is always the same as last modification time and does not change). i am thinking to leave `lastmodified()` as it is but replace the external usage of `lastmodified()` with `largesttimestamp()`. `largesttimestamp()` prefers to use the maxtimestampsofar if it exists, but falls back to lastmodified if no message has a timestamp, such that the external logic would be the same for all segments no matter whether they contains timestamp or not. i may have missed some usages of `lastmodified()` in the current patch. i will fix that in the coming patch.",0,0.9867896437644958
65023366,1215,becketqin,2016-05-30T04:55:32Z,"this is printing out the mismatches. the first timestamp is the timestamp in the index, and the second timestamp is the mismatch timestamp in the log. so the printed string seems correct?",0,0.9931796789169312
65023563,1215,becketqin,2016-05-30T05:01:36Z,"i was trying to list the offsets of the mismatch timestamp index entry. but the format seems wrong, i am thinking of something like the following: when timestamp does not match. `timestamp: 1000 (log timestamp: 2000) offset: 100` when timestamp and offset both do not match `timestamp: 1000 (log timestamp: 2000) offset: 100 (log offset: 200)`",0,0.9288225769996643
65999852,1215,junrao,2016-06-07T02:00:58Z,would it be better to name this searchtype?,0,0.9914167523384094
65999868,1215,junrao,2016-06-07T02:01:09Z,"hmm, this may not be reliable. could we just compare this to (long) int.max?",0,0.9176768660545349
65999871,1215,junrao,2016-06-07T02:01:13Z,unused import,0,0.9873000979423523
65999886,1215,junrao,2016-06-07T02:01:27Z,"to be consistent with the code, maxtimestamp should be before timestamp. also, timestamp is too generic and it's not clear what it really means. how about rename it to logappendtime?",0,0.9912428855895996
65999931,1215,junrao,2016-06-07T02:02:11Z,"hmm, this means that when upgrading, we are forced to scan all existing log segments since they won't have the timeindex. could we just create an empty timeindex file in this case? see my other comment in logsegment on whether it's useful to always have a non-empty timeindex.",0,0.9803960919380188
65999965,1215,junrao,2016-06-07T02:02:42Z,"hmm, we should be checking timeindex.entries instead of maxentries, right?",0,0.9697429537773132
65999990,1215,junrao,2016-06-07T02:03:12Z,"hmm, is the while loop necessary? it seems that if foundoffset is none, we can just return baseoffset of next segment or nextoffset if the search is on the active segment. also, if we have an empty log, do we loop forever?",0,0.9873353838920593
66000164,1215,junrao,2016-06-07T02:05:21Z,"in the proposal of kip-33, we changed the behavior of log rolling to be that if the largesttimestamp in the segment hasn't changed for the log rolling time, we will roll another log segment. thinking about this a bit more, i am wondering if it's better to preserve the current log rolling logic based on the log segment create time. the current behavior provides a nice property that a log segment is guaranteed to be rolled within certain amount of time. this is useful since there are use cases where people may have some sensitive data that has to be deleted or cleaned after certain amount of time. the new behavior will make this harder to enforce since the active segment is never deleted or cleaned and there is no time bound on when the new segment can be rolled. the log deletion policy can still be based on the timestamp in the message.",0,0.9040887951850891
66000207,1215,junrao,2016-06-07T02:06:06Z,extra space before *,0,0.9921203851699829
66000218,1215,junrao,2016-06-07T02:06:19Z,extra space before *,0,0.9921203851699829
66000237,1215,junrao,2016-06-07T02:06:33Z,should we append nextoffset or baseoffset here?,0,0.9935494065284729
66000245,1215,junrao,2016-06-07T02:06:39Z,extra space before *,0,0.9921203851699829
66000271,1215,junrao,2016-06-07T02:06:58Z,"hmm, if none of the message has timestamp, should we include the offset of the first message in the segment?",0,0.9842510223388672
66000275,1215,junrao,2016-06-07T02:07:04Z,we should document when we return none.,0,0.9916558265686035
66000282,1215,junrao,2016-06-07T02:07:08Z,foundtimestampoffsetopt is unused.,0,0.9938983917236328
66000320,1215,junrao,2016-06-07T02:07:44Z,"currently, we have the logic to force adding an index entry (with last modified timestamp) if none of the message has timestamp. i am wondering why this is necessary. it seems that we can just leave the timeindex empty in that case and largesttimestamp() can still return lastmodified? that may make the log recovery logic a bit simpler.",0,0.9670001268386841
66000326,1215,junrao,2016-06-07T02:07:49Z,unused import,0,0.9873000979423523
66000354,1215,junrao,2016-06-07T02:08:10Z,"the comment here says insert a time index entry with the last modified time and the base offset. however, in logsegment.onbecomeinactivesegment(), we insert the next offset, not the base offset. it seems that inserting the base offset makes sense.",0,0.9921297430992126
66000366,1215,junrao,2016-06-07T02:08:23Z,is the comment accurate? maybeappend() may see the same timestamp as long as no new messages have a larger timestamp.,0,0.9937134385108948
66000386,1215,junrao,2016-06-07T02:08:43Z,"the comment is not accurate. we don't return a number of entries. also, we are trying to find an entry with timestamp >= than targettimestamp",0,0.9630693793296814
66000434,1215,junrao,2016-06-07T02:09:22Z,"we will need to explain the output better. perhaps when we print ""mismatches in :"" , we can say these are cases where the timestamp in the wrapper message doesn't match the inner. also, it would also be useful to capture errors in which the timestamps are not increasing in the index.",0,0.9907445311546326
66187001,1215,becketqin,2016-06-08T03:13:26Z,"the assumption here is that `this.start + position` is a positive integer, and `size` is also a positive integer. when you say not reliable, do you mean `this.start + position` can also overflow?",0,0.9926081895828247
66188197,1215,becketqin,2016-06-08T03:34:23Z,"the current code actually creates the time index file in line 195 when it instantiate the logsegment. so the else branch seems never be called. i asked that question earlier and you suggested that we can check the index existence before we instantiate the logsegment. but the problem of that is we are not able to distinguish between 1) upgrade case and 2) the time index is missing. we want to create an empty index in case 1) and want to rebuild the time index in case 2). i thought case 2) only occurs when the time index is manually deleted, which is rare. therefore i left the code as it is, i.e. always create an empty time index when it is missing. this is essentially assuming that when a time index is missing it is the upgrade case.",0,0.9650418758392334
66188736,1215,becketqin,2016-06-08T03:46:00Z,"this is to make sure the time index file is not resized to zero so it can hold at least one time index entry. but putting the check here is a little confusing, i will move it into ensurenonemptytimeindex().",0,0.9723719358444214
66296450,1215,becketqin,2016-06-08T17:06:48Z,"i am not sure if we have the same guarantee even if we still let the log rolling based on the log segment create time. there are a few issues, 1. when the timestamp type is createtime, the messages in the segment may have older timestamp than the create time of the log segment. so the log rolling may still be delayed from the application perspective. 2. in some linux system, the create time of a file is not available. so based on segment file create time may not always work. i am thinking that maybe we can just let the log rolling based on the timestamp of the first time index entry. we can always insert an index entry when the first message is appended to the log segment. this provides similar guarantee of the previous log rolling and does not have the above two issues. what do you think?",0,0.9122200012207031
66299695,1215,becketqin,2016-06-08T17:25:05Z,"the main idea behind this while loop is to make sure we give user a good offset to our best effort. `targetseg.findoffsetbytimestamp()` only returns none when log truncation occurred after we find the physical position by looking up the offset index. in that case, the may be no message after the physical position because it could have been truncated. we cannot return the nextoffset in that case because it is possible that some new messages have been appended after `targetseg.findoffsetbytimestamp()` returns. we haven't checked the timestamp of those messages, so returning nextoffset in this case might result in skipping messages with larger timestamp. that said, this case should be very rare because truncation usually only occurs on the followers, so they should not server offset request. however, if we have a fast leadership fail over and failback, it could still happen. when the log segment is empty, baseoffset is returned by `targetseg.findoffsetbytimestamp()`.",0,0.9892918467521667
66301258,1215,becketqin,2016-06-08T17:32:07Z,"i was thinking the semantic meaning of this is that the timestamp of the last message in the segment is lastmodified. but you are right that during a search by timestamp, we would want to start from the base offset.",0,0.9887362122535706
66302572,1215,becketqin,2016-06-08T17:39:05Z,i think we do return the offset of the first message if none of the messages has timestmap.,0,0.9865924715995789
66318868,1215,junrao,2016-06-08T19:04:05Z,"right, could this.start + position overflow to a negative value and then + size bring it to positive again?",0,0.9916804432868958
66319046,1215,junrao,2016-06-08T19:05:03Z,"interesting. then, in the code, perhaps we should just get rid of the check of the existence of the offset and the time index files since they are guaranteed to be present after logsegment is created? i agree the case that people manually delete the index files is rare.",0,0.7897220849990845
66319077,1215,junrao,2016-06-08T19:05:14Z,"ok, perhaps we can add this in the javadoc.",0,0.9920089244842529
66319260,1215,junrao,2016-06-08T19:06:23Z,"ok, perhaps we can add some comments to make it clear why we need to do the loop. a related question is what happens when there is no offset whose timestamp is >= than the target timestamp? should we return the log end offset or sth like -1? if it's the former, the user may not know the fact that there is no offset with a larger or equal timestamp.",0,0.9924445748329163
66319334,1215,junrao,2016-06-08T19:06:48Z,"yes, what you suggested sounds like a good idea. i would just modify that slightly to do the time-based rolling based on the timestamp of the first message in the segment. we probably want to update the kip wiki and bring this up in the mailing list to see if people have any concern about the change.",0,0.5027106404304504
66376458,1215,becketqin,2016-06-09T03:05:27Z,"theoretically it is possible. but if it is a log segment it seems not possible because the `this.start` would be 0, so it is essentially `position + size`. i don't know if we ever call `read()` on a sliced filemessageset.",0,0.9824029207229614
66377571,1215,becketqin,2016-06-09T03:22:58Z,"thought about this a little more, it seems that it would be better to append the nextoffset - 1. the offset is essentially used in two cases: 1) search by timestamp 2) log truncation. for case 1, the previous behavior was that if the target timestamp is greater than the lastmodified, we will simply start from the next segment. this behavior will be changed if we append the baseoffset here. i.e. user needs to start consume from the beginning of this segment instead of the beginning of next segment. for case 2, if an inactive log is truncated and becomes the active log segment again, we will want to truncate the time index entry as well, if we append the nextoffset -1 here, the time index will also be truncated. but if we append baseoffset here, the time index entry won't be truncated.",0,0.9770128726959229
66479759,1215,becketqin,2016-06-09T16:58:29Z,"the patch currently returns log end offset if there is no offset whose timestamp is greater than the target timestamp. i am wondering in which case user would want to know there is no timestamp greater or equals to the target timestamp? currently, user can always start consuming from the returned offset and it is guaranteed that no message with larger timestamp will be missed. if we return -1, what user would do in that case? they can not seek to the end because after we return -1, some messages with larger timestamp could have been appended so consuming from log end offset will miss those messages.",0,0.9864707589149475
66480437,1215,becketqin,2016-06-09T17:02:43Z,"yes based on the timestamp of the first message sounds good. more precisely the time based log rolling will be based on the first message that has a timestamp if there is at least one such message. if there is no message that has a timestamp, the time based log rolling will be based on the create time, which is the same as previous behavior.",0,0.7621915936470032
66536970,1215,junrao,2016-06-09T23:00:02Z,"yes, that sounds reasonable.",0,0.9799597263336182
66540277,1215,junrao,2016-06-09T23:33:48Z,"i looked at the commit history on this class a bit more. it seems that the existing logic is because of a bug introduced in kafka-2012. we should check the existence of the offset index file before instantiating a logsegment, not after. then, if the offset index is missing, we will rebuild the index. so, perhaps we can fix the logic here as the following. (1) if offset index is missing, rebuild both indexes. (2) if only the timeindex is missing, create an empty timeindex file (i.e., assuming that it's an old segment from pre-v10).",0,0.9587699174880981
66561253,1215,becketqin,2016-06-10T04:45:37Z,"that is a good point. i think it should work. there is a slight difference. the current patch essentially takes a snapshot of the timestamp when last message is appended to the log segment. so even if user touched the segments later and changed the modification time, it does not affect the log retention. if we change the behavior to only use lastmodified of the file, it could change if user touch the file later. i remember our sre used to do touch the file for some reasons, but i am not sure if this is an important difference.",1,0.9361019730567932
66561646,1215,becketqin,2016-06-10T04:54:58Z,i see. that sounds reasonable to me.,0,0.9793521165847778
66696679,1215,junrao,2016-06-11T00:21:04Z,"yes, after the producer upgrades to 0.10, all new messages will have a timestamp and the time-based retention will be more accurate. for the old messages, the current behavior is to use the current last modified time for retention. we don't really have to improve it if that makes the new code simpler.",0,0.9917863011360168
67100177,1215,junrao,2016-06-15T05:05:33Z,"this iterator actually copies the key and value from the file channel to the buffer. for searching timestamp, we could do a special iteration that just copies the header part (like how we do in search by offset). we need to think through whether it's worth specializing.",0,0.9926382303237915
67100215,1215,junrao,2016-06-15T05:06:14Z,"hmm, is that true? the segment could have messages with and w/o timestamp. stopping early may prevent us from finding the offset with the timestamp that we want.",0,0.9773703217506409
67100246,1215,junrao,2016-06-15T05:06:25Z,"in this case, should we really maxtimestampchecked since it is not really associated with lastoffsetchecked + 1?",0,0.9915328621864319
67100351,1215,junrao,2016-06-15T05:06:48Z,"do we need to duplicate the code for index and timeindex? since both indexes are of abstractindex, perhaps we can just iterate two abstractindex in a loop and do the sanitycheck and recover in the loop (we may need to add a absolutepath() method in abstractindex).",0,0.991999626159668
67100430,1215,junrao,2016-06-15T05:07:17Z,it's a bit awkward to have to create logsegment here and in line 196. we can avoid that by just doing sth like the following val indexexist = indexfile.exists() segment = new logsegment(...) if (indexexist) else,-1,0.891248881816864
67100453,1215,junrao,2016-06-15T05:07:40Z,"for segments where no message has timestamp, should we really use last modified time?",0,0.9915298223495483
67100460,1215,junrao,2016-06-15T05:07:43Z,typo timestaamp,0,0.9715140461921692
67100462,1215,junrao,2016-06-15T05:07:47Z,an => a,0,0.9920908212661743
67100482,1215,junrao,2016-06-15T05:08:04Z,"it seems that we can retain the tombstone using the message timestamp, instead of segment time. we can file a separate jira to track that.",0,0.9911980032920837
67100485,1215,junrao,2016-06-15T05:08:09Z,no need for extra space before startms,0,0.9919890761375427
67100491,1215,junrao,2016-06-15T05:08:13Z,maxtimestampsofarbeforeappend is never used.,0,0.9921795129776001
67100692,1215,junrao,2016-06-15T05:10:25Z,"do we have to append the timestamp for the first message to the index? if so, we are not doing that consistently in recover(). for log rolling, it seems that we can just track the timestamp of the first message (if notimestamp, just use the create time) during startup or append w/o needing the index entry.",0,0.9924873113632202
67100718,1215,junrao,2016-06-15T05:10:48Z,"if we update offsetofmaxtimestamp, don't we need to update offsetofmaxtimestamp accordingly?",0,0.9946343898773193
67100724,1215,junrao,2016-06-15T05:10:55Z,could we improve the text to make it clearer how the index is corrupted?,0,0.9906071424484253
67100745,1215,junrao,2016-06-15T05:11:19Z,"there is inconsistency in the caller of maybeappend(). some of them does [code block] and some others don't do the check. it would be better if we can do this consistently. it seems if maybeappend() just ignores negative timestamp, the caller doesn't have to do the check anymore.",0,0.9649131894111633
67100751,1215,junrao,2016-06-15T05:11:26Z,this comment is a bit weird in that it tries to explain things that we don't do. is it useful?,-1,0.9899409413337708
67100757,1215,junrao,2016-06-15T05:11:31Z,could we improve the text to make it clearer how the index is corrupted?,0,0.9906071424484253
67100764,1215,junrao,2016-06-15T05:11:34Z,on => one,0,0.9909703731536865
67100776,1215,junrao,2016-06-15T05:11:44Z,"hmm, not sure why we need to have the while loop here. aren't we just loop the same wrappermessageopt over and over?",0,0.8429240584373474
67100784,1215,junrao,2016-06-15T05:11:51Z,this should probably go to stderr as those mismatches.,0,0.9872158169746399
67398599,1215,becketqin,2016-06-16T18:26:01Z,"hmm, i actually did that in my first patch. `searchforoffset()` and `searchfortimestamp` were sharing a `scanandhandlemessages()` function that does a special iteration by only looking at the headers. you suggested maybe we can just use the iterator in the comments and i thought it was a good suggestion because of the following reasons: 1. search by timestamp is a very infrequent call. 2. unlike searching by offset, searching by timestamp do need to look into the payload if the message is a compressed message. so copy the value into the buffer seems reasonable. 3. because we have the index, the number of bytes we read from the disk should be relatively small assuming the timestamps are not abnormal. so it seems not worth duplicating the code of the iterator here?",1,0.5024819374084473
67426111,1215,becketqin,2016-06-16T21:20:15Z,"yes, stopping early means we may not find the exact offset with a timestamp that we want. but it will not miss that message. in reality, a log segment may have messages w/ and w/o timestamp because some of the producers have been upgraded and others have not. what concerns me of not stopping when see old message is that if we don't have any message w/ a timestamp (or the timestamp we wanted locates close to the end of the log segment), we may end up with scanning the entire log segment. that will pollute the memory and impact the performance. since we are not appending a time index entry to the time index for the first message with a timestamp in a segment. can we do the following? 1. in `timeindex.lookup()`, when slotfor() returns -1 in the timeindex, we can just return the offset of the first entry instead of baseoffset (the offset will be baseoffset if the first message has a timestamp). this will essentially skip all the earlier messages w/o a timestamp in the log segment. if the time index is empty, we still return baseoffset. 2. in `searchfortimestamp()` we keep searching when we see message w/o a timestamp until we find the timestamp. the only risk is that if two indexed offset in the time index are far away, we may still be scanning the entire log. for example, if message 0 has a timestamp 100, message 100000 has timestamp 200. when people are searching for timestamp 150, we will scan the message from 0 to 100000. but this should be rare.",0,0.5644624829292297
67427456,1215,becketqin,2016-06-16T21:28:46Z,"currently this method returns the `maxtimestampchecked` and the `nextoffsettoread`, so it is not the exact timestamp to offset mapping. do you think it would be better to return a tuple `(timestamp, offset)` instead of a `timestampoffset`?",0,0.9923999309539795
67445751,1215,becketqin,2016-06-17T00:17:41Z,it seems reasonable to use the last modification time as the biggest timestamp of the segment. do you have any specific concern?,0,0.9910255074501038
67449438,1215,junrao,2016-06-17T01:12:15Z,"ok, sounds good. we can leave this as it is. sorry for going back/forth on this.",-1,0.9920439124107361
67449469,1215,junrao,2016-06-17T01:12:49Z,"1. slotfor returns -1 only when the timeindex is empty. in the case, the largest timestamp of the segment is notimestamp. so, this segment shouldn't need to be search since notimestamp is smaller than any target timestamp, right 2. yes, not sure how common the case you described can happen. given that search by timestamp is infrequent, perhaps scanning more is ok?",0,0.98831707239151
67449480,1215,junrao,2016-06-17T01:12:56Z,it doesn't seem timestamp is used by the caller. could we just return option[long]?,0,0.9902734160423279
67449925,1215,becketqin,2016-06-17T01:19:39Z,"if a log segment has messages w/ and w/o timestamp, the first message in a log segment may not always have the timestamp. so it seems we still need to store the timestamp of the first message that w/ a timestamp somewhere, right? or do you mean we only look at the timestamp of the first message to determine whether to use the message timestamp or segment create time?",0,0.9903505444526672
67454855,1215,becketqin,2016-06-17T02:48:30Z,i am not sure how to make the text clearer. it seems we have already specifically stated the problem?,0,0.6127550601959229
67455183,1215,becketqin,2016-06-17T02:55:00Z,i added this because offset index will throw exception if we attempt to insert an offset index entry whose offset equals to the previous offset. i am trying to avoid confusing future contributors here by adding these comments.,0,0.9886618852615356
67455678,1215,becketqin,2016-06-17T03:04:39Z,"the wrappermessageopt will be updated in line 206. we need to do this because if user is producing uncompressed messages, a ""batch"" would actually be multiple messages. the first message in the batch may not always have the the largest timestamp. so we need to scan a little. we should be able to find the indexed timestamp before the next indexed offset in the time index or the log end, whichever comes first.",0,0.992016077041626
67554576,1215,becketqin,2016-06-17T18:25:35Z,"1. slotfor also returns -1 if the timestamp is smaller than the first indexed timestamp. so the case i described is something like the following: say we have 1 gb log segment, the first message w/ a timestamp is offset 1234567 at position 900mb. and the timestamp is 1000. so the first time index entry will be (1000, 1234567) in this case. now if user come and search for timestamp 100, `indexslotfor` will return -1, and currently we will return baseoffset if `indexslotfor` returns -1. so we will scan the log from base offset and page 900 mb into memory. if we return the offset in the first time index entry. we don't need to scan the previous 900 mb in that segment. because we know that there is no timestamp before the offset of the first indexed offset in the time index, there is no need to scan that. in another scenario, if the time index is empty, that means there is no timestamp in the segment. but in that case `logsegment.largesttimestamp()` will return the last modification time. so `log.fetchoffsetsbytimestamp()` will not skip the segment but treat it the same way as the segments that have timestamps. this essentially means at log level, we people search for we do not distinguish between the largesttimestamp from the message timestamp or the largesttimestamp from last modification time. they provides a unified experience to the users. are you suggesting that we always ignore the old messages completely in the new way of searching for timestamp. i am worried about the transition period regarding that approach. for example, say some user is now using the timestamp search at segment granularity. if they want to consume all the data after 8:00 am, they can start to consume the data after the segment whose last modification time is before 8:00 am. there may be duplicates but it works. now the users upgraded to new consumer which search for timestamp based on message timestamp, suddenly we skip all the old segments and they always get log end offsets. that was also why i am not sure if we should skip the old messages or we should just stop on seeing old messages. 1. i agree the case i described would be rare, so scanning until we find timestamp should be fine.",0,0.9546216726303101
67583237,1215,junrao,2016-06-17T22:21:08Z,"thanks for the explanation. 1. yes, i agree that it's better to use last modified time for segments with no timestamp. so, if all messages have notimestamp, the semantic is that the search will return the offset of the first message in the segment whose last modified time is >= the target timestamp. 2. if a segment has messages with and w/o timestamp, to find the message matching the precise timestamp may require us scan most the segment, but is probably ok since it's rare. it would be useful to document the semantics in the comment above log.fetchoffsetsbytimestamp() on those corner cases.",1,0.9672195315361023
67583244,1215,junrao,2016-06-17T22:21:13Z,"ok, this is fine then.",0,0.9554449319839478
67583312,1215,junrao,2016-06-17T22:21:47Z,"yes, i was thinking of just looking at the timestamp of the first message. if it doesn't have timestamp, we use create time. this is probably simpler than having to force an index entry on first message with timestamp. for those segments with a mix of valid timestamp and notimestamp, we can decide whether the rolling will be based on the old or the new behavior. either is fine, but we probably want to pick one that's easier to implement.",0,0.987461268901825
67583331,1215,junrao,2016-06-17T22:21:59Z,"corrupt index found, index file (%s) has non-zero size and the last offset is %d is not larger than the base offset is %d",0,0.9944185018539429
67583348,1215,junrao,2016-06-17T22:22:18Z,"got it. then, is it enough to read only maxmessagesize from the log? it seems that we may need to scan to the end of the log to find the message that we are looking for.",0,0.9883154630661011
67591522,1215,becketqin,2016-06-18T00:40:28Z,"yes, you are right. we do need to read till the end of the log.",0,0.986890435218811
67594888,1215,becketqin,2016-06-18T03:53:16Z,"just want to make sure i understand the behavior we want here. it seems that sometimes we want to skip the messages w/o timestamps, and sometimes we don't skip. for example, if we have two log segments: segment 0: baseoffset=0, no message has timestamp, last offset 99, last modified=1000. segment 1: baseoffset=100, the first message with a timestamp is at offset 105, and the timestamp is 2000. the second message with a timestamp is at offset 150, and the timestamp is 3000. now if we search for timestamp 1500, it looks that we should return offset 100, i.e. we should not ignore messages 100 - 104 that do not have timestamps, even though the timestamp we wanted is at offset 105. on the other hand if we search for timestamp 2500, it seems that we will skip the messages 106 - 149 because they don't have timestamps. it seems a little weird that we treat the messages w/o timestamps differently depending on where the messages are. do you think that is the behavior we want or it would be better if we have a consistent behavior regarding messages w/o timestamps? previously i am taking the approach that we always don't skip the messages w/o timestamps. but that does mean we may not able to return the exact message with the timestamp we wanted. what do you think?",0,0.9210118055343628
67604184,1215,junrao,2016-06-18T17:46:39Z,"hmm, i was thinking that if you search for timestamp 1500, we will return offset 105 since that's the first message whose timestamp is >= 1500. similarly, if you search for timestamp 2500, we will return offset 150. in the case where a segment has no timestamp (we know that from largesttimestamp), we can optimize by not scanning the whole segment and just return the offset of the first message in the segment. otherwise, we will just scan the segment as much as needed.",0,0.9822477698326111
67605816,1215,becketqin,2016-06-18T19:57:05Z,"if we return 105 when search for 1500, would that cause problem for the transitional period? previously user will consume from 100, which may be the messages they actually wanted. once they switch to new timestamp search, the user will not see message 100 - 104 any more. in our example there are only 5 messages, but in real world there could be more. it looks there is a trade-off we need to make between backward compatibility and accuracy of search. i am not sure how critical the backward compatibility here is. personally i feel that when there are mixture of messages with and w/o timestamps, backward compatibility seems more important. because the accuracy will increase when more and more messages contains timestamp. and we will have the full accuracy once the users have fully rolled out the new message format.",0,0.9447648525238037
67625139,1215,junrao,2016-06-19T22:34:37Z,"to me, it seems that we just need to preserve compatibility when things are comparable. for example, if a segment has no message with timestamp, it makes sense to use the old behavior, i.e., treating all messages in the segment as if they have the last modified time. if a segment has messages with and w/o timestamp, it's not directly comparable with the old behavior. it seems to me that simply finding the first message with a timestamp >= than the target is easy to understand. stopping at the first message with notimestamp seems harder to explain since it depends on where those messages are and what the indexing interval is. in any case, we probably need a separate kip to expose the timestamp search in an api. we can discuss more and finalize the decision then.",0,0.9650253057479858
67625332,1215,becketqin,2016-06-19T22:51:54Z,"i see. i will create another kip then. the concern i have is that from user's perspective, they don't really care or know which segment the messages go into. they only want to make sure that all the messages produced after a certain timestamp **t** will be consumed. previously the offsets we return to the user are based on last modification time at segment level. it seems that now when we have old messages without timestamps, we should still keep the previous behavior.",0,0.8687196373939514
67796773,1215,junrao,2016-06-21T01:49:35Z,the previous indentation seems correct?,0,0.9913171529769897
67796777,1215,junrao,2016-06-21T01:49:41Z,do we need loadedsegment at all? it seems that loadedsegment is always segment.,0,0.9922286868095398
67796798,1215,junrao,2016-06-21T01:49:54Z,"could we get rid of indexortimeindex and change warn to log ""found corrupted index due to e.getmessage() ...""? the message in the exception tells us the file name, which should be good enough.",0,0.99366694688797
67796809,1215,junrao,2016-06-21T01:50:01Z,the comment is not accurate. the rolling is now based on the timestamp of the first message.,0,0.9605090618133545
67796815,1215,junrao,2016-06-21T01:50:05Z,do we need the extra new line?,0,0.9908298254013062
67796820,1215,junrao,2016-06-21T01:50:09Z,do we need the extra space before startms?,0,0.9934422969818115
67796828,1215,junrao,2016-06-21T01:50:16Z,the comment seems in the wrong location.,0,0.6923802495002747
67796839,1215,junrao,2016-06-21T01:50:24Z,unused val maxtimestampsofarbeforeappend,0,0.9929547905921936
67796844,1215,junrao,2016-06-21T01:50:28Z,this comment seems in the wrong location now.,0,0.8113924860954285
67796889,1215,junrao,2016-06-21T01:50:59Z,"this forces us to read one message from every log segment during clean startup, which may incur additional i/os. another way is to calculate rollingbasetimestamp lazily when timewaitedforroll() is first called and then remember it. this will avoid the potential extra i/os.",0,0.9893491268157959
67796907,1215,junrao,2016-06-21T01:51:14Z,"if we update maxtimestampsofar, don't we need to update offsetofmaxtimestamp accordingly? otherwise, the next time we add an entry to the time index, the offset may not match maxtimestampsofar.",0,0.9895496368408203
67796913,1215,junrao,2016-06-21T01:51:20Z,"to be more precise, we are not adding the last, but the largest time index entry.",0,0.9904476404190063
67796920,1215,junrao,2016-06-21T01:51:23Z,the comment seems inaccurate.,0,0.7177428603172302
67796925,1215,junrao,2016-06-21T01:51:29Z,the comment is no longer accurate now that we only return offset.,0,0.9879239201545715
67796958,1215,junrao,2016-06-21T01:51:46Z,"more precisely, the comment should be ""get the index entry with a timestamp less than or equal to the target timestamp"".",0,0.9909840822219849
67796971,1215,junrao,2016-06-21T01:51:55Z,could we use file.getabsolutepath instead file.getname here to make it consistent?,0,0.9942177534103394
67796980,1215,junrao,2016-06-21T01:52:01Z,that means the we => that means we,0,0.9932162165641785
67796995,1215,junrao,2016-06-21T01:52:12Z,"is the comment still accurate? we don't insert the last modification time of the file to the time index, right?",0,0.9925848841667175
67797002,1215,junrao,2016-06-21T01:52:19Z,we want to find the time index entry whose timestamp is less than or equal to the given timestamp.,0,0.9905949831008911
67797008,1215,junrao,2016-06-21T01:52:24Z,could we use file.getabsolutepath instead file.getname here to make it consistent?,0,0.9942177534103394
67797017,1215,junrao,2016-06-21T01:52:33Z,that may require a large heap for the tool. could we read messages in chunks up to maxmessagesize?,0,0.9873895645141602
67797065,1215,junrao,2016-06-21T01:53:06Z,"it seems that we just need to print timestamp and offset in the index. not sure why we need to print s""(log timestamp: $maxtimestamp)"" and s""(log offset: ${partialfilemessageset.head.offset})"".",0,0.9839411377906799
67797070,1215,junrao,2016-06-21T01:53:09Z,typo indexs,0,0.9856932163238525
67797073,1215,junrao,2016-06-21T01:53:11Z,typo indexs,0,0.9856932163238525
67968372,1215,junrao,2016-06-21T23:03:13Z,"hmm, is that right? the rolling check happens before the append. so, the first message in the segment is ""set"", which has notimestamp. then, we will be using the creation time of the segment. so, it seems that in the case, we should roll another segment after calling append() in line 94.",0,0.9825323820114136
67968389,1215,junrao,2016-06-21T23:03:19Z,"hmm, do we need the if test since the baseoffset is 0?",0,0.9874337315559387
67968395,1215,junrao,2016-06-21T23:03:22Z,the comment is no longer accurate.,0,0.9280774593353271
67968397,1215,junrao,2016-06-21T23:03:25Z,unused val msgperseg,0,0.9924337863922119
67968464,1215,junrao,2016-06-21T23:04:08Z,"hmm, shouldn't we populate messages of format 0.9.0 here since we want to set message format to 0.9.0 later?",0,0.9817379117012024
67968484,1215,junrao,2016-06-21T23:04:20Z,"to trigger the rebuild of the index, don't we need to set recoverypoint to 0?",0,0.994253933429718
67968492,1215,junrao,2016-06-21T23:04:24Z,unused import,0,0.9873000979423523
67968503,1215,junrao,2016-06-21T23:04:31Z,"hmm, why will the append hit the exception here? the timestamp seems larger than the ones in the index.",0,0.9686245322227478
67968517,1215,junrao,2016-06-21T23:04:37Z,"hmm, not sure why we will hit the exception since the offset to be appended is larger than the ones in the index.",0,0.7893462777137756
67968523,1215,junrao,2016-06-21T23:04:41Z,this is no longer accurate.,0,0.9130059480667114
67968533,1215,junrao,2016-06-21T23:04:48Z,"is ""might"" accurate? it seems it should be ""will"".",0,0.9883297681808472
67968542,1215,junrao,2016-06-21T23:04:52Z,offset index => offset index entry,0,0.9941270351409912
67968550,1215,junrao,2016-06-21T23:04:55Z,this is no longer true.,0,0.9732419848442078
68103620,1215,becketqin,2016-06-22T18:02:49Z,"not sure i fully understand this. it seems we need to read the first message from the file anyway, whether at the startup time or when the first message is appended after startup. if the first message received after startup and the first message in the segment resides in the same disk block, we only page in once. otherwise we still need to page in two blocks. so it seems the disk i/os are the same? do you mean we can save the disk i/o if there is no message appended to a partition after startup?",0,0.5307828783988953
68108307,1215,becketqin,2016-06-22T18:28:10Z,"hmm, i think filemessageset.read() only set a start position and end position. it does not really read anything into the heap, right? this is just allow the iterator to iterate until the end of the segment. it seems not creating any additional memory pressure.",0,0.9757434725761414
68109192,1215,becketqin,2016-06-22T18:32:30Z,"i was thinking this easier for user to find out what when wrong. when i run this command, i found it is a little ugly that we have to switch between the dumped errors and the printed index entries.",-1,0.9096096158027649
68109601,1215,becketqin,2016-06-22T18:34:34Z,"ah... sorry for the confusion, i changed the assertion expected value but forgot to change the assertion message.",-1,0.9934847950935364
68111083,1215,becketqin,2016-06-22T18:42:13Z,"logically the first message appended to a log segment does not cause the insertion of index entries, so searching for the timestamp of the first message should give base offset. but in our case the base offset happened to be the same as the offset of our first message.",0,0.9896680116653442
68111692,1215,becketqin,2016-06-22T18:45:29Z,it does not really matter whether we append message in 0.9.0 or 0.10.0 format because the log segment will do down conversion when the message is appended if the format is 0.10.0,0,0.9901933073997498
68112128,1215,becketqin,2016-06-22T18:47:50Z,"in our case, we will have corrupted log index, so no matter what recovery point it is, the index will be deleted and rebuilt.",0,0.9803732633590698
68112512,1215,becketqin,2016-06-22T18:49:59Z,this is because the time index entry is already full. we only allow maxentries - 1 entries to be appended if skip full check is set to false (which is the default value).,0,0.9945479035377502
68113246,1215,becketqin,2016-06-22T18:54:01Z,"our base offset is 45l, max entries = 30l. the offset of the last time index entry is (30 - 1) \* 10 + 45 = 335. we are appending an entry with offset (30 - 2) \* 10 = 280. so it is smaller.",0,0.9926069974899292
68166110,1215,junrao,2016-06-23T02:06:26Z,"mayberoll() is only called on the active segment. so, if we get first message on demand when mayberoll() is called, we can avoid reading the first message on all old segments.",0,0.9934480786323547
68166173,1215,junrao,2016-06-23T02:07:29Z,"good point. so, this is not an issue then.",1,0.9720983505249023
68166576,1215,junrao,2016-06-23T02:14:25Z,"but the log is not configured with 0.9.0 message format when the append happens, right?",0,0.9927700161933899
68167173,1215,junrao,2016-06-23T02:24:51Z,"got it. sorry, i thought the first field is the offset.",-1,0.9911786913871765
68244074,1215,becketqin,2016-06-23T14:26:12Z,got it. thanks for the explanation. that makes sense.,1,0.9914422631263733
68244889,1215,becketqin,2016-06-23T14:30:19Z,"ah, you are right. sorry i was reading the lines below this, which is recovering the log.",-1,0.9883295297622681
68306815,1215,ijuma,2016-06-23T20:16:47Z,doing this means that `comparekey` and `comparevalue` will cause boxing to take place. two ways to fix this: - use `` although it's a bit hard to know when the optimisation is not applied - use `long` everywhere when doing the comparisons,0,0.9931932091712952
68307091,1215,ijuma,2016-06-23T20:18:40Z,`java.util.long.compare`?,0,0.9936169385910034
68307419,1215,ijuma,2016-06-23T20:20:40Z,how can we say it is fully compatible and then say that there are `potential breaking changes`?,0,0.9665646553039551
68307613,1215,ijuma,2016-06-23T20:21:50Z,"for the two above, it would probably be useful to say what the previous behaviour was as well.",0,0.9863629937171936
68308726,1215,ijuma,2016-06-23T20:28:32Z,`asinstanceof` and `anyval` are generally avoided in scala as there is usually a cleaner and safer way to do things. maybe `indexslotfor` should take a function that does the comparison?,0,0.9918545484542847
68313140,1215,ijuma,2016-06-23T20:54:35Z,"this is a bit odd, why not the standard `int mid = (low + high) >>> 1`?",0,0.5653281211853027
68313919,1215,ijuma,2016-06-23T20:58:58Z,"a micro-optimisation is to leave this as the last `else` as we return once it succeeds. statistically, we are more likely to hit the other branches more times.",0,0.9873630404472351
70016160,1215,junrao,2016-07-08T01:51:20Z,timebased => time-based,0,0.9912952184677124
70016179,1215,junrao,2016-07-08T01:51:40Z,"on the leader, during append, we actually use the first offset in the messageset when adding the time index entry. to be consistent, we probably should do it here as well.",0,0.9924841523170471
70016194,1215,junrao,2016-07-08T01:51:52Z,"we need to set skipfullcheck to true when calling maybeappend here, right?",0,0.9927926063537598
70016202,1215,junrao,2016-07-08T01:51:57Z,would it be better to rename this to loadlargesttimestamp()?,0,0.9937684535980225
70016219,1215,junrao,2016-07-08T01:52:15Z,it's kind of verbose to have to do the assignment here and in line 256. perhaps we can move these two lines after line 241. then we can get rid of the two else clauses.,0,0.9580686688423157
70016230,1215,junrao,2016-07-08T01:52:24Z,"we need to set skipfullcheck to true when calling maybeappend, right?",0,0.9926435351371765
70016242,1215,junrao,2016-07-08T01:52:35Z,the error message is a bit hard to understand. could we improve that?,0,0.5786782503128052
70145743,1215,junrao,2016-07-08T21:45:34Z,"ran into an issue while testing dumplogsegments (details can be found in the jira since pr comment doesn't support attachment). it seems that if the producer sends a batch of non-compressed messages, in logsegment.append(), we always pass in the offset of the first message, but the offset of the largest message may not be the first. this seems to be what's failing the check in the tool. not sure if this is the behavior that we want. if yes, we will need to document this properly, i.e., the index may point to an offset before the message that has the corresponding timestamp. but then, we have to think through other implications such as how this affects truncation.",0,0.808691680431366
70380300,1215,becketqin,2016-07-12T05:48:19Z,"i meant it was compatible api wise, however there are potential breaking changes in resource footprint. i agree we should be clearer on this. i'll update the doc.",0,0.983894407749176
70680191,1215,junrao,2016-07-13T18:19:59Z,could we add offsetofmaxtimestamp?,0,0.9950597882270813
70680203,1215,junrao,2016-07-13T18:20:03Z,could we rename this to validateandoffsetassignresult?,0,0.9951027631759644
70680256,1215,junrao,2016-07-13T18:20:19Z,"we changed the logic to only use the wrapper message offset in time index in append(). so, perhaps we should do the same during recovery? also, it would be good to avoid calling entry.firstoffset twice since decompression is needed each time.",0,0.9937217831611633
70680297,1215,junrao,2016-07-13T18:20:33Z,"in line 460, do we still need the test messageformatversion > message.magicvalue_v0? it seems it's already covered by line 458.",0,0.9940302968025208
70680342,1215,junrao,2016-07-13T18:20:43Z,"hmm, in this case, if the targetcodec is nocompression, we should return the offset of the first message, right?",0,0.9817444682121277
70680368,1215,junrao,2016-07-13T18:20:52Z,"for the code btw 484 and 491, if messagetimestamptype and timestamp != maxtimestamp, don't we need to change the timestamp in the wrapper message?",0,0.9933494925498962
70680433,1215,junrao,2016-07-13T18:21:11Z,"typo firxst also, the next line of the comment seems to talk about the same thing.",0,0.9861443042755127
70680461,1215,junrao,2016-07-13T18:21:20Z,"when i ran the following command, i got an exception. bin/kafka-run-class.sh kafka.tools.dumplogsegments --files 00000000000000113931.timeindex dumping /users/junrao/downloads/00000000000000113931.timeindex exception in thread ""main"" java.lang.illegalargumentexception: invalid max index size: -1 at kafka.log.abstractindex. (abstractindex.scala:54) at kafka.log.offsetindex. (offsetindex.scala:51) at kafka.tools.dumplogsegments$.kafka$tools$dumplogsegments$$dumptimeindex(dumplogsegments.scala:185) at kafka.tools.dumplogsegments$$anonfun$main$1.apply(dumplogsegments.scala:101) at kafka.tools.dumplogsegments$$anonfun$main$1.apply(dumplogsegments.scala:91) at scala.collection.indexedseqoptimized$class.foreach(indexedseqoptimized.scala:33) at scala.collection.mutable.arrayops$ofref.foreach(arrayops.scala:108) at kafka.tools.dumplogsegments$.main(dumplogsegments.scala:91) at kafka.tools.dumplogsegments.main(dumplogsegments.scala)",0,0.9893965125083923
70684786,1215,junrao,2016-07-13T18:44:25Z,"since we changed the logic, so for compressed messages, we need the offset of the wrapper message for the timeindex. also, could we save the last messageandoffset to avoid calling retainedmessages.last (since it requires iteration)?",0,0.9935277104377747
70926518,1215,becketqin,2016-07-15T06:19:26Z,i was not able to reproduce this issue. it seems that the exception would only happen if the time index file does not exist.,0,0.9783633947372437
72359859,1215,junrao,2016-07-26T23:57:16Z,is removing the above code correct? it doesn't seem there is code to compute the largest timestamp lazily.,0,0.9916903972625732
72360736,1215,becketqin,2016-07-27T00:06:07Z,the maxtimestampsofar and offsetofmaxtimestamp are loaded when the log segment is constructed. so it seems that we don't need to load it again.,0,0.9933269023895264
72363721,1215,junrao,2016-07-27T00:39:52Z,got it. then the changes look good.,1,0.9827614426612854
75409338,1215,junrao,2016-08-18T23:50:45Z,typo timestmp,0,0.9878732562065125
75409364,1215,junrao,2016-08-18T23:51:01Z,could we just set appendinfo.maxtimestamp here and get rid of maxtimestampinmessageset?,0,0.9936633110046387
75409371,1215,junrao,2016-08-18T23:51:04Z,rollingbasetimestamp => rollingbasedtimestamp ?,0,0.9942213296890259
75409380,1215,junrao,2016-08-18T23:51:14Z,perhaps it would be safer for the callers to use named params since the first three params are of the same type.,0,0.9735725522041321
75409406,1215,junrao,2016-08-18T23:51:27Z,perhaps we should add largesttimestamp and offsetoflargesttimestamp to the trace logging too?,0,0.9929037690162659
75409414,1215,junrao,2016-08-18T23:51:31Z,typo messsage,0,0.8248897790908813
75409417,1215,junrao,2016-08-18T23:51:34Z,shouldn't we used created instead of 0 here?,0,0.9925752878189087
75409433,1215,junrao,2016-08-18T23:51:47Z,"we probably shouldn't eat the exception here. if there is an error when appending to the time index, we should probably just halt the jvm so that we can run recover on restart.",0,0.9881383776664734
75409443,1215,junrao,2016-08-18T23:51:54Z,that means the we => that means we,0,0.9932162165641785
75409460,1215,junrao,2016-08-18T23:52:06Z,"is the following comment still accurate? we don't insert the last modification time of the file to the time index, right?",0,0.9931591153144836
75409490,1215,junrao,2016-08-18T23:52:23Z,the name wrappermessagetimestamp seems inaccurate since the message set is not always compressed?,0,0.983198344707489
75409524,1215,junrao,2016-08-18T23:52:45Z,"in both this line and line 472, it seems that we should be using offsetofmaxtimestamp instead of the offset of the last message since validatedmessages may not be compressed when adding to the log. also, could we make wrappermessagetimestamp a non-option field since all possible values are some.",0,0.9933892488479614
75409563,1215,junrao,2016-08-18T23:52:59Z,"it seems that the ordering of the 2nd and the 3rd params is reversed? to avoid this, perhaps it will be clearer to use named parameters since timestamp and offset are of the same type.",0,0.9866592884063721
75410546,1215,junrao,2016-08-19T00:04:46Z,could we not print this if there is no error?,0,0.9799030423164368
75422544,1215,becketqin,2016-08-19T03:14:55Z,"i am thinking that if there is no message in the segment, the log segment would not have been waiting for rolling, so returning 0 seems reasonable. the return value here does not matter much because we check the segment size in log.mayberoll(). but it is probably better to return (now - created) since we have a trace level logging in log.mayberoll().",0,0.9786110520362854
75424163,1215,becketqin,2016-08-19T03:45:08Z,"hmm, if the message is not compressed, the offset should be the exact offset of the message that has the largest timestamp. when using create_time (line 472), that message would be offsetofmaxtimestamp. but when using log_append_time, it seems the offset should be the offset of the first message in the message set because all the messages in the validatedmessages will have the same timestamp. (on line 474, offsetcounter has not been incremented yet. so offsetcounter.value is still the offset of first message). i thought about making wrappermessagetimestamp non-option, but we actually will pass in none in the constructor in line 272.",0,0.9775915145874023
75424189,1215,becketqin,2016-08-19T03:45:45Z,good catch! i'll add a unit test for this. can't believe it is not caught in the unit tests.,1,0.9968876242637634
75425328,1215,junrao,2016-08-19T04:06:50Z,thanks for the explanation. that makes sense. the current logic is correct then.,1,0.9724892973899841
75517403,1215,junrao,2016-08-19T17:08:21Z,the comment is no longer valid. we can probably just remove it.,0,0.9915173053741455
75517610,1215,junrao,2016-08-19T17:09:30Z,"it seems that timeindex.maybeappend() won't throw ioexception. so, swallowing the exception here is actually fine.",0,0.9704649448394775
210999572,5527,Kaiserchen,2018-08-17T18:41:38Z,serialized wrapper?,0,0.9946162104606628
211006524,5527,Kaiserchen,2018-08-17T19:08:05Z,"can skip the second length, its known anyway.",0,0.9878575801849365
211006693,5527,Kaiserchen,2018-08-17T19:08:55Z,treating the whole thing as buffer?,0,0.9891566038131714
211008763,5527,Kaiserchen,2018-08-17T19:17:47Z,i think the step here an optimizer _could potentially_ exploit is the repartitioning. so one could try to only factor out the repartitioning,0,0.9814161062240601
211009275,5527,Kaiserchen,2018-08-17T19:20:07Z,probably need to wrap into delegatingpeekingkeyvalueiterator,0,0.9926300048828125
211347575,5527,bellemare,2018-08-20T17:38:36Z,"true, i could just do it as the remainder. thanks",1,0.958827793598175
211347916,5527,bellemare,2018-08-20T17:39:41Z,"i'll have to look more into the optimizer. tbh i built this originally in 1.0 and just did a functional port, not necessarily a best practices one. thanks",1,0.9724591970443726
211390368,5527,bellemare,2018-08-20T20:05:51Z,"i don't understand your question, can you elaborate?",-1,0.7208724617958069
211396540,5527,bellemare,2018-08-20T20:27:36Z,will do.,0,0.9465230703353882
211399371,5527,bellemare,2018-08-20T20:37:52Z,"i notice that in 2.x that i may be able to rework this to allow for enabled cache using a `prefixscan` function similar to `threadcache.range`. i will have to look into this a bit more, though i don't think it will affect performance much since i anticipate rocksdb prefixscan to take the longest overall.",0,0.9752950072288513
211510890,5527,Kaiserchen,2018-08-21T07:57:50Z,"might be, its one of the places i got stuck once. from experience i can tell that its working sufficiently well w/o cache. i think rocks does a pretty good job in not seeking around to randomly on the disk",0,0.8382361531257629
211511167,5527,Kaiserchen,2018-08-21T07:58:50Z,i would not recommend to spend to much energy. at the moment i really don't expect the optimizer to be able to exploit any of this. probably also not in the future. was just a though popping into my head,0,0.5683150887489319
211511539,5527,Kaiserchen,2018-08-21T08:00:21Z,i think the whole section could look nicer if you would start with bytebuffer.allocate(totallength).asintbuffer(keylength).asbytebuffer.put(key).put(key)... something,0,0.9556266069412231
214673257,5527,Kaiserchen,2018-09-03T12:23:37Z,would need to forward `null` here?,0,0.9932098984718323
214674662,5527,Kaiserchen,2018-09-03T12:29:31Z,would remove this class and avoid protected final here. doesn't seem like a convincing java programming style.,0,0.9658212661743164
214715526,5527,bellemare,2018-09-03T15:01:58Z,"i'll leave it out for now. if someone else thinks otherwise, they can speak up or it can be done in a subsequent pr.",0,0.9882404804229736
214744117,5527,bellemare,2018-09-03T18:30:42Z,"yes, cleaner to do so. the value is not relevant. i have fixed that and added a clarification comment (i can remove all comments if required before final submission).",0,0.9897597432136536
214744281,5527,bellemare,2018-09-03T18:32:41Z,"i will change this - but i do appreciate any advice on how i should changee that. i'll post my updated code and we can determine if it's any better, or if there is a more specific approach i should follow.",1,0.9328470230102539
275888898,5527,adaniline-traderev,2019-04-16T16:34:03Z,"why is the topic passed as null? it causes issues with genericrecord avro serializer, since it tries to register schemas under ""null-value"" subject, and the schema registry responds with ""version not compatible"" error",0,0.9821335673332214
275899695,5527,bellemare,2019-04-16T17:00:50Z,"the issue is actually with the confluent implementation of the serde, as they incorrectly attempt to register when null topics are passed in. read [a link] for more details. that being said, it has been extremely quiet in that git repo, i am not sure how much effort confluent puts into supporting work on that product.",0,0.9282178282737732
275904020,5527,adaniline-traderev,2019-04-16T17:11:42Z,"if this does not gets fixed either way, this pr will be unusable for most of the practical use cases. what is the downside of passing the topic name to the serializer? i tried it, and it seemed to work as expected. is there a workaround if confluentinc/schema-registry#1061 is not fixed?",0,0.8842602372169495
275908240,5527,bellemare,2019-04-16T17:22:45Z,"i think the main issue would be the large amount of internal topic schemas registered to the schema registry. this, combined with any breaking changes to the schema (due to normal business requirement changes) would make it such that you are now needing to manually delete schema registry entries made to internal topics. this is a workflow that i do not believe was ever intended to be done with the confluent serde. as it stands right now, there are allegedly other functionalities that require null serialization (""there are several places in streams where we need to serialize a value for purposes other than sending it to a topic (ktablesuppressprocessor comes to mind), and using `null` for the topic is the convention we have.""). these too will not work with the confluent serde. if they do not fix it, then the next best thing to do would be wrap it in your own implementation and intercept null-topic values to avoid registration. i do not see why it wouldn't be fixed since the current behaviour of registering ""null-topic"" is fundamentally useless. anyways, with all that being said, for this particular line i can certainly pass in the topic since it's fairly well-defined. if you wish to have your internal topics registered to the schema registry, no big deal. for other parts, such as [a link] there is no solution using the current confluent serde.",0,0.9735252261161804
275924688,5527,adaniline-traderev,2019-04-16T18:02:56Z,"confluent serde needs a schema id, and looks like it is not stored in genericdata.record instance - it may not be trivial to fix confluentinc/schema-registry#1061...",0,0.9919399619102478
275926845,5527,bellemare,2019-04-16T18:08:30Z,"that is a fair point. : it may not be as easy to get the hash value as we thought if we rely on the value serde, namely because of the interactions with the schema registry to serialize the data. though this is technically a confluent issue, it may be sufficient to put a blocker on this pr since, as adaniline demonstrates, many users of this use the confluent serde. any thoughts on a way forward are welcome.",1,0.8523135185241699
275978323,5527,vvcephei,2019-04-16T20:28:13Z,"hmm. this does seem like an impediment. the serializer interface doesn't specifically state whether the topic is nullable or non-nullable. what it does say is ` topic topic associated with data`. getting fully into armchair lawyer mode, it seems like this statement implies non-nullability, since `null` is not a valid topic name. if it could be null, it should say something like ""the topic associated with the data, or null if there is none."" also, backing up to a higher level, the serializer interface is specifically for serializing data for use with kafka topics. so, it's probably not appropriate to use it for general serialization. if we want to do that, maybe we should add a new interface that doesn't imply we're sending data to a topic. then again, this is in support of an optimization. perhaps we should just drop the optimization for now and go back to storing only the foreign key reference for the correctness check. for bonus points, we could design a message and storage format that leaves the door open for future optimizations like this, without an awkward upgrade procedure. wdyt, ?",0,0.8490757942199707
276022142,5527,guozhangwang,2019-04-16T22:48:53Z,"on the high-level, i think this should be fixed at confluent sr, rather than letting an ak feature blocked on it -- i.e. users should still be able to pass in not-null topic names while non-schema required typed data will not be registered. reading on the source code of avro-serializer, i think the root cause is that today we treat all primitive typed data as a simple avro-schema as well when serializing, hence still registering it. details are here: [a link] and [a link] we could, instead, fix sr to let it just use primitive serdes directly for primitive types. in this way users can still provide topic names.",0,0.9825745224952698
276026299,5527,pgwhalen,2019-04-16T23:08:22Z,"fwiw , as a user of the sr/serdes, i would consider ""fix sr to let it just use primitive serdes directly for primitive type"" to be a regression. registering primitive schemas with the schema registry is a feature, because it allows other applications (support tooling, etc.) to understand the data in a topic without any context whatsoever.",0,0.9694505333900452
276236590,5527,bellemare,2019-04-17T13:20:57Z,"i think to answer the question of if confluent needs to change their sr and serde, or if we need to take a different approach requires us to address john's first paragraph: ""the serializer interface doesn't specifically state whether the topic is nullable or non-nullable."" if the topic must be non-nullable, then the current approach with the hash code wont work, since the output topic is unknown by the ktablerepartitionerprocessorsupplier.java. if the topic must be nullable (and still provide a serialized output), then the confluent serde/sr needs to change to support this. this isn't clear from the contract and so it probably does need to be resolved. lastly, i do agree with pgwhalen on the usage of primitive schemas in support tooling. we use this functionality all the time with schema registry lookups, as opposed to having our team guess as to what it may have been serialized in. one last thought - for the confluent serde, if the topic is null and the type is a primitive, we can avoid registration and do as outlined. if the type is not a primitive, it can throw an exception (as it effectively does now, upon trying to register to topic-null). this does seem a bit hacky and perhaps a bit complicated, but it may work.",0,0.9827671051025391
276244207,5527,adaniline-traderev,2019-04-17T13:36:43Z,"can the solution be to have a separate interface to calculate data hash (hashsupplier, etc), and have confluent avro serializer implement it? looks like it is a separate concern from kafka data serialization this way ktablerepartitionerprocessorsupplier could do something like [code block]",0,0.9939066767692566
276324353,5527,guozhangwang,2019-04-17T16:17:04Z,"i see. that's a valid point. after a second thought i feel that instead of all / never (i.e. always register a simple avro schema, v.s. never register for primitive types) we should give users options to choose from the two. -traderev that should also work, in fact, we can just let streams to use a special serde other than whatever registered serde for this repartition topic's value, instead of asking the registered serde to provide a hashserde function: note that, the current serde precedence is, from high to low: 1) user overridden value at the dsl. 2) streams library hard-coded value internally (think: longserde for `count`). 3) default registered serde value. but i'm a bit concerned about adding more special handling of serdes at the streams side, i.e. add more scenarios of case 2) above: today streams try to reason about the resulted stream key/value type out of an operator in a best effort and try to use the serde correspondingly event if user does not specify any overrides. the goal is to try to be as adherent to case 1) as possible. although we do have special hard-coded serdes as case 2), e.g. in `count` operator, we hard-coded the serde as longserde unless user overrides it, we still want to keep such cases as small as possible, since having streams to special-handle, e.g. a `ktablerepartitionerprocessor` opens the door for more complexity, as this handling logic would be scattered across the classes and error-prone: note that besides the sink node, at the source node of the downstream sub-topology, streams then should also remember to use a special serde instead of the registered one to deserialize it as well. that being said, if people feels it is worth to add this complexity in streams for good reasons, i can be convinced as well ---------------- philosophically, i'd still argue that, the ak code should not yield to a single vendor's dependency when considering its logic (disclaimer: i'm currently employed at confluent). we should consider what's the best approach for ak streams here, and then if it affects the eco-system dependency we should fix it on the other side.",0,0.6674831509590149
276332348,5527,bellemare,2019-04-17T16:36:42Z,"i don't disagree with your stand on ak first. i do, however, agree with john that the contract is not quite clear on if topic should always be non-null or if topic can be nullable. this is pivotal for determining the way forward. i believe that a precedent has been set by the suppress functionality ( [a link] ), and if we wish to be consistent we should make clear that serializers need to handle null topics (though that handling could simply be throwing an exception.. as is effectively the case with the confluent serde / sr ).",0,0.9107248187065125
276340194,5527,guozhangwang,2019-04-17T16:56:51Z,"for this aspect, my personal take is streams should pass in the topic name whenever it knows -- for the example you brought up, currently it's because the operator does not know the topic name i believe, for which we could refactor internal code to fix it (would like to chime in here whether that is really doable) -- and not relying on any assumptions of the serdes itself, whether the topic is nullable or not.",0,0.9834814667701721
276340707,5527,vvcephei,2019-04-17T16:58:10Z,"hah! well, now i'm really in the middle of it ;) it's worth noting that there's plenty of precedent on both sides of the issue. i don't think the suppress implementation constitutes a contract. it could just as easily be argued that l95 there is a bug. actually, i still feel the way i did toward the beginning of the thread, that it makes more sense to say it's non-nullable (given the javadoc and the origin/ownership of the interface in `kafka-clients`). i'm happy to fix that bug in suppress, since we actually do send the serialized result there to a changelog topic, we should just provide the cl topic name to the serializer. this case is more of a bind because i'm not aware of anywhere else in streams where we legitimately serialize something we have no intention of sending to any topic.",1,0.9752286672592163
276375010,5527,mjsax,2019-04-17T18:24:46Z,"i think for suppress() it's a bug -- and it seems to break sr integration: on restore the schema needs to be fetches from the sr if avro is used, but with `null` topic on serialization the schema would never have be registered correctly and restore would fail with schema not found error. for passing in `null` in general, i think it should be allowed, but i also think it's not really necessary. we can pass in the repartition topic name here, too. with regard to the concern about writing something different into the topic compared to a registered schema: we do this already for windowed changelog topics (note that only the user-data-key is serialized as avro for this case, and we add one or two additional longs and maybe a unique counter before writing into the changelog). if we believe this is an issue, we can fix it, but i would not block this pr for it. it's orthogonal and if we think we need to fix it, we need to fix it for all topics. however, it was not an issue in practice so far, thus, my personal take it, that we should move forward with this pr and pass in the repartition topic name.",0,0.9449991583824158
276391436,5527,bellemare,2019-04-17T19:07:18Z,"i can certainly pass in the repartition topic name for the serializer without any issue for both the serializer and deserializer here. [a link] at that point, it's up to the confluent serde users to complain about their sr being populated with internal topic schemas (an issue we have run into at my company), though it's not a deal breaker. that being said, i am not aware of how to obtain the destination topic in [a link] this processor creates the hash code for the current event from the value serde (ie: confluent's), but has no knowledge of the downstream repartition topic, and thus cannot provide a topic. it is my understanding that this would require information not available to the processor, and so will not work as currently structured. this is the real issue that hasn't been adequately addressed yet, aside from the suggestion from john to drop the hash code optimization. this would skip the whole issue, though it may be sub-optimal in terms of developer experience.",0,0.9827873706817627
276433024,5527,adaniline-traderev,2019-04-17T21:04:07Z,here is another instance where a serializer is called with null topic. i was just wondering if it is possible to pass [code block] as topic name - seemed to worked in my testing scenario...,0,0.9915390610694885
276456917,5527,vvcephei,2019-04-17T22:24:43Z,"at the risk of being annoying, the processor _could_ just make up a topic name to use. this would also fix your problem. right now, i think we have three viable solutions (in order of my preference): 1. generate a topic name for the processor to pass to the serializer 2. pass null to the serializer, forcing confluent's sr and any other serializer/sr to handle nulls gracefully. 3. drop the optimization option 2 is a little unfriendly to confluent sr (and other serializer) implementations, but pragmatically, we _are_ upstream, so we have this leverage we can apply to force them to change.",0,0.8265202641487122
276716731,5527,vvcephei,2019-04-18T15:30:20Z,"further in support of making up a topic name to give the serializer, this is what we're currently doing with state stores, when change-logging is disabled. we unconditionally generate the topic name to pass, given only the appid and storename: [code block] when change-logging is disabled for a store, there is no such topic; i.e., it's a made-up topic name. it's not immediately clear how this is different from something like: `applicationid + ""-"" + processorname + ""-recordhash""`",0,0.9884873628616333
276720367,5527,vvcephei,2019-04-18T15:38:47Z,(tangential: i've just submitted [a link] to fix the suppression serde handling. please feel free to review it!),0,0.789599597454071
277324985,5527,bellemare,2019-04-22T15:24:41Z,"john, i do indeed like that option of `applicationid + ""-"" + processorname + ""-recordhash""` because of the existing precedence with the made-up changelog topic. i believe a decision like this would further align us with the statement ""topic should always be non-null in serialize/deserialize"". so it comes down to 3 options: 1) punt any question on the serde topic nullability by removing the optimization. 2) require that serde topic parameter be nullable by setting topic to null as i have already done in this pr. 3) require that serde topic parameter be non-nullable by creating a fake topic name. in order of preference, i believe 3 is most reasonable, followed by 1. i think 2 is actually fairly reasonable, but least likely to provide a productive way forward because of the existing ambiguous contract. nullability would require that the loosest form of string be used. if no one else objects, i'll go about using a `applicationid + ""-"" + processorname + ""-recordhash""` and post an update shortly.",0,0.6398730874061584
277394421,5527,bellemare,2019-04-22T18:55:23Z,"small change. wasn't able to figure out a clean way to get processorname, but since it's a dummy anyways, i went with context().topic() instead of processorname",0,0.9313784241676331
278785940,5527,guozhangwang,2019-04-26T01:44:10Z,"back to the sr / avro-serde issue we discussed above: after thinking about that a bit more, i'm wondering if we should just fix it by hard coding a serde for the hash value. since our current serde precedence is: 1) user specified serde at the dsl control object. 2) streams hard-coded serde on some special operator (e.g. at `count` operator we hard-code longserde). 3) globally registered serde via config. for the hashvalue, we can treat it as case 2) above and hard-code a serde internally that override the registered serde. and for this foreign key join operation we would not expose control objects for serde overrides case 1), hence this way we should be safe. wdyt?",0,0.9618716835975647
278872345,5527,mjsax,2019-04-26T09:25:08Z,"from my understanding, the design was to first serializer the data, and afterwards compute a hashvalue based on the `byte[]` array. however, for the first step, we don't know the type and thus cannot hard code a serializer. is my understanding incorrect?",0,0.9779738783836365
278953143,5527,bellemare,2019-04-26T13:41:49Z,"this is my understanding as well, which is why i do not see another way forward at the moment.",0,0.9698103070259094
279118475,5527,guozhangwang,2019-04-26T22:14:28Z,"ah okay, i think i was the culprit for the misunderstanding here: i was thinking that we will 1) compute the hash code first, and then 2) serialize that hash code, and hence the issue is that sr also register for a primitive type which i thought should be addressed at streams. now i realize that we are 1) serializing first, and then 2) compute the hash value based on the bytes. this actually makes much more sense since we cannot guarantee all typed objects have a consistent implementation of the `hashcode` interface. in this way though, the bottom line is that we are calling the serializer for getting the bytes, but we are not actually sending the bytes over the wire. and there are serializers like confluent avroserde out there which tries to remember which topics are serialized with which schema, which will then break since streams are not actually using the serialized bytes actually. given that scenario (hopefully i got it right this time :p), i think although it is indeed fixable on confluent avroserde to not register schema given `null` topic name, it is still only one serde and we cannot tell there are no other serdes in the wild that relies on the passed in topic name parameters to bookkeep some mappings, and therefore i think we still need to consider this issue at the streams layer. on this regard my preference is that, at the moment, we just pass in the actual topic name than using a consistent dummy topic name, and my reasoning is that repartition topics are really internal ones specific to the streams app itself, and not supposed to be exposed outside the app (though for changelog topics there may be some exceptions like other apps / consumers may want to read that topic directly, for repartition topics like this one i do feel that they should be really `transient` and not be leveraged by any external clients), and hence protecting such mis-usages sounds like an overkill to me. in the long run, we should consider adding extra apis in the general serde interface which does not take extra parameters (for this purpose i think neither `topic` name or `iskey` boolean should be included) but just object -> bytes and vice versa, to leave no space for any serdes have semantical business logic around those fields. at that time we can then be on the safer side by choose the new apis.",0,0.7657738327980042
279160285,5527,bellemare,2019-04-27T16:22:52Z,"- sounds very reasonable to me. my question is, do i now simply use `context().topic()`? i believe that is correct, since it'll be the topic that we're sourcing the data from, but i just want to verify.",0,0.7945472598075867
279167678,5527,mjsax,2019-04-27T20:37:59Z,"i discussed this with some other people, and somebody mentioned, that for the value we serialize, this value is actually also store in rocksdb (input `ktable`). we also know, that the corresponding `byte[]` are written into the store changelog topic. hence, instead of using the repartition topic, using the changelog topic should be a better option, as it does not leak anything into sr (or whatever other serdes might do with the topic name). even if there is not changelog topic for the input ktable (we do some optimizations and sometimes don't create one (eg, the store might actual be a logical view and is not materialized). but even for this case, using the changelog topic name seems to be save.",0,0.9685994386672974
279514920,5527,bellemare,2019-04-29T19:58:05Z,"`context().topic()` gives the repartition topic name in the serializer, which is what i want. in the processor sections, where i use null, `context().topic()` gives me the input-topic name for the ktable... which is also fine, since the serializer will check against the input topic schema, which must be valid by definition of the data being within the topic... so i suspect this issue can be laid to rest, in line with adaniline-traderev's suggestion. this removes any requirement for the upstream serializer to have to do special work for null values.",0,0.8524550795555115
279749459,5527,bellemare,2019-04-30T13:20:15Z,"after a long discussion, yes, this is what i think is currently the best option. thanks for the suggestion in the first place!",1,0.9917091727256775
280145412,5527,guozhangwang,2019-05-01T17:26:43Z,"i'm not sure i can fully follow the suggestion of using changelog topic v.s. the repartition topic here: are you suggesting to do it universally or just for this case? if it is the latter case, i felt it a bit awkward due to inconsistency with other source `ktable` cases where we will just follow the `sourcenode / recorddeserializer` path to deserialize using the source topic; it if it the first case, that also has some drawbacks since with today's topology generation not all source `ktable`s will need to be materialized to a store and hence not necessary having a changelog topic. i still feel that using the source topic name (and i.e. in this case, the repartition topic) admittedly exposed to sr but is philosophically the right thing to do, and we should consider fixing it on serde apis in the future. wdyt",-1,0.9047991037368774
280147603,5527,vvcephei,2019-05-01T17:33:38Z,might as well just remove it. i think murmur3 is fine.,0,0.9855411648750305
280147762,5527,vvcephei,2019-05-01T17:34:10Z,wouldn't hurt to have some tests for this. maybe copy those from hive as well.,0,0.9803270101547241
280158927,5527,vvcephei,2019-05-01T18:07:46Z,"recommend making this final as well, and just moving the null initialization to the fk constructor.",0,0.9919460415840149
280159330,5527,vvcephei,2019-05-01T18:08:52Z,[code block] we try to avoid unnecessary qualifiers. also applies elsewhere. i won't call them out further at this time.,0,0.989809513092041
280187466,5527,mjsax,2019-05-01T19:34:29Z,"i was just talking about the foreign-key case (not sure why you thought it might be anything else?). my understanding is the following: the contract is that we should pass a topic name into the serializer of which we want to write the data into. this contract breaks if we pass in the repartition topic name, because we write something different into the repartition topic. you are right that the changelog topic might not exist, however, my personal take is, that registering for a non-existing topic, is a smaller violation of the contract that passing in the ""wrong"" repartition topic name. note, that the changelog topic name is conceptually the ""right"" topic name. however, this case would not happen very often anyway (compare examples below). your comment trigger one more thought: the optimization framework could actually check for different cases, and if there is an upstream topic (either changelog or source topic that has the same schema), we could actually use this name. some examples (does not cover all cases): [code block] for this case we need to materialize the base table (that is also the join-table), and the schema is registered on `table-topic` already, so we can pass in `table-topic` to avoid leaking anything. [code block] for this case we materialize the derived table from the filter() and we get a proper `filter-changelog-topic` and we can pass this one. [code block] for this case, the agg result ktable is materialized and we can pass the `agg-changelog-topic` as name. [code block] for this case, the agg result ktable is materialized and we can pass the `agg-changelog-topic` as name, because the filter() does not change the schema. thus, even if the join-input ktable is not materialized, we can avoid to leak anything by ""borrowing"" the upstream changelog topic name of the filter input ktable. [code block] for this case, we need to materialize the result of `mapvalues()` and get a proper changelog topic for the join-input table. [code block] this might be a weird case, for which the base table is materialized, while the input join-table would not be materialized, and also the type changes via mapvalues(). hence, the `table-topic` schema is not the same as the join schema and we also don't have a changelog topic for the join-input ktable. we still use the changelog-topic name of the non-existent changelog topic (of the mapvalues() result ktable). as you can see, we can cover a large scope of cases for which we don't leak anything and can always use a topic name that contains data corresponding to the schema. does this explain my thoughts?",0,0.9688276648521423
280187571,5527,vvcephei,2019-05-01T19:34:49Z,"[code block] in general, we try to retrict visibility to the minimum required. i won't call these out further at this time.",0,0.9932841062545776
280188086,5527,vvcephei,2019-05-01T19:36:37Z,"might be a good idea to throw an exception here, to make sure we don't modify the code later and falsify this assumption.",0,0.97492516040802
280188308,5527,vvcephei,2019-05-01T19:37:30Z,"also, i'm not sure about the fact that configure is called outside of this chain, but close is part of this chain... seems like an ambiguous ownership situation.",0,0.7095276713371277
280189461,5527,vvcephei,2019-05-01T19:41:36Z,[code block] i personally prefer this any time you're specifically referencing the size of an int or long.,0,0.979496419429779
280189627,5527,vvcephei,2019-05-01T19:42:09Z,unused,0,0.96555495262146
280190516,5527,vvcephei,2019-05-01T19:44:58Z,"take this with a grain of salt if you don't like it, but you could save a fair bit of code if you just implement all the `serde`, `serializer`, and `deserializer` interfaces in this one class. (the `serializer()` and `deserializer()` getters can just return `this` in that case). personally, i kind of like this because it puts the serialization and deserialization logic right next to each other, which seems easier to maintain their symmetry.",1,0.6837952733039856
280191410,5527,vvcephei,2019-05-01T19:47:53Z,not sure what this means...,-1,0.5611412525177002
280192430,5527,vvcephei,2019-05-01T19:51:02Z,"my immediate reaction is that it's a little surprising that `byprimarykey := false` means ""use _only_ the foreign key"". boolean flags like this generally contribute to code complexity/obscurity. what do you think about just making separate partitioners for the primary and foreign keys?",0,0.9006463885307312
280193830,5527,vvcephei,2019-05-01T19:55:29Z,it's a little surprising that the store's name is the same as the topic name,0,0.6451358795166016
280194501,5527,vvcephei,2019-05-01T19:57:36Z,"generally, we forbid null keys in ktable apis for this reason. feel free to just drop the record, log a message, and increment the right metric (look around for other null-key checks in the ktable processors).",0,0.9911196827888489
280195544,5527,vvcephei,2019-05-01T20:00:35Z,"just dropping this in before i forget, following kip-307, we need to provide a mechanism to name these operators and internal states.",0,0.9902973771095276
280258689,5527,guozhangwang,2019-05-02T00:07:58Z,"i understand your reasoning now, but still i felt streams should not fix it trying to piggy-back on another topic that happens to be of the same schema that this serde is used for; or rather, i'd prefer to use a non-exist dummy topic than an existing topic if we do not like repartition topics (again, i agree that repartition topic is not ideal, since we are, in fact, not sending the bytes serialized in that way to the topic).",0,0.9736664891242981
281378147,5527,vvcephei,2019-05-06T21:53:40Z,"this reads a little funny to me. can we just say that it's a many:1 join with the other table, and the foreignkeyextractor selects the key in the other table to join with?",-1,0.7410369515419006
281378332,5527,vvcephei,2019-05-06T21:54:17Z,missing ``,0,0.9812607765197754
281378589,5527,vvcephei,2019-05-06T21:55:13Z,feels like this deserves a comment.,0,0.9217818975448608
283745078,5527,bellemare,2019-05-14T11:12:12Z,done.,0,0.9897913336753845
283746677,5527,bellemare,2019-05-14T11:17:24Z,roger that. will review code + apply.,0,0.9942178726196289
283748861,5527,bellemare,2019-05-14T11:24:01Z,done.,0,0.9897913336753845
283756936,5527,bellemare,2019-05-14T11:49:18Z,"done. i copied the tests over. they depend on guava so i added that as a test dependency for the kafka common package. it's also apache-2.0 license so i don't think there's a problem with this, but if there is please let me know.",0,0.61915123462677
283758235,5527,bellemare,2019-05-14T11:52:54Z,"i'm not sure i follow on this point. is it that the serdes may be closed multiple times, once by my combinedkey(ser/de)erializer and also outside of it?",0,0.8034073710441589
283758342,5527,bellemare,2019-05-14T11:53:12Z,"haha yes, programming 101. fixed. :)",1,0.9959101676940918
283759023,5527,bellemare,2019-05-14T11:55:15Z,thanks - removed.,0,0.9063630700111389
283759466,5527,bellemare,2019-05-14T11:56:34Z,deprecated comment. should have been removed. fixed.,0,0.927164614200592
283760279,5527,bellemare,2019-05-14T11:59:01Z,"good point. i think you are correct and that it will be clearer. the irony here is that i never use it with byprimarykey=true... i think i abandoned that part of the code and forgot to clean it up. so, no more boolean, and i will clean up the name.",1,0.9822964072227478
283766444,5527,bellemare,2019-05-14T12:16:09Z,"i think this makes sense. i did spend time tabbing back and forth while writing it, so having them together sounds like a better idea to me. done.",1,0.9253029823303223
283769402,5527,bellemare,2019-05-14T12:24:13Z,done.,0,0.9897913336753845
283779807,5527,bellemare,2019-05-14T12:49:23Z,bit of a typo there. it should be the state store name. this state store is materializing the combinedkey and so should not be associated with any particular topic name. i will clear this up.,0,0.9682656526565552
283816226,5527,bellemare,2019-05-14T14:06:20Z,done. let me know if it's still unclear.,0,0.9788033366203308
283816527,5527,bellemare,2019-05-14T14:06:58Z,done.,0,0.9897913336753845
283830915,5527,bellemare,2019-05-14T14:34:01Z,done.,0,0.9897913336753845
283833355,5527,bellemare,2019-05-14T14:38:09Z,the wiki says it's currently under discussion - has it already been accepted? just curious as to if this work needs to be done for 2.3 if it's not going to be a part of it.,0,0.9585559964179993
284348335,5527,vvcephei,2019-05-15T16:39:07Z,"i think this is fine, but of course i'm not a lawyer. :)",1,0.9967868328094482
284349058,5527,vvcephei,2019-05-15T16:40:44Z,"i haven't reviewed the most recent state, so this might not be relevant anymore, but i just meant that this class is *not* responsible for calling configure, but it *is* responsible for calling close. ideally, the same class should be responsible for both.",0,0.9866763353347778
284349463,5527,vvcephei,2019-05-15T16:41:40Z,"heh, i wouldn't say it's so basic. we use literals all over the code base for this; i've just recently started promoting the use of the constant field instead.",0,0.5416934490203857
284350221,5527,vvcephei,2019-05-15T16:43:25Z,"woah, it looks like the contributor forgot to update the kip. it was accepted. i'll update the wiki.",0,0.9769754409790039
284853800,5527,bellemare,2019-05-16T19:02:00Z,"i put this in its own interface for now because it's not immediately clear where it should live. it needs to be part of statestore, given how all of the various wrapper classes, like the metered, caching and logging ones work. however, i do not want it to be in the readonlykeyvaluestore as it shouldn't be exposed to the outside world.",0,0.9864292144775391
284854252,5527,bellemare,2019-05-16T19:03:19Z,one of the effects of prefixscan needing to be attached to statestore,0,0.9893681406974792
284854473,5527,bellemare,2019-05-16T19:03:57Z,"i'm not really sure how the timestamped statestores work, nor if i even need to support this (since my intention is to only use the non-timestamped versions).",0,0.6868398785591125
284854893,5527,bellemare,2019-05-16T19:05:12Z,"this is a weird one. i end up with a stack overflow error as the above function calls just go back and forth. it seems like it's getting some weird scope problem. this works around it, but i am not sure if i stumbled on an existing bug or if it's something i introduced. i'm just not really sure how what i did could have caused this.",-1,0.9637269377708435
284855494,5527,bellemare,2019-05-16T19:06:52Z,all the above will be cleaned up.,0,0.9942016005516052
284856271,5527,bellemare,2019-05-16T19:09:16Z,"i'm required to supply a materialized store with a name, otherwise the internals of ktableimpl cannot get the name for the state store, and therefore the subscriptionresolverjoinprocessorsupplier cannot access it (fails with npe). this is related to the aforementioned changes to the ktableimpl constructor dropping the `isqueryable` boolean.",0,0.9937573671340942
284857540,5527,bellemare,2019-05-16T19:13:03Z,"am i going to need to handle all of these statestore types? i suspect i'll need to handle both `timestampedkeyvaluestore` and regular `keyvaluestore`, but given that `context.getstatestore` can return any of them, i don't know if i should expect to handle the remainder.",0,0.9616825580596924
287059994,5527,bellemare,2019-05-23T17:44:50Z,"hi guozhang - i noticed that in this pull ( [a link] ) you made it such that the non-queryable store name is no longer obtainable in ktableimpl. i need access to the materializedinternal.storename, but cannot get it anymore (that i know of). do you have any suggestions of what i should do to get it? my only other options appear to be rewriting the ktableimpl constructors back to what they were before, but since you made this change i would like your input. basically, i am now being given materializerinternal.queryablestorename, but i need materializerinternal.storename for when the user does not specify the materialized store (which is frequently). please advise - thanks",0,0.7314887642860413
289081888,5527,guozhangwang,2019-05-30T17:06:36Z,"sorry i've just seen this now. the main motivation of that pr is to avoid materializing state stores unnecessarily and the queryable-name refacotring is sort of a by-product. i was thinking that the parent store names (user-specified or internal) can be accessed from `ktablevaluegettersupplier#storenames`, would that be a possible work-around for you?",-1,0.9823747277259827
289094679,5527,bellemare,2019-05-30T17:38:45Z,"edit: i may have something. i am leaving this here for now to show where i am stuck, but i will update it if i figure out how to properly use your suggestion... - thanks for the reply. basically `ktablea.dojoinonforeignkey(....) ` needs to be able to access `ktablea's` own internal state store to compare the hash values for the workflow we established in kip-213. when `ktablea` is not materialized (internally or by user-specified queryable-name), then i do not think we can query the parents directly since they are by definition different data stores. i do not see how they can slot in as a replacement for the following section (originalsource is what used to be the always-populated statestore, user-specified or internally materialized, represented by queryablestorename) [a link] based on my understanding, it appears i need to have tablea materialized, otherwise i am not sure how to proceed with this ticket. this is basically where i am stuck. i admit i don't know enough about this part of kafka streams to speak with certainty on this.",1,0.9699493646621704
289108628,5527,guozhangwang,2019-05-30T18:13:10Z,"i see. i think the protocol should be that when a join operator requires to access its parents (the joining ktables, for example in this case) it will quire from its parent's `valuegetter`, which would chase up until it finds some processor with associated state stores, or it would go all the way up and require the source ktable to be materialized (see `ktableimpl#valuegettersupplier` --- actually you can find the related materials i got from kafka summit this year, [a link] around slide 56 :) so back to your example, even if the source ktable is materialized without a name, calling a join later should cause its `ktablesource#materialize()` be triggered, where its internal `storename` which is always not-null since it would be auto-generated as `nameprovider.newstorename(generatedstoreprefix)` if not specified, would be assigned to its exposable `queryablename`. and then this name can be accessed by its descent processors in the topology if necessary. hope this would help for you to figure it out.",1,0.976371705532074
289109055,5527,guozhangwang,2019-05-30T18:14:22Z,"note the logic `should cause its ktablesource#materialize() be triggered` may need to be added by you, i.e. the `subscriptionresolverjoinprocessorsupplier` should require to get its parent's valuegetter, which eventually would trigger this function.",0,0.9922009110450745
289121346,5527,bellemare,2019-05-30T18:45:39Z,"i think i solved it with your original recommendation, though by getting the valuegettersupplier as you recommended and not the storenames directly. your follow up message is exactly what i did, so i am glad to have that confirmation. it's passing my tests now and appears to work with and without user-specified queryablestorenames, so i believe this did the trick! thanks for your help! :thumbs_up: now i just need to work on the remaining highlighted issues.",1,0.9963300824165344
289122840,5527,bellemare,2019-05-30T18:49:23Z,overcome by events. no longer relevant :thumbs_up:,1,0.9936815500259399
289124387,5527,guozhangwang,2019-05-30T18:53:10Z,great!,1,0.9950044751167297
296021873,5527,vvcephei,2019-06-20T21:31:11Z,this should get reverted before merging. also with the other commented-out stuff below.,0,0.9891911745071411
296022446,5527,vvcephei,2019-06-20T21:33:08Z,unused,0,0.96555495262146
296022680,5527,vvcephei,2019-06-20T21:34:01Z,"please attribute the source, along with noting the commit hash, as you did for the main code.",0,0.9942723512649536
296023510,5527,vvcephei,2019-06-20T21:36:54Z,"i've always felt that this was a weird use of the `valuemapper` class, elsewhere. what do you think about using `java.util.function.function ` instead?(just now having this thought)",-1,0.8915712833404541
296023880,5527,vvcephei,2019-06-20T21:38:09Z,"thanks! you can ""resolve"" this comment to clean up the pr.",1,0.9836275577545166
296025422,5527,vvcephei,2019-06-20T21:43:18Z,"documentation nit. since this is such a complicated operation, i think we might want some more verbose comments here. something like:",0,0.936678409576416
296025600,5527,vvcephei,2019-06-20T21:43:54Z,"as mentioned in the ktablerepartitionerprocessorsupplier, i'm wondering if we can do without this partitioner by using combinedkey only in the prefix-scan store, and not over the wire?.",0,0.9922745823860168
296026278,5527,vvcephei,2019-06-20T21:46:07Z,"""thisstatestorename"" is a little esoteric :) can we try to make this more self-documenting? i'm assuming that you're copying this convention over from the other join, where we say ""this"" and ""other"", but there's a lot going on here. maybe you can establish a different convention, like ""primary key table"" and ""foreign key table"", or ""left side"" and ""right side"", etc..",1,0.9775984287261963
296026592,5527,vvcephei,2019-06-20T21:47:06Z,"as i understand it, the value getter interface is mainly to support looking up values in another ktable. it's fine (and more direct) for you to just wire the same state store in to both processors. then, you won't need a ""prefix value getter"" interface anymore.",0,0.9853353500366211
296026762,5527,vvcephei,2019-06-20T21:47:34Z,"this doesn't seem quite right... i expected to see a *this* joiner handling updates from this table, and and *other* joiner handling updates from the other table (the subscriptionresolverjoinprocessorsupplier), followed by a merge node, but it looks like we're doing something else here?",0,0.5452346801757812
296026938,5527,vvcephei,2019-06-20T21:47:58Z,"didn't totally follow this todo... the pk-side ktable needs to be copartitioned with the input to the ""subcriptionresolverjoinprocessor"" the fk-side ktable needs to be copartitioned with the output of the ""ktablerepartitionerprocessorsupplier"" in both cases, there's one pre-determined topic and one repartition topic we control, so the co-partitioning should be trivial, unless i'm missing something...",0,0.9575495719909668
296027875,5527,vvcephei,2019-06-20T21:50:58Z,"can we assume both keys are not null (i.e., can we add a condition to skip any null-key updates in both processors so that we can rely everywhere on the fact that keys can never be null? other stateful operators already do something similar (see aggregations, for example), and there are metrics and logs for it. edit: i later figured out that this is part of the prefix-search magic.",0,0.9939224123954773
296028126,5527,vvcephei,2019-06-20T21:51:55Z,"not sure i follow what this case means edit: i later figured out that is a ""magic"" case for creating search prefixes...",0,0.7465900778770447
296028311,5527,vvcephei,2019-06-20T21:52:35Z,"can we name the type parameters pk and fk here and elsewhere, just so we don't have to remember which is which?",0,0.9938249588012695
296028562,5527,vvcephei,2019-06-20T21:53:35Z,"regarding `&& foreignvalueandtime.value() != null`, is this because we're only doing an inner join?",0,0.9943755865097046
296028691,5527,vvcephei,2019-06-20T21:54:08Z,there's a protocol for handling cases like this. check out the aggregate processors.,0,0.9933199882507324
296028773,5527,vvcephei,2019-06-20T21:54:26Z,"not sure if identity is sufficient here, since these objects come from deserializers (i.e., this condition may _never_ be true) also not sure if we can rely on `equals` to be any better than identity. i'm wondering, rather than checking inside this processor, we should ask the upstream table to suppress such no-ops, similar to how we request `sendoldvalues`. then, the upstream processor can perform this check on the serialized form of the data and save a bunch of work downstream (aka, right here).",0,0.836733341217041
296028913,5527,vvcephei,2019-06-20T21:55:02Z,"oooh... for reference, i just spent 30 minutes trying to figure out how the prefix scan is correct, only to realize that you have created a special ""search key"" that just happens to produce a prefix of the ""stored key"" when used in conjunction with your combinedkeyserde. this seems like a _very_ mysterious implicit coupling relationship among 4 different classes. there's got to be a better way...",-1,0.863219141960144
296028980,5527,vvcephei,2019-06-20T21:55:17Z,we'd better close this iterator.,0,0.9478012919425964
296029149,5527,vvcephei,2019-06-20T21:55:53Z,"maybe a nit, this sentinel is constant and small, so caching it in a static field is probably valuable.",0,0.9701359272003174
296029321,5527,vvcephei,2019-06-20T21:56:30Z,"can the key actually be an empty array? if so, it's not a safe sentinel value for null. the hashed value of an empty array is `[-7122613646888064702, -8341524471658347240]`. it seems like we could do better by actually using an empty array as the sentinel-hash representing a null value. then, we don't have to send any bytes over the wire to represent null, or store any bytes for that matter.",0,0.9870100021362305
296029499,5527,vvcephei,2019-06-20T21:57:20Z,"alternatively, does this mean there's no need to notify the other side at all, and we can just proceed to recompute the join result? might break semantics, though...",0,0.9632759690284729
296029644,5527,vvcephei,2019-06-20T21:57:52Z,"if we move the primary key into the value and just forward to the foreign key, we can drop the extra partitioner and also extra serde from the wire protocol",0,0.9932917356491089
296030000,5527,vvcephei,2019-06-20T21:59:09Z,"this hash _must_ match the one we produce in ktablerepartitionerprocessorsupplier. if we _ever_ produce a different hash for the same value, we will _lose data_. in light of this, it seems like both locations really need to reference the same logic somewhere, either in a static method somewhere, or passed in as a ""hash function"" over the values. as an illustration of the legitimacy of the concern, you're using a different topic here than in the other location, which could result in a different serial form of the same data.",0,0.9778504967689514
296030317,5527,vvcephei,2019-06-20T22:00:19Z,"maybe a nit... maybe move this byte to the front and make it a bit field, so that we have a straightforward path to pack more boolean flags into the value in the future.",0,0.9575653076171875
296031064,5527,vvcephei,2019-06-20T22:03:10Z,"adding this new interface to keyvaluestore may have some serious implications for implementers. are we sure we have to? at least, we need to add a default implementation.",0,0.7884804010391235
296031167,5527,vvcephei,2019-06-20T22:03:33Z,"note this isn't a byte[], but a k. not actually sure if this api makes sense. for example, what would this api mean if my key type is uuid or mycustomrecord? in other words, only some key types even have prefixes.",0,0.9419559836387634
296033792,5527,vvcephei,2019-06-20T22:13:07Z,"sorry, feeling a bit dense... is this right? it seems like it would cut off some results that should be at the end of the range. in particular, it seems like it cuts off keys like `[prefix]ff01`, since that key is strictly greater than `[prefix]ff`. you might want to take a look at the function that rocksdb uses to compute the range-end for range queries.",-1,0.9837772846221924
296034425,5527,vvcephei,2019-06-20T22:15:38Z,"just a thought, does rocks return in sorted order? if so, we can probably do better by comparing backwards from the end of the prefix. then again, that might screw up cache locality, not sure...",0,0.7877092957496643
296034482,5527,vvcephei,2019-06-20T22:15:50Z,probably should be illegalstateexception,0,0.7891701459884644
296034728,5527,vvcephei,2019-06-20T22:16:47Z,"huh, neat... as i read it, the serial format for our combinedkeys is [fk length][fk bytes][pk bytes] this means that all the records with same-length foreign keys are sorted together, a prefix scan won't suffer any ambiguity between fk and prefixes of the pk. this seems to avoid a problem we face in the session window store. putting it in terms of this key if we have two records with r1.fk=aa r1.pk=b and r2.fk=a and r2.pk=ab, they are both serialized as aab, and in particular, a prefix scan would get pseudomatches that are out of the range and have to handle it by decomposing the serial form and then double-checking the prefix. but since you prefix by the size of the fk, there's no ambiguity, even if the fks are variably sized! but it is worth noting that this depends on the exact serialization format.",1,0.791383683681488
296034895,5527,vvcephei,2019-06-20T22:17:23Z,"this is due to the subclassing. if you instead wrap and delegate, this won't be a problem.",0,0.9772449135780334
296857031,5527,bellemare,2019-06-24T18:29:39Z,"yep, this is the intended design. it definitely is sensitive to how the serialization is handled, but i think that it's okay as it currently stands.",1,0.7753132581710815
296858048,5527,bellemare,2019-06-24T18:31:57Z,"yep. i'm taking a look at this now and i don't know what i was thinking. i have tested some of the submap logic and it indeed seems that i am cutting off some values. thank you for catching this, ugh. range is a bit different because it specifies the entire key, whereas with prefix we're only concerned with the first n bytes of the key. i will think on this some more. i am wondering if it's best to just wrap the entire thing in an iterator that compares the prefix on each ""next()"" call, and only returns those that meet the full prefix, much like i already have established in the rocksdbdualcfprefixiterator.",-1,0.9916081428527832
296898877,5527,bellemare,2019-06-24T20:22:38Z,"okay, so i believe that i have figured out what i was doing wrong... i needed to do: `map.submap(fromkey, true, tokey, false);` and set tokey to be fromkey + 1 as a byte array. i am currently testing it and it seems to be working, but i want to test further in case i am misunderstanding the submap results.",1,0.534673273563385
296908737,5527,vvcephei,2019-06-24T20:48:08Z,"yeah, that last thing sounds like what i had in mind. the rocksdb function i had in mind is one that basically computes `+1` for an array of bytes (i.e., iterate backwards from the end to find the first byte that isn't already `0xff` and add `1` to it).",0,0.982774019241333
298135494,5527,bellemare,2019-06-27T11:45:43Z,:thumbs_up:,1,0.9533231854438782
298136127,5527,bellemare,2019-06-27T11:47:36Z,cleaned.,0,0.9603179693222046
298137597,5527,bellemare,2019-06-27T11:52:05Z,"done. hash included, along with link to file in github.",0,0.9898937344551086
298138716,5527,bellemare,2019-06-27T11:55:17Z,"to me it felt natural as i wanted to apply a mapping function to a value and obtain a result. semantically they feel the same though, so i don't really care one way or another. if you think it's more appropriate to go with `java.util.function.function ` i will make the change.",0,0.8900448083877563
298143733,5527,bellemare,2019-06-27T12:10:41Z,"according to their wiki ( [a link] ) it does provide a sorted iterator. the range function operates on this principle too, which confirms this to be the case in the code. we have to validate the entire prefix for each event either way, forwards or backwards. as soon as we run into an event which does not have the full prefix, we terminate and hasnext() will from then on return false. i don't think there's anything in terms of efficiency to be done here, but let me know if i misunderstood.",0,0.9724589586257935
298143789,5527,bellemare,2019-06-27T12:10:51Z,yup. thanks!,1,0.9906736016273499
298198372,5527,bellemare,2019-06-27T14:11:53Z,will be adding this in shortly.,0,0.9894038438796997
298669556,5527,bellemare,2019-06-28T16:45:02Z,i'll do my best to clarify the entire operation in the next commit.,0,0.9746427536010742
298670452,5527,bellemare,2019-06-28T16:47:50Z,"i'm fine with using the ""primary key table"" and ""foreign key table"" lingo, but given that this was stripped out of the function name somewhere previously in the review, i wasn't sure it was ""allowed"". to be frank, _i_ find it confusing to talk about this as if it's _not_ a `foreignkeyinnerjoin` and `foreignkeyleftjoin`, but instead some sort of special-case normal `join` and `leftjoin`. i'm just going to go ahead and call it what i want internally, and then we can all bicker about the bike-shed name afterwards. :)",-1,0.828611433506012
298799471,5527,bellemare,2019-06-29T13:20:55Z,"it just means the fk is the same - the hash may have changed. we need to update the hash in the subscription state store on the rhs, otherwise valid updates coming from the rhs table will join on a stale hash, and be discarded during the resolver phase (oldhash != currenthash).",0,0.9929895401000977
298799689,5527,bellemare,2019-06-29T13:30:26Z,"yep, you're correct. i believe this is an artifact left over from the initial design, when i used to send (combinedkey , v) as the event, and it was either put the fk in the key or in the value. i'll adjust the code accordingly.",0,0.9841821789741516
298801769,5527,bellemare,2019-06-29T14:52:45Z,"okay, while i took it out from over-the-wire, but we still need the serde for the `prefixscanstorebuilder`, since combinedkeys are stored to the changelog topic. the end result is that the only thing that is removed is the custom partitioner, which i like as i we no longer rely on a copied + pasted + slightly-edited partitioner.",0,0.822451651096344
298802096,5527,bellemare,2019-06-29T15:03:53Z,"while it could go into a static method, it will always need a topic name unique between all topologies because of the weak interface definition of `serialization`. it is ambiguous as to whether topic can be null in `serialize(topic,data)`. from experience, the confluent avro serde _will_ register once with a null topic, but then will forever give already-registered exceptions for all remaining registrations. this means that we will forever need some unique dummy topic per foreignkeyjoin schema, and it will need to live in some common place. i can create a dummy topic name in the `ktableimpl.doforeignkeyjoin()` and pass in the necessary common reference to both `subscriptionresolverjoinprocessorsupplier` and `ktablerepartitionerprocessorsupplier`. this will ensure that `serialize(topic,data)` is consistent, since the topic will not rely on the topology (outside of uniqueness).",0,0.9825496673583984
298802436,5527,bellemare,2019-06-29T15:16:43Z,"changed to instructions, no longer relevant",0,0.978847324848175
298802801,5527,bellemare,2019-06-29T15:31:05Z,"i am not sure we have to add this to all keyvaluestores. i had previously tried to limit it to the rocksdb instance only, but previously-given feedback suggested that it should support both caching and logging for performance related reasons. what we have now is due partially to a snowballing of inclusion of caching, logging and rocksdb store, and partially due to my thinking that ""if range can work in all tables, why not prefixscan since it's basically the same operation?"" the prefixscankeyvaluestore needs to support both get() (for lhs->rhs lookup) and prefixscan() (rhs->lhs lookup), and get() is tied to readonlykeyvaluestore. i also didn't want to expose prefixscan to the outside world via readonlykeyvaluestore. if you (or anyone else) feels strongly about removing it, please direct me on how you would see best to limit it to rocksdb + caching + logging. i am not confident in messing with the existing structure too much, so guidance / direction on it would be preferred than leaving it strictly up to me. :thumbs_up:",0,0.9551778435707092
298803316,5527,bellemare,2019-06-29T15:49:33Z,"the key can be anything. the issue is that murmur3 cannot hash a null to a unique sentinel that wouldn't also be available by hashing another value. so any value we choose will not work. that being said, i could do something like (you mentioned using a bit in another comment): hash is null: `{1-bit nullhash = true}{remaining-serialized-data}`. hash is notnull: `{1-bit nullhash = false}{2-bytes hash}{remaining-serialized-data}`. the only thing i am rusty on is how the bit is handled in over-the-wire communication. would it not simply end up being stored as a full byte anyways? in this case, we're adding a full byte to each message just to indicate if the hash is actually null, and this is in both directions. however, for correctness sake i believe we should do this as i don't think there is any safe sentinel we can use. if we want to save space, we have two more options. 1) fold this in with the version byte, and only give version 7-bits. {1-bit-nullhash}{7-bit-version} 2) can also switch to hash64 (50% chance of collision in ~4 billion events) instead of hash128 (50% chance of collision in ~1.844674407e19). for the sake of moving this along, i will just include a single-bit of isnullhash and take it from the version byte. this should satisfy our needs.",0,0.8831130862236023
298808164,5527,bellemare,2019-06-29T18:48:06Z,"i folded all this in, the 7-bit version and the 1-bit and the 1 bit ""isnull"". i'll resolve this one now and if it's no good for whatever reason then just open another.",0,0.9923592209815979
298808919,5527,bellemare,2019-06-29T19:20:22Z,overcome by events.,0,0.9661889672279358
298809600,5527,bellemare,2019-06-29T19:50:15Z,removed in latest version.,0,0.9863874912261963
298809661,5527,bellemare,2019-06-29T19:52:20Z,"all joins are being executed in the subscriptionresolverjoinprocessorsupplier. everything comes in from the subscriptionresponsewrapper topic, so there is no this/other.",0,0.9951700568199158
298809878,5527,bellemare,2019-06-29T20:03:23Z,"sorry, my comment was not very clear. currently what you described does work for a single `lefttable.joinonforeignkey(righttable, ...)`. however, i was concerned how it would work when we start chaining them together. i currently have a (somewhat complexly written) integration test (`ktablektableforeignkeyinnerjoinmultiintegrationtest`) where i do: [code block] and then: `table_1.joinonforeignkey(table_2, ... ).joinonforeignkey(table_3, ...)` the test does not pass (times-out after 60s of waiting) when `table_1_size != table_3_size` , using the co-partitioning as you suggested above. i'm not familiar enough with what's going on under the hood to explain it, nor have i spent much time digging deeper, but it seems that the partition distribution for chained `joinonforeignkey` needs some attention.",-1,0.9675716161727905
298810060,5527,bellemare,2019-06-29T20:12:27Z,it would make it inconsistent with the types in ktableimpl. i standardized them across all the code in this pr because once learned it's consistent everywhere you look. i am hesitant to change them because the next comment will be someone asking to make them consistent with ktableimpl...,-1,0.704910933971405
298864664,5527,bellemare,2019-07-01T02:18:54Z,"i will remove this. i am not sure how to go about asking the processor to not send no-ops, but unless it's built in i'd like to limit the scope. this pr is big enough that i don't want to add more than necessary.",0,0.9795499444007874
298865371,5527,bellemare,2019-07-01T02:26:44Z,"i will add more comments to make it clearer. the coupling is indeed tight because it's based strictly on the byte ordering of the key. i couldn't think of a better way, so if you think this is a deal-breaker please let me know and we'll throw it back on the mailing list.",0,0.979877769947052
298866241,5527,bellemare,2019-07-01T02:35:21Z,"corrected the comments - this is probably also related to your question about where should the prefixscan even go. the only real requirements are rocksdb, logging and caching stores. since they're so intertwined, it's hard for me to give you a good answer on if this should be here or not. if we have to ask, probably not, but tbh i'm really looking for guidance on this since i'm a bit over my head on where it should go. i have asked for feedback on this previously, but so far you're the only one to take not.",0,0.7429096102714539
299600884,5527,bellemare,2019-07-02T17:34:00Z,"can't handle multiple input partition counts if we chain foreignkeyjoins together. i did a few hours of investigation into this and it appears it's related to a combination of: a) multiple topicgroups ( [a link] ) b) creating sinks (for both the subscription and subscriptionresponse topics) c) how sinks are handled with copartitioning and a per-topic-group way: => the result is that sink topics are assigned the maximum number of partitions in the topicgroup (as all sink topics are treated - [a link] ""if this topic is one of the sink topics of this topology, use the maximum of all its source topic partitions as the number of partitions"" the result is that we end up with the wrong (ie: a maximum) number of partitions for some but not all of the internal repartition topics. for instance, if i have the following: `left.joinonforeignkey(rightonetable, named.as(""join1""), ...).joinonforeignkey(righttwotable, named.as(""join2""), ...)` [code block] i would expect to have the following topics with partitions: [code block] instead, due to the aforementioned dynamics, i get: [code block] as a result, i will not be supporting variable partition counts in this pr, but will put it off until after this one is comitted and roll it in its own pr. the scope on this pr is large enough.",0,0.9912663102149963
299612961,5527,bellemare,2019-07-02T18:01:42Z,"true - the unfortunate part is that wiring it in and getting it via `processorcontextimpl.getstatestore(..)` ( [a link] ) is that it does not match any of the store types, and so cannot be accessed that way. i can modify that further, but this is all due to the same original question - where in the interface definitions should `prefixscankeyvaluestore.prefixscan()` live?",0,0.8115651607513428
307344539,5527,vvcephei,2019-07-25T15:01:25Z,"hey , i think your feeling is reasonable, but to me it actually supports using a function more than using a valuemapper. what i mean is, you just want to run a _function_ on the value and obtain a result. the valuemapper implies you're mapping the value to a new value to produce a new ktable with the result value. in other words, it only makes sense in a `mapvalues()` operation. the valuemapper interface was introduced for the `mapvalues()` operator, and we abused (along with others of our functional interfaces) by using it other places where we just want a unary function (because java had no stdlib functions at that point). now that java has function, we can clean this mess up. right now, though, i'm just proposing not to create more mess that we have to clean up later. if people disagree with using function (for some reason), then we should make a new semantically correct interface instead of using valuemapper.",0,0.7319604754447937
307349571,5527,vvcephei,2019-07-25T15:10:40Z,"ok, just for the record, i think we have to fix this before merging... i'll see if i can figure it out.",0,0.9620522856712341
307394163,5527,bellemare,2019-07-25T16:39:15Z,i had researched it more extensively a few weeks ago but just realized now i forgot to post the findings. they were pending publishing in my own review...,0,0.9585586190223694
307394639,5527,bellemare,2019-07-25T16:40:15Z,i've just posted the findings. i am concerned about scope creep if we tinker with the copartitioner. as it stands right now i think the size of this pr is intimidating enough.,-1,0.9634842872619629
307397528,5527,bellemare,2019-07-25T16:47:19Z,function it is. your perspective on the misuse of valuemapper makes sense.,0,0.983644962310791
311715968,5527,abbccdda,2019-08-07T19:05:58Z,nit: newline,0,0.987245500087738
318776174,5527,cpettitt-confluent,2019-08-28T20:26:53Z,"it might be better to throw if there is overflow. otherwise the return prefixed key does not follow the protocol in combinedkeyschema. i don't think it would happen in practice, but if we're going to address it one way or the other i would probably lean toward explicitly failing on overflow. otherwise we should at least doc that this widens the array of bytes in the case of overflow.",0,0.9847701787948608
318778418,5527,cpettitt-confluent,2019-08-28T20:32:27Z,"as this is public documentation, it would be nice to explain what named is used for.",0,0.9873101711273193
318778654,5527,cpettitt-confluent,2019-08-28T20:33:05Z,as this is public documentation it would be nice to have documentation on it. it looks like it would be the same as the previous sans named.,0,0.977002739906311
318778736,5527,cpettitt-confluent,2019-08-28T20:33:18Z,same comment as above.,0,0.9935632944107056
318802475,5527,cpettitt-confluent,2019-08-28T21:32:47Z,do we need to be careful here about getting dos'd by an extreme length either due to malice or accident? do we have a key limit anywhere else that we could use to assert that `foreignkeylength` is within acceptable limit?,0,0.9888530969619751
318803831,5527,cpettitt-confluent,2019-08-28T21:36:44Z,"it seems given this that we can at least assert that foreignkeylength is less than or equal to 2147483643 bytes. though a better bound, if there is one, would be nice.",0,0.981842041015625
318813557,5527,cpettitt-confluent,2019-08-28T22:07:33Z,should this be sent only when the old and new key do not match?,0,0.9914476871490479
318814883,5527,cpettitt-confluent,2019-08-28T22:12:16Z,looks like dead code that can be removed?,0,0.9886300563812256
318816694,5527,cpettitt-confluent,2019-08-28T22:19:04Z,`value.getforeignvalue() == null && (!leftjoin || currentvaluewithtimestamp == null)` ?,0,0.992908239364624
318817354,5527,cpettitt-confluent,2019-08-28T22:21:28Z,minor: order of visibility keywords in field declarations are reversed here vs. other places in the code.,0,0.9702278971672058
318819397,5527,cpettitt-confluent,2019-08-28T22:30:04Z,"maybe worth an assert here that version fits in 7-bits? not that we're going to hit it any time soon, but if we set the 8th bit then given the semantics below we are considered to have a null hash.",0,0.9874122142791748
318820465,5527,cpettitt-confluent,2019-08-28T22:34:09Z,same comment re. version as above.,0,0.9946752786636353
318821811,5527,cpettitt-confluent,2019-08-28T22:39:37Z,`cache.isempty()` seems sufficient? curious why you needed to change this.,0,0.9847387075424194
318822498,5527,cpettitt-confluent,2019-08-28T22:42:21Z,curious: is there any functional change by moving this code?,0,0.9849307537078857
318822822,5527,cpettitt-confluent,2019-08-28T22:43:38Z,i think we can revert this for cleanliness.,0,0.9852352142333984
318822997,5527,cpettitt-confluent,2019-08-28T22:44:19Z,"given the size of this commit, it seems worth reverting non functional changes like this.",0,0.9817226529121399
318823102,5527,cpettitt-confluent,2019-08-28T22:44:43Z,same as last few comments :),0,0.9916377663612366
318823246,5527,cpettitt-confluent,2019-08-28T22:45:17Z,same as above.,0,0.9922299981117249
318824005,5527,cpettitt-confluent,2019-08-28T22:48:25Z,minor: you could get away with keeping this mutable if you initialize it here and do `addall` with `topicstocopartitiongroup.get` below. just check `copartitiongroup.isempty` to determine if you can break.,0,0.9918803572654724
318824758,5527,cpettitt-confluent,2019-08-28T22:51:26Z,is it? :d,1,0.9936630725860596
319131058,5527,bellemare,2019-08-29T15:23:00Z,"my understanding is that if the foreign key is too large it couldn't have been written as a message to kafka (exceeds maximum batch/message size). accordingly, the maximum size of the foreignkey is limited to the maximum allowable batch/message size. is this incorrect?",0,0.9917370676994324
319136512,5527,bellemare,2019-08-29T15:33:33Z,"i believe we chose this because with a regular join we propagate the same output value for each event sent in. if there are n events with the same old and new state, we output n joined events, even if they are the same. if we do not send when oldkey == newkey, then we swallow + hide the event.",0,0.9868218302726746
319136649,5527,bellemare,2019-08-29T15:33:50Z,yep. i'll go through and try to clean it up. lots of stuff changed and got reverted unsuccessfully.,0,0.8119578957557678
319137563,5527,bellemare,2019-08-29T15:35:36Z,"haha, good eye. i didn't notice the repeated logic at the end... sigh... thanks.",1,0.9907207489013672
319138304,5527,bellemare,2019-08-29T15:37:01Z,:thumbs_up:,1,0.9533231854438782
319139534,5527,bellemare,2019-08-29T15:39:27Z,i can put some validation in the serializer since it's the one that's forcing a byte into 7-bits.,0,0.991005539894104
319142830,5527,bellemare,2019-08-29T15:45:25Z,same solution - will validate in serialization since it's the serializer that is limiting it to 7 bits.,0,0.994244396686554
319144549,5527,bellemare,2019-08-29T15:48:52Z,"this is an artifact of a broken trunk that i needed to fix to get this to compile a few weeks back. currently in trunk it seems to be fixed ( [a link] ) , so i'll resolve this when i make a new pr rebasing this off of the murmur3hash pr that needs to be resolved prior....",0,0.9470822811126709
319150616,5527,cpettitt-confluent,2019-08-29T16:02:01Z,"my bad! i thought this was coming from a topic, but this is just for the prefix matching in the store. this can be closed out.",-1,0.995654821395874
319153538,5527,cpettitt-confluent,2019-08-29T16:08:32Z,":thumbs_up:makes sense. my understanding is that sending an output even for each input is best effort, e.g. the output event is not emitted if the hash changes more quickly than the updates get through the rhs.",1,0.7832896113395691
319153674,5527,cpettitt-confluent,2019-08-29T16:08:49Z,:thumbs_up:,1,0.9533231854438782
319172463,5527,bellemare,2019-08-29T16:53:53Z,"there was at one point - i believe i was using the storebuilder to build the store, then i had to connect it afterwards. it would throw an exception if i tried to connect a store that was not built yet. the work that john r did to fix up the topology seems to have remedied it, so i'll revert the order back to the original order.",0,0.9850559234619141
319174179,5527,bellemare,2019-08-29T16:58:03Z,"yes, i will do so. this was an artifact of my ide organizing the imports i believe.",0,0.9804410934448242
319195586,5527,bellemare,2019-08-29T17:50:08Z,deftly overcome by events! will remove the whole thing.,-1,0.9810662269592285
319198127,5527,bellemare,2019-08-29T17:56:13Z,"i'll leave that up to to comment on, as he is the one who made these changes... . actually, now i'm not sure why this change is in here, i think this was supposed to be in its own pr? john?",0,0.9218299388885498
319261222,5527,bellemare,2019-08-29T20:38:03Z,"i see what you're saying, but i am not sure it's proper to put the exception in the bytes.increment as it's doing what it says it should do (ie: increment the byte array by 1). john and i noticed this before, but since combinedkeyschema always starts with a positive integer, wrap-around won't affect us in either case. as john noticed 22 days ago: [code block] we're implicitly protected as long as the maximum of positive integers are always 0x7fff ffff.",0,0.9765863418579102
319263781,5527,bellemare,2019-08-29T20:45:03Z,:thumbs_up:,1,0.9533231854438782
319275297,5527,cpettitt-confluent,2019-08-29T21:16:08Z,good point. that seems to support an assertion / exception vs. adding behavior we don't expect to run though? if we overflow clearly there is a logic error somewhere in the callee and it would be better to find out directly vs. as a side effect of behavior we don't expect to exercise?,1,0.7905920147895813
320388724,5527,bellemare,2019-09-03T17:24:51Z,"yep, fair enough. i'll make it such that it'll throw an error if it would result in a wrap around. the caller will have to allocate additional room if they want it to roll over.",0,0.9492232799530029
320395570,5527,bellemare,2019-09-03T17:40:50Z,indexarrayoutofbounds? or do you have something else in mind? i can't seem to find a reasonable choice from the list...,0,0.9804996848106384
320401139,5527,cpettitt-confluent,2019-09-03T17:53:34Z,"i don't have a strong opinion. i suppose `illegalargumentexception(""overflow"")` would be fine. that seems most appropriate, especially if we document that increment only works for inputs up to max int - 1.",0,0.930888831615448
320401556,5527,cpettitt-confluent,2019-09-03T17:54:35Z,"btw, this is not a blocker to me. i think if we get the one change we discussed above (exception on overflow) that things are looking pretty good from my perspective. i'll do a pass on the tests too.",1,0.8796501755714417
321287361,5527,bbejeck,2019-09-05T14:09:51Z,nit: `prefix_scan_processor` and `join_on_foreign_key_name` names are unused.,0,0.994387149810791
321398773,5527,vvcephei,2019-09-05T17:49:17Z,"thanks, -confluent . i think we're better off favoring immutability unless there's a significant readability or performance advantage to mutable state.",1,0.9616532325744629
321400745,5527,vvcephei,2019-09-05T17:53:29Z,"using `size()` was actually identified as a performance regression. trunk is now using `isempty()`: [a link] regardless, this line should not appear in your diff at all. i'd just smash it with whatever is in trunk.",0,0.9874017834663391
322342024,5527,bbejeck,2019-09-09T16:40:07Z,"although this class is in an `internals` package, some brief javadoc would be helpful. the overall flow is complex, and a short description will help grok the functionality and where the class fits in the flow of things. same thing for all other classes in `internals.foreignkeyjoin` so i won't repeat the comment.",0,0.9622300267219543
322368963,5527,bbejeck,2019-09-09T17:42:07Z,this is unrelated to this pr but i'm wondering the `processorgraphnode` _always_ used as the node name we could simplify this class. but let's just leave it as is for now.,0,0.991664707660675
322376681,5527,bbejeck,2019-09-09T17:59:31Z,"nit: the test doesn't cover `prefixbytes` method. i'm not a proponent of 100% test coverage always, but imho that method is a main factor in the ""other->this"" join so it should have coverage in this case.",0,0.8166266083717346
322855625,5527,bellemare,2019-09-10T16:55:24Z,"according to the commits i made, this should be removed by now... not sure why it's still showing up in the review...",-1,0.5832050442695618
322918610,5527,bbejeck,2019-09-10T19:20:26Z,"i think it _may_ be possible to implement the integration tests using the `topologytestdriver`, the benefit of which would be that we could get coverage reports and the tests run faster without the embedded broker. the test cases look complete to me, but without coverage reports, we could be missing something.",0,0.9711096286773682
322919371,5527,bbejeck,2019-09-10T19:22:00Z,leftover debugging?,0,0.9827262163162231
323413934,5527,bellemare,2019-09-11T19:15:44Z,"i'm not familiar enough with this myself. if it's problematic i would be willing to address it in another pr, as i'm experiencing some fatigue on this one.",0,0.5888833403587341
323413988,5527,bellemare,2019-09-11T19:15:53Z,very much so. thanks!,1,0.993065357208252
323985652,5527,mjsax,2019-09-12T23:12:49Z,"seems we need to update `streamsresetter` to delete those topics, too?",0,0.9931166172027588
323985742,5527,mjsax,2019-09-12T23:13:15Z,as above.,0,0.9881609678268433
325438742,5527,vvcephei,2019-09-18T00:27:57Z,"yes, we do. good catch!",1,0.9951481223106384
326269999,5527,bbejeck,2019-09-19T16:30:05Z,"nit: enabling optimizations is a two-step process. in addition to setting the `optimize` flag in the configs, we also need pass in the configs to the overloaded `streambuilder#build(properties)` method here.",0,0.9915288686752319
326272813,5527,bellemare,2019-09-19T16:36:36Z,"whoops! that's not a nit, that's just a miss on my part. thanks!",1,0.9860949516296387
426783396,8680,abbccdda,2020-05-18T17:25:17Z,nit: we could use { versionrangetype} to reference to the classes.,0,0.9947408437728882
426783652,8680,abbccdda,2020-05-18T17:25:44Z,could be simplified as new features<>,0,0.9903427362442017
426783720,8680,abbccdda,2020-05-18T17:25:51Z,same here,0,0.99204421043396
426805425,8680,abbccdda,2020-05-18T18:06:33Z,nit: extra line,0,0.8243594765663147
426806321,8680,abbccdda,2020-05-18T18:08:17Z,is this function only used in unit test?,0,0.9941153526306152
426806671,8680,abbccdda,2020-05-18T18:09:02Z,we should ensure `features` is not null,0,0.993674635887146
426807646,8680,abbccdda,2020-05-18T18:10:58Z,"nit: just a personal preference, but getting one less internal reference to a public function `all` makes the code usage check easier, like `features.get(feature)`.",0,0.9634724855422974
426808456,8680,abbccdda,2020-05-18T18:12:36Z,"also if we could potentially have a not-found feature, we should either fail with illegal state, or make the return type `optional `",0,0.9918551445007324
426808879,8680,abbccdda,2020-05-18T18:13:21Z,maybe rephrase as `a map with the underlying features serialized`,0,0.9920194745063782
426809504,8680,abbccdda,2020-05-18T18:14:35Z,s/deserializes/deserialize,0,0.9771283864974976
426810909,8680,abbccdda,2020-05-18T18:17:09Z,we should check `null` for other.,0,0.993398904800415
426829453,8680,abbccdda,2020-05-18T18:53:37Z,nit: might make sense to build meta comment for parameters: [code block],0,0.9907461404800415
426836963,8680,abbccdda,2020-05-18T19:07:57Z,s/ !featuresandepoch.isempty / featuresandepoch.isdefined,0,0.9551029205322266
426838064,8680,abbccdda,2020-05-18T19:10:06Z,this is because the write path has not been implemented?,0,0.9927574396133423
426865773,8680,abbccdda,2020-05-18T20:07:15Z,nit: add a line,0,0.9932920932769775
426873359,8680,abbccdda,2020-05-18T20:23:39Z,i think we need to bump the schema version to 4? same with `apiversionsrequest.json`,0,0.9936597943305969
426875434,8680,abbccdda,2020-05-18T20:28:01Z,"looks like we have some gaps for unit testing `apiversionsresponse`. could we add unit tests for this class, since the logic `createapiversionsresponse` becomes non-trivial now?",0,0.9882522225379944
426875879,8680,abbccdda,2020-05-18T20:28:59Z,s/allapi/getallfeatures,0,0.9915961623191833
426876134,8680,abbccdda,2020-05-18T20:29:35Z,we need the apache license title,0,0.9937124848365784
426876793,8680,abbccdda,2020-05-18T20:30:54Z,we could use `org.apache.kafka.common.utils.utils#mkmap` here,0,0.9948697090148926
426876852,8680,abbccdda,2020-05-18T20:31:01Z,same here,0,0.99204421043396
426877891,8680,abbccdda,2020-05-18T20:33:12Z,nit: new line,0,0.9900916814804077
426884892,8680,abbccdda,2020-05-18T20:47:45Z,"in terms of naming, do you think `finalizedversionrange` is more explicit? also when i look closer at the class hierarchy, i feel the sharing point between finalized version range and supported version range should be extracted to avoid weird inheritance. what i'm proposing is to have `versionrange` as a super class with two subclasses: `supportedversionrange` and `finalizedversionrange`, and make `minkeylabel` and `maxkeylabel` abstract functions, wdyt?",0,0.9797130823135376
426890390,8680,abbccdda,2020-05-18T21:00:09Z,"note this function is public, which suggests there could be external dependency that we need to take care of. the safer approach is to keep this static function and create a separate one with augmented parameters. cc for validation.",0,0.9938899278640747
426931875,8680,abbccdda,2020-05-18T22:44:55Z,i think we could delay the addition for these helpers until we actually need them.,0,0.9828229546546936
426933479,8680,abbccdda,2020-05-18T22:49:35Z,"i gave it more thought, and wonder whether we could just call this function `features` to be more consistent with our convention for getters.",0,0.9576894640922546
426933776,8680,abbccdda,2020-05-18T22:50:20Z,need to check null,0,0.9943037629127502
426934551,8680,abbccdda,2020-05-18T22:52:20Z,is there a difference between `objects.equals` and `this.minkeylabel.equals(that.minkeylabel)`?,0,0.9947781562805176
426935082,8680,abbccdda,2020-05-18T22:53:54Z,"nit: testminmax, and we could reuse the same `new versionrange(1, 2)` by only creating it once.",0,0.9945377707481384
426936469,8680,abbccdda,2020-05-18T22:57:45Z,does l17-23 really necessary for testing?,0,0.9911808371543884
426936751,8680,abbccdda,2020-05-18T22:58:34Z,could we add a reference to the class?,0,0.9947214126586914
426937532,8680,abbccdda,2020-05-18T23:00:50Z,it seems that we don't have the handling logic for this featurecacheupdateexception. do we think this is fatal?,0,0.9883432984352112
426937944,8680,abbccdda,2020-05-18T23:02:01Z,is this function being used?,0,0.9936973452568054
426940597,8680,abbccdda,2020-05-18T23:10:12Z,do you expect these helper functions actually to be used in production logic with subsequent prs?,0,0.9928348064422607
426940830,8680,abbccdda,2020-05-18T23:10:56Z,i don't think we need a nested if-else: [code block],0,0.9860068559646606
426942377,8680,abbccdda,2020-05-18T23:16:03Z,could we make feature extraction as a helper function?,0,0.9932904243469238
426942842,8680,abbccdda,2020-05-18T23:17:26Z,could we make this parameter configurable?,0,0.9945883750915527
426976264,8680,abbccdda,2020-05-19T01:19:38Z,what would happen if we are dealing with a v4 json map containing features?,0,0.991801917552948
426976396,8680,abbccdda,2020-05-19T01:20:02Z,nit: this test could move closer to testfromjsonv4withnorack,0,0.9936841130256653
426976932,8680,abbccdda,2020-05-19T01:22:05Z,should we test `isdefined` before calling `get`?,0,0.9945685863494873
426977978,8680,abbccdda,2020-05-19T01:26:17Z,s/existingstr/oldfeatureandepoch,0,0.9897221922874451
426978090,8680,abbccdda,2020-05-19T01:26:43Z,this val seems redundant.,0,0.7504394054412842
426978267,8680,abbccdda,2020-05-19T01:27:25Z,nit: this errormsg val seems redundant.,0,0.8319383859634399
426979984,8680,abbccdda,2020-05-19T01:34:31Z,"this is only used on l53, maybe we could just use supportedfeatures instead",0,0.9878566265106201
426980855,8680,abbccdda,2020-05-19T01:37:40Z,"this comment is a bit vague to me, what are you referring by `incompatibilities`?",0,0.8069016933441162
426990007,8680,abbccdda,2020-05-19T02:12:55Z,nit: maybe rename to `incompatiblewith` and flip the boolean,0,0.9921208620071411
426990716,8680,abbccdda,2020-05-19T02:15:41Z,"might worth getting a ticket to define the handling strategy for such exception, and in general how `updateorthrow` will be used.",0,0.9840022325515747
426997108,8680,abbccdda,2020-05-19T02:39:40Z,does this event actually happen? will we hit illegal state exception in `updatelatestorthrow`?,0,0.9889203906059265
427022316,8680,kowshik,2020-05-19T04:25:04Z,done.,0,0.9897913336753845
427023280,8680,kowshik,2020-05-19T04:29:23Z,"do you feel strongly about this? the reasons why i ask the question is: 1. caller is unlikely to pass `null`. 2. i looked over a number of other existing classes in kafka, and there aren't any null checks for most constructor parameters. it will help me if you could share couple examples from existing code where the `null` check convention is followed in kafka.",0,0.9588110446929932
427023377,8680,kowshik,2020-05-19T04:29:55Z,done. good point!,1,0.9960730075836182
427023394,8680,kowshik,2020-05-19T04:30:00Z,done.,0,0.9897913336753845
427023705,8680,kowshik,2020-05-19T04:31:11Z,"done. yes, i've changed it to default visibility now.",0,0.9601917862892151
427023770,8680,kowshik,2020-05-19T04:31:31Z,done. removed it.,0,0.9904975295066833
427024341,8680,kowshik,2020-05-19T04:34:02Z,done. good point!,1,0.9960730075836182
427024379,8680,kowshik,2020-05-19T04:34:12Z,done. good point!,1,0.9960730075836182
427025378,8680,kowshik,2020-05-19T04:38:08Z,"the underlying data structure is a `map`. it would be simpler if this method just returns `null` if the feature doesn't exist. for example, that is how java's `map.get` works, here is the javadoc: [a link] also, i've documented this method now (doc was previously absent).",0,0.9943178296089172
427025539,8680,kowshik,2020-05-19T04:38:51Z,done.,0,0.9897913336753845
427025597,8680,kowshik,2020-05-19T04:39:05Z,done.,0,0.9897913336753845
427025866,8680,kowshik,2020-05-19T04:40:04Z,done. good point! added test as well.,1,0.9965484738349915
427027670,8680,kowshik,2020-05-19T04:47:29Z,it provides slightly better convenience: `object.equals` will also take care of the `null` checks for you. also it turned out it was overkill to use `objects.equals` for primitive type checks for `minvalue` and `maxvalue`. so i've simplified the code to use `==` those attributes. good point!,1,0.9851269125938416
427027909,8680,kowshik,2020-05-19T04:48:28Z,done.,0,0.9897913336753845
427033616,8680,kowshik,2020-05-19T05:10:37Z,done. also added a test. good catch!,1,0.9963854551315308
427034499,8680,kowshik,2020-05-19T05:13:51Z,done. good point!,1,0.9960730075836182
427034758,8680,kowshik,2020-05-19T05:14:57Z,"are you sure? all newly added fields are tagged (i.e. optional). going by [a link] in kip-482, it is not required to change the schema version whenever tagged fields are introduced.",0,0.9943566918373108
427035290,8680,kowshik,2020-05-19T05:16:58Z,done.,0,0.9897913336753845
427035380,8680,kowshik,2020-05-19T05:17:19Z,done.,0,0.9897913336753845
427042310,8680,kowshik,2020-05-19T05:42:26Z,done.,0,0.9897913336753845
427042434,8680,kowshik,2020-05-19T05:42:49Z,done.,0,0.9897913336753845
427043245,8680,kowshik,2020-05-19T05:45:33Z,"done. some of it is not required. good point, i have removed the unnecessary testing now. we still need to check if exception is thrown in these 4 basic tests: min < 1, max < 1, min & max < 1 and max > min.",1,0.9684832692146301
427043710,8680,kowshik,2020-05-19T05:47:05Z,done.,0,0.9897913336753845
427044348,8680,kowshik,2020-05-19T05:49:07Z,"no, this constructor overload was simply created to avoid a churn of test code at number of places adding the additional `supportedfeatures` parameter. how do you feel about keeping it?",0,0.9906654357910156
427045136,8680,kowshik,2020-05-19T05:51:37Z,done. good point!,1,0.9960730075836182
427045338,8680,kowshik,2020-05-19T05:52:15Z,done. it was unused and i have eliminated it now.,0,0.9929158687591553
427045754,8680,kowshik,2020-05-19T05:53:30Z,done.,0,0.9897913336753845
427045906,8680,kowshik,2020-05-19T05:54:00Z,done.,0,0.9897913336753845
427046004,8680,kowshik,2020-05-19T05:54:19Z,done.,0,0.9897913336753845
427046331,8680,kowshik,2020-05-19T05:55:17Z,it is used intentionally to split the log message into 2 lines (for ~100-char readability limit per line). otherwise the string will be huge and all in the same line.,0,0.9897435307502747
427046353,8680,kowshik,2020-05-19T05:55:21Z,it is used intentionally to split the log message into 2 lines (for ~100-char readability limit per line). otherwise the string will be huge and all in the same line.,0,0.9897435307502747
427047251,8680,kowshik,2020-05-19T05:58:04Z,"i have added comments now to the code. the idea i had was that this event may happen, rarely (ex: operational error). in such a case, we do not want to kill the brokers, so we just log a warning and treat the case as if the node is absent, and populate the cache with empty features. so, this case is actually handled inside `featurecacheupdater.updatelatestorthrow()`. the call to read zk node will return `zkversion.unknownversion` whenever the node does not exist in zk, and i've explicitly handled this returned version.",0,0.9889611601829529
427047400,8680,kowshik,2020-05-19T05:58:32Z,done.,0,0.9897913336753845
427048695,8680,kowshik,2020-05-19T06:02:19Z,good point. i have improved the doc now. let me know how you feel about it.,1,0.9850333333015442
427049093,8680,kowshik,2020-05-19T06:03:24Z,done.,0,0.9897913336753845
427049831,8680,kowshik,2020-05-19T06:05:39Z,done.,0,0.9897913336753845
427050030,8680,kowshik,2020-05-19T06:06:13Z,"yes, this will get used in the future. for example the write path will use it.",0,0.992766261100769
427050597,8680,kowshik,2020-05-19T06:07:55Z,done. good point!,1,0.9960730075836182
427057916,8680,kowshik,2020-05-19T06:27:29Z,done.,0,0.9897913336753845
427060765,8680,kowshik,2020-05-19T06:34:31Z,"the tests have been already added. pls check out the tests added in `apiversionsresponsetest.java`, particularly: `shouldreturnfeaturekeyswhenmagiciscurrentvalueandthrottlemsisdefaultthrottle`. let me know if this test does not look sufficient.",0,0.9929487705230713
427063053,8680,kowshik,2020-05-19T06:39:32Z,done.,0,0.9897913336753845
427063724,8680,kowshik,2020-05-19T06:40:58Z,done.,0,0.9897913336753845
427064271,8680,kowshik,2020-05-19T06:42:10Z,"in my understanding, this is an impossible case. because, we always write features into the json only in v5 or above. that is why, there is no test for it. let me know how you feel about it.",0,0.931598424911499
427064923,8680,kowshik,2020-05-19T06:43:33Z,done.,0,0.9897913336753845
427827018,8680,kowshik,2020-05-20T08:21:37Z,"as we discussed offline today, this exception is already handled in `changenotificationprocessorthread.dowork()` method defined in `finalizedfeaturechangelistener.scala`. basically, the zk change notification processor thread exits the broker with a fatal error (non-zero exit code) when this exception (or any exception) is caught while trying to update `finalizedfeaturecache`.",0,0.9929814338684082
427884165,8680,kowshik,2020-05-20T09:51:49Z,done.,0,0.9897913336753845
427885025,8680,kowshik,2020-05-20T09:53:14Z,"done. good point! - i have now created 3 classes as you proposed. `baseversionrange` is the base class, and, `supportedversionrange` & `finalizedversionrange` are it's child classes. - the key labels couldn't be made into abstract functions since these constants are needed within `deserialize()` which is a static method defined in the child classes.",1,0.9935473799705505
428080079,8680,abbccdda,2020-05-20T14:55:57Z,"yea, the reasoning is that we have `get` call blindly look up inside `features` which in this case null is not valid. and i don't feel passing `null` makes sense for the caller, correct?",0,0.9885919690132141
428367400,8680,abbccdda,2020-05-20T23:39:32Z,`deserialize()`? i think the second sentence is redundant.,0,0.9858071804046631
428370254,8680,abbccdda,2020-05-20T23:48:46Z,do we want to get a unit test class for `baseversionrange`?,0,0.9941873550415039
428370905,8680,abbccdda,2020-05-20T23:51:04Z,should be `supportedversionrange`,0,0.9958847165107727
428371260,8680,abbccdda,2020-05-20T23:52:20Z,"just for the sake of argument, i feel we could remove this method and just test: [code block] for incompatibility.",0,0.9888439178466797
428392754,8680,abbccdda,2020-05-21T01:13:18Z,nit: supportedversionrange,0,0.9927024841308594
428392936,8680,abbccdda,2020-05-21T01:14:10Z,why this is a `note`? could we just comment like: [code block],0,0.9901027679443359
428402864,8680,abbccdda,2020-05-21T01:54:32Z,"maybe i'm a bit too obsessive about code duplication, but after i made an attempt i thought we could actually have the internal deserialization logic shared between `deserializefinalizedfeatures` and `deserializesupportedfeatures` by making a template [code block]",0,0.691012442111969
428403904,8680,abbccdda,2020-05-21T01:58:35Z,missing header,0,0.985005259513855
428404068,8680,abbccdda,2020-05-21T01:59:14Z,seems we didn't trigger style check on this new class.,0,0.9830244779586792
428404491,8680,abbccdda,2020-05-21T02:00:52Z,what's the difference between this test class and its super class test case? same question for `supportedversionrangetest`,0,0.9940093755722046
428418517,8680,abbccdda,2020-05-21T02:58:16Z,could we move this logic as part of inner else? like: [code block] it makes the if-else logic more tight.,0,0.9889824986457825
428419538,8680,abbccdda,2020-05-21T03:02:18Z,"i think we don't need to talk about future work inside the comment, just making it clear that the read path for serving apiversionsrequest is the only reader as of now.",0,0.9813866019248962
428420141,8680,abbccdda,2020-05-21T03:04:59Z,nit: provide,0,0.9937765598297119
428421713,8680,abbccdda,2020-05-21T03:11:58Z,do we need the comment to be on info level?,0,0.994342565536499
428422280,8680,abbccdda,2020-05-21T03:14:25Z,nit: don't feel strong about having this parameter,-1,0.9756952524185181
428422483,8680,abbccdda,2020-05-21T03:15:18Z,feel neutral about this helper function,0,0.70148104429245
428422966,8680,abbccdda,2020-05-21T03:17:24Z,"i don't think this is scala accepted comment style to add `-`, do you see a warning?",0,0.9843636155128479
428424395,8680,abbccdda,2020-05-21T03:23:53Z,`feature cache update gets interrupted`,0,0.9854163527488708
428426189,8680,abbccdda,2020-05-21T03:31:57Z,"does the version field existence guarantee there is a valid feature data node or not? in fact, `getdataandversion` returns an optional data. i checked the getdataandversion caller `produceridmanager`, there is a handling for empty data which i feel we should have as well. additionally, i think since we haven't implemented the write path yet, could we get a ticket to write down a short description on how the write path shall look like, by defining the different cases like: [code block] if that makes sense, so that we could keep track of the design decisions we made in the read path pr when implementing the write path.",0,0.9903035759925842
428426448,8680,abbccdda,2020-05-21T03:33:03Z,"could we summary the possible thrown error code in the comment as well? for example, does a json deserialization error should be treated as fatal?",0,0.9924472570419312
428429013,8680,abbccdda,2020-05-21T03:44:51Z,"is it possible to have no enqueued updater, and cause this function block the thread indefinitely?",0,0.9888904094696045
428429615,8680,abbccdda,2020-05-21T03:47:38Z,"for an educational question, does the zkclient have a separate thread to do the node change monitoring?",0,0.9932026863098145
428430093,8680,abbccdda,2020-05-21T03:49:45Z,does the order matter here? i was wondering if there is any concurrent issue if we unregister before the queue and thread get cleaned up.,0,0.9857978224754333
428430356,8680,abbccdda,2020-05-21T03:50:57Z,we could just comment `for testing only`,0,0.9950123429298401
428430553,8680,abbccdda,2020-05-21T03:51:55Z,`wait time for the first feature cache update upon initialization`,0,0.9933944344520569
428430779,8680,abbccdda,2020-05-21T03:52:57Z,"i think the comment is not necessary, since we have already commented on `kafka_2_6_iv1`",0,0.9847756028175354
428431584,8680,abbccdda,2020-05-21T03:56:16Z,nit: returns a reference to the latest features supported by the broker.,0,0.9949843883514404
428432424,8680,abbccdda,2020-05-21T04:00:05Z,this logging is duplicate,0,0.9818582534790039
428432727,8680,abbccdda,2020-05-21T04:01:36Z,"i'm slightly inclined to return a set of features instead of just strings, and make the string conversion as a helper. but i leave this up to you to decide, and we could always adapt the function to make it more useful in other scenarios as needed.",0,0.9821233153343201
428432904,8680,abbccdda,2020-05-21T04:02:25Z,"if that's the case, i feel we could remove the testing only comment.",0,0.9874696731567383
428433279,8680,abbccdda,2020-05-21T04:04:10Z,"aha, the order is wrong for `kafka_0_10_0_iv1` and `kafka_2_6_iv1`",0,0.6439492106437683
428433517,8680,abbccdda,2020-05-21T04:05:31Z,"i think even if this is an operational error, the cluster is at risk of violating the feature semantics previously enabled, which is different from an unknown feature version from the beginning. i feel we should just exit in fatal error for this case, but would open for discussion.",0,0.9058453440666199
428434151,8680,abbccdda,2020-05-21T04:08:21Z,s/asjavamap/featuresasjavamap,0,0.9656270742416382
428434945,8680,abbccdda,2020-05-21T04:11:27Z,could we log statusint here as well? also i feel the exception should be thrown from `featureznodestatus.withnameopt`,0,0.9934749007225037
428435694,8680,abbccdda,2020-05-21T04:15:15Z,is there a more dedicated exception code for deserialization error? i feel the kafkaexception is a bit too general compared with illegalargument,0,0.936860978603363
428436046,8680,abbccdda,2020-05-21T04:16:59Z,could we name it v0 for simplicity?,0,0.9930446743965149
428436573,8680,abbccdda,2020-05-21T04:19:58Z,"i feel we might worth creating a separate thread discussing whether we could get some benefit of the automated protocol generation framework here, as i think this could be easily represented as json if we define it in the common package like other rpc data. the difficulty right now is mostly on the serialization and deserialization for feature itself, but these could have workarounds if we want to do so.",0,0.9727365970611572
428437318,8680,abbccdda,2020-05-21T04:23:22Z,"i'm a bit surprised, do we want to support feature znode deletion in long term?",-1,0.9237053394317627
428437571,8680,abbccdda,2020-05-21T04:24:39Z,could we extract some common initialization logic for the tests to reduce duplication?,0,0.9912471175193787
428437659,8680,abbccdda,2020-05-21T04:24:58Z,nit: space,0,0.787409245967865
428438063,8680,abbccdda,2020-05-21T04:27:00Z,"if we are not validating the features by extracting them, i think we do not need to pass in a non-empty feature list?",0,0.988241970539093
428573407,8680,kowshik,2020-05-21T10:32:12Z,"it is thoroughly tested in it's child class test suite: `supportedversionrangetest`. personally i feel it is good enough this way, because, anyway to test this class we need to inherit into a sub-class (since constructor is `protected`). and by testing via `supportedversionrangetest`, we achieve exactly the same. i have now added top-level documentation in the test suite of `supportedversionrangetest`, explaining the above.",1,0.6708665490150452
428576410,8680,kowshik,2020-05-21T10:39:55Z,done. i'm raising an exception now if it is `null`. i see your point. will be good to learn what is the convention in kafka for constructor param null checks.,0,0.9774242639541626
428577156,8680,kowshik,2020-05-21T10:41:42Z,done.,0,0.9897913336753845
428578424,8680,kowshik,2020-05-21T10:44:59Z,done.,0,0.9897913336753845
428578472,8680,kowshik,2020-05-21T10:45:04Z,done. good point!,1,0.9960730075836182
428578829,8680,kowshik,2020-05-21T10:45:53Z,done.,0,0.9897913336753845
428579070,8680,kowshik,2020-05-21T10:46:29Z,done. good point!,1,0.9960730075836182
428579884,8680,kowshik,2020-05-21T10:48:19Z,done.,0,0.9897913336753845
428580337,8680,kowshik,2020-05-21T10:49:28Z,done.,0,0.9897913336753845
428581013,8680,kowshik,2020-05-21T10:51:04Z,done. good point!,1,0.9960730075836182
428581253,8680,kowshik,2020-05-21T10:51:45Z,done.,0,0.9897913336753845
429069672,8680,kowshik,2020-05-22T06:41:44Z,done.,0,0.9897913336753845
429071500,8680,kowshik,2020-05-22T06:47:02Z,"done. i have simplified this test suite eliminating the redundant tests, and only keeping the ones specific to `finalizedversionrange`. also i have added documentation to both test suites explaining their purpose.",0,0.8687379956245422
429074215,8680,kowshik,2020-05-22T06:55:11Z,done. changed to `illegalargumentexception`. good point!,1,0.9914608001708984
429076303,8680,kowshik,2020-05-22T07:01:08Z,"done. for the other point, i don't feel strongly for it. i feel it is ok to have an api that doesn't throw and just lets the caller decide (based on the context) if an empty returned value is incorrect.",0,0.8960176110267639
429076742,8680,kowshik,2020-05-22T07:02:23Z,no. but we want to test the behavior about what happens during a deletion (ex: operational error).,0,0.9855942130088806
429077064,8680,kowshik,2020-05-22T07:03:13Z,done.,0,0.9897913336753845
429077469,8680,kowshik,2020-05-22T07:04:23Z,done.,0,0.9897913336753845
429078661,8680,kowshik,2020-05-22T07:07:36Z,"as far as i can see, no zk node class defined in this file is defined in such a way. every class in this file encodes/decodes json by itself, and manages its own attributes. should we break the norm?",0,0.9869937300682068
429086184,8680,kowshik,2020-05-22T07:27:10Z,done.,0,0.9897913336753845
429087972,8680,kowshik,2020-05-22T07:31:25Z,"see l848 below where it is validated. the call to `zkclient. getallbrokersincluster` decodes each `brokeridznode` content from json to `brokerinfo` object. then, we check whether the call returns exactly the same `brokerinfo` objects defined here, and, along the way features are checked too.",0,0.9936113953590393
429089245,8680,kowshik,2020-05-22T07:34:40Z,done.,0,0.9897913336753845
429089574,8680,kowshik,2020-05-22T07:35:30Z,done. good catch!,1,0.9956228137016296
429089817,8680,kowshik,2020-05-22T07:36:05Z,done.,0,0.9897913336753845
429090026,8680,kowshik,2020-05-22T07:36:42Z,done.,0,0.9897913336753845
429093727,8680,kowshik,2020-05-22T07:45:18Z,done. good point!,1,0.9960730075836182
429096612,8680,kowshik,2020-05-22T07:51:42Z,done. removed extra logging in the caller of this method (see `finalizedfeaturecache`).,0,0.990988552570343
429101010,8680,kowshik,2020-05-22T08:01:36Z,"done. yes, i feel json deserialization should be treated as fatal. it should never happen, and, can indicate corruption.",0,0.861683189868927
429107026,8680,kowshik,2020-05-22T08:14:57Z,done. removed.,0,0.9905270338058472
429107347,8680,kowshik,2020-05-22T08:15:43Z,"done. but it's actually ""change notification queue interrupted"".",0,0.9888521432876587
429109170,8680,kowshik,2020-05-22T08:19:43Z,"the function blocks indefinitely - yes. but this shouldn't cause a problem or lead to deadlock/limbo situation. even if this thread is waiting for an item to become available in the queue, the waiting thread can always get interrupted by the `finalizedfeaturechangelistener.close()` call which calls `shutdownablethread.shutdown()`. note that the `shutdownablethread.shutdown()` method interrupts the thread, which should unblock any waiting `queue.take()` operation and makes it raise an `interruptedexception`: [a link] [a link]",0,0.9921562671661377
429110087,8680,kowshik,2020-05-22T08:21:36Z,done. removed.,0,0.9905270338058472
429111103,8680,kowshik,2020-05-22T08:23:51Z,"i didn't understand the question. are you saying the logging severity should be lower or higher? this is a rare case anyway as the feature node doesn't get created often, so, `info` logging seems fine to me.",0,0.9124428629875183
429113491,8680,kowshik,2020-05-22T08:28:40Z,"you bring up a good point. my main concern is availability. if we exit the broker here, then, whenever the feature zk node gets deleted (accidentally), it could crash all brokers in the fleet all at once leading to an availability problem. with regards to violating feature semantics, good point. i'm in 2 minds here, and perhaps we can also hear 's thoughts on this topic.",1,0.9329150319099426
429117278,8680,kowshik,2020-05-22T08:36:30Z,yes. here is the documentation explaining the same: [a link],0,0.9917718768119812
429117918,8680,kowshik,2020-05-22T08:37:53Z,done. removed.,0,0.9905270338058472
429120585,8680,kowshik,2020-05-22T08:43:40Z,the order probably doesn't matter in this case. but logically i decided to follow the below order since i could reason about it better: 1. stop the inflow of new events 2. clear pending events 3. stop the processing of all events,0,0.9564914703369141
429120739,8680,kowshik,2020-05-22T08:44:04Z,done.,0,0.9897913336753845
429123988,8680,kowshik,2020-05-22T08:50:49Z,"i have added documentation here in this method describing all the cases. the empty data case should never happen and can indicate a corruption. the reason is that we always return non-empty data in `featureznode.encode`, so the zk node content should never empty. yes, i can add some more info to kafka-10028 or in the write path pr summary.",0,0.9866915941238403
429126751,8680,kowshik,2020-05-22T08:56:54Z,done.,0,0.9897913336753845
429126867,8680,kowshik,2020-05-22T08:57:07Z,done.,0,0.9897913336753845
429128812,8680,kowshik,2020-05-22T09:01:12Z,done.,0,0.9897913336753845
429474760,8680,abbccdda,2020-05-22T22:08:39Z,we could have multiple here,0,0.9904977679252625
429476928,8680,abbccdda,2020-05-22T22:19:31Z,"i didn't look thoroughly enough, but the only illegalargumentexception i found is [code block] which should never happen as we always use `matchanyversion` in `retryrequestsuntilconnected`. are we trying to catch some other exceptions here?",0,0.9485200643539429
429480603,8680,abbccdda,2020-05-22T22:38:14Z,"my feeling is that this could be on debug level, but no strong perference.",0,0.9659239649772644
429494635,8680,abbccdda,2020-05-23T00:13:07Z,nit: minkeylabel,0,0.9896031022071838
429495765,8680,abbccdda,2020-05-23T00:22:36Z,"i see, makes sense.",0,0.9701014757156372
429496037,8680,abbccdda,2020-05-23T00:24:54Z,nit: we could test `emptysupportedfeatures.features().isempty()`,0,0.9889928698539734
429497749,8680,abbccdda,2020-05-23T00:40:54Z,nit: could you elaborate why this helper function and `finalizedfeaturesandepoch` struct is useful in this context? just for easier message printing?,0,0.9931657910346985
429498395,8680,abbccdda,2020-05-23T00:48:10Z,so here we will directly throw nosuchelementexception if `maybefeatureznodebytes` is empty? do we want to check this case and throw a customized exception instead?,0,0.9942789077758789
429498408,8680,abbccdda,2020-05-23T00:48:17Z,nit: space,0,0.787409245967865
429499008,8680,abbccdda,2020-05-23T00:54:28Z,"this leads to a more general question: is there a way to cleanup all the zk feature path? reading from the kip, i don't see we have any admin api to do so, which makes me wonder how could this case happen in reality. in terms of severity, i think crushing the entire cluster seems to be an overkill as well, maybe we should have some blocking mechanism in place for any feature extraction call here, until we see `handlecreation` gets triggered again?",0,0.92356938123703
429509179,8680,abbccdda,2020-05-23T03:18:11Z,"nit: one liner: `this.features = objects.requirenonnull(features, ""provided features can not be null."");`",0,0.9255788326263428
429509941,8680,abbccdda,2020-05-23T03:30:12Z,nit: remove `only`,0,0.9939907789230347
429510099,8680,abbccdda,2020-05-23T03:32:02Z,"this comment should be frequent and the `featurezknodepath` is staying constant, could we just make it for debugging level?",0,0.9943206310272217
429510224,8680,abbccdda,2020-05-23T03:34:25Z,"i don't think this note is necessary, maybe just merge with the first line as: [code block]",0,0.9878355860710144
429510520,8680,abbccdda,2020-05-23T03:39:24Z,"do you think we should add this config as part of the kip since it is public? i think it would just be a minor update, but let's wait and see others thoughts on this.",0,0.9873698353767395
429510746,8680,abbccdda,2020-05-23T03:43:32Z,remove semi-colon,0,0.9917819499969482
429511091,8680,abbccdda,2020-05-23T03:50:12Z,s/it's/its,0,0.9548832178115845
429511146,8680,abbccdda,2020-05-23T03:51:19Z,`a kafka cluster exists already and the ibp config is less than kafka_2_6_iv1` to `an existing kafka cluster with ibp config less than kafka_2_6_iv1`,0,0.9850890040397644
429511236,8680,abbccdda,2020-05-23T03:52:57Z,"i think the norm exists because we don't have automated framework by then, and doing hand-written json serialization and deserialization is a bit wasting. cc as this is a major direction discussion.",0,0.9315876960754395
429589291,8680,kowshik,2020-05-24T00:51:52Z,done.,0,0.9897913336753845
429589607,8680,kowshik,2020-05-24T01:00:30Z,done. also added doc.,0,0.9890378713607788
429590012,8680,kowshik,2020-05-24T01:12:17Z,done.,0,0.9897913336753845
429590179,8680,kowshik,2020-05-24T01:16:53Z,"actually i've eliminated the helper method now, and, there is only 1 method: `updateorthrow(...)`.",0,0.9945331811904907
429590200,8680,kowshik,2020-05-24T01:17:20Z,done.,0,0.9897913336753845
429590218,8680,kowshik,2020-05-24T01:17:45Z,done.,0,0.9897913336753845
429590248,8680,kowshik,2020-05-24T01:18:15Z,done.,0,0.9897913336753845
429590426,8680,kowshik,2020-05-24T01:23:07Z,"fixed now. good point. actually the code was incorrect. i meant to wrap `featureznode.decode` call with the `try-catch`, since, it throws `illegalargumentexception`. i have fixed the code now to do the same.",1,0.9792022109031677
429590504,8680,kowshik,2020-05-24T01:25:20Z,done.,0,0.9897913336753845
429590532,8680,kowshik,2020-05-24T01:25:46Z,done.,0,0.9897913336753845
429590593,8680,kowshik,2020-05-24T01:27:36Z,"sounds good. yeah, it is minor and feels like an implementation detail to me. but we can wait to see what others say.",1,0.9166772365570068
429590614,8680,kowshik,2020-05-24T01:27:57Z,done.,0,0.9897913336753845
429590626,8680,kowshik,2020-05-24T01:28:30Z,done.,0,0.9897913336753845
429590656,8680,kowshik,2020-05-24T01:29:04Z,done.,0,0.9897913336753845
429591914,8680,kowshik,2020-05-24T01:59:16Z,done.,0,0.9897913336753845
429593151,8680,kowshik,2020-05-24T02:26:04Z,"the deletion of znode is a rare case, it should never happen in reality unless it is zk corruption, or rarely an operational error that deletes some zk nodes. it's not easy to prevent damage in such a case. from a correctness standpoint, imagine what would happen if the feature znode gets deleted, and, afterwards a broker restarts. it will start with empty cache, so the damage is done. therefore, it seems that even if we add a special logic here, we can not prevent damage if the source of truth is lost. two things to note here: 1. the client should anyway ignore older stale epoch responses, if it had seen newer epochs that are greater. in that spirit, the client can be also made to treat the absence of finalized features in an `apiversionsresponse` just like a stale epoch case, if, it had seen at least one valid `apiversionsresponse` earlier (i.e. at least one response with some valid epoch). 2. deletion of individual finalized feature is actually supported in [a link], but not deletion of the entire znode. search for the word 'deletion' in the kip write-up. if needed, this deletion functionality could be extended to provide the ability to delete all features too.",0,0.9024252891540527
430737606,8680,abbccdda,2020-05-26T22:15:42Z,"thanks, i don't think we need to be super paranoid with this rare scenario, but we should also be indicating this error state to the client suggesting that some manual fix is necessary. my proposed idea above is to add such an error state to the feature cache to refuse any further updates until we have: 1. a node creation event 2. restart of the broker (once the issue gets fixed), so this blocking behavior shall be ephemeral and recoverable from broker perspective. we don't have to implement this logic in the current pr, as we don't have a write path yet, just get a jira to track it sounds fine. make sense to cc and as well.",1,0.8335732817649841
432781217,8680,junrao,2020-05-29T23:29:07Z,"this won't make 2.6.0 release. so, perhaps we should use kafka_2_7 or whatever the next release is?",0,0.9905493855476379
432782068,8680,junrao,2020-05-29T23:33:18Z,"i missed this in the kip, but it seems that long is overkilling for version. the version in request is short and the version in zk data is int. so, perhaps this should just be short?",0,0.983606219291687
432782926,8680,junrao,2020-05-29T23:37:35Z,"minvalue > 1, maxvalue > 1 => minvalue >= 1, maxvalue >= 1",0,0.988108217716217
432783145,8680,junrao,2020-05-29T23:38:43Z,should we include the label too?,0,0.994030237197876
432783472,8680,junrao,2020-05-29T23:40:25Z,serialize typically means generating binary data. perhaps this is better called tomap()?,0,0.9933053851127625
433327328,8680,junrao,2020-06-01T15:53:29Z,missing license header,0,0.9829095602035522
433337829,8680,junrao,2020-06-01T16:10:17Z,empty => isempty ?,0,0.9854228496551514
433347401,8680,junrao,2020-06-01T16:27:29Z,"could we use map {case(feature, versionlevel, _) => ...} to avoid unnamed references like _1?",0,0.9940875768661499
433359805,8680,junrao,2020-06-01T16:50:36Z,the kip doesn't seems to include this field. could we add it to the kip wiki?,0,0.9901440143585205
433366871,8680,junrao,2020-06-01T17:03:47Z,"interruptedexception can be thrown if the thread is shut down explicitly. in this case, we probably don't want to throw runtimeexception to the caller.",0,0.9850003719329834
433373309,8680,junrao,2020-06-01T17:16:17Z,"hmm, could we just use config.zkconnectiontimeoutms for this, instead of introducing a new config?",0,0.9853094220161438
433375459,8680,junrao,2020-06-01T17:20:23Z,"hmm, is waitonceforcacheupdatems <=0 supported? in that case, it seems that we still need to read the /features path in zk?",0,0.987011730670929
433382257,8680,junrao,2020-06-01T17:32:58Z,"if this thread is being closed, the interruptedexception is expected and we don't need to log this.",0,0.9909152388572693
433384475,8680,junrao,2020-06-01T17:37:12Z,"hmm, this just kills the thread, but not the broker as the comment says. also, not sure about killing the broker. we probably should just log an error and continue since this is not necessarily fatal.",0,0.9083110690116882
433395727,8680,junrao,2020-06-01T17:58:03Z,"hmm, the epoch returned from zk is int32. does finalizedfeaturesepoch need to be int64?",0,0.988061785697937
433399575,8680,junrao,2020-06-01T18:05:16Z,"hmm, why is finalizedfeaturesepoch an optional but latestsupportedfeatures is not?",0,0.9843527674674988
433400012,8680,junrao,2020-06-01T18:06:06Z,should we add public methods for accessing those fields?,0,0.9937868118286133
433402784,8680,junrao,2020-06-01T18:11:26Z,it doesn't seem we store security protocol map in the broker registration.,0,0.9846901893615723
433403260,8680,junrao,2020-06-01T18:12:25Z,should we include the new field in tostring()?,0,0.9951385259628296
433409944,8680,junrao,2020-06-01T18:25:22Z,the existing comments seem incorrect since we don't store listener_security_protocol_map in zk.,0,0.9807532429695129
434343065,8680,kowshik,2020-06-03T06:47:41Z,done. made it kafka_2_7_iv0.,0,0.9761223196983337
434344257,8680,kowshik,2020-06-03T06:50:32Z,done. i have made it `int16` now. great point.,1,0.9943377375602722
434345400,8680,kowshik,2020-06-03T06:53:05Z,done.,0,0.9897913336753845
434346281,8680,kowshik,2020-06-03T06:55:08Z,done.,0,0.9897913336753845
434417020,8680,kowshik,2020-06-03T09:01:38Z,done.,0,0.9897913336753845
434428173,8680,kowshik,2020-06-03T09:20:02Z,"it's because non-existing supported features _can_ be represented by an empty map (i.e. broker does not advertise any features). but on the other hand, non-existing finalized features can not be represented by empty map alone, as we need a suitable epoch value that indicates the absence of finalized features. to address this case, i saw 2 ways: 1) provide a negative epoch value indicating absence of finalized features, or 2) represent using an empty `optional` for both finalized features and epoch. i chose the latter approach. please, let me know if you have concerns.",0,0.9823197722434998
434431330,8680,kowshik,2020-06-03T09:25:27Z,"i had added such apis previously. but wanted these removed, as they are not currently unused. please refer to this comment: [a link] please, let me know, and i can add them back if you prefer.",0,0.9726711511611938
434431880,8680,kowshik,2020-06-03T09:26:20Z,done. changed to `int32` now. great point!,1,0.9960378408432007
434434381,8680,kowshik,2020-06-03T09:30:30Z,done.,0,0.9897913336753845
434434804,8680,kowshik,2020-06-03T09:31:10Z,done. nice catch!,1,0.9957658052444458
434435193,8680,kowshik,2020-06-03T09:31:48Z,done.,0,0.9897913336753845
434435824,8680,kowshik,2020-06-03T09:32:53Z,done.,0,0.9897913336753845
434438288,8680,kowshik,2020-06-03T09:36:50Z,done. removed the catch clause and exception wrapping.,0,0.992767333984375
434441200,8680,kowshik,2020-06-03T09:41:16Z,done.,0,0.9897913336753845
434443007,8680,kowshik,2020-06-03T09:44:10Z,"it kills the broker because `shutdownablethread` catches `fatalexiterror` and triggers exit sequence: [a link] i have updated the comment to use the word ""eventually"". regarding logging fatal and continuing -- the exception caught here almost always indicates a feature incompatibility, and, that means the broker can cause damage if it sticks around. that is why i felt it is better to kill the broker in such a rare incompatibility case. please, let me know your thoughts.",0,0.8450494408607483
434444716,8680,kowshik,2020-06-03T09:46:55Z,done. i have changed the code disallowing values <= 0.,0,0.9861841797828674
434444848,8680,kowshik,2020-06-03T09:47:11Z,done. great point!,1,0.9967150688171387
434445428,8680,kowshik,2020-06-03T09:48:14Z,done.,0,0.9897913336753845
434448455,8680,kowshik,2020-06-03T09:53:30Z,done. removed. great catch!,1,0.996505618095398
434450195,8680,kowshik,2020-06-03T09:56:30Z,sure. i will be happy to follow up on this. trying to understand the process -- should i update the kip and send an email as fyi to `dev.apache.org` ?,1,0.9892075061798096
435543865,8680,junrao,2020-06-04T20:56:15Z,"to handle zk session expiration, we need to register a statechangehandler. that way, we can read the /features path from zk when the new session is established since the feature could have changed btw the old and the new zk sessions. see object zkstatechangehandler as an example.",0,0.9934051632881165
435558683,8680,junrao,2020-06-04T21:20:35Z,could we pass in `optional ` instead of two separate optional?,0,0.9931312203407288
435560941,8680,junrao,2020-06-04T21:23:29Z,"if finalizedfeaturesepoch is not present, we probably want to set the field to sth like -1 instead of leaving it as the default value of 0.",0,0.9925541281700134
435562341,8680,junrao,2020-06-04T21:26:15Z,the comment can be a bit misleading since features is not optional.,0,0.5800036787986755
435567942,8680,junrao,2020-06-04T21:39:10Z,it's probably better to close this before zkclient since the close call unregister from zkclient.,0,0.9905856251716614
435595571,8680,junrao,2020-06-04T22:53:02Z,the name of the method probably should include failure?,0,0.9914637207984924
435595915,8680,junrao,2020-06-04T22:54:00Z,missing license header,0,0.9829095602035522
435596401,8680,junrao,2020-06-04T22:55:36Z,"could we just assertequals(featureznode, decoded)?",0,0.9943641424179077
435597745,8680,junrao,2020-06-04T22:59:39Z,`version > currentversion` means that we can't downgrade the broker. we will need to relax this check.,0,0.9937947988510132
435598956,8680,junrao,2020-06-04T23:03:22Z,missing license header,0,0.9829095602035522
435601124,8680,junrao,2020-06-04T23:10:31Z,missing license header,0,0.9829095602035522
435604964,8680,junrao,2020-06-04T23:23:22Z,"hmm, if the feature is disabled, it seems that updatedfinalizedfeatures shouldn't be reflected in the cache, right?",0,0.9814267754554749
435606223,8680,junrao,2020-06-04T23:27:47Z,do we want to throw an exception here?,0,0.9827096462249756
435607391,8680,junrao,2020-06-04T23:31:54Z,missing license header,0,0.9829095602035522
436493426,8680,kowshik,2020-06-08T07:04:45Z,done.,0,0.9897913336753845
436493633,8680,kowshik,2020-06-08T07:05:14Z,done.,0,0.9897913336753845
436494049,8680,kowshik,2020-06-08T07:06:16Z,done.,0,0.9897913336753845
436495007,8680,kowshik,2020-06-08T07:08:46Z,done. great point!,1,0.9967150688171387
436495405,8680,kowshik,2020-06-08T07:09:48Z,done.,0,0.9897913336753845
436495661,8680,kowshik,2020-06-08T07:10:28Z,done.,0,0.9897913336753845
436496035,8680,kowshik,2020-06-08T07:11:21Z,done.,0,0.9897913336753845
436496254,8680,kowshik,2020-06-08T07:11:54Z,done.,0,0.9897913336753845
436515190,8680,kowshik,2020-06-08T07:53:52Z,done. i have modified the code such that `featurecacheupdater.updatelatestorthrow` will now clear the cache whenever it sees that the feature zk node is disabled. great point!,1,0.994963526725769
436524414,8680,kowshik,2020-06-08T08:11:36Z,done. changed it to use a latch that gets notified when the exit procedure is called. great point!,1,0.9958903193473816
436527003,8680,kowshik,2020-06-08T08:16:56Z,done.,0,0.9897913336753845
436532143,8680,kowshik,2020-06-08T08:26:36Z,done.,0,0.9897913336753845
436543251,8680,kowshik,2020-06-08T08:47:05Z,done.,0,0.9897913336753845
436544409,8680,kowshik,2020-06-08T08:49:14Z,"done. i'm no longer passing 2 optionals, since, we decided (below) that epoch can be set as -1 whenever it is absent.",0,0.9718611836433411
436607402,8680,kowshik,2020-06-08T10:44:45Z,this config has been eliminated now.,0,0.9952211976051331
437045081,8680,junrao,2020-06-08T22:54:43Z,"this is not really ""change-notification"". so, the name can just be featureznode.path.",0,0.9936138987541199
437049072,8680,junrao,2020-06-08T23:06:49Z,2.6.x => 2.7.x,0,0.991380512714386
437049227,8680,junrao,2020-06-08T23:07:19Z,2.6.x => 2.7.x,0,0.991380512714386
437123822,8680,kowshik,2020-06-09T03:56:53Z,done.,0,0.9897913336753845
437123965,8680,kowshik,2020-06-09T03:57:29Z,done.,0,0.9897913336753845
437124061,8680,kowshik,2020-06-09T03:57:53Z,done.,0,0.9897913336753845
437140900,8680,abbccdda,2020-06-09T05:10:27Z,nit: we could use utils.mkmap here,0,0.9941680431365967
437141678,8680,abbccdda,2020-06-09T05:13:44Z,"we don't need to check `other == null` here, the next condition check covers it.",0,0.992330014705658
437143331,8680,abbccdda,2020-06-09T05:19:56Z,"nit: should all the parameters be final here, not just minmagic?",0,0.9904323220252991
437145250,8680,abbccdda,2020-06-09T05:26:56Z,"i overlooked this case, let's maintain this static constructor without renaming it, since it is public.",0,0.9901266098022461
437146576,8680,abbccdda,2020-06-09T05:31:25Z,"nit: instead of using comments, better to build this into the test name, for example: `testinvalidsuppportedfeatureswithmissingmaxversion`",0,0.9890819787979126
437153379,8680,abbccdda,2020-06-09T05:53:27Z,nit: {} not necessary,-1,0.6233564019203186
437580565,8680,abbccdda,2020-06-09T16:57:16Z,nit: use `introduced` to align with previous comment?,0,0.9927680492401123
437582007,8680,abbccdda,2020-06-09T16:59:26Z,it's -> its,0,0.9861699342727661
437582948,8680,abbccdda,2020-06-09T17:00:59Z,could be simplified as `the latest known finalizedfeaturesandepoch or empty if not defined in the cache`,0,0.9945809245109558
437584758,8680,abbccdda,2020-06-09T17:04:11Z,"i think we could remove `if the cache update is not successful, then, a suitable exception is raised...` which is pretty obvious.",0,0.9805886149406433
437586235,8680,abbccdda,2020-06-09T17:06:41Z,"sorry it's been a while since my last review, but have we discussed the recovery path when we hit a data corruption exception for the cluster? is there a way to turn off the feature versioning completely to unblock, or we have a mechanism to wipe out zk data?",-1,0.9825793504714966
437592050,8680,abbccdda,2020-06-09T17:16:33Z,"being a bit paranoid here, would it be possible to have out-of-order updates from zk, such that the version number is not monotonically increasing? i'm thinking even we could throw in finalizedfeaturecache, do we really want to kill the broker, or we should just log a warning and proceed.",0,0.5100133419036865
437598721,8680,abbccdda,2020-06-09T17:27:52Z,"i think i'm no longer insisting on this point, as we could make this as a follow-up work. filed jira here: [a link]",0,0.975681722164154
437604015,8680,abbccdda,2020-06-09T17:36:59Z,nit: space,0,0.787409245967865
437605413,8680,abbccdda,2020-06-09T17:39:17Z,v4 doesn't have feature right? what's the purpose of this test?,0,0.9787266254425049
437606748,8680,abbccdda,2020-06-09T17:41:34Z,add the space back,0,0.9926840662956238
437607867,8680,abbccdda,2020-06-09T17:43:22Z,nit: we could add a minor test to verify a negative `waitonceforcacheupdatems` will throw,0,0.9902839064598083
437851289,8680,kowshik,2020-06-10T04:20:38Z,done.,0,0.9897913336753845
437851622,8680,kowshik,2020-06-10T04:21:57Z,done. good point.,1,0.9824387431144714
437855643,8680,kowshik,2020-06-10T04:38:46Z,done.,0,0.9897913336753845
437855789,8680,kowshik,2020-06-10T04:39:31Z,done.,0,0.9897913336753845
437856190,8680,kowshik,2020-06-10T04:41:11Z,done.,0,0.9897913336753845
437856298,8680,kowshik,2020-06-10T04:41:37Z,done.,0,0.9897913336753845
437856385,8680,kowshik,2020-06-10T04:41:59Z,done.,0,0.9897913336753845
437856510,8680,kowshik,2020-06-10T04:42:29Z,done.,0,0.9897913336753845
437857795,8680,kowshik,2020-06-10T04:47:48Z,done.,0,0.9897913336753845
437858130,8680,kowshik,2020-06-10T04:49:06Z,it's a 2-line block.,0,0.9780358076095581
437874395,8680,kowshik,2020-06-10T05:50:01Z,"1. re: out-of-order updates from zk: i don't understand. when a watch fires from zk, we react by issuing a zk read operation to obtain the latest value of the zk node (see l75). it is impossible that we get a stale read from zk after watch fires on the client side. 2. re: broker death: the exception thrown here almost always indicates a feature incompatibility, and, that means the broker can cause damage if it sticks around (because feature bumps are breaking changes and you can not allow an incompatible broker to stick around in the cluster). that is why i felt it is better to kill the broker in such a rare incompatibility case. note that after the controller has finalized features, there should be no brokers in the cluster with incompatibilites, so death here makes sense. note: i have also explained point #2 in this comment: [a link]",0,0.8788192272186279
437875708,8680,kowshik,2020-06-10T05:54:19Z,thanks. good idea to leave a jira. i have linked it to kafka-9755.,1,0.993501603603363
437875864,8680,kowshik,2020-06-10T05:54:45Z,done.,0,0.9897913336753845
437876419,8680,kowshik,2020-06-10T05:56:21Z,it checks backwards compatibility i.e. it checks whether the deserialization code (v5-based) can correctly deserialize v4 such that features are assigned empty value by default..,0,0.9944660067558289
437877179,8680,kowshik,2020-06-10T05:58:47Z,done.,0,0.9897913336753845
437877390,8680,kowshik,2020-06-10T05:59:31Z,done.,0,0.9897913336753845
437883374,8680,kowshik,2020-06-10T06:17:37Z,it's very rare especially when controller is the only entity writing to the zk node. i have now modified the code to handle this case and clear the cache. perhaps that's better than crashing the broker in such a case. remediation will need human intervention in fixing the zk node. we can provide tooling if required.,0,0.9841815233230591
1333345949,14406,philipnee,2023-09-21T16:40:02Z,is the extra line intentional?,0,0.984431803226471
1333349057,14406,philipnee,2023-09-21T16:42:59Z,kafkaexception?,0,0.9924355149269104
1333353029,14406,philipnee,2023-09-21T16:46:45Z,it is handled in the error event handler - which means the user should get the exception upon invoking poll. i wonder if we could just log info or at a different level. or even no logging.,0,0.9855782985687256
1333353596,14406,philipnee,2023-09-21T16:47:22Z,extra line :grinning_face_with_sweat:,0,0.9864046573638916
1333355626,14406,philipnee,2023-09-21T16:49:19Z,ditto : as the error is log here - we might not need the extra logging,0,0.9916867613792419
1333393941,14406,junrao,2023-09-21T17:28:22Z,"just to understand this. if the consumer gets a fenced_leader_epoch, a metadata update is triggered. once the new metadata is received, the validatepositionsapplicationevent will trigger the offsetforleaderepoch request to validate the fetch position. until the new metadata is received, the consumer will just continuously fetch from the old leader and receiving the same fenced_leader_epoch error?",0,0.9891062378883362
1333594757,14406,junrao,2023-09-21T20:54:51Z,"i guess the purpose of this code is when there is no pending records, we block until some new records are fetched. however, i am wondering if it achieves the purpose. when processing a fetchevent, applicationprocessor just calls requestmanagers.fetchrequestmanager.drain(). if there is nothing to drain, an empty queue is returned immediately. this will unblock fetchevent to return immediately without waiting for the poll time?",0,0.965452253818512
1333599432,14406,lianetm,2023-09-21T21:00:26Z,is this an old comment i guess?,0,0.9803469181060791
1333605133,14406,lianetm,2023-09-21T21:07:38Z,i find this name combination closer+assertopen kind of confusing. i even think it would it be easier to follow if we just had the explicit check `if(isclose()) throw` here,-1,0.7129931449890137
1333613388,14406,lianetm,2023-09-21T21:17:24Z,do we expect to have nulls here even if these come from the blockingqueue that does not accept nulls?,0,0.9917562007904053
1333616692,14406,philipnee,2023-09-21T21:21:51Z,have you ran into a scenario that the module is null?,0,0.9917077422142029
1333617066,14406,lianetm,2023-09-21T21:22:23Z,"need ""to"" throw",0,0.9838152527809143
1333620613,14406,lianetm,2023-09-21T21:27:18Z,debug level better? (same for all other log lines in this func),0,0.9876101016998291
1333698259,14406,junrao,2023-09-21T23:36:53Z,is this request guaranteed to be sent when the consumer is closed? do we need this guarantee?,0,0.9946010112762451
1333708126,14406,junrao,2023-09-21T23:55:37Z,is the rebalance callback called here?,0,0.9925219416618347
1333739561,14406,philipnee,2023-09-22T00:36:53Z,"current log is at trace level: `log.trace(""closing the kafka consumer"");`",0,0.9950194358825684
1333760307,14406,junrao,2023-09-22T01:07:10Z,"this logic is a bit weird. applicationeventprocessor handles fetchevent by draining all completefetches from fetchbuffer, but here we are just adding them back to fetchbuffer again.",-1,0.9650339484214783
1334577989,14406,junrao,2023-09-22T16:08:24Z,could we describe what this class does? it's a bit weird the `backgroundeventprocessor.process` is called from `prototypeasyncconsumer` in the foreground.,-1,0.8871024250984192
1334591301,14406,junrao,2023-09-22T16:20:46Z,this causes an exception to be thrown in the application thread. it seems that we should avoid doing that for at least the retriable exceptions? ditto below.,0,0.9929454922676086
1334595965,14406,junrao,2023-09-22T16:25:38Z,it seems that timer.currenttimems() doesn't change btw poll start and poll end because of the way that timer is constructed?,0,0.9912579655647278
1334596869,14406,junrao,2023-09-22T16:26:33Z,is that todo still needed since we implemented `poll` now?,0,0.9932793974876404
1334617225,14406,junrao,2023-09-22T16:47:30Z,should we wait for the time here like what we did in `refreshcommittedoffsetsifneeded`?,0,0.9943988919258118
1334630287,14406,junrao,2023-09-22T17:01:40Z,"this is an existing issue, but i don't quite understand this comment. in other places, we just use `time` directly assuming it's never null.",0,0.974648654460907
1334636045,14406,junrao,2023-09-22T17:08:20Z,do we need this since closetimer is already bounded by requesttimeoutms?,0,0.9941030144691467
1334639334,14406,junrao,2023-09-22T17:11:53Z,we are not really passing in closetimer below.,0,0.9754323363304138
1334651469,14406,junrao,2023-09-22T17:25:40Z,could we remove `this` for better consistency?,0,0.9922063946723938
1334655265,14406,junrao,2023-09-22T17:29:54Z,"we haven't implemented the group subscription logic in prototypeasyncconsumer, right? ditto for the pattern subscribe below.",0,0.9940487146377563
1334668882,14406,junrao,2023-09-22T17:45:36Z,"`fetchposition` is updated in the background thread, right? so, it could change anytime during the `poll` call in the consumer. do we need the info on `fetchposition` to be accurately reflected here?",0,0.9928216338157654
1334677351,14406,junrao,2023-09-22T17:55:10Z,the comment is a bit confusing. the code doesn't seem to do anything related to offsets and rebalance.,-1,0.7782058119773865
1334678608,14406,junrao,2023-09-22T17:56:44Z,no partitions are provided to this method.,0,0.994513988494873
1334719457,14406,junrao,2023-09-22T18:48:26Z,"this is an existing issue, but i am not sure why the comment mentions `fetchrecords`.",0,0.9849289059638977
1334720342,14406,junrao,2023-09-22T18:49:38Z,could we update the javadoc?,0,0.9946159720420837
1334733479,14406,junrao,2023-09-22T19:06:57Z,there is still a mention of `deserializers` above.,0,0.9904967546463013
1334734342,14406,junrao,2023-09-22T19:08:09Z,extra new line,0,0.9933451414108276
1334738863,14406,junrao,2023-09-22T19:14:25Z,it seems that none of the request managers implements `close`. does this need to be `closeable`?,0,0.9929332733154297
1334740555,14406,junrao,2023-09-22T19:16:49Z,`requestmanagers` doesn't take .,0,0.9905439019203186
1334821243,14406,junrao,2023-09-22T21:13:33Z,the noid part is a bit confusing. assignfromusersingletopic?,0,0.6053625345230103
1334829050,14406,junrao,2023-09-22T21:27:55Z,"`client.updatemetadata `eventually calls `metadata.updatewithcurrentrequestversion`. so, not sure why we are updating cluster metadata twice with different values.",0,0.9753869771957397
1334857621,14406,junrao,2023-09-22T22:25:49Z,could we be consistent with the use of `this`?,0,0.9902670979499817
1334860526,14406,junrao,2023-09-22T22:31:22Z,consumerclient => networkclientdelegate?,0,0.9951351284980774
1334869446,14406,kirktrue,2023-09-22T22:52:25Z,"yes, just to set off the child `subpackage` element more cleanly. but i can remove it if you'd like.",0,0.9950944185256958
1334870059,14406,kirktrue,2023-09-22T22:54:15Z,"are you saying that the incoming error (`t`) is already logged before the callback is invoked? if so, then yeah, it makes sense to remove it here.",0,0.9920454025268555
1334870549,14406,kirktrue,2023-09-22T22:55:37Z,"sorry, can you elaborate? where is the error logged other than this?",-1,0.9894950985908508
1334870694,14406,kirktrue,2023-09-22T22:56:06Z,yep. i'll remove it.,0,0.9825127124786377
1334870735,14406,kirktrue,2023-09-22T22:56:12Z,will remove.,0,0.9920058846473694
1334870782,14406,kirktrue,2023-09-22T22:56:20Z,ok. i'll change it. thanks.,1,0.9572823643684387
1334871262,14406,kirktrue,2023-09-22T22:57:46Z,"hmm... i can see your point. the naming is definitely confusing :grinning_squinting_face: it used to be named `maybethrowillegalstateexception()`, so it could be worse.",0,0.42973792552948
1334871627,14406,kirktrue,2023-09-22T22:59:03Z,i found the occasional `null` event in the past. the collections didn't prevent it. maybe it's an extra level of paranoia that has outlived its purpose?,0,0.9366002082824707
1334872019,14406,kirktrue,2023-09-22T23:00:22Z,do you mean if `networkclientdelegate` is still `null`? yes. that can happen if the object is constructed and then used without calling `initializeresources` beforehand. perhaps a comment or a restructuring of the code could be made.,0,0.9945703148841858
1334872655,14406,kirktrue,2023-09-22T23:02:24Z,"i need ""to"" proofread my comments more thoroughly :grinning_face_with_smiling_eyes:",1,0.9820263981819153
1334873271,14406,kirktrue,2023-09-22T23:04:12Z,"i'll change the log line at the start of the method from `info` to `trace` and leave the log line at the end of the method as `debug`. in so doing, both will match the levels in `kafkaconsumer.close()`.",0,0.9944614171981812
1334876767,14406,kirktrue,2023-09-22T23:16:05Z,"not yet, no. i'll remove the comment because we haven't implemented the callback mechanism here. it's in a draft pr #14357. we do have the _general_ mechanism for how we'll end up calling them, which is via the `backgroundeventprocessor`. i did notice a difference between `kafkaconsumer` and `prototypeasyncconsumer`the former is potentially invoking the rebalance callback on each iteration of the loop inside `poll()` whereas the latter implementation is only calling it once at the top of `poll()`. i'll change ours to work in a similar fashion.",0,0.9802139401435852
1334878210,14406,kirktrue,2023-09-22T23:21:07Z,"yes, this is ugly and ripe for reworking. there are two buffers to store `completedfetch`es: one for the background thread and one for the application thread. this way the background thread can write to _its_ buffer and the application thread can read from _its_ buffer without them stepping on each other's toes.",-1,0.9795235395431519
1334878765,14406,kirktrue,2023-09-22T23:23:21Z,"yeah, that is a bit weird. it's the same with `applicationeventprocessor.process()` being called from the background thread. each thread ""processes"" the events it received from the other thread.",-1,0.9715943932533264
1334878800,14406,kirktrue,2023-09-22T23:23:31Z,"but yes, i'll definitely add some comments here.",0,0.9923856258392334
1334879279,14406,kirktrue,2023-09-22T23:25:15Z,my understanding was that the failure is only propagated to this callback once the retries have been exhausted. am i misunderstanding?,0,0.6533452272415161
1334881403,14406,kirktrue,2023-09-22T23:32:36Z,"the `timer` is created inside `poll()` is passed into the other methods. the only one that updates it directly is `pollforfetches` which updates it only in the `finally` block at the end: [code block] i double-checked our implementation against `kafkaconsumer` and they seem to match in that regard. `kafkaconsumer` passes the `timer` into the methods related to the consumer coordinator, but since we don't have that functionality just yet, we don't.",0,0.9945295453071594
1334881860,14406,kirktrue,2023-09-22T23:34:21Z,good question. do we need to update our `poll` implementation to include the wakeup mechanism?,1,0.8518055081367493
1334882482,14406,kirktrue,2023-09-22T23:37:13Z,do you remember why we opted for a non-blocking event here?,0,0.9940590858459473
1334882689,14406,kirktrue,2023-09-22T23:38:10Z,`offsetfetcher.resetpositionsifneeded()` is used in the `kafkaconsumer` and it appears to send off the reset positions request asynchronously :thinking_face:,0,0.9103343486785889
1334884022,14406,kirktrue,2023-09-22T23:43:15Z,"`createtimerforrequest` appears to only be called from `close()`. some of the constructors' contents are wrapped in a `try-catch` block that attempts to close the consumer on initialization failure. so if the constructor fails before we initialize the `time` instance variable, it would be `null` when we attempt to `close()` up any resources. i'm assuming based on that comment that only `close()` has that concern about using `time`.",0,0.991905927658081
1334885217,14406,kirktrue,2023-09-22T23:48:32Z,true. there doesn't appear to be any blocking calls made from the `fetchbuffer.close()` path. i'll dig around some more.,0,0.9888584613800049
1334885226,14406,kirktrue,2023-09-22T23:48:34Z,true. we don't have to account for time it takes for the coordinator to close because we don't have a coordinator :grinning_face_with_smiling_eyes:. i'll remove that.,1,0.8690248131752014
1334885719,14406,kirktrue,2023-09-22T23:50:42Z,"the inclusion of `this` here is, in fact, to be more consistent... with the code in `kafkaconsumer.subscribe()`. at one point we took as much of the code from `kafkaconsumer` as we could, warts and all. i'll remove this `this`, though.",0,0.98939448595047
1334885895,14406,kirktrue,2023-09-22T23:51:38Z,"there are several other places in the `prototypeasyncconsumer` that we do things sub-optimally, just to match `kafkaconsumer`.",0,0.991853654384613
1334886142,14406,kirktrue,2023-09-22T23:52:47Z,i'll dig in on this a little deeper.,0,0.9519262313842773
1334886595,14406,kirktrue,2023-09-22T23:54:45Z,this is another case of grabbing the code verbatim from `kafkaconsumer`. does the code comment make sense to you?,0,0.9937053322792053
1334886820,14406,kirktrue,2023-09-22T23:55:41Z,good catch. old comments :frowning_face_with_open_mouth:,1,0.9823082685470581
1334888478,14406,kirktrue,2023-09-23T00:03:26Z,"i think i wrote the initial comment :grimacing_face: i was trying to explain that `drain()`-ing a `completedfetch` is like `close()`-ing it, in that we free its resources. but it's _unlike_ `close()` because we can technically still call `fetchrecords()` on it without throwing some sort of `illegalstateexception` or anything. is this better? or should i just scrap the whole comment altogether?",-1,0.9814789295196533
1334892999,14406,kirktrue,2023-09-23T00:28:08Z,will do.,0,0.9465230703353882
1334893011,14406,kirktrue,2023-09-23T00:28:13Z,will exorcise them.,0,0.9771271347999573
1334893046,14406,kirktrue,2023-09-23T00:28:28Z,i'll remove it.,0,0.9835598468780518
1334893631,14406,kirktrue,2023-09-23T00:32:19Z,"the `fetchrequestmanager` does by virtue of extending from `abstractfetch`. the sole reason for that it is so that it can prepare to send requests to the brokers to close their fetch sessions. it's kind of kludgey the way it's done, so i'll take another look to see if it can be done more cleanly.",0,0.5042980313301086
1334894116,14406,kirktrue,2023-09-23T00:35:10Z,thanks for the catch!,1,0.8897817730903625
1334896241,14406,kirktrue,2023-09-23T00:49:26Z,removed the extra line.,0,0.9891093969345093
1335942472,14406,lianetm,2023-09-25T14:07:00Z,"my understanding is that in that case it won't continuously fetch from the old leader because of the partition subscription state, which will transition to `awaiting_validation` (not a valid state for fetching). the moment a new metadata is discovered, [a link], so the [a link] will not fetch from them. to complete the validation picture, once the `offsetforleaderepoch` response is received, the subscription state will transition to `fetching` again and fetch requests should resume for that partition. my thoughts but please correct me if i'm missing something from the fetching story.",0,0.9778387546539307
1336253362,14406,junrao,2023-09-25T18:31:51Z,: thanks for the reply. that's my understanding too. my question was what happens before the new metadata is received. will the consumer continuously fetch from the older leader?,1,0.9716598987579346
1336273549,14406,junrao,2023-09-25T18:52:21Z,should this comment be moved to above the `client.prepareresponse` below?,0,0.9957576394081116
1337443244,14406,kirktrue,2023-09-26T15:54:24Z,i reverted the change to the comment. i don't remember changing it :man_shrugging:,1,0.48272228240966797
1337444033,14406,kirktrue,2023-09-26T15:55:02Z,i've updated this so that the `close()` method is a lot cleaner.,0,0.9899206161499023
1337444456,14406,kirktrue,2023-09-26T15:55:21Z,removed the unnecessary timer.,0,0.9903899431228638
1337444877,14406,kirktrue,2023-09-26T15:55:43Z,"`createtimerforrequest()` is no longer used, so marking this as resolved.",0,0.9947779178619385
1337660657,14406,kirktrue,2023-09-26T19:02:44Z,i've changed the mechanism to handle the responses from fetch such that we should now properly block until results are available.,0,0.9936085939407349
1337661714,14406,kirktrue,2023-09-26T19:03:54Z,"this has been reworked as part of a recent change. not only are there are still two `fetchbuffer`s, but i've _added_ a blocking queue between them since the `fetchbuffer` should not be updated on the `future` callback, since that is updated on another thread and `fetchbuffer` is not thread safe.",0,0.994062602519989
1337662384,14406,kirktrue,2023-09-26T19:04:41Z,"it is currently being worked on for the kip-848 work, so its development is running in parallel.",0,0.9924771189689636
1337849711,14406,kirktrue,2023-09-26T22:39:41Z,it looks like the other call sites that add error events to the handler also log them :man_shrugging:,0,0.7771837115287781
1337881130,14406,kirktrue,2023-09-26T23:43:17Z,"in the refactored version, the logging is not as verbose.",0,0.9854564070701599
1337881557,14406,kirktrue,2023-09-26T23:44:08Z,"this code has been refactored, but it still has the check, just to be paranoid.",0,0.8439748883247375
1337882369,14406,kirktrue,2023-09-26T23:45:52Z,added a brief comment to explain this case.,0,0.9909284710884094
1338972414,14406,philipnee,2023-09-27T17:35:33Z,"i am actually not sure if we need this as networkclientdelegate is already doing the connection checking. if the node is unavailable for reconnection, then it would fail the unsentrequest and presumably trigger a retry. the original code does the connection checking because the request is sent right after its creation; however, there's a time gap between the creation and the actual network io. i think it is harmless to leave it here but it would be great if we could clean them up later.",0,0.494387686252594
1338973379,14406,philipnee,2023-09-27T17:36:21Z,"per previous comment - if we actually clean up the code, we should only care if there's a fetchtarget or not.",0,0.9881672263145447
1339157715,14406,philipnee,2023-09-27T20:13:48Z,we are logging debug for the request manager but info here. just want to make sure we are consistent with the logging level.,0,0.9928130507469177
1339158103,14406,philipnee,2023-09-27T20:14:09Z,thanks for removing the boolean.,1,0.5695096254348755
1339158811,14406,philipnee,2023-09-27T20:14:54Z,my only fear is that this could spam the trace log,-1,0.928023636341095
1340402407,14406,philipnee,2023-09-28T16:26:40Z,should we use ( ) instead of { } ?,0,0.9938748478889465
1340690791,14406,philipnee,2023-09-28T21:36:39Z,"since we also need to send offsetcommit upon closing, maybe it is best to poll the networkclientdelegate upon closing.",0,0.9903282523155212
1342913561,14406,junrao,2023-10-02T16:29:31Z,could we describe what `poll` does?,0,0.9912809729576111
1342950743,14406,junrao,2023-10-02T17:11:23Z,the above comment that this class is only used from a single thread seems incorrect. the background thread adds fetched data into `completedfetches` and `prototypeasyncconsumer` drains `completedfetches` through `fetchcollector.collectfetch(fetchbuffer)`. there is actually very subtle synchronization between the two threads. could we document the correct way of using this class and how we achieve synchronization so that future developers don't break it?,0,0.9906796813011169
1342984775,14406,junrao,2023-10-02T17:50:15Z,"hmm, with this logic, there is a short window between `completedfetch` in `fetchresults` and `completedfetch` be added to back to `fetchbuffer`. during this window, `backgroundthread` could make a `poll` call, see no buffered data in `fetchbuffer` and fetch the same offset again? then the consumer could see duplicated data because of this.",0,0.9842333197593689
1343046752,14406,junrao,2023-10-02T18:58:21Z,"earlier, we have ""do not have a valid position and are not awaiting reset"". the reset there and the reset here mean different things. the former refers to resetting the offset based on offsetforleaderepoch and the latter refers to resetting the offset to either the earliest or latest. it would be useful to make this clear.",0,0.9912693500518799
1343059742,14406,junrao,2023-10-02T19:11:22Z,"it still seems weird that we only use the timer for `refreshcommittedoffsetsifneeded`, but not for other cases where we don't have valid fetch positions. for example, if all partitions are in await_validation state, it seems that prototypeasyncconsumer.poll() will just go in a busy loop, which is not efficient.",-1,0.9577807784080505
1343061015,14406,junrao,2023-10-02T19:12:57Z,"if `initializingpartitions` is empty, do we still send the offsetfetch request? i didn't see the logic for short-circuiting.",0,0.9927375912666321
1343147889,14406,junrao,2023-10-02T20:46:12Z,is `this` needed?,0,0.9953250885009766
1343150605,14406,junrao,2023-10-02T20:49:09Z,"to be consistent with other places, it seems that we want to combine this with the previous line. ditto below.",0,0.9942647814750671
1343163505,14406,junrao,2023-10-02T21:04:40Z,where is the callback handler?,0,0.9948129653930664
1343232059,14406,junrao,2023-10-02T22:44:17Z,"at this stage, we are just propagating connection level errors like disconnectexception, which is retriable. so, it seems that we shouldn't throw this error back to the application. ditto in `pollonclose`.",0,0.9904746413230896
1343246844,14406,junrao,2023-10-02T23:12:14Z,"if the background thread dies, should we throw an exception to the user thread on the next `poll` call?",0,0.989401638507843
1343251934,14406,junrao,2023-10-02T23:21:55Z,"instead of using `currenttimems`, we need to use `timer.currenttimems` to pick up the latest time, right?",0,0.9916449189186096
1343259817,14406,junrao,2023-10-02T23:40:32Z,is this comment addressed?,0,0.9930742979049683
1343265294,14406,junrao,2023-10-02T23:52:58Z,fetchposition is updated in the user thread.,0,0.9942980408668518
1343266219,14406,junrao,2023-10-02T23:54:58Z,was this comment addressed?,0,0.9917539358139038
1344756235,14406,kirktrue,2023-10-03T21:21:19Z,"it is now run as part of the `consumer.close()` process, yes.",0,0.9946656227111816
1344758105,14406,kirktrue,2023-10-03T21:22:10Z,"no, not yet. do we want to add something for wakeup here, or should i remove the comment? thanks.",1,0.7782800197601318
1344762836,14406,kirktrue,2023-10-03T21:26:43Z,can you look at the new `defaultbackgroundthread.runatclose()` method i added? do we need to update the `commitrequestmanager` to implement the `pollonclose()` api i added?,0,0.995712161064148
1344780023,14406,kirktrue,2023-10-03T21:47:18Z,updated to overload the `assignfromuser` method name with a single `topicpartition`. then that single partition is used to return the topic name to reduce the number of times `noid` appears in that code.,0,0.9934054613113403
1344786987,14406,kirktrue,2023-10-03T21:54:37Z,"good question. as a test, i made this change locally: [code block] i ran the tests and they all passed, so i don't know why it was written like that :man_shrugging: this code in `fetchrequestmanagertest` is copied from `fetchertest`; as much as we could was left verbatim.",1,0.9716014862060547
1344795530,14406,kirktrue,2023-10-03T22:03:44Z,done.,0,0.9897913336753845
1344799794,14406,kirktrue,2023-10-03T22:08:14Z,done.,0,0.9897913336753845
1344801112,14406,kirktrue,2023-10-03T22:09:55Z,fixed in both original `fetchertest` and the copied `fetchrequestmanagertest`.,0,0.9939883947372437
1344822614,14406,kirktrue,2023-10-03T22:34:18Z,i added documentation to the `requestmanager` interface with pointers to it from the methods in `fetchrequestmanager`.,0,0.9944818019866943
1344897098,14406,kirktrue,2023-10-04T00:05:17Z,"yes, the process is a bit convoluted... to perform the process of moving the fetched records from the background thread to the application thread and then on to the user, `prototypeasyncconsumer` has these three instance variables: 1. `fetchresults` 2. `fetchbuffer` 3. `fetchcollector` all three of those objects are created in the application thread when the `prototypeasyncconsumer` is created. `fetchbuffer` and `fetchcollector` are only ever referenced by the application thread; `fetchresults`, however, is used by **both** threads. `fetchresults` is referenced in the background thread when it is used in the `fetchevent` callback in the `sendfetches()` method: [code block] since the `whencomplete()` method is executed when the background thread ""completes"" the `future`, `fetchresults` is thus modified on the background thread. the rest of the process should occur on the application thread. during calls to `poll()` on the application thread, data from `fetchresults` is moved to `fetchbuffer` in `pollforfetches()`: [code block] the data in `fetchbuffer` is later extracted in `fetchcollector` during the `poll()` process, but this again is on the application thread. this roundabout way of getting the data is specifically done so that we don't write to the `fetchbuffer` inadvertently from the background thread. hence these javadoc comment for `fetchresults`: [code block] this is a rough idea of what happens on the background thread: then later in the application thread during `poll()`: let me know if that makes sense or if there is still a gap that i'm not seeing. i can write the above up (with any changes you'd like) in code comments.",0,0.889279305934906
1344899034,14406,kirktrue,2023-10-04T00:09:08Z,i've removed the qualifiers where they're not needed.,0,0.9936936497688293
1344900260,14406,kirktrue,2023-10-04T00:11:31Z,fixed.,0,0.9905837774276733
1344900777,14406,kirktrue,2023-10-04T00:12:12Z,fixed.,0,0.9905837774276733
1346179200,14406,junrao,2023-10-04T16:45:53Z,": thanks for the explanation. two followup questions. 1. the background thread has the following path` fetchrequestmanager.poll -> handlefetchresponse -> fetchbuffer.add(completedfetch)`. so, it seems that the background thread also writes the fetched data to `fetchbuffer`. 2. this is related to my other [a link]. the background thread has the following path `fetchrequestmanager.poll -> abstractfetch.preparefetchrequests -> abstractfetch.fetchablepartitions -> reads fetchbuffer.bufferedpartitions()`. since fetchbuffer is written by the application thread, how do we coordinate the synchronization btw the two threads?",1,0.9738346934318542
1346234546,14406,kirktrue,2023-10-04T17:33:01Z,you're right. thanks for catching that! changed.,1,0.9970722198486328
1346270372,14406,kirktrue,2023-10-04T18:05:36Z,yes. i added a check that it's not closed at the top of `runonce()`.,0,0.9920793175697327
1346278813,14406,kirktrue,2023-10-04T18:13:15Z,this was an outdated comment. fixed.,0,0.9667684435844421
1346451911,14406,junrao,2023-10-04T20:54:01Z,background network thread => network thread ?,0,0.994152843952179
1346463369,14406,junrao,2023-10-04T21:05:03Z,"this will cause a logging of error during normal shutting down of the consumer, right? it would be useful to avoid that.",0,0.9906129837036133
1346493970,14406,philipnee,2023-10-04T21:35:27Z,thanks - i think we will need to do that. i created kafka-15548 to handle the closing task.,1,0.9220893979072571
1346504058,14406,kirktrue,2023-10-04T21:47:38Z,i removed the error propagation (and logging).,0,0.990528404712677
1346508562,14406,kirktrue,2023-10-04T21:51:54Z,any reason we don't check if `initializingpartitions` is non-empty before creating the `offsetfetchapplicationevent`?,0,0.9873130917549133
1346517075,14406,kirktrue,2023-10-04T21:59:23Z,"regardless of the return value of `updatefetchpositions()`, `poll()` will still go on to call `pollforfetches()` which will block for data availability or timeout expiration.",0,0.9916930794715881
1346545044,14406,kirktrue,2023-10-04T22:32:56Z,"for point #1, the background thread has a _separate_ fetch buffer. it doesn't write to the same object. the application thread `fetchbuffer` is created in `prototypeasyncconsumer` and the background thread `fetchbuffer` is created in `abstractfetch`. for point #2, i think your [a link] is correct. i'm not yet sure how to maintain those two fetch buffers separately without running into that race condition.",0,0.9844735860824585
1346546088,14406,kirktrue,2023-10-04T22:34:22Z,"yes, i can see that now. given that there are two separate `fetchbuffer`s and the way they're populated, i think the window is actually a bit bigger. i need to noodle on this for a bit.",0,0.9807475209236145
1346562666,14406,junrao,2023-10-04T22:58:01Z,`fetcher` is a `testablefetchrequestmanager`. could we just do `poll` instead of `fetcher.poll`?,0,0.992728590965271
1346567694,14406,junrao,2023-10-04T23:06:49Z,"where is the callback? also,` networkclient#send` happens in the caller, not here, right?",0,0.9946750402450562
1346572630,14406,junrao,2023-10-04T23:15:53Z,it's very confusing that the above two `handlefetchresponse` refer to different methods. could we name them differently?,-1,0.9130550026893616
1346604856,14406,kirktrue,2023-10-05T00:00:01Z,"yes, it would, but what do you expect when you're logging at `trace`? :face_with_tongue:",0,0.9485598206520081
1346606768,14406,kirktrue,2023-10-05T00:02:48Z,changed to debug,0,0.9914407730102539
1346607807,14406,kirktrue,2023-10-05T00:04:39Z,i've removed the logging and error forwarding as it is handled in the `networkclientdelegate` layer.,0,0.9942208528518677
1346612374,14406,kirktrue,2023-10-05T00:11:20Z,"at the beginning of the `kafkaconsumer.poll()` loop, it does this: [code block] do we support _disabling_ wake-ups? i don't see the analogue to `maybetriggerwakeup()`, `disablewakeups()`, etc. in `wakeuptrigger`. can we emulate what `kafkaconsumer` is doing in the `poll()` loop with our current implementation? if not, i'd prefer to a) remove the comment, and b) file a new jira. thoughts?",0,0.9915565252304077
1346613925,14406,kirktrue,2023-10-05T00:12:42Z,i'll review with .,0,0.9888777136802673
1346615044,14406,kirktrue,2023-10-05T00:14:29Z,`abstractfetch` is used by both the current `fetcher` as well as the `fetchrequestmanager`. i'd have to refactor the code to rid ourselves of it. what do you think about filing a new jira to track a follow-up change for this?,0,0.9928475618362427
1346616102,14406,kirktrue,2023-10-05T00:16:29Z,"i'd like to file a separate jira for this, only because it's been this way for a while. i need more time to understand it before changing it, and would love to get the integration tests and perhaps even system tests online before changing it. thoughts?",1,0.5561836957931519
1346616646,14406,kirktrue,2023-10-05T00:17:22Z,i think i need to circle back with to get her input on this as she's much closer to it than i am.,0,0.9602991938591003
1347629215,14406,junrao,2023-10-05T15:39:53Z,"yes, it's fine to have a separate jira to clean this up.",0,0.9881902933120728
1347692761,14406,junrao,2023-10-05T16:28:21Z,"this logic looks correct in the test. however, in the actual code, there could be unconsumed data in `prototypeasyncconsumer.fetchresults `and `prototypeasyncconsumer.fetchbuffer`. how do we prevent those data from being returned to the user? same question when partition is paused.",0,0.993918776512146
1347727982,14406,junrao,2023-10-05T16:57:13Z,"hmm, should the code be commented out? it doesn't match the comment above.",0,0.9758565425872803
1347742323,14406,junrao,2023-10-05T17:10:13Z,"i don't quite understand these 3 lines. why are we polling the fetcher again since typically this doesn't happen after pollonclose is called on the fetcher? also, for the test as it is, it seems that the first request is the one with the final epoch, not the second?",0,0.7217182517051697
1347748114,14406,junrao,2023-10-05T17:15:36Z,does this test subsume `testinflightfetchonpendingpartitions`?,0,0.9948707818984985
1347751320,14406,junrao,2023-10-05T17:18:29Z,should the comment be moved to just above `client.prepareresponse` below?,0,0.9950684309005737
1347752851,14406,lianetm,2023-10-05T17:19:55Z,"agree , i will update the comments to better explain. the bottom line is that positions may be reset in 2 different ways: - using the committed offsets (retrieved with `offsetfetch` sent to the group coordinator). this if committed offsets are in use. - using the partition offsets (retrieved with `listoffset` sent to the partition leader + reset strategy) the `offsetforleaderepoch` request is the one used to validate positions, basically retrieving epoch and end offsets from a leader, to validate the the current position held on the consumer side. makes sense? i will update the comments for each step.",0,0.9820156097412109
1347759469,14406,junrao,2023-10-05T17:26:00Z,should the comment be moved to just above client.prepareresponse below? ditto in a few other places.,0,0.9948450326919556
1347768459,14406,junrao,2023-10-05T17:34:57Z,is the upgrade on the server or the client side?,0,0.9933050274848938
1347777973,14406,lianetm,2023-10-05T17:43:31Z,i updated the comments in this other pr that i had just opened [a link],0,0.9948712587356567
1347791680,14406,junrao,2023-10-05T17:56:33Z,it would be useful to clarify that `fetchedrecords()` is called deep inside `fetcher.collectfetch()`. ditto in a few other places mentioning `fetchedrecords()`.,0,0.9932329654693604
1347799078,14406,kirktrue,2023-10-05T18:03:41Z,i'm planning to remove the comments and create a new jira to track this change. cc,0,0.9941233992576599
1347806531,14406,junrao,2023-10-05T18:11:27Z,be consistent with usage of `this`.,0,0.9929643869400024
1347811905,14406,junrao,2023-10-05T18:17:09Z,where is the resizing?,0,0.9928118586540222
1347832688,14406,junrao,2023-10-05T18:40:09Z,its been => it has been,0,0.9890172481536865
1347834317,14406,junrao,2023-10-05T18:41:55Z,this seems unnecessary given the `assertemptyfetch` below?,0,0.987443745136261
1347865054,14406,kirktrue,2023-10-05T19:14:43Z,todo: fix the comment in the code and explain about the applicationeventprocessor.,0,0.9944677352905273
1347874026,14406,kirktrue,2023-10-05T19:25:07Z,todo: find case where we _might_ be sending rpcs with empty sets.,0,0.9937979578971863
1347874693,14406,kirktrue,2023-10-05T19:25:55Z,todo: to create a separate ticket to review/fix.,0,0.9947817921638489
1347883272,14406,junrao,2023-10-05T19:35:43Z,could we write this as parameterized test to avoid duplicating the code in the next few tests?,0,0.9931609630584717
1347884952,14406,junrao,2023-10-05T19:37:30Z,should we assert there is no pending request after this?,0,0.9934465289115906
1347885711,14406,lianetm,2023-10-05T19:38:19Z,"i know for sure we skip empty lists and don't send requests for all the partition offsets related events (on the `offsetsrequestmanager` on [a link], [a link] and [a link]. that being said, here is about fetching the committed offsets, and i don't see a clear early return but maybe i'm missing how it happens so let's wait for to give it a closer look.",0,0.9906678795814514
1347894828,14406,junrao,2023-10-05T19:45:34Z,it would be useful to add a comment why offset is not reset yet on `offset_out_of_range`. this is because the error handling happens when new records are polled.,0,0.9938755631446838
1347906316,14406,junrao,2023-10-05T19:57:07Z,could this be replaced with `fetchrecordsinto`?,0,0.994358479976654
1347908197,14406,junrao,2023-10-05T19:58:49Z,is this redundant given the test in 1811?,0,0.9805752038955688
1347910980,14406,junrao,2023-10-05T20:01:53Z,"hmm, why don't we return records from other partitions since maxrecords is maxint?",0,0.9779119491577148
1347913781,14406,junrao,2023-10-05T20:05:21Z,why don't we return records from tp1 since maxrecords is 2?,0,0.9921280145645142
1347914377,14406,junrao,2023-10-05T20:06:06Z,affect => effect,0,0.9630556702613831
1347923838,14406,junrao,2023-10-05T20:17:28Z,what's the purpose of this code? the receive is delayed and thus there is no throttledelayms received in the client.,0,0.9935142993927002
1347931744,14406,junrao,2023-10-05T20:26:15Z,why is `recordsfetchleadmin` different from `partitionlead` given there is only 1 assigned partition?,0,0.987849771976471
1347936262,14406,junrao,2023-10-05T20:31:04Z,"`expectedbytes` is calculated as total, instead of avg. is this correct?",0,0.9948722720146179
1347938331,14406,junrao,2023-10-05T20:33:31Z,"the name is a bit mis-leading. we get a full response, but skipped an offset before the fetch position.",0,0.6398376226425171
1347960253,14406,junrao,2023-10-05T20:54:36Z,the expected and actual are reversed.,0,0.9847748875617981
1348009426,14406,kirktrue,2023-10-05T21:36:47Z,i filed kafka-15555 as a separate follow-up task to handle the wakeup mechanics.,0,0.9887035489082336
1348009622,14406,kirktrue,2023-10-05T21:37:03Z,i will remove the temporary comment in a bit.,0,0.9891188144683838
1348011353,14406,kirktrue,2023-10-05T21:39:43Z,removed.,0,0.9612457156181335
1348019537,14406,junrao,2023-10-05T21:45:42Z,capitalize in?,0,0.9937751293182373
1348029408,14406,kirktrue,2023-10-05T21:58:16Z,"i have filed kafka-15556 (_remove networkclientdelegate methods isunavailable, maybethrowauthfailure, and tryconnect_) to address this issue since it's affecting other `requestmanager` implementations.",0,0.9940308928489685
1348029671,14406,kirktrue,2023-10-05T21:58:45Z,true. we'll handle that in kafka-15556.,0,0.9908360242843628
1348047927,14406,kirktrue,2023-10-05T22:14:19Z,i filed kafka-15557 (_fix duplicate metadata update in fetcher tests_) to address this issue.,0,0.9934177398681641
1348055761,14406,kirktrue,2023-10-05T22:21:17Z,created kafka-15558 (_determine if timer should be used elsewhere in prototypeasyncconsumer.updatefetchpositions()_) to address separately as the given implementation is the same as the current implementation. perhaps fixes in both `consumer` implementations is warranted?,0,0.9955689311027527
1348062340,14406,junrao,2023-10-05T22:22:48Z,node => note?,0,0.9943700432777405
1348062596,14406,kirktrue,2023-10-05T22:22:55Z,filed kafka-15551 (_evaluate conditions for short circuiting consumer api calls_) to implement this consistently.,0,0.9949743747711182
1348083698,14406,kirktrue,2023-10-05T23:00:07Z,"yes, it appears that it will continue to attempt to fetch from the old leader. when a fetch response is received from the broker and we notice that it has an error, we call `fetchcollector.handleinitializeerrors()` to deal with the different error conditions. when it notices that the error is `fenced_leader_epoch`, it will execute these two statements (from the `fetchutils.requestmetadataupdate()` method): [code block] that's all it does. the logic doesn't update the `fetchstate` for that partition. it doesn't clear out the leader epoch. nothing. the next time the user calls the `consumer.poll()` method, the `fetcher`/`fetchrequestmanager` will determine for which partitions we should issue `fetch` rpcs. the first step is to call the `subscriptionstate.fetchablepartitions()` method which checks each partition: [code block] because we didn't change anything in the underlying state of the partition in `subscriptionstate` previously, when the `topicpartitionstate.isfetchable()` method is invoked, it returns `true`. thus it is included in the list for which to fetch, and we will likely hit the same error.",0,0.9893401265144348
1348084921,14406,kirktrue,2023-10-05T23:02:32Z,the error message in `errors` for `fenced_leader_exception` states that this error is caused when...,0,0.9937760829925537
1348087535,14406,kirktrue,2023-10-05T23:07:55Z,"naively it seems like we want to clear/reset the partition's `metadata.leaderandepoch` value in the metadata cache locally. then in the fetch logic, that would allow us to skip that partition when we check for the presence of a leader: [code block]",0,0.9920543432235718
1348088801,14406,junrao,2023-10-05T23:10:38Z,should this comment be moved to just above `client.prepareresponse` below?,0,0.9955422282218933
1348091800,14406,junrao,2023-10-05T23:16:50Z,not sure what we are testing here. which handler is this referring to?,0,0.9314950108528137
1348107483,14406,junrao,2023-10-05T23:44:11Z,"hmm, the consumernetworkthread shouldn't die because of a topicauthorizationexception, right? ditto below.",0,0.9655369520187378
1348110728,14406,junrao,2023-10-05T23:51:45Z,which call is returning long.max_value?,0,0.9941704273223877
1348111165,14406,junrao,2023-10-05T23:52:48Z,does this test cover `testfindcoordinator`?,0,0.9951554536819458
1348903678,14406,junrao,2023-10-06T15:51:45Z,be consistent with the use of `this`. ditto below.,0,0.9925486445426941
1348915254,14406,junrao,2023-10-06T16:02:18Z,should we fix `this.records` above too?,0,0.9940902590751648
1348955876,14406,junrao,2023-10-06T16:31:47Z,this will run the network i/o in the application thread and break the model that all network i/os should be done in the background thread? will this be safe since now there could be two threads driving a shared networkclient?,0,0.9843674302101135
1348962486,14406,junrao,2023-10-06T16:38:11Z,called from by => called by,0,0.9924415349960327
1349023459,14406,junrao,2023-10-06T17:13:46Z,the auto offset commit seems to happen asynchronously? do we guarantee that the new owner of the unsubscribed partitions could pick up the latest committed offset?,0,0.9880831837654114
1349173413,14406,junrao,2023-10-06T18:18:01Z,"there is a subtle difference between transitioning to reset from initializing and transitioning to reset from `offsetoutofrangeexception` during fetch. in the latter, the application thread will call `fetchcollector.handleinitializeerrors()`. if there is no default offset reset policy, an `offsetoutofrangeexception` will be thrown to the application thread during `poll`, which is what we want. however, for the former, if there is no default offset reset policy, we simply ignore that partition through `offsetfetcherutils.getoffsetresettimestamp`. it seems in that case, the partition will be forever in the reset state and the application thread won't get the `offsetoutofrangeexception`.",0,0.9892759323120117
1349184330,14406,junrao,2023-10-06T18:28:19Z,"thanks, kirk. does the old consumer have the same behavior too? should we file a followup jira to improve this?",1,0.9505299925804138
1349221937,14406,philipnee,2023-10-06T19:11:48Z,"hi jun - i think we mostly use ""background thread"" in lieu of network thread, so maybe just use background thread?",0,0.9825237393379211
1349342751,14406,kirktrue,2023-10-06T21:44:50Z,"i will triple check, and if so, i will add a jira.",0,0.9933006763458252
1349343412,14406,kirktrue,2023-10-06T21:46:03Z,"i just pushed a proposed fix for this, which is basically to make the `fetchbuffer` thread safe. now there is only one fetch buffer for the consumer and is accessed by both threads.",0,0.9891077280044556
1349343753,14406,kirktrue,2023-10-06T21:46:49Z,you didn't see that i got fed up and changed the name of `defaultbackgroundthread` to `consumernetworkthread` :grinning_squinting_face:,1,0.5617554187774658
1349361459,14406,junrao,2023-10-06T22:15:08Z,"1. this is an existing issue. but the way we handle paused partitions in `collectfetch` seems problematic. the application thread first calls `fetchbuffer.setnextinlinefetch(null)` and then calls `fetchbuffer.addall(pausedcompletedfetches)`. this could leave a brief window where the paused partition is not included in either `nextinlinefetch` or `completedfetches`. if the background thread kicks in in that window, it could have fetched another chunk for that partition and added the response back to fetchbuffer. this would violate the assumption there is no more than one pending `completedfetch` per partition in fetchbuffer and could cause records returned not in offset order or duplicates to be returned. 2. the second existing issue is on the `fetchbuffer.setnextinlinefetch` call in `collectfetch`. the issue is that after all records are drained from `nextinlinefetch`. we only call `setnextinlinefetch` when there is a new `completedfetch`. however, until the drained `completedfetch` is removed from `nextinlinefetch`, the background thread can't fetch the next chunk. so, it seems that we will just be stuck here.",0,0.9682542085647583
1350689034,14406,junrao,2023-10-09T18:46:55Z,should we just remove this method?,0,0.9918308854103088
1350697908,14406,junrao,2023-10-09T18:54:59Z,the only useful part of this call is to wake up the consumernetworkthread so that it could prefetch the next data chunk. perhaps we could make that an explicit call like `applicationeventhandler.wakeup`?,0,0.9937757253646851
1350700366,14406,junrao,2023-10-09T18:57:04Z,this call seems unnecessary.,-1,0.671791136264801
1350703155,14406,junrao,2023-10-09T18:59:36Z,the comment seems obsolete since we are not fetching data below.,0,0.9788973331451416
1350707142,14406,junrao,2023-10-09T19:03:50Z,"`notemptycondition.await` returns false if the waiting time detectably elapsed before return from the method. this seems to be case to break out of the while loop. so, it seems that the `if` test should be reversed.",0,0.9933722019195557
1350773132,14406,junrao,2023-10-09T20:44:37Z,"currently, `fetchbuffer.setnextinlinefetch` and `fetchbuffer.poll` are separate operations and we expect the caller to call them in the right order to avoid a partition missing in fetchbuffer in the transition phase. it still leaves us with the situation that a partition could be in both completedfetches and nextinlinefetch at a particular time. it's not a problem for now, but it may be in the future. could we make them an atomic operation? if not, could we add a comment to document the correct usage of the api and the impact on partition being duplicated in completedfetches and nextinlinefetch?",0,0.9816727638244629
1351006437,14406,kirktrue,2023-10-09T23:58:22Z,removed.,0,0.9612457156181335
1351006470,14406,kirktrue,2023-10-09T23:58:29Z,done.,0,0.9897913336753845
1351011656,14406,kirktrue,2023-10-10T00:04:22Z,i removed the latter phrases to reduce confusion.,0,0.9774216413497925
1351011802,14406,kirktrue,2023-10-10T00:04:32Z,agreed. i've updated the names.,0,0.9691652655601501
1351042141,14406,kirktrue,2023-10-10T00:15:32Z,you're right. i've changed the core logic and updated that test (and another one that is essentially the same thing).,0,0.9786376357078552
1351054656,14406,kirktrue,2023-10-10T00:19:07Z,"yeah, i don't see it either. i'm not exactly sure what this testing is exercising. , do you remember?",0,0.9618390202522278
1351063405,14406,kirktrue,2023-10-10T00:24:28Z,yes. i've removed `testfindcoordinator()` as it's now superfluous.,0,0.9925516843795776
1351064502,14406,kirktrue,2023-10-10T00:26:59Z,"these are constructors, so even though it's not _strictly_ needed, i've been following the standard java convention.",0,0.98869788646698
1352874538,14406,kirktrue,2023-10-10T16:28:35Z,removed check to avoid.,0,0.9930881857872009
1352874719,14406,kirktrue,2023-10-10T16:28:44Z,done.,0,0.9897913336753845
1352876631,14406,kirktrue,2023-10-10T16:30:05Z,i've refactored the code to run it in the background thread again.,0,0.9923388957977295
1352879009,14406,kirktrue,2023-10-10T16:31:35Z,fixed.,0,0.9905837774276733
1357182316,14406,junrao,2023-10-12T17:43:47Z,not sure if this is a useful test since offsetsrequestmanager.resetpositionsifneeded() seems to never directly throw an exception?,0,0.8456260561943054
1357194942,14406,junrao,2023-10-12T17:55:19Z,"this needs to wait for the cleanup to be done until the timeout, right?",0,0.9862729907035828
1358651225,14406,kirktrue,2023-10-13T18:16:51Z,i removed the commented out code and explained why we need to use `runatclose()` instead of closing the fetcher directly.,0,0.9929701685905457
1358658187,14406,kirktrue,2023-10-13T18:19:15Z,"you are correct, sir. i removed those lines. thanks for the catch!",1,0.9880819320678711
1358665833,14406,kirktrue,2023-10-13T18:22:24Z,"the ordering and way they go about testing it is different. as this is an issue from the original `fetchertest`, i'll open a ticket to resolve separately. thanks!",1,0.9585769176483154
1358682245,14406,kirktrue,2023-10-13T18:33:16Z,"it looks like both. the test starts off mimicking a client that doesn't support topic ids. the test sets up the local subscriptions and metadata with a topic that has no id. then the test ""upgrades"" the client to a version that _does_ support topic ids. this is to validate that the fetch session (on the broker) should remove the topic without the id in favor of the topic with the id. and then the test ""downgrades"" the client again to ensure the opposite case. i haven't looked at the underlying code in any depth, however.",0,0.9787698984146118
1358693714,14406,kirktrue,2023-10-13T18:43:42Z,"`fetchedrecords()` calls `fetcher.collectfetch()`, so it's the other way around. i updated the call sites and changed `fetchedrecords()` to just `fetchrecords()` so that it's hopefully a little more clear.",0,0.9912569522857666
1358701620,14406,kirktrue,2023-10-13T18:53:30Z,"i had removed most unnecessary uses of `this` in a previous round of updates, but left these because they were necessary. there are three tests that create a locally-scoped variable named `records` that masks the instance-scoped variable of the same name, hence the use of `this` to distinguish them. i've updated the tests to change the name of the local variable to `testrecords` so it's a) more clear that they're separate from `records`, and b) removes the use of `this`.",0,0.990398645401001
1358712167,14406,kirktrue,2023-10-13T19:07:09Z,"the `testunauthorizedtopic()` test method was added to `fetchertest` almost eight years ago. here's what the test looked like when it was initially committed: [code block] the comment makes a little more sense when taken in its historical context. but it makes a little more sense still when you look at the test method that used to appear directly above `testunauthorizedtopic()`: [code block] my take is that the author copied the `testfetchrecordtoolarge()` to use as a starting point for the new `testunauthorizedtopic()` method. separately, although `testfetchrecordtoolarge()` is no longer around, we still test the 'record too large' case in `testfetchrequestwhenrecordtoolarge()`. i'm inclined to remove the comment because it's pretty clear that the intent of `testunauthorizedtopic()` is to validate that a `topicauthorizationexception` is thrown if the fetch response includes the `topic_authorization_failed` error. what do you think?",0,0.9911984801292419
1358713529,14406,kirktrue,2023-10-13T19:09:06Z,changed,0,0.7968646287918091
1358717315,14406,kirktrue,2023-10-13T19:14:04Z,correct. i've removed the unnecessary `fetchrecords()` call from `testpartialfetchwithpausedpartitions()` in both fetcher tests.,0,0.9870290756225586
1358758478,14406,kirktrue,2023-10-13T19:40:51Z,done.,0,0.9897913336753845
1358761112,14406,kirktrue,2023-10-13T19:43:39Z,done.,0,0.9897913336753845
1358764452,14406,kirktrue,2023-10-13T19:48:25Z,done.,0,0.9897913336753845
1358791361,14406,kirktrue,2023-10-13T20:21:36Z,"done. here's what i added: [code block] i'll admit, i don't know that i totally understand what i wrote or if it's correct :)",1,0.9913042783737183
1358832549,14406,junrao,2023-10-13T20:48:48Z,should the comment be moved to just above `consumernetworkthread.runatclose` below?,0,0.9949265718460083
1358914146,14406,kirktrue,2023-10-13T22:24:45Z,"i may be misunderstanding your comment, but the code to denote partitions as being revoked (via `subscriptionstate.markpendingrevocation()` will be handled in kafka-15539.",0,0.9536890387535095
1358914547,14406,kirktrue,2023-10-13T22:25:46Z,done.,0,0.9897913336753845
1358914571,14406,kirktrue,2023-10-13T22:25:51Z,done.,0,0.9897913336753845
1358918492,14406,kirktrue,2023-10-13T22:36:04Z,yes. done.,0,0.9106190204620361
1358949767,14406,kirktrue,2023-10-13T23:05:23Z,"i looked into this a bit, and it has to do with the records that are used for the different partitions, their counts, offsets, etc. i think it should be investigated and cleaned up for clarity and reassurance. i will open a new jira ticket since this is part of the existing `fetchertest` suite.",0,0.9107275009155273
1358952151,14406,kirktrue,2023-10-13T23:14:09Z,filed kafka-15606 to track.,0,0.9953562617301941
1358952187,14406,kirktrue,2023-10-13T23:14:15Z,added this to kafka-15606.,0,0.9955046772956848
1358953070,14406,kirktrue,2023-10-13T23:17:34Z,added a link to this question to kafka-15606.,0,0.9949824810028076
1358953131,14406,kirktrue,2023-10-13T23:17:49Z,fixed,0,0.920660674571991
1358953536,14406,kirktrue,2023-10-13T23:19:06Z,i'll file a bug to investigate this question. thanks!,1,0.9751365184783936
1358953612,14406,kirktrue,2023-10-13T23:19:25Z,i'll file a bug to investigate this question. thanks!,1,0.9751365184783936
1358953637,14406,kirktrue,2023-10-13T23:19:31Z,i'll file a bug to investigate this question. thanks!,1,0.9751365184783936
1358954499,14406,kirktrue,2023-10-13T23:22:49Z,maybe `testfetchresponsemetricswithskippedoffset()`?,0,0.99469393491745
1358955393,14406,kirktrue,2023-10-13T23:25:43Z,renamed and reversed.,0,0.96563720703125
1358956176,14406,kirktrue,2023-10-13T23:28:19Z,changed `testreturnabortedtransactionsinuncommittedmode()` to `testreturnabortedtransactionsinuncommittedmode()`,0,0.9942352175712585
1358956462,14406,kirktrue,2023-10-13T23:29:46Z,fixed.,0,0.9905837774276733
1358956804,14406,kirktrue,2023-10-13T23:31:02Z,fixed,0,0.920660674571991
1358957417,14406,kirktrue,2023-10-13T23:32:34Z,i believe it is referring to the `runnable` that is passed into `setwakeuphook()`.,0,0.990422248840332
1358990414,14406,kirktrue,2023-10-14T00:22:58Z,done.,0,0.9897913336753845
1358990445,14406,kirktrue,2023-10-14T00:23:03Z,done.,0,0.9897913336753845
1358990537,14406,kirktrue,2023-10-14T00:23:29Z,done. replaced with direct call to `applicationeventhandler.wakeup()`.,0,0.9931835532188416
1358990617,14406,kirktrue,2023-10-14T00:23:57Z,"we are not fetching, but we are waiting, so i reworded the comment. lmk if it still needs tweaking. thanks.",1,0.9663252830505371
1358990797,14406,kirktrue,2023-10-14T00:24:33Z,thanks for catching that. i fixed this but it's pretty clear now that i need unit tests to validate correctness.,1,0.9753413796424866
1360933149,14406,junrao,2023-10-16T16:27:06Z,"i made the comment when the code had a `fetchbuffer` in both `prototypeasyncconsumer` and `abstractfetch` since we need to apply the same check on `subscriptions.isfetchable` to both places. now, we only have a single fetchbuffer in `abstractfetch`. this is no longer an issue.",0,0.9916908740997314
1360942134,14406,junrao,2023-10-16T16:34:07Z,unsentrequest => lastunsentrequest ?,0,0.9877200722694397
1360995022,14406,junrao,2023-10-16T17:04:12Z,got it. this is referring to server side upgrade with topicid support.,0,0.6588259339332581
1360998263,14406,junrao,2023-10-16T17:07:32Z,fetchedrecords() => fetchrecords() ?,0,0.9939550757408142
1361004569,14406,junrao,2023-10-16T17:13:29Z,: thanks for the explanation. it makes sense to me to remove the comment here.,1,0.9593666791915894
1361103184,14406,junrao,2023-10-16T18:17:15Z,"thanks for updating the comment, kirk. the comment seems correct. it would be useful to further add that because the fetch position in the request is different from the one in fetch state, the fetched data, including the `offset_out_of_range` error is ignored in `fetchcollector.handleinitializeerrors` because of the following code. ` if (position == null || fetchoffset != position.offset) { ` it's a bit weird that the above check is only done for the `offset_out_of_range` error, instead of any error. it might be useful to file a jira to revisit this logic.",1,0.9737815260887146
1361109166,14406,junrao,2023-10-16T18:23:52Z,"yes, the proposed new name sounds good to me.",0,0.5362222194671631
1361131214,14406,junrao,2023-10-16T18:38:47Z,thanks for the reply. i still don't quite understand the test. why do we duplicate the following code both inside and outside of setwakeuphook? [code block] mockclient is only woken up through `networkclientdelegate.disconnectasync`.,1,0.9684202075004578
1361156117,14406,junrao,2023-10-16T19:05:33Z,the way the code is written. we will wake up `applicationeventhandler` whether fetch is empty or not. perhaps it's simpler to just always call `applicationeventhandler.wakeup()` after each `fetchcollector.collectfetch(fetchbuffer)` call?,0,0.990447998046875
1361329379,14406,kirktrue,2023-10-16T22:36:19Z,i have filed kafka-15615 to resolve.,0,0.9946645498275757
1361329900,14406,kirktrue,2023-10-16T22:37:18Z,"this is one of the more serious and subtle issues, so i want to know you're ok with the new approach before i resolve this conversation in the pr. thanks!",1,0.9683616161346436
1361332784,14406,kirktrue,2023-10-16T22:42:39Z,filed kafka-15617,0,0.9934619665145874
1361345756,14406,kirktrue,2023-10-16T23:07:23Z,"references were changed to either `fetchrequests` or `collectfetch` as appropriate. some minor refactoring was also introduced to use `assertthrows` instead, where possible.",0,0.9942594766616821
1361346244,14406,kirktrue,2023-10-16T23:08:26Z,removed.,0,0.9612457156181335
1361346884,14406,kirktrue,2023-10-16T23:09:43Z,changed.,0,0.9680466055870056
1361353808,14406,junrao,2023-10-16T23:23:31Z,": yes, the fix lgtm.",0,0.986822247505188
1361355764,14406,kirktrue,2023-10-16T23:27:28Z,great :grinning_face_with_smiling_eyes: thanks!,1,0.9971543550491333
1361357104,14406,junrao,2023-10-16T23:29:55Z,the comment is a bit mis-leading since the fetcher doesn't block. it throws an exception.,-1,0.5577688217163086
1361357218,14406,kirktrue,2023-10-16T23:30:05Z,can you chime in on this question? thanks!,1,0.946423351764679
1361357318,14406,kirktrue,2023-10-16T23:30:16Z,can you chime in on this question? thanks!,1,0.946423351764679
1361357471,14406,kirktrue,2023-10-16T23:30:32Z,can you chime in on this question? thanks!,1,0.946423351764679
1361358097,14406,kirktrue,2023-10-16T23:31:42Z,"i am not fond of this code as written, and have made at least two attempts to change it. it's a bit messy but i will take another pass to clean it up. ideally mostif not allof the logic would live in `fetchbuffer`.",-1,0.9647471904754639
1361358254,14406,kirktrue,2023-10-16T23:32:03Z,"ok, i'll look at this again.",0,0.9853569865226746
1364694361,14406,kirktrue,2023-10-18T23:39:42Z,filed kafka-15634.,0,0.9946224689483643
1364696003,14406,kirktrue,2023-10-18T23:42:49Z,filed kafka-15635.,0,0.9945067763328552
1364698472,14406,kirktrue,2023-10-18T23:47:24Z,filed kafka-15636.,0,0.9945456981658936
1364699488,14406,kirktrue,2023-10-18T23:49:29Z,filed kafka-15637.,0,0.9946581721305847
1364700996,14406,kirktrue,2023-10-18T23:52:47Z,filed kafka-15638.,0,0.9946500658988953
1364704339,14406,kirktrue,2023-10-18T23:59:55Z,filed kafka-15639.,0,0.9946696162223816
1364706025,14406,kirktrue,2023-10-19T00:02:24Z,i removed the comment since there's a more explanatory comment below already.,0,0.988974928855896
1364707771,14406,kirktrue,2023-10-19T00:04:26Z,done.,0,0.9897913336753845
1364712500,14406,kirktrue,2023-10-19T00:08:48Z,i've filed kafka-15640 to look into this in more detail.,0,0.9927023649215698
1364715414,14406,kirktrue,2023-10-19T00:13:45Z,i've added this to kafka-15640 for a dedicate effort to clean up the modifications to this data to make them atomic operations.,0,0.9948148131370544
1364758468,14406,kirktrue,2023-10-19T01:15:42Z,"i tried to update the comment, but ended up confused on how to explain it. because this looks like an existing issue that needs more investigation, i filed kafka-15641 to follow up.",0,0.960930585861206
1366182334,14406,kirktrue,2023-10-19T21:59:35Z,both `kafkaconsumer` and `prototypeasyncconsumer` commit offsets asynchronously. i've filed kafka-15651 to review.,0,0.9957497119903564
1366237460,14406,kirktrue,2023-10-19T23:37:40Z,"the issue is with how `offsetsrequestmanager.resetpositionsifneeded()` handles the call to `offsetfetcherutils.getoffsetresettimestamp()`. since `getoffsetresettimestamp()` may throw an exception, `offsetsrequestmanager` should catch it and forward it to the application thread. but instead, `offsetsrequestmanager` allows the error to bubble up to the `applicationeventprocessor`, which will then bubble it up to `consumernetworkthread`, which handles it by logging the error and exiting its `run()` method. in fact, this appears to be the intended behavior since `offsetsrequestmanagertest.testresetpositionsthrowspreviousexception()` explicitly tests that `offsetsrequestmanager.resetpositionsifneeded()` will throw the error directly at the caller. what needs to change is for `offsetsrequestmanager.resetpositionsifneeded()` to catch the exception and enqueue an `errorbackgroundevent` on the background event queue. in this way, the error will be processed on the application thread as part of `poll()`.",0,0.9854742288589478
1366237944,14406,kirktrue,2023-10-19T23:38:52Z,i don't see any existing unit tests which track the specific case that mentioned. i'm currently looking at the integration tests to see if those cover this case.,0,0.9852365255355835
1366262621,14406,kirktrue,2023-10-20T00:00:34Z,"yes. i've made the change that on `close()`, the application thread will wait for the network thread to finish its cleanup, up to the given timeout.",0,0.9933791160583496
1366266506,14406,kirktrue,2023-10-20T00:06:58Z,"unfortunately, there are no unit tests or integration tests which catch the offset reset case. i'll file a jira to have one concocted.",-1,0.6003531217575073
1366267515,14406,kirktrue,2023-10-20T00:09:25Z,i've made the following changes: 1. now `offsetsrequestmanager` correctly enqueues errors from `getoffsetresettimestamp()` onto the background event queue for use by the application thread 2. renamed `offsetfetchertest`'s `testrestoffsetsauthorizationfailure()` to `testresetoffsetsauthorizationfailure()` 3. renamed `offsetsrequestmanagertest`'s `testresetpositionsthrowspreviousexception()` to `testresetoffsetsauthorizationfailure()` and updated its logic to ensure the expected error is present in the queue for the application thread to check in `poll()`,0,0.9882696866989136
1367260539,14406,junrao,2023-10-20T16:53:42Z,could we just redirect the implement to the constructor above?,0,0.9929982423782349
1367369975,14406,junrao,2023-10-20T18:27:18Z,would it be clearer to rename refreshcommittedoffsetsifneeded to initwithcommittedoffsetsifneeded?,0,0.9901729822158813
1367383773,14406,junrao,2023-10-20T18:44:13Z,"in `offsetfetcherutils.getoffsetresettimestamp()`, if there is no offset reset policy, currently we just ignore it. it seems that we should throw an exception in that case?",0,0.9925404191017151
1367498133,14406,kirktrue,2023-10-20T21:30:10Z,filed kafka-15652 to ensure that we have tests that catch this case.,0,0.9941153526306152
1367508455,14406,kirktrue,2023-10-20T21:49:59Z,fixed.,0,0.9905837774276733
1367508628,14406,kirktrue,2023-10-20T21:50:19Z,done.,0,0.9897913336753845
1367510616,14406,kirktrue,2023-10-20T21:53:31Z,done.,0,0.9897913336753845
1367515674,14406,junrao,2023-10-20T22:03:20Z,"this doesn't seem quite right. it's possible for a fetchrequest to return no data. in that case, if we don't wake up the the network thread, it may not be able to send the next fetch request for a long time.",0,0.5782544612884521
1367516322,14406,junrao,2023-10-20T22:04:01Z,`wakeup` => `wakeupnetworkthread` ?,0,0.9934263229370117
1367517181,14406,kirktrue,2023-10-20T22:05:48Z,"there is a default offset reset strategy which is configured via `consumerconfig`, passed to the `kafkaconsumer`, and then to the `subscriptionstate`, right? why wouldn't we fall back to that if there's no overridden offset reset strategy for a particular partition?",0,0.9920227527618408
1367529409,14406,junrao,2023-10-20T22:33:26Z,"[a link] has 3 options: `latest`, `earliest`, `none`. it's possible for a user to choose `none`, which means ""throw exception to the consumer if no previous offset is found for the consumer's group"". but in that case, `offsetfetcherutils.getoffsetresettimestamp` just ignores that partition and won't reset it forever. we need to throw an exception so that the user knows. it's a bit of weird configuration since it means a consumer can't really consume for the very first time with this option. however, i tested it out with the existing consumer and it does throw an exception. [code block]",-1,0.5102596879005432
1367535648,14406,kirktrue,2023-10-20T22:51:18Z,"i changed the `return null` to `throw new nooffsetforpartitionexception(partition)`. i re-ran the tests and nothing failed, so there seems to be another gap in the tests.",0,0.9946129322052002
1367536108,14406,kirktrue,2023-10-20T22:52:38Z,"the enqueuing of other events will also call `wakeupnetworkthread`, so it shouldn't be a problem. but i went ahead and changed it as requested.",0,0.9931897521018982
1367536128,14406,kirktrue,2023-10-20T22:52:43Z,done,0,0.8682363629341125
1367537583,14406,junrao,2023-10-20T22:56:48Z,could we just return empty here instead of calling collectfetch() again since the caller is in a loop and can call this method to collect fetch again?,0,0.9918254613876343
1367545811,14406,junrao,2023-10-20T23:12:39Z,would it be clearer to rename `refreshcommittedoffsetsifneeded` to `initwithcommittedoffsetsifneeded`?,0,0.9910050630569458
1367556045,14406,kirktrue,2023-10-20T23:25:15Z,"the `refreshcommittedoffsetsifneeded()` name is derived from existing code in `kafkaconsumer` that calls out to `consumercoordinator.refreshcommittedoffsetsifneeded()`. if we change the method name in `prototypeasyncconsumer`, should we change `consumercoordinator`'s corresponding method name too?",0,0.9943616390228271
1367557772,14406,junrao,2023-10-20T23:32:12Z,"yes, in both cases, the method sets offsets for partitions in initializing state.",0,0.992652416229248
1367559124,14406,kirktrue,2023-10-20T23:37:47Z,"yes, we could update `pollforfetches()` to simply return `fetch.empty()` at the end. however, there's code that intentionally blocks (for a little bit) waiting for fetch data to arrive in the buffer: [code block] also, each loop through `poll()` executes `updateassignmentmetadataifneeded()` before checking the fetch buffer for any data. that method does a lot of work (network i/o) that we'd ideally skip if we already have the data. perhaps we could update `awaitnotempty()` with a return flag so that the tail end of `pollforfetches()` can look something like this: [code block]",0,0.990213930606842
1367562895,14406,junrao,2023-10-20T23:52:41Z,"thanks for the explanation, kirk. we can just leave the code as it is then.",1,0.9606519937515259
1367565477,14406,kirktrue,2023-10-21T00:03:02Z,updated and a bit of cleanup.,0,0.9880079030990601
1370389793,14406,lianetm,2023-10-24T15:20:23Z,"i had missed a detail here. we're only implementing this with the default timeout, but not the overloaded one below, that has the timeout provided by the user. is there a reason or is it just that we missed the latter one? (same for the `listtopics`)",0,0.9882708191871643
1370452938,14406,lianetm,2023-10-24T15:58:23Z,(i guess it will be all part of the integration with the metadata calls right?),0,0.9908917546272278
1370486899,14406,kirktrue,2023-10-24T16:21:12Z,good call out. i don't know that the necessary topic plumbing code was written at that time. would you mind filing a bug to resolve?,1,0.9881652593612671
751663483,11390,ccding,2021-11-17T21:48:45Z,why do we remove `false` from the third parameter? the default is `true`,0,0.9924858808517456
751670345,11390,ccding,2021-11-17T21:59:29Z,why do we remove the keyword `override` here?,0,0.9922444224357605
751673278,11390,ccding,2021-11-17T22:04:21Z,is this change intentional?,0,0.9857465028762817
754749020,11390,satishd,2021-11-23T01:26:46Z,"good catch, fixed it.",1,0.988362729549408
754749244,11390,satishd,2021-11-23T01:27:35Z,"intellij auto formatted, fixed it.",0,0.9856401681900024
755410314,11390,junrao,2021-11-23T18:38:36Z,is this change needed?,0,0.9939659237861633
755430690,11390,junrao,2021-11-23T19:08:52Z,"hmm, why do we want to eat the ioexception? ditto below.",0,0.942961573600769
755446235,11390,junrao,2021-11-23T19:32:40Z,"does the parent cl have a super set of classpathes than the child? if so, is urls1 a subset of urls2?",0,0.9933443069458008
755523984,11390,junrao,2021-11-23T21:42:25Z,i the local log => in the local log,0,0.9919518232345581
755548648,11390,junrao,2021-11-23T22:22:25Z,listoffset returns the leaderepoch for the localstartoffset. could we just use that leaderepoch? it will simplify the code below.,0,0.9939232468605042
760490750,11390,junrao,2021-12-01T19:04:46Z,could we add remotelogmanager to the javadoc too?,0,0.9949066042900085
760491245,11390,junrao,2021-12-01T19:05:34Z,does this need to be volatile?,0,0.9817500114440918
760630665,11390,junrao,2021-12-01T22:49:37Z,indentation,0,0.9911677837371826
760661057,11390,junrao,2021-12-01T23:54:44Z,could this case just be handled below for earliest_local_timestamp?,0,0.991939127445221
760671044,11390,junrao,2021-12-02T00:20:02Z,could this be private?,0,0.9816126227378845
761506462,11390,junrao,2021-12-02T22:15:31Z,"we need to find the first segment matching the timestamp from the remote segments, then the local segments.",0,0.9919752478599548
761524592,11390,junrao,2021-12-02T22:50:20Z,fetchremoteindex() can take time. could we call this asynchronously so that we don't block the request handler thread?,0,0.9933852553367615
762123788,11390,junrao,2021-12-03T17:33:27Z,this may not matter for now. but it's probably better to use config.maxindexsize as the max index size.,0,0.9905134439468384
762126153,11390,junrao,2021-12-03T17:37:24Z,should >= be > ?,0,0.9923574328422546
762129356,11390,junrao,2021-12-03T17:42:27Z,could we add a description for this class?,0,0.9947779178619385
762138449,11390,junrao,2021-12-03T17:57:18Z,should we close inputstream when done?,0,0.994300365447998
762171200,11390,junrao,2021-12-03T18:53:08Z,should we use a shutdownablethread?,0,0.992265522480011
762176132,11390,junrao,2021-12-03T19:01:36Z,"the abort marker for offsets within the fetch range could be in subsequent log segments. so, we need to collect aborted transactions beyond the segment that the fetch offset resides.",0,0.9930216670036316
762183906,11390,junrao,2021-12-03T19:15:33Z,could we just call loadclass() once as in createremotestoragemanager()?,0,0.9936189651489258
762188249,11390,junrao,2021-12-03T19:23:09Z,could we add topicids to javadoc?,0,0.9948446750640869
762189948,11390,junrao,2021-12-03T19:26:06Z,could we reuse the method unifiedlog.remotelogenabled()?,0,0.9946959614753723
762191856,11390,junrao,2021-12-03T19:29:25Z,should we just add remote_log_metadata_topic_name to topic.internal_topics?,0,0.9950685501098633
762193670,11390,junrao,2021-12-03T19:32:32Z,could we just get rid of filteredleaderpartitions as we have for followertopicpartitions?,0,0.9933590292930603
762195818,11390,junrao,2021-12-03T19:36:31Z,"hmm, it seems that we only want to remove topicid when all partitions in the topic are removed?",0,0.9832293391227722
762200473,11390,junrao,2021-12-03T19:44:52Z,does this need to be a concurrent map since there is no synchronization on access?,0,0.9926959276199341
762202911,11390,junrao,2021-12-03T19:49:17Z,"similar here, since fetch from remove storage can block, it would be better to do this asynchronously so that it doesn't block a request handler thread.",0,0.9882771372795105
762206303,11390,junrao,2021-12-03T19:55:19Z,should we also close all opened files in entries?,0,0.9948517680168152
762325936,11390,junrao,2021-12-03T22:36:03Z,"to use array(), we have to first check hasarray(). it's probably simpler to do buffer.put(logheaderbuffer).",0,0.9939133524894714
762355278,11390,junrao,2021-12-04T00:22:04Z,the code doesn't seem to check topicid.,0,0.9834529757499695
762355609,11390,junrao,2021-12-04T00:23:48Z,which request?,0,0.9944260120391846
762357821,11390,junrao,2021-12-04T00:34:25Z,"when receiving offset_moved_to_tiered_storage, we know the follower's offset is below leader's local start offset. it seems that we could directly ask for leader's local start offset instead of calling fetchlatestoffsetfromleader().",0,0.9914664030075073
762359179,11390,junrao,2021-12-04T00:41:01Z,it's less verbose to do [code block],0,0.9842677712440491
762362355,11390,junrao,2021-12-04T00:58:51Z,reloadsegments => reloadsnapshots ?,0,0.9949653744697571
762362423,11390,junrao,2021-12-04T00:59:17Z,is this needed since the caller calls this already?,0,0.993811309337616
762364294,11390,junrao,2021-12-04T01:11:13Z,where is the logic to rebuild remotelogmetadatasnapshotfile?,0,0.9936594367027283
762366976,11390,junrao,2021-12-04T01:29:24Z,loading from remote storage could be expensive. it would be useful to do this asynchronously so that the replication thread can make faster progress on other partitions.,0,0.969157874584198
762367379,11390,junrao,2021-12-04T01:32:13Z,do we want to include the change in fetchrequest too?,0,0.9956135749816895
762367939,11390,junrao,2021-12-04T01:36:36Z,"it's not really ""by local timestamp"". it's localstartoffset.",0,0.9914677143096924
767417471,11390,satishd,2021-12-13T05:14:43Z,this is added to exclude any generated files by the tiered storage test runs.,0,0.99539715051651
767425395,11390,satishd,2021-12-13T05:41:05Z,"it checks if the given resource exists within this class loader first, it delegates to the parent classloader if it is not found in this class loader.",0,0.9951168298721313
767426396,11390,satishd,2021-12-13T05:44:05Z,it is a `val` for now and it is not needed to be declared as volatile and the compiler does not allow too. this will be updated in the upcoming changes to `var` and then it can be declared as volatile.,0,0.9943366646766663
767427042,11390,satishd,2021-12-13T05:45:48Z,updated with shutdownablethread.,0,0.9952818751335144
767427379,11390,satishd,2021-12-13T05:46:46Z,this is an unused method. remotelogmanager handles going through subsequent segments and collect all aborted transactions. these changes will be added in the next pr. i will remove this unused method for now.,0,0.9940052628517151
767427546,11390,satishd,2021-12-13T05:47:16Z,"actually, that can still be improved. updated with the changes to avoid creating `classloaderawareremotestoragemanager` unnecessarily and calls going through classloader switching.",0,0.993794322013855
767427717,11390,satishd,2021-12-13T05:47:50Z,i plan to do that later. it requires the metadata topic configs to be built and auto topic creation manager needs to handle this topic creation etc.,0,0.992404043674469
767428241,11390,satishd,2021-12-13T05:49:29Z,good point. changed it to use topicpartition instead of topic as we need to maintain a different data structure for all the partitions and need to synchronize between them. having concurrentmap of topicpartion with topicid is simpler to manage here.,1,0.959823727607727
767428501,11390,satishd,2021-12-13T05:50:15Z,i will address in a followup pr.,0,0.992119550704956
767428782,11390,satishd,2021-12-13T05:51:13Z,this cleansup all the earlier loaded snapshots. it loads the newly created snapshot.,0,0.9949878454208374
767430230,11390,satishd,2021-12-13T05:55:41Z,"`rlsmetadata = rlm.fetchremotelogsegmentmetadata(partition, epoch.get, leaderlocallogstartoffset)` returns empty and this method throws an error back to the caller here. it retries again until the required `rlsmetadata` is available. `remotelogmetadatasnapshotfile` is loaded when assigning of partitions are done as part of `topicbasedremotelogmetadatamanager.assignpartitions()`.",0,0.9934972524642944
767430483,11390,satishd,2021-12-13T05:56:24Z,i will address this in a followup pr.,0,0.9924598336219788
767434452,11390,satishd,2021-12-13T06:08:20Z,used `option.foreach` here. can you be more specific here?,0,0.9954811334609985
767435783,11390,satishd,2021-12-13T06:11:55Z,i will address this in a followup pr.,0,0.9924598336219788
767698400,11390,satishd,2021-12-13T12:08:40Z,updated the javadoc.,0,0.9944857954978943
768141997,11390,junrao,2021-12-13T21:38:33Z,should we remove this?,0,0.9901718497276306
772110652,11390,junrao,2021-12-20T06:38:21Z,was this comment addressed?,0,0.9917539358139038
772110800,11390,junrao,2021-12-20T06:38:43Z,the return value is not very intuitive. i'd expect a true return value to indicate that the request is handled successfully.,-1,0.6284216642379761
772110895,11390,junrao,2021-12-20T06:38:56Z,could we add a comment on what this method does?,0,0.9949718713760376
772110978,11390,junrao,2021-12-20T06:39:11Z,"in the else case, should we truncate all local log?",0,0.992034375667572
772111057,11390,junrao,2021-12-20T06:39:21Z,change from ` replicamgr.remotelogmanager.foreach(rlm => { } ) ` to ` replicamgr.remotelogmanager.foreach{rlm => } ` ditto in a few other places.,0,0.9942255616188049
772111223,11390,junrao,2021-12-20T06:39:45Z,"hmm, the remote data could end at leaderlocallogstartoffset - 1. in that case, we won't find a corresponding rlsmetadata.",0,0.9807631969451904
772111916,11390,junrao,2021-12-20T06:41:23Z,"this is kind of awkward and inefficient. could we add a better api to avoid the trial and error approach? for example, we could have an api that waits for the remote log segment metadata up to offset leaderlocallogstartoffset - 1 becoming available with leader epoch less than or equal to currentleaderepoch.",-1,0.9425734877586365
772111987,11390,junrao,2021-12-20T06:41:35Z,it's awkward to stream into a temp file only to load it back in memory.,-1,0.9764336347579956
773121075,11390,satishd,2021-12-21T13:08:06Z,"updated the comment, we do not really need to have a check here. let me know if i am missing anything here.",0,0.9853595495223999
773121400,11390,satishd,2021-12-21T13:08:36Z,addressed it in the latest commit.,0,0.9935311675071716
773121903,11390,satishd,2021-12-21T13:09:20Z,this is inline with `handleoutofrangeerror` contract. i am fine with the suggested change but it is good to have similar semantics to `handleoutofrangeerror` method too for uniformity.,1,0.6825218200683594
773122505,11390,satishd,2021-12-21T13:10:13Z,good point. i updated it to address this scenario too in the latest commit.,1,0.9701968431472778
773123927,11390,satishd,2021-12-21T13:12:13Z,changed it to use the leader epoch of leader's local-log-start-offset and find the respective earlier epoch for (leader's local-log-start-offset -1) from the leader.,0,0.9942833781242371
773143045,11390,satishd,2021-12-21T13:39:14Z,filed [a link] to add the suggested improvement.,0,0.9950917959213257
773499214,11390,wyuka,2021-12-21T23:16:35Z,shouldn't this method be called `setremotelogmanager(...)`?,0,0.995153546333313
778990618,11390,ccding,2022-01-05T17:08:02Z,`local-log-start-timestamp` instead of `local-log-start-offset` in the comment?,0,0.9928907155990601
779060541,11390,junrao,2022-01-05T18:52:06Z,"when we hit offsetoutofrangeexception, it's possible that remote storage is enabled. in that case, we also need to rebuild the remote log metadata.",0,0.994247317314148
779089066,11390,ccding,2022-01-05T19:40:31Z,is it possible to make `topic.isinternal(topicpartition.topic())` to return true if `topicbasedremotelogmetadatamanagerconfig.remote_log_metadata_topic_name.eq(topicpartition.topic()))`? then we can get rid of the `topicbasedremotelogmetadatamanagerconfig.remote_log_metadata_topic_name.eq(topicpartition.topic()))` check,0,0.9944158792495728
779142706,11390,ccding,2022-01-05T21:17:24Z,do we need to log if there are any exceptions? or throw the exception out?,0,0.9929519295692444
779158936,11390,ccding,2022-01-05T21:47:49Z,is there any reason for not using the existing suffixes? [a link],0,0.9953824877738953
779162870,11390,ccding,2022-01-05T21:55:20Z,should the error message be `cleaned up`?,0,0.9879384636878967
779166585,11390,ccding,2022-01-05T22:02:35Z,why do we use `coreutils.tryall` in one case and use `array().foreach( try catch )` in the other case?,0,0.9868777394294739
779169864,11390,ccding,2022-01-05T22:09:02Z,"we can use `val dirname = ""remote-log-index-cache""` here",0,0.9952276945114136
779171925,11390,ccding,2022-01-05T22:13:11Z,what is the trade-off between using a daemon thread and using kafka scheduler?,0,0.9905981421470642
779175283,11390,ccding,2022-01-05T22:20:08Z,[code block] i think we don't need to flush the parent dir. it doesn't matter if the cache file is not renamed during an unclean shutdown.,0,0.9907928109169006
779177001,11390,junrao,2022-01-05T22:23:44Z,space after if.,0,0.9918387532234192
779177082,11390,ccding,2022-01-05T22:23:57Z,do we need to log/handle exception caused by fetchandcreateindex,0,0.9940329194068909
779191474,11390,junrao,2022-01-05T22:55:27Z,"topicbasedremotelogmetadatamanager independently updates the metadata state from the tier topic. when we make the `rlm.fetchremotelogsegmentmetadata` call, how does it make sure that it has caught up enough records from the tier topic including the segment covering the requested offset?",0,0.9931795597076416
779191948,11390,ccding,2022-01-05T22:56:38Z,"wanted to double check you mean `log.remotelogenabled()` or `!log.remotelogenabled()` here, because it is `filternot`",0,0.9944355487823486
779192232,11390,ccding,2022-01-05T22:57:20Z,"`log.remotelogenabled()` already checks internal and equals remote_log_metadata_topic_name, do we need to check again here?",0,0.9951891899108887
779196455,11390,junrao,2022-01-05T23:07:36Z,"endoffset is exclusive. so, we could just use leaderlogstartoffset.",0,0.9930245876312256
779199654,11390,junrao,2022-01-05T23:15:45Z,should we use foreach instead of map?,0,0.9927307963371277
779200299,11390,junrao,2022-01-05T23:17:30Z,should we flush the leader epoch file at the end?,0,0.9939540028572083
779213401,11390,junrao,2022-01-05T23:55:08Z,should we write the producer snapshot to a temp file first and then rename?,0,0.993962824344635
779216639,11390,junrao,2022-01-06T00:05:34Z,"it possible that the endoffset in rlsmetadata is larger than leaderlocallogstartoffset. if we fetch the local log from leaderlocallogstartoffset, duplicated tnx could be added to producerstatemanager. it's better to start fetching from rlsmetadata.endoffset + 1.",0,0.989762008190155
779223560,11390,junrao,2022-01-06T00:26:56Z,this is the top level error. unknown_topic_id and inconsistent_topic_id are partition level errors and don't need to be handled here.,0,0.9910991787910461
779233183,11390,junrao,2022-01-06T00:57:41Z,why does this method need to be protected instead of private? ditto for fetchoffsetandbuildremotelogauxstate.,0,0.989819347858429
784750507,11390,satishd,2022-01-14T10:57:46Z,we have not yet made `topicbasedremotelogmetadatamanagerconfig.remote_log_metadata_topic_name` as internal topic. i plan to make this change once it is created as an internal topic.,0,0.993381142616272
784751134,11390,satishd,2022-01-14T10:58:44Z,we do not want to log here. it should be handled by the invoker.,0,0.9898586869239807
784753702,11390,satishd,2022-01-14T11:02:40Z,there is no specific reason other than having a shorter suffix. i do not have a strong opinion on that. i am fine with eitherways.,0,0.8889413475990295
784764008,11390,satishd,2022-01-14T11:18:34Z,"in the earlier case, we want the exception to be thrown with the exception as mentioned in `coreutils.tryall`. but in this case, we want to catch each invocation and ignore it instead of collecting like coreutils.tryall.",0,0.993344783782959
784768268,11390,satishd,2022-01-14T11:25:20Z,"no, we want to throw it back so that invoker can handle it.",0,0.9896388053894043
784770314,11390,satishd,2022-01-14T11:28:57Z,nice catch!!,1,0.9957014918327332
784772939,11390,satishd,2022-01-14T11:33:21Z,"good point, i am making a simpler check here to use `filter`. [code block]",1,0.9255227446556091
784793287,11390,satishd,2022-01-14T12:08:32Z,we do not need to flush it as`cache.assign` already flushes the entry.,0,0.9940908551216125
784793923,11390,satishd,2022-01-14T12:09:39Z,"sure, it is good to do that. addressed it in the latest commit.",1,0.7626912593841553
784801502,11390,satishd,2022-01-14T12:22:42Z,"if it does not catchup then it returns `optional.empty`, and that we throw a remotestorageexception. as the caller receives remotestorageexception, it will be retried again.",0,0.9941852688789368
785875887,11390,satishd,2022-01-17T11:19:35Z,"in that case, i prefer to use '>' instead of '>=' like below. this is more clear and easy to read. i have also added a comment to talk about a case in leader epoch gap. [code block]",0,0.9000288248062134
786517360,11390,satishd,2022-01-18T08:36:13Z,"i refactored `assign` whether to flush or not with default as true for backward compatibility. in this case, i assign all the entries without flush, and flush to the file at the end.",0,0.994929313659668
786518882,11390,satishd,2022-01-18T08:38:15Z,"we encounter `offsetoutofrangeexception` only when the offsets are beyond the range of [logstartoffset, logendoffset]. why do we need to build remote log metadata in that case? i may be missing something here.",0,0.991843044757843
786736586,11390,satishd,2022-01-18T13:01:15Z,good point! made the respective changes in the latest commit.,1,0.9954568147659302
788215466,11390,junrao,2022-01-19T22:58:55Z,space after if,0,0.9908820390701294
788253183,11390,junrao,2022-01-20T00:23:47Z,"if we hit offsetoutofrangeexception, we call fetchearliestoffsetfromleader() inside fetchoffsetandapplyfun(), which fetches the localstartoffset. we then truncate the whole log and start fetching from localstartoffset. if the leader has data in remote storage, the follower won't have the remote log metadata for consumer fetch and won't have the same state (e.g. producer state) as the leader.",0,0.9924490451812744
788269196,11390,junrao,2022-01-20T01:02:58Z,fetchearlierepochendoffset(3) => fetchearlierepochendoffset(2) ?,0,0.9937961101531982
788270782,11390,junrao,2022-01-20T01:07:16Z,"it's possible for the local data to overlap a bit with what's in the remote storage. so, leaderlocallogstartoffset - 1 is not necessarily the highest offset in remote storage. could we name highestoffsetinremotefromleader more properly?",0,0.9915537238121033
788279027,11390,junrao,2022-01-20T01:29:23Z,we need to return nextoffset to the caller so that fetchoffsetandapplyfun() could set the next fetch offset to this.,0,0.9945003986358643
789307564,11390,wyuka,2022-01-21T02:46:58Z,we can use [code block] instead,0,0.9948529601097107
789308168,11390,wyuka,2022-01-21T02:48:04Z,we can use [code block] instead,0,0.9948529601097107
791322611,11390,satishd,2022-01-25T03:10:39Z,"sure, as we discussed offline, i added the approach to keep offsetoutofrange like earlier, which is to fetch the log-start-offset and it may get a response of offsetmovedtotieredstorage if it tries to fetch from log-start-offset and it is moved to tiered storage.",0,0.9901024103164673
791957579,11390,yyang48,2022-01-25T17:28:55Z,"just curious, why we need to read this value from the buffer and discard it immediately?",0,0.9709891080856323
791968984,11390,yyang48,2022-01-25T17:42:00Z,"i'm not sure whether this buffer is big enough or not? from the line 58: the size of the buffer is the record content size + 12. however, from the line 34, the logheaderbuffer is: 17. in the line 59, if we put the entire logheaderbuffer to this buffer, in the worse case, we need 5 bytes more space in the capacity. is this correct?",0,0.6880214810371399
796465473,11390,satishd,2022-02-01T10:40:54Z,good point. it is not really needed. looks like it was added earlier to log offset but the log was removed.,1,0.9613431096076965
796479255,11390,satishd,2022-02-01T10:58:08Z,"no, we do not really need more space here. i updated with more comments in the code on how it works. this is aligned with the existing code in other places like `filechannelrecordbatch`. payload : log_overhead + 4 + 1 (magic:byte) + reocrd-content log_overhead = 8(offset:long) + 4(size:int) = 12 `size` = 4 + 1(magic) + record-content-size. `logheaderbuffer` is read until magic. that is why the complete buffer-size is 12(log_overhead) + size. we do not count ""4 + 1(magic)"" here as it is already taken into account with size_read_from_header",0,0.9903563857078552
804020896,11390,junrao,2022-02-10T19:07:26Z,should we complete the javadoc? ditto for fetchearliestoffsetfromleader().,0,0.9943041205406189
804023336,11390,junrao,2022-02-10T19:10:45Z,could we add the javadoc for this one?,0,0.9942102432250977
804025075,11390,junrao,2022-02-10T19:13:07Z,"is ""related to offsets out of rage"" true? also, since we explained this error, do we need the error code?",0,0.9872511625289917
804026471,11390,junrao,2022-02-10T19:15:03Z,"is ""handle the offset out of range error"" true?",0,0.9922935962677002
804030400,11390,junrao,2022-02-10T19:20:34Z,"could we make it clear that the reason that we don't need to backoff and retry is because we move the partition to a failed state? also, could we put true in a separate line? ditto for handleoutofrangeerror().",0,0.9944243431091309
804042686,11390,junrao,2022-02-10T19:37:27Z,"the above long comment doesn't quite fit into remote storage. we could make it more general that covers both cases. if that's too complicated, perhaps have a separate method just for handling remote storage.",0,0.9913589954376221
804145767,11390,junrao,2022-02-10T21:59:14Z,could we change earliestorlatest to sth more generic now that it can have 3 values?,0,0.9931249618530273
804149120,11390,junrao,2022-02-10T22:00:51Z,there is no leader epoch before 0.10. so the leader epoch can just be -1.,0,0.9931928515434265
804186063,11390,junrao,2022-02-10T22:32:48Z,"this call writes another snapshot, which is unnecessary. perhaps we could just do producerstatemanager.truncateandreload()?",0,0.9918831586837769
804191359,11390,junrao,2022-02-10T22:38:43Z,"if we get here, it means the leader has started tiering the data but the follower hasn't received the remotestorageenable config yet. it seems that we should backoff and retry the same offset instead of just fetching from leaderlocallogstartoffset?",0,0.9917978048324585
804196978,11390,junrao,2022-02-10T22:45:04Z,this is not just an offset index.,0,0.9901610612869263
804200819,11390,junrao,2022-02-10T22:49:26Z,why is this called cleanableindex? it's bit confusing given log cleaner. maybe sth like baseindex?,0,0.8148174285888672
804201757,11390,junrao,2022-02-10T22:50:32Z,time stamp => timestamp,0,0.992039680480957
804203296,11390,junrao,2022-02-10T22:52:28Z,space after if,0,0.9908820390701294
804223128,11390,junrao,2022-02-10T23:14:55Z,"hmm, it's kind of weird to set the class loader on each call. is this needed? do other remote storage classes just use the classloader for rlm and rlmm?",-1,0.966672956943512
804234045,11390,junrao,2022-02-10T23:27:08Z,the original configs in config may contain implementation specific properties. how do we pass those to rlmm and rlm through remotelogmanager?,0,0.994612455368042
804239401,11390,junrao,2022-02-10T23:33:20Z,it seems that we never add to topicpartitionids?,0,0.9892834424972534
804245130,11390,junrao,2022-02-10T23:43:38Z,"in the local case, if all the messages in the remote storage have larger timestamps, it seems that we return the timestamp of the first message.",0,0.9908131957054138
804245833,11390,junrao,2022-02-10T23:45:16Z,could we call maybeepoch.get() once in the loop?,0,0.9933613538742065
804250739,11390,junrao,2022-02-10T23:56:46Z,previousepoch?,0,0.9929306507110596
804250861,11390,junrao,2022-02-10T23:57:03Z,nextepoch?,0,0.9896077513694763
804250995,11390,junrao,2022-02-10T23:57:19Z,epochentry?,0,0.9909341335296631
804251574,11390,junrao,2022-02-10T23:58:41Z,should previousepoch be initialize to none?,0,0.9930650591850281
804252215,11390,junrao,2022-02-11T00:00:12Z,this seems unused?,0,0.9904127717018127
804252997,11390,junrao,2022-02-11T00:02:09Z,it's not really local timestamp.,0,0.9573385119438171
804265970,11390,junrao,2022-02-11T00:35:38Z,"should we load up existing files to entries during init()? otherwise, it's not clear when they will be cleaned up.",0,0.9889167547225952
804266325,11390,junrao,2022-02-11T00:36:47Z,should we close the indexes too?,0,0.9919031262397766
804266637,11390,junrao,2022-02-11T00:37:38Z,this is never read?,0,0.9884973764419556
804267665,11390,junrao,2022-02-11T00:40:18Z,is this safe? the entry could be cleaned immediately after this check.,0,0.9936257600784302
804268708,11390,junrao,2022-02-11T00:43:07Z,rewind() is typically used after the buffer is written. should we use clear()?,0,0.9934611320495605
804270391,11390,junrao,2022-02-11T00:47:41Z,was this comment addressed?,0,0.9917539358139038
804274827,11390,junrao,2022-02-11T01:00:19Z,"this is not supported yet, right? should we throw an exception?",0,0.9768955707550049
804275488,11390,junrao,2022-02-11T01:02:03Z,should we just throw unsupportedexception?,0,0.9722050428390503
804277844,11390,junrao,2022-02-11T01:09:06Z,no need to pass in reloadfromcleanshutdown since it's always false?,0,0.9938031435012817
804280439,11390,junrao,2022-02-11T01:16:55Z,this seems an indirect way to check message version. should we just check that explicitly?,0,0.9792124032974243
804281396,11390,junrao,2022-02-11T01:19:46Z,"hmm, locallogstartoffset could change after the call the remotelogmanager.",0,0.9877203106880188
804843541,11390,junrao,2022-02-11T17:03:42Z,"for other broker side plugins (e.g. authorizer), we never needed a special class loader. why do we need this for the remote storage plugin?",0,0.9846151471138
812537683,11390,satishd,2022-02-23T03:44:29Z,"this is to avoid library conflicts directly or indirectly with the existing libraries in the system classpath. this classloader loads the libraries in the given paths. whenever a class needs to be loaded, it delegates to the system classloader only when it is not found in the configured paths. rsm or rlmm providers can have all the required libraries in given directories and add them as classpath for rsm or rlmm. this provides isolation with the libraries in the system classpath.",0,0.9885419607162476
813156759,11390,junrao,2022-02-23T17:48:17Z,"yes, i understand the intent. however, there are quite a few pluggable components on the broker side right now. sorting out the classpath dependencies among all of them seems quite complicated. another way to solve the issue is through shading. a potential conflicting library could be renamed to a different package.",0,0.9466245174407959
814028646,11390,satishd,2022-02-24T16:00:43Z,updated the statement and the error code is removed.,0,0.9934875965118408
814031095,11390,satishd,2022-02-24T16:03:07Z,"sure, i also updated the method to return true if it was able to handle it.",0,0.9922906756401062
814036592,11390,satishd,2022-02-24T16:09:03Z,`responsepartition.leaderepoch` returns -1 with <= kafka_0_10_1_iv2 version. no need to explicitly set it as -1.,0,0.994010329246521
814039902,11390,satishd,2022-02-24T16:12:30Z,`remotelogmanagerconfig#remotestoragemanagerprops()` and `remotelogmanagerconfig#remotelogmetadatamanagerprops()` return respective properties which are used while configuring rsm and rlmm in `remotelogmanager#configurersm()` and `remotelogmanager#configurerlmm()`.,0,0.9929025769233704
814041397,11390,satishd,2022-02-24T16:13:59Z,this code missed while merging other changes. addressed with the latest commit.,0,0.99440598487854
814045120,11390,satishd,2022-02-24T16:17:57Z,changed it to `version 8 enables listing offsets by local log start offset.`,0,0.9948726296424866
814046367,11390,satishd,2022-02-24T16:19:15Z,we do not need to explicitly close them as they are already closed inside `deleteifexists()` method.,0,0.9947478175163269
814050149,11390,satishd,2022-02-24T16:23:14Z,"this is used in dowork(), updated with the latest commit.",0,0.9953743815422058
814127632,11390,satishd,2022-02-24T17:53:23Z,good catch!! i will address it.,1,0.9966775178909302
814640948,11390,kowshik,2022-02-25T10:10:57Z,"this class is slim in functionality, and i don't feel there is any real benefit for introducing this. also for the future, it is not clear to me what operations can be included in this class, and which ones can't be. i feel that the earlier design without this base class was simpler. are we planning to add new functionality in the future into this class?",-1,0.9062687754631042
814642656,11390,kowshik,2022-02-25T10:13:11Z,"lets rename `x` to something more readable, ex: `index`.",0,0.9936020970344543
814658812,11390,kowshik,2022-02-25T10:35:11Z,s/related to offset moved to tiered storage/offset_moved_to_tiered_storage can we also log the topicpartition?,0,0.9927724003791809
814660162,11390,kowshik,2022-02-25T10:37:09Z,"this method `fetchoffsetandapplytruncateandbuild` is currently doing a number of things, which is clear from the method name. it will be hard to cover all test cases in unit test. so, it is better if its simplified.",0,0.9885529279708862
814668927,11390,kowshik,2022-02-25T10:50:08Z,"here to build the remote log aux state we only need the leader local log start offset, right? in such a case, i think it gets complicated if we try to repurpose `fetchoffsetandapplytruncateandbuild` here. can we just introduce a separate method that would just attempt to get the leader's local log start offset, and pass it into `buildremotelogauxstate`?",0,0.984821617603302
814678429,11390,kowshik,2022-02-25T11:04:36Z,"this method is doing a lot of things, and it is worthwhile thinking about how to simplify it. in its current form, it is going to be hard to test it.",0,0.8712112307548523
814981129,11390,junrao,2022-02-25T18:00:33Z,"i was referring to ""the timestamp will be message.notimestamp"". it should be the timestamp of the first message.",0,0.9901182055473328
818028561,11390,junrao,2022-03-02T19:29:10Z,"the purpose of a special class loader is to address potential class conflicts. if the same class exists btw the plugin and kafka, by switching the class loader, it seems that we don't know deterministically which version of the class will be loaded, which can be confusing.",0,0.9629083275794983
898097965,11390,divijvaidya,2022-06-15T15:02:56Z,the comment does not match the functionality for the function here. this implementation only performs delete.,0,0.9930515289306641
981140295,11390,divijvaidya,2022-09-27T11:51:53Z,nit i would suggest to move `testutils.resource` to `utils` and use that to mimic java's try-with-resource in scala.,0,0.9917293190956116
981150239,11390,divijvaidya,2022-09-27T12:02:42Z,"this could be refactored into a method in leaderepochcache, perhaps with signature `assign(seq(epochentry))`",0,0.9947350025177002
981152254,11390,divijvaidya,2022-09-27T12:04:55Z,"do we want to clear the existing cache first using `cache.clearandflush()`? asking because (and correct me if i am wrong) in the case of uncleanleaderelection, this follower may have log lineage belonging to previous leader. the new leader may have a different log lineage which doesn't contain epochs present in old lineage. those epochs absent missing in new lineage need to be removed from the cache.",0,0.989879846572876
983849860,11390,divijvaidya,2022-09-29T17:39:05Z,this offset is the `last-tiered-offset + 1` and not the `local-log-start-offset`. please correct me if i am wrong but this is inconsistent with what is described in the kip-405 where we say:,0,0.9785545468330383
985706396,11390,satishd,2022-10-03T12:06:00Z,this offset is not `last-tiered-offset + 1` but `previousoffsettoleaderlocallogstartoffset` which is `leaderlocallogstartoffset - 1`. this is aligned with what we mentioned in kip-405. you can take a look at the usage of `mayberlsm` which is [code block],0,0.9948669672012329
1025959204,11390,showuon,2022-11-18T03:46:54Z,nit: add a space before `new rcordheader`,0,0.9957389831542969
1026063322,11390,showuon,2022-11-18T06:18:22Z,nit: remotestoragesystemenable -> remotestoragesystemenable[d],0,0.9950523972511292
1026064974,11390,showuon,2022-11-18T06:22:09Z,nit: remote logging -> remote log,0,0.993330180644989
1026065351,11390,showuon,2022-11-18T06:22:57Z,should we also check `__cluster_metadata` topic? it isn't checked in `isinternal`,0,0.9952612519264221
1026079869,11390,showuon,2022-11-18T06:48:22Z,nit: remotestoragesystemenable -> remotestoragesystemenable[d],0,0.9950523972511292
1026086446,11390,showuon,2022-11-18T07:01:21Z,"there will be background thread to delete them later, right? i don't think this is necessary.",0,0.987603485584259
1026087680,11390,showuon,2022-11-18T07:03:42Z,where's the implementation?,0,0.9944392442703247
1026095589,11390,showuon,2022-11-18T07:18:10Z,"this `computifabsent` method might do 3 `fetchandcreateindex` for all 3 indexes, which will take many time, inside the lock. could we fetch them before we lock the `entries`?",0,0.9932419657707214
1026097879,11390,showuon,2022-11-18T07:21:53Z,forgot to add javadoc for 3 parameters,-1,0.5523175597190857
1026112608,11390,showuon,2022-11-18T07:44:38Z,"the implementation of `lookuptimestamp` above is also returning the `the timestamp of the first message.`. so, only javadoc needs to be updated",0,0.9945805668830872
1026121749,11390,showuon,2022-11-18T07:57:35Z,nit: additional comma at the end,0,0.9659497737884521
1026133917,11390,showuon,2022-11-18T08:14:42Z,updated partition fetch state,0,0.9934127926826477
1026146723,11390,showuon,2022-11-18T08:28:16Z,agree. there must be something wrong here. error log is also necessary.,0,0.9447945952415466
1026150319,11390,showuon,2022-11-18T08:32:22Z,nit: the indent is not quite right here,0,0.9607211947441101
1026173480,11390,showuon,2022-11-18T08:57:36Z,nit: give a change -> chance?,0,0.8373982906341553
1026175979,11390,showuon,2022-11-18T09:00:20Z,ditto,0,0.9754701256752014
1026242726,11390,showuon,2022-11-18T10:02:31Z,"i think it should `mock the segment of offset 0-4 moved to remote store.`, right?",0,0.9889442920684814
1026243503,11390,showuon,2022-11-18T10:03:18Z,ditto,0,0.9754701256752014
1032869910,11390,satishd,2022-11-27T05:35:05Z,we were doing that earlier but you suggested to do normal truncation until local-log-start-offset as mentioned [a link].,0,0.9939413070678711
1032869957,11390,satishd,2022-11-27T05:36:00Z,this is addressed with the latest changes.,0,0.9925143122673035
1032870167,11390,satishd,2022-11-27T05:38:00Z,we can keep it simple for now as you suggested. removed baseindex for now but we may add it later if needed.,0,0.9924694895744324
1032870377,11390,satishd,2022-11-27T05:39:57Z,adding space fails with style-check.,0,0.9315213561058044
1032870521,11390,satishd,2022-11-27T05:41:05Z,this is the existing convention used in other properties like unclean.leader.election.enable etc,0,0.9934428930282593
1032870562,11390,satishd,2022-11-27T05:41:34Z,this is the existing convention used in other properties like unclean.leader.election.enable etc,0,0.9934428930282593
1032870593,11390,satishd,2022-11-27T05:42:27Z,these are not loaded as entries marked for deletion. it is good to delete them any pending deletions when a broker is started.,0,0.9947282671928406
1032870604,11390,satishd,2022-11-27T05:42:41Z,it is addressed with the latest set of commits.,0,0.9947329759597778
1032871126,11390,satishd,2022-11-27T05:49:04Z,changed the text to make it more clear.,0,0.9890123605728149
1032871130,11390,satishd,2022-11-27T05:49:09Z,changed the text to make it more clear.,0,0.9890123605728149
1032944075,11390,satishd,2022-11-27T14:45:54Z,leaderepochcache is already cleaned up by the earlier `truncatefullyandstartat` call.,0,0.9933179616928101
1032945780,11390,satishd,2022-11-27T14:57:26Z,i will address in the next commit.,0,0.9863068461418152
1033092123,11390,showuon,2022-11-28T03:31:34Z,any reason why we don't want to `extends closeable` here?,0,0.9867620468139648
1033093221,11390,showuon,2022-11-28T03:34:54Z,"i saw we already updated the `_locallogstartoffset` in `maybeincrementlogstartoffset` method. if you know there are some other places we also need to update it, maybe you can make it much clear in the comment.",0,0.9930379986763
1033097357,11390,showuon,2022-11-28T03:45:59Z,fair enough,0,0.9672778844833374
1033136878,11390,showuon,2022-11-28T05:22:04Z,should we lock it?,0,0.9874762892723083
1033141283,11390,showuon,2022-11-28T05:32:56Z,"thanks for the update, but i think we still lock for the period of loading 3 index files. how about this: [code block] wdyt?",1,0.9127054214477539
1033492033,11390,satishd,2022-11-28T12:38:45Z,"added closeable as part of this pr, and we do not really need it with the latest changes..",0,0.9922934770584106
1033493533,11390,satishd,2022-11-28T12:40:19Z,locking is not really needed here as `init` method is invoked only when remoteindexcache instance is getting initialized.,0,0.9936329126358032
1033515905,11390,satishd,2022-11-28T13:02:53Z,"this creates race between writers and readers of these files which may fail readers with io errors. for ex: the race can occur in 3 ways 1. multiple writers writing those indexes concurrently 2. one of them will update the entry with the existing file but that file could have been over written in step-1 3. when readers start reading, those file might have been overwritten in step-1.",0,0.9739618897438049
1033516642,11390,satishd,2022-11-28T13:03:35Z,"please ignore the stale comment, removed with the latest commit.",0,0.9933104515075684
1034340498,11390,satishd,2022-11-29T06:20:02Z,"[a link] covers to get indexes or data in async manner for critical paths, we can cover as part of that jira. wdyt?",0,0.9945306181907654
1034345625,11390,showuon,2022-11-29T06:29:16Z,sounds good to me! i'll resolve this comment.,1,0.99588543176651
1034345639,11390,satishd,2022-11-29T06:29:18Z,good point. this is clarified in later comments.,1,0.9765807390213013
1041219212,11390,satishd,2022-12-06T16:50:10Z,"it does not really create another snapshot as it has the below check in producerstatemanager#takesnapshot. also, it is good to use `log.loadproducerstate` as any extra logic that may be added does not need to be added separately here. [code block]",0,0.9932793974876404
1041821188,11390,showuon,2022-12-07T06:52:56Z,nit: javadoc doesn't include all params,0,0.9903727769851685
1041842874,11390,showuon,2022-12-07T07:22:48Z,"nit: i know we don't test them, but could we add some comments here? thanks.",1,0.933606743812561
1042140948,11390,divijvaidya,2022-12-07T12:24:53Z,"consider the following scenario: 1. leader is archiving to tiered storage and has a follower. 2. follower has caught up to offset x (exclusive). 3. while follower is offline, leader moves x to tiered storage and expires data locally till y, such that, leaderlocallogstartoffset > x and y = leaderlocallogstartoffset. meanwhile, x has been expired from tiered storage as well. hence, x < globallogstartoffset as well. now, there could be a scenario where globallogstartoffset > leaderlocallogstartoffset because segments has been expired from remote but not from local. 3. follower comes online and tries to fetch x from leader, leader throws moved to tiered storage exception. 4. follower moves to buildaux state and tries to fetch the metadata. the metadata may not exist since the segment has been deleted in remote storage and we will get an error. this could be addressed at replica manager where it could detect if the remote segments have been deleted and accordingly throw an out of bound instead of move to tiered storage exception, but we should also add a defensive handling check here. in the above scenario, we should directly move to truncation instead of build aux state. the defensive check could be `&& leaderlocallogstartoffset > leaderlogstartoffset` over here. also, please add a test for this scenario.",0,0.9865977764129639
1043330520,11390,satishd,2022-12-08T13:04:03Z,this is addressed with the latest commit.,0,0.9942384958267212
1043330573,11390,satishd,2022-12-08T13:04:07Z,this is addressed with the latest commit.,0,0.9942384958267212
1043981337,11390,junrao,2022-12-09T01:39:11Z,the comment is a bit confusing since 4 bytes + magic doesn't add up to log_overhead.,-1,0.587368369102478
1043981867,11390,junrao,2022-12-09T01:40:03Z,same question here. it seems that it's better to make it clear that abstractindex is closable?,0,0.9912903308868408
1043982291,11390,junrao,2022-12-09T01:41:10Z,does this need to be volatile?,0,0.9817500114440918
1043982526,11390,junrao,2022-12-09T01:41:43Z,should we reset hwm too?,0,0.9933342933654785
1043982906,11390,junrao,2022-12-09T01:42:42Z,should this be in the storage module like classloaderawareremotelogmetadatamanager?,0,0.9947270750999451
1043983132,11390,junrao,2022-12-09T01:43:19Z,i guess we will add the logic to delete the remote data later?,0,0.9886337518692017
1043983263,11390,junrao,2022-12-09T01:43:42Z,target offset => start offset?,0,0.9954909682273865
1043983592,11390,junrao,2022-12-09T01:44:31Z,"do we need to make ""all the messages in the remote storage have larger timestamps"" a special case here? it seems the last option covers that case already.",0,0.9894606471061707
1043983792,11390,junrao,2022-12-09T01:45:04Z,could we just assign to maybeepoch directly and get rid of startingoffsetepoch?,0,0.99105304479599
1043984064,11390,junrao,2022-12-09T01:45:35Z,"if no message has timestamp, we will fall to here. this doesn't seem to implement what the comment says.",0,0.9900602102279663
1043984353,11390,junrao,2022-12-09T01:46:29Z,"it would be useful to make logging a complete sentence, so sth like debug(s""received error ${errors.offset_moved_to_tiered_storage} at "" + s""fetch offset: ${currentfetchstate.fetchoffset} for "" + s""topic-partition: $topicpartition"")",0,0.9931562542915344
1043984841,11390,junrao,2022-12-09T01:47:46Z,haven't => hasn't,0,0.9590250849723816
1043985073,11390,junrao,2022-12-09T01:48:20Z,"we already stopped processing requests at this point, right?",0,0.9766629338264465
1043985230,11390,junrao,2022-12-09T01:48:41Z,this seems unused?,0,0.9904127717018127
1043985494,11390,junrao,2022-12-09T01:49:22Z,could this be private?,0,0.9816126227378845
1043985686,11390,junrao,2022-12-09T01:49:51Z,should fetchearlierepochendoffset(2) be fetchearlierepochendoffset(90)?,0,0.9942933320999146
1043985886,11390,junrao,2022-12-09T01:50:14Z,"could we use complete sentence? e.g. s""active producers with size of ${log.producerstatemanager.activeproducers.size}, "" s""logstartoffset is $leaderlogstartoffset and logendoffset is $nextoffset"")",0,0.9951340556144714
1043986046,11390,junrao,2022-12-09T01:50:34Z,"yes, thinking about this more. i am not sure that truncating all local logs is the right thing to do. if we do that, the replica's log may not give a complete view of the data. we could get into this situation when (1) the topic level remote storage flag propagation is delayed; (2) incorrect configuration by the user (e.g. remotestoragesystemenable not enabled on all brokers). in both cases, it seems a better strategy is to error out and keep retrying. in the case (1), the issue will be resolved automatically when the topic level flag is propagated to this broker. in the case (2), this issue will be resolve after the user fixes the configuration.",0,0.9389466047286987
1043987311,11390,junrao,2022-12-09T01:51:30Z,it seems no non-test caller sets flushtofile to false?,0,0.9936695694923401
1043989048,11390,junrao,2022-12-09T01:52:25Z,truncateonfetch is always true?,0,0.9933273792266846
1043989337,11390,junrao,2022-12-09T01:52:47Z,add newline after,0,0.99489426612854
1043989757,11390,junrao,2022-12-09T01:53:22Z,could this be private?,0,0.9816126227378845
1043990559,11390,junrao,2022-12-09T01:54:23Z,could we add a description of the class?,0,0.9944984316825867
1044740416,11390,junrao,2022-12-09T18:47:37Z,could we use case statement to avoid using unnamed references?,0,0.9916530251502991
1044741168,11390,junrao,2022-12-09T18:48:41Z,"hmm, i am not sure that i understand the test. the snapshot corresponding to offset 5 should still be there, right? where did we delete it?",0,0.6851496696472168
1044757469,11390,junrao,2022-12-09T19:11:36Z,why are we calling the same thing a second time?,0,0.9611026644706726
1044758640,11390,junrao,2022-12-09T19:13:28Z,why are we calling the same thing a second time? ditto in two other places below.,0,0.9831016659736633
1044791351,11390,junrao,2022-12-09T19:42:37Z,"hmm, the log segment only has 1 record with timestamp and startoffset. why do we return timestamp + 1 here?",0,0.9843586683273315
1044796318,11390,junrao,2022-12-09T19:48:50Z,add a new line above,0,0.9941791296005249
1044806867,11390,junrao,2022-12-09T20:05:41Z,_locallogstartoffset could change after we find out the epoch. perhaps we could save it as a local val and use it in the return value.,0,0.9908158779144287
1046991743,11390,satishd,2022-12-13T10:58:07Z,comment does not say that magic+4 bytes adds upto log_overhead. updated the comment to make it more clear about the size used in the below code. `int buffersize = log_overhead + size;`,0,0.9942481517791748
1047001228,11390,satishd,2022-12-13T11:04:58Z,i will address it in a followup pr. filed [a link],0,0.9951010346412659
1047001890,11390,satishd,2022-12-13T11:05:34Z,right. added the respective delete part for now which is about removing the partitions. more on that will be added respectively when we add handling partition deletes with respect to remote storage also.,0,0.99399334192276
1047002015,11390,satishd,2022-12-13T11:05:45Z,done,0,0.8682363629341125
1047002223,11390,satishd,2022-12-13T11:05:58Z,done,0,0.8682363629341125
1047003879,11390,satishd,2022-12-13T11:07:40Z,"that case is taken care in `lookuptimestamp`. let me know if i am missing anything here. `val timestampoffset = lookuptimestamp(rlsmetadata, timestamp, startingoffset)`",0,0.9948816299438477
1047004756,11390,satishd,2022-12-13T11:08:10Z,done,0,0.8682363629341125
1047005713,11390,satishd,2022-12-13T11:08:41Z,updated it with the right text.,0,0.9934033751487732
1047007959,11390,satishd,2022-12-13T11:09:51Z,nice catch! this is moved to `metadataversion`.,1,0.9956833124160767
1047008633,11390,satishd,2022-12-13T11:10:15Z,"no, fetchearlierepochendoffset(2) is right. argument here is the leader epoch.",0,0.9894028902053833
1047008950,11390,satishd,2022-12-13T11:10:25Z,done,0,0.8682363629341125
1047009169,11390,satishd,2022-12-13T11:10:31Z,done,0,0.8682363629341125
1047014746,11390,satishd,2022-12-13T11:14:32Z,right.,0,0.9789980053901672
1047015681,11390,satishd,2022-12-13T11:15:31Z,`truncateonfetch` is the existing code. it is not added by this pr.,0,0.9942795038223267
1047016127,11390,satishd,2022-12-13T11:15:58Z,done,0,0.8682363629341125
1047017673,11390,satishd,2022-12-13T11:17:33Z,this is overridden by `listoffsetsrequestwithremotestoretest`,0,0.9959309697151184
1047018234,11390,satishd,2022-12-13T11:17:46Z,done,0,0.8682363629341125
1047018559,11390,satishd,2022-12-13T11:17:55Z,done,0,0.8682363629341125
1047019754,11390,satishd,2022-12-13T11:18:35Z,updated with javadoc to explain the testcases with the latest commits.,0,0.9933258295059204
1047020063,11390,satishd,2022-12-13T11:18:44Z,updated with javadoc to explain the testcases with the latest commits.,0,0.9933258295059204
1047020508,11390,satishd,2022-12-13T11:18:57Z,done,0,0.8682363629341125
1047020836,11390,satishd,2022-12-13T11:19:07Z,done,0,0.8682363629341125
1047024290,11390,satishd,2022-12-13T11:21:03Z,+1 on this approach. this is aligned with our initial proposal in this pr also. latest commit is updated with this change.,1,0.4986911118030548
1047369687,11390,satishd,2022-12-13T16:07:36Z,added more documentation about the test for better clarity with the latest commit. statemanager.reloadsnapshots() deletes the existing snapshots.,0,0.9903344511985779
1049205016,11390,satishd,2022-12-15T04:33:13Z,"as discussed offline, the current follower fetch retries when it receives an error while building aurxiliary state. it will eventually gets the auxiliary data from remote storage for the available leader-log-start-offset.",0,0.9941921830177307
1049392445,11390,showuon,2022-12-15T09:20:23Z,maybe we should have an assertion before and between the 1st and 2nd call to `getindexentry`? like this: [code block],0,0.9922886490821838
1049393028,11390,showuon,2022-12-15T09:20:56Z,typo: sis -> is,0,0.9915356636047363
1049396894,11390,showuon,2022-12-15T09:23:45Z,i saw there are many places have this assertion. i've created a jira to address it: [a link] . you can ignore it for this pr. thanks.,1,0.9648146629333496
1049993923,11390,junrao,2022-12-15T18:15:54Z,"this is still not very precise since size includes other fields like crc, attributes, etc. so, we could probably just omit it and say the total size of a batch is log_overhead + the size of the rest of the content.",0,0.9830957055091858
1050008020,11390,junrao,2022-12-15T18:31:58Z,it's better to use locallog.logendoffsetmetadata since it has the log metadata in addition to the offset.,0,0.9929901361465454
1050013671,11390,junrao,2022-12-15T18:39:10Z,"it seems that the ""no message in the remote storage has the given timestamp"" case is covered in the otherwise clause too?",0,0.9924545288085938
1050017122,11390,junrao,2022-12-15T18:43:27Z,it seems that both offsetforleaderepochrequestversion and listoffsetrequestversion are moved to metadataversion and can be removed here?,0,0.994544267654419
1050029710,11390,junrao,2022-12-15T18:57:17Z,"then, could we just remove this param?",0,0.9937886595726013
1050033092,11390,junrao,2022-12-15T19:01:07Z,inmemory => in memory,0,0.9919390082359314
1050035787,11390,junrao,2022-12-15T19:04:29Z,could we add a similar comment as in line 125?,0,0.9942054152488708
1050039191,11390,junrao,2022-12-15T19:09:04Z,change to curlocallogstartoffset = locallogstartoffset ?,0,0.9947956204414368
1050045012,11390,junrao,2022-12-15T19:16:40Z,should we add a test that explicitly tests the producer state after handling offset_moved_to_tiered_storage error? this can be done in a separate pr.,0,0.9948064684867859
1050536097,11390,satishd,2022-12-16T09:28:23Z,updated with what you suggested to make it more clear.,0,0.9921707510948181
1050536434,11390,satishd,2022-12-16T09:28:47Z,done,0,0.8682363629341125
1050536942,11390,satishd,2022-12-16T09:29:21Z,done,0,0.8682363629341125
1050537018,11390,satishd,2022-12-16T09:29:26Z,done,0,0.8682363629341125
1050537960,11390,satishd,2022-12-16T09:30:25Z,"as you suggested earlier, i created a [a link] for that and mentioned it in my earlier [a link].",0,0.9950065612792969
1051118349,11390,junrao,2022-12-16T20:06:38Z,logendoffset still uses offset. we want to use logendoffsetmetadata.,0,0.9942625164985657
1051439769,11390,ijuma,2022-12-17T18:26:58Z,+1,0,0.9816582202911377
263150141,6363,kkonstantine,2019-03-06T21:47:30Z,please skip this file and review: [a link] instead. thanks!,1,0.9443677067756653
263150256,6363,kkonstantine,2019-03-06T21:47:51Z,please skip this file and review: [a link] instead. thanks!,1,0.9443677067756653
263151738,6363,kkonstantine,2019-03-06T21:52:09Z,please skip this file and review: [a link] instead. thanks!,1,0.9443677067756653
263151859,6363,kkonstantine,2019-03-06T21:52:30Z,please skip this file and review: [a link] instead. thanks!,1,0.9443677067756653
263151902,6363,kkonstantine,2019-03-06T21:52:37Z,please skip this file and review: [a link] instead. thanks!,1,0.9443677067756653
263151960,6363,kkonstantine,2019-03-06T21:52:46Z,please skip this file and review: [a link] instead. thanks!,1,0.9443677067756653
263152009,6363,kkonstantine,2019-03-06T21:52:55Z,please skip this file and review: [a link] instead. thanks!,1,0.9443677067756653
263152049,6363,kkonstantine,2019-03-06T21:53:03Z,please skip this file and review: [a link] instead. thanks!,1,0.9443677067756653
263152103,6363,kkonstantine,2019-03-06T21:53:11Z,please skip this file and review: [a link] instead. thanks!,1,0.9443677067756653
263152397,6363,kkonstantine,2019-03-06T21:54:01Z,please skip this file and review: [a link] instead. thanks!,1,0.9443677067756653
263152448,6363,kkonstantine,2019-03-06T21:54:08Z,please skip this file and review: [a link] instead. thanks!,1,0.9443677067756653
263152502,6363,kkonstantine,2019-03-06T21:54:17Z,please skip this file and review: [a link] instead. thanks!,1,0.9443677067756653
263242755,6363,kkonstantine,2019-03-07T05:31:22Z,"this file changes can be omitted, although it'd be nice to consider whether we want to enable a few log messages in connect integration tests. this is something that manually needs to be enabled when someone debugs a failure at an integration test.",0,0.9944838881492615
268807968,6363,rhauch,2019-03-25T19:10:32Z,missing the `` for most of the parameters.,0,0.9440575242042542
268809353,6363,rhauch,2019-03-25T19:14:31Z,"nit: might this be null, or will it only be empty?",0,0.9821781516075134
268809411,6363,rhauch,2019-03-25T19:14:38Z,"nit: might this be null, or will it only be empty?",0,0.9821781516075134
268845523,6363,rhauch,2019-03-25T20:51:45Z,nit: should the header be in a ` ` section so it's easier to read given it uses constant-width formatting?,0,0.9845337867736816
268846278,6363,rhauch,2019-03-25T20:53:50Z,"the [a link] that `compatible` is the default. also, why is the protocol string for eager ""`default`""?",0,0.9941946864128113
268847672,6363,rhauch,2019-03-25T20:57:16Z,"why not define a new field in the enum and assign via a constructor, rather than define an abstract method and override in the definitions? see [a link] for an example.",0,0.9925767779350281
268847927,6363,rhauch,2019-03-25T20:57:50Z,the [a link] mentions that `compatible` is the default.,0,0.9944990873336792
268848356,6363,rhauch,2019-03-25T20:58:40Z,nit: maybe use `timeunit.seconds.tomillis(300)` for the value? that seems to be more in line with how we're doing time-related constants now.,0,0.9873249530792236
268848881,6363,rhauch,2019-03-25T21:00:06Z,can this be final? can it also be private? (i don't see it's used anywhere else in the code.),0,0.9929608702659607
268849865,6363,rhauch,2019-03-25T21:02:40Z,"doesn't each process only have a single distributedworker instance? if so, then would `connect_client_id_sequence.getandincrement()` ever return something other than 1?",0,0.9922614693641663
268868053,6363,rhauch,2019-03-25T21:53:33Z,"did you consider having a single log message that output all of these in one message? would that make it easier to follow what is being decided, especially if there are lots of interjected messages from currently-running connectors and tasks?",0,0.991778552532196
268869092,6363,rhauch,2019-03-25T21:56:44Z,add javadoc,0,0.9936287999153137
268882992,6363,rhauch,2019-03-25T22:43:19Z,is this method used anymore?,0,0.9936270713806152
268911175,6363,rhauch,2019-03-26T01:06:41Z,"the logic of these methods is not trivial, and while connectassignortest has unit tests that exercise some of these methods, what do you think about writing unit tests for these. they really don't use state, so they would seem straightforward to test and it would help any future work by preventing regressions.",0,0.9853364825248718
268911374,6363,rhauch,2019-03-26T01:08:03Z,this combination of javadoc and line comments is unusual. is there a reason this isn't in the javadoc?,0,0.9290996193885803
268912546,6363,rhauch,2019-03-26T01:16:43Z,nit: seems odd to have statics after member fields.,-1,0.8762219548225403
268913739,6363,rhauch,2019-03-26T01:24:46Z,how about a validator to ensure that worker configs are valid before the distributedworker starts instantiating its components and throwing illegalargumentexceptions?,0,0.9932423233985901
268913846,6363,rhauch,2019-03-26T01:25:27Z,"what happens if name is not lowercase? there's no validator for this, so it's possible to get an exception at a strange point.",0,0.9203506708145142
268914485,6363,rhauch,2019-03-26T01:29:39Z,i don't think this is used anywhere except for tests. is that intentional?,0,0.9720535278320312
268914753,6363,rhauch,2019-03-26T01:31:27Z,"i think these fields will never be null based upon how it is currently used, but there are no asserts or checks to ensure there are no npes here. is this intentional?",0,0.9843698740005493
268915078,6363,rhauch,2019-03-26T01:33:33Z,"it took me a while to find this class. would it make more sense if there were named `incrementalcooperativeassignortest` instead, since that's all that's being tested?",0,0.8240509629249573
268916477,6363,rhauch,2019-03-26T01:43:03Z,do you think it's easier to understand the test to simply do: [code block],0,0.9889425039291382
268916806,6363,rhauch,2019-03-26T01:45:25Z,"is this all that we can assert here? it doesn't really seem to validate much of the logic by just checking the sizes, does it?",0,0.9825160503387451
271858376,6363,kkonstantine,2019-04-03T17:46:44Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9941092729568481
271858438,6363,kkonstantine,2019-04-03T17:46:52Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9941092729568481
271858506,6363,kkonstantine,2019-04-03T17:47:02Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9941092729568481
271858588,6363,kkonstantine,2019-04-03T17:47:16Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9941092729568481
271858640,6363,kkonstantine,2019-04-03T17:47:23Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9941092729568481
271858676,6363,kkonstantine,2019-04-03T17:47:29Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9941092729568481
271858830,6363,kkonstantine,2019-04-03T17:47:41Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9941092729568481
271858905,6363,kkonstantine,2019-04-03T17:47:54Z,#6342 was merged. this pr is now rebased on top of it.,0,0.9941092729568481
271908729,6363,rayokota,2019-04-03T20:01:15Z,"wouldn't it be better to return an empty map? then it would be consistent with the code in the rest of the method body that also returns an empty map if both are `null`. and it would also be consistent with `asmap` that never returns `null` as well as a few other methods in this class that return `collections.emptylist` instead of `null`, and also remove a bunch of `null` checks.",0,0.9876349568367004
271909677,6363,rayokota,2019-04-03T20:03:53Z,"if `taskassignments` never returns `null`, you can simplify these checks.",0,0.9934179782867432
271910018,6363,rayokota,2019-04-03T20:04:51Z,"if `taskassignments` never receives `null`, you can simplify this so that it also never returns `null`.",0,0.9925317168235779
271910748,6363,rayokota,2019-04-03T20:06:58Z,`asmap()` never returns `null`; that's why it would be nice if `asrevokedmap` also never returns `null`.,0,0.990786612033844
271911651,6363,rayokota,2019-04-03T20:09:34Z,yay!,1,0.9680545330047607
271911745,6363,rayokota,2019-04-03T20:09:53Z,yay!,1,0.9680545330047607
271912716,6363,rayokota,2019-04-03T20:12:39Z,wouldn't it be better to have something like `public static connectprotocolcompatibility default = eager;`,0,0.9896218776702881
271913903,6363,rayokota,2019-04-03T20:16:03Z,"why can't this just be `name().tolowercase(locale.root)`. otherwise if `protocol()` is allowed to differ from `name()`, then how do i go from a `protocol()` to the enum (since there is only a way to go from `name()` to enum).",0,0.9865996837615967
271916281,6363,rayokota,2019-04-03T20:22:40Z,should we check that `update` is `null`? it's confusing if `running` is allowed to be `null` but `update` is assumed not to be.,0,0.5839981436729431
271917878,6363,rayokota,2019-04-03T20:27:21Z,nit: can be replaced with `computeifabsent`,0,0.9950317144393921
271918316,6363,rayokota,2019-04-03T20:28:35Z,nit: can be replaced with `computeifabsent`,0,0.9950317144393921
271918654,6363,rayokota,2019-04-03T20:29:29Z,nit: can be replaced with `getordefault`,0,0.9951617121696472
271918689,6363,rayokota,2019-04-03T20:29:35Z,nit: can be replaced with `getordefault`,0,0.9951617121696472
271919947,6363,rayokota,2019-04-03T20:33:02Z,do we need an `assert` that the `memberconfigs` is never empty? otherwise `return maxoffset` will throw npe.,0,0.9927511215209961
271920454,6363,rayokota,2019-04-03T20:34:20Z,"nit: this can be simplified to `maxoffset = math.max(maxoffset, memberrootoffset)` if we initialize `maxoffset` with `long maxoffset = long.min_value`.",0,0.9933555126190186
271923960,6363,rayokota,2019-04-03T20:43:37Z,"there is an `equals` call here, but i don't see `equals` and `hashcode` methods for `connectassignment`. if you are assuming reference equality, perhaps use `==`?",0,0.9934486746788025
271927037,6363,rayokota,2019-04-03T20:51:08Z,"why not return `connectassignment.empty()`? i found 2 callers to this method: `incrementalcooperativeconnectprotocol.derserializemetadata` sends the result to the `extendedworkerstate` constructor, which replaces null with `connectassignment.empty()`. the other caller, `workercoordinator.onjoincomplete()`, tries to call `version()` and would get an npe.",0,0.992254376411438
271928754,6363,rayokota,2019-04-03T20:55:39Z,nit: could add `throws schemaexception` to the method declaration if you want,0,0.9947546720504761
271930819,6363,rayokota,2019-04-03T21:01:10Z,do we need an `assert` that `allmembermetadata` is not empty? otherwise an npe would result here i think,0,0.9933136105537415
271933574,6363,rayokota,2019-04-03T21:08:51Z,should this return an empty `bytebuffer`? i think one of the callers will get a npe otherwise.,0,0.9911545515060425
271933845,6363,rayokota,2019-04-03T21:09:40Z,nit: `.stream().foreachordered()` can be replaced with `.foreach()`,0,0.9936656355857849
271934088,6363,rayokota,2019-04-03T21:10:24Z,nit: `.stream().foreachordered()` can be replaced with `.foreach()`,0,0.9936656355857849
271934289,6363,rayokota,2019-04-03T21:10:57Z,nit: `.stream().foreachordered()` can be replaced with `.foreach()`,0,0.9936656355857849
271979425,6363,kkonstantine,2019-04-04T00:16:31Z,"unfortunately this value has to stay as is, called `default`, otherwise we won't be able to have live rolling upgrades. in all the versions up to now, the `workercoordinator` sets the name of the embedded protocol in the joingrouprequest (aka metadata request) as `default`. small price to pay i think, because it's internal info. we can deprecate the term `default` eventually",-1,0.8645135164260864
271979799,6363,kkonstantine,2019-04-04T00:18:57Z,in the `reverse` map we put both values lowercase and uppercase (values are matching the enum name which is upper case). they can be used either way then. i don't think i was the first to introduce this. but i have found useful that we don't strictly accept only uppercase values. i don't see much downside to it.,0,0.6299364566802979
271980517,6363,kkonstantine,2019-04-04T00:23:32Z,"i find the two ways equivalent, with minor pros and cons in edge cases.",0,0.964815080165863
271980846,6363,kkonstantine,2019-04-04T00:25:39Z,correct. i didn't get to the removal of `cooperative` as well as the switch of default yet. will update in a bigger commit without other cleanup comments.,0,0.9753994345664978
271982564,6363,kkonstantine,2019-04-04T00:36:45Z,"the sets are many. i'd still like to take a final look on what is printed before we merge. but seems not printing as soon as possible, might hide issues, even during integration tests. but i see your point. let's get back to that.",0,0.9787084460258484
272760693,6363,kkonstantine,2019-04-05T22:24:34Z,i believe they are there now.,0,0.9864663481712341
272761166,6363,kkonstantine,2019-04-05T22:27:38Z,let me know if that's what you had in mind.,0,0.9689286351203918
274026037,6363,mumrah,2019-04-10T15:36:25Z,"`objects#requirenonnull` can be used during assignment as well, e.g. [code block]",0,0.9946163296699524
274068757,6363,mumrah,2019-04-10T17:13:39Z,"minor: since there are so few values to consider, maybe prefer a brute force approach? e.g., `values().stream().findfirst(mode -> mode.name().equalsignorecase(querymode)`",0,0.9724120497703552
275537294,6363,kkonstantine,2019-04-15T20:44:49Z,"this file contains the old code in `workercoordinator` _as-is_. i would prefer not to introduce changes at all, no matter how small the changes. in a pr that big, it's simply a matter of discipline not to try to change multiple execution paths at once. this and the optimizations below are small. additionally, this code is not expected to run if the new rebalancing policy is chosen. i'm happy to return to this code, that is know encapsulated in a separate and well defined class for a similar clean once the the code has been released.",1,0.6636747121810913
275537397,6363,kkonstantine,2019-04-15T20:45:07Z,same as above.,0,0.9922299981117249
275537442,6363,kkonstantine,2019-04-15T20:45:16Z,same as above,0,0.9918335676193237
275537487,6363,kkonstantine,2019-04-15T20:45:21Z,same as above,0,0.9918335676193237
275537527,6363,kkonstantine,2019-04-15T20:45:30Z,same as above,0,0.9918335676193237
275537593,6363,kkonstantine,2019-04-15T20:45:41Z,same as above,0,0.9918335676193237
275538726,6363,kkonstantine,2019-04-15T20:48:59Z,"it's not a checked exception. we don't add unchecked exception to the signature. only in javadoc. this method is `private`, so i'm adding the javadoc mention on the `public` methods that check version.",0,0.994045078754425
275549911,6363,kkonstantine,2019-04-15T21:22:22Z,fixed. with a note to improve logging and log messages in this class.,0,0.9868512749671936
275560677,6363,kkonstantine,2019-04-15T21:57:44Z,"the distinction i want to reflect here is that, task assignments have always been a required field of the connect protocol (v0 and therefore v1) and this can not change in a backwards compatible way. to the contrary, the revoked assignments correspond to a new field, which is also `nullable` which here means also optional. deprecating such a field if we need to might be easier in the future (although not completely transparent since we don't selectively unpack fields in the protocol schema). that's why `asmap` does not return `null` while `asrevokemap` might return `null`. i'll comment below too.",0,0.9893277287483215
275562433,6363,kkonstantine,2019-04-15T22:04:33Z,see previous comment.,0,0.9940604567527771
275563850,6363,kkonstantine,2019-04-15T22:10:28Z,"this is different. this takes you from on-the-wire representation to the in-memory representation. also, it's meant to be used both for assignments and revocations. of course, for this protocol it doesn't make sense to keep `null` in the in-memory representation of `connectassignment`. see another take on compatibility between v0 and v1 in `connectprotocolcompatibilitytest`",0,0.9915522933006287
275563890,6363,kkonstantine,2019-04-15T22:10:39Z,see comment above,0,0.9929077625274658
275567590,6363,kkonstantine,2019-04-15T22:25:40Z,"enums in java are more expressive. we don't have to restrict ourselves to what `name()` represents. here we have a good example, where the protocol has to stay as `default` for backwards compatibility but we don't have to call the enum literal `default`. giving the literal a more accurate name, while keeping compatibility is one of the reasons enums in java are more powerful than elsewhere.",0,0.9575358629226685
275567702,6363,kkonstantine,2019-04-15T22:26:14Z,let's revisit when we reduce the enum values to reflect the voted version of the kip,0,0.9919523596763611
275571648,6363,kkonstantine,2019-04-15T22:43:44Z,this is not meant to be a general method. i removed the `null` check because assignment collections should not be `null`. if we see fit later on we could factor out this logic to a more general diff method in `connectassignment` itself.,0,0.9932523369789124
275575635,6363,kkonstantine,2019-04-15T23:02:18Z,"with api generator has become a bit harder to argue about, but both current and new code depend on members this list (`allmembermetadata`) not being `null`. any gaps of api generator with `final` member fields and when arrays are allowed to be set to `null` instead of an empty array should not be addressed as part of this pr imo. i think it's safe to depend on the previous assumption, that `allmembermetadata` can not be `null`.",0,0.9810271263122559
275576977,6363,kkonstantine,2019-04-15T23:08:48Z,but if we were to introduce these methods on `connectassignment` this code would still work right? while reference equality would be harder to track in this case.,0,0.9891229271888733
275585786,6363,kkonstantine,2019-04-15T23:55:41Z,"currently this doesn't seem possible because we never send a `connectassignment.empty()` intentionally unless this is called in a metadata request. we might send an assignment that is practically empty on an error, but in this case equality here is not true. however, i'll tighten the checks and will increase coverage. we might end up diverging, depending on who's using this call. however, again for metadata we need `null` because this goes to a nullable field.",0,0.9857000708580017
275586823,6363,kkonstantine,2019-04-16T00:01:33Z,"see explanation above. this ties back to what we send over the wire. a `connectassignment.empty` assignment is never sent over the wire (you'll always have the leader and the leader url fields for instance, even if you receive an empty assignment).",0,0.9935711622238159
275587099,6363,kkonstantine,2019-04-16T00:03:19Z,"see answer in the other comment about `asmap`. the two methods are not symmetric to this respect, because one field is required and the other one is optional.",0,0.9914152026176453
275587135,6363,kkonstantine,2019-04-16T00:03:30Z,fixed,0,0.920660674571991
275587191,6363,kkonstantine,2019-04-16T00:03:50Z,"as mentioned above, these fields in `v1` protocol are `nullable`. therefore, instead of going back and forth from empty list to `null` and vice versa, i prefer to have `taskassignments` handle `null` and potentially return `null`, because `null` is what needs to be used when these optional fields are empty.",0,0.9927186965942383
275588182,6363,kkonstantine,2019-04-16T00:09:40Z,"changed, although with the need to convert `long` to `int` it's less brief than ideal. though still safer, i agree.",0,0.9192584156990051
275588691,6363,kkonstantine,2019-04-16T00:12:39Z,fixed. i must have had plans for parameterizing it in unit tests that i didn't follow after all.,0,0.8732285499572754
275588918,6363,kkonstantine,2019-04-16T00:13:49Z,this is older code which i chose not to change here. one place where you can see the counter making a difference is in integration tests with multiple workers at the moment.,0,0.9884465932846069
275589318,6363,kkonstantine,2019-04-16T00:16:11Z,i'm keeping the old comment from `connectprotocol`. not sure it belongs to the javadoc. wdyt?,0,0.9688008427619934
275589829,6363,kkonstantine,2019-04-16T00:19:14Z,"in general, i'm not sure our checkstyle is very opinionated w.r.t to this order. changed to bring empty first.",0,0.6590777039527893
275590343,6363,kkonstantine,2019-04-16T00:22:13Z,"this class has some overlap with other classes such as `connectorsandtasks` and even `leaderstate`. i agree and i would also like to consolidate, but maybe when we are near the end of the pr review.",0,0.9832544922828674
275590597,6363,kkonstantine,2019-04-16T00:23:38Z,i'll add a requirement in the constructor rather than here.,0,0.9913023710250854
275592326,6363,kkonstantine,2019-04-16T00:34:24Z,fixed,0,0.920660674571991
275592693,6363,kkonstantine,2019-04-16T00:36:30Z,"also, to comment, java allows us to not have strict binding to enum names. i'm inclined to use this functionality here.",0,0.9892442226409912
275593431,6363,kkonstantine,2019-04-16T00:41:13Z,javadoc fixed with reference to `null`,0,0.9937757253646851
275593446,6363,kkonstantine,2019-04-16T00:41:19Z,javadoc fixed with reference to `null`,0,0.9937757253646851
275893903,6363,mumrah,2019-04-16T16:46:38Z,does connect use the `time` utility class? my understanding is that it makes instrumenting time-based logic easier in the test code.,0,0.9938513040542603
275900247,6363,mumrah,2019-04-16T17:02:14Z,"i was wondering about the thread safety of this assignment, but i see that calls to this method are protected by upstream synchronization in abstractcoordinator. maybe we should include a note about thread safety in the class javadoc?",0,0.9786171317100525
275903378,6363,mumrah,2019-04-16T17:10:05Z,"maybe consider exposing only what is needed from workercoordinator rather than depending on the whole class here? instead, you could pass in a clusterconfigstate supplier and a leaderstate consumer. this would also make unit testing this method more straightforward. just a thought.",0,0.9871009588241577
275904303,6363,mumrah,2019-04-16T17:12:29Z,"how is error handling done for this method? it mutates its own state (previousassignment) as well as the workercoordinator. if we fail half way through the assignment procedure, how do we ensure a valid overall state?",0,0.9918713569641113
275905898,6363,mumrah,2019-04-16T17:16:39Z,why the explicit check for log level here?,0,0.986473560333252
275908713,6363,mumrah,2019-04-16T17:23:57Z,"nit: a method reference can be used here e.g., `foreach(workerload::assign)`",0,0.9951673746109009
275912009,6363,mumrah,2019-04-16T17:32:06Z,why iterator here instead of stream?,0,0.9903174638748169
275944942,6363,kkonstantine,2019-04-16T18:54:49Z,"we seem to follow this pattern in other enums elsewhere too, so i'm more inclined to keep it the same here too. i agree with your point. but also the footprint of a hashmap here is not an issue too i'd say. thus this is more stylistic than anything else i believe. wdyt?",0,0.9575587511062622
275945434,6363,kkonstantine,2019-04-16T18:56:08Z,"yes, i'm a big proponent of mocking time and `time` util specifically. i missed its use here. will add!",1,0.7120821475982666
275946661,6363,kkonstantine,2019-04-16T18:59:28Z,good point. in general we don't assume multi-threading for the code that is run by the herder and this has simplified things. i'll add a mention,1,0.9616519212722778
275953129,6363,kkonstantine,2019-04-16T19:18:02Z,to avoid the `foreach` loop if the log level is not at least debug (the methods called on `wl` don't compute anything indeed),0,0.9915356636047363
275955774,6363,kkonstantine,2019-04-16T19:25:52Z,"the `numtorevoke` that is used to exit the `for` loops (potentially early) is not effectively final. i could work around it, but i'm not sure the result would be more readable.",0,0.9659197330474854
275956315,6363,kkonstantine,2019-04-16T19:27:18Z,til. thanks!,1,0.9913028478622437
276076567,6363,kkonstantine,2019-04-17T04:39:04Z,added guard in the constructor,0,0.9955211877822876
276076869,6363,kkonstantine,2019-04-17T04:41:28Z,done,0,0.8682363629341125
276079316,6363,kkonstantine,2019-04-17T04:58:31Z,done,0,0.8682363629341125
276861923,6363,rayokota,2019-04-18T23:04:07Z,perhaps either 1) add `equals` and `hashcode` to `connectassignment` or 2) add a comment here stating that the `equals` method is relying on reference equality since `equals` is not overridden in `connectassignment`. wdyt?,0,0.992368757724762
277123841,6363,kkonstantine,2019-04-20T04:49:03Z,"sure! added a comment for now, and i'll revisit method implementation if we need it for general comparisons between assignments (i don't see a reason yet).",1,0.7086300849914551
277124243,6363,kkonstantine,2019-04-20T05:14:41Z,done,0,0.8682363629341125
277799701,6363,kkonstantine,2019-04-23T17:54:02Z,"the changes to the enum that reflect the latest kip version have been pushed. again, using ""default"" is required in order to be backwards compatible and support older workers.",0,0.9955046772956848
277800822,6363,kkonstantine,2019-04-23T17:56:56Z,"again, i'd prefer to support both: `eager` and `eager` as well as `compatible` and `compatible`. are we ok with that?",0,0.9868229627609253
277933842,6363,ewencp,2019-04-24T02:14:52Z,"why this particular setup with a new class? the naming seems like it's going to be confusing since there's no obvious differentiation in naming. its been awhile since i looked at the code, but i think the general pattern expected (from both `consumerprotocol` and `connectprotocol` when we generalized) is that we'd maintain the different version schemas alongside each other, much as we do for lower level message types (e.g. check what `metadatarequest` code looks like). this means we have mostly reuse and just a bit of delta for various parsing/serialization since lots of the code overlaps. at a minimum, i'd suggest renaming this class to something clearly tied to the updated code, whether similar to the `incrementalcooperativeconnectprotocol` class or some variant that is perhaps more general that would apply even with further extensions.",0,0.7411439418792725
277934191,6363,ewencp,2019-04-24T02:17:07Z,"currently with only 1 version we just do validation inline, but given this is common state between this class and the base class, why not make it a field and any necessary accessors on the base class? seems like ideally this class would only add new fields that are truly unique to it (and lack of stored state in one case vs the other seems weird).",-1,0.9556342363357544
277938290,6363,ewencp,2019-04-24T02:45:57Z,"at some length of fields, `stringbuilder` probably makes sense. not sure how frequently we're logging this, which i assume is main use case here",0,0.9853615164756775
277939161,6363,ewencp,2019-04-24T02:52:28Z,"why do we need distinct here but not on the subsequent task list? why would there be dups here but not there? i think its fine to include this if we want to be defensive, but seems like it should be used in both cases if that's the goal.",0,0.9758909344673157
277945505,6363,ewencp,2019-04-24T03:40:16Z,these methods could validate the `key` is in the expected set to be more defensive against coding errors,0,0.9944708347320557
277945625,6363,ewencp,2019-04-24T03:41:08Z,nit: you're doing a redundant lookup here after already assigning to `connectors` to do the `null` check,0,0.9901506900787354
277946373,6363,ewencp,2019-04-24T03:47:35Z,"why are we documenting v1 subscription here? it's also identical to v0, but even if it weren't, this code deals with v0, right?",0,0.9841923713684082
277946470,6363,ewencp,2019-04-24T03:48:27Z,"i guess this kind of explains my above question re: v1 docs here since this doesn't include everything for v0, but again, why re-document this here?",0,0.9755541682243347
277947459,6363,ewencp,2019-04-24T03:56:30Z,"if anything, it seems even better to just generalize to case insensitivity (which i am not a fan of in many cases, but in the context of enum configs should be harmless unless we make some pretty bad decisions). tbh, i'm not sure why elsewhere we're optimizing the string -> enum lookup unless it is in a hot path, which it doesn't seem like it should be here",0,0.8612719774246216
277947904,6363,ewencp,2019-04-24T04:00:14Z,"not sure if this was intended to apply to both connect protocol and scheduled rebalance max delay, but validator on the delay would make sense as well -- at a minimum to ensure non-negative",0,0.9472616314888
277948672,6363,ewencp,2019-04-24T04:06:36Z,"hmm, so this is a potentially interesting change. client.id can be used for some things like quotas. since this is for workers, i'm not sure we're actually changing behavior in any interesting way here, but we should consider what the possible fallout in behavior could be by changing the default client.id behavior here.",0,0.8548756241798401
277950243,6363,ewencp,2019-04-24T04:18:49Z,"we use normal logging elsewhere in this file, i assume this is stray debugging code?",0,0.9928572177886963
278276834,6363,ewencp,2019-04-24T19:11:50Z,what's the reason for removing this? if anything i would think we should have more logging around these operations rather than less.,0,0.9836121201515198
278278502,6363,ewencp,2019-04-24T19:16:38Z,"it seems like most of the other logic around the protocol versions is cleanly factored into the protocol classes. could we refactor this logic as well, e.g. to get this from `assignment`?",0,0.9919488430023193
278371438,6363,ewencp,2019-04-25T01:29:36Z,"why are we clearing these here? i would think the key thing in this class would just be to force the rejoin when tasks are revoked and it doesn't look like we use this anywhere else in this class that this would cause a problem. is there some sharing with code elsewhere that relies on this? (and if so, could we just hand this class a copy instead?)",0,0.9823220372200012
278372255,6363,ewencp,2019-04-25T01:36:27Z,"this might be worth a comment as well, or actually even restructuring a bit. it seems confusing that the `runningassignment` after starting all the connectors and tasks would be `empty()`. i *suspect* this is being done because on the subsequent round, this forces the `assignmentdifference` to be the full set of connectors/tasks in `assignment`. but it might be more intuitive to reset `runningassignment` to `empty()` in the `onrevoked` (where they actually stop running, and given that it's just based on the parameters, it might be more implicit based on what was passed in than based on the protocol version). i *think* that also handles my above comment because the check for protocol version is no longer necessary -- it should just work out.",0,0.9731267094612122
278374311,6363,ewencp,2019-04-25T01:54:11Z,"seems like copy paste? and a bunch of the utilities would be. aside from the diff to make protected, did you consider having this inherit from eager and override the key functionality but reuse the rest (which perhaps is better structured as utilities elsewhere, but your inclination to not change the existing implementation too much seems reasonable to me at least for awhile for maintenance reasons, although even there that code hasn't changed in a long time)?",0,0.9770044684410095
278732876,6363,kkonstantine,2019-04-25T21:09:29Z,"added a validation and a validator class that can allow anyone to write a validator in place. i think this is useful and will help with easy addition of validations, that currently are missing from several places. i believe this part belongs to a separate pr with a jira ticket that informs for the addition of what i called `lambdavalidator`. but before i create this i'd like to get some feedback here. wdyt ?",1,0.9112077951431274
278733160,6363,kkonstantine,2019-04-25T21:10:18Z,"given that i've added several integration tests that bring up several workers, i think it makes sense to leave this here.",0,0.9886533617973328
278741717,6363,kkonstantine,2019-04-25T21:36:44Z,"i'm using an assignment via `leaderset` to the coordinator itself though. i'm inclined to say that encapsulation makes sense for now. i feel it doesn't pose a big trade-off. i'd suggest leaving it for now, since it's an easy future refactoring.",0,0.9613633751869202
278751495,6363,kkonstantine,2019-04-25T22:12:31Z,that's a good question. we might need to reset this under certain errors. i'll get back to that.,1,0.8639916181564331
278752888,6363,ewencp,2019-04-25T22:18:41Z,this is getting a bit confusing -- this seems the same as `currentworkerassignment`. what mutates that causes this to be different?,0,0.5411333441734314
278755759,6363,kkonstantine,2019-04-25T22:31:50Z,added a note at the class level for both `eagerassignor` and `incrementalcooperativeassignor`. we could potentially add a more detailed note such as the one in `abstractcoordinator` on locking.,0,0.9948386549949646
278758021,6363,ewencp,2019-04-25T22:42:40Z,normally `time` would be injected for testing?,0,0.9925441741943359
278765522,6363,kkonstantine,2019-04-25T23:21:58Z,i like to keep the programmatic way of defining test cases. but you are right in that the workers here won't scale significantlly. changed.,0,0.9674220085144043
278766008,6363,kkonstantine,2019-04-25T23:24:35Z,the goal of this test is to validate balanced assignment. thus asserting the size is deterministic and probably sufficient. if we agree on the scheduling algorithms additional unit tests will be added (possibly here) and in `workercoordinatorincrementaltest`,0,0.9937679767608643
278772408,6363,ewencp,2019-04-26T00:01:36Z,it feels like we're getting inconsistent with the naming. `connectassignment` and `connectprotocol.assignment` vs `incrementalcooperativeconnectprotocol.extendedworkerstate` vs `connectprotocol.workerstate`.,0,0.9254963397979736
278785956,6363,ewencp,2019-04-26T01:44:19Z,"i realize we can get the value via `protocolcompatibility.protocol()` here, but might be clearer to just be explicit anyway. definitely in this case it feels like it makes it harder to parse what's going on here (to me at least)",0,0.7989546060562134
278786168,6363,ewencp,2019-04-26T01:46:02Z,what about `cooperative` here?,0,0.9899196624755859
278786302,6363,ewencp,2019-04-26T01:47:04Z,"seems we are missing `cooperative` case here? seems like if we don't handle it here, that setting won't work and having that mode doesn't serve much purpose (even if we encourage people to just leave it in `compatible` given expected low overhead generally)",0,0.9664616584777832
278787756,6363,ewencp,2019-04-26T01:59:34Z,"would any of this be better handled by dynamic dispatch rather than switch statements (for further extensibility)? not a huge deal, but given (at least in this case) it seems like we could dispatch to one of the `[x]connectprotocol` classes, i'm wondering if it avoids switch case hell and keeps the logic for each closer to related protocols and outside of otherwise more general logic. (this admittedly could have been done initially but not nearly as valuable with just one case...)",0,0.8717997670173645
278788073,6363,ewencp,2019-04-26T02:02:07Z,"i'm still working through updated code and all the classes, but this feels a bit messy. admittedly we just dumped the `connectprotocol` here initially when we only had one type. but now it seems confusing when i use the new protocol directly vs having to switch on compatibility, etc. not sure i have a concrete suggestion yet, but i worry about the more general classes here ending up with both explicit (compat mode) and implicit (this case where we always use `incrementalcooperativeconnectprotocol`) decisions about how to handle logic of different versions. i'll think more about how we can refactor...",-1,0.9632640480995178
278788840,6363,ewencp,2019-04-26T02:08:42Z,"we should move this log *above* any actions taken, even if for some reason we only want it in this conditional instead of immediately after the deserialization. since something in onrevoked code could log, ordering of events would be confusing with this where it currently is.",0,0.987071692943573
278789848,6363,ewencp,2019-04-26T02:17:05Z,"this approach seems interesting -- we previously had this class handle this as immutable (the entire snapshot was left unchanged or entirely replaced). do we actually need to mutate like we do here? a few lines down we do [code block] so main value here seems to be for the log statement a couple lines below. the other value in mutating things in this block seems to be for `newassignment`. but it's taking anything *left* in the old assignment and adding it to `newassignment`. but i thought in the kip we still reiterate to the member all assigned resources, so adding the old leftover ones seems redundant. shouldn't the `newassignment` already contain exactly what we want to update `assignmentsnapshot` with before we attempt any of these mutations?",0,0.9686163663864136
278790323,6363,ewencp,2019-04-26T02:21:21Z,this is another location where i wonder if we just maintain one assignor and update *it* when we see protocol version change rather than maintaining `currentconnectprotocol` and switching on it could refactor some of this logic to be more general,0,0.9842405915260315
278791412,6363,ewencp,2019-04-26T02:30:58Z,didn't notice earlier in review that we're making previously internal state mutable. seems to be used primarily by the assignors for identical logic. can we keep this internal state by pushing that logic into this class? i.e. some sort of `tryupdatesnapshot(maxoffset)`?,0,0.9807832837104797
278791963,6363,ewencp,2019-04-26T02:35:24Z,"i haven't worked through all of them, but i think at least `leaderstate()` and `currentprotocolversion()` can be private. with ^^ suggested update, i think some of the `config[x]snapshot()` methods could be as well. we should try to be conservative about what internal state we're exposing. `configstate` and `leaderstate` in particular worry me more since making that mutable by other classes makes this code a lot harder to reason about.",0,0.8107485175132751
278792696,6363,ewencp,2019-04-26T02:41:45Z,"nit: i found this terminology a bit weird. do we (or something else) use `embed` like this normally? if not using a builder pattern but wanting a static method instead of public constructor to build it (which, tbh, seems like a fine solution to me...), i would expect `build(..., ...)` or similar.",-1,0.9516022801399231
278795951,6363,ewencp,2019-04-26T03:07:44Z,appears to be unused?,0,0.9913063645362854
278796064,6363,ewencp,2019-04-26T03:08:38Z,sigh... one day this class will either disappear or become more than a mostly useless pass-through that is mostly here just for the constructor and fields...,-1,0.9918033480644226
278796757,6363,ewencp,2019-04-26T03:14:29Z,"might want to extend this comment to explain updated conditions, i.e. that in original mode all connectors and tasks are revoked, but in newer modes it may be a partial list. this is internal, so not critical, but if you're updating some of the other todo javadocs, this would be another nice improvement",0,0.8020888566970825
278798597,6363,ewencp,2019-04-26T03:28:13Z,"nit: just naming, but there's only one `clusterconfigstate` in this test... extra number not necessary",0,0.9929729700088501
278805479,6363,ewencp,2019-04-26T04:29:09Z,same question about `cooperative` enum option as before,0,0.9933144450187683
278806121,6363,ewencp,2019-04-26T04:34:43Z,"we should enable this for sure, at least at some level. they get stored in truncated logs if successful, and (as of recently) we store full logs for debugging purposes if the test fails. tbh, still not sure how we ended up in a log-free state by default -- it just results in having to turn this on manually, and if test failures are not reproducible locally and only in jenkins, this is a huge pain. in fact, i'd happily merge this as a separate pr even before this pr :) aside from performance or excessive logging, for tests there isn't much downside in ratcheting up the log level",1,0.9558733701705933
278806552,6363,ewencp,2019-04-26T04:38:52Z,"i think nm on this, pretty sure it was moved from other code. just hard to see without loading the full hidden diffs in github review",0,0.9749810099601746
278806717,6363,ewencp,2019-04-26T04:40:29Z,"primary question here is what coverage looks like. `distributedherder.java` now has paths that consider both protocol versions, but looks like these tests are only using `v0` paths. is that ok? based on herder changes, i think loc coverage may not have changed too much, but critical differences might not be well tested now?",0,0.9781914353370667
278807647,6363,ewencp,2019-04-26T04:49:36Z,are we missing other parameterizations? only have one here... `cooperative`?,0,0.9913989305496216
278807823,6363,ewencp,2019-04-26T04:51:38Z,logger or remove?,0,0.9886807203292847
278809207,6363,ewencp,2019-04-26T05:04:48Z,this is never a good sign in a test like this. what does this accomplish?,-1,0.9725481271743774
278810850,6363,ewencp,2019-04-26T05:18:23Z,"might want to highlight the `balanced` pieces below here, that's ultimately the critical bit beyond just running what we expect (which tbh, makes the most important part of these tests hard to find)",0,0.9726306796073914
278812987,6363,ewencp,2019-04-26T05:36:38Z,"just be wary that this entire loop capturing state is a bit dangerous. of course you don't expect it to happen, but it's possible there is a rebalance (unintentionally due to timeouts) and you get some inconsistent set of results wrt connector state/location. at a bare minimum, tons of repeated tests locally and many repeated tests on jenkins would be warranted here to avoid any potential flakiness, especially given ak jenkins' penchant for unexpected timing issues.",0,0.9053158760070801
278816564,6363,ewencp,2019-04-26T06:00:17Z,this is the kind of assertion that could become flaky given incremental population of `connectors`.,0,0.9562073349952698
279022852,6363,kkonstantine,2019-04-26T16:40:18Z,"you are right, this used to be bad, but for a few java versions now, the compiler is able to substitute [a link] to `stringbuilder` on the bytecode. for this class, what i get from: `javap -c connectassignment.class | less` is: [code block] based on that i avoid `+` in loops but in constant expression as this one i keep using `+` for readability. i'm inclined to leave it here, since i'd expect this transformation will be common among java compilers but i can also hardcode `stringbuilder`. wdyt?",0,0.9591372013092041
279027503,6363,kkonstantine,2019-04-26T16:54:39Z,"chose to be on the safe side and map to what we've been doing already in `connectprotocol#asmap`: [a link] and [a link] if we feel confident to diverge on the new protocol (slightly here), i'm happy to do that.",1,0.5864383578300476
279086507,6363,kkonstantine,2019-04-26T20:04:33Z,"since we use `assert` in a few places already, i'll use `assert` here too. let me know if you had something else in mind.",0,0.9686745405197144
279086549,6363,kkonstantine,2019-04-26T20:04:40Z,done here and below,0,0.9937368631362915
279087129,6363,kkonstantine,2019-04-26T20:06:37Z,typo since this was added after v1 javadocs. however the descriptions are correct. nothing should be v1 in this class.,0,0.9908863306045532
279087208,6363,kkonstantine,2019-04-26T20:06:56Z,same typo as above. format is correct,0,0.9886704683303833
279088293,6363,kkonstantine,2019-04-26T20:11:01Z,"if i understand correctly, you are suggesting something similar to what suggested. keep case insensitivity but remove the map. i'll apply this change.",0,0.9934543371200562
279088613,6363,kkonstantine,2019-04-26T20:12:09Z,comments are not in chronological order :) i hope you find inline validations useful and we can keep this. should i submit another pr with some unit tests?,1,0.9959255456924438
279089415,6363,kkonstantine,2019-04-26T20:14:45Z,"indeed, this code is not an addition. it's moved from `workergroupmember` _as-is_ to your point, here, every time i reload i search for ""load diff"" and i load the hidden files. thankfully only 5 or 6 so far :)",1,0.9881604909896851
279100216,6363,kkonstantine,2019-04-26T20:52:48Z,got a second comment on that. changed to runtime check.,0,0.9944724440574646
279135611,6363,kkonstantine,2019-04-27T00:28:05Z,"it was moved inside `onjoinprepare`. that's because now `onrevoked` might also be called in `onjoincomplete`. but this wouldn't mean that a ""rebalance started"".",0,0.9922264814376831
279136107,6363,kkonstantine,2019-04-27T00:36:22Z,"i did inject it elsewhere, especially after 's comment. but this was somehow missed even though i thought i grepped. fixed",0,0.9901913404464722
279136319,6363,kkonstantine,2019-04-27T00:39:55Z,"you are bringing up a good point. i considered `connectassignment` more involed and worthy of factoring out to its own class, but not `workerstate`. we haven't decided what we'll do yet, but i'm more inclined to suggest `connectassignment` and `connectworkerstate` as separate classes. wdyt?",1,0.935575008392334
279136441,6363,kkonstantine,2019-04-27T00:41:59Z,`cooperative` was removed as per the latest comments on the kip (the point was brought up by ). there's was a missed javadoc reference which i've just removed. only `eager` and `compatible` atm.,0,0.9920851588249207
279136636,6363,kkonstantine,2019-04-27T00:45:28Z,i agree,0,0.9744842648506165
279136696,6363,kkonstantine,2019-04-27T00:46:30Z,"maybe you started reviewing when it hadn't been removed. as mentioned in a comment above, `cooperative` has been removed to reflect the kip.",0,0.9850114583969116
279136963,6363,kkonstantine,2019-04-27T00:51:25Z,i thought i had a use of it :) removed now.,1,0.9933777451515198
279137024,6363,kkonstantine,2019-04-27T00:52:32Z,:) if i understand correctly this is not actionable immediately,1,0.9934764504432678
279586499,6363,kkonstantine,2019-04-30T00:33:51Z,make sense. updated!,1,0.8999180793762207
279587083,6363,kkonstantine,2019-04-30T00:38:25Z,i'm also hugely in favor of tests that don't depend on `sleep`. probably this was left here since earlier stages of manual debugging with these tests. removed from all tests. if needed the assertions will be improved.,0,0.9101830124855042
279587559,6363,kkonstantine,2019-04-30T00:41:53Z,"indeed. i'm saving this comment of yours for better verification of flakiness. given that reviews are in progress still, i haven't run integration tests in repeated mode, but i'll definitely do so before merging and will tighten the assertions if needed.",0,0.9219621419906616
279587997,6363,kkonstantine,2019-04-30T00:45:04Z,maybe you are referring to the assertion for imbalanced assignment? because the assignment being unique should be a strong deterministic requirement. but i agree with a holistic review of the assertions here.,0,0.9848063588142395
279588163,6363,kkonstantine,2019-04-30T00:46:18Z,fixed!,1,0.8815674781799316
279588578,6363,kkonstantine,2019-04-30T00:49:31Z,"indeed, the unit testing gaps currently are found here here and in `workercoordinatorincrementaltest`. these will be filled asap. but wanted to first get a round of reviews on the protocol, because these tests will pin the checks on the proposed functionality tbh (as opposed to integration tests for example). definitely a known gap atm.",0,0.9794541001319885
279588748,6363,kkonstantine,2019-04-30T00:50:41Z,"so, `cooperative` was removed, but i left the parameterization just in case we go back and for between `eager` and `compatible` still here (or the original `workercoordinatortest`). i might as well remove it if not.",0,0.9934157133102417
279588838,6363,kkonstantine,2019-04-30T00:51:20Z,debugging leftover probably.,0,0.9792540073394775
279589061,6363,kkonstantine,2019-04-30T00:53:14Z,"as mentioned above, `cooperative` was removed. left, in case some common tests are covered by both (although the assertions might be affected - hence the 1 failure i've left hanging around still so we don't have the impression that we are done with those unit tests).",0,0.992275059223175
279589343,6363,kkonstantine,2019-04-30T00:55:29Z,"removed, thanks!",1,0.9646617770195007
279590175,6363,kkonstantine,2019-04-30T01:02:09Z,"totally agree too. this is indeed weird given that the two commits that refer to this file, don't show evidence of when this change happened. i'll submit another pr that can backported. thanks!",1,0.7393445372581482
280291175,6363,rhauch,2019-05-02T05:20:11Z,"okay, that makes sense. but it might be nice to denote that requirement with a short comment.",0,0.9864110350608826
280291571,6363,rhauch,2019-05-02T05:24:51Z,i agree with (on a [a link] that a validator on the scheduled rebalance max delay is probably pretty beneficial to ensure non-negative values.,0,0.9691759943962097
280292191,6363,rhauch,2019-05-02T05:30:53Z,+1,0,0.9816582202911377
280292897,6363,rhauch,2019-05-02T05:36:54Z,"wouldn't it be helpful here to have more debug or trace logs in this method? i worry that without them, it's going to be hard to track what this logic is doing. it may makes sense to refactor a bit to have a single return preceded by a log message, rather than having multiple log messages for each of the returns.",-1,0.9188371300697327
280292977,6363,rhauch,2019-05-02T05:37:44Z,same comment hear about adding more debug/trace logging for most of the branches.,0,0.993161678314209
280294446,6363,rhauch,2019-05-02T05:51:26Z,"and given ewen's [a link], if `completeworkerassignment` is not different than `currentworkerassignment`, then will `connectorassignments` be any different than before, and `taskassignments` be any different than before?",0,0.9927531480789185
280294974,6363,rhauch,2019-05-02T05:56:18Z,"it'd be really great to have unit tests for many of these methods. the `performtaskassignment(...)` method is already pretty lengthy, and there are just a few unit tests whereas there seem to be lots of permutations and branches. not only would they help with confidence, but they'd help with regression testing if/when we have to get back into this code.",1,0.7235015630722046
280295034,6363,rhauch,2019-05-02T05:56:45Z,ping,0,0.4991936683654785
280295298,6363,rhauch,2019-05-02T05:58:58Z,"right, but everything in the for loop starting on line 335 (except for the return on line 347) is dealing with debug logging, right? if so, then line 336 could be moved into this debug-only block.",0,0.9885221719741821
280295967,6363,rhauch,2019-05-02T06:04:40Z,isn't it possible that some of these are 0 due to integer division truncating? seems like all 4 of these lines could be replaced with something like: [code block],0,0.9909728765487671
280296761,6363,rhauch,2019-05-02T06:10:52Z,"+1. the value of logging in this whole class is not really going to be knowing the final end state, but being able to track the logic in this class to figure out why the end state doesn't match an expected state on some user's connect cluster, and hopefully being able to learn enough to understand what paths are taken so that we can reproduce the case. the other approach is to log all of the initial state up front and all of the new state at the end, such that with that information we could reproduce any logged scenario with a unit test that we can then debug to trace the logic.",0,0.9320893287658691
280296881,6363,rhauch,2019-05-02T06:11:51Z,ping,0,0.4991936683654785
280297070,6363,rhauch,2019-05-02T06:13:38Z,i think it'd be useful to have just one style of javadoc.,0,0.9743906259536743
280297285,6363,rhauch,2019-05-02T06:15:29Z,+1 on the separate classes.,0,0.9614933133125305
280297897,6363,rhauch,2019-05-02T06:20:00Z,"right, and that would be easier to unit test, too.",0,0.9875478744506836
283517005,6363,kkonstantine,2019-05-13T20:15:26Z,"as mentioned this was an insightful observation. returning to this after i added several tests on the assignor code. we have the following two cases: 1) the assignment is computed by the assignor, it contains only revocations and it fails to be delivered. in the next round of rebalancing this failure to change the state of revoked tasks is detected by the assignor, and instead of skipping revocation according to its policy that mandates that there's no consecutive revocations, it re-applies revocation of tasks. this should happen until the assignment containing the revoked tasks succeeds. 2) the assignment is computed by the assignor, it contains only assignments and it fails to be delivered. distinguishing this case from the case that active assignments are detected as lost, would result in a more complicated logic of the assignor's state machine. instead of doing that, the current code, selects to interpret the failed assignment as referring to lost tasks and therefore it enters the deferred rebalancing period, with the specified delay. i believe this keeps things simpler. in a sense whether a worker goes down, or an assignment fails to be delivered, are both considered failures that takes us to the deferred rebalancing logic. the current unit tests currently confirm this behavior. wdyt ?",1,0.761452317237854
283518084,6363,kkonstantine,2019-05-13T20:18:05Z,"my rule of thumb is that i include in a if statement only the debug statements that would result in eager (and potential wasteful) computation of print arguments. the rest of the debug logging is kept outside the if branch, which will allow us to remove the if branch altogether if the line that requires it is removed. otherwise, we risk keeping redundant `if`s around.",0,0.9886217713356018
283528795,6363,kkonstantine,2019-05-13T20:44:26Z,"this test class, now called `incrementalcooperativeassignortest` has been significantly extended to include a big set of tests for the new assignor. resolving this comment and will follow up on other test additions.",0,0.9880805015563965
283529644,6363,kkonstantine,2019-05-13T20:46:37Z,changed to an explicit call to `compatible.protocol()`. resolving this comment. thanks,1,0.8768018484115601
283530355,6363,mumrah,2019-05-13T20:48:19Z,i think that sounds reasonable. thanks for the follow-up !,1,0.9883201122283936
283530780,6363,kkonstantine,2019-05-13T20:49:28Z,`sleep` statements have been removed.,0,0.9919483661651611
283553403,6363,kkonstantine,2019-05-13T21:54:32Z,fixed,0,0.920660674571991
283555350,6363,kkonstantine,2019-05-13T22:00:53Z,removed,0,0.9591778516769409
283557138,6363,kkonstantine,2019-05-13T22:07:18Z,i see your point. when i initially imported this comment _as-is_ i considered it non-javadoc comment and then i added javadoc. upgraded as javadoc now.,0,0.9797855019569397
283557471,6363,kkonstantine,2019-05-13T22:08:34Z,fixed. `stream` is used now instead of a static map.,0,0.9919781684875488
283558392,6363,kkonstantine,2019-05-13T22:11:56Z,"given the generated bytecode, i'll keep the current form of `tostring` if you don't mind. resolving here, but feel free to comment if you feel otherwise.",0,0.9883014559745789
283562360,6363,kkonstantine,2019-05-13T22:27:52Z,"added `between(0, integer.max_value)`",0,0.9946282505989075
284026277,6363,rhauch,2019-05-14T22:34:22Z,"i see what ewen is suggesting - it definitely could be confusing. concretely, at a minimum, rename `connectassignment` -> `incrementalcooperativeassignment` to tie it more closely with the `incrementalcooperativeconnectprotocol`. (even if we think it *might* be useful in a future protocol, we can refactor if/when that happens.) the design in this pr doesn't follow the `consumerprotocol` and `consumerassignor` model too closely. there, the assignor methods dealt with `subscription` and `assignment` types, and so those were defined in the `consumerassigner` class. the `consumerprotocol` just serialized those types. in the current design, the `connectassignor` doesn't deal with the `assignment` and `workerstate` types, and so defining those types in the `connectassignor` class doesn't make much sense. instead, the different `connectassignor` subclasses use their respective protocol in their implementation of `performassignment(...)`. given this difference, i suggest that we simply rename all of the classes that go with the incremental cooperative protocol / assignor to begin with `incrementalcooperative`.",0,0.9508393406867981
284026633,6363,rhauch,2019-05-14T22:35:33Z,+1,0,0.9816582202911377
284035771,6363,rhauch,2019-05-14T23:15:43Z,"when a user has this in their logs, what do they do? maybe add a bit more detail to this log message that lets them know what action they could/should perform, if any. when would the member configs be empty?",0,0.9916472434997559
284037825,6363,rhauch,2019-05-14T23:25:06Z,thoughts on this now that you've been running this a while in tests and in soak?,0,0.9744433760643005
284066405,6363,rhauch,2019-05-15T02:25:31Z,"is there _any_ chance we might have `totalworkersnum` might be 0, resulting in termination of the worker?",0,0.9872190952301025
284067290,6363,rhauch,2019-05-15T02:31:49Z,"`connectorsandtasks.embed(new arraylist<>(), new arraylist<>())` is called 5 places in non-test code. wdyt about adding a `connectorsandtasks.create()` method to reduce the code a bit?",0,0.9933329224586487
284067493,6363,rhauch,2019-05-15T02:33:14Z,"if you believe debug logging is sufficient at this point to be able to track behavior based only on logs, then go ahead and resolve this conversation. if not, maybe consider adding more in key places.",0,0.9849088788032532
284067892,6363,kkonstantine,2019-05-15T02:35:47Z,"actually, the current form, that prints each assignment set separately has been working out nicely in the logs even with lots of connectors. what i think is key, is to use `assignments: ` suffix (or similar) in the end. this way you can grep/collect these lines all together focusing on the logger of this class as well (either via log4j or again by grepping). the fact that these assignments (every set) are printed in a separate line makes the lineage of the assignment process easy to follow. i'll review their final message but again, i'm inclined to retain a common substring and have each one in their own line. rebalancing is happening in certain moments, so there's no significant issue with verbosity here.",0,0.8950265049934387
284068513,6363,rhauch,2019-05-15T02:39:42Z,these methods will sort `completeworkerassignment` -- is that worth a comment above these two lines?,0,0.9958071708679199
284068845,6363,rhauch,2019-05-15T02:42:03Z,i guess i'm a bit surprised that this method modifies `workerassignments`. maybe mention in the `` description here and in `assignconnectors(...)`?,0,0.6676611304283142
284069392,6363,rhauch,2019-05-15T02:45:59Z,"these assign methods are pretty boilerplate, with i think just 2 lines in each that is distinct (the log line and the worker.assign call). did you consider pulling into a method and supplying a bi-function that takes the connectortaskid and the worker?",0,0.9859781861305237
284069861,6363,kkonstantine,2019-05-15T02:49:38Z,it's mutated by: [code block] i see your point and we might be able to consolidate. but i feel that this is higher risk low value optimization at this point. i'm more inclined to leave a comment for a future refactoring.,0,0.9558055996894836
284070224,6363,rhauch,2019-05-15T02:52:11Z,"one thing that would be nice to have: what are the characteristics of the parameters and returned map? for example, is it possible that the returned map contain null `bytebuffer` reference, and if so what does that mean?",0,0.9855315685272217
284070727,6363,rhauch,2019-05-15T02:55:39Z,"but at least on the first line of this method, wouldn't it make sense to use an `connectassignment.isempty()` method here, rather than relying upon instance equality? same behavior, but that would seem less brittle.",0,0.9881762266159058
284071019,6363,rhauch,2019-05-15T02:57:18Z,"i added a comment regarding this regarding the `connectassignor.performassignment(...)` method's javadoc. iiuc, it's possible that the returned `map ` can contain a null byte buffer reference. is null allowed / handled everywhere this method (and others) are used?",0,0.9932424426078796
284071662,6363,rhauch,2019-05-15T03:01:55Z,though wouldn't it be helpful to have the names of the classes related to the incremental protocol all start with `incrementalcooperative`? this is related to my earlier comment (previous review).,0,0.9922427535057068
284072023,6363,rhauch,2019-05-15T03:04:32Z,+1,0,0.9816582202911377
284072326,6363,kkonstantine,2019-05-15T03:06:58Z,these are now specifically tested in `incrementalcooperativeassignortest` alone and as part of the tests cases for `performtaskassignment`. also tested in `workercoordinatorincrementaltest`,0,0.9947670698165894
284072920,6363,rhauch,2019-05-15T03:10:59Z,"we're starting 4 connectors, so should we check that all 4 are running?",0,0.9922375082969666
284072977,6363,rhauch,2019-05-15T03:11:28Z,"we're starting 4 connectors, so should we check that all 4 are running?",0,0.9922375082969666
284073066,6363,rhauch,2019-05-15T03:12:15Z,", can you provide an update?",0,0.9924780130386353
284073384,6363,rhauch,2019-05-15T03:14:30Z,can you provide an update?,0,0.9943128824234009
284074000,6363,rhauch,2019-05-15T03:18:48Z,what is the status of these tests that are commented out?,0,0.9932605624198914
284365134,6363,kkonstantine,2019-05-15T17:22:13Z,"indeed, when a `joingroupresponse` is received with no errors (`errors.none` in errors field) the response will have at least the leader itself as a member. removed this warning because it's a no-op.",0,0.9939258694648743
284366320,6363,kkonstantine,2019-05-15T17:25:18Z,"true. i'd like as part of this pr to apply minimal or no changes to v0 (now eager) protocol. also, as opposed to `connectprotocol` the overlap between the two assignor implementations is quite small, so i think subclassing is not worth it here. i suggest we consider a refactoring (including any helper methods in utils classes) in a subsequent iteration/cleanup.",0,0.9861164689064026
284366792,6363,kkonstantine,2019-05-15T17:26:35Z,good point. moved to builder pattern,1,0.9762183427810669
284367865,6363,kkonstantine,2019-05-15T17:29:02Z,we need the aggregated result of the assignment and creating a new list that we return as a result doesn't worth it i think. i'll update the javadoc to make it more clear. the signature of the method without a return type should also be a hint.,0,0.9833636283874512
284370260,6363,kkonstantine,2019-05-15T17:34:35Z,i see your point. but given that currently we provide only reference equality i wouldn't like to hide this fact within an `isempty` method that would implement this reference equality check. i wouldn't like this to be confused with an assignment that it just has no assigned or revoked resources at the moment.,0,0.9754854440689087
284374327,6363,kkonstantine,2019-05-15T17:45:05Z,fixed and improved all the logs in this method,0,0.9920439124107361
284375015,6363,kkonstantine,2019-05-15T17:46:44Z,fixed by introducing builders for both inner classes here.,0,0.9936627149581909
284375778,6363,kkonstantine,2019-05-15T17:48:22Z,"this remains the case. but for reasons of symmetry with `connectorsandtasks` which is similar i'm inclined to retain this for now, if that's ok.",0,0.9900651574134827
284381964,6363,kkonstantine,2019-05-15T18:02:28Z,i'll add a temp edit to `jenkins.sh` and will run the connect tests (unit and integration) in repeat today. locally i have not noticed flakiness after several runs.,0,0.9930878281593323
284388778,6363,kkonstantine,2019-05-15T18:19:34Z,leftovers of an early import of tests. removed.,0,0.9888028502464294
284539491,6363,kkonstantine,2019-05-16T05:00:16Z,"as discussed briefly offline, the new classes are now both separate public classes and are called `extendedassignment` and `extendedworkerstate`. one of the primary intentions is to leave the current protocol version (v0) with minimal changes. a subsequent refactoring in one of the next version could consolidate the two classes (maybe with a better name).",0,0.9930514097213745
284539787,6363,kkonstantine,2019-05-16T05:02:43Z,"dynamic dispatch is not very easy or elegant here, because the protocol classes are effectively static classes (have only static methods) and we can't hold on to a reference on their instance and use inheritance effectively. i've moved the creation of `joingrouprequestprotocolcollection` in the protocols though, and now the `switch` block (which i also dislike compared to dynamic dispatch) is small.",0,0.5323024988174438
284541423,6363,kkonstantine,2019-05-16T05:14:14Z,the above pr is merged. i removed this temp commit. thanks for reviewing!,1,0.9784061908721924
284542971,6363,kkonstantine,2019-05-16T05:25:34Z,"as mentioned in another thread, the classes are now named `extendedassignment` and `extendedworkerstate` respectively",0,0.995399534702301
284544064,6363,kkonstantine,2019-05-16T05:32:48Z,i have now added tests related to the new rebalancing protocol in this class too. (also the worker coordinator tests as well).,0,0.9944719076156616
284834540,6363,kkonstantine,2019-05-16T18:13:23Z,added: ` // we have at least one worker assignment (the leader itself) so totalworkersnum can't be 0`,0,0.9949455857276917
284834759,6363,kkonstantine,2019-05-16T18:13:54Z,same reason why we removed a warning about empty `memberconfigs` above,0,0.992364764213562
284835203,6363,kkonstantine,2019-05-16T18:15:00Z,this block now reads: [code block] we shouldn't mind these averages being 0. this means there's not much to revoke.,0,0.982260525226593
284843672,6363,kkonstantine,2019-05-16T18:36:05Z,added,0,0.8435775637626648
284845286,6363,kkonstantine,2019-05-16T18:39:52Z,this sorting should not matter in any decision. it does it to apply weighted round-robin internally. but the order in the list of assignments does not matter.,0,0.9858155250549316
284845721,6363,kkonstantine,2019-05-16T18:40:50Z,"i've added and improved debug logs. if during additional testing we consider that some info logs are warranted, we could return here.",0,0.9886616468429565
284846327,6363,kkonstantine,2019-05-16T18:42:15Z,add clarification.,0,0.9912983179092407
284846980,6363,kkonstantine,2019-05-16T18:43:45Z,i'll create a ticket for future refactoring to address this.,0,0.9931372404098511
284847996,6363,kkonstantine,2019-05-16T18:46:11Z,made `leaderstate` private. but `currentprotocolversion` is used by `workergroupmember`,0,0.995301365852356
284849064,6363,kkonstantine,2019-05-16T18:48:59Z,`null` value for the `bytebuffer` value of this map is not allowed. every member should have an assignment even if it's empty.,0,0.9932540059089661
284849278,6363,kkonstantine,2019-05-16T18:49:35Z,at this point i will clear this if needed in a subsequent cleanup/refactoring after more testing is applied.,0,0.9939110279083252
284849517,6363,kkonstantine,2019-05-16T18:50:12Z,this is also candidate for subsequent refactoring. will create a jira ticket.,0,0.9953672885894775
284849946,6363,kkonstantine,2019-05-16T18:51:18Z,"i'll leave the old method unchanged, but we can also consider enhancement during the refactoring described in other comments that will follow-up.",0,0.9927908182144165
284850119,6363,kkonstantine,2019-05-16T18:51:48Z,"also, leaving as-is since it's the old code. but will revisit",0,0.9931094646453857
284850476,6363,kkonstantine,2019-05-16T18:52:51Z,at this point i will avoid the risk of optimizations and will include this in the ticket that will revisit tuning of the new rebalancing code. thanks!,1,0.9688419103622437
284853764,6363,kkonstantine,2019-05-16T19:01:54Z,i'm disabling the assertion at the moment because it results in flaky runs on jenkins. will return to it in a separate pr. thanks!,1,0.9787901043891907
284876254,6363,ryannedolan,2019-05-16T20:06:57Z,"instead of biconsumer here, and relying on exceptions to pass validation errors back to the caller, maybe this should be `(k, v) -> error`?",0,0.9911271929740906
284879355,6363,ryannedolan,2019-05-16T20:15:45Z,"would be nice to roll up this re-throw into ensurevalid(), i.e. catch the exception and format a general error message there.",0,0.9867152571678162
284879788,6363,ryannedolan,2019-05-16T20:16:54Z,it's strange to rely on runtimeexceptions for validation like this. maybe narrow to configexceptions at least.,-1,0.9537681937217712
284882011,6363,kkonstantine,2019-05-16T20:22:55Z,i think the current pattern works. i'll resolve this comment.,0,0.8399438858032227
284882177,6363,ryannedolan,2019-05-16T20:23:22Z,:party_popper:,0,0.9779290556907654
284882599,6363,kkonstantine,2019-05-16T20:24:25Z,good points. let's revisit in a follow up cleanup/refactoring since this is not critical atm.,1,0.9526352882385254
284883108,6363,kkonstantine,2019-05-16T20:25:43Z,"again here the difficulty is part due to protocol classes being effectively static. since it's not critical for the initial version of the new rebalancing, let's revisit in a follow-up.",0,0.9881802797317505
284883316,6363,kkonstantine,2019-05-16T20:26:08Z,see comment above about protocol classes being effectively static.,0,0.9878089427947998
284884565,6363,kkonstantine,2019-05-16T20:29:30Z,made `protected` and added several tests in `incrementalcooperativeassignortest`,0,0.9944739937782288
284886129,6363,ryannedolan,2019-05-16T20:33:54Z,i think this is a lot of gymnastics to avoid writing a couple `if`s and `for`s.,-1,0.6089484095573425
284886324,6363,kkonstantine,2019-05-16T20:34:28Z,"since this doesn't influence the actual schemas of the protocols, i'd also suggest to punt to the next refactoring/cleanup of the protocol classes.",0,0.9878478050231934
284919786,6363,kkonstantine,2019-05-16T22:20:49Z,the current form maps exactly to `ensurevalid` in the validator interface. this addition here is minor. i'd suggest discussion any improvements on config defs in a separate pr/jira issue.,0,0.9935113787651062
284920523,6363,kkonstantine,2019-05-16T22:24:05Z,"again, this is added for convenience. it's not implementing the validation as other validators do in this class. what developers chooses to throw here, is their own responsibility, as when they implement the `validator` interface.",0,0.9871137142181396
284920787,6363,kkonstantine,2019-05-16T22:25:25Z,"not a bad idea. but at the moment, i'd suggest taking improvements on this code in a separate pr",1,0.656173050403595
284921328,6363,kkonstantine,2019-05-16T22:27:32Z,this is a two line lambda still and straightforward. still not in any critical path of this pr.,0,0.9870014190673828
284921479,6363,kkonstantine,2019-05-16T22:28:18Z,i've kept uniqueness requirement but have removed assertion around balancing atm.,0,0.9943948984146118
284952509,6363,kkonstantine,2019-05-17T01:34:30Z,10 successful consecutive runs of all the connect tests (including integration tests). [a link],0,0.986542820930481
284952789,6363,kkonstantine,2019-05-17T01:36:30Z,here just confirming that they've started to go to the next phase (which is to remove a worker). not an assertion of the connectors per se. but i agree we could tighten it in a subsequent iteration.,0,0.9919281005859375
220729441,5582,rajinisivaram,2018-09-26T21:27:38Z,i remember i had `supportsclientreauth` and `supportsserverreauth` in my commit. it may be worth checking if we can have a single `supportsreauth` method and have the caller track mode.,0,0.9921854138374329
220729477,5582,rajinisivaram,2018-09-26T21:27:44Z,confusing to have `supportsclientreauth` and `clientsupportsreauthentication`. perhaps `supportsreauth` instead of `supportsclientreauth` and `remotesupportsreauth` instead of `clientsupportsreauthentication` (or something along those lines)?,0,0.9242668747901917
220730428,5582,rajinisivaram,2018-09-26T21:31:36Z,"can't all this be done in the authenticator? we can move it to some shared class later if we need it in two places, but for now we just need this in `saslclientauthenticator`?",0,0.9938802719116211
220732429,5582,rajinisivaram,2018-09-26T21:39:59Z,i thought we weren't supporting re-authentication or connection termination for ssl. why do we need time?,0,0.9164761304855347
220732576,5582,rajinisivaram,2018-09-26T21:40:38Z,"as before with ssl, can we avoid tracking time unless it is actually used?",0,0.9918385148048401
220735918,5582,rajinisivaram,2018-09-26T21:54:37Z,we have to avoid invoking an extra `time.milliseconds()` for every request. actual time should get propagated from the caller.,0,0.9924740195274353
220736421,5582,rajinisivaram,2018-09-26T21:56:25Z,"`kafkachannel` is a network-layer class, not a security-related class, so this should perhaps say `authenticationsession` or something like that to make it more obvious.",0,0.9900797605514526
220736573,5582,rajinisivaram,2018-09-26T21:57:12Z,why do we need this?,0,0.9423887133598328
220740223,5582,rajinisivaram,2018-09-26T22:14:17Z,"seeing it here, the metric name doesn't look right. `v0` refers to saslauthenticaterequest version. perhaps `sasl-authentication` with tag `version=0` or something similar to our request metrics which has apikey and version would be better?",0,0.9727742671966553
220740427,5582,rajinisivaram,2018-09-26T22:15:20Z,why are we tracking time here?,0,0.9879042506217957
220741020,5582,rajinisivaram,2018-09-26T22:18:09Z,should this be `session_lifetime_ms`?,0,0.99405837059021
220741102,5582,rajinisivaram,2018-09-26T22:18:29Z,as before `sessionlifetimems`?,0,0.993990421295166
220742581,5582,rajinisivaram,2018-09-26T22:25:48Z,"do we need to track `interestedinwritingimmediatelyafterreauthentication`? aren't we starting reauthentication during write, so this would always be true?",0,0.9936273097991943
220745052,5582,rajinisivaram,2018-09-26T22:38:53Z,the comment is now incomplete. don't we still throttle in some cases?,0,0.985306978225708
220745279,5582,rajinisivaram,2018-09-26T22:40:03Z,this code looks totally out of place here.,-1,0.9166175723075867
220786458,5582,rondagostino,2018-09-27T03:49:07Z,":thumbs_up: i eliminated these two methods by adding `long clientsessionreauthenticationtimems()` and `long serversessionexpirationtimenanos()`. these new methods only ever return non-null on the client and server, respectively. `clientsessionreauthenticationtimems()` now contains the 85%-95% calculation that was in `kafkachannel` and you asked if it could be moved into the authenticator.",1,0.7789632678031921
220786477,5582,rondagostino,2018-09-27T03:49:21Z,:thumbs_up: i've renamed this to be `boolean connectedclientsupportsreauthentication()` which is clear and no longer is close to any other method names since i eliminated the other two that were close as described above.,1,0.812699019908905
220786498,5582,rondagostino,2018-09-27T03:49:30Z,:thumbs_up: i moved this into `saslclientauthenticator` -- the percentage calculation is now factored into the return value of `clientsessionreauthenticationtimems()`,0,0.7099493145942688
220786511,5582,rondagostino,2018-09-27T03:49:40Z,":thumbs_up: we don't need time. i added it in order to support the `long sessionbegintimems()` method i had added to `authenticator`, but now that the percentage calculation is moved into `saslclientauthenticator` we don't need the `sessionbegintimems()` method on `authenticator` anymore. this file is now untouched.",1,0.8967456221580505
220786528,5582,rondagostino,2018-09-27T03:49:47Z,":thumbs_up: agreed, same as above: i added it in order to support the `long sessionbegintimems()` method i had added to `authenticator`, but now that the percentage calculation is moved into `saslclientauthenticator` we don't need the `sessionbegintimems()` method on `authenticator` anymore. this file is now untouched.",1,0.9273360967636108
220786549,5582,rondagostino,2018-09-27T03:49:59Z,:thumbs_up: i moved the server-side-kill check from `kafkaapis` to `kafkarequesthandler` and now i pass in the nanos time that was already calculated.,1,0.794100821018219
220786564,5582,rondagostino,2018-09-27T03:50:08Z,:thumbs_up: it is now `boolean serverauthenticationsessionexpired(long nanos)`,1,0.8807738423347473
220786574,5582,rondagostino,2018-09-27T03:50:12Z,":thumbs_up: we don't need this. i added it in order to support the `long sessionbegintimems()` method i had added to `authenticator`, but now that the percentage calculation is moved into `saslclientauthenticator` we don't need the `sessionbegintimems()` method on `authenticator` anymore. this file is now untouched.",1,0.7981880903244019
220786590,5582,rondagostino,2018-09-27T03:50:19Z,":thumbs_up: we don't need this. i added it in order to support the `long sessionbegintimems()` method i had added to `authenticator`, but now that the percentage calculation is moved into `saslclientauthenticator` we don't need the `sessionbegintimems()` method on `authenticator` anymore. this file is now untouched.",1,0.7981880903244019
220786604,5582,rondagostino,2018-09-27T03:50:30Z,":thumbs_up: yes, it is always true -- i removed it.",0,0.5490302443504333
220786622,5582,rondagostino,2018-09-27T03:50:40Z,":thumbs_up: i moved it to `kafkarequesthandler` which also has the side-effect of making a nanosecond time value available for the comparison, which means we can eliminate the call to `time.milliseconds()` on every request that you had flagged as problematic.",1,0.5302368402481079
220789008,5582,rondagostino,2018-09-27T04:13:55Z,"i realized today that we also have to count the connections from older clients that do not send sasl_authenticate. so it might be good to not refer to ""version"" at all. maybe it is best to not refer to ""sasl"" either? how about `successful-authentication-no-reauth` as the metric name? then maybe we don't need a special tag? if we still do need a tag then maybe `reauthsupport=false` to avoid referring to ""version""?",0,0.9816205501556396
220789699,5582,rondagostino,2018-09-27T04:21:00Z,"not sure. i changed the names of the methods on `authenticator` so that we now have `serversessionexpirationtimenanos()` and `clientsessionreauthenticationtimems()`. this value is communicating the expiration time, and then the `saslclientauthenticator` applies the 85%-95% factor to get a re-authentication time. based on this, it probably shouldn't have ""reauth"" in the name since that implies the factor has been applied -- which it has not at this point. so i think yes, it should be session_lifetime_ms. do you agree? if so i will change -- just confirm or suggest otherwise.",0,0.95302414894104
220791745,5582,rondagostino,2018-09-27T04:41:24Z,:thumbs_up: i adjusted the javadoc. let me know if it is now more accurate.,1,0.9363740682601929
220917846,5582,rondagostino,2018-09-27T13:15:36Z,"oops, the file is not untouched -- just the sections related to ssl and plaintext are untouched.",-1,0.8111797571182251
220917981,5582,rondagostino,2018-09-27T13:15:59Z,"again, oops, the file is not untouched -- just the sections related to ssl and plaintext are untouched.",0,0.8190667629241943
220919003,5582,rondagostino,2018-09-27T13:19:09Z,"oops, the file is not untouched because it still needs to send in a `supplier ` rather than `authenticator` when it creates a `kafkachannel` -- but the reference to `time` is now gone.",0,0.9470882415771484
220919332,5582,rondagostino,2018-09-27T13:20:07Z,"again, oops, the file is not untouched because it still needs to send in a `supplier ` rather than `authenticator` when it creates a `kafkachannel` -- but the reference to `time` is now gone.",0,0.9347131848335266
221238033,5582,rondagostino,2018-09-28T12:37:26Z,:thumbs_up: changing to session_lifetime_ms,1,0.7398258447647095
221238079,5582,rondagostino,2018-09-28T12:37:35Z,:thumbs_up: changing to sessionlifetimems,1,0.8056530952453613
221241246,5582,rondagostino,2018-09-28T12:49:59Z,changing to `successful-authentication-no-reauth-total` without extra tags.,0,0.993498682975769
221574183,5582,rajinisivaram,2018-10-01T11:23:19Z,using a combination of nanos and millis in the reauthentication logic is very error-prone.,0,0.545011579990387
221575447,5582,rajinisivaram,2018-10-01T11:28:04Z,propagate time since we have tests that use mocktime.,0,0.9897243976593018
221576245,5582,rajinisivaram,2018-10-01T11:31:42Z,this is either a local client connection (on a client or inter-broker connection) or a remote client connection (on a broker).,0,0.9942294359207153
221576504,5582,rajinisivaram,2018-10-01T11:32:58Z,can we move this below the `final` fields?,0,0.9957139492034912
221580005,5582,rajinisivaram,2018-10-01T11:47:25Z,should this be under the `channel.successfulauthentications() == 1`? presumably a client can use v0 authenticate request and still reauthenticate.,0,0.9943227767944336
221580843,5582,rajinisivaram,2018-10-01T11:50:51Z,`responsesreceivedduringreauthentication.foreach`? also null check looks unnecessary since we guarantee it is never null?,0,0.9926421046257019
221581167,5582,rajinisivaram,2018-10-01T11:52:23Z,could just be part of the previous `if` statement?,0,0.9890956282615662
221581375,5582,rajinisivaram,2018-10-01T11:53:24Z,add `-ms` to the metric names?,0,0.9949446320533752
221581926,5582,rajinisivaram,2018-10-01T11:55:42Z,typo: `lifetime`,0,0.9954321384429932
221582659,5582,rajinisivaram,2018-10-01T11:58:42Z,need to either change the name of this constant or where it is defined. negotiated configs dont come from jaas.,0,0.9907407760620117
221583408,5582,rajinisivaram,2018-10-01T12:02:03Z,also set state to `send_handshake_request`,0,0.9959873557090759
221583541,5582,rajinisivaram,2018-10-01T12:02:42Z,this check is not needed if we set initial state during reauthentication to `send_handshake_request`,0,0.9954067468643188
221583677,5582,rajinisivaram,2018-10-01T12:03:17Z,"same as before, we dont need this if initial state is set for reauthentication,",0,0.9934606552124023
221584414,5582,rajinisivaram,2018-10-01T12:06:25Z,"this should only be done for re-authentication. otherwise it will end up with tight poll loop after authentication if there is nothing to be sent. in general, we need to make sure that we don't change any behaviour for the initial authentication.",0,0.989581823348999
221585462,5582,rajinisivaram,2018-10-01T12:10:56Z,"on the broker-side, i think we need a minimum re-authentication interval as well to restrict the rate at which clients re-authenticate. this is particularly important since we dont apply any quotas for authentication. without imposing a re-authentication rate limit, a client that enters a re-authentication loop (due to a bug or intentionally) would effectively stop the broker from doing anything useful.",0,0.9827877879142761
221587034,5582,rajinisivaram,2018-10-01T12:16:57Z,we have an exception that is going to result in the connection being closed. seems unnecessary to re-authenticate before closing connection.,0,0.9853909015655518
221587359,5582,rajinisivaram,2018-10-01T12:18:29Z,initiaize in the constructor similar to other fields?,0,0.9929846525192261
221588748,5582,rajinisivaram,2018-10-01T12:23:34Z,"can't we set buffers to a good state from `reauthenticate()` so that this method doesn't have to do anything special for re-authentication? we have received a handshake request, we just need to continue just as with authentication?",0,0.9930198788642883
221589195,5582,rajinisivaram,2018-10-01T12:25:18Z,nit: can we reduce the length of the method name?,0,0.9933221936225891
221591025,5582,rajinisivaram,2018-10-01T12:32:01Z,"in each of the tests, we could check metrics (expired-and-killed in some tests and re-authenticated where expected)",0,0.9938945174217224
221592475,5582,rajinisivaram,2018-10-01T12:37:22Z,this results in errors logged in the broker with stack trace. i don't think we want that.,0,0.7540940642356873
221824499,5582,rondagostino,2018-10-02T04:47:12Z,":thumbs_up: changed so that both use nanos. we need to use nanoseconds on the server side to avoid a call to time.milliseconds() on each request as per previous review comments, so i changed the client side to use nanos as well.",0,0.6128503084182739
221824522,5582,rondagostino,2018-10-02T04:47:24Z,"this class uses the time variable in multiple places already, so i simply replicated the same solution. if we wish to fix all of them then perhaps it can be resolved via a separate ticket as opposed to this kip?",0,0.9924901127815247
221824530,5582,rondagostino,2018-10-02T04:47:31Z,:thumbs_up: definitely; fixed.,1,0.9353153705596924
221824536,5582,rondagostino,2018-10-02T04:47:36Z,:thumbs_up: moved,1,0.8838840126991272
221824549,5582,rondagostino,2018-10-02T04:47:46Z,"we do not record latency for authentication, which is the case where `channel.successfulauthentications() == 1 ` -- the value `channel.reauthenticationlatencyms()` will be null in that case.",0,0.9946268200874329
221824558,5582,rondagostino,2018-10-02T04:47:54Z,"converted to `.foreach`, but we do have to check for null since that is the default (javadoc says null is possible, which it is)",0,0.9939005374908447
221824568,5582,rondagostino,2018-10-02T04:48:00Z,:thumbs_up: fixed,1,0.9491439461708069
221824578,5582,rondagostino,2018-10-02T04:48:06Z,"`request-latency-avg` and `request-latency-max` don't have it (neither do `commit-latency`, `poll-latency`, and `process-latency` metrics). assume this means it should remain as-is.",0,0.9920610189437866
221824588,5582,rondagostino,2018-10-02T04:48:11Z,:thumbs_up: fixed,1,0.9491439461708069
221824625,5582,rondagostino,2018-10-02T04:48:16Z,:thumbs_up: created `org.apache.kafka.common.security.authenticator.saslutils` to hold this constant.,1,0.5402737259864807
221824632,5582,rondagostino,2018-10-02T04:48:23Z,:thumbs_up: i created a `process_apiversions_response` state where we process the response we got -- either from the server in the auth case or from the previous authenticator in the re-auth case. this will be the initial state when re-authenticating. i think this makes it clear what is going on.,1,0.9154179096221924
221824639,5582,rondagostino,2018-10-02T04:48:29Z,:thumbs_up: removed,0,0.4982095956802368
221824664,5582,rondagostino,2018-10-02T04:48:45Z,":thumbs_up: agreed, no longer needed -- the initial state for client-side re-authentication is now `process_apiversions_response`.",1,0.6828085780143738
221824673,5582,rondagostino,2018-10-02T04:48:51Z,":thumbs_up: fixed. i think maybe the original code had kept track of whether we we needed to immediately write something or not, and perhaps it was handled there? can't remember, but regardless, it is fixed now -- we remove write interest as before when we are not in a ""re-authentication"" scenario.",1,0.9838482737541199
221824682,5582,rondagostino,2018-10-02T04:48:59Z,":thumbs_up: i defined a 1-second requirement that applies to the second and subsequent re-authentications. so the first re-authentication can happen immediately after authentication if desired, but the second re-authentication must then happen at least 1 second later (and so on), otherwise the sasl handshake is passed through without beginning the re-authentication process (and that would mean the connection is closed, which also results in the client experience the newly-implemented ddos delay). there are two reasons i set it for the second re-auth. one is is because `saslauthenticatortest` would end up running longer if we had to set the interval that much longer. the other is that we don't have a time value that we can use to set the start time until `kafkachannel.maybebeginserverreauthentication()` is invoked. i think this is reasonable -- is it okay with you?",0,0.8699123859405518
221824691,5582,rondagostino,2018-10-02T04:49:06Z,"actually, my understanding of this is that we received something that had been sent prior to the re-authentication process beginning -- it doesn't match what we were expecting back, so we didn't send it, so it must have come from before -- so we have to save it so it can be processed later. does that make sense? if so, then i think this code is correct.",0,0.9890806674957275
221824708,5582,rondagostino,2018-10-02T04:49:11Z,:thumbs_up: fixed,1,0.9491439461708069
221824720,5582,rondagostino,2018-10-02T04:49:20Z,":thumbs_up: good point. i split out the `processpayload()` method to address a cyclomatic complexity issue, and i did not see the simplification at that time. done.",1,0.9903085827827454
221824731,5582,rondagostino,2018-10-02T04:49:24Z,:thumbs_up: fixed,1,0.9491439461708069
221824759,5582,rondagostino,2018-10-02T04:49:41Z,:thumbs_up: removed,0,0.4982095956802368
221824978,5582,rondagostino,2018-10-02T04:52:09Z,"was unable to get this working, and it is almost 1am here at this point. will look again asap.",0,0.5986707210540771
221852361,5582,rondagostino,2018-10-02T07:50:04Z,"actually, i just got it working.",0,0.9819033145904541
221980284,5582,mk6i,2018-10-02T14:43:37Z,"i am confused by what this part of this sentence, can you elaborate? [code block]",-1,0.9526862502098083
221988637,5582,rondagostino,2018-10-02T15:02:55Z,here's the quote from the kip related to this: does that clarify it?,0,0.9939693212509155
222097603,5582,rajinisivaram,2018-10-02T20:20:08Z,`listener.name.sasl_ssl.oauthbearer.connection.max.expired.ms`?,0,0.9944238066673279
222103261,5582,rajinisivaram,2018-10-02T20:38:38Z,do you mean in a different class? because `channelbuilders` didn't have `time` before this pr.,0,0.9930764436721802
222104230,5582,rajinisivaram,2018-10-02T20:41:42Z,"nit: we initialize all other instance variables in the constructor, can we do the same here? i dont think we need the initialzations, especially nulls.",0,0.9914705157279968
222105405,5582,rajinisivaram,2018-10-02T20:45:20Z,"don't think we close the connection on processing saslhandshakerequest, we simply fail the request. do we want to close the connection for this case?",0,0.9909312725067139
222106188,5582,rajinisivaram,2018-10-02T20:48:04Z,`!ready()` here is an `illegalstateexception` since we never expect to here with with an not-ready channel?,0,0.9913544058799744
222106589,5582,rajinisivaram,2018-10-02T20:49:10Z,"since this is used only as the minimum reauthentication interval, can give it a name that indicates its usage?",0,0.9924420118331909
222108202,5582,rajinisivaram,2018-10-02T20:54:05Z,we could use the same name `reauthenticationlatencyms` for the method in authenticator as well? or use `reauthenticationelapsedtimems` in both cases?,0,0.9934244155883789
222111763,5582,rajinisivaram,2018-10-02T21:05:26Z,do we really need this method - test could just create one using hard-coded params?,0,0.9935342073440552
222115747,5582,rajinisivaram,2018-10-02T21:18:41Z,"now that we dont support java 7, we can use lambdas for these conditions (and the ones below).",0,0.9935885667800903
222116790,5582,rajinisivaram,2018-10-02T21:22:30Z,is this used?,0,0.9943179488182068
222117341,5582,rajinisivaram,2018-10-02T21:24:36Z,nit: `else if`?,0,0.9912612438201904
222118885,5582,rajinisivaram,2018-10-02T21:30:08Z,these two method use names that are not consistent with the config name.,0,0.974913477897644
222119990,5582,rajinisivaram,2018-10-02T21:34:35Z,"so many tests with these two calls, couldn't we just have additional parameters to `verifyauthenticationmetrics` that optionally verify reauthentication and no-reauth metrics?",0,0.9931530952453613
222121974,5582,rajinisivaram,2018-10-02T21:42:18Z,"as before, can we move initializations to the constructor and remove unnecessary null iniitializations?",0,0.9949637651443481
222122932,5582,rajinisivaram,2018-10-02T21:46:03Z,"yes, this code is fine.",0,0.9498263597488403
222123268,5582,rajinisivaram,2018-10-02T21:47:24Z,"same as before, null initializations unnecessary.",0,0.9871730804443359
222124202,5582,rajinisivaram,2018-10-02T21:51:04Z,can we create an inner class to store the re-authentication state? there are just too many of these relevant only for re-authentication.,0,0.9367072582244873
222125964,5582,rajinisivaram,2018-10-02T21:58:50Z,"why is this code here? `reauthenticate()` has the sasl request, so it can do this check specific to reauthentication.",0,0.992599368095398
222127047,5582,rajinisivaram,2018-10-02T22:03:34Z,we should be able to set up the state and call `authenticate` without separating out the methods.,0,0.9932490587234497
222144498,5582,harshach,2018-10-02T23:40:10Z,"is it going to be used for sasl only if so can you make it ""sasl.connection.max.reauth.ms""",0,0.9960166811943054
222161863,5582,rondagostino,2018-10-03T01:51:29Z,i think `listener.name.sasl_ssl.oauthbearer.connections.max.reauth.ms`?,0,0.9930126070976257
222164887,5582,rondagostino,2018-10-03T02:18:47Z,"oops, sorry, you are correct. fixed.",-1,0.9921650886535645
222358775,5582,rondagostino,2018-10-03T15:33:28Z,:thumbs_up:,1,0.9533231854438782
222359402,5582,rondagostino,2018-10-03T15:35:11Z,"ah, you are correct, we fail the request in kafkaapis and the connection is nor closed. doc adjusted accordingly here.",0,0.9888808727264404
222360598,5582,rondagostino,2018-10-03T15:38:22Z,:thumbs_up: `min_reauth_interval_one_second_nanos`,0,0.9474136829376221
222361705,5582,rondagostino,2018-10-03T15:41:08Z,:thumbs_up: renamed `authenticator` method to match this one: `reauthenticationlatencyms`,0,0.8310474753379822
222390337,5582,rondagostino,2018-10-03T17:04:46Z,:thumbs_up: we now throw `illegalstateexception` if that occurs,1,0.7115823030471802
222452923,5582,rondagostino,2018-10-03T20:18:01Z,:thumbs_up: removed it.,1,0.7560988068580627
222476244,5582,rondagostino,2018-10-03T21:37:07Z,:thumbs_up: added `` annotation to `testcondition` and implemented lambdas here. did not adjust any other uses of `testcondition` anywhere else unrelated to this pr.,1,0.9638002514839172
222477179,5582,rondagostino,2018-10-03T21:41:11Z,:thumbs_up: removed. this file is no longer affected by this pr.,0,0.5982668399810791
222477623,5582,rondagostino,2018-10-03T21:42:51Z,:thumbs_up: done,1,0.7493249177932739
222478232,5582,rondagostino,2018-10-03T21:45:26Z,:thumbs_up: fixed,1,0.9491439461708069
222478999,5582,rondagostino,2018-10-03T21:48:38Z,i believe there was a desire to keep our options open in this regard and not mention sasl explicitly -- thoughts?,0,0.978199303150177
222479519,5582,rondagostino,2018-10-03T21:50:49Z,:thumbs_up: done,1,0.7493249177932739
222480744,5582,rondagostino,2018-10-03T21:55:41Z,just want to confirm that this is acceptable.,0,0.9607653021812439
222486198,5582,rondagostino,2018-10-03T22:19:53Z,":thumbs_up: done. also shortened the max session reauth ms value from 500 ms to 100 ms, which shaved 20 seconds off of the test runtime (85 seconds dropped to 65 seconds locally). i'm interested to see if this exposes any errors when run on the build farm.",1,0.9286674857139587
222500340,5582,rondagostino,2018-10-03T23:39:47Z,:thumbs_up: fixed,1,0.9491439461708069
222501837,5582,rondagostino,2018-10-03T23:49:12Z,"the `reauthenticate()` method has the `networkreceive` instance. we don't parse that and extract the `saslhandshakerequest` that it contains until later in the flow, at this point in the code. is it okay to keep the changed mechanism check here, as-is?",0,0.9939576387405396
222509254,5582,rondagostino,2018-10-04T00:39:49Z,:thumbs_up: created a `private static class reauthinfo` that has three public final fields: eliminated the `private boolean reauthenticating;` field with `private reauthinfo reauthinfo;`,1,0.9161271452903748
222901371,5582,rondagostino,2018-10-05T06:19:47Z,:thumbs_up: i added a new `reauth_process_handshake` state and that is where re-authentication starts.,1,0.7620487213134766
223997295,5582,rajinisivaram,2018-10-10T09:16:02Z,"yes, since this config is used by the broker to force reauthentication using connection termination as well, there is no reason why we can't apply it for ssl as well in future. so it makes sense to keep it neutral.",0,0.9926440119743347
224002046,5582,rajinisivaram,2018-10-10T09:29:31Z,dont think we need the `mutestate` check on the server-side since we are processing a received packet when we invoke this.,0,0.9877188205718994
224005987,5582,rajinisivaram,2018-10-10T09:39:25Z,is there a reason why this is passing in `time.milliseconds` while the others don't? there is some scope to use a common time value in all of these records to avoid multiple calls to `time.milliseconds()`.,0,0.9927077889442444
224007360,5582,rajinisivaram,2018-10-10T09:42:49Z,could this just use `currenttimenanos`?,0,0.9920914173126221
224008571,5582,rajinisivaram,2018-10-10T09:46:24Z,"move this to the end of the class? we tend to have enum definitions at the start, but typically other inner classes at the end.",0,0.989972710609436
224009396,5582,rajinisivaram,2018-10-10T09:48:26Z,just return `pendingauthenticatedreceives` and remove the check for `null` in selector?,0,0.9957203269004822
224009880,5582,rajinisivaram,2018-10-10T09:49:51Z,update comment since reauth starts in the state above?,0,0.9948764443397522
224010118,5582,rajinisivaram,2018-10-10T09:50:36Z,include `reauth` in the state name?,0,0.9953343272209167
224010735,5582,rajinisivaram,2018-10-10T09:52:28Z,"isn't this the same as `initial`? from this state onwards, we could use common states? perhaps you have them separate to make it easy to fall through rather than loop back to the start of `authenticate()` when handshake response is received. if it is hard to keep a common state, it is fine to leave as-is.",0,0.9929313659667969
224012583,5582,rajinisivaram,2018-10-10T09:58:35Z,"couldn't we move all four of these (or some of these) into `reauthinfo`? we could create `reauthinfo` early on and populate reauthentication metadata into it. if we really need to separate out fields related to next reauth from the fields related to current reauth, perhaps we could have a separate class with these fields.",0,0.9929391145706177
224014312,5582,rajinisivaram,2018-10-10T10:04:18Z,move `math.min` to `saslauthenticateversion()` to avoid duplication?,0,0.9952985644340515
224017228,5582,rajinisivaram,2018-10-10T10:14:56Z,"this comment is odd because that is not quite what we would do. if we can't fall through, we would put `authenticate` in a loop to process the next state.",-1,0.6238247752189636
224017388,5582,rajinisivaram,2018-10-10T10:15:26Z,"if we need to keep `initial` and `reauth_initial`, we should have. a method to use common code for this state.",0,0.9924440979957581
224018091,5582,rajinisivaram,2018-10-10T10:17:43Z,"do we need this check at all? if it isn't, it is a bug in the implementation and we would see a classcastexception with the class names.",0,0.9914304614067078
224018434,5582,rajinisivaram,2018-10-10T10:18:55Z,"if we always stored `apiversionsresponsefromoriginalauthentication` in `reauthinfo`, we can avoid this check.",0,0.992642343044281
224021054,5582,rajinisivaram,2018-10-10T10:28:24Z,"looks like we are getting `time.milliseconds()` just for logging. log entries contain date and time anyway, so we could just log the intervals we actually use instead of computing new ones just for logging.",0,0.9888829588890076
224021468,5582,rajinisivaram,2018-10-10T10:30:00Z,nit: unnecessary `long.valueof`,0,0.6706310510635376
224023926,5582,rajinisivaram,2018-10-10T10:39:22Z,move this class to the end to be consistent with other classes?,0,0.9921765923500061
224024097,5582,rajinisivaram,2018-10-10T10:39:54Z,can we move these three fields into `reauthinfo`?,0,0.9957506656646729
224024425,5582,rajinisivaram,2018-10-10T10:41:11Z,"add checkstyle suppression instead for this file, rather than split the method with a checkstyle comment.",0,0.9938475489616394
224025199,5582,rajinisivaram,2018-10-10T10:44:19Z,"nit: this is not a `utils` class, more like `configs`?",0,0.9910257458686829
224026269,5582,rajinisivaram,2018-10-10T10:48:29Z,"nit: too many boolean params, making it hard to know what this is doing.",-1,0.673652708530426
224027337,5582,rajinisivaram,2018-10-10T10:52:17Z,why do we need this boolean?,0,0.991600513458252
224028035,5582,rajinisivaram,2018-10-10T10:55:07Z,i can't tell from the method name what the function returned is.,0,0.932091474533081
224028525,5582,rajinisivaram,2018-10-10T10:56:47Z,why?,0,0.9622438549995422
224029495,5582,rajinisivaram,2018-10-10T10:59:26Z,why is this in `testutils`?,0,0.9943293929100037
224031032,5582,rajinisivaram,2018-10-10T11:05:24Z,"we are doing at least two `time.nanoseconds` calls per channel, can we get the value at the start and use it in the three usages here.",0,0.99290931224823
224031497,5582,rajinisivaram,2018-10-10T11:07:25Z,"not sure this matches the actual implementation,",0,0.6765521168708801
224033627,5582,rajinisivaram,2018-10-10T11:16:04Z,"i think parameterization was useful at the start, but not sure we want to commit that. there are several tests where this parameter is not used at all, causing the same tests to be run twice. it feels like we should add some extra reauthentication tests and perhaps update some existing tests to also verify reauthentication. i think a new test which waits for multiple reauthentications while sending and receiving data continuously is sufficient (run with sasl_plaintext and sasl_ssl). it could run with a mechanism where reauthentication latency is higher and the test could run in a loop until latency > 0 to avoid timing errors in the test. all existing tests can stay as-is and use the existing `server.verifyauthenticationmetrics()` that just checks that there are no reauthentications. a new version of that with reauthentication count as arg could check for reauthentication metrics as well. what do you think?",0,0.926185667514801
224035834,5582,rajinisivaram,2018-10-10T11:24:51Z,do we need a boolean here? are there tests where it is guaranteed to be > 0?,0,0.9927846193313599
224041831,5582,rajinisivaram,2018-10-10T11:47:25Z,same as in saslclientauthenticator - unnecessary check since classcastexception gives all the information required in case there is a bug in the code.,0,0.9933158755302429
224042409,5582,rajinisivaram,2018-10-10T11:49:16Z,do we need this method?,0,0.9944741129875183
224042825,5582,rajinisivaram,2018-10-10T11:50:51Z,"why is this conditional, can't we always set it?",0,0.9836640357971191
224043656,5582,rajinisivaram,2018-10-10T11:53:15Z,need `ms` in the method name since it is returning millis.,0,0.9943931102752686
224044350,5582,rajinisivaram,2018-10-10T11:55:17Z,just `credentialexpirationms` is sufficient since this is not the server's credential?,0,0.9944114089012146
224045454,5582,rajinisivaram,2018-10-10T11:59:08Z,can we move this into `reauthinfo` (rename that class if required)?,0,0.9962032437324524
224045546,5582,rajinisivaram,2018-10-10T11:59:27Z,"same as above, move to `reauthinfo`?",0,0.9951584935188293
224045843,5582,rajinisivaram,2018-10-10T12:00:34Z,this can be in `reauthinfo` as well. and `reauthinfo` can have a method `authenticating()` or `reauthenticating()` to avoid all the checks for `null`. same for clientauthenticator as well.,0,0.9956279993057251
224162804,5582,rondagostino,2018-10-10T17:04:57Z,:thumbs_up: fixed,1,0.9491439461708069
224165591,5582,rondagostino,2018-10-10T17:13:46Z,:thumbs_up: now define `long readytimems = time.milliseconds()` at the top and use that time value for all metric `record()` calls.,1,0.941605806350708
224189017,5582,rondagostino,2018-10-10T18:20:58Z,"i don't think we can use `currenttimenanos` because it represents the time when `poll()` was invoked, and that could be as far back in time as the timeout value (i.e. a large timeout value could in theory result in `java.nio.channels.selector.select()` blocking for quite a while). if we use a time to far in the past it increases the chance of the reauth decision yielding `false` when in fact it should yield `true` -- and in that case we could end up with our connection being killed. what we can do is reuse the `channelstarttimenanos` if it is available (i.e. `channelstarttimenanos != 0 ? channelstarttimenanos : time.nanoseconds()`) since it is a very recent value. furthermore, we can delay actually getting the time as long as possible -- and therefore maybe we don't need to calculate it at all -- by making `kafkachannel` accept a `supplier ` rather than a `long`. i've made both of these changes.",0,0.9825943112373352
224209301,5582,rondagostino,2018-10-10T19:21:42Z,:thumbs_up: moved.,1,0.9540396332740784
224210770,5582,rondagostino,2018-10-10T19:26:35Z,:thumbs_up: return value is now always non-null.,0,0.5776451826095581
224211024,5582,rondagostino,2018-10-10T19:27:28Z,:thumbs_up: fixed,1,0.9491439461708069
224250048,5582,rondagostino,2018-10-10T21:35:37Z,:thumbs_up: now include `reauth_` prefix for all re-authentication states.,1,0.9050291180610657
224250994,5582,rondagostino,2018-10-10T21:39:12Z,"yeah, it is a fall-through issue. will keep code as-is given that the duplicated code is only two lines: [code block] however, in light of the comment below, i will refactor this out into a common method.",0,0.9863892197608948
224252644,5582,rondagostino,2018-10-10T21:45:34Z,:thumbs_up: created `private static class authinfoforreauth` to hold all of these in one place.,1,0.9112299680709839
224270430,5582,rondagostino,2018-10-10T23:11:04Z,":thumbs_up: done, we now send in the `apiversionsresponse` instance.",1,0.6659196019172668
224271563,5582,rondagostino,2018-10-10T23:17:28Z,:thumbs_up: fixed the comment -- it now states that we won't add the loop to minimize changes.,1,0.5997658371925354
224271904,5582,rondagostino,2018-10-10T23:19:29Z,:thumbs_up: added method `sendinitialtokenandsetintermediatestate()`,0,0.7122609615325928
224272371,5582,rondagostino,2018-10-10T23:22:31Z,:thumbs_up: removed.,0,0.58298259973526
224273014,5582,rondagostino,2018-10-10T23:26:45Z,`reauthinfo` will be null for the `saslclientauthenticator` instance associated with the initial authentication; that instance will have an instance of `authinfoforreauth` to hold the `apiversionsresponse` received from the broker. this check is therefore necessary under these conditions.,0,0.9944090247154236
224276026,5582,rondagostino,2018-10-10T23:46:27Z,:thumbs_up: done,1,0.7493249177932739
224276273,5582,rondagostino,2018-10-10T23:47:58Z,:thumbs_up: removed,0,0.4982095956802368
224436894,5582,rondagostino,2018-10-11T12:58:25Z,:thumbs_up: moved,1,0.8838840126991272
224439886,5582,rondagostino,2018-10-11T13:07:00Z,created `private static class authinfoforreauth`,0,0.9949584603309631
224442030,5582,rondagostino,2018-10-11T13:13:28Z,:thumbs_up: done,1,0.7493249177932739
224444370,5582,rondagostino,2018-10-11T13:19:45Z,"renamed it `saslinternalconfigs` (there is already a `org.apache.kafka.common.config.saslconfigs` class, and it is part of the public api, so it is not an appropriate place to put this internal constant).",0,0.9945350885391235
224506417,5582,rondagostino,2018-10-11T15:57:43Z,":thumbs_up: created `public enum metrictype` and the method `public void waitformetrics(string nameprefix, final double expectedvalue, set metrictypes)`. this method now looks like this: [code block]",1,0.9412473440170288
224508051,5582,rondagostino,2018-10-11T16:02:15Z,":thumbs_up: this is now removed, and the expected/actual values are now included as part of the assertion error message.",0,0.957852303981781
224509330,5582,rondagostino,2018-10-11T16:05:44Z,":thumbs_up: true that it is not really reusable; `nioechoserver` needs that functionality, so now it's a `private static boolean` method on that class rather than a `public static boolean` method on `testutils`.",0,0.8173685669898987
224514170,5582,rondagostino,2018-10-11T16:20:30Z,"the above change resulted in a disallowed import error, so i refactored out the following method and put it back into `testutils`. this is better than having the whole `maybebeginserverreauthentication()` method there. [code block]",0,0.987636923789978
224523568,5582,rondagostino,2018-10-11T16:49:37Z,"good question! there was a comment above that method that stated: [code block] i didn't think about it much; i just read that comment and figured that since i'm making a change to `saslauthenticaterequest` and `saslauthenticateresponse` and they don't contain a `hashmap` i could -- and should -- test for equality and hashcode. but now that you ask, and i do spend the time to think about it, it seems that testing equality and hashcode doesn't provide the value i thought it would (and that the comment seemed to imply that it would except for the annoying tendency of a hashmap to screw up the results)! all we would be testing for is to make sure the result of serializing a request to a `struct` can be deserialized back to a request and then serialized again to an equivalent `struct`. in other words, it doesn't actually test that the serialization code (i.e. `saslauthenticateresponse.tostruct()`) is working perfectly -- the equality and hashcode tests will still succeed even if that code serializes a field incorrectly because the same field will be serialized incorrectly both times (for example). note that incorrect serialization would presumably be caught indirectly via failure of other unit or integration tests. what maybe has to change here is the original comment. should i adjusted it?",1,0.9908083081245422
224526490,5582,rondagostino,2018-10-11T16:59:07Z,"ok, it's now just a single call to `time.nanoseconds()` under all circumstances except for when `sasl_handshake_request` is sent and either 1) re-authentication is not enabled; or 2) re-authentication is enabled but it occurred less than a second ago. in these two cases `time.nanoseconds()` will be invoked twice, but it probably doesn't matter since this is a rare occurrence and we are going to send an error back to the client if/when it happens.",0,0.9874677658081055
224600485,5582,rondagostino,2018-10-11T20:52:28Z,"fixed. there is now a processor-level metric `expired-connections-killed-count` that tracks the value on a per-(listener,processor) basis as well as an aggregated sum of these to provide a broker-wide metric. the aggregated sum metric is called `expiredconnectionskilledcount`. the `ops.html` doc is also updated to reflect this.",0,0.9812650084495544
224643320,5582,rondagostino,2018-10-12T00:36:27Z,:thumbs_up: removed,0,0.4982095956802368
224643550,5582,rondagostino,2018-10-12T00:38:09Z,no -- removed.,0,0.9770390391349792
224644898,5582,rondagostino,2018-10-12T00:49:37Z,:thumbs_up: changed.,1,0.7294001579284668
224645195,5582,rondagostino,2018-10-12T00:52:07Z,:thumbs_up: renamed,1,0.7649005651473999
224645547,5582,rondagostino,2018-10-12T00:54:51Z,:thumbs_up: moved,1,0.8838840126991272
224645875,5582,rondagostino,2018-10-12T00:57:22Z,:thumbs_up: moved,1,0.8838840126991272
224646884,5582,rondagostino,2018-10-12T01:06:23Z,:thumbs_up: i moved `authenticationorreauthenticationtext()` into `authinfoforreauth` and added a `private boolean reauthenticating()` method to `saslserverauthenticator`.,1,0.9325441718101501
224647371,5582,rondagostino,2018-10-12T01:11:20Z,did the same thing for `saslclientauthenticator`.,0,0.9946087598800659
224650731,5582,rondagostino,2018-10-12T01:42:13Z,"actually, after seeing some other review comments, i decided to do what you said: there is now a `reauthinfo` class only -- no additional `authinfoforreauth` class -- and we add the re-authentication data to it.",0,0.9931954145431519
224652056,5582,rondagostino,2018-10-12T01:53:43Z,now that i decided to get rid of the `authinfoforreauth` the code looks like this: [code block],0,0.9940001964569092
224652317,5582,rondagostino,2018-10-12T01:56:07Z,i decided to get rid of `authinfoforreauth` and keep everything in a single `reauthinfo` instance as you originally suggested.,0,0.9920042157173157
224888052,5582,rondagostino,2018-10-12T19:09:14Z,"the client sends multiple `sasl_authenticate` requests, and i was thinking the client is known to support the latest version if it sends at least one of them with the required version. i realize it is unlikely to send different versions each time, but technically if it sends the required version just once then we know it supports that version. so i was trying to take that (admittedly rare) possibility into account. another way to do it would be: [code block] i figured the way i did it was better than that since it avoids the write when the value is already true. i can always set it if you feel that is more appropriate -- just let me know, otherwise i'll leave it as-is.",0,0.9832795858383179
224890138,5582,rondagostino,2018-10-12T19:17:38Z,"sasl plain authenticates so quickly in the test case that the latency is 0, so if i check to make sure there is a non-zero latency in that case the test fails. i know you have a comment below about adjusting the unit tests to not be so wasteful. i may be able to get rid of this as i do that.",0,0.9489555954933167
224907777,5582,rondagostino,2018-10-12T20:34:55Z,"in the meantime, i added a comment describing the reasoning.",0,0.9953699707984924
225389120,5582,rondagostino,2018-10-16T03:52:30Z,"i eliminated this problem by always recording a latency of at least 1 ms when there is a non-zero latency to record. so now 100,000 nanoseconds of latency is recorded as 1 ms, for example.",0,0.9883739948272705
225389599,5582,rondagostino,2018-10-16T03:56:59Z,i just added a new `reauth_bad_mechanism` state on the `saslserverauthenticator` because a change in the mechanism wasn't being recorded as a failed re-authentication in the metrics. now it is being recorded correctly.,0,0.9928309917449951
225389740,5582,rondagostino,2018-10-16T03:58:28Z,resolved. i now record a latency of at least 1 ms when there is any non-zero latency.,0,0.96342933177948
225389970,5582,rondagostino,2018-10-16T04:00:32Z,"latest commit attempts to resolve this. all mechanisms include at least 1 re-authentication test. there is a multiple mechanism re-authentication test; there are tests for changing the principal, changing the mechanism, and re-authenticating too fast; and there is a test that continually sends data over the connection until the number of re-authentications is 5.",0,0.9931173324584961
227157687,5582,rajinisivaram,2018-10-22T22:16:49Z,do we need these two fields `clientsessionreauthenticationtimenanos` and `serversessionexpirationtimenanos`? couldn't we just use `authenticator.clientsessionreauthenticationtimenanos()` and `authenticator.serversessionexpirationtimenanos()`?,0,0.9939672946929932
227158301,5582,rajinisivaram,2018-10-22T22:19:31Z,reword exception message since channel is not ready on receiving first handshake?,0,0.9825291633605957
227159398,5582,rajinisivaram,2018-10-22T22:24:42Z,can we move this into `authenticator`?,0,0.9960002303123474
227159491,5582,rajinisivaram,2018-10-22T22:25:04Z,can we move this into `authenticator`?,0,0.9960002303123474
227160254,5582,rajinisivaram,2018-10-22T22:28:35Z,"there are so many methods in kafkachannel that simply call a method in `authenticator`. i wonder if it would be better to add an `authenticator()` method and let callers directly use `authenticator`, reducing the amount of code in `kafkachannel`.",0,0.963008463382721
227162913,5582,rajinisivaram,2018-10-22T22:40:48Z,not sure why this needs to be a suppiler of time rather than the value itself. the code would be more readable with just a value.,0,0.8503854870796204
227164081,5582,rajinisivaram,2018-10-22T22:46:25Z,"this no longer reflects the sequence of states, so it will be good to add javadoc for `saslstate` showing the two sequences for initial auth and reauth. i would probably move the reauth states to the end so that initial flows through to complete.",0,0.9944667220115662
227164773,5582,rajinisivaram,2018-10-22T22:49:51Z,leave `setsaslstate(saslstate.intermediate)` here similar to other cases?,0,0.9947280287742615
227165780,5582,rajinisivaram,2018-10-22T22:54:21Z,"as with client `saslstate`, since states don't flow through, we should have comment for `saslstate` showing the two sequences for initial auth and reauth. again, i would move reauth to the end so that `initial_request` flows through to `complete`.",0,0.9941779375076294
227166408,5582,rajinisivaram,2018-10-22T22:57:10Z,not sure we need this state. we can set state to failed and throw the appropriate exception.,0,0.8784656524658203
227168000,5582,rajinisivaram,2018-10-22T23:04:47Z,"looking at just this code, it looks like we record this for auth and reauth, even though it actually happens only once as expected. it would be more readable to move this code under the `if (channel.successfulauthentications() == 1)`.",0,0.99032062292099
227168301,5582,rajinisivaram,2018-10-22T23:06:23Z,why can't we just throw `saslauthenticationexception` here?,0,0.9892023205757141
227168794,5582,rajinisivaram,2018-10-22T23:09:04Z,not used?,0,0.992996871471405
227168816,5582,rajinisivaram,2018-10-22T23:09:12Z,not used?,0,0.992996871471405
227169229,5582,rajinisivaram,2018-10-22T23:11:14Z,"not sure whether these methods add any value since you could just use `enumset.of` instead of `metrictype.setof`? and actually looking at `waitformetrics`, it would be even better to use varargs.",0,0.95720374584198
227170791,5582,rajinisivaram,2018-10-22T23:19:42Z,we don't need a try-finally block when teardown does the cleanup.,0,0.9766631722450256
227170823,5582,rajinisivaram,2018-10-22T23:19:53Z,we don't need a try-finally block when teardown does the cleanup.,0,0.9766631722450256
227170844,5582,rajinisivaram,2018-10-22T23:20:00Z,we don't need a try-finally block when teardown does the cleanup.,0,0.9766631722450256
227170925,5582,rajinisivaram,2018-10-22T23:20:23Z,we don't need a try-finally block when teardown does the cleanup.,0,0.9766631722450256
227170945,5582,rajinisivaram,2018-10-22T23:20:30Z,we don't need a try-finally block when teardown does the cleanup. lots of these changes in this file are unnecessary (and the test is more readable without the try-finally.,0,0.9896294474601746
227393856,5582,rondagostino,2018-10-23T13:37:45Z,:thumbs_up: done,1,0.7493249177932739
227397762,5582,rondagostino,2018-10-23T13:46:33Z,"here's what i changed it to. not sure if this is what you were getting at. let me know if there is something else it should say. i also fixed the javadoc -- it was still referring to ""not muted"" when we got rid of that check based on a review comment. [code block]",0,0.9521268606185913
227401789,5582,rondagostino,2018-10-23T13:54:48Z,"i don't think so, no. for one, if we did, then `kafka.network.processor` would have to be able to get to the `authenticator` instance, and currently `kafkachannel` does not expose that publicly. the guts of this method also refers to state within `kafkachannel` as well (specifically, `lastreauthenticationstartnanos`), and while we could pass that in instead, fundamentally the `kafkachannel` instance also has to swap out its `authenticator` instances. so i think this method really has to belong in `kafkachannel`.",0,0.9709194302558899
227402058,5582,rondagostino,2018-10-23T13:55:19Z,"similar to above: i don't think so, no, for the same reasons.",0,0.9864019751548767
227408464,5582,rondagostino,2018-10-23T14:07:56Z,"not sure. my gut says the benefit would be minimal and the downside to exposing the `authenticator` (adding complexity to code that now simply asks the `kafkachannel` to do stuff) would outweigh any benefit, but regardless, if you decide it is something you would like to do maybe it can be addressed as a separate ticket?",0,0.7330231070518494
227409726,5582,rondagostino,2018-10-23T14:10:29Z,"there was a desire to not call `time.nanoseconds()` unnecessarily. we had a time value already, but it wasn't guaranteed to be current, so we have to get it again; making it a `supplier` meands we can delay getting it for as long as possible and avoid it completely if the logic is short-circuited first.",0,0.9904751181602478
227414037,5582,rondagostino,2018-10-23T14:18:22Z,:thumbs_up: javadoc added/declarations re-ordered,1,0.957694947719574
227418118,5582,rondagostino,2018-10-23T14:26:33Z,"lol. i changed this based on a previous review comment: `if we need to keep initial and reauth_initial, we should have. a method to use common code for this state.` . it didn't seem worthwhile to make a method with just `sendsaslclienttoken(new byte[0], true)` in it, so i put both that and `setsaslstate(saslstate.intermediate) ` in there and named it accordingly. i'm good whichever way you want to go -- just let me know if you decide it should be different than what it currently is (i.e. maybe put it back to the way it was?). will leave as-is otherwise.",1,0.9748639464378357
227421513,5582,rondagostino,2018-10-23T14:34:05Z,:thumbs_up: javadoc added/declarations re-ordered,1,0.957694947719574
227426184,5582,rondagostino,2018-10-23T14:43:53Z,:thumbs_up: moved,1,0.8838840126991272
227450301,5582,rondagostino,2018-10-23T15:37:53Z,see comment below.,0,0.9939999580383301
227451106,5582,rondagostino,2018-10-23T15:39:43Z,"i added this state because without it the attempt to change the mechanism isn't recorded as a failed re-authentication in the metrics. if we simply throw the exception then it is caught either by `nioechoserver.maybebeginserverreauthentication()` (in the case of a unit test) or by `kafka.network.processor.processcompletedreceives()` (in real-world use). in the unit test case the exception is simply ignored, and eventually the channel is closed while we are waiting in vain for the metric to update. in real-world use the channel would end up being closed -- but again no metric update occurs because the server-side `selector` never sees the channel as being ""`!channel.ready()`"" -- it needs to see this in order to call `channel.prepare()`, catch the `authenticationexception`, and record the failed re-authentication in the metric. i realize it is a bit odd to have to create this extra state, and we can avoid it if we are willing to not record the attempt as a failed re-authentication in the metrics, but i figured we would want to to record it.",0,0.990721583366394
227451806,5582,rondagostino,2018-10-23T15:41:21Z,:thumbs_up: removed,0,0.4982095956802368
227451895,5582,rondagostino,2018-10-23T15:41:36Z,:thumbs_up: removed,0,0.4982095956802368
227453157,5582,rondagostino,2018-10-23T15:44:39Z,":thumbs_up: agreed, eliminated all the methods and now invoke `enumset.of()` directly.",1,0.9283740520477295
227458546,5582,rondagostino,2018-10-23T15:57:23Z,"oops, didn't see that cleanup code. :thumbs_up: removed (everywhere)",1,0.9287993907928467
227458722,5582,rondagostino,2018-10-23T15:57:48Z,:thumbs_up: removed,0,0.4982095956802368
227458807,5582,rondagostino,2018-10-23T15:57:59Z,:thumbs_up: removed,0,0.4982095956802368
227458896,5582,rondagostino,2018-10-23T15:58:11Z,:thumbs_up: removed,0,0.4982095956802368
227458997,5582,rondagostino,2018-10-23T15:58:27Z,:thumbs_up: removed (everywhere),1,0.7755880951881409
227798966,5582,rajinisivaram,2018-10-24T13:56:03Z,"yes, let's leave it as is for now.",0,0.9796009659767151
227799411,5582,rajinisivaram,2018-10-24T13:57:04Z,does it really need to be that uptodate? couldn't we just use the time that we have?,0,0.9742298126220703
227800879,5582,rajinisivaram,2018-10-24T14:00:27Z,"looking at the rest of the code, i think it will be good to set the state here like in the rest of the code. perhaps: [code block]",0,0.9757106304168701
227801592,5582,rajinisivaram,2018-10-24T14:02:09Z,"thanks for the explanation. yes, we do want to record it, so let's keep the state.",1,0.9179341197013855
228162494,5582,rondagostino,2018-10-25T13:01:00Z,done,0,0.8682363629341125
228247041,5582,rondagostino,2018-10-25T16:32:54Z,"actually, i just realized that `currenttimenanos` does not represent the time when `poll()` was invoked -- it actually represents the moment after the `select()` returns. so we can use that value if necessary.",0,0.992326021194458
228248803,5582,rondagostino,2018-10-25T16:37:41Z,"yeah, we can. i mistakenly thought `currenttimenanos` represented the time when `poll()` was called, but it is actually the moment when the `select()` call returns, so it is relatively recent. so now i use the most recent value we have if there is one, otherwise we use `currenttimenanos`. i kept it as a `supplier<>` though -- for symmetry with `kafkachannel.maybebeginserverreauthentication()`. i can pass the long value in directly if you prefer, otherwise i think we're good here now.",0,0.8242281079292297
423906760,8657,chia7712,2020-05-12T17:25:21Z,"it collects the ""key"" used to complete delayed requests. the completion is execute out of group lock.",0,0.9953065514564514
423907638,8657,chia7712,2020-05-12T17:26:53Z,this is the main change of this pr (address [a link],0,0.9959422945976257
423908084,8657,chia7712,2020-05-12T17:27:34Z,new check for this pr. make sure it does not hold group lock,0,0.9947552680969238
423908468,8657,chia7712,2020-05-12T17:28:09Z,"this test case is for ""trylock"" so i just remove it.",0,0.9936140179634094
423913246,8657,chia7712,2020-05-12T17:35:42Z,"this is another case of deadlock. [code block] is in a **group lock** and it tries to complete other delayed joins which related to same **__consumer_offsets** partition. hence, this pr make it control the group lock manually in order to make sure it does not hold group lock when calling [code block]",0,0.99018794298172
426943627,8657,hachikuji,2020-05-18T23:19:57Z,"currently we have a somewhat convoluted model where `replicamanager` creates delayed operations, but we depend on lower level components like `partition` to be aware of them and complete them. this breaks encapsulation. not something we should try to complete in this pr, but as an eventual goal, i think we can consider trying to factor delayed operations out of `partition` so that they can be managed by `replicamanager` exclusively. if you assume that is the end state, then we could drop `completedelayedrequests` and let `replicamanager` _always_ be responsible for checking delayed operations after appending to the log. other than `replicamanager`, the only caller of this method is `groupmetadatamanager` which uses it during offset expiration. i think the only reason we do this is because we didn't want to waste purgatory space. i don't think that's a good enough reason to go outside the normal flow. it would be simpler to follow the same path. potentially we could make the callback an `option` so that we still have a way to avoid polluting the purgatory.",0,0.9211977124214172
426944679,8657,hachikuji,2020-05-18T23:23:37Z,"hmm.. does the group purgatory suffer from the same deadlock potential? if we call `checkandcomplete` for a group ""foo,"" i don't think we would attempt completion for any other group.",0,0.8634198307991028
426960637,8657,hachikuji,2020-05-19T00:20:05Z,"for reference, here are links to two alternative approaches that i considered earlier this year: - async completion: [a link] - lock-safe offset cache: [a link] i think jun was not satisfied with the first approach because it called for another thread pool. its advantage though was a simpler and more intuitive api than what we have here. an idea which i never implemented was to let the request handlers also handle delayed operation completion so that we did not need another thread pool. basically rather than calling the callback in `delayedproduce` directly, we add a new operation to the request queues. obviously this has its own tradeoffs. the second commit tries to use lock-free data structures so that we do not need the lock when completing the callback. this was only a partial solution which handled offset commit appends, but not group metadata appends. i am not sure how to handle join group completion asynchronously, so i gave up on this idea. only posting in case it's useful to see how some of these alternatives might have looked. i'm ok with the approach here, but i do wish we could come up with a simpler api. one thought i had is whether we could make the need for external completion more explicit. for example, maybe `appendrecords` could return some kind of object which encapsulates purgatory completion. [code block] just a thought.",0,0.9661200642585754
427095614,8657,chia7712,2020-05-19T07:45:43Z,thanks for reviews! we are on the same page :) (my previous comment [a link] this style lgtm :),1,0.997270405292511
427102729,8657,chia7712,2020-05-19T07:57:45Z,"you are right. it requires lock for group ""foo"" only. but the potential deadlock i tried to avoid/describe is that the caller has held a lock of group_a and then it tried to complete delayed request for group_b. it is possible to cause deadlock as it requires the lock of group_b to completing delayed request for group_b. that way the comment says the caller should not hold any group lock.",0,0.9841481447219849
427114083,8657,chia7712,2020-05-19T08:16:25Z,pardon me. i fail to catch your point.,-1,0.9373850226402283
427430032,8657,hachikuji,2020-05-19T16:19:03Z,"the join/heartbeat purgatories are a little different from the produce purgatory. the key is based on the groupid, so when we complete an operation for group ""foo,"" we won't complete for group ""bar"" incidentally. at least that is my understanding. if you look at `delayedoperationpurgatory.checkandcomplete`, we only complete watchers for the passed key.",0,0.9853813052177429
427432140,8657,hachikuji,2020-05-19T16:22:06Z,"sorry, let me be clearer: 1. mainly i'm suggesting moving the delayed operation checking into `replicamanager` instead of `partition`. 2. we can change the call to `appendrecordstoleader` in `groupmetadatamanager` to go through `replicamanager` as well. 3. we could make the callback optional in `replicamanager.appendrecords` so that we do not have to add a callback (which appears to be the only reason we write directly to `partition` from `groupmetadatamanager`). anyway, just a suggestion. i thought it might let us keep the completion logic encapsulated in `replicamanager`.",-1,0.932144820690155
427435780,8657,chia7712,2020-05-19T16:27:30Z,"you are totally right. my above comment is not clear. i added the comment to remind developers following code is dangerous. [code block] of course, the above code is nonexistent currently. i'm just worry that the deadlock is easy to produce in the future if we don't notice the lock issue.",-1,0.9430878758430481
427723802,8657,chia7712,2020-05-20T03:40:48Z,"in fact, there is a example of deadlock in join purgatories. [code block] called by [code block] is possible to call [code block] to append records to __consumer_offsets-{**partitionfor(group.groupid)**}. if there are groups related to same partition, [code block] which is holding a group lock will require locks for other groups.",0,0.9934386610984802
428949769,8657,junrao,2020-05-21T22:28:41Z,"perhaps reword like the following? returning a map of successfully appended topic partitions and a flag indicting whether the hwm has been incremented. if the caller passes in completedelayedrequests as false, the caller is expected to complete delayed requests for those returned partitions.",0,0.9947326183319092
428950361,8657,junrao,2020-05-21T22:30:37Z,"could we do `localproduceresults.filter{ case (tp, logappendresult) => ... }` to avoid unnamed references?",0,0.9945329427719116
428956078,8657,junrao,2020-05-21T22:48:37Z,could we add a comment for the return value?,0,0.9949612617492676
428958530,8657,junrao,2020-05-21T22:56:39Z,could we add a comment for the return value?,0,0.9949612617492676
428972538,8657,junrao,2020-05-21T23:47:16Z,"this is bit tricky to untangle. it seems the original code holds the group lock for both the `group.hasallmembersjoined` check and the call to forcecomplete(). so, we probably want to keep doing that. i am thinking that we could do the following. 1. change `groupcoordinator.oncompletejoin()` so that (1) it checks group.hasallmembersjoined inside the group lock and returns whether hasallmembersjoined is true. 2. in `delayedjoin.trycomplete() `, we do [code block] in oncomplete(), we do nothing.",0,0.9098871350288391
430253921,8657,chia7712,2020-05-26T08:47:57Z,"could you take a look? i'd like to address comment but it produces a big change to this pr. hence, it would be better to have more reviews/suggestions before kicking off.",0,0.9872881174087524
430748553,8657,junrao,2020-05-26T22:47:10Z,"i was trying to check if it's safe to do this. the intention for this is probably to avoid the deadlock between the group lock and the lock in delayedoperation. none of the caller of joinpurgatory.checkandcomplete holds a group lock now. the only other caller that can first hold a group lock and then the lock in delayedoperation is joinpurgatory.trycompleteelsewatch(). however, that's not an issue since that's when the delayedjoin operation is first added. so, this changes seems ok.",0,0.9197510480880737
430750020,8657,junrao,2020-05-26T22:51:20Z,"""as the lock is not free"" : do you mean ""when the lock is free""?",0,0.9924232959747314
430750723,8657,junrao,2020-05-26T22:53:22Z,a flag => a flag in replicamanager.appendrecords().,0,0.9924529194831848
430755656,8657,junrao,2020-05-26T23:08:08Z,could we add a comment to explain the return value?,0,0.9949502944946289
430756183,8657,junrao,2020-05-26T23:09:43Z,a map containing the topic partitions having new records and a flag indicating whether the hwm has been incremented.,0,0.9934379458427429
430757287,8657,junrao,2020-05-26T23:13:06Z,"i agree that it's simpler to let the caller in replicamanager to complete the delayed requests. this way, we don't need to pass completedelayedrequests in here.",0,0.9764962792396545
430761183,8657,junrao,2020-05-26T23:26:08Z,could we add a comment to explain the return value?,0,0.9949502944946289
431001869,8657,chia7712,2020-05-27T10:01:27Z,"it may produce deadlock if we hold the group lock for [code block]. [code block] is possible to append record to [code block] (see [a link] and hence it will try to complete other delayed joins which have groups belonging to same partition of [code block]. that is why i make [code block] control the group lock manually. for another, [code block] is used by [code block] only so it should be fine to change behavior of group lock in this case.",0,0.9889111518859863
431002494,8657,chia7712,2020-05-27T10:02:37Z,copy that.,0,0.9857287406921387
431003374,8657,chia7712,2020-05-27T10:04:13Z,"hmmm, i misunderstand your point. please ignore my first comment :)",-1,0.5956732034683228
431206147,8657,chia7712,2020-05-27T14:58:55Z,make sure [code block] does not cause deadlock,0,0.9902969002723694
431208549,8657,chia7712,2020-05-27T15:00:48Z,both methods are executed with lock,0,0.994838535785675
431209368,8657,chia7712,2020-05-27T15:01:31Z,this is a workaround to deal with deadlock caused by taking multiples group locks,0,0.9932872653007507
431210497,8657,chia7712,2020-05-27T15:02:28Z,this enum type is more readable than [code block],0,0.9944756627082825
439543737,8657,junrao,2020-06-12T17:12:08Z,it's cleaner to not pass in completedelayedrequests here and let the caller (`replicamanager.appendrecords()`) check and complete purgatory instead.,0,0.9795941114425659
439549136,8657,junrao,2020-06-12T17:23:34Z,"could we use `map {case (tp, appendresult) => ...}` here to avoid using unamed references?",0,0.9940481185913086
439872747,8657,junrao,2020-06-14T22:15:38Z,"another way that doesn't require checking lock.isheldbycurrentthread is the following. but your approach seems simpler. override forcecomplete() to [code block] in oncomplete(), do nothing. in trycomplete(), do [code block] in onexpiration(), [code block]",0,0.9933245778083801
439872846,8657,junrao,2020-06-14T22:16:58Z,expire -> oncomplete -> completedelayedrequests,0,0.9641541838645935
439873175,8657,junrao,2020-06-14T22:21:43Z,"delyaedoperation.lockopt defaults to none. so, we don't have to specify it explicitly.",0,0.9918076395988464
439873441,8657,junrao,2020-06-14T22:25:23Z,"""groupcoordinator#oncompletejoin() tries to complete delayed requests"" => since the completion of the delayed request for partitions returned from groupcoordinator#oncompletejoin() need to be done outside of the group lock.",0,0.9930776357650757
439875801,8657,junrao,2020-06-14T22:54:00Z,typo whihc,0,0.9894810914993286
439875892,8657,junrao,2020-06-14T22:55:07Z,the caller no longer passed in completedelayedrequests.,0,0.9927092790603638
439876215,8657,junrao,2020-06-14T22:59:03Z,all callers pass in completedelayedrequests as false. could we remove this param?,0,0.9955930113792419
439876392,8657,junrao,2020-06-14T23:01:18Z,there was => there were,0,0.9919862747192383
439876493,8657,junrao,2020-06-14T23:02:54Z,"replicamanager.appendrecords()., => replicamanager.appendrecords(),",0,0.9888912439346313
439876557,8657,junrao,2020-06-14T23:04:08Z,may requires => may require,0,0.9913827776908875
439878341,8657,junrao,2020-06-14T23:27:03Z,"hmm, why do we need this logic now?",0,0.9367671012878418
439878736,8657,junrao,2020-06-14T23:31:46Z,"hmm, why do we need to mock this since replicamanager.getmagic() is only called through replicamanager.handlewritetxnmarkersrequest()?",0,0.9601806998252869
439878969,8657,junrao,2020-06-14T23:34:51Z,"hmm, this should only be called with leaderhwchange.leaderhwincremented, but the mock later returns leaderhwchange.none? ditto below.",0,0.9866145253181458
439914680,8657,chia7712,2020-06-15T03:35:28Z,testreplicamanager#appendrecords ([a link] always complete the delayedproduce immediately so the txn offset is append also. this pr tries to complete the delayedproduce after releasing the group lock so it is possible to cause following execution order. 1. txn prepare 1. txn completion (fail) 1. txn append (this is executed by delayedproduce),0,0.9936529397964478
439915438,8657,chia7712,2020-06-15T03:39:51Z,the caller of [code block] may hold the group lock so it could produce deadlock if [code block] tries to complete purgatory.,0,0.9825319051742554
439920019,8657,chia7712,2020-06-15T04:03:59Z,[code block] ([a link] also call [code block]. there are delayed ops are completed by [code block] so we have to mock the [code block]. the mock is same to [a link],0,0.9929825067520142
439923720,8657,chia7712,2020-06-15T04:23:45Z,read [a link] again. it is a nice idea to refactor [code block] and [code block] to simplify the behavior of checking delayed operations. could i address the refactor in another pr to avoid bigger patch?,1,0.9450042247772217
440514740,8657,junrao,2020-06-16T00:14:56Z,"thanks. i am still not sure that i fully understand this. it seems that by not completing the delayedproduce within the group lock, we are hitting illegalstateexception. that seems a bug. do you know which code depends on that? it seems that we do hold a group lock when updating the txnoffset. [a link]",1,0.8980188965797424
440515043,8657,junrao,2020-06-16T00:15:55Z,"yes, we can refactor that in a separate pr. could you file a followup jira for that?",0,0.9949532151222229
440576071,8657,chia7712,2020-06-16T04:15:13Z,"the root cause (changed by this pr) is that the ""txn initialization"" and ""txn append"" are not executed within same lock. **the test story is shown below.** [code block] calls [code block] to add [code block] to [code block] (this is the link you attached). [code block] called by [code block] throws [code block] if [code block] is [code block] ([a link] **why it does not cause error before?** [code block] is updated by the callback [code block] ([a link] [code block] always create [code block] do handle the [code block] ([a link] the condition to complete the [code block] is [code block]. and the condition gets true when call both [code block] and [code block] since the former calls [code block] two times and another calls [code block] once. it means [code block] is always executed by [code block] and noted that [code block] is executed within a group lock ([a link] . in short, txn initialization ([a link] and txn append ([a link] are executed with same group lock. hence, the following execution order is impossible. 1. txn initialization 1. txn completion 1. txn append however, this pr disable to complete delayed requests within group lock held by caller. the [code block] which used to append txn needs to require group lock again.",0,0.9912358522415161
440585314,8657,chia7712,2020-06-16T04:53:54Z,nice caching. most methods don't need this flag. let me revert them :),1,0.9961052536964417
441175806,8657,junrao,2020-06-16T22:23:40Z,typo rebalacne,0,0.9865582585334778
441177055,8657,junrao,2020-06-16T22:27:14Z,the delayed requests may be completed as much as possible => the delayed requests may be completed inside the call with the expectation that no conflicting locks are held by the caller,0,0.9940218329429626
441177351,8657,junrao,2020-06-16T22:28:07Z,callers can complete the delayed requests manually => callers can complete the delayed requests after releasing any conflicting lock.,0,0.9944684505462646
441178418,8657,junrao,2020-06-16T22:31:00Z,"""if the caller no longer passed in completedelayedrequests"" the caller still passes this in, just as false.",0,0.9921398758888245
441180667,8657,junrao,2020-06-16T22:37:19Z,""" if the caller no longer passed in completedelayedrequests"" => there is no completedelayedrequests passed in.",0,0.9942995309829712
441182450,8657,junrao,2020-06-16T22:42:33Z,to to => to,0,0.9821929931640625
441186463,8657,junrao,2020-06-16T22:54:36Z,"thanks for the great explanation. i understand the issue now. essentially, this exposed a limitation of the existing test. the existing test happens to work because the producer callbacks are always completed in the same replicamanager.appendrecords() call under the group lock. however, this is not necessarily the general case. your fix works, but may hide other real problems. i was thinking that another way to fix this is to change the test a bit. for example, we expect completetxnoperation to happen after committxnoffsetsoperation. so, instead of letting them run in parallel, we can change the test to make sure that completetxnoperation only runs after committxnoffsetsoperation completes successfully. joingroupoperation and syncgroupoperation might need a similar consideration.",1,0.9939051270484924
441289689,8657,chia7712,2020-06-17T05:32:25Z,will roger that ! i didn't notice something interesting. could you share it with me?,-1,0.972442626953125
441846005,8657,junrao,2020-06-17T21:31:23Z,if there is no completedelayedrequests passed in => if completedelayedrequests is false,0,0.993224024772644
441846819,8657,junrao,2020-06-17T21:33:16Z,if there is no completedelayedrequests passed in => if completedelayedrequests is false,0,0.993224024772644
441859110,8657,junrao,2020-06-17T22:02:38Z,i think the intention for the test is probably to use the same producerid since it tests more on transactional conflicts.,0,0.9822300672531128
441859824,8657,junrao,2020-06-17T22:04:30Z,"hmm, why don't we need the lock here since committxnoffsetsoperation and completetxnoperation could still run in parallel?",0,0.9777716398239136
441862013,8657,junrao,2020-06-17T22:10:14Z,"perhaps change the comment to sth like the following? ""setting to true to make completetxnoperation and committxnoffsetsoperation complete atomically since they don't typically overlap. otherwise completetxnoperation may see a pending offsetandmetadata without an appendedbatchoffset.""",0,0.9938995838165283
441938174,8657,chia7712,2020-06-18T02:48:30Z,"got it. however, the same producerid means the group completed by completetxnoperation is possible to be impacted by any committxnoffsetsoperation (since the partitions are same also). hence, the side-effect is that we need a single lock to control the happen-before of txn completion and commit so the test will get slower.",0,0.9745112061500549
441938393,8657,chia7712,2020-06-18T02:49:28Z,you are right,1,0.7928295731544495
442330606,8657,junrao,2020-06-18T15:53:30Z,"since creategroupmembers() is called in multiple tests, it seems we will be accumulating allgroupmembers across tests. that seems unexpected?",0,0.9854356646537781
442337184,8657,chia7712,2020-06-18T16:03:15Z,"junit, by default, creates a new instance for each test case so [code block] is always new one for each test case.",0,0.9918783903121948
452634516,8657,ijuma,2020-07-10T05:48:24Z,it's weird to have a method that invokes a callback and returns a result. do we need both? we have a number of other methods that do something similar. it would be good to reconsider that as it's difficult to reason about usage in such cases.,-1,0.9710134863853455
452635111,8657,ijuma,2020-07-10T05:50:38Z,"the usual naming convention is to only capitalize the first letter, eg leaderhwchange.",0,0.9929191470146179
452754165,8657,chia7712,2020-07-10T10:12:49Z,"thanks for your reviews. you are totally right and had given a great refactor idea ([a link] given that refactor will bring a lot of changes to this pr, i had filed a ticket to refactor related code (see [a link] in order to make this pr focus on bug fix.",1,0.9955289959907532
452755236,8657,chia7712,2020-07-10T10:15:19Z,will roger that!,0,0.7773526310920715
463043040,8657,ijuma,2020-07-30T14:35:33Z,"i notice that we are including the `$` here and in a few other places, we should not do that.",0,0.9843764305114746
463044371,8657,ijuma,2020-07-30T14:37:19Z,i raised the point before that it's a bit unusual and unintuitive to have both a callback and a return value. any thoughts on this?,0,0.9133090972900391
463066191,8657,chia7712,2020-07-30T15:07:03Z,"the response was [a link] in short, we should have a way of fetching delayed request from partition instead of using return value to carry them.",0,0.9931663870811462
463066323,8657,chia7712,2020-07-30T15:07:14Z,will copy that!,1,0.869627058506012
463318346,8657,ijuma,2020-07-30T23:03:17Z,"thanks, i had missed that. will respond in that thread.",1,0.94057697057724
464562972,8657,junrao,2020-08-03T17:39:30Z,"could we change the explanation to sth like the following? this method may trigger the completeness check for delayed requests in a few purgatories. occasionally, for serialization in the log, a caller may need to hold a lock while calling this method. to avoid deadlock, if the caller holds a conflicting lock while calling this method, the caller is expected to set completedelayedrequests to false to avoid checking the delayed operations during this call. the caller will then explicitly complete those delayed operations based on the return value, without holding the conflicting lock.",0,0.9937431216239929
464567219,8657,junrao,2020-08-03T17:45:18Z,group lock => conflicting lock,0,0.9738359451293945
464567267,8657,junrao,2020-08-03T17:45:24Z,group lock => conflicting lock,0,0.9738359451293945
464574837,8657,junrao,2020-08-03T18:00:13Z,"perhaps add ""but completes the delayed requests without holding the group lock"".",0,0.9878952503204346
464580388,8657,junrao,2020-08-03T18:11:18Z,a lot of group lock => multiple group locks,0,0.9842879772186279
464580891,8657,junrao,2020-08-03T18:12:15Z,"""this method may hold a lot of group lock"" : this is actually not true. unlike producer/fetch purgatory, which is keyed on partition, joinpurgatory is keyed on the group. so, when we complete a key, only a single group's lock will be held. the reason that we don't want the caller to hold a group lock is that delayedjoin itself uses a lock other than the group lock for delayedoperation.maybetrycomplete() and we want to avoid the deadlock between that lock and the group lock.",0,0.9864258766174316
464697840,8657,junrao,2020-08-03T22:36:59Z,this could be `completedelayedjoinrequests(groupstocomplete)` ?,0,0.9952811598777771
464715376,8657,junrao,2020-08-03T23:33:17Z,perhaps we could add a comment on what this method is intended to test?,0,0.9930771589279175
464791414,8657,chia7712,2020-08-04T04:25:52Z,thanks for explanation. i will revise the comment according to your comment.,1,0.8786161541938782
465179335,8657,junrao,2020-08-04T16:31:50Z,"hmm, it seems that we are now introducing a new potential deadlock. the conflicting paths are the following. path 1 hold group lock -> joinpurgatory.trycompleteelsewatch(delayedjoin) -> watchforoperation (now delayedjoin visible through other threads) -> operation.maybetrycomplete() -> hold delayedjoin.lock path 2 delayedjoin.maybetrycomplete -> hold hold delayedjoin.lock -> trycomplete() -> hold group lock",0,0.9454247355461121
465200508,8657,chia7712,2020-08-04T17:07:08Z,how about removing inner lock ([code block]) from [code block] ? it seems to me [code block] does not need the inner lock.,0,0.9931198358535767
465206257,8657,chia7712,2020-08-04T17:17:09Z,"another approach is that - we introduce an new method ""aftertrycomplete"" to [code block]. the new method is invoked by [code block] after lock is released. [code block] still pass group lock to [code block] and use ""aftertrycomplete"" to complete delayed requests",0,0.9925957322120667
465867406,8657,junrao,2020-08-05T16:53:02Z,": yes, that's a possibility. it adds some complexity to delayedoperation. another possibility is to have a special case to complete the delayed requests from groupmanager.storegroup() in groupcoordinator.oncompletejoin() in a separate thread.",0,0.989942193031311
478599979,8657,junrao,2020-08-27T18:01:35Z,unneeded new line.,0,0.9814884662628174
478600507,8657,junrao,2020-08-27T18:02:36Z,we probably want to add a comment why this is needed.,0,0.9929749965667725
478603243,8657,junrao,2020-08-27T18:07:40Z,"hmm, why do we need to override this instead of using the one defined in delayedjoin?",0,0.9777271747589111
478603776,8657,junrao,2020-08-27T18:08:37Z,this probably should be included in the local time as before.,0,0.9896606206893921
478604292,8657,junrao,2020-08-27T18:09:33Z,could we add the new param to the javadoc?,0,0.9951393604278564
479379705,8657,junrao,2020-08-28T15:31:08Z,this can just be private.,0,0.989541232585907
479381963,8657,junrao,2020-08-28T15:34:58Z,kafkaapis.handle() => kafkaapis.handle() and the expiration thread for certain delayed operations (e.g. delayedjoin),0,0.9943798184394836
479382167,8657,junrao,2020-08-28T15:35:19Z,the above comment is outdated now.,0,0.9750918745994568
479382962,8657,junrao,2020-08-28T15:36:41Z,we probably should rename this to sth like safetrycomplete().,0,0.9892188906669617
479383807,8657,junrao,2020-08-28T15:38:11Z,the default value is none.,0,0.990405261516571
479389617,8657,junrao,2020-08-28T15:49:04Z,at the end of kafkaapis.handle() => at the end of kafkaapis.handle() and the expiration thread for certain delayed operations (e.g. delayedjoin),0,0.9945888519287109
479390056,8657,junrao,2020-08-28T15:49:47Z,in a queue => are stored in a queue,0,0.99212646484375
479467548,8657,junrao,2020-08-28T18:24:30Z,the last sentence doesn't complete.,0,0.9172451496124268
479474904,8657,ijuma,2020-08-28T18:41:05Z,can we not use a `boolean` here? `false` until it's been incremented and then `true`. is there value in having the third state?,0,0.9929129481315613
479475681,8657,ijuma,2020-08-28T18:42:47Z,should we be guarding against exceptions here?,0,0.9826288223266602
479661386,8657,junrao,2020-08-29T15:40:22Z,a action => an action,0,0.9935315251350403
479669354,8657,junrao,2020-08-29T17:05:19Z,"even if we hit an exception in handlexxx(), it would still be useful to complete the actionqueue.",0,0.9907678961753845
479670056,8657,junrao,2020-08-29T17:13:30Z,"it seems that we have to distinguish 3 states here: (1) records not appended due to an error; (2) records appended successfully and hwm advanced; (3) records appended successfully and hwm not advanced. in case (1), no purgatory needs to be checked.",0,0.9896469712257385
479670351,8657,junrao,2020-08-29T17:16:24Z,is this used?,0,0.9943179488182068
479670727,8657,junrao,2020-08-29T17:20:46Z,perhaps we could add a note at the top of delayedoperation so that people are aware of the need to complete actions for new delayedoperations in the future.,0,0.9810152053833008
479677889,8657,chia7712,2020-08-29T18:40:53Z,completing delayed actions may cause exception. should exception be swallowed and log if we move the completion to the final block?,0,0.992599606513977
479678653,8657,chia7712,2020-08-29T18:50:10Z,you are right. i miss the exception in [code block]. let me revert this change,0,0.9706274271011353
479678761,8657,ijuma,2020-08-29T18:51:18Z,what's the reasoning for taking just 1 item ? could this cause the queue to grow over time?,0,0.9892820119857788
479678812,8657,ijuma,2020-08-29T18:52:04Z,another approach would be for this queue to be per request thread instead of per server. that would simplify concurrency handling.,0,0.9912509918212891
479679930,8657,chia7712,2020-08-29T19:05:13Z,"it is dangerous to complete delayed actions by [code block] as most methods of [code block] are executed with locking. we, now, depend on [code block] to complete the delayed action produced by someone who can't complete delayed action due to locking. for example, [code block] can produce an new action and the new action can't be completed by [code block] itself due to group locking.",0,0.8054511547088623
479680637,8657,chia7712,2020-08-29T19:13:19Z,the thread has to pass queue to method of replicmanager/groupcoordinator if queue is kept by thread. a lot of methods are included so that is a big patch. i prefer to keep small patch though it gets bigger now :(,-1,0.9953924417495728
479682849,8657,junrao,2020-08-29T19:37:54Z,good question. it's based on the assumption that each kafkaapis.handle() call only calls replicamanager. appendrecords() once. not sure if this is always true in the future. perhaps a safer approach is to have action.trycompleteaction() get the current size of the queue and complete all those actions.,0,0.586988091468811
479683036,8657,chia7712,2020-08-29T19:40:00Z,it should be fine to let handler complete actions as much as possible since the response is created before handling delayed actions.,0,0.9920247793197632
479683212,8657,junrao,2020-08-29T19:42:24Z,"yes, if actionqueue.trycompleteaction() throws an exception, we can just catch it and log a warning in finally since the response has been sent by then.",0,0.9925327897071838
479683544,8657,junrao,2020-08-29T19:45:56Z,"i was thinking to add a comment so that if someone adds a future delayed operation that calls replicamanager.appendrecords() in oncomplete() like delayedjoin, he/she is aware that this operation's onexpiration() needs to call actionqueue.trycompleteaction().",0,0.9862415790557861
479684163,8657,junrao,2020-08-29T19:53:51Z,"perhaps we can make this a bit clearer. sth like the following. leaderhwincremented has 3 possible values: (1) if records are not appended due to an error, the value will be none; (2) if records are appended successfully and hwm is advanced, the value is some(true); (3) if records are appended successfully and hwm is not advanced, the value is some(false).",0,0.9840065836906433
479684353,8657,junrao,2020-08-29T19:55:43Z,"note that the action queue is not only called by requests threads, but also by the expiration thread for certain delayed operations.",0,0.9924750924110413
479686292,8657,ijuma,2020-08-29T20:17:33Z,good point .,1,0.9161118268966675
479686398,8657,ijuma,2020-08-29T20:19:12Z,i suggest using a sealed trait with 3 case objects to make this clearer. using `option[boolean]` as a tristate value is generally best avoided.,0,0.9911702871322632
479686517,8657,chia7712,2020-08-29T20:20:30Z,will copy that,0,0.9942620992660522
479689381,8657,chia7712,2020-08-29T20:55:45Z,please take a look at this method,0,0.9910747408866882
479689457,8657,ijuma,2020-08-29T20:56:53Z,"main thing to decide is what to do in case of exception, do we stop processing or do we continue?",0,0.9785731434822083
479689653,8657,ijuma,2020-08-29T20:59:38Z,why are we using a blocking queue? it doesn't seem like we ever need the blocking functionality. am i missing something?,0,0.6923372149467468
479689694,8657,chia7712,2020-08-29T20:59:55Z,i prefer to just catch it and log a warning as the response has been processed. wdyt?,0,0.9865258932113647
479689838,8657,chia7712,2020-08-29T21:01:42Z,you are right. how about using [code block] instead?,0,0.9848204255104065
479691180,8657,ijuma,2020-08-29T21:20:30Z,"yes, i think that's better. one thing i was wondering about is whether contention is going to be an issue for this `actionqueue`. multiple threads are adding items to it and then trying to consume from it. i haven't thought about all the details, but would a thread local work better? in that case, each thread would add and then drain. this works fine for the request threads, but i wasn't sure about the other case that pointed out.",0,0.6972296833992004
479692892,8657,chia7712,2020-08-29T21:44:06Z,handler (thread) can have local actionqueue and it is passed to each method to collect delayed actions. [code block] is specific case since the delayed actions are possible to be access by two thread (timeout thread and handler thread). a simple way to address thread local is that [code block] owns an actionqueue and the queue is passed to [code block] and then the queue is consumed by [code block]. both [code block] and [code block] are thread-safe so use a thread local queue is safe.,0,0.99213045835495
479706182,8657,junrao,2020-08-30T00:59:37Z,"if we are unlucky, a single thread could be held up in this loop for a long time. perhaps we could let each thread only complete the number of actions that it sees when entering trycompleteactions().",0,0.9578071236610413
479706303,8657,junrao,2020-08-30T01:01:16Z,"perhaps we could do the try/catch of each action here instead of kafkaapis. this way, we are guaranteed that all pending actions are processed in time.",0,0.9817797541618347
479706407,8657,junrao,2020-08-30T01:02:56Z,"since we are draining more than 1 item now, this comment is no longer accurate.",0,0.9877259135246277
479716882,8657,ijuma,2020-08-30T03:41:47Z,maybe we can go with a single `actionqueue` in this pr. we can submit a separate pr for reducing the contention by having one per thread.,0,0.9861840605735779
479737358,8657,chia7712,2020-08-30T08:05:15Z,"sure. i will file a pr to follow the pattern in #9229 in order to simplify code base, i will revert the action queue in ""per server"" :)",1,0.976796567440033
479802860,8657,junrao,2020-08-30T18:47:31Z,need => needs,0,0.9846673011779785
479802912,8657,junrao,2020-08-30T18:48:05Z,is failed => failed,0,0.9560673832893372
479803168,8657,junrao,2020-08-30T18:50:50Z,probably increased is clearer than incremental.,0,0.9808076024055481
479829275,8657,ijuma,2020-08-30T23:26:35Z,another nit: `leaderhwchange` adheres to the coding convention better.,0,0.7006585001945496
482743072,8657,chia7712,2020-09-03T06:50:50Z,"this change avoids deadlock in [code block]. if we update [code block] before [code block], the other threads can take the same key to complete delayed request. hence the deadlock happens due to following conditions. **thread_1** holds [code block] of transactionstatemanager to call [code block] and it requires lock of delayed request to call [code block]. **thread_2** holds lock of delayed request to call [code block] (updatecachecallback) and [code block] requires [code block] of transactionstatemanager.",0,0.9921990036964417
482753529,8657,chia7712,2020-09-03T07:06:44Z,"according to above case, there is a potential deadlock. [code block] [code block] is executed after updating [code block]. hence, it is possible that the lock of this request is held by **another thread**. the deadlock happens if this [code block] is holding the **lock** required by **another thread**. it seems to me the simple approach is to remove [code block]. that should be fine since we have called [code block] before.",0,0.9839143753051758
483276075,8657,junrao,2020-09-03T21:58:37Z,": 1. i think we still need `operation.safetrycomplete` in `delayedoperation.trycompleteelsewatch()`. the reason is that after the `operation.trycomplete()` call, but before we add the key to watch, the operation could have been completed by another thread. since that thread doesn't see the registered key, it won't complete the request. if we don't call `operation.safetrycomplete` after adding the key for watch, we could have missed the only chance for completing this operation. 2. i am not sure if there is a deadlock caused by transactionstatemanager. i don't see updatecachecallback hold any lock on statelock. the following locking sequence is possible through transactionstatemanager. thread 1 : hold readlock of statelock, call replicamanager.appendrecords, call trycompleteelsewatch, hold lock on delayedoperation thread 2: hold lock on delayedoperation, call delayedoperation.oncomplete, call removefromcachecallback(), hold readlock of statelock. however, since both threads hold readlock of statelock, there shouldn't be a conflict. do you see the test fail due to a deadlock?",0,0.970207929611206
483552275,8657,chia7712,2020-09-04T11:15:46Z,the following read/write lock is from[code block] of [code block] 1. thread_1: holding readlock and waiting for lock of delayed op (transactionstatemanager#appendtransactiontolog) 2. thread_2: waiting for writelock ([code block]) [code block] 3. thread_3: holding lock of delayed op and waiting for readlock (another thread is trying to complete delayed op) **deadlock** 1. thread_1 is waiting for thread_3 1. thread_3 is waiting for thread_2 1. thread_2 is waiting for thread_1,0,0.9944469928741455
483832980,8657,junrao,2020-09-04T20:33:01Z,": thanks for the explanation. `statelock` is created as an unfair reentrantreadwritelock. so, in that case, will thread_3's attempt for getting the readlock blocked after thread_2? did the test actually failed because of this?",1,0.976283073425293
483897245,8657,chia7712,2020-09-05T01:53:31Z,"to the best of my knowledge, writers have preference over readers in order to avoid starvation. that behavior is not public and we can get some evidence from source code. for example: [code block] at any rate, the non-fair mode does not guarantee above situation does not happen. hence, it would be better to avoid potential deadlock caused by [code block]. how about using [code block] in trycompleteelsewatch? it avoids conflicting locking and still check completion of delayed operations after adding watches?",0,0.9801300764083862
483966128,8657,junrao,2020-09-05T16:31:58Z,": thanks for the explanation. i agree that it's a potential problem. does using `trylock` in `trycompleteelsewatch()` lead us back to the previous issue that we could miss the opportunity to to complete an operation (fixed with kafka-6653)? another possibly is that we hold the lock in delayed operation while adding the operation to watch list and do the final `safetrycomplete()` check. this way, when the delayed operation is exposed to another thread, every thread, including the caller, always first acquires the lock in delayed operation. this should avoid all potential deadlocks between `trycompleteelsewatch()` and `checkandcomplete()`. what do you think?",1,0.9684938788414001
484039528,8657,chia7712,2020-09-06T08:22:57Z,nice idea. i have addressed this approach.,1,0.9881500005722046
484090245,8657,junrao,2020-09-06T16:38:01Z,requiring => requires,0,0.9942731261253357
484090563,8657,junrao,2020-09-06T16:41:37Z,it seems that we don't need the `if` here?,0,0.9901341795921326
484090694,8657,junrao,2020-09-06T16:43:11Z,we should return if `trycomplete()` returns true.,0,0.9952274560928345
484091466,8657,junrao,2020-09-06T16:51:33Z,"this is an existing issue. i am not sure if calling `trycomplete()` without holding the operation's lock guarantees visibility to another thread. for example, thread 1 changes the state in the operation in `trycomplete()`. it then calls `trycomplete()` holding the operations's lock but doesn't change the state in the operation. thread 2 calls `trycomplete()` holding the operations's lock. is thread 2 guaranteed to see the changes made by thread 1 since the update was made without crossing the memory boundary by subsequent readers? if this is an issue, we could extend to lock to do the first `trycomplete()` check.",0,0.9867208003997803
484092252,8657,junrao,2020-09-06T16:59:20Z,"this approach is fine but leaks operation.lock beyond tests. another way to package this is to add a new method in delayedoperation like trycompleteandmaybewatch(). if that's not very clean, we can keep the current approach.",0,0.9902338981628418
484092496,8657,junrao,2020-09-06T17:02:00Z,do we still need this change to avoid deadlocks?,0,0.9904423356056213
484092945,8657,junrao,2020-09-06T17:06:29Z,"with this change, `delayedoperations.checkandcompletefetch()` is only used in tests. i am wondering if it can be removed. it's fine if we want to do this in a followup pr. unrelated to this pr, `delayedoperations.checkandcompleteproduce` and `delayedoperations.checkandcompletedeleterecords` seem unused. we can probably remove them in a separate pr.",0,0.9730055928230286
484097161,8657,chia7712,2020-09-06T17:52:54Z,"pardon me, the latest commit does it. if the trycomplete return true, this method return true also. or you mean we can do return in the lambda function directly? if so, the reason i dont address it is the impl of return in lambda is to throws and then catch exception.that is anti-pattern in scala and we should avoid it from our hot methods.",0,0.8907275199890137
484097601,8657,chia7712,2020-09-06T17:57:55Z,there is an new test for this new behavior. in the delayedoperationtest.,0,0.9947710633277893
484097948,8657,chia7712,2020-09-06T18:01:29Z,"yep. if we add it to watch list too early, the concurrent issue happens as trycompleteelsewatch calls trycomplete without locking.",0,0.9911841750144958
484099709,8657,chia7712,2020-09-06T18:21:23Z,"it depends :) however, it should be fine to extend the lock to do it in this pr. will address it in next commit",1,0.9931278228759766
484101535,8657,junrao,2020-09-06T18:40:54Z,"yes, you are right. i missed the bracket alignment.",0,0.9854441285133362
484101769,8657,junrao,2020-09-06T18:43:34Z,"yes, it's just that if all non-testing usage of delayedoperation.lock is within delayedoperation itself, it makes it a bit easier to trace down all usage of lock.",0,0.9923658967018127
484138649,8657,chia7712,2020-09-07T00:59:57Z,"this approach can not resolve all potential deadlock. for example: 1. thread_a gets lock of op 1. thread_a adds op to watch list 1. thread_a calls op#trycomplete (and it requires lock_b) 1. thread_b holds lock_b 1. thread_b sees op from watch list 1. thread_b needs lock of op hence, we are facing the following issues. 1. the last completion check can cause deadlock after the op is exposed to other threads (by watch list). 1. the last completion check can not be removed due to kafka-6653. how about using actionqueue to resolve it? we add completion check to actionqueue after adding op to watch list. all handlers are able to complete it even if they don't have same key.",0,0.9406111240386963
484163863,8657,chia7712,2020-09-07T03:20:48Z,"as the potential deadlock caused by holding lock in [code block], i don""t change the [code block] to [code block]. maybe we can deal with this issue when we meet such issue.",0,0.9847853183746338
484164627,8657,chia7712,2020-09-07T03:24:50Z,i will file a ticket after this pr is merged. this is small change. i will remove them in this pr,0,0.9928324222564697
484181930,8657,junrao,2020-09-07T04:52:58Z,": what you described is possible, but probably not an issue in practice. since trycomplete() always completes a delayed operation asynchronously, there is no reason for the caller of a delayed operation to hold any lock while calling trycomplete. therefore, in step 4 above, the first lock that thread_b (assuming it's well designed) can acquire should be the lock in delayed operation.",0,0.9840837121009827
484209068,8657,chia7712,2020-09-07T06:32:29Z,"you are right. however, not sure how to maintain that ""well designed"" code in the future as the deadlock is implicit. it seems to me avoiding multiples exclusive lockings can avoid the deadlock. i will keep current approach since the story i described may be overkill in practice.",0,0.915999174118042
484519651,8657,junrao,2020-09-07T16:45:35Z,"since safetrycomplete() is no longer used in trycompleteelsewatch(), the above comment is not completely relevant. perhaps we could just explain what this method does ""thread-safe variant of trycomplete().""",0,0.9919724464416504
484521628,8657,junrao,2020-09-07T16:52:44Z,it requires lock_b => it tries to require lock_b,0,0.9946951270103455
484522816,8657,junrao,2020-09-07T16:57:32Z,"perhaps we could change this comment to sth like the following. to avoid the above scenario, we recommend delayedoperationpurgatory.checkandcomplete() be called without holding any lock. since delayedoperationpurgatory.checkandcomplete() completes delayed operations asynchronously, holding a lock to make the call is often unnecessary.",0,0.9914217591285706
484523257,8657,junrao,2020-09-07T16:59:24Z,there is a potential deadlock => there is a potential deadlock between the callers to trycompleteelsewatch() and checkandcomplete(),0,0.9887307286262512
484523534,8657,junrao,2020-09-07T17:00:21Z,thread_c holds lock of op => thread_c calls checkandcomplete () and holds lock of op,0,0.993130624294281
484524545,8657,junrao,2020-09-07T17:04:35Z,is this change still necessary now that we always call trycomplete() with lock in trycompleteelsewatch?,0,0.9940556287765503
484543835,8657,chia7712,2020-09-07T18:44:50Z,will copy that,0,0.9942620992660522
484605576,8657,junrao,2020-09-08T01:37:51Z,safetrycompleteandelse => safetrycompleteorelse ?,0,0.9907518625259399
484606811,8657,junrao,2020-09-08T01:43:41Z,"the above comment is a bit out of context now. perhaps we could change ""we do the check in the following way"" to ""we do the check in the following way through safetrycompleteandelse()"".",0,0.9813816547393799
484607882,8657,junrao,2020-09-08T01:48:33Z,do we still need to change the ordering now that we always call trycomplete() with lock in trycompleteelsewatch?,0,0.9933479428291321
484609072,8657,junrao,2020-09-08T01:53:44Z,checkandcomplete () => checkandcomplete(),0,0.9923641681671143
484610866,8657,junrao,2020-09-08T02:01:32Z,"perhaps change the above to the following? we hold the operation's lock while adding the operation to watch list and doing the trycomplete() check. this is to avoid a potential deadlock between the callers to trycompleteelsewatch() and checkandcomplete(). for example, the following deadlock can happen if the lock is only held for the final trycomplete() check.",0,0.9898048639297485
484622290,8657,chia7712,2020-09-08T02:52:05Z,i will revert this change,0,0.9905287623405457
484638938,8657,junrao,2020-09-08T04:08:51Z,"i think we still want to keep the rest of the paragraph starting from ""call trycomplete()."".",0,0.9864382743835449
484639236,8657,junrao,2020-09-08T04:10:06Z,"we hold => through safetrycompleteorelse(), we hold",0,0.9900636076927185
484640168,8657,junrao,2020-09-08T04:14:27Z,thread_b holds lock_b => thread_b holds lock_b and calls checkandcomplete(),0,0.9920641779899597
484640862,8657,junrao,2020-09-08T04:17:41Z,"noted that current approach can't prevent all deadlock. => note that even with the current approach, deadlocks could still be introduced.",0,0.9872328042984009
484644802,8657,junrao,2020-09-08T04:35:49Z,"instead of introducing a global var, could we add a new param when constructing committxnoffsetsoperation and completetxnoperation?",0,0.9942101240158081
484645849,8657,junrao,2020-09-08T04:40:17Z,thread_a gets lock of op => thread_a calls trycompleteelsewatch() and gets lock of op,0,0.9924490451812744
485026583,8657,junrao,2020-09-08T15:52:56Z,to call safetrycomplete => to call the final trycomplete(),0,0.9924564361572266
485026799,8657,junrao,2020-09-08T15:53:16Z,trycompleteelsewatch => trycompleteelsewatch(),0,0.978719174861908
485034262,8657,junrao,2020-09-08T16:04:21Z,causes error => causes an error,0,0.9683886766433716
485034296,8657,junrao,2020-09-08T16:04:23Z,such error => such an error,0,0.9630568027496338
94801659,2264,ijuma,2017-01-05T16:36:06Z,it seems like this field is not used anywhere.,0,0.9679965972900391
95000465,2264,hachikuji,2017-01-06T19:05:19Z,i think we need to enforce a minimum version of 2 since older versions would expect an older version of the message format. this is also an easy way to detect that we're talking with a version of the broker older than 0.10. i'm wondering if it would make sense to raise an exception to the user immediately when we connect to such a broker instead of waiting until we send an incompatible request?,0,0.9868972897529602
95016586,2264,cmccabe,2017-01-06T20:43:03Z,"sure, we can enforce a minimum version of 2 here. brokers earlier than 0.10 will automatically disconnect our clients, since those brokers don't support apiversionsrequest, which is the first thing we send after kafka-3600.",0,0.9930334091186523
95197805,2264,ijuma,2017-01-09T17:01:03Z,"nit: in kafka, we don't use `get` prefix for accessors.",0,0.9903672933578491
95198122,2264,ijuma,2017-01-09T17:02:33Z,"this is not needed, `stringbuilder` appends `null` for you.",0,0.9952926635742188
95204211,2264,ijuma,2017-01-09T17:35:24Z,nit: it may make sense to move the requestbuilder to the end as it's likely to be bigger and make it harder to read the other fields.,0,0.9851340055465698
95204352,2264,ijuma,2017-01-09T17:36:01Z,"we have a method `requestbuilder` that is the same as this, so we can remove this one.",0,0.9951619505882263
95215232,2264,cmccabe,2017-01-09T18:28:11Z,"ok, i'll remove that here (and elsewhere)",0,0.9935355186462402
95215682,2264,cmccabe,2017-01-09T18:30:19Z,k,0,0.8661732077598572
95239733,2264,cmccabe,2017-01-09T20:32:35Z,"this should be used any time that there is a version mismatch problem between the message we are trying to send and the message versions we can actually send to the desired broker. i fixed the fetcher to use this instead of doing its own thing to detect version problems. i also change the type of this to runtimeexception, so that the exact exception which the builder raised can be preserved here.",0,0.9874420762062073
95248631,2264,ijuma,2017-01-09T21:20:56Z,nit: should this be `newrequest` since it's a method in `kafkaclient`? or is it clearer how it is?,0,0.9921548962593079
95252239,2264,ijuma,2017-01-09T21:39:37Z,"nit: do we really need 3 lines for this? seems like we could do it in two. in kafka, we generally go for wider lines than the traditional 80 columns (100 to 120 is common).",0,0.8267536759376526
95252366,2264,ijuma,2017-01-09T21:40:22Z,can we expand on when this can happen?,0,0.9941692352294922
95261313,2264,hachikuji,2017-01-09T22:27:41Z,nit: this alignment is weird. are you using intellij defaults?,-1,0.9931272268295288
95262756,2264,hachikuji,2017-01-09T22:36:29Z,does it make sense to special case the apiversion request only instead of skipping the check for all internal requests?,0,0.9906775951385498
95263217,2264,hachikuji,2017-01-09T22:39:17Z,nit: we usually skip braces for one-line branches like this. a few more below.,0,0.9875592589378357
95264033,2264,hachikuji,2017-01-09T22:44:20Z,"would it make sense to push this check into `getusableversion`? i wouldn't consider a negative version ""usable.""",0,0.9902875423431396
95264436,2264,hachikuji,2017-01-09T22:46:54Z,is this equivalent to this? [code block],0,0.9959099292755127
95264759,2264,hachikuji,2017-01-09T22:48:56Z,nit: indentation,0,0.9914920926094055
95265028,2264,hachikuji,2017-01-09T22:50:32Z,nit: use string interpolation,0,0.9943169951438904
95265544,2264,hachikuji,2017-01-09T22:53:41Z,"there's a bug in `processdisconnection` (not introduced in this patch) that we ought to fix here. the type of `node` here is a string, but `nodeapiversions` is keyed by integer. (the conversion between string and int all over this class always pains me.)",-1,0.9167085886001587
95265740,2264,ijuma,2017-01-09T22:54:41Z,"unfortunately, 0.9.0.1 has a bug where it won't disconnect when it receives an unknown request. it will keep the connection open until the connection reaper comes along. a subsequent request can cause an immediate disconnection though.",-1,0.6741519570350647
95265836,2264,hachikuji,2017-01-09T22:55:18Z,i think `nodeid` is a more accurate name.,0,0.9856178164482117
95265980,2264,ijuma,2017-01-09T22:56:13Z,"nit: is it right to say it's an `obsolete` broker? seems a bit too strong, obsolete means `no longer produced or used; out of date` whereas it could be a broker that is just 4 months old given our current time-based release schedule.",0,0.8136722445487976
95266228,2264,ijuma,2017-01-09T22:57:44Z,do we really need to do this? i'd prefer if we didn't expose a static mutable array outside this class.,0,0.9762493371963501
95266232,2264,hachikuji,2017-01-09T22:57:45Z,nit: seems like there's enough room on the previous line for this,0,0.9791871309280396
95266343,2264,ijuma,2017-01-09T22:58:27Z,nit: `version`?,0,0.9893808364868164
95266684,2264,hachikuji,2017-01-09T23:00:39Z,seems this was our last usage for the `now` parameter.,0,0.9887763857841492
95266777,2264,hachikuji,2017-01-09T23:01:13Z,nit: can this fit on the line above?,0,0.9902327060699463
95267609,2264,ijuma,2017-01-09T23:06:14Z,"these 3 lines can simply be `val version = apiversion.getorelse(protoutils.latestversion(apikey,id))`.",0,0.9954534769058228
95267715,2264,hachikuji,2017-01-09T23:06:56Z,seems we can turn this into an assertion when it is not an apiversion request.,0,0.9890617728233337
95267760,2264,ijuma,2017-01-09T23:07:12Z,"nit: it should be `val version: short` (space after the colon, not before).",0,0.9928118586540222
95268226,2264,hachikuji,2017-01-09T23:10:16Z,`now` is never used.,0,0.9915383458137512
95268276,2264,ijuma,2017-01-09T23:10:37Z,"looks like the code for both `builder(...)` is the same, so maybe we can just do the `livebrokers` bit in the `if/else`.",0,0.9894281029701233
95268361,2264,ijuma,2017-01-09T23:11:14Z,"nit: the map creation is usually done like `map(securityprotocol.plaintext -> new endpoint(node.host, node.port))`.",0,0.9948734641075134
95268422,2264,hachikuji,2017-01-09T23:11:38Z,nit: you can leave out the type on the right-hand side.,0,0.9925705790519714
95268671,2264,ijuma,2017-01-09T23:13:10Z,nit: is there a reason why you didn't chain this one too?,0,0.9819163680076599
95268734,2264,ijuma,2017-01-09T23:13:39Z,seems like the `()` introduced here are not needed.,0,0.9877443909645081
95271011,2264,hachikuji,2017-01-09T23:28:58Z,`api` no longer used. indentation needs fixing also.,0,0.9696457386016846
95271585,2264,hachikuji,2017-01-09T23:32:24Z,there are a few javadoc references that need fixing as well.,0,0.9872735738754272
95274471,2264,hachikuji,2017-01-09T23:54:45Z,"i think it might be better to move this check into `consumernetworkclient.requestfuturecompletionhandler` to ensure that we don't forget any checks. also `onfailure` seems like a more appropriate callback for that case,",0,0.9865995645523071
95275129,2264,hachikuji,2017-01-10T00:00:05Z,"nit: string interpolation is preferred. another one below. also, not sure about the convention of including the function name. wouldn't the logger do that for us?",0,0.9849134087562561
95276737,2264,hachikuji,2017-01-10T00:13:40Z,"in this case, we're using the presence of the `offsets` field to indirectly determine that the version that was used was 0. i'm not sure we'll always have something so convenient, so i've been wondering if we need a way to determine the version that was used more directly. for example, we could have `clientresponse` or even `abstractresponse` include a field for the version.",0,0.9639361500740051
95276915,2264,cmccabe,2017-01-10T00:15:26Z,"ok, i realigned it with the left paren",0,0.9923635721206665
95276973,2264,cmccabe,2017-01-10T00:15:53Z,k,0,0.8661732077598572
95277223,2264,hachikuji,2017-01-10T00:18:28Z,why was this changed?,0,0.992620587348938
95277345,2264,cmccabe,2017-01-10T00:19:36Z,"hmm. i haven't thought about it that hard, but i think special casing will probably get messy here. it also duplicates work done elsewhere to check if the message is sendable.",0,0.8156543970108032
95277392,2264,hachikuji,2017-01-10T00:19:57Z,the `impl` suffix is a little unconventional. can we just use `getoffsetsbytimes`?,0,0.9824291467666626
95278127,2264,cmccabe,2017-01-10T00:26:26Z,k,0,0.8661732077598572
95278471,2264,cmccabe,2017-01-10T00:29:17Z,ok,0,0.9233372807502747
95278543,2264,cmccabe,2017-01-10T00:29:57Z,removed,0,0.9591778516769409
95278678,2264,hachikuji,2017-01-10T00:30:54Z,i think we need to pass this exception to the future instead of raising. would be good to have a test case if we don't already.,0,0.9691749215126038
95278757,2264,cmccabe,2017-01-10T00:31:41Z,"yeah, let's just do that.",0,0.9742481708526611
95278815,2264,cmccabe,2017-01-10T00:32:16Z,k,0,0.8661732077598572
95278891,2264,cmccabe,2017-01-10T00:33:00Z,yeah,0,0.811758279800415
95279595,2264,hachikuji,2017-01-10T00:39:47Z,"we didn't have it before, but maybe we should add a null check here for more resilience in the future.",0,0.990153968334198
95279607,2264,cmccabe,2017-01-10T00:39:56Z,"yeah, that is pretty nasty. i'll fix it. i wish there were some workaround for this, but it looks like java map still always supports put(object) to allow compatibility with the pre-generics days... we should start running findbugs to catch things like this",-1,0.9946656227111816
95279753,2264,hachikuji,2017-01-10T00:41:13Z,"i'm a little unclear on the pattern for which fields are included in the builder constructor and which are included through methods. i thought perhaps it would be the required arguments included in the constructor, but we didn't pass the timestamps to query in the `listoffsetrequest` above, which seems required.",0,0.898854672908783
95280248,2264,cmccabe,2017-01-10T00:45:07Z,k,0,0.8661732077598572
95280508,2264,cmccabe,2017-01-10T00:47:36Z,k,0,0.8661732077598572
95280577,2264,cmccabe,2017-01-10T00:48:05Z,k,0,0.8661732077598572
95280644,2264,cmccabe,2017-01-10T00:48:41Z,yeah,0,0.811758279800415
95281013,2264,cmccabe,2017-01-10T00:51:28Z,k,0,0.8661732077598572
95281567,2264,cmccabe,2017-01-10T00:56:07Z,i added a comment,0,0.9917899370193481
95282327,2264,hachikuji,2017-01-10T01:02:40Z,maybe `unsupportedbrokerexception`?,0,0.9876553416252136
95284742,2264,cmccabe,2017-01-10T01:26:27Z,"hmm, how would the 0.9.0.1 broker even know that it was getting another request? it doesn't know the size of the first request so it doesn't know where that request ends and a new one begins.",0,0.9511519074440002
95284792,2264,cmccabe,2017-01-10T01:26:58Z,k,0,0.8661732077598572
95284826,2264,hachikuji,2017-01-10T01:27:24Z,nit: would be nice to be consistent on the use of braces or parenthesis. i think we are trying to encourage the latter.,0,0.970639705657959
95286297,2264,junrao,2017-01-10T01:43:04Z,"when the transport is ssl, the client can't send requests immediately after the socket is connected. we have to wait for the ssl handshake to complete. so, perhaps the selector needs to further return the transport.ready() state in kafkachannel to networkclient.",0,0.9907655715942383
95286337,2264,junrao,2017-01-10T01:43:30Z,"using the current version is ok for now since there is currently only one version of saslhandshakerequest. it would be useful to add a comment that when there are new versions of saslhandshakerequest, we need to select the version based on the result of apirequest accordingly.",0,0.9922454953193665
95290016,2264,hachikuji,2017-01-10T02:25:10Z,we seem to be missing the version mismatch check in `handleproduceresponse`.,0,0.9922174215316772
95303775,2264,cmccabe,2017-01-10T05:53:19Z,k,0,0.8661732077598572
95304065,2264,cmccabe,2017-01-10T05:57:04Z,"setversion is a method on the base class, abstractrequest#builder. so it returns an instance of abstractrequest#builder rather than an instance of the derived class fetchrequest#builder, which is awkward for scala's type inference.",-1,0.6733747720718384
95304445,2264,cmccabe,2017-01-10T06:01:54Z,k,0,0.8661732077598572
95304662,2264,cmccabe,2017-01-10T06:04:57Z,nice,1,0.7884483337402344
95304719,2264,cmccabe,2017-01-10T06:06:13Z,k,0,0.8661732077598572
95304766,2264,cmccabe,2017-01-10T06:06:44Z,k,0,0.8661732077598572
95304877,2264,cmccabe,2017-01-10T06:08:33Z,k,0,0.8661732077598572
95305418,2264,cmccabe,2017-01-10T06:16:03Z,"ok, we can hide it",0,0.9908717274665833
95305559,2264,cmccabe,2017-01-10T06:17:31Z,"obsolete may be a little strong, but it's clear what it means and what the user should do if they want access to the feature. we could also go with something like ""outdatedbrokerexception""?",0,0.9563910365104675
95305659,2264,cmccabe,2017-01-10T06:18:44Z,"it sounds like we would be in the clear then, since we're sending an apiversionsrequest followed by a follow-on request?",0,0.9912350177764893
95305690,2264,cmccabe,2017-01-10T06:19:14Z,fixed,0,0.920660674571991
95305695,2264,cmccabe,2017-01-10T06:19:19Z,k,0,0.8661732077598572
95305967,2264,cmccabe,2017-01-10T06:22:42Z,k,0,0.8661732077598572
95305976,2264,cmccabe,2017-01-10T06:22:50Z,sounds good,1,0.8904690742492676
95305989,2264,cmccabe,2017-01-10T06:22:56Z,removed,0,0.9591778516769409
95306011,2264,cmccabe,2017-01-10T06:23:05Z,"yes, let's replace it with that",0,0.9913522005081177
95306022,2264,cmccabe,2017-01-10T06:23:14Z,fixed,0,0.920660674571991
95306030,2264,cmccabe,2017-01-10T06:23:21Z,k,0,0.8661732077598572
95306063,2264,cmccabe,2017-01-10T06:23:48Z,ugh. that's a nasty one. i fixed it in the patch. we should run findbugs...,-1,0.9955551028251648
95306070,2264,cmccabe,2017-01-10T06:23:54Z,k,0,0.8661732077598572
95306078,2264,cmccabe,2017-01-10T06:23:59Z,k,0,0.8661732077598572
95306086,2264,cmccabe,2017-01-10T06:24:06Z,yeah,0,0.811758279800415
95306094,2264,cmccabe,2017-01-10T06:24:11Z,ok,0,0.9233372807502747
95306102,2264,cmccabe,2017-01-10T06:24:17Z,yeah,0,0.811758279800415
95306242,2264,cmccabe,2017-01-10T06:26:07Z,"hmm. i think if it were just newrequest, i would wonder whether it was a new abstractrequest or a new clientrequest. what do you think?",0,0.9204779267311096
95306249,2264,cmccabe,2017-01-10T06:26:14Z,ok,0,0.9233372807502747
95306275,2264,cmccabe,2017-01-10T06:26:38Z,i added a comment,0,0.9917899370193481
95306664,2264,cmccabe,2017-01-10T06:32:08Z,k,0,0.8661732077598572
95307070,2264,cmccabe,2017-01-10T06:37:05Z,"hmm, i didn't see any code path where the return value could be null, or the value of the future itself, or the keys or values of the map. maybe an npe is ok in that case?",0,0.9786132574081421
95307372,2264,cmccabe,2017-01-10T06:40:56Z,"i wanted to avoid confusion with the public api of that name. how about ""retrieveoffsetsbytimes""?",0,0.992588222026825
95307500,2264,cmccabe,2017-01-10T06:42:28Z,"good catch. i made some other edits to the for loop, but they're no longer necessary now. reverted",1,0.9920223951339722
95308523,2264,cmccabe,2017-01-10T06:54:58Z,"i think abstractresponse should have a version number in it, since the data it contains varies based on the version. sometimes the interpretation of the data varies based on version as well. it's a property of the response and it belongs in the response object. but hopefully we can hold off on that for now since this patch is kinda big as-is...",0,0.8724058270454407
95308701,2264,cmccabe,2017-01-10T06:57:14Z,"yeah, let's leave the function name out. will use string interpolation",0,0.9926726222038269
95309085,2264,cmccabe,2017-01-10T07:02:05Z,"you are right that the general pattern is that constructor arguments are required, other things are optional. ideally we would have listoffsetrequest#builder(map ) and listoffsetrequest#builder(map ), but we can't do that because of a java limitation... both constructors would have the same type once type erasure has been performed, which is not allowed.",0,0.9906151294708252
95309234,2264,cmccabe,2017-01-10T07:03:58Z,"braces seem a little more familiar to me because of json. but if parentheses are the way to go, i can change it. it's a big change though since all the builders have a tostring. are we sure we want the parens?",0,0.9596678018569946
95324930,2264,ijuma,2017-01-10T09:19:53Z,i was debating that myself before writing the comment. let's leave it as is then.,0,0.9829493761062622
95342279,2264,ijuma,2017-01-10T11:04:44Z,"oh, i see. the compiler is correct in not allowing that then. one way to fix that is to change the definition of `builder` to be: [code block] but this makes it more awkward to use the abstract builder directly due to the additional type parameter (in scala we could use type members instead). an alternative is to override `setbuilder` in each builder and use the more specific type there. it's a bit annoying, but builders are supposedly used more times than they are defined.",-1,0.9481213688850403
95342721,2264,ijuma,2017-01-10T11:07:32Z,"the broker assumes that all requests are consistent with regards to the common request header elements. if we set the minimum versions correctly, we should be in the clear, i think. it would be good to have a test for 0.9.0.1, but we can do that in a follow-up.",0,0.9865162372589111
95343648,2264,ijuma,2017-01-10T11:13:53Z,"i think i prefer `unsupportedbrokerversion`. but it's subjective and `obsolete`/`outdated` are more explicit with regards that you want a newer broker. another point: if we think of the protocol as something independent from kafka (i.e. there could be other implementations), which is something that jay thinks we should, then `unsupportedbrokerversion` also seems better.",0,0.9648893475532532
95344394,2264,ijuma,2017-01-10T11:19:23Z,"there are indeed a few ways to do this. we tend to follow the `foo(a=""a"",b=""b"")` model and this is what public classes like `producerrecord` and `consumerrecord` do. also, it's worth saying that, outside of loops, `stringbuilder` is no better than string concatenation with regards to performance. up to java 8, javac will do the stringbuilder thing itself. from java 9, invokedynamic will be used to allow the runtime to choose the best strategy ([a link] my suggestion is to clean this up in a subsequent pr. it can even be done after the feature freeze.",0,0.9892587065696716
95358669,2264,ijuma,2017-01-10T13:01:34Z,", there is a comment already a couple of lines above (i asked ashish to add it as part of kafka-3600): [code block] maybe we can move the comment so that it's closer to the request creation.",0,0.9918842315673828
95358836,2264,ijuma,2017-01-10T13:02:45Z,"it's a bit odd that we add a hardcoded prefix and suffix in a generic `join` method. typically, these would be parameters and the default case would be no prefix or suffix (consistent with `join` that takes a `collection`).",-1,0.6824291944503784
95359080,2264,ijuma,2017-01-10T13:04:29Z,nit: space missing before `:`.,0,0.9539979696273804
95359283,2264,ijuma,2017-01-10T13:05:52Z,", have we tested with ssl enabled?",0,0.9942552447319031
95363623,2264,ijuma,2017-01-10T13:33:37Z,nit: `1: short` is a little better because it will fail to compile if the conversion is not possible where `toshort` will happily overflow. doesn't make a difference in these particular cases though.,0,0.9823163151741028
95368726,2264,ijuma,2017-01-10T14:04:14Z,nit: `0: java.lang.long` is a tiny bit shorter.,0,0.9753441214561462
95369472,2264,ijuma,2017-01-10T14:08:50Z,i think it would be worth adding an overload without the `callback` as it's optional and many callers don't need it.,0,0.9817891716957092
95370437,2264,ijuma,2017-01-10T14:14:21Z,this is unused.,0,0.9921370148658752
95373680,2264,ijuma,2017-01-10T14:31:44Z,i think is thinking of the case where `ret.get(partition)` returns `null`. not sure if we are enforcing that elsewhere though.,0,0.9865849018096924
95376734,2264,ijuma,2017-01-10T14:46:19Z,"typo, `r` missing.",0,0.9890069961547852
95378574,2264,ijuma,2017-01-10T14:54:01Z,nit: i think this is harder to read by being split into 3 lines like this. looks like a staircase. ;) there's one other case like that.,1,0.9901690483093262
95379773,2264,ijuma,2017-01-10T14:59:28Z,change `versionid` to `short` like you did in other places?,0,0.992305338382721
95394973,2264,ijuma,2017-01-10T16:01:54Z,it looks like we only need to support `2` and above: [a link],0,0.9912711381912231
95397340,2264,ijuma,2017-01-10T16:11:14Z,should we be validating that version is always `1`? version `0` would probably mean that something is wrong.,0,0.9745529890060425
95398519,2264,ijuma,2017-01-10T16:16:08Z,in other request classes we don't throw an exception in case the version is higher than expected. we should be consistent. i think this approach is good because it forces people to consider how to handle a new version when it's introduced.,0,0.8517066836357117
95399367,2264,ijuma,2017-01-10T16:19:57Z,i think we should set it to `-1` in this case to make it clear that it won't be used as we have the following: [code block],0,0.989297091960907
95400451,2264,ijuma,2017-01-10T16:24:42Z,we have 3 `getversion` calls. one should be enough.,0,0.9940236210823059
95402987,2264,ijuma,2017-01-10T16:35:38Z,parenthesis are not needed here or the other branches since a single value is being returned now.,0,0.9898778796195984
95403350,2264,ijuma,2017-01-10T16:37:05Z,nit: should be `fetchdata()`.,0,0.9918994903564453
95403601,2264,ijuma,2017-01-10T16:38:06Z,nit: there should be a space before `:`.,0,0.968906819820404
95403993,2264,ijuma,2017-01-10T16:39:51Z,"personally, i think `short` and `null` for no usable version is less error-prone (you'll get a npe if you accidentally try to use it instead of ending with a `-1` somewhere it should not be).",0,0.9722132682800293
95404122,2264,ijuma,2017-01-10T16:40:22Z,seems like this comment should be in the method documentation.,0,0.9892394542694092
95404878,2264,ijuma,2017-01-10T16:43:20Z,why not use `enummap `? it would be more readable imo.,0,0.9863280057907104
95405837,2264,ijuma,2017-01-10T16:47:11Z,can this ever be less than 0?,0,0.9418154358863831
95405971,2264,ijuma,2017-01-10T16:47:48Z,`math.min` and 4 lines become 1?,0,0.9888607859611511
95406464,2264,ijuma,2017-01-10T16:50:01Z,this `tostring` is quite long. :) it would be nice to break it down into smaller methods so that it's easier to understand.,1,0.9958807229995728
95407688,2264,ijuma,2017-01-10T16:55:15Z,"any reason we are using `linkedlist` instead of `arraylist`? we seem to be adding to the end, iterating and then clearing (after jason's suggestion), so `arraylist` seems like the better option.",0,0.9886510372161865
95409034,2264,ijuma,2017-01-10T17:01:28Z,"it would be good to include the most current version in this message as well. also, as jun said it may be a good to log at a higher level if we are downgrading a request. not sure what jun had in mind, but maybe `debug`?",0,0.9856002330780029
95410187,2264,ijuma,2017-01-10T17:06:45Z,we have the following code for failed metadata requests: [code block] should we be doing similarly for this case (since we now do `apiversionsrequest` before `metadatarequest`)?,0,0.9945650100708008
95410941,2264,ijuma,2017-01-10T17:10:14Z,`now` is no longer used,0,0.9934905767440796
95411451,2264,ijuma,2017-01-10T17:12:49Z,"we are now doing `apiversions` unconditionally. this means that 0.10.2 brokers won't be able to talk to 0.9.0.x brokers, right? we shouldn't do that.",0,0.9437687397003174
95418264,2264,cmccabe,2017-01-10T17:45:59Z,"hmm. just to clarify, you think that throwing the exception when we see an unexpected version is the right way to go? i can add that to the other requests if so.",0,0.9686073064804077
95418858,2264,cmccabe,2017-01-10T17:48:52Z,the other versions are used in unit tests. the server also can handle them to support older clients.,0,0.9955106973648071
95419171,2264,cmccabe,2017-01-10T17:50:25Z,"i wanted to do this, but it got messy. the problem is that there are a bunch of unit tests that are using reflection to call these methods-- and also some scala code. i think we should have a follow-on jira for converting the parse() methods to use 'short' for version.",0,0.5081236362457275
95419258,2264,cmccabe,2017-01-10T17:50:53Z,k,0,0.8661732077598572
95419528,2264,cmccabe,2017-01-10T17:52:23Z,that's a good point. what do you suggest? one approach is to (re)add a constructor parameter to networkclient that will allow the brokers to bypass sending apiversions.,1,0.8313628435134888
95438375,2264,cmccabe,2017-01-10T19:27:44Z,k,0,0.8661732077598572
95438824,2264,cmccabe,2017-01-10T19:29:50Z,i fixed it to be an exception instead,0,0.9911971092224121
95440180,2264,hachikuji,2017-01-10T19:36:18Z,i doubt it would add much to the size of this patch if you want to do it here. a follow-up would work as well. i'm anxious to have a good general approach in place so that we have clear patterns to follow going forward.,0,0.7833647131919861
95442388,2264,cmccabe,2017-01-10T19:47:17Z,"from a user point of view, unsupportedbrokerversion is that it doesn't make it clear whether the broker version is too new or old. it also suggests that the whole broker is unsupported, whereas just this one api is unsupported. hmm. it seems like we could still have other implementations of the protocol even if we used outdatedbrokerexception / obsoletebrokerexception? i'm open to ideas on this. i would kind of like something that gives the user a clear hint that they need to upgrade...",0,0.8337396383285522
95443442,2264,cmccabe,2017-01-10T19:52:32Z,"ah, good point. let me add a check for that just to be safe. after all, this data is coming over the wire, so we should not unconditionally trust it.",1,0.8805397152900696
95445212,2264,hachikuji,2017-01-10T20:02:02Z,note there was a previous comment about using `arraylist` instead of `linkedlist`.,0,0.9935190081596375
95449880,2264,cmccabe,2017-01-10T20:27:07Z,k,0,0.8661732077598572
95450837,2264,cmccabe,2017-01-10T20:32:37Z,"yeah, it would be good to have a clear pattern here. let's do it in a follow-on.",0,0.9796465039253235
95452015,2264,cmccabe,2017-01-10T20:39:34Z,"hmm. cansendrequest should be making sure that the ssl handshake is complete, right? call stack: [code block] kafkachannel#ready has: [code block]",0,0.9728739857673645
95452301,2264,cmccabe,2017-01-10T20:41:17Z,: i'll parameterize our ducktape tests for client compat with ssl,0,0.9937082529067993
95458316,2264,cmccabe,2017-01-10T21:13:47Z,renamed to utils#mkstring and made this optional with function overloads.,0,0.9954370856285095
95463538,2264,ijuma,2017-01-10T21:40:30Z,this should be `setversion(version)` i think.,0,0.9931106567382812
95465642,2264,hachikuji,2017-01-10T21:50:26Z,sounds reasonable to me.,0,0.9886166453361511
95466268,2264,hachikuji,2017-01-10T21:53:37Z,nit: string interpolation,0,0.9899719953536987
95466619,2264,hachikuji,2017-01-10T21:55:35Z,probably more helpful to convert the error code to an instance of `errors` and use `message()`. even better would be to have `apiversionsresponse` use a field of type `errors` instead of a short.,0,0.9884825348854065
95468151,2264,hachikuji,2017-01-10T22:03:47Z,"nit: the `tostring()` is not needed, right?",0,0.9905134439468384
95468429,2264,hachikuji,2017-01-10T22:05:28Z,i was thinking about this a little more. i wonder if we could just change the key type to string to make it consistent with `nodesneedingapiversionsfetch`?,0,0.9657307863235474
95469545,2264,hachikuji,2017-01-10T22:11:46Z,could we have this accept an `apikeys` instance instead of short? then we wouldn't need the check for a negative api key. also would be nice to document what exactly this method is returning. is it the largest version supported by both the client and server?,0,0.9908347129821777
95471626,2264,hachikuji,2017-01-10T22:23:31Z,"typo: ""reponse""",0,0.9956908822059631
95471877,2264,hachikuji,2017-01-10T22:25:04Z,i think i had a comment before about moving this check into `consumernetworkclient.requestfuturecompletionhandler`.,0,0.9906775951385498
95472157,2264,hachikuji,2017-01-10T22:26:54Z,"to be clear, if the broker doesn't support this then we'll raise `obsoletebrokerexception`? i wonder if that handling is consistent with the behavior when the broker is up to date, but has an old message format version. it seems our handling of the `unsupported_for_message_format` is to add a null entry to the result. maybe we should do the same?",0,0.9895312786102295
95472929,2264,hachikuji,2017-01-10T22:31:10Z,would we ever return a negative offset to the user?,0,0.9724408984184265
95473004,2264,hachikuji,2017-01-10T22:31:35Z,nit: move to previous line,0,0.9935577511787415
95473512,2264,hachikuji,2017-01-10T22:34:31Z,another suggestion: `incompatibleprotocolversion`?,0,0.9930610060691833
95475950,2264,hachikuji,2017-01-10T22:49:21Z,seems the only usage is internal to `networkclient`. maybe we could just use the variable directly?,0,0.9920058846473694
95477354,2264,ijuma,2017-01-10T22:57:56Z,"also, is `discoverpeerversions` the right name? seems like it should be `discoverbrokerversions` as `networkclient` is also used by clients.",0,0.9922248125076294
95477481,2264,cmccabe,2017-01-10T22:58:42Z,"ok, i added a constructor parameter and a unit test. thanks for catching this!",1,0.9875137209892273
95477659,2264,ijuma,2017-01-10T22:59:44Z,"are the comments inside the if/else adding anything over what the code does? to me, they seem to say exactly the same thing as the code.",0,0.9798163175582886
95479078,2264,cmccabe,2017-01-10T23:09:16Z,k,0,0.8661732077598572
95479437,2264,cmccabe,2017-01-10T23:11:52Z,"for some reason, there is no math.min(short, short), only math.min(int, int). i could use the int version with a typecast, but i thought the cast was ugly.",-1,0.99130779504776
95479552,2264,cmccabe,2017-01-10T23:12:44Z,k,0,0.8661732077598572
95480087,2264,cmccabe,2017-01-10T23:16:37Z,k,0,0.8661732077598572
95480896,2264,cmccabe,2017-01-10T23:22:12Z,k,0,0.8661732077598572
95481038,2264,cmccabe,2017-01-10T23:23:07Z,ok. will leave it as toshort here since the typecast is kind of annoying visually (edit: it's an ascription) ;),1,0.803439199924469
95481685,2264,cmccabe,2017-01-10T23:28:03Z,"not really, can remove",0,0.9626933932304382
95482457,2264,hachikuji,2017-01-10T23:33:37Z,seems this field could be final. might be worth a pass over the other request types to locate other fields that could be final.,0,0.9813531637191772
95482720,2264,hachikuji,2017-01-10T23:35:25Z,this seems unneeded.,0,0.8587985634803772
95483218,2264,hachikuji,2017-01-10T23:39:11Z,"it would be nice to be consistent about whether a field should be included in the constructor or whether it should have a setter. i don't know that we have any cases that call for mutating a field that was initialized in the constructor, so i would prefer to just leave off the setters in that case and make the field final.",0,0.9791466593742371
95483731,2264,cmccabe,2017-01-10T23:43:13Z,"oops, sorry, i meant to reply but i closed the browser window. arraylist seems like overkill here since we don't expect a lot of aborted sends to happen. also, the memory consumed by arraylist only grows and never shrinks (unless you call trimtosize), which seems like a bad choice here.",-1,0.985441267490387
95483834,2264,cmccabe,2017-01-10T23:43:59Z,k,0,0.8661732077598572
95484012,2264,cmccabe,2017-01-10T23:45:13Z,ok,0,0.9233372807502747
95484274,2264,cmccabe,2017-01-10T23:47:15Z,"yeah, let's use errors to get the error enum. can refactor further later",0,0.9915511608123779
95484396,2264,cmccabe,2017-01-10T23:48:10Z,"true, it should be called implicitly",0,0.9910104274749756
95484656,2264,cmccabe,2017-01-10T23:49:56Z,good ideas. done,1,0.9941097497940063
95484862,2264,cmccabe,2017-01-10T23:51:24Z,"i don't understand what you mean by ""the broker is up to date, but has an old message format version"".",-1,0.5042824149131775
95484986,2264,cmccabe,2017-01-10T23:52:18Z,"right, i have been looking at that. thinking of doing it in a follow-on jira since i will need to take a deeper look at the rpc paths when doing that",0,0.9808291792869568
95485081,2264,cmccabe,2017-01-10T23:53:03Z,k,0,0.8661732077598572
95485096,2264,cmccabe,2017-01-10T23:53:08Z,no,0,0.9063705205917358
95485142,2264,cmccabe,2017-01-10T23:53:26Z,k,0,0.8661732077598572
95486629,2264,hachikuji,2017-01-11T00:05:59Z,"i'm thinking of the case where the broker doesn't support v1 of listoffsets. for this case, i think we currently raise `obsoletebrokerexception`. i am questioning whether it would be more consistent to return a null entry in this case in the result of `offsetsfortimes`. currently it is possible for the broker to support the new api version, but not the message format version which is needed to answer the query. in this case, we return a null entry.",0,0.9826237559318542
95488513,2264,ijuma,2017-01-11T00:20:08Z,"well, the `arraylist` array would expand to 10 elements the first time an aborted send is added. and then, it will probably never grow beyond that. linkedlist in java is just not a very good collection in general. each node has 3 references and there is a node instance per item. a funny tweet by joshua bloch: "" does anyone actually use linkedlist? i wrote it, and i never use it."" [a link]",0,0.5781988501548767
95489336,2264,ijuma,2017-01-11T00:26:51Z,i asked colin to add this point to the follow-up jira.,0,0.9798504114151001
95490172,2264,ijuma,2017-01-11T00:33:36Z,we should not have it in the javadoc then as this is a class that is exposed to users.,0,0.9891140460968018
95504733,2264,junrao,2017-01-11T03:03:06Z,"in the patch, it seems that once a channel is connected, but is not necessarily ready, networkclient can start issuing apirequest. this can fail if transport is ssl and transportlayer.ready() is false. it's also too late to only start issuing apirequest after channel is ready since the apirequest should be sent before sasl handshake (sasl handshake completes when authenticator.complete() is true). what the networkclient is supposed to do is only start issuing apirequest after transportlayer.ready() is true. it's just that currently, this state is no propagated by selector.",0,0.9769177436828613
95506134,2264,ijuma,2017-01-11T03:23:02Z,"i'm not sure what you mean when you say that the patch starts issuing apiversions request before transport layer is ready: [code block] isn't that ok (we call `selector.ischannelready(node)`)? the point about sasl. the outcome of the discussion in the pr for kafka-3600 was that we don't have to send the api versions request before the sasl request for now since there's only one version of the saslhandshake request. if we ever introduce an additional version, we can change the client at the same time. it seems like there's no downside to this since brokers will have to keep supporting the old sasl handshake request anyway. do you feel differently?",0,0.8945121765136719
95507893,2264,junrao,2017-01-11T03:50:34Z,": yes, i missed the selector.ischannelready(node) check. so, this is fine. about the sasl, that's reasonable. we can keep the changes in the pr as they are.",0,0.9615553617477417
95579492,2264,ijuma,2017-01-11T13:41:57Z,"i submitted a pr that removes unused setters, makes fields final and tries to make things a bit more regular. makes it a bit simpler, but more could be done probably.",0,0.9654641151428223
95579966,2264,ijuma,2017-01-11T13:44:52Z,", this one seems important to resolve before merging.",0,0.976543128490448
95582701,2264,ijuma,2017-01-11T14:01:03Z,i've done this in my pr.,0,0.984430730342865
95582725,2264,ijuma,2017-01-11T14:01:11Z,removed in my pr.,0,0.9759604930877686
95582772,2264,ijuma,2017-01-11T14:01:25Z,fixed in my pr.,0,0.9923557043075562
95582876,2264,ijuma,2017-01-11T14:02:06Z,the server doesn't use the builder so i think that would be ok. but let's leave it for now.,0,0.9891513586044312
95582919,2264,ijuma,2017-01-11T14:02:21Z,"yes, but let's consider that in a separate pr.",0,0.9914109706878662
95583125,2264,ijuma,2017-01-11T14:03:35Z,changed in my pr.,0,0.9651243686676025
95583846,2264,ijuma,2017-01-11T14:07:42Z,i did this for a bunch of builders in my pr.,0,0.9443284273147583
95638931,2264,hachikuji,2017-01-11T18:21:36Z,can you address this comment please?,0,0.9933144450187683
95641786,2264,cmccabe,2017-01-11T18:35:12Z,done,0,0.8682363629341125
95641982,2264,cmccabe,2017-01-11T18:36:01Z,sounds good,1,0.8904690742492676
1290585581,14182,jeffkbkim,2023-08-10T19:23:36Z,i would include the priorities when considering uniform vs. sticky vs. rack-aware,0,0.988141655921936
1290588764,14182,jeffkbkim,2023-08-10T19:27:03Z,"is ""expected"" in the name bring necessary?",0,0.9935950636863708
1290589362,14182,jeffkbkim,2023-08-10T19:27:44Z,"is this ""remaining number of partitions""?",0,0.9903302192687988
1290591418,14182,jeffkbkim,2023-08-10T19:30:04Z,i don't think we need this comment,0,0.9816135168075562
1290591834,14182,jeffkbkim,2023-08-10T19:30:34Z,how's `previousowners`?,0,0.9944084286689758
1290610215,14182,jeffkbkim,2023-08-10T19:49:17Z,why is all of this under the constructor?,0,0.9846681952476501
1290610669,14182,jeffkbkim,2023-08-10T19:49:49Z,nit: can we match the argument ordering?,0,0.993498682975769
1290611774,14182,jeffkbkim,2023-08-10T19:51:09Z,"`buildassignment()` makes more sense. also, this should be an abstract method under `uniformassignor`",0,0.9925941824913025
1290636312,14182,jeffkbkim,2023-08-10T20:17:29Z,i'm noticing a pattern where we are using class variables when they can just be method variables. we should aim to use the smallest scope for all variables.,0,0.9395880103111267
1290763071,14182,rreddy-22,2023-08-10T23:12:48Z,including balance >rack>stickiness,0,0.9777954816818237
1290763624,14182,rreddy-22,2023-08-10T23:13:54Z,"yeah because the extra partitions haven't been assigned yet, i'm just taking a count of how many are expected to get the extra partition",0,0.983442485332489
1290764909,14182,rreddy-22,2023-08-10T23:16:54Z,"i think this name makes it clear that its a map, if we just used previousowners, its not clear whose previous owner right. we would then have to name it previouspartitionowners, which is kinda the same as partitiontopreviousowner?",0,0.9583616852760315
1290765488,14182,rreddy-22,2023-08-10T23:18:12Z,"any computations required to initialise the global attributes are done in this constructor, similar to the other existing assignors",0,0.9941549897193909
1290766391,14182,rreddy-22,2023-08-10T23:20:13Z,done,0,0.8682363629341125
1290813322,14182,jeffkbkim,2023-08-11T01:14:50Z,"`nummemberswithextrapartition` : number of members to get the extra partition, no? there is no expected vs. actual though, we always distribute that number",0,0.9946926236152649
1290813753,14182,jeffkbkim,2023-08-11T01:16:00Z,"it is implied by the type that the previous owners are keyed by topicidpartition. like how we are using `potentiallyunfilledmembers`, `unfilledmembers`, or `newassignment`",0,0.9949308037757874
1290880471,14182,rreddy-22,2023-08-11T04:25:37Z,"its typically called as assignor.build so i thought that makes it kinda clear that its building the assignment, and the return value also specifies the same",0,0.9743112921714783
1290880628,14182,rreddy-22,2023-08-11T04:25:58Z,"changed a few of them, rest we discussed on call",0,0.9857482314109802
1291715874,14182,jeffkbkim,2023-08-11T19:39:09Z,nit: `alltopicidpartitions` and newline each argument,0,0.9951775074005127
1291716306,14182,jeffkbkim,2023-08-11T19:39:46Z,nit: allsubscriptionsequal,0,0.9921340942382812
1291718703,14182,jeffkbkim,2023-08-11T19:43:22Z,"nit: ``` public groupassignment assign( assignmentspec assignmentspec, subscribedtopicdescriber subscribedtopicdescriber ) throws partitionassignorexception {",0,0.9903751015663147
1291718960,14182,jeffkbkim,2023-08-11T19:43:43Z,nit: new line each argument,0,0.989794909954071
1291724906,14182,jeffkbkim,2023-08-11T19:52:45Z,this and `parttiionracks` can be initialized as empty collections. then we just handle the case where `!membersbyrack.isempty()`,0,0.9940156936645508
1291729367,14182,jeffkbkim,2023-08-11T19:59:06Z,can you explain why we need to create `membersbyrack` then transform it to `memberracks`? can't we just create `memberracks` from the start?,0,0.9940202236175537
1291731843,14182,rreddy-22,2023-08-11T20:02:51Z,yeah my point was that nummemberswithextrapartition sounds like the members already have the extra partition but its actually a number of how many members we expect to have an extra and this number keeps decreasing as we assign the partitions.,0,0.9799823760986328
1291732541,14182,rreddy-22,2023-08-11T20:03:44Z,okay i'll rename it,0,0.9757737517356873
1293887191,14182,jeffkbkim,2023-08-14T19:32:12Z,we can move this to l93 and remove the else block,0,0.9939224123954773
1293887893,14182,jeffkbkim,2023-08-14T19:33:01Z,"can we use `this.classvariable = ...` for all the class scoped variables in the constructor? also, don't we get a nosuchelementexception if the iterator is empty? (do we test this case) lastly, we can just use the first member's subscribed topic ids because we know all members are subscribed to the same topics right?",0,0.9940326809883118
1293888288,14182,jeffkbkim,2023-08-14T19:33:30Z,do we need this variable?,0,0.995006799697876
1293889620,14182,jeffkbkim,2023-08-14T19:35:13Z,i think a debug log should suffice. logs will get flooded if a topic metadata changes,0,0.9846240282058716
1293893418,14182,jeffkbkim,2023-08-14T19:38:31Z,should we move this to the top of the method?,0,0.9944435954093933
1293898405,14182,jeffkbkim,2023-08-14T19:42:34Z,can we use `minquota = totalpartitionscount / numberofmembers;` and do we need to declare and initialize separately?,0,0.9949315190315247
1293910818,14182,jeffkbkim,2023-08-14T19:57:07Z,do we need this? we can iterate through a set,0,0.9920141100883484
1293913755,14182,jeffkbkim,2023-08-14T20:00:36Z,we can remove the parentheses,0,0.9940853118896484
1294009242,14182,jeffkbkim,2023-08-14T22:00:23Z,"this will iterate through the entire list. let's instead use a set to store subscriptions. also, if the subscription list does not contain the topic id, should we throw an illegal state exception? every topic id from the assigned partitions should exist in the subscription list right",0,0.9916892051696777
1294021888,14182,jeffkbkim,2023-08-14T22:19:36Z,"how's `retainedcurrentassignment`? in kafka, we don't use `get` in method names.",0,0.9935044050216675
1294034638,14182,jeffkbkim,2023-08-14T22:42:29Z,`k` --> `__`,0,0.963296115398407
1294037874,14182,jeffkbkim,2023-08-14T22:47:31Z,ditto,0,0.9754701256752014
1294047232,14182,jeffkbkim,2023-08-14T23:07:04Z,can we `continue` here instead of using `assigned` variable?,0,0.9947985410690308
1294051623,14182,jeffkbkim,2023-08-14T23:16:44Z,let's use streams api when possible [code block],0,0.9957003593444824
1294052212,14182,jeffkbkim,2023-08-14T23:18:06Z,"let's use streams api (foreach, intstream.foreach)",0,0.9946776628494263
1294054650,14182,jeffkbkim,2023-08-14T23:23:29Z,"this is implying we will be assigning an extra partition for this member right? how come we don't ""assign"" it here?",0,0.9889434576034546
1294062365,14182,jeffkbkim,2023-08-14T23:40:50Z,why can't we just create a new arraylist and add the ones where count > 0?,0,0.9891975522041321
1294064001,14182,jeffkbkim,2023-08-14T23:44:19Z,you can use getordefault,0,0.9937357306480408
1294068788,14182,jeffkbkim,2023-08-14T23:55:16Z,assignpartitiontomemberandupdateunfilledmembers it's hard to assume the side effects when looking at the existing name,0,0.9866819381713867
1294068919,14182,jeffkbkim,2023-08-14T23:55:35Z,i think we can use map#compute here right,0,0.9883372187614441
1294069200,14182,jeffkbkim,2023-08-14T23:56:10Z,we can break out of the for loop instead of using assigned here,0,0.993572473526001
1294076876,14182,jeffkbkim,2023-08-15T00:14:57Z,why do we need to remove here,0,0.9900456070899963
1294086512,14182,jeffkbkim,2023-08-15T00:38:49Z,"what i don't like about this approach is that the reader needs to know 2 things: 1. unfilledmembers (member -> remaining partition count) only exists when the count is > 0. 2. assignpartitiontomember removes a member from unfilledmembers if the count is 0 after decrementing or else we don't know whether this for loop will end. also i have not seen a for loop where we add something to the original collection we are iterating through. i think `while (!queue.isempty())` should be more readable. also, if there is a bug somewhere and for some reason the sum of all unfilledmembers` partition counts is greater than sortedpartitions size then we could have an infinite loop since there will be a member that still needs partitions to be assigned. we should add this check somewhere",-1,0.6988757848739624
1294086912,14182,jeffkbkim,2023-08-15T00:39:55Z,do we need this?,0,0.9930108189582825
1294086965,14182,jeffkbkim,2023-08-15T00:40:02Z,do we need this?,0,0.9930108189582825
1294087718,14182,jeffkbkim,2023-08-15T00:42:11Z,ditto on using continue,0,0.9874287247657776
1294087923,14182,jeffkbkim,2023-08-15T00:42:45Z,how come we iterate on unfilledmembers instead of roundrobinmembers as in `rackawarerounrobinassignment`? this looks like a bug; can we add a test that breaks this,0,0.9893031120300293
1294088129,14182,jeffkbkim,2023-08-15T00:43:19Z,ditto on using a while loop,0,0.9877015948295593
1295197016,14182,rreddy-22,2023-08-15T22:21:32Z,changed to something else,0,0.9361104965209961
1295198962,14182,rreddy-22,2023-08-15T22:22:32Z,this shouldn't even happen at all so that's why its a warning. this case is handled by the target assignment builder,0,0.974918782711029
1296343128,14182,jeffkbkim,2023-08-16T19:31:45Z,"if a topic is deleted, how does the target assignment builder handle it?",0,0.9911841154098511
1300462035,14182,rreddy-22,2023-08-21T17:52:49Z,"collections.emptymap is immutable though right, ig a better option would be to initliaze them as new hashmaps",0,0.990706741809845
1300620312,14182,rreddy-22,2023-08-21T20:36:34Z,"we check if rack aware assignment is possible i.e if partition racks and member racks exist and whether there's any intersection between the two sets, only then we assign the memberracks which is final.",0,0.9945255517959595
1300622597,14182,rreddy-22,2023-08-21T20:39:02Z,the code actually does just use the first members subscribed topic ids,0,0.9958611130714417
1300627015,14182,rreddy-22,2023-08-21T20:44:16Z,"that depends if the members map can be empty i guess which i think is checked before, it definitely can't be null",0,0.9864657521247864
1300631692,14182,rreddy-22,2023-08-21T20:50:14Z,"if a topic is deleted then it's basically the case where the topic doesn't exist in the topic metadata, it is just simply left off the subscription list before its sent to the assignor.",0,0.9900853633880615
1300633100,14182,rreddy-22,2023-08-21T20:52:07Z,we can't cause we might remove topics from the list just in case there's members subscribed to topics that don't exist in the topic metadata,0,0.9855095744132996
1300633833,14182,rreddy-22,2023-08-21T20:53:05Z,i wanted to keep them in just to segregate the replicaracks parts,0,0.9736422896385193
1300637770,14182,rreddy-22,2023-08-21T20:58:04Z,"not necessarily, since there could be partitions belonging to old subscriptions or topics that don't exist anymore and we don't need them anymore aka they're not valid anymore which is fine. mentioned in the javadoc",0,0.9869846105575562
1300779466,14182,rreddy-22,2023-08-22T00:25:27Z,"its not retained cause we didn't decide if we wanna keep it yet, that's decided in assignstickypartitions. this is just getting the valid assignment in terms of if the partitions are still part of the subscription topics and also if the racks don't match then we just store the prev owner info for the future",0,0.9873130917549133
1300780584,14182,rreddy-22,2023-08-22T00:27:40Z,i don't understand what's the change?,-1,0.7167691588401794
1303273451,14182,rreddy-22,2023-08-23T16:29:35Z,"so there's potentially unfilled members which includes members that have remaining number of partitions to receive as >=0, i.e there could be members that have met the quota but are eligible to receive an extra partition. what i'm doing in this step is increasing the remaining count if there's still a possibility that a member could receive an extra partition. if the remaining count is still > 0 after that we add it to the unfilled members list.",0,0.9924821257591248
1303299811,14182,rreddy-22,2023-08-23T16:54:38Z,"isn't it kinda expected that if i assign a partition to a member from the unfilled map and the remaining value is updated aka reduced by 1, and it's removed from the map if it isn't unfilled anymore.",0,0.9782556891441345
1303309866,14182,rreddy-22,2023-08-23T17:04:30Z,"i still have to update the rr members after assigning the partition, i can't break within this if statement right.",0,0.9908654093742371
1305945556,14182,rreddy-22,2023-08-25T17:26:18Z,discussed offline that this isn't possible,0,0.9846200942993164
1305948679,14182,rreddy-22,2023-08-25T17:29:41Z,we can't use continue cause there's multiple other steps after that which need to be executed before we exit the loop,0,0.966037929058075
1305956396,14182,rreddy-22,2023-08-25T17:37:07Z,"we are iterating over the roundrobin members, we're just using the size of all the unfilled members so that we do at least n number of iterations",0,0.9898840188980103
1305957286,14182,rreddy-22,2023-08-25T17:37:44Z,discussed offline that this isn't possible,0,0.9846200942993164
1305998324,14182,rreddy-22,2023-08-25T18:13:40Z,while loop instead of for loop?,0,0.9905023574829102
1308056437,14182,jeffkbkim,2023-08-28T23:42:28Z,can we keep rangeassignor changes in a separate pr?,0,0.9949681162834167
1308059442,14182,jeffkbkim,2023-08-28T23:49:03Z,what if the collections are out of order? can we add a test case for this,0,0.9874163866043091
1308060754,14182,jeffkbkim,2023-08-28T23:51:42Z,javadocs,0,0.9870727062225342
1308061244,14182,jeffkbkim,2023-08-28T23:52:48Z,"let's add javadocs for all of the methods below. also, can there be a case where any of the parameters are null? collections#disjoint can throw npe",0,0.9947007894515991
1308061768,14182,jeffkbkim,2023-08-28T23:54:00Z,nit: totopicidpartitions,0,0.987473726272583
1308061977,14182,jeffkbkim,2023-08-28T23:54:26Z,nit: topicidpartitions,0,0.980496346950531
1308062300,14182,jeffkbkim,2023-08-28T23:55:04Z,change k to __,0,0.992731511592865
1308062948,14182,jeffkbkim,2023-08-28T23:56:30Z,topics,0,0.9530820846557617
1308068063,14182,jeffkbkim,2023-08-29T00:08:19Z,how's [code block] this aligns with the parameters in userackawareassignment,0,0.994184672832489
1308072483,14182,jeffkbkim,2023-08-29T00:18:02Z,"i think we can do the following here: when initializing membersbyrack in l152, also initialize memberracks. then only set memberracks to collections.emptymap if userackawareassignment is false. then we don't have to do this transformation",0,0.9778984189033508
1308073563,14182,jeffkbkim,2023-08-29T00:20:43Z,nit: memberrack,0,0.9878048896789551
1308074883,14182,jeffkbkim,2023-08-29T00:23:59Z,"can you help me understand which part is rack-aware manner? also, can we add a test case for this?",0,0.9945464134216309
1308075407,14182,jeffkbkim,2023-08-29T00:25:09Z,this looks to be an exact copy of clients/common. can we move that instead?,0,0.9944513440132141
1308077282,14182,jeffkbkim,2023-08-29T00:29:12Z,do we need this change in this pr?,0,0.9949386119842529
1308077407,14182,jeffkbkim,2023-08-29T00:29:30Z,what's this change for?,0,0.9841262102127075
1308077660,14182,jeffkbkim,2023-08-29T00:30:06Z,"nit: we can remove kafka also, can we move this to buildassignment() and direct the reader to the method to see the step by step?",0,0.9945384860038757
1308079903,14182,jeffkbkim,2023-08-29T00:35:27Z,"nit: track it ""as the partition's"" prior owner",0,0.9945887327194214
1308081089,14182,jeffkbkim,2023-08-29T00:38:29Z,i'm wondering whether to have a userackawarestrategy field in rackinfo instead so that we don't have to infer this information here.,0,0.9640530347824097
1308081761,14182,jeffkbkim,2023-08-29T00:39:56Z,"actually, i think we should throw an illegal state exception. since this is not expected to happen",0,0.912898600101471
1308082801,14182,jeffkbkim,2023-08-29T00:42:39Z,why can't we do `final int minquota = totalpartitionscount / numberofmembers;`?,0,0.9934800863265991
1308083274,14182,jeffkbkim,2023-08-29T00:43:51Z,`assignmentspec.members().keyset().foreach(memberid -> ...`,0,0.9932124614715576
1308085281,14182,jeffkbkim,2023-08-29T00:48:43Z,nit: assignedstickypartitions,0,0.9753595590591431
1308086816,14182,jeffkbkim,2023-08-29T00:52:39Z,should we add a debug log indicating that the topic no longer exists in the metadata?,0,0.9937292337417603
1308086969,14182,jeffkbkim,2023-08-29T00:53:04Z,we can move the parentheses around (partition),0,0.9931831955909729
1308087850,14182,jeffkbkim,2023-08-29T00:55:05Z,we don't need this since retainedpartitionscount will be 0 in l178,0,0.9945212602615356
1308088960,14182,jeffkbkim,2023-08-29T00:57:28Z,"""previous"" step might not even need this comment. perhaps ""assign the extra partition if possible"" or something along those lines",0,0.9848427772521973
1308089767,14182,jeffkbkim,2023-08-29T00:59:28Z,nit: assignedstickypartitions,0,0.9753595590591431
1308090172,14182,jeffkbkim,2023-08-29T01:00:20Z,"personally, the word ""all"" does not add much value to variable names. how's `sortedtopics` also, what's the benefit of sorting the topics?",0,0.9889259934425354
1308091012,14182,jeffkbkim,2023-08-29T01:02:22Z,nit: can remove parentheses around (topic),0,0.9953851103782654
1308091211,14182,jeffkbkim,2023-08-29T01:02:52Z,we can inline partitioncount in l377,0,0.9947086572647095
1308093254,14182,jeffkbkim,2023-08-29T01:08:18Z,how's unassignedpartitionssizeequalsremainingassignments,0,0.9926962852478027
1308095670,14182,jeffkbkim,2023-08-29T01:13:56Z,"nit: ""sort"" and ""potential members""",0,0.9930410385131836
1308097288,14182,jeffkbkim,2023-08-29T01:17:54Z,is this a linked list?,0,0.9941786527633667
1308098707,14182,jeffkbkim,2023-08-29T01:19:55Z,`while(!roundrobinmembers.isempty() && !assigned)` is more readable since most for loops do not change the size,0,0.9904289245605469
1308102973,14182,jeffkbkim,2023-08-29T01:28:55Z,ah right. that makes sense,0,0.9478670358657837
1308137334,14182,rreddy-22,2023-08-29T02:48:14Z,"lets decide what to do here cause i've also asked david multiple times, i think he said a warning is enough let me double check",0,0.9726789593696594
1308140708,14182,rreddy-22,2023-08-29T02:55:31Z,i feel like a whole pr for minor changes which are kinda related to what i learn from doing the other assignors would be unnecessary especially cause even minor ones take time to go through the review process and stuff. they might just go undone,-1,0.6926800012588501
1308143447,14182,rreddy-22,2023-08-29T03:01:34Z,"that's kinda why i used list/set before but i changed it to collections on receiving comments on the interface. but that's a good point, i'll make sure the order doesn't matter",1,0.7900055646896362
1308150557,14182,rreddy-22,2023-08-29T03:18:54Z,"no they can't be null, they are all initialized in rackinfo",0,0.9910167455673218
1308150974,14182,rreddy-22,2023-08-29T03:19:52Z,"i named the method alltopicidpartitions to emphasize that its not a subset, so i feel like we can leave this as alltopicidpartitions as well",0,0.9891396164894104
1308151486,14182,rreddy-22,2023-08-29T03:21:17Z,renamed to alltopicids,0,0.9841120839118958
1308152462,14182,rreddy-22,2023-08-29T03:23:48Z,agreed but memberracks and partitionracks are more readable and concise i guess in my opinion so i would leave it like this,0,0.9308944344520569
1308155008,14182,rreddy-22,2023-08-29T03:30:00Z,its a final attribute that why can't assign it twice and i feel like what's the point of initializing it before hand if i'm doing it in an if else block later which guarantees initialization,0,0.798481285572052
1308164291,14182,rreddy-22,2023-08-29T03:52:16Z,i don't think i understand the question,0,0.7748438119888306
1308165291,14182,rreddy-22,2023-08-29T03:54:34Z,"it's not haha i would've used that otherwise, this has partition as an integer whereas that has topicpartition (another class) as the attribute in addition to topic id",1,0.9708533883094788
1308165924,14182,rreddy-22,2023-08-29T03:55:52Z,yes because we decided how we want to handle the non existent topic case in this pr and hence this is just a side effect of that,0,0.9880856275558472
1308166084,14182,rreddy-22,2023-08-29T03:56:13Z,"this just keeps happening idky, ignore this file we have to force push it in the end",-1,0.8849394917488098
1308167128,14182,rreddy-22,2023-08-29T03:58:46Z,"i feel like the code pattern has always been to explain what the assignor does at the top instead of at assign/build, and since this is basically the main function of the assignor, it shouldn't make a difference if its at the top explaining what the optimized uniform assignment builder does",0,0.9484673738479614
1308167658,14182,rreddy-22,2023-08-29T03:59:51Z,"since we mentioned partition's up front in the sentence it makes sense that from then onwards ""it"" always refers to the partition",0,0.9897351264953613
1308169146,14182,rreddy-22,2023-08-29T04:03:11Z,makes sense,0,0.9718289375305176
1308171085,14182,rreddy-22,2023-08-29T04:07:48Z,all is mentioned to emphasize that it's all of the members assigned sticky partitions,0,0.9929363131523132
1308172074,14182,rreddy-22,2023-08-29T04:10:08Z,it actually means that the topic is no longer subscribed to by the group but yes that also translates into not being in the topic metadata sometimes,0,0.9909194707870483
1308173102,14182,rreddy-22,2023-08-29T04:12:34Z,why will it be zero?,0,0.9768832921981812
1308173397,14182,rreddy-22,2023-08-29T04:13:20Z,"i feel like its very hard to understand without this comment, just for the sake of anyone trying to understand why i used that index for the extra partition i would leave it in",-1,0.9777082800865173
1308174183,14182,rreddy-22,2023-08-29T04:15:04Z,replied before,0,0.9929336309432983
1308174694,14182,rreddy-22,2023-08-29T04:16:12Z,"all means every single topic right, if it was just sorted topics, which/whose topics?",0,0.990053117275238
1308177084,14182,rreddy-22,2023-08-29T04:21:48Z,it makes sure that all the unassigned partitions are present topic wise and then when we do a rr distribution while assigning these partitions they are distributed more evenly by topic as well,0,0.9927540421485901
1308179490,14182,rreddy-22,2023-08-29T04:26:47Z,total again emphasizes that i'm talking about all the unassigned partitions and all the remaining assignments right? and also since it returns a boolean value doesn't is make sense still,0,0.9903507828712463
1308181709,14182,rreddy-22,2023-08-29T04:31:34Z,"i don't want the loop to run until the roundrobinmembers list is empty though, this could cause an infinite loop. i just want it to go through every member at the very least and then if it doesn't find a member that is suitable then we just move on and the partition might get assigned later",0,0.9774516224861145
1309478048,14182,jeffkbkim,2023-08-30T00:36:34Z,you can't change what's stored in an empty map but you can change which map the variable points to. though it seems fine in this case since we are using streams api and need a final variable,0,0.992520809173584
1309478864,14182,jeffkbkim,2023-08-30T00:38:35Z,space after `this.`,0,0.9800097346305847
1309479632,14182,jeffkbkim,2023-08-30T00:40:16Z,this can get npe if the members is empty right?,0,0.9949756860733032
1309481820,14182,jeffkbkim,2023-08-30T00:45:47Z,that seems like a big assumption; let's at least add something to the javadocs,0,0.9539252519607544
1309482536,14182,jeffkbkim,2023-08-30T00:47:07Z,can you remind me again why we need to do at least n number of iterations?,0,0.9940462112426758
1309482922,14182,jeffkbkim,2023-08-30T00:48:08Z,ok,0,0.9233372807502747
1309487439,14182,jeffkbkim,2023-08-30T00:57:49Z,"on i don't see which part is ""in a rack-aware manner"" in the code. can we test that the sorting happens as expected",0,0.9859805107116699
1309488516,14182,jeffkbkim,2023-08-30T01:00:25Z,"ah i see. i'm still leaning towards reusing that one, but will leave it up for david to decide",0,0.9319540858268738
1309488929,14182,jeffkbkim,2023-08-30T01:01:19Z,we should probably fix this..,0,0.9790564775466919
1309489359,14182,jeffkbkim,2023-08-30T01:02:29Z,we have the step by step details at `assign()` for the range assignor right,0,0.9950101375579834
1309492110,14182,jeffkbkim,2023-08-30T01:06:29Z,"i meant if currentassignmentsize is 0, then retainedpartitionscount will be 0 and hence we won't iterate anyways",0,0.9874809384346008
1309493644,14182,jeffkbkim,2023-08-30T01:08:40Z,"not sure why i left this comment, can disregard",0,0.5790535807609558
1309498804,14182,jeffkbkim,2023-08-30T01:16:13Z,"that would make sense if we are using collections that form a subset of all topics somewhere in the code. otherwise it seems redundant i'm not sure i follow. even if the topics weren't sorted, we would still ensure unassigned partitions are present, no? what makes them distribute more evenly?",0,0.9491804242134094
1309500746,14182,jeffkbkim,2023-08-30T01:19:20Z,"""is __ equals __"" is not grammatically correct. if we want to, we can do `is __ equal to __` but i felt that was too long. do we ever have a case where we handle a subset of unassigned partitions? even the variable is called unassignedpartitions",0,0.9427735805511475
1309503692,14182,jeffkbkim,2023-08-30T01:23:50Z,the while loop will still iterate through all members at the very least right? since we poll one every iteration can you help me understand why the while loop can be infinite whereas the for loop cannot?,0,0.9912104606628418
1309504407,14182,jeffkbkim,2023-08-30T01:24:47Z,can we add a test case?,0,0.9952530860900879
1309505394,14182,jeffkbkim,2023-08-30T01:26:18Z,seems like you've changed this to a set. is the comment above still valid?,0,0.991233766078949
1310726962,14182,jeffkbkim,2023-08-30T19:28:56Z,`if (unfilledmembers.containskey(memberid)`,0,0.9953188300132751
1310733452,14182,jeffkbkim,2023-08-30T19:35:51Z,"there are 2 cases i'm concerned about: 1. i == unfilledmembers.size() but roundrobinmembers is not empty. this means we still have members to distribute 2. roundrobinmembers.size() < unfilledmembers.size(): we'll get npe. these 2 cases may not happen in practice, but the code makes it seem they might. this makes it hard to read and reason about.",-1,0.8161677718162537
1310797271,14182,jeffkbkim,2023-08-30T20:41:10Z,nit: (member -> ...,0,0.6928553581237793
1310803310,14182,jeffkbkim,2023-08-30T20:47:16Z,"this looks like overkill and i don't think this works. for instance, if `totalassignmentsizesofallmembers.get(i)` keeps increasing by 1, we can have first member start off with 1 then the last member end with 100 if monotonically increasing. can we do a single iteration and track the maximum and minimum size? then we can do `asserttrue((max - min) <= 1)` right for ""partition assigned at most one member"", we can have a map and increment it. then after looping we just check whether the number of topic id partitions equals number of members and that each value is 1 i also wonder if we can add this check to uniformassignor, and run this at the end of `buildassignment()`. then the general assignor can also use this to see if it needs to do another iteration. we will need to add test cases for this",-1,0.8700735569000244
1310837682,14182,jeffkbkim,2023-08-30T21:19:41Z,"to confirm my understanding: 1. we assign t1p1 and t2p1 to memberb since they have rack info 2. roundrobin the rest (unassignedpartitions, starting with t1p0) is this correct?",0,0.9935961961746216
1310840406,14182,jeffkbkim,2023-08-30T21:22:35Z,"should we also check rack awareness? (if both partition and member rack exists, check they match)",0,0.9945729374885559
1310843247,14182,jeffkbkim,2023-08-30T21:25:49Z,we should assert computed assignment here,0,0.9957797527313232
1310843639,14182,rreddy-22,2023-08-30T21:26:13Z,"cause we want to iterate through/visit every member at least once, n is the number of members.",0,0.9911612272262573
1310845118,14182,jeffkbkim,2023-08-30T21:27:42Z,"i think ""n members m topics"" is understandable and simple. i've noticed other tests follow ""n members subscribed to m topics"". can we unify the format?",0,0.5913525223731995
1310846978,14182,rreddy-22,2023-08-30T21:29:45Z,"its just different formatting and every time i push any changes this file gets modified, i'll change it directly in the end",0,0.97920161485672
1310868257,14182,jeffkbkim,2023-08-30T21:51:30Z,"is membera assigned t1p0 and t2p0 because there is a replica for t1p0 and t2p0 that have ""rack1""? (from mkmapofpartitionracks) i'm just wondering what the assignment would be if we actually did a successful first assignment where a was in rack1 and b was in rack2.",0,0.9881928563117981
1310869571,14182,jeffkbkim,2023-08-30T21:53:06Z,"t1p0 and t2p0 technically have racks in ""rack1"" right? so they should be both assigned to member b but already met its quota?",0,0.9906013011932373
1310880384,14182,jeffkbkim,2023-08-30T22:04:57Z,"no, we could have removed members from unfilledmembers in the if block above. and if we do so, we would also remove them from roundrobinmembers. since they start with the same members, they will end up with the same members",0,0.9917253255844116
1310892402,14182,rreddy-22,2023-08-30T22:20:42Z,"yeah that's true sorry idr when i changed it, i'll move it",-1,0.9918210506439209
1310897847,14182,rreddy-22,2023-08-30T22:28:40Z,but this is for when currentassignmentsize is non zero,0,0.9946144223213196
1310903635,14182,rreddy-22,2023-08-30T22:36:50Z,"distribute evenly topic wise as well, as in if i distributed partitions in random order its possible that all the partitions from a single topic go to one member only, if i rr a list that goes topic wise i'm distributing each topics partitions evenly",0,0.9916433095932007
1310906983,14182,rreddy-22,2023-08-30T22:41:32Z,"got it, changed it",0,0.9549422264099121
1310919719,14182,rreddy-22,2023-08-30T22:55:28Z,"because we keep adding members back to the round robin queue until the remaining partitions to be received by the member hits 0. therefore, the roundrobinmembers queue will never be empty unless all the partitions are assigned/ all the quotas are met.",0,0.9928701519966125
1310920650,14182,rreddy-22,2023-08-30T22:56:41Z,here we might assign all the partitions that have matching racks but there's gonna be other partitions that haven't been assigned yet and therefore the remaining number of partitions to be received by members may not have reached zero yet.,0,0.9635803699493408
1310923371,14182,rreddy-22,2023-08-30T23:00:26Z,can members be empty?,0,0.9906963109970093
1310930694,14182,rreddy-22,2023-08-30T23:11:59Z,the efficiency is the same right? this shows that remaining is greater than zero. i also feel like its safer just incase we have any members with negative or 0 value as remaining,0,0.9892193675041199
1310941152,14182,rreddy-22,2023-08-30T23:28:53Z,its 300 partitions and 50 members xd,0,0.9886391162872314
1310948792,14182,rreddy-22,2023-08-30T23:40:20Z,cools i'll double check,0,0.9929613471031189
1310952891,14182,rreddy-22,2023-08-30T23:49:29Z,"yes that's correct, a is rack1 and p0 belongs to rack1",0,0.9917619228363037
1310961579,14182,rreddy-22,2023-08-31T00:03:21Z,"i think i might have to redo this example, thanks for the catch!",1,0.9806525707244873
1312351774,14182,jeffkbkim,2023-08-31T22:33:16Z,"if there's no pattern, can we change the name to testvalidityandbalanceforlargesampleset?",0,0.9932812452316284
1312392393,14182,rreddy-22,2023-08-31T23:49:36Z,"the test is correct if we let go of the fact that the current assignment wasn't done by this assignor, but with whatever information the assignor got, the behavior was as expected",0,0.9876964688301086
1312392493,14182,rreddy-22,2023-08-31T23:49:50Z,changed the current assignment to what this assignor would've returned,0,0.9912274479866028
1312392605,14182,rreddy-22,2023-08-31T23:50:05Z,explained offline,0,0.9826735854148865
1312609650,14182,rreddy-22,2023-09-01T06:07:33Z,"well since we check the exact assignment for each member, when i was writing the exact partitions i made sure that the racks are matching so i feel like that is checked there already. to write a check again we would have to do quite some steps since its not guaranteed that every partition assigned to a member has a matching rack even if both partition and member racks exist",0,0.9832087159156799
1312610747,14182,rreddy-22,2023-09-01T06:09:10Z,yes,0,0.9686408638954163
1312612036,14182,rreddy-22,2023-09-01T06:11:09Z,1) this part specifically was taken from the client assignor so we know it works. 2) this can't work for the general assignor cause the definition of balance will not remain the same. in general assignor the min and max could have a larger difference and it would still be the most balanced possible,0,0.9816965460777283
1312613499,14182,rreddy-22,2023-09-01T06:13:28Z,the total assignment size can't keep increasing by 1 ever xd total partitions divided by total members is how many they'll each have and at most some of them will get 1 extra partition,0,0.9885901808738708
1312619017,14182,rreddy-22,2023-09-01T06:22:01Z,"nummembersbypartition is a map that's part of the rack info which tracks how many members are in the same rack as the partition. the sum of those members is used to sort them right, that's the ""rack aware manner"". sorting happens as expected since i put in print statements to verify them but also without that the assignments wouldn't be as expected and we do a 1:1 check on every assignment in the test cases",0,0.9886124730110168
1312623868,14182,rreddy-22,2023-09-01T06:29:08Z,"1) it doesn't matter if round robin members is not empty, we're doing this by partition so it's very possible that after iterating through the list many members are yet to receive partitions. the only time round robin members will be empty/there's no more members that need partitions is for the last partition.",0,0.982314944267273
1312624721,14182,rreddy-22,2023-09-01T06:30:23Z,"unless round robin members is empty how will we get a npe, we would keep polling and adding it back right even if its just one member",0,0.9869706630706787
1312625110,14182,rreddy-22,2023-09-01T06:30:53Z,anyways i changed it to round robin members size just like the rack aware round robin,0,0.9887829422950745
1312625675,14182,rreddy-22,2023-09-01T06:31:40Z,it is in the javadoc,0,0.9932324886322021
1312625983,14182,rreddy-22,2023-09-01T06:32:03Z,"* if the member has met their allocation quota, the member is removed from the * tracking map of members with their remaining allocations. * otherwise, the count of remaining partitions that can be assigned to the member is updated.",0,0.9927452206611633
1313213976,14182,jeffkbkim,2023-09-01T15:59:03Z,can we just use subscriptionset instead of subscriptionlist? it doesn't seem like we need a list to do any of the other operations.,0,0.9887807369232178
1313281824,14182,jeffkbkim,2023-09-01T16:50:11Z,"the `&& !assigned` part would prevent the infinite loop, no?",0,0.9937461614608765
1313283639,14182,jeffkbkim,2023-09-01T16:52:33Z,"no, unless we have a bug. can we add a check in assign() and throw illegal argument exception if members is empty?",0,0.9838125705718994
1313292815,14182,jeffkbkim,2023-09-01T17:01:15Z,that makes sense,0,0.982693612575531
1313294383,14182,jeffkbkim,2023-09-01T17:02:37Z,"thanks, that makes sense",1,0.5199136734008789
1313393423,14182,jeffkbkim,2023-09-01T18:41:47Z,discussed offline. makes sense,0,0.9891712069511414
1313408646,14182,jeffkbkim,2023-09-01T19:02:23Z,this can be resolved,0,0.994145393371582
1313434102,14182,jeffkbkim,2023-09-01T19:33:18Z,"that makes sense -- i forgot we're checking each member. still, i think it's possible to check the balancedness without a nested for loop. not sure if that affects the validity part",0,0.9787793755531311
1313436894,14182,jeffkbkim,2023-09-01T19:36:10Z,nit: `foreach(partition -> {`,0,0.9923237562179565
1313437179,14182,jeffkbkim,2023-09-01T19:36:28Z,nit: foreach(partition ->,0,0.9922652244567871
1313439928,14182,jeffkbkim,2023-09-01T19:39:17Z,nit: javadocs,0,0.9916862845420837
1313441197,14182,jeffkbkim,2023-09-01T19:40:29Z,can we put the arguments into new lines?,0,0.9940595626831055
1313442250,14182,jeffkbkim,2023-09-01T19:41:29Z,nit: [code block],0,0.9919844269752502
1313442609,14182,jeffkbkim,2023-09-01T19:41:50Z,nit: [code block],0,0.9919844269752502
1313443677,14182,jeffkbkim,2023-09-01T19:43:00Z,indentation looks off. [code block],0,0.7345854043960571
1313444165,14182,jeffkbkim,2023-09-01T19:43:30Z,nit: [code block],0,0.9919844269752502
1313444928,14182,jeffkbkim,2023-09-01T19:44:18Z,indentation looks off. [code block],0,0.7345854043960571
1313445794,14182,jeffkbkim,2023-09-01T19:45:13Z,let's split this [code block],0,0.993501603603363
1313448367,14182,jeffkbkim,2023-09-01T19:47:52Z,"makes sense, let's leave it as is",0,0.9791702032089233
1315178473,14182,rreddy-22,2023-09-04T19:46:52Z,"as discussed on call, i added a check in the assign method instead",0,0.9956364035606384
1315178560,14182,rreddy-22,2023-09-04T19:47:07Z,done,0,0.8682363629341125
1315178781,14182,rreddy-22,2023-09-04T19:47:52Z,added check but i don't think we need to throw an illegal state exception,0,0.9772931933403015
1315178928,14182,rreddy-22,2023-09-04T19:48:32Z,we could but since we're checking for validity anyways we can leave it,0,0.9868285059928894
1315500509,14182,dajac,2023-09-05T07:41:53Z,nit: `log` -> `log` as this is a constant.,0,0.9931471943855286
1315500739,14182,dajac,2023-09-05T07:42:04Z,nit: we can remove this empty line.,0,0.9919142723083496
1315501863,14182,dajac,2023-09-05T07:42:59Z,nit: `log` -> `log`.,0,0.9851559400558472
1315502677,14182,dajac,2023-09-05T07:43:41Z,could we please add javadoc to all the attributes? we have been doing this for all the new code in this module so we should continue.,0,0.995751142501831
1315507070,14182,dajac,2023-09-05T07:47:13Z,nit: do we need to define `userackawarestrategy` as an attribute if we can get it from `rackinfo.userackstrategy`? we could perhaps have a method instead.,0,0.9877235889434814
1315508408,14182,dajac,2023-09-05T07:48:17Z,nit: there is an space between the `*`.,0,0.9913328289985657
1315509745,14182,dajac,2023-09-05T07:49:20Z,i suppose that we assume that we cannot get here if members is empty. is this correct?,0,0.9913614392280579
1315511582,14182,dajac,2023-09-05T07:50:52Z,i think that we should directly throw the illegalstateexception. it is a bit weird to construct it to wrap it in another one right away.,-1,0.9309778809547424
1315512642,14182,dajac,2023-09-05T07:51:49Z,this comment is incorrect as the implementation fails if the topic does not exist.,0,0.9512951374053955
1315513303,14182,dajac,2023-09-05T07:52:22Z,could this be final as well?,0,0.9913731217384338
1315529530,14182,dajac,2023-09-05T08:04:38Z,nit: `log` -> `log`.,0,0.9851559400558472
1315531958,14182,dajac,2023-09-05T08:06:51Z,is using an hashset necessary here? we could perhaps use `firstsubscriptionset.containsall(memberspec.subscribedtopicids())`. would it work?,0,0.9944936633110046
1315558356,14182,dajac,2023-09-05T08:28:24Z,"is there a reason to have this abstract class here? personally, i find it a bit weird as the concrete classes are not defined in this class. how about extracting it?",-1,0.97242671251297
1315560818,14182,dajac,2023-09-05T08:30:26Z,nit: javadoc.,0,0.9931857585906982
1315804029,14182,dajac,2023-09-05T12:09:33Z,nit: could this method be static?,0,0.9875215888023376
1315804175,14182,dajac,2023-09-05T12:09:42Z,ditto.,0,0.9384599328041077
1315805497,14182,dajac,2023-09-05T12:10:55Z,nit: do we really need to create the arraylist here?,0,0.9883785843849182
1315808858,14182,dajac,2023-09-05T12:14:13Z,we already have the very same class in the `metadata` module. i wonder if we should move that one to `server-common` module so that we could reuse it here. it could land in the `common` package over there. what do you think?,0,0.9859630465507507
1315811048,14182,dajac,2023-09-05T12:16:15Z,nit: could we keep the previous code and use `getordefault` instead of `get`? the code would be more concise...,0,0.9835542440414429
1315814176,14182,dajac,2023-09-05T12:19:10Z,nit: we should use `int` here.,0,0.9913890957832336
1315815939,14182,dajac,2023-09-05T12:20:48Z,nit: this code is duplicated. should we have an helper method for it?,0,0.9882550239562988
1315831564,14182,dajac,2023-09-05T12:34:20Z,nit: we can remove ` `.,0,0.9923931360244751
1315836673,14182,dajac,2023-09-05T12:38:40Z,shouldn't we keep what we had here?,0,0.9854992628097534
1315836903,14182,dajac,2023-09-05T12:38:52Z,nit: `log` -> `log`.,0,0.9851559400558472
1316096433,14182,rreddy-22,2023-09-05T15:50:54Z,yep i'll raise a different pr for range assignor changes,0,0.9924544095993042
1316390836,14182,rreddy-22,2023-09-05T20:47:41Z,"its not the exact same, that one has topicid mapped to topicpartition here its just the partition number",0,0.9869246482849121
1316396258,14182,rreddy-22,2023-09-05T20:54:00Z,removing this,0,0.9906535744667053
1316406386,14182,rreddy-22,2023-09-05T21:05:56Z,"ack will remove it but we can ignore this file for now since the implementation isn't in yet, just needed the initial template for now to get the conditional implementation of the specific assignment builder based on the subscriptions.",0,0.9869092106819153
1316408646,14182,rreddy-22,2023-09-05T21:08:55Z,yeah correct i added a check in the assign method so its not possible anymore,0,0.9869323372840881
1316429235,14182,rreddy-22,2023-09-05T21:30:10Z,done,0,0.8682363629341125
1316439651,14182,rreddy-22,2023-09-05T21:40:09Z,"yep makes sense i removed it, i thought in the future if we wanted to have a flag in the assignor to switch it on or off",0,0.9808505773544312
1316456003,14182,rreddy-22,2023-09-05T21:55:51Z,i wanted to throw a partition assignor exception since the exception is related to the assignor? can we do that only? or do we have to do just an illegal state exception?,0,0.9842871427536011
1316792230,14182,rreddy-22,2023-09-06T06:24:50Z,which concrete classes? we made it abstract so that any builder that implements this class would need to implement buildassignment which is the main function called within assign,0,0.9942030310630798
1316793219,14182,rreddy-22,2023-09-06T06:26:04Z,i believe it's easier to understand since alltopicidpartitions is a method that returns this list which is used later on no?,0,0.9918711185455322
1316806195,14182,rreddy-22,2023-09-06T06:41:06Z,will do,0,0.9619618058204651
1316955014,14182,dajac,2023-09-06T08:52:10Z,generaluniformassignmentbuilder and optimizeduniformassignmentbuilder. how about extracting abstractassignmentbuilder from uniformassignor and calling it abstractuniformassignmentbuilder?,0,0.9918212890625
1316956874,14182,dajac,2023-09-06T08:53:30Z,i was referring to `new arraylist<>(topicids)`. is creating a new arraylist from the set necessary? alltopicidpartitions could take a collection for instance to avoid it.,0,0.9933677315711975
1316961213,14182,dajac,2023-09-06T08:56:03Z,i was referring to [a link] it is really bad to have two classes with the same name but slightly different. i wonder if we can do something about it...,-1,0.9949532151222229
1317663852,14182,rreddy-22,2023-09-06T18:17:32Z,ohh got it yeah that makes sense,0,0.8657032251358032
1317669213,14182,rreddy-22,2023-09-06T18:23:27Z,"ohh my bad i got this question before so i instinctively replied, i realized i was thinking of the kafka common topicidpartition class but yeah this seems usable, would we need a new pr to move the file though?",-1,0.9901922941207886
1317676113,14182,rreddy-22,2023-09-06T18:30:53Z,"discussed offline, going to throw only partitionassignorexception",0,0.9930253028869629
1319775413,14182,dajac,2023-09-08T11:53:49Z,nit: we usually add an empty line before the javadoc for attributes.,0,0.9924037456512451
1319776220,14182,dajac,2023-09-08T11:54:38Z,nit: should we log at debug level here?,0,0.9925915002822876
1319779160,14182,dajac,2023-09-08T11:58:00Z,nit: empty line can be removed.,0,0.9955105781555176
1319810543,14182,dajac,2023-09-08T12:31:31Z,nit: int?,0,0.9874934554100037
1319811185,14182,dajac,2023-09-08T12:32:12Z,could we elaborate a bit more on why the sorting is important here?,0,0.9914348721504211
1319812206,14182,dajac,2023-09-08T12:33:18Z,i wonder if we could reuse the linked list that we already used in rackawareroundrobinassignment instead of re-creating a new one from scratch. is there a reason why we need it?,0,0.9750127792358398
1319812750,14182,dajac,2023-09-08T12:33:54Z,nit: should this comment be right before `if (unfilledmembers.containskey(memberid)) {`?,0,0.9930214285850525
1319814872,14182,dajac,2023-09-08T12:36:02Z,"is this really necessary? it is a tad annoying to have to compute the sum of all the unfilled members. if you really want to do this, we could perhaps maintain the total count as we update the unfilled members but i am not sure if it is worth it.",-1,0.987779974937439
1319816047,14182,dajac,2023-09-08T12:36:57Z,i was wondering whether we could avoid the copy and just update `potentiallyunfilledmembers`. have you thought about this?,0,0.9858067035675049
1319820875,14182,dajac,2023-09-08T12:41:33Z,"yeah, we can have a separate pr to move that class (and add some javadoc to it). i am actually annoyed by the fact that we have two topicidpartition classes but with different content. one with (id, name, partition) and one with (id, partition). this is really misleading...",-1,0.9938942790031433
1319824362,14182,dajac,2023-09-08T12:45:18Z,nit: could we just keep everything on one line?,0,0.9781046509742737
1319824635,14182,dajac,2023-09-08T12:45:35Z,still there :),0,0.9693350195884705
1320217221,14182,rreddy-22,2023-09-08T18:39:21Z,"i added it as a check to ensure we don't have more partitions to assign and less total required assignments count, i.e. jic our calculations are wrong. its not completely necessary",0,0.9890824556350708
1320220040,14182,rreddy-22,2023-09-08T18:42:10Z,in the comments? or should i explain it here,0,0.9931861162185669
1320220933,14182,rreddy-22,2023-09-08T18:42:58Z,we sort so that the partition with the least number of options for a matching rack member can receive the assignment first.,0,0.9925262928009033
1321023603,14182,rreddy-22,2023-09-11T05:54:15Z,added in the javadoc,0,0.9942598342895508
1321023849,14182,rreddy-22,2023-09-11T05:54:42Z,"rackaware round robin might not be called in every case, it is only called when userackaware strategy is true. i could make it a global attribute maybe but that seems odd since the queue is only used in these two methods.",0,0.7629332542419434
1321024671,14182,rreddy-22,2023-09-11T05:56:05Z,i remember getting comments to keep the comments at the beginning of the loop instead of inside,0,0.9784044623374939
1321033941,14182,rreddy-22,2023-09-11T06:08:17Z,"yeah you're right, it's an unnecessary extra map, i made it a local map, just wanna still keep it separate cause potentially unfilled members also has ones that have met the quota, but unfilled only has those that still need to be assigned partitions, might be hard to understand what types of members we have at each point. lmk if what i did makes sense or if we can optimize it more",0,0.9426799416542053
1321035644,14182,rreddy-22,2023-09-11T06:10:51Z,"yeah that's true i agree, i wasn't sure what else to call this one, okay i will add a new pr for this.",0,0.877537190914154
1325561675,14182,dajac,2023-09-14T08:17:15Z,"small nit: in such case, i usually prefer to put the mutated object first in the list of arguments. then, i would also put memberid, then topicid and finally partition to follow their hierarchy. i would also rename targetassignment to assignment because the method is not tight to a target assignment in the end. it could be any assignment map.",0,0.9844525456428528
1325563579,14182,dajac,2023-09-14T08:18:43Z,"bit: this parenthesis seems misplaced, no?",0,0.9910462498664856
1325598891,14182,dajac,2023-09-14T08:44:47Z,"i see... it is a bit annoying to copy the map here but i can live with it if you think that it is better like this. i have another question regarding this code. my understanding is that we basically decide here which members will get the extra partitions. basically, the first members while iterating over the map will get them. when the rack awareness is enabled, i wonder if we could get in a situation where the members with the extra partitions and the unassigned partitions are completely misaligned to due this. let's take an example. we have a group with 10 members (from 1 to 10) subscribed to topic a. topic a has 20 partitions so each member has 2 assigned partitions. all the partitions are available in a single rack. members 1 to 5 are in rack r1 and members 6 to 10 in rack r2. now let's say that we add 5 partitions to a. 3 are in r1 and 2 in r2. if we iterate from 1 to 10 to assign the extra partitions, it means that 1 to 5 will get an extra partitions even though two of the partitions are not in the same rack. is this a possible scenario? it is perhaps a bit too extreme...",-1,0.9587032198905945
1325600664,14182,dajac,2023-09-14T08:46:06Z,how about creating the queue just before calling rackawareroundrobinassignment and unassignedpartitionsroundrobinassignment and passing it as a parameter?,0,0.99405837059021
1325602326,14182,dajac,2023-09-14T08:47:19Z,"ah ah. you got me :). i actually raised this because in rackawareroundrobinassignment, your put it right before the if. that also works because the comment is really about that if.",1,0.9916011691093445
1325604357,14182,dajac,2023-09-14T08:48:52Z,nit: let's log before creating the builder to be consistent with the other branch.,0,0.9929438233375549
1325633887,14182,dajac,2023-09-14T09:07:37Z,nit: we have the same method in rangeassignortest. could we somehow share it for the two suites? we could perhaps introduce an assignortestutil class in this package and add it there.,0,0.9908114671707153
1326815225,14182,rreddy-22,2023-09-15T05:42:57Z,yessir done :),0,0.7714176177978516
1326817433,14182,rreddy-22,2023-09-15T05:46:40Z,i wasn't sure where it went tbh xd,0,0.6973106265068054
1326818424,14182,rreddy-22,2023-09-15T05:48:25Z,"makes sense, i put the order based on the method name like add partition to assignment so first partition then which topic then whose assignment and then which assignment",0,0.9882837533950806
1326819932,14182,rreddy-22,2023-09-15T05:50:52Z,i changed it now so we don't need the queue at all,0,0.9916715025901794
1326826466,14182,rreddy-22,2023-09-15T05:56:06Z,"yeah that's true i didn't think of how we're assigning the extra partitions, used the same logic as before, let me look into it. thanks for catching this!",1,0.9911086559295654
1326838235,14182,rreddy-22,2023-09-15T06:06:32Z,"i think one option would be to iterate through potentially unfilled members instead during the round robin process and if the member is a potential rack match plus can get an extra partition then we can assign it. we basically dynamically decide who gets the extra, instead of deciding before hand",0,0.9858351349830627
1326871177,14182,dajac,2023-09-15T06:48:03Z,"yeah, i was thinking about more or less the same. is it an small change?",0,0.982505202293396
1326872198,14182,dajac,2023-09-15T06:49:18Z,"in this case, i would put it back on the previous line.",0,0.9921758770942688
1332072827,14182,rreddy-22,2023-09-20T19:15:32Z,wasn't sadly but its done now,-1,0.8761821389198303
50180928,764,hachikuji,2016-01-19T21:48:28Z,"typo in ""messge""?",0,0.9930276274681091
50183536,764,hachikuji,2016-01-19T22:06:29Z,unneeded import (message)?,0,0.9937795996665955
50183902,764,hachikuji,2016-01-19T22:09:14Z,unneeded import (errormapping)?,0,0.9665239453315735
50186812,764,hachikuji,2016-01-19T22:32:18Z,"i wasn't clear from the kip, but is this a broker-wide setting or can it be overridden for each topic?",0,0.9879410266876221
50334745,764,apovzner,2016-01-20T22:57:35Z,"it would be useful to have a comment describing what this method does. especially because in one ""invalid"" case it throws exception, and in another case (when we need to overwrite timestamp) it returns true/false.",0,0.9913555979728699
50335106,764,apovzner,2016-01-20T23:00:58Z,"i am wondering if it would be better to pass 'now' as a parameter. we are calling this method for each message in a set, and getting current time every time. normally getting system time is an expensive call, so maybe better to get it once for a message set, and pass it to this method?",0,0.9611088633537292
50338001,764,apovzner,2016-01-20T23:27:22Z,"i see that in other places you did ""if (magicvalue > magicvalue_v0)"" comparison -- i think that one is better, since we would still want timestamp if we have magicvalue_v2 in the future, for example.",0,0.9840355515480042
50367205,764,becketqin,2016-01-21T07:16:24Z,"i was also thinking about that. currently whatever configurations in logconfig are per topic configurations. and the message timestamp type is a legitimate log config. so currently it is a per topic configuration. i can see some benefit of doing so from migration point of view. because most topics are owned by some applications. we can start to use the new format once all the client of that topic has migrated. and in the final state, we can choose to leave the topics whose owner are not able to migrate to use old format and still have zero-copy.",0,0.9331705570220947
50367268,764,becketqin,2016-01-21T07:17:55Z,good catch :) i remember i had this somewhere but did not find it before submit the pr.,1,0.9969430565834045
50442463,764,hachikuji,2016-01-21T18:36:26Z,"thanks for the explanation. makes sense to me. by the way, i've only done a quick pass on this patch so far, but i'm planning to spend a bit more time in the next couple days.",1,0.9798007011413574
50479362,764,apovzner,2016-01-21T23:04:46Z,"since we are adding timestamp field to producerrecord, i think we should add a comment to producerrecord class description about meaning of timestamp, what happens if user sets null, etc.",0,0.9920263886451721
50479481,764,apovzner,2016-01-21T23:06:04Z,"also would be good to add a comment to recordmetadata class description what timestamp is actually returned (either set by client, producer, or broker).",0,0.9941529631614685
50481259,764,apovzner,2016-01-21T23:23:53Z,"i understand that producer learns about the type of the timestamp after it gets first successful produce response. we are using the type of the timestamp in kafkaproducer.send() to set timestamp in producerrecord. i see that we default to handling timestamp as createtime timestamp if we don't know the type yet. what is the impact of doing this if the correct type turns out to be logappendtime? why don't we just always set timestamp on producer as if is createtime (basically, set local producer time if timestamp in producerrecord is null), and broker then overwrites it if the timestamp type is logappendtime. otherwise, looks like lots of added complexity just to decide whether set timestamp on the producer or not.",0,0.9823538064956665
50484068,764,apovzner,2016-01-21T23:52:00Z,"related to my other comment about learning about timestamp type for topic. so, the first set of produce messages will not have timestamp == inherited_timestamp if timestamp type == logappendtime, right? if setting timestamp to inherited_timestamp is required for compressed messages to work, does it mean we have a bug?",0,0.9858501553535461
50501215,764,becketqin,2016-01-22T04:29:28Z,"the reason we want to set the timestamp to -1 in producer when logappendtime is used for the topic is to avoid broker side recompression. if producer send createtime to a topic setup for logappendtime, recompression will occur on the broker if the received message timestamp is not -1. avoid recompression on broker is the key motivation of kip-31 so we don't want people to lose this feature if they are using logappendtime.",0,0.9889479875564575
50501355,764,becketqin,2016-01-22T04:34:01Z,"it is not required to be inherited_timestamp, but it is good to be so. like i answered in your other comment, if a topic is using logappendtime and a broker receives a message whose timestamp is not inherited_timestamp, it will overwrite it and do the recompression. so the first batch of a new producer might cause recompression on broker side, but after that, no recompression should be needed. i will add some comments so it is more clear.",0,0.7111047506332397
50597218,764,apovzner,2016-01-22T22:03:34Z,"i agree about avoiding broker side recompression. however, i still feel like we can achieve the same behavior with less changes. let me know if i am missing something, but couldn't we just do the following: 1. producer always sets timestamps (either producer client or kafkaproducer), as if timestamp type == createtime. for compressed message: timestamp of the outer message is set to the largest timestamp of the inner messages. 2. broker will overwrite timestamps if type == logappendtime. in case of compressed message, it will overwrite only outer message timestamp, and let inner messages have ""wrong"" timestamps. if message ever gets uncompressed on broker: set all inner timestamps to outer timestamp if type == logappendtime; 3. when messages get uncompressed on consumer (or any case when we don't have timestamp type info): we know that outer timestamp is either max of inner timestamps (if create time) or outer timestamp was overwritten (and so inner timestamps are not valid anymore). we check if outer (compressed message) timestamp == max of inner message timestamps, and if false, set all inner message timestamps to outer timestamp. if there is ever a case that overwriting timestamp results in a timestamp == max of inner message timestamps, this means that producer and broker times are in sync, and inner message timestamps should be close enough to outer timestamp to care overwriting it.",0,0.8673117756843567
50599954,764,becketqin,2016-01-22T22:29:40Z,"in your suggestion, how can we differentiate between the following two scenarios: 1. logappendtime is used, the inner message's largest timestamp happened to be the same as the logappendtime. 2. createtime is used. the compressed messages in both case are exactly the same, but one is using logappendtime and the other one is using createtime. how would the consumer decide which timestamp to use? please also notice that we always do decompression on broker side to verify the message. what we want to avoid is re-compression.",0,0.9899439811706543
50621173,764,dajac,2016-01-23T15:25:29Z,wouldn't it be better to put this conversion in kafkaapis or directly in messageset? i would prefer to keep fetchresponse and fetchresponsepartitiondata as simple as possible and focused on the serialization.,0,0.9926517605781555
50621383,764,dajac,2016-01-23T15:40:43Z,nitpick: indentation is not correct.,0,0.9006429314613342
50645225,764,becketqin,2016-01-24T23:42:32Z,"i agree it makes sense to put the message set format conversion code block into messageset instead of here. however, i make the io threads to do the conversion on purpose because i want to share the workload between kafkaapis threads and io threads. typically, io threads are more light-weighted than kafkaapis threads. if we have to make conversion for some requests, i am trying to put the conversion load on io threads.",0,0.9800522327423096
50743872,764,apovzner,2016-01-25T19:35:46Z,"i should have said ""if message ever gets re-compressed on broker..."" in #2. so we don't over-write timestamp and re-compress just for timestamps. to answer your question and clarify my suggestions, i am basing my suggestion on the assumption that we don't need to be very exact about timestamp -- meaning +- 1 ms is ok. so my proposal above is assuming that if your scenario happen and the inner message's largest timestamp happened to be the same as the current time on broker and we are using logappendtime, this means that producer and broker are in sync, and we don't care whether it is logappendtime or createtime. one more argument against: what if client sets ""bad"" timestamp in one of the inner messages. i realized that in your scenario my suggestion does not work well. i propose the following: on broker, when messages get decompressed, if timestamp type == logapendtime, then set outer message timestamp == current time. check if max timestamp of inner messages also contains this timestamp, and if so, decrement outer message timestamp by 1 ms. in this case, we know that we don't have the scenario above. on consumer, if outer message timestamp != max of inner messages timestamps, we know that this is logappendtime and set all inner message timestamps to outer message timestamp. **summary** i think we either need a cleaner way to get topic's timestamp type on producer or simplify timestamp code by allowing timestamps be not super exact, but no more than +- 1 ms error. the former i think is better solved by getting timestamp type with topic metadata, but that requires another wire protocol change. the latter is proposed above, but here is updated version based on the scenario in the previous comment: 1. producer always sets timestamps (either producer client or kafkaproducer), as if timestamp type == createtime. for compressed message: timestamp of the outer message is set to the largest timestamp of the inner messages. 2. broker will overwrite timestamps if type == logappendtime. in case of compressed message: it will overwrite only outer message timestamp, and let inner messages have ""wrong"" timestamps. if broker happens to overwrite outer message timestamp with with same timestamp, it means that outer timestamp would be equal to max of inner message timestamps. to allow consumer to differentiate between overwritten and not overwritten timestamp, we want to void the case where outer message timestamp == max of inner message timestamps when type == logappendtime. so, when overwriting outer message timestamp with same timestamp, we will decrement (or increment) outer message timestamp by 1 ms. 3. when messages get uncompressed on consumer, we know that outer timestamp is either max of inner timestamps (if create time) or outer timestamp was overwritten (and so inner timestamps are not valid anymore). we check if outer (compressed message) timestamp == max of inner message timestamps, and if false, set all inner message timestamps to outer timestamp.",0,0.9835772514343262
50764320,764,becketqin,2016-01-25T22:09:16Z,"personally i think the timestamp should be accurate. modifying the timestamp sounds very hacky and creates extra complexity. please also notice that the timestamp index built by the followers will be purely depending on the timestamp in outer message of compressed messages. the followers will not even decompress the messages. if we play the trick here, the time index on follower will also be affected. if we want to make things right, then producer should be able to get the necessary topic configuration info from broker, either from topicmetadatarequest or some other requests. so the producer can set the timestamp correctly to avoid server side recompression. but like you said this is a bigger change and it is unnecessary to block on that change. i think the current solution is reasonably clean as of the moment. once the producer is able to get the topic configuration from broker, we can simply migrate to use that. since everything is purely internal, the migration is very simple and transparent to users.",0,0.5458478331565857
51080192,764,apovzner,2016-01-28T04:59:25Z,"if we are exposing timestamp type in consumerrecord, should we declare timestamptype outside of record?",0,0.993619978427887
51082542,764,becketqin,2016-01-28T05:50:14Z,it is in kafkaproducer line 437. we just need a one liner now.,0,0.9949028491973877
51165826,764,apovzner,2016-01-28T18:39:07Z,the comment above the method does not match implementation anymore -- we are now only checking acceptable range for createtime timestamps.,0,0.9944502115249634
51221001,764,junrao,2016-01-29T03:00:09Z,it seems that we only reserved 3 bits for compression codec?,0,0.9933087825775146
51221007,764,junrao,2016-01-29T03:00:14Z,it seems that checking lastinneroffset itself is enough.,0,0.9908175468444824
51221024,764,junrao,2016-01-29T03:00:32Z,"since this is always called on the inner records, we probably don't need shallow in the param?",0,0.9913712739944458
51221029,764,junrao,2016-01-29T03:00:36Z,would it be better to name this lastinnerrelativeoffset?,0,0.9935140609741211
51221037,764,junrao,2016-01-29T03:00:44Z,fetch response v2 is actually different from v1 since the message format is different.,0,0.9910365343093872
51221069,764,junrao,2016-01-29T03:00:57Z,could we add timestamp to ?,0,0.9946183562278748
51221090,764,junrao,2016-01-29T03:01:13Z,is it useful for user to specify a -1 timestamp? would that be the same as passing in a null timestamp?,0,0.9931260347366333
51221091,764,junrao,2016-01-29T03:01:18Z,"the record is still sent to a topic/partition, not timestamp.",0,0.9924463629722595
51221099,764,junrao,2016-01-29T03:01:23Z,typo: record.record,0,0.9909748435020447
51221100,764,junrao,2016-01-29T03:01:25Z,typo: record.record,0,0.9909748435020447
51235304,764,becketqin,2016-01-29T08:18:35Z,"currently the message format change is not reflected in the fetch response protocol. the change is in the record class when it parses the bytebuffer. so the fetchresponse fields actually does not change. but i agree that ideally we should define all the wire protocols in protocol. i was planning to do it in another patch because this patch is already big. the comment here is actually not accurate. in fetchresponse v2 we may also see message format v0, because the broker will try to avoid losing zero copy by assuming the client sending fetchrequest v2 knows how to parse message format v0.",0,0.9825432300567627
51301463,764,apovzner,2016-01-29T19:08:50Z,"why do we ever need to recompute crc for timestamp type == createtime? since createtime is default, we should set all right attributes with the timestamp on the producer, and we don't need to update crc or do any related changes to timestamp/attributes on the broker. i think we should be clear about when crc can change on the broker and when it will not.",0,0.9871950745582581
51325920,764,becketqin,2016-01-29T22:37:12Z,we need to verify both the timestamp attribute bit and the actual timestamp. if one of them is not set properly we need to update it and recompute crc.,0,0.9941139817237854
51326334,764,apovzner,2016-01-29T22:42:22Z,"i see, so this is only the migration case, right? upgraded producer will set both attributes and timestamp correctly for the createtime topics, right?",0,0.990933895111084
51329584,764,becketqin,2016-01-29T23:21:45Z,for migration case and for producers that is not setting the timestamp of outer message correctly somehow. it should be fine since we are not changing the actual timestamps of messages.,0,0.9921322464942932
51502629,764,apovzner,2016-02-02T00:07:14Z,"thanks, that makes sense.",1,0.7010931968688965
51516461,764,junrao,2016-02-02T02:52:44Z,"right, perhaps we can make this clearer in the comment. sth like the following: even though fetch response v2 has the same protocol as v1, the record set in the response is different. in v1, record set only includes messages of v0 (magic byte 0). in v2, record set can include messages of v0 and v1 (magic byte 0 and 1). for details, see ref{bytebuffermessageset}.",0,0.9878794550895691
51516607,764,junrao,2016-02-02T02:54:29Z,"would it be better to rename this to wrappertimestamptype? also, since the way to interpret the timestamp is a bit subtle, especially with respect to compressed messages, could you document this in a comment?",0,0.9924902319908142
51516616,764,junrao,2016-02-02T02:54:34Z,"the comment says this is the constructor for version 1, but the code uses the latest version.",0,0.9927173852920532
51516635,764,junrao,2016-02-02T02:54:46Z,"we check version here, but uses the new field name in line 127 as the way to check the version. we should probably use a consistent approach.",0,0.9925999641418457
51516646,764,junrao,2016-02-02T02:54:59Z,could we add a comment before line 95 that we expect the caller to pass in a struct with the latest schema?,0,0.9938263297080994
51516833,764,junrao,2016-02-02T02:57:34Z,"in addition to have the internal versions, we probably should always have an ""0.10.0"" version in trunk so that it's in a releasable state. i was thinking that we always have ""0.10.0"" map to the last case object. in this case, both ""0.10.0"" and ""0.10.0-dv0"" will be pointing to kafka_0_10_0_dv0. when we add kafka_0_10_0_dv1, ""0.10.0"" will be pointing to kafka_0_10_0_dv1 and we will add ""0.10.0-dv1"", but leave ""0.10.0-dv0"" unchanged. in the code, we can just reference the first internal version in which a format change is introduced. then, for people deploy from trunk, they can use the internal version. for people who want to try trunk, they can use ""0.10.0"". also, would it be better to use iv (internal version) instead of dv? finally, it may make sense to make the next major release 0.10 instead of 0.9.1 since we will be including kstream. do you want to poll the mailing list to see if people are ok with this?",0,0.984843909740448
51516887,764,junrao,2016-02-02T02:58:28Z,"i agree that it's better to do the message conversion in kafkaapis. the reason is that a single network thread is used to handle many socket connections. if the sending of one response is slow (e.g., recompression when converting the message), it slows down the processing of all connections on this network thread. on the other hand, if the processing in a request handler thread is slow, it only slows down that request. other requests are unaffected.",0,0.970578134059906
51516906,764,junrao,2016-02-02T02:58:52Z,this means that we are paying the overhead of checking hasmagicvalue even after the consumer is upgraded to support both message format v0 and v1.,0,0.9896411299705505
51516922,764,junrao,2016-02-02T02:59:10Z,"should this be a topic level config? the issue is that this has to match the api version that the broker uses. for example, if the broker is on 0.9.x, setting the format in a topic to v1 is invalid, but is hard to enforce.",0,0.9798562526702881
51516927,764,junrao,2016-02-02T02:59:13Z,typo writtern,0,0.9904244542121887
51516929,764,junrao,2016-02-02T02:59:16Z,it simply write => it simply writes,0,0.9907910823822021
51516941,764,junrao,2016-02-02T02:59:28Z,can use innermessageandoffsets instead of messageandoffsets.,0,0.9951887130737305
51516961,764,junrao,2016-02-02T02:59:49Z,"if we don't need to re-compress, should we validate the crc of each of the inner message?",0,0.9917124509811401
51516975,764,junrao,2016-02-02T03:00:03Z,"it seems that we only need to convert message format on filemessageset. so, perhaps it's better to move this to filemessageset?",0,0.9915041327476501
51516977,764,junrao,2016-02-02T03:00:08Z,there are a few unused imports.,0,0.988497793674469
51517004,764,junrao,2016-02-02T03:00:31Z,"this probably shouldn't be info level logging, right?",0,0.9591435194015503
51517033,764,junrao,2016-02-02T03:00:56Z,could we document what the valid values are for message format? it seems that we are piggybacking on the apiversion number. it's probably clearer if just use v0 and v1 that matches the magic value since not every api version change implies a message format change.,0,0.989513099193573
51525824,764,becketqin,2016-02-02T05:28:21Z,read the code again. that's true. apparently i had some wrong impression about how we process the requests...,0,0.5998234152793884
51529150,764,becketqin,2016-02-02T06:30:05Z,good catch. we only need to do down convert for fetch request lower than v2.,1,0.988649845123291
51530067,764,becketqin,2016-02-02T06:38:39Z,"that is indeed a caveat. the reason i make message.format.version a topic level config is because it helps to roll out the change. in many cases topics are owned by different applications, so once the application finishes upgrade we can turn on the new message format for them without waiting for others. one way to enforce this is to add sanity check in both kafkaconfig and topicconfighandler. we can check to make sure the message format version config is valid.",0,0.9907407760620117
51531865,764,becketqin,2016-02-02T07:08:00Z,had some comments on the kip about this. i feel fine either way. the good thing about piggybacking apiversion is it is easy to validate the config. and from user's perspective it may be easier to understand. e.g. during upgrade they can simply put their previous kafka version there and after upgrade they just need to change it to the upgraded version. so users don't need to remember the magic values to put.,1,0.9113878607749939
51615655,764,junrao,2016-02-02T18:54:10Z,it's probably clearer to rename this to sth like magicvalueinallmessages().,0,0.989264726638794
51615665,764,junrao,2016-02-02T18:54:14Z,indentation,0,0.9911677837371826
51615681,764,junrao,2016-02-02T18:54:20Z,could you attach gwen's comment here?,0,0.994952917098999
51615706,764,junrao,2016-02-02T18:54:26Z,could we include the valid property values in the doc?,0,0.9951221346855164
51615770,764,junrao,2016-02-02T18:54:47Z,"we should use the magic configured for this topic and convert each message to the right version if needed, right?",0,0.9925278425216675
51615946,764,junrao,2016-02-02T18:55:53Z,"could we put those comments in a more prominent place like the beginning of the class? with v1 message format, we are adding a timestamp, a timestamp type attribute, and are using a relative for inner message. it would be useful to document the format in a bit more details for both the outer and the inner message. for example, should the timestamp type attribute be set for inner messages?",0,0.9902777075767517
51634795,764,becketqin,2016-02-02T21:05:21Z,"gwen gave the following feedback on the voting thread. ""2. apiversion has real version numbers. message.format.version has sequence numbers. this makes us look pretty silly :)""",1,0.9939693212509155
51637287,764,becketqin,2016-02-02T21:23:12Z,"i was thinking only applying the new message format to the messages appended after the change, so the log has a clear cut-off offset where all the new format comes after that. it is probably not necessary. what do you think?",0,0.9862884283065796
51672466,764,junrao,2016-02-03T02:51:10Z,could we add a comment to explain what the timestamp is?,0,0.9941973686218262
51672513,764,junrao,2016-02-03T02:51:55Z,the comment still says using v1 format.,0,0.9908353090286255
51672525,764,junrao,2016-02-03T02:52:14Z,it's probably useful to use the message format v1 on the topic. this can avoid the recompression overhead when compression is enabled.,0,0.992730438709259
51672530,764,junrao,2016-02-03T02:52:20Z,it's probably useful to use the message format v1 on the topic. this can avoid the recompression overhead when compression is enabled.,0,0.992730438709259
51672563,764,junrao,2016-02-03T02:52:53Z,"the thing is that the way topicconfigcommand works is that it just writes the config in zk and then writes the config notification. topicconfighandler just follows the notification. if we add the check in topicconfighandler, we need to remove the config in zk, which makes things more complicated. we can probably just leave this as a topic level config with the caveat that the config may be ignored if the broker property doesn't match.",0,0.975366473197937
51672667,764,junrao,2016-02-03T02:54:32Z,"the changes in this class is a bit complicated, makes the code a bit hard to read. this and the following are some suggestions on simplification. do we need convertnoncompressedmessages()? since we can't do things in place, could we just use the path that deals with recompression to handle it? this will save some duplicated code.",0,0.815172553062439
51672737,764,junrao,2016-02-03T02:55:35Z,"requirerecompression is a bit confusing. for example, requirerecompression will be true if the source data is compressed and the broker requires no compression. perhaps we can rename it to sth like inplaceconversion and negate the test?",0,0.8137450218200684
51672760,764,junrao,2016-02-03T02:56:06Z,"passing in messagesettimestampassignor makes the code a bit harder to read. i was wondering if we can obviate that and always scan the messages to get the max timestamp. this will add a bit overhead of making another iteration of all messages, but will simplify the code. the overhead should be small.",0,0.9823823571205139
51672770,764,junrao,2016-02-03T02:56:15Z,"so far, we have been using case classes to represent enum in scala (see compressioncodec). could we follow the same convention?",0,0.9932453036308289
51672776,764,junrao,2016-02-03T02:56:24Z,"hmm, producer request v2 is supposed to send message of v1, right? actually, should we enforce that on the broker?",0,0.984689474105835
51672781,764,junrao,2016-02-03T02:56:34Z,"hmm, what is %s for now? also, do we want to just log the text ""fetchrequest""?",0,0.9848932027816772
51672789,764,junrao,2016-02-03T02:56:43Z,would it be better to use the latest version of the message?,0,0.9871851801872253
51672844,764,junrao,2016-02-03T02:57:49Z,"right, we can use sth like v0, v1 to make it consistent.",0,0.9911202788352966
51682035,764,junrao,2016-02-03T06:06:48Z,"converting to message format v1 allows us to track timestamp at the message level, which will be useful for things like removing the tombstone.",0,0.9929684996604919
51768874,764,becketqin,2016-02-03T18:57:25Z,"hi jun, currently we always do re-compression when compacting the log, even if message format v1 is used. do you mean we should change that so if a compressed message set does not change after compaction we simply write the original message set back? if we do that (and we probably should), it seems it does not matter whether message format v0 or v1 is used, because it only depends on whether there is message in the message set got compacted out or not.",0,0.9881199598312378
51817003,764,hachikuji,2016-02-04T01:24:23Z,"took me a while to wrap my head around this line. it seems like the `lastinnerrelativeoffset` and `wrapperrecordoffset` are constants within the life of this instance, so i'm wondering if we could instead use a single constant (e.g. `absolutebaseoffset`) for this difference? then this line would just become: [code block] which is a lot more readable.",0,0.7629861235618591
51831822,764,junrao,2016-02-04T05:42:22Z,"that's not what i meant. since this message will be eventually appended to the log through log.append, if it's compressed and of format v0, we need to recompress it. if it's format v1, the recompression can be avoid. also, since v1 carries more metadata, it seems that we should always try to use message v1 if possible.",0,0.9889460206031799
51961629,764,becketqin,2016-02-05T00:39:38Z,"hi jun, do we also want the change in old producer request and old producer? it seems it will be deprecated pretty soon. so in the current patch i did not even change the scala producerrequest format, but i probably should just leave the scala producer version to 1. besides that, i realized that we have quite a few tools still using old consumer. i will update them.",0,0.9487013220787048
52074957,764,becketqin,2016-02-05T21:26:46Z,ack :),0,0.5039835572242737
52267507,764,junrao,2016-02-09T04:50:22Z,"reworded this a bit the default on-disk message format in 0.10.0 in v1. if a consumer client is on a version before 0.10.0, it only understands message format v0. in this case, the broker is able to convert messages of format v1 to v0 before sending a response to the consumer on an older version. however, the broker can't use zero-copy transfer in this case. to avoid such message conversion before consumers are upgraded to 0.10.0, one can set the message format to v0 after upgrading the broker to 0.10.0. this way, the broker can still use zero-copy transfer to send the data to the old consumers. once most consumers are upgraded, one can change the message format to v1 on the broker.",0,0.9922003149986267
52267511,764,junrao,2016-02-09T04:50:31Z,the comment is not accurate since the producer doesn't know the timestamp type.,0,0.9549742937088013
52267516,764,junrao,2016-02-09T04:50:38Z,are these comments correct? the timestamp in producerrecord is always set by the producer.,0,0.9932274222373962
52267522,764,junrao,2016-02-09T04:50:44Z,could we add a comment on the timestamp field?,0,0.9946516752243042
52267534,764,junrao,2016-02-09T04:51:06Z,"typo dv also, could we leave some comments so that people know what to do when changing the protocol again before 0.10.0 is released?",0,0.9948264956474304
52267543,764,junrao,2016-02-09T04:51:13Z,we no longer need this since 0_10_0 will just point to the latest iv.,0,0.9942502975463867
52267549,764,junrao,2016-02-09T04:51:21Z,the changes in this file seem no longer needed.,0,0.9923098087310791
52267569,764,junrao,2016-02-09T04:51:50Z,"i had a comment on this in the previous round of review. it seems that during compaction, it would be better to write the message in the configured message format : (1) this reduces the message conversion during fetch. (2) converting to message format v1 allows us to track timestamp at the message level, which will be useful for things like removing the tombstone.",0,0.9837867617607117
52267574,764,junrao,2016-02-09T04:51:56Z,should we just represent this as a byte to be consistent with message.magic?,0,0.9889256358146667
52267583,764,junrao,2016-02-09T04:52:05Z,should we assert that wrappermessagetimestamp is only set if compression is on and timestamptype is logappend?,0,0.9945149421691895
52267592,764,junrao,2016-02-09T04:52:10Z,adjust => adjusts,0,0.9878067374229431
52267595,764,junrao,2016-02-09T04:52:18Z,"could we make put the message in the exception clearer? e.g., the payload is null.",0,0.9912316203117371
52267604,764,junrao,2016-02-09T04:52:27Z,the confusion is that torelativeoffset() doesn't really return the relative offset as defined in line 150. would it be better to rename it to toinneroffset()?,0,0.9466517567634583
52267612,764,junrao,2016-02-09T04:52:41Z,"for compressed messages, we don't really set the timestamptype for inner messages. so, we need to make this clear. also, the inner message offset is not really the relative offset.",0,0.9914922118186951
52267620,764,junrao,2016-02-09T04:52:58Z,"since the offset of the inner message is not really the relative offset, we can probably just talk about how to derive the ao from the inner offset.",0,0.9911913275718689
52267622,764,junrao,2016-02-09T04:53:03Z,io is defined but not used.,0,0.9818388223648071
52267631,764,junrao,2016-02-09T04:53:19Z,"i left this comment in the previous review. do we need convertnoncompressedmessages()? since we can't do things in place, could we just use the path that deals with recompression to handle it? this will save some duplicated code.",0,0.993779718875885
52267646,764,junrao,2016-02-09T04:53:35Z,is this check needed since we can only do in-place if magic is > 0?,0,0.9941788911819458
52267649,764,junrao,2016-02-09T04:53:38Z,5th -> 4th?,0,0.9847054481506348
52267651,764,junrao,2016-02-09T04:53:42Z,should we change the description for attribute?,0,0.9938467144966125
52267666,764,junrao,2016-02-09T04:53:56Z,could we add a comment to explain when do we expect wrappermessagetimestamp and wrappermessagetimestamptype to be not none?,0,0.9950435161590576
52267675,764,junrao,2016-02-09T04:54:05Z,"in line 168, should we set timestamptype in attribute?",0,0.994971513748169
52267679,764,junrao,2016-02-09T04:54:08Z,indentation,0,0.9911677837371826
52267681,764,junrao,2016-02-09T04:54:12Z,there are unused imports.,0,0.9927347898483276
52267687,764,junrao,2016-02-09T04:54:19Z,we only return the max timestamp of the inner messages if timestamptype is createtime.,0,0.9945521950721741
52267690,764,junrao,2016-02-09T04:54:24Z,would it be better to change samplemagicvalue to firstmagicvalue?,0,0.9925837516784668
52267700,764,junrao,2016-02-09T04:54:32Z,the message in the exception can be mis-leading since validatemagicvaluesandgettimestamp may not be called on a set of uncompressed messages.,0,0.9890056848526001
52267706,764,junrao,2016-02-09T04:54:51Z,"the method only iterates shallow messages. so, perhaps changing the method to magicvalueinallwrappermessages and adjusting the comments?",0,0.9930691719055176
52267737,764,junrao,2016-02-09T04:55:43Z,we can probably just check if all messages are on v0 since not all existing messages necessarily match the message format config.,0,0.9927400946617126
52267746,764,junrao,2016-02-09T04:55:59Z,it's probably better to log the # of bytes in the messageset instead of # of messages. the later will invoke the iterator and is more expensive.,0,0.9856487512588501
52267748,764,junrao,2016-02-09T04:56:04Z,incorrect indentation since this is the parameter for responsesize().,0,0.7497374415397644
52267763,764,junrao,2016-02-09T04:56:17Z,"we want to make it clear that the performance impact is only during the upgrade period. once the clients are upgraded or if people are just starting to use 0.10, there is no performance impact.",0,0.9892834424972534
52356387,764,becketqin,2016-02-09T19:02:42Z,"hi jun, this patch is using the message format version configured for this topic when doing compaction. the configuration is passed in in line 373. do you mean something else?",0,0.9937509894371033
52380036,764,becketqin,2016-02-09T21:52:37Z,"having a separate `convertnoncompressedmessages()` saves one round of memory copy. in `convertnoncompressedmessages()` we read from the old format and write the converted format directly into the new byte buffer. so there is only one memory copy. if we let the path that deals with re-compression to handle it, we need to first convert messages to required format (first memory copy), then write them together to a new byte buffer (second memory copy).",0,0.9903351068496704
52387545,764,junrao,2016-02-09T22:48:26Z,"hmm, i don't see the logic of format conversion though. for example, if there are uncompressed messages of v0 and the format of the topic is configured with v1, we should write messages of v1 to the new log segment. currently, it seems that we just keep the original message format.",0,0.9606161117553711
52389495,764,becketqin,2016-02-09T23:03:43Z,we always return the max timestamp of the inner messages as long as they are in v1.,0,0.9941707253456116
52405180,764,becketqin,2016-02-10T01:44:59Z,"hi jun, the tests on the configuration here is trying to address the following problem. after people just upgrade to 0.10.0.0, most of the fetch request are still in v1. in this case, if we check whether all the messages are v0 or not, we are essentially iterating over the file message set. by checking the configuration, we can avoid that. after people set message format to v1, we will only do the iterative check for old consumers (hopefully there won't be many at that point). the caveat of this approach is mentioned in the comments. after user set the message format to v1, if they decide to change the message format back to v0. the old consumer may see message v1 because of the discrepancy between actual message format and the config as you pointed out. do you prefer to simply take the performance cost right after people finish upgrade? this cost will go away after all the clients are upgraded, but that could be an extended period.",0,0.9564054012298584
52503273,764,becketqin,2016-02-10T18:41:47Z,"ah, you are right. i'll fix that.",0,0.5008835196495056
52550562,764,becketqin,2016-02-11T00:34:48Z,"hi jun, i actually hesitated a little here. it seems this constructor should only be used by producer, so the timestamp should always be createtime. i added the timestamp type to constructor pretty lately because checksummessageformatter also needs to construct message in order to compute checksum. currently checksummessageformatter only takes key and value and always assume the compression type to be nocompression. this works because all the messages, including inner messages of compressed messages, should not have compression codec. however, because timestamp type can be different from message to message, we need to include timestamp type when computing checksum. we also need compression type because for compressed messages, inner message timestamp type is always createtime even when the timestamp type of the message is logappendtime defined by wrapper message. i did not find any usage of checksummessageformatter. i asked joel about this class, and it looks we used to use it in system test, but now we are not using it anymore. do you think we can simply remove this class?",0,0.6472247838973999
52609487,764,junrao,2016-02-11T14:44:42Z,"thanks, got your point. so, setting the message version to 0 in the config not only implies that future messages will be written in version 0, but all existing messages are of version 0 too? we should at least document this, but i am not sure if this is enough to warn people about the impact of switching back and forth of the message format config. could you run some experiments about the performance impact of doing the message format check?",1,0.9607805609703064
52780786,764,becketqin,2016-02-12T18:46:05Z,"hi jun, i ran the following experiment with the configuration check removed. i.e. always verify messages for fetch request v1. 1. start a new broker with message.format.version=v0. 2. produce 3000000 messages to topic with 128 partition using console producer. 3. consume the messages using console consumer in this rb (sending v2 fetch request, so no message format verification needed.) 4. consume the messages using console consumer in current trunk (sending v1 fetch request, so message verification is needed) the log below prints out the time cost on the verification code block: [code block] the first 4 lines are from v2 requests. the fifth line is from v1 and v2 mixed. the last 4 lines are from v1 requests. time unit is nano seconds. it seems the traversal cost is expensive.",0,0.9749659299850464
52814031,764,junrao,2016-02-12T23:47:08Z,"ok, then we can keep the version check there. could we update the config/upgrade doc to make it clear that by setting the message version on a topic, the user is certifying that all existing data are on that version and if that's not the case, the consumer before 0.10 will break?",0,0.9916211366653442
52815492,764,junrao,2016-02-13T00:08:23Z,"hi, jiangjie, independent of checksummessageformatter, shouldn't we set the attribute based on the timestamptype passed in? the caller is responsible for setting the timestamptype.",0,0.9930055737495422
52838521,764,junrao,2016-02-14T06:25:35Z,could we add the doc for timestamptype?,0,0.9949153661727905
52838529,764,junrao,2016-02-14T06:26:33Z,"since this will be part of the java doc, could we explain what the timestamp will be?",0,0.9947328567504883
52838534,764,junrao,2016-02-14T06:27:44Z,timestam -> timestamp type?,0,0.9941235184669495
52838535,764,junrao,2016-02-14T06:27:46Z,do we need the createtime at the end? ditto for the logappendtime at the end of line 30.,0,0.9940447211265564
52838538,764,junrao,2016-02-14T06:28:26Z,"if createtime is used, are we returning -1 for timestamp?",0,0.9942973256111145
52838543,764,junrao,2016-02-14T06:29:13Z,create times => createtime,0,0.9917987585067749
52838565,764,junrao,2016-02-14T06:32:40Z,the message format => that message format,0,0.9958192110061646
52838575,764,junrao,2016-02-14T06:34:35Z,need to remove prinitln.,0,0.9849196672439575
52838577,764,junrao,2016-02-14T06:35:01Z,should we throw kafkaexception instead?,0,0.9900508522987366
52838580,764,junrao,2016-02-14T06:35:43Z,"since the inner offset is not really the relative offset, we can probably just refer to it as inner offset and point to the description in the later text.",0,0.9905557036399841
52838587,764,junrao,2016-02-14T06:36:03Z,producer -> the producer create => creates,0,0.993198573589325
52838590,764,junrao,2016-02-14T06:36:36Z,followings situation => following situations,0,0.9884627461433411
52838592,764,junrao,2016-02-14T06:36:54Z,probably better to rename to expectedinneroffset?,0,0.9904286861419678
52838595,764,junrao,2016-02-14T06:37:24Z,"it doesn't seem that we need to valid the input message here since this is already done in log,analyzeandvalidatemessageset().",0,0.9918991327285767
52838598,764,junrao,2016-02-14T06:38:07Z,would it be better to return a magicandtimestamp so that the caller doesn't have to iterate the message set again to get the magic?,0,0.9919414520263672
52838602,764,junrao,2016-02-14T06:38:33Z,numfetch and totaltime are unused.,0,0.9863767027854919
52838603,764,junrao,2016-02-14T06:38:51Z,"the value is now in bytes, not messages.",0,0.9943950176239014
52838608,764,junrao,2016-02-14T06:40:00Z,the whether -> whether,0,0.9788181781768799
52839564,764,becketqin,2016-02-14T08:36:19Z,"it seems that if we do not have the creattime at the end, java doc will show the entire qualifier, i.e. org.apache.kafka.common.record.timestamptype#createtime. this works but seems a little verbose. alternatively we can import the timestamptype class so we don't need to have a display name for the ``. do we have a convention for java doc in kafka? it seems we have different styles in the code base.",0,0.9767001271247864
52839682,764,becketqin,2016-02-14T08:48:20Z,"if createtime is used, we are returning user provided timestamp if it exists or the time when the record was handed to the producer.",0,0.9942353367805481
52847115,764,junrao,2016-02-14T19:01:21Z,"it seems that we need to reset absolutebaseoffset when we are done iterating the inner records. otherwise, the next record could be uncompressed and we will set the offset incorrectly. could we add a unit test that covers this?",0,0.9922415018081665
52847119,764,junrao,2016-02-14T19:01:28Z,incomplete sentence,0,0.713310956954956
52847121,764,junrao,2016-02-14T19:01:36Z,"reworded this a bit. see if it's clearer. since the api protocol may change more than once within the same release, to facilitate people deploying code from trunk, we introduce internal versions since 0.10.0. for example, the first time that we introduce a version change in 0.10.0, we will add a config value ""0.10.0-iv0"" and a corresponding case object kafka_0_10_0-iv0. we will also add a config value ""0.10.0"" that will be mapped to the latest internal version object, which is kafka_0_10_0-iv0. when we change the protocol a second time while developing 0.10.0, we will add a new config value ""0.10.0-iv1"" and a corresponding case object kafka_0_10_0-iv1. we will change the config value ""0.10.0"" to map to the latest internal version object kafka_0_10_0-iv1. config value of ""0.10.0-iv0"" is still mapped to kafka_0_10_0-iv0. this way, if people are deploying from trunk, they can use ""0.10.0-iv0"" and ""0.10.0-iv1"" to upgrade one internal version at a time. for most people who just want to use released version, they can use ""0.10.0"" when upgrading to 0.10.0 release.",0,0.9867174625396729
52847126,764,junrao,2016-02-14T19:02:02Z,"we should use the message format specified for the internal topic. in addition, we have to be a bit careful here, during a rolling upgrade, if a broker's inter-broker protocol version is still before 0.10.0, even if the message format is for v1, we will still want to use message format v0. otherwise, if another broker is still on the pre 0.10.0 code, it can't read the v1 message in the internal topic. ditto to the magic value setting below.",0,0.9911561012268066
52847133,764,junrao,2016-02-14T19:02:21Z,"there is a similar issue here. during rolling upgrade to 0.10.0, if a broker's inter-broker protocol version is still before 0.10.0, even if the message format is for v1, we will still want to use message format v0. otherwise, if another broker is still on the pre 0.10.0 code, it can't read the v1 message in the internal topic for things like log cleaning.",0,0.9925432205200195
52847134,764,junrao,2016-02-14T19:02:33Z,"similar issue as before, we need to further guard the message format based on inter protocol version so that we only use message format ready for every broker.",0,0.983665406703949
52847137,764,junrao,2016-02-14T19:02:50Z,it seems that we may need to change the message format when copying out uncompressed messages too.,0,0.9895289540290833
52847141,764,junrao,2016-02-14T19:02:54Z,the inner message offset is not really relative.,0,0.9838491678237915
52847144,764,junrao,2016-02-14T19:02:57Z,the inner message offset is not really relative.,0,0.9838491678237915
52847146,764,junrao,2016-02-14T19:03:06Z,it seems that timestamptype can only be none if magic is 0?,0,0.990384578704834
52847149,764,junrao,2016-02-14T19:03:19Z,could we also add the need for this to be consistent with inter broker protocol (otherwise the setting will be ignored)?,0,0.9927365779876709
52847150,764,junrao,2016-02-14T19:03:23Z,are the changes here needed?,0,0.9940477609634399
52847151,764,junrao,2016-02-14T19:03:32Z,"since the fail and assertions are in the callback and we eat the exceptions, we probably need to propagate the failure to the main test method?",0,0.9911982417106628
52847154,764,junrao,2016-02-14T19:03:40Z,can we get the cause and check the exact exception time? ditto below.,0,0.9952489733695984
52847180,764,junrao,2016-02-14T19:05:18Z,it seems that we need to call validatetimestamp() in this case as well?,0,0.9931167364120483
52847192,764,junrao,2016-02-14T19:06:14Z,invalidmessageexception is used for corrupted messages. could we use a different exception and error code?,0,0.9913109540939331
52847218,764,junrao,2016-02-14T19:08:19Z,"thinking about this again, since it's possible for us to change the message format more than once within the same release and we need to make sure message format is consistent with inter protocol version, it's probably better to just use the values in apiversion to specify the message format. we can probably extend each of the case object in apiversion to add a magic field to indicate the message version associated with each protocol version. sorry for going back and forth on this one.",-1,0.9905644655227661
52850892,764,becketqin,2016-02-14T23:16:33Z,"hmm, absolutebaseoffset is only non-negative for inner iterators. the outer iterators always have absolutebaseoffset=-1. because we create a separate independent inner iterator for each compressed message set, the same absolutebaseoffset should be used by all the messages in that compressed message set. after we finish iterating one compressed message set and return to the outer iterator, the absolutebaseoffset of inner iterator will not affect the outer iterator, i.e. the outer iterator absolutebaseoffset remains -1. so even the next record is an uncompressed record, it should not be affected.",0,0.9871424436569214
52851922,764,becketqin,2016-02-15T00:20:05Z,"hi jun, we are doing message format conversion, right? if another broker is on old code and sends fetchrequest v1, we will down convert the message to v0. so it should not break even if leader has message format v1 on disk and follower is fetching using inter-broker protocol version before 0.10.0. i am wondering if we should simply let the internal topic message format comply with inter-broker protocol version. the reason is this guarantees no message format conversion is needed for internal topic replication. and it avoids manually setting message format version config for the internal topic.",0,0.9696215391159058
52852265,764,becketqin,2016-02-15T00:36:02Z,regarding the message format check. currently we do validate both broker and topic level configuration to make sure message format version is on or below inter-broker protocol version. so is it sufficient to simply use the message format version in the config?,0,0.9916591048240662
52852401,764,becketqin,2016-02-15T00:43:01Z,"sorry for the confusion, ""timestamptype"" in the comments should actually be ""wrappermessagetimestamptype"".",-1,0.9899622201919556
52852569,764,becketqin,2016-02-15T00:52:19Z,good catch. this might cause the test to just hang. it looks that in other multi-threaded test we have timeout in main thread. maybe we can do the same thing here.,1,0.9542058706283569
52852973,764,becketqin,2016-02-15T01:14:15Z,"i was also thinking about this when creating kafka-3203. currently we are also throwing invalidmessageexception if we non-keyed message for compacted topic. should we add invalidmagicbyteexception, invalidcodecexception, invalidtimestampexception and corresponding error mapping?",0,0.9908912777900696
52861805,764,junrao,2016-02-15T06:01:37Z,"yes, perhaps we can just add invalidtimestampexception in this patch and add others in kafka-3203.",0,0.9906689524650574
52861828,764,junrao,2016-02-15T06:02:18Z,"well, it may not hang. it just that if the assertion fails, the test may not fail since it only causes an exception in the callback thread. we can probably do sth like maintaining a successcount and check that at the end of flush.",0,0.9923452734947205
52861864,764,junrao,2016-02-15T06:03:24Z,"yes, you are right. didn't see the message format check in kafkaconfig. i think it's still better and simpler to just use the message format specified for the internal topic. this way, one can wait until inter protocol is upgraded to 0.10.0 in all brokers and then upgrade the message format w/o any conversion overhead. if we rely upon inter-broker protocol, there will still be some conversion while changing the inter-broker protocol in all brokers.",0,0.9760633707046509
52861870,764,junrao,2016-02-15T06:03:36Z,"thanks for the explanation. yes, i think this is fine since absolutebaseoffset is final.",1,0.9742847084999084
52861920,764,junrao,2016-02-15T06:04:11Z,"ok, sounds good.",1,0.509122371673584
52862221,764,junrao,2016-02-15T06:05:32Z,"could we also add sth like the following. in particular, after the message format is set to v1, one should not change it back to v0 since it may break the consumer on versions before 0.10.0.",0,0.9931232333183289
52862231,764,junrao,2016-02-15T06:05:39Z,"could we add the following breaking change in 0.10.0? messageformatter def writeto(key: array[byte], value: array[byte], timestamp: long, timestamptype: timestamptype, output: printstream)",0,0.9954442977905273
52862239,764,junrao,2016-02-15T06:05:55Z,indentation,0,0.9911677837371826
52862242,764,junrao,2016-02-15T06:06:01Z,are the changes in this file needed?,0,0.9952244758605957
52862251,764,junrao,2016-02-15T06:06:09Z,should we use magic v1 in this test?,0,0.9939894676208496
52862254,764,junrao,2016-02-15T06:06:13Z,typo converion,0,0.9890511631965637
52862293,764,junrao,2016-02-15T06:06:47Z,it's not clear why this is needed. isn't the default of message version v1?,0,0.9811652898788452
52862309,764,junrao,2016-02-15T06:06:56Z,could we put the block from 185 to 191 in a method and reuse it in the subsequent blocks?,0,0.992887556552887
52862322,764,junrao,2016-02-15T06:07:02Z,should we generate message of v1?,0,0.9950880408287048
52862344,764,junrao,2016-02-15T06:07:12Z,could we avoid duplicating the code btw v0 and v1?,0,0.9916040301322937
52862367,764,junrao,2016-02-15T06:07:23Z,"should we use message v1? since v1 is the default message format, it seems that v1 should be the format that we use in most tests.",0,0.9925661087036133
52862383,764,junrao,2016-02-15T06:07:31Z,"hmm, the overhead in message v1 is larger than message.minmessageoverhead.",0,0.9718044400215149
52862396,764,junrao,2016-02-15T06:07:36Z,"this same process can be used to upgrade from 0.8.x to 0.10.0, right?",0,0.9930435419082642
52865660,764,becketqin,2016-02-15T07:05:21Z,"just to clarify, by ""there will still be some conversion while changing the inter-broker protocol"", you meant downgrading inter-broker protocol, right? if user are bumping up inter-broker protocol, there will be no conversion. if so, considering inter-broker protocol downgrading is relatively rare and the impact is only during inter-broker protocol downgrade, does it still worth requiring user to change internal topic configuration as an extra step?",0,0.990012526512146
52865992,764,becketqin,2016-02-15T07:12:43Z,"right, we have already have successcount like check. the test hangs because we usually call flush() in main thread to ensure all the messages are sent. some callbacks won't fire if sender thread dies due to assertion failure, hence flush() blocks forever. i will instead use producer.close(timeout) in main thread so it does not wait forever for the callbacks.",0,0.9875505566596985
52869635,764,becketqin,2016-02-15T08:16:10Z,"yes, so i subtracted the additional timestamp length.",0,0.9927228093147278
52922474,764,junrao,2016-02-15T17:00:51Z,"if the message format is tied to the inter-broker protocol, the first broker that upgrades its inter-broker protocol to 0.10.0 will start to have v1 messages in its log. since the rest of the brokers' inter-broker protocol is still before 0.10.0, they can only send v1 fetch request. therefore, the first broker has to convert v1 messages down to v0 in the fetch response. if we decouple the message format from inter-broker protocol, we can first keep message format to be v0. after every broker upgrades inter-broker protocol to 0.10.0 and starts using v2 fetch request, we then change message format to v1. at that point, there is no message format conversion needed.",0,0.9867934584617615
52962132,764,ijuma,2016-02-16T02:14:23Z,`if user` would read better as `if the user`.,0,0.991157054901123
52962884,764,ijuma,2016-02-16T02:29:30Z,`overwritten by broker with broker local time when broker append` would read better as `overwritten by the broker with the broker local time when it appends`,0,0.9906173348426819
52963204,764,ijuma,2016-02-16T02:35:41Z,"`in either of the cases above, the timestamp that has actually been used will be returned to the user in`",0,0.9932159781455994
53015522,764,ijuma,2016-02-16T14:19:28Z,"shouldn't these be called `no_timestamp_type`, `create_time` and `log_append_time` since this is java code? i personally prefer the scala convention (which is what we are using here), but it is inconsistent with all the java enums i looked at.",0,0.9375244975090027
53017909,764,ijuma,2016-02-16T14:36:37Z,this doesn't seem to be used at the moment.,0,0.9735663533210754
53018211,764,ijuma,2016-02-16T14:38:50Z,"sorry if this has been mentioned elsewhere, but why don't we reuse the java `timestamptype` instead of introducing a duplicate instance in scala code?",-1,0.5967952609062195
53018917,764,ijuma,2016-02-16T14:44:21Z,"why are we using an atomiclong here? this code doesn't have to be thread-safe, right (we are adding to an arraylist a few lines below with no locking for example)?",0,0.9870460033416748
53035417,764,ijuma,2016-02-16T16:27:18Z,"why we are using a linkedlist here? it rarely makes sense to use it, even the person who wrote it says so ([a link]",0,0.9714260697364807
53036739,764,ijuma,2016-02-16T16:35:11Z,maybe `arraydeque` would be better?,0,0.9880111813545227
53040684,764,ijuma,2016-02-16T16:57:43Z,it would probably be good to mention that `inneriter` will always have at least one element (and hence why we can just call `next()` on it without calling `hasnext()` first).,0,0.9910452961921692
53040990,764,ijuma,2016-02-16T16:59:20Z,maybe reference `magic_value_v1` instead of hardcoding `1` here?,0,0.9909322261810303
53041472,764,bill-warshaw,2016-02-16T17:02:23Z,"how would you feel about adding a testing constructor for this class that matches the existing signature, and would just use dummy values for the timestamp and `timestamptype`? eliminating that constructor will break compilation for any unit tests that rely on building `consumerrecord`s",0,0.970407247543335
53048549,764,ijuma,2016-02-16T17:47:32Z,case 1 and 2 are the same at the moment. we could fall-through from case 1 to case 2 instead of having the same statement twice.,0,0.9885445237159729
53056249,764,becketqin,2016-02-16T18:39:32Z,do you mean the unit tests in projects other than kafka?,0,0.9923707246780396
53056903,764,bill-warshaw,2016-02-16T18:44:02Z,"yes. it's a minor change to update anywhere these constructors are used in unit tests, but any test that instantiates a `consumerrecord` isn't going to compile as soon as a user upgrades past `0.9.0.0`. we've used the `` annotation in the past to denote certain constructors that are only there for unit-testing.",0,0.9924150109291077
53058002,764,becketqin,2016-02-16T18:50:05Z,that makes sense. originally client side and server side timestamptype have some different methods. and i was thinking to combine the java and scala timestamptype class when we migrate server from message to record. we can probably combine the two classes in this patch.,0,0.988017201423645
53106467,764,becketqin,2016-02-17T00:54:53Z,"i am not sure if we should add the testing constructor for other projects. it is a little bit weird to have a testing constructor which never used by kafka but for some unknown external project. technically speaking consumerrecord should only be constructed by kafka, but not other projects. if we do so, arguably we should maintain the constructor backward compatibility for any public class, even though most of them are not supposed to be constructed by any user.",-1,0.9606946706771851
53110159,764,bill-warshaw,2016-02-17T01:39:29Z,"if `consumerrecord` is only intended to be instantiated by kafka, then i withdraw my comment. internal apis shouldn't be forced to remain backwards-compatible.",0,0.9799467921257019
53142209,764,ijuma,2016-02-17T09:58:29Z,"`consumerfetcherthread` and `simpleconsumer` still use this class. given that, are we sure that we don't need to add a mapping here?",0,0.9929904937744141
53143828,764,ijuma,2016-02-17T10:13:32Z,would this read better as `messagetimestampmaxdifferencems`?,0,0.9909640550613403
53144348,764,ijuma,2016-02-17T10:18:06Z,should we be catching `apiexception` instead of individual cases like this?,0,0.9846307635307312
53202790,764,becketqin,2016-02-17T17:52:22Z,only produce will see this error code. so i think we are fine here.,0,0.9627239108085632
53203160,764,becketqin,2016-02-17T17:54:35Z,"i agree that would read better (in fact i used to use that name), but it seems we have `""*maxms""` for other configurations, so i just followed the convention.",0,0.9837979674339294
53204217,764,becketqin,2016-02-17T18:00:52Z,i don't have strong opinion on this. one benefit of having individual cases is that it is clear what kind of api exceptions are expected since not all api exceptions can be thrown from replica manager.,0,0.6625592112541199
53263334,764,junrao,2016-02-18T02:08:56Z,"this comment is a bit hard to understand. given the comments at the beginning, we probably don't need the comment here.",-1,0.7520372271537781
53263338,764,junrao,2016-02-18T02:09:02Z,relative => inner,0,0.9932789206504822
53263354,764,junrao,2016-02-18T02:09:15Z,the way timestamp set is following => the way that timestamp is set is the following,0,0.9948636889457703
53263360,764,junrao,2016-02-18T02:09:21Z,is set => are set,0,0.9933098554611206
53263365,764,junrao,2016-02-18T02:09:26Z,following => the following,0,0.9924089908599854
53263370,764,junrao,2016-02-18T02:09:35Z,note => note; in a stream compressing way => in a streaming way,0,0.9890336990356445
53263375,764,junrao,2016-02-18T02:09:38Z,avoids => avoid,0,0.6084538102149963
53263382,764,junrao,2016-02-18T02:09:43Z,do we still need this comment?,0,0.9944447875022888
53263386,764,junrao,2016-02-18T02:09:50Z,it seems that minheadersize is the same as minmessageoverhead. could we consolidate them?,0,0.9936256408691406
53263400,764,junrao,2016-02-18T02:10:02Z,"would it be better to rename this to magicandlargesttimestamp()? also, the comment is outdated since we now return the magic as well.",0,0.9938346147537231
53263409,764,junrao,2016-02-18T02:10:07Z,could we use the constant variable instead of 0?,0,0.9918096661567688
53263420,764,junrao,2016-02-18T02:10:18Z,incorrect indentation. the original one is correct.,0,0.8542308211326599
53263431,764,junrao,2016-02-18T02:10:37Z,unused import here. could you check other classes too?,0,0.9928951859474182
53263446,764,junrao,2016-02-18T02:10:54Z,we probably shouldn't mention 0.10.0-iv0 since it's not intended for public usage.,0,0.9789591431617737
53263518,764,junrao,2016-02-18T02:11:50Z,"reworded the text a bit below. see if it's better. the maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message, if message.timestamp.type=createtime. a message will be rejected if the difference in timestamp exceeds this threshold. this configuration is ignored if message.timestamp.type=logappendtime.",0,0.9929649829864502
53263527,764,junrao,2016-02-18T02:11:58Z,"just to be consistent with what's in writeto, perhaps we should write the timestamp before key?",0,0.991234540939331
53263537,764,junrao,2016-02-18T02:12:07Z,"to avoid duplicating code, could we pull line 237 to 245 into a private method and then reuse?",0,0.9934412240982056
53263541,764,junrao,2016-02-18T02:12:11Z,invalid => invalid; ditto below.,0,0.9845865964889526
53263556,764,junrao,2016-02-18T02:12:21Z,"message.format.version change is an optimization. so, it's not really required. we can probably just cover that in the section on performance impact.",0,0.9920393228530884
53263559,764,junrao,2016-02-18T02:12:25Z,is this any different from any other topic?,0,0.9703444242477417
53263566,764,junrao,2016-02-18T02:12:33Z,"instead of using v1/v0 in the message format, it's probably easier to understand if we just use the api version.",0,0.9901229739189148
53263572,764,junrao,2016-02-18T02:12:40Z,"we can just say that ""for clients that are upgraded to 0.10.0.0, there is no performance impact.""",0,0.9898719191551208
53291250,764,ijuma,2016-02-18T09:44:46Z,fair enough.,0,0.9633647203445435
53291541,764,ijuma,2016-02-18T09:47:25Z,my concern is that it's easy to miss new `apiexception` instances that could be thrown by the code above since we don't get help by the compiler. but we can consider handling this in a separate pr as you are maintaining the existing approach.,0,0.9170204997062683
53322688,764,ijuma,2016-02-18T14:48:18Z,"is there a reason why we don't pass the timestamp as a parameter to `analyzeandvalidatemessageset`? that would mean that `timestamp` could be a `val` instead of `var`. it's a straightforward change, but it would mean that we read `config.messagetimestamptype` outside the synchronized block. is that a problem?",0,0.990545392036438
53342228,764,ijuma,2016-02-18T16:43:31Z,do we really need to mention the same thing so many times? it seems to me that it would be enough to mention once that message format 0 does not have a timestamp field and message format 1 does.,0,0.9747227430343628
53345876,764,ijuma,2016-02-18T17:05:16Z,"do we need this overload with timestamp and no timestamptype? there are only 3 usages in tests, i think i'd remove it.",0,0.9920008182525635
53383523,764,becketqin,2016-02-18T21:15:23Z,"if we do that, it seems possible to cause inconsistency order of message offset and timestamp. for example, message a comes and is stamped t1 by the broker, but before it is appended to the log, message b comes and is stamped t2 (t2 > t1) and gets appended to the log. after that, message a is appended. in this case, message a will have a smaller timestamp but a larger offset than message b, which is a bit confusing. we can put everything in the synchronized block, but it seems not worth doing if we only want to change a var to a val.",0,0.8764751553535461
53387576,764,becketqin,2016-02-18T21:44:34Z,"i am ok either way. as far as i understand, the purpose of the pre-existing constructor is to hide the payloadoffset and payloadsize from caller.",0,0.7400794625282288
53390466,764,ijuma,2016-02-18T22:06:34Z,"makes sense, thanks.",1,0.5818662643432617
53390818,764,ijuma,2016-02-18T22:09:44Z,"ok. since it was already there, better to handle the excessive use of constructor overloading separately.",0,0.9874721169471741
53413279,764,junrao,2016-02-19T01:51:17Z,can this be private?,0,0.9927625060081482
53413289,764,junrao,2016-02-19T01:51:25Z,the following properties => the following property,0,0.9949997663497925
53413303,764,junrao,2016-02-19T01:51:33Z,message format 0.10.0 => the message format in 0.10.0,0,0.9942523837089539
53413305,764,junrao,2016-02-19T01:51:35Z,of format 0.10.0 to earlier format => of the format in 0.10.0 to an earlier format,0,0.9873613119125366
53413325,764,junrao,2016-02-19T01:51:48Z,"could we add what the interface is changed from? also, def is scala specific. we just need to include the java interface.",0,0.9946229457855225
53413342,764,junrao,2016-02-19T01:52:02Z,indicate the client support quota => indicate that the client supports quota,0,0.9938532114028931
53413403,764,junrao,2016-02-19T01:53:09Z,reworded this a bit to the following. see if it's better. ditto in topiccommand. this configuration will be ignored if the value is on a version newer than that specified in inter.broker.protocol.version in the broker.,0,0.9944120049476624
53413412,764,junrao,2016-02-19T01:53:16Z,is the above addressed?,0,0.9946975708007812
53415057,764,becketqin,2016-02-19T02:18:05Z,it seems we cannot add scope modifier to a code block. compiler gives the following error: [code block] `verifyconvertedmessageset` itself seems private by nature and only accessible in `testmessageformatconversion`.,0,0.9925324320793152
53417265,764,becketqin,2016-02-19T02:50:09Z,"hi jun, this comment seems not accurate based on the current code. what we actually check is the message format version, not kafka version. for example, the current code will allow the message.format.version to be set to 0.9.0 even if the inter.broker.protocol.version is 0.8.2, because the underlying message.format.versions of those two kafka versions are the same. at some point i thought there was a use case for this, but i cannot think of any now. it is probably better to enforce the check as you described. i will make this change in the updated patch.",0,0.9181843996047974
1235169801,13870,dajac,2023-06-20T12:07:23Z,nit: could we prefix all those attributes with `genericgroup`?,0,0.9923930168151855
1235170208,13870,dajac,2023-06-20T12:07:48Z,we can't use the same config both both the consumer and the generic group because we have two configs for each.,0,0.9837344884872437
1235171243,13870,dajac,2023-06-20T12:08:49Z,nit: we can remove this one as there is the same phrase in the javadoc.,0,0.9924277663230896
1235178394,13870,dajac,2023-06-20T12:15:13Z,i am not a fan of returning a `group` here because it means that the caller have to cast the returned value. is it possible to avoid it?,-1,0.5304498672485352
1235178804,13870,dajac,2023-06-20T12:15:34Z,should we move this to the request validation?,0,0.9947109222412109
1235179626,13870,dajac,2023-06-20T12:16:19Z,i would remove this because it will be outdated extremely quickly.,0,0.9513518810272217
1235180677,13870,dajac,2023-06-20T12:17:16Z,should we have a method helper to validate the request?,0,0.9936556816101074
1235188456,13870,dajac,2023-06-20T12:24:19Z,nit: would it make sense to update `plainprotocolset` to take `request.protocols()`?,0,0.9862087965011597
1235190243,13870,dajac,2023-06-20T12:25:52Z,"when the group is created to the first time, i think that we need to write a record to the log; the group could be reverted in the timeline hash map otherwise.",0,0.9919834733009338
1235202608,13870,dajac,2023-06-20T12:36:20Z,we need to discuss whether we want to start the heartbeat timer here or not. see [a link].,0,0.9949204325675964
1235206095,13870,dajac,2023-06-20T12:39:01Z,"do we still need `hassatisfiedheartbeat` in the new model? if the timeout expires, it seems to me that it means that the member has failed to heartbeat in time; the timer would have been reset otherwise.",0,0.9914451837539673
1235232078,13870,dajac,2023-06-20T12:59:58Z,i wonder if we should use a different timer for this case. have you considered it?,0,0.9600005745887756
1235241285,13870,dajac,2023-06-20T13:07:13Z,"instead of storing the initial rebalance timeout and the initial rebalance delay in the group, could we imagine passing them as arguments to `trycompleteinitialrebalanceelseschedule`? that could simplify the logic as everything would be self contain here.",0,0.9921557903289795
1235274474,13870,dajac,2023-06-20T13:31:31Z,what happens if the group instance id is an empty string?,0,0.9880870580673218
1235276378,13870,dajac,2023-06-20T13:32:56Z,i suppose that being here means that group instance id is null.,0,0.9898109436035156
1235277768,13870,dajac,2023-06-20T13:33:58Z,i have seen this code in a few place. it would be great to avoid it if possible.,0,0.6555826663970947
1235310632,13870,dajac,2023-06-20T13:56:02Z,shouldn't we use `completablefuture ` and complete the future exceptionally with the exception corresponding to the error?,0,0.9927547574043274
1235497178,13870,jeffkbkim,2023-06-20T16:11:16Z,i think we should store generic groups separately. the added benefit here is that we wouldn't have to create a new record when a new group was created as you have mentioned in the comment below. wdyt?,0,0.9821703433990479
1235653740,13870,jeffkbkim,2023-06-20T18:24:23Z,i removed this; we have request validation in groupcoordinatorservice#joingroup. what do you think of having all request validation there?,0,0.9890530705451965
1235733198,13870,jeffkbkim,2023-06-20T19:26:09Z,"i don't think this fits well because we may have other records to append in this method. as mentioned above, i will store the generic groups in a separate hash map to prevent this from happening.",0,0.9797497987747192
1235734010,13870,jeffkbkim,2023-06-20T19:26:49Z,see [a link],0,0.9957407712936401
1235752587,13870,jeffkbkim,2023-06-20T19:46:36Z,"so that i understand: during completing rebalance, we schedule both pending sync (rebalance timeout) and heartbeats (session timeout). in practice, session timeout << rebalance timeout so heartbeats would expire and remove members. with cooperative rebalancing members should still be able to fetch records during completing rebalance phase. we want to extend the heartbeat here to rebalance timeout so that members are not removed by session timeout. is this correct? if so, i agree removing the heartbeat schedule sounds like the best approach since members are removed when pending sync expires anyways.",0,0.943710446357727
1235808438,13870,jeffkbkim,2023-06-20T20:44:35Z,if the member is awaiting on a join/sync response then we can't remove the member on hb expiration right?,0,0.9917141795158386
1235813521,13870,jeffkbkim,2023-06-20T20:50:21Z,are you suggesting a different key? what would be the benefit?,0,0.9923079013824463
1235818207,13870,jeffkbkim,2023-06-20T20:54:59Z,initial rebalances don't have check and complete as try complete always returns false so this works. thanks,1,0.9759230613708496
1235822238,13870,jeffkbkim,2023-06-20T20:58:34Z,the existing protocol allows empty group instance ids for static member,0,0.9946385025978088
1235823024,13870,jeffkbkim,2023-06-20T20:58:57Z,"you're right, removed.",0,0.9747255444526672
1238417804,13870,dajac,2023-06-22T11:51:17Z,"i am not convinced. the downside is that it will be harder to guarantee to uniqueness of the group id. it also means that we would have to check both maps for all other operations (e.g. list, delete, etc.). i think that it would be better to keep them in a single map. for this particular case, we could just have two methods: `getormaybecreateconsumergroup` and `getormaybecreategenericgroup`.",0,0.7051481604576111
1238418966,13870,dajac,2023-06-22T11:52:26Z,i think that static validation could be done in the group coordinator service; however we have to keep the validation which depends on internal values in the state machine.,0,0.9871852993965149
1238484735,13870,dajac,2023-06-22T12:52:04Z,"that's correct. however, it may be better to just cancel the previous one.",0,0.9926447868347168
1238491877,13870,dajac,2023-06-22T12:58:00Z,i think that the non-error case is actually incorrect based on the implementation in the runtime. the issue is that the future will be completed immediately after the records are written. this means that we would send the response before the record is committed. i think that the future should be completed only when the records are committed.,0,0.9801807999610901
1238494924,13870,dajac,2023-06-22T13:00:19Z,"what does happen when this exception is thrown? i mean, where is it handled?",0,0.9882676005363464
1238559395,13870,dajac,2023-06-22T13:48:16Z,did you consider using a switch here? it seems that it would fit nicely.,0,0.9715064167976379
1238565407,13870,dajac,2023-06-22T13:52:35Z,nit: should we have an method such as `hasassignment()` in member?,0,0.9916762113571167
1238585947,13870,dajac,2023-06-22T14:06:54Z,this feels a bit like a hack. i was wondering if we could push that call to `completegenericgroupjoin(group)` into the `genericgroupjoinnewmember` and `genericgroupjoinexistingmember` paths instead of handling it here for all cases. is it something that you have considered?,-1,0.9209770560264587
1238591771,13870,dajac,2023-06-22T14:11:10Z,"this is correct. btw, if we remove it, i think that we need to ensure that the session timeout is cancelled when a member rejoins.",0,0.9888030886650085
1238593470,13870,dajac,2023-06-22T14:12:26Z,"correct. however i think that the fundamental issues is that we do not cancel the session timeout while doing a rebalance. this is why we have this condition here. if we fix this, we may be able to remove it.",0,0.9770500659942627
1238594022,13870,dajac,2023-06-22T14:12:53Z,right. separation of concerns would be the benefit.,0,0.9815446138381958
1238626957,13870,dajac,2023-06-22T14:37:10Z,it seems that the condition was `group.is(empty)` in scala. what's the reason for changing it?,0,0.9930839538574219
1238627417,13870,dajac,2023-06-22T14:37:28Z,nit: extra empty line.,0,0.9813311696052551
1238630708,13870,dajac,2023-06-22T14:39:46Z,"actually, it seems that `completegenericgroupjoin` is already called in a few places on those paths.",0,0.9916536211967468
1238633046,13870,dajac,2023-06-22T14:41:05Z,nit: should we have an overload of `supportsprotocols` which takes `request.protocols()`?,0,0.9883329272270203
1238643069,13870,dajac,2023-06-22T14:48:13Z,nit: could we move this to the test then?,0,0.9905391931533813
1238647097,13870,dajac,2023-06-22T14:51:16Z,nit: let's remove this one as well.,0,0.9765772223472595
1238724392,13870,dajac,2023-06-22T15:49:12Z,"one issue here is that if `generaterecordsandappendfuture` thrown an exception (e.g. due to a bug), the request will never be completed because the future is not available yet. if we reuse `coordinatorwriteevent`, we could subscribe to the future returned by it and complete the response when an exception is raised.",0,0.9709110260009766
1238725344,13870,dajac,2023-06-22T15:49:57Z,we probably need to convert some of the exceptions like i did for the consumer group heartbeat request.,0,0.9907091856002808
1239316537,13870,jeffkbkim,2023-06-23T04:48:54Z,are you referring to any lingering heartbeats at this point? i think we can just cancel them here right,0,0.9916831254959106
1239318379,13870,jeffkbkim,2023-06-23T04:53:31Z,"i think we can cancel the existing heartbeat when a member rejoins during a rebalance. this will still expire if the member does not rejoin which is what we want. also, moving the new member join timeout to a different key will help remove this `hassatisfiedheartbeat`. is that what you had in mind?",0,0.9882223010063171
1239320095,13870,jeffkbkim,2023-06-23T04:57:15Z,i expected that kafkaapis#handlejoingrouprequest will handle them. is that not the case?,0,0.9917463064193726
1240399005,13870,jeffkbkim,2023-06-23T21:09:13Z,"this is now further worsened with the new records on creating a group. the only ""non-hacky"" approach i can think of is just returning `list , record>` which the runtime would append & commit then complete in order. but this adds a lot of complexity for something we actually won't use in practice. the other approach (which i have implemented) is to ignore the result from `completegenericgroupjoin` when invoked from the join group path. this works because `completegenericgroupjoin` only produces records when a member expires. also, when a new group is created we don't have any other records to append. however, this still feels a bit hacky. not sure how to resolve this.",0,0.8184889554977417
1240415098,13870,jeffkbkim,2023-06-23T21:23:12Z,"i thought the ""initial"" rebalance only applied to when the group is first created from [a link] but according to [a link] it looks like we want this for an empty group as well so, i will revert this change. however, it's awkward because here we consider ""initial rebalance"" to be an empty group. but a different part of the code checks generation id == 0. maybe it's because we don't know the previous state from groupcoordinator#addmemberandrebalance: [code block] i think we need to revert the change and include `initialrebalancedelayms` to the genericgroup object and rely on that to check whether the group is undergoing an initial rebalance.",-1,0.9074469804763794
1240441622,13870,jeffkbkim,2023-06-23T21:58:30Z,"i'm a bit confused, is the coordinator write operation future the result we wait for committing?",-1,0.9289036989212036
1243806647,13870,dajac,2023-06-27T14:04:01Z,"how about the following? we keep track whether the group was newly created in a boolean. when we get the result from those methods, we check if the group is new, if it is, we check if the result has at least one record. if it does not, we recreate it while adding an empty record for the group.",0,0.9931203126907349
1246778958,13870,dajac,2023-06-29T15:21:28Z,"yeah, it seems that the current implementation is inconsistent.",0,0.9555097222328186
1246964799,13870,CalvinConfluent,2023-06-29T18:24:56Z,the timer is not used yet. is it a place holder here?,0,0.9943612813949585
1246972433,13870,CalvinConfluent,2023-06-29T18:33:21Z,"i guess i missed some of the previous discussions, but why it is always either stable or empty when we load a group? does it mean the rebalancing process will be reverted if the coordinator fails?",0,0.9783052802085876
1246984793,13870,CalvinConfluent,2023-06-29T18:46:27Z,"the genericgroupjoinmember can returns a result, why don't we use the return value?",0,0.9935275912284851
1246995181,13870,CalvinConfluent,2023-06-29T18:56:21Z,do we need to handle the illegalstateexception(when member id is not known) and complete the responsefuture here?,0,0.9944106936454773
1247810650,13870,dajac,2023-06-30T12:31:40Z,"sorry, i was not clear. i meant that we need to port this [a link] here.",-1,0.962035059928894
1247812716,13870,dajac,2023-06-30T12:34:06Z,"nit: i am not a fan of this validation. i wonder if we should just have two helpers: `isgroupidnotnull` and `isgroupidnotempty`. in this pr, we would only need `isgroupidnotempty`. what do you think?",-1,0.9467021226882935
1247814090,13870,dajac,2023-06-30T12:35:49Z,"i wonder if we need to handle the future returned by `schedulewriteoperation` as well. at minimum, we may want to react to errors. this could for instance happen if something goes wrong before the join group handling is event triggered.",0,0.9725908637046814
1247815228,13870,dajac,2023-06-30T12:37:09Z,nit: `completionfuture` or smth similar may be a better name here because we could have an operation without any records.,0,0.9904689192771912
1247815765,13870,dajac,2023-06-30T12:37:47Z,how about adding a boolean `replayrecords` to the coordinatorresult?,0,0.995053231716156
1247816731,13870,dajac,2023-06-30T12:38:40Z,"i wonder if we should complete both future here. as `schedulewriteoperation` returns a future, it may be missed used otherwise. what do you think?",0,0.9539849162101746
1247817889,13870,dajac,2023-06-30T12:39:56Z,nit: could we revert this?,0,0.9835822582244873
1247820936,13870,dajac,2023-06-30T12:43:22Z,"`topicpartition` should also be required, i think.",0,0.9916267395019531
1247822722,13870,dajac,2023-06-30T12:45:23Z,i think that the group should be deleted in this case.,0,0.9714946746826172
1247825718,13870,dajac,2023-06-30T12:48:37Z,i wonder if we could avoid passing the version to this method by adding `-1` as the default value of `rebalancetimeout` in `groupmetadatavalue`. it seems that we could rely on this to decide here. another way that i was thinking about would be to pass the `record` to the replay method as it contains all the available information. have you considered this?,0,0.9828609228134155
1247826747,13870,dajac,2023-06-30T12:49:45Z,"we only write a record when the rebalance completes. this implies that the record is always empty or has members. as you pointed out, a failure happening before the rebalance complete is lost.",0,0.9914653897285461
1247831310,13870,dajac,2023-06-30T12:54:40Z,have you considered checking if the group exists in the map instead of adding this field? using a field like this has the disadvantage that we must ensure that it is set to false. i think that your implementation already misses it.,0,0.9823758006095886
1247837102,13870,dajac,2023-06-30T13:00:46Z,don't we need to fail the future if the write fails? or is it done somewhere else?,0,0.9856776595115662
1247839533,13870,dajac,2023-06-30T13:03:09Z,i am not satisfied with this logic here. i think that other folks won't understand this... we need to come up with a better way. i will think about it. i don't recall if i already asked this but would it be possible to push `completegenericgroupjoin` into `genericgroupjoinnewmember` and `genericgroupjoinexistingmember` instead of having it here?,-1,0.9588033556938171
1247843963,13870,dajac,2023-06-30T13:07:41Z,"hum... those exceptions will be caught by the `coordinatorwriteevent` and used to complete the future there. so, i suppose that they will be propagated to the api layer via this mechanism. do i get this right?",0,0.9279748797416687
1247846953,13870,dajac,2023-06-30T13:10:13Z,could we remove this? `genericgroupnewmemberjointimeoutms` is very likely passed to this object by the test itself so i am not sure to understand why we need to expose it to the test. is there a reason?,0,0.9885843992233276
1253477738,13870,jeffkbkim,2023-07-05T18:25:13Z,"i don't think this is the right place; we need to add the logic inside group metadata manager. i have done so in the sync pr. the reason is that for generic group apis, the append future is what we want the logic for when handling log append/commit errors. whereas for the new protocol, the consumer group heartbeat waits to return the results from the append/commit.",0,0.9707821607589722
1253484339,13870,jeffkbkim,2023-07-05T18:32:34Z,i'll remove this for now and add it back if we decide to pass it in later.,0,0.9921302199363708
1253487385,13870,jeffkbkim,2023-07-05T18:36:08Z,the approach is hacky. will be thinking of a different approach to resolve this,-1,0.9854757189750671
1253522689,13870,jeffkbkim,2023-07-05T19:11:59Z,"i will take your suggestion for this pr. however, it does make more sense to have the logic in one place instead of using isgroupidnotnull/isgroupidnotempty based on the request.",0,0.9889483451843262
1253525703,13870,jeffkbkim,2023-07-05T19:15:48Z,this is only used when records are generated (and need to be appended to the log) so i think append future makes more sense. `completionfuture` will be confusing alongside coordinator event's `future` field. wdyt?,0,0.9762895703315735
1253814655,13870,jeffkbkim,2023-07-06T01:27:38Z,for 1) doesn't it require a bump in the group metadata value version to add the default value? 2) i don't see much value in this and it feels more different to handle it this way compared to other record types in replicatedgroupcoordinator#replay(record),0,0.969761312007904
1253817939,13870,jeffkbkim,2023-07-06T01:33:42Z,will revisit this after refactoring the coordinatorresult return type / generate multiple records discussion. the reason that a field was set is because where we add the group to `groups` (and initialize the append future) and where we set it as a return type (l1265) are at different places. once the group is added we can't check via groups.get(groupid).,0,0.9932531714439392
1253948284,13870,jeffkbkim,2023-07-06T05:26:40Z,the write event will catch the exception and complete the event's future. i added a handler to groupcoordinatorservice.java for these unexpected exceptions.,0,0.994682252407074
1253948390,13870,jeffkbkim,2023-07-06T05:26:50Z,added a previousstate to genericgroup. we will rely on this instead to confirm that a group is undergoing an initial rebalance (previous state == empty),0,0.9955850839614868
1253948479,13870,jeffkbkim,2023-07-06T05:27:00Z,"yeah, i will log an error for this",0,0.9626228213310242
1254577233,13870,dajac,2023-07-06T15:07:30Z,i think that we can remove this and `metadataimage` as [a link] was merged.,0,0.9907370209693909
1254579000,13870,dajac,2023-07-06T15:08:56Z,why do we only handle `illegalstateexception` here? why if we get an unexpected npe for instance.,0,0.9810814261436462
1254579343,13870,dajac,2023-07-06T15:09:12Z,nit: this could be static.,0,0.982898473739624
1254580740,13870,dajac,2023-07-06T15:10:16Z,nit: should we move those two back to where they where?,0,0.7762578725814819
1254582473,13870,dajac,2023-07-06T15:11:39Z,could we move this one back to where it was? it should stay together with the other `withconsumergroup*` methods.,0,0.9945934414863586
1254582995,13870,dajac,2023-07-06T15:12:04Z,why did we move this one?,0,0.9904724359512329
1254584209,13870,dajac,2023-07-06T15:13:07Z,nit: empty line could be removed.,0,0.9938644766807556
1254584535,13870,dajac,2023-07-06T15:13:21Z,nit: should we revert this change?,0,0.9646462202072144
1254584801,13870,dajac,2023-07-06T15:13:33Z,nit: should we revert this change?,0,0.9646462202072144
1254585208,13870,dajac,2023-07-06T15:13:52Z,nit: should we revert this change?,0,0.9646462202072144
1254585768,13870,dajac,2023-07-06T15:14:19Z,nit: should we revert this change?,0,0.9646462202072144
1254587698,13870,dajac,2023-07-06T15:15:51Z,1) good question. the schema remains the same so it should be ok. it only adds a default value to the field.,1,0.981325626373291
1254612652,13870,dajac,2023-07-06T15:36:23Z,"i am not sure to follow. it seems to me that you could have a local boolean to track this. for instance, before calling `getormaybecreategenericgroup`, you could initialise a variable `groupexists` by checking the map.",0,0.9362764358520508
1254999681,13870,jeffkbkim,2023-07-06T22:53:31Z,"i misunderstood, moved to using a local variable",0,0.800063967704773
1255794837,13870,dajac,2023-07-07T13:05:30Z,would it make sense to move this block into the `if (isnewgroup && result == empty_result)`?,0,0.9937800765037537
1255797868,13870,dajac,2023-07-07T13:08:02Z,remember this [a link]? don't we need to convert the exception here as well? this is why i was suggesting to do it in the service to ensure that we do it in all cases.,0,0.9947758913040161
1255798698,13870,dajac,2023-07-07T13:08:41Z,nit: javadoc?,0,0.9899388551712036
1255799314,13870,dajac,2023-07-07T13:09:08Z,nit: empty line could be removed.,0,0.9938644766807556
1255799771,13870,dajac,2023-07-07T13:09:29Z,nit: empty line.,0,0.9438178539276123
1255800519,13870,dajac,2023-07-07T13:10:02Z,nit: empty line.,0,0.9438178539276123
1255803548,13870,dajac,2023-07-07T13:12:27Z,nit: incomplete javadoc.,0,0.9844071865081787
1255807406,13870,dajac,2023-07-07T13:15:14Z,nit: `containskey`?,0,0.9934678673744202
1255809962,13870,dajac,2023-07-07T13:17:08Z,nit: empty line.,0,0.9438178539276123
1255812336,13870,dajac,2023-07-07T13:18:48Z,nit: do we need this as all the states are covered?,0,0.990471601486206
1255826174,13870,dajac,2023-07-07T13:28:59Z,nit: should we inline this condition and move the comment within the branch?,0,0.9920440912246704
1255827611,13870,dajac,2023-07-07T13:30:02Z,nit: should we name this variable `newmember`?,0,0.9896543025970459
1255828754,13870,dajac,2023-07-07T13:30:54Z,nit: this could be inlined.,0,0.991331934928894
1255828976,13870,dajac,2023-07-07T13:31:03Z,nit: empty line.,0,0.9438178539276123
1255830986,13870,dajac,2023-07-07T13:32:33Z,nit: how about using: `.setmembers(isleader ? group.currentgenericgroupmembers() : collections.emptylist())`?,0,0.9920259118080139
1255832177,13870,dajac,2023-07-07T13:33:23Z,nit: i think that the error code is zero by default so we don't have to set it.,0,0.9847999811172485
1255832458,13870,dajac,2023-07-07T13:33:35Z,nit: empty line.,0,0.9438178539276123
1255833047,13870,dajac,2023-07-07T13:34:01Z,nit: empty line.,0,0.9438178539276123
1255833259,13870,dajac,2023-07-07T13:34:11Z,nit: ditto about error code.,-1,0.9145016074180603
1255833655,13870,dajac,2023-07-07T13:34:27Z,nit: empty line.,0,0.9438178539276123
1255836858,13870,dajac,2023-07-07T13:36:43Z,nit: empty line.,0,0.9438178539276123
1255838176,13870,dajac,2023-07-07T13:37:41Z,nit: the code style is a bit inconsistent between this line and l2526. i don't have a preference but it would be great if we could use the same format everywhere.,0,0.6947187185287476
1255839487,13870,dajac,2023-07-07T13:38:39Z,i think that we can remove those. it is clear that we do nothing for this state if it is not listed before. there are a few other cases.,0,0.9853271245956421
1255840000,13870,dajac,2023-07-07T13:39:00Z,is this used anywhere?,0,0.9940593242645264
1255849529,13870,dajac,2023-07-07T13:45:55Z,nit: empty line.,0,0.9438178539276123
1255851195,13870,dajac,2023-07-07T13:46:55Z,nit: empty line.,0,0.9438178539276123
1255863985,13870,dajac,2023-07-07T13:56:07Z,we could inline this as suggested earlier.,0,0.9941412806510925
1255864318,13870,dajac,2023-07-07T13:56:20Z,we can omit setting the error code.,0,0.9929845333099365
1255865580,13870,dajac,2023-07-07T13:57:08Z,ditto.,0,0.9384599328041077
1255868223,13870,dajac,2023-07-07T13:58:55Z,we need to update the javadoc here. i also wonder if we could find a better name now as it may also complete the join phase.,0,0.9911552667617798
1255878155,13870,dajac,2023-07-07T14:05:34Z,nit: we usually use `maybe`. i understand that this comes from the old purgatories but it may be better to use the correct naming convention.,0,0.9856857061386108
1255881371,13870,dajac,2023-07-07T14:07:59Z,nit: empty line.,0,0.9438178539276123
1255883963,13870,dajac,2023-07-07T14:09:59Z,nit: you can replace `{}-{}` with `{}` and directly pass the topicpartition.,0,0.9940641522407532
1255885261,13870,dajac,2023-07-07T14:10:54Z,nit: package private for testing.,0,0.9938995838165283
1255886494,13870,dajac,2023-07-07T14:11:43Z,nit: empty line.,0,0.9438178539276123
1255889149,13870,dajac,2023-07-07T14:13:25Z,nit: empty line.,0,0.9438178539276123
1255892012,13870,dajac,2023-07-07T14:15:01Z,why do we need a copy here?,0,0.9906747937202454
1255894010,13870,dajac,2023-07-07T14:16:12Z,could we expand this comment a little?,0,0.993073046207428
1255894583,13870,dajac,2023-07-07T14:16:34Z,we can remove this now.,0,0.9951152801513672
1256037213,13870,jeffkbkim,2023-07-07T15:48:20Z,which illegal state exception are you referring to?,0,0.9853062629699707
1256038506,13870,jeffkbkim,2023-07-07T15:49:17Z,"as discussed offline, we will complete both futures. the append future will be completed first and the event future will complete the join response if it's not already completed.",0,0.9945189356803894
1256056130,13870,jeffkbkim,2023-07-07T16:02:32Z,updated to all errors.,0,0.9928655624389648
1256069184,13870,jeffkbkim,2023-07-07T16:08:58Z,reverted the ordering,0,0.9902515411376953
1256110776,13870,jeffkbkim,2023-07-07T16:37:10Z,the issue is that the records need to be generated while the group is empty. after performing `genericgroupjoinnewmember()` the group will have added the member metadata. the existing protocol only allows records for empty groups or groups that have a defined protocol. this only applies to join group requests with `requireknownmemberid = false` or group instance id.,0,0.9911335110664368
1256152143,13870,jeffkbkim,2023-07-07T17:10:29Z,the main concern i had was completegenericgroupjoin() can be invoked by the timer which would miss this conversion but i guess it's not really an issue.,0,0.9716401696205139
1256157423,13870,jeffkbkim,2023-07-07T17:14:57Z,i added this in case we add a new state in the future. should i remove it?,0,0.9934433698654175
1256163265,13870,jeffkbkim,2023-07-07T17:19:38Z,isn't it more readable to keep it?,0,0.9881702661514282
1256180440,13870,jeffkbkim,2023-07-07T17:33:38Z,in `groupmetadatamanager#expirependingsync()` we remove members from the set while iterating,0,0.9941959381103516
1258225411,13870,dajac,2023-07-10T12:59:31Z,i wonder if we should remove this because it will log all errors now.,0,0.8544376492500305
1258226163,13870,dajac,2023-07-10T13:00:04Z,i am a bit confused here. don't we need to apply this conversion to `responsefuture` as well?,-1,0.814864993095398
1258226528,13870,dajac,2023-07-10T13:00:20Z,you can remove this one because it can't happen now.,0,0.9939274787902832
1258226646,13870,dajac,2023-07-10T13:00:26Z,ditto.,0,0.9384599328041077
1258228530,13870,dajac,2023-07-10T13:01:52Z,"it may be better to inline this code because the handling could be different depending on the request type. if i remember correctly, it is slightly different for offset commits for instance.",0,0.9884200096130371
1258228818,13870,dajac,2023-07-10T13:02:07Z,could we bring this back?,0,0.9929034113883972
1258229353,13870,dajac,2023-07-10T13:02:32Z,nit: should we add `throws groupidnotfoundexception`?,0,0.9902932643890381
1258230722,13870,dajac,2023-07-10T13:03:38Z,i think that we should rather add this to the `onloaded` method rather than here. the issue is that it will also log all the non-compacted records and that will be misleading.,0,0.9766653776168823
1258231101,13870,dajac,2023-07-10T13:03:55Z,nit: `data structure`?,0,0.9910827875137329
1258231284,13870,dajac,2023-07-10T13:04:03Z,nit: remove empty line.,0,0.9926633834838867
1258232766,13870,dajac,2023-07-10T13:05:13Z,"for my understanding, we don't fail the future here because the event future will do it. am i correct?",0,0.9901138544082642
1258235016,13870,dajac,2023-07-10T13:06:59Z,i see. i wonder if we could have a `newgroupemptymetadatarecord` which generate an empty record for the group in this case to avoid this issue. would this work? i am asking because i think that centralising would simplify the code.,0,0.9843481183052063
1258236219,13870,dajac,2023-07-10T13:07:54Z,nit: `maybe...`?,0,0.9792977571487427
1258269899,13870,dajac,2023-07-10T13:30:30Z,nit: i was considering whether we should have an helper in the joinrequest class for this. it could be something like `joinrequest#requireknownmemberid(short version)`. that advantage is that it would centralize all the version handling in one place. we could do the same for the other similar cases. what do you think?,0,0.9571566581726074
1258278071,13870,dajac,2023-07-10T13:35:54Z,"we can keep it, i suppose.",0,0.9856675863265991
1258280008,13870,dajac,2023-07-10T13:37:15Z,"nit: could we expand this error a little? it would be great if it could capture that it failed to update the metadata for a static member, etc.",0,0.8899234533309937
1258280313,13870,dajac,2023-07-10T13:37:27Z,i would remove them.,0,0.9545704126358032
1258281079,13870,dajac,2023-07-10T13:37:58Z,"nit: `"" + ""` the `+` in this case is not needed.",0,0.994172990322113
1258287486,13870,dajac,2023-07-10T13:42:02Z,"i just noticed that whenever we use `joinreason`, we also have the `joingrouprequestdata`. how about adding a helper in `joinrequest` class to get the reason from `joingrouprequestdata`? then, we don't have to pass it anymore to all the methods and we can remove the logic to compute it in `genericgroupjoin`. what do you think?",0,0.982648491859436
1258291357,13870,dajac,2023-07-10T13:44:19Z,nit: `replayrecords`?,0,0.9930353164672852
1258295996,13870,dajac,2023-07-10T13:47:02Z,i was wondering if the following is simpler: [code block] then [code block] i leave it up to you.,0,0.9869322180747986
1258313403,13870,dajac,2023-07-10T13:57:05Z,why is this false?,0,0.958389937877655
1258314600,13870,dajac,2023-07-10T13:57:49Z,it may be better to validate the full response here.,0,0.9891818165779114
1258314933,13870,dajac,2023-07-10T13:58:02Z,do we need to add tests for the errors convertion?,0,0.9950308799743652
1258319481,13870,dajac,2023-07-10T14:01:24Z,should we revert this?,0,0.9826757907867432
1258320244,13870,dajac,2023-07-10T14:02:02Z,could we revert this?,0,0.991129994392395
1258320551,13870,dajac,2023-07-10T14:02:16Z,why are we changing this?,0,0.9684451818466187
1258320790,13870,dajac,2023-07-10T14:02:26Z,nit: empty line.,0,0.9438178539276123
1258356121,13870,dajac,2023-07-10T14:29:27Z,this feels weird.... you pass the expected result and you alter it here. i think that it would be better to separate concerns and to return records and future to the caller and to let it do the validation.,-1,0.9925370812416077
1258356713,13870,dajac,2023-07-10T14:29:54Z,"do we need this? if we do, we should replace `e.printstacktrace();`.",0,0.9955946803092957
1258356890,13870,dajac,2023-07-10T14:30:03Z,ditto.,0,0.9384599328041077
1258362905,13870,dajac,2023-07-10T14:34:12Z,is this needed? i would have thought that the group should have been created by the first request.,0,0.9893688559532166
1258367695,13870,dajac,2023-07-10T14:37:48Z,nit: empty line.,0,0.9438178539276123
1258368278,13870,dajac,2023-07-10T14:38:12Z,is this needed as well?,0,0.9933544397354126
1258375164,13870,dajac,2023-07-10T14:43:18Z,"why do we need to handle the first request differently? is it because it may generate a record? if so, i would not do this in every tests but only in one test focused on this.",0,0.989997148513794
1258375867,13870,dajac,2023-07-10T14:43:48Z,"nit: `intstream.range(0, groupmaxsize + 1)` that you just used above is pretty nice. i wonder if we could use it here as well.",1,0.9560748338699341
1258376361,13870,dajac,2023-07-10T14:44:07Z,do we need this?,0,0.9930108189582825
1258378853,13870,dajac,2023-07-10T14:45:53Z,ditto.,0,0.9384599328041077
1258379838,13870,dajac,2023-07-10T14:46:31Z,nit: you should try to use the stream api more often.,0,0.9832116961479187
1258387036,13870,dajac,2023-07-10T14:51:10Z,"in scala, we had `unknown_member_id` here. is the change expected?",0,0.9949376583099365
1258391017,13870,dajac,2023-07-10T14:53:33Z,"in scala, this test runs with a dynamic member and a static member. we don't do the static part here. why?",0,0.9913402199745178
1258394371,13870,dajac,2023-07-10T14:55:54Z,we were asserting the leader here.,0,0.9839165806770325
1258396521,13870,dajac,2023-07-10T14:57:25Z,there is a `+ 1` in scala. don't we need it here?,0,0.9939088821411133
1258398177,13870,dajac,2023-07-10T14:58:35Z,nit: you can do: `group.allmembers().iterator().next()`.,0,0.9895455241203308
1258400111,13870,dajac,2023-07-10T15:00:00Z,there is a + 1 in scala.,0,0.9944993257522583
1258406471,13870,dajac,2023-07-10T15:04:08Z,there is `unknown_member_id` in scala?,0,0.9950372576713562
1258410034,13870,dajac,2023-07-10T15:06:24Z,is this a new test?,0,0.991793692111969
1258924230,13870,jeffkbkim,2023-07-10T21:17:10Z,this would log all errors while appending/committing and if `generaterecordsandresponse` throws an unexpected exception. shouldn't we log them? it doesn't seem like we do for `consumergroupheartbeat()` -- maybe just filter out the coordinator not available / not coordinator error codes?,0,0.9940998554229736
1258933631,13870,jeffkbkim,2023-07-10T21:30:02Z,"the responsefuture if completed inside genericgroupjoin will have an error code corresponding to the join group business logic. basically, we have already completed with the appropriate error if the response future is already completed at this line. the append future error is from the append/commit process which needs to be converted if we complete the response error here.",0,0.9942575693130493
1258934915,13870,jeffkbkim,2023-07-10T21:31:46Z,where should i look to confirm/learn this?,0,0.9937684535980225
1258937169,13870,jeffkbkim,2023-07-10T21:35:02Z,"confirmed that `storegroup` and `storeoffsets` have different handling. this will still be shared amongst join/sync/leave group, so i'll rename this to `appendgroupmetadataerrortoresponseerror`, wdyt?",0,0.9929827451705933
1258999406,13870,jeffkbkim,2023-07-10T23:18:33Z,is your suggestion to iterate through all groups & members and log each member after loading a partition is complete?,0,0.9951325058937073
1259002211,13870,jeffkbkim,2023-07-10T23:23:59Z,that's correct,0,0.9915915727615356
1259029305,13870,jeffkbkim,2023-07-11T00:24:18Z,great suggestion. thanks,1,0.9955398440361023
1259030830,13870,jeffkbkim,2023-07-11T00:28:01Z,a successful join group request will store the response future into the member's `awaitingjoinfuture` (could also complete if the join phase completes),0,0.9947099685668945
1259040832,13870,jeffkbkim,2023-07-11T00:43:14Z,we get illegal state exception if it's not initialized and since it doesn't affect the old protocol i thought it best to initialize it here.,0,0.9892053604125977
1259047855,13870,jeffkbkim,2023-07-11T00:53:11Z,"this is not to create a new group (note the `createifnotexists=false` argument) but to retrieve the group to do more validations such as group state, generation id, group size, etc. added a helper method `genericgroup()` to simplify the calls.",0,0.9947358965873718
1259049772,13870,jeffkbkim,2023-07-11T00:55:49Z,"for all tests, we always generate a new record. some tests hide this as it's called in `groupmetadatamanagercontext#joingenericgroupasdynamicmember()`. maybe we can simplify this and just manually create an empty group for all tests except 1 where we test the new record. wdyt?",0,0.9877469539642334
1259054321,13870,jeffkbkim,2023-07-11T01:01:57Z,addressed in above comment.,0,0.9938263297080994
1259059291,13870,jeffkbkim,2023-07-11T01:08:34Z,"for all places i use the old for each / for loops, there is an error `variable used in lambda expression should be final or effectively final` because i reuse variables (mainly joingrouprequestdata & responsefutures). i can use new variables instead, would that be better?",0,0.9924558401107788
1259062674,13870,jeffkbkim,2023-07-11T01:13:15Z,i was following the new protocol as it made more sense but i have changed to reflect the old behavior.,0,0.9501565098762512
1259095013,13870,jeffkbkim,2023-07-11T02:11:36Z,thanks for the catch. will add it.,1,0.9199039936065674
1259096806,13870,jeffkbkim,2023-07-11T02:14:34Z,there's a +1 on all advance clocks in scala. i haven't actually looked but assumed that it's in place due to how the purgatory works. the java timer implementation does not require a +1,0,0.9904696941375732
1259097546,13870,jeffkbkim,2023-07-11T02:16:06Z,have replied to a thread above,0,0.9938133955001831
1259098122,13870,jeffkbkim,2023-07-11T02:17:16Z,related to when a group is not found. have reverted and updated the error code,0,0.9869326949119568
1259098972,13870,jeffkbkim,2023-07-11T02:19:19Z,"yes, that's correct.",0,0.9849867224693298
1259103526,13870,jeffkbkim,2023-07-11T02:28:15Z,simplified the code a bunch. thanks for the suggestion!,1,0.9817686080932617
1259115771,13870,jeffkbkim,2023-07-11T02:53:23Z,"i'll think a bit more on this as it will require a large change in this class. one of the reasons i had it like this is that we mostly care about the responsefuture in the tests and wanted to hide the record/append future validations. the timer could also produce records which require setting things in advance. i agree it is unclean, i'll address this in the next commit.",0,0.9403280019760132
1259765086,13870,dajac,2023-07-11T13:46:46Z,yes. i would actually create a special test to validate this case and simplify all the others.,0,0.9892280101776123
1259767721,13870,dajac,2023-07-11T13:48:47Z,nit: empty line.,0,0.9438178539276123
1259774315,13870,dajac,2023-07-11T13:53:31Z,should we move `genericgroup` to the context?,0,0.9942808151245117
1259776117,13870,dajac,2023-07-11T13:54:42Z,nit: empty line.,0,0.9438178539276123
1259776394,13870,dajac,2023-07-11T13:54:53Z,nit: empty line.,0,0.9438178539276123
1259779633,13870,dajac,2023-07-11T13:57:09Z,i find the helpers a bit confusing. it is not clear what's the difference between `joingenericgroup` and `sendgenericgroupjoin` for instance. is it possible to simplify them?,-1,0.6795122623443604
1259789131,13870,dajac,2023-07-11T14:03:57Z,how do end up in this state here? is there some code to advance the timer to complete the prepare phase?,0,0.9922739863395691
1259793958,13870,dajac,2023-07-11T14:07:28Z,this is really surprising. `verify*` suggests that this method only verifies something but it also has side effects. i think that this should rather be done in the context like i did for the new protocol.,-1,0.919629693031311
1259795334,13870,dajac,2023-07-11T14:08:23Z,we need to align on this one as i also have an implementation [a link]. they look pretty close but they are different.,0,0.9823763370513916
1259836068,13870,dajac,2023-07-11T14:35:58Z,do we need to add a test for this one?,0,0.9940729737281799
1260282790,13870,jeffkbkim,2023-07-11T21:06:25Z,`sendgenericgroup...` methods send the request and return the future. `joingenericgroup...` methods invoke `sendgenericgroup` methods then advance the timer to move the group to completing rebalance state.,0,0.9944686889648438
1260298077,13870,jeffkbkim,2023-07-11T21:24:18Z,"yeah, i noticed. i don't mind using the other implementation. looks like java's priority queue does arbitrary ordering for the same priority so they should have the same behavior",0,0.693394124507904
1260497268,13870,jeffkbkim,2023-07-12T02:39:33Z,"with the latest changes, i renamed `joingenericgroup...` to ``joingenericgroupasdynamicmemberandcompletejoin` and `joingenericgroupandcompletejoin` to make it more explicit. let me know if this is more readable.",0,0.9757232666015625
1260497352,13870,jeffkbkim,2023-07-12T02:39:42Z,replied to comment below.,0,0.9938356280326843
1260500922,13870,jeffkbkim,2023-07-12T02:46:27Z,"removed this method, and now individual tests do the validation. one exception is for timer operation expirations - as the majority of the cases will not result in any records, i have done the validation inside mockcoordinatortimer.",0,0.9930485486984253
1263424766,13870,dajac,2023-07-14T07:56:38Z,"yeah, i think that it depends on what we mean by unexpected. i would remove it for now given that we also log something when the append future fails. we can always bring it back later if needed.",0,0.9838686585426331
1263429592,13870,dajac,2023-07-14T08:01:29Z,that makes sense.,0,0.9822883605957031
1263430125,13870,dajac,2023-07-14T08:02:02Z,that seems reasonable. we can see later if we could also share this logic with the consumer group heartbeat handling.,0,0.98796147108078
1263432212,13870,dajac,2023-07-14T08:04:12Z,extremely small nit: should you move `topicpartition` to the top? this is a common attribute.,0,0.6120352149009705
1263432742,13870,dajac,2023-07-14T08:04:46Z,nit: could you also move this one to the top of the attributes?,0,0.9939647316932678
1263435000,13870,dajac,2023-07-14T08:07:27Z,"nit: i was wondering whether it would make sense to move this to `coordinatorresult`. we could have a static public constant called `empty`. then, we could use `coordinatorresult.empty` in the code. this is a pattern that we already use in a few other places. what do you think?",0,0.9532822370529175
1263435600,13870,dajac,2023-07-14T08:08:05Z,nit: could we revert this change?,0,0.9879471659660339
1263436098,13870,dajac,2023-07-14T08:08:37Z,nit: add javadoc for unknownmemberidexception.,0,0.9946532249450684
1263437064,13870,dajac,2023-07-14T08:09:38Z,nit: there is a constructor which does not take the response. we could use it and remove `null` here. there are a few other cases. i won't mention them again.,0,0.9886378645896912
1263437658,13870,dajac,2023-07-14T08:10:17Z,nit: the format of the javadoc in is incorrect here.,0,0.9145462512969971
1263439020,13870,dajac,2023-07-14T08:11:42Z,correct. i think that you saw that in my other pr. the issue with logging here is that it will log state metadata as well and we don't want this.,0,0.9819050431251526
1263441311,13870,dajac,2023-07-14T08:14:13Z,is this one covered by a unit test?,0,0.9929935336112976
1263443960,13870,dajac,2023-07-14T08:16:52Z,i was wondering if it would be better to complete the future directly here as well in order to be consistent. i think that you did this in the sync handling if i understood you correctly. what do you think?,0,0.9749343395233154
1263446381,13870,dajac,2023-07-14T08:19:16Z,"note: we will have to also verify the number of member after the group is loaded, i think. this is something for another pr but to keep in mind.",0,0.9913240671157837
1263447316,13870,dajac,2023-07-14T08:20:21Z,nit: could we prefix this one and the two others with `genericgroup`?,0,0.9923616647720337
1263450237,13870,dajac,2023-07-14T08:22:52Z,would it make sense to make the copy on the other side? it is a bit weird to anticipate this here because we don't do this for other accessors. i am usually tempted to return unmodifiable collections in the case to prevent this kind of issue.,-1,0.8826152086257935
1263452425,13870,dajac,2023-07-14T08:25:00Z,nit: `testjoingroupappend...`?,0,0.9920720458030701
1263454213,13870,dajac,2023-07-14T08:26:50Z,nit: could we move this next to the other final private attributes? could we also invest private final to be consistent with the others?,0,0.993633508682251
1263454828,13870,dajac,2023-07-14T08:27:31Z,nit: could we move this one back to its original place?,0,0.9890945553779602
1263458200,13870,dajac,2023-07-14T08:30:58Z,"nit: what the reason for this? if you don't catch it, the test will also fail.",0,0.9137067198753357
1263459890,13870,dajac,2023-07-14T08:32:34Z,nit: let's revert this.,0,0.6265258193016052
1263459980,13870,dajac,2023-07-14T08:32:39Z,nit: let's revert this.,0,0.6265258193016052
1263460377,13870,dajac,2023-07-14T08:33:01Z,nit: `null` could be removed.,0,0.9942017197608948
1263461288,13870,dajac,2023-07-14T08:33:57Z,nit: `null` could be removed.,0,0.9942017197608948
1263463518,13870,dajac,2023-07-14T08:36:11Z,"this catch is a bit suspicious here. i suppose that it would also catch the error thrown by `assertequals`, no?",-1,0.6867402791976929
1263465299,13870,dajac,2023-07-14T08:37:56Z,"nit: while we are here, would it make to normalize the name of all tests starting with `should`? they should ideally start with `test...` like the others.",0,0.9853727221488953
1263471443,13870,dajac,2023-07-14T08:44:23Z,"it seems based on the usages of this method that only one timeouts is expected all the time. should we enforce it as well? more generally, i was wondering if having a `assertemptytimeout` helper method and using `assertemptytimeout(context.sleep(...))` would have a better separation of concerns. i leave this up to you.",0,0.9872166514396667
1263905173,13870,jeffkbkim,2023-07-14T16:11:41Z,that forces the coordinatorresult class to become non-generic which i don't think we want.,0,0.8378053307533264
1263922655,13870,jeffkbkim,2023-07-14T16:30:21Z,then do you think we can move `appendgroupmetadataerrortoresponseerror` back to groupmetadatamanager?,0,0.9941752552986145
1263925546,13870,jeffkbkim,2023-07-14T16:33:50Z,"to confirm, you're saying we should call `acceptjoiningmember` while loading members?",0,0.9954979419708252
1264075041,13870,jeffkbkim,2023-07-14T19:22:59Z,will keep it as assertemptyresult as the timeout is not empty (can be) but we want to assert that the coordinator result is.,0,0.9947201013565063
1264953365,13870,dajac,2023-07-17T07:04:25Z,ah.. did not think about that.,-1,0.498742938041687
1264954924,13870,dajac,2023-07-17T07:06:34Z,"yeah, possibly.",0,0.9675866961479187
1264955867,13870,dajac,2023-07-17T07:07:49Z,no. i think that the current coordinator triggers a rebalance if the number of members is higher than the max when a group is loaded.,0,0.9873504042625427
1264961072,13870,dajac,2023-07-17T07:13:31Z,do we really need to keep the try..catch?,0,0.9839712977409363
1264962406,13870,dajac,2023-07-17T07:14:49Z,nit: `assertnooremptyresult`?,0,0.9938819408416748
1264964347,13870,dajac,2023-07-17T07:17:13Z,this request timeout was coming from the delayed produce op in the purgatory. we don't have this anymore.,0,0.9734318256378174
1264965443,13870,dajac,2023-07-17T07:18:40Z,this was not addressed.,0,0.9489931464195251
1264967746,13870,dajac,2023-07-17T07:21:18Z,this was not addressed.,0,0.9489931464195251
1264968675,13870,dajac,2023-07-17T07:22:25Z,"yeah, we have to stick to the old one here.",0,0.8603589534759521
1265547819,13870,jeffkbkim,2023-07-17T15:32:01Z,i was thinking about the illegal state exceptions. wouldn't we hide the issue then? maybe we can log only for non api exceptions. wdyt?,0,0.9802742004394531
1265554449,13870,jeffkbkim,2023-07-17T15:37:23Z,this is required if we want to use the streams api. let me know if we should just use the for each loop,0,0.9942373037338257
1265574666,13870,jeffkbkim,2023-07-17T15:54:25Z,thought i addressed this. addressed it now,0,0.9859727621078491
1265577548,13870,jeffkbkim,2023-07-17T15:56:48Z,changed to logging only when the response future is not complete,0,0.9913254380226135
1265644331,13870,jeffkbkim,2023-07-17T16:51:05Z,updated and added a test case,0,0.9911268353462219
1265807220,13870,dajac,2023-07-17T19:25:12Z,"this would still log in expected cases, no? for instance, when the coordinator for the group is inactive, loading, etc. if you really want to log something, you could perhaps log only if `exception` is not a kafkaexception or only when it is a runtimeexception for instance.",0,0.9928346872329712
1265807612,13870,dajac,2023-07-17T19:25:41Z,gotcha. it is fine like this.,1,0.665912926197052
1265816192,13870,jeffkbkim,2023-07-17T19:35:47Z,ah makes sense. logging only when it is not a kafka exception makes sense.,0,0.9644246697425842
1266079310,13870,jeffkbkim,2023-07-18T01:36:33Z,i think our last discussion was to also revert this to the existing behavior right? i.e. not implement [a link],0,0.9923169612884521
1266264686,13870,dajac,2023-07-18T05:59:19Z,that's correct.,0,0.9909399747848511
1266267667,13870,dajac,2023-07-18T06:00:53Z,should we replace this by a constant if we can't change it based on config?,0,0.9910374879837036
1266269140,13870,dajac,2023-07-18T06:02:42Z,"so we actually need to reschedule the timer here, right?",0,0.9874693155288696
1266270587,13870,dajac,2023-07-18T06:04:21Z,nit: could we say `joingroup request {} hit....`?,0,0.9887009859085083
1267070768,13870,jeffkbkim,2023-07-18T17:00:13Z,yes. updated,0,0.9796229004859924
565612146,9944,jolshan,2021-01-27T20:29:10Z,i think i may want to do this in a simpler way. i want to keep track if we have ids for all the topics and i'm not sure if there is a better way to figure out when a topic is no longer in a session besides checking all the topic partitions.,0,0.9578985571861267
566449639,9944,rajinisivaram,2021-01-28T22:26:23Z,we don't use `get` prefix for getters,0,0.9932958483695984
566449805,9944,rajinisivaram,2021-01-28T22:26:42Z,comment needs updating?,0,0.9941587448120117
566453611,9944,rajinisivaram,2021-01-28T22:34:18Z,"we can use integer::sum as the last arg, but do we even need to maintain `partitionspertopic`?",0,0.9925845265388489
566458667,9944,rajinisivaram,2021-01-28T22:45:05Z,could just parameterize `findmissing`?,0,0.993779718875885
566464590,9944,rajinisivaram,2021-01-28T22:57:33Z,"there are several places where we use this combination of two maps, should we create a class that maintains a bidirectional map?",0,0.9933459758758545
566465893,9944,rajinisivaram,2021-01-28T23:00:16Z,can we end up with cases with some topics with ids and some without?,0,0.9932267069816589
566466426,9944,rajinisivaram,2021-01-28T23:01:33Z,the fact that you are running this code implies `apikeys.fetch.latestversion() >= 13`?,0,0.9949936270713806
567146583,9944,jolshan,2021-01-29T23:21:36Z,some of these tests may be flaky so i'm going to keep an eye on them.,0,0.8577643632888794
567172089,9944,rajinisivaram,2021-01-30T01:12:02Z,the whole fetchrequest class is quite hard to follow without reading the kip and looking at multiple places. it will be good to add some comments at the class level.,0,0.5009092092514038
567172368,9944,rajinisivaram,2021-01-30T01:13:50Z,"since we have session ids and topic ids in the context of a fetch request, we should probably qualify `topicid`",0,0.9939537644386292
567172755,9944,rajinisivaram,2021-01-30T01:15:54Z,`this.partitions.addall(partitions)`?,0,0.9949413537979126
567173386,9944,rajinisivaram,2021-01-30T01:19:17Z,does one non-zero id mean we have all ids?,0,0.9905558228492737
567173468,9944,rajinisivaram,2021-01-30T01:19:41Z,this suggests we can have a combination of zero and non-zero?,0,0.9900248050689697
567173993,9944,rajinisivaram,2021-01-30T01:22:18Z,it will be good to see if can separate out new and old forms of fetchrequest/response. it is not a big deal since it is just wrapping the protocol layer.,0,0.9325284361839294
567174143,9944,rajinisivaram,2021-01-30T01:23:34Z,shouldn't we be using versions and expect non-zero ids in new versions?,0,0.9888283014297485
567174731,9944,rajinisivaram,2021-01-30T01:27:08Z,we need to remember to set this based on which version this is being merge to.,0,0.9914038181304932
567175350,9944,rajinisivaram,2021-01-30T01:30:45Z,nit: indentation,0,0.9914920926094055
567175593,9944,rajinisivaram,2021-01-30T01:32:32Z,does an unresolved partition have all these fields populated? or do we have it here because the topic may be resolved later?,0,0.9924512505531311
567175893,9944,rajinisivaram,2021-01-30T01:34:49Z,is this part intentionally commented out?,0,0.9913203120231628
567188080,9944,jolshan,2021-01-30T03:13:51Z,no that should be removed :),0,0.9914525747299194
567188108,9944,jolshan,2021-01-30T03:14:14Z,we need to keep the data from the fetch request for when we resolve the partition.,0,0.9932318925857544
567188287,9944,jolshan,2021-01-30T03:16:00Z,the idea is that we should only be able to send this request version if we had an id for each topic. i do need to take a closer look at this,0,0.9891046285629272
567188652,9944,jolshan,2021-01-30T03:19:22Z,i had trouble getting the version into the response. the constructor is used in some places where we don't have access to the version.,0,0.8736632466316223
567188957,9944,jolshan,2021-01-30T03:22:37Z,that's true,0,0.9877513647079468
567189013,9944,jolshan,2021-01-30T03:23:35Z,i think this was a mistake. i need to see why i wrote it this way.,-1,0.9268894195556641
567189128,9944,jolshan,2021-01-30T03:24:54Z,i should also move that comment (and maybe simplify it) to the partitioniterator where i moved the code for removing partitions with stale ids.,0,0.9931655526161194
568033865,9944,jolshan,2021-02-01T18:10:10Z,"i remember why i did this. i wanted to not get a set of the zero id when the version was old. i think if we are able to get better versioning logic, this should be fixed easily.",0,0.9740909337997437
568034891,9944,jolshan,2021-02-01T18:11:54Z,abstractresponse does not maintain version like abstractrequest. so i'm not sure the best way to proceed with this.,0,0.5935590863227844
568078414,9944,jolshan,2021-02-01T19:20:40Z,"i'm thinking it may be possible if we had a response from a broker that supported topic ids and then a response from one that did not. of course, this should eventually get resolved, but i didn't know if it was worth it to try to avoid fetches that are unsupported in a few more cases.",0,0.976662278175354
568140154,9944,junrao,2021-02-01T21:07:54Z,space after comma,0,0.9786802530288696
568196064,9944,junrao,2021-02-01T22:51:09Z,gettopicids => topicnamestoids?,0,0.9935012459754944
568196201,9944,junrao,2021-02-01T22:51:32Z,gettopicnames => topicidstonames?,0,0.9950435161590576
568201144,9944,junrao,2021-02-01T22:58:56Z,"hmm, why do we need to do collect() at the end? the returned value doesn't seem be be used.",0,0.9660804867744446
568201276,9944,junrao,2021-02-01T22:59:07Z,"hmm, why do we need to do collect() at the end?",0,0.9829607009887695
568216529,9944,junrao,2021-02-01T23:34:43Z,it's a bit weird to add a comment that breaks the if/else clause. perhaps we could put the comment inside the `else if`?,-1,0.9822539687156677
568222532,9944,junrao,2021-02-01T23:50:06Z,"it seems that the following code makes changes to unresolvedpartitions, not topic ids.",0,0.9891567230224609
568223807,9944,junrao,2021-02-01T23:53:42Z,should we change `hashcode() `and `equals()` to include topicid?,0,0.9952077269554138
568230940,9944,junrao,2021-02-02T00:12:40Z,what's the definition of 'interesting'?,0,0.9878625869750977
568231067,9944,junrao,2021-02-02T00:13:05Z,"should we add the new params to the javadoc above? in particular, could we explain the relationship between responsedata and iderrors? also, could we name the params clearer? for example, responsedata => partitionswithmatchingtopicid, iderrors => partitionswithoutmatchingtopicid.",0,0.9936191439628601
568832800,9944,junrao,2021-02-02T18:26:24Z,"since we are adding some complexity, it would be useful to make the code a bit easier to understand for other people. for example, perhaps we could add comments to explain (1) what partitions will be included in unresolvedpartitions vs partitionmap? (2) are partitions mutually exclusive between unresolvedpartitions and partitionmap? (3) how are partitions in unresolvedpartitions and partitionmap handled different for fetch response?",0,0.9896350502967834
569824849,9944,junrao,2021-02-03T23:29:26Z,topicnames => topicidtonamemap?,0,0.9934537410736084
569829415,9944,junrao,2021-02-03T23:41:13Z,is there a reason to use 0 instead of the default capacity for the hashmap?,0,0.9932183623313904
569830803,9944,junrao,2021-02-03T23:45:03Z,we could probably just get rid of session since it's part of the session object. ditto below.,0,0.9931862354278564
569832071,9944,junrao,2021-02-03T23:48:16Z,"now that the constructor code is a bit more now, perhaps we could just forward `builder()` to `builder(int initialsize, boolean copysessionpartitions) `?",0,0.9928961396217346
569832450,9944,junrao,2021-02-03T23:49:14Z,id => topicid ?,0,0.9922493696212769
569834804,9944,junrao,2021-02-03T23:55:33Z,"hmm, we should be adding tp.partition() to the hashset and not using it for the initial capacity, right?",0,0.98248690366745
569862273,9944,junrao,2021-02-04T00:49:57Z,it seems that topicnames is unused?,0,0.9925712943077087
570397481,9944,junrao,2021-02-04T17:11:52Z,"it seems this is about a topic. so, unresolvedpartitions is better named as unresolvedtopic?",0,0.9874011874198914
570588361,9944,junrao,2021-02-04T22:29:45Z,"hmm, not sure if we need to distinguish here. it seems that it's easier to just always send a unknown_topic_id since the propagation of all topic ids could be delayed?",0,0.9338265657424927
570596351,9944,junrao,2021-02-04T22:46:08Z,"now that we are changing the semantics for this method to only iterating resolved partitions, it would be useful to have a more appropriate method name to make it clear. also, it seems that some of the callers need to iterate all partitions including unresolved ones (e.g., those checking for cluster action permissions) while some others need to iterate resolved ones (e.g, those checking for topic level permissions).",0,0.9927741289138794
570606630,9944,junrao,2021-02-04T23:08:08Z,"this method is kind of weird. it's only used in kafkaapis where topic name has already been resolved. the only reason for this method is that fetchcontext.updateandgenerateresponsedata() generates fetchresponse, which is used in createresponse(). instead, could we have fetchcontext.updateandgenerateresponsedata() return a different class that includes the resolved partitions?",-1,0.9705519080162048
570607999,9944,junrao,2021-02-04T23:11:22Z,perhaps we could log both the resolved partitions' size and unresolved partitions' size.,0,0.9833347797393799
570648997,9944,junrao,2021-02-05T00:58:06Z,it's kind of weird to pass in a request into fetchsession.,-1,0.9863118529319763
570650572,9944,junrao,2021-02-05T01:02:52Z,"hmm, do we need to check version here? fetchresponse.fetchdataanderror() already checked the version.",0,0.9820984601974487
570652174,9944,junrao,2021-02-05T01:07:51Z,"could we name the methods better to make it easier to understand? for example, createnewsession => generateresolvedpartitions createnewsessioniderrors => generateunresolvedpartitions",0,0.9936734437942505
572203478,9944,junrao,2021-02-08T16:52:18Z,the metadata cache could change between the two calls. could we have a single call to metadata cache that returns both topicnames and topicids?,0,0.9932053089141846
572208853,9944,junrao,2021-02-08T16:58:58Z,"`topicids.getordefault(part.topic(), uuid.zero_uuid)` if we always expect the topic to be found in topicids, we should just throw an exception instead of using a default. if this is expected, we probably should convert it to an unresolved partition?",0,0.9935484528541565
572218700,9944,junrao,2021-02-08T17:12:09Z,it seems that toforgetids is intended for unresolved topicids. could we name it more clearly together with toforget and add some comment?,0,0.9917231202125549
572220577,9944,junrao,2021-02-08T17:14:48Z,"i am not sure that i follow the logic here. it seems that we always put the forgot topic into unresolvedids. it seems that we should check the partitions size? also, perhaps rename partitions to sth like unresolvedpartitions?",0,0.5996795296669006
572228756,9944,junrao,2021-02-08T17:24:43Z,should we use mustadd()?,0,0.9945788383483887
572235515,9944,junrao,2021-02-08T17:33:23Z,do we need this part of the logic? it seems that the same is already done through fetchreqeust.fetchdataanderror().,0,0.994400680065155
572274967,9944,junrao,2021-02-08T18:31:40Z,"this excludes the partition in the response. however, it seems we need to send an error back for this partition?",0,0.9937080144882202
572281866,9944,junrao,2021-02-08T18:42:34Z,this seems unused?,0,0.9904127717018127
572287008,9944,junrao,2021-02-08T18:50:42Z,could we add the new param to the javadoc?,0,0.9951393604278564
572308958,9944,junrao,2021-02-08T19:25:33Z,should we use the latest version or fetchrequestversion guarded by ibp?,0,0.994392454624176
572350818,9944,jolshan,2021-02-08T20:31:46Z,sorry this was unclear. i meant changes involving topic ids. i will adjust this comment.,-1,0.983632504940033
572351801,9944,jolshan,2021-02-08T20:33:35Z,'interesting' was the name of the map of partitiondata. i believe they are topic partitions that are authorized and exist.,0,0.7552738785743713
572351945,9944,jolshan,2021-02-08T20:33:51Z,sounds good to me,1,0.963803231716156
572354491,9944,jolshan,2021-02-08T20:37:24Z,i think i was just matching `sessionpartitions` above,0,0.9877474308013916
572355958,9944,jolshan,2021-02-08T20:39:51Z,yeah. good catch. i'm going to experiment with this code a bit to see if it's faster to maintain this set or just get a set of topics from the map of topic partitions in` fetchrequestdata`,1,0.9893765449523926
572356813,9944,jolshan,2021-02-08T20:41:16Z,"the reason i name it this is we maintain such an object for each partition that was unresolved. if we simply have one object per topic, we would need a way to know all the partitions for the topic that were requested.",0,0.9908323884010315
572357857,9944,jolshan,2021-02-08T20:43:16Z,"i've gone back and forth on this. one one hand, you are right that this is confusing in the case where we are doing and upgrade and id propagation is delayed. on the other hand, in the non-upgrade case, returning an unknown_topic_id error when topic ids are not even supported might not be as informative.",0,0.9374168515205383
572363402,9944,jolshan,2021-02-08T20:52:25Z,"i agree. i think it stems from exactly what you said...that `fetchcontext.updateandgenerateresponsedata()` generates a response only for it to be generated again. currently ` fetchcontext.updateandgenerateresponsedata()` does include all partitions (resolved and unresolved). the issue is that the partitions need to be down-converted. the way this works is that the partitions are pulled from the fetchresponse object itself. however, the issue is that i've changed responsedata and since this is the newest version of the response, it will try to reconstruct the map instead of pulling the object `partitiondata`. (which is too slow) i thought about changing the method to always return the map when it is not null, but that caused some issues in some places as well. i can look into this again though.",0,0.9364731311798096
572367849,9944,jolshan,2021-02-08T20:59:54Z,this is for adding unresolved partitions in the session but not in the request. i can add comments to clarify what is happening.,0,0.9951947331428528
572370494,9944,jolshan,2021-02-08T21:04:38Z,"good point, it should probably be along the lines of `if (fetchrequestversion >= 13 && !fetchdata.canusetopicids) 12 else fetchrequestversion` to match how it is sent below.",1,0.6333019137382507
572373623,9944,jolshan,2021-02-08T21:09:56Z,"if we run into this scenario, does it make sense to always return with an unknown_topic_id error? sometimes partitions will be skipped over anyway when `mustrespond` is false, so should those also return unknown_topic_id?",0,0.9882856607437134
572377972,9944,jolshan,2021-02-08T21:13:56Z,i realize this is a bit confusing. addpartitions method takes a list what this line is doing is grabbing the iderror object and adding partitions to it.,-1,0.6817622780799866
572381787,9944,jolshan,2021-02-08T21:20:43Z,"ah. this is confusing due to how i named things. basically, i'm collecting a set of partitions `partitions` for a given topic where the id was not resolved. then i'm adding them to unresolvedids. this is a mapping from the topic id to all the partitions that should be forgotten. i can rename and add comments to clarify what is happening here.",-1,0.7223445773124695
572413017,9944,jolshan,2021-02-08T22:11:24Z,"i thought about this, but i was worried about some weirdness where we need to support partitions before and after they have an id. (the partitions are techincally equivalent, but equals wouldn't reflect that) this may also cause problems in cases where ids may change. consider the code ` val cachedpart = session.partitionmap.find(new cachedpartition(topicpart))` this is used in the path of deleting partitions with stale ids. we would need to know the topic id to find the partition here. i could see potential issues where we no longer have the id and would have trouble removing it.",-1,0.8717665076255798
572470829,9944,jolshan,2021-02-09T00:21:46Z,when you mention that some callers need to iterate over all partitions like cluster action -- i'm a little confused. i thought the request context was passed into authhelper for that.,-1,0.621932327747345
572472724,9944,jolshan,2021-02-09T00:25:21Z,i think we do since this is looking at the partitions cached in the session. i'll take another look though.,0,0.9892798066139221
572475014,9944,jolshan,2021-02-09T00:27:59Z,i think this is used for handling the case of older request versions.,0,0.9861379265785217
572512463,9944,junrao,2021-02-09T02:00:07Z,i was referring to the following code. it seems to need to iterate every partition through fetchcontext so that the unknown_topic_or_partition error code can be added for each partition. [code block],0,0.9934988021850586
573033865,9944,jolshan,2021-02-09T16:28:11Z,ok. i understand now. i think in this case though the expected behavior is to return unknown_topic_id if the topic id is unresolved.,0,0.9681941270828247
573046669,9944,jolshan,2021-02-09T16:43:18Z,"i just realized that fetchrequest.latestallowedversion is the version we use to build the request (latest and earliest are the same.) but this is a bit confusing, so i'll probably just use the logic mentioned above.",0,0.6760987043380737
573102028,9944,junrao,2021-02-09T17:53:19Z,"yes, we want to return unknown_topic_id for all partitions in this case. the unresolved partitions in this pr could also return the unsupported error code.",0,0.9935467839241028
574846728,9944,jolshan,2021-02-11T21:42:38Z,get rid of the word session in the variable name? i was following sessionpartitions as above. or get rid of this altogether?,0,0.9934666752815247
574909648,9944,jolshan,2021-02-11T23:57:11Z,i'm trying to think if we could have a situation where the partition already exists but without topic id. (like an older version of the request was sent previously?) maybe i could check if it was not already added like how it is done below for resolved partitions added to the session.,0,0.972939670085907
592335738,9944,chia7712,2021-03-11T12:54:16Z,i don't find any usage of this method. is it essential to keep this map in `topicnames`?,0,0.9876936078071594
592360300,9944,chia7712,2021-03-11T13:30:13Z,"it seems this method is used by server only. is it possible to have empty topic name when `kafkaapis` calls it? if not, we can remove this empty check and replace this method by `toresponsedatamap`",0,0.9917817711830139
592520900,9944,jolshan,2021-03-11T16:41:47Z,"i think i added it for completeness, but perhaps we don't need it.",0,0.9883205890655518
592524660,9944,jolshan,2021-03-11T16:46:21Z,"yes. we may have topic ids that could not be resolved. these topics will not have a topic name. i agree that this isn't the cleanest solution, but it was the one that worked while keeping topicpartitions as keys for the map.",0,0.9747945070266724
592530926,9944,chia7712,2021-03-11T16:53:36Z,maybe we should remove the usage of this method first. is it useful if we make all callers use auto-generated data (topic and partition) instead of this map (topicpartition)?,0,0.9897719025611877
592536126,9944,jolshan,2021-03-11T16:59:57Z,"i can remove it. i was keeping it as a placeholder for now. i was hoping to find a way to not regenerate the map that we just passed in to make the fetchresponse. i'm also not quite sure what you mean by ""auto-generated data""",0,0.9818691611289978
592542384,9944,chia7712,2021-03-11T17:08:03Z,"make all callers use fetchresponsedata instead of map[topicpartition, ...]. in other words, fetchresponse does not return topicpartition anymore.",0,0.9945566654205322
592546512,9944,jolshan,2021-03-11T17:13:17Z,ah i see. i'd have to take a look. i'm wondering if we would still need to convert to topic names for certain methods.,0,0.9742773771286011
592761061,9944,jolshan,2021-03-11T22:16:27Z,"yeah, so for example, `topicpartition`s are given to `replicamanager.fetchmessages` where it is used heavily. i think we still want the map for now. one thing i was confused about with this code is why we generate `unconvertedfetchresponse` with `updateandgenerateresponsedata`. we pass in the map to create `unconvertedfetchresponse`. with the optimization to lazily compute the map, recompute it a few lines of code later in `createresponse`. i'm hoping to avoid this somehow. (i think the optimization is great everywhere else though and i was heading in that direction originally with this pr)",0,0.9348520636558533
592885424,9944,chia7712,2021-03-12T03:27:47Z,"you are right. i feel it is the side-effect caused mixing `topicpartition` and generated code in production. the callers have to create a heavy copy to update some fields of passed data. btw, that is what [a link] want to resolve. the pr makes all code use auto-generated data so they can update fields of passed auto-generated data instead of creating a copy.",0,0.9768611788749695
593283525,9944,jolshan,2021-03-12T16:04:20Z,got it. i think the issue here then is that some of the information can not be auto-generated data. we need topic names for certain methods but names will not be in the auto-generated data.,0,0.9582933783531189
593293236,9944,jolshan,2021-03-12T16:17:49Z,"i suppose we could set them server side, but when we iterate though the topics, we would need to not include those whose topic ids could not be resolved.",0,0.987565815448761
593737385,9944,chia7712,2021-03-13T11:08:59Z,"as we resolve all ids before check permission, does it produce `topic_authorization_failed` with topic name even if it has no read permission to such topic (line#717)?",0,0.9939272403717041
593738472,9944,chia7712,2021-03-13T11:20:21Z,remove those code?,0,0.9934693574905396
593739424,9944,chia7712,2021-03-13T11:29:33Z,not sure whether this idea is valid. could we resolve all ids to names and then keep using previous code to handle fetch requests? for example: the code of deleting topic resolve ids to names first and then process the deletion by names. that is a good pattern to me as we don't need to trace id/name everywhere.,0,0.9317389726638794
593771946,9944,jolshan,2021-03-13T16:35:08Z,"for the most part, this is what we do. but we also have to keep track of unresolved names right? fetchsession makes this more complicated. we may get a topic id that we can't resolve, but with a subsequent update we can. i'm not 100% sure of the logistics of fetch sessions, but it doesn't seem like a good practice to leave unresolved ids out of the session.",0,0.6080945134162903
593772326,9944,jolshan,2021-03-13T16:37:56Z,"i would think so? the goal was for when the ids are resolved, the path would be the same. and i think we decided that topic_authorization_failed is the correct error when we don't have read permissions?",0,0.9812597632408142
593842004,9944,chia7712,2021-03-14T04:48:57Z,sorry for my unclear comment. my point was that the topic name is included by the response even if there is no read permission to resolve the topic is. that looks like a security issue that we expose the topic name.,-1,0.9862701296806335
593922148,9944,jolshan,2021-03-14T16:01:06Z,ah right. i will fix that.,0,0.9644994735717773
595284658,9944,jolshan,2021-03-16T15:31:23Z,i went to fix this but i realized something. correct me if i'm wrong. the newest version of fetch will only return topic ids (not topic names) so we won't expose topic names. the older version of fetch sends topic names so it will have to send topic names back. i don't think the name is ever incorrectly exposed.,0,0.9603918790817261
603506960,9944,jolshan,2021-03-29T18:09:58Z,removed this object,0,0.9941796064376831
603507748,9944,jolshan,2021-03-29T18:11:16Z,i simplified this path as well.,0,0.9904525279998779
617932245,9944,junrao,2021-04-21T22:26:04Z,extra newline.,0,0.9918083548545837
622349780,9944,junrao,2021-04-28T16:32:41Z,id => topicid ?,0,0.9922493696212769
622349941,9944,junrao,2021-04-28T16:32:54Z,id => topicid ?,0,0.9922493696212769
625164696,9944,jolshan,2021-05-03T15:23:38Z,"with the top level error change, we are no longer marking the partitions as `partitionswitherror`. i'm wondering if this is something we still want to do somehow to allow the broker's metadata time to update.",0,0.9751662015914917
625372843,9944,junrao,2021-05-03T21:15:05Z,"when will topicresponse.topic() be """"?",0,0.9950981736183167
625422142,9944,junrao,2021-05-03T23:09:32Z,an situation => a situation,0,0.9881056547164917
625429072,9944,junrao,2021-05-03T23:30:12Z,"it's a bit weird for `forgottentopics()` to have a side effect that changes the internal data structure since requests are typically immutable. it's all not consistent with topartitiondatamap(). if we do want to modify the internal data structure, we probably want to name the method more properly. also, why do we return a list of forgottentopic instead of list of topicpartition? the latter is easier to understand and it doesn't seem that we need topicid in forgottentopic,",-1,0.917813777923584
625431122,9944,junrao,2021-05-03T23:36:39Z,no need for extra new line.,0,0.9868784546852112
625432217,9944,junrao,2021-05-03T23:40:13Z,version seems unused?,0,0.982624351978302
625433357,9944,junrao,2021-05-03T23:43:56Z,"hmm, it seems that we can't pass in an empty topicids since partition iterator is not empty?",0,0.9785013794898987
625440965,9944,junrao,2021-05-04T00:09:25Z,does topicid need to be a var?,0,0.9934592247009277
625443921,9944,junrao,2021-05-04T00:19:34Z,"hmm, if the topicid has changed, it seems that we should send an error (e.g. invalidtopicid) back to indicate the topicid is no longer valid so that the client could refresh the metadata?",0,0.9856756925582886
625446144,9944,junrao,2021-05-04T00:27:26Z,could we explicitly define the type of topicnames ?,0,0.9948680400848389
625451257,9944,junrao,2021-05-04T00:46:05Z,the calculation of version is duplicated between here and replicafetcherthread. could we share them somehow?,0,0.994575023651123
625454055,9944,junrao,2021-05-04T00:56:19Z,"since there is only a single tp, does topics need to be a set?",0,0.991184413433075
626749507,9944,jolshan,2021-05-05T17:09:36Z,i ended up deciding to end the session and throw a top level error when we have an unknown topic id.,-1,0.7308323383331299
626894717,9944,junrao,2021-05-05T21:01:53Z,"since topartitiondatamap() handles all versions, could we just simply call topartitiondatamap()? then, i am not sure if we need to call topartitiondatamap() in the constructor.",0,0.9871723055839539
626897100,9944,junrao,2021-05-05T21:06:16Z,it seems it will be clearer if we put this in an else clause.,0,0.9807910919189453
626899596,9944,junrao,2021-05-05T21:11:05Z,it seems that we could share the code to populate this.data and this.metadata. we only use `this` in this method. should we just remove it?,0,0.992905855178833
626906972,9944,junrao,2021-05-05T21:24:45Z,do we need this method? it seems it's the same as toresponsedatamap().,0,0.9954771399497986
626907992,9944,junrao,2021-05-05T21:26:38Z,could we add the new param to javadoc?,0,0.995192289352417
626945454,9944,junrao,2021-05-05T21:55:31Z,it seems that this can just be a local val instead of an instance val?,0,0.9915382862091064
626947091,9944,junrao,2021-05-05T21:57:30Z,do the new fields need to be included in tostring()?,0,0.9953922033309937
626952683,9944,junrao,2021-05-05T22:09:42Z,could we build the full tosendtopicids and tosendtopicnames once and reuse in both full and incremental?,0,0.9939351677894592
626953162,9944,junrao,2021-05-05T22:10:50Z,the above comment needs to be changed accordingly.,0,0.9931695461273193
626954746,9944,junrao,2021-05-05T22:14:32Z,perhaps extra and omitted should be extrapartition and omittedpartitions to make it clear?,0,0.990992546081543
626958184,9944,junrao,2021-05-05T22:23:00Z,could we add the javadoc for the new param?,0,0.995112955570221
627026623,9944,jolshan,2021-05-06T01:58:33Z,realized this was no longer the case and removed in the most recent commit.,0,0.9906818866729736
627027261,9944,jolshan,2021-05-06T02:00:45Z,"i originally did this when dealing with unresolved partitions. i was wondering if it would be better to not create a second data structure. if creating another structure (as done before) is not a problem, we can go back to that.",0,0.9891329407691956
627027404,9944,jolshan,2021-05-06T02:01:20Z,ah good catch on this.,1,0.9839995503425598
627514050,9944,jolshan,2021-05-06T15:15:14Z,"this is a good point. in general, i think i need to go through the session logic for handling different scenarios. (what happens when we have a session with different version requests--should we allow that to happen, etc) depending on this, we may want topicid to be a var (to update the id when we change request versions). i'll write up a summary of the logic i'm thinking of when i get it worked out.",1,0.9789466857910156
627516643,9944,jolshan,2021-05-06T15:18:19Z,the difference is that we already have the topic names here. i added it for the optimization when we build the response data map again in kafkaapis (so we don't have to look up the topic ids again). but it is a little silly. one option is just to put that logic in the one place it is used instead of having such a method.,-1,0.9334121942520142
627518693,9944,jolshan,2021-05-06T15:20:46Z,"yeah. that seems cleaner. so the idea is that the constructor, won't set fetchdata for either version.",0,0.9564489126205444
627519381,9944,jolshan,2021-05-06T15:21:33Z,"as mentioned below, we can simply not set fetchdata here and use the other two assignments.",0,0.9928290247917175
627522339,9944,jolshan,2021-05-06T15:25:02Z,would this work if we added a new topic to the session? i would think that we would need to add the new topic's info and the map is unmodifiable. please correct me if this is not the case.,0,0.9909927845001221
627523117,9944,jolshan,2021-05-06T15:26:00Z,"i think the original idea was that i wanted to make sure that we don't go from request version 12 up to version 13 in the same session. but in general, i need to rethink this whole approach, so this will very likely change. as mentioned in another comment, i'll write up the logic i'm thinking about so we are on the same page.",0,0.9643915891647339
627523900,9944,jolshan,2021-05-06T15:26:58Z,"i wasn't sure on this, but i can add them. maybe it makes sense just to add topicids though? (not both maps)",0,0.9775844216346741
627723205,9944,jolshan,2021-05-06T19:56:00Z,ah another artifact from before. good catch.,1,0.9909343123435974
627724561,9944,jolshan,2021-05-06T19:58:26Z,ah wait. the iterator is empty here. we create a new one `(new fetchsession.resp_map).entryset.iterator` and do not use `updates`. this is because the session is an error one.,0,0.9853445887565613
627767360,9944,jolshan,2021-05-06T21:11:12Z,rewrote this comment to be more concise.,0,0.9864476919174194
627776011,9944,jolshan,2021-05-06T21:27:29Z,"ah i realize that since this is a single topic, we can change this logic.",0,0.9817599654197693
627840199,9944,jolshan,2021-05-07T00:05:48Z,decided that we can use either version throughout the course of a session. removed instance val,0,0.9937547445297241
628405414,9944,jolshan,2021-05-07T17:55:55Z,"after running through some tests i realized why this didn't work. we can go from version 13 to version 12 within the session, but we can't go from 12 to 13. this is because we have may have topics without ids in the session. we will try to return them using version 13 and they are all zero uuid. (we also have this issue when we send a full request version 12 and the subsequent request is empty. we could try to send version 13 request since we vacuously have ids for all topics in the request, but if we do have responses for the topics, then we will try to send them back without topic ids) if we tried to resolve them, we may end up in a case where there is no valid id and also no way to communicate this (since we send back ids). so i think we do need to store the state of the previous request version in the session.",0,0.9198960065841675
648811500,9944,jolshan,2021-06-10T02:49:34Z,"i noticed that i get topic ids from metadata here and in the replica fetcher thread, i get from the metadata cache. i don't think it is a big deal since we add to the fetchdata using the same source, but it might make sense to use fetchrequestdata's topicids() instead.",0,0.96250319480896
649585182,9944,junrao,2021-06-10T23:00:31Z,space after foreach.,0,0.9933011531829834
649603470,9944,junrao,2021-06-10T23:57:50Z,from topic name for topic id => from topic name to topic id ?,0,0.993025541305542
649607001,9944,junrao,2021-06-11T00:09:33Z,should we include topicid in hashcode() and equals()?,0,0.9951658248901367
650157796,9944,junrao,2021-06-11T17:31:30Z,do we need to handle unknown_topic_id here too?,0,0.9938271641731262
650161415,9944,junrao,2021-06-11T17:38:16Z,"since metadatasnapshot could change anytime, it's more consistent if we save a copy of metadatasnapshot and derive both maps from the same cached value.",0,0.9873006939888
650163078,9944,junrao,2021-06-11T17:41:14Z,could we use case to avoid unnamed reference _._2 to make it easier to read?,0,0.9929639101028442
650165036,9944,junrao,2021-06-11T17:44:44Z,"since metadatache could change, it's probably slightly better to get topicidstonames and topicnamestoids once from metadatache so that they are consistent.",0,0.9848833680152893
650166656,9944,junrao,2021-06-11T17:47:42Z,is the test apikeys.fetch.latestversion >= 13 necessary? this code is added when we introduce version 13 as the latest fetch version.,0,0.9952619075775146
650169478,9944,junrao,2021-06-11T17:52:40Z,is the test apikeys.fetch.latestversion >= 13 necessary? this code is added when we introduce version 13 as the latest fetch version.,0,0.9952619075775146
650612574,9944,jolshan,2021-06-14T01:59:16Z,734fd7f fixes this,0,0.9755920767784119
651075127,9944,junrao,2021-06-14T15:55:51Z,the kip talks about bootstrapping the topicid for the metadata topic. is that part done already? i don't see it included in this pr.,0,0.9931148886680603
651086239,9944,junrao,2021-06-14T16:10:24Z,"if we get fetchsessiontopicidexception, the existing session is going to be invalid. so, it seems that we should start a new session? the same thing seems to apply to unknowntopicidexception",0,0.9909611344337463
651096649,9944,junrao,2021-06-14T16:24:39Z,could we do the topicids part once after the if/else block to avoid duplication?,0,0.9915863275527954
651099635,9944,junrao,2021-06-14T16:28:37Z,does this work with topic recreation? will a client be stuck with the old topicid when topic is recreated?,0,0.9924218058586121
651124339,9944,junrao,2021-06-14T17:04:08Z,should we set sessiontopicids and sessiontopicnames to empty map if canusetopicids is false?,0,0.9942962527275085
651163378,9944,junrao,2021-06-14T18:03:14Z,"i am wondering if this solves the problem completely. the decision to use version 13 fetch request also depends on the kafka version on the broker. so, even if the client has all topic ids, the client may still send version 12 fetch requests to a broker. so, canusetopicids doesn't accurate capture the state whether a version 13 fetch request has been used. another possibility is to handle the switching from version 12 to 13 of the fetch requests on the server side in fetchsession. fetchsession already stores usestopicids. so, if usestopicids is false and a fetch request passes in topicid, we could send an error to the client to force the client to establish a new session. if we do this, we probably don't need to cache the canusetopicids in client fetch session. we can just calculated canusetopicids independently for each request. will this approach be better?",0,0.7135640382766724
651170786,9944,junrao,2021-06-14T18:15:00Z,it might be useful to include the topic name and topic id (old and new) for those inconsistent topic ids.,0,0.9915781021118164
651293905,9944,junrao,2021-06-14T21:35:11Z,"maxversion is not necessary the exact version used for fetch request. the exact version is determined in networkclient.dosend() based on the response of apiversions. so, here, it seems that we need to pass in the exact version number?",0,0.993154764175415
651294705,9944,junrao,2021-06-14T21:36:47Z,should we force close the fetchsession in this case too?,0,0.9923152923583984
651309361,9944,junrao,2021-06-14T22:05:50Z,"since topartitiondatamap() is only called here, should we just inline it here?",0,0.9931867122650146
651310206,9944,junrao,2021-06-14T22:07:39Z,should we document fetch_session_topic_id_error too?,0,0.9948006868362427
651310982,9944,junrao,2021-06-14T22:09:16Z,should unknown_topic_id be fetch_session_topic_id_error now?,0,0.9939960241317749
651314171,9944,junrao,2021-06-14T22:16:16Z,should we just inline toresponsedatamap() here?,0,0.9942007064819336
651314503,9944,junrao,2021-06-14T22:17:04Z,we choose to cache responsedata here but not in fetchrequest. is there a particular reason for this inconsistency?,0,0.9913846254348755
651329577,9944,jolshan,2021-06-14T22:53:56Z,"are you referring to creating a new topic id for the metadata topic? for now, we are simply using the sentinel id.",0,0.994274914264679
651331247,9944,jolshan,2021-06-14T22:58:05Z,this happens inside of `fetchsessionhandler.handleresponse`. we set the session to close upon the next request. the code path for fetcher is slightly different so it made sense for that code to have it there.,0,0.9944635033607483
651331636,9944,jolshan,2021-06-14T22:59:05Z,"this is no longer a partition level error. we can only get it as a top level error. if it is a top level error, i believe we return an empty map and do not go down this code path.",0,0.9902923703193665
651332118,9944,jolshan,2021-06-14T23:00:22Z,"if we try to put in a new topic id, the session should be closed.",0,0.9865962862968445
651332908,9944,jolshan,2021-06-14T23:02:23Z,ah i see what you are saying here. i think this will still close the session when we send the request. the other option is to set a boolean similar to `missingtopicid` (maybe just change to `inconsistenttopicid` that signals to close the session earlier (upon build),0,0.9871000051498413
651333015,9944,jolshan,2021-06-14T23:02:46Z,that makes sense to me.,0,0.9833141565322876
651334106,9944,jolshan,2021-06-14T23:05:39Z,"i think we already do something like this on the broker. we only get to the point of having a session if the broker had an id for all the topics in the request. i don't think we can calculate on a request basis since we may respond with topics that did not have ids associated. i may be misunderstanding what you are saying, but i'm very wary of trying to switch between versions 12 and 13 in the same session.",-1,0.6844806671142578
651335121,9944,jolshan,2021-06-14T23:08:31Z,i see what you mean. it is a little tricky to get the version from the fetchresponse itself. would `resp.requestheader().apiversion()` work?,0,0.9792755842208862
651335255,9944,jolshan,2021-06-14T23:08:49Z,this closes the session in handler.handlerresponse.,0,0.9954403638839722
651335666,9944,jolshan,2021-06-14T23:09:59Z,i think i just have the wrong things here completely. there should be inconsistent_topic_id here as well.,0,0.8929919004440308
651336157,9944,jolshan,2021-06-14T23:11:15Z,i think this inconsistency existed before i touched the code. :grinning_face_with_sweat:,1,0.9685437679290771
651373234,9944,junrao,2021-06-15T01:01:41Z,"got it. could we clean the existing code up a bit? since fetchsessionhandler.handleresponse() already handles the closing of the session on error, it seem that we could get rid of fetchsessionhandler.handleerror(t). also, it seems that if fetchresponse.error() != none, we want to throw the error as an exception. finally, if fetchsessionhandler.handleresponse() returns false, we probably want to throw an exception too?",0,0.9045406579971313
651933919,9944,junrao,2021-06-15T15:59:07Z,got it. we can keep the code as it is then.,0,0.9243322014808655
651939380,9944,junrao,2021-06-15T16:06:10Z,"if we are switching from version 12 to version 13 for a session, prevsessiontopicid will be null. should we also populate inconsistenttopicids in this case to force a new session in the client?",0,0.9938377737998962
651943909,9944,junrao,2021-06-15T16:11:49Z,"i added another comment in fetchsession. if the session starts with no topicid and a fetch request switches to using topicid, could the server just return an error to force a new session? will this avoid the need to track canusetopicids as a state? overall, it's probably a bit better to add a bit complexity on the server to simplify the development on the client since we implement the client multiple times in different languages.",0,0.9909329414367676
651946576,9944,junrao,2021-06-15T16:15:00Z,"yes, i think that works.",0,0.9319475293159485
651947708,9944,junrao,2021-06-15T16:16:03Z,thanks. sounds good.,1,0.9703129529953003
651969184,9944,jolshan,2021-06-15T16:42:29Z,i think there are other errors that can occur when trying to send the request which is why we have fetchsessionhandler.handleerror(t). but this all can probably be cleaned up a bit/improved so i will take a look.,0,0.9882254600524902
651970044,9944,jolshan,2021-06-15T16:43:38Z,"if we switch from 12 to 13, we will not get to this point. we will throw a fetch_session_id_error before we get here.",0,0.9841795563697815
651971564,9944,jolshan,2021-06-15T16:45:41Z,this is something that we are doing in fetchsession. we close the session if the requests switch between 12 and 13 (or vice versa). is the idea that we will just send the request based on the topic ids provided to the builder (if we have an id for each topic) and let the session code on the server handle it?,0,0.9935199618339539
651976677,9944,junrao,2021-06-15T16:52:21Z,"yes, if that makes the client code simpler and more consistent. for example, in [a link] the client also chooses to let the server handle the closing of the session.",0,0.9911038875579834
651977071,9944,junrao,2021-06-15T16:52:49Z,got it. make sense.,1,0.8852770328521729
651985270,9944,jolshan,2021-06-15T17:03:49Z,"i thought about this, and originally we compared the topic ids in the session by grabbing cached partitions and comparing to the ids in the request. since we have a new mechanism (the topic id map) we may no longer need to do this and i can add the id to the hashcode and equals methods.",0,0.9900374412536621
652228425,9944,jolshan,2021-06-15T23:27:39Z,this one is slightly different as we are checking the ibp to get fetchrequestversion. we could have an ibp where the version is lower than 12.,0,0.9917539358139038
652250666,9944,jolshan,2021-06-15T23:53:46Z,i was just thinking about this and realized we may send new error types to clients that may not be able to handle them. i need to review this code again.,0,0.9174026846885681
652835907,9944,jolshan,2021-06-16T16:04:40Z,"ok. just went through logic for old clients 1. unknown_topic_id should not be returned since we won't ever use topic ids (version 12 requests and below)"" 2. fetch_session_topic_id_error should not be returned since we won't send version 13+ in a session and will always have zero uuids 3. inconsistent_topic_id should not be returned, as we won't have topic ids in the request/session. the only thing i can think of is downgrading a client while a session is open. i'm not sure if this can happen.",0,0.8894153237342834
652838939,9944,jolshan,2021-06-16T16:08:28Z,"though in most cases, if we canusetopicids we likely have ibp 2.8, or are upgrading to it.",0,0.9887368083000183
652875100,9944,jolshan,2021-06-16T16:55:24Z,one option is to do what the raftmetadatacache does and simply create a copy of the maps themselves in topicnamestoids() and topicidstonames(),0,0.9923688769340515
653921888,9944,jolshan,2021-06-17T20:43:55Z,"i think the main reason we keep the state in the session for using topic ids is that some requests may not contain any new/updated partitions and we need to know which version to send. we don't want to close the session and simply send the version that was sent last time. i do think this code is quite confusing as is, so i think i can simply a lot of it.",0,0.733477771282196
654039106,9944,jolshan,2021-06-17T23:06:25Z,"ah, i found another use -- we lookup partitions toforget using the hashcode. right now, toforget is a list of topic partitions and we don't directly use the id provided in the request. we could look up the topic id from the topic id map and use it (we could also remove from the session map if we do remove the topic)",0,0.9884184002876282
654673513,9944,jolshan,2021-06-18T20:57:32Z,"this is causing build failures, will update to prevent this.",0,0.919495701789856
655561404,9944,junrao,2021-06-21T17:07:25Z,"the inconsistent_topic_id check in replicamanager is not very precise since the topicid could change immediately after the check. i am thinking that another way to do this is to validate the topicid in the session again when we are generating the fetch response. we could pass in the latest topicnametoid mapping from the metadata cache to updateandgenerateresponsedata(). if the topicid is different from those in the fetch session, we could generate a top level inconsistent_topic_id error. we could then get rid of the inconsistent_topic_id check in replicamanager.",0,0.9853814244270325
655565663,9944,junrao,2021-06-21T17:14:12Z,is there a benefit to have fetch_session_topic_id_error in addition to inconsistent_topic_id? could we just always use inconsistent_topic_id?,0,0.991593599319458
655574477,9944,junrao,2021-06-21T17:28:11Z,"in the latest pr, it seems that canusetopicids is updated on every build() call and can be a local val?",0,0.993522584438324
655574856,9944,junrao,2021-06-21T17:28:40Z,could we do this once at the beginning of build()?,0,0.9945737719535828
655590483,9944,junrao,2021-06-21T17:52:19Z,should we add topicid in tostring()?,0,0.9953606724739075
655593298,9944,junrao,2021-06-21T17:56:38Z,i thought that inconsistent_topic_id is always a top level error now?,0,0.9732061624526978
655598054,9944,junrao,2021-06-21T18:04:11Z,could we first save metadatasnapshot to a local val and then derive both maps so that they can be consistent?,0,0.9931499361991882
655599428,9944,junrao,2021-06-21T18:06:40Z,could we first save _currentimage to a local val and derive both maps from it so that they are consistent?,0,0.993304431438446
655603017,9944,junrao,2021-06-21T18:12:38Z,then could we try/catch just leaderendpoint.sendrequest and call fetchsessionhandler.handleerror(t) on exception? this will make the code easier to understand.,0,0.9937781095504761
655604345,9944,junrao,2021-06-21T18:14:53Z,could we just use errors.forcode() to translate errorcode to exception generically?,0,0.9911866784095764
655614034,9944,junrao,2021-06-21T18:30:41Z,"since we cache fetchdata before, perhaps we could cache it in the new implementation too? this will make it more consistent with fetchresponse. ditto for toforget().",0,0.9928973913192749
655614908,9944,junrao,2021-06-21T18:32:10Z,extra empty line.,0,0.9874565005302429
655621465,9944,junrao,2021-06-21T18:42:57Z,"since this tests non-existing topics, why do we pass in topicnames for fetch requests?",0,0.9932509064674377
655622855,9944,junrao,2021-06-21T18:45:21Z,"this is an existing issue, but could we use case to remove unnamed references _._1?",0,0.9943658113479614
655627698,9944,junrao,2021-06-21T18:53:31Z,could we share the common code btw testcontrollernewibp() and testcontrolleroldibp()?,0,0.9948765635490417
655629132,9944,junrao,2021-06-21T18:55:47Z,should we remove this line? ditto in a few other places in this file.,0,0.9935771822929382
655642933,9944,jolshan,2021-06-21T19:19:02Z,ah apologies i did not clean up as well as i should have.,-1,0.9802247881889343
655643270,9944,jolshan,2021-06-21T19:19:42Z,i can try to pick up all the changes i made that do this.,0,0.9922951459884644
655647688,9944,jolshan,2021-06-21T19:27:27Z,and i discussed this a bit. it seems that the metadata cache may be less accurate than the log itself and that is why we did away with the metadata check. i am also a little unsure (i'd have to check the code) but i'm not sure if the topicid can change. are we saying that the partition and/or the underlying log can change in this code block? i think we can say we will read from the partition with that id. [code block],0,0.9736701250076294
655648541,9944,jolshan,2021-06-21T19:28:56Z,"i think the main reason why i made the session id error was that the inconsistent topic id error's message was too specific for this use case. i suppose we could just make all the errors here session errors. i do like the inconsistent id error specifying the log (and being on the partition with the issue), but we can change this.",0,0.9729154109954834
655649094,9944,jolshan,2021-06-21T19:29:53Z,"it is both a top level and partition error here. i kind of like being able to identify the partition (kind of wish the other errors could do this in some cases), but we can change this.",0,0.676440954208374
655649425,9944,jolshan,2021-06-21T19:30:29Z,ok. i see what you mean here.,0,0.9552443027496338
655649858,9944,jolshan,2021-06-21T19:31:17Z,ah good point. i can look into this.,1,0.9847373366355896
655810138,9944,jolshan,2021-06-22T01:27:11Z,"i think because we still want to build the request. my understanding is that the topic is non-existing on the receiving side, but we still want to receive and handle the response.",0,0.983445942401886
660013467,9944,junrao,2021-06-28T18:14:42Z,"it seems that we should never change the topicid in sessiontopicids? perhaps we should use putifabsent. similarly, if the topicid changes, i am not sure if we should update partitionmap below.",0,0.9847028851509094
660016282,9944,junrao,2021-06-28T18:19:08Z,do we need to include the new fields in tostring()?,0,0.995364785194397
660018415,9944,junrao,2021-06-28T18:22:37Z,should we use usetopicid instead of version?,0,0.9934856295585632
660032238,9944,junrao,2021-06-28T18:45:23Z,should we rename error to toplevelerror to make it clearer?,0,0.9919680953025818
660032853,9944,junrao,2021-06-28T18:46:25Z,"typically, if there is a topic level error, we set the same error in every partition through fetchrequest.geterrorresponse(). should we do the same thing here? ditto for incrementalfetchcontext.updateandgenerateresponsedata().",0,0.9923465251922607
660034212,9944,junrao,2021-06-28T18:48:30Z,error => toplevelerror?,0,0.7380086779594421
660038680,9944,junrao,2021-06-28T18:55:42Z,"ok, this is fine. i was thinking that when topicid changes, a pending fetch request could still reference the outdated partition object and therefore miss the topicid change. this is unlikely and can be tighten up by clearing the segment list when a partition is deleted. regarding the metadata propagation, it's true that right now, we propagate the leaderandisrrequest before the updatemetadatarequest. with raft, the topicid will always flow through metadata update first, followed by the replicamanager. when we get there, maybe we could simplify the the logic a bit.",0,0.9001821875572205
660061129,9944,jolshan,2021-06-28T19:31:39Z,"if a topic id changes, the fetchsession will become a fetcherrorsession and close. i can change to putifabsent if it makes things clearer, but all this state will go away upon an error + session close.",0,0.9911312460899353
660061358,9944,jolshan,2021-06-28T19:32:04Z,i suppose it won't hurt :),0,0.7760183811187744
660061496,9944,jolshan,2021-06-28T19:32:18Z,we can do that to make things clearer.,0,0.9905161261558533
660062652,9944,jolshan,2021-06-28T19:34:17Z,"i think this goes back to the question of whether it is useful for us to have information on the specific partition that failed. if we do this, should we also return the error values for the other fields as we do in fetchrequest.geterrorresponse?",0,0.9821380376815796
660068452,9944,jolshan,2021-06-28T19:44:25Z,"i'm still not sure i follow ""pending fetch request could still reference the outdated partition object and therefore miss the topicid change"" my understanding is that the log is the source of truth and we will either read from the log if it matches and not read if it doesn't. i see we could get an error erroneously if the partition didn't update in time, but i don't see us being able to read from the log due to a stale partition. or are you referring to the getpartitionorexception(tp) call picking up a stale partition and both the request and the partition are stale? in this case, we will read from the log, but will identify it with its correct id. the client will handle based on this.",0,0.9335290193557739
660122565,9944,jolshan,2021-06-28T21:16:00Z,"i guess the only issue with using fetchrequest.geterrorresponse is that we may have different topics in the response than in the request. sessionerrorcontext deals with this by simply having an empty response besides the top level error. i'm wondering if we should do something like this. (likewise, with the unknown_topic_id error, should we also just send back an empty response?)",0,0.9671209454536438
660127887,9944,jolshan,2021-06-28T21:25:48Z,"taking a second look, seems like we just use partitionmap.size. not sure if it is useful to have sessiontopicids size (and if the whole map is too much). i'm thinking maybe just including the usestopicids boolean.",0,0.9566879272460938
660199209,9944,jolshan,2021-06-29T00:33:08Z,"we need to do something like this to easily get the top level error with no partition response for unknown_topic_id. i think this works, but we may want a version check as well just to be safe.",0,0.9579458236694336
660206465,9944,junrao,2021-06-29T00:57:22Z,"this kind of special treatment for unknown_topic_id is a bit weird. if you look at the comment above, the reason for setting the same error code in all partitions is for backward compatibility when we don't have a top level error code. so, we probably can just check the request version. if version is >=13, we just always return a top level error code with no partitions.",-1,0.9811525344848633
660209346,9944,junrao,2021-06-29T01:06:54Z,"this can also cause a bit confusing that we are treating inconsistent_topic_id differently from other top-level errors. since the only possible top level error is inconsistent_topic_id, perhaps we can change toplevelerror to hasinconsistenttopicid. ditto in incrementalfetchcontext.",0,0.9468514919281006
660211602,9944,junrao,2021-06-29T01:14:20Z,"a fetch request may pass the topicid check in replicamanager and is about to call log.read(), when the topicid changes. i was wondering in that case, if log.read() could return data that corresponds to the old topicid. it seems that's not possible since log.close() closes all segments.",0,0.9882529377937317
660228129,9944,jolshan,2021-06-29T02:06:34Z,yeah. i agree it is a bit weird. we can update as you mentioned.,-1,0.9566952586174011
660228674,9944,jolshan,2021-06-29T02:08:16Z,"the topic id should not change in the log once it is set. i think what you said in the last sentence is correct. my understanding is that if the log is closed, it can not read from it anymore.",0,0.9828893542289734
661716207,9944,junrao,2021-06-30T18:27:18Z,"could we adjust the above comment on ""the error is indicated in two ways: by setting the same error code in all partitions, and by setting the top-level error code. the form where we set the same error code in all partitions is needed in order to maintain backwards compatibility with older versions of the protocol in which there was no top-level error code."" ?",0,0.992685079574585
661716835,9944,junrao,2021-06-30T18:28:20Z,"if we can't merge this in 3.0, we will need to change the tag to 3.1.",0,0.9905127882957458
661788073,9944,jolshan,2021-06-30T20:26:49Z,we should adjust this to say we will no longer set on all partitions for versions 13+?,0,0.9935122132301331
661822644,9944,junrao,2021-06-30T21:27:16Z,right,0,0.9678029417991638
671728971,9944,chia7712,2021-07-17T18:30:04Z,"i noticed following warning message from our cluster (building on trunk). [code block] according to this code, changing the version in session is disallowed (please correct me if i misunderstood). should fetch thread keep version in session meta? or change the log level to `debug`?",0,0.9372173547744751
671730072,9944,chia7712,2021-07-17T18:40:57Z,"if there is a removing partition, the topic id is not added to this builder. the fetch request with version=13 will carry `topic='xxx'` and `id=aaa...`. however, the topic name get reset to empty string by kafka protocol. hence, the following error message is produced. [code block] if this is an expected behavior, should we change the log level from `error` to `debug`? or add more docs to say `this error may be returned transiently when xxx`?",0,0.9923186302185059
671754420,9944,jolshan,2021-07-17T23:12:32Z,hi i'm tracking this bug here and will work on the fix: [a link],0,0.9845207333564758
671754618,9944,jolshan,2021-07-17T23:14:47Z,"in general, we should not send a request without a valid name or id. we remove partitions from a session by not including them in the builder -- so theoretically, we should already have the topic id. the only case we don't is when we are in a session that doesn't use topic ids. i will fix this behavior to also check that the topics being removed have ids in the session, otherwise send a v12 request.",0,0.9859220385551453
671754732,9944,chia7712,2021-07-17T23:16:05Z,thanks for response and tracking! will watch the issue!,1,0.9854061603546143
671754759,9944,jolshan,2021-07-17T23:16:31Z,"changing the version is not allowed. i'm not sure i follow what you mean by keeping version. current usestopicids is set based on the version when the session is first created and maintained throughout the session. i think we will see this error transiently, but please let me know if you continue to see this issue after i fix the bug below.",0,0.9560208916664124
671755992,9944,chia7712,2021-07-17T23:33:04Z,thanks for explanation. will test it after you fix the issue!,1,0.9771773219108582
671773887,9944,jolshan,2021-07-18T03:16:33Z,this one too: [a link] i have an idea of how to fix this one as well and it should make a big difference based on the testing i've done so far.,0,0.8896760940551758
1146803694,13443,jeffkbkim,2023-03-23T20:35:42Z,this usually suggests that the code can be simplified. do we see this issue?,0,0.9938235282897949
1146805063,13443,jeffkbkim,2023-03-23T20:37:10Z,is it necessary to use list?,0,0.9932888150215149
1146877129,13443,philipnee,2023-03-23T21:23:46Z,hey do you want to move the document above the class definition?,0,0.9933176040649414
1148105873,13443,jeffkbkim,2023-03-24T22:19:19Z,do these methods need to be protected?,0,0.9937359094619751
1148110690,13443,jeffkbkim,2023-03-24T22:24:26Z,when should we throw partitionassignorexception? should we throw when topics are not co-partitioned?,0,0.9930099248886108
1148119606,13443,jeffkbkim,2023-03-24T22:36:05Z,can we just define this as minrequiredquota?,0,0.9943193197250366
1148125546,13443,jeffkbkim,2023-03-24T22:48:14Z,i might be missing something - is it possible to decrease the number of partitions? there seems to be a related kip: [a link] but i don't see the new record.,0,0.9647983312606812
1148129063,13443,jeffkbkim,2023-03-24T22:54:58Z,do we want to sort for every retainedpartitionscount?,0,0.9937313199043274
1148132025,13443,jeffkbkim,2023-03-24T23:01:45Z,"can you help me understand why we're incrementing? remaining is the number of partitions remaining to meet the min required quota so if we're giving one of the extra partitions to this member, my intuition tells me that remaining should decremented here.",0,0.9920222759246826
1148134237,13443,jeffkbkim,2023-03-24T23:08:04Z,can we create a new arraylist and add it at the end instead of accessing the map each time to add a new partition in l131?,0,0.9948496222496033
1148141785,13443,jeffkbkim,2023-03-24T23:29:17Z,i think we can make this more efficient. removing all elements from one list with another will take o(n^2) assuming both have same size.,0,0.9856308102607727
1148145596,13443,philipnee,2023-03-24T23:38:46Z,"i got pointed out several times to make the param final. i think it's a good practice, wdyt?",1,0.971886157989502
1148146400,13443,philipnee,2023-03-24T23:41:25Z,"i don't think we need this comment, the intent is pretty obvious.",0,0.9452622532844543
1148149978,13443,philipnee,2023-03-24T23:51:23Z,is it possible to do? [code block],0,0.9955388903617859
1148150169,13443,philipnee,2023-03-24T23:52:05Z,"this and step 2 can be more descriptive. but we probably don't need to explicitly describe the step, i guess.",0,0.9858542084693909
1149558270,13443,philipnee,2023-03-27T17:05:32Z,i wonder if we should put this in common - i assume there's a lot of common use case for pair,0,0.9602713584899902
1149567823,13443,philipnee,2023-03-27T17:15:08Z,i would refactor this into a separated function as it's kind of long.,0,0.9744455218315125
1149569835,13443,philipnee,2023-03-27T17:17:12Z,"you could avoid null check using getordefault(topicid, new hashset<>())",0,0.9953432083129883
1149570091,13443,philipnee,2023-03-27T17:17:29Z,"the comment is also not needed, null check here is pretty indicative.",0,0.9901129007339478
1149572710,13443,philipnee,2023-03-27T17:20:07Z,i'm not entirely clear about the point of conversion here: i think it is because of line 181. there couldn't use use the foreach/for( ... : ...) syntax?,0,0.9200835824012756
1149630814,13443,rreddy-22,2023-03-27T18:17:17Z,i tried to simplify it as much as possible but since we wanted to many properties the code is a little complex,0,0.9000051021575928
1149644261,13443,rreddy-22,2023-03-27T18:28:14Z,"no its not necessary but it's easier to work with, is there a reason why we should use collection instead of list?",0,0.99277663230896
1149647453,13443,rreddy-22,2023-03-27T18:31:26Z,"it's specific to the data structures we're using for the assignor so i made it protected so only classes that use the same maps can use it, to avoid confusion.",0,0.991916835308075
1149648624,13443,rreddy-22,2023-03-27T18:32:36Z,"this was added by david in the kip, i'm not sure when he meant for this exception to be thrown.",0,0.9710900783538818
1149650468,13443,rreddy-22,2023-03-27T18:34:27Z,"it's easier to understand if it's first named as numpartitionsperconsumer, i also tried to keep as many original variable names as possible so it's simpler to compare it with the client side/ existing range assignor",0,0.9910106658935547
1149655641,13443,rreddy-22,2023-03-27T18:37:49Z,oh! i wasn't sure if it was possible but i just designed the algorithm for all sorts of metadata changes. we could remove it and maybe if/when the removal of partitions is possible we can add it back. removed the code and the test case for now,1,0.4032883942127228
1149658306,13443,rreddy-22,2023-03-27T18:40:15Z,"my bad, moved it before the for loop",-1,0.993169903755188
1149659044,13443,rreddy-22,2023-03-27T18:41:02Z,"remaining = minrequiredquota - completedquota in cases where there are extra partitions after equally dividing the partitions amongst the consumers they will receive more than the minimum required quota, we're essentially increasing the quota by 1 -> requiredquota = minreq + 1 newremaining = requiredquota - completedquota = minreq + 1 - completedquota = minreq - completed + 1 = remaining + 1",0,0.9751756191253662
1149666320,13443,rreddy-22,2023-03-27T18:48:32Z,"okay yeah makes sense, i'll try to do it with a counter",0,0.9659281969070435
1152197788,13443,jeffkbkim,2023-03-29T16:24:47Z,collection allows iterating over elements which is the only use i see with subscribedtopics. it makes it more generic there's no need to use list here,0,0.9924722909927368
1152198768,13443,jeffkbkim,2023-03-29T16:25:38Z,can we make these private?,0,0.9928932785987854
1152199939,13443,jeffkbkim,2023-03-29T16:26:38Z,"you should clarify that, we should be throwing the exception here if that's expected.",0,0.9915111660957336
1152204557,13443,jeffkbkim,2023-03-29T16:29:48Z,we don't use this variable at all except renaming to minrequiredquota. the comments in l170-171 already explain well what the variable represents,0,0.9939268231391907
1152261139,13443,rreddy-22,2023-03-29T17:15:23Z,"yep clarified, we'll add those cases soon!",0,0.9172371625900269
1152265456,13443,rreddy-22,2023-03-29T17:19:13Z,cool i'll rename it,1,0.9778146147727966
1152272541,13443,rreddy-22,2023-03-29T17:26:17Z,yess thanks !,1,0.9596412181854248
1152275571,13443,rreddy-22,2023-03-29T17:29:21Z,"since its already private, its treated as a final param so prolly not necessary here",0,0.9926277995109558
1152276204,13443,rreddy-22,2023-03-29T17:29:59Z,"got it, removed",0,0.9664987325668335
1152284259,13443,rreddy-22,2023-03-29T17:36:42Z,"we need the integers that are not in the range [0, numpartitions] on comparison with assignedpartitions i.e we're calculating the difference between the set of assignedpartitions and the total set of partitions for that topic",0,0.9913284182548523
1152285443,13443,rreddy-22,2023-03-29T17:37:50Z,i just figured it would be easier to follow/correlate the code with the steps mentioned in the java doc,0,0.9823139905929565
1152306205,13443,rreddy-22,2023-03-29T17:58:36Z,ohh got it! thanks! changed it!,1,0.9968936443328857
1152313744,13443,rreddy-22,2023-03-29T18:05:48Z,"we need the order of the partitions to be guaranteed and sorted when we're retaining the prev assignment, that's why we had to convert it to a list first.",0,0.9903947710990906
1152314761,13443,rreddy-22,2023-03-29T18:06:51Z,okay i'll refactor it!,0,0.8803747892379761
1152318162,13443,rreddy-22,2023-03-29T18:10:19Z,changed it!,1,0.5473453402519226
1152434986,13443,philipnee,2023-03-29T20:14:32Z,i think the point is final makes the params unmodifiable.,0,0.976746678352356
1152440653,13443,philipnee,2023-03-29T20:21:08Z,wait why is it specific? this is just a generic tuple no?,0,0.9654621481895447
1153765068,13443,rreddy-22,2023-03-30T20:40:33Z,sry my bad! i was thtinking about the putlist and putset,-1,0.994624674320221
1156050423,13443,jeffkbkim,2023-04-03T14:32:42Z,this can be removed,0,0.9951673746109009
1156090957,13443,jeffkbkim,2023-04-03T15:03:49Z,should this be topic2name?,0,0.9943979382514954
1156091273,13443,jeffkbkim,2023-04-03T15:04:06Z,nit: consumer c,0,0.9876542687416077
1156108091,13443,jeffkbkim,2023-04-03T15:17:35Z,"for expectedassignment, can we add a layer for each memberid? this is blindly matching with any member's assignment which doesn't seem right. then we won't have to remove from the expectedassignment which is also not ideal",0,0.9733089208602905
1156116922,13443,jeffkbkim,2023-04-03T15:24:40Z,you can use map.values() instead of entryset() if you don't need the key.,0,0.9952164888381958
1156117116,13443,jeffkbkim,2023-04-03T15:24:49Z,same here,0,0.99204421043396
1156125078,13443,jeffkbkim,2023-04-03T15:31:14Z,"how do we know [0, 1] went to the same member from the initial assignment?",0,0.9915136694908142
1156240340,13443,rreddy-22,2023-04-03T17:18:04Z,this is a method though so private is implicitly final right?,0,0.9935793876647949
1156241130,13443,rreddy-22,2023-04-03T17:18:52Z,no we want all the mappings to be with uuid,0,0.9936047196388245
1156251873,13443,jeffkbkim,2023-04-03T17:29:52Z,"no, i'm referring to `assignmenttopicmetadata(topic1name, 3)`",0,0.9948891401290894
1156255508,13443,rreddy-22,2023-04-03T17:32:34Z,"no, this was done because we don't know which member gets which assignment. the order of members is not guaranteed at the time of assignment since they are stored in a hash map. so we're testing if the sets are correct and not testing the exact 1:1 mapping",0,0.9907830953598022
1157238218,13443,Hangleton,2023-04-04T13:20:44Z,are you referring to adding the `final` modifier to the parameter `assignmentspec` or the method `consumerspertopic`?,0,0.9948107004165649
1160097876,13443,rreddy-22,2023-04-06T17:54:18Z,ohhh yess thanks!,1,0.9848704934120178
1160098997,13443,rreddy-22,2023-04-06T17:55:36Z,going to add another test for stickiness,0,0.991569459438324
1160919328,13443,jeffkbkim,2023-04-07T19:34:00Z,"""map of assigned partitions by topicid"" is more readable to me. wdyt?",0,0.9905942678451538
1160920086,13443,jeffkbkim,2023-04-07T19:35:49Z,in kafka we typically name getters as the field itself. in this case it would be `members()`,0,0.9933977127075195
1160921964,13443,jeffkbkim,2023-04-07T19:39:58Z,same on getters,0,0.9915640354156494
1160923243,13443,jeffkbkim,2023-04-07T19:42:41Z,"this doesn't look right in the javadoc. also can we get rid of all of the hyphens after colons? "":-"" to "":"" also, i think [code block] is more readable",0,0.9723473787307739
1160925170,13443,jeffkbkim,2023-04-07T19:46:40Z,you can use for numbered lists,0,0.9940715432167053
1160925256,13443,jeffkbkim,2023-04-07T19:46:52Z,"same here for ordered list. also, ""generate a map of consumerspertopic with member subscriptions."" not sure we actually need this point",0,0.976867139339447
1160927503,13443,jeffkbkim,2023-04-07T19:51:37Z,we need another layer of lists,0,0.9903920888900757
1160929729,13443,jeffkbkim,2023-04-07T19:56:12Z,nit: can we \ all variables \ ?,0,0.992983341217041
1160933184,13443,jeffkbkim,2023-04-07T20:00:32Z,i don't think quota = minquota... is very helpful. how's,1,0.9711112976074219
1160934110,13443,jeffkbkim,2023-04-07T20:02:31Z,how's,0,0.9766974449157715
1160937277,13443,jeffkbkim,2023-04-07T20:10:03Z,"was this comment actually addressed? also, i'm wondering if just creating `member` private class which contains [code block] fields. the current use of the pair class makes the code harder to read.",0,0.9772216081619263
1160938321,13443,jeffkbkim,2023-04-07T20:12:17Z,"the method yes, but the param no. you can still modify assignmentspec inside the method",0,0.9946410655975342
1160939242,13443,jeffkbkim,2023-04-07T20:14:29Z,how's `consumersbytopic`?,0,0.994367778301239
1160940413,13443,jeffkbkim,2023-04-07T20:17:16Z,nit: `members`,0,0.9952437281608582
1160941760,13443,jeffkbkim,2023-04-07T20:20:15Z,i think [code block] looks simpler. wdyt?,0,0.9593632817268372
1160948260,13443,jeffkbkim,2023-04-07T20:34:27Z,nit: per topicid,0,0.9892789721488953
1160952656,13443,jeffkbkim,2023-04-07T20:44:09Z,do we really need to extract putlist and putset out? it makes the code harder to read. i don't see much benefit from this.,0,0.5392389297485352
1160953630,13443,jeffkbkim,2023-04-07T20:46:16Z,we can use keyset() here. we're not using the value,0,0.9948527216911316
1160954169,13443,jeffkbkim,2023-04-07T20:47:26Z,nit: `unassignedpartitionspertopic`,0,0.9949486255645752
1160959103,13443,jeffkbkim,2023-04-07T20:55:25Z,we can remove this comment,0,0.9940693378448486
1160967563,13443,jeffkbkim,2023-04-07T21:13:02Z,nit: i.e.,0,0.9902808666229248
1160972155,13443,jeffkbkim,2023-04-07T21:20:08Z,"nit: there's 2 spaces after ""="". also, let's break down the line into 2 lines.",0,0.975152850151062
1160977912,13443,jeffkbkim,2023-04-07T21:33:40Z,"nit: ""should get i.e. number of partitions per consumer""",0,0.9925763607025146
1160979189,13443,jeffkbkim,2023-04-07T21:37:41Z,"nit: i think we can remove "" = numpartitionsperconsumer"" also `int excesspartitioncount` is simpler and more readable to me. wdyt?",0,0.9770724773406982
1160980503,13443,jeffkbkim,2023-04-07T21:40:55Z,"the numbering is off and ""potentially unfilled consumer"" and l204 ""add to the potentially unfilled consumers""",0,0.9940255880355835
1160982741,13443,jeffkbkim,2023-04-07T21:47:34Z,"we are not ""assigning"" here, we're just increasing the quota. ""after possibly increasing the remaining quota with an excess partition"" makes more sense to me.",0,0.9864326119422913
1160987340,13443,jeffkbkim,2023-04-07T21:55:53Z,are we actually deleting here? we're moving the pointer and grabbing a subset of the unassigned partitions. let's update the comments if we changed the code,0,0.9915809035301208
1160992340,13443,jeffkbkim,2023-04-07T22:03:34Z,"nit: `list partitionstoassign`, `int unassignedpartitionpointer`",0,0.9945803284645081
1164463357,13443,rreddy-22,2023-04-12T17:51:48Z,changed in interface changes,0,0.9901868104934692
1164463758,13443,rreddy-22,2023-04-12T17:52:14Z,changed in interface changes pr,0,0.9927296042442322
1164463893,13443,rreddy-22,2023-04-12T17:52:21Z,changed in interface changes pr,0,0.9927296042442322
1164465796,13443,rreddy-22,2023-04-12T17:54:07Z,done,0,0.8682363629341125
1164469564,13443,rreddy-22,2023-04-12T17:57:55Z,sounds good thanks!,1,0.9891697764396667
1164470089,13443,rreddy-22,2023-04-12T17:58:28Z,done!,1,0.6799882054328918
1164884200,13443,rreddy-22,2023-04-13T02:03:12Z,changed to memberspertopic,0,0.9891437888145447
1164884866,13443,rreddy-22,2023-04-13T02:03:51Z,removed the whole comment cause unnecessary,0,0.9452788829803467
1164893597,13443,rreddy-22,2023-04-13T02:12:37Z,changed it,0,0.9852859377861023
1164894366,13443,rreddy-22,2023-04-13T02:13:41Z,removed,0,0.9591778516769409
1164894487,13443,rreddy-22,2023-04-13T02:13:50Z,done,0,0.8682363629341125
1164899524,13443,rreddy-22,2023-04-13T02:17:50Z,ok,0,0.9233372807502747
1164901673,13443,rreddy-22,2023-04-13T02:19:25Z,i edited it but i want to keep it in cause its important,0,0.919353723526001
1164901770,13443,rreddy-22,2023-04-13T02:19:32Z,ok,0,0.9233372807502747
1164902619,13443,rreddy-22,2023-04-13T02:20:32Z,doesn't exist anymore,0,0.928852915763855
1164905279,13443,rreddy-22,2023-04-13T02:23:32Z,removed comment,0,0.9634342789649963
1164906229,13443,rreddy-22,2023-04-13T02:24:25Z,each consumer gets one extra partition and i think the current name clarifies that,0,0.9910680651664734
1164906996,13443,rreddy-22,2023-04-13T02:25:13Z,done mb with the numbers,0,0.9953123331069946
1164908245,13443,rreddy-22,2023-04-13T02:26:48Z,cool changed it,1,0.9835441708564758
1164908509,13443,rreddy-22,2023-04-13T02:27:06Z,yeah sorry updated the comments,-1,0.9945390820503235
1164911085,13443,rreddy-22,2023-04-13T02:30:03Z,done,0,0.8682363629341125
1169925559,13443,dajac,2023-04-18T12:00:00Z,should we revert this change now?,0,0.9867462515830994
1169925666,13443,dajac,2023-04-18T12:00:06Z,should we revert this change now?,0,0.9867462515830994
1169925763,13443,dajac,2023-04-18T12:00:11Z,should we revert this change now?,0,0.9867462515830994
1169958192,13443,dajac,2023-04-18T12:25:56Z,all the html makes the text quite messy. should we just remove it?,-1,0.8398488163948059
1169959223,13443,dajac,2023-04-18T12:26:47Z,should this section go to the javadoc of `assign`? that would be closer to the implementation.,0,0.9923032522201538
1169966483,13443,dajac,2023-04-18T12:32:52Z,"nit: there is an extra space after `=`. moreover, it seems that we don't mutate `assignedpartitionsfortopic` so we could actually use `collections.emptyset()` instead of `new hashset<>()`.",0,0.9897634983062744
1169982137,13443,dajac,2023-04-18T12:45:18Z,nit: a small stylistic comment: it would be better to structure such line as follow: [code block] i find this more readable than those long lines.,0,0.971164345741272
1170005574,13443,dajac,2023-04-18T13:00:45Z,"is there a reason why we don't do step 4 and 5 directly in the `memberspertopic.foreach((topicid, membersfortopic)` loop?",0,0.9934632778167725
1170007516,13443,dajac,2023-04-18T13:02:11Z,nit: i have noticed that you use `computeifabsent` in a few places where `put` would just work.,0,0.9877980351448059
1170010343,13443,dajac,2023-04-18T13:04:31Z,"nit: whenever possible, let's use `collections.singletonmap`, `collections.emptymap`, `collection.emptylist`, etc.",0,0.9917125701904297
1170013892,13443,dajac,2023-04-18T13:07:19Z,nit: let's format such line as follow: [code block],0,0.9950685501098633
1170014726,13443,dajac,2023-04-18T13:07:58Z,nit: is `new arraylist<>` necessary here? there are many other cases.,0,0.9921948909759521
1170017991,13443,dajac,2023-04-18T13:10:28Z,i have a few utils [a link]. we could reuse them here as well. they allow you to define as assignment as follow: [code block] it makes the code easier to read.,0,0.9749139547348022
1170021475,13443,dajac,2023-04-18T13:13:12Z,i wonder if it would be better to actually create the expected `groupassignment` and to compare the computed one against it. we could then just use `assertequals` and this would verify the full output.,0,0.9766928553581238
1170322124,13443,rreddy-22,2023-04-18T16:52:38Z,"we discussed this before when i was writing the tests, that is how i did it earlier but i realized that the order of members isn't guaranteed in the hashmap so we don't know exactly what order the assignor used to predict the expected assignment",0,0.9911652207374573
1170357303,13443,dajac,2023-04-18T17:23:07Z,"if two maps have the same content, they will be equal, no? the order of the members does not matter here.",0,0.9870787858963013
1170658513,13443,rreddy-22,2023-04-18T23:21:37Z,remove the whole thing or just the html tags,0,0.9892013072967529
1170658595,13443,rreddy-22,2023-04-18T23:21:47Z,cool,1,0.6638733148574829
1170659867,13443,rreddy-22,2023-04-18T23:24:20Z,done,0,0.8682363629341125
1170662644,13443,rreddy-22,2023-04-18T23:30:19Z,the order in which the consumers were assigned partitions is unknown to us since at the time of computing the coordinator accesses the members map (order not guaranteed) so we can't predict which member gets which partitions in the first place. it could result in flaky tests,0,0.9750909805297852
1170981380,13443,dajac,2023-04-19T08:13:23Z,gotcha. i understand what you meant now.,1,0.7968060374259949
1171070403,13443,dajac,2023-04-19T09:23:44Z,just the html tags. the explanation is useful.,1,0.8996095657348633
1171777998,13443,rreddy-22,2023-04-19T19:37:45Z,"you're right, i've removed them!",1,0.6110378503799438
1171778657,13443,rreddy-22,2023-04-19T19:38:30Z,"the formatting is really off without them, that's why we had to add them",0,0.6502759456634521
1171781883,13443,rreddy-22,2023-04-19T19:42:18Z,"i removed most of them and converted them to put before, i'll check again",0,0.9929245710372925
1171782048,13443,rreddy-22,2023-04-19T19:42:27Z,got it,1,0.9044701457023621
1171783796,13443,rreddy-22,2023-04-19T19:44:36Z,like calculate unassigned partitions and assign them at the same time?,0,0.9912850260734558
1171913729,13443,rreddy-22,2023-04-19T22:33:48Z,re-checked and computeifabsent is the best safe way to do it,0,0.9926159381866455
1172314693,13443,dajac,2023-04-20T09:18:19Z,it does not have to be at the same time. i was wondering if there a reason why we need to do step 4 and 5 afterwards with all the unfilled members vs doing it per topic right after step 3.,0,0.98628830909729
1172321570,13443,dajac,2023-04-20T09:23:13Z,let's try at minimum to align/indent/format things correctly. it does not look good as it is.,-1,0.5882324576377869
1172322335,13443,dajac,2023-04-20T09:23:53Z,nit: we usually indent with 4 spaces in this case.,0,0.9914446473121643
1172324109,13443,dajac,2023-04-20T09:25:26Z,this is not correctly indented. it should be as follow: [code block],0,0.9680784344673157
1172325053,13443,dajac,2023-04-20T09:26:15Z,"nit: could we use `collections.singletonmap(topic1uuid, new assignmenttopicmetadata(3))`?",0,0.9944954514503479
1172325341,13443,dajac,2023-04-20T09:26:30Z,`singletonlist`?,0,0.9948640465736389
1172824513,13443,rreddy-22,2023-04-20T16:20:00Z,"i had changed it in my ide and it looked good, idky the formatting changed in the pr :( will take a look at it thanks!",-1,0.9954906105995178
1173050527,13443,rreddy-22,2023-04-20T20:17:51Z,okay,0,0.9793328642845154
1173172297,13443,rreddy-22,2023-04-20T23:26:12Z,done,0,0.8682363629341125
1173174594,13443,rreddy-22,2023-04-20T23:31:42Z,we need a set of sets so i added something similar in my test so facilitate the needs of this test case,0,0.9934229254722595
1173177108,13443,rreddy-22,2023-04-20T23:37:24Z,we could've computed if the partition is still unassigned in step 5 directly and assigned it but since this is a range assignor i need all the available partitions in in a sorted list and the list provided is sorted since we iterate through 0-n where n is the total partitions and only add it to unassigned list iff it doesn't exist in the sticky partitions list,0,0.9933898448944092
1173177198,13443,rreddy-22,2023-04-20T23:37:37Z,i hope i understood the question correctly,1,0.5843334197998047
1173179837,13443,rreddy-22,2023-04-20T23:43:38Z,also the entire unfilled members per topic list needs to be populated since the ranges depend on how many partitions were assigned to the prev member,0,0.9937406182289124
1175267055,13443,dajac,2023-04-24T13:14:17Z,would it be possible to directly use `memberassignment` instead of `map ` here? that would save allocating a hashmap at the end.,0,0.9918579459190369
1175273145,13443,dajac,2023-04-24T13:19:07Z,"i still wonder if we could combine steps 4 and 5 in this loop. for instance, could we do something like this? * we start by creating a sorted set with all the partitions of the topic. * then for each member, we do what is already done but instead of populating `assignedstickypartitionspertopic`, we remove assigned partitions from the sorted set. * then we go through the unfilled members and allocated the remaining partitions in the sorted set. this could potentially reduce the number of data structures.",0,0.9542678594589233
1175274363,13443,dajac,2023-04-24T13:20:01Z,should we break this loop when there are no more partitions left to be assigned?,0,0.9895843863487244
1175279644,13443,dajac,2023-04-24T13:24:14Z,nit: we need to close ` `.,0,0.9850363731384277
1175280542,13443,dajac,2023-04-24T13:24:54Z,nit: ` ` does not seem to be required.,0,0.9904298186302185
1175552910,13443,rreddy-22,2023-04-24T16:48:56Z,we need to able to modify the map > throughout the code as we assign partitions and since targetpartitions in memberassignment is private final we can't modify it once its initialized. this is why i had to do it this way.,0,0.9929713606834412
1175567311,13443,rreddy-22,2023-04-24T17:03:25Z,"theoretically the sum of all the ""remaining"" values in the unfilled members list for the topic will be equal to the total unassigned partitions so we don't need to break the loop cause it happens automatically. i could add a check to ensure this is the case, i've added a check in the uniform assignor anyways just for a correctness check.",0,0.9923486709594727
1175689958,13443,rreddy-22,2023-04-24T19:17:01Z,steps 3 & 4?,0,0.9888612627983093
1175701652,13443,rreddy-22,2023-04-24T19:30:51Z,we would need to have a map called partitions and to remove every assigned partition each removal would cost o(logn) so for n removals worst case o(nlogn). the time complexity of just calculating at the end is o(n). so its really just time vs space. we save space of one map o(n+m) in this method but we spend more time for removal.,0,0.9858670830726624
1175703194,13443,rreddy-22,2023-04-24T19:32:33Z,2maps and o(n) time vs 1map (potentially takes up more space if its a tree set for sorted order) and o(nlogn) time,0,0.9885850548744202
1176483468,13443,dajac,2023-04-25T13:01:28Z,"this is not entirely correct. yes, the assignment is private final but this does not prevent you from mutating the hash map. it only prevents you from re-assigning the attribute.",0,0.9851186275482178
1176489630,13443,dajac,2023-04-25T13:06:30Z,"i agree that the sorted set may not be the best so let's put this aside for now. coming back to my other point, would it be possible to compute the unassigned partitions and to assign them directly in this loop? i mean after the current logic in the loop. it does not have to be combined. i understand that we can't assign partitions while we check if we want to keep existing ones or not. if we do this, we could potentially eliminate step 3 or more precisely combine it with the next step. this would simplify the data structures overall, i think.",0,0.9432225227355957
1176631579,13443,jeffkbkim,2023-04-25T14:47:25Z,nit: unassignedpartitionspertopic,0,0.9899022579193115
1176636568,13443,jeffkbkim,2023-04-25T14:50:24Z,"nit: accessing the field looks straightforward enough, do we need this?",0,0.9912579655647278
1176654241,13443,jeffkbkim,2023-04-25T15:00:47Z,"nit: `(""member "" + memberid)`",0,0.9935798645019531
1176661712,13443,jeffkbkim,2023-04-25T15:06:20Z,"we can also change this to `int` once is removed. also, it would be good to describe what this remaining field represents",0,0.994941234588623
1176666308,13443,jeffkbkim,2023-04-25T15:09:50Z,what if the member already has min required quota + 1 assigned to it? i think it's handled in l192,0,0.9951522350311279
1176688479,13443,jeffkbkim,2023-04-25T15:26:48Z,"how's ""it has min req partitions but it may get an extra partition so it is a potentially unfilled member""?",0,0.9862068891525269
1176692608,13443,jeffkbkim,2023-04-25T15:29:52Z,"how's ""if remaining > 0: it has not met the minimum required quota and therefore is unfilled.""",0,0.9871926307678223
1176694961,13443,jeffkbkim,2023-04-25T15:31:44Z,nit: memberandremainingassignments,0,0.9896919131278992
1176836313,13443,jeffkbkim,2023-04-25T17:39:36Z,"do we have a test case where a consumer had 4 partitions, reassignment computes 3 + 1 including the extra partition and we ensure all 4 partitions stick? a case to test whether extra partition is also sticky",0,0.9926631450653076
1177109065,13443,rreddy-22,2023-04-25T22:01:44Z,"oh sorry my bad, i've always learnt that final means you can't modify the value after, but i guess for a map you can't modify the reference but can change the values. i'll see what i can change thanks!",-1,0.9902181029319763
1177128215,13443,rreddy-22,2023-04-25T22:30:12Z,"i think i made a new function cause the assign function was getting super long but yeah we can put just the calculation of unassigned partitions in the same loop, changed it now thanks! sry the step numbers were confusing",1,0.9879913926124573
1177128655,13443,rreddy-22,2023-04-25T22:30:59Z,i think you mean step 4? step 3 is filling in the potentially unfilled members map and that i can't elminate.,0,0.9864556789398193
1177136376,13443,rreddy-22,2023-04-25T22:45:36Z,yeah it is handled 173-179,0,0.9916302561759949
1177139606,13443,rreddy-22,2023-04-25T22:51:57Z,this whole function is removed now,0,0.9942933917045593
1177156557,13443,rreddy-22,2023-04-25T23:27:09Z,"removed, since it was derived from a generic pair class, missed removing it, thanks for the catch!",1,0.9864324927330017
1177156668,13443,rreddy-22,2023-04-25T23:27:23Z,done,0,0.8682363629341125
1177168353,13443,rreddy-22,2023-04-25T23:53:27Z,changed,0,0.7968646287918091
1177168484,13443,rreddy-22,2023-04-25T23:53:41Z,renamed to memberwithremainingassignments,0,0.9807114005088806
1177177698,13443,rreddy-22,2023-04-26T00:15:03Z,added another test just in case,0,0.9940540194511414
1177178765,13443,rreddy-22,2023-04-26T00:17:29Z,"not straightforward anymore with the new code, so kept it",0,0.9698659181594849
1177432844,13443,dajac,2023-04-26T07:05:14Z,should those be part of the preceding ` `?,0,0.9923045039176941
1177433390,13443,dajac,2023-04-26T07:05:47Z,nit: does it have to be public?,0,0.982291579246521
1177434215,13443,dajac,2023-04-26T07:06:42Z,"nit: let's use the javadoc format. also, i would not mention `potentiallyunfilledmembers` and `unfilledmembers` here. let's describe the purpose only.",0,0.9920164346694946
1177434539,13443,dajac,2023-04-26T07:07:06Z,"nit: if we put javadoc for attributes, let's do it for all of them.",0,0.9884910583496094
1177435182,13443,dajac,2023-04-26T07:07:52Z,"nit: as this class is purely internal, i think that we could make the attributes public and remove the getters. they don't bring anything here.",0,0.9895115494728088
1177435368,13443,dajac,2023-04-26T07:08:04Z,nit: javadoc?,0,0.9899388551712036
1177436746,13443,dajac,2023-04-26T07:09:29Z,nit: the javadoc is not aligned correctly.,0,0.8936554789543152
1177437828,13443,dajac,2023-04-26T07:10:37Z,nit: i would remove all the references to variables in the javadoc. they will get out of sync quickly. let's use plain english instead.,0,0.9893486499786377
1177438770,13443,dajac,2023-04-26T07:11:38Z,"now that we have all the logic in the main loop, it seems that those maps are not necessary anymore. we could just use lists/sets defined in the loop.",0,0.990402102470398
1177447096,13443,dajac,2023-04-26T07:20:03Z,now that we have everything in the main loop could we combine step 3 into step 5 and avoid having to recreate memberwithremainingassignments objects here? it seems that we could just adjust the `remaining` when we assign partitions. is it possible?,0,0.9934787750244141
1177447497,13443,dajac,2023-04-26T07:20:30Z,we already have `numpartitionsfortopic`. could we reuse it?,0,0.9950409531593323
1177450105,13443,dajac,2023-04-26T07:23:08Z,nit: we usually put a space before and after the `:`.,0,0.9899250268936157
1177452306,13443,dajac,2023-04-26T07:25:12Z,nit: we can remove this empty line.,0,0.9919142723083496
1177466123,13443,dajac,2023-04-26T07:37:01Z,"i have a general comment about the comments in the code. i think that your comments are very useful to understand the logic. however, they are a bit spread all over the places. i wonder if it would be possible to re-group them a bit. for instance in this case, we could either have one comment for the entire block or one comment per branch. [code block] or [code block]",1,0.6607092618942261
1177506264,13443,dajac,2023-04-26T08:13:32Z,nit: `testoneconsumerwithnosubscribedtopics`?,0,0.9934067726135254
1177508192,13443,dajac,2023-04-26T08:15:02Z,indentation of the arguments seems to be off. it should be like this: [code block],0,0.9317896962165833
1177509263,13443,dajac,2023-04-26T08:15:56Z,"nit: it is usually better to use assertequals for collections as it gives more information when it fails. `assertequals(collections.emptymap(), groupassignment.members())`.",0,0.9852547645568848
1177510234,13443,dajac,2023-04-26T08:16:35Z,nit: `testoneconsumersubscribedtononexistenttopic`?,0,0.9944717884063721
1177511835,13443,dajac,2023-04-26T08:17:38Z,nit: the closing parenthesis of `assignmentmemberspec` should be on a new line and aligned with `new assignmentmemberspec`. the closing parenthesis of `singletonmap` should be aligned with `map `.,0,0.9946395754814148
1177530072,13443,dajac,2023-04-26T08:29:30Z,"nit: this comment feels a bit weird here. i also wonder if this comment is necessary. the subscriptions are clear based on the specs. if you want to keep it, i would rather put it before `members` or you could also have one comment before each `members.put`.",-1,0.9812288880348206
1177541233,13443,dajac,2023-04-26T08:38:56Z,"as i told you offline, i am not a fan of this method. the main issue is that it does not really verify the co-partitioning. moreover, it does not verify the member ids. i am thinking about two alternatives: option 1: [code block] option 2: we could perhaps use a `treemap` instead of an `hashmap` for the members that we pass into the `assignmentspec`. the `treemap` guarantees the order so the algorithm may be deterministic with this. if it is, we could simply compute the expected `groupassignment` and use `assertequals`.",0,0.4915870130062103
1177543425,13443,dajac,2023-04-26T08:40:49Z,"this is a perfect example to illustrate my previous comment. in this case, `consumera` cannot get `topic3uuid` but we don't really verify this.",0,0.982999861240387
1177545492,13443,dajac,2023-04-26T08:42:35Z,nit: here we could use my `mkassignment` helper method and inline the current assignment. the would reduce the boilerplate.,0,0.993410050868988
1177546403,13443,dajac,2023-04-26T08:43:25Z,nit: indentation is off here.,0,0.7510121464729309
1177549003,13443,dajac,2023-04-26T08:45:28Z,nit: indentation is not correct here. there are a few other cases in this file.,0,0.9672749638557434
1177550694,13443,dajac,2023-04-26T08:46:56Z,nit: this empty line could be removed.,0,0.9941554069519043
1177553020,13443,dajac,2023-04-26T08:48:55Z,"in this case, the expected assignment seems to be deterministic so we could just use `assertequals`. this seems to be true for most of the `testreassignment` test cases.",0,0.9918707609176636
1177565215,13443,dajac,2023-04-26T08:58:36Z,should we add tests where we remove or add more than one members?,0,0.9924948215484619
1178059673,13443,rreddy-22,2023-04-26T15:37:31Z,"i got comments before to add tags and put the variable names, thats why i did it",0,0.99208003282547
1179556594,13443,rreddy-22,2023-04-27T18:44:47Z,changing multiple subscriptions has similar effects as adding and removing consumers and that test exists so i didn't add another one.,0,0.9890039563179016
1179557943,13443,rreddy-22,2023-04-27T18:46:26Z,on it,0,0.9889004230499268
1179746842,13443,rreddy-22,2023-04-27T22:26:20Z,changed,0,0.7968646287918091
1179749224,13443,rreddy-22,2023-04-27T22:28:52Z,"it was public in the client assignor so i kept it public, should i change it to private?",0,0.9947084188461304
1179787876,13443,rreddy-22,2023-04-27T23:13:05Z,regrouped as much as possible,0,0.9740623235702515
1179789140,13443,rreddy-22,2023-04-27T23:14:40Z,oh okay got it,0,0.8652936816215515
1179793263,13443,rreddy-22,2023-04-27T23:23:24Z,added them since during reassignment its not really clear what the old subscriptions were but i removed them wherever it wasn't required,0,0.9871783256530762
1179796793,13443,rreddy-22,2023-04-27T23:31:11Z,"this was my concern too which is why i had asked for advice and this was the best idea we had all come up with, but i like the treemap idea i'm gonna go ahead and do that",0,0.7522935271263123
1179797144,13443,rreddy-22,2023-04-27T23:31:54Z,i verified with print statements so there's no issue with the code however jic that was also a concern,0,0.9867457747459412
1179797402,13443,rreddy-22,2023-04-27T23:32:24Z,"i like the treemap idea, i wish we thought of this sooner :(",-1,0.9943206310272217
1179966618,13443,dajac,2023-04-28T06:10:02Z,ack. we can keep it as public.,0,0.9579604864120483
1179967228,13443,dajac,2023-04-28T06:10:57Z,i understand that the code is doing the right thing. what i meant is that the assertions would not catch all issues.,0,0.8907091617584229
1179968856,13443,dajac,2023-04-28T06:13:40Z,interesting... it is weird to have variable names in the description. plain english is much better than `memberspertopic`.,-1,0.9921770691871643
1179969167,13443,dajac,2023-04-28T06:14:13Z,"yeah, sorry for this. i only thought about it when i raised this comment.",-1,0.9943498969078064
1182715705,13443,rreddy-22,2023-05-02T15:32:13Z,changing it,0,0.982994556427002
1188009097,13443,rreddy-22,2023-05-09T00:34:03Z,done,0,0.8682363629341125
1188009762,13443,rreddy-22,2023-05-09T00:35:53Z,i think for readability its fine to have currentassignment for b and then just pass it,0,0.9726530313491821
1188270445,13443,dajac,2023-05-09T07:55:42Z,"i still find the html hard to read mainly because it is hard to visually know what is part of the main list and what is part of the sub-list. i wonder if we could indent things better. for instance, we could format it as follow. this is just a suggestion, there may be other ways. [code block]",-1,0.856376588344574
1188270698,13443,dajac,2023-05-09T07:55:58Z,we could use an `int` here.,0,0.9924499988555908
1188271077,13443,dajac,2023-05-09T07:56:18Z,nit: `topicids` -> `topic ids`?,0,0.9932250380516052
1188272308,13443,dajac,2023-05-09T07:57:26Z,i was thinking about this one. this should never happen because the `targetassignmentbuilder` handle this. therefore i wonder if we should throw a `partitionassignorexception` error with the same error here. what do you think?,0,0.9171260595321655
1188273956,13443,dajac,2023-05-09T07:58:59Z,"i have the same comment regarding the html here. moreover, let's remove those variables in the test and replace them with regular text.",0,0.9946402907371521
1188274698,13443,dajac,2023-05-09T07:59:38Z,nit: `step 1` alone reads weird. could we say `step 1: something...`?,-1,0.9832842350006104
1188278175,13443,dajac,2023-05-09T08:02:57Z,"nit: as `topicdata` is never reused, should we just define `numpartitionsfortopic` as `assignmentspec.topics().get(topicid).numpartitions()`?",0,0.9930701851844788
1188281712,13443,dajac,2023-05-09T08:06:21Z,this comment looks out of context here. would it make sense to have a comment which covers both `minrequiredquota` and `nummemberswithextrapartition` and explains all of this?,0,0.8345332741737366
1188283167,13443,dajac,2023-05-09T08:07:43Z,nit: let's add a small explanation here as well.,0,0.9936581254005432
1188283174,13443,rreddy-22,2023-05-09T08:07:43Z,all tests are checked with 1:1 mapping now so this is taken care of now,0,0.982382595539093
1188284004,13443,rreddy-22,2023-05-09T08:08:27Z,plain english for everything?,0,0.7780287265777588
1188291620,13443,dajac,2023-05-09T08:15:42Z,"nit: i wonder if we should just remove this part of the comment or shorten it. the important part, i think, is that we retain at max the min require quota.",0,0.9690430164337158
1188300132,13443,dajac,2023-05-09T08:23:09Z,"i feel like there are too many comments here. could we try to simplify and to re-group them? for instance, we could structure it as follow: [code block]",-1,0.5939369201660156
1188302467,13443,dajac,2023-05-09T08:25:15Z,nit: it would be good to explain why `ascending order` is required here.,0,0.9899550676345825
1188303243,13443,dajac,2023-05-09T08:26:00Z,nit: indentation should be 4 spaces in order to be consistent with how you did it previously. the same applies to l226.,0,0.9941837191581726
1188307585,13443,dajac,2023-05-09T08:29:55Z,"i am curious. is there a reason why you structured it like this? everywhere, we usually structure it as follow: [code block] this is more readable in my opinion.",0,0.895564615726471
1188323433,13443,rreddy-22,2023-05-09T08:43:39Z,changed it thanks!,1,0.9281958341598511
1188374768,13443,dajac,2023-05-09T09:25:54Z,nit: we should also assert the size.,0,0.9924772381782532
1188375282,13443,dajac,2023-05-09T09:26:23Z,is this still useful now that we have `assertassignment`?,0,0.9937658309936523
1188378752,13443,dajac,2023-05-09T09:29:18Z,let's remove step 5 here and include it in step 4.,0,0.9916943907737732
1188385263,13443,dajac,2023-05-09T09:34:38Z,this is interesting. should we still create a member in this case but with an empty assignment?,0,0.9298672676086426
1188387610,13443,dajac,2023-05-09T09:36:26Z,nit: you can use `mkassignment` to replace those. there are other similar cases.,0,0.9952511787414551
1188811581,13443,rreddy-22,2023-05-09T15:51:39Z,"it takes away from the fact that its step one if we write everything in the same line, i wanted to draw attention to it",0,0.9776408076286316
1188817725,13443,rreddy-22,2023-05-09T15:56:30Z,i had it before and then i was told to remove it,0,0.9728828072547913
1188819218,13443,rreddy-22,2023-05-09T15:57:42Z,"this was fixed already, please see the new code, it says outdated on the top",0,0.9923294186592102
1188821039,13443,rreddy-22,2023-05-09T15:59:12Z,"i think its fine honestly, its different from step 4. if its too much in one step there isn't really much point in breaking it up right?",0,0.7672979235649109
1188821932,13443,rreddy-22,2023-05-09T15:59:57Z,that's what i asked and you had told me that either way is fine. i can change it to anything depending on how the rest of the code works,0,0.975609302520752
1188823115,13443,rreddy-22,2023-05-09T16:00:55Z,we don't need it but we wanted separate property tests right?,0,0.9929425716400146
1188832049,13443,rreddy-22,2023-05-09T16:08:31Z,i just wanted to do it topic wise so its easier to understand but i'll change it,0,0.9696455001831055
1188856580,13443,dajac,2023-05-09T16:29:27Z,[code block] is also fine. my point is that `step 1` alone is weird.,-1,0.6347395777702332
1188857767,13443,dajac,2023-05-09T16:30:29Z,"interesting... i feel like this part is more important than all the rest, no?",1,0.8264304399490356
1188857900,13443,dajac,2023-05-09T16:30:36Z,ack.,0,0.5866091847419739
1188858930,13443,dajac,2023-05-09T16:31:36Z,"yeah, it was because we were not able to use equals. now that we can use it, i am not sure that this one bring any value. does it?",0,0.8603869080543518
1188873259,13443,dajac,2023-05-09T16:43:17Z,"yeah, that's right. it does not matter from the targetassignmentbuilder perspective. we can keep it as it is.",0,0.9839268326759338
1188891203,13443,rreddy-22,2023-05-09T16:59:51Z,done.,0,0.9897913336753845
1188891494,13443,dajac,2023-05-09T17:00:11Z,i think that it is better to have one comment for the entire block of code. it makes reading it easier.,0,0.9414969682693481
1188893117,13443,dajac,2023-05-09T17:01:47Z,nit: indentation is still inconsistent here.,0,0.9590185284614563
1188893187,13443,dajac,2023-05-09T17:01:51Z,nit: indentation is still inconsistent here.,0,0.9590185284614563
1188893478,13443,dajac,2023-05-09T17:02:07Z,nit: ` : `.,-1,0.47644829750061035
1188898373,13443,dajac,2023-05-09T17:06:58Z,`currentsize` does not exist any more. this is why i don't like to use variable names in comments :),1,0.8551045656204224
1189210485,13443,rreddy-22,2023-05-09T23:13:29Z,"it looks a bit wonky after formatting it like that, i don't think there's a great way to add this html",-1,0.9205740094184875
1189212267,13443,rreddy-22,2023-05-09T23:17:31Z,i did it in a way that looks best to me in the next commit,0,0.9778968095779419
1189213049,13443,rreddy-22,2023-05-09T23:19:18Z,"nop we can remove it, ig whoever wants it later can write it again",0,0.9871519804000854
1189214614,13443,rreddy-22,2023-05-09T23:23:00Z,okayyy,0,0.6759305596351624
1189216148,13443,rreddy-22,2023-05-09T23:26:11Z,sorry,1,0.6406954526901245
1189216494,13443,rreddy-22,2023-05-09T23:26:54Z,sorry fixed,-1,0.9954793453216553
1189229522,13443,rreddy-22,2023-05-09T23:57:16Z,i got comments saying don't repeat something that's already been mentioned before so i'm pretty sure i had something there and then removed it,0,0.9335463047027588
1189229707,13443,rreddy-22,2023-05-09T23:57:46Z,its already in the java doc step by step so that is merely there to make sure people understand which step we're talking about,0,0.9904865622520447
1189229928,13443,rreddy-22,2023-05-09T23:58:14Z,sure,0,0.9422702193260193
1189231170,13443,rreddy-22,2023-05-10T00:01:09Z,"i removed it, its not that necessary, i just wanted people to have more information on things that i personally got confused about",0,0.8794547319412231
1189231412,13443,rreddy-22,2023-05-10T00:01:40Z,"same explanation as before, i was told not to repeat things that have already been mentioned :(",-1,0.9954003691673279
1189231570,13443,rreddy-22,2023-05-10T00:01:58Z,i removed it,0,0.9886789917945862
1189235728,13443,rreddy-22,2023-05-10T00:11:46Z,okay i wont use variable names again,0,0.9743283987045288
1189237663,13443,rreddy-22,2023-05-10T00:16:32Z,thats how it was before and i was told to change it,0,0.9662755131721497
1189295560,13443,dajac,2023-05-10T02:31:46Z,ok. i was not aware of this.,0,0.979215681552887
1189296233,13443,dajac,2023-05-10T02:32:48Z,i understand. it was just misplaced in my opinion.,0,0.9005014896392822
1189296779,13443,dajac,2023-05-10T02:33:30Z,ok. i was not aware of this. sorry for this.,-1,0.9946997165679932
1189296913,13443,dajac,2023-05-10T02:33:41Z,ack.,0,0.5866091847419739
1189297499,13443,dajac,2023-05-10T02:34:49Z,"looks good, thanks.",1,0.9598045349121094
281150684,6592,miguno,2019-05-06T11:43:38Z,doesn't guard against npe (`data` might be null).,0,0.9903552532196045
281151355,6592,miguno,2019-05-06T11:45:36Z,why isn't there an additional constructor with a default `comparator`?,0,0.9859647750854492
281152067,6592,miguno,2019-05-06T11:47:38Z,"also, why does the serde need a `comparator` at all?",0,0.9835175275802612
281263059,6592,miguno,2019-05-06T16:41:25Z,we should use try-with-resources here (for `datainputstream`).,0,0.9948320388793945
281263464,6592,miguno,2019-05-06T16:42:38Z,we should use try-with-resources here (for `bytearrayoutputstream` and `datainputstream`).,0,0.9944642186164856
281263644,6592,miguno,2019-05-06T16:43:05Z,"this also fixes the problem that, in the current code, the `bytearrayoutputstream` was not closed.",0,0.9944190382957458
281264102,6592,miguno,2019-05-06T16:44:24Z,asking because neither a `list ` nor a `deserializer ` need a `comparator`.,0,0.9845527410507202
281285669,6592,yeralin,2019-05-06T17:43:15Z,put it on a discussion: [a link] thank you for your input! i highly appreciate it :),1,0.9960934519767761
287207631,6592,mjsax,2019-05-24T03:52:15Z,i think we should call `deserializer.configure(...)` here,0,0.9893409609794617
287207698,6592,mjsax,2019-05-24T03:52:47Z,i think we should call `deserializer.close()` here,0,0.989730715751648
287208093,6592,mjsax,2019-05-24T03:56:00Z,should we get the `size` first and pass it into `arraylist` constructor to make it more efficient?,0,0.9940990209579468
287208576,6592,mjsax,2019-05-24T04:00:08Z,forward call to `serializer`,0,0.9952046871185303
287460369,6592,yeralin,2019-05-24T17:55:17Z,is it sufficient for testing listserde?,0,0.9928868412971497
287470423,6592,mjsax,2019-05-24T18:26:10Z,"we should also test `null` and empty array imho. please, add new test methods for both cases.",0,0.989348292350769
296436321,6592,mjsax,2019-06-22T06:33:31Z,"as mentioned on the kip discussion, `bytesdeserializer` should not be included.",0,0.9924858808517456
296436331,6592,mjsax,2019-06-22T06:34:22Z,i using `stream.of` the best was to populate the map? seems to be unnecessarily complex to me?,0,0.7277151346206665
296436380,6592,mjsax,2019-06-22T06:37:34Z,"i would add test for all primitive types. the test should also check the expected `byte[]` array size after serialization and test a ""round trip"". we should also have a test for non-primitive type round-trip. lastly, i would add a test for deserializing different list-types. also `null` corer case should be tested.",0,0.9905795454978943
303481813,6592,yeralin,2019-07-15T14:59:13Z,replaced it with simpler approach: [code block],0,0.9948371648788452
304072719,6592,yeralin,2019-07-16T19:04:30Z,where should i place all of these new test cases? should i create a new class?,0,0.9902912974357605
307013332,6592,mjsax,2019-07-24T20:46:22Z,add new test methods to this test should be sufficient.,0,0.994933545589447
307015039,6592,mjsax,2019-07-24T20:50:28Z,both `_doc` variables should me moved to `commonclientconfigs`,0,0.9962206482887268
307015480,6592,mjsax,2019-07-24T20:51:21Z,nit: remove whitespace before `default` (similar for the other 3 `_doc` strings),0,0.9947922825813293
307016006,6592,mjsax,2019-07-24T20:52:38Z,"why `or default_list_value_serde_inner_class` ? for the key, we only care about the key part. (similar below for value -- we should only care about the value part.)",0,0.9929770827293396
307016504,6592,mjsax,2019-07-24T20:53:53Z,we should explain that this config is only used if `key.deserializer` is set to `listdeserializer`. similar for the type config below.,0,0.9945316314697266
307016893,6592,mjsax,2019-07-24T20:54:47Z,the class does not implement `deserializer` but `list`.,0,0.9936562180519104
307017972,6592,mjsax,2019-07-24T20:57:33Z,can we actually include uuid type? it always 16 bytes.,0,0.9955111742019653
307018186,6592,mjsax,2019-07-24T20:58:04Z,nit: maybe call this `fixedlengthdeserializers` -- it's not about primitive types.,0,0.9766270518302917
307026623,6592,abbccdda,2019-07-24T21:20:06Z,"avoid star import, same for the rest",0,0.9629037976264954
307036896,6592,mjsax,2019-07-24T21:50:20Z,both new configs should be added below: [code block] similar for `producerconfig` and `streamsconfig`,0,0.9965823292732239
307037138,6592,mjsax,2019-07-24T21:51:10Z,"i think this could be `string` or `class` type. not sure. for any case, we should test for both cases.",0,0.9821151494979858
307037211,6592,mjsax,2019-07-24T21:51:24Z,same here,0,0.99204421043396
307037543,6592,mjsax,2019-07-24T21:52:22Z,should we have two try-catch blocks? one for `listclass` and one for `inner` ?,0,0.9932833909988403
307037605,6592,mjsax,2019-07-24T21:52:35Z,nit: remove `this` (not required),0,0.9950811862945557
307037957,6592,mjsax,2019-07-24T21:53:41Z,how do we know that all list types implement a constructor like this? should we have a fall back to default constructor?,0,0.991211473941803
307038250,6592,mjsax,2019-07-24T21:54:41Z,rename similar to listdeserializer and add uuid type?,0,0.99517422914505
307038415,6592,mjsax,2019-07-24T21:55:13Z,rename? why not use `boolean`?,0,0.9893525838851929
307038590,6592,mjsax,2019-07-24T21:55:50Z,this could also be `class` type?,0,0.9939133524894714
307296391,6592,yeralin,2019-07-25T13:31:34Z,"fixed, had to change my intellij config.",0,0.7746734619140625
307302882,6592,miguno,2019-07-25T13:44:40Z,"why is the `bytearrayoutputstream` not covered by try-with-resources? it should, no?",0,0.9885890483856201
307305083,6592,miguno,2019-07-25T13:48:24Z,"shouldn't we also add `bytesserializer` and `bytearrayserializer` here? same question for deserialization. edit: i did notice that we do some ""testing for primitives"" by doing `contains()` on `primitiveserializers`. +1 to also adding uuid serializer (and deserializer).",0,0.9897499680519104
307308603,6592,miguno,2019-07-25T13:55:01Z,"why is this needed only for non-primitives, and not always?",0,0.9817548394203186
307309387,6592,yeralin,2019-07-25T13:56:31Z,i guess smth like this: [code block],0,0.9791005253791809
307309648,6592,miguno,2019-07-25T13:57:02Z,"i think the list serde should return null (after a round trip) if and only if the input was null. if the input was an empty list, then the list serde should instead return an empty list. that is, i believe the serde needs to distinguish between the absence of a collection (indicated by null) and a collection that happens to be empty.",0,0.979422390460968
307311596,6592,yeralin,2019-07-25T14:00:36Z,changed to boolean primitive. what do you think is the best name for it instead of `isprimitive`? `isfixedlength` maybe?,0,0.9928174018859863
307312643,6592,yeralin,2019-07-25T14:02:48Z,i was following impl of `sessionwindowedserializer`,0,0.9945801496505737
307316124,6592,yeralin,2019-07-25T14:09:34Z,mentioned during the kip discussion: [code block] i'll add uuid (de)serializers,0,0.9954530000686646
307320943,6592,yeralin,2019-07-25T14:19:01Z,you mean we can directly cast it to `class` object? i.e. `class listtype = (class) configs.get(listtypepropertyname);`,0,0.994032084941864
307321201,6592,yeralin,2019-07-25T14:19:28Z,i was following impl of `sessionwindoweddeserializer`,0,0.9946466088294983
307322886,6592,yeralin,2019-07-25T14:22:49Z,"yes, i think it will make errors more descriptive",0,0.9887759685516357
307323343,6592,yeralin,2019-07-25T14:23:38Z,probably add a warning log? what do you think?,0,0.9872117638587952
307326098,6592,yeralin,2019-07-25T14:28:36Z,"if i understand your question correctly: this was an optimization feature. if we have a collection of fixed length elements like `integer`, `long`, `uuid`, etc. we don't actually need to encode each element's size. that's why i have this extra if statement. if that's what you were asking",0,0.9639391303062439
307329101,6592,yeralin,2019-07-25T14:33:43Z,smth like: [code block],0,0.9912062287330627
307332736,6592,yeralin,2019-07-25T14:40:14Z,what `importance` should these configs be set to?,0,0.9902642965316772
307336073,6592,yeralin,2019-07-25T14:46:23Z,"should i add `doc`s for `default_list_key/value_serde_inner_class` configs? i was looking at `default_windowed_key/value_serde_inner_class` configs in `streamsconfig` class, and they don't have docs underneath them.",0,0.9926274418830872
307429344,6592,mjsax,2019-07-25T18:03:55Z,yes,0,0.9686408638954163
307429932,6592,mjsax,2019-07-25T18:05:13Z,i think low (or maybe medium) because it's dependent config,0,0.951440691947937
307431168,6592,mjsax,2019-07-25T18:08:12Z,"yes. the user can use the config two ways: [code block] both should be supported and the code need to be able to handle both cases. hence, we should get is as `object` and use `instanceof` to check the type.",0,0.9914838671684265
307432566,6592,mjsax,2019-07-25T18:11:21Z,this may indicate a bug in `sessionwindoweddeserializer`,0,0.9923006296157837
307433215,6592,mjsax,2019-07-25T18:12:50Z,don't think we need a warning. wondering if we should use try-catch or better pro-actively check if an int-constructor exists?,0,0.9509753584861755
307433392,6592,mjsax,2019-07-25T18:13:16Z,sgtm,0,0.9894869327545166
307433534,6592,mjsax,2019-07-25T18:13:36Z,seems like a bug in `sessionwindowedserializer`,0,0.9734256267547607
307434421,6592,mjsax,2019-07-25T18:15:42Z,"sound like something we should fix, ie, add corresponding doc entries to `streamsconfig`",0,0.986368715763092
307444815,6592,yeralin,2019-07-25T18:39:33Z,"yep, i think medium is more appropriate since it is a interconnected config scheme",0,0.9806640148162842
307448021,6592,yeralin,2019-07-25T18:47:13Z,something like this i presume: [code block],0,0.9919636249542236
307448892,6592,yeralin,2019-07-25T18:49:17Z,"we kind of implicitly check if int-constructor exists using this try-catch block, right?",0,0.9894551634788513
307464495,6592,yeralin,2019-07-25T19:28:42Z,"ok i added the following tests: `listserdeshouldroundtripprimitiveinput(): arrays.aslist(1, 2, 3)` `listserdeshouldrountripnonprimitiveinput(): arrays.aslist(""a"", ""b"", ""c"")` `listserdeshouldreturnemptycollection(): arrays.aslist()` `listserdeshouldreturnnull(): null` `listserdeserializershouldreturnbytearrayofsize(): arrays.aslist(1, 2, 3) => 16` `listserdeshouldreturnlinkedlist() new linkedlist<>()` `listserdeshouldreturnstack() new stack<>()` i think i covered it all. btw you said *all primitive types*, you mean all 6 of them, right?",0,0.9921780228614807
309339359,6592,mjsax,2019-07-31T17:22:07Z,seems this variable is still misssing the corresponding doc string? (same for `default_list_value_serde_inner_class` below),0,0.9928566217422485
309341518,6592,mjsax,2019-07-31T17:26:44Z,"we should point out, that this config is only affective iff `key.deserializer` is set to `listdeserializer`.",0,0.9931730628013611
309342714,6592,mjsax,2019-07-31T17:29:33Z,"seems you still did not add the config to the static `config` variable below. (this must be done for consumerconfig, producerconfig, and streamsconfig)",0,0.9921795129776001
309344282,6592,mjsax,2019-07-31T17:33:18Z,"not: remove space before `"" default...""` also, this variable should be moved to `commonclientconfigs` imho. (same commend for value below.)",0,0.9935944676399231
309344677,6592,mjsax,2019-07-31T17:34:24Z,this comment is not addressed yet,0,0.9910818338394165
310367315,6592,mjsax,2019-08-04T01:40:26Z,"`note when list serde class is used` -> seems be a little fuzzy if one does not know the context. it might be better to be very explicit. what about: [code block] we should be similarly explicit, for the ""inner serde"" configs.",0,0.9810035228729248
310367323,6592,mjsax,2019-08-04T01:41:02Z,avoid unnecessary reorderings (this class does not contain any actual code change).,0,0.9781621694564819
310367328,6592,mjsax,2019-08-04T01:41:34Z,as above (similar for other files below).,0,0.9947941899299622
310367336,6592,mjsax,2019-08-04T01:42:10Z,nit: fix indention and align to existing code,0,0.9885539412498474
310367353,6592,mjsax,2019-08-04T01:43:38Z,should be type `class` (similar below); cf. `key_deserializer_class_config`,0,0.9960254430770874
310367365,6592,mjsax,2019-08-04T01:44:10Z,as above: `class` and fix indention,0,0.9955053329467773
310618942,6592,yeralin,2019-08-05T14:00:08Z,"`default_key_serde_class_config` is not accessible from `comminclientconfigs` since it lives in `streamsconfig`, the same applies for `listserde.class.getname()`",0,0.9943683743476868
329244889,6592,mjsax,2019-09-27T20:45:58Z,"should this be `map , integer>` ? seem we should declare it as `static` ?",0,0.9939301013946533
329245133,6592,mjsax,2019-09-27T20:46:40Z,should it be `class listclass` ? (or `class ` if we don't introduce `l`),0,0.9919992089271545
329249087,6592,mjsax,2019-09-27T20:58:26Z,"i am wondering, if we should get the `list` type as generic (not sure). `public class listdeseializer , t> implements deserializer `",0,0.9714403748512268
329250304,6592,mjsax,2019-09-27T21:02:21Z,should this be `class >` (or maybe `class ` if we introduce `l extends list ` as class generic?,0,0.9931380152702332
329250920,6592,mjsax,2019-09-27T21:04:18Z,we should limit this suppression to the method for which we really need it instead of the whole class,0,0.9874292016029358
329251104,6592,mjsax,2019-09-27T21:04:55Z,`constructor >` (or `constructor ` if we introduce `l`),0,0.9937322735786438
329251296,6592,mjsax,2019-09-27T21:05:33Z,update return type to `l` (if we introduce `l`),0,0.9954962730407715
329251591,6592,mjsax,2019-09-27T21:06:32Z,update return type to `l` (if we introduce `l`),0,0.9954962730407715
329251673,6592,mjsax,2019-09-27T21:06:45Z,update return type to `l` (if we introduce `l`),0,0.9954962730407715
329252615,6592,mjsax,2019-09-27T21:10:07Z,avoid global suppress,0,0.8333720564842224
329253153,6592,mjsax,2019-09-27T21:12:14Z,`list >` should be `static`,0,0.9942741990089417
329253861,6592,mjsax,2019-09-27T21:14:49Z,`class ` (or just `class `?),0,0.9915892481803894
329254244,6592,mjsax,2019-09-27T21:16:20Z,"should we change to `listserde , t> extends wrapperserde >` (cf. `listdeserializer` comments) note: we should not use `wrappedserde ` because the wrapper `serializer` uses `list ` but not `l` (not sure if we want to tie the serializer type to a fixed list type, but i guess we should not).",0,0.993842601776123
329254510,6592,mjsax,2019-09-27T21:17:21Z,add missing `<>` to `new listserializer<>(...)`,0,0.9928544163703918
329255698,6592,mjsax,2019-09-27T21:21:49Z,"if we fix the generics, we don't need this suppress",0,0.9895955920219421
340187181,6592,vvcephei,2019-10-29T16:29:06Z,"it's better to avoid ""double-brace initialization"", which is actually declaring a new anonymous subclass of hashmap just to add some stuff to it in one statement. a little while back, i added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.utils#mkmap`, and the accompanying `org.apache.kafka.common.utils.utils#mkentry`.",0,0.9922326803207397
340190515,6592,vvcephei,2019-10-29T16:34:53Z,"this shouldn't be necessary. i believe the config parser will coerce the value to the type you declared the configuration as, `type.class`. might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.",0,0.9884148836135864
340191653,6592,vvcephei,2019-10-29T16:36:58Z,"that class is different because it doesn't actually `define` the config, it's just an undeclared ""extra"" config that gets passed around to be interpreted inside the serde. actually, this _is_ a bug, and that config _should_ be `define`d there the way you do it here.",0,0.9835854768753052
340192387,6592,vvcephei,2019-10-29T16:38:20Z,"+1, just add this suppression on the methods that need it.",0,0.9913275837898254
340237949,6592,vvcephei,2019-10-29T17:58:44Z,"these new tests look good. i agree, though, that we should test round trip + length for each of the primitive types (short, integer, long, float, double, and uuid). just because it would be easy to mess up just one of them, so we really should have test coverage for them all.",1,0.9793791770935059
342316240,6592,mjsax,2019-11-04T23:10:31Z,should we add a similar sentence like `this configuration will be read if....` to `commonclientconfigs#default_list_key_serde_inner_class_doc ` (similar for value) ?,0,0.9947691559791565
342320732,6592,mjsax,2019-11-04T23:27:37Z,nit: merge both lines: `byte[] payload = new byte[primitivesize == null ? dis.readint() : primitivesize];`,0,0.994900643825531
342321230,6592,mjsax,2019-11-04T23:29:29Z,nit: indentation should be 4 spaces?,0,0.9870506525039673
342321277,6592,mjsax,2019-11-04T23:29:38Z,nit: indentation should be 4 spaces?,0,0.9870506525039673
342326150,6592,mjsax,2019-11-04T23:48:49Z,nit: move this class definition to l127 (after `static public final class uuidserde extends wrapperserde {`) to group all defined serde classes.,0,0.9945911765098572
342326188,6592,mjsax,2019-11-04T23:48:58Z,can be removed (if we change the class to `extends wrapperserde `),0,0.9945631623268127
342326296,6592,mjsax,2019-11-04T23:49:23Z,the cast to `(deserializer >)` is not necessary if we change the class to `extends wrapperserde `.,0,0.9937812685966492
342326601,6592,mjsax,2019-11-04T23:50:40Z,nit: add those into section `// medium` and insert in alphabetical order within the section,0,0.9944862723350525
342337097,6592,mjsax,2019-11-05T00:35:31Z,nit: this method should be after static method `static public serde void() {` to keep stuff grouped,0,0.9868479371070862
342345719,6592,mjsax,2019-11-05T01:14:54Z,"i was playing with the code a little bit, and turns out using `class ` instead of `class ` might actually be too strict. compare my other comments.",0,0.9753960371017456
342345818,6592,mjsax,2019-11-05T01:15:29Z,not 100% sure -- but we need tests for this cases. the `configure()` code is untested atm,0,0.9582899808883667
342346108,6592,mjsax,2019-11-05T01:17:14Z,we could change the signature to [code block] to make it type safe... but there are issue (i also mentioned this for `listdeserializer` above -- also compare my comment below),0,0.9931454658508301
342346253,6592,mjsax,2019-11-05T01:17:59Z,"also could make types mores strict via `extends wrapperserde ` again, as mentioned above, not sure if this might be too strict.",0,0.9815587401390076
355461955,6592,JakobEdding,2019-12-09T13:56:55Z,"typo, `deerializer`",0,0.9955887794494629
364943202,6592,zorgz,2020-01-09T20:23:31Z,inner.serialize() can return null here in case of the list entry is null for example then npe will follow at [a link],0,0.9948510527610779
364993597,6592,yeralin,2020-01-09T22:35:10Z,"hmmm that's an interesting edge case. i cannot just return null since a list might contain real values i.e. `list data = {'a', null, 'c'}` i have to serialize `null` somehow...",0,0.9235351085662842
365021029,6592,zorgz,2020-01-10T00:13:25Z,i get it with abstractkafkaavroserializer and my custom array serde abstractkafkaavroserializer code: [code block],0,0.9947012662887573
368185579,6592,mjsax,2020-01-18T00:13:59Z,nit: should be `deserializer ` to avoid warnings about using a raw type,0,0.9941927790641785
368185717,6592,mjsax,2020-01-18T00:14:55Z,nit: should be ` >` to avoid warning about using a raw type,0,0.9915218353271484
368186003,6592,mjsax,2020-01-18T00:16:30Z,nit: should be `class >` (2 times) -- (not `serde` compare comment above) and we want to avoid warning about using a raw type also `innerserde -> innerdeserializerclass`,0,0.9945132732391357
368187510,6592,mjsax,2020-01-18T00:25:38Z,"this is `listdeserializer` hence, shouldn't we use `consumerconfig.list_key_deserializer_inner_class_config` ? the ""serde"" config should be used in kafka streams codebase only? (same for value, and for both inner types in the next line).",0,0.9951995611190796
368188170,6592,mjsax,2020-01-18T00:29:56Z,nit: should be `serializer ` to avoid warnings about using a raw type,0,0.9940611720085144
368188407,6592,mjsax,2020-01-18T00:31:15Z,"as above: use `producerconfg.list_key_serializer_inner_class_config` instead of ""serde"" config parameters (2 times) also `innerserdepropertyname -> innerserializerpropertyname`",0,0.9953184723854065
368188720,6592,mjsax,2020-01-18T00:33:05Z,nit: `innerserdepropertyname -> innerdeserializerpropertyname`,0,0.9937933683395386
368189063,6592,mjsax,2020-01-18T00:35:29Z,nit: `innerserde -> innerserializerclassorname`,0,0.9932155609130859
368189160,6592,mjsax,2020-01-18T00:36:10Z,should be: [code block],0,0.9951555728912354
368189561,6592,mjsax,2020-01-18T00:38:33Z,should be: [code block],0,0.9951555728912354
368189677,6592,mjsax,2020-01-18T00:39:28Z,"`""serde class ""` -> `""serializer class ""`",0,0.9891988635063171
368191352,6592,mjsax,2020-01-18T00:51:39Z,"that is a tricky question. there are multiple ways how we could encode this, but this seem to be a design question that required to go back to the kip discussion? for example, we could skip the optimization of fixed-length types and encode the length for every entry -- a length of `-1` would indicate a `null`. or we introduce a ""header"" that tells us if there are `null` in the list (either a bit-array for short list or a ""list of null positions"") example for list of null positions would be: ` ` ie, with the example for above, we encode `1-1- - `. as bit array, it would be ` ` ie, with the example for above, we encode `1-0100000- - `",0,0.7630188465118408
368191525,6592,mjsax,2020-01-18T00:53:02Z,should be ` >` to avoid raw type warning and make build pass,0,0.9940066337585449
368191582,6592,mjsax,2020-01-18T00:53:30Z,"should be ` , inner>` to avoid raw type warning and make build pass",0,0.9943401217460632
368191860,6592,mjsax,2020-01-18T00:55:56Z,"i am wondering now, why we actually need `commonclientconfigs.default_list_key_serde_inner_class` (maybe there was a reason by i forgot) -- can't we add the ""serde"" configs only to `streamsconfig`?",0,0.9809694290161133
369420107,6592,mjsax,2020-01-22T08:21:25Z,"thinking about it once more, it might not work what i suggested, because if you want to call `serde.listserde(arraylist.class, ...)` the `arraylist` does not specify any inner type information (but is a raw type) and thus it won't compile. i guess, we need to leave it as-is, and suppress the ""raw type"" warning (might be worth to add a comment why the raw type warning cannot be avoided for this case).",0,0.9773642420768738
369420640,6592,mjsax,2020-01-22T08:22:46Z,"same as below -- i guess my suggestion does not work in practice (it's correct that it would avoid the raw type warning, but it would make the api unusable in practise because we want to be able to pass in raw type list classes).",0,0.9830067753791809
370513438,6592,mjsax,2020-01-24T08:15:57Z,"i was thinking about this case more. i really think, that the fix-length optimization is valuable as it reduced the serialized byte size by 50% for e.g. integer lists. for the other two proposals, it's harder to judge which one is better. i see the following (dis)advantages for each: null-index-list: - low overhead for dense lists with few nulls (for zero nulls, its 4 byte overhead, for each null, its additional 4 bytes) - the longer the lists, the smaller the overhead bit-array: - low overhead for short lists (4 bytes for byte array length + list-lenght/8 bytes for the byte-array itself) - not ideal for long lists with few nulls hence, for short list both might be equally ok. for long lists, it depends of they are dense or sparse (for long-dense list, null-index-list seems to be better, for long-sparse-lists, bit-array seems to be better). it will be hard to tell which one is better, hence, i would suggest that we only implement the null-index-list list for now, because i assume that dense lists are more common and it works better for long dense lists than the bit-array idea. however, to allow us to support different serialization format in the future, we should add one more magic byte in the very beginning that encodes the choose serialization format. in our case, we will will have one format and the magic byte will always be ""zero"". if we add the byte-array format, we can just set the magic byte to one to indicate the other format. and we could even add more formats of people have a better idea how to do it later on. btw: we could actually already go with two formats: - 0 => optimized-fixed-length-encoding plus null-index-list - 1 => variable length encoding using `-1` in the length field to indicate `null` (no header to mark nulls is required at all for this case). if we agree on this design, we should update the kip accordingly. \cc : would love to hear your feedback, too.",0,0.6925207376480103
371434275,6592,yeralin,2020-01-27T19:23:57Z,"thank you for your input your outline makes sense, i like the idea of `null-index-list`, and i'm happy to jump back to the kip. however, could we please wrap up this round of review? make sure that all generics, docs, tests are in place. once it is clean and polished, i can start updating the kip and implementing this new feature. what do you think? p.s. rebased the branch with latest `trunk` and pushed another commit with review changes",1,0.9915903210639954
372120739,6592,mjsax,2020-01-28T23:41:43Z,"can be simplified to `(""unchecked"")`",0,0.9934064149856567
372121895,6592,mjsax,2020-01-28T23:45:47Z,`innerdeserializer` could be null; we should handle to case to avoid a npe calling `getclass()`,0,0.9937665462493896
372123553,6592,mjsax,2020-01-28T23:51:31Z,"there a two independent configs for the list-type and inner-type, hence it might be better to handle both independently: [code block]",0,0.993005096912384
372123738,6592,mjsax,2020-01-28T23:52:12Z,as above; simplify,0,0.9945936799049377
372125306,6592,mjsax,2020-01-28T23:57:44Z,use `kafkaexception` instead of `runtimeexception`,0,0.9951685667037964
372125767,6592,mjsax,2020-01-28T23:59:23Z,in `utils.newinstance()` we catch exceptions more fine grained -- might be worth to do the same here?,0,0.9915720224380493
372126337,6592,mjsax,2020-01-29T00:01:19Z,use `kafkaexception` instead of `runtimeexception`,0,0.9951685667037964
372126509,6592,mjsax,2020-01-29T00:01:57Z,as above,0,0.9888283014297485
372126925,6592,mjsax,2020-01-29T00:03:37Z,"should we throw `kafkaexception` instead? also, we need to add an error message that clarifies which class was not found.",0,0.9922122955322266
372128389,6592,mjsax,2020-01-29T00:08:53Z,as above: `serializer` could be `null` and we should handle this case gracefully,0,0.9873253107070923
372128852,6592,mjsax,2020-01-29T00:10:43Z,maybe add a `null` check and throw `configexception` with detailed error message similar to the `null`-check for `listclass` in the `listdeserializer#configure(...)`? i think `instanceof` would be false for `null` and thus the `null` check within `utils.newinstance(...)` would not be executed.,0,0.9911736845970154
372129532,6592,mjsax,2020-01-29T00:13:33Z,use `kafkaexception` instead of `runtimeexception`,0,0.9951685667037964
372129790,6592,mjsax,2020-01-29T00:14:31Z,we should add a `null` check to allow closing a deserializer that was not properly setup,0,0.9939900636672974
372129838,6592,mjsax,2020-01-29T00:14:42Z,we should add a `null` check to allow closing a serializer that was not properly setup,0,0.9938198924064636
372131801,6592,mjsax,2020-01-29T00:22:12Z,`serializer` -> `serde`,0,0.9935908317565918
372131842,6592,mjsax,2020-01-29T00:22:22Z,`serializer` -> `serde`,0,0.9935908317565918
372131861,6592,mjsax,2020-01-29T00:22:27Z,`serializer` -> `serde`,0,0.9935908317565918
372132594,6592,mjsax,2020-01-29T00:25:25Z,this method is hard to read... can we format it differently? (maybe a empty line before `return...` is sufficient?),0,0.6066167950630188
378457483,6592,yeralin,2020-02-12T19:14:33Z,"`catch (instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception e)` kind of long, but i agree for it to be more fine grained",0,0.9795336723327637
453892518,6592,yeralin,2020-07-13T19:50:12Z,make sure that the serialization flag is known to the application.,0,0.9928365349769592
453892850,6592,yeralin,2020-07-13T19:50:48Z,it's probably better to wrap it into `if/else` construct instead.,0,0.9879419207572937
453893460,6592,yeralin,2020-07-13T19:52:01Z,"by default, if we are dealing with a list of primitives, we are using `serializationstrategy.null_index_list` vs. a list of non-primitives (`uuid`, `string`, or some custom object) `serializationstrategy.negative_size`.",0,0.9931849837303162
453894509,6592,yeralin,2020-07-13T19:54:14Z,"this is what i was talking about in [a link] even if we are dealing with primitives, and a user chooses `serializationstrategy.negative_size`, we would have to encode each primitive's size in our payload.",0,0.9928964972496033
453894647,6592,yeralin,2020-07-13T19:54:32Z,should it be parametrized?,0,0.9904031753540039
613642681,6592,ableegoldman,2021-04-14T23:09:28Z,"just wondering, what is the reason for this change?",0,0.9693655371665955
613647496,6592,ableegoldman,2021-04-14T23:23:03Z,"should it be valid for this to be null? i would think that these serdes should be configured either by instantiating it directly via this constructor, or via the default constructor + setting configs (eg list.key.serializer.inner). it doesn't seem to make sense to use this constructor and not pass in valid arguments. wdyt about throwing an exception if either parameter is `null` -- not sure if configexception or illegalargumentexception is more appropriate, up to you",0,0.9758230447769165
613648141,6592,ableegoldman,2021-04-14T23:24:53Z,nit: use `private static` ordering (for consistency with the rest of the code base),0,0.99393230676651
613649139,6592,ableegoldman,2021-04-14T23:27:36Z,"if the `listclass` and `inner` have already been set by invoking the non-default constructor, but the user also set the `list.key.deserializer.inner` configs, should we verify that the configs match and throw a configexception otherwise?",0,0.9915036559104919
613651922,6592,ableegoldman,2021-04-14T23:36:10Z,what about the `list_key_deserializer_inner_class_config`?,0,0.995044469833374
613657189,6592,ableegoldman,2021-04-14T23:52:12Z,"hey, sorry that i'm jumping in here after there's been a long discussion which i missed, but i'm wondering why the serialization strategy would be configurable? iiuc the serialization strategy correctly, one of them basically means ""constant-size data/primitive type, don't encode the size only length of list"" while the other means ""variable-size data, encode the size of each element only"" i assume this is to allow users to indicate that their data is constant size when its a non-primitize type, to avoid the need to encode this same size data -- that makes sense to me. but i think we can simplify the api a bit so we don't have to let users shoot themselves in the foot, as you said earlier :slightly_smiling_face: how about: if it's a primitive type, and we can detect this (i think we should be able to), then we never encode the size info. if a user opts to do so, just log a warning and ignore it. by the way, this might also be due to some earlier discussion i missed, but i find the names of the two serializationstrategy enums super confusing. how about just `variable_size` and `constant_size`? imo it's better to describe what the enum actually _means_ than how its implemented, you can read the code to understand the latter. but you shouldn't need to read the code to understand what a config means. plus, this way we have flexibility to change the underlying implementation if we ever need to without also having to change the enum names which are now a public api",-1,0.9806389212608337
613658493,6592,ableegoldman,2021-04-14T23:56:23Z,"what is this? can you give it a name that describes what it means a little more -- iiuc this is a sentinel that indicates ""this list has variable-sized elements so we encode each element's size"". that said, coming up with names is hard -- you can probably do a better job than me but just to throw out a suggestion, what about something like `variable_size_sentinel`?",0,0.9860820770263672
613658799,6592,ableegoldman,2021-04-14T23:57:19Z,"nit: can we use `double.size` instead of just `8`, that way it's super clear that this value actually means?",0,0.9770176410675049
614950753,6592,yeralin,2021-04-16T15:54:30Z,hmmm `double.size` returns 64: [code block],0,0.9880677461624146
614954404,6592,yeralin,2021-04-16T15:59:41Z,otherwise the build will fail with: [code block] was addressed in [a link],0,0.9921942949295044
615005374,6592,yeralin,2021-04-16T17:14:20Z,"it was introduced in [a link] however, now i am looking at it and seems like we actually don't need any of: [code block] since we are operating only with: [code block] good observation, i'll remove these unused configs.",1,0.4985925257205963
615008995,6592,yeralin,2021-04-16T17:20:31Z,that's a good idea. i think `illegalargumentexception` is the most appropriate. something like: [code block],1,0.9788864850997925
615010709,6592,yeralin,2021-04-16T17:23:38Z,"i was following the logic defined in similar (de)serializers like `sessionwindowedserializer`. there they are doing similar thing, simply checking whether a (de)serializer is null, then trying to get a value from configs. they don't perform any verification. what do you think? should we divert from that approach?",0,0.9829469919204712
615020981,6592,yeralin,2021-04-16T17:41:33Z,"hey, no worries. for: i think i am already doing that in the constructors: [code block] if a user doesn't pass `serstrategy` flag, we pick the best one for her based on passed serializer. if a user passes her own `serstrategy` flag, we simply obey to it. however, we don't print any warning logs, since i assumed if the user passes the flag, then she probably knows what she is doing. what do you think? i could add a warning log otherwise.",1,0.9075610041618347
615021158,6592,yeralin,2021-04-16T17:41:56Z,"as per flag names, totally agree. changing them to `variable_size` and `constant_size`.",0,0.950011134147644
615075349,6592,yeralin,2021-04-16T19:23:08Z,"basically, if we are following `variable_size` serialization strategy **and** we have a `null` entry in our list, we encode this null entry as `-1`, so that during deserialization when we encounter `-1`, we append `null` entry to our list. example, to serialize a list like `{""a"", ""b"", null, ""c""}` of strings, the payload would look smth like: [code block]",0,0.992240309715271
615075871,6592,yeralin,2021-04-16T19:24:11Z,could be called something like `null_entry_value` instead maybe?,0,0.9915156364440918
618823378,6592,ableegoldman,2021-04-22T23:51:07Z,"yes, i think we should. and it's not even a diversion from the approach elsewhere because there's a kip in progress to do so in classes like `sessionwindowedserializer` as well",0,0.9838306903839111
618823669,6592,ableegoldman,2021-04-22T23:52:16Z,"cool. i think the fewer configs overall, the better. if we can get away with just the serde configs then let's do so to keep the api surface area smaller for users :thumbs_up:",1,0.9954516291618347
618824127,6592,ableegoldman,2021-04-22T23:53:50Z,"ah, my bad. i think the variable i had in mind is actually called `double.bytes`. not 100% sure it's defined for all possible primitive types, but i would hope so",-1,0.991685152053833
618824748,6592,ableegoldman,2021-04-22T23:55:45Z,that sounds good to me :thumbs_up:,1,0.9957780838012695
618826368,6592,ableegoldman,2021-04-23T00:00:19Z,"awesome. maybe i misunderstood this comment: or maybe you just wrote that a while ago and it's out of date. anyways what we're doing now sounds good, no reason to encode extra data even if the user selects this strategy for some reason. but i do think we should at least log a warning telling them they made a bad choice and it will be ignored. most likely they just didn't understand what the parameter meant, and it's a good opportunity to enlighten them",1,0.9879834651947021
618826641,6592,ableegoldman,2021-04-23T00:01:13Z,"ooooh ok, that makes a lot more sense now. i think your suggestion for the name sounds good",1,0.9669541716575623
618910174,6592,yeralin,2021-04-23T03:14:35Z,"yep, that checks out. only for `uuid` i'd have to leave hardcoded `36`.",0,0.9892198443412781
620449322,6592,yeralin,2021-04-26T16:17:55Z,"now, i am thinking about it. it seems a bit extra to compare the classes defined between the constructor and configs. maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? forcing the user to set only one or the other.",0,0.952239990234375
620457633,6592,yeralin,2021-04-26T16:28:34Z,"hmmm, i thought you wanted to simply warn the user that the serialization strategy she chose is not optimal. but seems like you want to ignore the choice completely. then it doesn't make sense to expose this flag at all for the user to change. me and were discussing it earlier [a link]",0,0.9572540521621704
620716670,6592,ableegoldman,2021-04-26T23:20:45Z,"that works for me. tbh i actually prefer this, but thought you might consider it too harsh. someone else had that reaction to a similar scenario in the past. let's do it :thumbs_up:",1,0.9904130101203918
620720140,6592,ableegoldman,2021-04-26T23:29:50Z,"ah, sorry if that wasn't clear. yes i was proposing to ignore the choice if a user selects the `variable_size` strategy with primitive type data. and to also log a warning in this case so at least we're not just silently ignoring it. but i think you made a good point that perhaps we don't need to expose this flag at all. there seems to be no reason for a user to explicitly opt-in to the `variable_size` strategy. perhaps a better way of looking at this is to say that this strategy is the default, where the default will be overridden in two cases: data is a primitive/known type, or the data is a custom type that the user knows to be constant size and thus chooses to opt-in to the `constant_size` strategy. wdyt? we could simplify the api by making this a boolean parameter instead of having them choose a `serializationstrategy` directly, something like `isconstantsize`.",-1,0.9274037480354309
620802248,6592,yeralin,2021-04-27T02:27:58Z,"hmmm, reasoning was that in the future we could introduce **more** serialization strategies [a link] as per ignoring the choice, also from [a link] ... personally, i have a slight preference to allow both strategies for all types as i think easy of use is more important, but i am also fine otherwise. here is my thought process, if a user chooses a serialization strategy, then she probably knows what she is doing. ofc, the user will have a larger payload, and we certainly will notify her that the serialization strategy she chose is not optimal for the current type of data, but i don't think we should strictly forbid the user from ""shooting herself in the foot"".",0,0.9102504849433899
620804518,6592,ableegoldman,2021-04-27T02:34:31Z,"my feeling is, don't over-optimize for the future. if/when we do want to add new serialization strategies it won't be that hard to pass a kip that deprecates the current api in favor of whatever new one they decide on. and it won't be much work for users to migrate from the deprecated api. i'm all for future-proofness but imo it's better to start out with the simplest and best api for the current moment and then iterate on that, rather than try to address all possible eventualities with the very first set of changes. the only exception being cases where the overhead of migrating from the initial api to a new and improved one would be really high, either for the devs or for the user or both. but i don't think that applies here. that's just my personal take. maybe would disagree, or maybe not. i'll try to ping him and see what he thinks now, since it's been a while since that last set of comments. until then, what's your opinion here?",0,0.7994822263717651
621475071,6592,yeralin,2021-04-27T18:13:14Z,"ok, in this case, i think the best course of action is to completely remove `serializationstrategy` flag, and replace it with a simple boolean. do not expose it to the user, and automatically choose the strategy based on the type of data. if you agree, i'll go ahead and make the change.",0,0.9687342643737793
621676170,6592,ableegoldman,2021-04-27T23:05:42Z,"just to clarify you mean don't expose this to the user at all, right? that sounds completely fine to me. if there are enough people trying to serialize lists of custom classes with all constant data size who want this optimization exposed for general use, then someone will request the feature and we can go back and add it in. then we can debate what the api should look like at that time, and keep things simple for now. personally i suspect the vast majority of non-primitive data types are not going to be constant size anyways. given the above, i think whether to track the strategy as an actual `serializationstrategy` enum vs a boolean flag becomes a matter of code style and personal preference, since it's no longer exposed to the user. so it's up to you whether you find the enum or the flag to be more readable or clean",0,0.9446468949317932
629768563,6592,ableegoldman,2021-05-11T00:34:30Z,"same here, --> `public static`. can you also leave it on one line? i know it's super long, but that's just the style we use in kafka",0,0.9699512720108032
629769396,6592,ableegoldman,2021-05-11T00:35:57Z,"super nit: we put the modifier first, ie use `public static` ordering.",0,0.8228835463523865
629770618,6592,ableegoldman,2021-05-11T00:40:07Z,"nit: kafka coding style doesn't use the `get` prefix in getters, ie this should be named `innerdeserializer` (same applies for any other getters in this pr, i won't bug you by commenting on every single one of them)",0,0.8760366439819336
629772320,6592,ableegoldman,2021-05-11T00:45:41Z,"is the unchecked warning coming from something in the test itself, or just from using the serde? it should be possible to just use the serde without getting a warning. i don't see anything in the test that looks suspicious so i'm guessing we need another suppression somewhere in the serde implementation?",0,0.976711630821228
629772466,6592,ableegoldman,2021-05-11T00:46:11Z,super nit: extra blank line,0,0.8859505653381348
629776651,6592,ableegoldman,2021-05-11T01:00:18Z,"i found it a bit difficult to understand what was going on here since i'm reading this first, before the serialize implementation, but i take it we just encode the indices of any null values at the beginning of the serialized list? can you leave a comment pointing that out, either here on the method itself or else down below where the method is used?",0,0.813530445098877
629777825,6592,ableegoldman,2021-05-11T01:04:18Z,"since we no longer expose the serializationstrategy or let users explicitly select it, these two equality checks should have both be true or both be false, right? might read a bit easier if we only check `serstrategy == serializationstrategy.variable_size` here, and then just verify that `primitivesize` is not null when we parse the serialization strategy flag at the top. wdyt?",0,0.9871785640716553
629781672,6592,ableegoldman,2021-05-11T01:17:17Z,"since we don't know what the underlying list structure is, using `get(index)` like this could be pretty costly -- for example with a linkedlist this will be o(n), which makes it o(n^2) overall. might be safer to just iterate through the list with a plain `for int i` loop and take note of the nulls that way",0,0.9544367790222168
629781907,6592,ableegoldman,2021-05-11T01:18:05Z,nit: put the `out.writeint` on its own line,0,0.9927021265029907
629782907,6592,ableegoldman,2021-05-11T01:21:16Z,"same as my suggestion in listdeserializer, can you add a quick comment here or above the `serializenullindexlist` method explaining what this is doing (like you have above with `// write serialization strategy flag`)",0,0.995446503162384
629784136,6592,ableegoldman,2021-05-11T01:25:13Z,"also similar to a comment in listdeserializer: it should not be possible for only one of these to be true, so let's just check one or the other here. in fact maybe we can get rid of the `isfixedlength` flag entirely now, since `serializationstrategy.variable_size` means exactly the same thing (or rather, the opposite of it)",0,0.9925968647003174
630539763,6592,yeralin,2021-05-11T21:04:20Z,would something like this work? [code block],0,0.9940260648727417
630542548,6592,yeralin,2021-05-11T21:09:26Z,the problem is [a link] list `static public` first. ![a link],-1,0.7463481426239014
630550102,6592,yeralin,2021-05-11T21:23:30Z,"unfortunately, it is unavoidable [a link] had to do it this way and sacrifice type safety for easier usage of this serde.",-1,0.916255533695221
630603333,6592,ableegoldman,2021-05-11T23:27:32Z,"ah, i didn't notice...tbh we should probably just fix all of them, but it's fine with me to leave that out of this pr and just conform to this for now. i'll leave it up to you",0,0.8291900157928467
630605834,6592,ableegoldman,2021-05-11T23:34:18Z,"thanks for the context, it is what it is (and i agree with your decision to prioritize ease of use). i was more wondering whether we might be missing a `suppresswarnings(""unchecked"")` on one of the methods in the implementation, so that the user isn't forced to do the suppression themselves. but i can't quite tell where the warning is coming from, since it seems like we do already suppress unchecked warnings in `listdeserializer#createlistinstance` where the casting occurs? is it possible this was just left over from an earlier version, and we no longer need all the suppressions on these tests?",1,0.9553041458129883
630606384,6592,ableegoldman,2021-05-11T23:36:01Z,"yep, exactly (not sure why i said to use `for int i`, obviously that suffers from the same problem -- the iterator is what i had in mind)",0,0.9724550247192383
631151867,6592,yeralin,2021-05-12T15:33:20Z,this is a common practice leaving empty lines at the end of files: [a link],0,0.9942002296447754
631158775,6592,yeralin,2021-05-12T15:40:10Z,"no, unfortunately they are still needed. afaik, suppression warnings cannot be propagated upwards. in `listdeserializer#createlistinstance` we indeed using `suppresswarnings(""unchecked"")` due to casting. however, in tests it is used bc `stack.class` (or `arraylist.class`, `linkedlist.class`, etc) is a raw-type and does not guarantee the required inner type (`integer` in this case). the only way to deal with these warnings is to create some wrapper classes as suggested, like: `public static class integerarraylist extends arraylist {}` but i do not this it is a scalable and clean solution. pretty much every time a user is calling `serdes.listserde(...)` they will have to put suppresswarnings statement. it is a limitation of java language. as said:",0,0.9709738492965698
631327191,6592,ableegoldman,2021-05-12T19:06:47Z,"well, it's not at the end of the file right? but if you'd prefer to keep it that's fine too, was just a ""super nit"" suggestion :slightly_smiling_face:",1,0.9811869859695435
631328727,6592,ableegoldman,2021-05-12T19:09:22Z,"can you move this up to the top of this file, under the `streams changes in 3.0` section? it's in reverse order, so the newest stuff goes at the top.",0,0.9945585131645203
631334877,6592,ableegoldman,2021-05-12T19:19:33Z,"ah, i see, it's from the implicit casting of the parameters. that makes sense, i was just wondering since i didn't see any ""obvious"" casting in the test code itself. thanks for the explanation",1,0.9470245242118835
631339580,6592,yeralin,2021-05-12T19:27:24Z,"omg i am blind. sorry, you are right!",-1,0.9959104061126709
212770210,5567,vvcephei,2018-08-24T22:37:13Z,i need to expose these so that i can query the window spec in ktableimpl,0,0.9934451580047607
212770275,5567,vvcephei,2018-08-24T22:37:50Z,"upon second look, i think i'll move these into a utility class to not pollute ktableimpl",0,0.9817700982093811
212770518,5567,vvcephei,2018-08-24T22:39:27Z,the basic idea is to traverse back through the topology until we find the window spec and get the grace period from it.,0,0.9907112717628479
212770687,5567,vvcephei,2018-08-24T22:40:59Z,on-the-side fixup of the generic types for groupby.,0,0.991869330406189
212770823,5567,vvcephei,2018-08-24T22:42:02Z,"this is where the buffering would take place. right now, we throw an exception unless we detect that we can pass-through the record.",0,0.9911618232727051
212770994,5567,vvcephei,2018-08-24T22:43:20Z,`suppress` is split into interface/impl mostly to support these kinds of internal methods.,0,0.9923386573791504
212771115,5567,vvcephei,2018-08-24T22:44:11Z,decided to start using fuzzing to avoid magic numbers in the tests. let me know if you prefer it different.,0,0.9785999655723572
212771290,5567,vvcephei,2018-08-24T22:45:40Z,"`mockprocessorcontext` is pretty nice for unit tests, but we need `internalprocessorcontext` for the suppress processor.",0,0.9737217426300049
212771356,5567,vvcephei,2018-08-24T22:46:17Z,so you can just print the result of `forwarded()` for debugging.,0,0.994716227054596
212771502,5567,vvcephei,2018-08-24T22:47:22Z,had to fix this to actually get the right timestamp forwarded.,0,0.9698430299758911
212771525,5567,vvcephei,2018-08-24T22:47:35Z,just to quit spamming the logs.,0,0.8833802342414856
213025428,5567,vvcephei,2018-08-27T15:56:16Z,"this preserves the existing behavior that if both `to.timestamp` and `this.timestamp` are unset, the forward time would be `-1`.",0,0.9937319159507751
213039753,5567,vvcephei,2018-08-27T16:46:07Z,"which i think is reasonable, since this context would only be used for unit tests.",0,0.982517421245575
213190515,5567,guozhangwang,2018-08-28T05:49:13Z,nit: `bytestouseforsuppressionstorage` -> `numbytestostore`?,0,0.9927965998649597
213190554,5567,guozhangwang,2018-08-28T05:49:30Z,`numberofkeystoremember` -> `numkeystoremember`?,0,0.9943201541900635
213192247,5567,guozhangwang,2018-08-28T06:01:31Z,`intermediateevents` -> `emitintermediateresults`?,0,0.9944769740104675
213192826,5567,guozhangwang,2018-08-28T06:05:43Z,nit: `intermediateemitconfig`?,0,0.9942919015884399
213193035,5567,guozhangwang,2018-08-28T06:07:02Z,"hmm.. this makes me thinking if we should consider duplicate the `bufferfullstrategy` to `finalbufferfullstrategy` and `intermediatebufferfullstrategy` and also the corresponding caller `bufferconfig` as well, to replace runtime error with complication error?",0,0.9780584573745728
213193122,5567,guozhangwang,2018-08-28T06:07:34Z,why not `timewindows`?,0,0.9828541278839111
213194261,5567,guozhangwang,2018-08-28T06:14:53Z,"let's use `topologyexception` instead of `illegalargumentexception` here, ditto below.",0,0.9933469295501709
213194430,5567,guozhangwang,2018-08-28T06:15:50Z,actually today we have undefined operator for windowed-table / windowed-table join at all. but the logic itself looks good :p,1,0.9844946265220642
213196512,5567,guozhangwang,2018-08-28T06:28:15Z,"nit: just define two static `timedefinition ` and `timedefinition , v>`, one with context.timestamp and one with window end time?",0,0.9916346073150635
213321144,5567,bbejeck,2018-08-28T13:50:40Z,since [a link] should this be `suppress suppress` for consistency with the rest of the api?,0,0.9931026697158813
213326969,5567,bbejeck,2018-08-28T14:04:48Z,one meta-comment about the static methods on the interfaces in `suppress`. would we want to consider making them `default` instead of `static` in case down the line we want to implement any of these interfaces to have different behavior in the various methods?,0,0.9917955994606018
213333450,5567,bbejeck,2018-08-28T14:20:32Z,nit: we can get rid of the `else` here,0,0.9934060573577881
213336080,5567,bbejeck,2018-08-28T14:26:44Z,is this intentional or left over debugging?,0,0.987472414970398
213376919,5567,vvcephei,2018-08-28T16:07:30Z,"this is actually ""suppress intermediate events"". it looks like this in the dsl: with static import: `table.suppress(intermediateevents(...))` without static import: `table.suppress(suppress.intermediateevents(...))` does that seem right?",0,0.9945671558380127
213377265,5567,vvcephei,2018-08-28T16:08:30Z,"yeah, i was thinking something similar... i'll sketch something up.",0,0.9729412794113159
213377504,5567,vvcephei,2018-08-28T16:09:14Z,how do you know it's a `timewindows`?,0,0.9933319687843323
213377758,5567,vvcephei,2018-08-28T16:09:57Z,ok. thanks. that sounds much better.,1,0.9738903045654297
213379204,5567,vvcephei,2018-08-28T16:14:23Z,"i see. well, it's permitted by the api, so i'd rather keep the sanity check. actually, it seems like the only problem with further manipulations of windowed tables is that we won't know to use a windowed store (as by that point, we only know it's a ktable). might be worth revisiting this at some point...",0,0.9040605425834656
213383840,5567,vvcephei,2018-08-28T16:28:32Z,"yes, it should! thanks for the catch and the reference.",1,0.9924851059913635
213385791,5567,vvcephei,2018-08-28T16:34:57Z,"in general, this is something that's good to start thinking about. i think we have two kinds of interfaces/non-final classes: ones that are for implementing and ones that are for encapsulation. for implementing: serde, windows, statestore, etc. for encapsulation: ktable, materialized, etc. to me, `suppress` is in the latter category: since we cast it to `suppressimpl` immediately, it's not possible to pass in any other implementations of it. the interface/impl split is purely to provide a clean division of external/internal members. the regular java access modifiers are insufficient for this purpose, since suppressimpl's internal members need to be accessed from other internal classes, but outside of its package.",1,0.5263522863388062
213387916,5567,vvcephei,2018-08-28T16:41:18Z,"it's intentional. we first randomly generate a seed, then we create a (pseudo)random for test data generation from the seed. if the test fails, we can deterministicaly reproduce the (pseudorandom) test exactly, but only if we know the seed. that said, i want to play around with it some more, and see if i can get it to only print the seed if there are test failures. also, there's currently no option to run the tests with the seed, but you could always just drop in the literal when you're debugging locally.",0,0.9346054196357727
213389544,5567,vvcephei,2018-08-28T16:45:31Z,see prior response,0,0.9921775460243225
213393351,5567,vvcephei,2018-08-28T16:56:01Z,"hmm, i don't know if i want to spend a bunch of time of this idea. i think what i'll do is switch to a fixed seed, so that we get deterministic testing while keeping the statement that there's nothing special about the values we're testing with.",0,0.6563794016838074
213414494,5567,vvcephei,2018-08-28T17:59:15Z,how about `maxbytes`?,0,0.993767499923706
213477348,5567,vvcephei,2018-08-28T21:24:05Z,"ah, it can't be static because of the generic parameters, but i can make it final, which would bring us to one anonymous class per instance ... but you get a new instance every time you call one of the builder methods anyway, so it's the same thing. i think this is what i was originally thinking when i left it like this.",0,0.9761731028556824
213479566,5567,vvcephei,2018-08-28T21:32:00Z,"actually, no it shouldn't ;) `suppress`'s bounds on `k` and `v` need to be tight, since the operator will actually serialize and deserialize the records (1. when it is size-constrained, 2. when it spills to disk, and 3. because this operator needs a changelog).",1,0.890769898891449
213479948,5567,vvcephei,2018-08-28T21:33:31Z,"i previously missed that last point... it means that suppress requires serdes and not just serializers, and it needs them always, not just when it's size constrained or spilling to disk.",0,0.98285311460495
213480277,5567,vvcephei,2018-08-28T21:34:44Z,"oh, and i've also just now realized that it should be called `suppressed`, not `suppress`, in keeping with the rest of the config objects... this is a lot of changes. i think we'll probably have to recast votes this time.",0,0.5346843600273132
213753581,5567,vvcephei,2018-08-29T16:45:49Z,"sorry, i was being silly, but upon second reading, it looks snarky... `windows ` is the tightest bound we can put on the window spec at this point, since this processor takes any window spec.",-1,0.9878284931182861
213760382,5567,vvcephei,2018-08-29T17:07:37Z,changed the name to `suppressed` in keeping with the other config objects.,0,0.9937210083007812
213819571,5567,vvcephei,2018-08-29T20:17:47Z,added these methods in lieu of the bufferfullstrategy enum,0,0.9952591061592102
213819739,5567,vvcephei,2018-08-29T20:18:25Z,"added `serialized` as a top-level property of the buffer, since the buffer itself will likely need a changelog for resilience.",0,0.9948890805244446
213820442,5567,vvcephei,2018-08-29T20:20:42Z,utility class just to encapsulate the graph search for looking back up the topology for the grace period (and verifying it's configured the same on all incoming branches),0,0.9933295249938965
213820698,5567,vvcephei,2018-08-29T20:21:33Z,i'll fill this in in the next pr.,0,0.9924382567405701
213820934,5567,vvcephei,2018-08-29T20:22:26Z,"added this ""test"" to demonstrate what compiles and what doesn't.",0,0.9932472705841064
213822461,5567,vvcephei,2018-08-29T20:27:16Z,this allows us to insist on a `strictbufferconfig` for the final results use case.,0,0.9946210384368896
214188984,5567,vvcephei,2018-08-30T21:37:52Z,"i had a potentially kooky idea... what if instead of bumping up the node index here, we just tack ""suppress"" on to the parent node name somehow? this way, it would become fine to slap suppressions into topologies and restart without any other changes (because it wouldn't cause all the other nodes to get re-numbered). this might be especially important if we intend to insert suppressions in the future for optimization reasons. thoughts?",0,0.7415521144866943
214207725,5567,guozhangwang,2018-08-30T23:14:02Z,"could you elaborate a bit more on `just tack ""suppress"" on to the parent node name somehow?` what is the concrete proposal of the naming scheme?",0,0.9939379692077637
214481155,5567,bbejeck,2018-08-31T21:38:59Z,"hmm, i'd have to see the concrete proposal. if we follow that approach wouldn't we still need to implement some sort of counter in the case of having multiple ""suppress"" nodes? then i think we'd still have the same issue, adding a new suppress operator would change the numbering scheme of the suppress nodes in the topology.",0,0.9713367819786072
214482095,5567,bbejeck,2018-08-31T21:44:40Z,we should have a unit test for this class covering both base cases as well as the success result,0,0.9933000802993774
214483409,5567,bbejeck,2018-08-31T21:51:23Z,this base case and the one below could be refactored into a method [code block] wdyt?,0,0.9934624433517456
214980375,5567,vvcephei,2018-09-04T16:21:43Z,"yeah, it would be like: [code block] so the suppressions would still be guaranteed a unique name, but any renumbering would only affect suppressions that are peers under the same ktable node.",0,0.9870182871818542
214982312,5567,vvcephei,2018-09-04T16:28:04Z,"yes, it seems like this would also work, but tbh it seems a little roundabout to me. is the objective to avoid duplicates of the error string? maybe we could just extract the exception construction into a method: [code block] then again, i have doubts about whether adding an extra method to de-duplicate the (to me) simple logic of creating the exception is worth it at all. especially considering that there's no particular reason that the exception message needs to be exactly the same in these two cases. what say you?",0,0.7840388417243958
214983712,5567,vvcephei,2018-09-04T16:32:32Z,"i should say: i don't want to add it to *this* pr (which is already large). if you think there's merit to this idea, i would tackle it in another pr.",0,0.9759286046028137
215067976,5567,vvcephei,2018-09-04T21:10:15Z,this is where we insist on strict buffering for final results.,0,0.9853813052177429
215068069,5567,vvcephei,2018-09-04T21:10:32Z,see: [a link],0,0.9953112006187439
215315559,5567,bbejeck,2018-09-05T15:21:49Z,"makes sense to me to require users to specify how to handle the different scenarios as each user will have different needs concerning when they want a result emitted. but i'm wondering if we want to restrict users from having to supply a `strictbufferconfig` in all cases. i think there could be a case when faced with the option of either shutting down or emitting an early ""non-final"" result; there is a subset of users that would prefer an initial possible duplicate result vs. a production shut-down. so maybe the type could be ` ` unless of course, i'm wrong with my assumptions about the semantics of `strictbufferconfig.shutdownwhenfull`.",0,0.9826372265815735
215333841,5567,bbejeck,2018-09-05T16:09:07Z,what are the semantics around `strictbufferconfig.unboundedbuffer`? wouldn't have the same behavior as the `strictbufferconfig.spilltodiskwhenfull` option? what is the behavior of `shutdownwhenfull`?,0,0.9942435622215271
215339913,5567,vvcephei,2018-09-05T16:27:17Z,"there are several buffering options available that provide strict buffers: * unbounded (just keep allocating more until you get an oome) * bounded, shut down gracefully when full * unbounded, using disk instead of memory i think this provides plenty of options. i'm not sure we want to get into providing an option that says ""emit final results only (unless it turns out you need more memory than you allocated, in which case emit both intermediate and final results)"". 1, that's pretty confusing. 2, the main justification for ""final results mode"" is that the destination is some kind of system that doesn't permit updates. if we *claim* to support final-results-only, but send updates instead, we risk causing harder-to-debug downstream failures.",0,0.8579888939857483
215340550,5567,vvcephei,2018-09-05T16:29:14Z,"an unbounded buffer has no specified bounds. it will just grow until the application runs out of heap. ""spill to disk"" and ""shut down when full"" are both bounded. you specify some limits on the size of the buffer or the number of keys, and it either shuts down gracefully or switches to disk when it runs out of space.",0,0.9888958930969238
215341057,5567,bbejeck,2018-09-05T16:30:36Z,i'm not opposed to the idea; i guess we'll need to weigh the pros and cons of having a separate approach to naming some nodes.,0,0.9069759845733643
215342060,5567,bbejeck,2018-09-05T16:34:06Z,"the overall objective was merely to reduce the duplication in code, as the two blocks seemed the same to me less the condition triggering the exception. but you have a point so maybe leave as is.",0,0.9886512756347656
215347029,5567,bbejeck,2018-09-05T16:49:32Z,"could maybe use `embeddedkafkacluster.deletealltopicsandwait` instead, as we've had problems in the past with test flakiness by not deleting internal topics.",0,0.9891313314437866
215350959,5567,bbejeck,2018-09-05T17:02:18Z,why not use `inegrationtestutils.produce..` method variants?,0,0.9921173453330994
215352500,5567,bbejeck,2018-09-05T17:07:10Z,"same here, why not use one of the `integrationtestutils.waitutill...` methods for consuming records?",0,0.9940589666366577
215352630,5567,bbejeck,2018-09-05T17:07:35Z,was this line intentional or leftover debugging?,0,0.9903181791305542
215354084,5567,bbejeck,2018-09-05T17:11:57Z,"we'll need a timeout here because unless i'm missing something, this method could block forever (or at least make the test run longer than necessary) if the expected number records aren't received. another plug for using `integrationtestutils.wait..` methods as those methods provide timeout functionality.",0,0.9918941855430603
215357092,5567,bbejeck,2018-09-05T17:19:52Z,thanks for adding the integration test. i'm thinking we'd want to add test methods using the different `strictbufferconfig` options and the `eagerbufferconfig`.,1,0.9022172689437866
215360179,5567,bbejeck,2018-09-05T17:29:35Z,"great coverage, thanks for adding",1,0.9950931072235107
215371772,5567,vvcephei,2018-09-05T18:05:33Z,"ah, good catch. thanks!",1,0.9967882633209229
215373053,5567,vvcephei,2018-09-05T18:09:55Z,"to improve these tests' readability, i created a simplified ""record"": `kvt`. this allows us to produce a batch of records, all with potentially different timestamps, at once. the `integrationtestutils` methods only accept a collection of `keyvalue`, all with the same timestamp, or a collection of `v`, all with the same key and timestamp.",0,0.9896631836891174
215373138,5567,vvcephei,2018-09-05T18:10:12Z,"basically, the same explanation as above.",0,0.9803462028503418
215373244,5567,vvcephei,2018-09-05T18:10:32Z,doh! this is left over. sorry.,-1,0.9960585832595825
215373535,5567,vvcephei,2018-09-05T18:11:31Z,fair enough. i'll add a timeout.,0,0.9857932925224304
215374308,5567,vvcephei,2018-09-05T18:14:00Z,"agreed. currently, no actual buffering is implemented. attempts to do anything but immediately emit will throw an exception. this is verified by the processor test. in the next pr, i implement buffering, and i have the integration tests for the different strategies there.",0,0.9741669297218323
215374466,5567,vvcephei,2018-09-05T18:14:27Z,thanks! i actually used the idea code coverage tool for this one :),1,0.9851111769676208
215375753,5567,vvcephei,2018-09-05T18:18:23Z,"i considered adding to the utils, but i would also have to add kvt. it seems unnecessary at this point to dump a new method and keyvalue-esque class, which are only used in this test, into util.",0,0.9830295443534851
215378941,5567,vvcephei,2018-09-05T18:27:54Z,"ah, i remember what i was thinking: that if we run integration tests in parallel, we should only delete the topics we need to. but maybe we don't parallelize the methods within a test class, and we don't share embedded clusters between test classes?",0,0.9618339538574219
215663637,5567,bbejeck,2018-09-06T15:09:45Z,"fair enough. but imho i can't envision a case where users will voluntarily let a production system shut down, but again that's just my opinion.",0,0.7525197863578796
215673339,5567,bbejeck,2018-09-06T15:34:05Z,nit: do you need `cleanstateaftertest`? in `getcleanstartedstreams` you already call `driver.cleanup` and delete all topics in `cleanstatebeforetest`,0,0.9912243485450745
215677905,5567,vvcephei,2018-09-06T15:46:05Z,"the (maybe imaginary) scenario i had in mind was: * your business logic depends on exact buffering behavior (otherwise you wouldn't be using ""final"") * you want to bound how much memory the app uses * you discover that in practice the app needs more memory than your bound it seems like in a situation like this, you would like a graceful shutdown with a clear message so that you can reconsider your options. * maybe you take a look at your metrics and discover that you can decrease the window grace period, thereby relieving memory pressure * maybe you change the environment so you can allocate more memory to the task unless you are using iq or doing something time-sensitive like high-frequency trading, shutting the app down for short periods of time when it's misbehaving should be acceptable. having hard failures like this can actually be more operationally friendly than grey failures like frequent gc or apps stealing memory from each other. but of course, it depends on the situation. there is a possibility of implementing more complex behaviors, such as pausing some tasks to allow others to flush more work, but i don't think we need to think about that right now. that was all for context. at the end of the day, if we don't think we need the ""graceful shutdown"" mode, i'd rather not implement it.",0,0.9814505577087402
215678896,5567,vvcephei,2018-09-06T15:48:47Z,it's a belt-and-suspenders thing. we want it at the end so that the tests don't leave garbage around (for example the last test). i also added it at the beginning just in case a prior run got forcibly killed and never had a chance to clean up.,0,0.9816824197769165
215804228,5567,mjsax,2018-09-06T23:07:21Z,nit: `by the supplied { suppressed} specification.` (or `configuration`?),0,0.9947152733802795
215804652,5567,mjsax,2018-09-06T23:09:17Z,nit: `k` -> `key` and `v` -> `value` (we should try to avoid abbreviations) should we add `final`?,0,0.9941820502281189
215805094,5567,mjsax,2018-09-06T23:12:13Z,"seem i am missing something, but why do we need `k, v` as generic types here?",0,0.9443982243537903
215805317,5567,mjsax,2018-09-06T23:13:35Z,nit: `eagerbcimpl` -> `eagerbufferconfigimpl` (avoid abbreviations -- make the code unnecessarily harder to read for newcomers),0,0.9881128668785095
215805813,5567,mjsax,2018-09-06T23:16:33Z,as above,0,0.9888283014297485
215806026,5567,mjsax,2018-09-06T23:17:59Z,seem the interface lacks some javadocs to explain this?,0,0.9795805811882019
215806779,5567,mjsax,2018-09-06T23:23:38Z,`boundedbykeys` -> `maxbufferedkeys` (cf. comment below),0,0.9950153231620789
215807022,5567,mjsax,2018-09-06T23:25:12Z,"if we rename above, rename this to `withmaxbufferedkeys` ? (other interfaced -- eg, `produced` -- also use `withxx` for all non-static methods as counterpart to `xx` for static ones. might be nice to follow this pattern? better suggestions are welcome.",0,0.896504819393158
215807451,5567,mjsax,2018-09-06T23:27:42Z,as above: `maxbufferedbytes` ?,0,0.9950793981552124
215807482,5567,mjsax,2018-09-06T23:27:54Z,`withmaxbufferedbytes` ?,0,0.9946258664131165
215807736,5567,mjsax,2018-09-06T23:29:19Z,"nit: to follow other interface, the non-static methods should have the `with` prefix (similar below)",0,0.9935831427574158
215808672,5567,mjsax,2018-09-06T23:35:23Z,"for the case you describe, `emitfinalresultsonly` seem to be the wrong user choice, and they should use `intermediateevents` with ""infinite time duration"" and limited buffer size.",0,0.9637754559516907
215809634,5567,mjsax,2018-09-06T23:42:03Z,"i understand the desire, however, it would not solve the overall re-naming issue -- i would prefer to have a holistic solution for the problem instead of introducing complex code that does not really help.",0,0.9445076584815979
215809978,5567,mjsax,2018-09-06T23:44:29Z,`findandverifywindowgraceorthrow` (and remove the comment) ? (self-documenting code ftw :)),1,0.8762932419776917
215810340,5567,mjsax,2018-09-06T23:46:44Z,nit: comment unnecessary,0,0.7663483619689941
215810366,5567,mjsax,2018-09-06T23:47:00Z,comment unnecessary,0,0.9826319217681885
215810406,5567,mjsax,2018-09-06T23:47:25Z,comment unnecessary,0,0.9826319217681885
215810981,5567,mjsax,2018-09-06T23:51:32Z,can we use ` ` directly here? also let `buildfinalresultssuppression` return this type instead of windowed?,0,0.995049774646759
215811536,5567,mjsax,2018-09-06T23:55:09Z,"""all parents"" ? `suppress` is only available for `ktable` and thus there should be only one parent node? also, do we need to handle chaining of `.suppress()` within `extractgraceperiod`? i also don't understand how there could be multiple parent grace periods (and thus, why do they need to match -- there should only be one anyway?) -- do i miss something? i also just realize, that windowed-ktables have another issue: we cannot only not join two, but we can also not `.filter(..., materialize)` because this would also create an ever growing key-value store instead of a windowed store... \cc thoughts?",0,0.9814091920852661
215813625,5567,mjsax,2018-09-07T00:10:34Z,"wy not use `new unsupportedoperationexception(""not implemented yet."")` :)",1,0.7042451500892639
215813819,5567,mjsax,2018-09-07T00:11:58Z,"nit: is a negative value valid? if `duration` does not check this, we should check and throw?",0,0.9910373687744141
215814619,5567,mjsax,2018-09-07T00:17:50Z,"don't understand the second check? why must the record-time (or window-end-time) be less-or-equal to current stream-time? for record-time, this should be true all the time, but for window-end time, i don't think this is true -- why do we want to fail for this case?",0,0.8299078941345215
215815381,5567,mjsax,2018-09-07T00:23:16Z,could this be `private`?,0,0.9911803603172302
215816045,5567,mjsax,2018-09-07T00:28:20Z,`keyvaluetimestamp`,0,0.9941369295120239
215816087,5567,mjsax,2018-09-07T00:28:39Z,`keyvaluetimestamp`,0,0.9941369295120239
215816526,5567,mjsax,2018-09-07T00:32:14Z,"""shouldaccept only"" -- sound like a negative test but i don't see any exception? the `doesn't compile because the buffer is eager` part is weird... the condition you express is ensured via the interface -- ie, it does not compile. thus, i don't think we need a negative test.",-1,0.974414050579071
215816861,5567,mjsax,2018-09-07T00:35:06Z,"i am fine with this; however, it might be better to take `system.currenttimemillis()` as seed and log the seed -- if it fails, we can reproduced using the logged seed? also: it's multiple test methods and i don't think that the execution order is defined. thus, we should initialize the with known seed, for each test, ie, via ``",0,0.9460904002189636
215817497,5567,mjsax,2018-09-07T00:40:48Z,`end` could be `0` and thus `nextint(end)` would throw. use `end = 1 + random.nextint(integer.max_value - 1);` above,0,0.9932171702384949
215817777,5567,mjsax,2018-09-07T00:43:16Z,should `timestamp` not fall into the window boundaries? not sure if it's important for the test?,0,0.9832504391670227
215818040,5567,mjsax,2018-09-07T00:45:22Z,why do we need an extra test for this? seems to be covered in `finalresultssuppressionshouldthrow` ?,0,0.9924631118774414
215818075,5567,mjsax,2018-09-07T00:45:38Z,as above,0,0.9888283014297485
215818472,5567,mjsax,2018-09-07T00:48:45Z,"there is already an `internalstreamsconfig` in `streamspartitionsassignor` -- if we want to use it multiple time, should we make it a public internal call that we can reuse here instead of duplicating code? maybe in a new package `...streams.internals` ?",0,0.9946947693824768
215993196,5567,vvcephei,2018-09-07T15:14:19Z,"good catch on the abbreviations. about `final`, i'll check. it might not be allowed in an interface method header.",1,0.9080349206924438
215993869,5567,vvcephei,2018-09-07T15:16:21Z,"hmm. maybe we don't... i used to have serdes in the buffer config, but they are gone now. also, we need k/v in `suppressed` so that we can bound the k to be windowed for final updates. i'll try and drop them. it would be awesome if we don't need them.",1,0.7902693748474121
215994325,5567,vvcephei,2018-09-07T15:17:42Z,"it's actually `eagerbritishcolumbiaimpl`, but i can see how you'd get confused.",0,0.9835938811302185
215995058,5567,vvcephei,2018-09-07T15:19:44Z,thanks for the suggestion. i've really struggled to come up with good names for these static/instance methods that make sense in context. i'll give this a shot.,1,0.9659812450408936
215997251,5567,vvcephei,2018-09-07T15:26:19Z,"i figured that ""verify"" means ""orthrow"". the comment is part of a series that explains why the casts in this method are safe. i think that it would be very difficult to understand later why it's ok to cast `k` to `windowed`, and then why we would cast the resultant suppression back to `k`.",0,0.9890052676200867
215998650,5567,vvcephei,2018-09-07T15:30:34Z,"no, the final results suppression is defined only for windowed tables, by design. as the comments explained, we happen to know that k is a windowed, but the generic bound is still just `k extends object`, so we have to ""forget"" our knowledge that k is a windowed in order to return the result properly typed. this is what i was trying to explain in the comments, and your question illustrates why i think the comments are necessary. but i guess i need to try harder to make the comments explain this situation fully.",0,0.983304500579834
216000969,5567,vvcephei,2018-09-07T15:37:15Z,"the last point is correct. i thought that we were already aware of this shortcoming... but now i don't remember who i was talking to about it. about the parents... the immediate parent of suppress is a single ktable, but may not be the one with a defined grace period. it might be a filter, in which case we need to examine the parent of the filter, or it might be a join, in which case we need to examine *both* parents of the join. the fact that we currently have a design flaw that prevents this situation doesn't imply that we should encode this limitation here. once we fix that design flaw, we would have to remember that we also coded that flaw into this method and come back to revert it to the state it's in right now!",0,0.9046306014060974
216002077,5567,vvcephei,2018-09-07T15:40:42Z,"` \_()_/ ` sure, that would work too. i'm removing this exception in the next pr, so i don't think it matters much. using the specifically defined exception makes it slightly easier to make sure i remove all usages of it in the next pr, as i can delete the exception class and the code won't compile until i remove all usages.",0,0.8864607214927673
216002534,5567,vvcephei,2018-09-07T15:42:13Z,i don't see why i need to worry about that here.,0,0.8993173241615295
216004459,5567,vvcephei,2018-09-07T15:48:09Z,"as you pointed out, a record in an open window will have a time greater than the current stream time. this means we should buffer it (when it's implemented) and *not* immediately emit it.",0,0.9907885193824768
216004765,5567,vvcephei,2018-09-07T15:49:08Z,"hmm, i'll check. i don't think so, but i don't remember why.",0,0.9209769368171692
216005077,5567,vvcephei,2018-09-07T15:50:07Z,k ;),0,0.9784352779388428
216006317,5567,vvcephei,2018-09-07T15:54:01Z,"the purpose of this ""test"" is explicitly to demonstrate what compiles and what doesn't. it's of course not possible to write code that doesn't compile in order to demonstrate that it doesn't compile, so i wrote the code and commented it out. if you'd like to ""run"" the test, you can uncomment the ""negative test"" lines and verify they are not permitted. if you think this is silly, i can rename the test.",0,0.9243735074996948
216007362,5567,vvcephei,2018-09-07T15:57:30Z,"what you are describing is what i had initially. it seemed a little too fancy, though. i think if we like this approach, we should consider bringing in a real fuzzing framework instead of hand-rolling it. about ``, this is a good point. i'll do it.",1,0.7982384562492371
216008190,5567,vvcephei,2018-09-07T16:00:14Z,"in practice, it would, but since the processor itself doesn't make any assumption between the record timestamp and the window boundary, it doesn't matter for the test. in fact, the test verifies that the processor makes no such assumption.",0,0.9927908182144165
216008629,5567,vvcephei,2018-09-07T16:01:31Z,"it's a stub of a test that i have in the next pr. when i extracted this one and replaced buffering with exceptions, i just replaced all the test bodies with verification of the exception.",0,0.9942893981933594
216008726,5567,vvcephei,2018-09-07T16:01:55Z,explained above.,0,0.9921060800552368
216009989,5567,vvcephei,2018-09-07T16:06:32Z,"i considered that, but it seemed better to keep the mockprocessorcontext in test-utils as decoupled as possible from the internals of streams. in general, when we're modifying streams code, we exercise a lot of freedom in modifying internals, and i don't want to risk accidentally changing the behavior of the mock if we decide to add some more stuff to the one used by streamspartitionassigner. if it helps, i can give this one a different name...",0,0.934445321559906
216041459,5567,guozhangwang,2018-09-07T18:01:14Z,`eagerbritishcolumbiaimpl` yeah that's what i thought too!,1,0.9766067862510681
216042101,5567,guozhangwang,2018-09-07T18:03:42Z,how about `emitintermediateevents` to be better aligned with `emitfinalresultsonly`?,0,0.994053065776825
216043674,5567,guozhangwang,2018-09-07T18:09:34Z,could you elaborate why we need `bc extends bufferconfig ` as its template?,0,0.9941984415054321
216044564,5567,guozhangwang,2018-09-07T18:12:29Z,`kstreamwindowaggregate` is used only for time windowed aggregations (the class name was added when we only have time windowed at that time). for session windowed aggregations we have `kstreamsessionwindowaggregate`.,0,0.9938219785690308
216044943,5567,guozhangwang,2018-09-07T18:13:49Z,"with this idea, whether or not we insert a suppression or not would not affect any downstream operators, right? why that would not solve the re-naming issue?",0,0.9876876473426819
216046368,5567,guozhangwang,2018-09-07T18:18:38Z,"nit: why put this class under `suppress`? we usually try to get consistent hierarchy among main v.s. test directories unless there is a strong motivation not to. i.e. it is fine to have `ktablesuppressprocessortest.java` under `suppress`, but this class may just be `ktablesuppresstest` under `kstream/internals`.",0,0.932205319404602
216068984,5567,vvcephei,2018-09-07T19:47:04Z,"yeah, this is another spot where i really struggled with naming. i liked `suppress(intermediateevents())` aka ""suppress intermediate events"", but the version for final would be like ""suppress all but final events"", and `suppress(allbutfinalevents()` just seems too confusing, so i compromised. note that this method isn't saying to _emit_ the events, but actually the opposite: to _suppress_ them. i think the symmetric name would be `suppressintermediateevents()`, which looks a little redundant in practice: `suppress(suppressintermediateevents())` or `suppress(suppressed.suppressintermediateevents())` :/ another idea would be to choose one of the synonyms. since we are accomplishing this suppression via buffering, we could call it `bufferintermediateevents` or just `buffer`... thoughts?",-1,0.6699962019920349
216070493,5567,vvcephei,2018-09-07T19:53:12Z,"ah! this has a name: ""curiously recurring generics"" (or ""curiously recurring template"" from c++). this allows us to declare builder methods in the interface that return an instance of whatever subclass was used to invoke the method. such as `bc bufferkeys(final long maxkeys)`. when we call this on an eager config, we get back an eager config, and when we call it on a strict config, we get back a strict config. if you recall the weird comment in windows that says ""all subclasses should override this method so they can return the correct type"", we were looking for the same property. if we had used this pattern, we wouldn't have needed that comment, as the overridden methods would automatically take on the correct return type.",-1,0.9366082549095154
216071247,5567,vvcephei,2018-09-07T19:56:14Z,"sure, i can do that. i agree 100% on the unit tests. for this semi-integration test, i stuck it in this package just because `internals` already has like 1.5m test classes in it. i'll move it.",0,0.8109764456748962
216071967,5567,vvcephei,2018-09-07T19:59:15Z,"i think `kstreamwindowaggregate` is used for any subclass of `windows`, of which `timewindows` is one. it's definitely not `sessionwindows`, since `sessionwindows` is not a subclass of `windows`, but it could be `unlimitedwindows` or any user-supplied `windows` subclass.",0,0.9897923469543457
216142211,5567,mjsax,2018-09-08T22:26:18Z,ack -- was just a thought.,0,0.6521041393280029
216142224,5567,mjsax,2018-09-08T22:27:34Z,"i understood the comments -- was just not sure if we can improve the code. if we cannot change the generic type, it's fine.",0,0.8584283590316772
216142390,5567,mjsax,2018-09-08T22:36:05Z,"hmmm... i did originally not consider ktable-ktable join -- however, a grace period is only defined for windowed aggregations, right? thus, this would only make sense if two windowed-ktables are joined? thus, if we consider that we might fix joining two windowed-ktables in the future (was is broker atm), i am wondering, if we should use the maximum grace period over both base-join-tables as required bound for the suppression, instead of forcing both base-windowed-tables to have the same grace period configured?",0,0.9602834582328796
216142405,5567,mjsax,2018-09-08T22:37:35Z,i guess `<=` is ok (it was a nit) -- was just wondering if we should use `==` instead.,0,0.9365546107292175
216142501,5567,mjsax,2018-09-08T22:43:20Z,"why should we buffer it? if `suppress.isimmediateemit()` is true, i though we would not buffer it but emit it immediately to obey the config? or do i miss understand the semantics of `isimmediateemit()`?",0,0.9836602210998535
216142530,5567,mjsax,2018-09-08T22:45:25Z,"well, i guess nobody will ever uncomment those lines to test if it does not compile -- seems to be dead code to me.",-1,0.6349493265151978
216142579,5567,mjsax,2018-09-08T22:47:58Z,"ack. fine with me to not go too fancy. however, for this case i don't see why we need `random` at all, and not just hardcode some values for window-start-time etc -- if we seed with `42`, we will get some (unknown) but fixed values anyway -- so what do we gain to use `random` ? we can just put some fixed values into the code directly.",0,0.7309258580207825
216149809,5567,mjsax,2018-09-09T07:22:32Z,i don't see a big risk in 'coupling' for this case -- but not a big deal anyway. renaming doesn't buy us anything. just leave it as is.,0,0.8904806971549988
216149889,5567,mjsax,2018-09-09T07:27:07Z,"because it does not help us, if somebody inserts a `filter()` for example. the overall renaming issue is, that inserting new operator results in re-indexing. this would be a ""local"" solution for `suppress()` only, but no global solution for all operators. thus, my concern is, that we end up with different solutions for different operators for the same underlying issue. it's about consistency. does this make sense?",0,0.9012640714645386
216358799,5567,vvcephei,2018-09-10T15:08:27Z,"ah, sorry, i misunderstood the root of your question. since the type system doesn't have evidence that `k` extends `windowed`, we have to do a cast to assign to ` `. i separated it into the next line just to avoid doing too much in one line of code.",-1,0.9560792446136475
216361603,5567,vvcephei,2018-09-10T15:15:53Z,"yeah, we could make it more permissive that way. this is a discussion for the future when we do fix that operation, but it seems safest to support that join only when both streams have the exact same window configuration (otherwise there's no guarantee that the streams have any keys in common). in such a situation, we wouldn't have to worry about enforcing it here. but for now, i was thinking to be strict about the common grace periods as a basic precaution against mixing window types. (even though the grace period isn't part of the windowed key).",0,0.9659069180488586
216365179,5567,vvcephei,2018-09-10T15:24:25Z,"hmm i guess my method name is misleading. it's not that the suppression is configured like ""emit immediately"" (there is no such config option, but maybe there should be). rather, it's an internal utility method to indicate whether the buffer config allows us to just emit events that are on-time or late, rather than buffering them. regardless, we still need to buffer future events if there is room to buffer them. this logic is just a little murky right now because there isn't a buffer yet. so this logic is an attempt to emit any event that we can determine right away is legal to emit, since any buffering operation is actually an exception in this pr. i guess i could have made it simpler by just unilaterally throwing an exception for any record here, but i thought it would be nice to have some non-exceptional paths to have tests for. even though the implementation details will change when we add the buffer, any tests that currently check for events getting immediately emitted should continue to pass on the buffer-based implementation.",0,0.8585071563720703
216370098,5567,vvcephei,2018-09-10T15:37:27Z,"yes, this is the downside i was concerned about. i won't make any change to this in this pr. i've created a jira to continue the discussion: [a link]",0,0.8180863261222839
216394282,5567,guozhangwang,2018-09-10T16:49:09Z,"i see. and with this reasoning i think i also like `intermediateevents` as well. how about `suppress(intermediateevents())` and `suppress(untilwindowends())` since the latter should be only called for windowed table result, and hence putting the keyword `window` as part of the func name should be fine?",0,0.9870092272758484
216394504,5567,guozhangwang,2018-09-10T16:49:54Z,ack.,0,0.5866091847419739
216405880,5567,vvcephei,2018-09-10T17:23:55Z,"ooh! i like it! (although i think i'll say `untilwindowcloses`, since it waits for the grace period after the ""end"" of the window (which reminds me that i should make sure the window lifecycle is well documented for the 2.1 release))",1,0.9872433543205261
216517843,5567,mjsax,2018-09-11T00:52:49Z,"cannot follow here. can you elaborate? also, thinking about this once more: why do we need to force `suppress` to have a larger grace period that it's parents?",0,0.9749094247817993
216518207,5567,mjsax,2018-09-11T00:55:52Z,ack.,0,0.5866091847419739
216826714,5567,vvcephei,2018-09-11T21:20:33Z,"what i meant is that if the left stream and the right stream have completely different window specs, then the join will be completely disjoint. this is probably a programming mistake, and i think it's better to fail fast.",-1,0.7666319608688354
216827058,5567,vvcephei,2018-09-11T21:21:45Z,about: i didn't understand. we set suppress's suppression time *equal* to the grace period of the parent.,0,0.9496694803237915
216870298,5567,mjsax,2018-09-12T01:08:21Z,"this makes sense -- however, if no suppress operation is defined, this would not be detected -- and if we put a check somewhere else, suppress does not need to check it either. does it? additionally, even if suppress does this check, i would exclude the grace period from the check. from my understanding, this method should checks that the grace period is larger than the window-size of the upstream ktable -- we don't need to set the grace-period, but just take whatever the users specified for it. there is no comparison of parent grace period and suppress grace period? and there is no need? or do i miss something?",0,0.9817975759506226
217177283,5567,vvcephei,2018-09-12T20:28:55Z,"yeah, i think we're miscommunicating. suppression does not have a ""grace period"", it only has the ""emit after"" config. the method `findandverifywindowgrace` only extracts the exact specified grace period, as configured upstream. we pass the value we get back to `org.apache.kafka.streams.kstream.internals.suppress.suppressedimpl#buildfinalresultssuppression`, which then creates a `suppressed` configuration using that time (the extracted grace period) as the ""emit after"" config, along with setting the `timedefinition` to the window end time. together these configs cause suppression to emit immediately right at the end of the grace period (as configured somewhere upstream).",0,0.798560619354248
217179331,5567,vvcephei,2018-09-12T20:34:57Z,"you raised a separate question about whether we should be strict or permissive if the suppression node actually has multiple parents which specify two different grace periods. i favored strict because i think this makes the situation more debuggable and comprehensible. but you are correct in stating that it's not a correctness issue, since the grace period doesn't affect the key. for this reason, i would be ok with logging a warning and just using the larger grace period. the consideration we need to weigh is in that situation with two different windowed tables getting merged/joined, assuming they only differ in grace period, how can we ensure that all operators follow the same strategy of taking the larger grace period. it affects windowed store retention as well as suppression. i think taking the larger is a reasonably obvious choice, so maybe it's not a big deal, though.",0,0.9601436257362366
217476838,5567,mjsax,2018-09-13T17:51:03Z,"thanks for clarification! would be good to get input from about this. should we fail? or should we pick ""max""? i still favor ""max"", but it's not a deal breaker if we fail instead. nevertheless, i don't think `suppress` should check the window spec (size/advance etc) -- if a user does a ""weird"" join and we want to disallow it, this check should be done in `join()` instead.",1,0.9900826811790466
217514478,5567,bbejeck,2018-09-13T19:58:51Z,"i would favor taking the `max` as well, as, imho, we can't account for all use cases so better to chose max. we should document the behavior so users can be made aware of what happens with setting different grace periods would it be too much to make this a configurable item? i'm not sure as we have several config items to consider already.",0,0.9654166102409363
217805092,5567,guozhangwang,2018-09-14T18:34:31Z,"regarding the `.filter(..., materialize)` issue, yes this is a known bug. i think has raised a kip for fixing this. regarding the windowed-ktable / ktable join, there are some very old discussions before on how to tackle it ([a link] is filed recently), and the idea at that time was: 1) we would require the joining table's window-spec to be well aligned, i.e. they must have the same length. note since window boundaries are the same as they are all starting from the epoch time, it means that same window length guarantees aligned windows, and each the join operation becoming joining each paired windows of the table. we do not yet have session windows at all so this was not discussed, but with session windows it is definitely more complicated.. as for grace period, i think we do not need to make it strict that requires grace to be the same as well. personally i think either `min` or `max` are fine (i'm slightly leaning towards `min` though :p).",0,0.9607025980949402
217850548,5567,mjsax,2018-09-14T21:46:34Z,"why `min`? `max` seems to be inclusive and guarantees to respect the configs of both upstream operators, while `min` does not?",0,0.9743397235870361
217853758,5567,vvcephei,2018-09-14T22:05:17Z,"ok, * fwiw: i 100% agree that it's not this component's job to verify other aspects of the window spec. it should only care about grace period. * i think the semantics are perfectly well defined with `max`, and i buy these arguments that it's unnecessary to fail. i'd like to log a warning (just during the topology build) in case the mis-match was accidental. : i agree with , i don't think that `min` has the right semantics. the purpose of configuring the suppression interval equal to the grace period to begin with is that we already know that the window results will never be updated after the grace period ends. if we set the suppression smaller than the grace period (or in this case _one_ of the grace periods), then there will be an inconsistency between the aggregation results upstream vs. downstream of suppression. in fact, it's generally ok if we make the suppression interval _larger_ than the grace period. it just means that we'll emit the final result ""after"" the window closes, not ""at"" the window close. thus, `max` satisfies everyone's semantics and ensures consistent results throughout the topology. the ""more graceful"" parent will see its final results close after its grace period expires, and the ""less graceful"" one has to wait longer, but they will both never see their materialized state differ from the results downstream of the suppression.",0,0.8538899421691895
217856097,5567,guozhangwang,2018-09-14T22:22:06Z,"to me the grace period for a window is letting users to trade-off between latency and correctness, and hence users may actually prefer latency over correctness in some cases, so i said in the previous comment that personally i'd prefer `min`, just to express this intention :) anyways, i do not have strong preference which option to go, and i'm also fine with `max` if most people feel that way.",1,0.984306812286377
217861650,5567,mjsax,2018-09-14T23:04:37Z,"from my understanding, using max will be the default behavior -- users can still manually specify a smaller one, right? it must just be larger than window-size?",0,0.9875725507736206
217868845,5567,guozhangwang,2018-09-15T00:24:11Z,"grace period is the additional time on top of the window-size, and assuming that the window-size of the joining tables are the same, the grace period of 0 can also be used right?",0,0.9927144646644592
218138620,5567,vvcephei,2018-09-17T16:29:29Z,"ok, recall that we are talking about the special case in which the suppress operation has two parents who have different grace periods configured. in this case, ""max"" means that the suppression will be configured with the larger of the two parents' grace periods. normally, suppression only has one parent, in which case, it's configured to suppress for n ms, where n equals it's parent's grace period. n might be 0. if you select ""final results"", there is *no* option to configure the suppression interval. it is _always_ taken from the parent(s)'s configured grace period. to do anything else would threaten consistency. however, it's always possible just to do regular intermediate suppression, and choose any time you like, larger or smaller than the window size. you're just not guaranteed to get exactly one result per key/window if you pick any time shorter than window size + grace period.",0,0.9804689288139343
218451116,5567,vvcephei,2018-09-18T14:16:33Z,it is used in the static factory method of the interface.,0,0.9947509169578552
218604503,5567,bbejeck,2018-09-18T21:40:20Z,nit: can we take this out?,0,0.9882935285568237
218611217,5567,vvcephei,2018-09-18T22:07:06Z,"sure. i actually used this multiple times during this refactoring, but i think it'll be stable and therefore less useful now.",0,0.9472439885139465
218622057,5567,mjsax,2018-09-18T23:03:37Z,"this was not included in the kip, but is also public api. i think, we need to update the kip accordingly. similar to `strictbufferconfig` below? or is this for internal use only? for this case, we might want to move them to `internal` package but not nest them within `suppressed` interface.",0,0.9914583563804626
218622547,5567,mjsax,2018-09-18T23:06:19Z,"this method is not mentioned in the kip either. (or is it renamed `withbufferedkeys` -- if yes, should the return type not be `bufferconfig` as describe in the kip?) it seems there is a glitch between the pr and the kip -- will not comment on it further -- please revisit and update pr and/or kip to align both (for kip updates, please follow up on the mailing list; just a fyi email if it's just renaming bunch of methods).",0,0.9925870299339294
218623475,5567,mjsax,2018-09-18T23:11:32Z,kip has different generic types.,0,0.9657353162765503
218626835,5567,mjsax,2018-09-18T23:30:21Z,nit: remove `this`,0,0.9929719567298889
218628237,5567,mjsax,2018-09-18T23:39:08Z,nit: `grace` -> `defaultgrace`,0,0.9919778108596802
218628588,5567,mjsax,2018-09-18T23:41:03Z,"should we not honor the grace period as specified in `suppress` and use default one only, if user did not specify one (ie, maybe optimized to `min(usergrace, defaultgrace)` -- not sure if this optimization is desired or not, or if we should ""blindly"" accept `usergrace` even if it's larger than `defaultgrace` what does not by anything and only increases latency...?) also, first parameter in `buildfinalresultssuppression` is called `windowclosetime`, thus, should this be `windowsize + grace` (or `maxwindowsize + grace` for multiple parents) ?",0,0.9838468432426453
218631401,5567,mjsax,2018-09-18T23:57:34Z,can we define this as `timedefinition ` ? (and get rid of `getdefaulttimedefinition()`),0,0.9954073429107666
218633801,5567,mjsax,2018-09-19T00:13:26Z,naming: `withuntiltimeelapses` sounds clumsy -- `withelapsetime` ?,0,0.8028682470321655
218634055,5567,mjsax,2018-09-19T00:15:19Z,`*not*` -> ` not ` (or other html markup),0,0.9883165955543518
218634393,5567,mjsax,2018-09-19T00:17:30Z,this is discussed in the kip. should it be defined within the interface? or removed from the kip if it's not public api but impl detail?,0,0.9948166012763977
218634430,5567,mjsax,2018-09-19T00:17:49Z,nit: indention,0,0.9862814545631409
218634537,5567,mjsax,2018-09-19T00:18:21Z,nit: remove empty line,0,0.9923680424690247
218655637,5567,vvcephei,2018-09-19T03:07:11Z,"yes, i plan to update the kip if you all liked this interface.",0,0.9491599202156067
218656056,5567,vvcephei,2018-09-19T03:10:50Z,"the user is not capable of specifying a suppress time for final results suppressions (see `suppressed.untilwindowclose`). only a buffer config. the grace period is the only way to ""set"" the suppression time. i'll rename the parameter to `graceperiod` this is correct, since the time definition for final results mode uses the window end as the starting point.",0,0.9938045740127563
218656226,5567,vvcephei,2018-09-19T03:12:22Z,"we can make it a ` `, but only if we drop the `static`. the static may be nice for performance, since we only need one function class & instance, but i'm not sure if it matters that much.",0,0.9668881893157959
218656366,5567,vvcephei,2018-09-19T03:13:29Z,"agreed. double preposition :( . on the other hand, i'm not sure what an ""elapse time"" might be. i'll try to think of something.",-1,0.9945110082626343
218656587,5567,vvcephei,2018-09-19T03:15:10Z,"yeah, if there were no objections on `suppressed`, i was basically going to smash what i had in the kip with it and send out an update. it's still fundamentally the same proposal, but i like the interface we've arrived at via this discussion a _lot_ better than what i originally proposed. so thanks!",1,0.9906768798828125
218659126,5567,vvcephei,2018-09-19T03:37:21Z,"but i don't like that this wasn't immediately obvious, so i'll make some clarifying changes.",-1,0.9714369773864746
218666331,5567,mjsax,2018-09-19T04:38:29Z,i see. than i need to have a closer look -- i usually compare the pr with the kip and try to catch gaps... if you don't update the kip on purpose (what is ok) i need to change my strategy.,0,0.9820976853370667
218666810,5567,mjsax,2018-09-19T04:43:23Z,why this limitation? let's say i have [code block] does this make sense?,0,0.9817976951599121
218666974,5567,mjsax,2018-09-19T04:45:10Z,"this is not runtime critical -- and having a few more objects (we don't have about hundreds) is not overhead concern imho. it would be cleaner with specify type and get rid of the ""cast helper method"" imho.",0,0.9245765209197998
218667036,5567,mjsax,2018-09-19T04:45:41Z,"maybe ""flushdelay"" ? or ""suppressperiod"" ?",0,0.9911710619926453
218667438,5567,mjsax,2018-09-19T04:48:30Z,independent of the kip update. why return `eagerbufferconfig` here instead of `bufferconfig`? just curious. what is the advantage/disadvantage for each case?,0,0.9851428866386414
218667521,5567,mjsax,2018-09-19T04:49:12Z,"nit: `maxkeystostore` -> `max[numberof]keystostore` ? (also, why `keys`? maybe `records` is better/more accurate?); do we need `tostore`? maybe we can strip this?",0,0.9934815168380737
218667577,5567,mjsax,2018-09-19T04:49:42Z,"nit `max[numberof]keystostore`? (or `records` -- cf, above)",0,0.9942628741264343
218668072,5567,mjsax,2018-09-19T04:54:26Z,`boundedbysize` above vs. `withbytesbound` -- should we align both?,0,0.9924045205116272
218668328,5567,mjsax,2018-09-19T04:55:56Z,`passes` -> `passed` ? `expires` -> `expired` ?,0,0.9919370412826538
218668393,5567,mjsax,2018-09-19T04:56:40Z,why `eventually` ?,0,0.9788690209388733
218668694,5567,mjsax,2018-09-19T04:59:25Z,"follow up: for `untilwindowcloses` it makes sense what you say -- my argument is, that offering only `untilwindowcloses` might not be flexible enough.",0,0.9879307746887207
218669272,5567,mjsax,2018-09-19T05:03:07Z,"i am not 100% convinced about `boundedbykeys` -- no better suggestion atm though. maybe tomorrow, or anybody else has some more ideas? maybe: `bufferconfig.maxrecords().withmaxrecords()` ? `bufferconfig.maxbytes().withmaxbytes()`?",0,0.6815637350082397
218840039,5567,vvcephei,2018-09-19T15:00:07Z,"sure, will do right now... including the cover page.",0,0.8826500177383423
218854676,5567,vvcephei,2018-09-19T15:36:19Z,"your example use case is legitimate, and it is indeed something that we sacrifice here. allow me to paraphrase: [code block] this was a point of discussion early on in the kip. the downside of this api is that querying ""count"" and observing ""output"", we will see divergent results, since ""count"" will permit some records that the suppression drops (say, any record that arrives more than 10ms later than its window). we felt that if the operator's job is to emit only ""final result"" of the window's aggregation, then that's exactly what it should do. redefining the window parameters is out of scope. however, to your second comment, i didn't follow. we don't _just_ offer `untilwindowcloses`. you could alternatively do: [code block] this won't give you ""final results"", since it will still emit updates if they are needed. final thought: like i said, i don't think it's unreasonable what you proposed, but i think it's better to start with something simple and safe. if people are asking for this api later on, we can always add it.",0,0.9826917052268982
218855860,5567,vvcephei,2018-09-19T15:39:04Z,"not in this case, since the sentence is in future tense. if i changed the verb to `would`, then it would be subjunctive, and we should say ""passed"" and ""expired"".",0,0.9857330322265625
218856509,5567,vvcephei,2018-09-19T15:40:45Z,"because the upstream state is updated immediately, but the suppression buffers the update and only emits it after the grace period passes. _then_ they will be consistent.",0,0.9910070300102234
218864237,5567,vvcephei,2018-09-19T15:59:54Z,"i've taken these naming suggestions. re: `eagerbufferconfig` -> `bufferconfig`, this works perfectly, it just didn't occur to me!",1,0.5632679462432861
218864734,5567,vvcephei,2018-09-19T16:01:10Z,"as discussed elsewhere, this is not a default. it's just the (only) grace period.",0,0.9838979840278625
218867967,5567,vvcephei,2018-09-19T16:10:53Z,i've imported 12mb of javascript libraries to italicize this word. i hope that's ok.,0,0.8179965019226074
218918921,5567,vvcephei,2018-09-19T18:38:52Z,"this is the ""partially built"" config you get when you call `untilwindowclose`. it's only partial because we need to get the grace period during the topology build.",0,0.9930419921875
218958071,5567,mjsax,2018-09-19T20:47:00Z,ack. thanks for clarification. it's a complex discussion... sorry for repeating part of the kip discussion here.,-1,0.991513192653656
218958929,5567,mjsax,2018-09-19T20:49:50Z,"grammar... at least i can play the ""i am not a native speaker""-card :)",1,0.9269073605537415
218958970,5567,vvcephei,2018-09-19T20:50:00Z,no worries. there are indeed a lot of nuances to keep track of.,1,0.8517809510231018
218959457,5567,vvcephei,2018-09-19T20:51:41Z,"heh, no worries. hope i didn't come on too strong.",1,0.9779072999954224
218959897,5567,mjsax,2018-09-19T20:53:04Z,"that is only regular latency. also, suppress did not emit anything before -- i wouldn't the ""missing result"" not consider an inconsistency? i understand what you are trying to say, but ""eventual consistency"" might not be the best term here imho. (might be a nitpick though...)",0,0.9121265411376953
218962219,5567,vvcephei,2018-09-19T21:00:43Z,"that is a good point. i was thinking of ""final results emitted"" in aggregate, as in the downstream state is eventually consistent with the upstream state. it sounds like your reading is more like ""each result emitted is eventually consistent with its upstream version"". i think this reading is actually the more likely one. and, as you point out, this statement is almost nonsense: if you look at each result when it gets emitted, it is fully consistent with the upstream state. and of course, ""eventual consistency"" as a term probably opens up a whole bag of worms we don't want to deal with anyway, as people may bring assumptions (and bad associations) from distributed databases. i'll just say ""will match the upstream"" instead.",1,0.9081178903579712
219002231,5567,mjsax,2018-09-20T00:14:40Z,sounds good.,1,0.857205867767334
219380904,5567,mjsax,2018-09-21T04:33:21Z,"do we need this here? ie, do we care if `streamsconfig` is logged in the test? if we do care, it might be good to do one pr that fixes it for all test? or at least make `internslstreamsconfig` it's own class for sharing?",0,0.9927453398704529
219381301,5567,mjsax,2018-09-21T04:37:44Z,meta comment: why is this called `initialized`? or should it be `initialize` ? where does it come from? could we fix it? or is it public api?,0,0.9946494698524475
219381463,5567,mjsax,2018-09-21T04:39:42Z,nit: simply to `private static long anylong = 5;`,0,0.9943405389785767
219381518,5567,mjsax,2018-09-21T04:40:14Z,as above,0,0.9888283014297485
219381601,5567,mjsax,2018-09-21T04:41:04Z,don't understand the test name. seem you test for `shouldemitimmediatelyifuntiltimelimitiszero` ?,0,0.8530770540237427
219382014,5567,mjsax,2018-09-21T04:43:38Z,as above,0,0.9888283014297485
219383229,5567,mjsax,2018-09-21T04:51:40Z,"why do we use a stateless here and a stateful above? if you want to test both cases, might be worth to add corresponding standalone tests?",0,0.9911605715751648
219383308,5567,mjsax,2018-09-21T04:52:39Z,wondering if this test subsumes the test from above?,0,0.8238866329193115
219384557,5567,mjsax,2018-09-21T05:04:20Z,"if you don't trust the regular cleanup, the question is why? also, should we apply this patter to other tests, too?",0,0.9751419425010681
219384803,5567,mjsax,2018-09-21T05:05:27Z,"this class seems to be duplicated below -- even if it's trivial, might be worth to share the code?",0,0.9881953001022339
219385047,5567,mjsax,2018-09-21T05:08:28Z,this can be an `else` as `committransaction()` would flush -- not even sure if flushing would be valid without calling `begintransaction()` before,0,0.988063633441925
219385150,5567,mjsax,2018-09-21T05:09:39Z,"not sure if i understand. if it's a the same argument, could you not use `integrationtestutils.waitutill..` twice instead of duplicating the code?",0,0.8384900093078613
219516422,5567,vvcephei,2018-09-21T14:26:31Z,"this change does fix it for all tests that use the mockprocessorcontext. i'm happy to remove this change from this pr and do a separate one, if you're not happy with the current state of it. i wouldn't want to mess with extracting it and bloating the current pr even more than it currently is. i think it's better not to log the config for unit tests. i disabled it because the extra logging made it hard for me to read the unit test output. logging the config is really only useful during runtime so we know what configurations people are running when they post logs to the mailing list. when a test fails, you can easily just look at the test's configuration. bill brought this up earlier. i can make a non-logging config for sharing between mockprocessorcontext and the topologytestdriver. i'm hesitant to share the config class between the test utils and production code, as the risk of making an apparently harmless change in one context and screwing up the other is non-trivial. let me know if you want me to remove this from this pr now, or i can also just create a jira to make a class for the test-utils to share.",0,0.5187780857086182
219516922,5567,vvcephei,2018-09-21T14:28:15Z,it's in internalprocessorcontext. i'll fix it in a separate pr today.,0,0.9931719303131104
219517355,5567,vvcephei,2018-09-21T14:29:27Z,"uh, yeah, i changed the api and not the test name :/",-1,0.9963791966438293
219536345,5567,vvcephei,2018-09-21T15:25:42Z,i'll check...,0,0.9882601499557495
219536496,5567,vvcephei,2018-09-21T15:26:10Z,"ah, ok.",0,0.9501436352729797
219540617,5567,vvcephei,2018-09-21T15:38:56Z,"ah, my apologies to . you are right. this is not the same argument as above, and the `waituntilminrecordsreceived` is fine here.",-1,0.9483213424682617
219544268,5567,vvcephei,2018-09-21T15:50:06Z,"specifically, the ""if"" i described above happens to me when i am debugging integration tests. if you set a breakpoint and then hit the ""stop"" button, it doesn't get a chance to run the normal ""after"" cleanup. depending on whether the test uses a randomized state directory or not, this will either give you dirty state for the next run, or it'll just consume more and more disk space in `/tmp` until you run out. i have had both happen to me in the last few months. i do think we should use the same pattern for all the integration tests.",0,0.973501980304718
219544784,5567,vvcephei,2018-09-21T15:52:00Z,"yes, now it does. they were separate when this method was checking for an exception. good catch!",1,0.9950413107872009
219546526,5567,vvcephei,2018-09-21T15:57:30Z,"the stateless node is the starting point for the search. the two parents are stateful nodes because the test needs the parents to be windowed aggregations, which are stateful. the child node could be stateful as well, but it's not necessary. do you think this test should be duplicated to make sure the search works using both a stateless and a stateful processing code as the starting point?",0,0.9927012920379639
219551965,5567,vvcephei,2018-09-21T16:16:47Z,"ok, here you go: [a link] i'll pull this code from this pr.",0,0.9937143921852112
219553532,5567,vvcephei,2018-09-21T16:22:11Z,here you go: [a link],0,0.9934523105621338
219597029,5567,mjsax,2018-09-21T18:58:08Z,"i understood the setup -- the question is, is there any difference in stateful/stateless parent that is worth testing? if not, we should use the same for all tests (otherwise, it's confusion --- at least to me -> ""why do you need to use the one or the other?"" question arrises)",0,0.9659587740898132
710561967,11331,jolshan,2021-09-16T23:19:51Z,nit: remove comment -- we add unresolved names now too.,0,0.9776025414466858
710590303,11331,jolshan,2021-09-16T23:59:44Z,can remove redundant this.topic == null,0,0.9944971203804016
710592488,11331,jolshan,2021-09-17T00:03:37Z,since we moved an inconsistent topic id check to the fetchresponse.of method we may want to remove this and similar checks in other contexts,0,0.9926602840423584
710592733,11331,jolshan,2021-09-17T00:04:05Z,nit: fix spacing in imports -- there are a few of these in the pr,0,0.9931961297988892
712488389,11331,jolshan,2021-09-20T20:24:23Z,not sure if i should go through and rename some of these to `topicidpartition`,0,0.7556183934211731
712491310,11331,jolshan,2021-09-20T20:29:01Z,nit: spacing,0,0.9841110706329346
712495759,11331,jolshan,2021-09-20T20:35:55Z,"i commented out this test, since i removed the behavior to catch inconsistent ids at this stage. i can try to simulate catching the inconsistent id later, but not sure if that is helpful to show in a test.",0,0.969943106174469
715684131,11331,dajac,2021-09-24T14:55:31Z,"when a session is used, resolving the topic ids is not really necessary here because we should already have the names in the session or we would resolve them later anyway. i wonder if it would be better to do this entirely in the `fetchmanager.newconext` based on the context type. have you considered something like this?",0,0.9840260744094849
715684533,11331,dajac,2021-09-24T14:56:02Z,do we still need this `sessiontopicids` mapping if we have the topic id in the `topicidpartition`?,0,0.9945673942565918
715685093,11331,dajac,2021-09-24T14:56:44Z,nit: could we add an overload to `partitionresponse` which takes a `topicidpartition`? this would reduce the boiler plate code a bit here.,0,0.9899485111236572
715686005,11331,dajac,2021-09-24T14:57:54Z,could we direclty check if the topic name is null here and put the unresolved ones to `erroneous`? this would avoid the filter on the next line.,0,0.9929156303405762
715687416,11331,dajac,2021-09-24T14:59:43Z,should we create `tp` after this check? we could also create a `topicpartition` as we don't really use `topicidpartition` for the metric.,0,0.9932259917259216
715690689,11331,dajac,2021-09-24T15:03:55Z,side note here: i think that we should implement `override def elementkeysareequal(that: any): boolean` from the `implicitlinkedhashcollection.element` interface to make it clear that we do this for comparing elements in the collections.,0,0.9878351092338562
715690947,11331,dajac,2021-09-24T15:04:17Z,could we add a scaladoc for this method which explains what we do and why?,0,0.9947576522827148
715691830,11331,dajac,2021-09-24T15:05:25Z,this might not be necessary if we won't resolve topic ids in the request in all cases (see my previous comment).,0,0.9900038838386536
715695751,11331,dajac,2021-09-24T15:10:21Z,"do we still need to return `inconsistent_topic_id` a top level error? fetcher prior to this change would need it, for sure. with this pr, we actually don't want the fetcher to treat it as a top level error but rather as a partition error. we need to think/discuss this a little more, i think.",0,0.9810818433761597
715697860,11331,dajac,2021-09-24T15:13:12Z,not related to this line. don't wee need to update the fetcher to handle the topic id errors at the partition level?,0,0.9932449460029602
715735268,11331,jolshan,2021-09-24T16:04:14Z,we could i suppose? i think the only difference is whether we pass in these values or the fetch request itself (+ topicname map). i don't know if how we handle changes based on context type (besides full/sessionless sessions not having forgotten topics). we could save time translating though if we end up having something like an error session.,0,0.9859704375267029
715736288,11331,jolshan,2021-09-24T16:05:50Z,hmmm maybe not. looks like i just put into this map but never get anything.,0,0.8628728985786438
715738000,11331,jolshan,2021-09-24T16:08:24Z,yes we will need to do that.,0,0.9858140349388123
715740312,11331,jolshan,2021-09-24T16:11:26Z,"yeah. we can change this but the issue was with how we deal with this partition after the error is returned. with the changes to the fetchsessionhandler, we will be able to distinguish the topics, but the implementation i have now still delays partitions on a topic partition level. we don't want to delay the topic partition with the valid id though! there may be something we can do to handle this case.",0,0.9222014546394348
715740801,11331,jolshan,2021-09-24T16:12:12Z,we should do that in addition to this method?,0,0.9936150312423706
715743267,11331,jolshan,2021-09-24T16:16:04Z,"i'm not sure i follow here. we have an unresolved partition in the session and we are updating it. why would we not resolve the partition? i suppose it will get picked up by the foreach partition resolving process, but not sure how the earlier comment applies here.",0,0.9163448214530945
718910814,11331,jolshan,2021-09-29T21:51:26Z,it seems like right now `elementkeysareequal` is just `equals`. is the idea in implementing this to prevent someone else from doing so and not using `equals`/the logic from equals?,0,0.9907864928245544
718911636,11331,jolshan,2021-09-29T21:53:20Z,or is it that the javadoc says things like `key.elementkeysareequal(e) and key.hashcode() == e.hashcode()` so we should be using elementkeysareequal in fetchsession?,0,0.9928533434867859
718912221,11331,jolshan,2021-09-29T21:54:28Z,^ this is still something we need to resolve.,1,0.6143081784248352
719649068,11331,jolshan,2021-09-30T18:15:00Z,reassigning partitions takes a topic id partition unfortunately. but i suppose we can change that. not sure if we want to distinguish between reassigning partitions if we had two with the same name in the session.,0,0.777804970741272
719668223,11331,jolshan,2021-09-30T18:42:24Z,"for the replica fetcher, we could choose not delay partitions with this error. seems like in the fetcher, we just choose whether to update metadata. so maybe this won't be too difficult. alternatively, we change the fetching flow to contain topic id earlier in the process and so we can include in the error response as well. that would be a lot of work. still need to think through the current setup to make sure we aren't losing critical data in this state.",0,0.9403252601623535
727155822,11331,dajac,2021-10-12T13:48:07Z,"i have been looking at the changes in the `fetchsessionhandler` as well at the changes in the related classes. i am a bit worried by two things: 1) the `fetchsessionhandler` is quite complicated now, at least a bit more than before; and 2) the reliance on the request version is spread in many places now. it seems that we could get away with a simpler solution which, i think, cover all the cases as well. at the moment in the `fetchsessionhandler`, we track the `added`, `removed` and `altered` partitions and the `fetchrequest` is constructed based `next` (`added` + `altered`) and `removed`. now imagine that we would track another list `replaced` (or `upgraded`...). we would add a partition to this list when we detect that the topic id of the partition in `next` is different from the one in the session. then, we would pass that new list to the `fetchrequestbuilder` as well. in the builder, we would add it to the forgotten set if version >= 13 or ignore it otherwise. i have tried to implement this based on `trunk`: [a link] i think that we should be able to do something similar based on your version which uses `topicidpartition`. the pros is that the version handling remains in the `fetchrequest` class. the cons is that it does not allow to restart the session immediately without doing a round-trip to the broker, which is not a big deal as this could only happen during the upgrade. what do you think? would this approach cover all the cases?",-1,0.8722264170646667
727909392,11331,dajac,2021-10-13T10:12:09Z,i have simplified the code and removed a few maps along the way. here is the diff: [a link],0,0.9907352924346924
727996093,11331,dajac,2021-10-13T12:12:52Z,with ismael's pr ([a link] this trick does not work any more. we need to think about an alternative/better approach.,0,0.9819229245185852
728096221,11331,ijuma,2021-10-13T14:00:29Z,"hmm, how does my pr affect this?",0,0.9801109433174133
728115288,11331,dajac,2021-10-13T14:19:30Z,"actually, you're right. that is not entirely true. i thought that the `requirenonnull` for the `topic` in one of the [a link] would prevent this to work. however as we use the other `topicidpartition` constructor in this case, it is not impacted by the `requirenonnull`.",0,0.9904594421386719
728124707,11331,dajac,2021-10-13T14:28:47Z,"in this case, it would be nice if we would have a `topicidpartition` which contains an optional topic name. for the context, the issue is that we might have partitions in the fetch requests for which the topic name is unknown or not yet known by the broker.",0,0.9933432340621948
728127262,11331,ijuma,2021-10-13T14:31:14Z,"we should probably remove that non null check, since it's weird to have it only in that one path. i can submit a pr.",-1,0.9772023558616638
728132912,11331,dajac,2021-10-13T14:36:38Z,"sounds good, thanks!",1,0.9935458302497864
728455837,11331,jolshan,2021-10-13T21:20:16Z,"i think we may even be able to get away with fewer maps. i see in the commit you have we add to topicids at the start but i'm not sure that works if we have more than one id for a topic. i was thinking if we stored the id in the fetch data, we wouldn't need to build a map from ids to names. do we still use that anywhere?",0,0.9766553640365601
735854783,11331,jolshan,2021-10-25T18:25:53Z,todo: we can also put toforget back after the update step as we handle forgetting using different ids.,0,0.995216965675354
735863741,11331,jolshan,2021-10-25T18:38:22Z,"todo 2: if we have an update with an unresolved name, should we change the name to be unresolved here? i think we should but want to confirm.",0,0.9887922406196594
735935021,11331,jolshan,2021-10-25T20:22:50Z,do we not care to change ids if the data is equal? we wouldn't usually send a request and i don't know if it is possible to even have the same data in such a case.,0,0.9711655974388123
741789472,11331,dajac,2021-11-03T10:20:45Z,could we iterate over `sessionpartitions` and directly populate `sessiontopicnames` by using `putifabsent` or even `put`? the grouping seems unnecessary to me here unless i am missing something.,0,0.986079752445221
741791658,11331,dajac,2021-11-03T10:22:16Z,"as `tosend` is not used before l288, how about putting this line over there?",0,0.9939948916435242
741793046,11331,dajac,2021-11-03T10:23:03Z,not related to this pr but could we use `collections.emtpymap` here? that would avoid allocating a `hashmap` all the times.,0,0.9916173815727234
741795602,11331,dajac,2021-11-03T10:25:08Z,same comment as before.,0,0.992302417755127
741796143,11331,dajac,2021-11-03T10:25:34Z,nit: could we align like it was before?,0,0.9860148429870605
741796825,11331,dajac,2021-11-03T10:26:09Z,nit: this change and the following ones do not seem necessary. i would revert them back.,0,0.9884822368621826
741797904,11331,dajac,2021-11-03T10:27:04Z,is this method still used? i can't find any usages of it.,0,0.986652135848999
741798898,11331,dajac,2021-11-03T10:27:52Z,it seems that this method is not used anymore. could we remove it?,0,0.993878185749054
741801854,11331,dajac,2021-11-03T10:30:20Z,"this block is identical to the previous one. should we pull it into a helper method? (yeah, i know, i wrote this...)",0,0.9513438940048218
741804871,11331,dajac,2021-11-03T10:32:43Z,should we add a comment here which explains that the topic name might be null in `topicidpartition` if we were unable to resolve it?,0,0.9949069619178772
741806142,11331,dajac,2021-11-03T10:33:46Z,i would also add a small comment here.,0,0.9936150312423706
741817990,11331,dajac,2021-11-03T10:46:40Z,"putting this here but it is not related to this line. it seems that we have an opportunity in `processfetchrequest` to better handle the `fetch_session_topic_id_error` error. at the moment, it delays all the partitions. it seems to me that we could retry directly, no? if you agree, we could file a jira and address this in a subsequent pr.",0,0.9927189350128174
741818303,11331,dajac,2021-11-03T10:47:08Z,"yeah, that would be great. `topicpartition.topicpartition` looks really weird while reading.",-1,0.9527554512023926
741823983,11331,dajac,2021-11-03T10:55:09Z,nit: should we format the code as follow? [code block],0,0.9934070110321045
741826013,11331,dajac,2021-11-03T10:58:00Z,`that.canequal(this)` seems weird to me. it seems that we could just remove it.,-1,0.9555158019065857
741938548,11331,dajac,2021-11-03T13:30:57Z,nit: the if/else inline reads a bit weird. should we extract the if/else? [code block],-1,0.9766671657562256
741939805,11331,dajac,2021-11-03T13:32:18Z,nit: we could add another constructor which takes a `topicidpartition`.,0,0.9929437041282654
741940362,11331,dajac,2021-11-03T13:32:52Z,is `usestopicids` used anywhere in this method?,0,0.9942786693572998
741943413,11331,dajac,2021-11-03T13:35:54Z,nit: how about naming it `cachedpartitionkey`? we could also benefits from passing `topicidpartition` to the constructor directly.,0,0.9915088415145874
741945969,11331,dajac,2021-11-03T13:38:24Z,nit: it might be better to encapsulate this in `cachedpartition`. we could add a method called `maybesettopicname` or piggy back on `updaterequestparams`.,0,0.9901442527770996
741964245,11331,dajac,2021-11-03T13:56:41Z,nit: there is an extra space after `== null`,0,0.9942276477813721
741967434,11331,dajac,2021-11-03T13:59:40Z,nit: we can remove the parenthesis here.,0,0.9943501353263855
741968413,11331,dajac,2021-11-03T14:00:35Z,i wonder if we should reply with `unknown_topic_id` for the topics whose are not resolved.,0,0.9277341365814209
741968554,11331,dajac,2021-11-03T14:00:43Z,nit: we can remove the parenthesis here.,0,0.9943501353263855
741969873,11331,dajac,2021-11-03T14:02:00Z,nit: we can use `tp.partition` here and a few other places.,0,0.9931508302688599
741974511,11331,dajac,2021-11-03T14:06:51Z,nit: parenthesis after `partitionindex` could be omitted.,0,0.9944556355476379
741976525,11331,dajac,2021-11-03T14:08:55Z,nit: parenthesis after partitionindex could be omitted.,0,0.9943274855613708
741982676,11331,dajac,2021-11-03T14:15:06Z,i already mentioned this before but it seems that we could retry immediately in this case when the session was upgraded/downgraded. that would avoid having to wait for the backoff.,0,0.9922886490821838
741983857,11331,dajac,2021-11-03T14:16:13Z,nit: `topicidpartition.topic` should work.,0,0.9939915537834167
741985410,11331,dajac,2021-11-03T14:17:34Z,nit: we could add another `apply` method to `topicpartitionoperationkey` which accepts a `topicidpartition`. that will be convenient.,0,0.9926597476005554
741987160,11331,dajac,2021-11-03T14:19:01Z,nit: `tp.topic`,0,0.9950652718544006
741990473,11331,dajac,2021-11-03T14:22:18Z,do we still use this constructor?,0,0.9944440722465515
742113471,11331,jolshan,2021-11-03T16:20:20Z,the idea was to not do a put operation for every partition but instead every topic. maybe grouping is slower though.,0,0.9893359541893005
742114292,11331,jolshan,2021-11-03T16:21:11Z,good catch,1,0.9915775060653687
742116109,11331,jolshan,2021-11-03T16:23:08Z,"fetch_session_topic_id_error occurs when we switch from not using topic ids in the request to using them (or vice versa). i think maybe we'd want to delay partitions to get the latest metadata, but not sure.",0,0.9886189699172974
742119691,11331,jolshan,2021-11-03T16:26:48Z,hmmm. so we'd sort out the ones with null names? what benefit are we thinking we'll get from this?,0,0.9695947766304016
742121483,11331,jolshan,2021-11-03T16:28:40Z,i think i wrote all of these before the class was updated. but i will change them. :),1,0.9933550357818604
742232425,11331,jolshan,2021-11-03T18:40:50Z,yeah. it's used in 49 places. some of the places i intentionally left as zero uuids. i can convert all of them to uuid.zero_uuid if we think this may be bug prone.,0,0.9783850908279419
742285803,11331,jolshan,2021-11-03T19:58:44Z,"this was here before my change, but i can remove it.",0,0.9940061569213867
742920899,11331,dajac,2021-11-04T14:58:23Z,nit: is it worth bringing back this line on the previous one as there is space now? it might be too long though.,0,0.9031736254692078
742926299,11331,dajac,2021-11-04T15:03:40Z,would it be more appropriate to move the above assertions to `fetchrequesttest`?,0,0.992745578289032
742928420,11331,dajac,2021-11-04T15:05:55Z,"should we also test when the current topic-partition in the session does not have a topic id? in this case, it should not be added to the `toreplace` set.",0,0.9939901828765869
742931656,11331,dajac,2021-11-04T15:09:21Z,why do we use 12 here?,0,0.992220938205719
742933244,11331,dajac,2021-11-04T15:11:00Z,it is curious that we don't assert the forgotten partitions here. is there a reason?,0,0.9447043538093567
742935279,11331,dajac,2021-11-04T15:13:04Z,is there any reason for this change?,0,0.9917586445808411
742936005,11331,dajac,2021-11-04T15:13:51Z,do we still need this change?,0,0.9931551814079285
742938518,11331,dajac,2021-11-04T15:16:26Z,do we still need this change?,0,0.9931551814079285
742938637,11331,dajac,2021-11-04T15:16:34Z,ditto. there is a few other cases in this file.,0,0.9938036203384399
742939518,11331,dajac,2021-11-04T15:17:24Z,nit: there are two spaces after `=`.,0,0.9846276640892029
742944210,11331,dajac,2021-11-04T15:22:16Z,the pr changed how some errors are handled in the `fetcher`. do we have any tests for this new behavior?,0,0.9945628046989441
742950222,11331,dajac,2021-11-04T15:28:22Z,nit: it seems that we could use `topicidpartition` directly and remove `topicids` map entirely. we could also pass the `topicidpartition` to `buildfetchmetadata`.,0,0.9894075989723206
742954020,11331,dajac,2021-11-04T15:32:15Z,`0.equals(0)` was very likely put here by mistake.,0,0.9552403092384338
742963289,11331,dajac,2021-11-04T15:42:04Z,nit: we could get the topic id from `tp*.topicid`.,0,0.9915602803230286
742968374,11331,dajac,2021-11-04T15:47:22Z,nit: i would expand this comment a little and stress the fact that topic names are lazily resolved when the partitions are iterated over.,0,0.988006055355072
742969700,11331,dajac,2021-11-04T15:48:38Z,should we assert that the `topicidpartition` received here contains the topic name?,0,0.9941154718399048
742975252,11331,dajac,2021-11-04T15:54:17Z,should we iterate over the partitions in the context to check the `topicidpartition`?,0,0.9946269392967224
742978184,11331,dajac,2021-11-04T15:57:14Z,it seems to be that it would be simpler to declare `fooid` and `barid` and to use them instead of getting them from the map.,0,0.9825513958930969
742979446,11331,dajac,2021-11-04T15:58:29Z,i wonder if we should add a third topic which is never resolved. what do you think?,0,0.7207906246185303
742987345,11331,dajac,2021-11-04T16:06:50Z,should we add any tests for the new logic in kafkaapis?,0,0.9938335418701172
742993451,11331,dajac,2021-11-04T16:13:22Z,this is not ideal. could we validate that the topic id is correct as well?,0,0.5395200252532959
743011890,11331,dajac,2021-11-04T16:33:33Z,"i wonder if we could add a few more unit tests. for instance, we should test the equals/hash methods of the cachedpartition (and possibly other methods there). we might want to add some for other classes as well. what do you think?",0,0.9652391672134399
743041695,11331,dajac,2021-11-04T17:06:58Z,"i think that the grouping is slower because it has to allocate another map, sets for each uuid, etc.",0,0.9524570107460022
743044369,11331,dajac,2021-11-04T17:10:17Z,"i think that would for instance happen when the controller fails over to an older ibp during an upgrade. this should remove the topic ids which means that v12 will be used for the next fetch request and trigger a fetch_session_topic_id_error. in this particular case, re-trying directly would be the optimal way to proceed for a follower. i wonder if they are other cases to consider here. for the consumer, it is definitely different.",0,0.9843201637268066
743044970,11331,dajac,2021-11-04T17:10:57Z,right. it seems to be that the `canequal(this)` does not make any sense here. could you double check?,0,0.9875407814979553
743046003,11331,dajac,2021-11-04T17:12:18Z,i guess that it does not change much in the end. i was considering this in order to be consistent with how we handle this for the consumer.,0,0.9669780135154724
743046927,11331,dajac,2021-11-04T17:13:29Z,"yeah, that's a good question. i guess that that constructor is convenient for tests but might be bug prone in the regular code. i am tempted to remove it entirely.... what do you think?",1,0.6518442034721375
743239514,11331,jolshan,2021-11-04T22:13:41Z,i moved some back.,0,0.9162310361862183
743240074,11331,jolshan,2021-11-04T22:14:51Z,ah good catch.,1,0.9837293028831482
743240526,11331,jolshan,2021-11-04T22:15:49Z,"to clarify -- are you referring to a case where we upgraded? ie, it started with no id in the first request and added one in the second request?",0,0.9939966201782227
743241204,11331,jolshan,2021-11-04T22:17:09Z,i could theoretically check replace in the other test that checks multiple scenarios,0,0.9915741086006165
743241513,11331,jolshan,2021-11-04T22:17:46Z,i'm not sure i follow. did you mean the other test file?,0,0.7913564443588257
743242346,11331,jolshan,2021-11-04T22:19:26Z,"this was the case i tested when we had the bug of sending v13 for this scenario. the idea was that the session was empty and we had the correct topic id usage, not whether forgotten partitions were added correctly. i can add a check for forgotten partitions for completeness.",0,0.9931809306144714
743242849,11331,jolshan,2021-11-04T22:20:26Z,it likely had something to do with how the mock client was handling metadata. but that may have been for the older version where we checked nodeapiversion. i can try to switch it back.,0,0.9913625121116638
743243111,11331,jolshan,2021-11-04T22:20:49Z,nope. looks like another change i forgot to cleanup.,0,0.9780958890914917
743243975,11331,jolshan,2021-11-04T22:22:40Z,i think i'm misunderstanding something here. did you mean to say append?,-1,0.6504339575767517
743349235,11331,jolshan,2021-11-05T02:23:35Z,are you referring to how we changed unknown_topic_id and inconsistent_topic_id? for these cases we have testfetchinconsistenttopicid and testfetchunknowntopicid which check that we update the metadata for a partition level error.,0,0.9945715069770813
743349370,11331,jolshan,2021-11-05T02:23:52Z,these tests changed from returning a top level error to partition level error.,0,0.9913396239280701
743350813,11331,jolshan,2021-11-05T02:28:10Z,what logic are we thinking? checking that the unresolved topics are handled correctly?,0,0.9874732494354248
743351017,11331,jolshan,2021-11-05T02:28:54Z,i can add some for the equals and hash methods in cachedpartition. what classes were you thinking of for others?,0,0.9955469369888306
743354926,11331,jolshan,2021-11-05T02:42:15Z,hmm. i'm not quite sure why this would not make sense. i believe it is checking the types are correct.,0,0.9239562749862671
743355748,11331,jolshan,2021-11-05T02:44:59Z,i think we would want to keep the authorization error. since it just logs a message. the unknown_topic_id error would request a metadata update which doesn't make sense when there is an authorization error.,0,0.9784309267997742
743360648,11331,jolshan,2021-11-05T03:01:38Z,or are you just referring to a case where we don't ever have topic ids?,0,0.9902565479278564
743361897,11331,jolshan,2021-11-05T03:05:57Z,looks like most of these changes were done by this commit: [a link] so i can remove them pretty easily.,0,0.988711953163147
743365481,11331,jolshan,2021-11-05T03:18:35Z,i have no idea why this is here.,-1,0.9312658309936523
743369512,11331,jolshan,2021-11-05T03:33:09Z,"not quite sure what you meant here but i added this for now: `context1.foreachpartition((topicidpartition, _) => assertequals(topicids.get(""foo""), topicidpartition.topicid))`",0,0.974157452583313
743370419,11331,jolshan,2021-11-05T03:36:47Z,"we could do that, but then this check will be a bit more complicated. `context2.foreachpartition((topicidpartition, _) => assertequals(topicnames.get(topicidpartition.topicid), topicidpartition.topic))`",0,0.9922926425933838
743370521,11331,jolshan,2021-11-05T03:37:06Z,i can think more on this.,0,0.97393798828125
743370708,11331,jolshan,2021-11-05T03:37:39Z,still todo for friday,0,0.8384321331977844
743574922,11331,dajac,2021-11-05T11:16:18Z,"sorry, i meant below assertions not above. yes, it seems that they are testing the logic of the `fetchrequest` itself and not really the logic of the fetchsessionhandler.",-1,0.9415017366409302
743575635,11331,dajac,2021-11-05T11:17:38Z,correct. i was referring to the upgrade case. we might need to handle the downgrade case for [a link],0,0.9838665723800659
743576928,11331,dajac,2021-11-05T11:20:00Z,"yeah, it would be good to assert what we expect in `data2` for completeness.",0,0.986907958984375
743577292,11331,dajac,2021-11-05T11:20:37Z,"yes, i was referring to those. ack, i missed them during my first read.",0,0.9472328424453735
743578252,11331,dajac,2021-11-05T11:22:24Z,"yeah, i meant exactly that. how about using `assertpartitionsorder` helper? the assertion would be more complete.",0,0.9917530417442322
743578382,11331,dajac,2021-11-05T11:22:41Z,you could use `assertpartitionsorder` helper here as well.,0,0.9954620003700256
743578530,11331,dajac,2021-11-05T11:22:54Z,that is right.,0,0.9914423823356628
743745314,11331,dajac,2021-11-05T15:09:43Z,should we add or extend a test in `fetchertest` to cover this change? i would like to have one which ensure that the request sent is populated correctly (especially the replaced part) by the fetcher based on the session handler. it seems that we don't have such test in the suite at the moment.,0,0.9898244738578796
743749915,11331,dajac,2021-11-05T15:15:11Z,should we add a few unit tests to validate the changes that we have done in this class? we could add a few to fetchrequesttest (not use if it already exists though).,0,0.9941104054450989
743750508,11331,dajac,2021-11-05T15:15:55Z,do we have a unit test for this one and for `forgottentopics`?,0,0.994858980178833
743751246,11331,dajac,2021-11-05T15:16:48Z,there are a few more cases where we could put the partition data back on the previous line in this file.,0,0.992817759513855
743753319,11331,dajac,2021-11-05T15:19:17Z,"sorry, i wanted to say happen.",-1,0.9917893409729004
743753874,11331,dajac,2021-11-05T15:19:55Z,"anyway, we don't need to address this in this pr. i just wanted to point out that there is an opportunity for an improvement.",0,0.9837349653244019
743755936,11331,dajac,2021-11-05T15:22:10Z,do we have unit tests covering those cases? there are almost no changes in `abstractfetcherthreadtest` so it seems that we don't. are they somewhere else perhaps?,0,0.9935871362686157
743756690,11331,dajac,2021-11-05T15:23:01Z,i guess that we could remove it now.,0,0.9849814176559448
743759128,11331,dajac,2021-11-05T15:25:46Z,"should we use the same name for both `maybesetunknownname` and `mayberesolveunknownname`? i guess that you could differ by their argument. if we add unit tests for other methods of this class, should we cover all the methods that we have changed or added as well?",0,0.9925376772880554
743763229,11331,dajac,2021-11-05T15:30:37Z,do we have tests verifying this change?,0,0.9946032166481018
743764793,11331,dajac,2021-11-05T15:32:14Z,should we use `equals` instead of `==`? we use `equals` at l304 btw.,0,0.993894636631012
743830587,11331,jolshan,2021-11-05T16:56:46Z,so you are asking for a test that is checking the fetcher builds the request correctly? is this a test for the fetcher or the builder?,0,0.9941260814666748
743830862,11331,jolshan,2021-11-05T16:57:08Z,i can do that but it will take some time. :grinning_face_with_sweat:,1,0.9849164485931396
743836225,11331,dajac,2021-11-05T17:04:29Z,we should have a test in the fetcher which ensure that the builder received the correct information. then we could have one for the request which ensure that the builder does its job correctly as well.,0,0.9938451647758484
743839587,11331,jolshan,2021-11-05T17:09:17Z,"the part i don't understand is that this building is in a method that sends the requests. i'm not sure how to pull that out and test specifically that the fetcher is getting the correct info. the fetcher is simply pulling from the fetchsessionhandler's build fetchrequestdata, so i feel like that is sufficient unless i'm missing something.",0,0.9735784530639648
743841128,11331,jolshan,2021-11-05T17:11:26Z,"i thought about the same name, but i thought it was a slightly different approach --> looking up in the map where it is maybe there vs. supplying the name.",0,0.9883790016174316
743908454,11331,dajac,2021-11-05T18:56:22Z,"right. you might have to assert on the request in the fetcher as well. as you said, we can't really get the data out from the builder otherwise.",0,0.9898775219917297
743909554,11331,dajac,2021-11-05T18:58:13Z,"yeah, i agree with you. perhaps, we could just remove the maybesettopicname and move its logic into the update request params method.",0,0.980653703212738
743949497,11331,jolshan,2021-11-05T20:09:27Z,"ok, so we'll pass a name and the reqdata in that method.",0,0.994553804397583
743968305,11331,jolshan,2021-11-05T20:47:38Z,so i can write a separate callback for each one that checks the id.,0,0.9944819211959839
743973388,11331,jolshan,2021-11-05T20:58:27Z,"hmm, so this looks like another case of not having a test file for the java (unit test version) i can create that and add the tests you've been mentioning here. alternatively i can put the tests in the scala integration test file. seems like there are unit tests mixed in there too.",0,0.9783563017845154
743973792,11331,jolshan,2021-11-05T20:59:21Z,so #11459 doesn't touch the fetchsessionhandler code. but i can still add these cases.,0,0.9947357773780823
743976846,11331,jolshan,2021-11-05T21:06:19Z,"i don't think processfetchrequest is tested anywhere. there tests for the much higher level method dowork, so i can try to write one like that and check if there is that partition with error?",0,0.979712963104248
743977547,11331,jolshan,2021-11-05T21:07:56Z,"i think i have the same confusion here as i do for the fetcher tests. i agree that changes should be tested, but i'm not really sure how to do this here.",0,0.7821717262268066
743979130,11331,jolshan,2021-11-05T21:11:07Z,"i think for correctness either works, but i will switch to equals for consistency.",0,0.9640774726867676
743981159,11331,jolshan,2021-11-05T21:15:45Z,ah i'm already doing this. :grinning_face_with_sweat: ok. sounds good.,1,0.9904292821884155
743983833,11331,jolshan,2021-11-05T21:21:23Z,sorry i'm still a bit confused. the request is sent in this method. we don't get access to the request. we have access to the data that is tested in fetchsessionhandler and that is passed into this method where the request is built and sent.,-1,0.9883165955543518
743997732,11331,jolshan,2021-11-05T21:56:17Z,nice. this works well.,1,0.990755021572113
744103895,11331,dajac,2021-11-06T09:18:49Z,"we must be able to verify that the request sent out by this method is correct. in the unit tests, we mock the network client for this purpose. if i remember correctly, we can pass a request matcher to it. i need to look into the existing unit tests for this class to see how we have done it for other cases. we might already have tests verifying that the version of the fetch request sent out is correct based on wether topic ids are used or not. if we do, i suppose that we could proceed similarly.",0,0.9826929569244385
744104240,11331,dajac,2021-11-06T09:22:33Z,let's create that file and put new unit tests there. that is the way it should be.,0,0.9948914051055908
744138150,11331,jolshan,2021-11-06T15:41:50Z,got it. i guess i was wondering if there would be an issue if we change semantics/expected flow for fetch again.,0,0.9277243614196777
744138204,11331,jolshan,2021-11-06T15:42:12Z,confirmed this was a strange quirk from 4 years ago,-1,0.5203418731689453
744177445,11331,jolshan,2021-11-06T22:57:45Z,"seems like the other issue is that fetchsessionhandler.fetchrequestdata constructor is private. so if i want to test in another file i need to either make the constructor public, create a fetchsessionhandler and duplicate the code here, or just put the values into the builder directly (skipping the class). i'm open to just putting the values directly if that makes sense.",0,0.9833903908729553
744875433,11331,dajac,2021-11-08T16:10:05Z,`buildfetch` seems to be well isolated so it should be quite easy to write a few unit tests for it. `buildfetch` returns a `builder` so you will have to build the request in order to inspect it.,0,0.9766697883605957
744877634,11331,dajac,2021-11-08T16:12:31Z,"yeah, that should work. otherwise, we could also make the method package private and add a few unit tests for it.",0,0.9780339598655701
744880575,11331,jolshan,2021-11-08T16:15:40Z,i guess the part i didn't understand is that buildfetch's builder is tested in fetchsessionhandler tests. but i guess there is one more method call we can test.,0,0.9824913144111633
744883112,11331,jolshan,2021-11-08T16:18:27Z,is there a reason we do this? if the previous data had a topic id and this one doesn't we should send a different fetch request version and the session will be closed.,0,0.990535318851471
744892585,11331,dajac,2021-11-08T16:28:38Z,"without this, when a topic id is set back to ""zero"", the former topic id is added to the replaced set which is a bit unintuitive, i think. in the end, it does not matter too much because the version is downgraded in this case so the replaced set is ignored. i was debating if it worth handling this case explicitly here.",0,0.897065281867981
744905470,11331,jolshan,2021-11-08T16:43:11Z,"i realize we may still want this as if the partition data is exactly the same, we will actually ignore the downgrade which is not good.",-1,0.9110302329063416
744906035,11331,jolshan,2021-11-08T16:43:48Z,i have a test where this happens. :grinning_face_with_sweat:,1,0.9825368523597717
744942958,11331,dajac,2021-11-08T17:27:58Z,right. here i would like to have tests which ensure that the builder is fed correctly based on the fetchsessionhandler's data.,0,0.9919065237045288
745010308,11331,jolshan,2021-11-08T19:00:45Z,do we need to reassign to empty map here?,0,0.9920672178268433
745033891,11331,jolshan,2021-11-08T19:35:27Z,i added the initialization in the other builder since we were missing it.,0,0.9927878975868225
745050242,11331,dajac,2021-11-08T19:59:14Z,that is a good question. i thought that it is better to empty the map if we don't use topic ids instead of keeping a out-of-date mapping. what do you think?,1,0.960139274597168
745050475,11331,dajac,2021-11-08T19:59:35Z,thanks!,1,0.8631753921508789
745053425,11331,jolshan,2021-11-08T20:04:05Z,i think the session will already have an empty map or close but it don't think it makes a big difference with or without this change.,0,0.9617798328399658
745060151,11331,dajac,2021-11-08T20:14:32Z,i am not sure that i follow. we should only test the fetchrequest/builder in fetchrequesttest.,0,0.7216243743896484
745091391,11331,jolshan,2021-11-08T21:04:31Z,i ended up making the new test file. i was confused because i thought the data object needed to be tested but it doesn't. i think this can be resolved.,0,0.9436516165733337
745182731,11331,jolshan,2021-11-08T23:56:28Z,"for my understanding, is this line necessary? we are assigning the same topic partition, right?",0,0.9926324486732483
745478693,11331,dajac,2021-11-09T10:24:12Z,nit: it might be worth expanding this comment a little more.,0,0.9753761887550354
745487251,11331,dajac,2021-11-09T10:34:59Z,nit: could we use `assertequals`? the advantage is that it ensure that the map contains only what we want.,0,0.9884431958198547
745488238,11331,dajac,2021-11-09T10:36:18Z,nit: could we use `assertequals` here as well?,0,0.9904815554618835
745492071,11331,dajac,2021-11-09T10:41:12Z,nit: i wonder if doing the following would be a bit more complete? [code block],0,0.9718688130378723
745495072,11331,dajac,2021-11-09T10:45:06Z,"no, it is not. i kept it for completeness.",0,0.9897457361221313
745497189,11331,dajac,2021-11-09T10:47:49Z,nit: could we actually compare the content of both collections instead of only verifying their size? that would be more complete.,0,0.9548371434211731
745499051,11331,dajac,2021-11-09T10:50:23Z,"nit: in this case, we could actually do the following which seems a bit better: [code block] then, we can use `tp.topicpartition` when we need it. what do you think?",0,0.9640183448791504
745499747,11331,dajac,2021-11-09T10:51:11Z,nit: could we put this on the top of the test?,0,0.9907230734825134
745505533,11331,dajac,2021-11-09T10:58:49Z,"nit: would it be simpler to do the following? [code block] we have to use `new topicidpartition(topicid1, new topicpartition(null, 0))` because [a link] is not merged yet. the advantage of this way is that it test the whole map, including the ordering.",0,0.9854723811149597
745506626,11331,dajac,2021-11-09T11:00:14Z,"i am not sure that we gain much by testing this because testing `fetchdata` already verify that all the partitions are included, no?",0,0.7960814237594604
745511442,11331,dajac,2021-11-09T11:06:56Z,"this is a bit weird. i would have expected a `null` as the topic name if `topicnames` does not contain the mapping, no?",-1,0.9762524366378784
745512157,11331,dajac,2021-11-09T11:08:07Z,can't we use `assertequals`? it seems that it should work here.,0,0.9948444366455078
745515647,11331,dajac,2021-11-09T11:13:12Z,"as discussed, we must test this.",0,0.9929240942001343
745518340,11331,dajac,2021-11-09T11:16:58Z,nit: should we put `topicid` first to be consistent with `topicidpartition`'s constructor?,0,0.9909544587135315
745518525,11331,dajac,2021-11-09T11:17:17Z,could we add a unit test for this?,0,0.9941440224647522
745518658,11331,dajac,2021-11-09T11:17:30Z,could we add a unit test for this new method?,0,0.9947528839111328
745518818,11331,dajac,2021-11-09T11:17:43Z,could we add a unit test for this one as well?,0,0.9941877126693726
745571481,11331,dajac,2021-11-09T12:31:38Z,"nit: fyi, you could use an anonymous class in this case: ``` val fetcher = new mockfetcherthread(fetchbackoffms = fetchbackoffms) { override def fetchfromleader(fetchrequest: fetchrequest.builder): map[topicpartition, fetchdata] = { } }",0,0.9780338406562805
745576080,11331,dajac,2021-11-09T12:38:04Z,nit: a space is missing before `10`.,0,0.9888516068458557
745576158,11331,dajac,2021-11-09T12:38:10Z,ditto.,0,0.9384599328041077
745577596,11331,dajac,2021-11-09T12:40:05Z,nit: there is an extra space after `foreach(`.,0,0.9918206930160522
745580364,11331,dajac,2021-11-09T12:43:45Z,nit: i am not a fan of this. i would usually prefer something like the following in this case. i guess that it is a matter of taste so i leave it up to you. [code block],-1,0.8103383779525757
745595523,11331,dajac,2021-11-09T13:03:52Z,should we assert the content of `context2`?,0,0.9942601919174194
745595783,11331,dajac,2021-11-09T13:04:14Z,"i guess that `respdata1` is used by mistake here, isn't it? this is a good example why it is better to use `assertequals` to verify collections instead of iterating over them. the assertions that you have below have not caught this.",0,0.9835225939750671
745597673,11331,dajac,2021-11-09T13:06:56Z,`startswithtopicids` and `endswithtopicids` are a bit misleading here. i suppose that they refer to either the broker knows about the topic id or not (present in its metadata cache). am i right?,0,0.9439239501953125
745612156,11331,dajac,2021-11-09T13:25:35Z,nit: a space is missing before `{` and `}` should be on a new line for blocks.,0,0.9898120760917664
745612631,11331,dajac,2021-11-09T13:26:10Z,ditto about the code format.,-1,0.5431584715843201
745613827,11331,dajac,2021-11-09T13:27:41Z,"the size is implicitly verified by the next assertion. we could remove it, i guess.",0,0.9917266368865967
745613931,11331,dajac,2021-11-09T13:27:47Z,ditto.,0,0.9384599328041077
745615375,11331,dajac,2021-11-09T13:29:29Z,can't we use `assertequals` here?,0,0.9940861463546753
745686335,11331,dajac,2021-11-09T14:46:02Z,"thinking a little more about this one. how about doing the following? we could define an helper method `fetchmessages` which wraps `replicamanager.fetchmessages` (takes the same arguments) and returns `seq[(topicidpartition, fetchpartitiondata)]`. this would avoid all these callbacks that we have here.",0,0.9855419397354126
745693355,11331,dajac,2021-11-09T14:52:41Z,"should we do another round before this one to ensure that a partition would be removed from the context while still having an `incrementalfetchcontext`? we could perhaps have multiple partitions in the context, resolved and unresolved, and then we could remove them one by one.",0,0.9925464987754822
745699410,11331,dajac,2021-11-09T14:58:37Z,"should we pass `topicnamesforrequest1` instead of `topicnames` here? in practice, we already use the same mapping in all cases when the context is created.",0,0.9920318126678467
745701165,11331,dajac,2021-11-09T15:00:19Z,should we make it private?,0,0.9904842376708984
745701266,11331,dajac,2021-11-09T15:00:25Z,should we make it private?,0,0.9904842376708984
745751523,11331,dajac,2021-11-09T15:49:55Z,"should we verify what the context contains? this is very likely the most important point to verify in this test, no?",0,0.9931031465530396
745789936,11331,dajac,2021-11-09T16:25:51Z,i find those block of code really hard to read. i wonder if we could simplify them.,-1,0.9707556366920471
745863973,11331,jolshan,2021-11-09T17:47:25Z,is `assertmapequals` not already doing this? it seems like we check all entries and make sure there is nothing left over.,0,0.9918835163116455
745864456,11331,jolshan,2021-11-09T17:47:59Z,unless you are referring to the sessiontopicnames line. :grinning_face_with_sweat:,1,0.7641994953155518
745865347,11331,jolshan,2021-11-09T17:49:03Z,assertequals for the tosend/toreplace lists/map?,0,0.9948346614837646
745867608,11331,jolshan,2021-11-09T17:51:48Z,are we thinking this would be in the if block? or in a separate one outside?,0,0.9894431829452515
745869793,11331,dajac,2021-11-09T17:54:22Z,"yes, i was referring to `sessiontopicnames`.",0,0.9941020607948303
745869947,11331,dajac,2021-11-09T17:54:34Z,right.,0,0.9789980053901672
745871819,11331,dajac,2021-11-09T17:56:55Z,"yeah, that could remain in the if block. we could simply replaces those two lines, i guess.",0,0.9880052208900452
745924906,11331,jolshan,2021-11-09T18:58:38Z,i caught a bug with our partitiondata.equals method from implementing this. (we should be using .equals and not ==),0,0.9775870442390442
745925751,11331,jolshan,2021-11-09T18:59:58Z,"i was mostly testing the serialization here, but maybe that's not important? i can remove if we don't need that.",0,0.989421010017395
745930497,11331,jolshan,2021-11-09T19:06:49Z,the expectedname will be null if it is not in the map. map.get returns null if the id is not in the map.,0,0.9950295090675354
745941900,11331,jolshan,2021-11-09T19:23:09Z,"is this different than assertpartitionsorder(context2, seq(foo0, foo1, emptyzar0))?",0,0.9953254461288452
745942320,11331,jolshan,2021-11-09T19:23:44Z,i can change the ordering of these asserts so they are consistent with the earlier ones,0,0.9930989146232605
745943714,11331,jolshan,2021-11-09T19:25:42Z,you are correct. i can change to `startswithtopicidsinmetadatacache` etc if that is not too verbose.,0,0.9825121164321899
745947154,11331,jolshan,2021-11-09T19:30:38Z,would we pass in the topicidpartition we want to match as well?,0,0.9942449927330017
745963579,11331,dajac,2021-11-09T19:54:23Z,gotcha. i missed it. changing the order to be consistent makes sense.,0,0.9289447665214539
745965419,11331,dajac,2021-11-09T19:57:02Z,hum.. i was thinking that the method would return the partitions and we would do the assertion after. that would make the helper generic enough to be reused in other places as well. i guess that either ways would work.,0,0.9384297132492065
746038595,11331,jolshan,2021-11-09T21:01:47Z,oh so we wouldn't do the filter as part of the method?,0,0.9906935095787048
746051435,11331,dajac,2021-11-09T21:14:01Z,correct. the method would return the full response. then we can assert it.,0,0.989721953868866
746077096,11331,jolshan,2021-11-09T21:56:06Z,we can do that. i believe this is being tested via `testfetchsessionwithunknownid` already. but an explicit test will be good.,0,0.9740450978279114
746078020,11331,jolshan,2021-11-09T21:57:39Z,"i can add another one that is more explicitly testing this method, but it is tested via `testupdatedpartitionresolvesid`",0,0.9952526092529297
746096126,11331,jolshan,2021-11-09T22:28:59Z,"i think the issue with that approach is it doesn't quite cover the four cases, right? i could keep as is, but have a second partition that just uses ids and resolve that one on the second round.",0,0.9688500761985779
746100239,11331,jolshan,2021-11-09T22:36:15Z,hmm. could i also just remove the filter and do that after to use just the single callback?,0,0.9728828072547913
746217460,11331,jolshan,2021-11-10T03:15:51Z,"is this replacing `testupdatedpartitionresolvesid`? this is definitely cleaner, but i'm not sure we are covering the same cases here. for context, the test i mentioned before is testing different update scenarios (i probably named it poorly). mostly the idea is that the update method works correctly. (ie, we update a partition that once had a topic id to one that does not, etc). maybe that is covered in some of the other tests i've added (like `def maybeupdaterequestparamsorname`) and we can just remove that test. what do you think? i'll also think about this a bit more.",0,0.9341678619384766
746220127,11331,jolshan,2021-11-10T03:24:38Z,alternatively i can just rewrite this.,0,0.9886929392814636
746220311,11331,jolshan,2021-11-10T03:25:14Z,^ this is what i've done.,1,0.9285419583320618
746376488,11331,dajac,2021-11-10T09:05:48Z,"yeah, that works as well.",0,0.9832838773727417
746404173,11331,dajac,2021-11-10T09:29:25Z,"i wrote that test to illustrate how we could improve the readability. my concern is that they are so many lines/assertions in `testupdatedpartitionresolvesid` and `testtoforgetcases` that we get distracted and we have almost missed the most important assertions - the ones which validate what the session contains (`assertpartitionsorder`). `assertpartitionsorder` is actually the piece which ensures that the names are resolved or not, right?",0,0.813992440700531
746420015,11331,dajac,2021-11-10T09:47:54Z,"could we simplify all of that by defining two `topicidpartition`? for instance, we could have the following: [code block] then, we can use them where we need them.",0,0.9927358627319336
746423986,11331,dajac,2021-11-10T09:52:41Z,we usually prefer to not use `any*` but to rather provide the expected values.,0,0.9922671914100647
746425514,11331,dajac,2021-11-10T09:54:31Z,we have two paths (fetch from follower and fetch from consumer) in `handlefetchrequest` where we handle unknown topic names. should we parameterize the test to cover both of them?,0,0.9937859773635864
746433053,11331,dajac,2021-11-10T10:03:26Z,"i am not sure that i understand the value that we get out of this logic. `updateandgenerateresponsedata` creates a fetchresponse based on its input. therefore, the response that we assert is not so surprising in the end, right? it will contain `inconsistent_topic_id` if when the method gets it as an input. this logic would make sense for a test which verifies `updateandgenerateresponsedata` but looks like a distraction in a test which verify the name resolution logic. am i missing something here?",-1,0.8332570791244507
746433401,11331,dajac,2021-11-10T10:03:52Z,nit: you could use `assertequals` as it calls `equals`.,0,0.9892838001251221
746461644,11331,dajac,2021-11-10T10:38:21Z,i guess that it does not hurt to keep it.,0,0.9703903198242188
746783340,11331,jolshan,2021-11-10T16:45:20Z,"there are two places it may be resolved -- either in the update method if the partition with the new id is sent in the request or in the assertpartitionsorder. i was also trying to ensure the correct error messages are returned in the response specifically via `updateandgenerateresponsedata`, but maybe we don't care about this here?",0,0.9927545189857483
746785542,11331,jolshan,2021-11-10T16:47:42Z,i copied this from the test above. :grinning_face_with_sweat: wasn't sure if we wanted consistency amongst the tests.,1,0.6092368960380554
746789815,11331,jolshan,2021-11-10T16:52:21Z,"sure. we can remove it. i think i was concerned about the correct handling of the resolved partitions (ie, we get a response back that we can actually parse), but maybe that's not really necessary.",0,0.9696688055992126
746803000,11331,dajac,2021-11-10T17:06:46Z,"do you mean the correct handling of the resolved partitions by `updateandgenerateresponsedata`? i think testing `updateandgenerateresponsedata` is a good thing in general. perhaps, we should just put this into a separate test specific to that method? we should also test it for all context types with and without topic id, i guess.",0,0.6436609029769897
746805054,11331,dajac,2021-11-10T17:09:04Z,"right. the question is how to validate that the first update method works? you have to get the partitions from the session as well, isn't it?",0,0.9910573959350586
746807276,11331,jolshan,2021-11-10T17:11:51Z,i suppose so. i wonder if we should even include the update method at all then...,0,0.9730682373046875
746826740,11331,dajac,2021-11-10T17:35:47Z,what do you mean?,0,0.9906946420669556
746829235,11331,jolshan,2021-11-10T17:39:01Z,"if we always resolve when iterating through the partitions, then do we need to resolve via the update method?",0,0.9936621189117432
746836952,11331,jolshan,2021-11-10T17:49:20Z,is there a way to make such a test without duplicating the newcontext portions?,0,0.9941068887710571
746852321,11331,dajac,2021-11-10T18:01:40Z,"yeah, that is not really necessary as you said. i don't mind if you remove it.",0,0.923616349697113
746867390,11331,jolshan,2021-11-10T18:22:07Z,should this be a check when topic is null?,0,0.9911342263221741
746870544,11331,dajac,2021-11-10T18:26:06Z,that could be :grinning_face_with_smiling_eyes:,0,0.7911781072616577
746873252,11331,jolshan,2021-11-10T18:29:51Z,i've concluded that your new test will now cover the necessary cases (especially with your new commit) so i think we can just remove this.,0,0.9912279844284058
176640732,4756,ijuma,2018-03-23T05:14:32Z,we don't use logback for anything else. i'd suggest keeping it consistent with the project.,0,0.9929705262184143
176640868,4756,ijuma,2018-03-23T05:15:57Z,`scalalogging` is already defined in this file.,0,0.9946605563163757
176640906,4756,ijuma,2018-03-23T05:16:15Z,this is already defined in this file.,0,0.995421826839447
176645062,4756,debasishg,2018-03-23T06:02:06Z,done ..,0,0.992914080619812
176645077,4756,debasishg,2018-03-23T06:02:13Z,removed.,0,0.9612457156181335
176645090,4756,debasishg,2018-03-23T06:02:21Z,removed.,0,0.9612457156181335
176799631,4756,guozhangwang,2018-03-23T16:56:25Z,do we need to import these two dependencies? could we use kafka's own embeddedkafkacluster?,0,0.9937880635261536
176799962,4756,guozhangwang,2018-03-23T16:57:34Z,does it worth to include this dependency at test runtime? cc .,0,0.9952844977378845
176800608,4756,guozhangwang,2018-03-23T16:59:42Z,could we add the default for short and bytebuffer as well?,0,0.994848906993866
176801533,4756,guozhangwang,2018-03-23T17:02:47Z,i'm wondering if we could provide default serdes for windowed key as well? see `o.a.k.streams.kstream.windowedserdes` for java code.,0,0.9904558062553406
176802156,4756,guozhangwang,2018-03-23T17:05:08Z,nit: how about rename to `flatvaluemapperfromfunction` for better understanding? ditto below.,0,0.9828886985778809
176802758,4756,guozhangwang,2018-03-23T17:06:56Z,"just for my own education: is it necessary to add `, _` in the end? what are the possible classes we want to still include?",0,0.9896474480628967
176803277,4756,guozhangwang,2018-03-23T17:08:49Z,nit: newline for the second parameter.,0,0.9956815242767334
176805401,4756,guozhangwang,2018-03-23T17:16:14Z,why we can ignore the topic here? ditto below?,0,0.9896975159645081
176806499,4756,guozhangwang,2018-03-23T17:20:01Z,"nit: `long2long(_)` to be consistent with others? actually, do we need to explicitly call it? i thought it will be implicitly triggered anyways from `predef`.",0,0.9641512036323547
176809033,4756,guozhangwang,2018-03-23T17:28:54Z,"could we add this syntax sugar in the implicit conversion so all classes like `kgroupedstream`, `ktable` and `streamsbuilder` can use it?",0,0.9947528839111328
176809497,4756,guozhangwang,2018-03-23T17:30:34Z,why do we need the `asvaluemapper` here explicitly? ditto below.,0,0.9891918301582336
176812165,4756,guozhangwang,2018-03-23T17:39:43Z,"do we have to convert two parameters to a tuple and then apply the function.tupled? i'm asking this because this is on the critical code path (called per map per record), and if there is non-negligible overhead..",0,0.9910027980804443
176812703,4756,guozhangwang,2018-03-23T17:41:40Z,"no `scalastyle:off null` before, is this intentional?",0,0.9932975172996521
176812967,4756,guozhangwang,2018-03-23T17:42:37Z,nit: space after comma.,0,0.9803071618080139
176816332,4756,guozhangwang,2018-03-23T17:53:26Z,"is it a syntax sugar as `branch`? i'd prefer to keep java and scala interfaces consistent, so that if we think it is worthwhile we'd better add it in java apis as well, otherwise we should remove it from scala apis. wdyt?",0,0.9908981919288635
176817831,4756,guozhangwang,2018-03-23T17:57:29Z,"this is a deprecated api in java, we should replace it with materialized.",0,0.99221271276474
176819139,4756,guozhangwang,2018-03-23T18:01:58Z,nit: default to `info`?,0,0.9898276329040527
176819498,4756,guozhangwang,2018-03-23T18:03:20Z,the file `logs/kafka-server.log` seems not appropriate as it is not for kafka broker logs right?,0,0.9933294057846069
176820184,4756,guozhangwang,2018-03-23T18:05:54Z,"this is a meta comment: i'd suggest we consider adding logback generally for kafka, instead of sneaking in for streams scala wrapper. we can still use log4j for now. see [a link] cc",0,0.9836709499359131
176897781,4756,debasishg,2018-03-24T03:00:43Z,this library `scalatestembeddedkafka` has a nice integration with scalatest. hence it makes writing tests easier and we don't have to bother starting / managing the embedded kafka instance. the test code becomes very concise.,1,0.9239033460617065
176897811,4756,debasishg,2018-03-24T03:02:24Z,it's only to demonstrate custom serdes. we picked up avro since (afair) suggested this example in one of the earlier pr discussions. this example goes to show that custom serdes can be handled as seamlessly as primitive ones.,0,0.9901357293128967
176897854,4756,debasishg,2018-03-24T03:05:35Z,we need this for sam type conversion which is not fully supported in scala 2.11. in scala 2.12 we don't need this. this code base runs both in scala 2.11 and scala 2.12.,0,0.9935316443443298
176898091,4756,debasishg,2018-03-24T03:18:32Z,"the `, _` takes care of the other imports that don't need to be renamed like `serialized`, `joined` etc.",0,0.9933809041976929
176898176,4756,debasishg,2018-03-24T03:23:51Z,don't find the `topic` being used in de-serializer implementations e.g. [a link],0,0.9897406101226807
176898673,4756,debasishg,2018-03-24T03:40:43Z,"we need to call it explicitly. `predef` has an implicit conversion between `long` and `java.lang.long` but not between `ktable[k, long]` and `ktable[k, java.lang.long]` which we are dealing with here.",0,0.9909374713897705
176899296,4756,ijuma,2018-03-24T04:05:50Z,"yes, let's stick to log4j in this pr.",0,0.9932425618171692
176899431,4756,debasishg,2018-03-24T04:10:36Z,this may not be relevant here. we were using scalastyle plugin with sbt. guess we can ignore it for now.,0,0.9792394638061523
176899457,4756,debasishg,2018-03-24T04:11:36Z,maybe we can have a `package object` with such stuff that can be reused across abstractions. better than repeating for every class. will do this.,0,0.9820960760116577
176899731,4756,debasishg,2018-03-24T04:27:28Z,we can add the following: [code block] but this one also may be useful when the user just needs to pass in the `keyserde`. she need not construct any `materialized` which is abstracted within the implementation of the api. suggestions ?,0,0.9941297769546509
176899763,4756,debasishg,2018-03-24T04:29:11Z,should we remove `logback.xml` ?,0,0.9950148463249207
176928234,4756,guozhangwang,2018-03-25T04:15:10Z,generally speaking ak repo tend to avoid dependencies unless it is necessary. i'm wondering if we can improve on kafka's own embeddedkafkacluster to have the same functionalities as the `net.manub:scalatest-embedded-kafka-streams`.,0,0.9795622825622559
176928257,4756,guozhangwang,2018-03-25T04:17:34Z,"are these interfaces only used for built-in primitive types, or are they going to be extended by users for their own serdes, like avro? if it is the latter case we cannot enforce users to always ignore the topic.",0,0.9886305332183838
176928265,4756,guozhangwang,2018-03-25T04:18:35Z,ack. makes sense. scala `predef` is not as smart as applying to nested types yet.,0,0.9173674583435059
176928266,4756,guozhangwang,2018-03-25T04:18:57Z,ack.,0,0.5866091847419739
176928367,4756,guozhangwang,2018-03-25T04:28:27Z,"i'd vote for keeping java / scala api consistent, and we are going to remove deprecated apis in future releases anyway. in current api we'd only have one additional overload: [code block] i think for users who do not want to specify the store name at all, they can rely on [code block] to still hide the `materialized` parameter with implicit conversion. for users who do want to specify the store name, but want to rely on type conversion, we could call `withkeyserde` and `withvalueserde` internally in the implicit conversion so that user only need to give `materialized.as(storename)` does that work?",0,0.9631775617599487
176928378,4756,guozhangwang,2018-03-25T04:28:53Z,"yup, please remove that file as well.",0,0.9901131391525269
176929613,4756,debasishg,2018-03-25T05:46:27Z,"we can definitely use kafka's own `embeddedkafkacluster` to integrate with scalatest. in `net.manub:scalatest-embedded-kafka-streams`, the main value add is integration with scalatest and hence you don't have to explicitly start / stop server as part of the test. also with kafka streams it has very nice constructs like the one we use here .. [a link] .. note you just have to define the transformations and do the publish and consume as part of a closure. no need to start / stop the topology. hence the test code becomes very concise. of course it depends on the opinion of the committee but i think this would be a great addition to the dependency. here's a suggestion .. we use `net.manub:scalatest-embedded-kafka-streams` for now. after all it's a *test* dependency. and work on a separate pr to make the integration between `embeddedkafkacluster` and scalatest better and in line with the functionalities offered by the library. wdyat ?",0,0.5965715050697327
176930041,4756,debasishg,2018-03-25T06:12:10Z,+1 .. will remove this overload for `count`.,0,0.9902299046516418
176931307,4756,debasishg,2018-03-25T07:21:36Z,the implementation [a link] is only for *stateless* serdes implementation where nothing gets stored in topics. for stateful implementation involving topics the user can provide her own implementation of `scalaserde`. we provide this as a reference implementation of stateless serdes that we use in implementing `avroserde` in the test. of course we can decide if we should bundle this as part of the source or test. but we thought that the implementation may be useful to users implementing stateless custom serdes. thoughts?,0,0.9833381772041321
176931378,4756,debasishg,2018-03-25T07:25:00Z,+1,0,0.9816582202911377
176931381,4756,debasishg,2018-03-25T07:25:14Z,+1,0,0.9816582202911377
176931387,4756,debasishg,2018-03-25T07:25:27Z,+1,0,0.9816582202911377
176931389,4756,debasishg,2018-03-25T07:25:38Z,+1,0,0.9816582202911377
176931394,4756,debasishg,2018-03-25T07:25:56Z,+1,0,0.9816582202911377
176931402,4756,debasishg,2018-03-25T07:26:13Z,+1,0,0.9816582202911377
176931414,4756,debasishg,2018-03-25T07:26:42Z,will change the name to `kafka-streams-scala.log`,0,0.9945806860923767
176931419,4756,debasishg,2018-03-25T07:26:52Z,+1,0,0.9816582202911377
176985739,4756,mjsax,2018-03-26T05:49:58Z,nit: those are actually sorted alphabetically -- can we clean this up? thx.,0,0.7889970541000366
176985752,4756,mjsax,2018-03-26T05:50:06Z,as above.,0,0.9881609678268433
176986121,4756,mjsax,2018-03-26T05:54:10Z,"should we add those exclusions? i know that we put exclusions when introducing findbugs because it is not possible to introduce it and rewrite all the code -- but for new code, we should consider changing the code. i am not a scale person though -- can you elaborate on this?",0,0.9877408146858215
176986532,4756,mjsax,2018-03-26T05:58:09Z,should this be `bytearraykeyvaluestore`? -- we don't use abbreviations in the java code base.,0,0.9927269220352173
176987291,4756,mjsax,2018-03-26T06:05:20Z,why do we need an `asinstanceof` here? (same below),0,0.9933660626411438
176987359,4756,mjsax,2018-03-26T06:05:52Z,why do we not import `bytes` ?,0,0.9897834658622742
176987713,4756,mjsax,2018-03-26T06:09:03Z,"nit: should we use `[k, v, vr]` as in java?",0,0.9918074011802673
176988085,4756,mjsax,2018-03-26T06:12:20Z,nit: name `v` instead of `vr` ?,0,0.9908210635185242
176988134,4756,mjsax,2018-03-26T06:12:39Z,nit: name `v` instead of `t` ?,0,0.9913773536682129
176988730,4756,mjsax,2018-03-26T06:16:53Z,nit: `kvo` -> `keyvalueother` ?,0,0.9935613870620728
176988977,4756,mjsax,2018-03-26T06:19:03Z,"for my own education. what is a ""stateless serde"" ?",0,0.9539200663566589
176989413,4756,mjsax,2018-03-26T06:22:09Z,"nit: remove spaced -> `{keyvalue, consumed}`",0,0.9939232468605042
176989878,4756,mjsax,2018-03-26T06:26:05Z,this should only take 4 parameters. we simplified the api and this method is deprecated (cf. [a link],0,0.9934446811676025
177137368,4756,debasishg,2018-03-26T15:39:23Z,+1 ..,0,0.9806662201881409
177184454,4756,mjsax,2018-03-26T18:09:25Z,"nit: i am not a fan of adding links in javadocs, because links might break; better reference to the corresponding class as javadoc cross reference? also: i am wondering if we should remove this method from the wrapper in the first place? imho, it's not a good idea to add deprecated api in new code?",-1,0.9627038836479187
177185072,4756,mjsax,2018-03-26T18:11:39Z,"a `valuetransformer` also have `init()`, `punctuate()` and `close()` method. why is this code much simpler than the wrapper for `transform()` above?",0,0.9901651740074158
177185869,4756,mjsax,2018-03-26T18:14:29Z,"as above. what about `init()`, `punctuate()`, and `close()` ?",0,0.9948023557662964
177188532,4756,mjsax,2018-03-26T18:23:14Z,"i agree that both apis should be consistent. does a `split` add much value compare to `branch`? btw, this might be related to [a link] i am also open to add a `split()` if we think it's useful.",0,0.956544816493988
177189344,4756,mjsax,2018-03-26T18:26:04Z,why do we only allow to specify a `keyserde` but not replace the store with a different one? scala noob question: would it be possible to have a single `count` / `reduce` etc instead of overloads and use `option` and implicits to infer optional arguments?,0,0.9862215518951416
177201338,4756,seglo,2018-03-26T19:06:51Z,"i'm a fan of `net.manub:scalatest-embedded-kafka-streams`, but i understand the concern about bringing in more deps. i only mentioned it on the dev-kafka list because i didn't think there was much value in improving the embedded kafka implementation in `kafka-stream-scala` and making it a public interface because `scalatest-embedded-kafka` already existed. i wasn't aware of `embeddedkafkacluster`. if `scalatest-embedded-kafka` were brought into the project then there will be drift between the version of kafka broker in code and whatever this test lib references. i like your suggestion: perhaps we can do this now for this pr, but keep it simple. i could work on it if you're busy.",1,0.849722146987915
177206327,4756,vvcephei,2018-03-26T19:25:44Z,"i'd like to confirm that this option is actually safe. is this a best practice at this point for targeting 2.11? also, how can we know we're not dragging in other (potentially unwanted) experimental compiler features with this?",0,0.9736033082008362
177206719,4756,vvcephei,2018-03-26T19:27:21Z,"cool. in that case, maybe we should also add 'streams:streams-scala:examples' and put it there?",1,0.9623433947563171
177207156,4756,vvcephei,2018-03-26T19:28:57Z,nit: this is a bit cumbersome. can we do project(':streams:scala-wrapper') and archive: 'kafka-streams-scala-wrapper' or some such instead?,-1,0.8427081108093262
177210106,4756,vvcephei,2018-03-26T19:39:58Z,"i have used `net.manub:scalatest-embedded-kafka-streams` before, and it *is* very nice. but i also worry about adding dependencies to the core project, even test deps. if our tests become a bit uglier, or if we have some test-util class that duplicates some of the functionality you're using, i would consider that to be a worthy tradeoff for dropping the dependency. i would absolutely support planning to come back in a follow-up pr to build out support for testing scala code and then terraforming these tests to use the new support. or even delaying this pr until a test-support one is available.",1,0.84428471326828
177211622,4756,vvcephei,2018-03-26T19:46:08Z,"i think it's because we're presenting the `serde[java.lang.long]` as a `serde[scala.lang.long]`, but casting the serde won't automatically cast the parameters and returns of its methods. i'm surprised you don't get cast class exceptions trying to use the java long serde as a scala long serde. unless i'm wrong about what this is for...",0,0.9171948432922363
177214912,4756,vvcephei,2018-03-26T19:58:11Z,"+1 on not including this method in the wrapper. the code that would use this library is not written yet, so it's better if deprecated methods are simply not available.",1,0.5744851231575012
177215699,4756,vvcephei,2018-03-26T20:00:27Z,i agree.,0,0.9653030633926392
177222153,4756,ijuma,2018-03-26T20:23:09Z,"there is no such thing as a `scala.long` at runtime, scala changed to use the same classes as java for boxing around the 2.8 timeframe if i remember correctly. previously there was a `richlong`, `richint`, etc. in any case, this seems like a variance issue, but i didn't look into it.",0,0.9873720407485962
177225591,4756,seglo,2018-03-26T20:35:21Z,"this seems to be a false positive. findbugs is reporting that `serializer` and `deserializer` should be defined as a different type name than what it's inheriting. iirc the consensus earlier is that we want type names the same as the base types they're wrapping (which includes traits and interfaces imo). i've updated the findbugs rule exclusion to be specific to the types generating the violation, rather than the entire `scalaserde` file.",0,0.9824156165122986
177227080,4756,seglo,2018-03-26T20:40:17Z,"i assume it was to disambiguate with `serdes.bytes`, but that's not a problem. i'll update it.",0,0.9896809458732605
177227812,4756,seglo,2018-03-26T20:42:47Z,i've renamed the type param to `va` to match the java dsl.,0,0.9946919083595276
177228111,4756,seglo,2018-03-26T20:43:44Z,i've renamed the type param to `va` to match the java dsl. is that ok?,0,0.9927680492401123
177228492,4756,guozhangwang,2018-03-26T20:45:05Z,thanks for your thoughts. we do have plans to publish testing-util artifacts inside ak in the future. and in fact we have been doing so for kafka-streams module as a first step and going to do that for kafka-core and kafka-clients soon. in kafka-clients testing utils we are going to include some improved version of embeddedkafkacluster for users to easily write their integration tests that involve interacting with a mock a kafka cluster. so i'd suggest we stay with the uglier implementation with the existing embedded kafka cluster and not bring in the dependency.,1,0.9427955150604248
177230451,4756,guozhangwang,2018-03-26T20:51:18Z,"i see. i guess i was a bit misled by the name itself: i was thinking ""stateless"" is for the stateless operators in kafka streams dsl, and thinking the inclusion of topic name or not does not necessarily depend on whether the serde is used for stateful or stateless operations. your explanation makes sense now. maybe we can add some comments on top of `statelessserde` claiming that this serde class is used for serde where topic names does not affect the serde logic, i.e. topic name will be ignored. if users need some serde mechanism that does differentiate on topic names, please implement the other underlying `serde` interface.",0,0.9095990657806396
177231716,4756,guozhangwang,2018-03-26T20:55:24Z,it is discussed in [a link] i think the name `stateless` may be a tart misleading but i cannot come up with a better name yet.,0,0.9784761071205139
177232798,4756,guozhangwang,2018-03-26T20:59:16Z,"i'm a bit on the fence for introducing avro as ""the one"" serde in our demonstration examples rather than keeping kafka and avro separate, since there are many protobufs / etc fans in the community. how about adding avro examples in eco-system repos, e.g. in lightbend / confluent / etc's own examples repo they can add their own example? cc",-1,0.7012054920196533
177238405,4756,seglo,2018-03-26T21:19:47Z,"i agree it looks concerning, i'll need to check what other potential features this brings in, unfortunately there's no way to be more specific about just enabling sam type conversion afaik. we could remove this flag, but we would need to desugar all the places where conversions occur.",-1,0.8084291815757751
177268099,4756,mjsax,2018-03-26T23:44:21Z,"maybe `simpleserde` as name ? ""stateless"" seems to be confusing.",0,0.9587918519973755
177268698,4756,mjsax,2018-03-26T23:47:33Z,+1 sounds reasonable to me.,0,0.9511469006538391
177289406,4756,debasishg,2018-03-27T02:19:29Z,- cool .. then we can remove the test `streamtotablejoinscalaintegrationtestimplicitserdeswithavro` and the dependencies from `build.gradle` .. ok ?,1,0.5864779353141785
177289806,4756,debasishg,2018-03-27T02:21:20Z,"for the time being, we can remove `split` from the scala api and rethink if / when it's implemented as a java api",0,0.9921761155128479
177290643,4756,debasishg,2018-03-27T02:28:37Z,in scala there's an implicit conversion between `scala.long` and `java.lang.long` but not between `serde[scala.long]` and `serde[java.lang.long]` - hence the cast. in fact picked this trick from [a link],0,0.9920269846916199
177296715,4756,debasishg,2018-03-27T03:19:43Z,"- i think i may be missing something here. we are allowing the user to pass in the `store` *and* `keyserde`. and we create the `materialized` out of the 2 with `long` as the value serde. however we were allowing the user to pass in the `keyserde` optionally and in case the user does not supply one we assumed it will be taken from the config. this is actually a remnant from the earlier thoughts where we thought passing serdes through config may be a good idea. however in the current context, we should not make `keyserde` optional. here's the suggestion for the changed api .. [code block] an alternative option could have been to allow the user to pass in the `materialized` instance itself (like we do in the `reduce` function). the problem with that alternative is that the java api expects `java.lang.long` as the value serde, while the scala api needs to take a `scala.long`. and there is no way we can convert a `materialized.as[k, scala.long, bytearraykeyvaluestore]` to `materialized.as[k, java.lang.long, bytearraykeyvaluestore]` without a cast. hence the divergence in the api signature between `count` and `reduce`. please share if u have any other thoughts.",0,0.9256147742271423
177297602,4756,debasishg,2018-03-27T03:24:58Z,"hi - regarding the above, we had a discussion on the 2 approaches on this thread only and the universal suggestion was to use the same name across scala and java apis. in fact in the initial version that we posted, we had different names (`kstream` / `kstreams`). the reasoning of using the same names is that the renaming of imports in the user code needs to be done only very occasionally when we mix usage of scala and java apis.",0,0.9556611180305481
177305370,4756,debasishg,2018-03-27T04:29:40Z,"here, the deprecation is on `punctuate`, which is part of the contract of `transformer`. how do we remove this ? we can *only* remove this when `punctuate` is removed from `transformer` ? or am i missing something ?",0,0.9917826652526855
177306580,4756,debasishg,2018-03-27T04:41:33Z,we don't need to provide implementation of `valuetransformer` here since the passed in `() => valuetransformer[a link] for sam type conversions in scala.,0,0.9946079254150391
177306659,4756,debasishg,2018-03-27T04:42:17Z,same logic as `valuetransformer` above.,0,0.9896907806396484
177320316,4756,debasishg,2018-03-27T06:34:09Z,thanks for your thoughts .. we will remove the dependency on `net.manub:scalatest-embedded-kafka-streams` and use `embeddedkafkacluster` instead.,1,0.944520115852356
177420275,4756,seglo,2018-03-27T13:20:12Z,"there's no list of what's brought in with the experimental flag, unless you grep the compiler code. the purpose of the sam type conversion feature in 2.11 was only to get early feedback and only properly finished in 2.12. as its name suggests it's not meant to be used in production code. since kafka is still targeting 2.11 it makes sense to not include this flag to build a releasable artifact. i'll remove the flag and desugar the conversions.",0,0.992378830909729
177438559,4756,vvcephei,2018-03-27T14:10:55Z,"thanks for the explanation, i missed that discussion. sorry to bring it back up! thanks! am i correct in thinking that only affects our code, and not our users' code? i.e., if they are using 2.12, they can pass in lambdas as arguments, right?",1,0.9106988906860352
177440570,4756,seglo,2018-03-27T14:16:01Z,"yes, this change won't affect end users at all. if kafka drops scala 2.11 support then we can bring back the sam conversions as they're available without any ominous compiler flags.",0,0.9895007014274597
177441103,4756,vvcephei,2018-03-27T14:17:26Z,"huh! well, that explains it. i have seen the conversions of the raw types, and also suffered from type errors that `serde[scala.long]` != `serde[java.lang.long]`, so i just assumed that `scala.long` was a different class than `java.long`. thanks for the explanation, .",1,0.991692066192627
177442727,4756,vvcephei,2018-03-27T14:21:33Z,"oh, right, i thought this was one of your scala replacement classes. what i have been doing for cases like this is throwing an `unsupportedoperationexception` in the body. it's not as good as not having the method, but it def. ensures it can't be used. and you don't have to maintain the code that's in the body.",0,0.9571526050567627
177449950,4756,vvcephei,2018-03-27T14:40:09Z,"that makes sense. my 2 cents: we're presenting the scala kgroupedstream basically *as* the java one, but not implementing the interface so that we can smooth over a couple of specific gaps. i think this is a good call, but it's also a huge risk for cognitive dissonance and developer confusion, since they will read the java version of the docs and try to use that knowledge in scala. therefore, it's important to be super disciplined about making sure the methods available are as close to the java interface as possible. clearly, moving serdes, etc., to implicit params is the kind of thing we *do* want to do. but i think that presenting `count(string,serde[k])` instead of `count(materialized[k, long, keyvaluestore[bytes, array[byte]]]` is too far off. i do agree that the method should take a scala type. apparently, it's perfectly fine to cast `serde[scala.long]` to `serde[java.long]`. does that same logic apply here? alternatively, we can actually convert the `materialized[java]` to a `materialized[scala]`.",0,0.6707620024681091
177457781,4756,debasishg,2018-03-27T15:00:05Z,.. sure we can do the following instead .. [code block] wdyt ?,0,0.985225260257721
177531590,4756,vvcephei,2018-03-27T18:44:36Z,"ok, i'm already a little nervous about the cast in one direction, so this feels super gross, but would this work? [code block] please understand i'm wincing as i type this.",-1,0.9953308701515198
177532059,4756,mjsax,2018-03-27T18:46:17Z,"well, we allowing to pass in a store ""name"" (string) but not a store. note, that `materialized` allows to replace default rocksdb with an in-memory story, disable change-capture-logging or even use a custom store implementation.",0,0.9948630928993225
177532408,4756,guozhangwang,2018-03-27T18:47:27Z,sounds good.,1,0.857205867767334
177532680,4756,guozhangwang,2018-03-27T18:48:20Z,sounds good.,1,0.857205867767334
177533039,4756,guozhangwang,2018-03-27T18:49:18Z,that sounds better.,0,0.9714751243591309
177534627,4756,debasishg,2018-03-27T18:54:13Z,how about the api that i suggested above ? it takes materialized much like the java api though we need a cast. - in my implementation we have 1 cast and the other map for the long conversion in ktable.,0,0.9940862655639648
177537597,4756,mjsax,2018-03-27T19:04:24Z,i understand that you cannot change the java `transformer` interface and must implement the deprecated method when calling `new transformer` -- what i was wondering is about `scala.transformer` interface -- should we add one and remove `punctuate` from it?,0,0.992753803730011
177540520,4756,vvcephei,2018-03-27T19:13:02Z,"sorry, i should have acked your implementation. i was actually proposing an evolution of it. it just seems a bit unfortunate to have to add a real function invocation to the topology in order to do the cast back to `scala.long`. the version i proposed just does a cast back out without adding anything new to the topology. does that make sense? at the risk of sounding like an idiot, if it's fine to do the cast on the way in, then it should be fine again on the way out, right?",-1,0.9897513389587402
177542082,4756,vvcephei,2018-03-27T19:17:17Z,"fwiw, i think adding a new scala interface just to remove a method that we plan to remove from the java interface is not necessary. better just to implement it and move on. also, it would be a bit trickier to swap in a scala replacement for `transformer` than for the top-level dsl classes, since implementations of the java `transformer` won't implement the scala `transfomer`, so you wouldn't be able to plug them in via the scala dsl wrapper. but there's otherwise no reason this shouldn't work.",0,0.9671049118041992
177554002,4756,mjsax,2018-03-27T20:01:50Z,"ack. was just an idea. i don't really speak scala (yet) -- this is an exercise to learn something about it... if we need to have it, i vote to throw an exception to forces users to use the new api.",-1,0.8777768611907959
177564717,4756,mjsax,2018-03-27T20:39:26Z,"this and all other classes are public api. thus, we should improve the javadocs for those classes and also add javadocs for all methods. i guess we can c&p from existing java classes.",0,0.9917908906936646
177636021,4756,debasishg,2018-03-28T04:25:29Z,- cast is a runtime operation and my philosophy is to minimize its use. and `scala.predef` indeed uses `long2long` to do such conversions. hence i would like to prefer using proper functions when available instead of the cast.,0,0.9806411266326904
177638616,4756,debasishg,2018-03-28T04:56:34Z,"ok, will remove `split` from `kstream` for now.",0,0.9939793348312378
177660176,4756,debasishg,2018-03-28T07:32:08Z,renamed to `simplescalaserde` ..,0,0.994888961315155
177660317,4756,debasishg,2018-03-28T07:32:45Z,removed!,0,0.9750316739082336
177662427,4756,debasishg,2018-03-28T07:42:53Z,- looking for suggestions. should we copy/paste javadoc from java classes or use `` annotation ? the problem with copy is maintenance - when one changes someone needs to be careful enough to change the other.,0,0.9695023894309998
177685679,4756,debasishg,2018-03-28T09:12:55Z,- removed all dependencies on `net.manub:scalatest-embedded-kafka` and `net.manub:scalatest-embedded-kafka-streams`. now using `embeddedkafkacluster` instead for tests. also removed the test that used avro - hence dependency on `avros` eliminated.,0,0.9748884439468384
177793180,4756,deanwampler,2018-03-28T15:34:39Z,"a little more detail; what this import is saying is ""import these items, but give them an alias, then import everything else without an alias"".",0,0.9925926327705383
177826543,4756,guozhangwang,2018-03-28T17:22:58Z,thanks !,1,0.8865044713020325
177950361,4756,mjsax,2018-03-29T04:19:27Z,good question. not sure. i agree that maintaining javadocs twice is a hassle and error prone. but might be annoying for user if it's only linked on the other hand. would be good to hear what others thing. \cc,1,0.9596848487854004
178029830,4756,seglo,2018-03-29T11:41:02Z,"adding javadocs to all the public api methods in the pr is the same amount of work any way we do it. from an end user perspective i agree it would be nice to have the same (or slightly tweaked, as necessary) javadocs for all public api methods, plus a `` or `` tag to the corresponding java api method. it will be a small burden to maintain it going forward so i defer to the ak committers to make the call on the format.",0,0.9221129417419434
178136346,4756,guozhangwang,2018-03-29T18:01:06Z,"i'd vote for using `` and `` to avoid maintaining two copies, because we have some public classes following this pattern in the repo (like [a link] and from the past i find most people would not remember or bother to update two places than one. i think the web docs (in `docs/streams`) needs to be updated as well, especially in the `upgrade-guide.html` page, as well as the `streams-api` page.",0,0.9813380241394043
178136538,4756,guozhangwang,2018-03-29T18:01:48Z,"for `streams-api` page above, i meant [a link]",0,0.9953645467758179
178139790,4756,ijuma,2018-03-29T18:13:51Z,"some thoughts: - i think the consumer and kafkaconsumer pattern is bad. the documentation should have been on `consumer` instead. the `adminclient` follows the latter pattern. - i think it's a poor user experience to ask users to read the docs in the java class. my recommendation would be to at least include a short description in the scala docs along with a link to the relevant java documentation. the short description is less likely to change and it helps users make progress without having to jump to the java code all the time. however, for more detailed information (which is more likely to change), they can check the java code.",0,0.4707898497581482
178448558,4756,mjsax,2018-04-01T05:20:06Z,"i tend to agree with comment about `kafkaconsumer`/`consumer` pattern -- it's quite annoying to not get the javadocs directly. thus, even if it's a burden it seems to be worth to maintain two copies.",-1,0.9560397267341614
178450057,4756,debasishg,2018-04-01T07:16:38Z,- i have started writing the scaladocs in the commit [a link] .. pls review if it's following the correct pattern,0,0.9873346090316772
178976326,4756,guozhangwang,2018-04-03T22:07:53Z,nit: period at the end of the sentence.,0,0.9889662861824036
178976444,4756,guozhangwang,2018-04-03T22:08:35Z,maybe mention again which artifact to include in order to import this package.,0,0.9914754629135132
178976955,4756,guozhangwang,2018-04-03T22:11:09Z,we do not need indentation in the code block; the following code blocks are formatted correctly.,0,0.9949958324432373
178977137,4756,guozhangwang,2018-04-03T22:12:07Z,this is not introduced in this pr: duplicated `provides`.,0,0.9955191612243652
179201680,4756,seglo,2018-04-04T16:20:47Z,"i fixed the typos in this line, but i'm not sure what you mean by it not being introduced in this pr. this line is to indicate the presence of the kafka streams dsl for scala library.",0,0.9871568083763123
179202074,4756,seglo,2018-04-04T16:22:13Z,i copied the formatting from the streams main page which indented the wordcount examples: [a link],0,0.9936164617538452
179202109,4756,seglo,2018-04-04T16:22:22Z,:+1:,0,0.9328674077987671
179202130,4756,seglo,2018-04-04T16:22:28Z,:+1:,0,0.9328674077987671
179202465,4756,seglo,2018-04-04T16:23:36Z,i removed the initial indentation for this example on this page to make it consistent with the others.,0,0.9905919432640076
179268477,4756,guozhangwang,2018-04-04T20:15:02Z,"i meant the duplicated `provides` exist before this pr, so it is not a regression introduced from this pr.",0,0.9894423484802246
181648477,4756,mjsax,2018-04-16T07:54:15Z,"""is available here"" is bad phrasing. `here` -> `in the developer guide`",-1,0.8493378758430481
181649571,4756,mjsax,2018-04-16T07:58:35Z,`to include it your maven` -- sounds weird,-1,0.9811428785324097
181649928,4756,mjsax,2018-04-16T08:00:05Z,i am wondering if this is correct? should the scala version not be included here?,0,0.9050021767616272
181650115,4756,mjsax,2018-04-16T08:00:56Z,"don't we need the scala version, here?",0,0.9910249710083008
181650350,4756,mjsax,2018-04-16T08:01:54Z,don't we need the scala version here?,0,0.9897903800010681
181650623,4756,mjsax,2018-04-16T08:03:07Z,typo: is a wrapper around `stream[s]builder`,0,0.9953479170799255
181650718,4756,mjsax,2018-04-16T08:03:31Z,nit: `wordcount` ?,0,0.9856327772140503
181650779,4756,mjsax,2018-04-16T08:03:47Z,typo: `stream[s]builder`,0,0.9957250356674194
181652632,4756,mjsax,2018-04-16T08:11:33Z,scala version missing?,0,0.9815621972084045
181652730,4756,mjsax,2018-04-16T08:12:00Z,scala version missing?,0,0.9815621972084045
181652863,4756,mjsax,2018-04-16T08:12:40Z,"i think, we should not have indention here for better rendering",0,0.8851404786109924
181653308,4756,mjsax,2018-04-16T08:14:23Z,nit: should be added such the alphabetical order is maintained.,0,0.994583785533905
181653441,4756,mjsax,2018-04-16T08:14:56Z,can't we merge this with the one from above?,0,0.9941697120666504
181656561,4756,mjsax,2018-04-16T08:27:10Z,this seems to be rather short compared to `stream` and `table` docs from above.,0,0.9649608135223389
181656843,4756,mjsax,2018-04-16T08:28:06Z,"maybe we can add, that a store must still be ""connected"" to a `processor`, `transformer`, or `valuetransformer` before it can be used?",0,0.990577220916748
181657170,4756,mjsax,2018-04-16T08:29:17Z,"maybe add, that global stores do not be added to `processor`, `transformer`, or `valuetransformer` (in contrast to regular stores).",0,0.990856409072876
181658989,4756,mjsax,2018-04-16T08:36:36Z,"maybe add a sentence, that stores must be added via `addstatestore` or `addglobalstore` before they can be connected to the `transformer` ?",0,0.991579532623291
181659066,4756,mjsax,2018-04-16T08:36:53Z,as above?,0,0.9936766028404236
181659114,4756,mjsax,2018-04-16T08:37:05Z,as above?,0,0.9936766028404236
181659257,4756,mjsax,2018-04-16T08:37:38Z,as above?,0,0.9936766028404236
181660310,4756,mjsax,2018-04-16T08:41:42Z,"maybe explain, that there is not ordering guarantee for the merged result stream for records of different input streams? relative order is only preserved for record of the same input stream?",0,0.9886329770088196
181662152,4756,mjsax,2018-04-16T08:48:00Z,markup seems weird? why do you have javadoc comment markup? would a single `#` not be sufficient?,-1,0.9481009840965271
181904753,4756,guozhangwang,2018-04-16T22:31:18Z,"for different scala version compiled packages, their project name is actually the same. and here people only need to specify the version of the artifact itself, which will be the kafka version. users can, indeed, build kafka-streams-scala with different scala versions other than the default one, but that is to be done before they include it in the dependency. for maven, it will always be whatever is uploaded to maven central.",0,0.9911648631095886
181909480,4756,guozhangwang,2018-04-16T22:57:47Z,"cc -hamill we are adding a few new sections in web docs regarding the streams scala api, which may be affecting [a link]",0,0.9932208061218262
181909865,4756,guozhangwang,2018-04-16T23:00:09Z,"i think the scala version cannot be changed when specifying the `kafka-streams-scala` artifact, as it is encapsulated when that artifact is compiled already. please correct me if i'm wrong.",0,0.9769663214683533
181910307,4756,guozhangwang,2018-04-16T23:02:43Z,i think we do not need avro4sversion any more? same as line 86 here.,0,0.9914547204971313
181910344,4756,guozhangwang,2018-04-16T23:02:56Z,this is not needed.,0,0.9940305352210999
181910430,4756,guozhangwang,2018-04-16T23:03:34Z,do we still need `scalatestembeddedkafkaversion`?,0,0.9953250885009766
181910448,4756,guozhangwang,2018-04-16T23:03:40Z,+1,0,0.9816582202911377
181910836,4756,guozhangwang,2018-04-16T23:06:10Z,should we add `copyright 2018 the apache software foundation.` as well?,0,0.9951258301734924
181911680,4756,guozhangwang,2018-04-16T23:11:08Z,"ping on this comment again, could you elaborate if my concern is valid or not?",0,0.6200476884841919
181911985,4756,guozhangwang,2018-04-16T23:12:59Z,could we remove this line then?,0,0.9939821362495422
181916063,4756,guozhangwang,2018-04-16T23:39:02Z,"nit: move `import org.junit.assert._` after line 22, ditto below elsewhere.",0,0.9937094449996948
181916302,4756,guozhangwang,2018-04-16T23:40:40Z,"nit: replace the `_1/2/3` suffix with some more meaningful name? e.g. `simple`, `aggregate`, `join`?",0,0.9915528893470764
181972834,4756,debasishg,2018-04-17T07:18:17Z,done ..,0,0.992914080619812
181973173,4756,debasishg,2018-04-17T07:19:47Z,done ..,0,0.992914080619812
181974944,4756,debasishg,2018-04-17T07:28:02Z,enriched ..,0,0.9883397817611694
181975406,4756,debasishg,2018-04-17T07:30:03Z,done ..,0,0.992914080619812
181975843,4756,debasishg,2018-04-17T07:31:59Z,done ..,0,0.992914080619812
181978439,4756,debasishg,2018-04-17T07:43:03Z,done ..,0,0.992914080619812
181978475,4756,debasishg,2018-04-17T07:43:11Z,done ..,0,0.992914080619812
181978790,4756,debasishg,2018-04-17T07:44:41Z,done ..,0,0.992914080619812
181979232,4756,debasishg,2018-04-17T07:46:16Z,done ..,0,0.992914080619812
181979824,4756,debasishg,2018-04-17T07:48:50Z,done ..,0,0.992914080619812
181980358,4756,debasishg,2018-04-17T07:50:55Z,done ..,0,0.992914080619812
181980630,4756,debasishg,2018-04-17T07:52:07Z,removed ..,0,0.9841299057006836
181981140,4756,debasishg,2018-04-17T07:54:09Z,removed ..,0,0.9841299057006836
181982186,4756,debasishg,2018-04-17T07:57:46Z,done ..,0,0.992914080619812
181984159,4756,debasishg,2018-04-17T08:02:37Z,done ..,0,0.992914080619812
181985862,4756,debasishg,2018-04-17T08:09:17Z,"i am not sure i understand your concern. the only purpose of this implicit is to allow an implicit conversion from `tuple2` to `keyvalue(key, value)`. just a helper which we found useful in many cases for developing applications or tests.",0,0.5241698026657104
181986497,4756,debasishg,2018-04-17T08:11:46Z,removed the duplicate entry ..,0,0.9946812987327576
182133565,4756,guozhangwang,2018-04-17T15:59:15Z,"here is my concern: in `map` and `flatmap`, we call [code block] does that mean that for each pair of k, v pair parameters, we would first construct a `tuple2` object of this case class, and then apply the mapper, and then create a new `keyvalue` from the result `tuple2` object? if that is true, then we are creating a short-lived object for each record processed in `map`. i'm not sure if it will have a pressure on the gc.",0,0.9371514916419983
182333791,4756,debasishg,2018-04-18T07:37:56Z,- you are correct that with the current implementation there will be `tuple2`s created. but it's difficult to say if there will be gc pressure. for that we need to analyze runtime behaviors and see what the jit does. there's of course a way we can fall back to the implementation which does less allocation .. [code block] we did run some tests in bulk to check the diff in performance between the 2 versions. couldn't find much of a difference though.,0,0.9840059280395508
182418338,4756,seglo,2018-04-18T13:05:49Z,:+1:,0,0.9328674077987671
182418770,4756,seglo,2018-04-18T13:07:07Z,:+1:,0,0.9328674077987671
182424831,4756,ijuma,2018-04-18T13:25:51Z,not sure what you mean . the scala version is usually part of the artifact name.,0,0.9213536381721497
182448107,4756,seglo,2018-04-18T14:30:39Z,"i'm not very familiar with gradle, but it appears to not support cross building jars in the same manner as sbt. the build needs to be run for each scala version you want a jar for, but the output won't encode the version into the filename. i think what we need to do is add a task to the gradle file, or some other build related packaging script, to pluck the generated `kafka-streams-scala` file, rename it to include the scala version, and then publish it to maven central. ex) the built outputs this when specifying a 2.12 `scala_version` (`./gradlew -pscalaversion=2.12 jar`) [code block] when a release artifact is published we'll publish a file: `kafka-streams-scala_2.12-1.2.0.jar` with the scala major version encoded into the artifact name. a maven user would reference the artifact with: [code block] please let me know if i'm missing something here about the kafka build system. on a related note i found a gradle build plugin that handles cross building projects and referencing scala dependencies in a sbt style here: [a link]",0,0.9608535766601562
182454071,4756,ijuma,2018-04-18T14:45:42Z,"we already so the right thing for core jars. we just need to follow the same approach. and yes, the scala version needs to be encoded in the artifact id. not sure what was trying to say, but doesn't seem correct to me.",0,0.965535044670105
182461208,4756,seglo,2018-04-18T15:04:21Z,"ok, is the approach you refer to in the core project of the `build.gradle`? i'll take a closer look. wrt the docs is correct that we should update the maven dependency examples to include the scala version.",0,0.9926725029945374
182503294,4756,guozhangwang,2018-04-18T17:13:46Z,"what i was saying is that when we build the artifact we already chose which scala version to use compiling the jar and made the scala version as part of the artifact name, so users do not need to specify the scala version in declaring the dependency, but just: [code block]",0,0.9925976991653442
182704470,4756,seglo,2018-04-19T10:40:56Z,i'll correct this to include the scala version (2.11) across all the maven `pom.xml` references.,0,0.9952093958854675
182704820,4756,seglo,2018-04-19T10:42:14Z,we don't need to specify the scala version here. the `%%` operator in sbt will automatically determine the right artifact based on the running scala version.,0,0.993694007396698
182705719,4756,seglo,2018-04-19T10:46:15Z,:+1:,0,0.9328674077987671
182705959,4756,seglo,2018-04-19T10:47:21Z,:+1:,0,0.9328674077987671
182706259,4756,seglo,2018-04-19T10:48:44Z,:+1:,0,0.9328674077987671
182706791,4756,seglo,2018-04-19T10:51:22Z,:+1:,0,0.9328674077987671
182707211,4756,seglo,2018-04-19T10:53:13Z,"i followed the convention of preceding java examples which also have indentation, but i'll remove the indentation for the scala example.",0,0.9929528832435608
182711723,4756,seglo,2018-04-19T11:13:11Z,:+1:,0,0.9328674077987671
182742751,4756,mjsax,2018-04-19T13:21:46Z,that's what i meant by my comment -- sorry for expressing myself unclear.,-1,0.9886727929115295
184075333,4756,miguno,2018-04-25T14:16:17Z,"this doesn't look right to me. the latest `trunk` build of kafka only generates the following artifact(s): [code block] the maven coordinates for the artifacts above have an `artifactid` of `kafka-streams-scala`, not `kafka-streams-scala_2.11`.",0,0.969764769077301
184082552,4756,miguno,2018-04-25T14:34:24Z,"this example code doesn't compile, because e.g. the import for `streamsbuilder` is missing (from package `org.apache.kafka.streams.scala`). i would probably double-check the other examples that are shown in the documentation, too.",0,0.9871354699134827
184119748,4756,guozhangwang,2018-04-25T16:11:54Z,"looking at the `build.gradle` again, today we only build `kafka-streams-scala` with the default scala versions defined in `dependencies.gradle`, 2.11.12. if we want to publish multiple artifacts with different scala versions we should follow the `core` project pattern, i.e. sth. like: [code block] we could also consider just building one artifact with the default scala version, in this case we would remove the suffix here and add the explanation which scala version users should be expected to use.",0,0.9920722842216492
184124327,4756,seglo,2018-04-25T16:25:25Z,"i recommend releasing versions of `kafka-streams-scala` for both major versions of scala currently supported by kafka. we should copy build and release conventions used by kafka core so that both artifacts are produced. i'm not very familiar with gradle or the kafka release process, so i wasn't sure how far to go with this, but now that that gradle snippet is right in front of me it's clear that the same should be done for this library. i believe recommended this earlier, but i didn't make the appropriate update before the merge. ~~ how are multiple versions of kafka core published at part of the release process? is the build script called twice with appropriate `scalaversion` parameter?~~ nevermind, i see how it's done now. only making the library available to scala 2.11 will leave behind a lot of users that are already on 2.12, which has been out for several years now. cross building (building an artifact per version of scala) will also make it a trivial matter to support future of versions of scala in the release process.",0,0.8477092981338501
184148190,4756,miguno,2018-04-25T17:42:03Z,"i agree that we should generate artifacts for both 2.11 and 2.12, like we do for kafka core.",0,0.9827119708061218
184153041,4756,guozhangwang,2018-04-25T17:56:24Z,sounds good. could you submit a follow-up pr to modify `build.gradle` for publishing multiple artifacts for different scala versions of `kafka-streams-scala` then?,0,0.5677922964096069
184153302,4756,guozhangwang,2018-04-25T17:57:11Z,could you take a look?,0,0.9896900653839111
184193473,4756,seglo,2018-04-25T20:20:20Z,"yes. i'm travelling atm, but i'll make a new pr in the next few days.",0,0.9826839566230774
184193680,4756,seglo,2018-04-25T20:21:11Z,yes. i'll test the snippets in the build pr.,0,0.9940462112426758
186375027,4756,miguno,2018-05-07T09:37:32Z,"the single parameter for `transform()` is a `transformer`, not a `transformersupplier`. the variable needs renaming and the javadocs updating.",0,0.9940409064292908
186387729,4756,miguno,2018-05-07T10:44:02Z,i raised [a link] for this.,0,0.9919028878211975
65546724,1446,enothereska,2016-06-02T14:13:40Z,"these name changes are not strictly part of this fix, i'm wondering if we can open a minor pr for these while having this pr focus on streams only (to avoid confusion).",0,0.9772554039955139
65564787,1446,aartigupta,2016-06-02T15:42:11Z,"agreed, theses were not intended for this fix, they managed to sneak their way in. my bad, fixed it now",-1,0.9928519129753113
65923002,1446,jklukas,2016-06-06T16:32:36Z,the line break here seems unnecessary.,0,0.5935757160186768
65923529,1446,jklukas,2016-06-06T16:36:02Z,"since there are now two implementations of `streamsmetrics`, is it confusing to have them both named `streamsmetricsimpl`? this could be `threadstreamsmetrics` and the other could be `processornodestreamsmetrics`.",0,0.9860397577285767
65947627,1446,enothereska,2016-06-06T18:56:29Z,do we still need the subsequent variable?,0,0.9927732348442078
65948134,1446,enothereska,2016-06-06T18:59:27Z,i wonder if there is a way to use the other sensor calls for the latency sensor too. or will this one always remain special?,0,0.9596478343009949
65948578,1446,enothereska,2016-06-06T19:02:06Z,"would it be better for `metrics` to be passed in the `processornode` constructor instead? for example, like it's done in the `streamthread` constructor.",0,0.9894435405731201
65948746,1446,enothereska,2016-06-06T19:03:11Z,same comment as above about passing in constructor instead.,0,0.9933170080184937
65948820,1446,enothereska,2016-06-06T19:03:36Z,same comment as above about passing in constructor instead.,0,0.9933170080184937
65951530,1446,enothereska,2016-06-06T19:20:32Z,is it correct to do the commit sensor recording for task.node() or even here? why not do it in `streamtask's` `commit`?,0,0.994906485080719
65951650,1446,enothereska,2016-06-06T19:21:19Z,is it correct to do the punctuation sensor recording for task.node() or even here? why not do it in `streamtask's` `punctuate`?,0,0.9947503209114075
66099715,1446,aartigupta,2016-06-07T15:58:00Z,"there seem to be two ways to make this happen a. for the processornode to accept metrics in the constructor, the processornodefactory would have to have a pointer to metrics, which would imply that addprocessor in topologybuilder would need to have that, and since metrics is internal to kstreams, users of topologybuilder do not have a pointer to metrics. alternatively b. the build method of processornodefactory can take metrics in addition to applicationid and then a processornode can be constructed by passing metrics in the processornode constructor as opposed to piggy backing on the streamsmetrics which the current review request shows (which is not uniform with streamthread...) b, would look like this [code block]",0,0.9912390112876892
66102111,1446,aartigupta,2016-06-07T16:11:35Z,"you are correct, previously this made sense since we did not expose adding arbitrary sensors onto the base metrics registry, but now that we do, having this in the interface stands out as odd that said there seems to be a lot of boiler plate code around tags, parsing and logging. // first add the global operation metrics if not yet, with the global tags only sensor parent = metrics.sensor(scopename + ""-"" + operationname); addlatencymetrics(metricgroupname, parent, ""all"", operationname, this.metrictags); [code block] what do these tags buy us ? (it is not clear :) ) if we can get rid of the tags, then does it make sense to have an a base implementation of the streamsmetrics interface, because with the exception of the actual sensors contained in them, the two implementations start to look very similar protected class processornodestreamsmetrics implements streamsmetrics .... protected class threadstreamsmetrics implements streamsmetrics ....",0,0.8007228374481201
66291188,1446,aartigupta,2016-06-08T16:35:15Z,"you are right, this was not the right place. streamtask's commit is the right place. fixed locally and working on a unit test and integration test to ""count down"" commit and punctuate metrics to ensure correctness.",0,0.8836895823478699
91086491,1446,ijuma,2016-12-06T14:23:19Z,should this be `recordlevel`?,0,0.9920920133590698
91086702,1446,ijuma,2016-12-06T14:24:24Z,"we don't need the `sensor` prefix in the name. also, are these the only two levels we care about?",0,0.9916364550590515
91231975,1446,aartiguptaa,2016-12-07T06:08:57Z,"info would map to the level we use for normal production runs, and debug could be used to optimize the job in the development or instrumentation/debugging phase. can't think of any more use cases, maybe trace could be a finer level, but personally have never found that useful.",0,0.9800002574920654
91587971,1446,guozhangwang,2016-12-08T19:25:50Z,"nit: new line between functions, ditto below.",0,0.9930403232574463
91588145,1446,guozhangwang,2016-12-08T19:26:45Z,"also we need to add the javadoc for those newly added functions, especially explain the `recordlevel`.",0,0.9950018525123596
91588780,1446,guozhangwang,2016-12-08T19:29:50Z,"we can reuse `recordlevel.sensor_info_str` etc here, to avoid split places of those global constant strings.",0,0.9932854175567627
91589025,1446,guozhangwang,2016-12-08T19:31:07Z,could this result in npe? may be we can directly throw an illegalargumentexception here.,0,0.9853615164756775
91589076,1446,guozhangwang,2016-12-08T19:31:25Z,"how about returning ""unknown"" or ""illegal_level"" than null?",0,0.9920756816864014
91590844,1446,guozhangwang,2016-12-08T19:39:29Z,"this is a meta comment: in additional to skip `record`, we can probably go further to even avoid registering the sensor at all in the reporter. its benefits are: 1. the reporter will not show these metrics at all (i.e. they will not display in the monitoring ui, for example), whereas today the reporter will still show these metrics but the value is always the initialized value (most likely 0). 2. we can further reduce the overhead of function calls as well as the registry space; i'm not sure by how much though. admittedly this will require a larger change on `o.a.k.common.metrics`. what do you think ?",0,0.9777277708053589
91591063,1446,guozhangwang,2016-12-08T19:40:45Z,ditto above.,0,0.9910715222358704
91591235,1446,guozhangwang,2016-12-08T19:41:40Z,is this really part of this pr?,0,0.9903193712234497
91592681,1446,guozhangwang,2016-12-08T19:48:09Z,"won't time be always null here, since it is never initialized?",0,0.983646035194397
91594176,1446,guozhangwang,2016-12-08T19:55:40Z,"`streams-processor-node-metrics` to be consistent with other group names, and only include the node name in the tags as `put(""processor-node-id"", name);` (not sure why you added a ""-"" before the name?).",0,0.9929574728012085
91594356,1446,guozhangwang,2016-12-08T19:56:39Z,"nit: ""processor-node"" to be more clear with other scope, for example ""producer-metrics"" also have a per-node sensor level, where `node` there means the destination brokers.",0,0.9947287440299988
91595483,1446,guozhangwang,2016-12-08T20:02:31Z,"this is not introduced in this patch, but we could fix it together: in line 1133 below [code block] we'd better change it to [code block]",0,0.995361864566803
91596211,1446,guozhangwang,2016-12-08T20:06:29Z,"again, to be consistent the sensor name better be the form of `(sensornameprefix + "".node-forward-time""): to add a `.` after the prefix, and we do not need the `name` as the suffix since it is already used in tags.",0,0.9931628704071045
91596966,1446,guozhangwang,2016-12-08T20:10:50Z,"the explanation does not sound right to me. i think it is ""the average per-second number of records processed by this processor"". also maybe we can rename the variable name to `nodethroughputsensor` to be more meaningful?",0,0.9567278623580933
91596999,1446,guozhangwang,2016-12-08T20:11:03Z,ditto for other sensor names.,0,0.9906392097473145
91597224,1446,guozhangwang,2016-12-08T20:12:24Z,seems like the explanation text are not updated after copying :p,1,0.9754257798194885
91597427,1446,guozhangwang,2016-12-08T20:13:33Z,"is the creation and deconstruction rate really useful? i feel the creation and deconstruction latency is more useful, since for rate it is mostly 0 unless there is a rebalance.",0,0.9826427698135376
91597796,1446,guozhangwang,2016-12-08T20:15:57Z,"also we do not need the prefix in metric name, but only in sensor name.",0,0.9938749670982361
91598240,1446,guozhangwang,2016-12-08T20:18:23Z,"and following that comment, the sensor name can be changed to `(sensornameprefix + "".process-throughput"")`, and the metrics name can be changed to `""record-process-rate""`.",0,0.9950897097587585
91598693,1446,guozhangwang,2016-12-08T20:21:13Z,"i think this is not a per-node sensor, but rather a per-task sensor right? shall we create a `taskmetrics` class accordingly for this layer?",0,0.9911330342292786
91598975,1446,guozhangwang,2016-12-08T20:22:59Z,"by layer i mean three layers: thread, task, node, and for task i think just one sensor ""commit"" is good enough, for punctuating the node-level metrics should be sufficient to cover.",0,0.9905154705047607
91599246,1446,guozhangwang,2016-12-08T20:24:37Z,why we want to pass in these as parameters instead of computing them internally? it seems `streamsmetricsimpl` is still only used once.,0,0.98770672082901
91599430,1446,guozhangwang,2016-12-08T20:25:45Z,why we do not want to use `computelatency` any more?,0,0.9830583333969116
91668435,1446,aartiguptaa,2016-12-09T07:13:36Z,"removed it for now, don't remember why and when this was added.",0,0.8781960606575012
91676685,1446,aartiguptaa,2016-12-09T08:42:53Z,"done, that makes it consistent. feeling better about it after that refactor.",1,0.7273749113082886
91679111,1446,aartiguptaa,2016-12-09T09:02:50Z,fixed the variable name to streamsmetrics (was sensors) streamsmetricsimpl is used 12 times. also fixed the computation,0,0.9938496947288513
91680753,1446,dguy,2016-12-09T09:16:06Z,why protected?,0,0.9910496473312378
91685809,1446,dguy,2016-12-09T09:49:32Z,why not record this inside `init`? it seems wrong to expose a field of `processornode`,0,0.981670618057251
91700552,1446,enothereska,2016-12-09T11:25:12Z,"unfortunately 2 different tasks on the same thread can register the same two metrics and we'll get an exception in the thread library (current test fails because of this). so the prefix is not sufficient just for the sensor, but is also needed for the metric.",0,0.7328024506568909
91821831,1446,guozhangwang,2016-12-10T00:43:02Z,"that's right, but shouldn't the `sensornameprefix` contains that? currently it only contains the taskid but i think it should include both since each task can have its own copy of the topology. as for the group name, it is used for grouping metrics that may come from different classes even (see producer's `sender` and `selector` classes), so it should not include the node id, but rather just ""streams-processor-node-metrics"".",0,0.9900155663490295
91821954,1446,guozhangwang,2016-12-10T00:45:08Z,"this is at the very critical path of streams, called millions of times per sec, so calling `time.nanoseconds()` on each call is really expensive if `debug` level is used.",0,0.9085800647735596
91822004,1446,guozhangwang,2016-12-10T00:45:45Z,+1.,0,0.9864034652709961
91822140,1446,guozhangwang,2016-12-10T00:47:38Z,do we still need to keep this variable as it is now in the taskmetrics already?,0,0.9948840737342834
91922123,1446,enothereska,2016-12-12T10:40:57Z,done.,0,0.9897913336753845
91923060,1446,enothereska,2016-12-12T10:46:48Z,done.,0,0.9897913336753845
91923083,1446,enothereska,2016-12-12T10:46:56Z,done.,0,0.9897913336753845
91924605,1446,enothereska,2016-12-12T10:56:27Z,i'm not sure i understand your comment. `sensornameprefix` contains the task id. we use that for both sensor and metric name. with your last comment you seem to be saying the same we're saying. unless i misunderstood it. so as action item i'm just re-adding `sensornameprefix` to the metric name? (i can probably rename `sensornameprefix` to just `prefix` since it's used for sensor and metric). anything else? thanks.,1,0.919996976852417
91926667,1446,enothereska,2016-12-12T11:10:52Z,fixed.,0,0.9905837774276733
91927862,1446,enothereska,2016-12-12T11:19:14Z,actually i still need protected because source and sink node have to use this field.,0,0.9881448745727539
92004035,1446,dguy,2016-12-12T18:07:12Z,can this be private now?,0,0.9947187900543213
92006773,1446,dguy,2016-12-12T18:21:24Z,"in this method and `punctuate` the blocks of code are largely the same. is this pattern going to be common? if it is just in this class, then i'd probably create a method in here that accepts a `runnable` and have `process` and `punctuate` delegate to it, i.e., [code block]",0,0.991135835647583
92021599,1446,enothereska,2016-12-12T19:31:49Z,annoyingly sourcenode uses it.,-1,0.9838036894798279
92027755,1446,guozhangwang,2016-12-12T20:01:12Z,"my suggestion is to remove the suffix of `name`, which is the processor name in sensor, since it is already included in the tags. take the `jmxreporter` as an example, it generates the mbean for streams as: [code block] where `kafka-streams` is the prefix passed in `kafkastreams`, and `streams-processor-node-metrics` is the pre-defined `metricgrpname `. you can see here that the processor name suffix in attribute names are redundant, and more generally for any reporters implementations, metrics will be grouped by ""group name"" and ""tags"".",0,0.9905499815940857
92028572,1446,guozhangwang,2016-12-12T20:05:35Z,"tags are not used at all, actually do they need to be added? see my previous comment.",0,0.9927338361740112
92028877,1446,guozhangwang,2016-12-12T20:07:04Z,tags are not used here.,0,0.9862843751907349
92029084,1446,guozhangwang,2016-12-12T20:08:02Z,"this additional tag pair `""processor-node-id"" -> name` is redundant since it is already added in line 168.",0,0.99276202917099
92029769,1446,guozhangwang,2016-12-12T20:11:32Z,"i left a follow-up comment about not needing to include `name` in the prefix anymore, let me know what do you think.",0,0.9835448861122131
92033622,1446,guozhangwang,2016-12-12T20:33:02Z,"one more meta comment about `scopename`, `entityname` and `operationname`: in latency sensors they are managed as a two-layer metrics with the top-level metrics as: 1. `prefix.scopename-operationname`; which is the parent of all: 2. `prefix.scopename-entityname-operationname`; which means that whenever any of the children get updated, the parent also gets update. so for state store operations. `scopenames` are `in-memory-state`, `rocksdb-state` etc, and `entitynames` are specific store names, and `operationname` are `put`, `get` etc. in addition, the `scopename` is also used in the group name, so you can think of groupnames as `streams-in-memory-state-metrics` `streams-rocksdb-state-metrics` `streams-processor-node-metrics` `streams-task-metrics` `streams-metrics` /* this is actually per-thread metrics */ etc where scope is `processor-node`, `task`, etc. in your implementation, the `scopename` is removed from the sensor name, which i think is a good fix as it would redundant since it is already in the group name. however, the parental hierarchy is not encoded in the scopename / entityname / operationname in this function, and i'm wondering if it still makes sense to still capture this hierarchy in these names while still letting users specify ""additional"" parents in the last parameters?",0,0.9883198738098145
92224454,1446,enothereska,2016-12-13T17:42:54Z,"ok, it's latency now.",0,0.9710561037063599
92228908,1446,enothereska,2016-12-13T18:05:21Z,one problem here is the `prefix` which so far has been hardcoded in `streamthread.java`,0,0.9822496175765991
92230530,1446,guozhangwang,2016-12-13T18:12:51Z,"i'm not sure i understand your comment above? btw following my comment below i think we still cannot remove the `scopename` from the sensor name, since otherwise they will be collapsed into the same sensor.",0,0.9038903713226318
92235489,1446,enothereska,2016-12-13T18:36:31Z,i only have 2 cases of this so far. worried about one more layer of indirection.,-1,0.9697756767272949
92237153,1446,enothereska,2016-12-13T18:44:00Z,"i see, sure. thanks.",1,0.9233055710792542
92248305,1446,enothereska,2016-12-13T19:35:26Z,"with my latest commit i think i have got things consistent, could you have a look if you can. with `jconsole` i can verify that i can see the sensors and metrics.",0,0.9703341722488403
92681462,1446,mjsax,2016-12-15T19:25:52Z,"of -> or ""to ensure name well-formedness and conformity "" -> to ensure that metric names are well-formed and conform",0,0.9906784296035767
92709588,1446,mjsax,2016-12-15T22:00:00Z,in `processornode` we also do should we do the same here? what about a more general way to measure this latency? it seems we do not do this correctly right -- we could abstract `nodemetrics` such that it can be private in and avoid code duplication. i am also wondering why `this.processor.init(...)` is only called `processornode` and not in `sourcenode` or `sinknode`.,0,0.9818090796470642
92719109,1446,guozhangwang,2016-12-15T22:57:38Z,"honestly i am not sure if we should ever be ""completely generic"" or not. but if we feel that we should do it, then we can simply expose them as [code block] in stead of still enforcing the naming convention in terms of `scope, entity, operation`? or simply just expose the internal `metrics` to let users call its `sensor` functions directly: [code block] if we do not want to allow ""completely generic sensor registry"", then i'd suggest renaming the functions to `addgenericsensor` and make it very clear how the `scope / entity / operation` names will be used to construct the group-name, sensor name, or even tags, etc in the javadoc.",0,0.6455519199371338
92724770,1446,guozhangwang,2016-12-15T23:40:34Z,"this is not introduced in this pr, but i'm wondering if there is any value we add this specific `addcachesensor` instead of just using the ""generic adding sensor"" functions since we have already introduced them in this pr. afterwards there is only one place using it for recording `cache hits` with `min, max, avg` which to me is quite generic usage.",0,0.9803771376609802
92725173,1446,guozhangwang,2016-12-15T23:43:58Z,we could save this `nanoseconds` with `mayberecord` pattern as well with debug level.,0,0.9941381216049194
92725338,1446,guozhangwang,2016-12-15T23:44:59Z,we could apply the `mayberecord` pattern in the `meteredstore` as well for all these debug level sensors.,0,0.9934240579605103
92725404,1446,guozhangwang,2016-12-15T23:45:36Z,ditto above.,0,0.9910715222358704
92725740,1446,guozhangwang,2016-12-15T23:48:22Z,there are a couple of other places where we can potentially save `nanoseconds` calls (left comments on those places where `sensor_debug` sensors may require getting the startns and endns). so i feel this could be a common pattern to add.,0,0.9926037192344666
92870610,1446,enothereska,2016-12-16T19:24:35Z,"this pr is not about allowing users to register their own sensor yet, for the scope of this pr these are helper functions for our own usage internally. i'd like to separate the two if possible.",0,0.9900424480438232
92999354,1446,enothereska,2016-12-19T09:57:26Z,"good catch, thanks!",1,0.9951314926147461
92999461,1446,enothereska,2016-12-19T09:58:00Z,thanks!,1,0.8631753921508789
93007886,1446,enothereska,2016-12-19T10:48:03Z,ok.,0,0.980760931968689
93012648,1446,enothereska,2016-12-19T11:19:33Z,the answer is that we'll provide helper functions but also expose the metrics registry as well.,0,0.9940115809440613
93102705,1446,enothereska,2016-12-19T19:32:23Z,"done, thanks.",1,0.5576635599136353
93230666,1446,ijuma,2016-12-20T12:50:12Z,maybe `the higher recording level for metrics` or something like that?,0,0.9910017848014832
93230738,1446,ijuma,2016-12-20T12:50:39Z,adding a config typically requires a kip. are we planning to do that?,0,0.9928030371665955
93231030,1446,ijuma,2016-12-20T12:52:30Z,why is this not simply `info` and `debug`?,0,0.9839767217636108
93231096,1446,ijuma,2016-12-20T12:52:55Z,why do we expose this instead of getting it via the enum?,0,0.9894776940345764
93231227,1446,ijuma,2016-12-20T12:53:51Z,"typically, this would be done by iterating over the enums (i.e. `recordlevel.values()`) and then it doesn't have to be changed if we add more levels. any reason why we can't do that?",0,0.991600751876831
93231324,1446,ijuma,2016-12-20T12:54:33Z,"instead of doing this, we can simply override `tostring` in each enum. however, if we go with my suggestion of renaming the enum values, the `tostring` will be the right one by default, i think.",0,0.9915863275527954
93231397,1446,ijuma,2016-12-20T12:55:07Z,this should disappear with my suggestion.,0,0.987761378288269
93232020,1446,ijuma,2016-12-20T12:59:15Z,"we shouldn't really be using the `ordinal` in this way imo. we should expose a method in the `recordlevel` class to return a boolean in this case. for example, the invocation could look like `recordlevel.shouldrecord(config.recordlevel)`. also, using the `ordinal` internally can work, but it's a bit opaque (i.e. if people change the order of definition, they break the code). one often adds a new parameter to the enum instance to make it clearer.",0,0.9782677888870239
93232147,1446,ijuma,2016-12-20T13:00:06Z,`shouldrecord`? `mayberecord` sounds like it would record it for you.,0,0.9919431209564209
93275266,1446,enothereska,2016-12-20T16:39:03Z,ok,0,0.9233372807502747
93275350,1446,enothereska,2016-12-20T16:39:25Z,what do you think?,0,0.9730982184410095
93275549,1446,enothereska,2016-12-20T16:40:24Z,ok,0,0.9233372807502747
93275798,1446,enothereska,2016-12-20T16:41:36Z,good point.,1,0.9140551090240479
93276750,1446,enothereska,2016-12-20T16:46:33Z,yup.,0,0.9632495641708374
93276771,1446,enothereska,2016-12-20T16:46:38Z,yup.,0,0.9632495641708374
93276794,1446,enothereska,2016-12-20T16:46:44Z,"yup, thanks.",1,0.6701683402061462
93277891,1446,enothereska,2016-12-20T16:51:44Z,"makes sense, thanks.",1,0.5818662643432617
93283534,1446,enothereska,2016-12-20T17:18:07Z,ok,0,0.9233372807502747
93296992,1446,guozhangwang,2016-12-20T18:33:22Z,"yup, sounds good to me.",0,0.5088075399398804
93298089,1446,guozhangwang,2016-12-20T18:39:23Z,do we really want to expose this function as a public api ?,0,0.9919849634170532
93298423,1446,guozhangwang,2016-12-20T18:41:15Z,"so what is the final decision for these two functions? i saw that you have already exposed the underlying `metrics` registry directly; in this case do we still need these two functions? personally i feel it is not necessary any more, but if you have a strong opinion maybe we should at least rename it to `addgenericsensor` to be consistent with other two.",0,0.9879533052444458
93298928,1446,guozhangwang,2016-12-20T18:43:54Z,shall we add a `recordthroughput` function as well?,0,0.9951243996620178
93304064,1446,ijuma,2016-12-20T19:10:19Z,"thanks for the updates. looking better. :) one thing i wasn't too clear about. for the `shouldrecord` case, we can pass a number to make the comparison more efficient. it's pretty similar to using `ordinal`, but the number is explicit instead of being based on the order of definition. classes like `apikeys` and `securityprotocol` do that. we could also just use the ordinal if it's just used internally. another thing is that enums get a `name` method that returns the declaration name. in this case `info` and `debug`. so, again, if it's an internal thing, we could potentially reuse that. defining it explicitly is fine too (we tend to do that for public enums. finally, we don't use getter notation in kafka so `getvalue()` should be `value` (if we decide to keep it).",1,0.9964748024940491
93305783,1446,enothereska,2016-12-20T19:19:21Z,sure. it's useful internally as well. this pr is primarily for internal needs so far.,0,0.7367933988571167
93310227,1446,guozhangwang,2016-12-20T19:43:16Z,"the issue is that, streamsmetrics is a public class so any public functions of this interface will be accessible to users as well. if we really want to add it to let users be able to use it, we need to think about how to clearly differentiate with `recordlatency`, when to use which, etc. personally i'd rather not exposing it but only for internal usage, and let users to make their own optimizations if they want.",0,0.8935344815254211
93505557,1446,junrao,2016-12-21T19:39:40Z,do we need to expose a similar config on the broker side since the broker also uses the client side metrics in certain cases?,0,0.9933972358703613
94743881,1446,enothereska,2017-01-05T10:22:16Z,done.,0,0.9897913336753845
94746977,1446,enothereska,2017-01-05T10:44:00Z,ok.,0,0.980760931968689
94748307,1446,enothereska,2017-01-05T10:53:17Z,"ok, removing.",0,0.9917057752609253
94751245,1446,enothereska,2017-01-05T11:16:35Z,yeah probably. will add. thanks.,1,0.9274466037750244
94757229,1446,enothereska,2017-01-05T12:09:16Z,"will do this, ideally before feature freeze, but definitely before code freeze. stay tuned.",0,0.7189266085624695
95413470,1446,guozhangwang,2017-01-10T17:22:32Z,i am not sure if it is needed: `metrics.sensor` will recursively link parent sensor to its children; `metrics.removesensor` will recursively remove its children sensor as well.,0,0.9371888637542725
95413953,1446,enothereska,2017-01-10T17:25:00Z,"`addlatencymetrics` is supposed to return 1 sensors, but it creates 2 internally. one of them, the parent, is never exposed to the user, so the user has no way of deleting it. with this solution, the user deletes the child sensor and we internally delete the parent sensor.",0,0.990591824054718
95415769,1446,guozhangwang,2017-01-10T17:33:39Z,"got it, thanks.",1,0.9691224694252014
95559941,1446,enothereska,2017-01-11T11:24:12Z,"done now, thanks",1,0.9483387470245361
95629070,1446,guozhangwang,2017-01-11T17:30:33Z,is this intentional? ditto below.,0,0.911350429058075
191968009,5101,lindong28,2018-05-31T01:29:34Z,why do we need to change it to 0? do we expect to initialize `controllercontext.epochzkversion` to -1?,0,0.9935950636863708
192005699,5101,lindong28,2018-05-31T07:05:43Z,nits: we probably don't need `{` here so that the code style is consistent with the existing code.,0,0.9880902767181396
192008864,5101,lindong28,2018-05-31T07:22:46Z,"here `setdatarequest/setdataresponse` is replaced with `multioprequest/multiopresponse`. this may cause problem for existing code (e.g. `zookeeperclient.send()`) whose logic relies on the type of the request. instead of adding a new subclass of asyncrequest, would it be better to modify the existing request (maybe the asyncrequest) to include the expected controller epoch version so that, when the expected controller epoch exists, zookeeperclient.send() will take care of the version check?",0,0.9906103014945984
192020116,5101,hzxa21,2018-05-31T08:13:18Z,"i think the `initialcontrollerepochzkversion` represents the initial value when the controller epoch znode first gets created so it should be set to 0 for consistency just like `initialcontrollerepoch`. also, during cluster initialization (i.e controller epoch znode does not exists), we explicitly set `controllercontext.epochzkversion` to `initialcontrollerepochzkversion`, which was 1 before. ([a link] this will cause problems for the first controller to update zk states after this patch because the actual znode version is 0. this is not a problem before because we didn't use `controllercontext.epochzkversion` to fence zk state updates and after controller failover, we will update it by reading controller epoch znode. this change is only for readbility. actually we can just remove the line to set `controllercontext.epochzkversion` to `initialcontrollerepochzkversion` and keep `initialcontrollerepochzkversion` to be 1.",0,0.990680992603302
192020231,5101,hzxa21,2018-05-31T08:13:50Z,thanks for pointing out. will fix that.,1,0.9501776099205017
192023554,5101,hzxa21,2018-05-31T08:27:18Z,"that is a good point. the reason why i add the multiop subclass is that we can extend `zookeeperclient` to handle arbitrary multi() operations, not specifically for checking controller epoch version and updating zk states. also, i think `zookeeperclient` should only be aware of zookeeper related context not the kafka related context (e.g. controller epoch version) for cleanness. instead of modifying asyncrequest, do you think it is better to add some helper functions in `kafkazkclient` to wrap around the check and set/update/create logic? also, i am a little bit confused on what are the problems caused by `zookeeperclient.send()` if we use `zookeeper.multi()` for `multioprequest`. can you give me more contexts on that?",1,0.8444553017616272
192188682,5101,lindong28,2018-05-31T18:09:13Z,cool. this makes sense.,1,0.9889733195304871
192206415,5101,lindong28,2018-05-31T19:10:04Z,"i think it is reasonable not to have kafka specific thing in zookeeperclient. on the other hand we don't have to -- we can provide anther zk path and expected version as parameters to these apis, the api should return proper error without executing the original request if the version of the path is different from the expected version. this solution is probably not kafka specific. not sure that we don't need arbitrary multi() operations in the near future. currently we only need to check the zk version of another path when controller changes zookeeper state. after checking the code, it seems that there is no current problem caused by using multioprequest. but some information (e.g. `createresponse.name` and `setdataresponse.stat`) is discarded in the response which may potentially be problem in the future. in general it seems more flexible to be able to use different case class for different requests so that we can have different parameters (as is the case now) and apply different processing logic to different case class. just my opinion. if you like the current solution, maybe you can keep it and other committers can comment on this.",0,0.8933612704277039
192302796,5101,hzxa21,2018-06-01T05:46:08Z,i see what you mean. that makes sense to me. i will update the pr to differentiate set/update/create with check parameters provided in `zookeeperclient` to expose different information. thanks for the explanation.,1,0.9769918322563171
194241899,5101,lindong28,2018-06-10T00:17:10Z,should the comment be `expected controller epoch zkversion`?,0,0.993800699710846
194241972,5101,lindong28,2018-06-10T00:24:23Z,do we need the `path` field here? can we remove this class and replace it with e.g. `zkversioncheckresultcode: resultcode`?,0,0.9950801134109497
194242568,5101,lindong28,2018-06-10T01:08:00Z,"in general we want to the exception returned to the caller to uniquely identify the problem. but here we can output the badversionexception if either the controller epoch zkversion is bad or the data znode zkversion is bad. it maybe confusing. it is probably simpler to create a new exception, e.g. `controllerepochzkversionmismatchexception` and do the following before checking `setdataresponse.resultcode`: [code block]",0,0.9507565498352051
194242678,5101,lindong28,2018-06-10T01:17:21Z,"can we name it `case class zkversioncheck(path: string, zkversion: int )`",0,0.9945949912071228
194242922,5101,lindong28,2018-06-10T01:34:55Z,typo,0,0.9826471209526062
194243046,5101,lindong28,2018-06-10T01:44:43Z,we can name it to be `controllerepochzkversion` to be consistent with `controllercontext.epochzkversion`? same for other uses of `controllerepochversion`.,0,0.9930058717727661
194243176,5101,lindong28,2018-06-10T01:55:46Z,"the current patch checks `resultcode`, and based on its value, adds additional logic to check `checkresult`. similar to the comment for `updateleaderandisr`, could we simplify the logic here by checking `deleteresponse.checkresult` before the existing logic of checking the resultcode?",0,0.9943881630897522
194243224,5101,lindong28,2018-06-10T02:00:42Z,it seems that we will return `badversionexception` for two different scenarios. can we output a unique exception if the controller znode has different version from what is expected?,0,0.9911832809448242
194244953,5101,lindong28,2018-06-10T04:37:09Z,"`generateasyncresponsewithcheckresult()` is called for `createrequest`, `setdatarequest` and `deleterequest`. however, most of the code (or logic) in `generateasyncresponsewithcheckresult()` is different for these three requests anyway. would it be more intuitive and simpler to remove the method `generateasyncresponsewithcheckresult()` and moves its request-specific logic in `send()`? we can put the logic that is common to all requests, e.g. the first part of generateasyncresponsewithcheckresult(), in a method if needed.",0,0.9876700639724731
194577297,5101,hzxa21,2018-06-11T23:28:09Z,yes. will fix it.,0,0.8695363998413086
194577987,5101,hzxa21,2018-06-11T23:32:42Z,"the path is needed to generate keeper exception with path information without assuming it to be controller epoch path. if we are going to generate the `controllerepochzkversionmismatch` exception in `kafkazkclient` instead of `keeperexception` in `zookeeperclient`, i think we can remove the path and just keep the resultcode.",0,0.9938189387321472
194578905,5101,hzxa21,2018-06-11T23:38:42Z,"thanks for the suggestion. it is simpler and cleaner this way. btw, i think we can just use `controllermoveexception()` in this case. also, related to your comment on my last commit, instead of putting the exception in some data structures, can we just simply throw the exception when the check fails? in this case, we can skip processing unnecessary controller event until we hit `controllerchange` event. to optimize it further, we can also catch 'contollermoveexception' explicitly in the `controllereventthread` and let the controller resigns immediately.",1,0.9802133440971375
194578945,5101,hzxa21,2018-06-11T23:38:58Z,sure. will do.,0,0.6459586024284363
194578974,5101,hzxa21,2018-06-11T23:39:07Z,thanks. will fix.,1,0.9375205636024475
194578989,5101,hzxa21,2018-06-11T23:39:14Z,sure.,0,0.9824982285499573
194579028,5101,hzxa21,2018-06-11T23:39:29Z,will fix it. thanks for pointing out.,1,0.9764519333839417
204258438,5101,lindong28,2018-07-22T23:09:20Z,maybe rename `controllermovelistener` to `controllermovedlistener` so that it is more consistent with the existing name `eventprocessedlistener`.,0,0.990047037601471
204258805,5101,lindong28,2018-07-22T23:21:35Z,type: should be `emptyeventqueueandreelect`. also it seems the name `cleareventqueueandreelect` is more consistent with the existing method names.,0,0.9936091899871826
204258904,5101,lindong28,2018-07-22T23:24:44Z,"nits: we typically just use `e: controllermovedexception` here for simplicity. `cme` does not provide much information since most users would still need to read the actual type to understand what it is. if it makes sense, can you rename it here and in other places of the patch?",0,0.9935821890830994
204259174,5101,lindong28,2018-07-22T23:32:47Z,in general the code may be more consistent and readable if we name the variable after this type. and `zkversioncheck` seems more informative than the `checkinfo`. can you rename the `checkinfo` here and in other places of the patch (including local variable)?,0,0.9922257661819458
204259221,5101,lindong28,2018-07-22T23:34:24Z,"would it be better to rename `controllerepochzkversion` to `expectedcontrollerepochzkversion`? the current method signature seems to suggest that the `controllerepochzkversion` will be written to the znode. if it makes sense, can you rename the variable here and in other places of the patch?",0,0.9936211705207825
204259339,5101,lindong28,2018-07-22T23:37:53Z,i am wondering whether it will be useful to print the expected/current controllerepoch and zkversion. not sure if this information is already printed when controller processes `reelect` etc.,0,0.9062480330467224
204259617,5101,lindong28,2018-07-22T23:45:57Z,"just in case this patch causes any issue, it may be useful if we still print the message such as `error completing reassignment of partition ...`. if it makes sense, can you add the additional log based on the existing log (if exists) here and in other places where the `controllermovedexception` is caught and thrown?",0,0.9941496849060059
204259978,5101,lindong28,2018-07-22T23:56:12Z,"can we specify `zkversion` in the name, e.g. `controllerzkversioncheck`? also, can you add the return type to the method signature?",0,0.995098888874054
204260316,5101,lindong28,2018-07-23T00:05:52Z,"it seems that checkopresult should be either `checkresult` or `errorresult`. maybe we should throw illegalstateexception otherwise? by doing so we could simplify the signature of `getmultiopresults` to `(code, opresult)`. and we can also simplify the signature of e.g. `createresponse` such that zkversioncheckresultcode is of type `code`.",0,0.9912359714508057
204260401,5101,lindong28,2018-07-23T00:08:58Z,would it be simpler to name it `zkversioncheck`?,0,0.9877703189849854
204260465,5101,lindong28,2018-07-23T00:10:59Z,can you add the return type to the signature of `checkop()`?,0,0.9956794381141663
210026725,5101,hzxa21,2018-08-14T16:53:58Z,done.,0,0.9897913336753845
211706198,5101,hzxa21,2018-08-21T18:12:07Z,done.,0,0.9897913336753845
211706290,5101,hzxa21,2018-08-21T18:12:24Z,done.,0,0.9897913336753845
211706505,5101,hzxa21,2018-08-21T18:13:01Z,done.,0,0.9897913336753845
211706631,5101,hzxa21,2018-08-21T18:13:27Z,done.,0,0.9897913336753845
211707860,5101,hzxa21,2018-08-21T18:16:52Z,that is a good point. i have added a log in the reelect controller event to print out this information.,1,0.9253396391868591
211708052,5101,hzxa21,2018-08-21T18:17:25Z,done.,0,0.9897913336753845
211708354,5101,hzxa21,2018-08-21T18:18:20Z,done.,0,0.9897913336753845
211708407,5101,hzxa21,2018-08-21T18:18:30Z,done.,0,0.9897913336753845
211708530,5101,hzxa21,2018-08-21T18:18:49Z,yes. done.,0,0.9106190204620361
211708610,5101,hzxa21,2018-08-21T18:19:02Z,done.,0,0.9897913336753845
211709050,5101,hzxa21,2018-08-21T18:20:15Z,done.,0,0.9897913336753845
211709057,5101,hzxa21,2018-08-21T18:20:16Z,done.,0,0.9897913336753845
211719034,5101,lindong28,2018-08-21T18:50:34Z,"not sure if this line invokes the callback. maybe we should change it to controllermovedlistener.apply(). if the existing version does not actually execute this callback, then it means all existing test does not catch this issue. then it may be worthwhile adding a test.",0,0.9758747816085815
211720966,5101,lindong28,2018-08-21T18:56:54Z,"nits: it seems a bit confusing that we print more information (i.e. newreplicas) for `controllermovedexception` than all other exception. it may be better to make the log information consistent and still print `error(s""error completing reassignment of partition $tp"", e)`.",0,0.7548969388008118
211721256,5101,lindong28,2018-08-21T18:57:52Z,"can we still print `error(s""error completing preferred replica leader election for partitions ${partitions.mkstring("","")}"", e)` for consistency?",0,0.9945409893989563
211721459,5101,lindong28,2018-08-21T18:58:29Z,nits: can we replace `epoch version is now` with `epoch zk version is now`,0,0.9927707314491272
211731340,5101,lindong28,2018-08-21T19:32:32Z,"since `kafkacontroller.incrementcontrollerepoch()` will always print controllercontext.epochzkversion, the only extra information we are seeking here is the current zkversion of the controller epoch znode. it seems that we only need this information when the broker observes controllermovedexception when it thinks it is controller. since `reelect` is triggered in every broker every time there is controller movement, it may not be very intuitive or necessary to print the extra log here in `relect.process()`. another thing to note that that we would like to know the zkversion of the controller epoch znode that causes the controllermovedexception, but this zk version may have changed after the controller observes controllermovedexception but before the controller processes reelect event. so it is better to read the zkversion earlier (e.g. in `controllereventthread.dowork()`) than later. the best solution is probably to include the expected zkversion in the message of `controllermovedexception` thrown by `maybethrowcontrollermoveexception()`.",0,0.9805041551589966
211734782,5101,lindong28,2018-08-21T19:44:24Z,"given that there may be other zookeeper operation other than `controllerzkversioncheck` which can also check the zkversion of the corresponding znode, some response may also show `zkversioncheckresultcode != code.ok` and cause `maybethrowcontrollermoveexception` to throw `controllermovedexception` even if it is not for the `controllerzkversioncheck`. will this be a problem? also, any chance we can also include the expected zkversion in the message of `controllermovedexception`?",0,0.9901186227798462
211735664,5101,lindong28,2018-08-21T19:47:24Z,"for code style consistency, can you change the code to use one of the following styles: [code block] or [code block]",0,0.9941703081130981
211738667,5101,lindong28,2018-08-21T19:57:09Z,"nits: i am not sure what is the expected code style here. but if there is no clear standard and it is not very obvious, it is probably simpler to keep the existing style so that we avoid back-and-force change in the open source community.",0,0.9791160225868225
212047310,5101,hzxa21,2018-08-22T17:51:22Z,done.,0,0.9897913336753845
212050784,5101,hzxa21,2018-08-22T18:01:05Z,"yes, i think it is better to include the expected zkversion in the zookeeper response and extract the information from the response when throwing `controllermovedexception`. i have added `zkversioncheckresult: option[zkversioncheckresult]` to achieve this.",0,0.9899283051490784
212059088,5101,hzxa21,2018-08-22T18:24:40Z,make sense. i have removed the extra logs and included the expected zkversion in the message of `controllermovedexception`.,0,0.9894687533378601
212059196,5101,hzxa21,2018-08-22T18:24:57Z,done.,0,0.9897913336753845
212059233,5101,hzxa21,2018-08-22T18:25:04Z,done.,0,0.9897913336753845
212059283,5101,hzxa21,2018-08-22T18:25:13Z,done.,0,0.9897913336753845
212059557,5101,hzxa21,2018-08-22T18:26:05Z,i have changed it to `controllermovedlistener.apply()`. will add a test in future commits.,0,0.9950489401817322
212083665,5101,lindong28,2018-08-22T19:43:26Z,nits: can we also replace `-1` with `zkversion.matchanyversion`?,0,0.9935139417648315
212085220,5101,lindong28,2018-08-22T19:49:09Z,it seems that we need extra indentation for the body of the `if` statement.,0,0.9868054389953613
212086207,5101,lindong28,2018-08-22T19:52:42Z,`zoodefs` seems to be unused.,0,0.9911619424819946
212086264,5101,lindong28,2018-08-22T19:52:52Z,`checkresult` seems to be unused.,0,0.9881014823913574
212086460,5101,lindong28,2018-08-22T19:53:36Z,`checkresult` and `errorresult` seems to be unused.,0,0.9920336604118347
212128308,5101,hzxa21,2018-08-22T22:18:47Z,fixed.,0,0.9905837774276733
212128341,5101,hzxa21,2018-08-22T22:18:56Z,removed.,0,0.9612457156181335
212128387,5101,hzxa21,2018-08-22T22:19:03Z,removed.,0,0.9612457156181335
212128438,5101,hzxa21,2018-08-22T22:19:10Z,removed.,0,0.9612457156181335
212144205,5101,junrao,2018-08-22T23:42:44Z,"hmm, technically, only when the error code is badversion, it's an indication that the controller has moved. for other errors, we probably just want to propagate as they are to the caller.",0,0.9689444899559021
212144563,5101,junrao,2018-08-22T23:44:48Z,could this just be controllermovedlistener()?,0,0.9922162294387817
212147981,5101,junrao,2018-08-23T00:05:44Z,"we probably need to be a bit careful about bumping up the controller epoch at the beginning of oncontrollerfailover(). currently, the reading and the incrementing of the controller epoch is done independently after the controller path has been created successfully. this can create the following problem. broker a creates the controller path and is about to call oncontrollerfailover(). admin deletes the controller path and broker b creates the controller path, reads the controller epoch and updates it to 1. broker a reads the controller epoch and updates it to 2. now broker b is the controller, but its controller epoch is outdated. one way to address this issue is to use multi() when creating the controller path. to elect a new controller, a broker first reads the current controller epoch from zk and then do a multi() to (1) write the controller path (2) do a conditional update to the controller epoch. not sure if this is the best way though.",0,0.9691652655601501
212153922,5101,junrao,2018-08-23T00:48:34Z,we log e here but not in line 260. it would be useful to be consistent.,0,0.9924594759941101
212155652,5101,junrao,2018-08-23T01:01:49Z,could this be private?,0,0.9816126227378845
212155764,5101,junrao,2018-08-23T01:02:40Z,could this be private?,0,0.9816126227378845
212793210,5101,hzxa21,2018-08-25T08:48:27Z,done.,0,0.9897913336753845
212793216,5101,hzxa21,2018-08-25T08:48:36Z,yes. done.,0,0.9106190204620361
212793218,5101,hzxa21,2018-08-25T08:48:43Z,yes. done.,0,0.9106190204620361
212793233,5101,hzxa21,2018-08-25T08:49:02Z,that is a good point. fixed.,1,0.9799613356590271
212793237,5101,hzxa21,2018-08-25T08:49:13Z,yes. fixed.,0,0.9165666699409485
212793993,5101,hzxa21,2018-08-25T09:25:41Z,"thanks for pointing this out. this is indeed a very dangerous race condition. if it happens, the current controller (broker b) cannot update any zookeeper state due to controller epoch zkversion mismatch and no other broker can become the controller because the current controller (broker b) does not release the ""lock"" for `\controller` znode. wrapping `\controller` creation and `\controller_epoch` update in a zookeeper transaction can prevent this race condition and i think it is a safe option. i will make the change and see whether there will be performance overhead in the perf testing.",1,0.9709573984146118
212843697,5101,lindong28,2018-08-26T23:56:09Z,"hey , it seems that what you and jun suggested to do is to have a single multiops that 1) updates controller path, 2) read controller epoch and 3) updates controller epoch. another alternative approach is to have a single multiops that 1) updates controller path and 2) reads controller epoch with its zkversoin. then the controller can updates controller epoch with the addition zkversion check. do you think the alternative approach would avoid the race condition and ensure correctness? if so, i am wondering if the alternative would be easier to reason about. i find it a bit easier because the it follows the idea that all zookeeper write operation by controller will be based on the controller epoch zkversion check, except for the controller znode write operation which by design can not rely on the controller epoch zkversion check. and a multiop that does one write and one read seems simpler than a multiop that does write-read-write.",0,0.8953091502189636
212868803,5101,hzxa21,2018-08-27T05:26:48Z,"from a design and code readability perspective, i agree with what you have proposed (first atomic read `\controller_epoch` and create `\controller`, then update `\controller_epoch`). from the implementation perspective, zookeeper does not have a `read` op meaning that we cannot perform `read` operation with the `multi` (see [a link] basically, we use the time when a broker succeeds in incrementing the controller epoch as the ""commit"" point of the controller election and use the time when a broker succeeds in creating `\controller` znode as the ""prepare"" point. so for the correctness of the controller election ""commit"", we need to ensure `\controller_epoch` doesn't change from ""prepare"" to ""commit"". to achieve, we can implement the logic using zk `multi` following the steps: 1. read `\controller_epoch` to get the current controller epoch **e1** with zkversion **v1** 2. create `\controller` if `\controller_epoch` zkversion matches **v1** (use zk `multi`) 3. update `\controller_epoch` to be **e1+1** if its zkversion matches **v1** (zk conditional set)",0,0.9753318428993225
212913449,5101,hzxa21,2018-08-27T09:12:14Z,pr updated to address this issue.,0,0.9910156726837158
213035777,5101,lindong28,2018-08-27T16:31:37Z,"if `oncontrollerfailover()` throws `controllermovedexception` after controller has registered itself as controller, it seems possible that some events may have already been inserted into the controller event queue. should we propagate the `controllermovedexception` to `controllereventthread` in order to clear the controller event queue? also, i think in most places we will just name the exception varaible as `e` and throwable variable as `t`. naming them e1, e2, and specifically naming a throwalble as `e2`, seems unusual. i know this style is used in the existing controller code. i am wondering if we can change this.",0,0.9858274459838867
213040676,5101,lindong28,2018-08-27T16:49:32Z,i am wondering if the code will be more readable by removing this method and putting these three lines in `elect()` directly. the method is used only once and it is very short. and the two additional lines used to update the in-memory controllercontext seems more inline with the update of `activecontrollerid` in `elect` than with the name of `tryregistercontroller()`.,0,0.941701352596283
213041250,5101,lindong28,2018-08-27T16:51:44Z,"if there is no existing controller, `getcontrollerepoch` returns `none`. should we still try to register controller in this case?",0,0.9931368827819824
213041939,5101,lindong28,2018-08-27T16:54:32Z,can we rename this method to `maybecreatecontrollerznode` so that it is more consistent with the existing names such as `kafkacontroller.maybetriggerpartitionreassignment()`?,0,0.9944362640380859
213043734,5101,lindong28,2018-08-27T17:01:26Z,currently the variable `timestamp` is passed all the way from `elect()` to `kafkazkclient.trycreatecontrollerznode()`. would it be simpler to replace this variable with `time.milliseconds` in `kafkazkclient.trycreatecontrollerznode()`?,0,0.9928106665611267
213087554,5101,lindong28,2018-08-27T19:29:41Z,"since it is not very intuitive from the method name to understand the meaning of the returned value `(int, int)`, can we add java doc for the returned value? since the new implementation of this method will try to create/update controller znode and increments controller epoch in a safe manner, would it be better to rename the method `registercontrollerandincrementcontrollerepoch`?",0,0.9934792518615723
213089263,5101,lindong28,2018-08-27T19:35:44Z,"info level logging is needed if user always want to see the message and it is usually used when something major is completed, e.g. server is started, rather than when something is attempted. it seems that ""try to create.."" and ""try to increment controller..."" may be more appropriate to be debug level logging if they are needed. the controller epoch and zkversion have been logged at info level in `elect()`.",0,0.991719126701355
213097271,5101,lindong28,2018-08-27T20:03:39Z,"prior to this patch, if setcontrollerepochraw fails and the error is not `nonode`, controllermovedexception will be thrown which will be caught and `triggercontrollermove()` will be executed. after this patch, if setcontrollerepochraw returns a non-ok error code, we will always throw controllermovedexception(), which will be caught in the upper layer without executing `triggercontrollermove()`. i am wondering if we should throw illegalstateexception if the error code suggests something other than controller move, so that we can still execute `triggercontrollermove()` in this scenario.",0,0.959114670753479
213100747,5101,junrao,2018-08-27T20:16:30Z,"for errors other than badversion, we should just propagate the original error as an exception.",0,0.9727858901023865
213112066,5101,junrao,2018-08-27T20:54:22Z,"not sure if we need to explicitly do the creation here. when the controller path is removed, every broker's controller listener will fire, which will trigger the controller election logic again.",0,0.9485535025596619
213118760,5101,hzxa21,2018-08-27T21:18:09Z,you are right. we should propagate the exception here. done.,0,0.9339556097984314
213118780,5101,hzxa21,2018-08-27T21:18:13Z,done.,0,0.9897913336753845
213122229,5101,hzxa21,2018-08-27T21:30:23Z,"no. previously we create `/controller_epoch` on-demand if it does not exist when we try to increment controller epoch. imo, this makes the code hard to read and reason about, especially after this patch because in that way we need to either create `/controller_epoch` if not exists and retry the atomic operation or we have two different atomic operations (one for check+create, the other one for create+create). i think `/controller_epoch` should pre-exists before we actually use it, like other persistent zk paths (e.g. /brokers, /admin/delete_topics) . so i have included `/controller_epoch` in the ""persistentzkpaths"" so that it will be created if not exists on broker startup. in this case, `getcontrollerepoch` should not return none unless admin deletes `/controller_epoch` explicitly, which will ruin the cluster anyway. one drawback of pre-creating `\controller_epoch` is that admin now cannot re-initialize controller epoch by simply deleting `\controller_epoch`. instead, admin should delete `/controller` and `/controller_epoch`, then re-create `\controller_epoch` to achieve this. but i don't know whether that is a valid use case. may i have your opinion?",0,0.9108772873878479
213122263,5101,hzxa21,2018-08-27T21:30:31Z,done.,0,0.9897913336753845
213122308,5101,hzxa21,2018-08-27T21:30:40Z,i agree. fixed.,0,0.8586177825927734
213122347,5101,hzxa21,2018-08-27T21:30:45Z,done.,0,0.9897913336753845
213122376,5101,hzxa21,2018-08-27T21:30:49Z,done.,0,0.9897913336753845
213124615,5101,junrao,2018-08-27T21:39:33Z,"this is called on controllermovedexception. in this case, we know that another broker has become the controller. we just need to clear the event queue, mark the controller as inactive and call oncontrollerresignation() . there is no need to do the controller election. if the new controller is gone afterward, every broker's controller path watcher will be triggered and a controller election will be tried. we probably should rename this method accordingly. also, we probably want to consolidate this method and triggercontrollermove() somehow. to me, the latter will just do what this method does and one more thing, removing the controller path.",0,0.973365843296051
213126066,5101,hzxa21,2018-08-27T21:45:16Z,"per [a link] `/controller_epoch` should exists and `setcontrollerepochraw` should not return `nonode`. if that does happen, we will rely on admin to recover and `triggercontrollermove()` will not help. i agree that throwing `controllermovedexception` is not a good idea. maybe we should just throw `illegalstateexception` and indicate that is a fatal error. what do you think?",0,0.9578319787979126
213136758,5101,junrao,2018-08-27T22:37:02Z,perhaps we should just fold the logic in here to cleareventqueueandreelect() and always let eventmanager handle controllermovedexception.,0,0.9849386215209961
213137736,5101,junrao,2018-08-27T22:42:18Z,could we just do the conditional controller epoch update and the creation of the controller path together in trycreatecontrollerznode()? this avoids an extra zk step.,0,0.993331253528595
213140323,5101,junrao,2018-08-27T22:56:14Z,it process => it processes,0,0.9940882921218872
213140367,5101,junrao,2018-08-27T22:56:27Z,what's ple?,0,0.9912103414535522
213141257,5101,junrao,2018-08-27T23:00:57Z,"suspend()/resume() are deprecated. we can probably simulate this by adding a new controller event type. within the event, we can let it wait on a countdownlatch. once the controller is moved, we can unblock the countdownlatch.",0,0.9923778772354126
213142512,5101,junrao,2018-08-27T23:08:35Z,should we assert the return value?,0,0.9919684529304504
213142665,5101,junrao,2018-08-27T23:09:21Z,it seems that the last one is enough?,0,0.9910604357719421
213142925,5101,lindong28,2018-08-27T23:10:34Z,"prior to this patch, we only include znode in zkdata.persistentzkpaths() if there is no need for the data in the znode. this patch changes this behavior such that we create znode will null data and we assume epoch is -1 if the data is null. the previous approach says that either the znode does not exist, or the znode exists with valid data. the new approach says that either the znode exists with null, or the znode exists with valid data. i personally prefer the previous approach and i would prefer not to define a znode with null data and add additional code to handle that case. and in general it is probably better to keep the existing code if there is no difference in correctness/performance and the difference in code style is not very obvious w.r.t which one is better. it looks like the main concern with the previous approach is about code complexity. how about we have create and call method `maybecreatecontrollerepochznode` at the beginning of `registercontroller()`?",0,0.770599365234375
213143236,5101,junrao,2018-08-27T23:12:20Z,this is an existing issue. could you add a space after the comma in the next line?,0,0.993330180644989
213144214,5101,lindong28,2018-08-27T23:18:33Z,"now that `controllermovedexception` may be handled differently from other exceptions, the logic would be cleaner if we use this exception only when we know the another broker is the controller. thinking about it more, illegalstateexception means something impossible has happened inside the controller state. in this case the exception can happen if controller fails to write to controller epoch znode, which is possible from controller's point of view since zookeeper service is out of controller of the controller. how about `zookeeperclientexception(...)` and include error code in the message of the exception?",0,0.988847017288208
213144670,5101,junrao,2018-08-27T23:21:30Z,"since createandregister has side effect, we should do createandregister().",0,0.9925944209098816
213145071,5101,junrao,2018-08-27T23:23:46Z,should we clear events?,0,0.9888797998428345
213151722,5101,hzxa21,2018-08-28T00:07:57Z,thanks for the suggestion. i have added `maybecreatecontrollerepochznode` and avoid crearting the znode on broker start up.,1,0.9491667747497559
213158074,5101,hzxa21,2018-08-28T01:00:08Z,thanks for the comment. i have updated the pr to throw `controllermovedexception` only when we see badversion in `setcontrollerepochraw`. i also applied the same idea to `maybecreatecontrollerznode`.,1,0.9360302686691284
213179550,5101,hzxa21,2018-08-28T04:11:44Z,"if we don't try to trigger `elect` after we clear the queue and the new controller goes away before we clear the queue, the watch may have put `reelect` in the queue before the clear happens. in this case, that broker will miss controller election. from the correctness point of view, this may not be a problem because at least one other broker will conduct the controller election and become the controller. it is safe to clear and resign if we don't care about fairness in controller election.",0,0.9775895476341248
213436446,5101,junrao,2018-08-28T19:05:53Z,"great point. we could just do reelect here as you suggested. i was thinking that we could also potentially inline the logic (clear the event queue, mark the controller as inactive and call oncontrollerresignation()) here instead of enqueuing the logic to the event queue. however, it seems that the former may be simpler.",1,0.9849803447723389
213610117,5101,omkreddy,2018-08-29T09:38:39Z,"nit: we can remove ""unit""",0,0.9945957064628601
213726027,5101,omkreddy,2018-08-29T15:29:31Z,do we need [code block] flag? looks like none of the tests depends on deletetopicenable=false. all tests are passing without this line.,0,0.9945454597473145
213727391,5101,omkreddy,2018-08-29T15:32:47Z,do we need these changes? tests are passing without these changes.,0,0.9896835088729858
213880720,5101,hzxa21,2018-08-30T01:26:49Z,done.,0,0.9897913336753845
213880874,5101,hzxa21,2018-08-30T01:28:21Z,you are right. changed to throw `controllermovedexception` instead.,0,0.9807044863700867
213880937,5101,hzxa21,2018-08-30T01:28:56Z,agree. code refactored.,0,0.9774162173271179
213880947,5101,hzxa21,2018-08-30T01:29:03Z,done.,0,0.9897913336753845
213881008,5101,hzxa21,2018-08-30T01:29:37Z,"yes, you are right. fixed.",0,0.7818349599838257
213881027,5101,hzxa21,2018-08-30T01:29:43Z,fixed.,0,0.9905837774276733
213881117,5101,hzxa21,2018-08-30T01:30:27Z,i use that to stand for preferredleaderelection. fixed the comments to make it more clear.,0,0.9933465719223022
213881217,5101,hzxa21,2018-08-30T01:31:14Z,remove the deprecated methods and added the additional event for the test.,0,0.9942948222160339
213881231,5101,hzxa21,2018-08-30T01:31:20Z,yes. fixed.,0,0.9165666699409485
213881242,5101,hzxa21,2018-08-30T01:31:27Z,yes. fixed.,0,0.9165666699409485
213881251,5101,hzxa21,2018-08-30T01:31:33Z,done.,0,0.9897913336753845
213881264,5101,hzxa21,2018-08-30T01:31:38Z,done.,0,0.9897913336753845
213881314,5101,hzxa21,2018-08-30T01:31:59Z,done.,0,0.9897913336753845
213881326,5101,hzxa21,2018-08-30T01:32:04Z,done.,0,0.9897913336753845
213881555,5101,hzxa21,2018-08-30T01:34:03Z,yes. i added that for `testcontrollermoveontopicdeletion` but it turns out we don't actually need to enable topic deletion to test throwing and handling `controllermovedexception` happening in `topicdeletion` event. fixed.,0,0.9560497403144836
213881574,5101,hzxa21,2018-08-30T01:34:10Z,removed.,0,0.9612457156181335
214443770,5101,lindong28,2018-08-31T18:44:42Z,would logic be more intuitive to just treat the controllermovedexception as `controllerchange` event and do `mayberesign()`? the code would be simpler since this approach doesn't need `markinactiveandresign`.,0,0.9910769462585449
214444603,5101,lindong28,2018-08-31T18:48:10Z,"nits: ""controller move listener"" -> ""controllermovedlistener"". also, it seems simpler to just remove `trigger controller move listener immediately` as we typically do not log which method is executed next other than logging the event itself. developer is expected look into the code and understand what happens next in the code after this event.",0,0.9930742979049683
214444932,5101,lindong28,2018-08-31T18:49:39Z,can you remove `awaitonlatch` if it is not used?,0,0.9952501058578491
214447851,5101,lindong28,2018-08-31T19:00:50Z,"this line throws `nosuchelementexception` if controller epoch does not exist. it seems better to do `getcontrollerepoch.getorelse(throw new illegalstateexception(""...""))`.",0,0.9930077791213989
214524631,5101,lindong28,2018-09-01T22:51:44Z,would it be more consistent with the other code in this method to do `case code.ok =>`?,0,0.9927536845207214
214524720,5101,lindong28,2018-09-01T22:59:50Z,"when sre deletes controller znode, multiple brokers may be doing `elect()` concurrently and all but one broker will find that the controller znode alread exists. prior to this patch, these brokers will log `debug(s""broker $activecontrollerid was elected as controller instead of broker ${config.brokerid}"")` if controller znode exists and the controller id is not this broker. after this patch, these brokers will log `error(s""error while creating ephemeral at ${controllerznode.path}, node already exists and owner ${getdataresponse.stat.getephemeralowner} does not match current session ${zookeeperclient.sessionid}"")` and `error(s""error while electing or becoming controller on broker ${config.brokerid} because controller moved to another broker"", e)` if controller znode exists and the controller id is not this broker. since we expect most brokers to find znode to be created by another broker during `elect()`, we probably want to keep the old behavior instead of having error level logs.",0,0.993316113948822
214524844,5101,lindong28,2018-09-01T23:09:45Z,"it seems that we can enter this state only if broker executes `registercontrollerandincrementcontrollerepoch()` and finds that the controller znode has already been created by itself. the question is, is this possible? previously if broker tries to create controller znode and node already exists, the broker will simply read the controller id from the controller znode and move on. this patches added quite a few new logic in `controllernodeexistshandler()`, e.g. uses zk session id to detect whether the controller znode is created by this broker, handles the scenario that the controller znode is created by this broker. so the new code is more complicated than the previous version. can you explain a bit why we need these new logic?",0,0.983668863773346
214525056,5101,lindong28,2018-09-01T23:28:05Z,is it possible for error code to be `code.ok` while `zkversioncheckresult.opresult` is of type `errorresult`?,0,0.994283139705658
214525058,5101,lindong28,2018-09-01T23:28:33Z,is it possible for `controllerepochznode.path` to be different from `zkversioncheck.checkpath`?,0,0.9939736723899841
214534027,5101,hzxa21,2018-09-02T09:15:22Z,"yes. for example, if we wrap `check` + `create` in zookeeper `multi`, and `multi` fails due to `create` fails, the result of `check` will be of type `errorresult` with `code.ok` as error code.",0,0.985913097858429
214534041,5101,hzxa21,2018-09-02T09:15:47Z,`awaitonlatch` is used in `controllerintegrationtest`,0,0.994770348072052
214534378,5101,hzxa21,2018-09-02T09:28:42Z,"in short, the purpose of `controllernodeexistshandler` is to mimic `checkedephemeralcreate `, which previously is used to create `/controller` ephemeral node. in `checkedephemeral`, we need to double check the owner of the node if we saw `code.nodeexists`. i think the purpose of the check and the additional logic is to handle transient network connection loss while creating the ephemeral. let's say our client sent a `create` request to zookeeper to create ephemeral znode and zookeeper receives this request and successfully creates the znode but fail to send back the response to our client because of transient network issue. in `retryuntilconnected`, our client tries to resend the request and gets the `code.nodeexists`. in this case, our client actually successfully creates and owns the znode.",0,0.9844975471496582
214534566,5101,hzxa21,2018-09-02T09:36:15Z,currently no. the check here is for general purpose and safety because the zkversioncheck can apply on any znode if needed.,0,0.9908047914505005
214535433,5101,hzxa21,2018-09-02T10:15:22Z,agree. fixed.,0,0.9858681559562683
214535436,5101,hzxa21,2018-09-02T10:15:28Z,done.,0,0.9897913336753845
214535441,5101,hzxa21,2018-09-02T10:15:39Z,done.,0,0.9897913336753845
214535445,5101,hzxa21,2018-09-02T10:15:54Z,yes. done.,0,0.9106190204620361
214535450,5101,hzxa21,2018-09-02T10:16:05Z,agree. fixed.,0,0.9858681559562683
214542290,5101,lindong28,2018-09-02T14:12:48Z,"the creation of the ephemeral znode `/controller` is probably a bit different from the creation of other ephemeral znode. the broker which creates the ephemeral znode `/controller` is explicitly specified in the znode data. thus the old approach, which reads the broker id from the controller znode after seeing `code.nodeexists`, seems ok. and that old approach seems to handle the network connection loss scenario described here. i am wondering if we can use the old approach since its logic looks simpler. what do you think?",0,0.9655280113220215
214542333,5101,lindong28,2018-09-02T14:14:01Z,cool. i see.,1,0.7881407737731934
214542476,5101,lindong28,2018-09-02T14:17:24Z,got it. could you add a comment above the case class `` that says `used only by test`? this is similar to e.g. `replicamanager.markpartitionoffline(...)`.,0,0.9193404316902161
214542542,5101,lindong28,2018-09-02T14:19:30Z,got it.,1,0.8578740358352661
214542750,5101,lindong28,2018-09-02T14:25:53Z,"btw, for the case `getdataresponse.stat.getephemeralowner != zookeeperclient.sessionid`, we know this case may happen and the code will automatically recover from this. in this case it is probably better to log at warning level instead of error level. here is a good explanation for how to choose log level. [a link]",0,0.984476625919342
214760829,5101,hzxa21,2018-09-03T22:52:10Z,"i am a little bit confused about what do you mean by the old approach. are you referring to `checkedephemeralcreate`? the logic in `controllernodeexistshandler ` is essentially the same as `checkedephmeralcreate` when the node already exists, except that `controllernodeexistshandler` will read `/controller_epoch` to get back the epoch zkversion when the owner of `/controller` is the current broker.",-1,0.5412930250167847
214780256,5101,lindong28,2018-09-04T03:43:44Z,"my bad. i missed the fact that the controller znode was created using `kafkazkclient.checkedephemeralcreate()` which has the logic similar to what you are doing here. it seems that the most important logic in the `kafkazkclient.checkedephemeralcreate` is to translate `code.nodeexists` to `code.ok` for the znode creation operation if `getdataresponse.stat.getephemeralowner == zookeeperclient.sessionid`. this logic was added in [a link] by onur. my understanding is that, in case of connection issue between broker and zookeeper, it is possible for controller znode to be successfully created and yet the return code is `code.nodeexists`. `kafkazkclient.checkedephemeralcreate` will handle this scenario properly. it will be good for to clarify whether this understanding is correct so that we can decide whether we should keep this logic. here is another question. with the current patch, if the controller znode creation has failed due to znode exists exception and then broker find that `getdataresponse.stat.getephemeralowner == zookeeperclient.sessionid`, it seems `registercontrollerandincrementcontrollerepoch()` can return `(newcontrollerepoch, stat.getversion)` if `epoch == newcontrollerepoch`. but is controller epoch incremented in this case? if not, then it seems something is wrong?",-1,0.9861792325973511
214995831,5101,hzxa21,2018-09-04T17:11:11Z,"i re-think about your previous suggestion for checking the payload of `/controller` only and i think it will work. i will check with onur offline to understand more about `checkedephemeralcreate` and confirm. in terms of your second concern, if we already see `getdataresponse.stat.getephemeralowner == zookeeperclient.sessionid`, that means `/controller` has been created successfully. since the only code path to create `/controller` is within a zookeeper transaction along with the `/controller_epoch` update, we can infer that the controller epoch must get incremented in this case.",0,0.7343019247055054
215069911,5101,hzxa21,2018-09-04T21:17:26Z,"discussed with onur offline, the purpose of `getafternodeexists` in `checkedephemeral` is indeed used to handle the case when zk connection loss happens. after digging around both zookeeper and kafka codes, we think it is safe to remove the extra complexity for `controllernodeexistshandler` in this pr when we make `/controller` creation and `/controller_epoch` update atomic. so the logic will be: 1). try to create `/controller_epoch` if not exists 2). read `/controller_epoch` from zk 3). atomically create `/controller` and update `/controller_epoch` 4). if 3) throws nodeexistsexception, read `/controller` and if controller id in zk equals the current broker id and if controller epoch in zk equals the expected epoch, successfully finish controller election; otherwise, throw controllermovedexception.",0,0.9883965849876404
215105046,5101,junrao,2018-09-05T00:26:22Z,"since we are doing a conditional setdata in line 117, we don't need the check operation here.",0,0.9931955337524414
215107229,5101,junrao,2018-09-05T00:41:49Z,"if the client loses a connection to a zk server in the middle of an operation, the client will get a connectionlossexception. normally, we handle this by retrying through retryrequestsuntilconnected(). so, we probably need to create a similar routine to retry on connectionlossexception when doing transaction.commit() too. the controller path could have been created successfully when connectionlossexception was incurred. a retry could result in either nodeexistsexception or badversionexception. you handled the former properly in the code below. we will need to do the same thing for the latter.",0,0.9839370250701904
215109171,5101,junrao,2018-09-05T00:56:27Z,"for any other types of exceptions, we want to just propagate the keeperexception to the caller.",0,0.9911963939666748
215109447,5101,junrao,2018-09-05T00:58:36Z,"in the common case, the controller epoch path already exists. so, perhaps it would be better to always do getcontrollerepoch first and then try maybecreatecontrollerepochznode if we hit a nonodeexception.",0,0.9900918006896973
215109576,5101,junrao,2018-09-05T00:59:41Z,the info level will be too verbose if we call maybecreatecontrollerepochznode() on every controller election.,0,0.8854353427886963
215112397,5101,junrao,2018-09-05T01:22:17Z,"""before the pre-defined logic is triggered and before it processes controller change."" it seems that we just need one of the two before?",0,0.9919840693473816
215135718,5101,junrao,2018-09-05T04:55:18Z,"hmm, i am not sure this is safe. the controller path could have been deleted and grabbed by another broker in the window between line 123 and here. then, we would have grabbed the wrong controller epoch.",0,0.7540798187255859
215176421,5101,hzxa21,2018-09-05T08:22:50Z,"you are right. but in line 133 we will check the epoch value. if it is different from what we expected, we will throw `controllermovedexception`. in the case of `/controller` gets deleted between line 123 and 127, and another broker becomes the controller, the controller epoch will increment accordingly, causing line 133 to fail.",0,0.9897493720054626
215359852,5101,junrao,2018-09-05T17:28:33Z,ah. ok. that's fine then.,0,0.7016391754150391
215360130,5101,junrao,2018-09-05T17:29:25Z,"should we explicitly call return here? otherwise, it seems that we are always throwing controllermovedexception.",0,0.9864060282707214
215418284,5101,hzxa21,2018-09-05T20:40:41Z,that's right. fixed.,0,0.9791172742843628
215418324,5101,hzxa21,2018-09-05T20:40:47Z,done.,0,0.9897913336753845
215418651,5101,hzxa21,2018-09-05T20:41:51Z,here we don't catch other types of exceptions so the keeperexception is already propogated to the caller.,0,0.9902251362800598
215420284,5101,hzxa21,2018-09-05T20:47:19Z,done.,0,0.9897913336753845
215420905,5101,hzxa21,2018-09-05T20:49:25Z,"this log will only get print when `/controller_epoch` is absent, which is typically when the cluster gets initialized, not on every controller election.",0,0.9919230341911316
215420928,5101,hzxa21,2018-09-05T20:49:31Z,fixed.,0,0.9905837774276733
215420986,5101,hzxa21,2018-09-05T20:49:43Z,ah... my bad. fixed.,-1,0.9950957894325256
215444417,5101,junrao,2018-09-05T22:25:17Z,"on connectionlossexception, it's not efficient to blindly retry immediately. instead, it's better to wait until the zk connection is ready before retry. you can check how this is done in retryrequestsuntilconnected().",0,0.9914899468421936
215444912,5101,junrao,2018-09-05T22:27:36Z,"it is possible that the controller_epoch path is created by another broker between getcontrollerepoch() and createcontrollerepochznode(). in this case, we want to get the controller epoch again, instead of throwing controllermovedexception.",0,0.9911342263221741
215447046,5101,junrao,2018-09-05T22:37:52Z,it seems that every usage of kafkacontroller.initialcontrollerepoch and kafkacontroller.initialcontrollerepochzkversion as 0 requires subtraction by 1. could we just define them as 0?,0,0.9905961751937866
215448079,5101,junrao,2018-09-05T22:43:14Z,"according to zk doc, multi propagates the error from one of the operations. the badversionexception could be the result of a retry after connectionlossexception. so, it seems that we need to handle it in the same way as nodeexistsexception.",0,0.9910257458686829
215462227,5101,hzxa21,2018-09-06T00:10:45Z,got it. thanks for pointing this out.,1,0.9919638633728027
215462635,5101,hzxa21,2018-09-06T00:13:29Z,"if the controller_epoch path is created by another broker between getcontrollerepoch() and createcontrollerepochznode(), i was thinking whether we can infer that other broker wins in this round of controller election even if it hasn't created the controller znode. after a second thought, i think we should follow what you suggested for extra safety because if the broker fails to talk to zk for some reason, the cluster will get into a no-controller state.",0,0.9815401434898376
215466660,5101,hzxa21,2018-09-06T00:45:31Z,"correct me if i am wrong, i think there are two cases when we see badversionexception here: 1. another round of controller election kicks in and the controller does switch. it is safe to throw `controllermovedexception` in this case. 2. the current broker loss zk connection after zk successfully finishes the transaction, **but the controller znode is gone before the next retry**. in this case, another round of controller election will be triggered by zk watcher `handledeleted`. so i think it is also safe to throw `controllermovedexception` here.",0,0.9229941368103027
215467856,5101,hzxa21,2018-09-06T00:55:55Z,yes. done.,0,0.9106190204620361
215467866,5101,hzxa21,2018-09-06T00:56:00Z,fixed.,0,0.9905837774276733
215467880,5101,hzxa21,2018-09-06T00:56:06Z,done.,0,0.9897913336753845
215561349,5101,omkreddy,2018-09-06T09:42:13Z,nit: missing expectedcontrollerepochzkversion params in method comments,0,0.9948379397392273
215570923,5101,omkreddy,2018-09-06T10:12:30Z,can we use initialcontrollerepochzkversion constant in place of zero?,0,0.9944962859153748
215576221,5101,omkreddy,2018-09-06T10:31:49Z,looks like this line is not required.,0,0.9882269501686096
215711690,5101,hzxa21,2018-09-06T17:28:21Z,added.,0,0.9917559623718262
215711716,5101,hzxa21,2018-09-06T17:28:29Z,sure. done.,0,0.9720492362976074
215711801,5101,hzxa21,2018-09-06T17:28:43Z,thanks for pointing out. removed.,1,0.9293795824050903
215738649,5101,junrao,2018-09-06T18:52:06Z,perhaps it's better to name this maybecreatecontrollerepochznode?,0,0.9901228547096252
215740626,5101,junrao,2018-09-06T18:58:19Z,"i was thinking about case 2, but with the controller path still there. the zk multi api doesn't say that it will run the operations in a multi request in any particular order. so, during the retry on a connectionlossexception, it may be possible that the conditional update of the controller epoch path is executed first and a badversionexception is thrown?",0,0.9877533316612244
215769317,5101,hzxa21,2018-09-06T20:38:10Z,"thanks for the prompt reply! i actually checked both client and server side codes of zookeeper, the implementation honors the order and the thrown exception will correspond to the first error it sees. but since the muli api doesn't explicitly say that it is the case or it will maintain this guarantee in the future, i agree to also handle badversion the same way as nodeexists for safety given that the performance overhead is little.",1,0.9902700185775757
215773516,5101,hzxa21,2018-09-06T20:49:54Z,done.,0,0.9897913336753845
215773534,5101,hzxa21,2018-09-06T20:49:58Z,done.,0,0.9897913336753845
215775823,5101,junrao,2018-09-06T20:57:12Z,could this be private?,0,0.9816126227378845
215779888,5101,hzxa21,2018-09-06T21:11:24Z,done.,0,0.9897913336753845
215847375,5101,lindong28,2018-09-07T05:09:12Z,"i have two questions here: 1) when would we enter a scenario that `controllerid == curcontrollerid` and `epoch != newcontrollerepoch)`? 2) currently when this happens, `checkcontrollerandepoch` will throw `controllermovedexception()`, which is caught in `kafkacontroller.elect()` and trigger `mayberesign()`. however `mayberesign()` will do nothing because `controllerid == curcontrollerid` and this broker is considered to be the active controller. in this case no other broker will be controller. and the current broker will not function properly as controller because it has not executed `oncontrollerfailover()`. so maybe we should throw `illegalstateexception` here if `controllerid == curcontrollerid` and `epoch != newcontrollerepoch)`?",0,0.9868869185447693
215847674,5101,lindong28,2018-09-07T05:12:27Z,"in `maybecreatecontrollerepochznode()`, we throw `illegalstateexception(...)` if we first find controller epoch znode exists and then find it disappeared. following the same logic, it is probably consistent and reasonable to throw `illegalstateexception(...)` if `checkcontrollerandepoch(...)` can not read controller epoch, right?",0,0.9916261434555054
215849517,5101,lindong28,2018-09-07T05:28:04Z,"if `registercontrollerandincrementcontrollerepoch()` has successfully written the broker id to controller znode but then an illegalstateexception is thrown (e.g. in the case `controllerid == curcontrollerid` and `epoch != newcontrollerepoch` described in the other comment), an illegalstateexception will be thrown which is caught in `elect()` and `triggercontrollermove()` will be executed. however, since the `activecontrollerid` has not been updated, `isactive()` is evaluated to false and `triggercontrollermove()` will do nothing. maybe we should first do `activecontrollerid = zkclient.getcontrollerid.getorelse(-1)` in `triggercontrollermove()`. also, to be consistent with most other usage of `isactive()`, can we do something like the code below instead of using if/else? [code block]",0,0.993459939956665
215849923,5101,lindong28,2018-09-07T05:31:43Z,nits: can we use `controllercontext.epochzkversion` instead of using `expectedcontrollerepochzkversion` to be consistent with other usage of `controllercontext.epochzkversion` in this patch?,0,0.9933069348335266
215851146,5101,lindong28,2018-09-07T05:41:07Z,nits: `successfully create` => `successfully created`,0,0.9920389652252197
216039463,5101,hzxa21,2018-09-07T17:54:48Z,"1. because we first get /controller and then get /controller_epoch (rather than do it atomically), it is possible that after we see `controllerid == curcontrollerid` and before we get /controller_epoch, another round of controller election is triggered. in this case, we will see `epoch != newcontrollerepoch`. 2. when we see `epoch != newcontrollerepoch`, `controllerid == curcontrollerid` does not hold because another broker must become the controller. in this case, `mayberesign` will work fine.",0,0.986346423625946
216039681,5101,hzxa21,2018-09-07T17:55:27Z,make sense to me. will fix it.,0,0.5681235790252686
216044300,5101,hzxa21,2018-09-07T18:11:45Z,"in `oncontrollerresignation`, `controllercontext` will be reset. so here we need to keep the value before `oncontrollerresignation` and reuse it in deletion.",0,0.994049072265625
216048155,5101,hzxa21,2018-09-07T18:25:39Z,yes. fixed.,0,0.9165666699409485
216048195,5101,hzxa21,2018-09-07T18:25:45Z,done.,0,0.9897913336753845
216048226,5101,hzxa21,2018-09-07T18:25:51Z,fixed.,0,0.9905837774276733
216049295,5101,lindong28,2018-09-07T18:30:20Z,thanks for the explanation. this makes sense.,1,0.953412652015686
216049364,5101,lindong28,2018-09-07T18:30:36Z,this makes sense.,0,0.9870937466621399
216108832,5101,junrao,2018-09-07T23:23:46Z,": actually, i am wondering if it's simpler to replace lines 116-124 with a check that the ephemeral owner of the controller path equals to the zk session id (like we did before in checkedephemeralcreate()). the controller path or the controller epoch path could change after that check. but that's fine and will be handled by the next zk event on the controller path change.",0,0.9848982691764832
216150289,5101,hzxa21,2018-09-09T07:49:41Z,it is safe to replace the /controller payload check with session id check but we still need to read /controller_epoch to get back the corresponding zk version if we loss connection when doing the zk transaction.,0,0.9932843446731567
216521044,5101,junrao,2018-09-11T01:18:07Z,"hmm, to me, if the ephemeral owner of the controller path equals to the zk session id, it means that at that particular time, the controller path and the controller epoch path are created by the current zk session, and therefore the controller epoch used for creation should be valid. this seems to be equivalent as checking the value of the controller path and the controller epoch value. in both cases, after the check, the controller could change again. however, that will be handled by the zk watcher event.",0,0.9804865121841431
216524610,5101,lindong28,2018-09-11T01:45:34Z,"my understanding is that the approach using ephemeral owner has the same performance and correctness guarantee as the current approach which uses epoch from the znode data. the approach using ephemeral owner is probably more intuitive/readable because it exactly handles the root cause of `nodeexistsexception | _: badversionexception`, i.e. `checkcontrollerandepoch()` should effectively translate nodeexistsexception/badversionexception to `code.ok` if and only if `ephemeral owner of the controller path equals to the zk session id`. and it is also more consistent with the existing logic in `checkedephemeralcreate()`. if it sounds reasonable, maybe we can have a minor followup patch (without requiring a jira ticket) to improve it.",0,0.9821473360061646
216723540,5101,junrao,2018-09-11T15:57:24Z,"i was thinking that the ephemeral owner approach will be cheaper since we only need to read the controller path, not both controller path and the controller epoch path.",0,0.9804362654685974
216757532,5101,hzxa21,2018-09-11T17:41:08Z,"from the correctness and performance point of view, checking `/controller` payload and checking `/controller` ephemeral owner is the same. the question is whether we need to read `/controller_epoch`. the reason why i do it is because if `nodeexistsexception| badversionexception` happens, we no longer have the `stat` (new zkversion) of `/controller_epoch` even though the `/controller_epoch` update succeeds in zookeeper server. we can avoid the extra read on `/controller_epoch` if we can assume that zkversion is always incremented by one. since `/controller_epoch` zkversion is critical for us after this patch and zookeeper doc does not explicitly say that this assumption holds, i think it is safer to do one extra read during controller election.",0,0.9873807430267334
217395000,5101,junrao,2018-09-13T14:01:19Z,: that's a great point. thanks. then we can just keep the code as it is.,1,0.9951937794685364
263337259,6295,enothereska,2019-03-07T11:13:10Z,not clear from the kip why you need to keep track of both downstream and upstream offset.,0,0.9574127197265625
263338227,6295,enothereska,2019-03-07T11:16:00Z,looks like it's missing the methods like shouldcheckpointtopic. i'm assuming that is because this is still wip.,0,0.9764496684074402
263340233,6295,enothereska,2019-03-07T11:22:15Z,the methods here are slightly different from what was described in the kip but you're using the helper class to create adminclient so i'm on with it (as long as we update the kip at some point).,0,0.9919747710227966
263461244,6295,ryannedolan,2019-03-07T16:27:17Z,"the discussion so far has been about emitting upstream offsets and then translating them within remoteclusterutils. however, i've found it's just as easy for the checkpoints to be translated already, which drastically simplifies remoteclusterutils. i'm not certain both upstream and downstream offsets are really necessary here, but it's nice as a sanity check when tailing the checkpoint stream, at least.",0,0.7890142202377319
263462174,6295,ryannedolan,2019-03-07T16:29:15Z,i'll update the kip and call out the changes to the discuss thread prior to marking this ready-for-review.,0,0.9944519400596619
263469394,6295,ryannedolan,2019-03-07T16:44:58Z,"i plan to remove those methods from the kip, for a few reasons: 1) the same logic is encoded in the config, for the most part. e.g. shouldcheckpointtopic is just combining the topic and group whitelists. if we already have those properties, it's best not to provide a second mechanism to redefine the behavior here. i think regexes are sufficiently powerful. 2) i want to enable using the same replication policy for both the connectors and the clients. the clients don't care about most of the methods in the kip, so it's best not to make a client define them. 3) i want replication policies to be pretty much static across an entire organization, not per-cluster. the organization decides what remote topics look like, and then all connectors and clients know how to interpret them. so anything related to specific topics or groups doesn't fit that goal. it's possible that replicationpolicy is no longer a good name for this, but i think it works.",0,0.940963625907898
266605739,6295,williamhammond,2019-03-18T19:29:17Z,should non-replicated topics be filtered before being passed in potentially should this be an exception? in `mirrorclient#upstreamclusters` do we need to filter nulls similar to how `mirrorclient#replicationhops` needs to filter -1?,0,0.9947509169578552
266610210,6295,ryannedolan,2019-03-18T19:41:47Z,"thanks for the suggestion. i think it's reasonable to throw an exception here and in replicationhops(), but i'll need to add an additional method like hassource() or something. seems like a good trade to reduce magic numbers and nulls.",1,0.9863578081130981
269820527,6295,williamhammond,2019-03-28T00:27:21Z,shouldn't this be false?,0,0.9781789183616638
269831729,6295,ryannedolan,2019-03-28T01:45:38Z,thanks :),1,0.9231597781181335
271842542,6295,ryannedolan,2019-04-03T17:05:46Z,"update: i've broken the missing methods out into topicfilter, groupfilter, configpropertyfilter, instead of having them all in replicationpolicy. lmk what you think.",0,0.9804565906524658
272189918,6295,viktorsomogyi,2019-04-04T13:53:44Z,nit: i think it'd be better to keep this and the zkclient on info level as they might be useful in a troubleshooting scenario.,0,0.972594141960144
272195234,6295,viktorsomogyi,2019-04-04T14:05:26Z,"have you considered using the protocol generator framework that is available for clients or would it make this more complicated than necessary? as i see you're simply using these messages as payload and they're not really protocol messages but we might gain something as they generate hashcode and equals methods. also, why are these (checkpoint, heartbeat) not protocol messages?",0,0.9925681352615356
272263389,6295,ryannedolan,2019-04-04T16:28:32Z,"will do, thanks",1,0.9606329202651978
272269172,6295,ryannedolan,2019-04-04T16:44:13Z,"as you say, these aren't really protocol messages, as they are not requests or responses, so i don't think the generator stuff would be a good fit here. maybe there are parts of it i could use. i suppose we could use json here as well. these are simple, unstructured records, so there isn't much to be gained from encoding in json, but it would be nice to get rid of some of this code.",0,0.844651997089386
272558159,6295,kujon,2019-04-05T12:09:56Z,i'm wondering: what is the advantage of using `-1` over say `null` to represent no value?,0,0.9311096668243408
273276967,6295,ryannedolan,2019-04-08T23:31:34Z,that would work too. whatever is more conventional in kafka is fine with me.,0,0.9801939725875854
274046687,6295,ryannedolan,2019-04-10T16:18:38Z,let's change to latency.,0,0.9920782446861267
274671893,6295,halorgium,2019-04-11T21:25:14Z,this needs the `security_protocol` added. [code block],0,0.9960940480232239
281541554,6295,viktorsomogyi,2019-05-07T09:14:22Z,as i understand this is a standard property of the connector config but i think it could be omitted in this case as we're always using mirrorsourceconnector. perhaps we can dynamically add this config in mirrormaker on creation time. or is it there because of the mirrorsinkconnector you'll create according to the kip?,0,0.9923303723335266
281572293,6295,viktorsomogyi,2019-05-07T10:47:32Z,"i think it would be safer to use the `await(long, timeunit)` method with a reasonable value (maybe taking it from a config) with both this one and with `startlatch` so we won't wait if the other thread died and never gonna count down.",0,0.9802281260490417
281855279,6295,ryannedolan,2019-05-07T22:35:30Z,thanks for catching! fixed.,1,0.9940482378005981
282122493,6295,ryannedolan,2019-05-08T15:33:19Z,"yes, mirrormaker fills this in for you normally. this config file is provided just for running mirrorsourceconnector in ""standalone mode"" as follows: ./bin/connect-standalone.sh config/connect-standalone.properties config/connect-mirror-source.properties i.e. without the top-level mm2 driver doing the work for you. organizations that already have a connect-as-a-service cluster will find this useful as well, as they may wish to leverage their existing cluster and just configure it to run the mm2 connectors.",0,0.9848083257675171
282141748,6295,ryannedolan,2019-05-08T16:16:57Z,"this latch is being used as a signal that stop() has been called, so we can't timeout here. but i've added a timeout to the shutdown hook and added a `finally` to ensure that stop() is called.",0,0.9953174591064453
282144470,6295,ryannedolan,2019-05-08T16:23:54Z,"i was able to drop this file entirely, and just use the existing connect-log4j.properties file. it's a little verbose that way, but no more so than connect-distributed.sh.",0,0.9860381484031677
284428968,6295,viktorsomogyi,2019-05-15T20:06:42Z,nit: exception is not thrown by anyone,0,0.8816626071929932
284431092,6295,viktorsomogyi,2019-05-15T20:12:24Z,"there is no clusters config, i think you should add `clusters=upstream`. i get an npe without it: [code block]",0,0.995015561580658
284432272,6295,viktorsomogyi,2019-05-15T20:15:29Z,the adminclient requires a bootstrap.server property. would it make sense to pass either the source or the target's bootstrap.server property? [code block],0,0.9956860542297363
284433973,6295,viktorsomogyi,2019-05-15T20:20:06Z,also on a second note i think it'd be nice to give the users some meaningful error here.,0,0.9759716391563416
284434170,6295,viktorsomogyi,2019-05-15T20:20:36Z,what should be the real version?,0,0.9871581196784973
284443402,6295,viktorsomogyi,2019-05-15T20:45:39Z,"i would consider using `optional ` here and probably in other places in this interface too. these are interface methods, used in a bunch of places and i think it's better to enforce null checks in a safe way.",0,0.9857811331748962
284444200,6295,viktorsomogyi,2019-05-15T20:47:42Z,`.evolving` (and generally to all interfaces),0,0.9897425174713135
284446688,6295,viktorsomogyi,2019-05-15T20:54:18Z,distinct is not needed because of it'll be collected into a set.,0,0.98868328332901
284446809,6295,viktorsomogyi,2019-05-15T20:54:38Z,not needed either.,0,0.9923133254051208
284447065,6295,viktorsomogyi,2019-05-15T20:55:22Z,this method doesn't seem to be used. what's the purpose?,0,0.9915987253189087
284447829,6295,viktorsomogyi,2019-05-15T20:57:31Z,nit: these are not thrown anywhere,-1,0.8849480748176575
284448042,6295,viktorsomogyi,2019-05-15T20:58:06Z,"nit: could be made private, or is there a reason for this to be protected?",0,0.9918361306190491
284448576,6295,viktorsomogyi,2019-05-15T20:59:36Z,this method doesn't seem to be used.,0,0.9851240515708923
284450836,6295,viktorsomogyi,2019-05-15T21:05:45Z,nit: this doesn't seem to be used nor contains the required information.,0,0.9864481687545776
284453686,6295,viktorsomogyi,2019-05-15T21:13:32Z,"usually the kafka convention of internal topic notation is double underscore, such as `__topic-name`. i wonder if we'd should to apply this here too. also it seems to me that there internal topics are `mm2-offsets...`, `mm2-status...`, `mm2-offset-syncs` and `mm2-configs...` for the source and target clusters so we might be able just dynamically populate the topic blacklist for these and that way we'd probably leave the `.internal` notation. just putting this out for conversation.",0,0.9851828217506409
284455448,6295,viktorsomogyi,2019-05-15T21:18:55Z,"why do we need to throw `executionexception, timeoutexception` in these methods?",0,0.9900409579277039
284458764,6295,viktorsomogyi,2019-05-15T21:28:42Z,would it make sense to be the implementation of `org.apache.kafka.common.utils.scheduler`?,0,0.992279052734375
284459118,6295,viktorsomogyi,2019-05-15T21:29:39Z,nit: `interruptedexception` is not thrown.,0,0.9871612191200256
284459418,6295,viktorsomogyi,2019-05-15T21:30:27Z,this doesn't seem to be used.,0,0.9637539386749268
284460793,6295,viktorsomogyi,2019-05-15T21:34:18Z,nit: this isn't actually used.,0,0.9547615051269531
284461711,6295,viktorsomogyi,2019-05-15T21:37:08Z,what should be the real version?,0,0.9871581196784973
284462552,6295,viktorsomogyi,2019-05-15T21:39:45Z,nit: these can be private,0,0.9930322170257568
284462956,6295,viktorsomogyi,2019-05-15T21:41:01Z,how much effort would be to expose this property? as far as i can tell all we need is to provide a config and then we'd be good to go.,0,0.9898861646652222
284463213,6295,viktorsomogyi,2019-05-15T21:41:53Z,nit: what is the real version? :),0,0.8824599981307983
284464247,6295,viktorsomogyi,2019-05-15T21:45:17Z,as i see this is assigned only in `start()` but i think just for the sake of clean code we should use a `final object` to lock.,0,0.990561306476593
284464701,6295,viktorsomogyi,2019-05-15T21:46:34Z,nit: this is not used,0,0.9900055527687073
284464776,6295,viktorsomogyi,2019-05-15T21:46:47Z,nit: this is not used,0,0.9900055527687073
284523993,6295,kamalcph,2019-05-16T03:04:56Z,nit: unused variable.,0,0.9391619563102722
284524085,6295,kamalcph,2019-05-16T03:05:38Z,topic_filter_class_doc -> group_filter_class_doc,0,0.9914078116416931
284524187,6295,kamalcph,2019-05-16T03:06:13Z,unused variable.,0,0.9783101081848145
284524413,6295,kamalcph,2019-05-16T03:07:52Z,whether to include `__transaction_state` internal topic here?,0,0.9927011728286743
284524591,6295,kamalcph,2019-05-16T03:09:16Z,could you change the method name in symmetry to the topic name? (offsetsyncstopic()),0,0.9953385591506958
284524745,6295,kamalcph,2019-05-16T03:10:37Z,give a name to this scheduler to track it in threaddump.,0,0.994921863079071
284524882,6295,kamalcph,2019-05-16T03:11:36Z,give a name to this thread.,0,0.9944444298744202
284525104,6295,kamalcph,2019-05-16T03:13:08Z,"once a lock is taken, no other operation should be done outside the try-catch block. call the `consumer.close()` either inside the try-catch or before taking the lock.",0,0.9954029321670532
284525159,6295,kamalcph,2019-05-16T03:13:30Z,unlock the taken lock.,0,0.9938788414001465
284525244,6295,kamalcph,2019-05-16T03:14:10Z,ie is not thrown. could you please remove the `throws ie`?,0,0.9913820624351501
284526932,6295,kamalcph,2019-05-16T03:26:01Z,consider taking the `lock` before the try-catch block as it's best practice.,0,0.9895119071006775
284611735,6295,kamalcph,2019-05-16T09:13:17Z,"you may have to update the description of the max, min and avg for record_age, replication_latency and checkpoint_latency metric name templates. (eg) the **maximum** age of incoming ...",0,0.9948805570602417
284612564,6295,kamalcph,2019-05-16T09:15:13Z,"`pause()` and `resume()` methods are unused. and, you can merge both these methods by taking action as a parameter.",0,0.994365930557251
284613640,6295,kamalcph,2019-05-16T09:17:47Z,nit: pending todo.,0,0.8594362139701843
284614159,6295,kamalcph,2019-05-16T09:18:56Z,unused variable.,0,0.9783101081848145
284614303,6295,kamalcph,2019-05-16T09:19:17Z,unused variable.,0,0.9783101081848145
284614370,6295,kamalcph,2019-05-16T09:19:26Z,unused variable.,0,0.9783101081848145
284615520,6295,kamalcph,2019-05-16T09:22:05Z,it's better to unlock the taken lock.,0,0.990472674369812
284648386,6295,arunmathew88,2019-05-16T10:48:23Z,"from my experience with large kafka clusters, one node being down for maintenance or so is very common, so for topics with more than one replica in source topic, we should have at least 2 replicas in destination, for the data to be realistically available in failover scenarios. just my thought.",0,0.9773561954498291
284898791,6295,ryannedolan,2019-05-16T21:07:51Z,"this config is for the mirrorsourceconnector alone, not a top-level mm2.properties file. the properties required in either case are distinct. i can see this is a source of confusion, so i'll add a comment here. i think maybe we need an example mm2.properties file as well.",0,0.9874336123466492
284899900,6295,ryannedolan,2019-05-16T21:11:03Z,"you're using the wrong config file (see above). you need something like: clusters = upstream, downstream upstream.bootstrap.servers = ... downstream.bootstrap.servers = ... then, the mirrormaker driver sets up a bunch of connectors with the required properties, which will look like the connect-mirror-source.properties here.",0,0.9905371069908142
284900808,6295,ryannedolan,2019-05-16T21:13:47Z,"i think optional is supposed to be used only within the context of the java 8 streams api. it's not unusual to return nulls in java, nor in this code base. (though coming from scala this hurts a bit :grinning_face_with_smiling_eyes:)",1,0.8803989887237549
284945642,6295,ryannedolan,2019-05-17T00:41:48Z,"will fix, thanks.",1,0.8308497667312622
284947928,6295,ryannedolan,2019-05-17T00:59:12Z,"let's add min.insync.replicas here too, as this is likely to cause problems. h/t",0,0.9932953715324402
284948127,6295,ryannedolan,2019-05-17T01:00:47Z,"yeah let's blacklist anything with `__` prefix, thanks.",0,0.8173967599868774
284948535,6295,ryannedolan,2019-05-17T01:04:18Z,"yeah, herder requires an advertisedurl, tho we don't use it. i'll change this to `not used` to avoid confusion.",0,0.9882148504257202
284948676,6295,ryannedolan,2019-05-17T01:05:40Z,"we can drop these, thanks.",1,0.5423797965049744
284950066,6295,ryannedolan,2019-05-17T01:16:28Z,"i've left this as-is because it's convenient to test whether a topic has a source with `topicsource(topic) != null`, rather than to define and use a separate method like `hassource()` or something.",0,0.9907569289207458
284950514,6295,ryannedolan,2019-05-17T01:19:51Z,"`toset()` will throw an exception if it finds duplicates. this seems unlikely unless someone defines a really strange `replicationpolicy`, but i think it's worthwhile to avoid the exception just in case.",0,0.985346794128418
284952693,6295,ryannedolan,2019-05-17T01:35:53Z,"this is just a convenience method, but i believe it is worthwhile. otherwise it is a bit cumbersome to recreate externally: [code block]",1,0.5599268078804016
284954715,6295,ryannedolan,2019-05-17T01:51:24Z,this is useful for external tooling.,0,0.9777812361717224
284957873,6295,ryannedolan,2019-05-17T02:16:00Z,"i think the `__` should be limited to topics internal to kafka proper. the topics `mm2-offsets...`, `mm2-status...`, and `mm2-config...` are based on connect's defaults, `connect-offsets`, `connect-config` etc, which are not internal per se. i've added .internal to these so that you don't need to configure mm2 to blacklist itself, thought it's an interesting idea to just blacklist them automatically.",1,0.7962438464164734
285062422,6295,enothereska,2019-05-17T10:08:44Z,the readme could be re-worded a bit to start with a quickstart simplest case and then build from there to increasingly more complex cases. this could be done at a later pass too.,0,0.9942488670349121
285063053,6295,enothereska,2019-05-17T10:10:54Z,could we add a sentence on what the implications of this are? it's not immediately clear what should happen if mm runs with same source and target...perhaps nothing at all?,0,0.9890977144241333
285063661,6295,enothereska,2019-05-17T10:12:45Z,should we check in such a sample file in the config folder?,0,0.9948646426200867
285064156,6295,enothereska,2019-05-17T10:14:12Z,nit: mm2.properties or mm2.config?,0,0.9939274787902832
285480888,6295,viktorsomogyi,2019-05-20T08:40:35Z,"yea that would be helpful, people could use it as a template.",0,0.8750662207603455
285488395,6295,viktorsomogyi,2019-05-20T08:57:43Z,"well, oracle's own example uses optional in the context of return values so i think it'd be idiomatic to do so: [a link] generally i agree that in this codebase we often return nulls but if you look at for instance the transactionmanager, it uses optionals this way, so i think it's definitely encouraged here too :) [a link]",1,0.9884365797042847
285507212,6295,viktorsomogyi,2019-05-20T09:42:38Z,on this note we probably want to document that it doesn't work for transactional topics (also as this was one of the first questions on the summit :) ),1,0.9732500910758972
285510919,6295,viktorsomogyi,2019-05-20T09:51:48Z,i think it would make sense to pass `true` (or use the single param super constructor). it helps debugging the config.,0,0.97599196434021
285513326,6295,viktorsomogyi,2019-05-20T09:57:38Z,`type.list` would be better maybe?,0,0.9878689646720886
285518598,6295,viktorsomogyi,2019-05-20T10:10:50Z,i'd like to make a general point but i didn't know any specific places so i'd put it here. it'd be helpful from the usability perspective to validate configs. i've tried to specify this config: [code block] you can notice that i put a `;` in the cluster separator config but nothing thrown an exception saying that i haven't specified the correct clusters (mm2 just started up and shut down).,0,0.9652919173240662
285562725,6295,viktorsomogyi,2019-05-20T12:21:22Z,we might pass `true` if that makes sense.,0,0.9920282959938049
286460327,6295,viktorsomogyi,2019-05-22T12:22:07Z,nit: maybesendoffsetsync?,0,0.9885886907577515
286465012,6295,viktorsomogyi,2019-05-22T12:34:12Z,i was wondering if - would it make sense to make this configurable? - wouldn't this be mostly the same as configuring the `max.in.flight.requests.per.connection` property of the `offsetproducer` and have you thought about using just that config?,0,0.9854308366775513
286471163,6295,viktorsomogyi,2019-05-22T12:48:53Z,i think it would be better to use some timeout here as it spams the log with the below warn message.,0,0.9774959087371826
286475429,6295,viktorsomogyi,2019-05-22T12:58:11Z,as far as i understand offsets would be synced eventually so i think we might want to reconsider if this is a warn level log message (maybe even lower it to debug?).,0,0.9843090772628784
286585537,6295,jeremy-l-ford,2019-05-22T16:41:55Z,should the returned classloader be restored at the end of the method?,0,0.9949629306793213
286638392,6295,harshach,2019-05-22T18:58:03Z,there seems to be null some places and other places -1. if possible can we standardize or leave a comment.,0,0.9822606444358826
288238131,6295,jeremy-l-ford,2019-05-28T18:17:28Z,"i have been testing this branch and used the connector.class option noted above in my configuration. i noticed that records were being copied 3x instead of the expected 1. debugging through the source, apparently that configuration will override the connector name that is setup during mirrormakerconfig.connectorbaseconfig. since mirrormaker attempts to setup the source, health, and checkpoint connectors, i actually ended up with 3 source connectors.",0,0.9615738987922668
288280080,6295,ryannedolan,2019-05-28T20:07:25Z,"-l-ford funny problem! i think this, along with others' experiences here, indicates i need to remove this sample configuration altogether, and just provide a top-level configuration file like in the ""quick start"" above. the connector configuration is just confusing. moreover, it doesn't really demonstrate anything beyond the existing generic connect-standalone.properties file. i'll remove this file, thanks.",-1,0.49873635172843933
289196474,6295,OneCricketeer,2019-05-30T22:26:56Z,"related to i assume with the addition of record header copying, it will also only work for when `log.message.format.version` >= `0.11.0` ? at least, we've noticed that when clients try to use headers (or transactional producers) after broker upgrades, but before log format changes, then they are usually throwing `unknownserverexception`. --- one workaround i did (for an smt) was to conditionally copy the headers to the transformed record. e.g. [a link]",0,0.9878519773483276
289495296,6295,jeremy-l-ford,2019-05-31T18:03:55Z,try/finally close the consumer,0,0.9890298247337341
290088869,6295,ryannedolan,2019-06-04T00:36:16Z,let's just remove the log message altogether.,0,0.989777147769928
290090082,6295,ryannedolan,2019-06-04T00:43:44Z,"i'm not certain, but the other drivers (connect-standalone, connect-distributed) do it this way. i'll just cargo-cult here.",0,0.9805812835693359
290369229,6295,ryannedolan,2019-06-04T15:50:36Z,"my intention is to support 0.11.0 onwards, at least for now. we can revisit making headers optional to support older versions, but i think this probably isn't the only thing that would break before 0.11.0.",0,0.9872835874557495
290371819,6295,ryannedolan,2019-06-04T15:55:40Z,i dropped this file to avoid confusion.,0,0.9672037959098816
290372405,6295,ryannedolan,2019-06-04T15:56:58Z,"this method doesn't contain a conditional branch (the existing maybesendoffsetsync does), so i'll leave this as is.",0,0.9928410053253174
290372816,6295,ryannedolan,2019-06-04T15:57:53Z,"i dropped the logging entirely. there is no harm if tryacquire fails, so better to not spam the log as you say.",0,0.9851672053337097
290407619,6295,ryannedolan,2019-06-04T17:22:51Z,"fixed. this was b/c mm was finding only a single cluster (""upstream;downstream"") and had no source->target pairs to replicated. i've added an exception ""no source->target replication flows"" in this case, which should at least point you in the right direction.",0,0.9898180365562439
291329247,6295,vpernin,2019-06-06T19:06:16Z,is this intended to not set the interrupted flag again ? same question elsewhere like in mirrorsourcetask.cleanup().,0,0.994314968585968
291333700,6295,vpernin,2019-06-06T19:19:28Z,is there a risk the semaphore not to be released if the async send fails internal before invoking this callback ?,0,0.9915493726730347
291354482,6295,vpernin,2019-06-06T20:19:21Z,"the underlying client method seems to use a default timeout of long.max_value, timeunit.milliseconds. i'm worried that it can prevent the jvm to stop ?",-1,0.8609936833381653
291590085,6295,vpernin,2019-06-07T13:24:28Z,the kip seems to refresh.topics is true by default. the property refresh_topics_enabled is named refresh.topics.enabled and the default does not seem to be refresh_topics_enabled_default used. so the topics are not refreshed by default.,0,0.9937021732330322
291660048,6295,ryannedolan,2019-06-07T16:11:37Z,the default is set here: [a link] and used here: [a link] i've verified this works as expected. happy to take suggestions if this is not clear.,1,0.9734702110290527
291839414,6295,williamhammond,2019-06-09T14:58:07Z,don't we need a catch for `org.apache.kafka.common.kafkaexception` as well when calling `consumer.close()`?,0,0.9929139614105225
291840811,6295,williamhammond,2019-06-09T15:44:07Z,i feel like i must be missing something obvious but since the source admin client will be an instance of `kafkaadminclient` since we're calling `[a link] to create the client and the `kafkaadminclient` overrides close as such [a link] are we not actually releasing resources but calling close without a duration? i'm probably misremembering something about inheritance but either way i think we should be passing in a duration here since the default close just is kind of odd vpernin pointed out.,0,0.7662817239761353
296221720,6295,jeremy-l-ford,2019-06-21T12:51:34Z,"based on [a link] seems like the consumer may be null when attempting to close it. also, should the call to close the producer be in a separate try/catch to at least attempt to close the producer in the case where closing the consumer causes an exception?",0,0.9924516081809998
297175786,6295,vpernin,2019-06-25T13:03:58Z,"you're right. i might miss something obvious, but the propagation of topic creation on downstream cluster does not seem to work. the mirrorsourceconnector.refreshtopicpartitions detects a new topic properly and and it requests a task reconfiguration. but the code that really proceed to the topic creation seems to be in mirrorsourceconnector.createtopicpartitions and this task is only executed once at startup and not at the reconfigure phase.",0,0.9775440096855164
298207543,6295,vpernin,2019-06-27T14:30:17Z,"shouldn't we have a check on the enabled status of the herder like b->a.enabled = false ? with a simple setup enabled on the a->b direction and disabled on the b->a, i see that the herder b->a is created and heartbeats are emitted to cluster[a].topic[heartbeats], to its replicated on cluster[b].topic[a.heartbeats] and also on cluster[b].topic[heartbeats].",0,0.9922423362731934
298289975,6295,arunmathew88,2019-06-27T17:34:21Z,"as per the kip the mirrored topic should be writable by mirror maker only, how is this ensured? i couldn't find a filter rejecting any write acls to the topic in this call?",0,0.9954728484153748
298543696,6295,vpernin,2019-06-28T10:37:46Z,"shouldn't we have a public way to deserialize heartbeat object, heartbeat.deserializerecord not being public ?",0,0.9905917048454285
299083439,6295,ryannedolan,2019-07-01T14:55:06Z,"this behavior is subtle but correct. we want heartbeats going everywhere, even to clusters that aren't a target of any source->target replication. this is because we need heartbeats to exist upstream in order to replicate them downstream. if we are replicating a->b, we don't want to emit heartbeats only to b -- that wouldn't really tell us much, except that mm can send to b. what we want to know is how long it takes records to travel from a to b. so we emit heartbeats to a and _replicate them_ to b. this lets us monitor latency between a and b even when no other records are being replicated. specifically, we create herders between every pair of clusters (a fully-connected mesh) and emit heartbeats everywhere. then, for the subset of ""enabled"" replications, we start at least one mirrorsourceconnector task. these tasks _always_ replicate heartbeats, so the result is ""a.heartbeat"" in cluster b whenever a->b is enabled. we could _only_ emit records upstream (i.e. only to sources and not targets) and achieve this same result, but heartbeats are useful for more than measuring cross-cluster latency. emitting heartbeats everywhere makes various other tooling possible. for example, you can query any single cluster and find out about every other cluster just by consuming the heartbeat topic, since heartbeats will have come from everywhere.",0,0.9500609636306763
299085902,6295,ryannedolan,2019-07-01T14:59:43Z,i'm fine with that.,0,0.9213682413101196
299213804,6295,ryannedolan,2019-07-01T20:55:04Z,connector.reconfigure() by default just calls stop() and start(config). there is no other logic related to reconfiguration at present.,0,0.994067907333374
299324123,6295,vpernin,2019-07-02T06:45:34Z,"ok, i understand this conception. maybe, this clear explanation has its place in the kip and the documentation.",0,0.9645145535469055
299339279,6295,vpernin,2019-07-02T07:32:33Z,"i'm just noticing, that in my case, the creation of a new topic (matching replication pattern) upstream is not propagated downstream. the subject of the reconfigure process is just a attempt to explain the problem. kmm2 need to be restarted, so mirrorsourceconnector.createtopicpartitions is called. connector.reconfigure() does indeed stop and start, which would work, but this is not invoked. we call context.requesttaskreconfiguration() and it does not do that.",0,0.9848579168319702
308616567,6295,o-kasian,2019-07-30T09:16:29Z,"this should probably be `this.herderpairs = config.enabledclusterpairs().stream()`, otherwise `a->b.enabled` makes no sense",0,0.9932854175567627
308690793,6295,o-kasian,2019-07-30T12:27:26Z,"`kafka/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/mirrorsourceconnector.java:106` offset sync topic is created in `target`, however offsetproducer uses `config.sourceproducerconfig()` it results in messages like `error while fetching metadata with correlation id 416 : {mm2-offset-syncs.backup.internal=unknown_topic_or_partition}` in logs, and is not able to write offset mappings",0,0.9932543635368347
308953520,6295,ryannedolan,2019-07-30T21:35:28Z,"good catch, thanks!",1,0.9951314926147461
308954111,6295,ryannedolan,2019-07-30T21:37:07Z,see this earlier comment: [a link] i'll add a comment in the code somewhere to explain.,0,0.9959893822669983
310134951,6295,mimaison,2019-08-02T13:37:55Z,`record.value()` can be null here. this leads to [a link],0,0.9952000379562378
310137707,6295,mimaison,2019-08-02T13:44:46Z,"the order of the arguments is inverted, `(short) 1` should be the 2nd argument and the replication factor the 3rd one. the prototype is `createtopic(string topicname, short partition, short replicationfactor, map adminprops)`",0,0.9953823685646057
310138665,6295,mimaison,2019-08-02T13:46:59Z,"the order of the arguments is inverted, `(short) 1` should be the 2nd argument and the replication factor the 3rd one. the prototype is `createtopic(string topicname, short partition, short replicationfactor, map adminprops)`",0,0.9953823685646057
311630254,6295,mimaison,2019-08-07T15:50:11Z,"should this use `config.sourceadminconfig()` instead of `config.targetadminconfig()` ? otherwise, i'm getting: [code block] and the topic is only created in the target cluster.",0,0.9941576719284058
311789488,6295,ryannedolan,2019-08-07T22:29:05Z,"fixed, thanks",1,0.9271016120910645
311789612,6295,ryannedolan,2019-08-07T22:29:31Z,"fixed, thx",0,0.9884433150291443
311790132,6295,ryannedolan,2019-08-07T22:31:41Z,"fixed, thx",0,0.9884433150291443
312966989,6295,mimaison,2019-08-12T14:53:36Z,`x.getkey()` is the topic name. we need to iterate over `topicconfigs.values().entries()` instead to filter out topic properties.,0,0.9940837025642395
312967159,6295,mimaison,2019-08-12T14:53:56Z,should we also filter configs with `static_broker_config` as the source?,0,0.9944362640380859
314489069,6295,ryannedolan,2019-08-15T20:41:47Z,"i dropped the enabledclusterpairs() method, so marking this resolved.",0,0.9948734641075134
314559556,6295,ryannedolan,2019-08-16T01:52:52Z,great catch! i've fixed and added a unit test.,1,0.9959598183631897
314801873,6295,ryannedolan,2019-08-16T16:46:05Z,i _think_ isdefault() will catch that case? not sure.,0,0.9799841046333313
314809527,6295,mimaison,2019-08-16T17:08:11Z,`isdefault()` only matches `configsource.default_config`. see [a link],0,0.9960910677909851
314812870,6295,ryannedolan,2019-08-16T17:17:16Z,"ah, thanks . fixed.",1,0.989273726940155
317319292,6295,ryannedolan,2019-08-23T22:20:08Z,we never block on the semaphore -- only trywait() -- so there is no chance of deadlocking at least. i don't think there is any other consequence if we don't get around to releasing a semaphore.,0,0.98826003074646
317335237,6295,ryannedolan,2019-08-24T00:15:52Z,"do you mean to implement the ..utils.scheduler interface here, or to instead use the internal kafka.utils.kafkascheduler? the latter would work just fine, but i'm reluctant to depend on something in kafka.utils.",0,0.8088313341140747
317342841,6295,ryannedolan,2019-08-24T03:22:37Z,"fixed, thx",0,0.9884433150291443
317343051,6295,ryannedolan,2019-08-24T03:30:54Z,"it's hard to imagine a case where you'd need to tweak this property. i guess if you had offsets.lag.max set to zero, which means every replicated record would cause an offset sync, then you'd run up against the max outstanding offset syncs limit pretty quick. but i don't know why you'd do that. normally offset syncs are very sparse, and it never matters if you drop a few occasionally. so this is mostly an arbitrary number, and anything greater than 0 will work fine.",0,0.9459378719329834
317346004,6295,ryannedolan,2019-08-24T05:39:36Z,"fixed, thx",0,0.9884433150291443
317346028,6295,ryannedolan,2019-08-24T05:41:12Z,"thanks guys, this does seem like a problem. fixed by adding a configurable timeout.",1,0.9821571111679077
323912773,6295,qihongchen,2019-09-12T19:31:32Z,"there's no argument for `""metatadata=%s""`, it should be removed, or add an argument for it (correct the typo as well).",0,0.9920815229415894
326590142,6295,dataGeeek,2019-09-20T11:43:38Z,"knowntargettopics state is currently only refreshed at two occasions: * startup of the connector, before topics in downstream cluster are created and therefore stays empty * new partitions/ dead partitions in upstream cluster are found. in the case of no creation of new partitions in upstream cluster, the state remains empty, which blocks config syncing, since only configs of knowntargettopics will be synced. i propose refreshing the state of knowntargettopics at startup after topics in downstream cluster are created and have provided a pr: [a link]",0,0.9904531240463257
327205321,6295,ryannedolan,2019-09-23T16:15:16Z,great find! merged.,1,0.996408998966217
327276472,6295,dataGeeek,2019-09-23T18:56:10Z,"your're welcome! besides that, our tests of the mm2 were very promising. great work and lgtm",1,0.9972558617591858
328867657,6295,junrao,2019-09-26T23:41:46Z,"hmm, why do we need to call commitrecord twice?",0,0.9713470935821533
328867839,6295,junrao,2019-09-26T23:42:42Z,should we version the value schema for potential future extension? ditto is other newly added schemas.,0,0.9947355389595032
328867958,6295,junrao,2019-09-26T23:43:24Z,could we add the javadoc for each of the public method in this and other user facing classes?,0,0.99430251121521
328867995,6295,junrao,2019-09-26T23:43:34Z,is it useful to have a metric that just captures the lag of the current record?,0,0.9879475235939026
328868071,6295,junrao,2019-09-26T23:43:57Z,should we add max in the description? ditto in a few other places.,0,0.9941449761390686
328868144,6295,junrao,2019-09-26T23:44:25Z,"hmm, the downstream offset doesn't alway advance faster than the upstream. for example, when mirroring a compacted topic, the downstream offset could advance slower than upstream when the upstream offsets have holes.",0,0.9789032936096191
328868189,6295,junrao,2019-09-26T23:44:40Z,"hmm, how do we make sure that the latest offset in offsetsyncstore match what's needed for the consumer offset?",0,0.9849911332130432
328868228,6295,junrao,2019-09-26T23:44:51Z,do we need debug by default? it could slow down the tests on jenkins.,0,0.9748905897140503
328868442,6295,junrao,2019-09-26T23:46:06Z,calling system.currenttimemillis() on every record could be expensive.,0,0.9440290331840515
328868644,6295,junrao,2019-09-26T23:47:12Z,should we update lastsyncupstreamoffset and lastsyncdownstreamoffset only after the offsets have been successfully written to the offset sync topic?,0,0.9951684474945068
328868859,6295,junrao,2019-09-26T23:48:22Z,should offsetsync topic always be single partition?,0,0.9929103255271912
328869797,6295,junrao,2019-09-26T23:53:43Z,should we replicate prefix acls too?,0,0.994594395160675
329268348,6295,ryannedolan,2019-09-27T22:13:48Z,"offset syncs (and checkpoints and heartbeats) are sparse and rare in practice, so this topic is very small. it's only written to when the upstream and downstream offsets for a partition don't match what is expected, which is approximately as rare as duplicate records being sent to a topic. mm2 can run for days without sending a message here. so there isn't a need to have multiple partitions, and doing so would complicate the logic for scanning the topic for a given offset, to some extent.",0,0.9890075922012329
329268969,6295,ryannedolan,2019-09-27T22:15:59Z,"good point, will fix.",1,0.9789354801177979
329274932,6295,ryannedolan,2019-09-27T22:46:42Z,"yes that would be useful, however, not nearly as useful as latency of each record, since latency is more easily aggregated over entire topics (and, externally, over entire clusters), and is much more relevant to the operator. consider that an mm2 operator would not know how to compare a lag of 100 offsets in one partition to a lag of 1 offset in another partition, as they could both represent <1s behind real-time, depending on the size of messages etc. so while offset lag may be very useful to an operator of a specific app consuming from specific topics, it is unlikely useful to an mm2 operator replicating entire clusters.",0,0.9802215695381165
329277034,6295,ryannedolan,2019-09-27T22:59:00Z,"a sourcetask implementation is unlikely to implement both methods. they are nops by default. if it does, it's unlikely an implementation would do the same thing in both methods. if it does, the interface does not guarantee that commitrecord() is called exactly once per record anyway (or even at least once). and indeed other methods, e.g. stop() and commit(), make no such guarantees either. i'd be in favor of deprecating commitrecord(record) to avoid confusion here, but that is out of scope for this kip and pr.",0,0.9807355999946594
329835717,6295,ryannedolan,2019-10-01T00:07:02Z,done,0,0.8682363629341125
329835749,6295,ryannedolan,2019-10-01T00:07:10Z,done,0,0.8682363629341125
329835788,6295,ryannedolan,2019-10-01T00:07:20Z,done,0,0.8682363629341125
329835885,6295,ryannedolan,2019-10-01T00:07:49Z,done,0,0.8682363629341125
329863044,6295,ryannedolan,2019-10-01T03:00:19Z,"good idea, this would improve accuracy of the offset syncs and checkpoints. i've made this change locally and don't see any problems. however, i'd rather not make a functional change this close to a code freeze. let's make this improvement in a short follow-up pr.",1,0.9430711269378662
330097541,6295,junrao,2019-10-01T14:42:48Z,"since this is a public api change, i think it's important to think through the impact to connector developers. i am thinking that we can (1) provide a default implementation of commitrecord(sourcerecord record, recordmetadata metadata) in sourcetask that calls commitrecord(sourcerecord record) by ignoring recordmetadata to provide backward compatibility; (2) only use commitrecord(sourcerecord record, recordmetadata metadata) in workersourcetask; (3) mark commitrecord(sourcerecord record) as deprecated to encourage people to use the new api and document the behavior if both methods are implemented (the implementation for the old api will be ignored). any thought on this?",0,0.984939455986023
330130857,6295,rhauch,2019-10-01T15:41:22Z,"so far, the connect api exposes only a few kafka client types in a few areas (right now just `sinktask`). we should be careful and explicit about making the `sourcetask` interface use `recordmetadata`. but assuming that's okay, i think having connect call two distinct `commitrecord(...)` methods with different signatures is at best confusing for developers (which do i implement) and at worst a potential source of error. we have resolved similar evolutions in the past by following the approach that mentioned, and i think that makes the most sense here. (we've not always deprecated the older method when it still applicable, but in this case i think we'd want to deprecate the older method.) however, before we introduce a new variant of an existing method, we should also consider whether we might need to again modify the signature in the future. if so, we should consider whether it makes sense to create a new interface type to pass to the method that would make it easier in the future. i'm not sure that we do, since the `workersourcetask` calls this from within the producer callback and only when the exception is not null, meaning there currently is no other data available to the invocation.",0,0.9612515568733215
330134311,6295,rhauch,2019-10-01T15:47:50Z,this pr probably needs to mention it is also implementing kip-416.,0,0.989977240562439
330137341,6295,ryannedolan,2019-10-01T15:53:53Z,happy to deprecate the older method if we have concensus here.,0,0.9128616452217102
330149902,6295,ewencp,2019-10-01T16:20:22Z,"given we can use default implementations now, just providing a default implementation and not deprecating seems better. afaik, `recordmetadata` has never been requested before, but a number of connectors use the existing signature for `commitrecord`. calling twice and having to understand that does seem confusing, but having overloads and simplified versions doesn't -- you just get to choose to implement something simpler. we've been pretty conservative with deprecation in the connect and that has served us well wrt broad compatibility -- i think only `onpartitionsassigned/revoked` for sink tasks and a couple of configs have gone through this, and still haven't been removed (with little maintenance cost afaik), which means we've remained cleanly compatible in most ways all the way back to 0.9. i'm generally for deprecation and removal (e.g. there's lots of core configs that i think are unnecessary and could be cleaned up), but only if the cost is worth it. in this case, there *is* a transition cost since the existing api is being used, and i'm not sure the reduction in confusion is worth it (vs some simple api docs explaining default impl).",0,0.9130340218544006
330154422,6295,rhauch,2019-10-01T16:30:30Z,"good point about not deprecating, . i could definitely go either way, and definitely see value in not deprecating and leaving it up to the implementer to choose which they'd implement. but i do think overriding one method is better than having to potentially override both methods for different purposes. because this is changing the connect api, it does seem like we need to come to consensus and approve kip-416 before this pr can be merged, though.",1,0.9318244457244873
330162479,6295,ryannedolan,2019-10-01T16:49:07Z,"that would be neat, but there are landmines here. we don't want a prefix pattern to accidentally apply to topics on another cluster, so we can't just copy prefixes across. we could maybe expand a prefix ""foo"" on cluster ""primary"" to an equivalent ""primary.foo"" prefix, but that would only work if replicationpolicy used something like the default topic renaming convention -- a custom naming convention like ""topic-dc1"" would not work with prefixes this way. we could maybe find all prefix patterns and replicate them as explicit literal patterns. so a prefix of ""foo"" turns into literals ""primary.foo-1"", ""primary.foo-bar"", etc. but even that is a little dangerous, as it is not easily reversible. for example, what happens when an upstream prefix acl is deleted? if there is a safe way to do this, i haven't thought of one yet. we should stick with literals only for now.",0,0.88728266954422
330168213,6295,ryannedolan,2019-10-01T17:01:31Z,"my vote is for keeping both methods (as implemented here), since this doesn't break or deprecate existing code, nor is it especially confusing to see the same method with overloaded parameters in an interface, especially when neither are required to implement. i think the confusing part is just in the workersourcetask implementation, not the sourcetask interface -- it's a little surprising to see the same method called twice here. i suggest we add a comment here and move on. thoughts?",0,0.7776535749435425
330203738,6295,ryannedolan,2019-10-01T18:20:07Z,"done, thanks.",1,0.5576635599136353
330206785,6295,AndrewJSchofield,2019-10-01T18:26:49Z,"i'd prefer to see kip-416 introduce `public void commitrecord(sourcerecord sourcerecord, recordmetadata recordmetadata)` which is called in exactly the same situations as the existing `public void commitrecord(sourcerecord sourcerecord)`. the new method might be called with null record metadata. the implementor has a choice of which to implement.",0,0.9882994890213013
330209568,6295,rhauch,2019-10-01T18:32:48Z,", i disagree that the confusing part is just in the `workersourcetask` implementation. i believe it is confusing that both methods might be called with the same record, and that there is no benefit from doing that. so the issue i have is that i believe the proposed changes to the connect api make it less clear how to properly implement it. it is much clearer for the api to offer two methods and to say the framework always calls the new one, the new one by default calls the old one, and that task implementations can override one or none of them. then it is entirely up to the task implementation to decide whether to even treat these conditions as distinct.",0,0.8088826537132263
330213298,6295,ryannedolan,2019-10-01T18:41:02Z,"just clarifying, are you suggesting we take 's suggestion, except we don't deprecate the existing method? i.e. have the new method call the old? does that satisfy your concern as well?",0,0.9903942942619324
330304627,6295,rhauch,2019-10-01T22:28:58Z,", yes, i am suggesting that we follow 's suggestion minus deprecating the old method. iow, we'd do the following: 1) add the new method that by default calls the old method; and 2) change all uses in the connect runtime (namely in workersinktask and its test class) to use the new method and update kip-416 accordingly.",0,0.986299455165863
330323913,6295,ryannedolan,2019-10-01T23:50:39Z,sounds like we have concensus. will update shortly.,0,0.9583136439323425
330852160,6295,ryannedolan,2019-10-03T03:33:55Z,i made the change. happy with either approach.,1,0.7424874901771545
331279220,6295,junrao,2019-10-03T22:24:15Z,could we add some comments to make it clear that one only needs to implement one of the commitrecord()?,0,0.9951083064079285
331279346,6295,ryannedolan,2019-10-03T22:24:53Z,"agree, there is room for improvement here. an obvious improvement would be to track latency only for the last record in each batch. i can address this in a later pr.",0,0.9745149612426758
331283010,6295,ryannedolan,2019-10-03T22:40:15Z,"we don't use the offsetsyncstore's offsets until we create a checkpoint. if the offsets are invalid or too far behind (-1 here), the checkpoint is not emitted for that topic-partition. so a downstream consumer would see an older checkpoint record for that topic-partition, which in turn was computed from a previous (valid) offset-sync. when replication first starts, there will be no checkpoints. once offsetsyncstore is primed with offset-offset pairs, checkpoints will be emitted. if, say, mm2 fails to send to the offset-syncs topic for whatever reason, there will be no checkpoints until this process succeeds. both offset-syncs and checkpoints are ""opportunistic"" in the sense that it is never _essential_ that they are sent at any given point in time in order for downstream consumers to be correct. so we only send them when we are in a good state and have enough information to send a valid checkpoint.",0,0.9892446994781494
331283663,6295,ryannedolan,2019-10-03T22:43:07Z,"yes, this is actually handled here. any holes upstream will trigger an offset-sync immediately. if such an offset-sync _fails_, for whatever reason, it just means that a checkpoint will not be emitted until the next sync... generally a few seconds later. i'll call out a unit test that shows this in action.",0,0.9886077046394348
331284770,6295,ryannedolan,2019-10-03T22:47:52Z,"holes in a compacted topic are handled, as shown here.",0,0.9859634041786194
331301537,6295,junrao,2019-10-04T00:10:16Z,"unused exceptions interruptedexception, timeoutexception. also, does this test cover anything more than the previous test?",0,0.990208625793457
331494794,6295,omkreddy,2019-10-04T13:16:35Z,"we need to include javadocs section for newly added public interfaces/classes. example: [a link] i assume, we will be adding kafka website documentation as part of kafka-8930. [a link] also looks like test failures are related.",0,0.9948758482933044
331577566,6295,ryannedolan,2019-10-04T16:08:07Z,"ah thanks i'll fix the javadocs this morning. for the website documentation, we'll need to keep the existing mirror-maker section for now, but i'll add a section re mm2, probably in a separate pr. the failing tests seem to be related to flakiness in the connect integration test framework. i'll see what i can do.",1,0.9499643445014954
331732524,6295,ryannedolan,2019-10-05T04:44:20Z,"fixed. in the second test, additional topics are added, detected, and replicated. detecting new topics will trigger a task rebalance in the middle of the test, which doesn't happen in the first. granted, it might make sense to collapse these into a single test rather than bring up and tear down the clusters twice.",0,0.9844205975532532
331732663,6295,ryannedolan,2019-10-05T04:49:34Z,added a couple lines locally. will hold on to the commit for now -- i don't want to trigger another build at the moment.,0,0.9869447350502014
331746988,6295,rhauch,2019-10-05T13:37:45Z,", we need to clearly specify that `metadata` parameter can be null, and then in the javadoc above specify what this means for the source task, namely that a transform dropped/skipped the record and it was not written to kafka. imo this is necessary so that developers of connector implementations know what the behavior is so they can properly implement their task. (the javadoc was not in [a link] i also think that it's also worth mentioning here that `sourcetask` implementations need only implement this method *or* the older `commitrecord(sourcerecord)` *or* neither method, but that generally they do not need to implement both since connect will only call this method. again, this will help developers that are implementing their own `sourcetask` what they need to do.",0,0.9847313165664673
331750101,6295,ryannedolan,2019-10-05T15:15:01Z,i improved the javadocs further. should be clear now.,0,0.9903214573860168
331750119,6295,ryannedolan,2019-10-05T15:15:46Z,i collapsed the two integration tests into one -- seems to save 30 seconds or so.,0,0.9855115413665771
331795997,6295,ijuma,2019-10-06T15:42:24Z,is there a reason why this is not using the `time` interface? we generally never use `system.currenttimemillis()` in kafka.,0,0.9927242398262024
331800260,6295,ryannedolan,2019-10-06T17:14:55Z,"good idea, we should replace these in a subsequent pr.",1,0.9585909247398376
381865765,6295,amanullah92,2020-02-20T09:06:17Z,"this directive (a->b.enabled) is missing in kip in the ""running mirrormaker in production section""-- i got the cluster up but no replication was happening. until i saw this and fixed this. i am new to mirrormaker/connect framework- forgive me if this is a well known thing.",0,0.9099351167678833
526479473,9485,rajinisivaram,2020-11-18T22:58:26Z,we should document what this default implementation does and why a custom implementation may want to override this default.,0,0.9921374917030334
526479478,9485,rajinisivaram,2020-11-18T22:58:26Z,we should document what this default implementation does and why a custom implementation may want to override this default.,0,0.9921374917030334
526481573,9485,rajinisivaram,2020-11-18T23:03:40Z,nit: indentation,0,0.9914920926094055
526482899,9485,rajinisivaram,2020-11-18T23:07:07Z,"this looks identical to the code block above for prefix, we could just run the same code in a loop that checks both allow literals and prefixes.",0,0.9930853843688965
526483476,9485,rajinisivaram,2020-11-18T23:08:45Z,we should have exactly one call to `logauditmessage` that says whether access was allowed or denied.,0,0.9917565584182739
526486028,9485,rajinisivaram,2020-11-18T23:15:24Z,"request.principal can be a custom extension of kafkaprincipal, we cannot use tostring for comparison",0,0.9918335676193237
526487176,9485,rajinisivaram,2020-11-18T23:18:26Z,not sure it is worth making a whole copy of this structure for a method that is not used frequently. it will be good to add microbenchmarks to `aclauthorizerbenchmark` to understand how the new method performs.,0,0.8781665563583374
526487761,9485,rajinisivaram,2020-11-18T23:19:56Z,"same as in the authorizer default method, we cannot use request.principal().tostring()",0,0.9952503442764282
526489152,9485,rajinisivaram,2020-11-18T23:23:54Z,"we should optimize for the case where there are no deny acls. there is no point in finding all matching allow entries in that case, we would just need to check for one allow.",0,0.9923570156097412
526494014,9485,rajinisivaram,2020-11-18T23:37:05Z,make this all the methods below `private`,0,0.9956579208374023
526494298,9485,rajinisivaram,2020-11-18T23:37:54Z,we coul just inline all the methods below instead of separate methods for host etc.?,0,0.9907386302947998
526495928,9485,rajinisivaram,2020-11-18T23:42:06Z,"hmm, produce s authorized for topic anyway. why would we use a very expensive authorizebyresourcetype here?",0,0.9697384238243103
526496224,9485,rajinisivaram,2020-11-18T23:42:56Z,"first authorize should use `logifallowed=true`, `logifdenied=false`",0,0.9959028363227844
526496998,9485,rajinisivaram,2020-11-18T23:44:48Z,`durability`?,0,0.9915584325790405
526499159,9485,rajinisivaram,2020-11-18T23:50:40Z,it may be better to put the mock tests into another test class. that wouldn't request zookeeper for example.,0,0.9843881130218506
526499504,9485,rajinisivaram,2020-11-18T23:51:38Z,"as before, references to durability in authorizer tests are confusing.",0,0.8361326456069946
526500688,9485,rajinisivaram,2020-11-18T23:54:50Z,are we going to add tests here?,0,0.9943583607673645
526502000,9485,rajinisivaram,2020-11-18T23:58:19Z,we should run the microbenchmarks in aclauthorizerbenchmark to make sure we don't add too much overhead here.,0,0.9926925897598267
526503975,9485,rajinisivaram,2020-11-19T00:03:44Z,don't we reuse this in multiple tests? how do we guarantee that no state is preserved between tests?,0,0.9881454706192017
526504244,9485,rajinisivaram,2020-11-19T00:04:32Z,we could mock this fully instead of using aclauthorizer?,0,0.9911887645721436
526504251,9485,rajinisivaram,2020-11-19T00:04:33Z,we could mock this fully instead of using aclauthorizer?,0,0.9911887645721436
529008307,9485,ctan888,2020-11-23T21:29:27Z,"yeah, that's right. construct a kafkaprinciple instance with params referred from principal.gettype() and getname() commit 89df4d7600cad4e3785d0d95624d0918efce1f44",0,0.9920156002044678
529008818,9485,ctan888,2020-11-23T21:30:18Z,"yeah, that's right. construct a kafkaprinciple instance with params referred from principal.gettype() and getname() commit 89df4d7600cad4e3785d0d95624d0918efce1f44",0,0.9920156002044678
529031043,9485,ctan888,2020-11-23T22:15:54Z,yes. using an arraylist to group allow-literals & allow-prefixes in order to deduplicate the logic using a loop commit 188536ad8df13fc327008e59c9787ad2230a7186,0,0.991572380065918
529089666,9485,ctan888,2020-11-24T00:45:42Z,good point. deferred the collection generation until we need it. commit 3906f978e62255ff266f081bf646a4b3c6b896ad,1,0.9508233070373535
529089823,9485,ctan888,2020-11-24T00:46:09Z,good catch. commit 3906f978e62255ff266f081bf646a4b3c6b896ad,1,0.991482138633728
529090156,9485,ctan888,2020-11-24T00:47:03Z,yeah. but i'd guess that the compiler will optimize for us. commit 3906f978e62255ff266f081bf646a4b3c6b896ad,0,0.9832561016082764
532327560,9485,ctan888,2020-11-30T03:20:04Z,"commit 230ee36b9147a11d7ce299aa9fcbb590324faf68 added the authorizebyresourcetype() api to the benchmark and simulate the worst case: every allow acl on the same resource has a dominant deny acl. adjust the `resourcecount` parameter to ""10000"", ""40000"", ""80000"" since each cluster is unlikely to have more than 10k resources. also, since we are testing against the worst case mentioned above, i think the ""10000"" cases are adequate for us. performance result here: [a link]",0,0.9673882722854614
532327775,9485,ctan888,2020-11-30T03:21:02Z,"commit 230ee36b9147a11d7ce299aa9fcbb590324faf68 added the authorizebyresourcetype() api to the benchmark and simulate the worst case: every allow acl on the same resource has a dominant deny acl. adjust the `resourcecount` parameter to ""10000"", ""40000"", ""80000"" since each cluster is unlikely to have more than 10k resources. also, since we are testing against the worst case mentioned above, i think the ""10000"" cases are adequate for us. performance result here: [a link]",0,0.9673882722854614
532336627,9485,ctan888,2020-11-30T04:03:00Z,yes. commit 254af37df5e2d6ec462e7b70497ceb655edea596,0,0.9874202609062195
532337358,9485,ctan888,2020-11-30T04:06:39Z,right. deleted the else branch. commit 254af37,0,0.9913089275360107
532337445,9485,ctan888,2020-11-30T04:06:59Z,commit 254af37,0,0.9917953610420227
532337761,9485,ctan888,2020-11-30T04:08:19Z,i was trying to prove that the new api can work properly with multiple add / remove operations. changed to `testauthorizeranymultipleaddandremove` for now. any naming suggestion? commit b0aa305d8c043075ef0bb7b41d2c37e0072284c5,0,0.9913557171821594
532338240,9485,ctan888,2020-11-30T04:10:31Z,the mockauthorizer is an aclauthorizer using the interface default to do `authorizebyresourcetype`. i was trying to prevent the duplicated code and ease the test implementation. do you think we can keep it here?,0,0.9945230484008789
532341814,9485,ctan888,2020-11-30T04:27:40Z,right. didn't realize that staitc variables in the permgen area will stay there during the whole unit test process. turn the class variable into the instance variable.,0,0.9866355061531067
532342253,9485,ctan888,2020-11-30T04:29:39Z,"if we are mocking this fully, we'd probably need tests on the `authorize` api which the interface default `authorizebyresourcetype` is based on. also, we'll have much more duplicated code in order to implement all the interfaces.",0,0.979282796382904
532343635,9485,ctan888,2020-11-30T04:36:10Z,i was trying to prove that the new api can work properly with multiple add / remove operations. changed to `testauthorizeranymultipleaddandremove` for now. any naming suggestion? commit b0aa305d8c043075ef0bb7b41d2c37e0072284c5,0,0.9913557171821594
532343754,9485,ctan888,2020-11-30T04:36:40Z,no. i was going to but that would add tons of duplicated codes. so i added the interface default test logic into aclauthorizertest. file deleted.,0,0.9123866558074951
532346213,9485,ctan888,2020-11-30T04:48:19Z,yes. let's document this after we finally settle down all the implementations.,0,0.9892043471336365
533501963,9485,rajinisivaram,2020-12-01T15:29:01Z,"this looks odd, do we really need these to index into arrays?",-1,0.8361032605171204
533502417,9485,rajinisivaram,2020-12-01T15:29:33Z,why do we create arraylist(arrays.aslist)?,0,0.99303138256073
533503119,9485,rajinisivaram,2020-12-01T15:30:24Z,we could get host address and store in a variable outside the loop.,0,0.9927242398262024
533503166,9485,rajinisivaram,2020-12-01T15:30:27Z,why is this inside the for loop? we could just create one principal and use it inside the loop.,0,0.9892178773880005
533505561,9485,rajinisivaram,2020-12-01T15:33:34Z,an enummap may be neater.,0,0.9886717796325684
533510467,9485,rajinisivaram,2020-12-01T15:39:45Z,we should probably move this common code to securityutils and use it both here and in the default implementation.,0,0.9920637011528015
533510477,9485,rajinisivaram,2020-12-01T15:39:46Z,we should probably move this common code to securityutils and use it both here and in the default implementation.,0,0.9920637011528015
533513021,9485,rajinisivaram,2020-12-01T15:42:54Z,"we have lost the resource type for auditing, we should include a resource pattern with empty name or something.",0,0.9782521724700928
533564908,9485,rajinisivaram,2020-12-01T16:49:59Z,"ok, i seem to have forgotten this. why is this code different from the one in the default implementation?",0,0.9877447485923767
533567312,9485,rajinisivaram,2020-12-01T16:53:18Z,we should try to preserve the format for this for compatibility with scripts that parse these logs.,0,0.992520809173584
533622127,9485,rajinisivaram,2020-12-01T18:15:06Z,do we have a benchmark for updates (not authorize)?,0,0.9951800107955933
533623715,9485,rajinisivaram,2020-12-01T18:17:41Z,"if `denyallresource` is true, we can just return denied?",0,0.9935616254806519
533626460,9485,rajinisivaram,2020-12-01T18:21:58Z,looks like a lot of duplicate code here. we should see how to share code for all this. can we move the default implementation into securityutils and share some of the matching implementation across the classes?,0,0.9766849279403687
533630212,9485,rajinisivaram,2020-12-01T18:27:59Z,should this be `&&` since we we only need one?,0,0.9926846027374268
533644589,9485,rajinisivaram,2020-12-01T18:51:24Z,"i wasn't sure what the result shows (not that familiar with the output format, sorry) the useful comparisons would be: 1) for authorizebyresourcetype, what is the performance advantage we get by using this duplicate cache versus just using `aclcache`. 2) what is the impact on updates which hold a lock for maintaining two caches (without the pr vs with this pr) 3) does this pr impact regular authorize() calls? i think the answer is no. in any case, it seems unnecessary to maintain a second cache with all acls. we never use authorizebyresourcetype for anything other than topics, so it seems a waste to store acls for other resource types here. we could just use `super.authorizebyresourcetype` for other types.",-1,0.9820204377174377
533720425,9485,rajinisivaram,2020-12-01T21:04:39Z,this should perhaps be called delegatingauthorizer rather than mockauthorizer since it is not a mock and requires zk.,0,0.9893386960029602
533720971,9485,rajinisivaram,2020-12-01T21:05:42Z,"i am not sure why we would make this change. if we need the change because we have become slower, we need to understand why.",-1,0.5170193910598755
533722349,9485,rajinisivaram,2020-12-01T21:08:29Z,spelling: principal,0,0.9907168745994568
533723836,9485,rajinisivaram,2020-12-01T21:11:24Z,"we probably want to retain the old benchmark as-is and add a different one for `authorizebyresourcetype`. we were testing a common pattern before, but now we seem to be testing a very unlikely scenario. while this may be useful for testing `authorizebyresourcetype`, it is not what we want for regression testing the authorizer.",0,0.9662997722625732
533724379,9485,rajinisivaram,2020-12-01T21:12:21Z,spelling: principal (multiple places),0,0.9935116171836853
533727081,9485,rajinisivaram,2020-12-01T21:17:34Z,can we move testing of `interfacedefaultauthorizer.authorizer` into another class? this is `aclauthorizertest` and testing of `interfacedefaultauthorizer` seems unrelated to this test.,0,0.9871327877044678
533737220,9485,ctan888,2020-12-01T21:37:01Z,right. delegatingauthorizer is more reasonable as a design pattern naming here.,0,0.9892981052398682
533765909,9485,ctan888,2020-12-01T22:32:01Z,"the underlying algorithm of authorizebyresourcetype() implementation in aclauthorizer has several characteristics: 1. if any ""allow resource"" of the given ace does not have a dominant ""deny resource"", the api will return immediately 2. the complexity is o(n*m) where `n` is the number of ""allow resources"" of the given ace, 'm' is the number of ""deny resources"" of the given ace, but not related to the number of ""ace"" in the cluster. $1 means that, given an ace, suppose `p%` of its ""allow resource"" does not have a dominant ""deny resource"", if `resourcecount` is `r`, on average, after checking `r * p * 0.01` ""allow resources"", the api will return. a) if we are let the ""dominant deny resource"" distribute evenly, like use the (loop index % something) to determine which ""allow resource"" should have a dominant ""deny resource"", we end up iterating the same amount of the ""allow resource"" and returning from the api call every time, which is `r*p*0.01` b) if we are determine which ""allow resource"" should have a dominant ""deny resource"", the result will be too noisy. we may iterate only 1 resource or iterate all resources based on the randomize algorithm and seed. $2 means that, the api time cost is not related to the number of ""ace"" but is hyperbolically increasing when `resourcecount` is increasing. under the assumption in (1), the actual complexity would be (r * r * p * 0.01) as a result, we should get an insight into how long does the worst case takes, as `t`. then we can estimate some reasonable values of `p` and then estimate the api cost by `t * p`. so i was directly testing the worst case, where p = 1, which means 100% of the ""allow resource"" will have a dominant ""deny resource. the complexity hence would be (r^2). it's rare that a cluster can have 200k ""allow resources"" and 200k corresponding ""dominant deny resources"" for each user, and it's not fair to have a relatively smaller `aclcount` and huger `resourcecount`, as the api is optimizing the performance by indexing on `ace`.",0,0.9911744594573975
533915036,9485,ctan888,2020-12-02T05:57:25Z,enummap make sense. commit 1a139ce744a279e4424188008ee5158186b0fcbe,0,0.9905636310577393
533915142,9485,ctan888,2020-12-02T05:57:49Z,yeah. took out. commit 1a139ce744a279e4424188008ee5158186b0fcbe,0,0.964024543762207
533915261,9485,ctan888,2020-12-02T05:58:12Z,enummap make sense. commit 1a139ce744a279e4424188008ee5158186b0fcbe,0,0.9905636310577393
533915275,9485,ctan888,2020-12-02T05:58:15Z,enummap make sense. commit 1a139ce744a279e4424188008ee5158186b0fcbe,0,0.9905636310577393
533916889,9485,ctan888,2020-12-02T06:03:33Z,right. just as what we've done to principle. commit 29ac8628089ddf1210072bbf52e01a41e123a718,0,0.9880436062812805
533919425,9485,ctan888,2020-12-02T06:10:11Z,commit f6d2a39706998160ebe77a854b8bf64268eec68a,0,0.9883434176445007
533922526,9485,ctan888,2020-12-02T06:19:38Z,commit 6ab95d3668b3de27a7f6f58fc171a1e2e8925f69,0,0.9891167283058167
533922580,9485,ctan888,2020-12-02T06:19:47Z,commit 6ab95d3668b3de27a7f6f58fc171a1e2e8925f69,0,0.9891167283058167
534447773,9485,ctan888,2020-12-02T20:05:42Z,"use ""none"" for the pattern name and ""unknown` for the pattern type commit cebbbd47a8e7d318e327e3a279072c718b535abd",0,0.993880033493042
534447894,9485,ctan888,2020-12-02T20:05:57Z,leave the message as it is now. commit cebbbd47a8e7d318e327e3a279072c718b535abd,0,0.9954860806465149
534477631,9485,ctan888,2020-12-02T20:59:42Z,"i just realized that, in order to check the dominant denies, my aclauthorizer implementation is calling `string::startwith` which also has an o(d) complexity where `d` is the length of the ""deny pattern"" string of the given acl. so the complexity would be o(n * m * d). so given all ""allow pattern"" and ""deny pattern"" of a given ace, we have 2 algorithms now 1. iterate through all the prefixes of the `allow pattern` string and check if any prefix is contained in the set of `deny pattern`, which has a complexity of o(n * a), where `a` is the length of the ""allow pattern"" string. my interface default is using this approach. 2. iterate through all the ""deny patterns"", which has a complexity of o(n * m * d), where d is the length of the `deny pattern` string. my aclauthorizer is using this approach. comparasion: since the average of the `allow pattern` string length should be close to that of the `deny pattern`, we can say `a = d`. so o(n * a) = o(n * d) > o(n * m * d), which means approach 1 is much better. conclusion: i'll change aclauthorizer to use approach 1.",0,0.9762587547302246
534589923,9485,ctan888,2020-12-03T01:07:31Z,right. just as what aclauthorizer does. commit 18c5c04ad4d8c98dc3cdaa6d15bf70b9991a6b88,0,0.9909130334854126
534751595,9485,ctan888,2020-12-03T06:51:40Z,"yeah, moved to securityutils. commit 30899c45ac50b70625baa2e5f12f58cfe9d79404",0,0.9655977487564087
534755163,9485,ctan888,2020-12-03T06:53:59Z,"now the only difference is that the aclauthorizer is indexing on ace, so the number of ace won't impact the query efficiency.",0,0.992133378982544
534763817,9485,ctan888,2020-12-03T06:59:40Z,"i think adding some dominant denies won't change the performance pattern of aclauthorizer::acls and aclauthorizer::authorize. 1. aclauthorizer::acls just return all the matching acls by the filter rule. the portion btw ""allow"" and ""deny"" resources doesn't matter. 2. aclauthorizer::authorize will iterate the and filter out the allow and deny aces respectively. since it's using resourcepattern as its indexing method, the portion btw ""allow"" and ""deny"" resources doesn't matter as well.",0,0.975695788860321
534983615,9485,ctan888,2020-12-03T09:12:16Z,"move the interface default test to a new class. also, created a util class for code sharing. commit 6c550fd04a0c1912e669bf18d60dee27dd03e53c",0,0.993760883808136
536305219,9485,ctan888,2020-12-04T18:46:54Z,commit 7af4a7ff7ed2dddc06cf11ab7ff2d4b9fee5fb56,0,0.987885594367981
537657552,9485,ctan888,2020-12-07T16:46:03Z,good catch commit 031c2f41e6611df3d18ef9b709c7d98c91b93326,1,0.9693940877914429
537667755,9485,ctan888,2020-12-07T16:58:58Z,please see below,0,0.9934720993041992
538522173,9485,lbradstreet,2020-12-08T15:49:08Z,"nit, unnecessary whitespace in `i++`.",0,0.6324160695075989
538524117,9485,lbradstreet,2020-12-08T15:50:45Z,i think it's useful to understand how the cache performs at smaller sizes as well as larger sizes. is there a reason we went with a fixed size and fixed number of resources now?,0,0.91517573595047
538528015,9485,lbradstreet,2020-12-08T15:54:15Z,it might be better for the purpose of this microbenchmark to setup the cache with the desired size ahead of the time and then measure the time to update the cache with one entry. otherwise you risk measuring a lot of the setup costs rather than the cost of the typical usage.,0,0.9834850430488586
538553851,9485,lbradstreet,2020-12-08T16:16:33Z,"if you take an async profile of this benchmark method you end up spending most of the time in building the entries and immutable set, and barely any time on `aclauthorizer#updatecache`.",0,0.9889041781425476
538613769,9485,ctan888,2020-12-08T17:09:18Z,"oh, i'm just demonstrating the chart 3 i uploaded. i'll change them back.",0,0.9868725538253784
538618149,9485,ctan888,2020-12-08T17:13:15Z,"do you think we'll keep this `testupdatecache` and merge it into trunk? if so, let's setup the cache ahead of time. but i think this benchmark is mainly for comparing the trunk with my branch, which means that we probably won't merge this `testupdatecache` into master, which also means the same procedure constructing some memory records are acceptable since we are taking the time cost difference.",0,0.9907808899879456
538618817,9485,ctan888,2020-12-08T17:13:55Z,yeah. agree. let's see what think about the above discussion,0,0.6847406625747681
538768554,9485,ctan888,2020-12-08T20:04:09Z,thanks. fixed.,1,0.921301543712616
539594382,9485,rajinisivaram,2020-12-09T19:42:17Z,"this package is part of the public api, but the class looks like it should be internal?",0,0.9899521470069885
539595584,9485,rajinisivaram,2020-12-09T19:44:19Z,perhaps resourceaclentry or something along those lines would be better than `resourceindex` since this class has no notion of index.,0,0.9860911965370178
539599430,9485,rajinisivaram,2020-12-09T19:50:25Z,can we remove the todo comments?,0,0.9947803020477295
539602809,9485,rajinisivaram,2020-12-09T19:55:39Z,"in the typical case, we have a large number of `allowliterals` and `allowprefixes`, no `denyliterals` or `denprefixes`. i think it would make sense to special case `denyliterals.isempty && denyprefixes.isempty`. in this case, we don't need to find all matching resources, we just need to check that there is at least one matching resource.",0,0.9844689965248108
539604360,9485,rajinisivaram,2020-12-09T19:58:05Z,why can't this be a `set` instead of `list of sets`?,0,0.9850589036941528
539604845,9485,rajinisivaram,2020-12-09T19:58:51Z,`aclentry.wildcardprincipalstring`,0,0.9941218495368958
539607223,9485,rajinisivaram,2020-12-09T20:02:33Z,this method can be in securityutils and shared with the default authorizer?,0,0.9959249496459961
539607563,9485,rajinisivaram,2020-12-09T20:03:07Z,private def?,0,0.9934050440788269
539612536,9485,rajinisivaram,2020-12-09T20:11:00Z,"we cannot do this here. `authorizerwrapper` is used to wrap any custom authorizer using the old authorizer api. `alloweveryoneifnoaclisfoundprop` is a custom config of `simpleaclauthorizer` and `aclauthorizer`, we cannot use that with any custom authorizer. we should find a way to support the config for simpleaclauthorizer that doesn't impact other custom authorizers.",0,0.9912089109420776
539614719,9485,rajinisivaram,2020-12-09T20:14:37Z,does this work with an acl with wildcard host?,0,0.9946382641792297
539614739,9485,rajinisivaram,2020-12-09T20:14:38Z,does this work with an acl with wildcard host?,0,0.9946382641792297
539615189,9485,rajinisivaram,2020-12-09T20:15:25Z,"the main logic of this could potentially be moved to securityutils since the default authorizer implementation, aclauthorizer and the wrapper all do this.",0,0.9935492873191833
539630084,9485,rajinisivaram,2020-12-09T20:37:40Z,why do we need this in teardown?,0,0.9830361008644104
539631425,9485,rajinisivaram,2020-12-09T20:40:04Z,a lot of these changes look unnecessary,-1,0.7443810701370239
539632426,9485,rajinisivaram,2020-12-09T20:41:50Z,looks like this hasn't been reverted?,0,0.9899071455001831
539632653,9485,rajinisivaram,2020-12-09T20:42:14Z,revert?,0,0.9847967624664307
539634789,9485,rajinisivaram,2020-12-09T20:45:38Z,why? this no longer reflects the comment above. can we revert?,0,0.9867768883705139
539635426,9485,rajinisivaram,2020-12-09T20:46:42Z,we should revert changes to existing benchmark because it hard to tell why these changes were made and what impact it has on the original benchmark.,0,0.9524531364440918
539638872,9485,rajinisivaram,2020-12-09T20:52:14Z,it makes sense to merge the benchmarks to trunk. let's make sure it measures just updatecache.,0,0.9907896518707275
539730884,9485,ctan888,2020-12-09T23:41:08Z,shall we make the class constructor package-private or make this class an inner class of aclauthorizer?,0,0.9952771663665771
539734315,9485,ctan888,2020-12-09T23:47:14Z,i used index as it's used as the index of the hashmap. what about something like `resourcenamefilter`?,0,0.9948142766952515
539734983,9485,ctan888,2020-12-09T23:48:51Z,yeah. removed.,0,0.9502331614494324
539736828,9485,ctan888,2020-12-09T23:53:14Z,yes. commit 2fd4babe2c27ee0723fa1cd720ca35d2bbefe57b,0,0.9779337048530579
539737110,9485,ctan888,2020-12-09T23:53:55Z,commit 2fd4babe2c27ee0723fa1cd720ca35d2bbefe57b,0,0.9854725003242493
539737287,9485,ctan888,2020-12-09T23:54:20Z,sure,0,0.9422702193260193
539751258,9485,ctan888,2020-12-10T00:28:50Z,yes. commit 1dc143fc78a3b9927189751255346ef0b6cafd90 if (nodeny) { ..if (hasallow) { ....return authorize.allowed ..} else { ....return authorize.denied // since no allow exists ..} },0,0.9914450645446777
539782093,9485,ctan888,2020-12-10T01:50:16Z,because we don't wanna reconstruct a new large set containing all the matching resources. we are constructing a list of ~ 3 * 3 * 3 elements which refer to existing hashsets maintained by `updatecache`.,0,0.9915342926979065
539787542,9485,ctan888,2020-12-10T02:03:20Z,i was trying to share it but it seems like the different collection type btw java and scala is a headache. we'll then need some java converters or instantiate a java collection in the scala code. do you think it deserves this?,-1,0.9394922852516174
540418386,9485,ctan888,2020-12-10T18:56:44Z,"given that we probably don't want to change the deprecated authorizer interface, i can only think of one way to achieve this: besides checking if the `alloweveryoneifnoaclisfoundprop` exists and if it equals to `true`, i added another check to authorize on a hardcoded session, operation, and resource. since configure() will be called immediately after the authorizer instantiation, it's guaranteed that no acls would exist when we do this check. override def configure(configs: util.map[string, _]): unit = { ..baseauthorizer.configure(configs) ....shouldalloweveryoneifnoaclisfound = (configs.asscala.get( ......aclauthorizer.alloweveryoneifnoaclisfoundprop).exists(_.tostring.toboolean) ........&& baseauthorizer.authorize( ..........new session(kafkaprincipal.anonymous, inetaddress.getbyname(""1.2.3.4"")), ............read, new resource(topic, ""hi"", patterntype.literal))) } commit 2ed79a0a7788f8841475badfd1c26adf0eb3435c",0,0.991951584815979
540655651,9485,ctan888,2020-12-11T03:03:41Z,"good catch. commit 8263bd319f63d39808f90129db55427b98385dd4 since it's a bit hard to test `allowanyoneifnoaclfound` and many other logics in the integration test, i added a new test class `authorizerwrappertest`.",1,0.9874413013458252
540658692,9485,ctan888,2020-12-11T03:13:10Z,commit 8263bd3 changed the authorizerwrapper logic and optimized the performance a bit. now authorizerwrapper#denyallresource will 1. only use authorizer#acls() to filter out the `wildcardresource` with the pattern type `literal`. 2. check if any of the filtered out bindings match the `request principle` and `request host`. so it's behavior diverges more from the interface default now.,0,0.9819329380989075
540705023,9485,ctan888,2020-12-11T05:43:38Z,"otherwise ""deny all"" will remain in zk during the whole test process since zk won't be restarted or re-instantiated.",0,0.9909150004386902
540706117,9485,ctan888,2020-12-11T05:46:49Z,"since `authorizerinterfacedefaulttest`, `aclauthorizertest`, and `authorizerwrappertest` are sharing some test utils, we need to make this method signature abstract a bit, in order to make it usable by authorizertestfactory.",0,0.9915252327919006
541202572,9485,ctan888,2020-12-11T19:35:27Z,yeah. i was doing resourcename = resourcename + 95 to re-use this variable. we can revert it.,0,0.9882533550262451
541206048,9485,ctan888,2020-12-11T19:38:55Z,yes.,0,0.9851860404014587
541206648,9485,ctan888,2020-12-11T19:39:31Z,yes,0,0.9686408638954163
541212190,9485,ctan888,2020-12-11T19:45:19Z,"the existing benchmark does not have any deny resource in it. adding some deny bindings whose percentage is controlled by parameters will be an improvement to the existing benchmark and help us understand the performance better. i've reverted all changes other than adding some deny bindings. also, i moved those memory intense operations into the phase so now the benchmark just measures updatecache(). does the benchmark look good to you now? commit 6536cea788210860a764f3f0a6901244e8d974fe",0,0.8108013868331909
541779975,9485,ctan888,2020-12-12T21:02:27Z,reverted other test changes commit 4f9b79a810c4da3030fe262d4bfdc97df4945e8c,0,0.9937760829925537
542039322,9485,ctan888,2020-12-14T00:14:52Z,"benchmark result: [a link] performance pattern doesn't change, except `testupdatecache` runs much faster now.",0,0.985755980014801
542790510,9485,rajinisivaram,2020-12-14T21:10:16Z,"we have to move the class outside of the public package, so putting it alongside aclauthorizer makes sense.",0,0.9917750358581543
542830098,9485,rajinisivaram,2020-12-14T21:47:04Z,"since this is the javadoc of a public api, we should move the details on how the default implementation works outside of the javadoc. we can move this list of comments inside the method.",0,0.9938114285469055
542851551,9485,rajinisivaram,2020-12-14T22:07:06Z,"we don't currently have anything in the default implementation to support super.users right? unlike `allow.everyone.if.no.acl.found` which is not particularly suitable for production use, `super.users` is a commonly used config that is likely to be in use in a lot of deployments. the simplest fix may be to `authorize()` with a hard-coded name and return allowed if `authorize()` returns allowed before any of the logic below is executed.",0,0.9908269047737122
542854629,9485,rajinisivaram,2020-12-14T22:09:57Z,this needs to be an immutable map or a concurrenthashmap since we read this without lock.,0,0.9925642609596252
542855316,9485,rajinisivaram,2020-12-14T22:10:36Z,we need to check if the principal is a super.user and return allowed for super users before executing any of the logic below.,0,0.992676317691803
542860969,9485,rajinisivaram,2020-12-14T22:16:10Z,"ok, makes sense",0,0.9771971106529236
542861839,9485,rajinisivaram,2020-12-14T22:16:57Z,"ok, let's leave as is.",0,0.9802365899085999
542871579,9485,rajinisivaram,2020-12-14T22:26:24Z,"this is too hacky. and it breaks if anonymous has all access (e.g. because inter-broker listener alone uses plaintext). we could check `baseauthorizer.isinstanceof[simpleaclauthorizer]` perhaps. it is not perfect since it would break if there was a custom authorizer that extended simpleaclauthorizer, but doesn't support alloweveryoneifnoaclisfoundprop and the prop was set to true. but that seems like an unlikely scenario.",-1,0.93597412109375
542879143,9485,rajinisivaram,2020-12-14T22:33:41Z,this sequence doesn't work with super.users. we probably should do something like: [code block],0,0.9803979992866516
542881770,9485,rajinisivaram,2020-12-14T22:36:27Z,we could have done principal.tostring() once in the caller rather than convert everytime.,0,0.9854394793510437
542884517,9485,rajinisivaram,2020-12-14T22:39:08Z,zk is reinstantiated for every test.,0,0.9889178276062012
542887409,9485,rajinisivaram,2020-12-14T22:41:58Z,"as in the other class, we don't need this in teardown",0,0.9901180863380432
542888614,9485,rajinisivaram,2020-12-14T22:43:13Z,we should add tests for super users.,0,0.9898701310157776
542890465,9485,rajinisivaram,2020-12-14T22:45:10Z,why are we storing these?,0,0.9879457950592041
542892942,9485,rajinisivaram,2020-12-14T22:47:34Z,why?,0,0.9622438549995422
542893393,9485,rajinisivaram,2020-12-14T22:48:00Z,why was this changed from aclauthorizer to authorizer?,0,0.9943903088569641
542893665,9485,rajinisivaram,2020-12-14T22:48:15Z,why are we storing this?,0,0.9877886176109314
542900213,9485,rajinisivaram,2020-12-14T22:54:40Z,it would be better to move this inside authorizerinterfacedefaulttest since it is specific to that test.,0,0.991479754447937
542906008,9485,rajinisivaram,2020-12-14T23:00:35Z,"for map, you would say `key` rather than `index`. but this is not a `resource` or `resourcename` - it has no resource name, it is not a filter, but it includes accesscontrolentry. maybe just resourcetypekey is sufficient, but you could also include something to indicate it includes the accesscontrolentry if you want. either way, putting it along with aclauthorizer would make naming less critical.",0,0.9928488731384277
543080612,9485,ctan888,2020-12-15T06:30:16Z,sure. commit 25e0bfcc97f956ceb4254ab8c457fe5d8d250e82,0,0.9825181365013123
543093393,9485,ctan888,2020-12-15T07:00:05Z,"so we have three approaches here: 1. use .getclass 2. use .isinstanceof 3. only configure the property with the key ""aclauthorizer.alloweveryoneifnoaclisfoundprop"" in the authorizerwrapper instance construction so no other property will get in. neither of them is perfect but approach 2 also seems better to me. commit 1217394c0c3767ac11df958c02a681c8cbc8382b",0,0.9795100092887878
543099934,9485,ctan888,2020-12-15T07:14:00Z,yeah. i was trying to restrict the type in order to remind people to construct a kafkaprinciple first. but tostring() is an expensive operation. commit 16576f85a858648cfc4ff882b554ddc65922021c,0,0.9316920042037964
543114091,9485,ctan888,2020-12-15T07:41:41Z,"i replied here. maybe i shouldn't have resolved it. [a link] since authorizerinterfacedefaulttest, aclauthorizertest, and authorizerwrappertest are sharing some test cases, we need to make this method signature abstract a bit, in order to pass the method reference to authorizertestfactory.",0,0.9545599818229675
543116084,9485,ctan888,2020-12-15T07:45:14Z,"for this method, i changed the signature back to aclauthorzier as the authorizertestfactory is not depending on it.",0,0.9953201413154602
543117875,9485,ctan888,2020-12-15T07:48:38Z,removed as we are not removing acls in teaddown() anymore. commit 825a8ba77ad1766f998a71a9a15f21e73daad84a,0,0.9934883117675781
543117908,9485,ctan888,2020-12-15T07:48:42Z,commit 825a8ba77ad1766f998a71a9a15f21e73daad84a,0,0.9875199794769287
543117954,9485,ctan888,2020-12-15T07:48:48Z,commit 825a8ba77ad1766f998a71a9a15f21e73daad84a,0,0.9875199794769287
543118616,9485,ctan888,2020-12-15T07:49:54Z,removed as we are not removing acls in teaddown() anymore. commit 825a8ba,0,0.994317352771759
543120808,9485,ctan888,2020-12-15T07:53:47Z,make sense. commit e31f157eaac1213445dd284fd2209a29f4fa18fd,0,0.9877229928970337
543134773,9485,ctan888,2020-12-15T08:18:45Z,"would scala ""foreach"" throw any exception when read operation races with write in hashmap / hashset? if not, i think we can tolerate some read inconsistency as zk is also broadcasting the acl changes asynchronously to brokers.",0,0.9895170331001282
543174139,9485,ctan888,2020-12-15T09:18:00Z,"i tested a bit, using 1 bg thread adding and removing elements to a mutable.hashset while the main thread constantly iterating the hashset using ""foreach"". the ""foreach"" call doesn't throw any exception. but i'm a bit unsure what would happen if the iteration hits a bucket where some elements are being added to or deleted from. let me test what's the overhead using the immutable map. i'd prefer this approach as we're expecting much more read than write to the hashset.",0,0.9672951698303223
543744087,9485,ctan888,2020-12-15T22:49:36Z,good catch. this is super important. commit dae1a788b70ebc03eab265b1027a4b43ad8e773b,1,0.9970260262489319
543744182,9485,ctan888,2020-12-15T22:49:47Z,good catch. this is super important. commit dae1a788b70ebc03eab265b1027a4b43ad8e773b,1,0.9970260262489319
543745352,9485,ctan888,2020-12-15T22:52:00Z,"test added for authorizerinterfacedefaulttest, aclauthorizertest, authorizerwrappertest. commit dae1a788b70ebc03eab265b1027a4b43ad8e773b",0,0.9838755130767822
543805858,9485,ctan888,2020-12-16T01:18:49Z,"use immutable collections: benchmark (aclcount) (denypercentage) (resourcecount) mode cnt score error units aclauthorizerbenchmark.testaclsiterator 50 100 200000 avgt 5 4132.824  2967.122 ms/op aclauthorizerbenchmark.testauthorizebyresourcetype 50 100 200000 avgt 5 46.733  5.397 ms/op aclauthorizerbenchmark.testauthorizer 50 100 200000 avgt 5 6.844  0.915 ms/op aclauthorizerbenchmark.testupdatecache 50 100 200000 avgt 5 7219.696  4018.189 ms/op jmh benchmarks done use mutable collections: aclauthorizerbenchmark.testupdatecache 50 100 200000 avgt 5 4927.832  2570.786 ms/op when aclcount = 50, denypercentage = 100, resourcecount = 200000, the time cost is 2.3 seconds more with immutable collections. but since adding 50 * 20000 acl bindings only takes ~7 seconds, i think the performance should be acceptable.",0,0.9927404522895813
543813486,9485,ctan888,2020-12-16T01:39:14Z,removed.,0,0.9612457156181335
543814295,9485,ctan888,2020-12-16T01:41:28Z,resourcetypekey sounds good: commit 7fe92c6436432760adf9465c3f0bcf3c91104b10,1,0.661894679069519
543814563,9485,ctan888,2020-12-16T01:42:04Z,make resourcetypekey an inner class of aclauthorizer commit 7fe92c6436432760adf9465c3f0bcf3c91104b10,0,0.994686484336853
543814681,9485,ctan888,2020-12-16T01:42:19Z,good catch. this is super important. commit dae1a78,1,0.9970408082008362
543817949,9485,ctan888,2020-12-16T01:51:12Z,commit 62c44ade550a90671ff41bfb847e2bc28adc7baa,0,0.98995041847229
544223127,9485,rajinisivaram,2020-12-16T11:29:11Z,use `op` rather than read since that fits with why we are allowing access. we also need a test that verifies that permission to read everything doesn't imply `authorizebyresourcetype` for write.,0,0.9940972328186035
544223630,9485,rajinisivaram,2020-12-16T11:29:58Z,use `logifallowed=true` since we are granting access in that case.,0,0.9950528740882874
544229673,9485,rajinisivaram,2020-12-16T11:40:14Z,can we used named arguments for the booleans: `authorized = false` - we should update all usages of `logauditmessage` below.,0,0.9951052665710449
544232558,9485,rajinisivaram,2020-12-16T11:44:53Z,"we should make this a `case class`. we can then remove all the methods (equals, hashcode and tostring) since we get those for free.",0,0.9946666955947876
544239742,9485,rajinisivaram,2020-12-16T11:56:47Z,"not a `custom` principal, just a `principal`.",0,0.9860039353370667
544239749,9485,rajinisivaram,2020-12-16T11:56:48Z,"not a `custom` principal, just a `principal`.",0,0.9860039353370667
544240156,9485,rajinisivaram,2020-12-16T11:57:27Z,all these tests are using `read` which happens to work for the default implementation since we used read there.,0,0.9937750101089478
544244813,9485,rajinisivaram,2020-12-16T12:05:14Z,can we check how much work it would be to convert `authorizertestfactory` into an `abstract baseauthorizertest` class that the three xxxauthorizertest classes extend? having to repeat these tests in all three places makes it too easy to miss one in the future.,0,0.9824556112289429
544246252,9485,rajinisivaram,2020-12-16T12:07:37Z,nit: principle => principal,0,0.9923135638237
544545938,9485,ctan888,2020-12-16T18:57:59Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9881827235221863
544545948,9485,ctan888,2020-12-16T18:58:00Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9881827235221863
544545971,9485,ctan888,2020-12-16T18:58:04Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9881827235221863
544546002,9485,ctan888,2020-12-16T18:58:07Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9881827235221863
544546101,9485,ctan888,2020-12-16T18:58:15Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9881827235221863
544546172,9485,ctan888,2020-12-16T18:58:22Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9881827235221863
544546946,9485,ctan888,2020-12-16T18:59:31Z,"yeah. since i've changed `read` to `op`, this has been resolved.",0,0.9817703366279602
544547081,9485,ctan888,2020-12-16T18:59:40Z,commit ec80dc4e55758d83835f3ecde381a988d6dd4779,0,0.9881827235221863
544713670,9485,ctan888,2020-12-17T00:09:14Z,"commit 092fec70a9547ec07cba999e77be1c0cf79fa275 commit e5e3d18f57ab22df20133f9841905af384d9b641 these two commits are condensing the class methods and members into the baseauthorizertest. in baseauthorizertest, the only abstract method is an authorizer provider. after overriding the provider, those test cases in it are sufficient to run. now the test code looks much cleaner. if the changes look too much to you, we can revert 092fec70a9547ec07cba999e77be1c0cf79fa275 and move the head to e5e3d18f57ab22df20133f9841905af384d9b641",0,0.9260526299476624
545246428,9485,rajinisivaram,2020-12-17T16:56:46Z,`resourceindex` => `resourcetypekey` and omit `new`.,0,0.9939975738525391
545247397,9485,rajinisivaram,2020-12-17T16:58:03Z,couldn't we just check:`resourcecache.contains(resourcekey)` ?,0,0.9945977926254272
545261128,9485,rajinisivaram,2020-12-17T17:17:49Z,"`resourceindex` => `resourcetypekey`, also we can omit new for resourcetypekey since it is a case class.",0,0.9945672750473022
545264795,9485,rajinisivaram,2020-12-17T17:23:02Z,`private def`,0,0.9941629767417908
545264898,9485,rajinisivaram,2020-12-17T17:23:10Z,`private def`,0,0.9941629767417908
545267737,9485,rajinisivaram,2020-12-17T17:27:13Z,we can use `map` instead of `match`: [code block],0,0.9953203797340393
545270222,9485,rajinisivaram,2020-12-17T17:30:45Z,"`resourceindex` => `resourcetypekey`, omit `new`",0,0.9940419793128967
545270292,9485,rajinisivaram,2020-12-17T17:30:53Z,"`resourceindex` => `resourcetypekey`, omit `new`",0,0.9940419793128967
545273561,9485,rajinisivaram,2020-12-17T17:35:05Z,`candenyall` => `denyall` since `can` doesn't fit with `deny`,0,0.9933180809020996
545280654,9485,rajinisivaram,2020-12-17T17:45:19Z,"suggestions to improve this (feel free to ignore/update): ``` custom authorizer implementations should consider overriding this default implementation because: 1) the default implementation iterates all aclbindings multiple times, without any caching for resource types. more efficient implementations may be added in custom authorizers that directly access cached entries. 2) the default implementation cannot integrate with any audit logging included in the authorizer implementation. 3) the default implementation does not support any custom authorizer configs or other access rules apart from acls.",0,0.9884825348854065
545282374,9485,rajinisivaram,2020-12-17T17:47:45Z,add a comment to say that we check for one hard-coded name to ensure that super users are granted access regardless of deny acls.,0,0.9950656294822693
545287419,9485,rajinisivaram,2020-12-17T17:55:22Z,can we make this comment two lines instead of 4 since each sentence seems short enough to fit into a line?,0,0.9911064505577087
545325909,9485,rajinisivaram,2020-12-17T18:53:16Z,"`patterntype.unknown` looks odd in audit logs, `any` may be better.",0,0.7452578544616699
545363933,9485,rajinisivaram,2020-12-17T19:55:50Z,the nested for loop can be replaced with: [code block],0,0.9953286647796631
545365855,9485,rajinisivaram,2020-12-17T19:58:45Z,we can make this a `val` by using an arraybuffer instead of list that we keep recreating,0,0.9932297468185425
545366101,9485,rajinisivaram,2020-12-17T19:59:08Z,"as before, we can use a single for loop instead of nested loop",0,0.992938220500946
545367497,9485,rajinisivaram,2020-12-17T20:01:27Z,can use `denyliterals.exists(_.contains(resourcepattern.wildcard_resource))`,0,0.995352029800415
545368045,9485,rajinisivaram,2020-12-17T20:02:13Z,"can use `allowprefixes.exists(_.exists`, similarly for `allowliterals`.",0,0.9952280521392822
545368198,9485,rajinisivaram,2020-12-17T20:02:31Z,nit: space before {,0,0.7268314957618713
545369571,9485,rajinisivaram,2020-12-17T20:04:55Z,can be `!denyliterals.exists(_.contains(literalname))`?,0,0.9941388368606567
545399101,9485,rajinisivaram,2020-12-17T20:57:59Z,we should use the same pattern as the usage of `aclcache` where we get a `aclcachesnapshot` at the start of the method and then use the same snapshot throughout the method rather than use a changing value of resourcecache within the loop.,0,0.9940401315689087
545410322,9485,rajinisivaram,2020-12-17T21:19:25Z,could just close `interfacedefaultauthorizer` instead of creating an `authorizers` collection?,0,0.9931707382202148
545411361,9485,rajinisivaram,2020-12-17T21:21:34Z,the `authorizer` parameter is not used. can't we just move this into the test method `testauthorizebyresourcetypenoaclfoundoverride` above?,0,0.9949589967727661
545411829,9485,rajinisivaram,2020-12-17T21:22:24Z,can't this be `aclauthorizer`?,0,0.9867115020751953
545412639,9485,rajinisivaram,2020-12-17T21:24:09Z,"there is only one authorizer, we could just use it directly instead of creating a seq",0,0.9933566451072693
545413800,9485,rajinisivaram,2020-12-17T21:26:29Z,"looks like there is opportunity to move some of this stuff into baseauthorizertest, but we can do that in a follow-up later.",0,0.9869443774223328
545471749,9485,ctan888,2020-12-17T23:26:46Z,[code block] i think the resourcepattern constructor is preventing us passing patterntype.any. it's only usable with filter.,0,0.9911515116691589
545525163,9485,ctan888,2020-12-18T02:04:45Z,right. to prevent the phantom problem.,0,0.9906522035598755
545527187,9485,ctan888,2020-12-18T02:11:19Z,"i think that the zookeeperclient has a different metric group name. i'm not sure how the name will be used though. and yes, we can do that in a follow-up pr later.",0,0.9909871220588684
545529131,9485,ctan888,2020-12-18T02:17:51Z,commit b6a766b228034a442e3a6e8b71ecee78eefdbfd3,0,0.9872938990592957
545529436,9485,ctan888,2020-12-18T02:18:49Z,commit b6a766b,0,0.9906277656555176
545529534,9485,ctan888,2020-12-18T02:19:03Z,commit b6a766b,0,0.9906277656555176
545531049,9485,ctan888,2020-12-18T02:24:18Z,commit b6a766b,0,0.9906277656555176
545531079,9485,ctan888,2020-12-18T02:24:22Z,commit b6a766b,0,0.9906277656555176
545576162,9485,ctan888,2020-12-18T05:09:08Z,commit b6a766b,0,0.9906277656555176
545576394,9485,ctan888,2020-12-18T05:10:16Z,commit b6a766b,0,0.9906277656555176
545576579,9485,ctan888,2020-12-18T05:11:03Z,commit b6a766b,0,0.9906277656555176
545576700,9485,ctan888,2020-12-18T05:11:32Z,commit b6a766b,0,0.9906277656555176
545576808,9485,ctan888,2020-12-18T05:11:58Z,![a link] commit b6a766b,0,0.7587697505950928
545577772,9485,ctan888,2020-12-18T05:15:41Z,// check a hard-coded name to ensure that super users are granted // access regardless of deny acls.,0,0.9950162768363953
545577832,9485,ctan888,2020-12-18T05:15:56Z,commit b6a766b,0,0.9906277656555176
545577865,9485,ctan888,2020-12-18T05:16:03Z,commit b6a766b,0,0.9906277656555176
545577952,9485,ctan888,2020-12-18T05:16:18Z,commit b6a766b,0,0.9906277656555176
545578070,9485,ctan888,2020-12-18T05:16:49Z,"right, though it's only a list of 8. commit b6a766b",0,0.9892421364784241
545578559,9485,ctan888,2020-12-18T05:18:28Z,commit b6a766b,0,0.9906277656555176
545578734,9485,ctan888,2020-12-18T05:18:58Z,yes. didn't realize the existence of this syntax be4. thanks. commit b6a766b,1,0.9645910859107971
545579837,9485,ctan888,2020-12-18T05:23:04Z,commit b6a766b,0,0.9906277656555176
545581171,9485,ctan888,2020-12-18T05:27:40Z,commit b6a766b,0,0.9906277656555176
545584468,9485,ctan888,2020-12-18T05:39:14Z,right. we can bring the ! to the front. commit 9407b1697d976fc6cff90703573a64f7a3c9f348,0,0.9933367967605591
545584783,9485,ctan888,2020-12-18T05:40:19Z,commit b6a766b,0,0.9906277656555176
545584825,9485,ctan888,2020-12-18T05:40:28Z,yes. commit b6a766b,0,0.9847804307937622
545584872,9485,ctan888,2020-12-18T05:40:35Z,yes. commit b6a766b,0,0.9847804307937622
545585037,9485,ctan888,2020-12-18T05:41:19Z,yes. renamed to aclauthorizer. commit b6a766b,0,0.9861853718757629
545585355,9485,ctan888,2020-12-18T05:42:34Z,yes. remove the seq construction and make a single class member call. commit b6a766b,0,0.9931327700614929
76054354,1776,ijuma,2016-08-24T13:20:34Z,the scala `enumeration` class has a bunch of problems and we typically use adts. an example is `rackawaremode`.,0,0.9664308428764343
76104237,1776,benstopford,2016-08-24T17:43:14Z,changed - thanks bud.,1,0.9469863772392273
76720190,1776,junrao,2016-08-30T02:00:43Z,delta is no longer valid. typo evalutated,0,0.8077955842018127
76720206,1776,junrao,2016-08-30T02:00:53Z,"is that only used for testing? if so, could we define it under src/test?",0,0.9950370192527771
76720217,1776,junrao,2016-08-30T02:01:03Z,do we need this new class? rate.windowsize() is modified this way to address kafka-2443 and kafka-2567. it would be better if all sensors are of the same type of rate.,0,0.9929159879684448
76720224,1776,junrao,2016-08-30T02:01:07Z,kip says using comma separated.,0,0.991078794002533
76720231,1776,junrao,2016-08-30T02:01:11Z,the kip says it's comma separated.,0,0.9903467297554016
76720243,1776,junrao,2016-08-30T02:01:17Z,"perhaps we can avoid calling split(""-"") twice by doing that once first?",0,0.9882692098617554
76720245,1776,junrao,2016-08-30T02:01:25Z,"to be consistent with the existing naming, perhaps the params can be brokerid and brokerconfig?",0,0.9949951171875
76720249,1776,junrao,2016-08-30T02:01:26Z,space after if,0,0.9908820390701294
76720258,1776,junrao,2016-08-30T02:01:31Z,shouldn't we do this check before line 127?,0,0.9939854741096497
76720265,1776,junrao,2016-08-30T02:01:37Z,it's clearer if we use quota.upperbound(limit) in this and the next line.,0,0.9894796013832092
76720272,1776,junrao,2016-08-30T02:01:41Z,this can be private?,0,0.9948434829711914
76720336,1776,junrao,2016-08-30T02:02:47Z,"does this guarantee that the minbytes requirement is met? for example, suppose that all replicas are throttled and quota is not exceeded at this point. however, when we call forcecomplete(0, we could get fewer bytes than minbytes and return the fetch response prematurely. same question in case c on line 94. if the fetch offset is on an old segment from the last segment, we force a return immediately. however, it could be that the quota is violated and we will return an empty response.",0,0.9892963767051697
76720343,1776,junrao,2016-08-30T02:02:51Z,"to be consistent, should broker be brokers?",0,0.9901382923126221
76720349,1776,junrao,2016-08-30T02:02:55Z,no need to change this line?,0,0.9941256046295166
76720356,1776,junrao,2016-08-30T02:03:04Z,this can be private?,0,0.9948434829711914
76720360,1776,junrao,2016-08-30T02:03:07Z,an => a,0,0.9920908212661743
76720364,1776,junrao,2016-08-30T02:03:12Z,could we use the defined name for quota.replication.throttled.replicas?,0,0.9949033260345459
76720369,1776,junrao,2016-08-30T02:03:16Z,missing license header.,0,0.9558560252189636
76720377,1776,junrao,2016-08-30T02:03:19Z,extra space after object,0,0.9918816685676575
76720409,1776,junrao,2016-08-30T02:03:46Z,perhaps noquota is better?,0,0.9585892558097839
76720415,1776,junrao,2016-08-30T02:03:51Z,"for clarity, would it be better to rename leaderreplication and followerreplication to leaderquotamanager and followerquotamanager?",0,0.9930233955383301
76720426,1776,junrao,2016-08-30T02:04:01Z,no need for the package name org.apache.kafka.common.utils. ditto two lines below.,0,0.9919098019599915
76720437,1776,junrao,2016-08-30T02:04:14Z,do we really need fetchresponseprocessingcomplete()? could we just do the logic here in processpartitiondata?,0,0.9937574863433838
76720447,1776,junrao,2016-08-30T02:04:22Z,"is this still needed? if not, it seems that we don't need to expose bound() as a public api in replicationquotamanager.",0,0.9944620728492737
76720504,1776,junrao,2016-08-30T02:05:11Z,"does this need to be info? also, don't need to reference logger. there are a few other places like that.",0,0.9954584836959839
76720509,1776,junrao,2016-08-30T02:05:16Z,typo excedded,0,0.9926034808158875
76720512,1776,junrao,2016-08-30T02:05:21Z,"hmm, shouldn't we pass in fetch.messageset.sizeinbytes to quota.isquotaexceededby()?",0,0.9756045341491699
76720516,1776,junrao,2016-08-30T02:05:27Z,do we have to read from the log again? it seems that we can just set fetch.messageset to an empty bytebuffermessageset.,0,0.993606686592102
76720525,1776,junrao,2016-08-30T02:05:31Z,unused import coreutils,0,0.9918099045753479
76720529,1776,junrao,2016-08-30T02:05:37Z,readonlyquota seems a bit too general. perhaps sth like replicaquota?,0,0.7724547982215881
76720550,1776,junrao,2016-08-30T02:05:41Z,bound() => upperbound() to make it clear?,0,0.9870806336402893
76720605,1776,junrao,2016-08-30T02:06:24Z,"this may not be enough since the sensor can be removed after it's inactive for some time (say, throttled replicas are removed). when that happens, sensor will be pointing to an obsolete object. to be safe, we probably need a getorcreatequotasensors() method like in clientquotamanager.",0,0.9818500876426697
76720612,1776,junrao,2016-08-30T02:06:26Z,could this be a val instead of a method?,0,0.9886026382446289
76720626,1776,junrao,2016-08-30T02:06:32Z,"it seems that this can be private? also, getquota() can be just quota().",0,0.9917750358581543
76720637,1776,junrao,2016-08-30T02:06:41Z,"does this need to be at info? also, not need to use logger. info() is enough.",0,0.9957706332206726
76720651,1776,junrao,2016-08-30T02:06:52Z,"hmm, should bound() return int? with things like infiniband, it actually can be legit to set a quota larger than 2gb/sec.",0,0.9716346859931946
76815241,1776,benstopford,2016-08-30T15:11:18Z,"our standard mechanism won't permit commas in config, hence i proposed this. i did actually change the kip.",0,0.9918426275253296
76815773,1776,benstopford,2016-08-30T15:13:40Z,will change to quota.isquotaexceededby(fetchmetadata.fetchminbytes).,0,0.9952489733695984
76816162,1776,benstopford,2016-08-30T15:15:42Z,i'll fix all logging etc when i have something i'm prepared to merge. this is just a first cut remember.,0,0.9859240055084229
76817729,1776,benstopford,2016-08-30T15:22:59Z,yes - that's better.,0,0.7978855967521667
76817871,1776,benstopford,2016-08-30T15:23:42Z,that makes sense. will change. thanks for the heads up.,1,0.9700427055358887
76817957,1776,benstopford,2016-08-30T15:24:08Z,no should be long everywhere. will change.,0,0.9907681345939636
76819932,1776,benstopford,2016-08-30T15:33:39Z,"sorry - deleted previous. as i understand it the fetch, here, is just a single partition's data. thus i'm keeping a running total of throttled bytes in all partitions, checking against the quota to see when the 'proposed' fetch will exceed to. remember isquotaexceededby() doesn't record anything. let me know if i'm missing something.",-1,0.9750195741653442
76946201,1776,ijuma,2016-08-31T08:38:48Z,these should be final and probably exposed via an accessor.,0,0.9938099980354309
76947111,1776,ijuma,2016-08-31T08:44:36Z,"i think ben just meant the `value` parameter to be called `delta`. from an api perspective, it seems like it would make sense to also have a public `checkquota` method if we expose a `checkquotawithdelta`.",0,0.9886383414268494
76948313,1776,ijuma,2016-08-31T08:52:43Z,"not sure i understand, we support multiple items separated by commas in configs via the `list` type.",0,0.7914993762969971
76948517,1776,ijuma,2016-08-31T08:54:18Z,not sure if these formatting changes are intended.,0,0.8271262049674988
76948664,1776,ijuma,2016-08-31T08:55:22Z,nitpick: we don't usually include the type annotation for simple local variables like this.,0,0.9829714894294739
76948830,1776,ijuma,2016-08-31T08:56:22Z,it seems to me that the `partitions.map(_.tostring)` doesn't do anything since the default behaviour is to call `tostring` on each element anyway.,0,0.9815387725830078
76958141,1776,ijuma,2016-08-31T09:55:37Z,"generally in scala, you would write this like: [code block]",0,0.9863974452018738
76958968,1776,ijuma,2016-08-31T10:00:47Z,nitpick: we don't need the `string` type annotation.,0,0.9929618239402771
76959741,1776,ijuma,2016-08-31T10:05:48Z,can we not make a copy of kafkaconfig instead?,0,0.9931314587593079
76959836,1776,ijuma,2016-08-31T10:06:36Z,`unboundedquota` maybe?,0,0.9882889986038208
76960609,1776,ijuma,2016-08-31T10:09:22Z,"given that the containing class is `quotamanagers`, it seems like it may be ok to not repeat `quotamanager` for each field. if we do rename it as per jun's suggestion, then we probably should rename `client` too.",0,0.9906414151191711
76961281,1776,ijuma,2016-08-31T10:14:22Z,"this class seems a bit inconsistent in that it groups the client replication types in a map, but not the replication ones. it seems like it might be better to either have them all as fields or all in maps. is there a reason to do it this way instead?",0,0.8871351480484009
76961490,1776,ijuma,2016-08-31T10:16:00Z,it would be nice if a `time` instance was passed instead of hardcoding `systemtime` here.,0,0.9855902791023254
76962421,1776,ijuma,2016-08-31T10:23:20Z,there should be no `unit.` here.,0,0.9892914891242981
76964270,1776,ijuma,2016-08-31T10:37:15Z,nitpick: methods should start with lowercase letter.,0,0.9899551868438721
77510050,1776,benstopford,2016-09-05T11:45:24Z,renamed value->delta. added an (unused) method: public void checkquotas(),0,0.9947970509529114
77542394,1776,benstopford,2016-09-05T16:27:23Z,dynamic configs don't support commas. i've added a task to look at changing this.,0,0.9906781911849976
77543779,1776,benstopford,2016-09-05T16:44:59Z,thanks,1,0.8643599152565002
77544027,1776,ijuma,2016-09-05T16:49:06Z,"they should do, see `cleanup.policy` for an example. there's a test in `logcleanerintegrationtest.testcleanscombinedcompactanddeletetopic` that verifies this.",0,0.9934564232826233
77544671,1776,benstopford,2016-09-05T16:56:04Z,ok,0,0.9233372807502747
77544719,1776,benstopford,2016-09-05T16:56:56Z,thanks,1,0.8643599152565002
77544895,1776,benstopford,2016-09-05T17:00:00Z,"yes, good spot. thank you.",1,0.9925657510757446
77545048,1776,benstopford,2016-09-05T17:02:02Z,agreed. changed.,0,0.9725301265716553
77545600,1776,benstopford,2016-09-05T17:08:33Z,yeah - it was just used by a test. have changed to test the ensurevalid method instead.,0,0.9930324554443359
77545753,1776,benstopford,2016-09-05T17:11:11Z,done. thanks,1,0.9871130585670471
77545866,1776,benstopford,2016-09-05T17:13:16Z,sure can,0,0.9901240468025208
77545936,1776,benstopford,2016-09-05T17:14:33Z,thanks,1,0.8643599152565002
77545961,1776,benstopford,2016-09-05T17:14:59Z,good idea. thanks.,1,0.9949343800544739
77546037,1776,benstopford,2016-09-05T17:16:39Z,added. thanks,1,0.9740782380104065
77546111,1776,benstopford,2016-09-05T17:17:55Z,thanks,1,0.8643599152565002
77546161,1776,benstopford,2016-09-05T17:18:51Z,unboundedquota sounds good to me.,0,0.8063467144966125
77549097,1776,benstopford,2016-09-05T18:16:57Z,yeah - i should have put a comment on that. it's a historical artefact from the way the original client quota managers worked. i knew i had to rework it. it should be a bit better now.,0,0.9548436403274536
77549138,1776,benstopford,2016-09-05T18:17:51Z,done,0,0.8682363629341125
77549657,1776,benstopford,2016-09-05T18:30:34Z,nope. hangover from when we had separate throttled replica fetcher threads. removed.,0,0.9472421407699585
77554690,1776,ijuma,2016-09-05T20:36:09Z,you can express the the rhs of `==` as: [code block],0,0.9949331879615784
77554722,1776,ijuma,2016-09-05T20:36:44Z,is this a left-over debugging thing? it seems like you don't need this var at all.,0,0.9752905964851379
77625349,1776,benstopford,2016-09-06T12:36:06Z,nope. removed.,0,0.9702181220054626
77626384,1776,benstopford,2016-09-06T12:43:41Z,"that test verifies you can create a logconfig object, but doesn't verify that you can update that same log config from the configcommand, which you can't currently.",0,0.9935256242752075
77627001,1776,ijuma,2016-09-06T12:48:10Z,"interesting, this is an issue for kip-71 too then. cc",0,0.7275530695915222
77632698,1776,dguy,2016-09-06T13:23:27Z,"hmm, yes indeed. it appears configcommand doesn't like commas. topiccommand otoh does.",0,0.9674876928329468
77806141,1776,benstopford,2016-09-07T11:44:55Z,thanks,1,0.8643599152565002
77806226,1776,benstopford,2016-09-07T11:45:37Z,ok,0,0.9233372807502747
77806309,1776,benstopford,2016-09-07T11:46:13Z,good idea.,1,0.9783411622047424
77855115,1776,benstopford,2016-09-07T16:14:31Z,"have extracted the logic from the clientquotamanager and reused, which, i think, is better!",1,0.6800233721733093
77855598,1776,benstopford,2016-09-07T16:17:02Z,sure can.,0,0.9810815453529358
77855719,1776,benstopford,2016-09-07T16:17:42Z,yes. thanks,1,0.981682538986206
77855772,1776,benstopford,2016-09-07T16:18:04Z,will do all these at the end.,0,0.991696298122406
77855817,1776,benstopford,2016-09-07T16:18:21Z,this was changed,0,0.9887082576751709
77856461,1776,benstopford,2016-09-07T16:22:17Z,"i wouldn't typically add accessors here, although i would have some years back. if you're super keen on this kind of stuff i'll change.",0,0.9716612100601196
77856804,1776,benstopford,2016-09-07T16:24:06Z,nope. removed,0,0.977545440196991
77857026,1776,benstopford,2016-09-07T16:25:25Z,good spot. thank you.,1,0.99420565366745
77857237,1776,benstopford,2016-09-07T16:26:34Z,cool. thanks.,1,0.9931080341339111
77862056,1776,benstopford,2016-09-07T16:53:20Z,changed,0,0.7968646287918091
77868592,1776,benstopford,2016-09-07T17:31:01Z,"interesting. so it's not actually used anywhere. the value is just passed into the quota managers, following the same pattern used in the clientquotamanager. so maybe we don't need to change kafkaconfig at all? what do you think?",0,0.6388317346572876
77873545,1776,ijuma,2016-09-07T17:59:02Z,"i'm not super-keen on the accessors, it's just the general kafka convention. i'm keen on the fields being `final` though. also, do we want `value` and `bound` to be nullable? if not, then they should be lowercase `double`.",0,0.9115199446678162
77880926,1776,benstopford,2016-09-07T18:44:11Z,ok,0,0.9233372807502747
77881060,1776,benstopford,2016-09-07T18:44:55Z,thanks,1,0.8643599152565002
77881100,1776,benstopford,2016-09-07T18:45:11Z,ok,0,0.9233372807502747
77881343,1776,benstopford,2016-09-07T18:46:39Z,ah yes. thanks,1,0.9823461174964905
77881777,1776,benstopford,2016-09-07T18:49:13Z,it most certainly is. thank you. i'll do a refactor of these tests in my final pass.,1,0.9790157079696655
77893695,1776,benstopford,2016-09-07T20:06:14Z,ok - changed,0,0.9893825054168701
77974298,1776,ijuma,2016-09-08T09:34:33Z,"we are leaking the thread right? if you just want to execute something in the background, you can do something like: [code block] if you store the future, you can also await on the result or just completion by using `await.result` or `await.ready` (probably not applicable in this case, but worth knowing).",0,0.9926068782806396
78008266,1776,benstopford,2016-09-08T13:45:41Z,thanks. good to know.,1,0.9795812964439392
78140580,1776,ijuma,2016-09-09T07:45:12Z,nitpick: `value` and `bound` should be lowercase `double` since they can't be null (annoying that scala and java are different in this respect so it's a bit confusing when writing code in both languages).,-1,0.6890023946762085
78140755,1776,ijuma,2016-09-09T07:46:58Z,nitpick: should be `brokers` to be consistent with the other ones? or should the other ones be made singular?,0,0.9828342199325562
78141062,1776,ijuma,2016-09-09T07:49:48Z,nitpick: no return needed and no blocks are needed. example: [code block],0,0.9938355088233948
78141122,1776,ijuma,2016-09-09T07:50:16Z,i'd include the `broker` variable in the message.,0,0.9942981600761414
78141182,1776,ijuma,2016-09-09T07:50:49Z,i think it would be a bit better if this method returned an `int` and the caller just wrapped the result in `seq(...)`.,0,0.9759730100631714
78141363,1776,ijuma,2016-09-09T07:52:32Z,"seems like this code would be a bit nicer if we had a `val supportedtypes = set(configtype.topic, configtype.client, configtype.broker)` somewhere.",0,0.9760002493858337
78141952,1776,ijuma,2016-09-09T07:58:20Z,"maybe something like: [code block] i think you also need to handle errors if the format doesn't match what you expect, right? at the moment, we will get unhelpful `arrayoutofboundsexception`s and `numberformatexception`s.",0,0.982144832611084
78142068,1776,ijuma,2016-09-09T07:59:32Z,"i see that there's a `throttledreplicavalidator`, is that ensuring that things will be in the right format by the time we get here?",0,0.9946208000183105
78142129,1776,ijuma,2016-09-09T08:00:03Z,nitpick: space after `:`,0,0.9889611601829529
78142280,1776,ijuma,2016-09-09T08:01:30Z,"unless i am missing something, i think this should take a `string` since the caller is passing it a `string`. then you don't need `tostring` below.",0,0.9903460144996643
78142342,1776,ijuma,2016-09-09T08:02:13Z,this message doesn't mention `broker`. another case where having a definition of supported types would make the code more robust.,0,0.9918521046638489
78142470,1776,ijuma,2016-09-09T08:03:42Z,wouldn't it be better to have a `shutdown()` in `quotas` that closes all of them?,0,0.9892919659614563
78142661,1776,ijuma,2016-09-09T08:05:36Z,it doesn't seem like this is used any more.,0,0.9436127543449402
78142693,1776,ijuma,2016-09-09T08:05:55Z,do we still need this?,0,0.9930538535118103
78142931,1776,ijuma,2016-09-09T08:08:06Z,"maybe this should be `def props(map: map[string, string])` and then you would use it like: [code block]",0,0.989909291267395
78143052,1776,ijuma,2016-09-09T08:09:27Z,thanks for changing the calling code. can we remove this method then?,1,0.6572100520133972
78143150,1776,ijuma,2016-09-09T08:10:18Z,have you seen `testutils.producemessages`?,0,0.9951772689819336
78143190,1776,ijuma,2016-09-09T08:10:43Z,`unit.` should not be here.,0,0.9693893790245056
78147862,1776,benstopford,2016-09-09T08:52:10Z,"good point. i've changed to ""add/remove entity config for a topic, client or broker"" (command only lets you change one at a time)",1,0.9762665033340454
78147928,1776,benstopford,2016-09-09T08:52:40Z,thanks,1,0.8643599152565002
78148028,1776,benstopford,2016-09-09T08:53:24Z,good idea. thanks,1,0.9955853223800659
78148279,1776,benstopford,2016-09-09T08:55:32Z,ok,0,0.9233372807502747
78149087,1776,benstopford,2016-09-09T09:02:07Z,definitely!,1,0.8349277973175049
78149712,1776,benstopford,2016-09-09T09:06:56Z,yep. that's the idea.,0,0.9009779095649719
78150344,1776,benstopford,2016-09-09T09:11:59Z,"it just means the tostring has to be called in the ensurevalid method, so six of one and half a dozen of the other. unless i'm missing something.",0,0.9906373620033264
78150565,1776,benstopford,2016-09-09T09:13:27Z,done (with enumerated list),0,0.9925060868263245
78150976,1776,benstopford,2016-09-09T09:16:47Z,ok.,0,0.980760931968689
78151082,1776,benstopford,2016-09-09T09:17:29Z,thanks,1,0.8643599152565002
78151223,1776,benstopford,2016-09-09T09:18:29Z,yep. it's the definitive list of broker configs you can change.,0,0.9459922313690186
78151950,1776,benstopford,2016-09-09T09:23:48Z,have removed & refactored original. was a bit pointless.,-1,0.8520423173904419
78152713,1776,ijuma,2016-09-09T09:30:00Z,"no, you don't need to do that because of the pattern matching clause. you have to pass `s` instead of `value`.",0,0.9928799271583557
78154280,1776,benstopford,2016-09-09T09:42:58Z,have changed,0,0.9908889532089233
78154318,1776,benstopford,2016-09-09T09:43:19Z,thanks,1,0.8643599152565002
78159088,1776,benstopford,2016-09-09T10:28:01Z,"ah, gottcha. thanks",1,0.9928285479545593
78160093,1776,benstopford,2016-09-09T10:37:03Z,"i've consolidated onto a single class, keeping simplerate. this encompasses a different approach to fixing kafka-2567 whilst being a little simpler to test.",0,0.9905551075935364
78160165,1776,benstopford,2016-09-09T10:37:41Z,ok,0,0.9233372807502747
78160327,1776,benstopford,2016-09-09T10:39:04Z,done. thanks.,1,0.9554389715194702
78231105,1776,benstopford,2016-09-09T18:54:39Z,"i've added support for comma separated lists in the configcommand. you specify the list using a square bracket: k1=v1,k2=[v2,v3]",0,0.9876053333282471
78249903,1776,apurvam,2016-09-09T21:12:02Z,nitpick: would it be better to just use `messageset` from line 118 instead of doing `partitiondata.tobytebuffermessageset` again? this way you save an allocation.,0,0.9836295247077942
78259626,1776,apurvam,2016-09-09T22:40:41Z,would this be better as a typed enum rather than a string? makes compile time checks stronger.,0,0.989733874797821
78265368,1776,apurvam,2016-09-10T00:04:53Z,"this message doesn't match the test. shouldn't it be ""throttled replication of n ms should > m ms""",0,0.9756181836128235
78269010,1776,junrao,2016-09-10T02:01:24Z,timems in the comment is no long valid.,0,0.979836642742157
78269016,1776,junrao,2016-09-10T02:01:46Z,"having two different rates is going to make it harder for developers to decide which one to use. if this is strictly better than rate, perhaps we should just change rate.windowsize(). if this is just for testing, perhaps we can create simplerate in test?",0,0.9215676188468933
78269021,1776,junrao,2016-09-10T02:01:54Z,"the comment in line 470 doesn't seem to match the test. also, space before 0.",0,0.9843131303787231
78269023,1776,junrao,2016-09-10T02:02:00Z,is this comment accurate?,0,0.9903568625450134
78269027,1776,junrao,2016-09-10T02:02:03Z,space before {,0,0.9892727136611938
78269029,1776,junrao,2016-09-10T02:02:07Z,space after if,0,0.9908820390701294
78269031,1776,junrao,2016-09-10T02:02:13Z,this doesn't seem to be used?,0,0.9879355430603027
78269033,1776,junrao,2016-09-10T02:02:17Z,does --execute block?,0,0.9952267408370972
78269036,1776,junrao,2016-09-10T02:02:20Z,b/s => bytes/sec ?,0,0.9868664741516113
78269040,1776,junrao,2016-09-10T02:02:33Z,addthrottle => maybeaddthrottle ?,0,0.9923295378684998
78269041,1776,junrao,2016-09-10T02:02:37Z,unused import javaconverters,0,0.9914417862892151
78269052,1776,junrao,2016-09-10T02:03:12Z,"if quota is not exceeded, should we check (accumulatedsize + accumulatedthrottledsize) >= fetchmetadata.fetchminbytes?",0,0.9946653842926025
78269056,1776,junrao,2016-09-10T02:03:18Z,extra space before result,0,0.9903143048286438
78269059,1776,junrao,2016-09-10T02:03:22Z,a few unused imports.,0,0.9781590700149536
78269063,1776,junrao,2016-09-10T02:03:29Z,the upper bound => the upper bound in bytes/sec ?,0,0.9932071566581726
78269069,1776,junrao,2016-09-10T02:03:42Z,unused import,0,0.9873000979423523
78269090,1776,junrao,2016-09-10T02:04:27Z,would it be better to just check quota.isquotaexceeded once and make the same decision for each throttled partition on whether it should be included or not?,0,0.9870197772979736
78269091,1776,junrao,2016-09-10T02:04:31Z,there is already a trace statement in abstractfetcherthread that logs each fetch request. do we still need this trace logging?,0,0.9936416745185852
78269148,1776,junrao,2016-09-10T02:07:42Z,unused imports metricname and rate.,0,0.9943882822990417
78269151,1776,junrao,2016-09-10T02:07:48Z,allreplicas instead?,0,0.9927358627319336
78269161,1776,junrao,2016-09-10T02:08:16Z,the above may not be 100% safe since the metric could be expired and removed between the two statements. it's safer if we save metrics.metrics.get(ratemetricname) to a local val and then check null and update the config.,0,0.9892471432685852
78269165,1776,junrao,2016-09-10T02:08:23Z,"since sensor() has side effect, it would be clearer if all references to sensor are sensor().",0,0.9899191856384277
78269169,1776,junrao,2016-09-10T02:08:44Z,"the convention is to use trace() which does does the if check already. also, for string formatting, we are moving towards the s notation instead of format. ditto in a few other places.",0,0.9943053126335144
78269173,1776,junrao,2016-09-10T02:08:56Z,partitions == allreplicas should probably be partitions eq allreplicas?,0,0.9941120743751526
78269178,1776,junrao,2016-09-10T02:09:08Z,"to be consistent, if there is no return value, we just do method() {}.",0,0.9927254915237427
78269179,1776,junrao,2016-09-10T02:09:11Z,"if partitions is empty, should we remove that topic from the map?",0,0.9942358136177063
78269182,1776,junrao,2016-09-10T02:09:18Z,is there a reason to remove these? it seems the test is still useful.,0,0.9929134249687195
78269185,1776,junrao,2016-09-10T02:09:21Z,unused import,0,0.9873000979423523
78269187,1776,junrao,2016-09-10T02:09:25Z,10 sec seems inaccurate now?,0,0.9426549077033997
78269190,1776,junrao,2016-09-10T02:09:29Z,is this really done in a separate thread?,0,0.9886104464530945
78269192,1776,junrao,2016-09-10T02:09:33Z,1 second seems inaccurate now?,0,0.9379441142082214
78269194,1776,junrao,2016-09-10T02:09:34Z,20s seems inaccurate now?,0,0.9313135147094727
78269197,1776,junrao,2016-09-10T02:09:37Z,remove unit,0,0.9920222759246826
78269199,1776,junrao,2016-09-10T02:09:41Z,is len 100 or 1?,0,0.9930647015571594
78269200,1776,junrao,2016-09-10T02:09:44Z,unused imports,0,0.9898548126220703
78269203,1776,junrao,2016-09-10T02:09:49Z,could this and next method be private?,0,0.9916216135025024
78269206,1776,junrao,2016-09-10T02:09:56Z,"do we ""put replicas for all partitions on the not-started brokers""?",0,0.9934645295143127
78269212,1776,junrao,2016-09-10T02:10:06Z,the text in here and line 172 seem inaccurate.,0,0.9186729788780212
78269223,1776,junrao,2016-09-10T02:10:35Z,"with this, after recording the bytes, the quota could be exceeded? the earlier approach where we use quota.isquotaexceed(expectedbytes) seems more conservative and is less likely for quota to be exceeded. is there a reason not to use quota.isquotaexceed(expectedbytes)?",0,0.984464704990387
78298061,1776,junrao,2016-09-11T16:29:39Z,"it seems that we need to handle case c better. if the follower is lagging on old segments and the quota is exceeded, we may return an empty result well before max wait. returning an empty result early occasionally is fine. however, in this case, it seems that this can happen continuously.",0,0.9868831038475037
78298089,1776,junrao,2016-09-11T16:31:28Z,"there could be a subtle issue with timeout. say we check the quota and it's exceeded, and we will put the delayedfetch in the purgatory. if no more bytes are produced, the delayedfetch has to wait for maxwait. however, quota could become available before maxwait (and we won't get a chance to check). one potential way to address this is that if quota is exceeded, we calculate the amount of time that needs to pass before quota is available. we set the timeout in delayedfetch to the be smaller of that time and maxwait. then, if delayedfetch expires, in delayedfetch.oncomplete(), if minbytes is not satisfied and maxwait hasn't been exceeded. we put delayedfetch to purgatory again.",0,0.9738904237747192
78318335,1776,benstopford,2016-09-12T06:02:51Z,thanks,1,0.8643599152565002
78320891,1776,benstopford,2016-09-12T06:39:58Z,yes. agree.,0,0.9238324165344238
78321116,1776,benstopford,2016-09-12T06:43:20Z,thanks. changed.,1,0.6466229557991028
78321156,1776,benstopford,2016-09-12T06:43:49Z,thanks,1,0.8643599152565002
78321274,1776,benstopford,2016-09-12T06:45:31Z,good spot. thanks,1,0.9951783418655396
78321313,1776,benstopford,2016-09-12T06:46:10Z,yes it is. have clarified the test comment a bit.,0,0.99128258228302
78321694,1776,benstopford,2016-09-12T06:51:30Z,thanks,1,0.8643599152565002
78321704,1776,benstopford,2016-09-12T06:51:34Z,thanks,1,0.8643599152565002
78321742,1776,benstopford,2016-09-12T06:52:05Z,oops - thanks,1,0.8119947910308838
78321998,1776,benstopford,2016-09-12T06:54:54Z,no. mistake. thanks,1,0.9895201921463013
78322063,1776,benstopford,2016-09-12T06:55:42Z,done,0,0.8682363629341125
78322189,1776,benstopford,2016-09-12T06:57:17Z,done. thanks,1,0.9871130585670471
78322192,1776,benstopford,2016-09-12T06:57:21Z,done. thanks,1,0.9871130585670471
78322413,1776,benstopford,2016-09-12T07:00:09Z,yes. that's a great spot. thank you.,1,0.9946823716163635
78322533,1776,benstopford,2016-09-12T07:01:44Z,thanks,1,0.8643599152565002
78322678,1776,benstopford,2016-09-12T07:03:28Z,good spot,1,0.9885575771331787
78322720,1776,benstopford,2016-09-12T07:03:59Z,thanks,1,0.8643599152565002
78323225,1776,benstopford,2016-09-12T07:09:45Z,sure thing.,0,0.986527144908905
78323280,1776,benstopford,2016-09-12T07:10:27Z,thanks. removed,1,0.5871383547782898
78323319,1776,benstopford,2016-09-12T07:10:54Z,thanks,1,0.8643599152565002
78323346,1776,benstopford,2016-09-12T07:11:08Z,ok. cool,1,0.9896905422210693
78325258,1776,benstopford,2016-09-12T07:31:41Z,i've changed this both here and also in the clientquotamanager (which had the same logic),0,0.9938045740127563
78325391,1776,benstopford,2016-09-12T07:33:06Z,yes - good call. thanks,1,0.9937188625335693
78326425,1776,benstopford,2016-09-12T07:43:20Z,thanks for the heads up. changed,1,0.9376490712165833
78327387,1776,benstopford,2016-09-12T07:51:33Z,ok - makes sense.,0,0.9852790832519531
78328609,1776,benstopford,2016-09-12T08:02:26Z,ok - thanks for the heads up - have changed tidied up where this was wrong elsewhere too.,1,0.9302886128425598
78333596,1776,ijuma,2016-09-12T08:40:30Z,probably unintended change?,0,0.8643335700035095
78333653,1776,ijuma,2016-09-12T08:40:58Z,probably unintended change?,0,0.8643335700035095
78404954,1776,benstopford,2016-09-12T16:22:47Z,"no, i missed that somehow. have added it now.",0,0.9829386472702026
78406716,1776,benstopford,2016-09-12T16:32:52Z,how strange. that was removed when i merged from my previous branch. good spot.,-1,0.9734309911727905
78407140,1776,benstopford,2016-09-12T16:35:15Z,thanks,1,0.8643599152565002
78407153,1776,benstopford,2016-09-12T16:35:20Z,thanks,1,0.8643599152565002
78407241,1776,benstopford,2016-09-12T16:36:03Z,it certainly isn't! thanks.,1,0.9854932427406311
78407355,1776,benstopford,2016-09-12T16:36:44Z,thanks,1,0.8643599152565002
78407542,1776,benstopford,2016-09-12T16:38:05Z,thanks,1,0.8643599152565002
78407632,1776,benstopford,2016-09-12T16:38:36Z,thanks,1,0.8643599152565002
78407763,1776,benstopford,2016-09-12T16:39:17Z,thanks,1,0.8643599152565002
78407832,1776,benstopford,2016-09-12T16:39:39Z,thanks,1,0.8643599152565002
78408120,1776,benstopford,2016-09-12T16:41:14Z,sure can,0,0.9901240468025208
78408614,1776,benstopford,2016-09-12T16:44:06Z,clarified. thanks,1,0.9679923057556152
78410438,1776,benstopford,2016-09-12T16:54:31Z,"yes - the idea seemed like a good one, but it led to some complexities. the main problem was that the ratio of the requestsize:quotasize correlated with the amount the throttle would be undercut. also, if you asked for more than the quota in a single request you could never make progress. the upshot was that the behaviour was a little unintuitive, and the simpler mechanism seems to work well on aggregate. so after thinking about it for a while i decided to ditch the isexceededby(bytes) approach. keep it simple ... and this way it more closely matches the way the follower works more closely. i hope that makes sense.",0,0.8846198916435242
78411666,1776,benstopford,2016-09-12T17:02:01Z,"i did consider this issue. you are right that we could make the leader algorithm more responsive by altering the timeout (i didn't think of that - good idea). for now i'm inclined to raise a jira for this as a future enhancement. it shouldn't affect throttling significantly. the extra delay will even out over time. also, this problem exists on the follower too so the optimisation is only of value for the leader side of the throttle. the main concern i have is actually the lack of smarts on the follower, particularly if throttled partitions enter the isr, as the follower logic is very basic.",1,0.5287724137306213
78412609,1776,benstopford,2016-09-12T17:07:49Z,thanks,1,0.8643599152565002
78412775,1776,benstopford,2016-09-12T17:08:59Z,thanks,1,0.8643599152565002
78432823,1776,benstopford,2016-09-12T18:56:06Z,good spot. i think this should be as simple as: [code block] but i'll need to write a test which will take a little time.,1,0.9309541583061218
78783831,1776,junrao,2016-09-14T16:25:33Z,"yes, the follower has a similar issue. there is already logic to add a delay per partition. so, if a partition is throttled in the follower, we can calculate a delay from quota and delay the partition accordingly. we probably also need to change the backoff logic in abstractfetcherthread a bit. instead of always backing off for a fixed amount of time, it's probably better to backoff based on the smallest delay among all partitions. i agree that this is probably not a common issue. it only becomes a big issue if the maxwait or replica backoff time are configured very large (say close to the metric window \* sample size). so, we can address that in a followup jira.",0,0.956518292427063
78865421,1776,junrao,2016-09-14T23:43:57Z,"processconfigchanges() only gets called if there is overridden config on brokerid in zk. so, if that doesn't exist, it seems that we won't apply the static default throttledreplicationlimit in broker property file?",0,0.9934900999069214
78865431,1776,junrao,2016-09-14T23:44:05Z,extra space after :,0,0.9919030070304871
78865451,1776,junrao,2016-09-14T23:44:17Z,throttle should be type long?,0,0.9932727813720703
78865458,1776,junrao,2016-09-14T23:44:22Z,convention: use trace().,0,0.994809627532959
78865572,1776,junrao,2016-09-14T23:45:23Z,unused import,0,0.9873000979423523
78865576,1776,junrao,2016-09-14T23:45:27Z,typo bakc,0,0.9869669079780579
78865588,1776,junrao,2016-09-14T23:45:34Z,"perhaps we should just test excluding the property, which is consistent with the test in line 484?",0,0.9889862537384033
78865602,1776,junrao,2016-09-14T23:45:40Z,should we make limit long since throttledreplicationratelimitprop is of type long?,0,0.9941101670265198
78865609,1776,junrao,2016-09-14T23:45:44Z,take => taken,0,0.9911807179450989
78865626,1776,junrao,2016-09-14T23:45:49Z,are we using a separate thread?,0,0.9918600916862488
78865633,1776,junrao,2016-09-14T23:45:55Z,are we using a separate thread?,0,0.9918600916862488
78865643,1776,junrao,2016-09-14T23:46:00Z,should this be private?,0,0.9887549877166748
78893471,1776,junrao,2016-09-15T05:47:04Z,"i think we can just get rid of the static config throttledreplicationratelimitprop and just rely on the dynamic broker level config, which is more flexible.",0,0.9812683463096619
78959050,1776,benstopford,2016-09-15T13:10:37Z,"yes - i raised a bug for this, but it's not a big deal so lets lose the config it as you say.",0,0.9843181371688843
78959367,1776,benstopford,2016-09-15T13:12:20Z,thanks. done,1,0.9440580606460571
78959375,1776,benstopford,2016-09-15T13:12:24Z,thanks. done,1,0.9440580606460571
78959967,1776,benstopford,2016-09-15T13:15:33Z,thanks,1,0.8643599152565002
78959976,1776,benstopford,2016-09-15T13:15:37Z,thanks,1,0.8643599152565002
78961026,1776,benstopford,2016-09-15T13:20:52Z,"we have that already on line 428. are you concerned about it being there, or objecting to the format of the test?",0,0.9699440598487854
78961219,1776,benstopford,2016-09-15T13:21:56Z,ok,0,0.9233372807502747
78979265,1776,benstopford,2016-09-15T14:38:40Z,"the nice thing about having it in the config is validation. if we remove the prop, we'd probably need another list of dynamic broker configs somewhere. what do you think?",0,0.9402154684066772
78994469,1776,junrao,2016-09-15T15:38:36Z,"yes, we are doing similar things in kip-55. we are deprecating the static client quota configs in the broker in favor of dynamic quotas. so, for new broker configs, if it can be made dynamically, it seems it's less confusing to also add a static config in the broker property.",0,0.9905647039413452
79071084,1776,apurvam,2016-09-15T21:57:41Z,"you should log a message here, with information of the old and new quota topic for the broker/topic/partition being modified. otherwise these dynamic changes without any auditing will be impossible to debug.",0,0.992827832698822
79080424,1776,benstopford,2016-09-15T23:03:46Z,it should be visible from the logging in the dynamicconfigmanager (line 106). do you not see that?,0,0.9950821399688721
79080650,1776,apurvam,2016-09-15T23:05:40Z,"yes, i see it now. sorry for the false alarm.",-1,0.9937552213668823
1379392210,14690,kirktrue,2023-11-01T22:26:33Z,"now that i'm noticing, is this a public api violation? it's not in `internals` and we're adding a `public` method :thinking_face:",1,0.5776560306549072
1379396122,14690,kirktrue,2023-11-01T22:31:10Z,nit: more idiomatic: [code block],0,0.9663477540016174
1379398154,14690,kirktrue,2023-11-01T22:34:25Z,"i'm probably confused by taking the naming of the `onheartbeatrequestsent` method too literally, but the request hasn't been _sent_, only _enqueued_. do we need to call this when it's really _sent_ or is enqueued ""good enough?""",-1,0.5529918074607849
1379399402,14690,kirktrue,2023-11-01T22:36:41Z,"this is the case where the consumer is not in a group _presently_, right? a consumer without a configured group id wouldn't get to this point, would it?",0,0.9884548187255859
1379400497,14690,kirktrue,2023-11-01T22:38:28Z,"as i understand, this is saying the consumer will leave the `acknowledging_reconciled_assignment` state as soon as the next heartbeat is sent off, rather than the next heartbeat is received, right? what happens if that heartbeat request gets lost?",0,0.9913522005081177
1379402695,14690,kirktrue,2023-11-01T22:42:06Z,"sorry to retread this: how are `leaving_group` and `sending_leave_request` different? they both will call the `onpartitionslost()` callback first, right?",-1,0.9845289587974548
1379404682,14690,kirktrue,2023-11-01T22:45:53Z,does the consumer transition from `join` to `reconciling` mean that the first heartbeat response after the join request will (may?) contain an assignment?,0,0.9927189350128174
1379407419,14690,kirktrue,2023-11-01T22:50:32Z,`targetassignment()` looks to only be used by unit tests at the moment. does it make sense to remove it from the interface and leave it as a method on the implementation only?,0,0.9930045008659363
1379408357,14690,kirktrue,2023-11-01T22:52:23Z,can this be called directly via the `applicationeventprocessor` when the consumer sends an event to the network thread to state it is closing? the only other place i see it called at the moment is from a unit test.,0,0.9932460188865662
1379413852,14690,kirktrue,2023-11-01T23:02:28Z,"the ide is showing this line with a warning because it's invoking `get()` without a `ispresent()` check. i know that it's being set in `settargetassignment` right above, but can we refactor this code to make it more obvious to the compiler (and any humans reading it)? here's a quick take: [code block] that way all the logic is together and we can remove `settargetassignment()`, too. just a thought.",0,0.9617862105369568
1379415462,14690,kirktrue,2023-11-01T23:05:54Z,would you mind making a constant for `-1` just so it's easier to grep through the code and find places where the consumer is in this state?,0,0.9922441840171814
1379415743,14690,kirktrue,2023-11-01T23:06:34Z,"same here, regarding the magic numbers.",0,0.9889733195304871
1379418198,14690,kirktrue,2023-11-01T23:11:23Z,"i guess it's ok to use `consumermetadata` directly like this as we ""own"" updating it on the consumer network thread.",0,0.9883198738098145
1379419317,14690,kirktrue,2023-11-01T23:13:40Z,"yes, we'll have to resolve how the callbacks fit into this model that uses `future`s, because the callbacks need to be invoked on the application thread.",0,0.9922428727149963
1379420036,14690,kirktrue,2023-11-01T23:15:16Z,i made a comment up above about removing `targetassignment()` from the `membershipmanager` interface because it was only used for testing. does the removal of this statement imply that it will be used in non-testing later?,0,0.9937627911567688
1379420603,14690,kirktrue,2023-11-01T23:16:23Z,"would it be ""wrong"" to have the method implementation log the message instead of throwing an error?",0,0.9422584176063538
1379420811,14690,kirktrue,2023-11-01T23:16:48Z,this makes sense!,0,0.8072646856307983
1379422902,14690,kirktrue,2023-11-01T23:20:46Z,"two questions: 1. `topic` wants to unify the topic id and topic name information, but it explicitly allows either to be `null`. technically, since there are no checks, both values could be `null`. is that intentional? 2. notwithstanding the above, can we add this class without a kip? if not, can we move it to `o.a.k.common.internals`?",0,0.9840496778488159
1379423191,14690,kirktrue,2023-11-01T23:21:23Z,"this would throw a `nullpointerexception`, wouldn't it?",0,0.9865218997001648
1380063605,14690,AndrewJSchofield,2023-11-02T13:00:44Z,"i see what means, but this package is not part of the public javadoc. the closest that the public interface has to exposing this kind of information is `org.apache.kafka.common.cluster`.",0,0.9862254858016968
1380073097,14690,AndrewJSchofield,2023-11-02T13:07:41Z,"i'm surprised that the previous valid states for fatal is not all of the other states, such as fenced.",-1,0.8802686333656311
1380077957,14690,AndrewJSchofield,2023-11-02T13:11:42Z,`topicidpartition`? you do know the topic ids and they're relevant for guarding against topics which have been recreated.,0,0.9909798502922058
1380079966,14690,AndrewJSchofield,2023-11-02T13:13:15Z,"i suggest ""skip sending the heartbeat to the coordinator"". i do like the method naming convention you're establishing with ""skip"" in the name.",0,0.7742760181427002
1380080844,14690,AndrewJSchofield,2023-11-02T13:14:02Z,"just ""leaving"" would match the other states better.",0,0.9604132771492004
1380083241,14690,AndrewJSchofield,2023-11-02T13:16:03Z,`transitiontojoining`?,0,0.9930385947227478
1380083590,14690,AndrewJSchofield,2023-11-02T13:16:20Z,`transitiontofatal`?,0,0.9819303154945374
1380086392,14690,AndrewJSchofield,2023-11-02T13:18:34Z,"personally, i'd capture the value of `state()` in a local variable and then use it twice, rather than calling the method twice. there are a couple of instances of this.",0,0.9939477443695068
1380088445,14690,AndrewJSchofield,2023-11-02T13:20:16Z,"i think so. also, the set return by `consumermetadata` is immutable.",0,0.98358154296875
1380090093,14690,AndrewJSchofield,2023-11-02T13:21:37Z,i think that theoretically it could and the action you've proposed is correct.,0,0.9774790406227112
1380092591,14690,AndrewJSchofield,2023-11-02T13:23:36Z,interesting :),1,0.991432785987854
1380121804,14690,AndrewJSchofield,2023-11-02T13:31:50Z,i would say that it needs a kip in this package.,0,0.9864566326141357
1380144482,14690,AndrewJSchofield,2023-11-02T13:35:57Z,`objects.hashcode()` is your friend.,0,0.9937410950660706
1380218718,14690,lianetm,2023-11-02T14:17:40Z,totally! i missed that,1,0.9926517605781555
1380372614,14690,lianetm,2023-11-02T15:53:22Z,"that was considering that the member could only got to fatal from states where it sends heartbeat, when receiving non-retriable errors in the heartbeat response (and states like fenced or leaving do not send heartbeat)",0,0.9888939261436462
1380393617,14690,AndrewJSchofield,2023-11-02T16:06:13Z,that's ok. i was just asking an innocent question. makes sense to me.,1,0.7512413859367371
1380592053,14690,lianetm,2023-11-02T17:59:27Z,"i expect that topic class will be exposed at some point, as we spread the usage of topic id in the client code, that's why i added it there, but totally missed that it could then require a kip. so i just moved it to the internal package, as it is truly only internal for now.",0,0.9852063059806824
1380659584,14690,lianetm,2023-11-02T19:06:20Z,"i moved it to the internals for now, as it's truly for internal use (even though i expect we might want something similar later on as we use topicid more in the client code).",0,0.9919608235359192
1380660843,14690,lianetm,2023-11-02T19:07:45Z,"you're right, this is the case where a consumer, with a groupid, is not part of the group (either it hasn't called subscribed, or it called unsubscribe)",0,0.9897624850273132
1380683789,14690,lianetm,2023-11-02T19:31:50Z,"this is the check we discussed earlier about target assignment and subscription. leaving it for now only so you can see exactly what it is, but we can remove it then if we still think it should be better to let the broker drive this.",0,0.9946046471595764
1380693973,14690,lianetm,2023-11-02T19:43:42Z,"good catch, i needed it public at some point but it ended up not being needed in the end. so putting it back to package-private and ""visible for testing""",1,0.9387442469596863
1380694833,14690,lianetm,2023-11-02T19:44:42Z,"totally, it seemed it was needed here at some point but not anymore. removing it & cleaning up, thanks!",1,0.9847217202186584
1381667636,14690,dajac,2023-11-03T13:17:23Z,nit: i think that we tend to indent with 4 spaces in this case.,0,0.9864072203636169
1381676706,14690,dajac,2023-11-03T13:25:32Z,"i think that this is not enough because we only need to send it if it has changed and we also need to re-send them on failure. i was thinking about introducing a stateful builder object for the request which remembers the last fields sent out and decider whether the fields must be set or not. on errors, we could just reset the builder to re-send all fields. i think that could possibly always set all the fields in this pr and tackle this separately as we need to solve it more generally. what do you think?",0,0.9624450206756592
1381679771,14690,dajac,2023-11-03T13:27:57Z,i am not a big fan of the `not_in_group` name because the consumer could still have a group id configured and commit offsets to a group. this is why i used `unsubscribed` earlier. i wonder if we could find a better name... what do you think?,0,0.7157530784606934
1381680532,14690,dajac,2023-11-03T13:28:35Z,could we extend the description to explain what we do in this state? i would also do it for the others.,0,0.9949209094047546
1381683004,14690,dajac,2023-11-03T13:30:21Z,"so i i understand it correctly, the member transitions to this state as soon as the reconciliation is done and then transition to stable as soon as the ack is sent out. did i get it right?",0,0.9886936545372009
1381683686,14690,dajac,2023-11-03T13:30:53Z,do we call `lost` in this case?,0,0.9864046573638916
1381686009,14690,dajac,2023-11-03T13:32:50Z,i also wonder if we should call it `acknowledging` to follow the naming of the other states. thoughts?,0,0.964891254901886
1381688086,14690,dajac,2023-11-03T13:34:36Z,"my understanding is that `leaving` do the pre-leaving steps (e.g. pause partitions, commit offsets, etc) while `sending_leave_request` sends out the actually leave request. perhaps, using `prepare_leaving` and `leaving` would make it clearer. thoughts?",0,0.988010823726654
1381690930,14690,dajac,2023-11-03T13:36:52Z,i think that we already define them in the `consumergroupheartbeatrequest` class. we could reuse them.,0,0.988187849521637
1381692974,14690,dajac,2023-11-03T13:38:13Z,`targetassignment` seems to be accessible directly. do we really need to pass it here?,0,0.9939999580383301
1381801641,14690,dajac,2023-11-03T14:44:53Z,"okay. i think that we could get into this situations in two cases. 1. an assigned topic was just created and the metadata request got to a broker unaware of it yet. in this case, ignoring it means that the newly created topic will never be consumed by the member. or, at least, it won't be consumed until another assignment is received. in the current implementation, i think that the fetcher will keep retrying on those topics. ideally, we would need something similar here. 2. an assigned topic was just deleted before the member got the chance to get the metadata. this is somewhat the opposite case. in the case of 1., we could argue that we should just keep retrying until it succeeds and it should eventually succeed. in this case of 2., it would never succeed if the topic is deleted so the member will never send an ack and will eventually be kicked out from the group. to make it worst, the member won't receive an new assignment without the deleted topic because the previous assignment is not ack'ed. the issue is that there is no way to differentiate the two cases. ideally, we should set the subscription based on the topic ids instead of the topic names. however, this does not resolve the need to have the topic names for the callbacks. there are really annoying... another thing that i wanted to point out is that it is not all or nothing. for instance, the member could get 10 partitions assigned to him and only one is unresolvable.",0,0.9342437386512756
1381802659,14690,dajac,2023-11-03T14:45:40Z,"as discussed offline, i would remove this. in my opinion, the member should just follow what the coordinator provide and should not try to be too smart here.",0,0.9804518818855286
1381802850,14690,dajac,2023-11-03T14:45:49Z,nit: extra line.,0,0.9561603665351868
1381810747,14690,dajac,2023-11-03T14:52:17Z,i wonder if we should also check if the target assignment is still the same one. i am not sure if it is possible but could we have a callback coming really late and the state machine could have already transitioned to fenced and rejoined the group and got a new assignment so be in reconciling state again?,0,0.9790337681770325
1381814507,14690,dajac,2023-11-03T14:55:03Z,"one concern that i have with using the manager directly is that it does not seem to populate the metadata cache afterwards. so, we would resolve topics once here and then the fetcher would redo it because the metadata cache does not have the topics. this is not ideal.",-1,0.5437706112861633
1381819971,14690,dajac,2023-11-03T14:58:48Z,from the kip:,0,0.9941920638084412
1382108731,14690,philipnee,2023-11-03T18:50:20Z,we should just return early here. `return completablefuture.completedfuture(null);`,0,0.9950944185256958
1382450219,14690,philipnee,2023-11-04T19:50:27Z,i believe the reconciliation result is completed by the main thread.,0,0.9892900586128235
1382665763,14690,lianetm,2023-11-05T22:51:45Z,`unsubscribed` describes the state better to me too. renamed it and added comments explaining better how the member gets there and what it can do while in this state.,0,0.9847689867019653
1382666152,14690,lianetm,2023-11-05T22:54:17Z,"you're right, this state is only until the next hb is sent, and then the member moves on. if the hb with the ack is lost, what happens is that, when the rebalance timeout expires, the broker will re-assign the partitions to another member and kick this one out of the group.",0,0.9904828071594238
1382666539,14690,lianetm,2023-11-05T22:56:18Z,"you're right about what each does, and agree with the `prepare_leaving` and `leaving`. renamed them and updated comments, it looks clearer.",0,0.7088255882263184
1382666673,14690,lianetm,2023-11-05T22:57:15Z,"removed all static membership logic for now, given that is it not supported yet.",0,0.990972638130188
1382666792,14690,lianetm,2023-11-05T22:57:56Z,done,0,0.8682363629341125
1382666862,14690,lianetm,2023-11-05T22:58:42Z,totally. done.,0,0.8715993762016296
1382667315,14690,lianetm,2023-11-05T23:01:42Z,"good point. i reused the -1, and removed the static membership constant and logic from our side given that it is not supported yet.",1,0.9607864022254944
1382667377,14690,lianetm,2023-11-05T23:02:08Z,"you're right, not needed, removed.",0,0.9443451762199402
1382668541,14690,lianetm,2023-11-05T23:08:59Z,"good point, this was not the right way so i updated how metadata is used here, all based on the metadata object now (request update when needed, and get notified when it happened). this ensures that the centralized cache is updated, and this is actually how other managers interact with metadata (ex. `offsetsrequestmanager` when it needs metadata to find leaders).",1,0.9051437377929688
1382724053,14690,lianetm,2023-11-06T02:20:05Z,"exactly, that's the case the transition is covering.",0,0.9893180727958679
1382728096,14690,lianetm,2023-11-06T02:31:49Z,"makes sense, i will include the changes for the initial approach sending all, to tune it afterwards and send only what's needed",0,0.9900338053703308
1382742662,14690,lianetm,2023-11-06T03:08:57Z,"done. i updated them all, explaining more of what the member does in each and the relationship with the hb requests content and timing.",0,0.9780474305152893
1382772899,14690,lianetm,2023-11-06T04:35:39Z,"yes, we do, based on the epoch (epoch > 0 => onpartitionsrevoked, else onpartitionslost). the prepare leaving will trigger the `onpartitionsrevoked` in most of the cases i expect, but if the member is not in the group anymore it calls `onpartitionslost`. i was mainly thinking about the edge case where a member gets fenced, and while fenced (ex. waiting for user callback to complete), there is a call to unsubscribe. at that point the member would attempt to leave the group, but it is not currently an active member, so will call `onpartitionslost`. makes sense? that being said, i realize that even though the implementation supports that case, it was not a valid transition, so i just added it. will add tests for it shortly.",0,0.9873722791671753
1383374287,14690,lianetm,2023-11-06T13:59:51Z,"the callback execution will be completed in the main thread (when implemented), but this is the reconciliation result that completes here in the background thread, that involves not only the callbacks. it involves 3 main async operations: - metadata (to resolve topic names for assignment) - commit - user callbacks (executed in the main thread)",0,0.9947319030761719
1383433245,14690,lianetm,2023-11-06T14:32:23Z,"thanks for confirming . after the change to integrate this with the centralized metadata object and cache, we do achieve this behaviour (we keep retrying until all assigned topic ids are found in metadata)",1,0.9343371391296387
1383435641,14690,lianetm,2023-11-06T14:34:08Z,"totally, all changed, thanks!",1,0.9837460517883301
1383513687,14690,lianetm,2023-11-06T15:26:08Z,"done, i updated it back to sending all fields for now. i will follow up in a next pr to send only what's needed. i expect that it will be the existing `heartbeatstate` the one to extend, to be able to build a `consumergrouprequestdata` based on the last one sent, the member info, and the subscription info (determine difference to send only what changed, and send all on the failed attempts that it already handles for retry/backoff)",0,0.9705377221107483
1383532710,14690,lianetm,2023-11-06T15:36:59Z,"i think we should have both points solved now with the new metadata approach. 1. we continue to request metadata updates as long as there are assigned topic ids not resolved ([a link]. this will solve the first case as you described. 2. we keep a local cache of assigned topicid->topicnames for assigned topics that have been previously resolved. if topic is not in metadata when it comes in a next target assignment it will be resolved from the local cache ([a link], as it is a known/assigned topic. this will solve case 2. thoughts?",0,0.839172899723053
1383551733,14690,lianetm,2023-11-06T15:48:15Z,"just for the record, it wasn't integrated initially when you took a look but it was added in this pr. and yes, you're right, it is integrated via the applicationeventprocessor and the hbmanager",0,0.9926115870475769
1383566278,14690,philipnee,2023-11-06T15:57:47Z,if the reconciliationresult is completed by the main thread then i think the whencomplete block is also completed by the main thread.,0,0.9917290806770325
1383599082,14690,lianetm,2023-11-06T16:19:09Z,"i will share thoughts on this on our next sync with and you , as this is interesting. just for the record, i do agree that spreading topic ids is the right way forward, and we do have them now in the assignment path, but i realized when exploring this suggestion that it is a much bigger change if we move away from `topicpartition`, and we're not ready for it at this point (mainly tricky/ugly because not all paths support topicid yet but most of them access/update the shared `subscriptionstate` component and `topicpartition`) at this point looks to me that we're better of making use of the topic ids kind of ""on the side"", like we're doing now in the `membershipmanager`, that keeps the assigned topicid/names but still uses the same `topicpartition`. this is the same approach followed by the `fetch` and `metadata` paths, that introduced topic ids in a similar ""on the side"" way. there's interesting food for thought here anyway.",1,0.6294705867767334
1383610788,14690,lianetm,2023-11-06T16:27:55Z,"i'm using `send` to align with how the hb manager was naming the existing `onsendattempt` and such, and i think that as seen from the manager point of view it is enough, the membership manager only needs to know that the request is sent out of the hb manager to transition accordingly. it is not literally sent over the network. i would leave send/sent to keep it consistent between the 2 managers, but let me know if you think it would be clearer differently.",0,0.970314085483551
1383623183,14690,dajac,2023-11-06T16:33:24Z,"i think that a client could still get an unresolvable topic id and be stuck in the reconciling state. for instance, it could happen if the member sees a topic id for the first time and the topic id is deleted just before it could resolve it.",0,0.9823909401893616
1383699023,14690,philipnee,2023-11-06T17:21:25Z,is there any reason we want to combine onpartitionslost and onpartitionsrevoke into a single function? couldn't we directly invoke `invokeonpartitionsrevoke` or `invokeonpartitionslost`? i.e. by the time the consumer is fenced or would know we need to invoke onpartitionslost,0,0.9908632040023804
1383701313,14690,philipnee,2023-11-06T17:23:02Z,"as previously mentioned, it is clearer to directly invoke `invokeonpartitionslost` here. is there a case we don't invoke onpartitionslost?",0,0.9941898584365845
1383780173,14690,philipnee,2023-11-06T18:21:36Z,i don't think the exception will actually be thrown here.,0,0.9477021098136902
1383786483,14690,philipnee,2023-11-06T18:26:42Z,"looking at the current consumer, i think it can be quite complicated in this implementation. maybe what we should do is to invoke the listener on the spot, then send an even to the background thread to leave group.",0,0.9657594561576843
1383791886,14690,philipnee,2023-11-06T18:32:02Z,i'm guessing the idea is we need to ignore the backoff and heartbeat.,0,0.9662027359008789
1383959347,14690,lianetm,2023-11-06T20:42:13Z,"yes, as we discussed for the states that would send heartbeat without waiting for the interval (sending ack for an assignment and leave group requests basically)",0,0.9926683306694031
1383962388,14690,lianetm,2023-11-06T20:44:53Z,"you're right, it should happen in the poll to maintain the current contract. i will just remove it since we don't execute callbacks yet, and it should be included in the pr that introduces the callback execution.",0,0.9919453263282776
1383968073,14690,philipnee,2023-11-06T20:49:52Z,can we use the standard tostring format? topic(topicid=...),0,0.9955319166183472
1383974744,14690,philipnee,2023-11-06T20:54:17Z,can we just fail the consumer?,0,0.7332229614257812
1383979443,14690,lianetm,2023-11-06T20:58:28Z,"the reason is the leave group logic. on leave group it could be lost or revoked, depending on the epoch. on fence or fatal is always lost. i was just reusing the same func for convenience, but will change the fence and fatal transitions to directly invoke the `onpartitionslost` just to make the intention clearer.",0,0.9918355941772461
1383983917,14690,lianetm,2023-11-06T21:02:21Z,"the kip states that we should do exactly this, and actually the consumer would stay functional. `consumer#enforcerebalance will be deprecated and will be a no-op if used when the new protocol is enable. a warning will be logged in this case.` do you have a concern that i may be missing?",0,0.9934004545211792
1383986418,14690,lianetm,2023-11-06T21:04:19Z,"actually i intentionally followed the standard of the topicpartition and topicidpartition tostring implementations, since this new topic class is kind of a sibling, makes sense?",0,0.9929836988449097
1383995398,14690,philipnee,2023-11-06T21:11:42Z,thanks for the clarification!,1,0.8992339372634888
1384004581,14690,philipnee,2023-11-06T21:19:24Z,thanks for the clarification!,1,0.8992339372634888
1384016549,14690,philipnee,2023-11-06T21:29:38Z,"i think unsubscribe() actually blocks on callback invocation and throw if possible. instead of putting the logic in whencomplete, it seems like we should try to wait till the callback completes then throw if needed. i assume we want to maintain this behavior for the async consumer.",0,0.9882411360740662
1384076305,14690,philipnee,2023-11-06T22:00:43Z,"i think this kafkaexception might not be in the right place because the rebalance listener needs to be invoked on the mainthread, probably before sending out the event. i wonder if we could just remove this whencomplete and rely on the background thread to log the failures during the leave group event. if there's a fatal exception being thrown there, it seems the sensible way is to enqueue to the backgroundeventqueue and handle in the poll. wdyt? in the current code path, i think only exceptions can only be thrown in `onleaveprepare`.",0,0.9822569489479065
1385059304,14690,lianetm,2023-11-07T14:59:12Z,"agree that the unsubscribe blocks on the callbacks, but since we don't have the implementation for how callbacks are going to be executed on this pr this unsubscribe is still not using it. it should come when we nail the implementation details on the follow-up pr (will depend on how we end up doing it, maybe blocking not here, but on the subscribe/unsubscribe events) as for the exception, it will originate in the application thread, where the callback is executed, and it should only be returned to the user when it calls poll, to maintain the current behaviour, so i removed it from here to stay consistent and leave all logic related to the callback execution out, i see the confusion introduced. the when complete should stay because it represents a concept we need, un-related to callbacks: we do need to update the `subscriptionstate` only when the unsubscribe event completes (hb to leave group sent to the broker). we need it know to make sure we are able to run unsubscribe, no callbacks, sending leave group, and clearing up the subscription state after sending the request. trying to leave it in a consistent state with no callbacks. follow-up pr should introduce implementation for executing them, blocking appropriately on the execution, and throwing the exceptions.",0,0.9896977543830872
1385082158,14690,lianetm,2023-11-07T15:14:06Z,"agree, done here. note my answer above though, about the cases where we do need revoke or lost, that one should stay.",0,0.9567223787307739
1385085418,14690,lianetm,2023-11-07T15:15:58Z,"just for the record, as discussed offline, none of these futures are expected to be completed in the main thread. this is a reconciliation future, which is much more than the callbacks (metadata, commit, callbacks). and callbacks, when implemented, will be based on events shared between the app thread and the background thread (not based on futures from one thread complete on the other, as that would be problematic)",0,0.9912374019622803
1385350785,14690,lianetm,2023-11-07T18:18:35Z,"agree. just for the record, we're trying to figure out how to properly handle the cases where metadata wouldn't be available for a target assignment (permanently when topic deleted, or even just temporarily). with the current shape where the client attempts to reconcile the full target assignment, what happens now is rather disruptive, as the member would be kicked out of the group after rebalance timeout expires.",0,0.972588300704956
1387282757,14690,philipnee,2023-11-08T22:48:58Z,this is just a transient state for the member to send the leave group heartbeat with epoch -1/-2 (dynamic/static membership) right?,0,0.9929128289222717
1389220863,14690,dajac,2023-11-10T10:31:26Z,do we still need the changes in this class? it seems that we don't use them anymore. i have the same question for the new `topic` class.,0,0.9847279787063599
1390582429,14690,lianetm,2023-11-13T03:01:07Z,"you're right, not needed anymore (all metadata interaction is now based on the centralized metadata cache). all removed.",0,0.9850566983222961
1390583612,14690,lianetm,2023-11-13T03:03:33Z,"yes, similar to the acknowledging in the sense that they are just a way to indicate that a heartbeat must be sent without waiting for the interval, and as soon as the request is sent the member transitions out of the state.",0,0.9922971129417419
1390590490,14690,lianetm,2023-11-13T03:20:45Z,"totally valid point. i fixed it, but comparing assignments seemed more complicated and harder to reason about with the current approach. now the target assignment is kind of a moving target, it can be modified anytime not only from the server, but also from metadata updates. so back to the problem of making sure that delayed reconciliations are not applied after a member rejoins, i added just a check based on the current member id, to identify that a reconciliation completed but the member is already re-joining. what do you think? (whenever there are no rejoins in the picture, i expect that the reconciling state check alone should be enough given that reconciliations are always applied sequentially)",0,0.8657863140106201
1391828060,14690,kirktrue,2023-11-14T00:01:15Z,"the closure that the application thread is passing to `whencomplete()` will be run in the background thread, right? the closure is modifying the `subscriptionstate`, it shouldn't cause any problems, but still... since we have access to the `subscriptionstate` in the background thread already, can the background thread just update the `subscriptionstate` directly?",0,0.9723044037818909
1391862343,14690,kirktrue,2023-11-14T01:04:51Z,"there's another `subscribeinternal()` for the topic pattern path. we want this there too, right?",0,0.9941038489341736
1391875622,14690,kirktrue,2023-11-14T01:30:29Z,"i apologize if it's here somewhere, but i don't see where we ""register"" the membership manager with the cluster resource listeners.",-1,0.8250347971916199
1391875744,14690,kirktrue,2023-11-14T01:30:45Z,good call!,1,0.99321448802948
1391876960,14690,kirktrue,2023-11-14T01:33:12Z,"the intention of the `completeableapplicationevent` was to have a way for the consumer to block on the results of operations performed in the background thread. since the `consumer.unsubscribe()` api call is non-blocking, i'm thinking this should be a subclass of `applicationevent`.",0,0.9915662407875061
1391879026,14690,kirktrue,2023-11-14T01:37:29Z,are we missing the initialization of `unsubscribed`?,0,0.9917546510696411
1391880921,14690,kirktrue,2023-11-14T01:41:16Z,[code block] `subscription_change` is a bit vague. does it encompass more than the event of the user calling `consumer.subscribe()`?,0,0.9894466400146484
1391882860,14690,kirktrue,2023-11-14T01:45:20Z,[code block] suggestion: use the double-underscore to denote to the reader that the variable is intended to remain unused.,0,0.994215190410614
1391883884,14690,kirktrue,2023-11-14T01:47:24Z,"suggestion: consider moving this to an `assignpartitions()` method, similar to the `revokepartitions` method, for consistency and readability.",0,0.9909383058547974
1391885027,14690,kirktrue,2023-11-14T01:49:38Z,"suggestion: make `groupinstanceid` and `serverassignor` `optional` as constructor parameters to convey to the callers that they are, indeed, _optional_.",0,0.9937964677810669
1391885243,14690,kirktrue,2023-11-14T01:50:07Z,[code block] haha. i don't really care :smirking_face:,1,0.9921022057533264
1391888737,14690,kirktrue,2023-11-14T01:56:43Z,[code block] nit: remove extra newline.,0,0.9948103427886963
1391889559,14690,kirktrue,2023-11-14T01:58:16Z,[code block] nit: it'll be visually easier to parse with the space before the next sentence.,0,0.9828650951385498
1391890695,14690,kirktrue,2023-11-14T02:00:28Z,"i think this `equals()` call is ok. from looking at `abstractset`, it appears that `sortedset.equals()` is ok to accept any ol' `set` implementation.",0,0.6741043925285339
1392717259,14690,lianetm,2023-11-14T14:50:53Z,"the `consumer.unsubscribe` does block on the callback execution, that's why it is a `completableapplicationevent`. only after the callback completes the unsubscribe can send the actual leave group heartbeat request. makes sense?",0,0.9937001466751099
1392732597,14690,lianetm,2023-11-14T14:59:46Z,"i see, i was just intentionally leaving out all the pattern based logic because we don't support it at this point. but this makes me realize that that `subscribeinternal` based on pattern that you mentioned is wired to the `subscribe(pattern pattern)` api call, when it's truly not supported yet. i think we should disable all the subscribe based on patterns until we implement them properly. what do you think?",0,0.9712225198745728
1392733198,14690,lianetm,2023-11-14T15:00:07Z,"good catch, added.",1,0.9779465198516846
1392744058,14690,lianetm,2023-11-14T15:05:01Z,"indeed, only from the state when the leave group hb is sent out. added and test. thanks!",1,0.9882118105888367
1392748787,14690,lianetm,2023-11-14T15:07:53Z,"it's exactly when the user changes the subscription via a call to subscribe. i used the name `subscription_change` because it seemed clear and to be consistent with the existing `assignment_change`, but let me know if you think another name would be better.",0,0.9950343370437622
1392790381,14690,lianetm,2023-11-14T15:32:12Z,"done. just to make sure we are on the same page, the whole snippet marked is not really assign. assign is only ln 581 and ln 591 where the subscription state is updated and calling callbacks, and yes, i extracted those into an `assignpartitions()`. the rest of the checks, cache and errors is related to the revocation (or the transition from revocation to assign) so leaving it here where the revocation and assign are linked.",0,0.9826657772064209
1392802141,14690,lianetm,2023-11-14T15:38:34Z,"he he, i do avoid this, missed it here, fixed ;)",1,0.9899778366088867
1392827512,14690,kirktrue,2023-11-14T15:55:51Z,where does it block? i didn't see a call to `future.get()` when i looked.,0,0.9899605512619019
1392829031,14690,kirktrue,2023-11-14T15:56:51Z,"i never liked `assignment_change` either, but i guess it's consistent, so :thumbs_up:",1,0.9895434379577637
1392830639,14690,kirktrue,2023-11-14T15:57:54Z,"those kinds of things tend to jump out in _other people's_ code, but i frequently miss them in my own :grinning_face_with_smiling_eyes:",1,0.971390426158905
1392954694,14690,lianetm,2023-11-14T17:18:17Z,"agree that the equals here does what we want, but actually this made me notice another detail. i wasn't passing the custom comparator when creating the `assignnedpartitions` sorted set. also, for the owned ones, i already have a sorted set a few lines below so just moving it up to reuse it and make the comparison clearer.",0,0.9870801568031311
1393793669,14690,dajac,2023-11-15T07:59:21Z,nit: we could remove this empty line.,0,0.9807522892951965
1393794196,14690,dajac,2023-11-15T07:59:49Z,should we add a unit test for the newly added topic names mapping?,0,0.9948554039001465
1393830838,14690,dajac,2023-11-15T08:30:47Z,"from an architectural point of view, i wonder if this method and the next one are in the right place. intuitively, i would have put them into the membership manager directly because they don't interact with the heartbeat manager state at all. what's your take on this?",0,0.934634268283844
1393833703,14690,dajac,2023-11-15T08:33:05Z,"have we reached a conclusion on this one? it seems correct to me to consider it as a no-op if the member is already leaving. however, i was wondering whether we should return a future here that will be completed only when the on-going leave operation completes.",0,0.987165629863739
1393834178,14690,dajac,2023-11-15T08:33:32Z,"nit: we could remove a few empty lines here, i suppose.",0,0.9719083309173584
1393839254,14690,dajac,2023-11-15T08:37:43Z,nit: -1 or -2.,0,0.6965910196304321
1393842585,14690,dajac,2023-11-15T08:40:19Z,could we transition to fatal from prepare leaving and leaving?,0,0.9846636652946472
1393842889,14690,dajac,2023-11-15T08:40:35Z,could we transition to fatal from prepare leaving?,0,0.9663069248199463
1393848768,14690,dajac,2023-11-15T08:45:11Z,`acknowledges the target assignment` is confusing here. my understanding is that it will acknowledge the part of the target assignment that was actually reconciled. am i correct?,0,0.7924624681472778
1393850232,14690,dajac,2023-11-15T08:46:22Z,nit: i think that we usually put static variables first when declaring attributes.,0,0.9849328398704529
1393852447,14690,dajac,2023-11-15T08:47:55Z,nit: should we move this one to `consumergroupheartbeatrequest` as we already have `leave_group_member_epoch` there?,0,0.984093964099884
1393854091,14690,dajac,2023-11-15T08:49:07Z,i am confused by this. did we say that we should keep the member id forever when we receive one?,-1,0.9674449563026428
1393856821,14690,dajac,2023-11-15T08:51:05Z,"note that it is possible to receive the exact same assignment multiple times. i suppose that in this case, we transition to reconciling and the reconciliation process will be a no-op because the current and the target are the same. did i get it right?",0,0.9930095672607422
1393914776,14690,dajac,2023-11-15T09:32:14Z,nit: i wonder whether we should log this as an error.,0,0.8993563652038574
1393915412,14690,dajac,2023-11-15T09:32:42Z,should we also react to the future completion here for e.g. log something?,0,0.9941468238830566
1393915845,14690,dajac,2023-11-15T09:33:01Z,don't we need to call `subscriptions.assignfromsubscribed(collections.emptyset());` here as well?,0,0.9942206144332886
1393916982,14690,dajac,2023-11-15T09:33:50Z,nit: we could remove this empty line.,0,0.9807522892951965
1393917097,14690,dajac,2023-11-15T09:33:55Z,ditto.,0,0.9384599328041077
1393958634,14690,dajac,2023-11-15T10:03:02Z,"is this really true? we could have the same topic name in both but with different topic ids for instance. in my opinion, we should move towards using topicidpartition for both the assigned partitions and the partitions ready to reconcile. we can of course tackle separately from this pr.",0,0.9906841516494751
1393958878,14690,dajac,2023-11-15T10:03:13Z,nit: we can remove an empty line here.,0,0.9924375414848328
1393960227,14690,dajac,2023-11-15T10:04:15Z,should we trigger both in parallel?,0,0.9915449619293213
1393962052,14690,dajac,2023-11-15T10:05:30Z,nit: we could remove this empty line.,0,0.9807522892951965
1393962754,14690,dajac,2023-11-15T10:06:01Z,should we log this as an error?,0,0.986903190612793
1393968230,14690,dajac,2023-11-15T10:09:53Z,"as i said before, this does not seem correct to me because we should keep the member id forever.",0,0.978453516960144
1393968517,14690,dajac,2023-11-15T10:10:06Z,nit: we could remove this empty line.,0,0.9807522892951965
1393970046,14690,dajac,2023-11-15T10:11:17Z,nit: we could remove this empty line.,0,0.9807522892951965
1393972135,14690,dajac,2023-11-15T10:12:59Z,what happen in this case? i suppose that the reconciliation will be retried. did i get it right?,0,0.9893667101860046
1393972399,14690,dajac,2023-11-15T10:13:13Z,nit: we can remove the space after the `.`.,0,0.9913600087165833
1393972835,14690,dajac,2023-11-15T10:13:35Z,nit: we could remove this empty line.,0,0.9807522892951965
1393973543,14690,dajac,2023-11-15T10:14:13Z,nit: we could remove this empty line.,0,0.9807522892951965
1393974377,14690,dajac,2023-11-15T10:14:56Z,i agree that the other state transition should take care of updating the state. we should only abort here.,0,0.9786746501922607
1393976328,14690,dajac,2023-11-15T10:16:29Z,nit: we could remove this empty line.,0,0.9807522892951965
1393977197,14690,dajac,2023-11-15T10:17:09Z,"nit: using `ifpresent` would be a bit more idiomatic, i think.",0,0.9802559614181519
1393987062,14690,dajac,2023-11-15T10:24:43Z,"i am not sure to understand how the metadata cache knows which new topic ids it should resolve. or does the consumer request metadata for all topics in the cluster? looking at the code, it is may be what it does.",0,0.916399359703064
1393993623,14690,dajac,2023-11-15T10:29:34Z,+1,0,0.9816582202911377
1394012157,14690,dajac,2023-11-15T10:44:58Z,"there is a subtile behaviour changes here. 1) in the legacy implementation, `this.coordinator.onleaveprepare()` is called here and it triggers the callback before returning from `unsubscribe`. 2) `subscriptions.unsubscribe()` is actually called before `unsubscribe` returns as well.",0,0.9926742911338806
1394032677,14690,dajac,2023-11-15T10:55:05Z,"btw, it seems that we could have transitioned to another state while waiting on this one as well.",0,0.9847996234893799
1394042794,14690,dajac,2023-11-15T11:00:07Z,"i also wonder whether if would be possible to parallelize more. for instance, is there a reason not to trigger the revocation and the assignment callbacks at the same time? this would ensure that they are call within one poll; otherwise, it can take multiple calls to poll to complete the assignment. we could consider this as a optimization for the future.",0,0.9832187294960022
1394053638,14690,dajac,2023-11-15T11:09:11Z,`partitionsassigned` could also be empty here so we should handle this case appropriately. e.g. we should not trigger the callback.,0,0.9943788647651672
1394322340,14690,lianetm,2023-11-15T14:55:14Z,filed [a link] for this and i will take care of it right after this pr as a follow-up.,0,0.9899834394454956
1394344222,14690,lianetm,2023-11-15T15:10:46Z,"yes, done.",0,0.9739049077033997
1394493344,14690,lianetm,2023-11-15T16:57:39Z,"yes, that's what it does, get metadata for all topics [a link]. it seems that there was an intention of a partial update [a link] but not fully implemented, so it effectively ends up getting them all anyways.",0,0.9917305111885071
1394570775,14690,lianetm,2023-11-15T18:00:25Z,"yes, you're right, i will rephrase this. it acknowledges the reconciled assignment, which is the subset of the target that was resolved from metadata and actually reconciled.",0,0.9915134310722351
1394581206,14690,lianetm,2023-11-15T18:07:38Z,"done, re-arranged a couple of them.",0,0.9876882433891296
1394585362,14690,lianetm,2023-11-15T18:10:24Z,"totally, done.",0,0.9212836027145386
1394619681,14690,lianetm,2023-11-15T18:28:38Z,"yes, done. it is actually the level used for this in the legacy coordinator.",0,0.9803643226623535
1394629300,14690,lianetm,2023-11-15T18:37:34Z,"cool, thanks for confirming.",1,0.9866863489151001
1394646561,14690,lianetm,2023-11-15T18:51:40Z,"the legacy coordinator does trigger the `onpartitionsassigned` with empty partitions (not the `onpartitionsrevoked` though), so i intentionally left the same behaviour, makes sense? i had also added a note on the [a link] to make sure that we keep that contract when implementing callbacks.",0,0.9942755103111267
1394733589,14690,lianetm,2023-11-15T20:03:07Z,"yes, done. that's how it's done for other callbacks (aligned the messages too to make them consistent for all callbacks)",0,0.9826923608779907
1394742401,14690,lianetm,2023-11-15T20:12:53Z,"you're right, we do. added it, along with a log in case of error.",0,0.9238659739494324
1394746271,14690,lianetm,2023-11-15T20:17:20Z,"sure, done. logging error in the same way that it's done for other callback failures.",0,0.9855349063873291
1394753399,14690,lianetm,2023-11-15T20:24:11Z,"yes, i just updated this. we're on the same page regarding that the client will keep the member id forever and provide it back....but i was wrongly expecting it would change after rejoining. updated now. the goal is to be able to identify a rejoin, so using the member epoch (expecting that every time a member rejoins will get a bumped epoch).",0,0.8984880447387695
1394759427,14690,lianetm,2023-11-15T20:28:46Z,"you got it right, i expect the same thing (i had this [a link] for that)",1,0.6393479108810425
1394774045,14690,lianetm,2023-11-15T20:42:16Z,"agree, same member id forever. updated this to use the member epoch as a way of identifying that the member has rejoined.",0,0.9927819967269897
1394786770,14690,lianetm,2023-11-15T20:53:01Z,"yes, makes sense to me. it could be bundled up along with the callbacks triggering (both, revocation and assign), so that we trigger them all in the same poll iteration, while still making sure that they are executed in the right order. filed [a link] and i will address that as a follow-up right after this.",0,0.9907938838005066
1394789418,14690,lianetm,2023-11-15T20:55:11Z,"agree, filed [a link] and i will address that as a follow-up right after this (considering all the 3 parts: commit, revoke callback, assign callback)",0,0.9913588762283325
1395130865,14690,lianetm,2023-11-16T04:18:22Z,"agree, i merged them into the membership manager, and this actually goes in the same direction we've discussed about the membership manager becoming a first-class manager (supporting poll, for instance).so for now i integrated it with the `applicationeventprocessor` already, to be able to move these 2 funcs that i totally agree make sense in the membership manager (when tackling the poll for triggering reconciliations, i will extend on this same direction)",0,0.9407528042793274
1395132794,14690,lianetm,2023-11-16T04:22:54Z,"done (now in the membership manager `leavegroup`). no-op if already leaving, and returning the future that will complete when the ongoing leave completes. also handling the case where the member already left (no-op and return right away)",0,0.9929512143135071
1395138233,14690,lianetm,2023-11-16T04:33:38Z,"there is no transition from prepare leaving to fatal with the current usage of fatal (only when receiving fatal errors in hb response), because we don't send hb while in prepare leaving. as for leaving, i would say we shouldn't either, because even if it is a state where we do send hb, we transition out of it as soon as the hb request is ready to be sent (without waiting for the actual send or any response). that being said, this makes me realize that the same reasoning applies for acknowledging, there shouldn't be a way of transitioning from ack to fatal, just because we transition out of it on heartbeat sent.",0,0.9804034233093262
1395138981,14690,lianetm,2023-11-16T04:35:13Z,not with the current usage of fatal as i see it (message above),0,0.8767699003219604
1395143611,14690,lianetm,2023-11-16T04:43:07Z,"agree, filed [a link] to extend topic id usage in the whole assignment reconciliation flow to make sure we handle topic re-creation properly.",0,0.9933642148971558
1395665723,14690,dajac,2023-11-16T13:07:00Z,"we don't send an explicit hb while in prepare leaving. however, we continue to heartbeat so i assume that we could receive an error or be fenced while in this state. regarding the ack case, i think that we could receive a similar response while in ack so the same applies. do you agree?",0,0.982459306716919
1395667965,14690,dajac,2023-11-16T13:08:56Z,interesting... i wonder if this was done on purpose or if this just a bug. i don't really see the value in calling `onpartitionsassigned` without any partitions. i suppose that we should double check this. we could perhaps file a jira and clarify this separately. what do you think?,0,0.5852653980255127
1395669911,14690,dajac,2023-11-16T13:10:27Z,"let's file a jira to improve this as well. ideally, assuming that we don't use client side regex anymore, the client should only request the topics that it needs.",0,0.9936876893043518
1395677889,14690,dajac,2023-11-16T13:16:48Z,nit: i suppose that this one should go on the previous line.,0,0.9840751886367798
1395680718,14690,dajac,2023-11-16T13:17:46Z,i would remove the todos for which we have jiras.,0,0.9872568845748901
1395687362,14690,dajac,2023-11-16T13:22:10Z,nit: i may be worth logging something here as well to be consistent with `transitiontofatal`.,0,0.8387415409088135
1395689326,14690,dajac,2023-11-16T13:23:36Z,nit: should we also log the member epoch?,0,0.9933597445487976
1395690012,14690,dajac,2023-11-16T13:24:13Z,is this still valid? it looks like we call onpartitionslost explicitly now.,0,0.9944148063659668
1395691085,14690,dajac,2023-11-16T13:25:09Z,i wonder why we clear it here whereas in transitiontofenced we clear it when the callback future is completed. is there a reason for this subtile difference?,0,0.947911262512207
1395691853,14690,dajac,2023-11-16T13:25:43Z,is there a reason why we don't do this as the first thing in this method? this would be more consistent with transitiontofenced.,0,0.9911490678787231
1395693217,14690,dajac,2023-11-16T13:26:48Z,"i think that the next hb should pick it up. otherwise, we could perhaps transition to joining to force an immediate hb. i am not sure that it is worth it.",0,0.67745041847229
1395697755,14690,dajac,2023-11-16T13:30:35Z,"i am a bit confuse by where we call `clearpendingassignmentsandlocalnamescache`. sometime we call it when the callback future is completed, sometime right after scheduling the callback. i wonder if it would be possible to be more consistent or if there are specific reasons that i did not get.",-1,0.782917857170105
1395717674,14690,dajac,2023-11-16T13:46:36Z,"note that here we clear the `assignedtopicnamescache` but we only clear the assigned partitions after the callback is executed. this means that we have a period of time during which we are not able to resolve ids from the names in the subscription. i suppose that it does not matter in this case but this could be a source of subtile bugs. as we discussed offline, i think that we really need to update the subscriptions to use topicidpartitions. if this is not possible, an intermediate approach would be to keep the assigned topicidpartitions in this manager and to update the subscriptions with `subscriptions.assignfromsubscribed` when we update it. or, we could also move the bookkeeping of the cache closer to calls to `subscriptions.assignfromsubscribed`.",0,0.9766863584518433
1395721501,14690,dajac,2023-11-16T13:49:34Z,nit: we could use `==` here now.,0,0.9900649189949036
1395722320,14690,dajac,2023-11-16T13:50:12Z,do we need to check the epoch here as well?,0,0.9929266571998596
1395747556,14690,dajac,2023-11-16T14:06:11Z,nit: `t` -> `it`?,0,0.9916987419128418
1395783384,14690,dajac,2023-11-16T14:31:03Z,`the broker will continue to send the assignment to the member.` this is not entirely true. the broker may not send anything.,0,0.9858518838882446
1395862422,14690,lianetm,2023-11-16T15:05:18Z,"agree, rephrased it. this test is just for the case where the broker does keep sending (and the test above for when it does not)",0,0.9895604848861694
1395877609,14690,lianetm,2023-11-16T15:14:22Z,"agree, done. all todos in this class have jiras already.",0,0.7813320159912109
1395894946,14690,lianetm,2023-11-16T15:21:59Z,"you're right, not needed anymore. the member will transition to fatal state but can keep its last member id and epoch.",0,0.9855588674545288
1395907406,14690,lianetm,2023-11-16T15:28:39Z,"no reason, moved it to after the callback completes, consistent with how it is done on fencing, leave and reconcile",0,0.9857797622680664
1395912856,14690,lianetm,2023-11-16T15:32:16Z,"no reason, updated it to make it consistent with the fencing transition",0,0.9864231944084167
1395929369,14690,lianetm,2023-11-16T15:42:56Z,agree that the next hb will pick it up based on the interval (also not seeing much need/value in the forced hb). removed the todo.,0,0.992222249507904
1395947490,14690,lianetm,2023-11-16T15:55:00Z,"yes, i think we need it too. added.",0,0.9313383102416992
1396006392,14690,lianetm,2023-11-16T16:31:16Z,"i moved the clear cache close to the `assignedfromsubscribed` in this manager, as a first step to align both and have a consistent usage",0,0.9932960867881775
1396013115,14690,lianetm,2023-11-16T16:35:22Z,"agree it was not consistent. i moved it close to the call to `assignpartitions`, so when callbacks complete we have a single `updateassignment` that makes the assignment effective and clears cache if needed.",0,0.9894266128540039
1396088885,14690,lianetm,2023-11-16T17:26:05Z,"agree on handling that separately, but leaving the current behaviour as in the legacy coordinator. i also don't see the value either but it would introduce a change on when the `onpartitionsassigned` is called or not, so let's put some more though on it. filed [a link] to follow-up on this.",0,0.9880048632621765
1396462214,14690,lianetm,2023-11-16T22:50:07Z,"i updated it to align with the current behaviour (callbacks, best effort to send leave group request without any response handling or retry, and call to `subscriptions.unsubscribe` when everything completes). this has the gap of the callback execution that would require a poll. given that we don't support callbacks in this pr, it won't block the flow, but definitely to be solved (i added the details of the challenge to solve in the [a link]",0,0.9878857135772705
1396474166,14690,lianetm,2023-11-16T23:01:39Z,"makes sense, [a link]",0,0.980607271194458
1396494887,14690,lianetm,2023-11-16T23:26:51Z,"yes, it will be retried on the next reconciliation loop (known shortcoming is how we trigger the reconciliation loops. it will be improved right after with [a link]",0,0.9943932294845581
1396826235,14690,lianetm,2023-11-17T07:55:29Z,"pushed one fix as a first step towards integrating topicidpartitions, which i agree should be the way forward. for now it is integrated in the membershipmanager, only in the reconciliation path where we do have all the info clearly in hand. will continue the integration as follow-up with [a link] as it requires a little bit more thought",0,0.904887855052948
1398998763,14690,dajac,2023-11-20T10:41:19Z,"i think that this should actually outside of the `else` branch, isn't it?",0,0.9881237149238586
1399012130,14690,dajac,2023-11-20T10:50:03Z,"nit: if we would use `consumergroupheartbeatrequestdata.topicpartitions` in the `hashmap` and the `list`, we could skip this step.",0,0.9929880499839783
1399012491,14690,dajac,2023-11-20T10:50:20Z,nit: we could probably use `computeifabsent` to simplify this code.,0,0.9905151128768921
1399013422,14690,dajac,2023-11-20T10:50:43Z,we still need to conclude on this one.,0,0.9615252614021301
1399026661,14690,dajac,2023-11-20T10:59:17Z,nit: should we move this code into `assignpartitions`?,0,0.9870972633361816
1399044241,14690,dajac,2023-11-20T11:14:04Z,i am curious here. is it better to build a `sortedset` with all elements and then to add it to `assignmentreadytoreconcile` vs adding to `assignmentreadytoreconcile` directly?,0,0.974706768989563
1399045098,14690,dajac,2023-11-20T11:14:49Z,nit: i have noticed that most of the comments end with a period but not all of them. it may be good to be consistent.,0,0.9211318492889404
1408353902,14690,lianetm,2023-11-28T19:58:37Z,"yeah, no value in it. i simplified it by just adding the topicpartition items directly to the `assignmentreadytoreconcile` (in [a link]",0,0.9817054271697998
1408354526,14690,lianetm,2023-11-28T19:59:17Z,"totally, and actually it made me realize it could be further simplified by retaining the assigned. it is included now in the [a link] with the other minor fixes.",0,0.9739039540290833
1408355119,14690,lianetm,2023-11-28T19:59:53Z,"definitely, done in the [a link]",0,0.9897491335868835
1408357542,14690,lianetm,2023-11-28T20:02:32Z,agree. it disappeared anyways after simplifying it all with the use of topicpartitions.,0,0.9803078770637512
1408361923,14690,lianetm,2023-11-28T20:07:07Z,"agree, we were definitely missing here transitions to fatal/fenced that may occur while the member is leaving (any of the 2 phases of leaving). i included the changes to properly handle them in the [a link] so we can continue the conversation there.",0,0.9877594113349915
98550533,2466,mjsax,2017-01-30T21:54:48Z,"this should be added to the first paragraph: [code block] please make sure, that the line is not longer than 120 chars. please adjust other javadocs, too.",0,0.9952072501182556
98553210,2466,mjsax,2017-01-30T22:06:11Z,"`return stream(null, null, keyserde, valserde, topics);` do the call directly instead of the cast.",0,0.9931995272636414
98553705,2466,mjsax,2017-01-30T22:08:30Z,"update to `return stream(offsetreset, null, null, null, topics);` to avoid too many indirections. to this for other overloads, too, please.",0,0.9941828846931458
98554156,2466,mjsax,2017-01-30T22:10:41Z,this should be the only method with actual code. all other overloads should call this one.,0,0.9946297407150269
98554261,2466,mjsax,2017-01-30T22:11:18Z,should not have an implementation but call overloaded method.,0,0.9861702919006348
98554337,2466,mjsax,2017-01-30T22:11:40Z,should not have an implementation but call overloaded method.,0,0.9861702919006348
98554471,2466,mjsax,2017-01-30T22:12:27Z,remove this line -- not required.,0,0.9943072199821472
98554659,2466,mjsax,2017-01-30T22:13:24Z,"nit: adjust indention of other parameters; line should not be longer than 120 chars. indent second/third/etc line, too. text can be shorter: [code block] (no need to link to `timestampextractor` as there will be a link in the javadocs anyway.",0,0.9933462142944336
98555452,2466,mjsax,2017-01-30T22:17:42Z,as above.,0,0.9881609678268433
98555469,2466,mjsax,2017-01-30T22:17:48Z,as above,0,0.9888283014297485
98555494,2466,mjsax,2017-01-30T22:17:56Z,remove,0,0.9896913170814514
98555525,2466,mjsax,2017-01-30T22:18:06Z,as above,0,0.9888283014297485
98555721,2466,mjsax,2017-01-30T22:19:11Z,remove,0,0.9896913170814514
98555745,2466,mjsax,2017-01-30T22:19:21Z,as above,0,0.9888283014297485
98555929,2466,mjsax,2017-01-30T22:20:16Z,"no reformatting, please",0,0.9894912242889404
98555957,2466,mjsax,2017-01-30T22:20:24Z,"no reformatting, please",0,0.9894912242889404
98556721,2466,mjsax,2017-01-30T22:24:30Z,nice catch!,1,0.9932061433792114
98557646,2466,mjsax,2017-01-30T22:29:44Z,we should not add this to the context -- see comments below.,0,0.9906882047653198
98558044,2466,mjsax,2017-01-30T22:31:50Z,keep this but rename to `defaulttimestampextractor`,0,0.9961034059524536
98558367,2466,mjsax,2017-01-30T22:33:32Z,"add line: `timestampextractor sourcetimestampextractor = source.gettimestampextractor();` and change to `recordqueue queue = createrecordqueue(partition, source, sourcetimestampextractor != null ? sourcetimestampextractor : defaulttimestampextractor);`",0,0.995209276676178
98770837,2466,mjsax,2017-01-31T21:09:30Z,"nit: ""default { timestampextractor}[,] and"" the rule is ""a and b"" (for two things no comma), but ""a, b, c, and d"" (for three or more things, use commas)",0,0.9942938685417175
98771506,2466,mjsax,2017-01-31T21:13:00Z,"nit: please use the same order in all javacode -- above timestampextractor is second -- i don't care which order, but please be consistent. maybe follow parameter order of the method overload that provides all parameters ?",0,0.9787148237228394
98771974,2466,mjsax,2017-01-31T21:15:16Z,"remove ""(if any)""",0,0.9945671558380127
98772167,2466,mjsax,2017-01-31T21:16:10Z,"nit: no ""."" at the end please update everywhere.",0,0.9913632869720459
98773132,2466,mjsax,2017-01-31T21:20:22Z,update javadoc. same below,0,0.9920827150344849
98773266,2466,mjsax,2017-01-31T21:20:59Z,as above,0,0.9888283014297485
98773635,2466,mjsax,2017-01-31T21:22:48Z,nit: can you insert this method further down -- we want to order method overloads with regard to number of parameters -- it simplifies to keep track of what overloads are there.,0,0.9932492971420288
98777135,2466,mjsax,2017-01-31T21:38:44Z,check `source != null` not necessary. in doubt add an assertion.,0,0.9945619702339172
98777360,2466,mjsax,2017-01-31T21:39:46Z,this can be reverted.,0,0.9944069385528564
98777858,2466,mjsax,2017-01-31T21:41:49Z,"does this add anything -- i doubt it? (ie, using a second mock tsextractor)",0,0.9387935996055603
98779356,2466,jeyhunkarimov,2017-01-31T21:48:56Z,which does not make sense: using two separate tsextractors or this test case as a whole?,0,0.9846195578575134
98780572,2466,jeyhunkarimov,2017-01-31T21:54:56Z,once i removed it failed most of the tests of `streamthreadstatestoreprovidertest` class with nullpointerexception.,0,0.9918884634971619
98781354,2466,mjsax,2017-01-31T21:58:42Z,the test is fine -- but what's the value in testing overwrite the default extractor two times.,0,0.9915890097618103
98782371,2466,jeyhunkarimov,2017-01-31T22:03:37Z,i see. so i will remove `mocktimestampextractor2` class and correct the test accordingly.,0,0.9929888844490051
98847610,2466,dguy,2017-02-01T08:44:58Z,guaranteed -> guarantees,0,0.9746322631835938
98847825,2466,dguy,2017-02-01T08:46:39Z,"same as above. i guess this is largely copy & pasted from other javadoc, so the issue is most likely elsewhere",0,0.9861292243003845
98849518,2466,dguy,2017-02-01T08:58:47Z,"topics -> topic. this may well be elsewhere in the java-doc, too",0,0.9902106523513794
98850120,2466,dguy,2017-02-01T09:02:55Z,"i know you've only added the one param here, but seeing as you are changing it can you make all the params `final`?",0,0.9933326840400696
98850172,2466,dguy,2017-02-01T09:03:19Z,make all params `final`,0,0.9949113726615906
98850208,2466,dguy,2017-02-01T09:03:31Z,as above,0,0.9888283014297485
98850243,2466,dguy,2017-02-01T09:03:48Z,as above,0,0.9888283014297485
98850272,2466,dguy,2017-02-01T09:04:01Z,as above,0,0.9888283014297485
98850377,2466,dguy,2017-02-01T09:04:40Z,"here also, would be great if you could make the params `final`",0,0.9858163595199585
98850934,2466,dguy,2017-02-01T09:08:22Z,and again with `final` if you don't mind,0,0.9912312626838684
98851089,2466,dguy,2017-02-01T09:09:29Z,`final` ? all of the fields should be `final` really,0,0.9868170619010925
98851203,2466,dguy,2017-02-01T09:10:13Z,this method can be package-private,0,0.9959249496459961
98851316,2466,dguy,2017-02-01T09:10:54Z,"we should make this `final`, too",0,0.9927918910980225
98853125,2466,dguy,2017-02-01T09:22:44Z,+1 to what said. the `source` should never be null. so you should change the `streamthreadstatestoreprovidertest`. it just needs to have the topic name extracted to a field on line 73. and then that same topic name used on line 189 in `new topicpartition(...)`,0,0.9695755839347839
98853314,2466,dguy,2017-02-01T09:23:49Z,i'd also consider extracting: `source.gettimestampextractor() != null ? ...` into a local as the line is quite long and it will make the code a bit easier to read.,0,0.9909268617630005
98853584,2466,dguy,2017-02-01T09:25:26Z,maybe `shouldaddtimestampextractorpersource` ?,0,0.9933433532714844
98853717,2466,dguy,2017-02-01T09:26:13Z,make all locals `final`,0,0.9950892329216003
99165540,2466,dguy,2017-02-02T16:51:07Z,"i'd probably extract lines 121 -> 130 into a method, i.e, `findsourcenode(...)` also, we -> if",0,0.9935223460197449
99165983,2466,dguy,2017-02-02T16:52:46Z,there is no need to test this as it is calling the same method as above.,0,0.9939680099487305
99167116,2466,dguy,2017-02-02T16:57:08Z,i'm not sure what this test has to do with `streamtask`? to me this test should be in `topologybuildertest`. you don't need a `streamtask` in this case to check that the `timestampextractor` was assigned to the source,0,0.948883593082428
99200243,2466,mjsax,2017-02-02T19:30:02Z,"i just realized, that we use different wording for topics as array of strings and topic pattern: ""there is no ordering guarantee"" vs ""there are no ordering guarantees"" -- i think we should clean this up for consistency. would you mind to add this fix to this pr? the singular version sounds better, imho.",0,0.8660008311271667
99200386,2466,mjsax,2017-02-02T19:30:57Z,sorry -- mixed it up with `table`.,-1,0.9926183819770813
99201790,2466,jeyhunkarimov,2017-02-02T19:37:55Z,"i found `streamtasktest` the best suitable place, as it was suggested to make `sourcenode.gettimestampextractor()` method available within package. so, it is not accessible inside `topologybuildertest` currently. then i am making `sourcenode.gettimestampextractor()` public and moving the tests to `topologybuildertest`.",0,0.9822525978088379
99202642,2466,mjsax,2017-02-02T19:41:54Z,key -> topic,0,0.9883734583854675
99203389,2466,mjsax,2017-02-02T19:45:19Z,"i am still confused, about `source` being `null`. in the original code (l121) `source` is handed to `createrecrodqueue` and must not be `null` -- because this was never an issues before, i am still puzzled. why it is now.",-1,0.8948212265968323
99204674,2466,mjsax,2017-02-02T19:51:20Z,"i agree with if you test `topologybuilder#addsource()` it should go to `topologybuildertest`, and if you test `kstreambuilder#stream` it should go to `kstreambuildertest` -- this also implies, you should split this test into two. also testing `kstreambuilder#addsource` is redundant because its inherited from `topologybuilder`.",0,0.98549485206604
99206508,2466,jeyhunkarimov,2017-02-02T19:59:00Z,"when we add the sources by pattern (`kstreambuilder.stream(final pattern topicpattern)`), the source name is given like `""pattern ["" + regex + ""]""`. for example, for `t.*` pattern it would be `""pattern[t.*]""`. in `streamtask`, we search for sources (in 121) by topic name. for example, for topic name`""topic1""`, it gives `null`,because the source name is `""pattern[t.*]""`.",0,0.9877985119819641
99446130,2466,mjsax,2017-02-03T23:55:23Z,"revert this for `.stream(...)`, because it can be multiple here. original comment only applies to `.table()` has has always a single input topic.",0,0.9943256974220276
99499027,2466,mjsax,2017-02-05T20:38:46Z,"can you address this comment, too?",0,0.9942479133605957
99499541,2466,mjsax,2017-02-05T20:58:02Z,can you please add `final` wherever possible.,0,0.9953159093856812
99499677,2466,mjsax,2017-02-05T21:02:29Z,why do you not reuse `kstreambuildertest#builder` ?,0,0.9936679005622864
99499696,2466,mjsax,2017-02-05T21:03:00Z,"it's better to split this test into multiple -- here you test if no source specific extractor is set, thus, this should be a test method `sourceextractorshouldbenull` (or similar) and the test should end here. apply to below tests, too. (split into positive/negative tests and own tests for stream/table -- for stream/table add overload methods same way to test `topologbuilder.addsource()`",0,0.9934296011924744
99500035,2466,mjsax,2017-02-05T21:16:02Z,add `final` wherever possible,0,0.9951803684234619
99500140,2466,mjsax,2017-02-05T21:19:41Z,why this change?,0,0.9828922748565674
99500765,2466,mjsax,2017-02-05T21:39:07Z,why not use `topology.sourcetopicpattern()` ? and than check if `partition.topic()` matches the pattern?,0,0.9933140873908997
99500810,2466,mjsax,2017-02-05T21:40:36Z,why this change?,0,0.9828922748565674
99500845,2466,mjsax,2017-02-05T21:42:09Z,apply `final` wherever possible (also within method),0,0.9953272342681885
100309277,2466,jeyhunkarimov,2017-02-09T13:51:52Z,"i think `sourcetopicpattern()` is a method of `topologybuilder`. in `streamtask` on the other hand, we get `processortopology` instance.",0,0.9876794219017029
100309989,2466,jeyhunkarimov,2017-02-09T13:55:31Z,"if we need to find the `topic` of the given source (`streamtask.findsource()`) by pattern, either we have to remove `""pattern [ ]""` part from source name and try all matches, or we can remove it (`""pattern [ ]""` part) when we assign the name for `sourcenode` and directly use its name as `pattern`. i thought the second case would be more usable.",0,0.9893552660942078
100310215,2466,jeyhunkarimov,2017-02-09T13:56:37Z,"because the test classes (`topologybuildertest` for example) cannot access the protected method , i leave it as it is",0,0.9931898713111877
100374990,2466,mjsax,2017-02-09T18:23:53Z,ack. by bad.,-1,0.9938719272613525
100493505,2466,dguy,2017-02-10T08:56:52Z,it would be nice if you made these `final` while you are doing this change.,0,0.9775992631912231
100493542,2466,dguy,2017-02-10T08:57:06Z,+1,0,0.9816582202911377
100493741,2466,dguy,2017-02-10T08:58:40Z,`return topology.source(topic);`,0,0.9930029511451721
100493758,2466,dguy,2017-02-10T08:58:50Z,`final`,0,0.9897204041481018
100493997,2466,dguy,2017-02-10T09:00:43Z,"using `assertthat` is nicer as it gives better failure messages. `assertthat(sourcenode.gettimestampextractor(), instanceof(mocktimestaampextractor))` in other places, too",0,0.9865173101425171
100494305,2466,dguy,2017-02-10T09:02:58Z,"typo: kstreamhould... -> kstreamshould in fact i'd probably rename these methods to begin with should, i.e., `shouldaddtimestampextractortostreamwithoffsetresetpersource` etc",0,0.9926038384437561
100494435,2466,dguy,2017-02-10T09:03:54Z,"as per previous `assertthat(..., instanceof(...))` would be better",0,0.9949814677238464
107829914,2466,mjsax,2017-03-24T03:39:21Z,please fix this: `use { } instead`,0,0.9953410625457764
107830212,2466,mjsax,2017-03-24T03:42:17Z,nit: add missing `.` at the end.,0,0.9937620759010315
107830238,2466,mjsax,2017-03-24T03:42:34Z,nit: missing `.`,0,0.9795658588409424
107830487,2466,mjsax,2017-03-24T03:46:55Z,nit: add `final` twice,0,0.9946176409721375
107830501,2466,mjsax,2017-03-24T03:47:08Z,nit: add `final`,0,0.9956295490264893
107830511,2466,mjsax,2017-03-24T03:47:21Z,nit: add `final`,0,0.9956295490264893
107830528,2466,mjsax,2017-03-24T03:47:36Z,add `final`,0,0.9953774213790894
107830534,2466,mjsax,2017-03-24T03:47:45Z,nit: add `final`,0,0.9956295490264893
113301565,2466,mjsax,2017-04-25T20:28:20Z,"just some nitpick: we started to to order all configs alphabetically here -- it make it a little simpler to keep an overview and to maintain the code. would you mind to not move configs that get deprecate and add the new config at the ""right"" place. thanks a lot. :)",1,0.9956642985343933
113312440,2466,mjsax,2017-04-25T21:09:13Z,"just some nitpick: we started to to order all configs alphabetically here -- it make it a little simpler to keep an overview and to maintain the code. would you mind to not move configs that get deprecate and add the new config at the ""right"" place. thanks a lot. :)",1,0.9956642985343933
113312517,2466,mjsax,2017-04-25T21:09:35Z,"for backward compatibility, we need to keep the old default value. btw: we don't do any ordering here yet -- just above. so no need to reorder anything here.",0,0.9894078969955444
113312570,2466,mjsax,2017-04-25T21:09:50Z,as above: need to keep default value.,0,0.9943400025367737
113312651,2466,mjsax,2017-04-25T21:10:11Z,you can simple call `serde = defaultkeyserde()` here.,0,0.9952493906021118
113312708,2466,mjsax,2017-04-25T21:10:27Z,"`.configure()` is called within `getconfiguredinstance()` already -- you can remove this line (i know this pattern was there before, but it's wrong -- can you please fit it :)) this can be a single liner within try-catch-block: `return getconfiguredinstance(default_key_serde_class_config, serde.class);`",1,0.9577953219413757
113312767,2466,mjsax,2017-04-25T21:10:44Z,as above,0,0.9888283014297485
113312830,2466,mjsax,2017-04-25T21:11:04Z,as above.,0,0.9881609678268433
113508449,2466,jeyhunkarimov,2017-04-26T17:02:32Z,"if we want to distinguish between `value_serde_class_config` and `default_value_serde_class_config` for example, in `public serde valueserde()` method, we have to differentiate whether ` serde serde = getconfiguredinstance(value_serde_class_config, serde.class); ` is default or not. if it is default, then we will call `defaultvalueserde()` method. if we don't set the default value to `null`, then its default value will be some object initialized with `serdes.bytearrayserde.class.getname()` class. in this case, it is hard to know whether the old `serde` (`value_serde_class_config`) is overridden (so we return it) or it has default value (so we call `defaultvalueserde() `method). moreover, because we are controlling the access to `value_serde_class_config` via `valueserde()` method, we handle `null` cases here as well. the same applies to `key_serde_class_config` and `timestamp_extractor_class_config` as well.",0,0.990117609500885
113564584,2466,mjsax,2017-04-26T21:16:04Z,ah. makes sense!,1,0.966735303401947
113564805,2466,mjsax,2017-04-26T21:17:08Z,it's actually pretty elegant! :),1,0.9966616630554199
113777778,2466,jeyhunkarimov,2017-04-27T19:06:41Z,"i think in `getconfiguredinstance() ` method, `configurable.configure(map configs)` method is called, but in `keyserde() `and `valueserde() `methods we need also to call `serde.configure(map configs, boolean iskey)` method. so i think the two `configure` methods are different.",0,0.9886162877082825
113808802,2466,mjsax,2017-04-27T21:37:30Z,`serde` implements `configurable` -- the object `o` in `((configurable) o).configure(originals());` is the serde object.,0,0.9946662187576294
113811258,2466,jeyhunkarimov,2017-04-27T21:50:46Z,"yes i want to say that `serde.configure(arg1, arg2)` is different from `configurable.configure(arg1)`. so, inside `getconfiguredinstance()` method it is not called `configure(arg1, arg2)` but `configure(arg1)`",0,0.993956446647644
113829911,2466,mjsax,2017-04-28T00:13:13Z,i did have a closer look into the code. you are right. i also double checked and `serde` does actually not implement `configurable` (so there will also not be two calls what would be bad). sorry for the confusion -- and thanks a lot for pointing out that it is correct as is!!,-1,0.9910805821418762
115824780,2466,guozhangwang,2017-05-10T18:59:48Z,with this change how would the caller differentiate between the case that of a single subscribed topic v.s. a subscribed pattern?,0,0.9942200183868408
115825542,2466,guozhangwang,2017-05-10T19:02:52Z,could we add a similar function in `streamsconfig` as `keyserde` in which we capture the deprecated / new default values there so that we do not need to leak that logic here?,0,0.9928187727928162
115826174,2466,guozhangwang,2017-05-10T19:05:50Z,"related to the question i have before: in the `tostring` function at line 85, we are printing `topics:string`, and we canno tell if it is a pattern or a single topic right?",0,0.988491415977478
115826873,2466,guozhangwang,2017-05-10T19:09:14Z,"why do we need to augment this function here? i.e. by the time the stream task is created, we should have populated the `sourcebytopics` map with the pattern matched topics already, so i'm not sure if the additional computational logic is needed? cc .",0,0.9914044141769409
115845233,2466,jeyhunkarimov,2017-05-10T20:33:16Z,"actually `""pattern[ ]""` string is just cosmetic part of the code snippet `""pattern["" + pattern + ""]""`. we don't use `""pattern""` string (anywhere in the code) for detecting if it is a single subscribed topic or subscribed pattern.",0,0.9893963932991028
115847989,2466,jeyhunkarimov,2017-05-10T20:45:21Z,you are right. the main reason that i put this extra function is that i was getting many fails in tests. there were some tests with no source nodes defined in the test topology or the defined source nodes are not related with partitions.,0,0.975135862827301
115850388,2466,guozhangwang,2017-05-10T20:55:16Z,"hmm, maybe it's better to fix these tests than modifying the production-code? e.g. we can add some test-only function to fill the topics from the pattern in `` rule.",0,0.9788910746574402
115850952,2466,jeyhunkarimov,2017-05-10T20:57:43Z,i fixed the tests as well and added this code snippet too. i mentioned this in [a link],0,0.9957178235054016
115852641,2466,jeyhunkarimov,2017-05-10T21:05:15Z,"yes, once the source is defined and added to topology, we cannot tell if it is defined by name or by pattern. this was the case before this pr as well.",0,0.9924396276473999
115853285,2466,jeyhunkarimov,2017-05-10T21:08:34Z,but i got your point,0,0.9807660579681396
115907018,2466,guozhangwang,2017-05-11T05:24:18Z,"thanks for the explanation, makes sense.",1,0.9005445837974548
115907121,2466,guozhangwang,2017-05-11T05:25:37Z,yeah i think if the logic is not needed in real cases then we should not add that since it may hide some potential bugs. as long as the tests can be covered then we can get rid of the unnecessary logic.,0,0.9763251543045044
115925128,2466,jeyhunkarimov,2017-05-11T07:53:51Z,"i recognized this issue: `builder.stream(pattern.compile(""t.*""))`; // this line adds sourcenode with name ""t*"", (before this pr it was `""pattern[t*]""`) after that, in `streamtask:120` when one executes: `final sourcenode source = topology.source(partition.topic());` // where `partition.topic()` is ""t1"" here the `source` will be `null` because `topology.source()` is just key value lookup. so i moved extra extra lookup for patterns from `streamtask` to` topology.source()`",0,0.9916925430297852
116282834,2466,guozhangwang,2017-05-12T17:27:51Z,"hmm, in `topologybuilder#build` when we are adding the source node we will execute the pattern matching from the current topic metadata so the map should already be filled with the actual topic right? i think the problem, as i added in `sourcenodefactory#gettopics`'s comment, is that under debugging / unit testing environment, there is no topic metadata available to pass the topic list to `list gettopics(collection subscribedtopics)`. what we need to do to fix the unit tests then is to call `subscriptionupdates#updatetopics()` before calling `builder.build()` for regex involved tests. [code block]",0,0.9729808568954468
116317477,2466,bbejeck,2017-05-12T20:26:15Z,sorry for jumping in a little late. is correct about the test. an example for unit-testing with regex defined topics using the `topologybuilder` is `topologybuildertest#shouldsetcorrectsourcenodeswithregexupdatedtopics` (line 675),-1,0.9853615164756775
116348919,2466,jeyhunkarimov,2017-05-13T02:50:11Z,thanks for your comments. done.,1,0.8630430698394775
281873083,6694,ableegoldman,2019-05-08T00:04:47Z,nit: use recordqueue.unknown instead of -1,0,0.9893953204154968
281885338,6694,ConcurrencyPractitioner,2019-05-08T01:27:58Z,"no problem, could fix that.",0,0.8428521156311035
282344028,6694,ableegoldman,2019-05-09T05:38:23Z,"can we add separate unit tests to confirm this produces the expected behavior? i think the jira had some examples highlighting why this is a problem, it would be good to convert those into tests to make sure we're really fixing the problem at hand :)",0,0.8403968811035156
282726631,6694,ConcurrencyPractitioner,2019-05-10T02:16:04Z,no problem. added a new test case to confirm behavior.,0,0.8066927790641785
289592039,6694,mjsax,2019-06-01T04:34:51Z,"can we add those method to the end of the class -- we have already a ""section"" for methods that we only need for testing.",0,0.9943577647209167
289592091,6694,mjsax,2019-06-01T04:37:43Z,"to be future prove, we should encode a version number as prefix in case we ever what to change this metadata. what about ` : ` with version number ""1"" ? also, line is too long. move both parameters to their own lines.",0,0.9939151406288147
289592181,6694,mjsax,2019-06-01T04:41:15Z,"i am not an expert on this api, but i would expect that even if we commit using the producer, the consumer should still be able to read the metadata. did you verify that we cannot retrieve the metadata if eos is enabled? if this is the case, i would claim it's a bug that need to be fix.",0,0.9668142199516296
289592249,6694,mjsax,2019-06-01T04:44:17Z,"we call `addrecords` during regular processing but only need to restore the partition time if a rebalance happened. hence, i don't think this is the right place to add this code. from my understanding, we should do this in `streamthread#rebalancelistener.onpartitionsassigned` instead? \cc to confirm/comment",0,0.9892402291297913
289592273,6694,mjsax,2019-06-01T04:45:41Z,we should not piggy-back test for new features to existing tests. it's better to add a new test method `shouldaddpartitiontimetooffsetmetatdataoncommit`,0,0.9944273233413696
289592283,6694,mjsax,2019-06-01T04:46:20Z,"nit: `shouldrestorepartitiontimeonrestart` -- ""update timestamp"" is a little fuzzy",0,0.9817323088645935
289609768,6694,ConcurrencyPractitioner,2019-06-01T15:48:41Z,"alright, i will check on that.",0,0.9906468391418457
289613688,6694,ConcurrencyPractitioner,2019-06-01T17:51:50Z,just realized the test i added included the test for commit mechanism anyways.,0,0.9850645661354065
289613963,6694,ConcurrencyPractitioner,2019-06-01T18:03:07Z,"ok, so after some checks, i have discovered the following: the producer and consumer are not assigned to the same topicpartition (however, that is not necessarily the reason for the failure i'm about to describe.) i'm not 100% sure if this was supposed to happen. when producer committed the transaction, that is supposed to mean the consumer group coordinator was notified to commit the offsets right? however, when the consumer available to streamtask is called (i.e. [code block]), null is returned (indicating no offsets were committed). producer's sendoffsetstotransaction requires the user to also enter a consumer group id (which is specified by user config) which we send the offsets to commit to. it is possible that unless the user specifies the right consumer group id, we would not be able to retrieve associated metadata.",0,0.9541826248168945
289677945,6694,ConcurrencyPractitioner,2019-06-03T03:17:38Z,"oh, thats a good suggestion. would need to change test location in that case.",1,0.8874205350875854
299187366,6694,abbccdda,2019-07-01T19:36:08Z,should we check for partition existence for 2 calls?,0,0.9931574463844299
299187593,6694,abbccdda,2019-07-01T19:36:56Z,better to append suffix for time variables like `timestampms`,0,0.9936386942863464
301350910,6694,mjsax,2019-07-09T00:14:07Z,"what do you mean by ""for 2 calls""? the call to `partitiontime()`? if the partition does not exists, it's a bug anyway and current code throws a npe. what do we gain by checking if the partition exists? there is still a bug and we would need to throw an exception, too, imho. what do we gain by manually throwing an exception?",0,0.9210653305053711
301351239,6694,mjsax,2019-07-09T00:15:46Z,"it's not a duration, hence, i am not sure if adding `ms` suffix helps much here? `timestamp` is always unix epoch in ms throughout the whole code base and we never add `ms` so far. thoughts?",0,0.9362374544143677
301351580,6694,mjsax,2019-07-09T00:17:51Z,might be better to use `recordqueue.unknown` instead of `no_timestamp` (cf. `clear()` below),0,0.9910181760787964
301351875,6694,mjsax,2019-07-09T00:19:26Z,wdyt about this?,0,0.9858492612838745
301354251,6694,mjsax,2019-07-09T00:32:55Z,"i sync with guozhang about this. it's not correct to get the committed offsets within `onpartitionsassigned()` callback, because the consumer might not have fetched/updated the offsets from the brokers. however, we should still move the off the main loop. we only need to initialize the partition time if we get a new task assigned. hence, we should move it into `assignedtasks#initializenewtasks()`?",0,0.984419047832489
301355250,6694,mjsax,2019-07-09T00:38:34Z,"not sure what you mean by this? a producer is never _assigned_ any partitions. we use the term _assigned_ for consumers only. can you clarify? absolutely. the `group.id` used to commit offsets via the producer must match the `group.id` used by the consumer to read those offsets. in kafka streams the `application.id` is used as `group.id` for the consumer and it's also passed into `producer.sendoffsetstotransaction()`. hence, i still think that we don't need to handle eos differently to get the partition-time. does this help?",0,0.9529379606246948
301355349,6694,mjsax,2019-07-09T00:39:05Z,nit: revert,0,0.787084698677063
301668666,6694,ConcurrencyPractitioner,2019-07-09T16:02:31Z,"sure, no problem with that.",0,0.907990574836731
301685923,6694,ConcurrencyPractitioner,2019-07-09T16:41:21Z,"ah, forgot that producer isn't assigned partitions. let me see what i can do to handle to the eos case then.",0,0.9680613875389099
309349352,6694,mjsax,2019-07-31T17:45:04Z,"this code would crash if the cast fails. to avoid the issue, we should add `setassignmenttostoredtimestamps` to `task` interface (and remove the cast here) and add an empty implementation of the method to `standbytask`. i would also rename the method to `initializetasktime()`",0,0.9823964834213257
309349964,6694,mjsax,2019-07-31T17:46:30Z,we don't need to add this any longer. we added `public long streamtime()` in another pr already.,0,0.9935053586959839
309351486,6694,mjsax,2019-07-31T17:49:54Z,"i think we should throw an exception for this case, because the added partitions of the queue are fixed and should never change (and we should never request the partition time for unknown partitions -- it we do this, it would indicate a bug and would should raise it as an exception). [code block]",0,0.9878407120704651
309351989,6694,mjsax,2019-07-31T17:50:59Z,"nit: can we rename this to `partitiontime` (to align the name to `streamtime()` method) -- in kafka, we usually omit the `get` prefix on getter methods, and a record has a ""timestamp"" while for a partition or task it's a ""time"" (of course, both a ""timestamp"" and a ""time"" is just a long and quite similar, whoever, it seems more accurate to refer to their semantic meaning correctly).",0,0.9880583882331848
309352168,6694,mjsax,2019-07-31T17:51:22Z,nit: rename to `setpartitiontime()` (cf. other comment from above) also rename parameter `timestamp -> partitiontime`.,0,0.995157778263092
309352994,6694,mjsax,2019-07-31T17:53:16Z,"similar as above, we should throw an exception here.",0,0.9885507225990295
309354307,6694,mjsax,2019-07-31T17:56:06Z,nit: rename `timestamp -> partitiontime`,0,0.995383083820343
309354740,6694,mjsax,2019-07-31T17:57:06Z,"why do we need to make `partitiontime` `public` ? in any case, please preserve the javadocs if you move the method.",0,0.9932131767272949
309355477,6694,mjsax,2019-07-31T17:58:36Z,"we merge another pr recently that updates `partitiontime` already (cf. below) -- hence, no need to add this any longer.",0,0.9950917959213257
309359552,6694,mjsax,2019-07-31T18:07:51Z,i don't understand the purpose of this method. why not just get the `partitiontime` of the task and commit it?,0,0.5790504813194275
309360061,6694,mjsax,2019-07-31T18:09:05Z,do you think it's worth to add a version number for the binary format of the committed offsets (i tend to think we should add a version number). i would also not encode the timestamps as `string` but as 8-byte binary long.,0,0.9932305812835693
309362468,6694,mjsax,2019-07-31T18:14:41Z,so we need to log this at info level? seems error might be more appropriate because it actually indicates corrupted metadata? we should also update the error message accordingly: [code block],0,0.9932843446731567
309363884,6694,mjsax,2019-07-31T18:17:51Z,why is the return type not `void` (similar for `setassignmenttostoredtimestamps` below)? seem you added it for testing? i would prefer to keep it `void` and change the tests if possible.,0,0.992113471031189
309364369,6694,mjsax,2019-07-31T18:18:53Z,nit: remove `get` prefix (similar below for `getpartitiontime()`,0,0.9948662519454956
309364980,6694,mjsax,2019-07-31T18:20:05Z,"instead of using 3 broker for this test, we should reconfigure the brokers to allow using eos with a single broker. to do this, we need to set `transaction.state.log.replication.factor=1` in the passed-in broker config (maybe something else... not 100% sure).",0,0.9878227710723877
309366581,6694,mjsax,2019-07-31T18:23:34Z,nit: simplify to `throws exception`,0,0.9936164617538452
309366881,6694,mjsax,2019-07-31T18:24:11Z,this seems to be rather complicate. just hard code the `appid` ?,0,0.9625170826911926
309367084,6694,mjsax,2019-07-31T18:24:29Z,why do we need a store for this test? i think a simple `builder.stream().to()` should be sufficient?,0,0.9915353059768677
309367958,6694,mjsax,2019-07-31T18:26:20Z,"not sure what your comment means. can you elaborate? (i think it makes sense to test with multiple partitions, but i am not sure if i understand the comment -- how id the default key partitioner related?)",0,0.7036194801330566
309368689,6694,mjsax,2019-07-31T18:27:42Z,"nit: rename `driver -> kafkastreams` (we always name it `kafkastreams` in test, and it would be good to keep the name for consistency)",0,0.99457848072052
309369523,6694,mjsax,2019-07-31T18:29:34Z,"we don't need to sleep (in general, sleeping is bad practice because it makes test flaky), because when `close()` is called below, it is ensured that offsets are committed.",0,0.9746266603469849
309371664,6694,mjsax,2019-07-31T18:34:30Z,"why do we need this validation step? the partition time or stream time is not exposed in the `context` and thus, i don't understand what this step verifies? why do we need to check the topic name?",0,0.9876877665519714
309371951,6694,mjsax,2019-07-31T18:35:09Z,nit: rename `maxtimestamp -> partitiontime`,0,0.9954310655593872
309372240,6694,mjsax,2019-07-31T18:35:52Z,why do we need to write two records?,0,0.9843877553939819
309373077,6694,mjsax,2019-07-31T18:37:56Z,this variable is accessed by multiple threads that thus should be declared `volatile`,0,0.9948949217796326
309373488,6694,mjsax,2019-07-31T18:38:57Z,unnecessary comment,0,0.83234041929245
309373698,6694,mjsax,2019-07-31T18:39:30Z,no need to call `cleanup()` if we remove the state.,0,0.9903799295425415
309375797,6694,mjsax,2019-07-31T18:44:23Z,"we should not care about `record.timestamp()` imho, but instead use a second variable similar to `lastrecordedtimestamp`: something like `map expectedpartitiontimeperpartition`. this allows us to set an expected partition time per partition and compare it to the passed in `partitiontime` (what you now call `maxtimestamp`) if passed in partition time does not match expected partition time, we can just throw an `runtimeexception` what will kill kafkastreams and the test will eventually time out.",0,0.9885103106498718
309375948,6694,mjsax,2019-07-31T18:44:44Z,seem not to be required?,0,0.9929954409599304
309457372,6694,ConcurrencyPractitioner,2019-07-31T22:25:10Z,"ah, this was something i added after i discovered a bug during integration tests. what happened was that offsets are periodically right (that is, it is automated)? so imagine this, the partitiontime has advanced to 10 milliseconds. we commit that time, and then streams experienced some sort of failure (akin to a restart of streams). that would mean the locally stored partitiontime was reset to -1. let's say we start processing again, and the partition time is now 9. what happens is that 9 is the timestamp committed, not 10. it overwrites the previous committed timestamp. so what we need to do is retrieve the previously committed timestamp if there was any, and then commit _that_ one instead, since that is the correct one. i had some second thoughts on this, particularly since it becomes a little difficult to distinguish between restarts, cleanups, or failures which could have the same effect. so i'm not so sure if this is still needed or we still need to modify the behavior for these cases. the thing is without this method, the test that i have added at any rate fails.",0,0.9539836049079895
309457844,6694,ConcurrencyPractitioner,2019-07-31T22:27:03Z,"yeah, forgot to remove it during previous debugging.",0,0.8215442895889282
309459876,6694,ConcurrencyPractitioner,2019-07-31T22:34:50Z,"oh, the thing is this logic is neccessary, or otherwise the test will crash. if you were to look closely at [code block] logic, the class updates the partitiontime _after_ timestampextractor was called. this is important, because partitiontime is always passed in first. that means that [code block] is always passed in first when we first start processing, and if we always return maxtimestamp without checking if record.timestamp() is greater, than that means -1 will be returned no matter how many records are passed through timestampextractor. thus, what we do here is stimulate an update to partitiontime _before_ it is actually updated in [code block].",0,0.9565445780754089
309466633,6694,ConcurrencyPractitioner,2019-07-31T23:03:31Z,"alright, will do.",0,0.957654595375061
309469061,6694,ConcurrencyPractitioner,2019-07-31T23:14:47Z,"actually, on further investigation, this method might not be needed. we will see.",0,0.9870566129684448
309478195,6694,mjsax,2019-08-01T00:01:01Z,"yes. yes, but you code return `return record.timestamp();` anyway. so for the second call of `extract()` method, `partitiontime` (ie, `maxtimestamp`) gets advanced. for a stop-restart of `kafakstreams`, with this fix on restart `partitiontime` should be `unknown` any longer, as it's should be initialized from the commit-metadata that is preserved. hence, we should see `unknown` only a single time, and the integration test should verify that we only see on the first start of `kafakstreams` but not for the second start. i cannot follow here. `partitiontime` is tracked internally and it will be updated after timestampextractor returns, base on the value that is provided in `return`.",0,0.984175980091095
309749298,6694,ConcurrencyPractitioner,2019-08-01T15:07:52Z,"ah, but if we do throw a nullpointer here, the test i added fails. so i don't know if that is what we really should do.",0,0.9261038303375244
309776403,6694,ConcurrencyPractitioner,2019-08-01T16:01:29Z,"yeah, accidentally removed it when i was rebasing the pr. will add it back.",0,0.9626677632331848
309795005,6694,ConcurrencyPractitioner,2019-08-01T16:45:43Z,"ah, okay. then i will change that.",0,0.9497941732406616
309917436,6694,mjsax,2019-08-01T22:12:31Z,not sure -- but maybe you setup the test incorrectly? `partitiongroup` constructor get a `map partitionqueues` and you should only call `setpartitiontimestamp()` for `topicpartitions` that are provided by this map. could this explain the test issue?,0,0.9735012650489807
309918847,6694,ConcurrencyPractitioner,2019-08-01T22:17:53Z,"oh, that might be the case. i was going through the consumer assignment's topic partitions instead. will check it out.",0,0.9846518039703369
309933316,6694,ConcurrencyPractitioner,2019-08-01T23:23:00Z,"well, i put the sleep there because otherwise the test (eos enabled case) breaks. i have done quite a bit of digging, and it appears what happens is that the committed metadata retrieved is incorrect after the streams restart. i added some debug statements, and the strange thing is though is that committed() doesn't return the right metadata. i made two calls to committed() -- this is during initializetasktime() -- and the first call returns the incorrect metadata (the result suggests that no offsetandmetadata was committed), yet on the second call, it returns the correct metadata (perhaps because this time offsetandmetadata has been persisted and could now be returned by committed()). the sleep() method i put there because it seems that offsetandmetadata needs enough time to actually persist in kafka log in eosenabled=true case, otherwise, consumer#committed() returns inconsistent results.",0,0.9626471400260925
309968392,6694,ConcurrencyPractitioner,2019-08-02T03:13:55Z,"oh, i could remove them. done that.",0,0.9890716075897217
310275056,6694,abbccdda,2019-08-02T19:50:28Z,nit: space before `no-op`,0,0.9890607595443726
310275504,6694,abbccdda,2019-08-02T19:52:04Z,is old metadata missing expected after we start off? might be useful to add a debug log or trace if this is not normal.,0,0.9924291968345642
310275800,6694,abbccdda,2019-08-02T19:53:05Z,would be favorable to order comparison result according to first citizen. like `metadatatimestamp >= localpartitiontime ? metadatatimestamp : localpartitiontime;`,0,0.9889485836029053
310275999,6694,abbccdda,2019-08-02T19:53:45Z,maybe refactor out a helper for the above condition?,0,0.9887592792510986
310276422,6694,abbccdda,2019-08-02T19:55:06Z,why `-1`?could we define a constant referring to it?,0,0.9904172420501709
310276582,6694,abbccdda,2019-08-02T19:55:38Z,this comment is not needed.,0,0.9924317598342896
310276679,6694,abbccdda,2019-08-02T19:56:00Z,s/time stamp/timestamp,0,0.9927341938018799
310276764,6694,abbccdda,2019-08-02T19:56:17Z,would be good to define `1000` as a variable.,0,0.9924132227897644
310276812,6694,abbccdda,2019-08-02T19:56:26Z,same here,0,0.99204421043396
310319615,6694,mjsax,2019-08-02T22:50:32Z,we can remove this method -- it's declared in the interface and there is no need to have an implementation in `abstracttask`,0,0.9942542910575867
310320109,6694,mjsax,2019-08-02T22:53:28Z,can `setpartitiontime()` be package-private?,0,0.9953380823135376
310320883,6694,mjsax,2019-08-02T22:58:18Z,still not sure why we need this method? (or did you forget to remove it?),0,0.9175114631652832
310321420,6694,mjsax,2019-08-02T23:02:07Z,why do we call `initializetasktime` in `addrecordstotasks()` -- in a previous version it was called in `initializenewtasks()` what seems to be more appropriate -- why did you move it?,0,0.9929632544517517
310321680,6694,mjsax,2019-08-02T23:03:47Z,"nit: `shouldpreservepartitiontimeonkafkastreamrestart` (nothing is reset in this test). (also, avoid naming overlap with `kstream` and `ktable`)",0,0.9950377345085144
310321935,6694,mjsax,2019-08-02T23:05:34Z,why do we need to suffix the appid and topic names with the `testid` ?,0,0.9925133585929871
310322139,6694,ConcurrencyPractitioner,2019-08-02T23:06:58Z,"well, since before, we never stored any metadata in kafka log, especially relating to committed timestamps. there is a possibility that an old version of offsetandmetadata is committed where it doesn't contain the committed timestamp, so i suppose this is expected behavior.",0,0.9922587275505066
310322225,6694,ConcurrencyPractitioner,2019-08-02T23:07:37Z,"well, the order in general doesn't seem to matter that much. but could change it.",0,0.9557806849479675
310322293,6694,ConcurrencyPractitioner,2019-08-02T23:08:04Z,"yeah, it looks like it appeared several times in the code, might want to add it as some separate static helper method.",0,0.9849929809570312
310322589,6694,mjsax,2019-08-02T23:10:17Z,"that is weird. \cc how could the happen? if we stop the first instance, the transactions should be committed and afterwards, if we start a new instance, the new consumer client should be able to read the correct offset and metadata. any idea?",-1,0.9928608536720276
310323805,6694,ConcurrencyPractitioner,2019-08-02T23:19:48Z,"oh, tried to run a test without this method, but abstracttasktest would break unfortunately if this method is not implemented in abstracttask (apparently, abstracttask's constructor is called, and compiler complains about it as a result).",0,0.7144579291343689
310324030,6694,ConcurrencyPractitioner,2019-08-02T23:21:31Z,"oh, actually, yeah, we can remove this method. we could just modify the abstracttasktest itself.",0,0.9903250932693481
310324216,6694,ConcurrencyPractitioner,2019-08-02T23:22:56Z,"sure, there shouldn't be any problems.",0,0.972162127494812
310324305,6694,ConcurrencyPractitioner,2019-08-02T23:23:33Z,"ok, no problem.",0,0.9008136987686157
310324616,6694,ConcurrencyPractitioner,2019-08-02T23:26:15Z,just thought it would be a good idea to include more information in the the id names. they can be hardcoded.,0,0.9334692358970642
310324663,6694,ConcurrencyPractitioner,2019-08-02T23:26:36Z,done.,0,0.9897913336753845
310327228,6694,ConcurrencyPractitioner,2019-08-02T23:51:20Z,"ok, i realized what is happening. during the process to close a streamtask, the partitiontimes are reset to -1 first before the local partition times are committed. effectively, what is occurring is that we are committing -1 during close() due to the order of operations we are performing it. i have found a solution to it, so i will push a change shortly.",0,0.8722642660140991
310327593,6694,mjsax,2019-08-02T23:55:17Z,good find!,1,0.9936373233795166
310704615,6694,ConcurrencyPractitioner,2019-08-05T17:10:51Z,"how would you do that though? i don't think offsetandmetadata could store an 8-byte binary long directly, so we have to use encode and decode the byte array as some string. is that how we should do it?",0,0.9903139472007751
310707714,6694,ConcurrencyPractitioner,2019-08-05T17:19:15Z,i was thinking about using utf8 conversions.,0,0.9868436455726624
310722093,6694,mjsax,2019-08-05T17:56:43Z,"good pointed. i missed that the type is `string` (expected it to be `byte[]`). hence, for efficient encoding, and to allow us to add a magic/version byte, we should first serialize the timestamp, prefix it with a magic byte and then ""deserialize"" it to `string`. [code block]",1,0.8876953125
310764557,6694,ConcurrencyPractitioner,2019-08-05T19:50:43Z,"okay. i pushed a version of what i thought was pretty close to the process you were describing. mind taking a look? at the moment, it doesn't seem to work though. i did some research and what we are using is basically utf8 encodings. it did look like however that some information was lost. (i did some debug statements and found that the decoded value was 1007 instead of 1000, somewhat bizarre).",0,0.5872546434402466
310803256,6694,ConcurrencyPractitioner,2019-08-05T21:39:26Z,"alright, i have done thorough investigations and here is what i found. i came across the following on stack overflow: [a link] if one looks closely, they would quickly realize that utf8 is not fit for the task at hand. in reality, we would need to do something like using base64 encodings instead (which is supposedly part of java since version 1.8). however, gradle does not allow the usage of base64 since it ""could not be found"" according to the compiler anyways. in conclusion, i don't think the current approach as it is will work. if things don't progress any further, i'd suggest sticking with the original idea of just sticking the long unencrpyted directly into the string (plus a version number). your thoughts ?",0,0.9094889163970947
311705840,6694,mjsax,2019-08-07T18:42:09Z,`task` is of type `task` -- no need to cast :),1,0.7931095361709595
311707813,6694,mjsax,2019-08-07T18:46:49Z,"good find! how did you try to use it? everything from the standard library should be available... i would prefer to use base64 if we can. if not possible, we can still fall back to using string, but i would really like to avoid it if we can.",1,0.9957796335220337
311713153,6694,mjsax,2019-08-07T18:59:17Z,nit: avoid changes in unrelated files,0,0.9633463621139526
311714343,6694,mjsax,2019-08-07T19:02:03Z,why not do this unconditionally? if it's not `clear` we won't commit anyway. it's seems cleaner to avoid to many branches and it's not on the hot code path so the overhead of updating `partitiontime` is not relevant.,0,0.9861915111541748
311714674,6694,mjsax,2019-08-07T19:02:49Z,i am not sure why we need this variable? can you elaborate?,0,0.8576555252075195
311817120,6694,ConcurrencyPractitioner,2019-08-08T00:45:54Z,"alright, that's fine.",0,0.9777958989143372
311817419,6694,ConcurrencyPractitioner,2019-08-08T00:47:53Z,"oh, because we need to differentiate between a commit that is triggered by a regular process or by a close. if we call partitiontime() in a commit triggered by a close() call, then partitiontime() would always return -1. (recall that due to the order of operations in close, the partition times has been reset to -1 first before the commit call was made).",0,0.9916101098060608
311819651,6694,ConcurrencyPractitioner,2019-08-08T01:01:37Z,"ah okay, so this is the error that i've found. [code block] notice that the package name does not start with java. it might be some third party library that gradle does not account for.",0,0.9626986980438232
311819717,6694,ConcurrencyPractitioner,2019-08-08T01:02:01Z,this might help explain why base64 might not be used.,0,0.9889179468154907
311820182,6694,ConcurrencyPractitioner,2019-08-08T01:05:13Z,yeah. my bad. didn't realize t extends task.,-1,0.9938861727714539
311849604,6694,mjsax,2019-08-08T04:14:21Z,seem you include the wrong class/package: [a link],0,0.9341883659362793
311850528,6694,mjsax,2019-08-08T04:20:46Z,is the any advantage of this library compare to [a link] \cc,0,0.9943031072616577
311851742,6694,mjsax,2019-08-08T04:30:36Z,"thanks. understood. it might be better, to actually change `stream#commit(boolean startnewtransaction)` to accept a second parameter `map partitiontimes` to pass in the information. in `close()` before we actually ""loose"" the timestamps we preserve them and pass into `commit()` later. in a regular `commit()` we get the timestamps from the `partitiongroup` (ie, some code that is now in `commit(boolean)` would go into `commit()`). this would avoid the requirement to introduce the flag and make the code more readable, because decision are more local an encapsulated in each method without cross-method dependencies.",1,0.9670274257659912
311852052,6694,mjsax,2019-08-08T04:32:39Z,we should return `recordqueue.unknown` instead.,0,0.9941825270652771
311852198,6694,mjsax,2019-08-08T04:33:39Z,"same as above: also, we should log a warn message there, that the the found metadata is corrupted and cannot be decoded.",0,0.9942142367362976
311859113,6694,ConcurrencyPractitioner,2019-08-08T05:20:50Z,"actually, just realized that this library existed. :p didn't know until later. will remove this dependency (the old bouncycastle one).",1,0.9927833080291748
311862190,6694,ijuma,2019-08-08T05:38:39Z,sounds good.,1,0.857205867767334
312137582,6694,ConcurrencyPractitioner,2019-08-08T16:48:16Z,"oh, sure, that would work.",0,0.9536749720573425
312165368,6694,mjsax,2019-08-08T17:51:53Z,"passing in `null` is not idea imho. at this point, we _know_ that we want to get the timestamps from the `partitiongroup`. hence, seems better to build up the correct `map< topicpartition, long>`, by looping over all committed offsets: [code block]",0,0.9872159361839294
312165647,6694,mjsax,2019-08-08T17:52:27Z,i think we don't need this method if we apply my other suggestions,0,0.9730640649795532
312166158,6694,mjsax,2019-08-08T17:53:38Z,"input parameter `partitiontimes` should always contain the correct partition time, hence, we can just get it: [code block]",0,0.9955328702926636
312166420,6694,mjsax,2019-08-08T17:54:11Z,nit: `partitiontimemap` -> `partitiontimes`,0,0.9934178590774536
312167539,6694,mjsax,2019-08-08T17:56:37Z,this block can be moved outside of the `try-catch-block`,0,0.9937840700149536
312167714,6694,mjsax,2019-08-08T17:56:57Z,i guess we can remove this comment,0,0.9878597855567932
312169542,6694,mjsax,2019-08-08T18:00:42Z,might be good to add an `else` and also add a debug log stating that no committed offset was found,0,0.9910503625869751
312170299,6694,mjsax,2019-08-08T18:02:20Z,this method is not only _receiving_ but also _setting_ the partition time. what about renaming it to `initializepartitiontime()`,0,0.993786096572876
312170692,6694,mjsax,2019-08-08T18:03:15Z,return type is `void` -- remove this line,0,0.9955497980117798
312171157,6694,mjsax,2019-08-08T18:04:15Z,nit: add comment `// visible for testing` (same for decodetimestamp() below) also add test methods to `streamtasktest` to test both methods.,0,0.9953603148460388
312171865,6694,mjsax,2019-08-08T18:05:40Z,"nit: (simplify to) `""unsupported offset metadata version found. supported version {}. found version {}.""`",0,0.994155764579773
312235875,6694,mjsax,2019-08-08T20:47:29Z,nit: could we use `getstartedstreams()` again?,0,0.9783977270126343
312237424,6694,mjsax,2019-08-08T20:51:27Z,"`assertthat(task.decodetimestamp(consumer.committed(partition1).metadata()), equalto(default_timestamp));` simplify `task.cosumer` -> `consumer`",0,0.9936102032661438
312238609,6694,mjsax,2019-08-08T20:54:22Z,nit: remove unnecessary comment,0,0.9380438327789307
312239083,6694,mjsax,2019-08-08T20:55:32Z,nit: remove unnecessary comment,0,0.9380438327789307
312239225,6694,mjsax,2019-08-08T20:55:50Z,nit: remove unnecessary comment,0,0.9380438327789307
312289819,6694,mjsax,2019-08-09T00:06:23Z,"this test setup defeats the purpose fo this test. if eos is enabled, the producer is used to commit offsets, and thus, we should check if the producer does commit the corresponding metadata correctly. therefore, we need to change the test setup a little bit. in `createstatelesstask()`, we create an anonymous `producersupplier` and we need to get hold off the generated mock-producer instance. we can then use `mockproducer#consumergroupoffsetshistory` to get the committed offsets and metadata.",0,0.9656661748886108
312289927,6694,mjsax,2019-08-09T00:07:06Z,as above (similar below),0,0.992952287197113
312309368,6694,ConcurrencyPractitioner,2019-08-09T02:23:56Z,done that.,0,0.9241076111793518
312581629,6694,mjsax,2019-08-09T17:38:06Z,not 100% sure if we nee this `null` check any longer after the refactoring. \cc wdyt?,0,0.9371846914291382
312588676,6694,mjsax,2019-08-09T17:57:06Z,"seems we should test `partitiontimestamp` above already, when we `verifybuffered(6, 3, 3);` ? also, we should check the returned time for both partitions each time? i would also add a test of `group.streamtime()` for each step in the test (not sure why it's missing -- this would be a good additional improvement).",0,0.9782575964927673
312588867,6694,mjsax,2019-08-09T17:57:43Z,we should test this method in it's own test method,0,0.993835985660553
312589597,6694,mjsax,2019-08-09T17:59:44Z,"use `assertthrows` instead of the try catch block, and use `assertthat` to verify the exception message. also, this should be two tests, one for ""set"" and one for ""get"".",0,0.9949910044670105
312590312,6694,mjsax,2019-08-09T18:01:52Z,"in addition, we should check if ""stream time"" was updated correctly. nit: `assertequals` take ""excepted value"" as first parameter, so you need to flip both (otherwise the error message would be confusing if the test fails)",0,0.9953649044036865
312592021,6694,mjsax,2019-08-09T18:07:04Z,please rewrite using `assertthat` (or at least `assertequals`) -- similar below,0,0.9954572916030884
312592448,6694,mjsax,2019-08-09T18:08:18Z,"we should add more test method for the different error cases, too.",0,0.9912609457969666
312593338,6694,mjsax,2019-08-09T18:10:52Z,"this whole block (l680-687) can be remove -- there is no need for the test to commit anything in addition. note that the `assert` above tests the previous `commitsync()` what is not useful, as test-code should not test other test-code :)",1,0.9578155279159546
312595808,6694,mjsax,2019-08-09T18:17:49Z,no need to use a nested for loops. this can be simplified to: [code block],0,0.9942939877510071
312634550,6694,ableegoldman,2019-08-09T20:18:36Z,"yeah, i don't see how a partition could be in `consumedoffsets` but not in `partitiontimes`?",0,0.9865455627441406
313846296,6694,cadonna,2019-08-14T12:26:00Z,why do you need this assertion? `close()` waits for `long.max_value` for state `not_running`.,0,0.9925170540809631
313850160,6694,cadonna,2019-08-14T12:36:04Z,the order of the imports in kafka streams is usually as follows: kafka imports and 3rd-party imports in one block a block of `java.*` imports `import static`.,0,0.9943479895591736
314216469,6694,cadonna,2019-08-15T08:26:06Z,"wouldn't creating a new task be better? afaik, that is what happens during a restart. no need to simulate anything. furthermore, it avoids introducing a new method just for testing.",0,0.9866757988929749
314220806,6694,cadonna,2019-08-15T08:39:56Z,"would be good to extract `""stream-task-test""` to a member field of the test and use it in `createconfig()` and here.",0,0.9935951828956604
314221852,6694,cadonna,2019-08-15T08:43:09Z,see above,0,0.985628604888916
314223844,6694,cadonna,2019-08-15T08:49:05Z,see above,0,0.985628604888916
314223931,6694,cadonna,2019-08-15T08:49:18Z,why do we need this assertion here?,0,0.9888123273849487
314226105,6694,cadonna,2019-08-15T08:55:49Z,"i see that you tested the different error cases as suggested. however, i would put each test in its own test method.",0,0.9934267997741699
314227123,6694,cadonna,2019-08-15T08:58:51Z,see my comment on the usage of this method in `streamtasktest`.,0,0.9940404295921326
314230884,6694,cadonna,2019-08-15T09:09:53Z,i would put methods to write and read record metadata in their own classes. those classes would be kind of serdes for metadata. such serdes would make the code better testable and separates the concerns of a task and reading and writing metadata which are completely independent. it does not need to be done in this pr. i just wanted to mention it.,0,0.9744859337806702
314236760,6694,cadonna,2019-08-15T09:28:24Z,please remove empty line before this line.,0,0.9929861426353455
314238406,6694,cadonna,2019-08-15T09:33:50Z,"this tests misses to verify whether `streamtime` is set or not. furthermore, i would write two (or three) distinct tests: - `partitiontimestamp` is set (could be further split for `streamtime` is set or not) - `nullpointerexception` is thrown",0,0.9743883609771729
314241100,6694,cadonna,2019-08-15T09:42:10Z,the code block from the beginning of the method until here can be extracted and re-used in this and the previous test methods.,0,0.9951496720314026
314241548,6694,cadonna,2019-08-15T09:43:59Z,"i think, we use `should...` for newly added test methods.",0,0.9848434329032898
314375243,6694,ConcurrencyPractitioner,2019-08-15T15:49:28Z,its just to confirm that there's no problems with the state being removed. thought it would be good to keep that at the very least.,0,0.9605745077133179
314398959,6694,ConcurrencyPractitioner,2019-08-15T16:46:54Z,"yeah, that would probably be a good idea in the future.",0,0.669376015663147
314402987,6694,ConcurrencyPractitioner,2019-08-15T16:57:09Z,"yeah, it can be removed. its somewhat redundant.",0,0.9756419062614441
320293937,6694,cadonna,2019-09-03T14:11:38Z,here it would be better to call `partitionqueues.get(partition)` only once and store its result in a variable. then check the variable for `null` and call `partitiontime()` on the variable.,0,0.9921135902404785
320294207,6694,cadonna,2019-09-03T14:12:03Z,same as above.,0,0.9922299981117249
321203916,6694,cadonna,2019-09-05T11:18:20Z,"i am wondering whether we can do better here. encoding partition time in base64 seems to me a bit a waste of space. as far as i can see, a 8 byte value is encoded in 11 bytes with base64. would be great, if we could store partition time in 8 bytes. i am also wondering why `metadata` in `offsetandmetadata` is a `string` and not something more bytes friendly.",-1,0.6886671781539917
321938111,6694,ConcurrencyPractitioner,2019-09-06T23:14:51Z,"yeah, it is still unclear at this point if the [code block] field in [code block] could be used in this manner. or knows this matter better. anyhow, offsetandmetadata right now is the only medium through which we can checkpoint partition time anyways. so we might be stuck with using the [code block] field.",0,0.9517613053321838
323392057,6694,mjsax,2019-09-11T18:25:53Z,"i know that i recommended to add this parameter, but now, after more refactoring of the code, i am not sure any longer why we need it? it seems that this method is called twice and both calls pass in the result of `extractpartitiontimes()` as parameter -- hence, it seems we can remove the parameter and do the call to `extractpartitiontimes()` within the method itself?",0,0.980588972568512
323397342,6694,mjsax,2019-09-11T18:37:46Z,"this is a blocking call, and just proposed kip-520 to make it more efficient by allowing to pass in multiple partitions at once. should we wait for kip-520 to be implemented? if now, we should make sure the update this code after kip-520 is merged. i am also wondering how we should handle `timeoutexception` for this call? maybe not, but might be worth to clarify? \cc",0,0.9563325643539429
323496050,6694,mjsax,2019-09-11T23:03:23Z,"i don't have the full context on the history, but it would not be easy to change the api... i talked to jason about it, and it seem we can just move forward with this pr as-is, and could do a kip later that allows us to store metadata as `byte[]` type if we really need to change it. atm, the metadata is just a few bytes and the overhead does not really matter imho.",0,0.786907970905304
323621863,6694,cadonna,2019-09-12T08:40:55Z,agreed,0,0.9598594307899475
324510011,6694,mjsax,2019-09-16T04:55:22Z,i remember now -- can we add a comment to explain that we need to get `partitiontimes` before we `closetopology()` (sorry for my previous comment -- forgot about that),-1,0.937538206577301
324917516,6694,guozhangwang,2019-09-16T22:48:38Z,in my pr ([a link] i've refactored this part in streamtask. i'd suggest we merge that one before this.,0,0.9947488903999329
324926772,6694,ConcurrencyPractitioner,2019-09-16T23:29:05Z,"cool, got it done.",1,0.9892103672027588
325385581,6694,guozhangwang,2019-09-17T21:05:42Z,just realized i need to do another rebase on my pr. so if this pr is closer to be merged i'd suggest you guys just move forward and i will rebase mine later.,0,0.9273927807807922
325432250,6694,ConcurrencyPractitioner,2019-09-17T23:53:00Z,"cool, sounds good. in that case, we could get this one merged since it is about complete.",1,0.9833298325538635
184775884,4931,rhauch,2018-04-27T18:47:37Z,it'd be nice to have javadoc for this interface (and all other public api types) that explains the purpose.,0,0.9762829542160034
184776184,4931,rhauch,2018-04-27T18:48:44Z,"nit: this method returns a list of connector _names_, not connector instances.",0,0.9927310347557068
184776264,4931,rhauch,2018-04-27T18:49:05Z,how about just `connectorstate`?,0,0.9933468103408813
184776561,4931,rhauch,2018-04-27T18:50:16Z,"missing javadoc on the type and method. imo, the javadoc on the interface should fully describe how to provide an implementation (by implementing this class, but what about other interfaces), how to package it (e.g., java service provider file), and how to install it (put it on the plugin path). it should also go into detail about how connect uses this interface, when implementations are instantiated and when the register method is called, and when the close method is called. what exceptions can be thrown by this method? will the supplied context ever be null? what are the behaviors that are expected/allowed? what happens when a resource is already registered?",0,0.9776300191879272
184777667,4931,rhauch,2018-04-27T18:54:30Z,"it should be clear that implementations are provided by the framework, but it should be clear what this does and how it can be used by extension implementations.",0,0.9937611222267151
184777830,4931,rhauch,2018-04-27T18:55:11Z,"why not an interface? that would offer us so much more flexibility in the implementation, and all of the implementation details can be hidden from the public api. by having the nested classes here, they are in the public api and need to be managed through kips.",0,0.984623908996582
184778299,4931,rhauch,2018-04-27T18:57:11Z,minor: let's not add unnecessary whitespace.,0,0.9688733220100403
184778412,4931,rhauch,2018-04-27T18:57:41Z,unnecessary whitespace.,-1,0.5128718018531799
184778471,4931,rhauch,2018-04-27T18:57:58Z,this can be `final`.,0,0.994678258895874
184778842,4931,rhauch,2018-04-27T18:59:34Z,how about javadoc that explains that this class is for hiding the jax-rs framework implementation and for handling registration of duplicate resources.,0,0.9930258989334106
184779307,4931,rhauch,2018-04-27T19:01:24Z,"as i mentioned earlier, we need to use java service provider api to find which plugin has the specified implementation, and we should change plugins to support creating these instances. this code only works if the implementations are on the classpath.",0,0.9938894510269165
184829319,4931,mageshn,2018-04-27T23:48:41Z,yes agreed. i still haven't integrated with the plugin classloader yet. hence used this method for the draft so that we get a better picture of the public interfaces.,0,0.9719557762145996
184829507,4931,mageshn,2018-04-27T23:51:05Z,connectorstatedetails provides both the connectorstate and connector taskstate. the original entity class has a name of connectorstateinfo but didn't want to use the same name because i thought it might be a little confusing,0,0.9890156388282776
184829705,4931,mageshn,2018-04-27T23:53:26Z,"the nested classes are also technically part of the public api since user can access it. but imo, having interfaces for pojo or entities might be a little bit of overhead. the only thing we can hide by making it an interface is the constructor.",0,0.9755270481109619
184830969,4931,rhauch,2018-04-28T00:09:38Z,"using an interface gives us more options on the implementation side, and it helps clarify intentions more explicitly and minimally, without exposing implementation details.",0,0.9883098602294922
184830991,4931,rhauch,2018-04-28T00:09:56Z,or maybe just `connectordetail` or `connectordescription`?,0,0.993148148059845
184831075,4931,rhauch,2018-04-28T00:11:01Z,"is it intentional that these tasks are ordered? to the indexes correspond to the task id? if not, perhaps a collection is sufficient, or a map keyed by task id.",0,0.9906708002090454
185244935,4931,rhauch,2018-05-01T15:12:34Z,"first, the iterator returned by the `serviceloader.load` method will be instances of `t`, not `class `, so the call to `addplugindesc` above should result in a class cast exception. third, since these are already instantiated by the serviceloader and match the specified type, why not forgo the logic in `addplugindesc` and simply instantiate a `plugindesc like the only thing we need to do is finally, `serviceloader` is `iterable`, which means the iterator logic can be simpler. put all these three together: [code block] in order to do this, we would need to add a `versionable` interface so that connector and rest extension can extend it.",0,0.9877654314041138
185245899,4931,rhauch,2018-05-01T15:16:10Z,"i know that much of this logic was from the original code, but it might be good to add some debug/trace log messages here, especially in the missing `else` condition (e.g., ""skipping {} since it is not a concrete type."").",0,0.9901936650276184
185246193,4931,rhauch,2018-05-01T15:17:10Z,this won't work for interfaces other than `connector`.,0,0.9927216172218323
185256557,4931,mageshn,2018-05-01T15:56:01Z,"good catch on the serviceloader returning an implementation. having said that, do you think we should cache these implementations instead of creating an instance ourselves? i don't personally see a benefit to using the same instance the one returned by the serviceloader.",0,0.5776809453964233
185260491,4931,rhauch,2018-05-01T16:12:16Z,"if we can make this method more generic or general purpose, then this method should probably be called within a conditional block checking whether it implements `configurable`.",0,0.9927492141723633
185261384,4931,rhauch,2018-05-01T16:15:52Z,this method does not have much logic that is specific to `connectrestextension`. have you thought about making this more general-purpose to load any extensions (other than when a more specific method is available)? doing that might make it easier to add future extensions.,0,0.993280827999115
185262140,4931,rhauch,2018-05-01T16:18:36Z,"the serviceloader is usually just used directly to load all instances of a particular extension point, but that's not really what we do. and really there's nothing special about _how_ serviceloader instantiates the class: it really just does a new instance on the class.",0,0.9911981225013733
185262431,4931,rhauch,2018-05-01T16:19:51Z,"btw, we should have a test case that loads a test implementation of `restextension` using plugins.",0,0.9928021430969238
185384782,4931,mageshn,2018-05-02T03:11:12Z,"yes, i will be adding more tests. once we all agree on the public interfaces, i will update the kip and refine this pr",0,0.993239164352417
185385261,4931,mageshn,2018-05-02T03:17:30Z,would be good to have state or status in there since its just not a connectordescription,0,0.9860390424728394
185537702,4931,rhauch,2018-05-02T15:26:54Z,"use ""component"" rather than ""plugin""?",0,0.9938468337059021
185539183,4931,rhauch,2018-05-02T15:30:46Z,"how about `connectorhealth`, since this is likely to be used by health check extensions? the `detail` in `connectorstatedetail` just seems superfluous to me.",0,0.9828726649284363
185540424,4931,rhauch,2018-05-02T15:34:18Z,suggest at a minimum:,0,0.9930717349052429
185540807,4931,rhauch,2018-05-02T15:35:30Z,this logic is in two places. how about a helper method? if it were named `vesrionfor(class clazz)` then it could be more easily inlined where it's used.,0,0.9918881058692932
185892000,4931,wicknicks,2018-05-03T18:13:24Z,"maybe you guys have already talked about this, but does it make sense to have a per extension prefix for the configs? similar to how it is done for transformations?",0,0.9873628616333008
185893483,4931,wicknicks,2018-05-03T18:18:40Z,should we pass in `connectrestextensioncontext` with the `newconnectrestextensions(..)` method above? it will be cleaner to create and register the plugin in one place.,0,0.9935008883476257
185903792,4931,wicknicks,2018-05-03T18:56:19Z,"yeah, i agree with randall here. `detail` is not a good fit here. maybe you can use `connectorscontext`?",0,0.9809747934341431
185904747,4931,wicknicks,2018-05-03T18:59:53Z,should we expose connector metrics here? it could be a good fit for the health check resource in the kip).,0,0.9928452372550964
186196449,4931,kkonstantine,2018-05-04T19:43:23Z,i think we are stretching the use `-able` here. i'd suggest `versioned` as one of the less frequent cases where we'd use an adjective that does not and in `-able` but which makes a lot of sense for the functionality that this interface describes.,0,0.9756879806518555
186197396,4931,kkonstantine,2018-05-04T19:47:59Z,javadoc?,0,0.9890388250350952
187750001,4931,kkonstantine,2018-05-11T22:52:32Z,i think we are stretching the use -able here. i'd suggest `versioned` as one of the less frequent cases where we'd use an adjective that does not and in -able but which makes a lot of sense for the functionality that this interface describes.,0,0.9714825749397278
187750848,4931,kkonstantine,2018-05-11T23:00:25Z,nit: missing ``,0,0.9185428023338318
187750866,4931,kkonstantine,2018-05-11T23:00:33Z,nit: missing ``,0,0.9185428023338318
187756954,4931,kkonstantine,2018-05-12T00:10:00Z,"if we want to be precise, we shouldn't mention `list` here. this is implementation specific but the interface could return a set or actually anything that is a `collection`. i'd love if we could rephrase the descriptions here to keep our options open.",0,0.8132590651512146
187757323,4931,kkonstantine,2018-05-12T00:15:16Z,"i'd suggest referring to plugin path as only `plugin.path` and basically when it makes more sense referring to the parameter. maybe here you could replace with something like: `for the connect's class loader's to be able to discover the ...""",0,0.992195725440979
187757374,4931,kkonstantine,2018-05-12T00:16:11Z,typo? `place` -> `placed`? also maybe rephrase into shorter sentences to make easier to follow?,0,0.9937491416931152
187757473,4931,kkonstantine,2018-05-12T00:17:59Z,"i'm torn about upper casing here. feels like lower cased words make more sense: `security (authentication and authorization), logging, request validations, etc`. ...",-1,0.8014102578163147
187757938,4931,kkonstantine,2018-05-12T00:25:48Z,"nit: framework means connect here i assume. so, maybe it's better to call this out as: `connect` or `connect framework`",0,0.988494336605072
187758006,4931,kkonstantine,2018-05-12T00:27:05Z,nit: again i'd use lower case for anything that's not a name or a code class (mostly): `connect resources`,0,0.9574752449989319
187758037,4931,kkonstantine,2018-05-12T00:27:34Z,nit: extra blank line,0,0.9695041179656982
187758071,4931,kkonstantine,2018-05-12T00:28:08Z,nit: `provides the ability`?,0,0.9928378462791443
187758104,4931,kkonstantine,2018-05-12T00:28:58Z,`the connect framework`? which framework?,0,0.993990957736969
187758167,4931,kkonstantine,2018-05-12T00:29:55Z,description is missing. i'm not a fan of javadoc that contains only ``. maybe most text could be in the description and `` could be brief.,-1,0.5450954437255859
187758286,4931,kkonstantine,2018-05-12T00:31:44Z,"typos: return a -> return an (no 1+ spaces), ot -> to",0,0.9928666353225708
188085678,4931,kkonstantine,2018-05-14T20:22:57Z,this applies unchecked overriding of the return type. in `connectrestextensioncontext` its `configurable ` and the same should be used in the member field as well as the return type here.,0,0.9949794411659241
188085791,4931,kkonstantine,2018-05-14T20:23:17Z,`configurable ` same as below,0,0.9943698048591614
188086026,4931,kkonstantine,2018-05-14T20:24:04Z,"nit: extra blank line, here and elsewhere in this class.",0,0.991956353187561
188086886,4931,kkonstantine,2018-05-14T20:26:56Z,"javadoc would be nice, here and in the rest of the public inner classes (especially since we have `abstractstate` elsewhere too)",0,0.9674025774002075
188087495,4931,kkonstantine,2018-05-14T20:28:53Z,"should this be called `taskid`, equivalently to `workerid` above? it'll make initialization and usage clear (i think)",0,0.9914862513542175
188088345,4931,kkonstantine,2018-05-14T20:31:44Z,an `enum` with the same name and the same `tostring` implementation is already defined here: `org.apache.kafka.connect.runtime.rest.entities.connectortype` do we need to add this one?,0,0.9945077300071716
188089609,4931,kkonstantine,2018-05-14T20:35:59Z,it's common to write `username` as `password` (instead of `password`). would you agree changing it wherever we use `username` in this pr? (check with `grep -rl username`),0,0.9950836896896362
188090162,4931,kkonstantine,2018-05-14T20:37:47Z,not clear what's the meaning of `32` here. can we declare an intuitive `static final` variable?,0,0.9467573165893555
188090361,4931,kkonstantine,2018-05-14T20:38:33Z,also a nice candidate for `static final` member variable.,1,0.757733166217804
188091528,4931,kkonstantine,2018-05-14T20:42:51Z,should we throw `unsupportedcallbackexception` if it doesn't match? especially since we declare it and that's the intended use of this exception according to the interface (actually we're violating the interfaces contract if we don't).,0,0.9677160382270813
188093766,4931,kkonstantine,2018-05-14T20:50:37Z,"probably makes sense to be `static`, especially because of its size.",0,0.9735678434371948
188093995,4931,kkonstantine,2018-05-14T20:51:27Z,nit: should be in the same line as above,0,0.9922863245010376
188094029,4931,kkonstantine,2018-05-14T20:51:33Z,nit: should be in the same line as above,0,0.9922863245010376
188094120,4931,kkonstantine,2018-05-14T20:51:51Z,nit: should be in the same line as above,0,0.9922863245010376
188094141,4931,kkonstantine,2018-05-14T20:51:56Z,nit: should be in the same line as above,0,0.9922863245010376
188094184,4931,kkonstantine,2018-05-14T20:52:05Z,nit: should be in the same line as above,0,0.9922863245010376
188094421,4931,kkonstantine,2018-05-14T20:52:55Z,"`class names`. no caps (same as classloader, etc).",0,0.9915633201599121
188094764,4931,kkonstantine,2018-05-14T20:53:59Z,"nit: you may fit args in one line, as in `newheaderconverter`",0,0.994404673576355
188094969,4931,kkonstantine,2018-05-14T20:54:37Z,nit: extra space between: `of plugins`,0,0.9949703812599182
188096167,4931,kkonstantine,2018-05-14T20:58:50Z,"no caps pls. `empty` -> `empty list`, `null` -> `{ null}`",0,0.9887711405754089
188096202,4931,kkonstantine,2018-05-14T20:58:58Z,"no caps pls. empty -> empty list, null -> { null}",0,0.9893469214439392
188097792,4931,kkonstantine,2018-05-14T21:04:02Z,"also the generic name of this method contradicts its functionality. in not general, but pertains only to `connectrestextension`. should probably be named same as with the others above, until we perform some short of consolidation in the functionality. so `newconnectrestextensionplugins` here",0,0.9893024563789368
188097949,4931,kkonstantine,2018-05-14T21:04:28Z,"for the same reasons as above, this should probably be: `newconnectrestextensionplugin`. the log message bellow shows that this method is specific to `connectrestextensions `",0,0.994246780872345
188099111,4931,kkonstantine,2018-05-14T21:08:33Z,nit: extra blank line,0,0.9695041179656982
188099600,4931,kkonstantine,2018-05-14T21:10:17Z,~java.util.~ collection,0,0.9839923977851868
188100389,4931,kkonstantine,2018-05-14T21:13:15Z,should be `final`,0,0.9946359992027283
188100820,4931,kkonstantine,2018-05-14T21:14:44Z,"if that's a todo comment (which we should avoid adding if we can), it should be marked as `//todo: log ... something more` i'm only guessing what it means here.",0,0.9640600085258484
188100846,4931,kkonstantine,2018-05-14T21:14:51Z,"if that's a todo comment (which we should avoid adding if we can), it should be marked as `//todo: log ... something more`",0,0.9935966730117798
188101268,4931,kkonstantine,2018-05-14T21:16:21Z,both exception are unused here.,0,0.9918451905250549
188101632,4931,kkonstantine,2018-05-14T21:17:43Z,"symmetrically to the above similar method, it's better if `result` is declared close to where it's used. here just before the `for (t impl : serviceloader)` loop",0,0.9914500117301941
188102042,4931,kkonstantine,2018-05-14T21:19:11Z,nit: alignment probably better as: [code block],0,0.9881505966186523
188108937,4931,mageshn,2018-05-14T21:47:39Z,there was a debate about moving the required entity class from runtime to api but we decided not to. hence we see this copy. the connecthealth class introduced itself is pretty much same as connectorstateinfo. i personally still think that entities can be part of the public api. but i'm fine either ways.,0,0.905932605266571
188110010,4931,mageshn,2018-05-14T21:52:15Z,"it started as newconnectrestextensionplugins and based on earlier pr discussion, we decided to make it generic. may be i missed out generalizing some of the log statements",0,0.9892728924751282
188802909,4931,rhauch,2018-05-16T23:40:05Z,"i'm fine with `versioned`, since this interface defines something that has a version and is not something that can be versioned.",0,0.9691258668899536
188803007,4931,rhauch,2018-05-16T23:40:51Z,nit: rest should be capitalized.,0,0.8212618231773376
188803095,4931,rhauch,2018-05-16T23:41:21Z,"""plugin class loading mechanism"" rather than ""class loader's"".",0,0.9926797151565552
188803391,4931,rhauch,2018-05-16T23:43:26Z,"""implementations should be packaged in a jar that includes the file { meta-inf/services/org.apache.kafka.connect.rest.extension.connectrestextension} that contains the fully-qualified name of the implementation class."" also, ` ` tags should always start on new lines, and for readability should probably be preceded by a blank line.",0,0.993198573589325
188803420,4931,rhauch,2018-05-16T23:43:39Z,+1 for fixing this.,1,0.943868100643158
189633739,4931,rhauch,2018-05-21T16:00:00Z,javadoc for this interface. a simple sentence would suffice.,0,0.9921478629112244
189633925,4931,rhauch,2018-05-21T16:00:34Z,javadoc ... a simple sentence would suffice.,0,0.9076065421104431
189634016,4931,rhauch,2018-05-21T16:00:54Z,javadoc ... a simple sentence would suffice.,0,0.9076065421104431
189634067,4931,rhauch,2018-05-21T16:01:02Z,javadoc ... a simple sentence would suffice.,0,0.9076065421104431
189634263,4931,rhauch,2018-05-21T16:01:43Z,javadoc ... a simple sentence would suffice.,0,0.9076065421104431
189634410,4931,rhauch,2018-05-21T16:02:07Z,"""rest"" is an acronym and should be capitalized.",0,0.9888604283332825
189634561,4931,rhauch,2018-05-21T16:02:37Z,paragraphs should begin on a new line and have a blank line before them in javadoc.,0,0.9923446774482727
189634630,4931,rhauch,2018-05-21T16:02:48Z,paragraphs should begin on a new line and have a blank line before them in javadoc.,0,0.9923446774482727
189634810,4931,rhauch,2018-05-21T16:03:21Z,"""connect"" is a name and should be capitalized.",0,0.9919760823249817
189635129,4931,rhauch,2018-05-21T16:04:30Z,"use quotes or `{ }` around ""kafkaconnect"" to highlight the importance of that literal.",0,0.9927945733070374
189635519,4931,rhauch,2018-05-21T16:05:38Z,"how about also mentioned that it must be configured in the worker configuration, and providing an example configuration fragment that shows how to use this sample extension.",0,0.9938398003578186
189636428,4931,rhauch,2018-05-21T16:08:40Z,"should this mention that this is a sample implementation? how does it work, and where does it get the credentials? seems like this needs a lot more context to be useful as an example.",0,0.8537590503692627
189637087,4931,rhauch,2018-05-21T16:10:39Z,how about `to connect's rest api` rather than `to connect rest`?,0,0.9935924410820007
189637462,4931,rhauch,2018-05-21T16:11:43Z,nit: this can be defined on one line.,0,0.9942389726638794
189637562,4931,rhauch,2018-05-21T16:12:03Z,nit: this can be one line.,0,0.9868817329406738
189637966,4931,rhauch,2018-05-21T16:13:27Z,"nit: would using `state` rather than `taskstatefromherder` make this a bit more readable, such that the instantiation of the `taskstate` could be done on a single line?",0,0.9863240122795105
189639210,4931,rhauch,2018-05-21T16:17:52Z,why do we need this conditional logic? is it ever called with a classloader that is not a pluginclassloader?,0,0.9932458996772766
189640314,4931,rhauch,2018-05-21T16:22:00Z,"this should be usable by plugin types other than just connect rest extensions, so i think the non-specific name is important. if we want a specific name for the connect rest extension, then we should add that as the public method and keep this as a protected/private method.",0,0.9881570935249329
189640748,4931,rhauch,2018-05-21T16:23:33Z,seems like this boolean check is backwards. shouldn't this method return true if the component is _not_ already registered?,0,0.9350069165229797
189640850,4931,rhauch,2018-05-21T16:23:59Z,"same incorrect boolean logic here, too.",0,0.6821374297142029
189641853,4931,rhauch,2018-05-21T16:27:28Z,"is this the only rest extension that we'll have in this project? if so, should we have a better and more descriptive name for the project rather than simple `rest-extension`?",0,0.9920393228530884
189966266,4931,rhauch,2018-05-22T16:22:13Z,"perhaps ""connect requires some components implement this interface to define a version string.""",0,0.989194393157959
189966612,4931,rhauch,2018-05-22T16:23:17Z,"again, capitalize ""connect"" as a name rather than ""connect"" as a verb.",0,0.9886395931243896
189966880,4931,rhauch,2018-05-22T16:24:09Z,need javadoc here. what does the string value represent? can this method ever return null or an empty string?,0,0.9939020872116089
189966913,4931,rhauch,2018-05-22T16:24:14Z,need javadoc here. what does the string value represent? can this method ever return null or an empty string?,0,0.9939020872116089
189966983,4931,rhauch,2018-05-22T16:24:29Z,need javadoc here. what does the string value represent?,0,0.9942230582237244
189967160,4931,rhauch,2018-05-22T16:25:04Z,"are there any requirements about whether these can be null or empty? what is `trace`? need javadoc since this is part of the api, and also verify the arguments match the requirements.",0,0.9949508905410767
189967589,4931,rhauch,2018-05-22T16:26:22Z,"""connector"" is not a name and should not be capitalized.",0,0.9871648550033569
189967877,4931,rhauch,2018-05-22T16:27:17Z,"grammar: it's more correct to say ""get the names of the connectors currently running..."", since the names are not running in the cluster. :-) also, do the connectors need to be running for them to be included here? what if they died and were not restarted? i suggest the statement refer to connectors **_deployed_** in this cluster.",1,0.9590945243835449
189968731,4931,rhauch,2018-05-22T16:30:01Z,need javadoc here to define which parameters can be null and/or empty.,0,0.9932193160057068
189968885,4931,rhauch,2018-05-22T16:30:28Z,"add javadoc, since this is part of the public api.",0,0.995353102684021
189968977,4931,rhauch,2018-05-22T16:30:48Z,"add javadoc, since this is part of the public api. which of the parameters are allowed to be null and/or empty?",0,0.9951574206352234
189969183,4931,rhauch,2018-05-22T16:31:28Z,"nit: remove the unnecessary ""the"" on this line.",0,0.9803942441940308
189969774,4931,rhauch,2018-05-22T16:33:18Z,"nit: i'd suggest ""the implementation class must be packaged in a jar that includes the { ...} file containing the fully qualified name of the implementation class.""",0,0.9924077987670898
189970477,4931,rhauch,2018-05-22T16:35:32Z,"suggest: ""when connect's worker configuration uses the rest extension implementation class, upon startup connect will instantiate the implementation and pass the configuration to the instance via { configurable#configure(map)}.""",0,0.9938627481460571
189970682,4931,rhauch,2018-05-22T16:36:13Z,"use ""the connect framework ..."" instead.",0,0.9909026026725769
189970767,4931,rhauch,2018-05-22T16:36:35Z,"nit: singular ""implementation""",0,0.9924271702766418
189971395,4931,rhauch,2018-05-22T16:38:35Z,"rather than use ` ` tags, rst files use two sequential back quotes before and after code-like text.",0,0.9919339418411255
189971743,4931,rhauch,2018-05-22T16:39:36Z,"grammar: ""... allows you to inject into connect's rest api user defined resources like filters.""",0,0.9936315417289734
189971830,4931,rhauch,2018-05-22T16:39:53Z,replace the ` ` tags.,0,0.991214394569397
190068865,4931,mageshn,2018-05-22T22:09:26Z,other places like metrics reporter use the same convention. tried to be consistent with it.,0,0.9818236231803894
190069307,4931,mageshn,2018-05-22T22:11:13Z,"atm, this is the only implementation. i named it just like other components for transforms. i'm not too particular about the module name being generic. i could call it connect-basic-auth-extension",0,0.987316906452179
190759541,4931,rhauch,2018-05-24T23:42:08Z,"yeah, maybe `basic-auth-extension` (e.g., to go with `file`, etc.). i'm just concerned that `rest-extension` is pretty generic and actually sounds like it's the api, not a reference impl.",0,0.7803018093109131
190793197,4931,mageshn,2018-05-25T05:18:35Z,other places like metrics reporter class use the same convention of using <code> tried to be consistent with the same.,0,0.9913226366043091
190793246,4931,mageshn,2018-05-25T05:19:06Z,this is fixed,0,0.9859667420387268
190955448,4931,mageshn,2018-05-25T17:06:13Z,"the method is now generic enough to instantiate any plugin. irrespective, i think registering resources belongs in restserver.",0,0.9926717281341553
190956787,4931,rhauch,2018-05-25T17:12:32Z,ack.,0,0.5866091847419739
190958825,4931,rhauch,2018-05-25T17:20:37Z,"don't we want these classes to be in a different package than `org.apache.kafka.connect.rest.extension`, since that's the package that exists in the api? the file source and sink, for example, are in `org.apache.kafka.connect.file`. i'd recommend something like `org.apache.kafka.connect.extension.auth.jaas`.",0,0.9903924465179443
190959257,4931,rhauch,2018-05-25T17:22:11Z,"also, since this is a reference implementation, perhaps we could have some javadoc that explains at a high level how this implements the `connectrestextension`, how it works (briefly), and how it is packaged.",0,0.9919137954711914
190959594,4931,rhauch,2018-05-25T17:23:23Z,"make sure this package name is changed accordingly. also, this is a good reason why we want a different package name, since this looks like the extension implementation is built-in to the connect framework.",0,0.9947170615196228
190959834,4931,rhauch,2018-05-25T17:24:18Z,"are we okay with people using this in production? if not, we need to say so. if we're okay with it, we should probably outline a few caveats or important things to keep in mind when evaluating whether to use it. for example, passwords will be stored in cleartext in the property file. this alone suggests that maybe we should call it out as a sample reference implementation that may not be suitable for production use.",0,0.9814522862434387
190960784,4931,rhauch,2018-05-25T17:28:23Z,"i think we should highlight the characteristics that users should be aware of, such as that passwords are stored in plaintext in the referenced file, and that because of this it is likely not recommended for production but is instead part of a sample implementation of the connect rest extension and should not be used in production. perhaps the same paragraph with bold `note:` in all of the files in this package.",0,0.9904568791389465
190961652,4931,rhauch,2018-05-25T17:31:58Z,can this be private?,0,0.9927625060081482
190961740,4931,rhauch,2018-05-25T17:32:19Z,nit: blank line at the beginning of the method is unnecessary.,0,0.9915245175361633
190962339,4931,rhauch,2018-05-25T17:34:48Z,nit: `into` rather than `in to`.,0,0.9857479929924011
190962903,4931,mageshn,2018-05-25T17:36:55Z,ack,0,0.9149930477142334
190996405,4931,rhauch,2018-05-25T19:59:24Z,ping.,0,0.857026219367981
190996589,4931,rhauch,2018-05-25T20:00:18Z,maybe just `rest_extension`?,0,0.9907479286193848
190996744,4931,rhauch,2018-05-25T20:01:10Z,always need a sentence in javadoc.,0,0.9893648624420166
190996769,4931,rhauch,2018-05-25T20:01:16Z,nit: add a period.,0,0.9908370971679688
190997074,4931,rhauch,2018-05-25T20:02:51Z,"rather than describe the return in the description (2nd sentence), i'd suggest putting it in the param: state of the connector or task; never null or empty it's more concise, and it puts the information where people will look for it.",0,0.9893686175346375
190997151,4931,rhauch,2018-05-25T20:03:12Z,"nit: ""id"" or ""identifier"" (or even ""id""), but not ""id"".",0,0.9895552396774292
190997266,4931,rhauch,2018-05-25T20:03:48Z,"again, remove the 2nd sentence in the description and put it in the param: the worker id; never null or empty",0,0.9941650032997131
190997323,4931,rhauch,2018-05-25T20:04:07Z,"again, remove the 2nd sentence in the description and put it in the param: the trace message; may be null or empty",0,0.9944391250610352
190997381,4931,rhauch,2018-05-25T20:04:24Z,"how about `tracemessage`, rather than `trace`?",0,0.9927961230278015
190997661,4931,rhauch,2018-05-25T20:05:49Z,for consistency: * state - the status of connector or task; may not be null or empty * workerid - the workerid associated with the connector or the task; may not be null or empty * tracemsg - any error trace message associated with the connector or the task; may be null or empty,0,0.9940500259399414
190997897,4931,rhauch,2018-05-25T20:06:53Z,how about: the version string; may not be null or empty,0,0.9948467016220093
190998205,4931,rhauch,2018-05-25T20:08:09Z,"`isempty()` just checks whether the length is 0, so a string with 1+ whitespace will be allowed. instead, use: assert state != null && !state.trim().isempty();",0,0.9936512112617493
190998580,4931,rhauch,2018-05-25T20:09:18Z,nit: period.,-1,0.6804956793785095
190998660,4931,rhauch,2018-05-25T20:09:41Z,this should be a sentence.,0,0.9764725565910339
190998760,4931,rhauch,2018-05-25T20:10:11Z,"the connector name can this be null or empty? if not, then should check in the constructor. and if the framework calls the constructor, asserts are fine; if users can call it, then `objects.requirenotnull` is better.",0,0.9944506883621216
190999238,4931,rhauch,2018-05-25T20:12:32Z,"same here. sentence, and specify whether it can be null",0,0.9944698810577393
190999527,4931,rhauch,2018-05-25T20:13:58Z,"no need to specify the type; it can only get lost and it's already in the signature. again, full sentences are needed in javadoc, and the state for each task id; never null",0,0.9930296540260315
190999572,4931,rhauch,2018-05-25T20:14:09Z,check the input parameters here.,0,0.9945173859596252
190999619,4931,rhauch,2018-05-25T20:14:23Z,same here.,0,0.9916109442710876
190999676,4931,rhauch,2018-05-25T20:14:45Z,need a sentence in javadoc.,0,0.9867540001869202
190999795,4931,rhauch,2018-05-25T20:15:23Z,"nit: it's sufficient to just say ""describes the status, worker id, and any errors associated with a connector."" no need to include a link to this class.",0,0.9921345710754395
190999885,4931,rhauch,2018-05-25T20:15:51Z,"this is public api, so we need javadoc for this class and the enumeration literals.",0,0.9948292374610901
191000029,4931,rhauch,2018-05-25T20:16:37Z,"""describes the state, ids, and any errors of a connector task."" no link, no capitalized ""connector"", and consistent use of ""id"".",0,0.9931735396385193
191000240,4931,rhauch,2018-05-25T20:17:44Z,"for consistency, use `; may not be null or empty` in parameter descriptions. also, no `-` after the parameter name since javadoc already handles this. fix these everywhere.",0,0.9948775768280029
191000313,4931,rhauch,2018-05-25T20:18:12Z,"full sentence, and ` the task id`",0,0.993425726890564
191000490,4931,rhauch,2018-05-25T20:19:03Z,"nit: multiple `by` in this sentence, so change this one to `using`.",0,0.9923730492591858
191001129,4931,rhauch,2018-05-25T20:21:54Z,perhaps the following helps better explain all of the packaging requirements: [code block],0,0.9872037768363953
191002545,4931,rhauch,2018-05-25T20:29:16Z,nit: [code block],0,0.9919844269752502
191002688,4931,rhauch,2018-05-25T20:30:02Z,the jax-rs { javax.ws.rs.core.configurable}; never null,0,0.9945949912071228
191002712,4931,rhauch,2018-05-25T20:30:12Z,missing a period.,0,0.9139365553855896
191003024,4931,rhauch,2018-05-25T20:31:52Z,change to: provides the cluster state and health information about the connectors and tasks. the cluster state information; never null,0,0.9946321249008179
191003130,4931,rhauch,2018-05-25T20:32:27Z,"nit: begin without a link to this class: ""a sample rest extension that authenticates incoming ...""",0,0.9928306937217712
191013751,4931,mageshn,2018-05-25T21:30:44Z,i don't think we can guarantee or enforce the version,0,0.8677790760993958
191061506,4931,ewencp,2018-05-27T00:29:20Z,very minor nit: easier to keep track of these if we group common package prefixes together,0,0.8774489164352417
191061533,4931,ewencp,2018-05-27T00:31:38Z,isn't this the same subpackage we're defining rules for? self-referential imports shouldn't need to be defined here -- imports from the same package shouldn't need special allowance.,0,0.9894283413887024
191061585,4931,ewencp,2018-05-27T00:35:26Z,"this doesn't seem like a good thing to enable -- it's the opposite dependency we would normally want to have here. i see the only use is in a javadoc, can we adjust that so the import is not required? for example, use the fully qualified class name instead of just the class name so we don't rely on the import?",0,0.8421419262886047
191062417,4931,ewencp,2018-05-27T01:50:27Z,"we don't enforce this today, though you could reasonable argue this is a ""bug"" that we don't validate them today. i think documenting this in the interface as an expectation would be reasonable. whether we enforce it or not on various `versioned` implementations might vary -- we could, for example, enforce proper versioning from day 1 of these new rest extensions, whereas for, e.g., connectors, we might want to think about adding validation that produces warnings if they return `null` or empty values, then eventually actually enforcing it (say, with ak 3.0).",0,0.9866043925285339
191062502,4931,ewencp,2018-05-27T01:54:20Z,"do we want these to be asserts or check conditions and throw, e.g., `illegalargumentexception` with a more useful message?",0,0.9855985641479492
191062585,4931,ewencp,2018-05-27T02:00:04Z,"`connectorstate` is the wrong capitalization for a javadoc, i'd also simplify to just ""about the connector and its tasks"", rest of the api docs can give further details.",0,0.9608407020568848
191062771,4931,ewencp,2018-05-27T02:14:01Z,"is this actually what we want? seems like if you wanted to keep a previous `taskstate` and check whether it had changed, this is going to be confusing behavior.",-1,0.5230578780174255
191063008,4931,ewencp,2018-05-27T02:36:32Z,"i'm noticing now that the context object exposes the cluster state, but doesn't explain the semantics for the returned state. since the extension only gets a hook into the context on the register() call, that means this must be returning dynamic state. it seems like you don't necessarily get a consistent snapshot of the state when you call this -- you get a `connectclusterstate`(`impl`) object back, but that object can mutate out from under you since it's backed just by the dynamic herder state. this is actually problematic and kind of difficult for plugin implementations since the calls to get the list of connectors and to get their state are separate and non-atomic. which means there are chances of hitting `notfound` exceptions and maybe others, which aren't clear from the interfaces. is there any reason not to make collection of the cluster state atomic and take a snapshot instead? that has way more intuitive semantics. if we don't do that, i think we need to clearly document the semantics in the javadocs.",0,0.7772642970085144
191063158,4931,ewencp,2018-05-27T02:52:03Z,"nit: typo ""teh""",-1,0.7085840702056885
191063275,4931,ewencp,2018-05-27T03:03:30Z,"seems redundant, we could just refactor out the part up to `getpassword` to a statement before this.",0,0.9193222522735596
191063281,4931,ewencp,2018-05-27T03:04:26Z,is `credentialproperties` guaranteed non-null? it doesn't really seem like it given the logic in `initialize`.,0,0.9907556176185608
191063473,4931,ewencp,2018-05-27T03:19:11Z,"this is global, static state. i think we should be careful to clean this up after the test.",0,0.9800006747245789
191063510,4931,ewencp,2018-05-27T03:23:08Z,"yeah, we just don't have a good way to handle multiple formats today. we'll want to adjust to rst-style if we implement kafka-2967",0,0.904478132724762
191063925,4931,ewencp,2018-05-27T03:59:08Z,"nit: typo: ""no re-registering"" -> ""not re-registering""",0,0.792216956615448
191063955,4931,ewencp,2018-05-27T04:01:12Z,"doesn't matter much, but seems weird to use `boolean.true` and `boolean.false` instead of just `true`/`false` literals here",-1,0.9664933085441589
191064077,4931,ewencp,2018-05-27T04:10:34Z,"should these calls be protected by exception handlers for each since they're user pluggable? i.e. so if one fails, we don't just skip closing the rest (and the jetty server)?",0,0.991689145565033
191292103,4931,mageshn,2018-05-29T02:23:49Z,good point. i will add documentation to mention that these are not atomic and could potentially get an exception.,1,0.9708295464515686
191292150,4931,mageshn,2018-05-29T02:24:25Z,good catch. throwing an exception now if the file can't be loaded.,1,0.9718465209007263
191293267,4931,mageshn,2018-05-29T02:37:15Z,added some docs on connectclusterstate. let me know,0,0.9367302656173706
191598513,4931,rhauch,2018-05-29T22:52:14Z,"i also think that it's useful to specify the expectations on an interface like this that's intended to be implemented by others. it provides useful guidance for implementers, whether or not we enforce it now.",0,0.8286861777305603
191599600,4931,rhauch,2018-05-29T22:58:18Z,"with the changes to externalize secrets in [a link], the existing connectclusterstate is going to output the transformed configurations, which may include secrets. do we want to do that? or, would we prefer to get the pre-transformed configurations?",0,0.9929433465003967
191599981,4931,rhauch,2018-05-29T23:00:23Z,nit: javadoc for a class shouldn't really have links to that same class. readers will think that it's something different.,0,0.8873008489608765
191600425,4931,rhauch,2018-05-29T23:02:33Z,"""the connect framework"", not ""connect framework"". check this elsewhere, since it seems like i've requested this change multiple times already and the usage in this commit still is not consistent. :-)",1,0.960574209690094
191600823,4931,mageshn,2018-05-29T23:04:35Z,"iiuc, kip-297 is for connector configurations and we are only dealing with those here atm.",0,0.9924289584159851
191601149,4931,mageshn,2018-05-29T23:06:29Z,the latest commit already specifies this.,0,0.9945684671401978
191601292,4931,rhauch,2018-05-29T23:07:18Z,"""... current configuration, which may change over time.""",0,0.9835968613624573
191601381,4931,rhauch,2018-05-29T23:07:51Z,"the method description in the javadoc says that a `notfoundexception` will be thrown if no connector with the supplied name exists when this method is called, but the `` description says that the method can return null. we should decide: is it better to throw an exception or return null. if we throw an exception, we should add ` notfoundexception if a connector with the supplied name does not exist` to fully document the behavior. (in general, the kafka javadocs are relatively poor on this front.)",0,0.961030125617981
191602202,4931,rhauch,2018-05-29T23:12:30Z,missing a period to terminate the sentence.,0,0.9634930491447449
191602750,4931,rhauch,2018-05-29T23:15:29Z,capitalize the first word in the sentence.,0,0.9885938167572021
191602778,4931,rhauch,2018-05-29T23:15:39Z,"capitalize the first word in the sentence. (check for other places, too.)",0,0.9886139631271362
191602947,4931,rhauch,2018-05-29T23:16:39Z,"it'd be better to call the parameter `tracemessage` and then use ""any error message..."" in the description.",0,0.9909915924072266
191603062,4931,rhauch,2018-05-29T23:17:18Z,nit: missing the period to terminate the sentence.,0,0.8940051198005676
191603211,4931,rhauch,2018-05-29T23:18:06Z,nit: should be `class(es)` to match line 33.,0,0.9941469430923462
191603371,4931,rhauch,2018-05-29T23:19:10Z,"nit: ""implementations"" (plural)",0,0.9940639138221741
191603895,4931,rhauch,2018-05-29T23:22:16Z,"we shouldn't use ` `; instead, use a ` ` section around the lines.",0,0.9894550442695618
191604301,4931,rhauch,2018-05-29T23:24:44Z,"these should be ` ` rather than ` `. the latter is more for phrases, not blocks, and loses all indentation and line breaks within a block of code. then you can get rid of the ` ` tags.",0,0.9945040941238403
191605111,4931,rhauch,2018-05-29T23:29:21Z,"good point, but it could be clearer. this implementation can be used in production, but the `propertyfileloginmodule` that also ships with this reference implementation should not be used in production.",1,0.7044886350631714
191605490,4931,rhauch,2018-05-29T23:31:43Z,"should we log a warning in an `else` block for this `if` block? if somebody does not specify the filename, this login module will always fail authentication, right?",0,0.987354576587677
191605741,4931,rhauch,2018-05-29T23:33:21Z,"for 2.0, should we log this as an error rather than throw an exception? iiuc, this is what you suggested, .",0,0.9950674772262573
191605853,4931,rhauch,2018-05-29T23:34:04Z,nit: why `boolean` rather than `boolean`?,0,0.9728400111198425
191606424,4931,rhauch,2018-05-29T23:37:49Z,"sorry, i now realize that this connectclusterstate is the interface in the api, whereas kip-297 is changing the implementation in the runtime. the api interface doesn't expose the configuration, so that's a good thing.",-1,0.958160936832428
191618735,4931,mageshn,2018-05-30T01:14:57Z,my understanding was that we enforce it strictly for restextension in 2.0. older implementations can be enforced in 3.0,0,0.9911516308784485
191637634,4931,ewencp,2018-05-30T04:09:22Z,"i think there's confusion in the discussion. i think 's point is that, since we have not enforced correctness in returned values thus far, we should be liberal in what we accept for now. so if they return `null` or an empty value, we should log an error, but not throw an exception that would kill the connector. on 3.0 or some later version, we'd do as this code currently does and throw an exception since we will have given connectors a reasonable grace period to fix their behavior given that we didn't previously enforce the behavior.",0,0.6525400876998901
191638435,4931,ewencp,2018-05-30T04:17:50Z,"i actually think the question is still relevant -- `connectclusterstate` used to be purely immutable and now we'll be exposing an interface that changes based on when you call it. i think it doesn't matter much here, but it is mainly relevant because the docs on `connectclusterstate` aren't really accurate anymore since the contents can change over time. but it's also a weird mix of mutability -- the set of connectors & tasks won't change in the `connectclusterstate` object, you would need to re-callthis method to get updated cluster state. however, the actual values returned for a connector/task config *could* change due to kip-297 replacements.",0,0.7693641185760498
249744367,6177,stanislavkozlovski,2019-01-22T11:38:07Z,should we mention that this configuration enabled a static membership and its lack would mean dynamic membership?,0,0.9905423521995544
249745157,6177,stanislavkozlovski,2019-01-22T11:40:41Z,is there any reason to not maintain backward compatibility here? why not have dynamic members continue to rely on `leavegrouponclose`? (i lack the context of why this setting exists in the first place),0,0.9872753620147705
249749343,6177,stanislavkozlovski,2019-01-22T11:54:37Z,"_this is me thinking out loud. for the record i don't believe we should apply my suggestion in this pr as it would over-complicate things_ i'm wondering whether it will be worth it to think about cleaning up this bloated constructor, it takes almost 20 parameters with no defaults. the book [a link] makes a good point on how bundling up related parameters into separate classes results in code that is more domain-oriented (reads better) and is easier to mock/construct. ([a link] we have done something similar in `groupcoordinator` with its [a link] regardless, i was just interest in hearing people's thoughts on this matter",-1,0.9017898440361023
249749782,6177,stanislavkozlovski,2019-01-22T11:55:54Z,should we maintain the present tense? `member.id does not match the record on coordinator`,0,0.9946973323822021
249856731,6177,abbccdda,2019-01-22T16:25:04Z,"yea, good idea! let me update both the doc and kip",1,0.9920510649681091
249862352,6177,abbccdda,2019-01-22T16:37:27Z,"`leavegrouponclose` was set through internal config `internal.leave.group.on.close` which is by default set to true for normal consumer/connect, but set to false for streams. checking groupinstanceid could perfectly remove this internal config without backward compatibility concern (since the config is not exposed)",0,0.9940853118896484
249864434,6177,abbccdda,2019-01-22T16:42:27Z,"hey stanis, i'm also in favor of simplifying the constructor logic here. i will get a jira to resolve this issue once this diff is landed.",0,0.955001175403595
249864597,6177,abbccdda,2019-01-22T16:42:51Z,done!,1,0.6799882054328918
250660764,6177,stanislavkozlovski,2019-01-24T15:47:08Z,could we add a javadoc explaining when we expect to receive this exception and what could cause it? my understanding is that a consumer that was part of the group used a `group.instance.id-member.id` pair and later that pair got updated with a new `member.id` by another consumer? that is what i understand as a possibility from the explanation in the kip:,0,0.9945403933525085
250662548,6177,stanislavkozlovski,2019-01-24T15:50:48Z,could we update the kip as it currently says: [code block] which is not true as we can raise this for joingroup requests as well,0,0.9931708574295044
250664415,6177,stanislavkozlovski,2019-01-24T15:54:42Z,nit: should we call this empty_group_instance_id? `unknown` implies that it will be known in some time (like with member.id) but in this case it is intentionally set to none,0,0.9779437780380249
250672375,6177,stanislavkozlovski,2019-01-24T16:11:05Z,nit: could we append the comment above with `if member id required (dynamic membership)` just to make it even more clearer than static members won't be pending members (i know this is noted in `dojoingroup`,0,0.9814638495445251
250672737,6177,stanislavkozlovski,2019-01-24T16:11:59Z,nit: space between comma and `clientid`. i guess that comma could be on the line above,0,0.990851104259491
250672974,6177,stanislavkozlovski,2019-01-24T16:12:33Z,nit: `informing member` - `inform the member to`,0,0.9952641725540161
250673259,6177,stanislavkozlovski,2019-01-24T16:13:09Z,nit: `should inform` - `inform duplicate instance...` this keeps it consistent with the tense in the other comments,0,0.9940993785858154
250674281,6177,stanislavkozlovski,2019-01-24T16:15:17Z,nit: i think that it will be clearer if we define this variable inside `dojoingroup()`,0,0.9854660034179688
250678345,6177,stanislavkozlovski,2019-01-24T16:24:41Z,nit: `a un-recognized` - `an unrecognized`,0,0.9821564555168152
250678917,6177,stanislavkozlovski,2019-01-24T16:26:00Z,good call with splitting this logic into a method! :thumbs_up:,1,0.9969657063484192
250685315,6177,stanislavkozlovski,2019-01-24T16:41:01Z,should we also test `member.isstaticmember`?,0,0.9949823021888733
250686301,6177,stanislavkozlovski,2019-01-24T16:43:27Z,"we don't have `group.getstaticmemberid` in tests anywhere, i think this is a good spot to assert it works as well",0,0.9736045598983765
250688550,6177,stanislavkozlovski,2019-01-24T16:48:38Z,"not sure of the implications here, should we somehow work on removing the static member when the same `memberid` re-joins as a dynamic member? i guess it might not hurt, it will eventually get removed when the member leaves or its heartbeat fails, but we will continue to lock that `group.instance.id` with the `member.id` so new joins from static members with that group.instaince.id won't work. in other words, if a consumer becomes a static member and later re-joins as a dynamic, that `group.instance.id` is still taken. am i correct? that might not be unwanted behavior though",0,0.897270143032074
250692730,6177,stanislavkozlovski,2019-01-24T16:58:26Z,should we add a test which exercises this code path? i think it's critical for the kip that this works,0,0.990951657295227
250693889,6177,stanislavkozlovski,2019-01-24T17:01:14Z,"if it's not too much work, maybe we could add a test to ensure `member_id_mismatch` is fatal?",0,0.9907487034797668
250775259,6177,abbccdda,2019-01-24T21:02:21Z,"hey stanis, once i started the implementation, i realized that it's more clear to use the current member.id for static members instead of generating a new one, since we need member.id to track heartbeat & stuffs. i will update the kip to reflect this change. as for the `memberidmismatchexception`, i put the explanation within errors.java as error message to feedback end user.",1,0.5384209156036377
250776499,6177,abbccdda,2019-01-24T21:06:21Z,good catch! will address this.,1,0.9956117868423462
250780087,6177,abbccdda,2019-01-24T21:17:15Z,+1,0,0.9816582202911377
250780539,6177,abbccdda,2019-01-24T21:18:32Z,"yea of course, will try to see how to make that happen",0,0.9640657305717468
250781826,6177,abbccdda,2019-01-24T21:22:22Z,it should be trivial to test.,0,0.9860329031944275
250782168,6177,abbccdda,2019-01-24T21:23:22Z,lol,1,0.8464275002479553
251090933,6177,abbccdda,2019-01-25T18:39:32Z,sounds good!,1,0.9884929060935974
251091132,6177,abbccdda,2019-01-25T18:40:01Z,make sense,0,0.9741621613502502
251092116,6177,abbccdda,2019-01-25T18:41:30Z,+1,0,0.9816582202911377
251093276,6177,abbccdda,2019-01-25T18:45:00Z,"hey stanis, the condition you proposed here is not possible within the current setup. membership type transformation has to go through service restart, which will inevitably reset the member.id. so there is no way we see a dynamic member joining with its member.id points to a known static member. however this is a vaild concern, which i think by enforcing an assertion would be safer!",0,0.650092601776123
251669585,6177,Ishiihara,2019-01-29T02:16:43Z,do we want to use assert here? it will crash the broker if this happens.,0,0.9660861492156982
251683035,6177,Ishiihara,2019-01-29T03:46:22Z,"can you also add comments to the case when the member doe not have a valid protocol, why do we want to force rebalance? are we handling the case of rolling upgrades?",0,0.9947654008865356
251684242,6177,Ishiihara,2019-01-29T03:55:07Z,"as a disclaimer, i have forgotten the kafka coding style. do we use assert in code?",0,0.9874348044395447
251685753,6177,Ishiihara,2019-01-29T04:07:32Z,"this should be a fatal exception to the client, right?",0,0.9594506025314331
251686132,6177,Ishiihara,2019-01-29T04:10:02Z,this makes sense. although the name is a bit confusing.,0,0.9664888381958008
251686408,6177,Ishiihara,2019-01-29T04:12:09Z,"this handles consumer restarts, correct? in that case, the member id will be unknown.",0,0.9945328235626221
251936369,6177,abbccdda,2019-01-29T17:27:40Z,the reason to use `assert` is to prevent future implementation from breaking the existing assumption. basically known static member should never be `pending`.,0,0.993463397026062
251937129,6177,abbccdda,2019-01-29T17:29:40Z,"yes we do have examples using assert, see `oncompletejoin()` in groupcoordinator.scala",0,0.9944571256637573
251937266,6177,abbccdda,2019-01-29T17:29:58Z,yes that's right.,0,0.9855737090110779
251937638,6177,abbccdda,2019-01-29T17:30:57Z,that is correct. in `dounknownjoingroup` we don't have a known member id to process with.,0,0.9938488602638245
251939458,6177,abbccdda,2019-01-29T17:35:28Z,"usually a change of protocol indicates that the group needs to use a different strategy to allocate topic partitions. current logic is to trigger rebalance anyway to find a common agreed strategy for all current members. this diff doesn't change this part of the logic, however this is a good thing to discuss in a separate jira!",1,0.9278596043586731
260423217,6177,hachikuji,2019-02-26T18:25:01Z,"rather than adding more exceptions, should we try to refactor the code?",0,0.989762008190155
260426269,6177,hachikuji,2019-02-26T18:32:40Z,"i am wondering if `fenced_member_id` would be a clearer indication of the likely problem. in any case, we should try to give the user a helpful exception message.",0,0.9680948853492737
260429304,6177,hachikuji,2019-02-26T18:40:32Z,do we need a new error code for this case? i'm wondering if we could just use unknown_member_id.,0,0.9872491955757141
260432780,6177,hachikuji,2019-02-26T18:48:54Z,nit: a bit more intuitive to put the static member check first. maybe we can also have an `isdynamicmember` or an `isstaticmember` method.,0,0.9744190573692322
260437389,6177,hachikuji,2019-02-26T18:59:43Z,"is there a good reason to favor """" over null for indicating that no instance id is provided? i think using null would reduce the chance of providing an invalid value by mistake. in fact, we can reject the use of """" and raise an error. so if a user provides any instance id, it must be valid.",0,0.9897748231887817
260439690,6177,hachikuji,2019-02-26T19:05:19Z,"so clearly the intent is to silently fall back to the old join group logic, which means we become a dynamic member. it may be helpful having a log message indicating that this has happened. one additional note: if the brokers are later upgraded to a version that does support static membership, we don't have any logic to detect it. i think this is probably fine, just worth keeping in mind.",0,0.6258284449577332
260442064,6177,hachikuji,2019-02-26T19:10:47Z,hmm.. i think i missed this addition in the kip. how much effort would it be to pull this change into a separate pr? i think we may need some discussion.,0,0.9302586317062378
260608268,6177,abbccdda,2019-02-27T06:28:52Z,"yes, good suggestion! i got a jira to track this work [a link] will attempt to fix it once this change is merged.",1,0.9915964007377625
260609201,6177,abbccdda,2019-02-27T06:33:25Z,sounds good!,1,0.9884929060935974
260611209,6177,abbccdda,2019-02-27T06:44:15Z,maybe unknown instance id is more aligned? it's slightly different comparing with member id unknown.,0,0.9694538116455078
260611350,6177,abbccdda,2019-02-27T06:44:54Z,sounds good.,1,0.857205867767334
260886942,6177,hachikuji,2019-02-27T18:38:43Z,"our response to this error is to discard our current memberid and rejoin. that seems true regardless whether static or dynamic membership is used, so i thought we may as well make the error consistent. does that make sense?",0,0.9901044964790344
260902762,6177,abbccdda,2019-02-27T19:17:55Z,"it should be ok since the error message clearly states: `the group.instance.id is already in the consumer, however the corresponding member.id is not matching the record on coordinator`",0,0.9881680607795715
260923497,6177,abbccdda,2019-02-27T20:09:39Z,sure,0,0.9422702193260193
260935391,6177,abbccdda,2019-02-27T20:43:08Z,why couldn't we piggy-back the change in this pr? connect could also benefit from using static membership right.,0,0.988366425037384
261272738,6177,kkonstantine,2019-02-28T16:19:30Z,i agree with this is too significant to be omitted from a kip and we should probably avoid piggybacking such a change in a subtle way in this already big pr. the doc of the config below is indicative that we need to give this more thought. the connect worker is not a consumer and it doesn't use the group membership protocol in the same way. this is even more true with the changes being introduced soon with incremental cooperative rebalancing in connect. the interplay between kip-415 and static membership has not been sufficiently studied yet and therefore i'd suggest not introducing everything at once with the upcoming release.,0,0.9528123736381531
261308442,6177,abbccdda,2019-02-28T17:44:05Z,"sounds great! my original thought was that the change happens on abstract coordinator layer, so consequently we could cover all the subclass use cases (both consumer and connect). i will revert connect related changes.",1,0.9936946034431458
261350730,6177,hachikuji,2019-02-28T19:33:17Z,"possibly so, though i am not sure since it does not have local state like streams. in any case, i do not want to see this pr blocked by this discussion, so my thought was to split it out. cc any thoughts about this?",0,0.8739151358604431
261353864,6177,abbccdda,2019-02-28T19:41:27Z,"although we would react the error with same handling logic, i do see the benefit of decoupling error for now, because the error log could better help user triage during consumer incident.",0,0.9806247353553772
261403394,6177,hachikuji,2019-02-28T22:05:40Z,apologies for the late comment above. i hadn't refreshed the page and seen the updates.,-1,0.8893817663192749
261448929,6177,abbccdda,2019-03-01T01:09:11Z,it's fine :),1,0.9787351489067078
261759212,6177,hachikuji,2019-03-01T21:11:35Z,"hmm.. the unknown_member_id error is unambiguous in either case. it means that the coordinator isn't aware of the memberid. what debugging benefit is there in having another error code? the reason i'm resisting a little bit is that every error code adds more complexity to the protocol, so we should be sure it's necessary. here is the reason i find it confusing. with a provided instance id, there are two join cases: 1) joingroup(instanceid=""foo"", memberid=""""): the consumer has no memberid and needs to be assigned one. 2) joingroup(instanceid=""foo"", memberid=""xyz""): the consumer has a memberid and expects it to be valid. the group_instance_id_not_found would only make sense if it was a valid error in both cases. but it only applies to the second case. so my suggestion is that we view the second case as having a missing memberid. then the behavior is consistent for static and dynamic members.",-1,0.5531094074249268
261792206,6177,hachikuji,2019-03-01T23:41:22Z,i think it would be clearer if we represented this as `option[string]`.,0,0.9783511757850647
261792477,6177,hachikuji,2019-03-01T23:42:56Z,we generally frown on assertions. it is usually better to raise an exception with a clear message.,0,0.915126621723175
261793705,6177,hachikuji,2019-03-01T23:50:50Z,hmm.. i thought the proposal called for generation of a new memberid when a static consumer is restarted. the purpose is to fence the old static member. how do we avoid two static members from being active at the same time? perhaps i'm missing something?,0,0.9141605496406555
262186803,6177,abbccdda,2019-03-04T18:31:48Z,"i see your point jason, make sense here. the logic is the since `group_instance_id_not_found` is not covering the whole cases (like when member id is unknown), we could just bypass this check.",0,0.9190853834152222
262201770,6177,abbccdda,2019-03-04T19:12:33Z,"good catch! we have slightly diverged from the original proposal, so that we no longer kick off rebalance when static member rejoins with unknown member id. thus the generation could not be used to fence against duplicate static members. will address this problem by replacing with a new member id.",1,0.9936816692352295
262203003,6177,abbccdda,2019-03-04T19:16:05Z,"could you share more details? the reason for using assertion is to avoid creating invalid state from the code change stage. for example, we have [code block] and [code block] it would be great if you shed light on the trade-offs on these cases, thank you!",1,0.9831667542457581
262788694,6177,abbccdda,2019-03-06T04:32:21Z,i think we handle the null case when building the join group request struct?,0,0.9916937947273254
268418696,6177,abbccdda,2019-03-24T05:18:08Z,could you give me some guidance on this? thank you!,1,0.9702513813972473
268419130,6177,stanislavkozlovski,2019-03-24T05:44:40Z,"- judging by `groupmetadata#replace()`, the current behavior is to generate a new member id and return it, right? what happens if a misconfigured consumer joins with an existing, duplicate `consumer.instance.id`? it essentially kicks out the old consumer using it (by invalidating its member.id)? does the old consumer try to rejoin with its group.instance.id afterwards? we could get into a bad loop if that is the case",0,0.9059473872184753
268446363,6177,abbccdda,2019-03-24T18:33:39Z,"thats a very good question. previously my thought was to use conflict member.id to shut down duplicate consumer instances. however, this probably wont work because upon receiving unknown_member_id exception in either `syncgroup, heartbeat, offsetcommit` requests will immediately reset the generation info which includes the member.id. one approach i could think of is to restrict the caller of `resetgeneration` on client side to only joingroup logic, which means for any other types of requests after receiving unknown_member_id will be rejoining the group with their current generation info (the conflicting member.id). this should be able to help us detect the id collision and shut down duplicate member with member_id_mismatch exception. thoughts?",1,0.9445701241493225
268484117,6177,stanislavkozlovski,2019-03-25T04:13:37Z,"i don't understand, who would receive the unknown_member_id? if consumer a has `member.id=1, instance.id=one` and consumer b joins with `member.id=2, instance.id=one`, wouldn't a receive member_id_mismatch and shut down?",0,0.7120444178581238
268491234,6177,abbccdda,2019-03-25T05:16:58Z,"this won't happen automatically. the flow is like: 1. consumer a with `member.id=1, instance.id=one` is working under stable group. the static member metadata map contains kv entry `one=1`. 2. consumer b starts up, joining with same `instance.id=one` and `member.id=unknown` 3. consumer b enters `dounknownjoingroup` block and successfully gets identity `member.id=2`. the static member metadata map now updates to `one=2` 4. consumer a gets fenced by either `syncgroup, heartbeat, offsetcommit` which informs a with `unknown_member_id` error, which will trigger `resetgeneration()` on client side abstractcoordinator. 5. now consumer a rejoins with `instance.id=one` and `member.id=unknown`, repeating step 2 like b. so eventually a, b will bounce forever within the loop 2~5 unless one of them refuses to reset their assigned member.id. otherwise `member_id_mismatch` shall never trigger.",0,0.9922045469284058
268790882,6177,stanislavkozlovski,2019-03-25T18:27:48Z,"aha, yeah. we can only raise `member_id_mismatch ` in the `joingroup` request because that's the only request that has the group instance id field, right? as you proposed, i think making the consumer issue a new joingroup with the same member.id would be the better approach. otherwise, we'd probably need to add the new field to all the requests. the old functionality of resetting the generation should continue to work just fine, we'd just be adding an extra hop.",0,0.7324761152267456
270133661,6177,guozhangwang,2019-03-28T18:06:11Z,"not clear if this is right to me: from my understanding ([a link] in case 6, we will still require a member.id and hence would reply the error with `member_id_required` if it is not specified, right?",0,0.9325250387191772
270134521,6177,guozhangwang,2019-03-28T18:08:12Z,"nit: can we just do this check inside `dojoingroup`, seems unnecessary to create a boolean at the caller and pass in to `dojoingroup`.",0,0.8073862195014954
270136870,6177,guozhangwang,2019-03-28T18:13:59Z,nit for doc: .. for static members only.,0,0.9690513014793396
270137792,6177,guozhangwang,2019-03-28T18:16:15Z,`new member id will be the same`: what does this mean?,0,0.994063675403595
270139366,6177,guozhangwang,2019-03-28T18:20:10Z,"following the comment of `kafkaapis`: current logic is that if instance.id is not empty, then `requireknownmemberid` would never be required. is that intentional? i think even with non-empty instance.id, if there's no existing entry in static members, we would still return the created member.id with member_id_required to let the client re-join?",0,0.9902481436729431
270140569,6177,guozhangwang,2019-03-28T18:23:13Z,"yeah to be honest we do use assertions somewhere like mentioned in ongrouploaded; they are used to indicate ""this should never happen, and if it happens, it's a bug"". as a hind-sight we can actually just replace with if-throw-illegal-state-exception across the board so that when it happens indeed, it will crash hard but leave us a meaning stack trace.",0,0.9373499155044556
270140799,6177,guozhangwang,2019-03-28T18:23:53Z,hmm... this is not what i was thinking. maybe we can elaborate a bit more on the kip wiki?,0,0.848091185092926
270142218,6177,guozhangwang,2019-03-28T18:26:51Z,what if two consumers joining with the same instance id and member id?,0,0.9914965629577637
270236415,6177,guozhangwang,2019-03-28T23:28:56Z,"i think restricting `resetgeneration` to only joingroup request is not the best approach since we do rely on, e.g. heartbeat response to notify consumers as early as possible. on the other hand, this issue would only raise if users mis configure their `instance.id` to have two running instances to have the same id, such issue is similar to producer client that two instances mistakenly configured with the same `transactional.id` and today it is handled by letting one of them to receive a fatal error (`fenced`) and either handle it themselves or die hard -- the bottom line is, brokers would not need to be responsible for abstracting such human errors from clients. so i'd like to present an alternative proposal: 1) when receiving a join group of null member.id, but existing instance.id, create a new member.id just instead of returning the associated member.id to the client (your pr already did this anyways) 2) when receiving a join group of non-empty member.id, and existing instance.id, but is inconsistent with the static members map, return error `member_id_required`. now the only issue is what if two instances come with the same instance.id and the same member.id. i think it would not be possible for new members due to 1) since we always generate a new member.id. ----------------------- edit: after thinking about this and discussing with a bit more, i am now inclined towards the original proposal now, i.e. for all responses other than join-group request, we let it client to not reset generation / member-id immediately, but try to re-join the group again. this logic is simpler because: 1. for static members, not reseting the member-id and re-join, will then result in an fatal `member-id-mismatch`, and hence we can avoid the ping-pong scenario of two mis-configured clients keep kicking each other out by reseting the member id and re-join. 2. for dynamic members, not resetting the member-id and then rejoin will likely to get the same `unknown-member-id` again, and then it can reset generation. the cons is that this requires one more round-trip. but to me, simpler logic that does not require much complexity worth the cost, compared to my proposal above that special handles static and dynamic members on client side much more. 3. moreover, as we move on to kip-429 which will assume the assignors to be ""sticky"" somehow anyways, so even if somehow the member-id is still recognized by the group-coordinator when re-joining and the member happen to be the leader, this unnecessary rebalance triggered will be cheap. cc",0,0.9530762434005737
270628741,6177,abbccdda,2019-03-30T14:51:43Z,i believe the `member_id_required` exception is assumed to be used only for dynamic members now.,0,0.9892604351043701
270645251,6177,abbccdda,2019-03-30T23:46:18Z,"as we have discussed, we shall generate a new member id each time the static member rejoins. so the former consumer will not have the same member.id as the previous one",0,0.9941337704658508
270679831,6177,guozhangwang,2019-03-31T19:00:54Z,"ack, i will update the comment on the kip regarding the updated logic. could you update the kip wiki with that logic and also update the voting thread as well?",0,0.9937720894813538
270680233,6177,guozhangwang,2019-03-31T19:12:21Z,updated the comment in the wiki page: [a link] please double check and also update the wiki page for better illustration if that makes sense.,0,0.99124675989151
271098896,6177,abbccdda,2019-04-02T00:37:32Z,"i see, so we should choose to throw exception for most times?",0,0.9887586832046509
272441872,6177,guozhangwang,2019-04-05T04:34:35Z,yeah i'd suggest so.,0,0.9714945554733276
273648617,6177,hachikuji,2019-04-09T18:46:33Z,the thing about an empty id might be misleading since we use null to indicate absence. a few more details may also be helpful. perhaps we can say something like this:,0,0.9904369711875916
273671882,6177,hachikuji,2019-04-09T19:49:31Z,nit: perhaps quote the exact config? for example: [code block],0,0.9926457405090332
273673756,6177,hachikuji,2019-04-09T19:54:40Z,i think one of the things we have regretted is not limiting the group.id to a reduced character set. this has made acls more difficult for example. do you think it is worth being stricter about the instance id? potentially we could limit the character set to the same characters we allow for topics.,0,0.6397435069084167
273674941,6177,hachikuji,2019-04-09T19:57:54Z,let me try one more time. how about `fenced_instance_id`?,0,0.9951165914535522
273727881,6177,hachikuji,2019-04-09T22:22:41Z,hmm.. this method is also called when a call to `unsubscribe()` is made. would we not want a static member to leave in this case?,0,0.9771439433097839
273728352,6177,hachikuji,2019-04-09T22:24:20Z,this is unused since we use the generated classes now.,0,0.994164764881134
273733855,6177,hachikuji,2019-04-09T22:47:16Z,"i think we can be a little clearer in this message. how about simply ""the coordinator reports a more recent member.id associated with the consumer's group.instance.id.""",0,0.9839291572570801
273734276,6177,hachikuji,2019-04-09T22:49:14Z,"i may have asked this before, but do we want to use empty to indicate no group instance id? alternatively, we can let the `groupinstanceid` type be nullable in the schema and we can use null. this would be consistent with the config.",0,0.9944230914115906
273737121,6177,hachikuji,2019-04-09T23:03:22Z,"i'm just saying that it would be clearer to represent the difference between static and dynamic members by using an optional field. otherwise you have to dig into the code to make sure the uses are all safe. for example, we have a bunch of cases below where we are using the empty instance id in calls to `hasstaticmember`. this opens the door to bugs if we are not really careful with our checking. the nice thing about options is that they force us to check for absence.",0,0.9704639911651611
273738245,6177,hachikuji,2019-04-09T23:08:38Z,nit: you can drop the `s` since there are no substitutions.,0,0.9935392737388611
273738796,6177,hachikuji,2019-04-09T23:11:29Z,can you elaborate on this comment? i'm not sure i understand the problem.,0,0.652077317237854
273739061,6177,hachikuji,2019-04-09T23:12:49Z,i think we should not try to overload `requireknownmemberid`. it makes this pretty confusing.,-1,0.553811252117157
273739420,6177,hachikuji,2019-04-09T23:14:32Z,"yes, exactly. we like stack traces and nice error messages! a lot of these impossible states have a way of becoming more possible over time.",1,0.9953858256340027
273742089,6177,hachikuji,2019-04-09T23:27:52Z,maybe slightly nicer: [code block],0,0.9793927073478699
273743469,6177,hachikuji,2019-04-09T23:35:19Z,we did get some flack in 2.1 for a change to this format. the problem is that we cannot downgrade once the new format is in use. we will probably have to mention this in the upgrade notes at a minimum. unfortunately i don't see any great options at the moment to avoid this. perhaps we should just switch to json.,-1,0.8704443573951721
273744396,6177,hachikuji,2019-04-09T23:40:22Z,i'm trying to think through the implications of this. we are silently discarding the instance id which means that replicas won't know about it. the member will be considered a static member until there is a coordinator change. then it will suddenly become dynamic again and i think that would trigger this assertion: [a link] i think we probably need to avoid using the static membership logic entirely until the ibp supports it.,0,0.9582841992378235
274084303,6177,abbccdda,2019-04-10T17:53:39Z,sure!,0,0.972205400466919
274157146,6177,abbccdda,2019-04-10T20:56:44Z,thanks!,1,0.8631753921508789
274157459,6177,abbccdda,2019-04-10T20:57:38Z,sounds good,1,0.8904690742492676
274162476,6177,abbccdda,2019-04-10T21:11:41Z,fixed. i was about to say the new heartbeat shall be scheduled with new member id.,0,0.9901356101036072
274163062,6177,abbccdda,2019-04-10T21:13:40Z,"yes, for static member we shall never require a rejoin, because its identity is declared by the instance id.",0,0.9924401044845581
274163632,6177,abbccdda,2019-04-10T21:15:25Z,thanks!,1,0.8631753921508789
274261445,6177,abbccdda,2019-04-11T05:23:58Z,"i see, we could discuss offline some time for a holistic solution.",0,0.9882683157920837
274261996,6177,abbccdda,2019-04-11T05:27:51Z,"that sounds reasonable. i'm not sure i'm fully following here because unless broker upgrades to latest, the group instance id should not include the join group because of automatic request downgrade.",0,0.9817173480987549
274263375,6177,abbccdda,2019-04-11T05:35:38Z,"yea, updated explicitly in the kip",0,0.9930832386016846
274263890,6177,abbccdda,2019-04-11T05:38:46Z,"ugh, `empty_group_instance_id` will just be empty string right?",-1,0.7570545673370361
274265007,6177,abbccdda,2019-04-11T05:45:00Z,"let me check the code real quick, do you have good example for character set check? right now what i found on admin client is sth like: [code block] which is not very useful.",0,0.9287335872650146
274265965,6177,abbccdda,2019-04-11T05:50:52Z,"i quickly checked `unsubscribe()` use cases, and there are mainly two: 1. illegal topic/partition data, i.e empty topic partitions to subscribe 2. consumer self managed membership (subscription) i think it makes sense to make static member behavior consistent in these two cases, because the effect of leaving is minimal.",0,0.9867451786994934
274266402,6177,abbccdda,2019-04-11T05:53:18Z,this is just for the sake of reducing code duplication and keep if-else blocks intact.,0,0.9883131384849548
274267268,6177,abbccdda,2019-04-11T05:57:41Z,i don't think that comment is needed here. it's just an edge i caught during my experiment.,0,0.9796978235244751
274667775,6177,abbccdda,2019-04-11T21:16:28Z,"we still need an empty string field to make sure we could correctly serialize the member metadata. also checking null for string is not very intuitive in java compared with scala option, so my suggestion is to keep using empty string on client side for now.",0,0.9891290068626404
274731954,6177,guozhangwang,2019-04-12T01:19:13Z,the topic validation logic can be found at `org.apache.kafka.common.internals.topic`,0,0.9953533411026001
274732699,6177,guozhangwang,2019-04-12T01:25:05Z,what's `ibp`?,0,0.9932777285575867
274750177,6177,abbccdda,2019-04-12T03:39:32Z,inter broker protocol,0,0.992392897605896
275141269,6177,abbccdda,2019-04-14T05:38:54Z,sounds like a good idea!,1,0.9833879470825195
275591198,6177,hachikuji,2019-04-16T00:27:22Z,"i'm not sure i follow this. we _can_ serialize null. my point is we should try to be consistent. null is a good way to represent something which is missing. java also has an `optional` type which we could use, but we'd still have to decide what gets transmitted in the protocol.",0,0.7159146666526794
275592368,6177,hachikuji,2019-04-16T00:34:39Z,nit: this could probably be implemented more concisely with a regex.,0,0.9864383935928345
275593388,6177,hachikuji,2019-04-16T00:40:57Z,this method doesn't really make sense if `groupinstanceid` is `none`. wouldn't it clearer to force the caller to ensure that that is the case? same for the other methods below.,0,0.985009491443634
275595976,6177,hachikuji,2019-04-16T00:58:51Z,"we expose the new joingroup protocol as soon as the binary is updated. the client will begin using it. that itself is fine, but it is not safe for the broker to use the static member logic until we are sure that all brokers support it, as indicated through the ibp. otherwise, the case i mentioned is possible. we seem to have removed the assertion i mentioned above, but i am still not sure the logic is correct. the simplest option would be to set `groupinstanceid` to `none` if the ibp is below `kafka_2_3_iv0`.",0,0.9855024814605713
275596088,6177,hachikuji,2019-04-16T00:59:38Z,shouldn't this be `kafka_2_3_iv0`? do we have any tests?,0,0.9947220087051392
275596574,6177,hachikuji,2019-04-16T01:02:33Z,why not let `groupinstanceid` be represented as an `option` inside `membermetadata` as well?,0,0.9930608868598938
275597196,6177,hachikuji,2019-04-16T01:06:07Z,nit: parenthesis are unneeded,0,0.9891019463539124
275607536,6177,abbccdda,2019-04-16T02:13:53Z,i tried one time and it failed due to serialization issue. let me try one more time.,0,0.976209819316864
275630797,6177,abbccdda,2019-04-16T05:07:57Z,"to make the full e2e consistency, we should consider supporting optional[string] type for part of auto-mated protocol in `joingrouprequest.json` and other protocol classes. otherwise, we still need to have `empty_instance_id` as a special type to handle null case in the serde of request.",0,0.9942210912704468
276082373,6177,abbccdda,2019-04-17T05:19:07Z,good catch!,1,0.9941828846931458
276083793,6177,abbccdda,2019-04-17T05:28:24Z,"i think adding an assertion here would be helpful. would be messy if we do null check in caller every time when we call `replace`, `addstaticmember` and `getstaticmemberid`, what do you think?",0,0.9634462594985962
276084326,6177,abbccdda,2019-04-17T05:31:37Z,"sounds good, i think it's probably better to do the refactoring in one diff for both topic and group instance id.",1,0.682167649269104
276085073,6177,abbccdda,2019-04-17T05:35:56Z,addressed in groupcoordinator.scala,0,0.9945341348648071
276745404,6177,guozhangwang,2019-04-18T16:45:46Z,how about rename it to `maybereplacegroupinstance` and do the check in the callee and make it no-op if `groupinstanceid` is empty then?,0,0.9948306679725647
276749603,6177,guozhangwang,2019-04-18T16:57:47Z,"the automated protocol supports `nullable string` (it will be serialized and stored as `0xffff` over the wire), and hence could we encode null for this instance id, and then: 1) on client side we can have this parameter nullable, and upon constructing join-group request it will be auto-serialized. 2) on broker side we can have this parameter as `option[string]`, upon deserializing if the returned value is null construct the field as `none`.",0,0.9934117197990417
276750288,6177,guozhangwang,2019-04-18T16:59:51Z,"i think on the broker side we should be using `option` in scala to be consistent with other fields (see my other comment). on the client side though, it is true that since we only recently dropped j7, `optional` is not commonly used elsewhere, and i think having it just as a nullable field is fine (we can, do a universal refactoring on client side using `optional` in another pr but this does not need to be done in this scope).",0,0.9792176485061646
276827600,6177,abbccdda,2019-04-18T20:46:28Z,thanks for the info!,1,0.8781626224517822
276828558,6177,hachikuji,2019-04-18T20:49:21Z,"sorry, if this wasn't clear, but here is what you need to add to the schema definition. see the `nullableversions` field. [code block] in the common tongue, 0xffff is -1 :wink:. this is how we represent null arrays and strings.",-1,0.8498218655586243
276836547,6177,abbccdda,2019-04-18T21:14:10Z,"yea, i just figured it out, thank you!!",1,0.9966532588005066
276864867,6177,abbccdda,2019-04-18T23:21:00Z,i agree with renaming but feel slightly against second proposal. i think the goal is to avoid people from passing in null group.instance.id in the code level.,0,0.9279123544692993
277374681,6177,guozhangwang,2019-04-22T17:59:41Z,"i've thought about this a bit more, and also searched in github: [a link] i think a third common case is to use a temporary consumer for its apis, like get offset by timestamp, get log end offset etc; generally speaking for temporary consumer case, they should not use static members (and by default it would not be the case). so i think it really boils down to: for static members, do we consider the admin request kicking it out of the group be the only appropriate way for it to leave in time or not? i.e. even if the consumer shuts down itself, it should not be considered as ""i want to leave"" but another request has to be made to effectively kick him out.",0,0.9738187193870544
277477265,6177,guozhangwang,2019-04-22T23:55:45Z,should we remove this const string then?,0,0.9939630627632141
277478955,6177,guozhangwang,2019-04-23T00:05:31Z,should we still need these calls if we can get rid of const `empty_group_instance_id` with optional?,0,0.9910804629325867
277480160,6177,guozhangwang,2019-04-23T00:12:40Z,nit: i think it worth being an `info` since this should not happen frequently and hence each time it happens we should pay attention.,0,0.8534345030784607
277480223,6177,guozhangwang,2019-04-23T00:13:09Z,also: better include the groupinstanceid as well?,0,0.9944396018981934
277480459,6177,guozhangwang,2019-04-23T00:14:29Z,"as we discussed before, better change `assert` to `throw illegalstateexception` with a meaningful error message; ditto below.",0,0.9940350651741028
277481055,6177,guozhangwang,2019-04-23T00:18:13Z,for all the three callers of it: two already checks `member.isstaticmember` and one has the assert already. so i'd suggest we pass in `groupinstanceid: string` as parameter directly from caller.,0,0.9931544065475464
277481439,6177,guozhangwang,2019-04-23T00:20:36Z,"hmm.. does this function only have one caller who's already checked `group.hasstaticmember(groupinstanceid)`? in this case i think we can just name it `replacegroupinstance` as it should always replace unless we have a bug. originally i was thinking there are multiple callers of it, and some may really turn into a no-op since it is not for static members, but now the call trace seems to indicate only one caller.",0,0.9718747735023499
277481592,6177,guozhangwang,2019-04-23T00:21:38Z,just to confirm: is `map.remove(null)` a no-op with no side-effect?,0,0.9929721355438232
277481815,6177,guozhangwang,2019-04-23T00:22:58Z,nit: we can just do `else if` and `else`.,0,0.9853019714355469
277482417,6177,guozhangwang,2019-04-23T00:26:46Z,if this is nullable we can get rid of `empty_group_instance_id` right?,0,0.9909427762031555
277482886,6177,guozhangwang,2019-04-23T00:29:58Z,"actually, for all such `setgroupinstanceid` calls we can by default remove it since without any setters is equal to using `setgroupinstanceid(null)` right?",0,0.9927024841308594
277483066,6177,guozhangwang,2019-04-23T00:31:15Z,do we have unit test coverage on compatibility? i.e. old formatted data can be loaded with new versioned byte code with new fields set to default (null) values?,0,0.9948188662528992
277483221,6177,guozhangwang,2019-04-23T00:32:14Z,i think we should remove this part from streams first. there are some open questions that i've in mind and needs to potentially create a new streams kip for it. cc,0,0.9861857891082764
277484517,6177,guozhangwang,2019-04-23T00:41:13Z,"i think `null` default value should still work, e.g. the group-id used `null` as default values above.",0,0.986553966999054
277503483,6177,abbccdda,2019-04-23T02:57:03Z,the tricky thing is that we couldn't set the key to `null` in `verifiableconsumer` because it will throw exception.,0,0.8739804625511169
277503751,6177,abbccdda,2019-04-23T02:59:19Z,sounds good,1,0.8904690742492676
277503848,6177,abbccdda,2019-04-23T03:00:04Z,"my bad, didn't see the upper comment.",-1,0.991962730884552
277513354,6177,abbccdda,2019-04-23T04:20:25Z,"we could remove the assertion here, but i guess we still need to throw exception since new caller may forget to check it.",0,0.9887986779212952
277515294,6177,abbccdda,2019-04-23T04:36:42Z,yep!,1,0.5487254858016968
277515412,6177,abbccdda,2019-04-23T04:37:41Z,we don't,0,0.7383074164390564
277813801,6177,abbccdda,2019-04-23T18:28:46Z,mind giving me an example for compatibility test? i look around and haven't found one good example.,0,0.9077690243721008
277912948,6177,abbccdda,2019-04-23T23:51:03Z,"after offline discussion with , we sort out following key points: 1) will the static membership affect unit test independence? short answer: no. the reason is because without explicitly setting the `client.id` config for stream instances, the static member id will be changed throughout the restarts since we add a random hash to `client.id`. it will essentially behave the same as current dynamic membership. also one another confusion was that we are changing *max session timeout cap* to 30 min, instead of *default session timeout* which will remain as 10 s for either static or dynamic member. so the out-dated members will be kicked out in 10 seconds as expected. 2) the concern about thread id change throughout restarts. this is a valid concern in case where we configure two stream jobs within one jvm, so the threads will sometime shuffle from job a to job b, which unfortunately breaks the expectation of persistent thread-id numbers. this, however, shall not block us from enabling static membership for streams because the worst case is just doing repetitive rebalances as current dynamic membership. we could choose to address this application layer problem in another diff. the conclusion is that, it does no harm to enable static membership on streams, we are just realizing there are more subtle cases we need to handle. let me know if this addresses your concern, thanks!",0,0.9784058332443237
277927199,6177,guozhangwang,2019-04-24T01:28:38Z,that sounds good. we can check that the passed in `string` (not `option[string]` for simplicity since all current callers actually can pass in the string parameter) is not null and throw otherwise.,0,0.7479684948921204
277927290,6177,guozhangwang,2019-04-24T01:29:16Z,is that the case?,0,0.991124153137207
277927492,6177,guozhangwang,2019-04-24T01:30:40Z,"you can for example take a look at this pr: [a link] when we update the consumer protocol, we added unit test to make sure old versioned code can still deser it, and similarly in this case, we need to change that new versioned code can still deser old versioned data.",0,0.9933214783668518
277927851,6177,guozhangwang,2019-04-24T01:33:11Z,"i'd still suggest we add streams logic leveraging static members in this pr for further discussion than rush it in this pr. for people who wants to use the feature in streams asap, they can still do it by manually set the group.instance.id via consumer config prefix in streamsconfig. but we need to think through all the cases before making it turned on by default in streams.",0,0.987764298915863
277950657,6177,abbccdda,2019-04-24T04:21:56Z,"i see. however it's currently not possible, since they need to have access to stream internal to set `group.instance.id` config.",0,0.9931895732879639
277953016,6177,abbccdda,2019-04-24T04:40:56Z,thanks!,1,0.8631753921508789
277953572,6177,abbccdda,2019-04-24T04:45:48Z,i feel we could keep option[string] in the function parameters. the reason is for consistent handling of this piece of information in groupcoordinator until we actually extract the string for internal data structure update. the other approach would be using the case switch here which is more option friendly. wdyt?,0,0.9852573275566101
278737190,6177,guozhangwang,2019-04-25T21:22:33Z,"got it, that makes sense. i think we would consider fixing the following the static stream-thread suffix number first, and then requiring users who wants to turn on static membership to specify the client-id then (otherwise internally created client-id would never be the same across lives of a streams instance). i saw you've created jira tickets for these tasks.",0,0.9416354894638062
278737600,6177,guozhangwang,2019-04-25T21:23:36Z,"after a second thought i think i agree with you, it's not worth optimizing the parameter while giving up consistency in call traces.",0,0.9641296863555908
278739994,6177,guozhangwang,2019-04-25T21:31:03Z,we should check that `staticmembers` is also empty by default when deserializing from old versions.,0,0.9934325218200684
109102899,2772,michaelandrepearce,2017-03-31T07:29:53Z,"accidental formatting, no need, need to revert.",0,0.9409545660018921
109102944,2772,michaelandrepearce,2017-03-31T07:30:14Z,remove extra space,0,0.9927523136138916
109102987,2772,michaelandrepearce,2017-03-31T07:30:33Z,remove extra un-needed whitespace,0,0.9926247000694275
109103041,2772,michaelandrepearce,2017-03-31T07:30:54Z,is this needed?,0,0.9945470094680786
109103189,2772,michaelandrepearce,2017-03-31T07:31:53Z,"remove accidental, whitespace formatting change.",0,0.9801948070526123
109141852,2772,jeroenvandisseldorp,2017-03-31T11:37:45Z,"you use pretty much everywhere k, v, h as parameter order, so would be more consistent to do so here too.",0,0.990939736366272
109150487,2772,michaelandrepearce,2017-03-31T12:39:53Z,"good spot, and its a very good point, will adjust to make it more consistent. thanks :)",1,0.9972877502441406
109287859,2772,radai-rosenblatt,2017-04-01T16:01:42Z,"nit pick - returns all headers _in the order they were added in_, also clarify if returns null or some empty collection if nothing found",0,0.9951460957527161
109287981,2772,radai-rosenblatt,2017-04-01T16:09:02Z,header doesnt allow for a null key. should lastheader(null) throw or just return nothing?,0,0.980600893497467
109288040,2772,radai-rosenblatt,2017-04-01T16:12:35Z,can this inner class be made static? if so would save an outerclass.this call above,0,0.9948463439941406
109292288,2772,michaelandrepearce,2017-04-01T19:32:43Z,"yes this one could have been, it was using java 8 feature previous, was simply quickly removing our usage of java 8, as kip 118 isn't in master and thus would cause a build failure as still needing java 7 support atm. i will change to static inner class for now. didn't actually even need the recordheaders.this call it the method call filter was in scope, but will make it a static inner class. n.b the other closeaware iterator we cannot make static inner, as it needs reference to isclosed, unless we made that an atomic which would be more of an overkill imo.",0,0.9722201228141785
109292305,2772,michaelandrepearce,2017-04-01T19:33:15Z,"good point, behaviour should be as per creating a header with a null, and throw.",1,0.8649163246154785
109292344,2772,michaelandrepearce,2017-04-01T19:34:00Z,"will update java doc with additional detail, was just copying java doc that was as per kip page for the interfaces.",0,0.9948004484176636
110308619,2772,becketqin,2017-04-07T02:56:08Z,can we use standard java doc in the public interface?,0,0.9955962300300598
110308937,2772,becketqin,2017-04-07T03:00:14Z,this java doc seems a little misleading. even for kafka 0.11 we can still use this constructor to construct a consumer record although the headers is empty. and the message format will still be in 0.11.,0,0.8046403527259827
110310796,2772,becketqin,2017-04-07T03:27:30Z,it is a little unfortunate that we have to do this hack just to maintain the backwards compatibility of the serializer and deserializer interface. there were some discussion about this on the side channel that we hope can start to use java 8 so a default implementation can be added to the existing serde interface. personally i think it is fine to just start to set sourcecompatibility to 1.8 in this patch and drop support for java 1.7 given that kip-118 has already passed. this way we can avoid this hack. what do you think?,-1,0.927636444568634
110314115,2772,becketqin,2017-04-07T04:22:00Z,can we rename this to `closeheaders`?,0,0.9957648515701294
110314866,2772,becketqin,2017-04-07T04:34:55Z,is this change intentional? this change will cause an additional memory copy in `defaultrecord.readfrom()`.,0,0.9937289953231812
110315042,2772,becketqin,2017-04-07T04:37:46Z,it seems we already has a `record.empty_headers`. can we reuse that?,0,0.9936503767967224
110315300,2772,becketqin,2017-04-07T04:41:46Z,"""recordheaders has been closed.""",0,0.9942559599876404
110315649,2772,becketqin,2017-04-07T04:47:10Z,it is a little tricky here because we would require the order of the header to be the same as well. i am wondering if this would be a little too demanding.,0,0.6730513572692871
110316068,2772,becketqin,2017-04-07T04:53:50Z,see previous comment about memory copy.,0,0.9930260181427002
110316561,2772,becketqin,2017-04-07T05:02:32Z,is there any special consideration of creating a mutable new header here?,0,0.9935943484306335
110316924,2772,becketqin,2017-04-07T05:08:16Z,do we want to close the headers here?,0,0.9936822652816772
110319166,2772,michaelandrepearce,2017-04-07T05:39:29Z,"the discussion in the kip seemed to come to conclusion we only want to close them on produce. as in consume if you consume you may wish via the interceptors to manage the headers again, e.g. remove it. on the front of mutability if you change the headers but consumed again the headers would be per the original messages as it would be created again. this is different to the producer record issue, which is why we closed that during send.",0,0.9922548532485962
110319402,2772,michaelandrepearce,2017-04-07T05:42:32Z,"so here the only thing we do is create the header object which is string, byte[]. as per kip. should note the string is memory copied already. as such we can make this a buffer but a line or two down when we hand over to the header object it would be a byte[]. also same comment as above, in kip we agreed on interface to be byte[] we can change this to a bytebuffer, and personally not opposed to this, just we should note, it would be a change to the kip",0,0.9900541305541992
110319457,2772,michaelandrepearce,2017-04-07T05:43:11Z,"yes we could, alas the import check would fail, i can amend the import check and reuse it. i will do this",0,0.9430072903633118
110319516,2772,michaelandrepearce,2017-04-07T05:44:06Z,"sure, good point, was just copying off the kip document. i will do this.",1,0.94687819480896
110319547,2772,michaelandrepearce,2017-04-07T05:44:24Z,sure :). i will do this,1,0.9937560558319092
110319762,2772,michaelandrepearce,2017-04-07T05:47:12Z,"so this is to the equality of arraylist equals. i believe therefor we get this for free. as per java doc compares the specified object with this list for equality. returns true if and only if the specified object is also a list, both lists have the same size, and all corresponding pairs of elements in the two lists are equal. (two elements e1 and e2 are equal if (e1==null ? e2==null : e1.equals(e2)).) in other words, two lists are defined to be equal if they contain the same elements in the same order. we should also note ordering is important, as noted in kip discussion as we use the ordering for add/lastheaders, as such if i had two headers but for the same key the order was different, lastheaders would return differently, therefor i would argue the headers are there for not equal.",0,0.9814949631690979
110319886,2772,michaelandrepearce,2017-04-07T05:49:07Z,"this is inline with the comment left when the constructor for timestamp was added. it also is the same, it created a valid / correct message format still, and you can still use the constructor. see constructor directly above, its pretty much a copy and paste job, with just slight modification. constructor comment added when 0.10 changes done. * creates a record to be received from a specified topic and partition (provided for * compatibility with kafka 0.9 before the message format supported timestamps and before * serialized metadata were exposed). * our new constructor comment with 0.11 changes, following same lines. * creates a record to be received from a specified topic and partition (provided for * compatibility with kafka 0.10 before the message format supported headers).",0,0.981745183467865
110320089,2772,michaelandrepearce,2017-04-07T05:51:45Z,"yes there was. so that it is set so if someone in their consumer interceptors consumes and needs to modify headers. also recordheaders uses array list, which does an empty array memory saving, so really the over head for cleaness of code and keeping in line with producerrecord, for empty headers the overhead is just the recordheaders object, no real sizeable data/memory. if this really is of a concern, we could do null and then have a if null create lazily on the headers() method. though we wouldn't be able to make the same saving on producerrecord as we call the headers() method on send to get them, if we wanted to do the same we would need to introduce a hasheaders() or headerssize() method on the producer/consumer record, so you can avoid calling headers() and initialising the object. also trying to make this saving would cause complexity where we want to provide headers to the ser/des for the linkedin use case's [a link] where they may need or want access to headers, we need to pass headers object, if not to force it to handle null headers also which would uk.",0,0.9852522611618042
110321627,2772,michaelandrepearce,2017-04-07T06:08:18Z,"yes it was, as the kip interface and constructor for a header is byte[]. when we create the headers in producer it will be a byte[] as such this would not be any memory copy, like wise on consume when the header is read a byte[] would need to be returned as such any saving would be negated. if we want bytebuffer, then it would be best to change that you construct headers with a bytebuffer value, and like wise byte[] value(), changes to bytebuffer value(). im not opposed to this, just isn't as agreed in kip, we would update the kip if we changed this.",0,0.9713888168334961
110321649,2772,michaelandrepearce,2017-04-07T06:08:36Z,sure. i will do this.,1,0.5536143183708191
110321692,2772,michaelandrepearce,2017-04-07T06:09:16Z,"yes totally agree, and as per commit comment, this was for lack of java 8 optimisation.",0,0.9458749294281006
110335355,2772,michaelandrepearce,2017-04-07T07:55:24Z,"on seeing what we can do to try alleviate your concern as much as possible we can make it so it uses bytebuffer, again we should note though, that on header.value() will incure a memory copy still, as simply we move when this copy occurs. as such its only incurred if the header is read.",0,0.9899550676345825
110335364,2772,michaelandrepearce,2017-04-07T07:55:29Z,"on seeing what we can do to try alleviate your concern as much as possible we can make it so it uses bytebuffer, again we should note though, that on header.value() will incure a memory copy still, as simply we move when this copy occurs. as such its only incurred if the header is read.",0,0.9899550676345825
110414387,2772,ijuma,2017-04-07T15:17:32Z,"as i explained here [a link] we need to update our system tests infrastructure to run with java 8 before we can make the switch. it may take a bit of time to get that done, so my suggestion was to do what can be done with java 7 in the initial pr and file a jira for the follow-up work once the java 8 switch happens. that way, we can make progress instead of being blocked.",0,0.9845852255821228
110428445,2772,michaelandrepearce,2017-04-07T16:22:17Z,"ok, so i have pushed a commit to revert back to java 7 (again) so this pr could be merged to make progress. i have locally stashed the java 8 changes for later.",0,0.9912365674972534
112817815,2772,hachikuji,2017-04-22T20:16:43Z,nit: is this needed?,0,0.9847797751426697
112817938,2772,hachikuji,2017-04-22T20:22:21Z,nit: could we use `record.empty_headers` instead of `null` for all of these?,0,0.9872036576271057
112817953,2772,hachikuji,2017-04-22T20:23:03Z,we should probably update the producer and consumer config documentation to mention these new interfaces. it should probably also be added to the kip.,0,0.9941125512123108
112818039,2772,hachikuji,2017-04-22T20:26:11Z,"does this need to be public? not much harm, but maybe unnecessary.",0,0.6645317077636719
112818193,2772,hachikuji,2017-04-22T20:32:52Z,"could replace this constructor with `this(key, utils.wrapnullable(value))`?",0,0.9941775798797607
112818215,2772,hachikuji,2017-04-22T20:34:10Z,maybe we should cache this value and potentially set the buffer to null?,0,0.9866459369659424
112818309,2772,hachikuji,2017-04-22T20:39:09Z,"if we added another method `add(string key, byte[] value)`, would there be any need to expose a concrete implementation of `header`?",0,0.9934426546096802
112818423,2772,hachikuji,2017-04-22T20:45:15Z,"if we want this package to be included in the javadocs (i.e. if we want it to be exposed to users), then we need to update `build.gradle`.",0,0.9940869808197021
112819053,2772,michaelandrepearce,2017-04-22T21:17:13Z,"no its not, was just left in by accident, good spot, will remove.",1,0.8832970261573792
112819065,2772,michaelandrepearce,2017-04-22T21:17:59Z,"makes sense, will update.",0,0.9842320680618286
112819106,2772,michaelandrepearce,2017-04-22T21:19:55Z,"agreed, was hoping that we get to have source in java 8 and thus then don't need these class's. as discussed previously we will do the java 8 changes in separate pr, once kip 118 is implemented.",0,0.9684865474700928
112819124,2772,michaelandrepearce,2017-04-22T21:21:09Z,"agreed. though based on below comment on note on cache and set buffer to null, then for the byte[] constructor, we should then not wrap but simply set the byte array value.",0,0.9866700768470764
112819135,2772,michaelandrepearce,2017-04-22T21:21:43Z,"a nice optimisation, this actually saves us on the produce side, as we don't then need to wrap the byte array and then unwrap it again.",1,0.9634277820587158
112819183,2772,michaelandrepearce,2017-04-22T21:24:22Z,"agreed, i recall during the kip discussion we originally had add(string key, byte[] value) but someone (will need to trawl the history) requested it to be add(header header). im happy having both, as such will add it, and once merged to master will update the kip document and send out a notification.",1,0.9321205019950867
112819919,2772,michaelandrepearce,2017-04-22T22:14:22Z,"no it doesn't. again anyhow once kip 118 (java 8) is done, will raise separate pr, which this would be removed anyhow. this is so we can merge/commit to master with current java 7.",0,0.9924314022064209
112821175,2772,michaelandrepearce,2017-04-22T23:27:53Z,"thanks, will update",1,0.5314746499061584
113302283,2772,hachikuji,2017-04-25T20:31:46Z,"since we now only have the `header` and `headers` classes public, maybe we could locate them under `common`?",0,0.9934520721435547
113338574,2772,michaelandrepearce,2017-04-25T23:51:50Z,"i was purposely wanting to avoid that and use packaging structure to keep things tidy/grouped together as is nicely done with other parts, else the common package level (one level up) would become a dumping ground over a period, if that approach was constantly taken. this is simply allowing package org.apache.kafka.common.record import org.apache.kafka.common.header",0,0.9814234375953674
113436597,2772,ijuma,2017-04-26T12:22:16Z,this constructor doesn't take a timestamp. is that intentional?,0,0.990358293056488
113438319,2772,michaelandrepearce,2017-04-26T12:31:15Z,"yes it was, there is a constructor line 66, that does take timestamp, which this one delegates to. [code block]",0,0.9944527745246887
113439712,2772,ijuma,2017-04-26T12:38:23Z,"yes, but one takes `headers` and the other takes `iterable ` and it's unclear why that is so.",0,0.9893761873245239
113455023,2772,michaelandrepearce,2017-04-26T13:46:11Z,"ah no that is a mistake it should be `iterable `, gotcha now, good spot, will correct it.",1,0.8547026515007019
113456401,2772,michaelandrepearce,2017-04-26T13:51:12Z,fix committed.,0,0.9709958434104919
113772475,2772,hachikuji,2017-04-27T18:42:20Z,fair enough.,0,0.9633647203445435
113832198,2772,ijuma,2017-04-28T00:38:49Z,"nit: we typically don't use all caps in our javadocs. it's ok to just say ""all headers"", i think. there are a few cases like this.",0,0.9850273132324219
113832491,2772,ijuma,2017-04-28T00:41:59Z,"i don't think this comment is accurate. [code block] and `arrays.aslist.toarray`: [code block] i'd just remove the comment. the code is implemented as one would expect, we don't need to worry about java's implementation details.",0,0.967719554901123
113832530,2772,ijuma,2017-04-28T00:42:27Z,"no need for this comment, it just repeats what the code is doing.",0,0.988430380821228
113833156,2772,ijuma,2017-04-28T00:49:14Z,"as you can see in the code i pasted in the other comment, the first thing that the constructor does is call `c.toarray` so it actually depends on the collection. `arraylist` does `arrays.copyof` today, but could be something else later. i think a single comment at the top saying ""use efficient copy constructor if possible, fallback to iteration otherwise"" is clear and not dependent on implementation details.",0,0.9664007425308228
113833598,2772,ijuma,2017-04-28T00:53:59Z,`headers` is missing from here and from the other `append` that was added.,0,0.9924038052558899
113833664,2772,ijuma,2017-04-28T00:54:42Z,`front` seems to be redundant,0,0.9905709028244019
113833820,2772,ijuma,2017-04-28T00:56:07Z,nit: `standardcharsets.utf_8` is nicer than `charset.forname`,0,0.9854853749275208
113834118,2772,ijuma,2017-04-28T00:58:41Z,"it would be good to exercise a few more methods after `remove` is called. also, it would be good to interleave `add` and `remove` calls in one test.",0,0.9916845560073853
113834436,2772,ijuma,2017-04-28T01:01:31Z,"i was thinking about this and maybe `close` is not the right name. because we can still use the class, we simply cannot mutate it any more. the name that came to mind is `seal`, but maybe that's not clear either. we could do the boring `closeforupdates` or something like that. thoughts?",0,0.8438560962677002
113834747,2772,ijuma,2017-04-28T01:04:50Z,we should check the keys too in every case in this test.,0,0.9923298954963684
113835397,2772,michaelandrepearce,2017-04-28T01:12:53Z,"close, is what was the end method, in the kip discussion, and is naturally for java what you tend to implement closable interface for.",0,0.9916062355041504
113835523,2772,michaelandrepearce,2017-04-28T01:14:22Z,agreed.,0,0.954565167427063
113835615,2772,ijuma,2017-04-28T01:15:30Z,"this is an internal method, so it's really part of the kip. in java, you typically can't use a class after you call `close()`, so i don't really agree. for example, using try with resources doesn't make sense for this class.",0,0.9421350955963135
113836292,2772,ijuma,2017-04-28T01:22:33Z,"one more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.",0,0.9902940988540649
113837107,2772,michaelandrepearce,2017-04-28T01:33:15Z,"it is true, that as you say, it is meant to be no longer useable. how about setreadonly() inline with file.setreadonly() from java api's",0,0.9943932294845581
113837206,2772,michaelandrepearce,2017-04-28T01:34:34Z,will remove,0,0.9864876866340637
113837251,2772,michaelandrepearce,2017-04-28T01:35:05Z,will add,0,0.9736777544021606
113837325,2772,michaelandrepearce,2017-04-28T01:36:00Z,laptop died as i was committing this will do tomorrow now. could we merge? and i open another pr tomorrow?,0,0.851146936416626
113837349,2772,michaelandrepearce,2017-04-28T01:36:20Z,will enhance,0,0.9540045857429504
113837395,2772,michaelandrepearce,2017-04-28T01:36:57Z,"sure, more test ideas always welcome",1,0.5600537061691284
113869779,2772,michaelandrepearce,2017-04-28T07:34:41Z,added,0,0.8435775637626648
113869831,2772,michaelandrepearce,2017-04-28T07:34:58Z,added,0,0.8435775637626648
95493943,2330,ewencp,2017-01-11T01:08:45Z,nit typo: mey,0,0.6609639525413513
95495767,2330,ewencp,2017-01-11T01:25:32Z,it seems like the channelbuilder implementations respect the possibility that these are null but we always seem to pass `none` if we don't want an implementation? did the intended usage just diverge during development of the pr? should we stick to only one or the other?,0,0.985759437084198
95502827,2330,ewencp,2017-01-11T02:37:23Z,"nit throughout -- all lowercase is fine for stuff like comments, but for user-facing messages, it'd be nice to emphasize proper capitalization, grammar, etc.",0,0.9624068140983582
95503095,2330,ewencp,2017-01-11T02:41:00Z,"not critical since these aren't public apis, but there are a bunch of references to methods in these javadocs that could be ``ified.",0,0.9690966010093689
95503684,2330,ewencp,2017-01-11T02:48:51Z,it seems this class isn't even used anywhere. maybe we should just remove it entirely?,0,0.9731854200363159
95505219,2330,ewencp,2017-01-11T03:09:58Z,"using the `memorypool` for `networkreceive` only works if everyone actually uses the `memorypool` for all relevant allocations. there are still uses of the other constructores -- this is only used by `kafkachannel`. i just want to verify we know the implications of leaving the other ones. obviously the constructor with `bytebuffer` doesn't need the `memorypool`. a few are used in `saslclientauthenticator`/`saslserverauthenticator`. those seem fairly reasonable (one is unbounded, which doesn't seem ideal, although i'm not sure a bound can easily be placed on it). the last case is in `blockingchannel`. it seems this is only used in controlled shutdown. i assume the kip was mainly targeted at client requests and the controlled shutdown message is constrained enough in its request size that we just don't need to worry about that case? (i'm not sure how completely we want to make the enforcement for this kip, i.e. want to catch everything except stated exceptions to protect against even malicious users or if we are just trying to address ""accidental"" issues caused by clients.)",0,0.9892861247062683
95505706,2330,ewencp,2017-01-11T03:17:19Z,"re: comment, do you have a stacktrace or something from where this happens? would be good to know if there's a valid case or if the condition checked a few lines up should be `receivesize <= 0`. intuitively, a zero length receive seems like it would be invalid (but possible for clients to transmit, and so perhaps handled gracefully even if it is invalid).",0,0.987228512763977
95505922,2330,ewencp,2017-01-11T03:20:24Z,these don't need `public` on them since it's an interface.,0,0.9912214279174805
95506702,2330,ewencp,2017-01-11T03:31:41Z,would this be worth raising to `warn`? seems like it might be relevant for users to know via the logs that they are effectively throttling reads. or are we assuming the new sensor is sufficient?,0,0.9882526993751526
95508527,2330,ewencp,2017-01-11T04:00:44Z,"this is fine. you can also put those all in an array and just index with `min(ordinal, units.length-1)`.",0,0.9913763403892517
95508782,2330,ewencp,2017-01-11T04:04:41Z,"is there any concern that we might lose track of updating this properly? it's not just an issue with adding new request types; it's also a problem if a request type that didn't have `bytes` or `nullable_bytes` fields is updated to a version of the schema that does have them. i'm skeptical that folks will even know about, let alone remember to update, this list if they introduce such a field. would some sort of static determination based on the full list of schemas be more reliable but equally fast?",-1,0.6752675175666809
95511403,2330,ewencp,2017-01-11T04:44:34Z,"is there any concern about efficiency here? in particular, this allocates a new list and runs an additional linear time algorithm. a simpler alternative that has weaker randomization guarantees would be to select a random starting offset and use a couple of iterators to implement a sort of rotated view of the original list. or perhaps overall it's not a concern since we have a linear cost to process all the keys anyway?",0,0.9791842699050903
95548748,2330,ijuma,2017-01-11T10:15:32Z,"i think it would be nice to avoid unnecessary naming inconsistencies between this and `bufferpool`. it may make sense to deviate in some cases, but could you take a pass and see if some names here or there should be renamed for consistency?",0,0.9639999270439148
95550443,2330,ijuma,2017-01-11T10:25:52Z,"`controlledshutdown` only uses `blockingchannel` if the `inter.broker.protocol.version < 0.9.0.0`, so it's safe to ignore. it's only there to allow rolling upgrades from 0.8.x. i haven't checked the other cases, it would indeed be good to know if there's a good reason why they are not using the memory pool.",0,0.9911940693855286
95582422,2330,rajinisivaram,2017-01-11T13:59:16Z,are there scenarios where you would expect this to be different from `transportlayer#ready()`?,0,0.9944360256195068
95583150,2330,rajinisivaram,2017-01-11T14:03:43Z,perhaps you want to return `this.ready()`? it looks like both ssl and sasl handshakes are done without using the memory pool. so the check should be for any handshake.,0,0.9925370812416077
95584021,2330,rajinisivaram,2017-01-11T14:08:42Z,i am not sure of the value of this loop. it is muting a subset of channels (ones that are not in handshake and have not allocated memory and have started read). channels not muted here and new channels are muted when and only when allocation for read fails. wouldn't it be better to do the same for the subset handled here as well and remove this loop altogether? it seems to me that this loop simply prevents channels from reading the 4-byte size for which space has already been allocated.,0,0.8150995373725891
95589701,2330,rajinisivaram,2017-01-11T14:38:14Z,"not sure about this. `ssltransportlayer#hasbytesbuffered` returns true if there is any data in `netreadbuffer`. if more data is needed to unwrap and no data arrives from the client, i think the handling of `keyswithbytesbuffered` results in a tight polling loop with timeout=0.",0,0.9175592064857483
95611883,2330,rajinisivaram,2017-01-11T16:13:52Z,i think you can have empty message body in sasl exchanges.,0,0.9866883158683777
95612479,2330,rajinisivaram,2017-01-11T16:16:22Z,perhaps we don't want to release `empty_buffer`?,0,0.9782997369766235
95613398,2330,rajinisivaram,2017-01-11T16:19:58Z,"similar to the mute in `poll()` - the mute could be delayed until a buffer needs to be allocated? it is possible that the channel already has a buffer allocated, in which case, we want it to complete read.",0,0.9906725287437439
95638139,2330,ewencp,2017-01-11T18:17:51Z,"it's just more proactive, right? if you're out of memory, you're not going to be able to do anything (beyond the handshake) on any channel anyway. i think the value is that instead of going through a more polling unnecessarily only to end up muting all the channels, you can just do so immediately.",0,0.9736517667770386
95754342,2330,rajinisivaram,2017-01-12T09:41:39Z,"the code looks like it is proactively closing most channels. but actually it closes a small subset of channels. channels can be in one of these states: 1. handshake 2. authentication 3. waiting to receive a message (receive == null) 4. received partial message size (receive != null, buffer == null) 5. received size and partial message body (receive != null, buffer != null) 6. muted after receiving size due to oom 7. explicitly muted 8. disconnect the loop actually handles only 4). it mutes 2) at the moment, but that is pointless since authentication doesn't use the pool, so that needs fixing anyway. 4) already has the size buffer, so there is not much point in muting before size is read, after which it will move to 6) if still oom. muting proactively is not particularly helpful since disconnect processing gets delayed as well, hence 3) is not muted. if we decide to allocate small buffers outside the pool to handle consumers as mickael has suggested, it will be useful to mute only in one place - i.e. when a buffer needs to get allocated and its size is known. i think `isinmutablestate` is unnecessary if muting is done on allocation failure and that makes the code simpler.",0,0.9706516265869141
95868086,2330,radai-rosenblatt,2017-01-12T19:37:53Z,"mostly because i was going after a specific oom scenario - dos by large producer requests. anything can be ""opted-in"" to using memory pools later on, i was trying to solve just one problem.",0,0.9583439826965332
95868466,2330,radai-rosenblatt,2017-01-12T19:39:30Z,i originally had a <= 0 check which triggered while testing my code. it surprised me (as evident by the comment) but i decided to live with it instead of tracking it down. also looks like its an expected scenario. i'll update the comment to reflect this,0,0.7993597984313965
95868992,2330,radai-rosenblatt,2017-01-12T19:41:59Z,"thats a good idea, i'll see if i can improve this.",1,0.98818039894104
96104452,2330,radai-rosenblatt,2017-01-14T01:43:22Z,"i account for null as a safety net even though using none is clearer. so its both by design. having said that, i'll gladly go for one or the other if there's a style guideline.",0,0.9021164774894714
96104700,2330,radai-rosenblatt,2017-01-14T01:48:29Z,personally i dont think this is a warning - its normal operations. users who care can get at this information in a much better way via the sensors exposed in this kip.,0,0.9355250597000122
96105233,2330,radai-rosenblatt,2017-01-14T02:00:23Z,this whole clause is (in my opinion) premature optimization of an edge case - trying to guarantee fairness when operating under memory pressure and assuming that selectionkeys iteration order is not pseudo random. i'll improve on it if you insist but i would prefer to wait for real world complaints,-1,0.8614329099655151
96512094,2330,radai-rosenblatt,2017-01-17T21:16:12Z,- i've implemented a simple schema visitor and used that to find the relevant api keys for this dynamically. please see the revised code.,0,0.9915745854377747
96512145,2330,radai-rosenblatt,2017-01-17T21:16:26Z,done,0,0.8682363629341125
96512217,2330,radai-rosenblatt,2017-01-17T21:16:50Z,done,0,0.8682363629341125
96512883,2330,radai-rosenblatt,2017-01-17T21:19:43Z,"right now no, this exists as a separate api becuase its a different ""aspect"". ideally under java8 i could have made this a method with a default impl",0,0.982494056224823
96513168,2330,radai-rosenblatt,2017-01-17T21:21:02Z,again - its an issue of mutability vs ready being 2 logically different things (even if they are tied for the 2 current implementations of transport). you could think of a future qos implementation where inter-broker transports arent mutable (as opposed to client-broker transports),0,0.9838249683380127
96514142,2330,radai-rosenblatt,2017-01-17T21:25:51Z,"ssltransportlayer#hasbytesbuffered returns true if either the net or app buffers have data. its possible that net is done/empty, nothing will ever again be coming out of the socket, but there is data unread in app buffer (so already decrypted, just not read out)",0,0.9936450719833374
96515272,2330,radai-rosenblatt,2017-01-17T21:30:48Z,it looks like this code is only ever called from tests?,0,0.9914104342460632
96522660,2330,radai-rosenblatt,2017-01-17T22:08:37Z,done,0,0.8682363629341125
96522883,2330,radai-rosenblatt,2017-01-17T22:09:40Z,"i have removed the ""mute everything in advance"" loop in favor of letting channels mute themselves.",0,0.9915903210639954
96606921,2330,rajinisivaram,2017-01-18T10:42:38Z,"if this code was only called from tests, then channels would remain in `explicitlymutedchannels` forever :-) it is actually called by the broker - mute/unmute to control reading from the channel and hence the need to track explicitly muted channels.",1,0.9625959396362305
96609022,2330,rajinisivaram,2017-01-18T10:54:43Z,"-rosenblatt i agree you do need the logic to read buffered data from `ssltransportlayer`. but i think the implementation needs to ensure that it doesn't end up in a tight polling loop when attempting to drain the buffered data. when there is data in the app buffer, it is reasonable to set timeout=0 and read the data. when there is some data in the net buffer, it is likely that more data is required to unwrap the data to move it from net to app buffer. if there is a network issue that stops any more data arriving, then i think `keyswithbytesbuffered` will set timeout=0 and continue in a polling loop until idle timeout causes the connection to be closed (i.e. 10 minutes of tight polling).",0,0.9173454642295837
96611992,2330,rajinisivaram,2017-01-18T11:11:49Z,-rosenblatt it is also about which layers need to know about these different aspects. does `ssltransportlayer` really need to know about mutability of buffers? and the reason i suggested the change was because `kafkachannel.isinmutablestate()` should return false if either of the conditions in `this.ready()` is false (i.e. transport layer handshake or authenticating). i don't think it makes sense for transport later or authenticator to have to worry about mutability of buffers.,0,0.9703974723815918
96612136,2330,rajinisivaram,2017-01-18T11:12:44Z,see comment below.,0,0.9939999580383301
96726102,2330,radai-rosenblatt,2017-01-18T20:25:46Z,": 1. is it guaranteed that if there's anything in net buffer after a read there must always be more incoming? because if so i can just react solely to data in app buffer. 2. i think i now understand the scenario you describe. my ""best"" idea of how to solve it would be have a boolean return value from pollselectionkeys() to indicate if any ""progress"" has been made. if no progress has been made in the previous call to poll() the next call would not set timeout to 0. my issue with this solution is that getting progress indications out of channel.read() / channel.write() is a non-trivial refactor (they are currently designed to return null or a complete object, would need to be extended)",0,0.698165774345398
96774619,2330,radai-rosenblatt,2017-01-19T01:25:16Z,- i've introduced a simple (relatively...) notion of progress made to try and prevent the tight loop you pointed out.,0,0.9799799919128418
96777022,2330,radai-rosenblatt,2017-01-19T01:47:23Z,- i've dropped transport.ismutable() in favor of just calling ready(),0,0.989657461643219
96855844,2330,rajinisivaram,2017-01-19T13:10:48Z,it may be better to call `this.ready()` rather than `transportlayer.ready()` authenticators don't use the memory pool and channels don't need to be muted during authentication.,0,0.9917659163475037
96856882,2330,rajinisivaram,2017-01-19T13:17:12Z,"why does this check `datainbuffers`? with ssl, poll will go through this conditional block most of the time and it (the trace in particular) can be confusing. wouldn't the first poll after oom is reset handle the unmute?",0,0.9626532793045044
96858147,2330,rajinisivaram,2017-01-19T13:25:02Z,you want the loop to read even when there is no data from the network. so the condition needs to be something along the lines of `if (channel.ready() && (key.isreadable() || channel.hasbytesbuffered()) && !explicitlymutedchannels.contains(channel) && !hasstagedreceive(channel))`,0,0.9928520321846008
96859079,2330,rajinisivaram,2017-01-19T13:30:26Z,"since`keyswithbytesbuffered` was cleared earlier, it needs to be populated regardless of the status of staged receives. i think `""if(..) { keyswithbytesbuffered.add(..); }""` should be done outside the outer if that checks staged receives.",0,0.9922601580619812
96860499,2330,rajinisivaram,2017-01-19T13:39:14Z,"the current implementation of `addtocompletedreceives` moves receives from staged to completed state if the channel is not muted. i think it will better to replace `!channel.ismute()` with `!explicitlymutedchannels.contains(channel)`. buffers have already been allocated for the staged receives, so we should allow them to make progress and release the buffers.",0,0.9912744164466858
96914943,2330,radai-rosenblatt,2017-01-19T17:41:09Z,"this isnt about handling the unmute, this is about not waiting (up to 300ms currently) on other sockets if we know we have socket(s) with data in buffers that we can read immediately.",0,0.990323543548584
96919823,2330,radai-rosenblatt,2017-01-19T18:05:03Z,"will do. also, to save on the cost of the explicitlymutedchannels map, do you think its better to replace it with an extra boolean flag on channel? have boolean muted and boolean explicitelymuted? (or rather bool mutedforoom and bool mutedforordering)",0,0.9918417930603027
96948979,2330,rajinisivaram,2017-01-19T20:21:01Z,"i think it would be slightly neater to store the muted state in channel rather than selector (not necessarily to save on cost, it just feels like channel state).",0,0.9755756258964539
96949265,2330,rajinisivaram,2017-01-19T20:22:30Z,there are two if statements - one just above this one sets timeout to zero and that needs to check `datainbuffers`. this one is just unmuting and resetting `outofmemory` flag. not sure why this needs to check `datainbuffers`.,0,0.9792461395263672
97010154,2330,radai-rosenblatt,2017-01-20T04:16:52Z,done,0,0.8682363629341125
97012152,2330,radai-rosenblatt,2017-01-20T04:47:19Z,"youre probably right. if datainbuffers = true it means either: 1. there is data in app buffer. only way (i think?) to get to this situation is that it could not be read out of app buffer because no memory, hence outofmemory will be true, which will be enough to trigger an unmute when memory becomes available 2. there's data only in net buffer. this means must data must come from socket and we have successfully read out everything that may have been in app buffer, so we didnt run oom, so channel is not muted and will show up in a future poll as a read key",0,0.7869684100151062
97012165,2330,radai-rosenblatt,2017-01-20T04:47:27Z,done.,0,0.9897913336753845
97282273,2330,rajinisivaram,2017-01-23T09:49:48Z,"-rosenblatt i tried running this test and the test passes for me when run on its own, but fails consistently when the whole class is run. this assertion is not safe since `ismadeprogresslastpoll()` can be true for various reasons including the key being writable - key may be writable for ssl handshake and so when the handshake completes, madeprogress is set. you could make the flag more conservative in the implementation, but not sure that is worthwhile - you could just remove this assertion from the test.",0,0.9156747460365295
97354296,2330,radai-rosenblatt,2017-01-23T16:19:05Z,"thats odd. the loop above explicitly waits for both handshakes to complete, and there should only ever be those 2 connections. i will remove the offending check, but i dont think its the handshake",-1,0.88571697473526
97360992,2330,rajinisivaram,2017-01-23T16:44:24Z,"i think the loop waits for handshakes to complete from the client point of view, so the server has done its final writes. but kafka's ssltransportlayer code updates its handshake status a bit lazily, so there is a small window where the server has not yet updated its status after the final write.",0,0.9869231581687927
97428810,2330,rajinisivaram,2017-01-23T22:10:53Z,sslsender?,0,0.9924688935279846
97453785,2330,radai-rosenblatt,2017-01-24T00:59:21Z,fixed,0,0.920660674571991
97744192,2330,rajinisivaram,2017-01-25T10:01:45Z,"-rosenblatt this needs to be ""tlsv1.2"" to work with java 7 since the server side properties in tests explicitly set ""tlsv1.2"" and the default tls version in java 7 is lower.",0,0.9867086410522461
97749640,2330,rajinisivaram,2017-01-25T10:29:09Z,"minor typo (doesn't impact the test, but is confusing). i think you want to use `sslserverconfigs` here and remove `sslclientconfigs` setting just above since only one server channel builder is used in the test?",0,0.94704270362854
97924111,2330,junrao,2017-01-26T02:43:40Z,this seems never used?,0,0.9894492626190186
97924116,2330,junrao,2017-01-26T02:43:46Z,does oomtimesensor need to be volatile?,0,0.9891023635864258
97924129,2330,junrao,2017-01-26T02:43:54Z,sizebytes = > sizeinbytes maxsingleallocationsize => maxsingleallocationbytes?,0,0.9923256635665894
97924148,2330,junrao,2017-01-26T02:44:08Z,"probably better with ""requested size "" + sizebytes + "" <=0 ""?",0,0.9918066263198853
97924251,2330,junrao,2017-01-26T02:45:33Z,"in the case when the memory pool is full for a long time, we may not be able to update oomtimesensor for a long period of time, which can make metric inaccurate. we could probably update the sensor periodically (e.g., based on the window size of sensor) when the allocation is unsuccessful?",0,0.9883412718772888
97924265,2330,junrao,2017-01-26T02:45:45Z,could we just iterate explicitlymutedchannels directly?,0,0.9930129647254944
97924301,2330,junrao,2017-01-26T02:45:58Z,perhaps we can use a better name for keyswithbytesfromsocket since selectedkeys() include keys ready for writes too.,0,0.9857233166694641
97924332,2330,junrao,2017-01-26T02:46:38Z,"when will keyshandled and selectionkeys have different size? if that happens, it seems that we still need to remove all keys in selectionkeys to clear the ""ready for selection table"" in the nio selector. also, do you know if selectionkeys.clear() clears the ""ready for selection table""?",0,0.9939588308334351
98138485,2330,junrao,2017-01-27T03:01:49Z,this constructor seems never used?,0,0.991438627243042
98138501,2330,junrao,2017-01-27T03:01:59Z,"not very clear on the above comment. is ""do we do not"" a typo? is the comment in the right place?",0,0.8820390105247498
98138532,2330,junrao,2017-01-27T03:02:26Z,"is the check (madeprogresslastpoll && datainbuffers) necessary? datainbuffers is caused by no memory in the memory pool. it seems that it's simpler to wait for the default selector poll time, which is what we do when the pool is out of memory in other cases.",0,0.9921332597732544
98138539,2330,junrao,2017-01-27T03:02:32Z,could we just clear the set to avoid recreation overhead?,0,0.9877886176109314
98138545,2330,junrao,2017-01-27T03:02:40Z,"is this test needed? if a channel is explicitly muted, it won't be selected by the selector, right?",0,0.9901339411735535
98138556,2330,junrao,2017-01-27T03:02:52Z,is the change needed since it seems memorypool is never null from the caller?,0,0.9930701851844788
98138581,2330,junrao,2017-01-27T03:03:15Z,"since this is a server side metric, it's probably better to use a yammer metric to be consistent. currently, we try only using the client metric on the server side if it needs additional functionality from the client metric (e.g., quota).",0,0.9919778108596802
98138585,2330,junrao,2017-01-27T03:03:18Z,would memorypoolused be better?,0,0.9854743480682373
98138605,2330,junrao,2017-01-27T03:03:33Z,"we are not blocking the network threads, right?",0,0.9802534580230713
98138611,2330,junrao,2017-01-27T03:03:38Z,"this is optional. so, it probably should be of medium instead of high?",0,0.9937368631362915
98791618,2330,radai-rosenblatt,2017-01-31T22:53:09Z,probably yes.,0,0.9665880799293518
98792151,2330,radai-rosenblatt,2017-01-31T22:56:07Z,"i dont understand. the sensor is updated on every single tryallocate call - successful or not. only way for the sensor to stop being updated is if the server id idle, in which case there should be plenty of memory available? if you want better accuracy i could update the sensor when calling release() - this by definition means we have memory, so i could zero-out the oom time",0,0.6979411840438843
98793590,2330,radai-rosenblatt,2017-01-31T23:04:19Z,"there's a (hypothetical) corner case where there's data in the ssl app buffer but the underlying socket is done. this means the socket will never come back from a poll call, and you may wait 300ms for no reason instead of servicing the buffer immediately. this is why datainbuffers exists. i agree its simpler to just wait a whole poll cycle, but this is an attempt to shave off the latency. the made progress flag exists because the downside of the above condition is you may be stuck in a tight loop trying to service the buffer and so we dont try if no progress was made previous attempt.",0,0.9697026610374451
98794090,2330,radai-rosenblatt,2017-01-31T23:07:31Z,"explicitlymutedchannels are channels muted because they already have an outstanding request in progress. we never want to service them until they are (explicitely) unmuted and taken out of the set ? so this loop iterates over _all_ channels, unmuting anything that _isnt_ in explicit.",0,0.9884860515594482
98794457,2330,radai-rosenblatt,2017-01-31T23:09:53Z,renamed int readykeys --> numreadykeys and keyswithbytesfromsocket to readykeys,0,0.9933091402053833
98795499,2330,radai-rosenblatt,2017-01-31T23:16:41Z,"not really - because then topoll would be a copy ctr. i need to iterate over keys with buffered data i also need to record keys that (still?) have buffered data these have to be different sets or i would be forced to use a thread-safe collection, as i'll be modifying the structure im iterating over? this set gets ""cycled"" only when under memory pressure, so this is not expected to happen very often. i could pre-allocate both sets as instance variables on the class, if you want",0,0.9656826257705688
98797148,2330,radai-rosenblatt,2017-01-31T23:26:50Z,"a channel can be in explicitelymuted and in keyswithbytesbuffered at the same time - ssl may try and read several requests at once into stagedreceives. if it reads once request and then has no memory for the next the channel will be in keyswithbytesbuffered. the 1st request out of staged will be moved to completed, causing the channel to be muted when socketserver picks it up (still on the same thread). under this condition channel.hasbytesbuffered() == true and also !hasstagedreceive(channel), causing data to be read for a channel that already has a request in progress",0,0.9900276064872742
98800869,2330,radai-rosenblatt,2017-01-31T23:52:08Z,"the sizes will differ only if some uncaught exception terminates the loop early (so never, unless bug?). the code path for different sizes is there to try and match what the previous code would produce under those conditions (which are, again, a bug). under ""normal"" operating conditions the sizes should always be the same, which i think makes the clear() calls a faster implementation (n * arraylist.add() + 2*clear() < n * set.iterator.remove()). what do you mean by ""ready for selection table""? looking at the code for openjdk 8 selectors use a normal set, wrapped to disallow external add() calls. all selectors do is call add() on the set of keys, there's no special ""hook"" to react to removes/clears",0,0.9910228252410889
98805695,2330,radai-rosenblatt,2017-02-01T00:30:15Z,"i was trying to be safe, so i ""support"" nulls by translating them to none. if you want me to choose either null or none (instead of both) - just choose which.",0,0.9652620553970337
98806646,2330,radai-rosenblatt,2017-02-01T00:38:25Z,would be much simpler if i could :-d,1,0.9928421974182129
98813839,2330,radai-rosenblatt,2017-02-01T01:38:35Z,"the memorypool interface and implementations are in clients, which has no dep. on yammer. i could either add a dep on yammer (probably bad idea) or introduce an intermediary interface ?",-1,0.5017127394676208
98814575,2330,radai-rosenblatt,2017-02-01T01:44:32Z,also updated the kip doc,0,0.9931824803352356
115627162,2330,junrao,2017-05-09T23:40:23Z,madeprogressthispoll seems unused?,0,0.9891218543052673
115627211,2330,junrao,2017-05-09T23:40:51Z,"selector is shared between client and server. so, it's better not to mention server here.",0,0.9920169115066528
115627311,2330,junrao,2017-05-09T23:41:34Z,is the comment accurate? it seems that the underlying socket may still have bytes when there is buffered data.,0,0.991596519947052
115627435,2330,junrao,2017-05-09T23:42:31Z,keyswithbytesbuffered => keyswithbufferedread?,0,0.9943231344223022
115627563,2330,junrao,2017-05-09T23:43:35Z,previous message => previous receive,0,0.9947279095649719
115627970,2330,junrao,2017-05-09T23:47:05Z,"so it seems the only reason for this method is to optimize iterator.remove (by using keyshandled .clear())? if so, i am not sure if it's worth doing this optimization since this makes the code a bit harder to read.",0,0.937775194644928
115859559,2330,junrao,2017-05-10T21:39:58Z,"would it be simpler to check channel.ismuted() instead of channel.isinmutablestate()? then, the latter can be a private method in kafkachannel.",0,0.9920181632041931
115883466,2330,junrao,2017-05-11T00:30:42Z,"i am wondering if we really need madeprogresslastpoll. in general, if the selector runs out of memory, selector.poll will just block for 300ms in socketserver. if datainbuffers is true, it's due to out of memory. so, it seems that it's more consistent and simpler to just wait for the default 300ms in socketserver?",0,0.9268480539321899
115891794,2330,junrao,2017-05-11T01:58:19Z,"hmm, not sure if this is very reliable since the bytes may still be in the client socket buffer. perhaps a more reliable way is to do a waituntil wrapping selector.poll() on the server side.",0,0.8544347286224365
115892226,2330,junrao,2017-05-11T02:03:23Z,& => && ?,0,0.983468770980835
115892482,2330,junrao,2017-05-11T02:06:25Z,"since this is only called in testmuteonoom, which is overridden in sslselectortest, perhaps the method can just be private?",0,0.9890261292457581
116027427,2330,junrao,2017-05-11T15:47:43Z,could we track this at nano sec level and pass the value as double in ms for better accuracy?,0,0.9922980666160583
116027727,2330,junrao,2017-05-11T15:48:49Z,could we just set oomperiodsensor in the constructor and get rid of this method?,0,0.9915832877159119
116772044,2330,radai-rosenblatt,2017-05-16T15:13:48Z,:+1:,0,0.9328674077987671
116772303,2330,radai-rosenblatt,2017-05-16T15:14:37Z,:+1: left over from testing,0,0.9741965532302856
116776829,2330,radai-rosenblatt,2017-05-16T15:29:45Z,"- the progress indicator was added to prevent a tight looping schenarion that spotted at jan 18 (see above discussion on an old version of selector, cant find a way to link to it). i believe the issue is that there may be bights in an underlying ssl buffer that would cause timeout = 0",0,0.9911971092224121
116777012,2330,radai-rosenblatt,2017-05-16T15:30:22Z,:+1:,0,0.9328674077987671
116777231,2330,radai-rosenblatt,2017-05-16T15:31:08Z,no because a channel can be muted for 2 reasons - 1 request at a time or memory pressure.,0,0.9673824906349182
116778212,2330,radai-rosenblatt,2017-05-16T15:34:34Z,we subtract the ready set from keyswithbufferedread and to topoll (set of keys we poll from under this condition) ends up being the set of keys for which there is data in buffers but not from the underlying socket (else they would be in the ready set),0,0.9934677481651306
116781172,2330,radai-rosenblatt,2017-05-16T15:44:42Z,:+1:,0,0.9328674077987671
116781268,2330,radai-rosenblatt,2017-05-16T15:45:04Z,:+1:,0,0.9328674077987671
116781973,2330,radai-rosenblatt,2017-05-16T15:47:30Z,"the sender only terminates after it completely flushes its output stream, so i would expect everything to have been written out? also, we accept() both incoming connections before the call to poll so that we know that at least handshaking has been done at that point. given that this is all local networking i think the timing is loose enough (also i've not see this fail in all the times that i've rebased and retested this branch).",0,0.9904375672340393
116783226,2330,radai-rosenblatt,2017-05-16T15:52:21Z,:+1:,0,0.9328674077987671
116784228,2330,radai-rosenblatt,2017-05-16T15:56:04Z,this assignment operator is defined differently for boolean operands (so it doesnt perform a bitwise operation) and so there is no &&=. i'll refactor the code to avoid this (as its rather obscure),0,0.9908874034881592
116801727,2330,radai-rosenblatt,2017-05-16T17:09:41Z,:+1:,0,0.9328674077987671
128666574,2330,junrao,2017-07-21T01:26:26Z,"since dispose() can be called by both network threads and request handler threads, should we make buffer volatile?",0,0.992399275302887
128906634,2330,junrao,2017-07-22T22:54:57Z,it seems that we can just check !keyswithbufferedread.isempty?,0,0.991859495639801
128906636,2330,junrao,2017-07-22T22:55:15Z,"hmm, it seems that madeprogresslastpoll needs to be set to false somewhere?",0,0.9592459797859192
128906639,2330,junrao,2017-07-22T22:55:28Z,"since there is no guarantee when the server will receive those bytes, should we put this code block in a waituntil loop?",0,0.9892832040786743
128906644,2330,junrao,2017-07-22T22:55:49Z,"since there is no guarantee when the server will receive those bytes, should we put this code block in a waituntil loop?",0,0.9892832040786743
128906645,2330,junrao,2017-07-22T22:55:56Z,memorypoolavgdepletedpercent => memorypoolutilization?,0,0.9931913018226624
128906650,2330,junrao,2017-07-22T22:56:02Z,memorypoolavgdepletedpercent-avg => memorypoolavgdepletedpercent,0,0.989543080329895
128906668,2330,junrao,2017-07-22T22:56:13Z,"would it be better to name this queued.max.request.bytes? otherwise, it's not obvious what queued bytes are for.",0,0.9835904240608215
128906671,2330,junrao,2017-07-22T22:56:21Z,"instead of defaulting it to null, should we default it to defaults.queuedmaxbytes?",0,0.9936676621437073
129095498,2330,radai-rosenblatt,2017-07-24T17:07:51Z,will fix,0,0.9934358596801758
129099716,2330,radai-rosenblatt,2017-07-24T17:23:54Z,will fix,0,0.9934358596801758
129099747,2330,radai-rosenblatt,2017-07-24T17:24:04Z,will fix,0,0.9934358596801758
129107398,2330,radai-rosenblatt,2017-07-24T17:53:14Z,"the test asserts on the state of the progress flag, meaning we cant call poll() more than once (2nd+ call will wipe the progress flag). will do",0,0.9944576025009155
129107452,2330,radai-rosenblatt,2017-07-24T17:53:26Z,will do,0,0.9619618058204651
129147307,2330,radai-rosenblatt,2017-07-24T20:39:15Z,will do,0,0.9619618058204651
129147337,2330,radai-rosenblatt,2017-07-24T20:39:21Z,will do,0,0.9619618058204651
129147672,2330,radai-rosenblatt,2017-07-24T20:40:48Z,will do,0,0.9619618058204651
129148372,2330,radai-rosenblatt,2017-07-24T20:43:47Z,the null was the validator. i've simply removed it now,0,0.9954806566238403
129403649,2330,junrao,2017-07-25T19:35:22Z,could we add a comment to explain why madereadprogresslastpoll is used for?,0,0.9946789741516113
129403695,2330,junrao,2017-07-25T19:35:36Z,is there a need to set madereadprogresslastpoll here? it seems we only need to set when doing reads?,0,0.9924474954605103
129403711,2330,junrao,2017-07-25T19:35:43Z,is there a need to set madereadprogresslastpoll here? it seems we only need to set when doing reads?,0,0.9924474954605103
129408331,2330,junrao,2017-07-25T19:55:20Z,"since on the server side, we release memory through requestchannel.dispose(). however, memory is also released here through kafkachannel.close(). will this cause the same memory to be released more than once in certain cases?",0,0.9911291599273682
129412615,2330,radai-rosenblatt,2017-07-25T20:14:00Z,will do,0,0.9619618058204651
129412879,2330,radai-rosenblatt,2017-07-25T20:15:14Z,"i was being cautious. but youre right, given the progress flag is only used in combination with datainbuffers its probably impossible for a poll() round to involving the progress flag to consist solely of handshaking and connecting operations.",0,0.9589986801147461
129412922,2330,radai-rosenblatt,2017-07-25T20:15:26Z,removed (see above comment),0,0.9905575513839722
129419356,2330,radai-rosenblatt,2017-07-25T20:40:32Z,"kafkachannel.receive is a receive _in progress_. once its compete its read out (field is nulled) and the buffer passed to a requestchannel.request. so any given buffer exists either as part of an in-progress receive or as part of a completed receive (that was transferred to request channel). given the transition happens on the same thread that would close a kafkachannel, i dont think this would be a problem?",0,0.9855345487594604
311655316,7170,mjsax,2019-08-07T16:46:14Z,nit: `creates` -> `create`,0,0.9936466217041016
311655490,7170,mjsax,2019-08-07T16:46:41Z,"nit: `deserializers, [and] producer's`",0,0.9924218058586121
311657543,7170,mjsax,2019-08-07T16:51:17Z,"nit: `the number of partitions is determined based on the upstream topics partition numbers.` one may use `merge()` and there may be multiple upstream topic[s] -- for this case, we use max-partitions over all upstream topics. hence, i would be a little bit more fuzzy and avoid ""inherit"" as it implies it's the same number of partitions, but that only holds for the case of a single upstream topic. i would also use ""upstream"" instead of ""input"" because there might be an upstream repartition topic, too.",0,0.9664970636367798
311658732,7170,mjsax,2019-08-07T16:54:06Z,"do we need to have those two lines? we use `` usually to point to similar method, but not to point to overloads. for example, `map()` points to `mapvalues()`, but `map()` would not point to another variant of `map()`. the idea is to point people to different functionality, but if one know about `repartition` we assume they consider all overloads they can use.",0,0.9891722202301025
311658960,7170,mjsax,2019-08-07T16:54:33Z,nit: `creates` -> `create`,0,0.9936466217041016
311659340,7170,mjsax,2019-08-07T16:55:31Z,"nit: `partitions[,] and`",0,0.9933357238769531
311660226,7170,mjsax,2019-08-07T16:57:20Z,"nit: `name[,] and` why ""if repartitioning is required"" ? from my understanding, calling `repartition()` should always repartition, ie, enforce it. that's why we included `groupby()` in the kip -- if one does not want to force repartitioning, but want to control repartition topic properties, one can pass in `repartitioned` into `groupby` but would not use `kstream#repartition`. at least, that was my understanding of the kip?",0,0.9912838935852051
311660448,7170,mjsax,2019-08-07T16:57:52Z,why `(and potentially repartitioned)` ? should be removed imho,0,0.9798012971878052
311660775,7170,mjsax,2019-08-07T16:58:39Z,as above. my comments form above also apply to the third overlaod. not repeating them again.,0,0.9941851496696472
311661094,7170,mjsax,2019-08-07T16:59:23Z,this will not render as expected in the javadocs. you need to you html markup to define bullet points.,0,0.988126277923584
311661405,7170,mjsax,2019-08-07T17:00:04Z,nit: remove empty lines between members,0,0.9939268231391907
311661640,7170,mjsax,2019-08-07T17:00:37Z,"nit: remove ""if required"" nit: `{ repartitioned}` -> `{ repartitioned}` (no need to link to itself -- it's considered bad practice). both nits apply to other javadocs, too. will not comment on the other ones, but please fix everywhere.",0,0.9856980443000793
311663095,7170,mjsax,2019-08-07T17:04:09Z,should we add an import to avoid the long package name?,0,0.993242084980011
311668500,7170,mjsax,2019-08-07T17:16:53Z,why not `repartitioned.as(null)` ? this way we can remove `empty()` -- it would align with the pattern we apply in existing code.,0,0.9927070736885071
311670840,7170,mjsax,2019-08-07T17:22:03Z,"compare my other comment: from my understanding, we would always repartition.",0,0.9875364899635315
311672777,7170,mjsax,2019-08-07T17:26:27Z,nit: keep existing formatting or more `.withkeyserde(...)` into its own line.,0,0.9805799126625061
311674136,7170,mjsax,2019-08-07T17:29:29Z,"as the parent class contains the corresponding member, both method should be added there",0,0.9949154853820801
311677453,7170,mjsax,2019-08-07T17:36:40Z,seems do don't need `namedinternal namedinternal` as it's own variable?,0,0.9933731555938721
311693215,7170,mjsax,2019-08-07T18:12:47Z,we should extend existing `addinternaltopic` instead of having two method.,0,0.9932935237884521
311696457,7170,mjsax,2019-08-07T18:20:30Z,updating `repartitiontopicconfig` in this method may not be the best pattern. could we pass the number of partitions into the constructor of `repartitiontopicconfig` instead?,0,0.9858143925666809
311708461,7170,lkokhreidze,2019-08-07T18:48:18Z,"yeah, that was something i wanted to verify actually. for example with dsl, user can do something like: `stream(...).mapvalues().repartition()`. in this case repartition topic doesn't make much sense. so i chose to guard against situations like that. open to suggestions.",0,0.9413827657699585
311713308,7170,lkokhreidze,2019-08-07T18:59:38Z,"i added integration test to verify that repartition topic won't be created if key-changing operation isn't performed. if number of partitions is specified, repartition topic will be created though.",0,0.9942704439163208
311803123,7170,mjsax,2019-08-07T23:27:48Z,"if we don't repartition if user calls `repartition()` what is the purpose of the operation? the new operator is similar to `through()`, with the difference that kafka streams manages the topic. note, that one motivation for adding `repartition()` was, to allow users to repartition data before `transform()`. atm, this in only possible via `through()` forcing users to create the corresponding topic manually what is cumbersome. if a user does `stream(...).mapvalues().repartition()` i agree that repartitioning is not really required, but i would see this as a user error. at the same time, i see the potential to address this in the optimization layer: if we detect this case, we could remove the `repartition()` operator. it seems to be a subtle difference, but it's semantically two different approaches ihmo -- what you suggest is to keep the operator but to make it a no-op, while i suggest to _remove_ the operator. this would result in the same topology but the code how it is achieve is different and i believe it's an important difference.",0,0.9853245615959167
311879654,7170,lkokhreidze,2019-08-08T06:54:26Z,i like the idea of addressing this on optimization layer. i think this depends on how end implementation would look like and what we gonna agree on in our main discussion thread on this pr. if we gonna have only `repartitioned` operator i guess it make sense to always force repartitioning. if we gonna go with `groupby` and potentially `join` - optimization layer should be smarter about this in that case. i'll wait for an outcome of our discussion and update this accordingly.,1,0.779049277305603
312410620,7170,lkokhreidze,2019-08-09T09:58:28Z,"i've removed this check from here, but i'll investigate if we can do this in optimization layer as suggested in this thread: [a link]",0,0.9947792291641235
312427351,7170,lkokhreidze,2019-08-09T10:51:54Z,"none of the other members have corresponding methods in parent class. do you think it's still okay to move only this two members? if that's the case, i would prefer moving all of the accessor methods there. i guess accessors are added only to `optimizablerepartitionnode` because accessing members is needed only in case of optimization (`internalstreamsbuilder#getfirstrepartitiontopicname`)",0,0.9922917485237122
312732526,7170,lkokhreidze,2019-08-11T10:18:23Z,"based on comments from i've removed `repartition` operations from optimization logic altogether. now, when calling `repartition` operations, corresponding repartition topic will be always created.",0,0.9911361932754517
316772010,7170,vvcephei,2019-08-22T16:24:53Z,"just as a general note, i 100% sympathize with the impulse to clean stuff up alongside your changes, but it would really help the reviewers if you made a pass over the pr and just removed all changes that aren't related to kafka-8611. it's not a big deal with small changes, but when the pr is over a thousand lines of code, it really adds a lot of distraction when reviewers have to consider cleanup alongside substantial changes.",0,0.8014628887176514
316781727,7170,vvcephei,2019-08-22T16:48:13Z,"i was looking at how this is used, and there are only two usages. in both cases, we create the builder, then call a method that populates the builder, then call `build()`. maybe we can just ditch the builder and invoke the constructor from that static method?",0,0.9806844592094421
316783992,7170,vvcephei,2019-08-22T16:53:45Z,"this invocation has the side effect of incrementing the ""topology name counter"". in other words, this means that inserting a ""repartition"" node with a name will cause all the other processors, stores, and repartition topics in the topology to get renamed anyway. to clarify (because it's confusing) this method increments the counter even if it's not generating a name. should we consider instead making it like suppression, which does not increment the counter if you provide a name?",0,0.9729142785072327
316790193,7170,vvcephei,2019-08-22T17:09:02Z,it seems this method is unused. are we missing test coverage?,0,0.9931198358535767
316790517,7170,vvcephei,2019-08-22T17:09:48Z,"likewise, this one is unused.",0,0.9877043962478638
316790765,7170,vvcephei,2019-08-22T17:10:29Z,thanks for avoiding mutable state in this class!,1,0.9362001419067383
316794184,7170,vvcephei,2019-08-22T17:18:57Z,"it seems like this might be able to just replace `internaltopicnames`. we only add to `internaltopicnames` in one place, where we also (maybe) add to this map. we can't (shouldn't) make the value `null`, but i noticed that `internaltopicproperties` allows its parameter (`numberofpartitions`) to be null, which seems like it should have the same effect as a null `internaltopicproperties`... what do you think about requiring `iternaltopicproperties` to be non-null in `addinternaltopic`, although it might have a null number of partitions. then, we can get rid of `internaltopicnames` and just use `internaltopicnameswithproperties.keyset()`?",0,0.9833284616470337
316795023,7170,vvcephei,2019-08-22T17:21:08Z,"if we add this to `equals`, we *must* add it to `hashcode` as well, and we _should_ also add it to `tostring()`.",0,0.9938408136367798
316795418,7170,vvcephei,2019-08-22T17:22:03Z,should be final,0,0.9917559623718262
316795547,7170,vvcephei,2019-08-22T17:22:24Z,these three fields should be final as well.,0,0.9923580288887024
316796336,7170,vvcephei,2019-08-22T17:24:14Z,generics can be inferred here.,0,0.9941196441650391
316796825,7170,vvcephei,2019-08-22T17:25:17Z,"variable can be final. i won't comment on final-able variables anymore. do the tests pass? there should be a check that fails on variables that aren't final, but could be.",0,0.9879429936408997
316796993,7170,vvcephei,2019-08-22T17:25:43Z,method should be static,0,0.9936119914054871
316797085,7170,vvcephei,2019-08-22T17:25:55Z,"likewise, this one can be static",0,0.9929292798042297
316798314,7170,vvcephei,2019-08-22T17:28:41Z,"not sure what the intent is here, to increment the number between each test, or between each instance of this integration test class within the jvm... it actually does the latter.",0,0.8995451927185059
316798925,7170,vvcephei,2019-08-22T17:30:02Z,"this can (and should) be a unit test, since we don't need to produce data or run kafka to build and verify the topology.",0,0.9927512407302856
316802639,7170,vvcephei,2019-08-22T17:38:10Z,"maybe consider: [code block] then, this method won't return until streams is actually started, which we've seen can increase test stability.",0,0.9888097643852234
317388374,7170,lkokhreidze,2019-08-25T08:46:32Z,"interesting... yup, checkstyletests pass. i think checkstyle don't cover `try with resources` usage. anyway, it should be final yes, will update this everywhere. thanks.",1,0.991921067237854
317389525,7170,lkokhreidze,2019-08-25T09:19:55Z,"i can change it, sure. but personally i would prefer to have the builder here because 1) it follows same standard as other `baserepartitionnode` implementations 2) static factory method for the `unoptimizablerepartitionnodebuilder` will have a lot of parameters and it'll make code uglier. wdyt?",0,0.9695991277694702
317390219,7170,lkokhreidze,2019-08-25T09:41:47Z,so that each individual test has its own input/output topics. there's code in `` that increments `test_num`,0,0.9945238828659058
317412260,7170,lkokhreidze,2019-08-25T19:50:33Z,done,0,0.8682363629341125
317412281,7170,lkokhreidze,2019-08-25T19:51:11Z,added `streamsgraphtest#shouldnotoptimizewhenrepartitionoperationisdone`,0,0.9954366087913513
317412296,7170,lkokhreidze,2019-08-25T19:51:32Z,done,0,0.8682363629341125
317412304,7170,lkokhreidze,2019-08-25T19:51:38Z,done,0,0.8682363629341125
317412334,7170,lkokhreidze,2019-08-25T19:52:23Z,done,0,0.8682363629341125
317412354,7170,lkokhreidze,2019-08-25T19:53:02Z,added tests.,0,0.9920015335083008
317412360,7170,lkokhreidze,2019-08-25T19:53:11Z,added tests,0,0.9943349957466125
317412366,7170,lkokhreidze,2019-08-25T19:53:23Z,done.,0,0.9897913336753845
317412373,7170,lkokhreidze,2019-08-25T19:53:30Z,done,0,0.8682363629341125
317412377,7170,lkokhreidze,2019-08-25T19:53:38Z,done,0,0.8682363629341125
317412381,7170,lkokhreidze,2019-08-25T19:53:44Z,done,0,0.8682363629341125
317412451,7170,lkokhreidze,2019-08-25T19:55:45Z,"very fair point, totally agree. sorry about that. there're not many changes related to ""cleanup"" in this pr, but if you think it creates noise and makes it harder to do the review, i'll revert all cleanup related code.",-1,0.692707896232605
320850937,7170,vvcephei,2019-09-04T16:17:30Z,fair enough. thanks for the reply.,1,0.955407440662384
320859172,7170,vvcephei,2019-09-04T16:35:57Z,"thanks for your understanding. i just mentioned it because it seemed like there wasn't a ton of review activity. just thought i'd share the tactic with you, since rightly or wrongly, the large ""diff"" numbers in the pr can scare off reviewers. for myself, i didn't have trouble overlooking it.",1,0.9729588627815247
320859948,7170,vvcephei,2019-09-04T16:37:42Z,"ah, yeah, there are some limitations to the linter. thanks for taking care of it.",1,0.9627640843391418
320861613,7170,vvcephei,2019-09-04T16:41:31Z,"i see. but even though the number gets incremented after each test method, the string `inputtopic` is already fixed when the class is constructed, so it won't automatically get incremented. i think you need to make this a method to achieve the effect you intended.",0,0.988784909248352
320868518,7170,lkokhreidze,2019-09-04T16:57:19Z,hi thanks for the comment. sorry if i'm missing something... but junit creates new instance of the class before each test case. since those are non-static fields they'll be initialized during each test run with incremented `test_num`. i've verified it one more time and during each individual test topic number gets incremented. here are the screenshots just for the sake of clarity:,-1,0.9060289859771729
321099321,7170,lkokhreidze,2019-09-05T06:51:57Z,"makes total sense, thanks for sharing. i will definitely take this into account for the future prs.",1,0.9946565628051758
321394898,7170,vvcephei,2019-09-05T17:41:10Z,"ok, i'm convinced :) thanks for clearing up my confusion.",1,0.9958236217498779
329290021,7170,mjsax,2019-09-28T01:10:35Z,should we explain the difference to `through()`? something like: [code block] we might also update the docs for `through()` and point to the new operator. we should also cross-link using `` tags,0,0.9952000379562378
329290382,7170,mjsax,2019-09-28T01:18:11Z,"while i agree that immutability is great, i am wondering about consistency. the other configuration classes are mutable. do we think that might be of any concern? should we just update all other configuration classes an make them immutable, too? (of course not in this pr...) \cc",-1,0.6793656945228577
329290536,7170,mjsax,2019-09-28T01:21:53Z,"nit: remove `this.` (we only use `this` is we must -- applies to other parts, too)",0,0.9939549565315247
329290692,7170,mjsax,2019-09-28T01:25:27Z,"this method share a lot of code with `repartition(repartitioned)` -- we should create `private dorepartition(keyvaluemapper, repartitioned)` and all 4 public method should call it and just have a block [code block]",0,0.9944235682487488
329291018,7170,mjsax,2019-09-28T01:33:09Z,"seems we should add this to the parent class? and also use `optimizablerepartitionnode` and `groupedtableoperationrepartitionnode`. as a side cleanup, we should remove the `get` prefix -> `keyserializer()` -- we should also remove the `get` from `baserepartitionnode#getkeyserializer()` (same for value)",0,0.9939950108528137
329291182,7170,mjsax,2019-09-28T01:37:28Z,not sure why we need this? couldn't we use `internaltopicconfig`?,0,0.9625393152236938
329291498,7170,mjsax,2019-09-28T01:45:23Z,wondering if we should treat `numberofpartitions` as a regular config and add to `map topicconfigs` instead using `num.partitions` as parameter name? \cc,0,0.9905993342399597
329291593,7170,mjsax,2019-09-28T01:48:31Z,it seems also a little inconsistent with `internaltopicconfig` that uses `optional` but not `int`...,0,0.9716582894325256
329291663,7170,mjsax,2019-09-28T01:50:38Z,the whole method could be simplified to (and hence removed and embedded): [code block] if we let `#getnumberofpartitions()` return an `optional`.,0,0.994251012802124
329311990,7170,lkokhreidze,2019-09-28T14:19:49Z,"thought about it, but it felt more natural to introduce separate class rather than using `repartitiontopicconfig` in current design. `repartitiontopicconfig` potentially can be package-private (haven't touched this in current pr) and i wanted to avoid leaking it through other packages. it felt like best to leave construction of `repartitiontopicconfig` in `internaltopologybuilder` class since `internaltopologybuilder` ""knows the best"" how to construct it. idea of this class is to provide bare minimum configs of internal topic properties. hope my way of thinking around this makes sense. wdyt?",1,0.7910247445106506
329329123,7170,lkokhreidze,2019-09-28T22:01:50Z,done.,0,0.9897913336753845
329329133,7170,lkokhreidze,2019-09-28T22:02:31Z,done,0,0.8682363629341125
329329200,7170,lkokhreidze,2019-09-28T22:06:17Z,"fixed, `numberofpartitions` is now optional",0,0.9949994087219238
329329236,7170,lkokhreidze,2019-09-28T22:07:25Z,"did what you suggested. `baserepartitionnode` now has following methods: [code block] i've refactored `groupedtableoperationrepartitionnode`, `optimizablerepartitionnode` and `unoptimizablerepartitionnode` accordingly.",0,0.9884386658668518
329329258,7170,lkokhreidze,2019-09-28T22:08:26Z,done,0,0.8682363629341125
329329268,7170,lkokhreidze,2019-09-28T22:08:51Z,done and added more javadocs,0,0.9903318881988525
361869452,7170,lkokhreidze,2019-12-29T20:02:17Z,i've created jira ticket for it: [a link],0,0.991101861000061
368248756,7170,mjsax,2020-01-18T21:11:21Z,nit: you need to insert ` ` markup if you want to get a new paragraph.,0,0.9905030727386475
368248926,7170,mjsax,2020-01-18T21:15:07Z,i don't think that `{ #through}` is correct markup. should be `{ #through(string)}`,0,0.967463493347168
368249035,7170,mjsax,2020-01-18T21:16:57Z,`created topic` -> `[the] created topic is considered [an] internal topic` ?,0,0.9932636022567749
368249068,7170,mjsax,2020-01-18T21:18:01Z,"as above -> ` ` (seems other comment from above apply here, too -- won't repeat them)",0,0.9935885667800903
368249232,7170,mjsax,2020-01-18T21:21:51Z,nit: `selector` -> `keyselector` (we recently did a cleanup pr that uses `keyselector` as name is all other method that set a new key -- would be nice to align the names),0,0.9918996095657349
368249741,7170,mjsax,2020-01-18T21:33:51Z,"nit: in other classed, we just add `` tags instead of mentioning it in the text. should we do the same here for consistency?",0,0.9905481934547424
368250067,7170,mjsax,2020-01-18T21:41:06Z,"we can do all `null` checks in a single place within `dorepartition()` -- also, all other methods just say ` can't be null` (ie, please remove `parameter` for consistency)",0,0.9945969581604004
368250271,7170,mjsax,2020-01-18T21:46:00Z,"i don't think we can use `this.keyserde` that should align to the type of the input key, ie, type ` ` -- instead, we should set `keyserde` to `null` if not specified by `repartitioned` and fall back to the default key serde from `streamsconfig` during runtime. (this issue is also indicated by the ""unchecked"" warning that you suppress...)",0,0.9902995824813843
368250370,7170,mjsax,2020-01-18T21:48:15Z,comment seems redundant,0,0.6836931109428406
368250670,7170,mjsax,2020-01-18T21:54:42Z,not sure if i understand why we need this? it seems also to be tricky to understand the code if one calls `repartitiontopicconfig#setnumberofpartitions` and nothing happens because the actual object is of type `immutablerepartitiontopicconfig`.,0,0.5294269323348999
368251040,7170,mjsax,2020-01-18T22:02:16Z,"should be better throw here as this should never be called? what raised the question (we you actually do check the type already: should be flip the hierarchy as being mutable is a superset of being immutable and thus it should be `repartitiontopicconfig extends immutablerepartitiontopicconfig` -- for this case, `immutablerepartitiontopicconfig` would not have this method at all what seems to be cleaner)",0,0.9923335313796997
368251147,7170,mjsax,2020-01-18T22:05:25Z,to what extent is this check different from the check above when we call `validateandgetnumofpartitionsofimmutabletopics` -- or can we remove it here as it's redundant?,0,0.9926701784133911
368251683,7170,mjsax,2020-01-18T22:16:36Z,"i am wondering, if we should really throw an exception for this case? why do we not create this repartition topic with the same number of partitions as specified on the second input topic instead? iirc, for the following case we would also adjust the number of partitions: [code block] this code above is very similar to: [code block] in both cases, the number of partitions of one topic is fixed, while the second one has key-changing operation and thus we can just create a reparition topic that matches the number of partitions of the first topics?",0,0.9529017210006714
368421799,7170,lkokhreidze,2020-01-20T08:40:38Z,thanks for the suggestion. we can do null check in `dorepartition` for `repartitioned` parameter. null check for `selector` parameter should be on upper level since in some cases we do pass selector as `null`. for example: [code block] will update the error msg as well.,1,0.9440484642982483
368425477,7170,lkokhreidze,2020-01-20T08:49:46Z,good call. done.,1,0.9873448014259338
369771654,7170,lkokhreidze,2020-01-22T19:56:18Z,"interesting point. i guess in that case idea would be if in the `copartitiongroup` there's one `immutablerepartitiontopicconfig` and rest are repartition topics, we will enforce number of partitions from `immutablerepartitiontopicconfig`. in cases when there're more than one `immutablerepartitiontopicconfig` we would still throw an exception. does this make sense?",0,0.6386201977729797
369775730,7170,lkokhreidze,2020-01-22T20:05:04Z,"this check covers the case when number of partitions do not match between immutable repartition topics (aka created via `repartition` operation) and _ordinary_ repartition topics. but considering your comment below, different logic is needed here.",0,0.9933112859725952
369784339,7170,lkokhreidze,2020-01-22T20:24:25Z,"originally i've implemented this method with throwing an exception. but it seems like this method is being called from various places, like `streamspartitionassignor#preparetopic`. my thinking was - instead of each individual caller checking if `internaltopicconfig` supports setting number of partitions, it makes more sense to delegate this to the ""builder"" that chooses appropriate implementation based on some logic. `setnumberofpartitions` is part of `internaltopicconfig` so even i flip the hierarchy, i can't avoid `setnumberofpartitions` method. so i don't think it gives any benefit if we flip the hierarchy. i also thought instead of adding new class, i could maybe enhance `repartitiontopicconfig` to support ""immutability"" in cases when topics are for `repartition` operation, but in that case i have to add a flag to the class to indicate that this `repartitiontopicconfig` is actually for `repartition` operation which seems a bit worse compared to introducing new class. thoughts?",0,0.9756132960319519
369788818,7170,lkokhreidze,2020-01-22T20:35:33Z,"not ideal, agree. but tbh whole repartition topic management is complicated and is built around the idea of updating the number of partitions during different phases of kafka streams lifecycle. seems like adding new concrete class that indicates ""immutability"" the easiest and safest solution for now without changing current implementation and logic too much. would appreciate your ideas around this. not sure how to accommodate and guarantee immutability of partitions in some other (without introducing some major changes current internal topic management logic. maybe followup ticket is in order?)",1,0.9382065534591675
373849243,7170,lkokhreidze,2020-02-02T14:14:32Z,"hi this is now implemented. logic is the following: if `repartitiontopicconfig`s which have enforced number of partitions have the same value, non-enforced repartition topics (like for mapper) will be created with the num of partitions specified via `repartition` operation. `shoulddeductnumberofpartitionsfromrepartitionoperation` integration tests verifies this case.",0,0.9847367405891418
373849898,7170,lkokhreidze,2020-02-02T14:23:47Z,"hi gave it a bit more thought and decided to ditch this class altogether. `repartitiontopicconfig` and `immutablerepartitiontopicconfig` are exactly the same, just one wouldn't allow setting num of partitions. also, considering your comment about it being tricky to understand when num of partitions can be set or not (which is very valid concern) i've decided to encapsulate necessary logic into `repartitiontopicconfig` and `internaltopicconfig` classes. `internaltopicconfig` now can accept in the constructor `enforcenumberofpartitions` boolean flag: [code block] if `enforcenumberofpartitions` is set as `true`, and somebody decides to call `setnumberofpartitions` method, exception will be raised. i think this should make things much more clear. looking forward to your feedback.",0,0.9530507922172546
373849925,7170,lkokhreidze,2020-02-02T14:24:14Z,this class was removed. check my comment here: [a link],0,0.9948506951332092
373863902,7170,lkokhreidze,2020-02-02T18:02:01Z,update: i've added `numberofpartitions` as int this constructor overload to indicate that passing `numberofpartitions` is mandatory when one wants to use this constructor. corresponding internaltopicconfig constructor also uses int.,0,0.9905833005905151
392608571,7170,vvcephei,2020-03-14T18:24:49Z,"looking at this again with fresh eyes, i can't remember what advantage this has over `selectkey(keyvaluemapper).repartition(repartitioned)`. can you remember why we decided to add this, ?",0,0.9720823764801025
397650119,7170,lkokhreidze,2020-03-25T07:24:30Z,"hi as far as i remember we didn't have any specific discussion around this operation. main reason why we have added it i think is because of the convenience (merging selectkey and repartition into single operation). similarly how `groupby(final keyvaluemapper selector, final grouped grouped)` does it.",0,0.9802109599113464
398113069,7170,vvcephei,2020-03-25T19:25:52Z,"i see. iirc, your initial thought was to replace `groupby` with `repartition`, but we've gotten away from that design. now, it's more like a managed-topic version of `through` (in fact, this is what the javadoc for the method says). maybe this is why i was confused to see this overload, since it makes less sense to think of changing the key at the last minute before `though` or `to`. are you particularly attached to this convenience overload? i'm just thinking it's a safer bet to add it later if people really want it than to add it now and never really know if it's useful or not.",0,0.9133815169334412
398366211,7170,lkokhreidze,2020-03-26T07:36:34Z,"i can't say i am particularly attached to it, but i think it's useful one. from personal experience, we, at our company, often write topologies similar to this: [code block] here we need to explicitly use through in order to trigger repartitioning by selecting key (and we have to manage topic that we create in advance for `through` operation) new way of doing same thing is quite nice i think: [code block] for us, it's quite common use-case. and.my _guess_ is it will be common use-case for anyone using complex `transform` operations in dsl. does this make sense? on the other hand, if you believe that it's safer to remove `keyvaluemapper` overloads, i'll definitely do it.",1,0.9775477647781372
398927435,7170,vvcephei,2020-03-26T22:20:37Z,"i certainly agree that it would be common to do a `selectkey` before a `repartition`. there's a trade-off to strike between the number of different operations you need and the number of options on a single operation you have to choose from. i guess my hesitation is that it's still two different operations. for example, it also seems like it would be common to do a `map` before a `repartition`, but it's clearly now too much piled on if we have a fourth `repartition` overload also folding in the `map` operation. when i imagine coming to the api as a user, especially for the first time, i worry that i'd already have a lot of documentation to read to understand the implications of `repartition`, and each new overload adds linearly to the amount i have to learn to use the api. plus, i just feel like i would be puzzled about the exact same question i asked above: is this overload just the same as `selectkey().repartition()`, or does it do something subtly different? as you can tell, i worry quite a bit about how we can make sure the api stays as simple as possible while we still add new functionality. i guess this is just a long-winded way of saying that, yes, i would prefer to remove it :) hopefully, this isn't too disappointing for you, since the main motivation was to save on managing the `through` topic, not necessarily to save on that extra `selectkey` operator.",0,0.9325488805770874
399058852,7170,lkokhreidze,2020-03-27T06:30:00Z,"thanks john, that's a valid point. agree, i'll remove it.",1,0.9885857701301575
399067977,7170,lkokhreidze,2020-03-27T06:59:31Z,done. i'll resolve this conversation.,0,0.9474794864654541
401253268,7170,vvcephei,2020-03-31T22:30:12Z,[code block] looks like an accidental formatting change.,0,0.9697147011756897
401349352,7170,mjsax,2020-04-01T04:28:23Z,typo: `producer's`,0,0.9959626793861389
401349473,7170,mjsax,2020-04-01T04:28:51Z,`[c]reated`,0,0.9941710829734802
401349644,7170,mjsax,2020-04-01T04:29:27Z,`by [the] current`,0,0.9938676953315735
401349985,7170,mjsax,2020-04-01T04:30:58Z,`explicitly` -> `automatically` ? (not sure which one is better),0,0.9180141687393188
401350251,7170,mjsax,2020-04-01T04:32:09Z,`[c]reated` `by [the] current`,0,0.9939696788787842
401350309,7170,mjsax,2020-04-01T04:32:27Z,`automatically` ?,0,0.9903396964073181
401350867,7170,mjsax,2020-04-01T04:34:46Z,nit: do we need to add the `` tag to every method? seems somewhat redundant (it's already mentioned in class javadocs above)? (similar below for other methods),0,0.9457849860191345
401351951,7170,mjsax,2020-04-01T04:39:27Z,why would we not use an upstream `keyserde` (similar to `valueserde = valserde` l584 above) if `repartitioninternal` has a `null` key serde?,0,0.988914430141449
401352615,7170,mjsax,2020-04-01T04:42:42Z,why do we need to duplicate this method? might it be better to have just a single one and let caller set a `null` `streampartitioner` is they can't set it?,0,0.9909479022026062
401354459,7170,mjsax,2020-04-01T04:50:33Z,"for a `groupedtableoperationrepartitionnode` we should never have a customized `internaltopicproperties` object, but it should always be `internaltopicproperties.empty()` -- can we simplify this and not pass this parameter at all?",0,0.9940102100372314
401354751,7170,mjsax,2020-04-01T04:51:55Z,similar as above: can we avoid this parameter?,0,0.9931461811065674
401355550,7170,mjsax,2020-04-01T04:55:00Z,"`this.name = objects.requirenonnull(name, ""name can't be null"");` ? also, i believe `topicconfig` should not be `null` either -- can we add a check (also for the existing constructor above?",0,0.9951488375663757
401358667,7170,mjsax,2020-04-01T05:08:44Z,"with parallel test runners, would it be better to call this as first line in `before()` method (and use the returned value instead of calling `get()` in addition -- otherwise, we might get multiple different numbers per test run)? also wondering if we should assign the topic names that use the counter within before? for a clean isolation, it might also be good to add the test number to the `application.id`",0,0.9889497756958008
401359192,7170,mjsax,2020-04-01T05:10:53Z,should we setup all topics name within `before`?,0,0.9953749775886536
401360195,7170,mjsax,2020-04-01T05:14:55Z,"for this particular test, it seems we could detect the issue during topology `build()` already? ie, we could do an additional early check? if we think it's worth doing, we should do it in follow up pr to not drag this pr any longer. \cc (if yes, we could change this test from an integration test to a unit test)",0,0.9920935034751892
401361948,7170,mjsax,2020-04-01T05:21:56Z,"why do we have a `map()` step here? wouldn't this imply a repartition topic that would match whatever number of partitions is used on the other stream? ie, only without the map(), we guarantee that `topicbstream` has a certain number of partitions? with the `map()` step it seems to be the same test `shoulddeductnumberofpartitionsfromrepartitionoperation` as above?",0,0.9918246865272522
401362636,7170,mjsax,2020-04-01T05:24:32Z,"do we need an integration test for this? using `topology#describe()`, i think we could verify this with a unit test.",0,0.9938576817512512
401362888,7170,mjsax,2020-04-01T05:25:34Z,not sure why we need this test?,0,0.6906020641326904
401363128,7170,mjsax,2020-04-01T05:26:37Z,"nit: in test code, the signature can always be simplified to `throws exception` (there is no value to list exceptions) -- same for all test methods in this class (and maybe somewhere else?)",0,0.9930617213249207
401364227,7170,mjsax,2020-04-01T05:30:40Z,similar to above: we should be able to test with via unit tests using `topology#describe()`,0,0.9936270713806152
401364387,7170,mjsax,2020-04-01T05:31:15Z,seems to be unit-test able via `topology#describe()` ?,0,0.9944934844970703
401364523,7170,mjsax,2020-04-01T05:31:46Z,"not sure what this test is about, ie, how does is relate to the `repartition()` feature?",0,0.9435163736343384
401365280,7170,mjsax,2020-04-01T05:34:11Z,not sure what this test actually verifies?,0,0.6857213377952576
401365442,7170,mjsax,2020-04-01T05:34:48Z,using `mockprocessorsupplier` is an old test pattern -- we should use the new `testoutputtopic` instead.,0,0.992878258228302
401368679,7170,mjsax,2020-04-01T05:46:09Z,"i realize that this contradicts a previous review comment, but i think that the older comment was incorrect, because `repartition()` might be called to just scale out without a key changing operation and thus for this case we should reuse the upstream `keyserde` (note that if there was an upstream key changing operation, `keyserde` would be set to `null` and we would still fall back to the default serdes from the config).",0,0.9870607852935791
401369054,7170,mjsax,2020-04-01T05:47:16Z,why do we introduce a new type ` `? the key type of the input and output kstream does not change during repartitioning.,0,0.9853222370147705
401372458,7170,mjsax,2020-04-01T05:58:29Z,"can you update the kip wiki page accordingly and send an follow up email to the vote thread of the kip to highlight the change as an fyi that the kip was modified (just in case somebody would have an objection, what i don't expect -- it's just custom in the community to do this).",0,0.9927534461021423
402561217,7170,lkokhreidze,2020-04-02T19:32:00Z,"i've followed same standard as other configurations classes (produced, grouped, etc). to keep things consistent maybe worth cleaning up all the config classes with redundant `` tags? (in the follow up pr maybe) wdyt?",0,0.9923123717308044
403061232,7170,lkokhreidze,2020-04-03T14:51:10Z,`application.id` already has test number. will do as you suggested.,0,0.9843526482582092
403097472,7170,lkokhreidze,2020-04-03T15:44:39Z,you're right. this test is redundant. removed it.,0,0.9606911540031433
403098661,7170,lkokhreidze,2020-04-03T15:46:32Z,"wanted to verify that key changing operation with `repartition` works as expected. i think it adds value, especially considering the fact that we've removed `repartition(keyselector` overloads.",0,0.7402398586273193
403109967,7170,lkokhreidze,2020-04-03T16:05:00Z,"this was the ""easiest"" way i could figure out to verify that custom partitioner is invoked when it's set",0,0.9877142906188965
403372355,7170,lkokhreidze,2020-04-03T22:48:53Z,it's related to this comment [a link],0,0.9950624108314514
403374045,7170,lkokhreidze,2020-04-03T22:54:37Z,"thought about that, but somehow it felt ""safer"" with integration tests. mainly because i was more comfortable verifying that topics actually get created when using repartition operation.",0,0.9138379096984863
403374128,7170,lkokhreidze,2020-04-03T22:54:55Z,"thought about that, but somehow it felt ""safer"" with integration tests. mainly because i was more comfortable verifying that topics actually get created when using repartition operation.",0,0.9138379096984863
403374331,7170,lkokhreidze,2020-04-03T22:55:41Z,i'll create followup ticket on that.,0,0.9940648674964905
403374552,7170,lkokhreidze,2020-04-03T22:56:35Z,"yes, thanks for reminding me. was meaning to do it.",1,0.9673991203308105
403449003,7170,lkokhreidze,2020-04-04T09:36:26Z,done,0,0.8682363629341125
404993384,7170,vvcephei,2020-04-07T17:39:46Z,"yeah, i'd agree with checking as early as possible in the special cases where we can know the partition counts statically. but also agree with doing it in a follow-on ticket, since it's kind of a nice-to-have.",0,0.8486838936805725
404994770,7170,vvcephei,2020-04-07T17:42:00Z,"i had a similar thought, that it looks like good fodder for unit testing, but i did like the safety blanket of verifying the actual partition counts. i guess i'm fine either way, with a preference for whatever is already in the pr ;)",1,0.9833939671516418
406532074,7170,mjsax,2020-04-09T23:34:00Z,"yeah. was just a general inquire and we don't really have a guideline for it... if you are interested, it would be great to draft some guidelines (maybe just for kafka streams first, and we could propose them for other client apis, later) as a wiki page and we could discuss them on the dev mailing list?",1,0.881922721862793
406532691,7170,mjsax,2020-04-09T23:36:34Z,cool. did you create a ticket already? (just want to make sure we don't drop this on the floor.),1,0.9626748561859131
406532989,7170,mjsax,2020-04-09T23:37:44Z,ok. thanks for clarifying.,1,0.9196388125419617
406533537,7170,mjsax,2020-04-09T23:39:49Z,i guess that is fair. (i just try to keep test runtime short if we can -- let's keep the integration test.),0,0.9712905287742615
406533774,7170,mjsax,2020-04-09T23:40:52Z,thanks for clarifying!,1,0.8754435777664185
406535443,7170,mjsax,2020-04-09T23:47:20Z,"seems unnesseary complex? a simple [code block] would do, too :) (feel free to ignore the comment.)",1,0.9910316467285156
406535968,7170,mjsax,2020-04-09T23:49:15Z,"a simple [code block] would be sufficient instead of adding a constructor and those lines could go into `before()`. (as above, feel free to ignore this comment.)",0,0.9950299263000488
406839201,7170,lkokhreidze,2020-04-10T16:39:43Z,"yes, here it is [a link]",0,0.9880792498588562
406899069,7170,mjsax,2020-04-10T19:04:51Z,thank you!,1,0.9448403120040894
365485878,7884,junrao,2020-01-11T01:08:13Z,"ltc => logtoclean ? also, do we need to use another local val since ltc is only used once?",0,0.9940352439880371
365486280,7884,junrao,2020-01-11T01:12:19Z,need to change the javadoc above to currenttime.,0,0.9922744631767273
365486311,7884,junrao,2020-01-11T01:12:45Z,could we add the new param to javadoc?,0,0.995192289352417
366049275,7884,junrao,2020-01-13T21:55:01Z,"we should make it clear the difference btw retaindeletesandtxnmarkers and tombstoneretentionms. also, it's probably better to put they as adjacent params.",0,0.9939684867858887
366061210,7884,junrao,2020-01-13T22:23:48Z,"hmm, iscontrolbatchempty is a bit misleading since batch is not always a control batch.",0,0.8657703399658203
366064567,7884,junrao,2020-01-13T22:32:30Z,retaintxnmarkers is no longer used in shoulddiscardbatch().,0,0.9942229390144348
366085895,7884,junrao,2020-01-13T23:36:42Z,"it's a bit awkward to have to pass in the same batch to two different methods iscontrolbatchempty and checkbatchretention, during filtering. i was thinking that perhaps that we could just combine them into a single method checkbatchretention(), which returns (batchretention, shouldsethorizon). we could then extend shoulddiscardbatch() to sth like the following. the result of shoulddiscardbatch() can then be used to build the result for checkbatchretention(). [code block]",-1,0.9628819227218628
366086360,7884,junrao,2020-01-13T23:38:16Z,"we probably need to do the check based on the batch magic. if magic is >=v2, check based on the new deletehorizonms. otherwise, check based on the old approach.",0,0.9916934370994568
366090028,7884,junrao,2020-01-13T23:51:19Z,"it's probably better to have the logic to determine if deletehorizonms should be set here instead of memoryrecords since it's log cleaner specific logic. i was thinking that we could extend checkbatchretention() to return (boolean, shouldsethorizon).",0,0.9890642762184143
366093839,7884,junrao,2020-01-14T00:05:55Z,"hmm, if deletehorizonset is not set, we shouldn't be deleting the tombstone. so, not sure what newbatchdeletehorizonms is intended for.",0,0.9398913979530334
366093991,7884,junrao,2020-01-14T00:06:30Z,"hmm, why are we passing in containstombstonesormarker, which is always false?",0,0.9823158383369446
366095048,7884,junrao,2020-01-14T00:10:34Z,"since deletehorizonms can be obtained from batch, it's not clear why we need to pass that in as a param.",0,0.9867554903030396
366098944,7884,junrao,2020-01-14T00:25:10Z,"i am not sure about this. a round of cleaning can be expensive since we need to read in all existing cleaned segments. that's why by default, we only trigger a round of cleaning if the dirty portion of the log is as large as the cleaned portion. not sure if it's worth doing cleaning more aggressively just to remove the tombstone. so, perhaps we can leave it outside of this pr for now.",-1,0.6173697710037231
367151238,7884,ConcurrencyPractitioner,2020-01-15T22:56:48Z,"yep, done so.",0,0.9339219331741333
367151276,7884,ConcurrencyPractitioner,2020-01-15T22:56:54Z,done.,0,0.9897913336753845
367152424,7884,ConcurrencyPractitioner,2020-01-15T23:00:16Z,"oh, this is used as a means to help the tests in logcleanertest.scala pass. logcleanertest usually wants the tombstones removed in a single pass (but that pass is usually used for setting the delete horizon ms, which means without doing the above, we would be unable to remove tombstones). therefore, by adding the [code block] argument (which is passed in by memoryrecords), whenever logcleaner calls clean log with the current time marked as [code block], we will be able to remove the tombstones / control records in one pass.",0,0.9924083948135376
367152628,7884,ConcurrencyPractitioner,2020-01-15T23:00:52Z,"oh, i can remove that.",0,0.9897627830505371
367153616,7884,ConcurrencyPractitioner,2020-01-15T23:03:46Z,"oh, look in comment above. this delete horizon is used for the case where we want to remove the tombstones in a single pass. on the first iteration of log cleaner, we are unable to remove the tombstone because no delete horizon has not been set yet. therefore, when we compute the delete horizon, we need to pass the delete horizon back into [code block] so that tombstones can be removed in one iteration. on second thought, i think we don't need to add an extra parameter to the [code block] method. such logic would only need to be restricted to logcleaner. i.e. we store the delete horizon in another variable in the record filter we implemented in logcleaner.",0,0.9734810590744019
367154887,7884,ConcurrencyPractitioner,2020-01-15T23:07:25Z,"i did some thinking about this. the integration test i added does not pass without this part. because what happens is that in logs with tombstones, there is the possibility that without further throughput, the cleanable logs will always be empty. therefore, as i mentioned in the comment, since we are in a low throughput situation, logcleaner's workload is relatively light anyways. in that case, we can clean tombstones since we don't have much else to do.",0,0.9493964910507202
367675732,7884,junrao,2020-01-16T22:08:25Z,tombstoneretentionms is duplicated in the javadoc.,0,0.9943563342094421
367675858,7884,junrao,2020-01-16T22:08:39Z,could we add currenttime to the javadoc?,0,0.993954598903656
367679076,7884,junrao,2020-01-16T22:17:04Z,this seems never used?,0,0.9894492626190186
367692941,7884,ConcurrencyPractitioner,2020-01-16T22:57:49Z,"there is a way to figure out whether if log cleaner has a heavy workload or not. if cleanable logs has remained empty for a long period of time (for a set threshold), then we can safely say that the log cleaner thread isn't busy since there is no logs to clean. after that threshold has passed, we can start processing logs with tombstones and removing them. this should help us know exactly when we can go back and remove tombstones.",0,0.9837906956672668
367711171,7884,junrao,2020-01-17T00:02:22Z,"perhaps, we can keep track of the largest deletehorizonms in the cleaned portion. we can then trigger a round of cleaning when the current time has passed the largest deletehorizonms.",0,0.9872758984565735
367731735,7884,junrao,2020-01-17T01:29:55Z,"i am not sure that i understand the need for overloading this and the other method. it seems that this is just so that we can remove the tombstone in one pass in the test? if so, could we just design/fix the test accordingly?",0,0.8464404940605164
367732948,7884,junrao,2020-01-17T01:35:23Z,"hmm, i am still not sure why we need to remove a tombstone in one pass. if a tombstone's delete horizon is not set, it can't be removed in this round of cleaning.",0,0.8612866401672363
371018776,7884,ConcurrencyPractitioner,2020-01-26T18:08:45Z,"yep, i realized that was probably unnecessary, so i removed it.",0,0.9736443161964417
371018800,7884,ConcurrencyPractitioner,2020-01-26T18:08:57Z,"yeah, will get rid of that.",0,0.9135013222694397
371019104,7884,ConcurrencyPractitioner,2020-01-26T18:14:07Z,"alright, acknowledged. i think thats a good point.",1,0.9515682458877563
372143661,7884,ConcurrencyPractitioner,2020-01-29T01:09:37Z,"yeah, i found that this approach probably is a lot better.",0,0.8702921867370605
374441552,7884,junrao,2020-02-04T02:08:37Z,deletehorizonms in the next line is no longer present.,0,0.9847127199172974
374442122,7884,junrao,2020-02-04T02:11:12Z,could we move this up to below retaindeletesandtxnmarkers?,0,0.9948086738586426
375562926,7884,junrao,2020-02-05T23:18:14Z,it's probably better to name writeoriginalbatch here to sth like recordsfiltered since we combine other information to determine writeoriginalbatch later on.,0,0.9902932643890381
375565104,7884,junrao,2020-02-05T23:24:38Z,it seems that the logic can be simplified a bit. it seems that we can do this branch if writeoriginalbatch is true and needtosetdeletehorizon is false (`needtosetdeletehorizon = (batch magic >= v2 && containstombstonesormarker && batch's deletehorizon not set)`).,0,0.9879204034805298
376105398,7884,junrao,2020-02-06T21:58:24Z,"this may not be the best place to track latestdeletehorizon. perhaps we can return the largest deletehorizon in memoryrecords.filterto() and keep track of latestdeletehorizon in the while loop in line 713. if we do that, i am not sure if we need retrievedeletehorizon() since memoryrecords.filterto() can obtain whether deletehorizon is set from the batch and calculate the new deletehorizon if needed.",0,0.9628310799598694
376109770,7884,junrao,2020-02-06T22:08:23Z,"hmm, it seems that we only want to pass in deletehorizonms if `containstombstonesormarker && deletehorizon is not set`.",0,0.9762730002403259
376111679,7884,junrao,2020-02-06T22:12:46Z,islatestversion => supportdeletehorizon?,0,0.9947150349617004
376120400,7884,junrao,2020-02-06T22:34:58Z,could we put the common logic into a shared method to avoid duplicating most of the code below?,0,0.9906445741653442
376122666,7884,junrao,2020-02-06T22:41:04Z,this method seems unused?,0,0.9897484183311462
376122878,7884,junrao,2020-02-06T22:41:37Z,this method seems unused?,0,0.9897484183311462
376124221,7884,junrao,2020-02-06T22:45:04Z,it seems that we need to reinitialize this value at the start of each round of cleaning.,0,0.9889573454856873
376138391,7884,ConcurrencyPractitioner,2020-02-06T23:23:32Z,"oh, that's a good catch! otherwise, we might end up cleaning the logs over and over again.",1,0.9917429089546204
376142170,7884,ConcurrencyPractitioner,2020-02-06T23:35:23Z,"oh, sure, that's fine. but we also still need to account for the control batch and check whether or not it is empty yet.",0,0.9717782139778137
376147542,7884,junrao,2020-02-06T23:53:27Z,"for a control batch, it's only removed at the batch level. so, if the batch can be deleted at the batch level, we won't get in here. if the batch can't be deleted at the batch level, the record within the batch will always be retained.",0,0.9913792610168457
378016120,7884,ConcurrencyPractitioner,2020-02-12T02:54:11Z,"by current logic, this would actually break the code. since we don't pass a [code block] boolean flag into the memoryrecordsbuilder constructor, the memoryrecordsbuilder class's current logic actually relies on the passed in argument to tell if the delete horizon has been set or not. i.e. (if deletehorizonms > 0l, then we set delete horizon, else we assume that it has not been set). should i change the code correspondingly to accomadate your comment?",0,0.9806828498840332
378017124,7884,ConcurrencyPractitioner,2020-02-12T02:58:14Z,"is this always the case? if i remember correctly in the kip, control batches, if it contains only tombstones, will be persisted in the logs for a set period of time i.e. we need to at some point remove the tombstones first _before_ the control batches can be deleted. therefore, i think it would be very much possible that we need to check for [code block] here.",0,0.9904927611351013
378019351,7884,ConcurrencyPractitioner,2020-02-12T03:08:21Z,"well, i think there is multiple problems we might need to think about: 1. we don't know what the current time is since memoryrecords doesn't have access to a [code block] instance. 2. for control batches, [code block] serves a critical function: we call [code block] there to determine if we can set a delete horizon for our batch. in summation, i think that there are multiple dependencies (located in logcleaner) which must be called from [code block]. it would be more of a hassle i think if we need to figure out a way how to call all these methods from filterto as well.",0,0.8798722624778748
378046269,7884,junrao,2020-02-12T05:26:10Z,": a control batch has only a single marker record (either a commit or abort). when all records before the control batch are removed, we set the deletehorizon for the control batch. when the time passes the deletehorizon, the control batch is removed. a control batch never contains a tombstone.",0,0.9904325604438782
379089454,7884,junrao,2020-02-13T20:03:44Z,"good point on #2. my concern is that the batch could be filtered after retrievedeletehorizon() is called. then, the latestdeletehorizon maintained here won't be very accurate.",1,0.7618684768676758
379094481,7884,junrao,2020-02-13T20:14:36Z,"yes, it's just that in this pr, retrievedeletehorizon() returns deletehorizonms > 0 even for batches where deletehorizonms doesn't need to be set. then, we will be setting deletehorizonms for those batches unnecessarily.",0,0.9910166263580322
381024939,7884,junrao,2020-02-19T01:06:47Z,this batch could be filtered later in memoryrecords.filterto(). so if we maintain latestdeletehorizon here. it may not be accurate.,0,0.990689754486084
381031162,7884,junrao,2020-02-19T01:29:53Z,"you were correct earlier that for a control marker, deletehorizon should only be set after transactional records before the marker have already been removed. so, we can't just set needtosetdeletehorizon based on containstombstonesormarker. also, i still feel that retrievedeletehorizon() is a bit weird since it mixes deletehorizonms that's already set with the deletehorizonms to be set. so, perhaps it's clearer if we instead have a method containemptymarker() that simply passes along the return value of shoulddiscardbatch(). then `needtosetdeletehorizon = batch.magic() >= 2 && (containemptymarker || containstombstones) && !batch.deletehorizonset())`. if we need to set deletehorizon, deletehorizonms can be computed off tombstoneretentionms, which can be passed into filterto().",0,0.7611411809921265
381031270,7884,junrao,2020-02-19T01:30:19Z,it seems we should check needtosetdeletehorizon ?,0,0.9938778281211853
381454797,7884,ConcurrencyPractitioner,2020-02-19T18:15:32Z,"alright, sounds cool. this actually makes sense. i got it done.",1,0.9866840243339539
381551654,7884,junrao,2020-02-19T21:21:55Z,this check seems redundant since the caller has verified it already. we can just always return the expected deletehorizon.,0,0.9337124228477478
381552110,7884,junrao,2020-02-19T21:22:56Z,this should now be named containstombstones.,0,0.9950541257858276
381554557,7884,junrao,2020-02-19T21:27:44Z,these two lines are awkward. could we pass them through the constructor of recordfilter?,-1,0.985483705997467
381598053,7884,junrao,2020-02-19T23:03:08Z,"i am not sure that i follow the logic here. to me, the easiest way is to reset log.latestdeletehorizon at the beginning of each round of cleaning. then, we update it with the latestdeletehorizon remaining in each cleaned segment.",0,0.693342924118042
381599279,7884,junrao,2020-02-19T23:06:12Z,"could we just fold containsemptymarker() into this method and let checkbatchretention() return (batchretention, containsemptymarker)?",0,0.993671178817749
382869365,7884,junrao,2020-02-22T01:00:22Z,"cleansegments() just cleans a portion of the log. so, we need to reset log.latestdeletehorizon in the caller doclean().",0,0.9942387342453003
383572781,7884,junrao,2020-02-24T23:20:23Z,this seems to be only used in tests. could we just create a util method in test?,0,0.9920662641525269
383572822,7884,junrao,2020-02-24T23:20:32Z,firstclean is unused.,0,0.9926148653030396
383573289,7884,junrao,2020-02-24T23:21:50Z,"it would be useful to indicate that trackedhorizon is to cover tombstones in legacy message format. so, perhaps we could name it sth like legacydeletehorizonms?",0,0.9939940571784973
383574205,7884,junrao,2020-02-24T23:24:38Z,discarding tombstones => discarding legacy tombstones ?,0,0.9906007051467896
383575250,7884,junrao,2020-02-24T23:27:41Z,deletion horizon => legacy deletion horizon ?,0,0.9910995364189148
383576155,7884,junrao,2020-02-24T23:30:28Z,no need for space before (.,0,0.9941337704658508
383577646,7884,junrao,2020-02-24T23:34:52Z,containsemptymarker => containsmarkerforemptytxn ?,0,0.9939086437225342
383578258,7884,junrao,2020-02-24T23:36:54Z,we can just do [code block],0,0.9946105480194092
383579725,7884,junrao,2020-02-24T23:41:45Z,this can be [code block],0,0.9956766963005066
383580041,7884,junrao,2020-02-24T23:42:55Z,it seems this can be simplified to the following? `shouldretaindeletes = !batch.deletehorizonset() || currenttime < batch.deletehorizonms()`,0,0.993110179901123
383580335,7884,junrao,2020-02-24T23:43:50Z,retaindeletes => retaindeletesforlegacyrecords ?,0,0.9926309585571289
383581756,7884,junrao,2020-02-24T23:48:20Z,batchretentionandemptymarker => batchretentionresult ?,0,0.9917919635772705
383582417,7884,junrao,2020-02-24T23:50:19Z,the tombstones => the tombstones or txn markers,0,0.9946514964103699
383585273,7884,junrao,2020-02-24T23:59:07Z,"not sure if we need these comments. if we do need them, it seems they should be added to the implementation in logcleaner.",0,0.89239501953125
383585606,7884,junrao,2020-02-25T00:00:14Z,"hmm, this comment seems out of place.",0,0.6454674005508423
383619974,7884,junrao,2020-02-25T02:02:28Z,this doesn't look right. we need to track not only newly generated deletionhorizon but also existing one if the batch is kept.,-1,0.5266073346138
383620136,7884,junrao,2020-02-25T02:03:11Z,batch and containsemptymarker are unused.,0,0.9941824078559875
384268522,7884,ConcurrencyPractitioner,2020-02-26T04:25:16Z,aren't we already keeping track of each individual delete horizon in each batch's first timestamp? my impression was that this result would just return the biggest delete horizon seen so far.,0,0.9813123345375061
384284272,7884,junrao,2020-02-26T05:41:46Z,": if we get into the else branch in line 210, it seems that we still need to call filterresult.updatelatestdeletehorizon() since the batch may contain deletehorizon?",0,0.9903479814529419
384597604,7884,ConcurrencyPractitioner,2020-02-26T16:10:30Z,"oh, i see. makes sense. i misunderstood what the comment was suggesting.",0,0.8968217372894287
384611807,7884,ConcurrencyPractitioner,2020-02-26T16:30:59Z,"just a note, i actually did resolve this comment with my previous push. turns out i spotted this error while running over the code previously. just didn't realize that it actually resolved this one as well.",0,0.9515140652656555
384793024,7884,junrao,2020-02-26T21:59:46Z,retaindeletesandtxnmarkers => retainlegacydeletesandtxnmarkers ?,0,0.9923697710037231
384795228,7884,junrao,2020-02-26T22:04:17Z,batchretentionandemptymarker => batchretentionresult ?,0,0.9917919635772705
384804732,7884,junrao,2020-02-26T22:24:41Z,"if we get in here, it could be that this batch already has deletehorizon set. if we pass in recordbatch.no_timestamp to buildretainedrecordsinto(), we will lose the deletehorizon. so, we need to pass in the existing deletehorizon to buildretainedrecordsinto() and also reflect that deletehorizon in filterresult.",0,0.9927270412445068
384806582,7884,junrao,2020-02-26T22:28:41Z,typo thoroughput,0,0.991868257522583
384810439,7884,junrao,2020-02-26T22:37:28Z,we probably don't need to assert this since we explicitly inserted some tombstones.,0,0.9859886169433594
384810766,7884,junrao,2020-02-26T22:38:17Z,"to avoid transient failures, we probably want to give long enough maxwaitms, sth like 5 secs.",0,0.9866853952407837
384811017,7884,junrao,2020-02-26T22:38:53Z,this seems unnecessary since we are waiting in cleaner.awaitcleaned() already later.,0,0.9053515195846558
384811420,7884,junrao,2020-02-26T22:39:55Z,this seems to be a complicated way of getting latestoffset. we could just do log.logendoffset.,0,0.8671212196350098
384818440,7884,junrao,2020-02-26T22:56:55Z,"the value of the map is an offset. so, it's weird to put in deletehorizon as the value. also, there seems to be an existing issue with the test. it seems that shouldremain in line 90 should be computed before line 89.",-1,0.964134693145752
384827619,7884,junrao,2020-02-26T23:22:15Z,"why do we need to set current time to long.maxvalue - tombstoneretentionms - 1? for verifying the removal of the tombstone, it's clearer if we set the currenttime in mocktime before the first round of cleaning and then explicit set current time to be tombstoneretentionms longer than that currenttime in a subsequent round of cleaning to verify that the tombstone is removed. ditto below.",0,0.99228435754776
384829410,7884,junrao,2020-02-26T23:27:43Z,could we add a comment on why we need two passes?,0,0.9938190579414368
384835414,7884,junrao,2020-02-26T23:46:13Z,"since there is no marker, it seems that containsmarkerforemptytxn should be false.",0,0.9913801550865173
384835749,7884,junrao,2020-02-26T23:47:16Z,"since there is no marker, it seems that containsmarkerforemptytxn should be false.",0,0.9913801550865173
384835973,7884,junrao,2020-02-26T23:48:03Z,"since there is no marker, it seems that containsmarkerforemptytxn should be false.",0,0.9913801550865173
384837927,7884,junrao,2020-02-26T23:54:01Z,could we use recordbatch.no_timestamp instead of -1l?,0,0.9939634203910828
384848752,7884,ConcurrencyPractitioner,2020-02-27T00:28:59Z,"this was one part of the test which i had some problems with. notably, what happens is that we will try to calculate the delete horizon using long.maxvalue as the current time. inherently, an integer overflow error will occur (and we end up with some very low negative number). therefore, i thought that we can get around it by setting the delete horizon to some value which would not have problems with overflow (hence largedeletehorizon having the above value you mentioned.)",0,0.9008388519287109
384854011,7884,ConcurrencyPractitioner,2020-02-27T00:46:54Z,"yeah, it definitely is inconsistent with other tests in that there is a thread.sleep(). problem is that this test seems prone to be somewhat flaky. without the sleep, at the present state, it definitely fails.",0,0.8148474097251892
384855964,7884,ConcurrencyPractitioner,2020-02-27T00:53:07Z,"also, about setting mock time. mock time is in fact never called in doclean. it is called in just clean(). the currenttime supplied to doclean is from clean(). so what you stated probably only applies to methods which call the regular clean() method.",0,0.9918264150619507
385391824,7884,junrao,2020-02-27T21:50:31Z,"instead of sleeping, it's more reliable to just do cleaner.awaitcleaned() and assert the return value to be true.",0,0.9912277460098267
385393585,7884,junrao,2020-02-27T21:54:21Z,"hmm, in the previous round of cleaning, the dirty offset is already moved to log.logendoffset. so, this call seems to also hit the timeout. another way is to do testutils.waituntiltrue(log.size() == 0). then, we don't need the code in line 214 to 216.",0,0.9837536215782166
385402234,7884,junrao,2020-02-27T22:13:38Z,"if we set currenttime to largedeletehorizon in the previous round of cleaning, we need to set the current time to long.maxvalue - 1 in order for the marker to be removed.",0,0.9937492609024048
385409940,7884,junrao,2020-02-27T22:31:37Z,it doesn't seem that we need to convert this to runtwopassclean().,0,0.991999089717865
385409985,7884,junrao,2020-02-27T22:31:43Z,it doesn't seem that we need to convert this to runtwopassclean().,0,0.991999089717865
385410725,7884,junrao,2020-02-27T22:33:33Z,it seems this is a case that we should use runtwopassclean().,0,0.9913123250007629
385412064,7884,junrao,2020-02-27T22:37:09Z,it seems that currenttime should be set to long.maxvalue - 1 to make sure the record still remains after the deletehorizon.,0,0.992580771446228
385414150,7884,junrao,2020-02-27T22:42:40Z,"it's clearer if we set currenttime to largedeletehorizon here and in the second round of cleaning, set currenttime to long.maxvalue - 1. we also want to change the comment above accordingly.",0,0.9926276803016663
385414334,7884,junrao,2020-02-27T22:43:11Z,"in this case, it seems that one round of doclean() is enough.",0,0.9919995665550232
385416143,7884,junrao,2020-02-27T22:48:06Z,"similar here. if we set currenttime to largedeletehorizon in the first round cleaning, we can just do one round of cleaning with currenttime set to long.maxvalue - 1 and the first marker should be removed.",0,0.991701066493988
385418628,7884,junrao,2020-02-27T22:55:11Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9920443296432495
385419500,7884,junrao,2020-02-27T22:57:42Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9920443296432495
385419989,7884,junrao,2020-02-27T22:58:59Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9920443296432495
385420266,7884,junrao,2020-02-27T22:59:48Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9920443296432495
385420579,7884,junrao,2020-02-27T23:00:44Z,no need for this change since recovery point is not related to deletehorizon.,0,0.9915231466293335
385420800,7884,junrao,2020-02-27T23:01:15Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9920443296432495
385420835,7884,junrao,2020-02-27T23:01:21Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9920443296432495
385420853,7884,junrao,2020-02-27T23:01:26Z,no need for this change since the intention is to put maxvalue as the offset in the map.,0,0.9920443296432495
385422158,7884,junrao,2020-02-27T23:05:04Z,"perhaps it's clearer with ""on the first run, set the delete horizon in the batches with tombstone or markers with empty txn records.""",0,0.983290433883667
385429375,7884,junrao,2020-02-27T23:27:13Z,"with this pr, we can set currenttime to largedeletehorizon and the marker should still be preserved. we can change the comment above accordingly.",0,0.9943985342979431
385841515,7884,junrao,2020-02-28T18:03:18Z,let's assert that the return value is true.,0,0.9930269122123718
385841874,7884,junrao,2020-02-28T18:04:07Z,this is unnecessary given the waituntiltrue() below.,0,0.9943438768386841
385843938,7884,junrao,2020-02-28T18:09:10Z,"we can be more generous with waittimems. so, using the defaults for both waittimems and pause is probably fine.",0,0.9889147877693176
385848945,7884,junrao,2020-02-28T18:20:20Z,"this is still a bit confusing. could we define 2 vals, beforedeletehorizon and afterdeleteionhorizon? the former takes long.maxvalue - tombstoneretentionms - 1 and the latter takes long.maxvalue. the comment can be changed to sth like ""current time is still before deletehorizon"". it would be useful to do this consistently across other tests.",-1,0.5039217472076416
385851682,7884,junrao,2020-02-28T18:26:00Z,the previous comment was not addressed. it doesn't seem that we need to convert this to runtwopassclean().,0,0.9946650266647339
385854943,7884,junrao,2020-02-28T18:32:59Z,"in this case, it seems that one round of doclean() is enough as long as we set currenttime to postdeletehorizon.",0,0.9918268918991089
385855310,7884,junrao,2020-02-28T18:33:46Z,"similar here. if we set currenttime to largedeletehorizon in the first round cleaning, we can just do one round of cleaning with currenttime set to long.maxvalue - 1 and the first marker should be removed.",0,0.991701066493988
386758173,7884,junrao,2020-03-03T01:56:04Z,"could we add the following comment above? ""the deletehorizon for {producer2: commit} is still not set yet.""",0,0.9953727126121521
386758582,7884,junrao,2020-03-03T01:57:36Z,"could we add the following comment above? ""in the first pass, the deletehorizon for {producer2: commit} is set. in the second pass, it's removed.""",0,0.9953289031982422
388490888,7884,junrao,2020-03-05T18:49:32Z,"could we add the following comment? ""in the first pass, deletehorizon is set for the abort marker. in the second pass, the abort marker is removed.",0,0.9958083629608154
388507941,7884,junrao,2020-03-05T19:18:44Z,we could just use one pass of cleaning with currenttime = long.maxvalue.,0,0.9942606687545776
388509040,7884,junrao,2020-03-05T19:20:36Z,"could we add the following comment? ""in the first pass, the deletehorizon for the commit marker is set. in the second pass, the commit marker is removed, but the empty batch is retained for preserving the producer epoch.""",0,0.9951478838920593
388511801,7884,junrao,2020-03-05T19:25:20Z,"could we change the comment to the following? ""aborted records are removed, but the abort marker is still preserved.""",0,0.9933005571365356
388512379,7884,junrao,2020-03-05T19:26:18Z,"could we change the comment to the following? ""in the first pass, the delete horizon for the abort marker is set. in the second pass, the abort marker is removed.""",0,0.9947391152381897
388514252,7884,junrao,2020-03-05T19:29:45Z,"could we change the comment to the following? ""in the first pass, the delete horizon for the first marker is set. in the second pass, the first marker is removed.""",0,0.9946451187133789
388516416,7884,junrao,2020-03-05T19:34:06Z,this can just be one pass cleaning with currenttime = largetimestamp.,0,0.9937347769737244
388517353,7884,junrao,2020-03-05T19:35:57Z,"could we add the following comment? ""in the first pass, the delete horizon for the abort marker is set. in the second pass, the abort marker is removed.""",0,0.9952238202095032
391180372,7884,hachikuji,2020-03-11T18:32:07Z,why don't we move these into `abstractlegacyrecordbatch`?,0,0.9933983087539673
391184841,7884,hachikuji,2020-03-11T18:40:03Z,nit: can we use `hasdeletehorizonms`. another option would be to make `deletehorizonms` return an optional long.,0,0.9918268918991089
391187776,7884,hachikuji,2020-03-11T18:45:22Z,"hmm.. it seems a bit brittle to rely on documentation for this. i'm considering if we should change names to better reflect this. for example, maybe we should call this `basetimestamp` and add a new method for `firstrecordtimestamp` or something like that.",-1,0.5775684118270874
391189939,7884,hachikuji,2020-03-11T18:49:05Z,nit: why don't we initialize the variables here? e.g. [code block],0,0.9908169507980347
391190505,7884,hachikuji,2020-03-11T18:50:08Z,nit: no need for parenthesis,0,0.9940282106399536
391194791,7884,hachikuji,2020-03-11T18:57:46Z,why do we pass `writeoriginalbatch` here? its value is always `true`.,0,0.9927385449409485
391198263,7884,hachikuji,2020-03-11T19:04:26Z,"if we are not retaining this record, then records have been filtered, so shouldn't `recordsfiltered` be true? the original code used `writeoriginalrecord` instead of `recordsfiltered`, which seems clearer to me. even `batchiterationresult` still preserves the original name.",0,0.9905019998550415
391199350,7884,hachikuji,2020-03-11T19:06:43Z,i think we can name this more specifically to its usage in filtering. perhaps call it `batchfilterresult` or something.,0,0.9831436276435852
391199694,7884,hachikuji,2020-03-11T19:07:21Z,nit: fix alignment,-1,0.7171973586082458
391200796,7884,hachikuji,2020-03-11T19:09:30Z,maybe we can call this `filterbatch`,0,0.9878547787666321
391203869,7884,hachikuji,2020-03-11T19:15:37Z,"i guess this should take into account the magic version? if the magic version is older than v2, i think this should return false?",0,0.9886188507080078
391204835,7884,hachikuji,2020-03-11T19:17:28Z,not sure why current time needs to be passed through here. are you trying to save an extra call to `time.milliseconds()` or something?,0,0.9638276100158691
391205039,7884,hachikuji,2020-03-11T19:17:53Z,i think `deleteretentionms` would be a better name since it is more general than tombstone cleanup.,0,0.9762735366821289
391224340,7884,hachikuji,2020-03-11T19:54:15Z,i'm trying to understand why we need to collect this from `checkbatchretention`. why don't we collect this in `iterateoverbatch` as we do for `containstombstones`?,0,0.9796575903892517
391228346,7884,hachikuji,2020-03-11T19:58:33Z,we are only updating `firsttimestamp` when a record gets appended. does that mean we cannot create an empty batch with the delete horizon set? i would expect that the constructor would initialize `firsttimestamp` to `deletehorizonms` if it is greater than 0.,0,0.9938523769378662
391239196,7884,hachikuji,2020-03-11T20:10:52Z,"note that `batchretention` is an enum. if there is some state that it is not sufficient to capture, then we can add a new state.",0,0.9935281872749329
391331852,7884,ConcurrencyPractitioner,2020-03-11T23:46:09Z,"yeah, record filter seemed to be the most convenient medium through which we can pass the current time. i don't want to pass in the time instance, so i just passed the time here.",0,0.9858770370483398
391334367,7884,ConcurrencyPractitioner,2020-03-11T23:54:47Z,"ah, perhaps i should've some comments to indicate what is going on. if you would look through the [code block] implementation, you would note that [code block] must be called to determine if the control batch is empty. and the content of that call is stored in containsmarkerforemptytxn. furthermore, this value is crucial for [code block] to function correctly (as it needs to know if the control batch can be removed). therefore, what we decided to do, is that we call oncontrolbatchread at the beginning of checkbatchretention and return it along with the batchretention enum (as we will need to use containsmarkerforemptytxn later for checking whether or not we retain individual records.)",0,0.9757107496261597
391335870,7884,ConcurrencyPractitioner,2020-03-12T00:00:22Z,acknowledged. the name is a bit contradictory with its value assignments.,0,0.5765786170959473
391336806,7884,ConcurrencyPractitioner,2020-03-12T00:03:40Z,"if i am understanding this correctly, an empty batch does not contain tombstones, right? if we append a tombstone as the first record, then the delete horizon will be set. but if there isn't any tombstones, there isn't any delete horizon to set. so how would we set a delete horizon for an empty batch?",0,0.9686350226402283
393876656,7884,ConcurrencyPractitioner,2020-03-17T18:12:54Z,"oh, sorry about the misunderstanding. i see what you mean by that now. you're right. i should take this into account.",-1,0.9892838597297668
393880203,7884,ConcurrencyPractitioner,2020-03-17T18:18:41Z,"good point, version checking would be needed.",1,0.9532691240310669
108020004,2735,hachikuji,2017-03-24T23:58:22Z,i think we should consider turning off `parameternumber` check if we're just going to keep increasing it.,0,0.9783323407173157
108020604,2735,hachikuji,2017-03-25T00:07:22Z,the name seems like it could be a source of confusion. i wonder if we should rename this to something like `pidstate` or `produceridstate` and maintain the actual transaction state separately? do you think the coupling will be so tight that they will need to be tracked in the same class?,0,0.9743590950965881
108021095,2735,hachikuji,2017-03-25T00:15:06Z,i think this comment is out of date.,0,0.6505255699157715
108021197,2735,hachikuji,2017-03-25T00:16:57Z,"i wonder if we should require the string to be null or non-empty. in guozhang's current tc patch, we treat the empty string the same as null, but maybe we shouldn't actually allow the client to send an empty string? seems doing so would be more likely to cause problems than not.",0,0.9238340258598328
108027736,2735,apurvam,2017-03-25T04:24:37Z,"yes. we should not allow empty strings imo. my transactional producer patch treats an empty transactionalid as being 'unset', and i think it makes sense to enforce that across the board.",0,0.9702543020248413
108027961,2735,apurvam,2017-03-25T04:39:37Z,"i don't know what a good name is for this. it currently maintains the `pidandepoch` and the pid->sequence number mappings. eventually, it will also store the transactional id, whether there is an active transaction, and the partitions belonging to the currently active transaction. there is no real coupling between the latter transactional state and the sequence number tracking except for the `pidandepoch`. as such, if we want to separate them, then a clean separation would require 3 classes. my preference would be to keep them all together, and just call it `transactionstate` or `transactionalstate`.",0,0.8476756811141968
108027985,2735,apurvam,2017-03-25T04:40:57Z,"i think there is still some value in keeping this check. the reason the number is being bumped here is because the sender constructor has added an argument. the solution would be to have a builder, but then a builder doesn't make sense for the sender. it may make sense to just exempt the `sender` for this check, but i am not sure if that is possible.",0,0.9763045907020569
108027989,2735,apurvam,2017-03-25T04:41:04Z,"i think we should modify this check and throw an `illegalstateexception` if we try to set producer state after the batch is closed, as that should never happen with the current code.",0,0.9841939806938171
108296196,2735,hachikuji,2017-03-27T22:29:39Z,"this should either be `>` or `>= 0`. we could also move this check to the caller. either way, we probably need a test case.",0,0.9939445853233337
108311921,2735,apurvam,2017-03-28T00:32:34Z,this is now fixed.,0,0.972129225730896
108311947,2735,apurvam,2017-03-28T00:32:54Z,i have addressed this.,0,0.9923794269561768
108320177,2735,hachikuji,2017-03-28T02:00:26Z,we seem to have lost this comment.,0,0.958361029624939
108558825,2735,ijuma,2017-03-28T23:06:29Z,"hmm, are we going to remove these methods before we merge this pr?",0,0.9819721579551697
108558953,2735,ijuma,2017-03-28T23:07:18Z,this seems unused?,0,0.9904127717018127
108559235,2735,apurvam,2017-03-28T23:08:55Z,"yes.. i am about to push changes that removes these, here and in other places.",0,0.9828377962112427
108559389,2735,apurvam,2017-03-28T23:10:03Z,good catch. it was added during the initial implementations to generate pids before the server side code was ready.,1,0.9885678291320801
108571037,2735,junrao,2017-03-29T00:43:59Z,it doesn't seem time is being used.,-1,0.618641197681427
108571055,2735,junrao,2017-03-29T00:44:11Z,"log entry => record batch. perhaps it's clearer to say records received in the follower, instead of replication.",0,0.9934386610984802
108571063,2735,junrao,2017-03-29T00:44:17Z,"hmm, not sure why we need to expire the ids before the dirty offset.",0,0.8096150159835815
108571083,2735,junrao,2017-03-29T00:44:25Z,"it seems that the snapshots are created under a dir named topic-partition. so, it seems we don't need to include ${topicpartition.topic}-${topicpartition.partition} here?",0,0.9928373694419861
108571107,2735,junrao,2017-03-29T00:44:31Z,is this needed since we already did that during initialization of the class?,0,0.9939135909080505
108571120,2735,junrao,2017-03-29T00:44:35Z,"it doesn't seem that we are returning a value. if so, we want to remove =.",0,0.9883132576942444
108571134,2735,junrao,2017-03-29T00:44:41Z,probably log initpidrequest too?,0,0.9939224123954773
108571140,2735,junrao,2017-03-29T00:44:43Z,we will need to check if the request is authorized.,0,0.9915599226951599
108577375,2735,junrao,2017-03-29T01:54:04Z,"in replicafetcherthread, we probably want to log a warning if logappendinfo.isduplicate is true after the append() call since it's not expected.",0,0.9919375777244568
108577383,2735,junrao,2017-03-29T01:54:12Z,do we need this? it seems that we already validate this in producerequest.validaterecords() when the broker receives the produce request.,0,0.9947274327278137
108577397,2735,junrao,2017-03-29T01:54:23Z,could we make it clear that the latter epoch is the server epoch?,0,0.9921092391014099
108577429,2735,junrao,2017-03-29T01:54:37Z,should we do the same check for expiration when loading a snapshot?,0,0.9928680658340454
108577433,2735,junrao,2017-03-29T01:54:41Z,what is a base name?,0,0.9939675331115723
108577476,2735,junrao,2017-03-29T01:55:14Z,it doesn't seem that we have the logic to take snapshots periodically since this method is only called from tests?,0,0.9900469183921814
108577487,2735,junrao,2017-03-29T01:55:18Z,remove after?,0,0.9940006136894226
108593416,2735,apurvam,2017-03-29T05:23:32Z,"it is actually the producer epoch which is stale in this case, but will clarify the exception message.",0,0.9916443228721619
108593532,2735,apurvam,2017-03-29T05:24:58Z,"good catch, will add a periodic cleaner task.",1,0.9851464629173279
108593569,2735,apurvam,2017-03-29T05:25:31Z,i added a jira to track this in a future pr: [a link],0,0.9955728054046631
108730187,2735,junrao,2017-03-29T16:57:16Z,"it would be inconvenient for a user to have to configure 2 other properties after enabling idempotence. perhaps we could set these 2 values to a reasonable default (e.g., 3 retries) if the user doesn't configure these properties explicitly. if the user explicitly set those properties with an incorrect value, we can then throw an exception.",0,0.9260677695274353
108730238,2735,junrao,2017-03-29T16:57:24Z,"hmm, in sendandawaitinitpidrequest(), we just initiate a pid request w/o checking if we actually can send to the node. not sure if this is safe. networkclient also sends internal metadata request. so, it's possible that an ongoing metadata request is still pending on the same node and the send of pid request will hit an illegalstateexception in networkclient.dosend().",0,0.9397011399269104
108746944,2735,hachikuji,2017-03-29T18:07:27Z,nit: `is true` seems redundant.,0,0.8700786828994751
108747353,2735,hachikuji,2017-03-29T18:09:15Z,discussed offline. we agreed it's not actually necessary to block here since the sequence number is not assigned until the batch is ready to be sent anyway.,0,0.9923496842384338
108751964,2735,apurvam,2017-03-29T18:28:51Z,it seems to be called from `kafkaserver.scala:236`,0,0.9941376447677612
108758172,2735,apurvam,2017-03-29T18:53:31Z,not sure i follow. the `producerequest.validaterecords` just checks that the right message format goes with the right version. this check further validates that there is exactly one `recordbatch` in a produce request with the new message format. seems to me that the checks complement each other.,0,0.952607274055481
108763087,2735,junrao,2017-03-29T19:15:17Z,"producerequest.validaterecords() has the following, right? [code block]",0,0.9956015348434448
108763450,2735,junrao,2017-03-29T19:16:51Z,"apply() is being called, but is time actually being used?",0,0.9903726577758789
108764029,2735,apurvam,2017-03-29T19:19:39Z,you are right. will delete this check.,0,0.963342010974884
108764889,2735,apurvam,2017-03-29T19:23:53Z,"ah. so this is a reduced version of the class in the transactions branch. `time` is used in the `transactionstatemanager`, which is instantiated in the apply method.",0,0.9912506341934204
108766424,2735,apurvam,2017-03-29T19:31:23Z,good catch. deleted.,1,0.99398273229599
108783378,2735,hachikuji,2017-03-29T20:49:21Z,this is no longer used.,0,0.9890861511230469
108784158,2735,hachikuji,2017-03-29T20:52:32Z,"now that we've merged the crc32c patch, we may as use that.",0,0.9929711222648621
108788282,2735,apurvam,2017-03-29T21:10:42Z,i think this comment is outdated. i updated with the actual logic. the snapshot files will be located inside a `pid-mapping` subdirectory of the log directory. the files themselves will be named with the pattern `$lastoffset.snapshot`.,0,0.9811400175094604
108793143,2735,junrao,2017-03-29T21:34:12Z,"not sure if we strictly needs to iswriteable. currently, during append(), if the current producerbatch is full, we just create a new batch.",0,0.9670512676239014
108822679,2735,apurvam,2017-03-30T01:09:32Z,"actually, i undeleted these lines as they are needed. the `loadsnapshot` can be called in two cases: during initial start, and also when the log is truncated. in the latter case, if there is no previous snapshot, we need to reset to the start offset, which is what this code does.",0,0.9935757517814636
108841803,2735,apurvam,2017-03-30T05:05:10Z,"i have implemented this. the silght modification is that since the only invalid retries config is 0, which is the default, i just override the default to 3 when idempotence is enabled.",0,0.9924155473709106
108842422,2735,apurvam,2017-03-30T05:14:16Z,i just deleted this block from the producer.,0,0.9946125745773315
108844057,2735,apurvam,2017-03-30T05:35:50Z,"hmm. you may be right. the reason i introduced `iswritable` is because we can no longer close a batch when it is full. we can only close it at the point of sending in order to set the right sequence number. so i introduced `iswritable` to denote the state where it can no longer take appends, but is not closed. your point is valid: once a batch is considered full for a particular append, no future appends should go to it since there will be another batch at the tail which should get the new appends.",0,0.9177924394607544
108844701,2735,apurvam,2017-03-30T05:42:24Z,"so, looking over it a bit more, i now know why i introduced `iswritable`. the `isfull` method is not only used during append. it is also used to wake the sender up: if the deque is of size one and the only batch in there is not full, the sender will not be woken up to drain until it hits the linger ms. by introducing `iswritable` we can get the batch to be drained slightly quicker. not sure if the extra state is worth that optimization though.",0,0.9437289237976074
108957136,2735,junrao,2017-03-30T15:26:11Z,"hmm, in recordaccumulator.append(), we return the following. so if the current batch doesn't have enough space, we will create another one. then dq.size() will be > 1 and isfull will be true anyway. `return new recordappendresult(future, dq.size() > 1 || batch.isfull(), true);`",0,0.9806506037712097
108990172,2735,apurvam,2017-03-30T17:40:56Z,yes. that makes sense. i will drop `iswritable`.,0,0.984387993812561
108999545,2735,apurvam,2017-03-30T18:18:17Z,i have added this log line.,0,0.9950656294822693
109008262,2735,apurvam,2017-03-30T18:53:33Z,"synced offline, and we agreed this isn't a real problem since both `getreadynode` and `sendandawaitinitpidrequest` call poll. this will mean than any outstanding requests will get a chance to be processed there will be no deadlock.",0,0.992095947265625
109035640,2735,junrao,2017-03-30T20:57:34Z,a more reliable way to check if a user explicitly sets the config is to check from config.originals(). ditto for configureretries().,0,0.9933556318283081
109035825,2735,junrao,2017-03-30T20:58:23Z,should we add the comment for isduplicate too?,0,0.9917778968811035
109035966,2735,junrao,2017-03-30T20:58:57Z,perhaps we should default to 2 to increase the chance that we can rebuild from a snapshot after truncation?,0,0.9877951145172119
109036428,2735,junrao,2017-03-30T21:01:07Z,it seems this method is never called?,0,0.9889811277389526
109036442,2735,junrao,2017-03-30T21:01:10Z,"lasttimestamp => maxtimestamp? also, probably add some comments to make it clear that firstseq, lastseq lastoffset and lasttimestamp refer to what's in the last appended batch?",0,0.9943448305130005
109036449,2735,junrao,2017-03-30T21:01:12Z,remove () to be consistent with how we call other methods?,0,0.9919527173042297
109045847,2735,hachikuji,2017-03-30T21:46:55Z,we should probably mention in the docs that enabling idempotence will change the default configurations for retries and in-flight requests. i think it might also be worth adding at least a `debug` level log message in the code that we are overriding the defaults.,0,0.991579532623291
109046583,2735,hachikuji,2017-03-30T21:51:11Z,do we have a test case for this?,0,0.9938742518424988
109047045,2735,hachikuji,2017-03-30T21:53:33Z,"nit: we might want to spell out ""producerid"" in log messages, so there's no potential for confusion.",0,0.9800022840499878
109047372,2735,hachikuji,2017-03-30T21:55:32Z,"given that this class will be used to maintain transactional state as well, perhaps we should use a more explicit name. for example, `resetproducerid`, or maybe `invalideproducerid`.",0,0.9906540513038635
109047769,2735,hachikuji,2017-03-30T21:57:49Z,we shouldn't need a placeholder for the exception unless the intention is to not print the stack trace.,0,0.9890930652618408
109048485,2735,hachikuji,2017-03-30T22:01:48Z,maybe we can add the pids to the exception message?,0,0.9910481572151184
109048510,2735,hachikuji,2017-03-30T22:01:59Z,nit: move to previous line,0,0.9935577511787415
109048622,2735,hachikuji,2017-03-30T22:02:28Z,nit: this could be `else if`?,0,0.9886865615844727
109049954,2735,hachikuji,2017-03-30T22:10:34Z,"we don't have to do it here, but we should make these messages a bit more user-friendly. for example, here we should mention the fact that an old epoch means that this process is probably a zombie and another producer has taken over.",0,0.9858341813087463
109050497,2735,hachikuji,2017-03-30T22:13:57Z,replace log entries with record batches,0,0.9938795566558838
109050709,2735,ijuma,2017-03-30T22:15:09Z,"i don't have all the context, but isn't `3` pretty low? we don't do exponential back-offs, so the recommendation for no data loss is typically higher.",0,0.9456976056098938
109050957,2735,apurvam,2017-03-30T22:16:37Z,what is the recommendation for no data loss?,0,0.9925422668457031
109051026,2735,hachikuji,2017-03-30T22:17:01Z,can we list the possible errors in a comment like we do for other responses?,0,0.9919621348381042
109051149,2735,hachikuji,2017-03-30T22:17:52Z,"we can assert the epoch also? also, this is backwards: the expected value should be listed first.",0,0.9885541796684265
109051741,2735,hachikuji,2017-03-30T22:21:48Z,"i was looking for a test case which verified that the producer pid, epoch, and sequence number are set correctly in the records included with the produce request (e.g. using a `requestmatcher`). do we have one?",0,0.9933706521987915
109051933,2735,hachikuji,2017-03-30T22:22:54Z,what are we aborting? can you clarify in the name?,0,0.9935104250907898
109052070,2735,hachikuji,2017-03-30T22:23:48Z,missing a test case for `reset`?,0,0.9915984869003296
109052173,2735,hachikuji,2017-03-30T22:24:29Z,nit: the convention we're using elsewhere is `pid`. same below.,0,0.994243323802948
109052264,2735,hachikuji,2017-03-30T22:25:01Z,nit: we could probably `import networkclientutils._`,0,0.9923357367515564
109052858,2735,hachikuji,2017-03-30T22:28:31Z,might be a good idea to keep this private. we could add an `increment` method instead of writing to the field directly from external classes.,0,0.9815162420272827
109053045,2735,hachikuji,2017-03-30T22:29:47Z,nit: can we make this `producerid manager`?,0,0.9935239553451538
109053126,2735,hachikuji,2017-03-30T22:30:15Z,nit: no need for the type on the left-hand side.,0,0.9913955330848694
109054302,2735,hachikuji,2017-03-30T22:37:56Z,nit: no need for type on lhs.,0,0.99277663230896
109054659,2735,hachikuji,2017-03-30T22:40:34Z,nit: we can assign `batch.lastoffset - batch.baseoffset +1` to a local variable so it's easier to understand.,0,0.991969645023346
109054856,2735,hachikuji,2017-03-30T22:41:57Z,why was the comment moved here?,0,0.9928243160247803
109054973,2735,hachikuji,2017-03-30T22:42:36Z,probably we should add something to the comment above about doing pid validation.,0,0.9861519932746887
109055788,2735,hachikuji,2017-03-30T22:47:51Z,"might be worth mentioning that the loop will only iterate once for a duplicate client request to be clear that the values below will not be overwritten. would be nice if we could just break, but alas.",0,0.967228353023529
109055870,2735,hachikuji,2017-03-30T22:48:25Z,`warn` seems a bit high. could this be `debug`?,0,0.9566319584846497
109056087,2735,apurvam,2017-03-30T22:49:50Z,"actually, this is called from `produceridmappingtest.checkandupdate`. not sure why the ide doesn't find the usage, but the compiler definitely does!",0,0.9700700640678406
109056104,2735,apurvam,2017-03-30T22:49:57Z,changed the name and added a comment.,0,0.9917746782302856
109056127,2735,hachikuji,2017-03-30T22:50:08Z,is this config part of the kip? do we really need it? i know we had discussed at one point just using a reasonable default.,0,0.9842613935470581
109056174,2735,apurvam,2017-03-30T22:50:31Z,good point. i think an `info` level log would be even more appropriate.,1,0.9687934517860413
109056729,2735,hachikuji,2017-03-30T22:54:13Z,"not clear what a ""valid"" entry is. maybe the check should be inverted and phrased as `hasentryexpired`?",0,0.9520691633224487
109057025,2735,hachikuji,2017-03-30T22:56:19Z,seems this loop would be a little clearer if we just built a list of the snapshot files sorted by offset and iterated over it?,0,0.9865373373031616
109057203,2735,hachikuji,2017-03-30T22:57:30Z,"one thing i was thinking about (for another patch) is whether we should have like a minimum number of messages before it's worth doing another snapshot. if only 5 messages have been written since the last snapshot, for example, maybe we can just skip the new snapshot.",0,0.9714713096618652
109057493,2735,hachikuji,2017-03-30T22:59:29Z,was this intentional?,0,0.9802688956260681
109057570,2735,hachikuji,2017-03-30T23:00:02Z,not sure why the variable name was changed: `error` is more accurate.,0,0.9412769079208374
109058568,2735,hachikuji,2017-03-30T23:06:48Z,nit: you can use `fail` instead,0,0.550036609172821
109058879,2735,hachikuji,2017-03-30T23:09:10Z,nit: seems convention is to have spaces before and after `=`?,0,0.9850316047668457
109062426,2735,ijuma,2017-03-30T23:38:20Z,"i don't think we should split the logic between this and `shouldretainmessage`. for example, the latter already checks `record.iscontrolrecord`.",0,0.9790769815444946
109065402,2735,apurvam,2017-03-31T00:05:33Z,just added one.,0,0.9923717975616455
109065473,2735,apurvam,2017-03-31T00:06:10Z,ok will update as and when i see them. updated this one.,0,0.9892756342887878
109066830,2735,apurvam,2017-03-31T00:20:04Z,"in this case, we want to swallow the exception and try again, since we can't do anything without a pid when idempotence is enabled.",0,0.9892838001251221
109067904,2735,apurvam,2017-03-31T00:32:14Z,"hmm. the only real error codes are when there are transactions, ie. `coordinatornotavailable`, `invalidtransactiontimeout`, and `notcoordinatorfortransactionalid`. i wonder if it makes sense to add these in this patch, or wait till we add transactions.",0,0.9332572221755981
109070585,2735,apurvam,2017-03-31T01:03:23Z,i just added this test.,0,0.9939238429069519
109071152,2735,apurvam,2017-03-31T01:09:52Z,i actually prefer to avoid wildcard imports.,0,0.9570915699005127
109086998,2735,apurvam,2017-03-31T04:42:24Z,not sure how that moved around like that. i think it must have been a fat fingered cut/paste from last night. moved it back now.,0,0.6173867583274841
109087940,2735,apurvam,2017-03-31T04:58:38Z,"i'll bump it down to info. debug seems too low, since this should happen fairly rarely.",0,0.9656486511230469
109088180,2735,apurvam,2017-03-31T05:02:32Z,"not sure if it would be more clear, but probably more efficient. i made the change this way so that we retain the existing logic for picking the latest snapshot less than the given offset.",0,0.9513317942619324
109088358,2735,apurvam,2017-03-31T05:05:11Z,nope. seems to have been there since fpj's time. i fixed it.,0,0.9854221343994141
109088745,2735,apurvam,2017-03-31T05:10:57Z,"hmm. it is not part of the kip. we agreed that 2 would be a good static value, i think. will update.",0,0.9350986480712891
109089311,2735,apurvam,2017-03-31T05:19:20Z,"the reason to choose a positive name is that we use it to retain unexpired entries. if we choose something like `hasentryexpired` we would have to negate the usage everywhere. seems like both have their tradeoffs, so i would prefer to leave it as is.",0,0.9830726385116577
109090712,2735,apurvam,2017-03-31T05:37:14Z,added the comment.,0,0.9931591153144836
109090729,2735,apurvam,2017-03-31T05:37:25Z,added the comment.,0,0.9931591153144836
109090769,2735,apurvam,2017-03-31T05:37:42Z,added a test case.,0,0.9951791763305664
109090797,2735,apurvam,2017-03-31T05:38:10Z,added a line for `isduplicate`,0,0.995081901550293
109092828,2735,apurvam,2017-03-31T06:02:38Z,i consolidated all the logic into `shouldretainmessage`.,0,0.9929728507995605
109131783,2735,ijuma,2017-03-31T10:27:02Z,wouldn't `awaitleastloadednodeready` be a clearer name?,0,0.9809058904647827
109132404,2735,ijuma,2017-03-31T10:31:37Z,nit: it's a bit nicer if we return `long` here.,0,0.9834021329879761
109132472,2735,ijuma,2017-03-31T10:32:05Z,"for my benefit, when we do we use `producer_id` and when do we use `pid`?",0,0.994652271270752
109133247,2735,ijuma,2017-03-31T10:36:33Z,"we can avoid the `currenttimemillis` if `timestamptype` is `create_time`. in that case, we can simply use `no_timestamp`. the same applies for a couple of other methods.",0,0.9934988021850586
109134063,2735,ijuma,2017-03-31T10:41:54Z,it would probably be useful to include some data in this message. maybe the existing pid/epoch/basesequence and the new proposed values?,0,0.9917580485343933
109134528,2735,ijuma,2017-03-31T10:45:09Z,please add a simple unit test in byteutilstest for this.,0,0.9953423738479614
109134743,2735,ijuma,2017-03-31T10:46:43Z,nit: long line.,-1,0.9533277153968811
109135119,2735,ijuma,2017-03-31T10:49:23Z,"hmm, but this same file has been changed to use wildcard imports at the top (e.g. `import org.apache.kafka.common.network._`)?",0,0.9789372086524963
109135874,2735,ijuma,2017-03-31T10:54:46Z,the 5 lines above can be written as: [code block],0,0.9951871037483215
109136849,2735,ijuma,2017-03-31T11:01:42Z,simpler perhaps: [code block],0,0.9917238354682922
109137853,2735,ijuma,2017-03-31T11:09:11Z,"nit: it seems odd to have ""added this test"" as a test comment. something like ""verify behaviour of zkutils.createsequentialpersistentpath since pidmanager relies on it"" seems like the expected style.",-1,0.7122659087181091
109137937,2735,ijuma,2017-03-31T11:09:45Z,why do we have this at error level?,0,0.9750177264213562
109139892,2735,ijuma,2017-03-31T11:22:44Z,"great question. :) infinite is often what is said in talks. but that may not be the right value either. i think it's worth thinking about what the retries help us recover from and how long would we want to keep retrying for. because with the default retry backoff of 100ms, 3 retries get used pretty fast. say that we wanted to keep retrying for 10 seconds, that would be roughly 100 retries. the other side of the coin is: what is the cost of having a high retry number?",1,0.9968692660331726
109161698,2735,ijuma,2017-03-31T13:41:03Z,"nit: i personally find comments that just repeat what the code is doing not so useful. however, if we explained why we need to reset the pid in this case, that would be pretty useful.",0,0.8344599604606628
109162930,2735,ijuma,2017-03-31T13:46:52Z,have we done any performance tests to see the impact of this change? the change i made to close the memory records here made a huge difference to the amount of memory used by the producer due to temporary compression buffers.,0,0.9898721575737
109163235,2735,ijuma,2017-03-31T13:47:58Z,nit: this could just be `recordsbuilder`. we generally avoid the `get` prefix in kafka.,0,0.9892981052398682
109261455,2735,apurvam,2017-03-31T22:29:59Z,"so i thought about this a bit more. i think it still make sense to validate this on the server side. i assume that the librdkafka clients may not have the request side validation, so it would be good to have server side validation before we write to the log.",0,0.9818090796470642
109266099,2735,apurvam,2017-03-31T23:19:18Z,i added this documentation to the `transactionstate.resetproducerid` method.,0,0.9952398538589478
109266180,2735,apurvam,2017-03-31T23:20:06Z,was used during debugging. reverted to debug level.,0,0.9885576963424683
109267210,2735,apurvam,2017-03-31T23:33:57Z,"i think it is a bit arbitrary. it started with pid everywhere, but then started changing gradually to producerid or producer_id.",-1,0.5319858193397522
109269845,2735,apurvam,2017-04-01T00:10:55Z,"actually, the whole error message is out dated. we should not be calling `setproducerstate` on a closed batch any more. doing so is a bug on the client. updated the message to indicate that.",0,0.9902318120002747
109270153,2735,apurvam,2017-04-01T00:16:23Z,done.,0,0.9897913336753845
109277377,2735,junrao,2017-04-01T04:26:50Z,"similar to this, it seems the default acks=1 doesn't make sense when idempotence is enabled. this is because with acks=1, acked messages could be lost during leader change. then, the producer will be out of sequence. perhaps if idempotence is enabled, we should enforce acks=all.",0,0.9854700565338135
109290030,2735,apurvam,2017-04-01T17:45:08Z,"sounds good. of course, we also depend on some topic level settings like: replication.factor >= 3, min.isr >= 2, unclean.leader.election=false. but i agree, we should do what we can on the client.",1,0.7539204955101013
109290465,2735,apurvam,2017-04-01T18:06:22Z,i added the override for acks. will make a note to update the kip as well.,0,0.9942927360534668
109333086,2735,junrao,2017-04-03T02:43:38Z,entry => record,0,0.9902471303939819
109333094,2735,junrao,2017-04-03T02:43:48Z,i thought we agreed that this check is unnecessary given the check in producerequest?,0,0.9915642738342285
109481971,2735,apurvam,2017-04-03T17:52:20Z,"we did, initially, but then i followed up on that thread (which is now impossible to find on github). here is what i wrote:",0,0.9918012022972107
109488221,2735,junrao,2017-04-03T18:18:32Z,"hmm, producerrequest.validaterecords() is called on the broker side when converting bytes from socket to a request object. so, even if librd client has an issue, the broker should still be able to capture this when constructing producerrequest.",0,0.9881622195243835
36813449,130,hachikuji,2015-08-11T23:46:46Z,can you add some documentation for some of these interfaces?,0,0.9948498606681824
37058213,130,ijuma,2015-08-14T08:32:18Z,"since this class is used a lot, making the name short would help (as long as clarify is maintained). how about calling it `pair`?",0,0.9924916625022888
37058443,130,ijuma,2015-08-14T08:36:39Z,this makes `compareto` inconsistent with `equals`. is that intentional?,0,0.9801796674728394
37058480,130,ijuma,2015-08-14T08:37:14Z,maybe explain why?,0,0.983171820640564
37058865,130,ijuma,2015-08-14T08:43:02Z,wouldn't this be better as `return new hashset<>(arrays.aslist(elems))`?,0,0.9940097332000732
37059011,130,ijuma,2015-08-14T08:45:43Z,there is already a `join` method in this class. can you not use that?,0,0.9945747256278992
37059086,130,ijuma,2015-08-14T08:47:15Z,rely on auto-boxing for less verbosity?,0,0.9771721959114075
37146536,130,rhauch,2015-08-16T14:46:09Z,"do you mean ""better"" to be more readable? or more efficient? the current code is does less work than `new hashset<>(arrays.aslist(elems))`.",0,0.9857292175292969
37147003,130,rhauch,2015-08-16T15:37:38Z,"the `run()` and `close()` methods should not be synchronized. because they are, then once `run()` is called it will block any other synchronized method, including `close()`, and because `run()` only completes when `close()` is called, `run()` will never complete. in other words, the thread will never stop. you should be able to simply remove the `synchronized` keywords with the current code and maintain thread safety of the `running` volatile boolean field: the only method that reads that field is the private `stillrunning()` (called via private `runloop()` which is called via public `run()`), while the only method that writes to the field is `close()`.",0,0.9917137622833252
37147025,130,rhauch,2015-08-16T15:40:33Z,"this `recordsprocessed` field is never changed. if it were, it'd probably need to be made volatile, or better yet changed to be `final atomiclong` so that operations are atomic.",0,0.9914553761482239
37147089,130,rhauch,2015-08-16T15:44:05Z,add `lastcommit = now' as a last line in this method?,0,0.9954609274864197
37169892,130,ijuma,2015-08-17T09:13:30Z,", i meant both. by passing the collection to the copy constructor of the `hashset`, the initial size of the internal array is big enough to contain the elements of the collection. this avoids reallocation and rehashing. note that `arrays.aslist` doesn't copy elements, it's just a view over the array. if this view is deemed too expensive (seems doubtful), we could keep the existing code, but then we should pass the correct sizing parameters to the `hashset` constructor.",0,0.980923056602478
37339719,130,rhauch,2015-08-18T19:05:31Z,"the `producerrecord` class has a constructor that takes the partition number, yet that doesn't appear to be exposed in these two `send(...)` methods. am i missing how to specify the partitioning logic for each of the sent messages? update: okay, it's pretty obvious you can set the `partitioner.class` property in the producer's configuration to the name of the `partitioner` implementation class. doing this makes the `kafkaproducer` pass the message key to the `partitioner` to determine the partition number. is this a best practice, or is it still logical for our `processor` implementation to determine the partition, perhaps based upon something other than they key. if so, then it'd be great to have additional `send(...)` methods that take the partition number.",0,0.9900151491165161
37673148,130,rhauch,2015-08-21T20:09:58Z,"the `createsensor(...)` method called on lines 68-75 uses the `this.metrics` field, and because `this.metrics` is not set until line 76 the result is a `nullpointerexception`. to fix, simply move the `this.metrics = context.metrics();` line before the first call to `createsensor(...)`.",0,0.9940692186355591
37675103,130,rhauch,2015-08-21T20:32:23Z,these two lines should get the **de**serializer from the context: [code block],0,0.9956988096237183
37711404,130,rhauch,2015-08-23T22:38:16Z,"this would be easier to implement if the parameter to this method were an `iterable >` than a `list >`. for example, the current `rocksdbkeyvaluestore` uses `byte[]` for the keys and values, and it's pretty easy to wrap that with a parameterized class that uses provided `serializer` and deserializer`instances for the keys and values -- except that the`putall`method cannot be easily implemented as a delegate if it takes a`list`. (in essence, the list has to be fully-copied before the delegation can be made. i'd be happy to provide a patch with this fix.",0,0.9877651333808899
38231414,130,guozhangwang,2015-08-28T18:47:48Z,ack.,0,0.5866091847419739
38231825,130,guozhangwang,2015-08-28T18:51:45Z,"does compareto have to be consistent with equals? i though compareto is supposed to be used as comparable for priorityqueue, etc while equals is for identity matching in map, etc?",0,0.9871992468833923
38232147,130,guozhangwang,2015-08-28T18:54:20Z,ack.,0,0.5866091847419739
38232260,130,guozhangwang,2015-08-28T18:55:31Z,ack.,0,0.5866091847419739
38232422,130,guozhangwang,2015-08-28T18:57:01Z,ack.,0,0.5866091847419739
38232732,130,guozhangwang,2015-08-28T19:00:00Z,"not sure if we can use auto-boxing here, since need to explicitly transform string to integer here.",0,0.9085264205932617
38234637,130,guozhangwang,2015-08-28T19:21:50Z,ack.,0,0.5866091847419739
38237786,130,ijuma,2015-08-28T19:55:28Z,"my bad, i misread.",-1,0.9950941801071167
38237961,130,ijuma,2015-08-28T19:56:57Z,it's generally a good idea. the documentation for `comparable` says: [code block],1,0.9803988337516785
38252600,130,guozhangwang,2015-08-28T23:00:23Z,"ok makes sense, however after a second thought i feel by ""consistency"" we want: 1) if compareto() returns none-zero, equals() should return false; 2) if equals() returns true, compareto() should return zero. but: 3) if equals() returns false, compareto() does not necessarily returns none-zero. 4) if compareto() returns zero, equals() does not necessarily returns true. if we enforce 3) and 4) as well, it means sorted set / map will not allow two records who are comparably same to each other as the docs stated; but for our case, we actually want two stamped objects with the same timestamp to still be stored at the same time as keys if we ever want to do so.",0,0.9809713959693909
38252639,130,guozhangwang,2015-08-28T23:01:09Z,ack.,0,0.5866091847419739
38252646,130,guozhangwang,2015-08-28T23:01:20Z,ack.,0,0.5866091847419739
38252729,130,guozhangwang,2015-08-28T23:02:51Z,ack.,0,0.5866091847419739
38252996,130,guozhangwang,2015-08-28T23:07:55Z,i think we can wrap the producer / consumer configs in the streaming / processor congis as you mentioned.,0,0.9888301491737366
38253008,130,guozhangwang,2015-08-28T23:08:11Z,ack.,0,0.5866091847419739
38589091,130,rhauch,2015-09-02T21:48:22Z,"when a `processor` instance is started, the framework calls `init(processorcontext)`, but with the most recent changes it is no longer possible for a `processor` implementation to get the configuration from the `processorcontext`. how can one pass in the configuration into the `processor`? for example, my processor implementation might require several configuration properties to control or alter the default behavior. using the same configuration sure seemed like a natural way to do this. one option is to pass the `streamingconfig` object into the `processordef` constructor, which would change line 94 to be something like: [code block] the `processdef` could then pass the configuration into the constructor of the `processor` implementation. while that works, it seems like this would then require the `topologybuilder` to contain objects that are dependent upon a configuration, and that might not be the same configuration passed into `new kafkastreaming(builder, config);` (line 98 above). it sure seems better and far simpler to instead allow `processor.init(processorcontext)` access to the same configuration that kafkastreaming has when it is initializing the processor. iow, either change `processorcontext` to expose the configuration (as before), or (better yet imo) add a second parameter to `processor.init(...)` so it then becomes: [code block] thoughts? am i missing something more obvious?",0,0.9865924715995789
38593399,130,rhauch,2015-09-02T22:31:44Z,"can `addsource`, `addsink`, and `addprocessor` be changed to return `topologybuilder` instance so that the builder's methods can be chained together. if so, then this: [code block] becomes: [code block] might not be useful in all situations, but in some cases it works quite beautifully. i'd be happy to submit a pull-request for this. update: here's the very simple pr: [a link]",1,0.7081210017204285
38677576,130,guozhangwang,2015-09-03T18:11:44Z,"that is a good point, will review the pr.",1,0.9598955512046814
38678884,130,guozhangwang,2015-09-03T18:21:45Z,"streamingconfig is supposed to only include config values that are used by the kafkastreaming runtime but not in the user logic, if users do want to modify the behavior of their processors based on some streamingconfig values they can either do: [code block] or they can also pass-in the whole streamingconfig object, which of course can be different from the one they passed into kafkastreaming, into their instantiated processordef constructors, although i personally would not recommend this way. generally i think streamingconfig should not be exposed to the processor interface layer, since it is designed to be used only at the runtime level.",0,0.9831086993217468
38683389,130,rhauch,2015-09-03T19:00:04Z,"okay, that sounds reasonable.",0,0.9763482213020325
38684688,130,rhauch,2015-09-03T19:12:28Z,"the casting done on line 53 from `processorcontext` to `processorcontextimpl` makes testing difficult, as the tests would require a `processingcontextimpl` rather than an alternative. (see how `kstreamtestdriver` uses a `mockprocessorcontext` for an example.) i assume that `recordcollector()` was removed from `processorcontext` to hide it from `processor` implementations, so this cast can either be kept and the test classes required to use a subclass of `processorcontextimpl`, or the `processorcontextimpl` implements another internal interface that `sinknode` can use here when casting and the test classes can choose to implement. thoughts? (it looks like tests that use `kstreamtestdriver` do so by implementing a tail-end mock processor. i'm trying to create a similar test driver for testing a `processor` and a `topology`. right now the only problem is that the `sinknode` throws a classcastexception on line 53.)",0,0.9894184470176697
38686619,130,rhauch,2015-09-03T19:30:48Z,"another option might be to break the current `processorcontextimpl` into two classes: one that holds the objects that all impls would need (e.g., the (de)serializers, the `recordcollector`, the `streamingconfig`, the `arraydeque `, and maybe the `metrics`), and a subclass that adds `streamtask` and `processorstatemanager`. the `sinknode` could cast to the base impl, and the test drivers could have impls that extend the base impl. if this sounds interesting, let me know and i'll create a pr for easier evaluation and comparison.",0,0.9844040274620056
38795321,130,rhauch,2015-09-04T21:21:44Z,"the fact that the `processorcontextimpl` class is creating its own consumer turns out to be a fairly significant problem for test cases, especially those that directly use `streamtask`. i'd love to introduce a `consumersupplier` (in java 8 it'd simply be `supplier `, but alas) and pass an implementation into this constructor and actually into the `streamtask` constructor. this would then move the creation of this `consumersupplier` into the `streamthread`, which is already creating the `kafkaproducer` and `kafkaconsumer` instances used to consume records to pass to the `streamtask`. and if this is acceptable, is it still desirable to use a _separate_ `kafkaconsumer` instance for the `processorstatemanager`?",0,0.8893184065818787
38795471,130,rhauch,2015-09-04T21:24:00Z,"i've been able to work around this problem by directly using `streamtask`, which internally creates its `processorcontextimpl` instance. however, the only roadblock i have is that the `processorcontextimpl` is explicitly creating a `kafkaconsumes`. see the details in [a link].",0,0.9874243140220642
38967999,130,guozhangwang,2015-09-08T19:20:06Z,"yeah i agree this is kinda awkward. the reason we need a separate consumer for restoring state is that the other consumer is 1) created for the thread and shared among its tasks, and 2) its subscribed topics is determined by the topology statically. while for local state the topic name is defined dynamically and the restoration is only one-time: once it is done you do not need to keep subscribing to it anymore. i think one thing we can do here is to move the creation of the restoration consumer into the processor-state-manager, and set a flag into the processor-state- manager's constructor indicating whether we need to create this consumer (set to false for unit tests, for example).",-1,0.9494512677192688
38968103,130,guozhangwang,2015-09-08T19:21:12Z,"btw are you working on adding some unit test classes? since i am also working on some of them, would like to avoid any duplicate work or conflicts :)",0,0.759594202041626
38974963,130,rhauch,2015-09-08T20:22:45Z,"actually, i've written a `processingtopologytestdriver` class under `src/test` that takes a topologybuilder and will make it very easy for projects that use kafka streams to test their topologies with unit tests that do not use a real kafka. each test method can set up the driver, pass one or more methods to the driver (which then forwards them to the appropriate source), and finally check the messages output by the sinks. it's pretty simple, and it uses mock consumers and producers along with a single `streamtask` to do all the heavy lifting. (this has the benefit of also testing the bulk of the `streamtask` implementation.) so, it'd be great if this test driver could pass the consumer for state manager into the `streamtask` constructor took a consumer (or consumer supplier) so that the tests can inject mocks instead; the `streamtask` constructor already takes a consumer and producer, so taking a second consumer for state management seems consistent. right now `streamtask` is the only thing that constructs a `processingcontextimpl`, so passing the consumer down also seem reasonable. this approach also seems to have minimal impact on other code, and imo is better than passing a flag into the processor state manager's constructor or calling a method on the processor state manager, since right now the the `processorstatemanager` is constructed within the `processingcontextimpl` class which itself is constructed within the `streamtask` constructor. btw, the test driver class and a unit test is ready for a pr, except that the tests that use state management are failing right now because it's trying to create a real consumer for state management. i'll go ahead and make the aforementioned change to pass in the consumer, fix my tests, and submit a pr for review first thing tomorrow.",0,0.9550191164016724
39053621,130,rhauch,2015-09-09T15:00:22Z,the pr is now available: [a link],0,0.9933962821960449
39055740,130,rhauch,2015-09-09T15:16:23Z,", how should i proceed with new unit tests. any suggestions so we don't duplicate effort? is there a better way to coordinate other than comments in this pr?",0,0.9758148789405823
39055851,130,rhauch,2015-09-09T15:17:13Z,added a pr with the simple correction: [a link],0,0.9960390329360962
39056201,130,rhauch,2015-09-09T15:19:40Z,"with this configuration of `stream`, the test jars are not build and uploaded to maven. i created a pr ([a link] that corrects this so that the test jars are created and uploaded similarly to how `client` does it.",0,0.9949213862419128
39059471,130,eribeiro,2015-09-09T15:44:26Z,"see, here you should evaluate what is the semantic that `paused` should have. if we want to return a **snapshot** of the paused `topicpartition` then it's better to do: [code block] if we want to return a **dynamic** view of the `paused` then it's better to use: [code block] in either case, we should return an unmodifiable view of the set, because it's not very nice to expose a mutable field directly to callers as above.",0,0.9913608431816101
39059935,130,eribeiro,2015-09-09T15:47:34Z,nit: rename this method to `remove` or `delete`,0,0.9954512715339661
39060300,130,eribeiro,2015-09-09T15:50:39Z,"""returns an empty collection if this list is empty or null""",0,0.9939356446266174
39060354,130,eribeiro,2015-09-09T15:51:00Z,"it is best practice to use `collections.emptylist()` instead of `collections.empty_list` also, would make a difference to return `collections.emptylist()` if the `other` is empty? i mean, like this: ` return other == null || other.isempty() ? collections.emptylist() : other; `",0,0.9917578101158142
39061914,130,eribeiro,2015-09-09T16:02:27Z,private **final**?,0,0.9926930665969849
39062322,130,eribeiro,2015-09-09T16:05:23Z,"why not use `((long) key);` or even `((integer) key)`. no need to call `longvalue()` as the autoboxing is called automatically, afaik.",0,0.9873365759849548
39062772,130,eribeiro,2015-09-09T16:08:56Z,nit: can remove this blank line.,0,0.9935491681098938
39062866,130,eribeiro,2015-09-09T16:09:42Z,it's nice to expose those as: ``public final list keys = new arraylist<>()` same for line 35,0,0.9470492601394653
39062965,130,eribeiro,2015-09-09T16:10:20Z,it's nice to expose those as: `public final list processed = new arraylist<>() same for line 29,0,0.9327090382575989
39063280,130,eribeiro,2015-09-09T16:12:57Z,"paraphrasing joshua bloch, prefer collections to arrays so i would use: [code block]",0,0.9939040541648865
39063561,130,eribeiro,2015-09-09T16:15:18Z,better to make `state` volatile too.,0,0.9886595010757446
39063741,130,eribeiro,2015-09-09T16:16:51Z,"still in this mood, this method could be rewritten as: [code block]",0,0.9899264574050903
39064142,130,eribeiro,2015-09-09T16:20:17Z,"if `state` is different from `created` then lines l#93 and l#94 are unreachable. therefore, why not move them to end of the `if` block? [code block]",0,0.9949178695678711
39064231,130,eribeiro,2015-09-09T16:20:52Z,same as above: lines 121 and 123 can be moved to inside the if block.,0,0.9931673407554626
39065910,130,eribeiro,2015-09-09T16:35:20Z,nit: `private list list = new linkedlist ();`,0,0.9942533373832703
39067165,130,eribeiro,2015-09-09T16:47:24Z,"as all the methods synchronize on the whole body why not make all the methods `synchronized`, like: `public synchronized void close() {` ?",0,0.9927748441696167
39067236,130,eribeiro,2015-09-09T16:48:12Z,formatting: break line as: [code block],0,0.9948182702064514
39067357,130,eribeiro,2015-09-09T16:49:14Z,nit: prefer interfaces on field declaration as: `private final deque nodestack = new arraydeque ();`,0,0.9951297044754028
39067577,130,eribeiro,2015-09-09T16:51:20Z,"tip: you can rewrite as `final int[] expectedkeys = {1, 10, 100, 1000};`",0,0.9901986122131348
39067625,130,eribeiro,2015-09-09T16:51:56Z,"tip: you can rewrite as final `string[] expected = {""1:1"", ""10:2"", ""100:3"", ""1000:4""};`",0,0.9891741275787354
39067732,130,eribeiro,2015-09-09T16:52:53Z,"tip: you can rewrite as `string[] expected = {""0:v0"", ""0:v0"", ""1:v1"", ""1:v1"", ""2:v2"", ""2:v2"", ""3:v3"", ""3:v3""};`",0,0.9882149696350098
39067794,130,eribeiro,2015-09-09T16:53:25Z,"tip: you can rewrite as `final int[] expectedkeys = {0, 1, 2, 3};`",0,0.990044891834259
39089821,130,guozhangwang,2015-09-09T20:11:31Z,i am working on calling for a review round and push the first patch to os now. once that is done further prs can be submitted directly to apache/kafka. could you hold the current changes and rebased them to the apache trunk once this patch is checked in?,0,0.9891680479049683
39090342,130,guozhangwang,2015-09-09T20:16:00Z,ack.,0,0.5866091847419739
39090441,130,guozhangwang,2015-09-09T20:16:43Z,ack.,0,0.5866091847419739
39090503,130,guozhangwang,2015-09-09T20:17:14Z,ack.,0,0.5866091847419739
39090892,130,guozhangwang,2015-09-09T20:20:34Z,"good point, changed to `collections.emptylist()`. the semantics is only to return an empty list if `other` is null, if it is empty then we will still return itself.",1,0.8290067911148071
39090991,130,guozhangwang,2015-09-09T20:21:28Z,ack.,0,0.5866091847419739
39091129,130,guozhangwang,2015-09-09T20:22:51Z,the value integer cannot be cast directly to long.,0,0.988132894039154
39091209,130,guozhangwang,2015-09-09T20:23:27Z,ack.,0,0.5866091847419739
39091297,130,guozhangwang,2015-09-09T20:24:14Z,ack.,0,0.5866091847419739
39091428,130,guozhangwang,2015-09-09T20:25:18Z,ack.,0,0.5866091847419739
39092030,130,guozhangwang,2015-09-09T20:30:19Z,ack.,0,0.5866091847419739
39092290,130,guozhangwang,2015-09-09T20:32:35Z,since the start() / close() are synchronized the states will not be accessed concurrently. so i think it is not necessary?,0,0.9923880100250244
39092328,130,guozhangwang,2015-09-09T20:32:54Z,ack.,0,0.5866091847419739
39092500,130,guozhangwang,2015-09-09T20:34:28Z,ack.,0,0.5866091847419739
39092546,130,guozhangwang,2015-09-09T20:34:53Z,ack.,0,0.5866091847419739
39092616,130,guozhangwang,2015-09-09T20:35:33Z,we used linkedlist's offerlast / etc functions later so we have to declare it as linkedlist.,0,0.9949423670768738
39092736,130,rhauch,2015-09-09T20:36:21Z,it should be volatile so that different threads see the actual value at the same time.,0,0.9872215390205383
39098298,130,eribeiro,2015-09-09T21:22:58Z,"oh, ok. excuse me for overlooking this. you right.",-1,0.9233765602111816
39197241,130,eribeiro,2015-09-10T18:40:16Z,"i would suggest to use a more modern approach that is replace int constants by enums. therefore, it becomes: [code block]",0,0.9916691780090332
39197493,130,eribeiro,2015-09-10T18:42:27Z,nit: a nifty trick to use here (reduces the scope of `iter` would be): [code block],1,0.6161906123161316
39198066,130,eribeiro,2015-09-10T18:47:38Z,using lock objects is considered a old fashioned approach. better to use a reentrantlock as below: [code block],0,0.9781808257102966
39198676,130,eribeiro,2015-09-10T18:52:36Z,"nit: maybe name this method as `of`, like `keyvalue.of(10, ""hello"")`",0,0.9877539277076721
39198875,130,eribeiro,2015-09-10T18:54:24Z,"this line and line below can be : `public final list = new arraylist<>();`, as well as line below.",0,0.9954445362091064
39199065,130,eribeiro,2015-09-10T18:56:02Z,lines 34-36 can be simplified as: `return timestamp - othertimestamp;` a nifty trick ;),1,0.9723280072212219
39199114,130,ijuma,2015-09-10T18:56:33Z,"this is not really true. there are advantages and disadvantages when it comes to choosing between `synchronized` and `reentrantlock`. for low contention cases, `synchronized` tends to do better, in fact.",0,0.9808201193809509
39199275,130,eribeiro,2015-09-10T18:58:03Z,it's usually advisable to 1) make pq final; or 2) create a lock field or 3) synchronize the whole method only don't synchronize on a **non final** field.,0,0.9915329813957214
39199569,130,eribeiro,2015-09-10T19:00:44Z,"yeah, you right. my fault. for low contention synchronized is better.",-1,0.9869160652160645
39212009,130,eribeiro,2015-09-10T20:51:24Z,"i feel maybe we need a method to check the status of this class, that is: [code block] wdyt?",0,0.987274169921875
39214847,130,eribeiro,2015-09-10T21:15:09Z,typo: 'coresponds' should be `correponds`,0,0.9950996041297913
39215090,130,eribeiro,2015-09-10T21:17:13Z,"nit: **i** would name this method as `nulltoempty` to let it clear what it does, but up to you. :)",1,0.9927499294281006
39215276,130,eribeiro,2015-09-10T21:18:57Z,"nit: **i** would name this method `newset`and make it return `set` instead of a `hashset`, but, again, up to you. :) ps: btw, once guava is incorporated into kafka project, the `sets` helper class has methods to replace this one. ;)",1,0.9944027066230774
39228036,130,eribeiro,2015-09-10T23:42:05Z,as above,0,0.9888283014297485
39228037,130,eribeiro,2015-09-10T23:42:05Z,"declare as `public final list keys = new arraylist<>();`, as well as line below",0,0.9954759478569031
39228134,130,eribeiro,2015-09-10T23:43:18Z,"i suppose this is a leftover, right?",0,0.9845178723335266
39228245,130,eribeiro,2015-09-10T23:45:08Z,declare as `private final deque nodestack = new arraydeque<>();`,0,0.9946510195732117
39228751,130,eribeiro,2015-09-10T23:52:50Z,that kafka convention: ` if (condition) statement ` on the following line too.,0,0.9934651255607605
39228814,130,eribeiro,2015-09-10T23:53:34Z,**final** for `keyserializer` and `valserializer`?,0,0.9945347309112549
39228849,130,eribeiro,2015-09-10T23:54:01Z,define as `private final deque fifoqueue;`,0,0.9938083291053772
39471570,130,eribeiro,2015-09-15T03:33:29Z,"hey, why don't we return a empty `iterator` here? you can do this with `collections. emptylist().iterator()`. returning null is usually a code smell. wdyt?",0,0.9517019987106323
39472217,130,eribeiro,2015-09-15T03:50:47Z,can be simplified as `for (int i : expectedkeys) {`,0,0.9938485026359558
39472298,130,eribeiro,2015-09-15T03:53:05Z,format: [code block],0,0.9959810972213745
39472324,130,eribeiro,2015-09-15T03:53:37Z,formatting: no need for curly braces here,0,0.9936422109603882
39472333,130,eribeiro,2015-09-15T03:53:50Z,format: no need for curly braces,0,0.9944583177566528
39472370,130,eribeiro,2015-09-15T03:54:44Z,lines l#53 to l#55 can be simplified as: [code block],0,0.9941415190696716
39472425,130,eribeiro,2015-09-15T03:55:57Z,"i like to rewrite those if-else condition as: `return (stamped == null) ? lastknowntime : stamped.timestamp`, but up to you.",0,0.9883418679237366
39472674,130,eribeiro,2015-09-15T04:02:25Z,formatting: no need for curly braces,0,0.9928838014602661
39472691,130,eribeiro,2015-09-15T04:02:50Z,formatting: no need for curly braces.,0,0.9907959699630737
39472770,130,eribeiro,2015-09-15T04:05:04Z,that **snapshot** vs **dynamic view** intention: what do we want here? if it's the current snapshot then it's `return new hashset<>(partitionqueues.keyset());`,0,0.9948365688323975
39472806,130,eribeiro,2015-09-15T04:06:00Z,formatting: no need to curly braces,0,0.9917578101158142
39472985,130,eribeiro,2015-09-15T04:10:55Z,doesn't it need a `new hashset<>(sourcebytopics.keyset())` to return a snapshot as line 46?,0,0.9945171475410461
39473139,130,eribeiro,2015-09-15T04:14:03Z,`list result = new arraylist<>();`,0,0.9911454319953918
39473154,130,eribeiro,2015-09-15T04:14:24Z,`list expected = new arraylist<>();`,0,0.9910274147987366
39473162,130,eribeiro,2015-09-15T04:14:41Z,`list expected = new arraylist<>();`,0,0.9910274147987366
39473198,130,eribeiro,2015-09-15T04:15:47Z,can be simplified as `for (int i : expectedkeys) {`,0,0.9938485026359558
39679109,130,rhauch,2015-09-16T20:15:28Z,"it does not appear that `kafkaconsumer` (or rather the `subscriptionstate` class it uses) allows using both `subscribe(...)` and `assign(...)`. given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: [code block]",0,0.9919230341911316
39904068,130,guozhangwang,2015-09-18T21:41:29Z,ack.,0,0.5866091847419739
39904149,130,guozhangwang,2015-09-18T21:42:37Z,ack.,0,0.5866091847419739
39904467,130,guozhangwang,2015-09-18T21:46:39Z,ack.,0,0.5866091847419739
39904581,130,guozhangwang,2015-09-18T21:47:56Z,"the topology's immutable, such that the processornodes and sourcebytopics will not be modified.",0,0.9939039349555969
39904795,130,guozhangwang,2015-09-18T21:50:39Z,"yeah, it will be replaced with the unsubscribe() api introduced in [a link]",0,0.9931455850601196
39912569,130,onurkaraman,2015-09-19T00:12:25Z,so i have very little context in this kip. is there any sort of expected size for the inner iterator? you may get stuck in the constructor's call to findnext() for a long time. it might be less surprising to postpone calling findnext() in hasnext() and next().,0,0.9770283102989197
39916442,130,rhauch,2015-09-19T05:09:32Z,"sounds good. the proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. thanks!",1,0.994752049446106
40004856,130,guozhangwang,2015-09-21T18:12:02Z,"the iterator will be constructed at around the same time when it is used to get next() (usually in process() call), so i feel postponing findnext() would not change much. but if we encountered some cases that this did become an surprise for users we can change it then.",0,0.9896894693374634
40112156,130,onurkaraman,2015-09-22T16:58:21Z,"minor, but this can alternately be called filternot just like in scala's collections.",0,0.982653021812439
40122437,130,ijuma,2015-09-22T18:14:01Z,we should use `$junit` here.,0,0.9948301911354065
40123138,130,ijuma,2015-09-22T18:19:27Z,there are no plans to incorporate guava by the way.,0,0.9907230734825134
40124198,130,ijuma,2015-09-22T18:26:12Z,"we may not care in this case, but nio.2 in java 7 provides a mechanism to do this in a more efficient way: [a link]",0,0.9941527247428894
40125291,130,ijuma,2015-09-22T18:33:44Z,"what is the reasoning for having different prefixes in `kafkastreaming`, `streamingconfig` and `kstream`?",0,0.9913091659545898
40126053,130,ijuma,2015-09-22T18:39:10Z,"also, is it actually useful enough? particularly if there is a `negate` method on `predicate`. in scala, one benefit of `filternot` is when using the underscore notation to make lambdas more concise. in java, that seems less useful.",0,0.9708996415138245
40126098,130,ijuma,2015-09-22T18:39:28Z,`valuesa` -> `values`,0,0.9919825196266174
40127893,130,ijuma,2015-09-22T18:51:40Z,is this actually needed?,0,0.9916319251060486
40128094,130,ijuma,2015-09-22T18:53:14Z,"some of this are private while others are public, is there a reason for that?",0,0.9907185435295105
40128168,130,ijuma,2015-09-22T18:53:46Z,is there a reason why these are not final?,0,0.9909865260124207
40128440,130,ijuma,2015-09-22T18:55:36Z,we should probably have a method that takes the name as a parameter and returns the new name using `index`. less error-prone and easier to change in the future.,0,0.9894679188728333
40128852,130,ijuma,2015-09-22T18:58:43Z,the suggestion to have a method that does this concat becomes even more appealing when seen in the light of subclasses like this one.,0,0.9833099246025085
40128890,130,ijuma,2015-09-22T18:59:07Z,"also, have we considered using an enum instead of strings?",0,0.9941903352737427
40128968,130,rhauch,2015-09-22T18:59:38Z,"currently, since kafka can't use java 8 functions nor static methods on interfaces, there is a `predicate` interface in this package that is semantically equivalent to `java.util.function.bipredicate`. unfortunately, without static methods, it's difficult to create a `not( predicate...)` method. so using `filterout` seems to be the easiest approach.",0,0.9745415449142456
40129636,130,rhauch,2015-09-22T19:04:42Z,"if the `apply` method were changed to `test`, then when kafka moves to java 8 this interface could extend `java.util.function.bipredicate `. that wouldn't really benefit anyone that simply supplied their own lambdas, but it might make it a bit easier or more obvious that existing `bipredicate` implementations could be passed in. regardless, aligning with java 8 might be a good thing in and of itself.",0,0.9680730104446411
40129686,130,ijuma,2015-09-22T19:05:10Z,"i was thinking of adding a default method to `predicate` itself, but i now realise that we can't do that in java 7 without changing it to an abstract class. fair enough.",0,0.9616411328315735
40149196,130,guozhangwang,2015-09-22T21:50:45Z,ack.,0,0.5866091847419739
40149364,130,guozhangwang,2015-09-22T21:52:36Z,"kafkastreaming / streamingconfig is aligned with kafkaproducer (kafkaconsumer) / producerconfig (consumerconfig), and kstream is just a name of the higher-level dsl api.",0,0.9935571551322937
40149430,130,guozhangwang,2015-09-22T21:53:07Z,ack.,0,0.5866091847419739
40149490,130,guozhangwang,2015-09-22T21:53:49Z,ack.,0,0.5866091847419739
40149757,130,guozhangwang,2015-09-22T21:56:22Z,ack.,0,0.5866091847419739
40149780,130,guozhangwang,2015-09-22T21:56:35Z,"some of them are used outside kstream, for example source is used in kstreambuilder, and join is in kstreamwindowed, etc.",0,0.993701696395874
40150351,130,guozhangwang,2015-09-22T22:02:45Z,"not sure i got the motivation: when we moved to java 8 and removed this interface with bipredicate directly, even with test() existing users still need to make code change, right?",0,0.7763364315032959
40167379,130,rhauch,2015-09-23T02:55:58Z,"renaming `apply` to `test` now gives us a slow, non-breaking migration path so that when moving to java 8 we could: - change `predicate ` to extend `java.util.function.bipredicate ` and remove the `apply` method from `predicate ` since it would unnecessarily override `bipredicate.test(...)`; - change `kstream` methods to use `bipredicate ` instead of this `predicate `; - deprecate `predicate ` and tell people to use `bipredicate` instead. no users would have to change their code, although anyone using `predicate ` directly would get deprecation warnings and could but would not be required to change. in a later release, we can remove `predicate `, and anyone _still_ using it would then have to change their code. otoh, if we keep `apply` as it is now, then when we moved to java 8 and change to `java.util.function.bipredicate `, all users directly using the interface would _have_ to change. of course, neither of these options affects those users who are already on java 8 and using lambdas rather than `predicate ` implementation classes.",0,0.9920300245285034
40215978,130,rhauch,2015-09-23T15:17:20Z,", why is the `rocksdbkeyvaluestore` not parameterized like `inmemorykeyvaluestore`? i have a version of this that is parameterized (yes, it does require passing in key and value serializers and deserializers), and it makes using it very similar to `inmemorykeyvaluestore`. any interest in it?",0,0.9647259712219238
40237923,130,guozhangwang,2015-09-23T18:17:30Z,"agree, do you want to create a new pr?",0,0.9889509081840515
40239203,130,rhauch,2015-09-23T18:27:47Z,", yes i will create a new pr shortly.",0,0.9847723245620728
40239945,130,ymatsuda,2015-09-23T18:32:40Z,"i am not sure if we want to migrate to `java.util.function.bifunction` at this point. but, by this change, we can maintain the source level compatibility of user code if we want to migrate. a good idea. what happens to the binary level compatibility? does a user using predicate have to recompile?",1,0.9710903763771057
40240252,130,guozhangwang,2015-09-23T18:35:25Z,i think recompilation are not avoidable anyways..,0,0.9183701872825623
40240731,130,rhauch,2015-09-23T18:39:28Z,"inserting new class or interface types in the type hierarchy is listed as a [a link] and [a link]. so if we rename the method now, then if/when `predicate ` is changed to extend `java.util.function.bipredicate ` and released clients using `predicate ` should not have to recompile.",0,0.994708776473999
40243229,130,guozhangwang,2015-09-23T19:00:05Z,correct: [a link],0,0.99281245470047
131572299,3621,becketqin,2017-08-07T04:52:30Z,"not sure if we want to have this interface added while we have not supported the intra broker replica move yet. also, we probably don't want to expose the implementation detail to the users about how the replicas are moved . so it would be better to not ask users to manually specify the replica dir before they do the partition reassignment. so the end state of adminclient after kip-179 and kip-113 would be having two methods for partition movement: 1. a method for partition reassignment in general, include both inter and intra broker reassignment. (e.g. `altertopics()`) 2. a method to only move replicas within a broker. (e.g. `alterreplicadir`) btw, i still feel that having (1) is sufficient. it would be useful to explore possibility of only having (1) so users don't need to deal with two different interfaces for replica movement. with that, regarding this patch, i was thinking doing the following: 1. let `reassignpartitioncommand` take new input format which includes the log dir. 2. do a sanity check in the `reassignparititioncommand` to ensure no intra broker replica movement is specified. otherwise throw `unsupportedoperationexception`. 3. in `reassignpartitioncommand`, it should just send `changereplicadirrequest` to the related brokers before the partition movement. 4. do not add `alterreplicadir()` to the adminclient until the broker supports that. would the above way be sufficient for what we want to achieve for this patch?",0,0.9493350982666016
131573994,3621,lindong28,2017-08-07T05:17:37Z,"thanks for your comment! here is what i think: - i think the interface is useful. the alterreplicadirrequest (renamed from changereplicadirrequest per ismael's comment) is used to 1) create replica in the specified log directory later and 2) move replica to the specified log directory if it has already been created yet. this patch supports the first part and thus the new api `alterreplicadir` in adminclient is useful and well-defined. if we don't add this method and its implementation in adminclient, we would have to implement it in `reassingpartitioncommand` and move the implementation to adminclient later, which seems like unnecessary work. - can you clarify a bit what implementation detail is exposed to user in this patch? - i have thought about the possibility of using only one method in adminclient to do both partition reassignment and replica -> log directory reassignment. my conclusion is that it is still better to put them into two separate methods. for example, if we do both using one method, the method would probably look like `reassignpartition(map > newpartitionassignment, map newreplicadirassignment)`. this method merges two inherently different parameters and functionality into one method, which seems less clean than using two methods. do you any suggestion on how that one method would look like if we were to use only one method for this? - i agree with the tasks 1-3. i still think it is better to put `alterreplicadir` in admclient as long as we documents it properly. but it also works for me to move this code to `reassignpartitioncommand`.",1,0.9910695552825928
131574245,3621,lindong28,2017-08-07T05:21:42Z,and good point about checking that no intra broker replica movement is specified. i will add this logic in `reassignpartitioncommand`,1,0.7969964146614075
131777843,3621,lindong28,2017-08-07T22:18:18Z,discussed with offline. i will not add `alterreplicadir()` api in adminclient in this patch. i will add `alterreplicadir()` as a public method in kafkaadminclient so that this method can be used by reassignpartitionscommand in this patch.,0,0.9945341348648071
132356130,3621,becketqin,2017-08-10T03:18:39Z,we have agreed the next major version would be 1.0.0.,0,0.9923462867736816
132356186,3621,becketqin,2017-08-10T03:19:25Z,should this be `describelogdirs`? also why this method is abstract?,0,0.9936829805374146
132356414,3621,becketqin,2017-08-10T03:22:35Z,"not sure if it is worth having this query granularity. it seems that when we query a broker, the cost to query all log directories and query some particular log directories are pretty much the same. and i think typically users would have to query all log dirs in order to get the dir names first. if so, would it be simpler to just use `collection ` instead?",0,0.686662495136261
132359600,3621,becketqin,2017-08-10T04:03:56Z,it seems a little verbose to have all these options with a timeout. it seems cleaner to merge them to a `timeoutoption` and extends from that.,0,0.5319842100143433
132359818,3621,becketqin,2017-08-10T04:06:38Z,this method does not exist.,0,0.9825406670570374
132359891,3621,becketqin,2017-08-10T04:07:13Z,this method does not exist.,0,0.9825406670570374
132832597,3621,becketqin,2017-08-13T05:19:26Z,this comment seems a little too verbose. do we need to mention this or the api of `alterreplicadirresult` is already clear enough?,0,0.7198929190635681
132832605,3621,becketqin,2017-08-13T05:19:52Z,1.0.0,0,0.9778755903244019
132832726,3621,becketqin,2017-08-13T05:32:05Z,"hmm, in which case would the future be null?",0,0.9739019274711609
132832899,3621,becketqin,2017-08-13T05:50:43Z,logdirnotavailableexception?,0,0.9897741079330444
132833418,3621,lindong28,2017-08-13T06:36:04Z,good point. i have changed it to take `collection `.,1,0.9735427498817444
132833428,3621,lindong28,2017-08-13T06:36:38Z,thanks. i have changed it to 1.0.0.,1,0.9520798325538635
132833468,3621,lindong28,2017-08-13T06:40:22Z,"i think `logdir` may be a bit more verbose than dir. it seems ok to be use `dir` instead of `logdir` as long as logdir will be the only ""dir"". if it is necessary to use `dir` instead of `logdir`, do you think we should rename `describedirsrequest` to `describelogdirsrequest`?",0,0.9825147986412048
132833487,3621,lindong28,2017-08-13T06:41:42Z,"besides, this is an abstract method because its implementation is in adminclient. this follows the same pattern as existing apis in `adminclient`.",0,0.9935687780380249
132833512,3621,lindong28,2017-08-13T06:42:55Z,"thanks. i replaced it with `{ kafkaadminclient#alterreplicadir(map, alterreplicadiroptions)}`",1,0.9540048837661743
132833528,3621,lindong28,2017-08-13T06:44:07Z,"thanks. i replaced it with `{ kafkaadminclient#alterreplicadir(map, alterreplicadiroptions)}`",1,0.9540048837661743
132833575,3621,lindong28,2017-08-13T06:48:34Z,sure. i removed the sentence `updates are not transactional...` from this comment. does this address the problem?,0,0.9869014620780945
132833579,3621,lindong28,2017-08-13T06:48:52Z,sure. fixed now.,0,0.9459871053695679
132833626,3621,lindong28,2017-08-13T06:51:20Z,"this follows the same pattern of the implementation of other existing apis in kafkaadminclient. i don't think future will be null unless there is bug. i think it is ok for the kafkaadminclient to have extra check to protect itself form server side's bug. but if you don't like it, i can also remove it and in the worse case we just see npe if future is null.",0,0.9742923974990845
132833666,3621,lindong28,2017-08-13T06:54:21Z,sure. renamed to `logdirnotavailableexception`.,0,0.9862815737724304
132833688,3621,lindong28,2017-08-13T06:55:55Z,"and if we were to rename it to `describelogdirs`, should we also rename `describereplicadir` to `describereplicalogdirs`?",0,0.9942432045936584
132833755,3621,lindong28,2017-08-13T07:00:42Z,"how about this: i added an abstract class named `configoptions`. this class will have a timems variable and `integer timeoutms()` api. this abstract class can be used to hold all future apis that are shared among all (or most) ""*configoptions"" classes. on the other hand i also think it is ok to keep it as is given that there are is only one common api (i.e. timems()) shared among those classes.",0,0.9765015244483948
132857316,3621,becketqin,2017-08-13T23:56:05Z,"if we do not expect this to happen. shouldn't we throwi illegalstateexception? in this case, if the broker returned a replica that is not in the request, the broker may have somehow misplaced a replica. we should probably alert in this case.",0,0.9711423516273499
132868453,3621,becketqin,2017-08-14T03:29:15Z,"personally i prefer avoiding the potential confusion, especially given dir is a pretty commonly used name in many places. i am not sure if in the future we will have some other dirs, but describedir() itself seem lacking some necessary context to me. and yes, i do feel `describelogdirrequest` is a better name. `describereplicadir` sounds ok though, as replicadir must be a log dir.",0,0.8491395711898804
132868590,3621,becketqin,2017-08-14T03:31:37Z,i am not sure what is the best solution here either. it just feels a little silly that we have all those classes that are essentially identical except the class name.,-1,0.9759209156036377
132868863,3621,becketqin,2017-08-14T03:36:25Z,should this comment be updated?,0,0.9944274425506592
132868995,3621,becketqin,2017-08-14T03:38:36Z,ditto above.,0,0.9910715222358704
132869443,3621,becketqin,2017-08-14T03:47:23Z,"technically speaking we are query the log directory in which the replica locates. i.e. the root_log_dir, not root_log_dir/replica_dir. speaking of this, it might still be better to change the method name to `describereplicalogdir`.",0,0.9904122948646545
132871530,3621,becketqin,2017-08-14T04:24:17Z,is the left parenthesis missing?,0,0.9903566241264343
132872895,3621,becketqin,2017-08-14T04:42:22Z,the default lag should probably be something like -1 and preferably a macro. it is also a little weird to allow those non-final fields to be tweaked. see the other comment in `kafkaadminclient`,-1,0.9720369577407837
132873131,3621,becketqin,2017-08-14T04:44:52Z,would it be better to construct the result after the response is returned instead of create the result beforehand and modify it later?,0,0.9913705587387085
132873593,3621,becketqin,2017-08-14T04:53:18Z,"given this change, is the log dir field still needed in the `describedirrequest`? it seems that we can just leave the replica list there and remove the log dir list?",0,0.9946877956390381
132874067,3621,becketqin,2017-08-14T04:59:49Z,"not found and not available seems slightly different. it would be useful to distinguish between ""exist but not available"" vs ""does not exist"".",0,0.9753221273422241
132874436,3621,becketqin,2017-08-14T05:06:23Z,"by ""remaining"" do you mean ""available""?",0,0.9899610280990601
132874540,3621,becketqin,2017-08-14T05:08:34Z,"see the other comment, maybe we don't need the log dir list anymore.",0,0.9865241050720215
132876992,3621,becketqin,2017-08-14T05:44:15Z,"hmm, why are we do the validation after executing the reassignment?",0,0.9818914532661438
132878069,3621,becketqin,2017-08-14T05:59:02Z,"the comment is a little confusing. maybe change to ""remove the preferred log dir since it has already been satisfied."". btw, should we remove it after the log has actually been created? otherwise if storage exception happens during the log creation we may lose the preferred log dir information.",0,0.6368713974952698
132878098,3621,becketqin,2017-08-14T05:59:27Z,can you explain the reason of these changes?,0,0.9926882982254028
132879332,3621,becketqin,2017-08-14T06:13:27Z,"i know this is in the kip, but it still seems a little weird to throw exception in this case as the request is kink of legitimate. not sure if there is a better way though.",-1,0.9795628786087036
132880098,3621,becketqin,2017-08-14T06:22:33Z,"why should this be -1 instead of 0? this is essentially caught up, right?",0,0.9615230560302734
133014020,3621,lindong28,2017-08-14T17:43:13Z,sure. good point. i have updated the patch with the following changes: - renamed describedirsrequest to describelogdirsrequest (same for response) - renamed adminclient api to describelogdirs - renamed adminclient api to describereplicalogdirs,1,0.9777566194534302
133014235,3621,lindong28,2017-08-14T17:44:04Z,i have added the class `abstractoptions` that provides apis to set and get timeoutms.,0,0.9952804446220398
133014767,3621,lindong28,2017-08-14T17:46:14Z,good point. i have updated the patch to throw illegalargumentexception if the future is not found.,1,0.9648215174674988
133015323,3621,lindong28,2017-08-14T17:48:30Z,sure. i replaced this comment with `query the information of all log directories on the given set of brokers`.,0,0.984154462814331
133015335,3621,lindong28,2017-08-14T17:48:33Z,sure. i replaced this comment with `query the information of all log directories on the given set of brokers`.,0,0.984154462814331
133015631,3621,lindong28,2017-08-14T17:49:36Z,good point. i have updated the protocol to remove `log_dirs` field from `describelogdirsrequest`.,1,0.9544094204902649
133015745,3621,lindong28,2017-08-14T17:50:00Z,sure. i have renamed `describereplicadir` to `describereplicalogdir`.,0,0.9781175255775452
133021670,3621,lindong28,2017-08-14T18:13:58Z,good point. i replaced `-1` with `describelogdirsresponse.invalid_offset_lag`.,1,0.9811166524887085
133021896,3621,lindong28,2017-08-14T18:14:54Z,left parenthesis actually exists.,0,0.9919405579566956
133022382,3621,lindong28,2017-08-14T18:16:48Z,yeah. i have removed this field from describelogdirsrequest.,0,0.9757729768753052
133023112,3621,lindong28,2017-08-14T18:19:57Z,good point. i have renamed this exception to `logdirnotfoundexception`. i think we can assume `not found` indicates `does not exist` given that we already have `notfoundexception`.,1,0.9513779878616333
133023274,3621,lindong28,2017-08-14T18:20:43Z,i removed the `remaining` from this comment since it appears unnecessary.,0,0.9906080961227417
133026257,3621,lindong28,2017-08-14T18:32:37Z,this is just an extra verification to confirm that we are only sending alterreplicadirrequest for replicas that have not been created yet.,0,0.9949169158935547
133026969,3621,lindong28,2017-08-14T18:35:29Z,good point. i have updated the comment as suggested. and it is only removed after the log has been successfully created.,1,0.9778448343276978
133027534,3621,lindong28,2017-08-14T18:37:25Z,this is because we receive logdir as a strong from alterreplicadirrequest and it is inserted into `preferredlogdirs` as a strong. when we get it from `preferredlogdirs` it will be a strong not a file. it is a minor change. alternatively i can insert preferred log directory into that map as a file. i just feel the current approach is simpler.,0,0.9867143034934998
133028201,3621,lindong28,2017-08-14T18:40:00Z,"imo it is reasonable to throw exception here. this is because it is not guaranteed that the replica will be moved to the destination log directory if the replica is not already on the broker. for example, if the broker restarts after it receives alterreplicadirrequest but before it receives the upcoming leaderandisrrequest, it will forget the cache in the memory.",0,0.9791810512542725
133028267,3621,lindong28,2017-08-14T18:40:15Z,discussed offline. i have updated the patch to remove this logic.,0,0.9950163960456848
133028981,3621,lindong28,2017-08-14T18:42:54Z,"are you talking about the `futures` map or the `replicadirinfobypartition`? the former needs to be constructed in advance as does the implementation of other apis in adminclient. the latter needs to be constructed in advance because its result maybe a combination of two entries in the response, i.e. primary and temporary replica of the same partition.",0,0.9935089945793152
134098378,3621,becketqin,2017-08-19T18:52:50Z,can we add a java doc for this class?,0,0.9955911636352539
134098547,3621,becketqin,2017-08-19T19:01:19Z,version should be 1.0.0.,0,0.9948561191558838
134098552,3621,becketqin,2017-08-19T19:01:27Z,ditto.,0,0.9384599328041077
134098889,3621,becketqin,2017-08-19T19:19:36Z,should we change this name to alterreplicalogdiroptions as well?,0,0.9945800304412842
134100952,3621,becketqin,2017-08-19T21:13:57Z,do we need to have the `replicalogdirinfo` printed? it seems the output format would be pretty verbose.,0,0.9457672238349915
134101186,3621,becketqin,2017-08-19T21:28:44Z,we are still not throw exception here? am i missing something?,0,0.8904138803482056
134101387,3621,becketqin,2017-08-19T21:43:08Z,this assumes the only possibility of error is partition does not exist. is this always true?,0,0.9892880916595459
134101520,3621,becketqin,2017-08-19T21:51:45Z,the class also includes the broker id.,0,0.9956746697425842
134101861,3621,becketqin,2017-08-19T22:14:29Z,alterreplicalogdirrequest?,0,0.9946538209915161
134101922,3621,becketqin,2017-08-19T22:18:15Z,alterreplicalogdirresponse?,0,0.9931507110595703
134101991,3621,becketqin,2017-08-19T22:21:31Z,nit: dir -> dir,0,0.9890255331993103
134102436,3621,becketqin,2017-08-19T22:51:34Z,i see. we probably need more comments to explain this. from the code itself it is weird that we always expect an exception from a future.,-1,0.986170768737793
134102479,3621,becketqin,2017-08-19T22:54:52Z,we may also need to update the command help message.,0,0.9947683811187744
134102637,3621,becketqin,2017-08-19T23:08:57Z,"do we also want to look into the `preferredlogdirs`? in another word, do we want to have the preferred dir shown as temporary dir in the describelogdirresponse even if the replica has not been created yet?",0,0.9949864149093628
134102674,3621,becketqin,2017-08-19T23:13:23Z,should we also assert the log dir is non-null?,0,0.9938040971755981
134102720,3621,becketqin,2017-08-19T23:17:23Z,can we define a val for the number of log dirs?,0,0.9945160746574402
134102789,3621,becketqin,2017-08-19T23:21:43Z,"this test seems a little overlapping with the test in `adminclientintegrationtest.testalterreplicalogdirbeforetopiccreation`, do we need both?",0,0.9916788935661316
134103147,3621,lindong28,2017-08-19T23:50:04Z,sure. i added this comment `this class implements the common apis that are shared by options classes for various adminclient commands`.,0,0.9835704565048218
134103158,3621,lindong28,2017-08-19T23:50:34Z,"sorry, my bad. it is fixed now.",-1,0.9957190155982971
134103164,3621,lindong28,2017-08-19T23:50:58Z,fixed now.,0,0.9943431615829468
134103288,3621,lindong28,2017-08-20T00:00:20Z,"if we were to change it, we probably want to rename `alterreplicadirrequest` to `alterreplicalogdirreqeust`. but this seems a bit verbose to me. i think `alterreplicadirrequest` is probably ok and should not cause any confusion going forward. do you think this may cause confusion if we don't name it `alterreplicalogdirreqeust`?",0,0.9634374976158142
134103332,3621,lindong28,2017-08-20T00:04:53Z,"the current patch doesn't not print `replicalogdirinfo` anywhere to user except possibly in debug log. as far as the implementation of the `replicalogdirinfo` is concerned, i think it makes sense to print all its fields as does in the current patch. do you see any log statement that prints the `replicalogdirinfo` in an unnecessary manner?",0,0.9913749098777771
134103367,3621,lindong28,2017-08-20T00:07:38Z,oops.. i must have made some mistake such that the change is lost.. i have fixed it now.,-1,0.8895346522331238
134103401,3621,lindong28,2017-08-20T00:10:36Z,"i added this `throw new illegalargumentexception(""the partition "" + tp + "" in the response from broker "" + brokerid + "" is not in the request"");`",0,0.9940181970596313
134103422,3621,lindong28,2017-08-20T00:12:57Z,"this assumes that if `logdirinfo.error != errors.none`, then the log directory must be offline on this broker and the `replicainfos` in this `logdirinfo` will be empty. this is a valid assumption as of the current design.",0,0.9939356446266174
134103428,3621,lindong28,2017-08-20T00:13:52Z,"thanks a lot for the detailed review! i have changed it to `the topic name, partition number and the brokerid of the replica`.",1,0.9953794479370117
134103435,3621,lindong28,2017-08-20T00:14:46Z,thanks! fixed now.,1,0.9920086860656738
134103699,3621,lindong28,2017-08-20T00:38:03Z,"i don't think we should do that. including this information in `describelogdirrequest` will complicates the design of related apis and expose an internal optimization detail to user. on the other hand, i don't think it provides any benefit to the user. the purpose of describelogdirrequest is to get the load distribution of log directories on the broker so that user can determine a good reassignment replicas across log directories. is there any information in `preferredlogdirs` that can help with this purpose of the `describelogdirrequest`?",0,0.9027948379516602
134103805,3621,lindong28,2017-08-20T00:50:43Z,sure. i added the following check: [code block],0,0.9895578026771545
134103834,3621,lindong28,2017-08-20T00:55:17Z,not sure if i fully understand your question. do you mean something like `protected def logdircount: int = 1` which is added by this patch in `baserequesttest.scala`? i think we only need to add this when we need to vary the logdircount based on the test. it seems ok and simpler to just set logdircount to 2 for all tests in `adminclientintegrationtest`.,0,0.8267644047737122
134103883,3621,lindong28,2017-08-20T01:01:18Z,"i think it is ok to have both. if `alterreplicadirrequesttest.testalterreplicadirrequestbeforetopiccreation` passes but `adminclientintegrationtest.testalterreplicalogdirbeforetopiccreation` fails, it suggests that something is wrong in the kafkaadminclient. this seems to follow the existing pattern -- tests such as `deletetopicsrequesttest` and `createtopicsrequesttest` probably would not be needed for the same reason given that we already have tests for higher level apis that use them (if not then we should add the test for higher level apis that uses them). but i am not strong on this. i will remove this test if you think it is not necessary.",0,0.8834019899368286
134104058,3621,lindong28,2017-08-20T01:19:24Z,good point. i added the following comments in the code: [code block] and i updated the help message for option `--reassignment-json-file` to the following: [code block],1,0.9802850484848022
134106014,3621,becketqin,2017-08-20T04:27:38Z,"i think we usually do not print the field name of a map value, we usually not not print the name field of the value. otherwise shouldn't we print the field name of the key as well? so for maps, it would simply be [key, value]. in this case, each entry could be printed as something like [topic-0-1, (currentlogdir=xxx, temporarylogdir=yyy, temporaryreplicaoffsetlag=zzz)], which is probably clear enough. btw, i forgot to comment that i think we should add documentation about what are the value combination of those fields mean. for example is it possible i get a currentlogdir=null, templogdir=xxx, offsetslage=-1? if so what does that mean.",0,0.9658822417259216
134124244,3621,lindong28,2017-08-20T19:32:23Z,"i see. i didn't understand the question previously. i wasn't aware that the conversion is to not print the name fild of the value. sure. i just changed both the `replicalogdirinfo.tostring()` and `replicainfo.tostring()` so that they don't print the class name in the string. btw, i assume that this conversion only applies to internal classes, which i think is reasonable. for public classes such as `alterreplicadirrequest`, the patch will still print the class name in the `tostring()` method as we do in e.g. `deletetopicsrequest`. i also added comment to fields in the `replicalogdirinfo` as show below. i think each fields can be interpreted independently and there is no need to explain how to interpret various combinations. for the example you mentioned, if currentlogdir=null, templogdir=xxx, offsetslage=-1, it means the primary replica is not found and there is only a temporary replica for this partition on the given broker, which is possible if the primary replica is in an offline log directory. [code block]",0,0.92838054895401
134592277,3621,junrao,2017-08-22T20:26:50Z,unused import replicainfo. should we add the package name in front of describelogdirsresponse?,0,0.9947932362556458
134594816,3621,junrao,2017-08-22T20:36:53Z,would it be better to change the schema to have log_dir at the top level. sth like log_dirs => [log_dir [partitions]] partitions => [topic [int32]] this representation is more concise and is more consistent with how describe_log_dirs_response_v0 is structured.,0,0.9901178479194641
134616464,3621,junrao,2017-08-22T22:21:47Z,"in handletopicmetadatarequest(), if topics() is null, we treat it as for all topics. if topics() is empty, we just treat it as no topics. it would be useful to use the same approach here for consistency.",0,0.9914836287498474
134632381,3621,junrao,2017-08-23T00:23:26Z,"hmm, if we are representing the dir for the permanent and the temporary replica together here, shouldn't we further keep the lag for both permanent and the temporary replicas? also, it's not clear to me why we don't return the same info in describelogdirsresult.",0,0.9770812392234802
134632961,3621,junrao,2017-08-23T00:28:39Z,"it's probably better to include alterreplicadir() here too. if we think the api may change, we can mark it as unstable.",0,0.9921362400054932
134633840,3621,junrao,2017-08-23T00:37:27Z,this seems no longer used?,0,0.9919549822807312
134638546,3621,junrao,2017-08-23T01:21:01Z,"""on the broker ${replica.brokerid()}"" => ""on broker ${replica.brokerid()}""",0,0.9935599565505981
134639735,3621,junrao,2017-08-23T01:34:04Z,"with this, it's possible for a created log not to be in logs. then, we won't find this log in logmanager.getlog(). when serving requests like offsetbytimestamp, we will probably return unknowntopicpartitionexception, but ideally we want to return kafkastorageexception.",0,0.9926525354385376
134661753,3621,lindong28,2017-08-23T05:46:53Z,my bad. it is removed now. i will go over the patch again to look for unused import.,-1,0.9937644004821777
134662104,3621,lindong28,2017-08-23T05:50:00Z,sure. the original schema is motivated by the idea that alterreplicadir operation naturally maps a replica to a log directory. i am not very sure alterreplicadirrequest needs to be consistent with describelogdirrequest. but i think what you suggested will make the request more compact and smaller in size. i have made the change as suggested. thanks!,1,0.8629356026649475
134663181,3621,lindong28,2017-08-23T05:59:49Z,"the class `replicalogdirinfo` doesn't include that currentreplicalag because this information is not currently used in this patch. previously i think we can include `currentreplicalag` in this when it is needed, i.e. to track reassignment progress in kip-179. i have updated the patch to include `currentreplicalag` in `replicalogdirinfo`. i am not sure i fully understand the second question. what information should we add or remove from `describelogdirsresult`? i think `describelogdirsresult` and `describereplicalogdirresult` has different format because they are used to serve two different use-cases. these two classes are structured in a way that makes the respective adminclient apis easier to use.",0,0.9890563488006592
134663259,3621,lindong28,2017-08-23T06:00:48Z,sure. i have added it back to adminclient.,0,0.9852479696273804
134663285,3621,lindong28,2017-08-23T06:01:03Z,ah.. my bad. it is removed now.,-1,0.9945865869522095
134663350,3621,lindong28,2017-08-23T06:01:36Z,i have fixed this as suggested in multiple places in this method.,0,0.9943764209747314
134663939,3621,lindong28,2017-08-23T06:06:44Z,"after double checking the logic, i think we will actually return `kafkastorageexception` for `offsetbytimestamp` query if log creation failed. this logic is enforced in kip-112. more specifically, after broker receives leaderandisrrequest to create the log, if `logmanager.getorcreatelog()` throws `kafkastorageexception`, `partition.getorcreatereplica()` will also throw exception without putting this replica in the `partition.assignedreplicamap`. later we will execute the following code in `replicamanager.becomeleaderorfollower()`: [code block] this logic makes sure that this partition will map to `replicamanager.offlinepartition` when this broker receives any request from user, including requests for offsetbytimestamp. the response will return `kafkastorageexception` to the user.",0,0.9905038475990295
134683583,3621,lindong28,2017-08-23T08:09:29Z,sure. i have updated the patch as suggested.,0,0.9880368709564209
134794883,3621,cmccabe,2017-08-23T15:57:43Z,"we should use an accessor function for the following fields-- for all the usual reasons we do this in java. (unlike in scala, you cannot write an accessor later to transparently switch over users.)",0,0.9938680529594421
134795363,3621,cmccabe,2017-08-23T15:59:15Z,"is right-- you should handle this case. perhaps the server sent back bad data. the way to handle it is not to throw an exception, but to complete the relevant future(s) with an error. there are a few other cases where we handle bad server data by completing a future with failure in adminclient.",0,0.9851439595222473
134795858,3621,cmccabe,2017-08-23T16:01:02Z,i don't think we should map zero responses to cluster_authorization_failed. what if we need to return different error codes later? we should have an error code per log dir response.,0,0.9678788781166077
134807975,3621,lindong28,2017-08-23T16:50:37Z,"currently the only request level error for describelogdirresponse is if the cluster_authorization_failed. this error will happen if and only if the error there is no log directories in the response. this is because if a broker is online and the user is authorized to describe cluster resource, then it is guaranteed that describelogdirresponse should return some log directories. also note that describelogdirresponse does include per-logdir error in the response. thus we don't need request level error for describelogdirresponse at this moment. is there any scenario that will request this error field in the future? if we don't have specific use-case for this field, can we add it only when we need it in the future?",0,0.9861554503440857
134809797,3621,lindong28,2017-08-23T16:58:18Z,good point. i have updated the code to complete all futures with illegalargumentexception when this happens.,1,0.9528127312660217
134815324,3621,lindong28,2017-08-23T17:21:46Z,i noticed that classes such as `updatemetadatarequest.partitionstate` makes its fields public instead of using accessor fields. are accessor fields needed by replicalogdirinfo because it is exposed to user via `adminclient.describereplicalogdir()`?,0,0.9910014271736145
135162431,3621,junrao,2017-08-25T00:33:41Z,should we guard the case that the same partition or the same log dir is specified more than once and error out?,0,0.9917442202568054
135165084,3621,junrao,2017-08-25T01:01:20Z,getpermanentreplicalogdir seems to match gettemporaryreplicalogdir better. ditto on getcurrentreplicaoffsetlag.,0,0.9826304316520691
135166115,3621,junrao,2017-08-25T01:12:42Z,"instead of using (_._2), could we use case to define named variables to make it clear? ditto on line 233.",0,0.9940620064735413
135167112,3621,junrao,2017-08-25T01:22:57Z,"hmm, intuitively, if a replica doesn't exist, setting a log dir for it should succeed, instead of getting an error. perhaps we should return success if the replica doesn't exist or is in the right dir, and throw an unsupported exception for now otherwise.",0,0.9771274924278259
135167447,3621,junrao,2017-08-25T01:26:43Z,do you mean broker 101?,0,0.9916492700576782
135167654,3621,junrao,2017-08-25T01:29:04Z,do you mean broker 102?,0,0.9924213290214539
135168551,3621,junrao,2017-08-25T01:38:48Z,is the comment accurate? it seems the test has invalid log dir.,0,0.9885185360908508
135168609,3621,junrao,2017-08-25T01:39:23Z,is the comment accurate?,0,0.9898896217346191
135168812,3621,junrao,2017-08-25T01:41:35Z,"could we add a test case that the length of ""log_dirs"" doesn't match that in ""replicas""?",0,0.9918415546417236
135168953,3621,junrao,2017-08-25T01:42:54Z,unused import,0,0.9873000979423523
135169300,3621,junrao,2017-08-25T01:46:53Z,"hmm, the event will be processed asynchronously after this call returns. should we guarantee that this event is processed before sending describe_log_dirs request?",0,0.9894477128982544
135182887,3621,lindong28,2017-08-25T04:45:59Z,"i think we don't need to add this logic in `alterreplicadirrequest` because the current implementation will always provide unique partition and log when instantiating `alterreplicadirrequest`. `alterreplicadirrequest` will only be instantiated in `adminclient.alterreplicadir()`. because `adminclient.alterreplicadir()` takes `map replicaassignment` as input, it guarantees that the partition in the `alterreplicadirrequest` will be specified only once. also, `alterreplicadirrequest.tostruct()` will group `topicpartitionreplica` by logdir and thus the logdir in the `alterreplicadirrequest` will be specified only once.",0,0.982084333896637
135183018,3621,lindong28,2017-08-25T04:48:13Z,i am bit concerned that `getpermanentreplicalogdir` may mislead user into thinking log directory of this partition will never change. how about we rename `gettemporaryreplicalogdir` to `getfuturereplicalogdir`?,-1,0.8062222599983215
135183254,3621,lindong28,2017-08-25T04:51:51Z,sure. i replaced them with the following: [code block],0,0.9913964867591858
135184008,3621,lindong28,2017-08-25T05:03:03Z,"i think it depends on the semantics of alterreplicadirrequest. in my understanding ""alter"" means ""change the proper of something that already exists"". thus broker should not create replica for this partition if this replica does not already exist. and it is reasonable to throw exception to user because user requested to alter log directory of a replica that doesn't exist. does this make sense?",0,0.9787667989730835
135184035,3621,lindong28,2017-08-25T05:03:35Z,my bad. fixed now. thanks.,-1,0.987311601638794
135184065,3621,lindong28,2017-08-25T05:04:11Z,ah.. fixed now. thanks!,1,0.9951533079147339
135184249,3621,lindong28,2017-08-25T05:07:10Z,my bad.. i replaced the comment with `when we execute an assignment that specifies an invalid log directory`.,-1,0.9947071671485901
135184640,3621,lindong28,2017-08-25T05:13:13Z,no... i have replaced the comment with the following: [code block],0,0.9923025369644165
135184811,3621,lindong28,2017-08-25T05:16:04Z,good point. i have changed the code to do `servers.head.replicamanager.handlelogdirfailure(offlinedir)`.,1,0.9709892272949219
135193414,3621,lindong28,2017-08-25T06:48:56Z,sure. i have added test `shouldfailifproposedhasinconsistentreplicasandlogdirs` for this.,0,0.9831243753433228
135372907,3621,junrao,2017-08-25T23:51:52Z,"yes, the java client behaves as you described. i was mostly concerned about how the broker handles requests from non-java clients.",0,0.9852039813995361
135372918,3621,junrao,2017-08-25T23:52:05Z,perhaps use getcurrentreplicalogdir and get getnewreplicalogdir?,0,0.9928931593894958
135372984,3621,junrao,2017-08-25T23:53:05Z,"hmm, i think alterreplicadirrequest just means the intention to alter the dir. it doesn't mean the change has to be completed. as long as the intention is remembered by the broker, it seems it's reasonable to return success. the weird thing right now is that in reassignpartitionscommand, the happy path is actually based on an exception in the response of alterreplicadirrequest. normally, the happy path should be when the response has no error.",0,0.806734561920166
135374404,3621,lindong28,2017-08-26T00:14:00Z,"thanks for the comment ! by non-java clients, do you mean the clients written by third-party and not maintained by in apache kafka repository? here is my thought: - if a thirty party client constructs the `alterreplicadirrequest` using the api `alterreplicadirrequest.builder(map partitiondirs)`, we still guarantee that both log directory and the topicpartition in the resulting `alterreplicadirrequest` will be unique. thus server doesn't have to worry about it. - if a third party client constructs `alterreplicadirrequest` without using our builder, and it constructs `alterreplicadirrequest` with duplicated topicpartition by mistake, the server won't be affected by this. this is because the `alterreplicadirrequest(struct struct, short version)` will generate the `map partitiondirs` which contains well-defined and unique partition to logdir mapping. also, since user constructs `alterreplicadirrequest` without using our builder, we won't help user detect this mistake by changing the code here. btw, this issue seems to also exist in `alterconfigsrequest`, which may contain duplicated entries for the same resource type and resource name. it may be reasonable to handle them in the same way as this patch does. does it make sense?",1,0.9721344113349915
135374956,3621,lindong28,2017-08-26T00:23:36Z,"i agree it doesn't have to be completed as long as it is remembered. however, currently this is only remembered in the memory which may be lost if broker restarts after it receives alterreplicadirrequest but before it receives leaderandisrrequest to create the replica. i think we probably don't want to return success to user and create replica is a different log directory later (if restart happens in the above case). has similar comment regarding the weirdness that we expect response to throw exception. but this weirdness exists only because this patch represents the first part of kip-113. after we fully implement the kip-113, we won't expect to see exception in the happy path. the logic in the reassignment will look like this: - call `adminclient.alterreplicadirrequest(replicaassignment)` without waiting for response - create the reassignment znode so that controller can start replica reassignment across brokers. - call `adminclient.alterreplicadirrequest(replicaassignment)` and verify that there is no error in the response. the implementation of `adminclient.alterreplicadirrequest` will treat `replicanotavailableexception` as a retriable error and retry up to the user-specified timeout. i think it is ok for this weirdness to exist for a short period of time before kip-113 is fully implemented. user won't be affected by this weirdness. does this make sense?",0,0.9403493404388428
135375065,3621,lindong28,2017-08-26T00:25:20Z,sure. i will update the patch to use `getnewreplicalogdir` and rename other fields as appropriate.,0,0.9860352277755737
135376799,3621,lindong28,2017-08-26T01:08:36Z,"after discussing with , i think it may be better to use `getfuturereplicalogdir`. if we were to use `getnewreplicalogdir`, do you think we should rename `is_temporary` field in `describe_log_dirs_response_v0` to `is_new`? if so, it kinds of collide with the `is_new` field in `leader_and_isr_request_partition_state_v1`. it seems a bit confusing. also, if we were to use `getfuturelogdir`, are you ok with renaming the field `is_temporary` to `is_future` in `describe_log_dirs_response_v0`?",0,0.9647659659385681
135377833,3621,junrao,2017-08-26T01:36:04Z,"ok, if doesn't do harm on the server, we can punt on this.",0,0.9435727596282959
135377868,3621,junrao,2017-08-26T01:37:01Z,"ok, future is fine then. changing is_temporary to is_future also sounds good.",1,0.795188844203949
135377870,3621,junrao,2017-08-26T01:37:03Z,"hmm, i thought for verification, we want to use describelogdirs not alterreplicadirrequest? also, for the first adminclient.alterreplicadirrequest(), i am not sure that we want to completely ignore the response. for example, if the request fails with authentication error, we probably want to error out, right? overall, are you saying that alterreplicadirrequest only returns no error if the log dir is in the target log dir? that means most of the time, the request will return error. this seems unintuitive since error should be the exception, not the norm.",0,0.8487004637718201
135378158,3621,lindong28,2017-08-26T01:47:38Z,"yes, we only use `describelogdirs` for verification. in the current patch, `reassignpartitionscommand` only checks for `replicanotavailableexception` using `alterreplicadirrequest` during execution (i.e. when --execute is specified). you are right. i simplified the logic of the first `adminclient.alterreplciadir()` in my previous response. more specifically, after kip-113 is fully implemented, the `reassignpartitionscommand` should use `adminclient.alterreplciadir()` to send `alterreplicadirrequest` without retry. and it should verify that either there is no error or the error is `replicanotavailableexception`. the second `adminclient.alterreplciadir()` should retry `alterreplicadirrequest` upon `replicanotavailableexception` until timeout. `alterreplicadirrequest` can also return no error even if the log directory is not the target log directory, as long as replica already exists on the broker. this is because if the replica already exists on the broker, the broker will create a directory for the temporary replica in the destination log directory. because this information is persisted on the disk rather than in memory, broker will continue to move replica to the destination log directory after restart.",0,0.9881636500358582
136207465,3621,junrao,2017-08-30T22:37:28Z,"the name of the method seems a bit confusing. it's not really clear what withoutdedup really means. could it be just named parsepartitionreassignmentdata()? also, could we document the return value?",0,0.7329156994819641
136208723,3621,junrao,2017-08-30T22:45:52Z,"ok, thanks for the explanation. this is fine then. could we document the error code/exception in alterreplicadirresult?",1,0.9480639100074768
136209635,3621,lindong28,2017-08-30T22:52:06Z,"this name is used following the name of the existing method `zkutils.parsepartitionreassignmentdatawithoutdedup`. if we name it `parsepartitionreassignmentdata` in `reassignpartitionscommand`, should we also rename the method in `zkutils` for consistency? note that there is an existing method `parsepartitionreassignmentdata(jsondata: string): map[topicandpartition, seq[int]]` in zkutils which justifies the use of `parsepartitionreassignmentdatawithoutdedup` in zkutils.",0,0.9947570562362671
136210274,3621,lindong28,2017-08-30T22:56:29Z,sure. previously the error is only documented in `alterreplicadirresponse`. just now i added the error code documentation in `alterreplicadirresult` as follows: [code block],0,0.9870848059654236
136211210,3621,junrao,2017-08-30T23:03:06Z,perhaps we can just get rid of zkutils.parsepartitionreassignmentdatawithoutdedup since the only caller is zkutils.parsepartitionreassignmentdata?,0,0.9854279160499573
136211869,3621,lindong28,2017-08-30T23:08:07Z,sure. i have updated the patch as suggested. thanks for taking time to review the patch!,1,0.9875697493553162
136690443,3621,becketqin,2017-09-02T06:25:28Z,"can we add a comment here for this? also, if the only possible error is log dir offline, would it be clearer to only check for that error and log an error message or throw exception in other cases?",0,0.9940264225006104
136703340,3621,becketqin,2017-09-02T20:31:09Z,"maybe worth adding a comment? also usually the clients do not infer an error code while the broker did not return it. maybe it is better to let the server to return cluster_authorization_failed. we are doing the same for `describeaclsrequest`. if we do that we will need to add response level error code, which probably makes sense.",0,0.9883635640144348
136710394,3621,ijuma,2017-09-03T07:28:17Z,", jun was referring to clients that don't use our code at all. librdkafka, kafka-python, etc.",0,0.9702605605125427
136711246,3621,ijuma,2017-09-03T08:21:42Z,"sorry for being late on this. why is this `alterreplicadir` instead of `alterreplicadirs` (or some other version that indicates the batch nature)? this is a batch api like every other api so it should indicate that via the name, right?",-1,0.9922424554824829
136711278,3621,lindong28,2017-09-03T08:23:58Z,i see. thanks for the information.,1,0.9324073791503906
136711440,3621,lindong28,2017-09-03T08:32:55Z,"i think one reason to use alterreplicadir is that it presents a map from replica -> dir. it is probably a bit different from other names such as describeconfigs, which represents a collection of configs. do you like me to submit a patch to change it to a different name? what do you think about this name?",0,0.970054030418396
136711492,3621,ijuma,2017-09-03T08:36:14Z,why did we remove this?,0,0.991465151309967
136711557,3621,ijuma,2017-09-03T08:39:15Z,"thanks for the quick reply. right, it's a map from replica to dir instead of a single replica to dir. the name sounds like the latter to me. before doing a pr, let's see if we get consensus amongst yourself and the reviewers.",1,0.9774366021156311
136711582,3621,lindong28,2017-09-03T08:40:42Z,originally i added a similar comment to the new api. commented that this is unnecessary. i agree with this is unnecessary because `alterconfigsresult` returns `map >` which suggests that some configs may be updated successfully while others fail. thus there is no need to have extra comment in the api documentation to specify this. does this make sense?,0,0.9825308918952942
136712129,3621,ijuma,2017-09-03T09:10:32Z,"while i understand the sentiment, we have to remember that these apis will be used by people who are not familiar with kafka in the same way we are. we often get support questions because things that seem obvious to us are not clear to users. i disagree that we should remove clarification comments like the above in public apis.",-1,0.5371798276901245
136712322,3621,lindong28,2017-09-03T09:20:39Z,"i see. sure, i can submit a minor patch tomorrow for this (or please feel free to just commit a minor patch if you prefer). to keep the api document consistent and for the same reason you described, maybe we should have this comment (i.e. api is not transactional) for all those apis in the adminclient which may partially succeed, e.g. deletetopics?",0,0.9544740319252014
136712993,3621,ijuma,2017-09-03T09:58:32Z,"yes, i think that's a good idea. if you are ok with submitting a pr, that would be great. it's not urgent, we should aim to do it before 1.0.0 is released.",1,0.990744948387146
136741892,3621,tedyu,2017-09-04T04:16:18Z,is illegalstateexception more approriate for this situation ?,0,0.9487555623054504
136742443,3621,tedyu,2017-09-04T04:27:46Z,nit: the 'else' can be omitted.,0,0.9941269159317017
136772853,3621,lindong28,2017-09-04T08:52:23Z,thanks much for catching this . you are right. i will fix this in [a link],1,0.9911606907844543
136772976,3621,lindong28,2017-09-04T08:53:01Z,originally i think the if/else may be better. the difference is very minor to me. i will remove `else` in [a link],0,0.9792966246604919
399149713,7898,OneCricketeer,2020-03-27T09:54:44Z,"imo, why not rewrite against `org.slf4j`?",0,0.991236686706543
399149940,7898,OneCricketeer,2020-03-27T09:55:09Z,"based on the comments, how about `2.13.x`?",0,0.994886577129364
399333888,7898,dongjinleekr,2020-03-27T15:08:24Z,"yes, i am now working with `2.13.1` and it seems like good.",1,0.7339874505996704
399335778,7898,dongjinleekr,2020-03-27T15:11:10Z,"`log4jcontroller` provides a dynamic `logger` querying functionality, not logging itself. it is why it uses log4j `logger`s directly. in contrast, the streams module does not provide those kinds of functionality so it uses slf4j fascade.",0,0.9916497468948364
400595313,7898,OneCricketeer,2020-03-31T01:48:42Z,"is zookeeper duplicated here?? also, does zookeeper transitively bring in log4j anywhere?",0,0.9916199445724487
400595736,7898,OneCricketeer,2020-03-31T01:50:16Z,it seems `org.apache.kafka.*` imports used to be first,0,0.992294430732727
400596128,7898,OneCricketeer,2020-03-31T01:51:49Z,is the `.map()` needed? [code block],0,0.9958906173706055
400596367,7898,OneCricketeer,2020-03-31T01:52:44Z,"also, `collectors.tocollection(treeset::new)` might be useful",0,0.9950319528579712
400596620,7898,OneCricketeer,2020-03-31T01:53:34Z,can `logger == null`?,0,0.9943758249282837
400597136,7898,OneCricketeer,2020-03-31T01:55:15Z,it seems these imports used to be first,0,0.9881066083908081
400597441,7898,OneCricketeer,2020-03-31T01:56:30Z,"personally, rather than rely on src/test/resources, i would pull from the classpath... `loggingresourcetest.class.getclassloader().getresource(""log4j2.properties"")`",0,0.9950025677680969
400598244,7898,OneCricketeer,2020-03-31T01:59:26Z,remove this?,0,0.9919736385345459
400598312,7898,OneCricketeer,2020-03-31T01:59:40Z,remove this?,0,0.9919736385345459
400598447,7898,OneCricketeer,2020-03-31T02:00:11Z,this pattern looks different,0,0.9821712970733643
400598659,7898,OneCricketeer,2020-03-31T02:00:56Z,nit: these got rearranged,-1,0.6636356115341187
401709877,7898,dongjinleekr,2020-04-01T15:35:11Z,fixed. please have a look at [a link]. :),1,0.9963485598564148
401713158,7898,dongjinleekr,2020-04-01T15:39:40Z,"this duplication has been addressed in [a link]. since this setting contols only direct imports only, it does not bring `log4j` transitively.",0,0.9947307109832764
401713391,7898,dongjinleekr,2020-04-01T15:39:59Z,great. i will apply it. :),1,0.9972944855690002
401713720,7898,dongjinleekr,2020-04-01T15:40:27Z,no. log4j2 does not allow `logger == null`.,0,0.9913114309310913
401714074,7898,dongjinleekr,2020-04-01T15:40:58Z,agree. i will have a try.,0,0.9596101641654968
401714449,7898,dongjinleekr,2020-04-01T15:41:30Z,not yet. `log4j-appender` is still using log4j; `log4j2-appender` is under progress. :),1,0.9927647709846497
401714669,7898,dongjinleekr,2020-04-01T15:41:48Z,ditto :smiley:,1,0.9899060130119324
401715288,7898,dongjinleekr,2020-04-01T15:42:40Z,"yes, but the reason is that it follows deleted `quickstart/java/src/main/resources/archetype-resources/src/main/resources/log4j.properties`; it has different pattern so i followed it.",0,0.9946767091751099
497371849,7898,tombentley,2020-09-30T09:30:32Z,shouldn't `connect.log.pattern` actually be something like this: [code block] ?,0,0.9920558333396912
497376858,7898,tombentley,2020-09-30T09:38:53Z,is the `policies` really necessary if we're only using a single triggering policy? i t_hink_ you could just say [code block],0,0.9894428253173828
497378983,7898,tombentley,2020-09-30T09:42:20Z,use a `\` escaped newline to avoid the very long line.,0,0.9908658862113953
497380746,7898,tombentley,2020-09-30T09:45:17Z,"also since log4j2 i think it's often unnecessary to have to specify` loggers` and `appenders` upfront, they can be determined during parsing. unfortunately the docs don't bother saying when it _is_ necessary, but it would be easy for users to add their `logger....name` and `logger....level` properties only to find it didn't work because they forgot about adding the name to `loggers`, so it would be good to only specify `loggers` if we really need to. same applies to appenders and the other log4j config files too, of course.",0,0.9734704494476318
497381662,7898,tombentley,2020-09-30T09:46:48Z,why was `log4j.rootlogger=off` before but `warn` now?,0,0.9841760993003845
497385774,7898,tombentley,2020-09-30T09:53:23Z,"collect has a overload which takes a supplier of empty maps (i think you also have to provide a lamda for duplicate keys, annoyingly). that would allow you to avoid needing the `new treemap` in the `return`. alternatively just use `foreach` as previously.",0,0.8277735710144043
497387063,7898,tombentley,2020-09-30T09:55:23Z,you can avoid the `if` using `found.orelse(null)`,0,0.9947682619094849
497387624,7898,tombentley,2020-09-30T09:56:17Z,was changing the parameter name really necessary? it makes the diff noisier and the old name wasn't _so_ bad.,-1,0.6935492157936096
497391073,7898,tombentley,2020-09-30T10:02:20Z,"it's a pre-existing issue, but i think this is slightly incorrect since it would tread `com.foo` as an ancestor of `com.foobar`. really we should be using `startswith` with a logger name that we know ends with a `.`.",0,0.9874557256698608
497392952,7898,tombentley,2020-09-30T10:05:18Z,"this is the second time you've got a `.equals("""")`. it might be worth factoring into a `isrootlogger(logger)` method.",0,0.9935495257377625
497393514,7898,tombentley,2020-09-30T10:06:13Z,why was this necessary?,0,0.9785187244415283
497396302,7898,tombentley,2020-09-30T10:11:25Z,"the default when the level is not set should be the ancestor logger's level, rather than the root logger level, but i guess you're waiting for my pr to be merged, right?",0,0.9897499680519104
497400286,7898,tombentley,2020-09-30T10:18:56Z,"we probably need better coverage in the alter case (`testincrementalalterconfigsforlog4jloglevels()`, below). it tests inheritance from the root logger, but not an ancestor logger. but i guess this is something i should add to my pr.",0,0.9886977672576904
497402528,7898,tombentley,2020-09-30T10:23:06Z,"`s""${classof[controllerintegrationtest]}#testcontrollermoveontopiccreation""`, and if not then there should be no need for the `tostring`",0,0.992998480796814
497402639,7898,tombentley,2020-09-30T10:23:18Z,same comment.,0,0.9916985034942627
497402786,7898,tombentley,2020-09-30T10:23:37Z,same comment.,0,0.9916985034942627
497402868,7898,tombentley,2020-09-30T10:23:48Z,same comment,0,0.9920485615730286
497410244,7898,tombentley,2020-09-30T10:37:28Z,"it's a shame about the new asynchrony here, but i don't see an obvious we of avoiding it.",-1,0.9808909893035889
497412007,7898,tombentley,2020-09-30T10:40:48Z,again it's not really clear to me why this is added,0,0.8731753826141357
497413476,7898,tombentley,2020-09-30T10:43:42Z,"i can see this being a source of difficult to maintain tests, if you have to tweak the latch every time logging statements are added or removed.",0,0.9392622113227844
497415319,7898,tombentley,2020-09-30T10:47:28Z,"do we really need the caller to supply a `name`? it seems to force you to have to construct a unique name each time you want to use it, based on the test class and method name. but all that's needed is uniqueness and the removal of the appender at the end of the test, afaics. so just using a uuid or similar generated name would be sufficient and make call sites rather easier to read.",0,0.9864098429679871
497416562,7898,tombentley,2020-09-30T10:50:02Z,"i wonder if it would simplify the tests if this had methods for asserting the existence of messages (optionally within a timeout) rather than having to use the `setlatch(), await(), getmessages()` pattern in every test.",0,0.971524715423584
497417343,7898,tombentley,2020-09-30T10:51:31Z,was this really necessary?,0,0.8834714293479919
500806583,7898,dongjinleekr,2020-10-07T07:50:01Z,"oh, i don't know why it is shown as a modification in diff view. in `config/tools-log4j.properties ` root logger level is `warn` by `log4j.rootlogger=warn, stderr`.",0,0.9784051775932312
500807752,7898,dongjinleekr,2020-10-07T07:51:52Z,great. i will improve the formatting and lining. let me see.,1,0.9607312679290771
500821253,7898,dongjinleekr,2020-10-07T08:14:05Z,no. `connect.log.pattern` is get referenced at the lines below: [code block],0,0.9932250380516052
500829824,7898,dongjinleekr,2020-10-07T08:27:30Z,"is this possible? all examples i saw explicitly state `policies`, like: - [a link] - [a link]",0,0.9924582242965698
500830940,7898,dongjinleekr,2020-10-07T08:29:14Z,"oh, i thought making it consistent with `loggingresource#setlevel` would be better.",0,0.988067626953125
500838684,7898,dongjinleekr,2020-10-07T08:41:15Z,"it is related to a issue between log4j2 2.13.x and powermock; in short, it causes `java.lang.linkageerror` as of present. please see: - [a link] - [a link]",0,0.99480140209198
500840081,7898,dongjinleekr,2020-10-07T08:43:23Z,right. fixed.,0,0.9873952865600586
500849730,7898,dongjinleekr,2020-10-07T08:58:12Z,"oh my, your approach is much simpler and more clear. okay, i will take this approach.",1,0.9414134621620178
500870442,7898,dongjinleekr,2020-10-07T09:30:27Z,"as you can see below, `new streamsconfig(props);` is called in every test method of this suite. so, this line is redundant. more importantly, it generates duplicated log messages and makes log message related test cases hard to validate.",0,0.988052487373352
500882458,7898,dongjinleekr,2020-10-07T09:49:59Z,"good proposal. actually, it is the first approach i have taken. however, while running the tests repeatedly, i found that the log messages are not forwarded in designated timeout properly, and the tests go so flaky. each test runs correctly when i run them individually, but 3 ~ 5 tests were randomly failed when i run them in bulk, with `./gradlew :streams:test`. it seems like this symptom is related to the busy wait implementation of `listappender#getmessages` but i can't certain yet. after numerous trial and error, i found that the current approach is a little bit verbose but makes the test suites sustainable. it is the background of this api design.",1,0.8986364603042603
501043518,7898,dongjinleekr,2020-10-07T14:09:17Z,"exactly. however, i thought introducing randomness to the test cases is worse than some verbosity. let's wait for others' opinions.",0,0.9084465503692627
501046635,7898,dongjinleekr,2020-10-07T14:13:18Z,agree. let's add a additional test about that case.,0,0.9842448830604553
501048158,7898,dongjinleekr,2020-10-07T14:15:19Z,exactly.,0,0.9872387051582336
501054972,7898,dongjinleekr,2020-10-07T14:23:52Z,"agree. i am now thinking about a utility class that determines whether a given logger name is a child, descendent, parent, or ancestor of another logger.",0,0.9760323762893677
501060061,7898,dongjinleekr,2020-10-07T14:30:04Z,"well, i found a similar method to what you described in `collectors`, not in `stream#collect`. is this what you mean? [code block]",0,0.9950469732284546
769044309,7898,rafalmag,2021-12-14T21:04:51Z,please use 2.15.0 instead to avoid noise about cve-2021-44228,0,0.9936813116073608
769083607,7898,amuraru,2021-12-14T22:07:30Z,actually 2.16 please,0,0.9811990261077881
769193981,7898,showuon,2021-12-15T02:24:53Z,"we should say, please use the **latest** release of log4j2, please! :)",1,0.9946235418319702
779703586,7898,ispringer,2022-01-06T17:05:23Z,can this be bumped to `2.17.1` ([a link],0,0.9961109757423401
780114085,7898,dongjinleekr,2022-01-07T08:59:50Z,"yes, i did [a link] for [a link] and it will be also applied to this pr. :+1:",1,0.9937481880187988
783853620,7898,viktorsomogyi,2022-01-13T11:03:14Z,i think renaming in this case makes the code a bit clearer and consistent.,0,0.84099280834198
783871962,7898,viktorsomogyi,2022-01-13T11:29:10Z,nit: instead of `.map(_._2)` you could use `.values`,0,0.9932102560997009
785830903,7898,viktorsomogyi,2022-01-17T10:32:27Z,i think i would also prefer generating a name in the `apply()` method. if someone uses the same name twice it might introduce an error but it's indeed easier to read without the `name` as tom proposed.,0,0.9852994680404663
785843643,7898,viktorsomogyi,2022-01-17T10:48:28Z,ran the tests and it seems like the powermock class loader isn't able to load these classes (as they have previously been loaded?). it doesn't cause a test failure but it's ugly and deferring to the system classloader fixes the issue. maybe has a more specific answer but i think it's fine to have this annotation here. [code block],-1,0.9541414976119995
786045157,7898,dongjinleekr,2022-01-17T14:14:41Z,"got it. i will update the pr to generate the context name automatically, like `logcapturecontext-xxxxxx`.",0,0.595592200756073
786067964,7898,dongjinleekr,2022-01-17T14:41:52Z,"oh yes, initially `kafkastreamstest` needed `({""javax.management.*"", ""org.apache.log4j.*""})` like `workersourcetasktest` but, it does not need it anymore. it would be better to remove this annotation.",0,0.9924443364143372
788006560,7898,viktorsomogyi,2022-01-19T17:58:25Z,"why don't you change this (and all the similar cases) to the log4j2 property? if i get it right then after the upgrade `-dlog4j.configuration` won't work anyway so while i see the value of notifying the user, i think we should just use the log4j2 property outright. or is there a backward compatibity, so does `log4j.configuration` work under log4j2?",0,0.9915063977241516
788034050,7898,rgoers,2022-01-19T18:34:38Z,"yes, if you set log4j.configuration to reference a log4j.xml (log4j 1 configuration) and you have log4j-1.2-api on the classpath then log4j 2 will process the log4j 1 configuration. we improve this support with every release. substantial improvements will be in 2.17.2 which should come out by the end of the month.",0,0.9827060699462891
788207067,7898,dongjinleekr,2022-01-19T22:42:42Z,thanks for the clarification. it seems like we also have to upgrade to log4j 2.17.2 soon.,1,0.9506006836891174
793571163,7898,dongjinleekr,2022-01-27T12:48:30Z,"for `level#tolevel` semantics, see: - [a link] - [a link] - [a link] as you can see here, all of above follows the same semantics - they fallback to `debug` with unknown level.",0,0.9941092729568481
794332702,7898,dongjinleekr,2022-01-28T09:24:29Z,fyi: [a link] cc/,0,0.9950612187385559
797627738,7898,mimaison,2022-02-02T13:53:12Z,nit: can we get rid of the extra spaces and have `name=value` for all these lines like in the other files?,0,0.9924788475036621
803805924,7898,mimaison,2022-02-10T15:36:58Z,is the plan to remove this and use the log4j2 file by default in the next major release?,0,0.9945337772369385
803816355,7898,mimaison,2022-02-10T15:46:17Z,nit: this is not aligned,0,0.7575708627700806
815384279,7898,showuon,2022-02-27T03:54:18Z,nit: can be simplified to: [code block],0,0.9941446185112
815400322,7898,showuon,2022-02-27T07:36:10Z,+1,0,0.9816582202911377
815400528,7898,showuon,2022-02-27T07:38:25Z,"is the additional ending ""space"" expected? and why?",0,0.9941015839576721
815400630,7898,showuon,2022-02-27T07:39:32Z,is the catch block expected?,0,0.9890084862709045
815401329,7898,showuon,2022-02-27T07:47:35Z,nice refactor,1,0.9835012555122375
815401515,7898,showuon,2022-02-27T07:49:17Z,"again, why additional ending space?",0,0.9683622121810913
815401739,7898,showuon,2022-02-27T07:52:04Z,why did we need these 2 supplier? i didn't see them get used in this test.,0,0.9615993499755859
815402457,7898,showuon,2022-02-27T07:59:29Z,"i'm thinking that we should add a clear javadoc in `logcapturecontext`, to explain when we should add `setlatch`, and when we should do `await`. i can see sometimes we don't set latch, but sometimes we set, and sometimes we do `await`, but sometimes not. could you help other developer with it?",0,0.979965329170227
815403276,7898,showuon,2022-02-27T08:07:11Z,"since we only care about `warn` level in this test, we could create `ktablesource.class` with `warn` log as before, right?",0,0.9924874305725098
815403282,7898,showuon,2022-02-27T08:07:20Z,ditto,0,0.9754701256752014
815403425,7898,showuon,2022-02-27T08:08:34Z,any reason why we change the expected log message here?,0,0.9905539155006409
815404230,7898,showuon,2022-02-27T08:16:29Z,why can't we verify whole messages?,0,0.978807806968689
815404252,7898,showuon,2022-02-27T08:16:46Z,ditto,0,0.9754701256752014
815404272,7898,showuon,2022-02-27T08:16:53Z,ditto,0,0.9754701256752014
815404434,7898,showuon,2022-02-27T08:18:21Z,nit: could we create log with warn only?,0,0.992049515247345
815404547,7898,showuon,2022-02-27T08:19:35Z,+1,0,0.9816582202911377
815404639,7898,showuon,2022-02-27T08:20:46Z,"and, also please add docs for what latch size should be set.",0,0.9949691891670227
815407543,7898,showuon,2022-02-27T08:47:35Z,why did we remove `finally` block for `rocksdbstore.close()`? is there possible that we have resource leak here?,0,0.992144763469696
815407744,7898,showuon,2022-02-27T08:50:03Z,ditto: potential resource leak?,0,0.9350858926773071
829746139,7898,dongjinleekr,2022-03-18T07:22:54Z,because of `streams/src/test/resources/log4j2.properties`: [code block],0,0.9954339861869812
829748108,7898,dongjinleekr,2022-03-18T07:26:53Z,no. this is a debris from the old code. removed.,0,0.9887604713439941
829777640,7898,dongjinleekr,2022-03-18T08:19:44Z,documentaton on `logcapturecontext` added.,0,0.9955405592918396
830011584,7898,dongjinleekr,2022-03-18T13:42:48Z,the try block with `logcaptureappender` resource was removed; that's the reason.,0,0.9950522780418396
461887873,9039,ableegoldman,2020-07-28T21:23:12Z,"not sure if you did this or your ide did it automatically, but nice :thumbs_up:",1,0.9952099919319153
462625072,9039,ableegoldman,2020-07-29T22:24:57Z,nit: call this `timedifferencems` to be in sync with `gracems`. also it can be private,0,0.9926274418830872
462626773,9039,ableegoldman,2020-07-29T22:29:17Z,nit: also rename the method `timedifferencems` to be consistent with `graceperiodms`,0,0.9946257472038269
462627186,9039,ableegoldman,2020-07-29T22:30:26Z,i think we can remove this suppression (and all the ones below),0,0.9838755130767822
462627276,9039,ableegoldman,2020-07-29T22:30:39Z,nit: extra space after `return`,0,0.9937307834625244
462640050,9039,ableegoldman,2020-07-29T23:06:31Z,"seems like this should have also had a check for `sessionwindows != null`, right? can we add that as well?",0,0.9911072850227356
462646319,9039,ableegoldman,2020-07-29T23:26:36Z,nit: alignment is off by one on the parameters,0,0.985626757144928
462647029,9039,ableegoldman,2020-07-29T23:29:01Z,"i think it's ok to skip this; since it's a new operator, there's no old topology to be compatible with",0,0.9489557147026062
462647656,9039,ableegoldman,2020-07-29T23:30:52Z,i wonder why we have to do this for `count` but not for `aggregate` and `reduce`? is this intentional or an oversight? cc,0,0.9098712205886841
462653088,9039,ableegoldman,2020-07-29T23:48:39Z,"can we add an `else` here with `builder.withcachingdisabled()`? it doesn't make a difference logically, it just seems easier to understand (again, also in `slidingwindowedcogroupedkstreamimpl`)",0,0.9920262694358826
462653237,9039,ableegoldman,2020-07-29T23:49:12Z,you should be able to remove this suppression and comment (here and in `slidingwindowedcogroupedkstreamimpl`),0,0.9956806898117065
462653505,9039,ableegoldman,2020-07-29T23:50:01Z,let's just remove this comment since it's the only style retention here (also in `slidingwindowedcogroupedkstreamimpl`),0,0.9940657615661621
462653753,9039,ableegoldman,2020-07-29T23:50:47Z,we can remove this,0,0.9941775798797607
462655858,9039,ableegoldman,2020-07-29T23:58:03Z,"i was wondering what this method is actually used for so i checked out the callers of `kstreamwindowaggregate#windows`. there's a method called `extractgraceperiod` in `graphgracesearchutil` where we might actually need to make a small addition to include the new sliding window processor. i think it's for suppression, which needs to figure out the grace period of the upstream operator since grace period doesn't get passed in directly to `suppress`",0,0.97394198179245
462658903,9039,ableegoldman,2020-07-30T00:08:03Z,"do you think we actually need to enforce that the retention period be a little longer for sliding windows? i was just thinking that since the range scan starts at `timestamp - 2 * windows.timedifference()`, maybe we should actually enforce that the retention period be >= `2 * timedifference + graceperiod` in case we need to get the aggregate value from some older window that has technically expired. haven't checked the math so i'm not sure that's the correct value exactly, but it seems like it might need to be a little bigger. any thoughts?",0,0.968521773815155
462660320,9039,ableegoldman,2020-07-30T00:13:10Z,"in general it's better to use a more descriptive variable name than a shorted one with a comment. it's not always possible to describe a variable exactly in a reasonable length, but i think in this case we can say `curleftwindowalreadyexists` or `curleftwindowalreadycreated` or something might be better to use `alreadycreated` when we're specifically talking about whether or not a window already exists in the window store, and can use `exists` when we're talking about whether a window is possible regardless of whether it currently has been created or not",0,0.9837192893028259
462661922,9039,ableegoldman,2020-07-30T00:19:14Z,"does that make sense? in particular i feel like we're using `exists` to mean one thing for `left/rightwindowexists`, and then we mean another thing entirely in `prevrightwindowexists`. ie `prevrightwinalreadycreated` is more similar to what we mean by the `left/rightwindowexists` variables",0,0.9870719313621521
462662132,9039,ableegoldman,2020-07-30T00:19:57Z,this comment doesn't seem quite correct,0,0.7980865836143494
462662498,9039,ableegoldman,2020-07-30T00:21:20Z,can we also name this variable a bit more clearly instead of the comment? like `foundcloseststarttimewindow` or something. same with `foundfirstendtime`,0,0.9941818118095398
462663297,9039,ableegoldman,2020-07-30T00:24:13Z,maybe add a comment saying that this condition will only be hit on the very first record. or it might be reasonable to pull this one condition out of the loop and just handle it before entering the loop,0,0.9861337542533875
462663911,9039,ableegoldman,2020-07-30T00:26:22Z,"actually maybe `foundright/leftwindowaggregate` would be good, since that's what ""the window with the closest start/end time to the record"" actually means to us",0,0.9885990619659424
462667387,9039,ableegoldman,2020-07-30T00:38:53Z,"should this be inside the `if (!foundfirst)` condition above? we only want to save the aggregate of the first window we find with a start time less than the timestamp right? also, i think we might need to check that the max timestamp of this window is greater than the current record's timestamp. if not, then the right window will be empty. for example, we have a record a at 10 and a record b at 11 and then process a record at 15. obviously, the new right window will be empty. but the first window we'll find with a start time less than 15 will be [11, 21] with agg b.",0,0.9822106957435608
462667988,9039,ableegoldman,2020-07-30T00:40:56Z,nit: put each parameter on its own line,0,0.9892721176147461
462669250,9039,ableegoldman,2020-07-30T00:45:20Z,"seems like we're aggregating with the new value twice; we call `aggregator.apply` once in this if/else branch but then also call it again in `putandforward`, right?",0,0.9883891344070435
462677427,9039,ableegoldman,2020-07-30T01:16:27Z,can we add a comment to clarify that we're checking whether it's a left window because that tells us there was a record at this window's end time,0,0.9943623542785645
462677774,9039,ableegoldman,2020-07-30T01:17:55Z,"i feel like i'm just way overthinking this, but i keep getting these variables confused. maybe we could call this guy `prevrightwindowcanexist`? does that seem to get at its underlying purpose?",-1,0.9774101376533508
462678777,9039,ableegoldman,2020-07-30T01:21:38Z,can we remove this and just `break` out of the loop immediately at the end of the `isleftwindow` condition block?,0,0.9948638081550598
462679991,9039,ableegoldman,2020-07-30T01:26:22Z,"i think we need to pass in the new maximum window timestamp here, not the window start time",0,0.9895750880241394
462682266,9039,ableegoldman,2020-07-30T01:32:45Z,ok i may have lost the trail of logic here...are we just checking `prevrightwinexists` as an indicator of whether we actually found any records to the left of our record within range? could/should we check `foundfirstendtime` instead?,0,0.852196991443634
462682718,9039,ableegoldman,2020-07-30T01:34:10Z,"since it's a left window, the max timestamp should always be `timestamp`, right?",0,0.9902920126914978
462683258,9039,ableegoldman,2020-07-30T01:36:00Z,can we put this condition into a method and give it a clear name to describe what this means? eg [code block],0,0.9950287938117981
463026843,9039,lct45,2020-07-30T14:13:34Z,"the original just had the check for `sessionmerger != null`, are there scenarios where the sessionmerger would be null but the sessionwindows wouldn't? i did think it was kind of inconsistent to check 'sessionmerger' just that one time and check 'sessionwindows' the other times so maybe it was a mistake",0,0.9700323343276978
463036048,9039,lct45,2020-07-30T14:26:20Z,done!,1,0.6799882054328918
463039985,9039,lct45,2020-07-30T14:31:32Z,"that's a good point. i think that `>= 2* timedifference + graceperiod` makes sense. adding graceperiod is just to help with out-of-order records, right? since for a normal record we won't need anything beyond 2*timedifference",1,0.9732100963592529
463046306,9039,lct45,2020-07-30T14:40:00Z,"yeah this makes sense, the boolean naming has definitely been a struggle. i think it's clearer actually if i change `prevrightwinexists` to `prevrightwinpossible` since that's what we're saying. i agree that for `leftwinexists` and `rightwinexists`, `alreadycreated` makes more sense.",0,0.9254327416419983
463047237,9039,lct45,2020-07-30T14:41:16Z,"yeah that's much clearer, and differentiates between the other bools better",0,0.9671524167060852
463056420,9039,lct45,2020-07-30T14:53:37Z,"i'm not sure if it can be moved out of the loop unless we also move a check for if the first is a window whose aggregate we need to update, which is easy to do but gets back to the redundant code that the algorithm had before having one while loop. i did update the comment though",0,0.9839040040969849
463063406,9039,lct45,2020-07-30T15:03:02Z,"yeah i think you're right that the aggregate should be in the `if()`, good catch. we could check max timestamp, but this scenario should be covered already. before we create a right window we do the boolean checks and since any in-order-record won't have either a `foundleftwinfirst` or the `prevrightwinalreadycreated` and one of them needs to be true for the right window to get created after the `while()`. i haven't fully thought through checking with maxtimestamp but it seems like that would work, if that way seems clearer i can alter the algorithm and run through the examples to make sure that covers everything",1,0.6421645283699036
463073842,9039,lct45,2020-07-30T15:17:48Z,"aha, i thought there was a scenario where the `putandforward` function wouldn't be so simple. yeah you're right, i updated it so the value of the record is only added in `putandforward`",1,0.9034700393676758
463076565,9039,lct45,2020-07-30T15:21:23Z,"updated above! changed to `prevrightwindowpossible` , lmk if that still seems confusing. i definitely kept getting them all mixed up so i think this will help",1,0.8681619763374329
463077196,9039,lct45,2020-07-30T15:22:21Z,100%,0,0.9416722059249878
463078058,9039,lct45,2020-07-30T15:23:36Z,good catch,1,0.9915775060653687
463083346,9039,lct45,2020-07-30T15:31:00Z,"yeah that's what `prevrightwinexists` is doing right now, we could store the full `valueandtimestamp` for `foundfirstendtime` and check to see if the max timestamp is within the range of recordtime-timedifference",0,0.991558313369751
463083821,9039,lct45,2020-07-30T15:31:38Z,yes!,1,0.4961845874786377
463088582,9039,lct45,2020-07-30T15:38:57Z,"changed to ` if (leftwinagg.timestamp() < timestamp && leftwinagg.timestamp() > timestamp - windows.timedifferencems()) { valueandtime = valueandtimestamp.make(leftwinagg.value(), timestamp); } else { //left window just contains the current record valueandtime = valueandtimestamp.make(initializer.apply(), timestamp); }`",0,0.9938774704933167
463091437,9039,lct45,2020-07-30T15:42:56Z,"to go with your above comment about the maxtimestamp, i changed this to be `if (!rightwinalreadycreated && rightwinagg.timestamp() > timestamp)` is this clearer or should it still be in a new method?",0,0.9954491257667542
463092579,9039,lct45,2020-07-30T15:44:41Z,"changing both of the `if()` for creating new windows cut down like half of the booleans too, which i think is good",1,0.721589207649231
464728426,9039,mjsax,2020-08-04T00:19:22Z,"the build should actually fail on wildcard imports... do we have some checkstyle gaps? can you maybe look into that (if not, also ok).",0,0.9919561147689819
464728901,9039,mjsax,2020-08-04T00:21:03Z,this pr is rather larger. would it maybe make sense to split it into 2 and add co-group in it's own pr?,0,0.9876975417137146
464729126,9039,mjsax,2020-08-04T00:21:44Z,nit: double `/**`,0,0.9861140847206116
464729311,9039,mjsax,2020-08-04T00:22:28Z,"nit: if you want to have a new paragraph, you need to insert ` ` tag -- otherwise, the empty line is just ignored all it's going to be one paragraph. -- if you don't want a paragraph, please remove the empty line.",0,0.9728431105613708
464729348,9039,mjsax,2020-08-04T00:22:35Z,as above.,0,0.9881609678268433
464729534,9039,mjsax,2020-08-04T00:23:14Z,type `[w]indows`,0,0.9951500296592712
464729743,9039,mjsax,2020-08-04T00:23:56Z,`and [a] given` ?,0,0.9916648268699646
464730686,9039,mjsax,2020-08-04T00:26:58Z,"we must use html list markup to get bullet points rendered, ie, ` ` and ` ` (cf [a link]",0,0.9945694804191589
464731092,9039,mjsax,2020-08-04T00:28:25Z,"`are processed` -> sounds like processing time semantics; maybe better `occur in the stream (i.e., event timestamps)`",0,0.9919456839561462
464731554,9039,mjsax,2020-08-04T00:29:58Z,reference to `cogroupedkstream` is missing,0,0.9878668785095215
464731762,9039,mjsax,2020-08-04T00:30:46Z,as above (won't comment on this again) -- please address throughput the whole pr.,0,0.9928983449935913
464732204,9039,mjsax,2020-08-04T00:32:24Z,`timedifference (timedifference)` (redundant) should be `time difference (timedifference)` `must be larger than zero.` -> `must not be negative.`,0,0.9914026856422424
464732462,9039,mjsax,2020-08-04T00:33:30Z,i guess a `timedifference` of zero should be allowed to define a sliding window of size `1ms`,0,0.9861899018287659
464732572,9039,mjsax,2020-08-04T00:33:53Z,as above -> should be `timedifferencems < 0`,0,0.9945217370986938
464733014,9039,mjsax,2020-08-04T00:35:30Z,"for consistency: `grace period (grace) must` ? frankly, i am not sure if we need to have ""natural language"" and the parameter name in those error messages -- also above. but we should do it in a consistent manner imho.",0,0.9338786602020264
464734041,9039,mjsax,2020-08-04T00:39:23Z,i agree with sophie that his check seems a little weird. we should check that either both (sessionwindows and sessionmerger) are null or not null.,-1,0.8062703013420105
464735173,9039,mjsax,2020-08-04T00:43:50Z,"i think we should do this check in `init` and use a `runnable` that we just call blindly (ie, depending on the check, we instantiate the one or other `runnable` and each `runnable` implements a different algorithm.",0,0.9852956533432007
464735252,9039,mjsax,2020-08-04T00:44:11Z,why do we suppress instead of fix the issue? (or add an exception to the `suppress.xml` file if we really need it),0,0.9835512042045593
464736052,9039,mjsax,2020-08-04T00:47:16Z,"i think we should also drop if `value == null` ? (it seem this `null` check is missing in the existing time/session-window aggregate processors, too)",0,0.9915263056755066
464736550,9039,mjsax,2020-08-04T00:49:24Z,"maybe we have the same issue in other processors, too (we might even have a ticket for it?) but won't we need to preserve `observedstreamtime` across restarts? it's transient atm... (just want to confirm -- maybe it's ok as other processor do it the same way and we need to fix if for all of them at once?)",0,0.9799485802650452
464736969,9039,mjsax,2020-08-04T00:51:12Z,the comment seems redundant -- it just says exactly what the next line of code says.,0,0.9023348093032837
464737602,9039,mjsax,2020-08-04T00:53:54Z,"no need to pass in an `instant` -- we should just pass in the `long` directly. it might not be clear from the type hierarchy, but the overloads that accept `long` are only deprecated for the `readonlyxxx` store, but are still available on the ""read/write"" stores to avoid unnecessary runtime overhead.",0,0.9931455850601196
464738212,9039,mjsax,2020-08-04T00:56:11Z,why `+ 1` ?,0,0.9886309504508972
464738932,9039,mjsax,2020-08-04T00:59:18Z,"as above. (also, this code seems to be duplicated; we should move it into `process()` before we call the the actual `processreverse` or `processinorder` methods.",0,0.9942554831504822
464739084,9039,mjsax,2020-08-04T00:59:53Z,as above,0,0.9888283014297485
464739153,9039,mjsax,2020-08-04T01:00:07Z,nit: move `key` to the next line,0,0.9943270087242126
464739977,9039,mjsax,2020-08-04T01:03:19Z,why `* 2` ?,0,0.9883502721786499
464740108,9039,mjsax,2020-08-04T01:03:51Z,why `* 2` ?,0,0.9883502721786499
464740325,9039,mjsax,2020-08-04T01:04:45Z,why this?,0,0.883537232875824
464740712,9039,mjsax,2020-08-04T01:06:18Z,we should not use this annotation (even if we still have code that used it... we are working on migrating test away lazily). we should instead use `assertthrows` and also verify the exception error message. same below.,0,0.9921261072158813
464740960,9039,mjsax,2020-08-04T01:07:06Z,"beside the fact, that zero should be valid imho, what do we gain by testing `0` and `-1` ?",0,0.9836020469665527
464741103,9039,mjsax,2020-08-04T01:07:51Z,this line seems to be unnecessary for this test?,0,0.9902160167694092
464741202,9039,mjsax,2020-08-04T01:08:16Z,this is also a pattern we try to move off. use `assertthrows` instead.,0,0.9945411086082458
464741688,9039,mjsax,2020-08-04T01:10:08Z,"why do we need three tests? if you want to ""randomize"" it, maybe just use `random` to generate `difference` and `grace` input instead of hard coding them?",0,0.9891082048416138
464741801,9039,mjsax,2020-08-04T01:10:33Z,as above.,0,0.9881609678268433
464741983,9039,mjsax,2020-08-04T01:11:13Z,what is the difference between `verifyinequality` and `assertnotequals` ?,0,0.9921147227287292
464742330,9039,mjsax,2020-08-04T01:12:30Z,this should be two test: - `shouldnotbeequalfordifferenttimedifference` - `shouldnotbeequalfordifferentgraceperiod`,0,0.9914630055427551
464744504,9039,mjsax,2020-08-04T01:20:48Z,why is `endtime = long.max_value`? should it not be `firstbatchtimestamp` ?,0,0.9932367205619812
464744963,9039,mjsax,2020-08-04T01:22:32Z,`firstbatchleftwindow` -> `firstbatchleftwindowstart` maybe also introduce `firstbatchleftwindowend = firstbatchtimestamp`,0,0.9936282634735107
464746013,9039,mjsax,2020-08-04T01:26:26Z,maybe add comment to clarify which input should trigger which output: [code block],0,0.9939866065979004
464746981,9039,mjsax,2020-08-04T01:30:05Z,"we should add a fourth batch with ts like 10k to get the windows when the second batch drops outs, too.",0,0.9897366762161255
465073439,9039,lct45,2020-08-04T14:02:56Z,"would checking both be redundant? it looks like the method that ultimately calls this one will check that sessionmerger is not null for session windows, so i think either both of these will be null or neither will be null",0,0.9833541512489319
465079294,9039,lct45,2020-08-04T14:10:57Z,"we want to be able to find the furthest window for which we can create a corresponding right window, so for any record the furthest window we will ever need will start at `timestamp - 2 * timedifference`, but we will need to have these around to calculate new windows, hence the longer retention time.",0,0.9914855360984802
465094963,9039,lct45,2020-08-04T14:30:49Z,"because the windows are sorted, the windows created by each record aren't consecutive, so i added comments describing each window, but only did it for a since all the other keys are processed the exact same way. sample comment: `// a @ secondbatchtimestamp left window created when a @ secondbatchtimestamp processed`",0,0.9942585229873657
465097558,9039,mjsax,2020-08-04T14:34:22Z,"well, yes and no. we can follow two strategies: (1) we rely on the user to only set all `null` (for the non-windowed aggregation case) or either one of `windows`, `slidingwindow`, or `sessionwindow+sessionmerger` and we don't do any verification if the method is called correctly or not. however, for this case, we don't need to do any redundant not-null check and we could just write: [code block] or, (2) we do not ""trust"" the caller and do a proper check that the provided arguments make sense. and the existing code already has such a safe guard and does checks that not multiple windows are passed in and throws an `illegalargumentexception` if the caller makes a mistake. i personally prefer to have a safe guard (especially on the non-hot code path) as it may prevent bugs. however, the current check is not complete, as it does not verify that `sessionmerger` must be not-null when `sessionwindows` is not-null; this may lead to a potentially cryptic `nullpointerexception` later that is harder to understand. if we do the check and throw a proper `illegalargumentexception(""sessionmerger cannot be null for sessionwindows"")` and `illegalargumentexception(""unexpected sessionmerger parameter: should be null because sessionwindows is null"");` help to identify the issue quickly.",0,0.9886897206306458
465099913,9039,mjsax,2020-08-04T14:37:23Z,"ack. makes sense. might be worth to add a comment why we need an ""unexpected"" large retention time.",0,0.9407016038894653
465101059,9039,mjsax,2020-08-04T14:39:00Z,with regard to above: the error message to does align to the required minimum retention time. it says `must be no smaller than its window time difference plus the grace period.`...,0,0.9930112957954407
465111665,9039,lct45,2020-08-04T14:53:23Z,"good catch, will do",1,0.9921390414237976
465191505,9039,lct45,2020-08-04T16:51:54Z,"there seems to be a bug in `timewindoweddeserializer` related to [a link] that ends up setting the windowsize to `long.max_value`. for the purposes of testing, i don't think having it as the max value is totally awful (just somewhat awful) and the window end calculations are all tested in a different set of tests done through topology driver. i'll make a ticket for this bug and try to get it fixed when i'm done with testing",-1,0.7218659520149231
465193735,9039,lct45,2020-08-04T16:55:32Z,"i think just confirming that the correct error will be thrown when someone sets a `timedifference` we don't want. i'll update all the `windowsize` to be `timedifference` and i agree, no need to check that it isn't 0",0,0.9872960448265076
465194845,9039,lct45,2020-08-04T16:57:19Z,"re-examining the test, it looks like it does the same thing as `graceperiodmustnotbenegative()` so i think the test can be removed entirely",0,0.9899910688400269
465205088,9039,lct45,2020-08-04T17:15:08Z,"whoops, not on purpose. thanks for the check",1,0.7994833588600159
465219522,9039,lct45,2020-08-04T17:40:13Z,"to clarify, are you wanting to add records that would fall after the third batch _outside_ of all the existing windows, or so that it will fall into the third batch's windows but not the second batch's windows?",0,0.9915323853492737
465334577,9039,lct45,2020-08-04T21:15:01Z,"we could, but it would only pull out 3ish classes and not very many lines, so i don't think it would make this pr feel much smaller",0,0.9251867532730103
465336976,9039,lct45,2020-08-04T21:20:12Z,so we can check to see if the record that is being processed has an already existing right window (that would start at timestamp+1) without doing another call to the store,0,0.9933631420135498
465339322,9039,lct45,2020-08-04T21:25:19Z,fixed for both,0,0.9886190891265869
465348679,9039,lct45,2020-08-04T21:46:37Z,"they look to be fairly similar, and it seems like the tests use both consistently. `verifyinequality` seems to be more thorough, and to be consistent with the above `equalsandhashcodeshouldbevalidforpositivecases` i think i'll use `verifyinequality` for this test, unless someone has an objection",0,0.8916191458702087
465369865,9039,ableegoldman,2020-08-04T22:40:42Z,"why do we have a single method that accepts all three window types and then checks them all individually to enforce that only one type of window is actually ""set""? seems like we could enforce this implicitly by having a separate method for time, session, and non-windowed aggregates and then just calling the correct signature. ie `sessionwindowedcogroupedkstreamimpl` calls `build(...sessionwindows, sessionmerger) and so on. maybe i'm missing something here because i wasn't following the cogroup kip that closely, but is this even exposed to the user in any way? my understanding is that there's no way for this check to be violated by any kind of user input, because this method is only ever called directly by streams internal code with `null` hardcoded for the unused window types. i think it's more of an internal consistency check for streams than an input validation for the user (and it seems unnecessary: see above)",0,0.9619834423065186
465371635,9039,ableegoldman,2020-08-04T22:45:29Z,"seems like the cogroup stuff makes up a pretty small amount of the overall pr, but up to leah",0,0.9685691595077515
465374004,9039,ableegoldman,2020-08-04T22:52:21Z,"we definitely have the issue in all processors right now lol. it's not any more of a problem for this sliding windows algorithm as for any other operator that defines a grace period, at least. we might end up not dropping a late record that we should have; for sliding windows we'd get one extra window (with this record at the window end) whereas for a hopping/tumbling window we'd get n extra windows (however many overlaps there are)",1,0.9659896492958069
465379071,9039,ableegoldman,2020-08-04T23:07:35Z,not saying all this needs to be cleaned up in this pr. if we check one thing (eg `sessionmerger`) then we should check everything (eg `sessionmerged != null && sessionwindows != null`). we can decide whether we really need to check anything as followup,0,0.9879769682884216
465379566,9039,ableegoldman,2020-08-04T23:09:14Z,maybe we can add this answer as a comment in the code for future readers,0,0.9838288426399231
465380753,9039,ableegoldman,2020-08-04T23:13:03Z,"just to clarify, we don't get any additional output when the stream time is advanced and older windows drop out of the grace period. we've already forwarded their final state when the last record to update that window was processed. not sure if that's what you meant by ""get the windows when the batch drops out"" or not?",0,0.9856603145599365
465382189,9039,ableegoldman,2020-08-04T23:17:51Z,"not sure, i think `and given window grace` makes grammatical sense. but either way",0,0.8626003265380859
465382663,9039,ableegoldman,2020-08-04T23:19:29Z,"it took me a second to understand the structure of this sentence, can we insert an `and` after the `record's timestamp`?",0,0.9904634952545166
465399031,9039,ableegoldman,2020-08-05T00:13:33Z,extra `/*` here,0,0.9950234889984131
465399853,9039,ableegoldman,2020-08-05T00:16:39Z,technically this is an `xor` not an `or` :face_with_tongue:,0,0.9909777641296387
465400403,9039,ableegoldman,2020-08-05T00:18:42Z,"can you revert the line changes here and below? nothing wrong with them, but the fewer lines/classes changed in the pr, the better",0,0.9888140559196472
465401189,9039,ableegoldman,2020-08-05T00:21:40Z,"think you missed changing this in the cogrouped class, this should be 2*timedifference right?",0,0.9858279228210449
465402473,9039,ableegoldman,2020-08-05T00:26:16Z,i think we need a null check here like we have down in `slidingwindowedkstreamimpl#materialize`,0,0.9888900518417358
465407448,9039,ableegoldman,2020-08-05T00:45:26Z,+1 to add a comment on the extra retention (here and in slidingwindowedcogroupedkstreamimpl),0,0.9899551868438721
465407638,9039,ableegoldman,2020-08-05T00:46:16Z,should be `no smaller than twice its window time difference...`,0,0.9891681671142578
465408876,9039,ableegoldman,2020-08-05T00:50:59Z,"+1 to using a random number instead of multiple lines. if it does happen to fail on a specific random number, we should be sure to print that number for reproducing it later. see taskassignorconvergencetest#runrandomizedscenario for example",0,0.8995286226272583
465409330,9039,ableegoldman,2020-08-05T00:52:44Z,"took me a second to understand this test, ""negativecases"" made me think the timedifference/grace were supposed to be negative. +1 to matthias's suggestion for naming (and splitting into two tests)",1,0.9506656527519226
465412482,9039,ableegoldman,2020-08-05T01:03:59Z,"can you leave a todo here to make sure we remember to change this to `reversefetch`? seems unlikely we'd forget, but you never know",0,0.9899529814720154
465414316,9039,ableegoldman,2020-08-05T01:11:09Z,"which check? i was just thinking that, since the window starting at record.timestamp + 1 is basically a special case, we can just pull it out of the loop completely. we don't have to update anything since the record doesn't fall into this window, right? basically just before entering the loop we check `if next.key.window().start() == timestamp + 1` and if so set `rightwinalreadycreated` and then skip to the next record",0,0.9801059365272522
465414863,9039,ableegoldman,2020-08-05T01:13:02Z,"we don't technically need `continue` at the end of each condition, right?",0,0.9834432005882263
465416585,9039,ableegoldman,2020-08-05T01:19:27Z,"awesome! i might still recommend pulling the `rightwinagg != null && rightwinagg.timestamp() > timestamp` check out into a method called `rightwindowisnonempty` or something, but it's definitely a lot easier to understand now even without that :grinning_face_with_smiling_eyes:",1,0.9966592788696289
465418942,9039,ableegoldman,2020-08-05T01:28:01Z,"we need to check `leftwinagg` for null, right? also, is it ever possible for `leftwinagg` to be non-null but not satisfy this condition? maybe we can just check `leftwinagg != null` and if so, then assert that `leftwinagg.timestamp() < timestamp && leftwinagg.timestamp() > timestamp - windows.timedifferencems()` is always true (eg throw an `illegalstateexception` if it's not)",0,0.9903267025947571
465419531,9039,ableegoldman,2020-08-05T01:30:09Z,can we remove the `math.max` thing for now and just drop records that are too early for us to process for now?,0,0.9931754469871521
465421190,9039,ableegoldman,2020-08-05T01:36:28Z,"just a note to other reviewers: we're planning to revisit the issue of ""early"" records later and are just dropping them for now to make the general algorithm easier to review and understand. it needs some special handling for the edge case of records that arrive earlier than the full sliding window due to the inability to store windows with negative start times",0,0.9740420579910278
465421265,9039,ableegoldman,2020-08-05T01:36:42Z,nit: put this on one line,0,0.9426054954528809
465421657,9039,ableegoldman,2020-08-05T01:38:18Z,comment doesn't seem to match the query bounds (missing a +1?),0,0.9887059926986694
465421880,9039,ableegoldman,2020-08-05T01:39:08Z,is there any reason this wouldn't just be `window.start + timedifferencems`?,0,0.993230938911438
465424346,9039,ableegoldman,2020-08-05T01:48:06Z,"same here, let's not pin the start time to 0 for now and just drop the early records",0,0.9887853860855103
465425090,9039,ableegoldman,2020-08-05T01:50:32Z,"yeah especially since we use the same condition for both the forward and reverse case, let's just pull the `rightwinagg != null && rightwinagg.timestamp() > timestamp` out into a separate method",0,0.9878338575363159
465725011,9039,lct45,2020-08-05T13:26:48Z,"yeah that works unless the first window isn't the right window, in which case we would need to process it (save as the rightwinagg, update its aggregate if the current record falls into it, etc) before going to the next record at the top of the while loop. it definitely works and is what we had before, it just makes the code a little less clean.",0,0.8132842183113098
465751597,9039,lct45,2020-08-05T14:05:28Z,"hmmmm yeah, i think if there's something in the left window then we will always initialize `leftwinagg` to something other than null, good catch. we essentially check `leftwinagg.timestamp() < timestamp` in the while loop, so i don't think that should cause a problem, and `leftwinagg.timestamp() > timestamp - windows.timedifferencems()` will never be true because that window would be out of range, right? and we only take the first left agg. long way of saying, i think we can do the null check and nothing else but will know slightly more when we can test it",0,0.6961609125137329
465756356,9039,lct45,2020-08-05T14:12:12Z,"nope, since we aren't storing truncated windows",0,0.9843053817749023
466026007,9039,mjsax,2020-08-05T21:54:05Z,the ticket is already fixed. you need to pass in the `windowsize` into the the constructor of `timewindowdeserializer` to get rid of the problem.,0,0.9947764873504639
466028866,9039,mjsax,2020-08-05T22:00:39Z,"i guess testing both cases would be good. even if testing the former (fall outside of all existing windows) was my original intent. and thank for comment sophie: i tend to forget that we should produce all (non-empty) right windows already upfront/eagerly (and not delayed/lazily when stream-time advances beyond window-end time). in any case, it seems to be a good test case to make sure we don't (re-)emit an (unexpected) window if stream-time jumps ahead?",1,0.9261016845703125
466029116,9039,mjsax,2020-08-05T22:01:14Z,ack. was just a thought.,-1,0.5785934329032898
466032331,9039,mjsax,2020-08-05T22:09:37Z,"we pass in all parameter to sharing to code that creates the `statefulprocessornode` -- not sure if it's the best way to structure the code and i am happy to split it up into multiple methods call (as long as we avoid code duplication). and yes, you are right, it's internal and the checks are just for us to avoid programming errors. users should never be exposed to it. i personally tend to make a lot of mistakes and the more checks we have in place the better imho :) if want's she can just do a side cleanup pr to fix it, and rebase this pr after the cleanup pr was merged? or we do it as follow up. whatever works best for you.",1,0.9907041192054749
466032804,9039,mjsax,2020-08-05T22:10:51Z,thanks for confirming. let keep this issue out for this pr than.,1,0.9646708369255066
466033381,9039,mjsax,2020-08-05T22:12:25Z,i am not a native speaker... don't ask me... mr.john should know -- he has the proper education for it.,-1,0.6502184867858887
466042505,9039,lct45,2020-08-05T22:38:04Z,"that should be covered in `kstreamslidingwindowaggregatetest`, which goes through more of the edge cases using the `topologytestdriver` which is a little easier to manipulate than this set up",0,0.9928547739982605
466050097,9039,ableegoldman,2020-08-05T23:00:38Z,"well, if the first window isn't the right window then we just wouldn't call `iterator.next` again, right? so we wouldn't have to do anything at all",0,0.9868564009666443
466051779,9039,ableegoldman,2020-08-05T23:05:45Z,"ok cool, just checking. either `endtime = window.start + timedifferencems` or `endtime = window.end` is fine as long as we're consistent (i guess we only define it in two places, the forward and reverse algorithms?)",1,0.7085065245628357
466052825,9039,ableegoldman,2020-08-05T23:08:41Z,"sounds good. we definitely need the null check just to avoid getting an npe, but whether we _only_ need the null check is something we should put to the test",1,0.5892482995986938
466063583,9039,ableegoldman,2020-08-05T23:42:35Z,"no she's right, this problem is not resolved at all. you can pass in `windowsize` to the constructor for `timewindoweddeserializer` all you want but it just gets ignored because the actual deserializer object you instantiate is thrown away. whether you're reading in records through a java consumer or the console consumer (for some reason this test does both), the actual deserializer is always constructed within the consumer based on the configs. there's a config for the windowed inner class which is properly set in `timewindoweddeserializer#configure` but no config for the `windowsize` so there's no way to set it at the moment. tl;dr there's no point in having serde constructors accept parameters, they need to be set through `configure`",0,0.976655125617981
466070317,9039,lct45,2020-08-06T00:05:50Z,created a ticket for this here: [a link] let me know if the description isn't clear,0,0.9935495257377625
466425932,9039,lct45,2020-08-06T13:49:17Z,"i'm happy to do a pr! looking into it now though, `getstatefulprocessornode` is called by `build`, so i think to really separate it by type we'd need a different `build` _and_ `statefulprocessornode`, otherwise we'd be moving the null checks into `build` and then calling the correct `getstatefulprocessornode`, which does't seem to really fix anything. thoughts? it's easy to create new `build` functions but i figured this might fall under not avoiding code duplication :)",1,0.994550883769989
466618450,9039,ableegoldman,2020-08-06T18:52:07Z,"i do think we'd need separate `build` methods, since that's where we originally accept multiple windows as arguments (where all but one type is set to null in each caller). but most of `build` doesn't touch the windows arguments so you could probably factor out all the window-independent code into a single method and just have each `build` method call that",0,0.9857633113861084
467231847,9039,mjsax,2020-08-07T19:33:46Z,thanks. i missed the point that this trick to pass in the windowsize only works for kafkastreams when we pass in `serdes` object that are used as provided...,1,0.9567009210586548
467260318,9039,lct45,2020-08-07T20:44:35Z,"sounds good, i'll change that when i implement the reverse iterator in the next pr",0,0.5394924283027649
467296111,9039,ableegoldman,2020-08-07T21:50:49Z,clearly kafka streams is superior to the plain consumer :smiling_face_with_horns:,1,0.9871888756752014
468214782,9039,vvcephei,2020-08-10T22:11:47Z,"haha, my specialty! the distillation of this sentence is ""windows are defined based on a record's timestamp, window size, and window grace period."" i think the meaning is pretty clear, so no need to change anything. just to point it out, there's structural ambiguity about whether the sentence is saying ""a record's (timestamp, window size, window grace period)"" (i.e., three properties of the record), or whether there are three top-level things that define the window. the latter was intended. i think actually inserting ""the"" before ""window"" both times would clear it up: ""windows are defined based on a record's timestamp, the window size, and the window grace period."" another note is that because the second item in the list is so long, the structure of the list gets a little lost. it would be better in this case to use the oxford comma to clearly delineate the boundary between the second and third items. so, although i think this is fine as-is, if you want me to break out the red pen, i'd say: [code block]",1,0.9858118295669556
468216620,9039,ableegoldman,2020-08-10T22:16:48Z,comment on the reverse case left behind,0,0.9887813329696655
468217437,9039,ableegoldman,2020-08-10T22:19:00Z,nit: extra line breaks,0,0.7888405919075012
468217987,9039,ableegoldman,2020-08-10T22:20:29Z,you should check to make sure all of these are still needed. in particular i bet we can get rid of the cogroupedstreamaggregatebuilder suppression once your cleanup pr is merged and this one is rebased,0,0.993395984172821
468218540,9039,ableegoldman,2020-08-10T22:22:02Z,i think we usually leave the arguments on the same line as the method declaration (even if that line ends up way too long),0,0.9805963039398193
468219113,9039,ableegoldman,2020-08-10T22:23:34Z,"kind of hard to tell, but is the alignment in this method a bit off? might be good to just highlight and auto-indent everything, intellij will take care of any issues if it's configured properly",0,0.8788589835166931
468290069,9039,ableegoldman,2020-08-11T02:28:07Z,nit: extra spaces after the `->`,0,0.992306649684906
468291563,9039,ableegoldman,2020-08-11T02:34:01Z,"the input is the same for each test so the output is too, right? maybe we can we pull all the output verification into a single method",0,0.9906043410301208
468292711,9039,ableegoldman,2020-08-11T02:38:04Z,"can we add some tests to verify the other materialized properties, specifically the retention? you can just pick a single operator (eg `reduce`) and write a test to make sure data is available (only) within the retention period. also, do you think we can write a test to verify that the default retention is as expected when we don't specify it?",0,0.9947608113288879
468293244,9039,ableegoldman,2020-08-11T02:40:05Z,"this comment needs to be updated, looks like we do allow a grace period of zero in the code/tests",0,0.9935246706008911
468293930,9039,ableegoldman,2020-08-11T02:42:39Z,`assertthrows` :slightly_smiling_face:,1,0.9724695682525635
468294181,9039,ableegoldman,2020-08-11T02:43:41Z,"awesome, thanks for cleaning up some of these older tests :grinning_face_with_smiling_eyes:",1,0.9966627955436707
468653951,9039,lct45,2020-08-11T15:07:03Z,"i pulled it out for all except one, because there's one call to `windowstore` that returns a ` , long>` and the other calls to `windowstore` return a ` , string>`",0,0.9929872155189514
468690429,9039,lct45,2020-08-11T15:58:35Z,"i'm not sure if i'm just missing something, but it doesn't look like there's a way to check what retention is. i created a test to make sure anything lower than our bound throws an exception, but i can't find anywhere the retention time is exposed for me to check what it's set to",0,0.4993562698364258
468796354,9039,lct45,2020-08-11T18:53:42Z,update: the windows themselves are the same but the value is different for each test,0,0.9928102493286133
468814368,9039,ableegoldman,2020-08-11T19:27:39Z,"yeah sorry i should have been more clear, i just meant push some data through and try to query the store to make sure it is/isn't there according to the retention period. you're right, it's not directly exposed anywhere",-1,0.9844170808792114
471797422,9039,ableegoldman,2020-08-17T21:57:26Z,do we still need this one after the cleanup you did?,0,0.9930058121681213
471798256,9039,ableegoldman,2020-08-17T21:59:31Z,"[code block] also i think this set is pretty clearly named, so we probably don't need a comment for it",0,0.9879244565963745
471798801,9039,ableegoldman,2020-08-17T22:00:50Z,nit: can we use the full word `window` in method names at least,0,0.9916388392448425
471801743,9039,ableegoldman,2020-08-17T22:08:09Z,"nit: you could use the version of `fetch` that just takes a single key instead of a key range, since there's only one key here",0,0.9882325530052185
471820115,9039,ableegoldman,2020-08-17T23:01:12Z,"can we insert one that's like right on the border of the retention period? so if the streamtime at the end is 2,000 then the window cut off is 800 (or start time of 700), and verify that anything starting before 699 is gone and everything after that is there.",0,0.9921472668647766
471823061,9039,ableegoldman,2020-08-17T23:09:53Z,"for readability, could we mark the final results for each window? we want to make sure all the intermediate results are as expected, but what we really care about is what we got in the end. it would just help to have the critical output easier to find and get oriented in the tests",0,0.9865183234214783
471824209,9039,ableegoldman,2020-08-17T23:13:31Z,it might be nice to use different values for each record (at least within the same key). i don't think there are really any edge cases we should worry about when records have the same value so we may as well use a distinct one to make the tests a bit easier to read,0,0.9779070615768433
471825457,9039,ableegoldman,2020-08-17T23:17:24Z,"i still don't exactly understand why we have a join test in the `kstreamxxwindowaggregatetest`, but thanks for adding it for sliding windows. i'm sure there was a good reason for it, probably long ago",1,0.9245541095733643
471827371,9039,ableegoldman,2020-08-17T23:23:35Z,"sorry that i only just got to looking through this class :disappointed_face: . the tests here look good but can we add some more test coverage of possible edge cases? i know we can't test early records until the next pr, but we should probably have more than just the one test of the core functionality. i know it's really annoying to have to think through all the intermediate output, so maybe you can write a helper method that just grabs the final result of each window in the output? then we could have a number of tests that go through a larger number of input records without you having to spend all day manually processing them yourself :grinning_face_with_smiling_eyes:",-1,0.9951788187026978
472436400,9039,lct45,2020-08-18T19:41:02Z,we don't!,0,0.8607931137084961
472440045,9039,lct45,2020-08-18T19:48:20Z,"that `fetch` only returns a `windowstoreiterator` instead of a `keyvalueiterator`, which i don't think is a huge deal but we wouldn't get the start/end time of the window which is nice to have for the test",0,0.8276532292366028
472441802,9039,ableegoldman,2020-08-18T19:51:48Z,"oh right, forgot that it doesn't have the window times either. nevermind then",0,0.882766604423523
474966465,9039,ableegoldman,2020-08-21T20:59:10Z,"can we actually wrap the whole `testprocessorrandominput` test in the try-catch? or at least, everything after the initial setup? would be nice to have the seed in case something weird happens during the processing itself",0,0.9839985370635986
474977836,9039,ableegoldman,2020-08-21T21:28:42Z,"just a minor note, can we order the expected results by window timestamp?",0,0.9926915764808655
475919413,9039,ableegoldman,2020-08-24T22:02:05Z,"nit: can you call this something a bit more direct, eg `verifyrandomtestresults` ?",0,0.9922731518745422
475922761,9039,ableegoldman,2020-08-24T22:10:32Z,nit: `testaggregaterandominput` to match up with other test names,0,0.9950469732284546
475923788,9039,ableegoldman,2020-08-24T22:13:19Z,can you leave a brief comment here explaining why we're doing something slightly more complicated in the aggregator for this test,0,0.9937297105789185
478518760,9039,vvcephei,2020-08-27T15:45:49Z,"i'm reviewing this whole pr as-is, so there's no need to do anything now, but 's specific suggestion is beside the point. the general feedback is that this pr is too large, which it is. we shoot for under 1k, and it's the pr author's responsibility to figure out the best way to break it up. this policy isn't just ""reviewers complaining,"" it's an important component of ensuring ak's quality. long prs overwhelm any reviewer's cognitive capacity to pay attention to every detail, so oversights are more likely to slip through into the codebase, and once they're there, you're really at the mercy of the testing layers to catch them. when the oversights are very subtle, they wind up getting released and then surface as user-reported bugs. reviewers can't guarantee to notice every problem, but our capacity to notice problems is inversely proportional to the length of the pr.",0,0.6840218901634216
478627800,9039,vvcephei,2020-08-27T18:53:31Z,"is this condition supposed to be checking whether records are ""early"" with respect to now? it looks like it should be: [code block]",0,0.9944255352020264
478664149,9039,vvcephei,2020-08-27T20:03:13Z,minor: this could be declared `final` at the assignment on line 161,0,0.9927317500114441
478669986,9039,vvcephei,2020-08-27T20:14:32Z,might not be a bad idea to have an assertion here that the timestamp is actually in the window boundaries.,0,0.9730997085571289
478671190,9039,vvcephei,2020-08-27T20:16:55Z,"is it already guaranteed that this window actually contains the current record? it doesn't look like we're checking that `endtime >= timestamp` anywhere, and it seems like the start of the range (`timestamp - 2 * windows.timedifferencems()`) could give back a window that starts and ends before the current record's timestamp.",0,0.9915430545806885
478702517,9039,vvcephei,2020-08-27T21:20:46Z,"the achilles heel of implementing new ktable features has historically been that we forgot to test them in a context that required the valuegetter to work properly, of which join is a notable use case. i'd actually say it should be required for every ktable operator to have a test where it's the source of a join. for stateless operators, we should test both with and without a materialized argument on the operator.",0,0.8491913676261902
478703452,9039,vvcephei,2020-08-27T21:22:51Z,"i'd normally say we should have a test also to verify we log properly on early records, but you already opened the pr to add early record handling, so we're good.",0,0.8666120767593384
478704359,9039,vvcephei,2020-08-27T21:24:45Z,awesome test. thanks!,1,0.9969099164009094
478705942,9039,vvcephei,2020-08-27T21:28:18Z,"aside from join, forgetting to test new operators in front of suppress has also been an issue. it's great to see this test here!",1,0.9949340224266052
478707997,9039,vvcephei,2020-08-27T21:32:52Z,"coming back to this after completing the review, i'd say the biggest advice i'd share is to avoid whitespace changes and cleanups on the side when the pr is so long already. in fact, for my own super-complex prs, i tend to go back over the whole diff and back out anything that's not critically important, just to lighten the load on the reviewers. cleanups are nice to have, but it's better to keep them in their own prs or in more trivial ones.",0,0.8861552476882935
478715664,9039,ableegoldman,2020-08-27T21:50:34Z,"no, the condition is correct. in this context ""early"" just means ""within timedifferencems of the zero timestamp"". we need some special handling to cover this full range of all record timestamps due to the inability to store negative timestamps. this algorithm works correctly for all records outside of this regardless of ""now""",0,0.989947497844696
478716769,9039,ableegoldman,2020-08-27T21:53:00Z,"to be honest, it might not be so bad to just leave things as is and drop early records, since any sensible timestamps are unlikely to be that close to the epoch. but i do believe users may want to use lower timestamps in their unit testing (`1598565116374` is not a very human readable number) and would be surprised to see these records just dropped.",0,0.7656683325767517
478717127,9039,ableegoldman,2020-08-27T21:53:52Z,"aha, so there was a good reason for it :grinning_face_with_smiling_eyes:",1,0.9908473491668701
478726427,9039,lct45,2020-08-27T22:17:40Z,is that possible? it's reassigned for every iteration of the `while()`,0,0.9943423271179199
478728829,9039,lct45,2020-08-27T22:24:19Z,"while the range might give a window that starts and ends before the current record's timestamp, the current record would fall into the right window of the records _within_ those windows. ex: timedifference = 10, record @ 30, range from (10,31). the earliest start time of a window we can have is 10, so the earliest `lefttypewindow` we can find is from [10,20]. if there's a record at 2, it's right window would be [21,31], which our record @ 30 would fall within. because this is true for the furthest possible record, it'll be true for the others that we find.",0,0.9882211089134216
478730796,9039,lct45,2020-08-27T22:29:46Z,"i don't think that would be true all the time, since the current record's right window wouldn't contain the current record and is created through this method. if it helps for clarity, i can add a check that if we're _not_ creating the right window then the timestamp needs to be within the window, and otherwise confirm that we're creating the right window",0,0.9863452315330505
478751787,9039,ableegoldman,2020-08-27T23:35:06Z,"i think he means, instead of declaring it once up here and then reassigning it every iteration, we can just do `final keyvalue<> next = iterator.next()` down on line 161. we don't need it outside the loop",0,0.9862724542617798
478753568,9039,lct45,2020-08-27T23:41:39Z,"aha, that makes sense",1,0.7424238324165344
478756346,9039,ableegoldman,2020-08-27T23:51:15Z,"now that you bring it up, that's kind of a weird case for this method, and it's currently handled in a pretty subtle way. for example down on line 233 we are effectively checking for this case, and line 234 just happens to work correctly for it. but it's not at all obvious that we're even handling this case. can we avoid the ternary operator when setting `newagg` and `newtimestamp` and just use a normal if/else to explicitly set both of these for the special case? (ie `if (windowstart == timestamp + 1)`...)",-1,0.6368175745010376
479344784,9039,vvcephei,2020-08-28T14:32:35Z,"thanks. from the other thread, it sounds like i misunderstood `putandforward` as adding the `value` to the `window`.",1,0.8560929298400879
479362665,9039,lct45,2020-08-28T15:01:33Z,"yeah it's definitely vague, i'll update",0,0.9750858545303345
480429410,9039,vvcephei,2020-08-31T22:16:28Z,thanks for the confirmation! i agree with your thinking.,1,0.992328941822052
1655160528,16456,apoorvmittal10,2024-06-26T16:15:11Z,is it possible to use `default_client_rack` already defined in configs?,0,0.9950835704803467
1655173636,16456,apoorvmittal10,2024-06-26T16:25:12Z,nit: [code block],0,0.9919844269752502
1655178863,16456,apoorvmittal10,2024-06-26T16:27:31Z,query: can you please help what issue actually occurs and why we need to update the cache i.e. how can the cache eviction be prevented with the cache update?,0,0.9931528568267822
1655181963,16456,apoorvmittal10,2024-06-26T16:28:54Z,query: is it always guranteed that a non-null share session will exist?,0,0.9932631850242615
1655189309,16456,apoorvmittal10,2024-06-26T16:31:53Z,nit: should we declare the helper methods post `handle` methods?,0,0.9915773868560791
1655198343,16456,apoorvmittal10,2024-06-26T16:35:14Z,nit: do we need this or can work with existing `randombytes`?,0,0.9857296943664551
1655203506,16456,apoorvmittal10,2024-06-26T16:37:46Z,where does this mocked version used later? if we don not define the setter of sharpartitionmanager then ll it make a difference?,0,0.9926676154136658
1656904716,16456,chirag-wadhwa5,2024-06-27T10:37:57Z,it should not make a difference. i removed the mock and passed optional.empty() in setsharepartitionmanager method. did the same in metadatarequestbenchmark.java as well,0,0.9917633533477783
1656905232,16456,chirag-wadhwa5,2024-06-27T10:38:27Z,"didn't realise the existence of randombytes. made the amends, thanks for the review",1,0.9525812864303589
1660544030,16456,chirag-wadhwa5,2024-07-01T06:40:32Z,"upon going through the code again, i guess with the new changes it doesn't make sense at all to update the cache here at all. with no asynchronous process happening between the 2 updates, the second update could be removed altogether. i have made the required changes in the most recent commit. thanks",1,0.924723207950592
1660544678,16456,chirag-wadhwa5,2024-07-01T06:41:12Z,removed this method in the latest commit. pls refer to the reply for above comment for further context. thanks !,1,0.9909551739692688
1662479127,16456,apoorvmittal10,2024-07-02T13:04:06Z,"time is already defined in the class, can we please re-use that: [code block]",0,0.9956715106964111
1662482911,16456,apoorvmittal10,2024-07-02T13:06:44Z,i don't see `option` suffix for other optionals in this class: [code block],0,0.9911752939224243
1662487187,16456,apoorvmittal10,2024-07-02T13:09:35Z,should we be relying on this config for `share groups`?,0,0.9926562905311584
1662490711,16456,apoorvmittal10,2024-07-02T13:11:53Z,"are we introducing this config to ak, i do not see the config in the kip `group.share.enable`. cc:",0,0.9950504899024963
1662494555,16456,apoorvmittal10,2024-07-02T13:14:08Z,can we move this line after checking whether `sharepartitionmanageroption` has a value?,0,0.9952234625816345
1662497106,16456,apoorvmittal10,2024-07-02T13:15:51Z,"do we need `()` or can work without them as like elsewhere, can we please be consistent. [code block]",0,0.9949522018432617
1662497519,16456,apoorvmittal10,2024-07-02T13:16:09Z,same as above and elsewhere.,0,0.9934410452842712
1662550023,16456,apoorvmittal10,2024-07-02T13:39:36Z,can we delay the fetch of this when actually it's required later?,0,0.9909374713897705
1662556294,16456,apoorvmittal10,2024-07-02T13:42:22Z,"it's odd to see that we need to expose `cachedtopicidpartitionsinsharesession` externally. we should not have the release api to have `list topicidpartitions`, only `string groupid, string memberid` should be sufficient. can we please change the `releaseacquiredrecords` api to below, and use `cachedtopicidpartitionsinsharesession` internally only? cc: [code block]",0,0.6628808975219727
1662566850,16456,apoorvmittal10,2024-07-02T13:47:01Z,"i hardly see much of `breakable` usage in entire `kafka` repository. how does the other part of code `breaks` in scala, any idea?",0,0.9581512212753296
1662638990,16456,apoorvmittal10,2024-07-02T14:26:48Z,any advise what's the best way to write such code in scala and kafka?,0,0.9904852509498596
1662644808,16456,apoorvmittal10,2024-07-02T14:29:43Z,"can we declare variables when needed. it's anyways tough to read scala code with `def` inside `def`, declaration of variables without order makes it harder.",0,0.9385966658592224
1662653794,16456,apoorvmittal10,2024-07-02T14:34:04Z,"i am not sure what does this case means i.e. is this check required? if yes, then what handling is done when `sharefetchresponse` is not returned by the method call i.e. how it further gets handled? shouldn't we complete the request and return right away?",0,0.8849702477455139
1662666354,16456,apoorvmittal10,2024-07-02T14:40:39Z,"why the validation of the request is done later prior initializing context and other processing, shouldn't that be the first step?",0,0.9850279092788696
1662673852,16456,apoorvmittal10,2024-07-02T14:44:40Z,query: why do we only authorize in subsequent request i.e. when acknowledge data is present?,0,0.9926361441612244
1662675191,16456,apoorvmittal10,2024-07-02T14:45:14Z,shouldn't this be an `async` call?,0,0.9919901490211487
1663148002,16456,apoorvmittal10,2024-07-02T20:43:48Z,can i get review on this please: [a link],0,0.993362545967102
1663964233,16456,chirag-wadhwa5,2024-07-03T10:26:58Z,"hi, thanks for the review. yes this check is required here, because `sharepartitionmanager.newcontext` might throw errors during its execution. initially, `sharefetchresponse` is defined as a null there. if an error is thrown, then its value is set as an error response. after this check, the acknowledging and fetching only proceeds if `sharefetchresponse` is null. if it is not null, then a final `sharefetchresponse` object is prepared with the error code and appropriate values for the acknowledgements and sent back to the user",1,0.9454554915428162
1663972187,16456,chirag-wadhwa5,2024-07-03T10:33:18Z,"hi, thanks for the review. according to my knowledge, this auth check is only required for acknowledgement and not for fetching. so, if there's nothing to acknowledge, there won't be any need for this auth check.",1,0.9522327780723572
1663976290,16456,chirag-wadhwa5,2024-07-03T10:36:55Z,"thanks for the review. `handleacknowledgements` would internally call `acknowledge` in `sharepartitionmanager`, which is an asyn function returning a future. according to the code that we already have in kip-932 branch, `handleacknowledgements` method returns the value by waiting for the future to execute completely. so, this piece is synchronous. we can maybe return a future from `handleacknowledgements` and wait for its completion here here, but i'm not sure how would that help us in any way.",1,0.9164495468139648
1664101522,16456,apoorvmittal10,2024-07-03T12:21:03Z,"are these intended changes, if yes then we shall have it in separate pr.",0,0.9951424598693848
1664119319,16456,chirag-wadhwa5,2024-07-03T12:34:51Z,"yes, the commit history got changed a bit. it should be fine now with the latest push in place",0,0.9910661578178406
1664122712,16456,apoorvmittal10,2024-07-03T12:37:31Z,is this method being used anywhere now?,0,0.9931544065475464
1664131801,16456,apoorvmittal10,2024-07-03T12:44:00Z,"my concern is on below code, should we complete the api call if `errorresponse` is constructed? ``` case e: exception => sharefetchresponse = sharefetchrequest.geterrorresponse(abstractresponse.default_throttle_time, e) match { case response: sharefetchresponse => response case _ => null",0,0.9929485321044922
1664144313,16456,chirag-wadhwa5,2024-07-03T12:53:07Z,"nope, already taken care of in the latest commit. thanks",1,0.9651474356651306
1664178535,16456,adixitconfluent,2024-07-03T13:17:19Z,"i agree with , seeing the `newcontext` function, the possible errors are `invalid_request`, `share_session_not_found` and `invalid_share_session_epoch`. in all such cases, we should be completing the api call with a top level error code there itself.",0,0.988815426826477
1664193628,16456,adixitconfluent,2024-07-03T13:27:03Z,we can remove this check if we return the api response with top level error code wherever it occurs. wdyt -wadhwa5 ?,0,0.9942135214805603
1664202015,16456,adixitconfluent,2024-07-03T13:32:33Z,"comment should say ""share"" instead of ""regular""",0,0.9912185072898865
1664266986,16456,adixitconfluent,2024-07-03T14:14:03Z,"can we not club all of this ""if"" and the below ""if"" conditions into a single if?",0,0.9860979318618774
1664271714,16456,adixitconfluent,2024-07-03T14:17:13Z,not sure if these dummy values are the ones we want to go ahead. perhaps / would know better which values to use here?,0,0.7107529044151306
1664273428,16456,adixitconfluent,2024-07-03T14:18:21Z,"nit: instead of partitions.size, maybe use partitions size",0,0.9908548593521118
1664275271,16456,adixitconfluent,2024-07-03T14:19:23Z,"nit: add a ""."" at the end of comment. can you do this for other added comments as well?",0,0.995081901550293
1665550477,16456,AndrewJSchofield,2024-07-04T11:08:41Z,"i think so, at least for now. the eventual switch will be `group.version=2` as the second version of the new group coordinator feature. unfortunately, `group.version` has been backed out and will not be re-introduced until 4.0. this is an internal (undocumented) config for the broker. it does the necessary thing, which is to enable the new gc, so it seems like a safe temporary answer here.",0,0.9267680644989014
1665552665,16456,AndrewJSchofield,2024-07-04T11:10:49Z,"it's an internal (undocumented) configuration. as mentioned above, the configuration we are using is temporary for now. i'm happy with it being used until we get the real configs in place.",1,0.8731277585029602
1665590294,16456,chirag-wadhwa5,2024-07-04T11:45:24Z,"that makes sense. thanks for the review, will make the changes in the next commit",1,0.9536250829696655
1665592992,16456,chirag-wadhwa5,2024-07-04T11:47:48Z,"thanks for the review ! yes we can but i did that for better readability, without affecting the execution at all.",1,0.984872579574585
1665594694,16456,chirag-wadhwa5,2024-07-04T11:49:18Z,"yes, i wanted to have a discussion regarding these dummy values with as well",0,0.9862099289894104
1665597002,16456,chirag-wadhwa5,2024-07-04T11:51:28Z,thanks for the review. i think i copied this comment from the regular fetch request implementation. but yeah its very trivial. i will make the change in the next commit.,1,0.9708922505378723
1665633847,16456,apoorvmittal10,2024-07-04T12:22:03Z,"i find following line from the kip which says following, hence shouldn't we authorize for read on fetch as well? ``` operations which change information about a share group (such as consuming a record) need permission to perform the read action on the named group resource",0,0.9939497709274292
1665637301,16456,apoorvmittal10,2024-07-04T12:25:03Z,"also, do we need to re-authorize on every request in session? what behaviour we have on regular fetch? does it authorize everytime or once in session? if we do it only at session establishment, i do get that if an api key is unauthorized then existing session might continue reading/acknowledging, but re-authorization is taxing as well. hence checking what's the flow looks like on regular fetch. cc:",0,0.9856277704238892
1665642977,16456,apoorvmittal10,2024-07-04T12:29:40Z,"hmmm, this is not clean. why can't we have `handleacknowledgements` api to receive `mutable.map[topicidpartition, util.list[shareacknowledgementbatch]]`? then `sharefetch` and `shareacknowledgerequest` can send respective data to `handleacknowledgements` method and we need not to use `asinstanceof` or any type casting.",0,0.9462215304374695
1665645855,16456,apoorvmittal10,2024-07-04T12:32:05Z,isn't the `sharepartitionmanager.acknowledge` already implemented?,0,0.9948207139968872
1665661239,16456,apoorvmittal10,2024-07-04T12:44:44Z,"i do not see any futures handled here hence this maked the processing synchronous, irrespective if other api calls to sharepartitionmanager are async. moreover i am failed to understand the behaviour of `handleacknowledgements` method i.e. i do see `shareacknowledgeresult` is returned right away but there might be a delay in getting reposne from `sharepartitionmanager.acknowledge` method hence how that's handled?",0,0.9884328246116638
1665668978,16456,apoorvmittal10,2024-07-04T12:51:03Z,"should we throw an exception here of complete the request by unsupported version error? what's followed in other apis? for kip-714, i added something below: ``` case none => info(""received get telemetry client request for zookeeper based cluster"") requesthelper.sendmaybethrottle(request, subscriptionrequest.geterrorresponse(errors.unsupported_version.exception))",0,0.9952653646469116
1665672326,16456,apoorvmittal10,2024-07-04T12:53:41Z,i see this is a copy from `fetch` but do we need to define same functionality again or create a common `def/method` for both?,0,0.9936571717262268
1665676287,16456,apoorvmittal10,2024-07-04T12:56:43Z,shouldn't this be like below? [code block],0,0.9949117302894592
1665689981,16456,apoorvmittal10,2024-07-04T13:07:43Z,"do you need `asjava` conversion just ofr iteration? if yes, then aren't there better way in scala? [code block]",0,0.9950886368751526
1665702943,16456,apoorvmittal10,2024-07-04T13:18:08Z,"isn't the response is already returned and this is async call, what does `requesthelper.handleerror(request, throwable)` does then?",0,0.9927412271499634
1665708594,16456,apoorvmittal10,2024-07-04T13:22:52Z,"hmm the whole processing is `synchronous`, why can't we work with callbacks i.e. when complete?",0,0.983040988445282
1665714440,16456,apoorvmittal10,2024-07-04T13:27:37Z,can you please write comment regaridng what exaclty is happening and why we are going to modify the `sharefetchresponse` later? i am not sure if there is a better way of combinig 2 responses and construct `sharefetchresponse` just once rather first generating it in fetch and then modifying same.,0,0.9891820549964905
1665777016,16456,chirag-wadhwa5,2024-07-04T14:18:10Z,"as per my knowledge the regular fetch does not authorize for read operation on the named group. only the topics from where data is to fetched, are authorized for read operation",0,0.9921854138374329
1665987792,16456,apoorvmittal10,2024-07-04T18:19:48Z,should it be in `error`?,0,0.9904493689537048
1665988915,16456,apoorvmittal10,2024-07-04T18:22:26Z,should it be `private def`?,0,0.9928398132324219
1665990669,16456,apoorvmittal10,2024-07-04T18:26:06Z,"i am not sure how costly the api for `asscala` on map is, but should have some cost, so do you want to have conversion in foreack loop?",0,0.9708415865898132
1665993309,16456,apoorvmittal10,2024-07-04T18:31:49Z,"does `topicidnames` seems better? it was hard to relate later in the code what this variable holds, seems more like just name of topics.",0,0.8766703605651855
1665994321,16456,apoorvmittal10,2024-07-04T18:33:51Z,do we validate somewhere that partition index exists for the topic i.e. what if client request for partition 5 when there exists only 4 partitions for topic?,0,0.9941887855529785
1665995004,16456,apoorvmittal10,2024-07-04T18:35:15Z,what exception is being thrown?,0,0.9882163405418396
1665995891,16456,apoorvmittal10,2024-07-04T18:37:21Z,"yeah it's much readable this way, i agree.",0,0.6356298327445984
1665996271,16456,apoorvmittal10,2024-07-04T18:38:21Z,will it not be better to mock `sharepartitionmanager`?,0,0.9626049995422363
1665997840,16456,apoorvmittal10,2024-07-04T18:41:18Z,"this change will be not needed if we use mock, that we should.",0,0.9931932091712952
1665998426,16456,apoorvmittal10,2024-07-04T18:42:41Z,nit: would it better to have these methods defines later when used in tests?,0,0.9869642853736877
1666000193,16456,apoorvmittal10,2024-07-04T18:46:23Z,"seems the methods are same as defined in `sharepartitiontest`, shall we move them to common test utils (in java)?",0,0.9931368827819824
1666000611,16456,apoorvmittal10,2024-07-04T18:47:18Z,"i see we are using mock here, why not to define it on the top itself?",0,0.9902046918869019
1666001021,16456,apoorvmittal10,2024-07-04T18:48:11Z,is `asjava` required? isn't it already a java api?,0,0.9948220252990723
1666723067,16456,chirag-wadhwa5,2024-07-05T12:00:46Z,i think it should be just return. `completablefuture.completedfuture[unit](())` shouldn't be there at all because return type of `handlesharefetchrequest` is `unit` and not `completablefuture[unit]`,0,0.9830297827720642
1666735395,16456,chirag-wadhwa5,2024-07-05T12:14:10Z,"yep, this doesn't make sense. if there is an error here, the broker will send out 2 responses for that. i have changed this to the following logic - 1) if throwable is not null, it will simply throw the throwable. 2) i have surrounded the call of `combinesharefetchandshareacknowledgeresponses` with a try catch. if error is not thrown then `requestchannel.sendresponse` with appropriate arguments. if error is thrown, then `requesthelper.handleerror(request, throwable)` with appropriate arguments. also change the log from debug to error here.",0,0.9542186856269836
1668159303,16456,chirag-wadhwa5,2024-07-08T07:55:34Z,"this was a mistake, will remove the try catch block. thanks!",1,0.9887552261352539
1668342690,16456,chirag-wadhwa5,2024-07-08T09:55:53Z,"thanks for the review. actually yes it is required, since the list() is a scala list. there are other ways that do not use asjava, but they span over multiple lines, and would require new variable initialisations, reducing the code readability.",1,0.9528079628944397
1669768302,16456,chirag-wadhwa5,2024-07-09T05:47:45Z,hi thanks for reviewing. i think the first occurrence of these methods is in the test just underneath them. isn't that what you mean here ?,1,0.9528050422668457
1669815168,16456,chirag-wadhwa5,2024-07-09T06:31:01Z,"yep, the true place for these methods should be in testutils file, but both sharepartitiontest and kafkaapistest import separate testutils files. sharepartitiontest use the java one and kafkaapistest use the scala one. as far as i know, java does not support aliasing and neither do the older versions of scala.",0,0.9923205971717834
1669817534,16456,chirag-wadhwa5,2024-07-09T06:33:40Z,not currently. i think that can be done using the metadatacache which is accessible in the kafkaapis. i will create a separate jira for this. thanks !,1,0.9856989979743958
1672098926,16456,apoorvmittal10,2024-07-10T11:24:59Z,i raised a query earlier regaridng why we only want to authorize when acknowledgements exist?,0,0.993198573589325
1672102704,16456,apoorvmittal10,2024-07-10T11:28:08Z,why do we require `.get` here? will it not block the calls?,0,0.9911375045776367
1672103745,16456,apoorvmittal10,2024-07-10T11:28:57Z,why this exception is only about `release`?,0,0.9877312779426575
1672106900,16456,apoorvmittal10,2024-07-10T11:31:48Z,i can find this comment is yet not addressed. i think we discussed that the code shall be asynchronous. in case we are finding it difficult in this pr then please log a jira and work on it post merge of this pr.,0,0.9920021295547485
1672107334,16456,apoorvmittal10,2024-07-10T11:32:14Z,again we have a blocking call here.,0,0.9423701763153076
1672108309,16456,apoorvmittal10,2024-07-10T11:33:07Z,-wadhwa5 did you get a chance to work on this?,0,0.9857127666473389
1672109076,16456,apoorvmittal10,2024-07-10T11:33:49Z,why do we need `breakable` here?,0,0.9743322730064392
1672111524,16456,apoorvmittal10,2024-07-10T11:36:00Z,it's not that important but generally the helper method will come post the usage i.e. test -> helper method.,0,0.9887990355491638
1672112684,16456,apoorvmittal10,2024-07-10T11:37:11Z,so why not to have either in java or scala test utils which can be used by both?,0,0.9898592829704285
1672113400,16456,apoorvmittal10,2024-07-10T11:37:47Z,do we have the jira now? can we please link here?,0,0.9959273934364319
1672117974,16456,apoorvmittal10,2024-07-10T11:41:46Z,yeah but kip-932 defines the behaviour for auth during fetch.,0,0.9892473816871643
1675361989,16456,chirag-wadhwa5,2024-07-12T06:05:25Z,"i think this log is not in the right place. the only thing that throws an exception in the try block is the releasing the acquired records part, moved this log to that position.",0,0.9738913178443909
1675585257,16456,chirag-wadhwa5,2024-07-12T09:30:47Z,created a separate jira to track this - [a link],0,0.9958447813987732
1675597142,16456,chirag-wadhwa5,2024-07-12T09:40:35Z,"hey yep, the jira has been created - [a link]",0,0.9895977973937988
1675597743,16456,chirag-wadhwa5,2024-07-12T09:41:04Z,created a jira - [a link],0,0.9958974123001099
1690482997,16456,junrao,2024-07-24T21:37:14Z,fetchoncomplete => onfetchcomplete?,0,0.9912462830543518
1690501820,16456,junrao,2024-07-24T21:54:18Z,"for consistency, could we remove `this`?",0,0.9925181865692139
1690504262,16456,junrao,2024-07-24T21:56:13Z,this only happens in zk mode. we probably want to improve logging to reflect that.,0,0.9890361428260803
1690509290,16456,junrao,2024-07-24T22:00:30Z,we could get rid of {}.,0,0.9910484552383423
1690510398,16456,junrao,2024-07-24T22:01:36Z,we could get rid of {}. ditto in a few other places.,0,0.9929928779602051
1690517906,16456,junrao,2024-07-24T22:08:19Z,"instead of foreach, perhaps you could do `sharefetchrequest.data.topics.stream().anymatch` ?",0,0.9944568872451782
1690528671,16456,junrao,2024-07-24T22:24:41Z,the convention is to have no space before `:`. ditto in a few other places below.,0,0.9925254583358765
1690529065,16456,junrao,2024-07-24T22:25:21Z,space after `if`. ditto in a few other places below.,0,0.9853011965751648
1690566819,16456,junrao,2024-07-24T23:13:41Z,"hmm, should we get the partitions for fetch from sharefetchcontext instead from the request? the request may not include all partitions in the session since it can be incremental.",0,0.9838738441467285
1690594851,16456,junrao,2024-07-24T23:46:04Z,could this be private?,0,0.9816126227378845
1690595889,16456,junrao,2024-07-24T23:47:38Z,this comment seems out of place.,-1,0.6714578866958618
1690596169,16456,junrao,2024-07-24T23:48:07Z,datas is weird since data is already the plural form of datum.,-1,0.9898290038108826
1690599349,16456,junrao,2024-07-24T23:53:51Z,interestingwithmaxbytes => interestedwithmaxbytes ?,0,0.7886695265769958
1690612220,16456,junrao,2024-07-25T00:14:57Z,could this block of code be replaced with sth like the following using lamda? [code block],0,0.995230495929718
1691763015,16456,junrao,2024-07-25T16:17:40Z,sharefetch is implemented on the latest version of the client and understands all versions of the message format. why do we need to down convert here?,0,0.9939526915550232
1691773793,16456,junrao,2024-07-25T16:25:50Z,should we use consumer_replica_id?,0,0.99443119764328
1691814103,16456,junrao,2024-07-25T16:45:35Z,"could this code just be `requesthelper.throttle(quotas.fetch, request, maxthrottletimems)`?",0,0.9933358430862427
1691823423,16456,junrao,2024-07-25T16:53:11Z,"if the response is not ready immediately, `combinesharefetchandshareacknowledgeresponses()` needs to be called asynchronously, right?",0,0.9905439019203186
1691825148,16456,junrao,2024-07-25T16:54:42Z,we could get rid of {} here.,0,0.9937857389450073
1691839730,16456,junrao,2024-07-25T17:06:48Z,we are doing this check for fetching already. do we need to do this again?,0,0.9943341016769409
1691841163,16456,junrao,2024-07-25T17:08:02Z,combine with the previous line?,0,0.9942165613174438
1691841383,16456,junrao,2024-07-25T17:08:12Z,topicidnames and clientid seem unused?,0,0.9882436990737915
1691842743,16456,junrao,2024-07-25T17:09:17Z,we can get rid of {}.,0,0.9925583600997925
1693588726,16456,junrao,2024-07-26T20:42:20Z,merge with previous line?,0,0.992335855960846
1693601483,16456,junrao,2024-07-26T20:59:28Z,merge with previous line?,0,0.992335855960846
1693602221,16456,junrao,2024-07-26T21:00:34Z,space after `if`,0,0.9910434484481812
1693628707,16456,junrao,2024-07-26T21:41:26Z,this is an existing issue. why do we need to pass in both interestingtopicpartitions and interestingwithmaxbytes? they have the same keyset. could we just pass in interestingwithmaxbytes?,0,0.9902578592300415
1693631675,16456,junrao,2024-07-26T21:45:46Z,"hmm, i am not sure that i understand the logic here. the partition set for topicpartitionacknowledgements is a subset of that for sharefetchresponse, right? if so, there is no remaining acknowledgements.",0,0.7827229499816895
1695140156,16456,apoorvmittal10,2024-07-29T12:37:56Z,yeah as per suggestion here: [a link] if we have it consistent across other logs then it would be good: [code block],0,0.9487727880477905
1695145736,16456,apoorvmittal10,2024-07-29T12:42:08Z,is `()` required or we can just write `if(tp.partition == partition) {`,0,0.9956178665161133
1695595126,16456,junrao,2024-07-29T17:23:53Z,`thenapply` => `.thenapply` ?,0,0.9940213561058044
1695660706,16456,junrao,2024-07-29T18:09:47Z,"`isinvalidsharefetchrequest()` checks `ispartitionpresent`. if there is a partition level error, we should send a errors.unknown_topic_or_partition at the partition level, instead of errors.invalid_request at the request level.",0,0.9933552742004395
1695831694,16456,junrao,2024-07-29T20:30:49Z,why do we need `partitiondatas`? could we just iterate `erroneousandvalidpartitiondata.validtopicidpartitions` directly?,0,0.9927881360054016
1695851702,16456,junrao,2024-07-29T20:37:31Z,this can a bit simpler like the following. [code block],0,0.993527352809906
1695877000,16456,junrao,2024-07-29T20:44:46Z,the convention is to combine with the previous line.,0,0.9930998086929321
1695885553,16456,junrao,2024-07-29T20:47:08Z,could this be private?,0,0.9816126227378845
1695923179,16456,junrao,2024-07-29T20:57:29Z,it seems cleaner if we just create `erroneous` inside `handleacknowledgements()`?,0,0.9895451664924622
1695953996,16456,junrao,2024-07-29T21:05:50Z,indentation,0,0.9911677837371826
1695961725,16456,junrao,2024-07-29T21:08:14Z,why does this return a mutable map? ditto for `handleacknowledgements()`.,0,0.9920199513435364
1695973614,16456,junrao,2024-07-29T21:15:32Z,why do we need to copy the entries to `partitions`? we could just keep using `responsepartitiondata`?,0,0.9926239252090454
1696012525,16456,junrao,2024-07-29T21:59:12Z,could this be private?,0,0.9816126227378845
1696053083,16456,junrao,2024-07-29T22:51:55Z,there is some validation inside `sharepartitionmanager.newcontext`. should we just fold this logic there?,0,0.9943933486938477
1696057694,16456,junrao,2024-07-29T22:59:49Z,why is this request invalid?,0,0.939517080783844
1696066333,16456,junrao,2024-07-29T23:14:22Z,this seems unnecessary since we already tested that the array is empty above.,0,0.9383543133735657
1696077755,16456,junrao,2024-07-29T23:20:21Z,should we set records to `memoryrecords.empty`?,0,0.9947792291641235
1696078584,16456,junrao,2024-07-29T23:21:26Z,merge into previous line?,0,0.9923793077468872
1696079560,16456,junrao,2024-07-29T23:22:33Z,this is not the first request.,0,0.9867945313453674
1696081720,16456,junrao,2024-07-29T23:24:45Z,"is this test useful? in both cases, we mock `sharepartitionmanager.newcontext` to return errors.share_session_not_found regardless whether there is a wrong member id or group id. should we mock `sharepartitionmanager.newcontext` to return a sharesessioncontext with the wrong group/member id?",0,0.9933357238769531
1696083957,16456,junrao,2024-07-29T23:27:07Z,"merge into previous line? also, should we mock sharepartitionmanager.newcontext to return a sharesessioncontext with the wrong epoch instead of directly throwing an exception?",0,0.9860271215438843
1696094681,16456,junrao,2024-07-29T23:35:48Z,"hmm, the expected epoch should be 2 for the last call, right?",0,0.9786702990531921
1696108097,16456,junrao,2024-07-30T00:00:53Z,this is not the first fetch request.,0,0.9887887835502625
1696112503,16456,junrao,2024-07-30T00:09:07Z,`sharefetchdata` seems unused?,0,0.9930095672607422
1696113299,16456,junrao,2024-07-30T00:10:46Z,sharefetchdata seems unused?,0,0.9873573780059814
1696113985,16456,junrao,2024-07-30T00:12:00Z,quite a long name. could it be sth like `testhandlesharefetchfetchmessagesreturnerrorcode`?,0,0.9007765650749207
1696114858,16456,junrao,2024-07-30T00:13:37Z,sharefetchdata seems unused?,0,0.9873573780059814
1696116555,16456,junrao,2024-07-30T00:17:09Z,merge with previous line?,0,0.992335855960846
1696116942,16456,junrao,2024-07-30T00:17:53Z,could this be private?,0,0.9816126227378845
1696116973,16456,junrao,2024-07-30T00:17:58Z,could this be private?,0,0.9816126227378845
1696118317,16456,junrao,2024-07-30T00:20:55Z,"i understand the logic better now. so, this is fine.",1,0.5723678469657898
1696118888,16456,junrao,2024-07-30T00:22:11Z,i understand the code better now. this is fine.,1,0.882297933101654
1696517878,16456,chirag-wadhwa5,2024-07-30T08:07:31Z,"thanks a lot for the review. i actually had some unit tests in place for this method, that is why left it as public. should i add a comment saying `//visible for testing` ?",1,0.9841672778129578
1696558877,16456,chirag-wadhwa5,2024-07-30T08:33:53Z,"hi, thanks a lot for the review. i guess this comment refers to the code before the last commit. i believe all the issues with asynchronous code have been resolved with that. let me know if you find any other gaps. thanks !",1,0.9964274764060974
1696677665,16456,chirag-wadhwa5,2024-07-30T09:50:14Z,"thanks for the review ! with the new code in place, i believe this problem has also been resolved.",1,0.9830893278121948
1697309981,16456,chirag-wadhwa5,2024-07-30T17:10:39Z,"thanks for the review. actually the code does not down convert anything, its just the variable names and the comments that suggest that. made the required changes",1,0.9622614979743958
1697405173,16456,chirag-wadhwa5,2024-07-30T18:33:05Z,"thanks for the review. you are correct here. but the code actually has that check already, i think this is not needed at all. i will remove this in the next commit",1,0.9784956574440002
1697422741,16456,chirag-wadhwa5,2024-07-30T18:48:42Z,"thanks for the review. actually, the upcoming pr for shareacknowledgerequest would make it clear why it has been one this way. the acknowledgement data sent to `handleacknowledgements` is retrieved using different methods in case of a fetch request and an acknowledge request. these methods can themselves identify some erroneous topic partitions, so that is why the map is being passed on to the method",1,0.8789801001548767
1697447600,16456,chirag-wadhwa5,2024-07-30T19:07:17Z,"thanks for the review. given that a single fetch from a partition can sometimes contain significant amount of data, copying the entire map again whenever a new element is added could be a little extensive. but i don't think this choice of using a mutable.map or simply a map would make a huge difference. do you have any better suggestions though ?",1,0.9692586660385132
1697502447,16456,chirag-wadhwa5,2024-07-30T19:53:44Z,"thanks for the review. yes we could use the same, but the definition of some methods of sharefetchcontext require a util.linkedhashmap, so we would anyways require a new variable to store the converted map as it is required as an argument to multiple methods. talking about why do we need a util.linkedhashmap altogether, maybe we could change those method signatures to use a scala map as well, but i think that would out of scope for this pr as it would include making changes to others code as well.",1,0.9409230947494507
1697672536,16456,junrao,2024-07-30T22:29:09Z,"it seems that we never add/remove elements in the returned mutable.map? if the map doesn't need to be mutated, returning just map reduces potential side effect.",0,0.9891636371612549
1697988104,16456,chirag-wadhwa5,2024-07-31T06:48:01Z,"thanks for the review. the logic dictates, that a final share fetch request should only be sent for acknowledging previously fetched records, and not for fetching new records (the new records wouldn't be acknowledged since this is the final request). so, if the the partition max bytes field is non zero for any share partition in the request, that mens the client expects records as a result, which should not be the case, since it is a final fetch request. hence this is an invalid request. i know it is very trivial, but in the long run, the final epoch would be sent via a shareacknowledge request and not a sharefetch request, thereby resolving this altogether",1,0.9506649971008301
1698763204,16456,junrao,2024-07-31T16:03:31Z,thanks for the explanation. make sense. could we add a comment about this?,1,0.9778364896774292
1699474736,16456,chirag-wadhwa5,2024-08-01T06:05:14Z,"thanks for the review. i'm sorry but i don't understand how returning a sharesessioncontext with the wrong group/member id will help. the entire logic to handle the groupid/memberid is in newcontext and if a wrong groupid/memberid is provided in the request, an newcontext throws an error, which is what this test tries to mimic. pls let me know if my understanding is wrong anywhere, thanks !",1,0.9835467338562012
1699483505,16456,chirag-wadhwa5,2024-08-01T06:09:02Z,"thanks for the review. again, i'm sorry but i don't see how that is going to help. the expected behaviour is that the newcontext method should throw an exception in case of wrong epoch. if it successfully returns a sharesessioncontext, then the fetching would proceed without any issues, because that does not care about epochs at all. i have tried to simulate the expected behaviour in the test. pls let me know if my understanding is wrong anywhere, thanks !",1,0.9832490682601929
1699487912,16456,chirag-wadhwa5,2024-08-01T06:10:20Z,"thanks for the review. yes, you are right. actually, the sharefetchmetadata would include the current epoch in the request, but the sharesession would contain the next epoch, as the epoch is bumped in the newcontext method. i have made the change here, as well as in the other functions. thanks again for pointing it out !",1,0.994861900806427
1699568098,16456,chirag-wadhwa5,2024-08-01T07:22:47Z,"thanks for the review. i already changed this piece of code in the last commit, it does not use any breakable now.",1,0.9717824459075928
1699569869,16456,chirag-wadhwa5,2024-08-01T07:24:21Z,thanks for the review. i think there is a difference between both the if and else cases. i actually used the code from the normal fetch request and the throttling logic is the same as it is there.,1,0.9492402672767639
1699572051,16456,chirag-wadhwa5,2024-08-01T07:26:11Z,"thanks for the review. i think this comment was addressing an issue in the previous version of the pr. i pushed a commit later, which i believe resolved all issues related to asynchronous code. if you find any other gaps, pls let me know. thanks !",1,0.9949939846992493
1700521738,16456,junrao,2024-08-01T17:01:25Z,move the statement to a separate line since this case has multiple statements.,0,0.9919127225875854
1700530866,16456,junrao,2024-08-01T17:09:57Z,could we make `fetchresult` a val by calling `handlefetchfromsharefetchrequest` here?,0,0.9947124719619751
1700533859,16456,junrao,2024-08-01T17:11:42Z,merge into previous line,0,0.9895362854003906
1700558567,16456,junrao,2024-08-01T17:32:45Z,is the todo still needed?,0,0.9922071099281311
1700562536,16456,junrao,2024-08-01T17:35:39Z,this can be a bit simpler like [code block],0,0.9924721717834473
1700566242,16456,junrao,2024-08-01T17:39:01Z,no space before (,0,0.99143385887146
1700574089,16456,junrao,2024-08-01T17:46:10Z,interesting => interested ?,1,0.8694580793380737
1700580952,16456,junrao,2024-08-01T17:50:48Z,shareacknowledgeresult seems unused?,0,0.9934873580932617
1700583206,16456,junrao,2024-08-01T17:52:10Z,this can be a bit simpler like [code block],0,0.9924721717834473
1700589809,16456,junrao,2024-08-01T17:55:30Z,merge into previous line,0,0.9895362854003906
1700595263,16456,junrao,2024-08-01T18:00:08Z,"there is no conversion, right? so `converted` is inaccurate.",0,0.976069986820221
1700596185,16456,junrao,2024-08-01T18:01:01Z,add an extra new line below.,0,0.9944726824760437
1700596862,16456,junrao,2024-08-01T18:01:27Z,there is no down conversion.,0,0.9808198809623718
1700603141,16456,junrao,2024-08-01T18:06:24Z,"throttling is done inside this method. so, `invoked before throttling` is inaccurate.",0,0.9909791946411133
1700604916,16456,junrao,2024-08-01T18:08:13Z,could this be private?,0,0.9816126227378845
1700605031,16456,junrao,2024-08-01T18:08:20Z,indentation,0,0.9911677837371826
1700609451,16456,junrao,2024-08-01T18:12:26Z,this can be a bit simpler like [code block],0,0.9924721717834473
1700619173,16456,junrao,2024-08-01T18:17:45Z,could this be private?,0,0.9816126227378845
1700620774,16456,junrao,2024-08-01T18:19:16Z,could we add the new param to javadoc?,0,0.995192289352417
1700655193,16456,junrao,2024-08-01T18:42:27Z,we could use a mutable map locally for better efficiency and return it as `map`.,0,0.9922263622283936
1700657160,16456,junrao,2024-08-01T18:43:49Z,we could use a mutable map locally for better efficiency and return it as `map`.,0,0.9922263622283936
1700662501,16456,junrao,2024-08-01T18:48:30Z,"i mean that since we mock `sharepartitionmanager.newcontext` to return errors.share_session_not_found, we are not really testing whether `sharepartitionmanager.newcontext` could handle incorrect group/member id properly. we are just testing if the caller can behave properly when `sharepartitionmanager.newcontext` returns an error. so, testing just one of incorrect group/member id seems enough.",0,0.9836007952690125
1700679813,16456,junrao,2024-08-01T18:59:08Z,"why is isacknowledgedatapresent true? there is no acknowledgement, right? ditto in a few other cases below.",0,0.987885594367981
1701337300,16456,chirag-wadhwa5,2024-08-02T06:19:08Z,"understood, thanks a lot",1,0.9589391350746155
1701341077,16456,chirag-wadhwa5,2024-08-02T06:23:02Z,it's not. i have removed it. thanks !,1,0.9901198148727417
1701409939,16456,chirag-wadhwa5,2024-08-02T07:22:33Z,"thanks for the review ! during the invocation of `sharepartitionmanager.newcontext` we don't pass any acknowledgements, so there's no way to know whether acknowledgements are present or not, only the variable `isacknowledgedatapresent` provides that information. my understanding says that in the general case, only the first fetch request (with request epoch 0) will not contain any acknowledgements, but all the subsequent requests would. going by that logic, i have set this variable to false in case request epoch is 0, and true in all the other cases.",1,0.9534649848937988
1702138634,16456,junrao,2024-08-02T17:37:00Z,this should be [code block],0,0.9952785968780518
1702139817,16456,junrao,2024-08-02T17:38:28Z,indentation,0,0.9911677837371826
1702140987,16456,junrao,2024-08-02T17:39:53Z,merge with previous line?,0,0.992335855960846
1702141861,16456,junrao,2024-08-02T17:40:47Z,extra new line,0,0.9933451414108276
1702159875,16456,junrao,2024-08-02T17:59:37Z,"`sharefetchmetadata(uuid.zero_uuid, -1)` could just be `newreqmetadata`?",0,0.9931192398071289
1702169187,16456,junrao,2024-08-02T18:09:59Z,this is fine. we can leave it as it is.,0,0.7543355822563171
1704485591,16456,junrao,2024-08-05T18:24:21Z,this is unnecessary since `sharepartitionmanager.close()` already calls `persister.stop()`.,0,0.9941447377204895
1704494394,16456,chirag-wadhwa5,2024-08-05T18:33:45Z,"ohh yes, you are right, missed it. thanks. i have pushed the change",1,0.9873995780944824
1325138384,14364,philipnee,2023-09-13T22:32:26Z,just to create a coherent format,0,0.9882027506828308
1325368170,14364,philipnee,2023-09-14T05:21:01Z,we should submit a patch to combine groupstate into memberstate.,0,0.9951367974281311
1325381139,14364,philipnee,2023-09-14T05:41:03Z,"it might be helpful to read the test: `public void testheartbeatresponse_errorhandling(final errors error, final boolean isfatal)`",0,0.9922682642936707
1325382420,14364,philipnee,2023-09-14T05:43:03Z,i wonder if this can be moved to the memberstatemanager.,0,0.9787889719009399
1325383326,14364,philipnee,2023-09-14T05:44:36Z,current i'm unable to reference the assignor config in memberstatemanager because it is always null.,0,0.9781299829483032
1325999433,14364,lianetm,2023-09-14T13:59:12Z,"totally, but is there a reason why we couldn't just use the `membershipmanager` here already? i though that was the point of unblocking the state pr that includes all that's needed here.",0,0.9912870526313782
1326031428,14364,lianetm,2023-09-14T14:21:24Z,makes sense. let's move it on this same pr i would suggest,0,0.9823197722434998
1326089090,14364,lianetm,2023-09-14T14:56:57Z,"it's null here simply because it wasn't defined when creating the `membershipmanager` in the defaultbackgroundthread. my understanding is: - if the client specifies an assignor (client or server), we should make sure to set it in the `membershipmanager` when creating it in the defaultbackgroundthread [a link]. this will ensure that it is available here to send it on the heartbeatrequest. - if the client did not specified any assignor, then it will be ok to have null here, and we don't need to include anything for it in the heartbeatrequest. we let the group coordinator on the server select the default assignor for the member from the `group.consumer.assignors` config. correct me here if i'm missing something.",0,0.9842110276222229
1326105802,14364,dajac,2023-09-14T15:08:30Z,"that's right. the (server) assignor should be null be default as defined in the [a link]. when null, the server uses the first one in the list on the server side.",0,0.9944211840629578
1326205537,14364,philipnee,2023-09-14T16:14:48Z,thanks for the clarification.,1,0.5338528752326965
1326228037,14364,philipnee,2023-09-14T16:28:49Z,actually - my bad: i think we can just get rid of the groupstate.,-1,0.992456316947937
1326232358,14364,philipnee,2023-09-14T16:31:52Z,"there's a bit of refactoring needed, to keep things in scope for this pr - i will be submitting another pr to address this.",0,0.9836992025375366
1326463429,14364,lianetm,2023-09-14T20:09:54Z,"the subscription state already has it, and it is a component that is all over, so i would try to keep the regex in that single place",0,0.9898415207862854
1326478655,14364,lianetm,2023-09-14T20:24:07Z,"just for the record, that regex that we keep in the client (now on the subscriptionstate), will need to be updated to move away from the java `pattern` and use the new `subscriptionpattern` defined in the protocol i expect.",0,0.9938143491744995
1327513916,14364,philipnee,2023-09-15T16:09:28Z,"sounds good thanks! fwiw, a bit out of the scope here: we discussed the plan to split subscriptionstate to remove (some of) the synchronization locks. as users don't need to access the regex pattern directly (aside from submitting one), it might just live in the background thread once this refactor happens.",1,0.9946762323379517
1329227271,14364,lianetm,2023-09-18T20:14:47Z,this is not using the state from params so i expect the `else` part will never be executed (member should be always in the default unjoined). is it missing mocking the state value using the param i guess?,0,0.9934506416320801
1329251065,14364,philipnee,2023-09-18T20:34:22Z,you are right! i will rewrite this test just mocking the notingroup response.,1,0.9566861987113953
1329477649,14364,philipnee,2023-09-19T02:12:01Z,"i wonder if we could just call this ""shouldheartbeat"" as the server side protocol is tight to the heartbeat",0,0.948183536529541
1330246922,14364,lianetm,2023-09-19T14:38:43Z,"sure, sounds good to me",0,0.5305511355400085
1330274787,14364,dajac,2023-09-19T14:57:39Z,nit: i think that we usually use `()` instead of `{}` in to strings.,0,0.9812739491462708
1330275873,14364,dajac,2023-09-19T14:58:23Z,"should we add javadoc to attributes, classes and methods? i think that we usually do it for all the new java code these days.",0,0.9917173981666565
1330276646,14364,dajac,2023-09-19T14:58:52Z,this is incorrect. the heartbeat interval comes is provided in the response.,0,0.9796522259712219
1330277639,14364,dajac,2023-09-19T14:59:37Z,nit: let's add javadoc to be consistent with the other methods.,0,0.993019163608551
1330280744,14364,dajac,2023-09-19T15:01:22Z,"i am not sure to follow the `membershipmanager.notingroup()` part here. if we are not in the group, shouldn't we heartbeat to join (or rejoin) it?",0,0.953052282333374
1330281420,14364,dajac,2023-09-19T15:01:42Z,nit: we could use `ifpresent`.,0,0.9923794269561768
1330282085,14364,dajac,2023-09-19T15:02:04Z,nit: this empty line could be removed.,0,0.9941554069519043
1330286961,14364,dajac,2023-09-19T15:04:58Z,"when we transition to failed in updatestate, i think that it analogous to a non retriable error. is our plan to capture all the non-retriable errors before we reach this? we also do some error handling in updatestate. the responsibilities are not clear here.",0,0.9859877228736877
1330288247,14364,dajac,2023-09-19T15:05:56Z,nit: the naming does not respect our conventions here. we should use camel case.,0,0.8791577219963074
1330319691,14364,lianetm,2023-09-19T15:27:08Z,"agree that we need to better define responsibilities. as i see it for now, the membershipmgr should only come into play here when it's time to `updatestate`, and that would be : - when no errors in hb response (to extract relevant state info from the response and transition to `stable`) - when there is a non-retriable error (to transition to `failed`) any retriable error received in the hb response would be handled in the heartbeat manager here, while the state remains unchanged (ex. unjoined). with this approach, there would error handling in both, the heartbeat manager and the membership manager but for different purposes: - heartbeatmanager handles errors to continue retrying the request if needed (until it gets a success or fatal error, in which case it would stop retrying and call `updatestate`) - membershipmanager `updatestate` internally handles fatal errors only, just to update state info accordingly (ex. reset epoch on fence) and do the right transition. thoughts?",0,0.977102518081665
1330451339,14364,philipnee,2023-09-19T17:04:22Z,i see - i think we've been consistently using { in the refactor. maybe we should change that,0,0.9875202178955078
1330458175,14364,philipnee,2023-09-19T17:11:10Z,will do. sorry for completely missing this part.,-1,0.9939462542533875
1330460386,14364,philipnee,2023-09-19T17:13:24Z,"thanks, just note it here: `group.consumer.heartbeat.interval.ms is defined on the server side and the member is told about it in the heartbeat response.`",0,0.6621784567832947
1330475695,14364,philipnee,2023-09-19T17:25:35Z,"as previously commented, maybe let's use `shouldheartbeat` to be more explicit",0,0.9913798570632935
1330480862,14364,philipnee,2023-09-19T17:28:37Z,i've seen it in quite a few places so i thought we don't have a conventions :grinning_face_with_sweat:,1,0.9439934492111206
1330940223,14364,philipnee,2023-09-20T03:45:13Z,"thanks, i made some update to the manager, in particular, i split the fatal error out of the updatestate, lmk if you like the change, or we could do better.",1,0.9095665812492371
1331809403,14364,lianetm,2023-09-20T15:26:35Z,"this `onfatalerror` does update the state for the member, so separating it from the `updatestate` leads to having the update logic and transitions in 2 places (which i think is harder to follow/troubleshoot). what about we go back to a single `updatestate` responsible for updating state (aka. member info and transitions) . and if we make this single `updatestate` return the optional that it may find in the response, then we could leave the error handling only in the membershipmanager, and the heartbeatmanager could be much simplified. take a look at [a link] draft pr and let me know your thoughts",0,0.9857096672058105
1331811249,14364,lianetm,2023-09-20T15:27:56Z,this whole func would completely disappear if we agree on the something like the draft pr [a link],0,0.9570022225379944
1331828912,14364,lianetm,2023-09-20T15:40:02Z,"again brainstorming based on the [a link], this would be much simplified with the move of the error handling more into the membershipmanager i expect. here, instead of having to paths to update state (now there are 2 calls, one to membershipmanager.updatestate and another for all the error handling), we could simply have something like: [code block]",0,0.9862110018730164
1331895217,14364,philipnee,2023-09-20T16:21:45Z,"why don't we let the heartbeat request manager to handle all the errors? technically, these are heartbeat errors, and it would be more centralized to handle them on the manager. the membershipmanager really could just ensure if the transition is valid.",0,0.9884755611419678
1331944957,14364,lianetm,2023-09-20T17:05:56Z,"sounds good, actually better to move it all to the heartbeat manager, given that it is the more concerned about the hb errors. the membershipmgr in the end only needs to know about what affects the state (success, fencing and fatal failures)",0,0.6955567002296448
1331948509,14364,lianetm,2023-09-20T17:09:14Z,"this could still be simplified a lot like i was suggesting in the comment above. not handling all errors, only the fencing/fail ones. for all the rest is a common action that could be done with a single `nonretriableerrorhandler.handle(error.get().exception());`",0,0.9890135526657104
1331997791,14364,lianetm,2023-09-20T17:56:41Z,this will be invoked on any non-retriable error i expect (not only the unreleased_member_id),0,0.9945341348648071
1332028195,14364,lianetm,2023-09-20T18:27:58Z,this could be final now,0,0.9921993613243103
1332033298,14364,lianetm,2023-09-20T18:33:35Z,nit nit: i find it a better format to read the code if adding the separators at the end of the previous line for better alignment (having all the added `propid=` at the beginning of each line),0,0.9483700394630432
1332033928,14364,lianetm,2023-09-20T18:34:17Z,indentation,0,0.9911677837371826
1332038622,14364,lianetm,2023-09-20T18:39:21Z,indentation? (i guess it shouldn't be the same as in the requestmanager down below),0,0.9934826493263245
1332041024,14364,lianetm,2023-09-20T18:41:52Z,this is only needed when there is a groupid defined so i would move it completely to the `if (groupstate.groupid != null)` block,0,0.9953004121780396
1332064354,14364,lianetm,2023-09-20T19:06:17Z,"i think we should explain a bit here about the timing of the heartbeat requests, which is also managed by this class. it would be good to explain the timing logic based on the interval as max waiting time, but also mentioning that the manager may send out a hb request without waiting for the interval, ex. when completing processing an assignment.",0,0.9791288375854492
1332069325,14364,lianetm,2023-09-20T19:11:45Z,"given that the `cansendrequest` checks the heartbeat interval, this means that we'll be only sending heartbeats on the interval (heartbeattimer.isexpired()), but we also need to have a mechanism for sending heartbeat requests ""on-demand"" (ex. when rebalance callbacks execution finishes, we should send a hb request right away , without waiting for the interval timer to expire)",0,0.9932880997657776
1332077647,14364,lianetm,2023-09-20T19:20:50Z,do we need this at the class level? seems to only be needed in the constructors for initializing the heartbeattimer,0,0.9937887787818909
1332093119,14364,lianetm,2023-09-20T19:38:01Z,final,0,0.9173561930656433
1332115559,14364,lianetm,2023-09-20T20:03:05Z,"i think we should still validate here that the response contains no error (and throw illegalargument if so), as this func now is only expected to be called on successful responses. without such validation, an erroneous call to this func in the case of an error would end up going unnoticed and transition the member to stable.",0,0.9857742786407471
1332177568,14364,kirktrue,2023-09-20T21:00:24Z,can we resolve the error code to an `errors` object via `errors.forcode()`?,0,0.9947531223297119
1332178673,14364,kirktrue,2023-09-20T21:01:15Z,"same question here, can we use and compare errors based on `errors` (which we can get via `errors.forcode()`)?",0,0.9909425377845764
1332183105,14364,kirktrue,2023-09-20T21:04:48Z,same request here: use `errors` to remove unnecessary use of raw error `code`.,0,0.99540776014328
1332190917,14364,kirktrue,2023-09-20T21:11:24Z,can we rename `failmember` to be more descriptive?,0,0.9924516081809998
1332191970,14364,kirktrue,2023-09-20T21:12:39Z,"per the related comment, can we rename `failmember` something that is more descriptive of what action _happened_ vs. that action's _result_?",0,0.9922201037406921
1332443272,14364,philipnee,2023-09-21T04:40:54Z,"this is a pretty common pattern to override tostring. do you mean making it doing? [code block] currently everything is in a single line. though - this can be used for logging, so i wonder what would it look like it if we add line separator.",0,0.9821908473968506
1332444068,14364,philipnee,2023-09-21T04:41:41Z,:person_facepalming:,0,0.9812792539596558
1332446857,14364,philipnee,2023-09-21T04:44:25Z,make sense.,0,0.9763523936271667
1332454913,14364,philipnee,2023-09-21T04:54:32Z,i thought it would be more clear on how to implement this after the revocation is implemented or implement it with the assignment logic - can we punt it to a separated pr?,0,0.9851169586181641
1332455723,14364,philipnee,2023-09-21T04:55:43Z,"this is left non-final intentionally - as sometimes we might want to spy the membership class, so the test function can override it.",0,0.9920416474342346
1332466756,14364,philipnee,2023-09-21T05:11:46Z,maybetransitiontofailure ?,0,0.9800453782081604
1333624789,14364,lianetm,2023-09-21T21:33:13Z,"agree with the pattern, i was only referring to having the nit of having props aligned : [code block]",0,0.8429297208786011
1333629206,14364,lianetm,2023-09-21T21:39:58Z,"ok with having it in a separate pr but let's maybe add a comment/todo here, and think about how to define the interaction between the assignmentreconciler and this hb manager. they need to somehow communicate to trigger a hb request when the callbacks complete successfully (exactly what came out in the assignmentreconciler pr review [a link]",0,0.9921013712882996
1334626047,14364,lianetm,2023-09-22T16:57:01Z,typo membershipmanager,0,0.99039626121521
1334633010,14364,lianetm,2023-09-22T17:04:49Z,i think this is not only for revocation. i expect members should send a heartbeat request as soon as they complete processing an assignment without waiting for the interval (for both cases: new partitions being added and partitions being revoked). let's double check with,0,0.986464262008667
1334636930,14364,lianetm,2023-09-22T17:09:23Z,unused since the class level var was removed,0,0.9910451173782349
1334645635,14364,lianetm,2023-09-22T17:19:05Z,"i find it a bit confusing to say that the member won't send hb when it left the group. agree that it holds true when a member intentionally leaves a group (ex. when the consumer is closed), but it's not true for when a member is left out of the group by the server (ex. all fencing scenarios). when left out of a group because of a fencing situation, the member will release its assignment and send hb again to rejoin.",0,0.5184221863746643
1334652824,14364,lianetm,2023-09-22T17:27:10Z,"i think we're still missing important info in the doc about the hb interval and how it is applied. (the heartbeat sent on the heartbeat interval, that is received from the server on the first hb response. if the member finishes processing an assignment (partitions assigned/revoked) the interval is not honored and the hb request is sent out right away)",0,0.9448401927947998
1334657428,14364,lianetm,2023-09-22T17:32:14Z,uhm we're using a 0 as default `heartbeatintervalms` here. this will only get updated when we get the value from the server in the first hb response. thinking about the case where we send an initial hb request but never get a response...does this 0 then mean that we'll continue to send a hb on every poll iteration?,0,0.9720406532287598
1334659219,14364,lianetm,2023-09-22T17:34:12Z,nit: review punctuation marks usage,0,0.98661208152771
1334668800,14364,lianetm,2023-09-22T17:45:30Z,"agree that we'll ""update the timer when the response is received"", but i see here that the timer is only used on the case where it is not time to send hb yet (if block above, ln 112). in the case of this return, which is the case when the hb request manager is polled and notices it is time to send the hb, we're always passing `long.max_value` as `timemstillnextpoll`. shouldn't we use the timer here too (that will have its default value if this is a first req, or the one provided by the server in a previous hb response)?",0,0.993454098701477
1334734541,14364,philipnee,2023-09-22T19:08:25Z,"the cansendrequest should take care of the inflight request. if the request has been sent w/o a response/error, it won't try to send again. for the initial state, i really just need to set to a specific number as we get the hb response from the server. i set to 0 because i think the client should quickly poll the manager against to see if it can send a heartbeat. another alternative is to use `backoffs` to prevent a tight loop there. wdyt?",0,0.9888733625411987
1335289660,14364,lianetm,2023-09-25T01:02:54Z,"got it, seeing that the `cansendrequest` considers inflight requests then it makes sense to set an initial value of 0 i would say, so that we send the first hb as soon as the hm manager starts. i would only suggest to add some tests for the interval, including this case where we might not get a response to our first hb request.",0,0.9664698243141174
1335295791,14364,lianetm,2023-09-25T01:20:46Z,`shouldsendheartbeat` returning false when unjoined does not seem right. we do need to send hb when unjoined to be able to join the group. i would say failed is the only state we we shouldn't send hb.,0,0.9537515044212341
1335297785,14364,lianetm,2023-09-25T01:27:16Z,"given that the current `shouldsendheartbeat` returns false when unjoined, i expect the second part of this condition will be true when a members starts for the first time and we'll return a pollresult with empty request list, so we'll never be sending the first hb request?",0,0.9918593764305115
1335304701,14364,lianetm,2023-09-25T01:46:06Z,"this is a non-retriable exception, so i expect we should be calling `membershipmanager.transitiontofailure()`? (same for all other fatal exceptions up to the `unreleased_instance_id`, which is properly doing the transition)",0,0.9918860197067261
1335307959,14364,lianetm,2023-09-25T01:55:36Z,"from the hb request manager point of view, this means that when polled, it won't return any request right? could we assert that to ensure that the request manager is actually not generating requests at this point?",0,0.9907926321029663
1335309021,14364,lianetm,2023-09-25T01:58:34Z,"if we agree on the [a link] regarding missing transitions when handling fatal errors, i expect this will be updated to reflect align with it and check transition to failed on all fatal errors other than the 2 fencing ones.",0,0.9918853044509888
1336389075,14364,philipnee,2023-09-25T21:06:06Z,i think you are right.,1,0.6776596903800964
1336390801,14364,philipnee,2023-09-25T21:08:17Z,the updated pr should invoke maybetransitiontofailurestate() on a few fatal exceptions.,0,0.9927196502685547
1336429379,14364,philipnee,2023-09-25T22:03:13Z,"so when we startup the manager, the timer will be set to 0 until the first heartbeatinterval response is received. which means, we will get a heartbeat request on the first poll. i added a test for this.",0,0.9929525256156921
1337234985,14364,lianetm,2023-09-26T13:42:35Z,wrong placeholder {},-1,0.7412189245223999
1337235694,14364,lianetm,2023-09-26T13:43:05Z,ditto,0,0.9754701256752014
1337238424,14364,lianetm,2023-09-26T13:44:57Z,"tries ""to"" rejoin",0,0.9937835931777954
1337239851,14364,lianetm,2023-09-26T13:45:54Z,"and ""try""",0,0.9862099289894104
1337258265,14364,lianetm,2023-09-26T13:57:51Z,"this format won't show as a proper list in the java doc, we should use ` ` tags (similar for the empty lines)",0,0.9938122034072876
1337263803,14364,lianetm,2023-09-26T14:00:56Z,"true, but the poll is much more than just determining the wait time, so i would add to this something like "" it builds the heartbeat request, including the logic for handling the responses""",0,0.9916254878044128
1337265790,14364,lianetm,2023-09-26T14:02:19Z,comma after expired,0,0.9843259453773499
1337269007,14364,lianetm,2023-09-26T14:04:32Z,these empty lines won't show as such in the java doc so let's add tags to ensure we have the separation we want,0,0.9934513568878174
1337275381,14364,lianetm,2023-09-26T14:08:55Z,"just for my understanding, what's the idea behind this todo? i thought we had inflight req handling in the parent `requeststate`, that already identifies `log.trace(""an inflight request already exists for {}"", this);`. and what would be the concurrent scenario if there is a single background thread sending heartbeats and it is not resending while there is one inflight?",0,0.9887664914131165
1337278130,14364,lianetm,2023-09-26T14:10:40Z,extra space after state.,0,0.9912475943565369
1337278315,14364,lianetm,2023-09-26T14:10:47Z,ditto,0,0.9754701256752014
1337282271,14364,lianetm,2023-09-26T14:13:22Z,final,0,0.9173561930656433
1337282860,14364,lianetm,2023-09-26T14:13:46Z,extra line,0,0.9940018057823181
1337295428,14364,lianetm,2023-09-26T14:20:46Z,seems we're not using `memberassignment` in the test anymore? let's remove if unused,0,0.9933257102966309
1337309504,14364,lianetm,2023-09-26T14:28:25Z,"high level comment, i do see this test covering the timing logic for sending, and the response handling on error, but nothing for the successful hb response handling (important to ensure that it is updating the target assignment so that it can be processed by other components). also it would be helpful to have some tests around hb timeouts, mainly to validate the retry logic around that. (just suggestions for better coverage of core actions, ok for me if we prefer to target that in a separate pr)",0,0.9438742399215698
1337418980,14364,philipnee,2023-09-26T15:37:20Z,this is just for comment formatting.,0,0.9931544065475464
1337420489,14364,philipnee,2023-09-26T15:37:58Z,"i think it was a note from before, removed.",0,0.9864934682846069
1337423659,14364,philipnee,2023-09-26T15:39:35Z,we don't make these var final in tests because we could change them later,0,0.9890496730804443
1337428627,14364,lianetm,2023-09-26T15:43:11Z,"ok, that's fine but not enough. i think here we also need the tags. if you look at the java doc it shows as a giant block, which i expect it is not what we want.",0,0.9720944166183472
1337639317,14364,lianetm,2023-09-26T18:42:23Z,"agree, with the fix for the `shouldsendheartbeat` this should now work as expected.",0,0.9817011952400208
1340176254,14364,lianetm,2023-09-28T13:40:51Z,seems this is still wrong? same for the following comment,0,0.978968620300293
1340351740,14364,philipnee,2023-09-28T15:44:05Z,for some reason the change didn't get pushed.,-1,0.5125400424003601
1341528842,14364,dajac,2023-09-29T15:42:23Z,i actually missed this in the other pr but the assignor selection should be based on the new `group.remote.assignor` config which should be null by default. null means that the server selects the assignor.,0,0.9907498955726624
1341531725,14364,dajac,2023-09-29T15:44:30Z,don't we need to rejoin with epoch 0 when the member is kicked out of the group? we should actually remove all partitions and trigger the partition lost callback as well before doing so.,0,0.9905533194541931
1341532755,14364,dajac,2023-09-29T15:45:21Z,what's the delay for the next event loop?,0,0.9920518398284912
1341535159,14364,dajac,2023-09-29T15:47:25Z,i wonder if we really need this. i would expect retriable exception to inherit from `retriableexception` and the fatal ones to not inherit from it. is it possible to leverage this somehow?,0,0.9445686936378479
1341535814,14364,dajac,2023-09-29T15:47:51Z,should we have javadoc for all those attributes?,0,0.9925685524940491
1341539358,14364,dajac,2023-09-29T15:50:34Z,"when the reconciliation of the local assignment is completed, we need to send the heartbeat request immediately to ack it. is this going to be another condition here?",0,0.9952971339225769
1341540248,14364,dajac,2023-09-29T15:51:17Z,this answers my previous comment :). note that we also need to do this when partitions are assigned.,1,0.9841740131378174
1341547285,14364,dajac,2023-09-29T15:56:40Z,"most of the fields in the consumergroupheartbeat req/rsp are optional. our aim was to avoid having to send unnecessary information when the group is stable. in this case, the request/response should be as lightweight as possible. there are basically three requires fields: groupid, memberid, memberepoch. those must be set all the time. i am also debating whether groupinstanceid should also be. for all the others, they should only be set if they have changed. we should also send out a full request when we recover from a recoverable error (e.g. fenced, network issues, timeouts, etc.).",0,0.9379122853279114
1341548905,14364,dajac,2023-09-29T15:57:54Z,"on the regex topic, keep in mind that we will support both the java regex and the new sever side one for a while. when the java regex is used, the resolution must be done locally. when the server side regex is used, we must pass it to the server.",0,0.9897232055664062
1341588720,14364,dajac,2023-09-29T16:40:07Z,i don't really get the value of this map given that we handle all (known) errors anyway. should we just move `transitiontofailure` to there?,0,0.9028753638267517
1341590757,14364,dajac,2023-09-29T16:42:44Z,"the name `onfatalerrorresponse` is incorrect here, isn't it? we handle recoverable errors (e.g. fenced_member_epoch). personally, i would prefer to re-group all errors in `onerrorresponse` and have a `switch` covering all of them there. this would simplify the code and avoid repetition such as `errors.forcode(response.data().errorcode())` which is in both places. thoughts?",0,0.9885202050209045
1341591777,14364,dajac,2023-09-29T16:44:00Z,we also pass the `errormessage` to `exception()` here in order to give it back to the user.,0,0.9949251413345337
1341592473,14364,dajac,2023-09-29T16:44:54Z,don't we need to propagate those unknown errors to the user as well? what's our strategy here?,0,0.9914420247077942
1341592782,14364,dajac,2023-09-29T16:45:16Z,nit: we usually declare final attributes before the others.,0,0.9929178357124329
1341593245,14364,dajac,2023-09-29T16:45:51Z,nit: couldn't it be final as well?,0,0.9881160259246826
1341596109,14364,dajac,2023-09-29T16:49:23Z,"why do we need this try catch here? if we remove it, where would the exception be caught?",0,0.9898290038108826
1341597457,14364,dajac,2023-09-29T16:50:52Z,nit: `transitiontofenced` to be aligned with the other one?,0,0.9928020238876343
1341597673,14364,dajac,2023-09-29T16:51:08Z,nit: should it be `transitiontofailed`?,0,0.9736148118972778
1341662210,14364,lianetm,2023-09-29T18:00:53Z,"agree, i missed this too. we agreed that we would have no default on the client side, and would let the server choose.",0,0.9609002470970154
1341666380,14364,lianetm,2023-09-29T18:06:37Z,"agree too. it's only when the member leaves the group intentionally (ex. when consumer closes) that i expect this applies, no more hb. (addressed also on [a link] comment)",0,0.9828261733055115
1341669179,14364,philipnee,2023-09-29T18:10:28Z,"yeah possible - but i'll need to encode the 2 exceptions, i.e. unknown member id and fenced epoch, somewhere",0,0.9840447902679443
1341690694,14364,philipnee,2023-09-29T18:37:33Z,"it is a little bit tricky here, because the background thread loop is blocked until either it receives some responses, or the timer of the minimum of the heartbeat, metadata, or request timeout is expired. what we would do is to reset the heartbeatrequeststate so that we could ensure the next event loop will trigger a heartbeat. the timing, however, is a little tricky here, because it can be non-deterministic of when the next heartbeat will be sent.",0,0.967089831829071
1341699215,14364,philipnee,2023-09-29T18:49:09Z,left a todo. will have a separated pr to fix this.,0,0.9940342307090759
1341767013,14364,philipnee,2023-09-29T20:27:16Z,"actually i think we should, thanks for the catch.",1,0.9057366847991943
1341775832,14364,philipnee,2023-09-29T20:41:42Z,"we don't, it is purely for logging purposes. for the case of this exception, maybe we should fail the request and retry.",0,0.9829822182655334
1341778036,14364,philipnee,2023-09-29T20:45:03Z,we probably don't need it after all. because error is thrown when an error is presented in the response.,0,0.9609057307243347
1342665614,14364,dajac,2023-10-02T13:03:52Z,"my understanding is that we basically retry on all exceptions here. am i correct? it seems to me that we could also get non-retriable exceptions here (e.g. unsupportedversionexception, etc.). how do we handle those?",0,0.9895111918449402
1342666388,14364,dajac,2023-10-02T13:04:24Z,"we also need to handle `unsupportedversionexception` error, i think.",0,0.9908892512321472
1342667683,14364,dajac,2023-10-02T13:05:20Z,"would it make sense to just call `membershipmanager.transitiontofailed();` in all errors instead of having this one? at the movement, the handling is a little inconsistent.",0,0.9080587029457092
1342669966,14364,dajac,2023-10-02T13:06:52Z,nit: we usually put an empty line between cases. it makes it a bit more readable.,0,0.9881198406219482
1342674863,14364,dajac,2023-10-02T13:10:14Z,"when we get this one, i understand that we will mark the coordinator as unknown to rediscover it. is it going to apply the exponential backoff after that?",0,0.992644190788269
1342677484,14364,dajac,2023-10-02T13:12:26Z,this message is not consistent with the others. should it also start with `groupheartbeatrequest failed due to...`? i would also replace `retrying` by something like `will attempt to find the coordinator again and retry`.,0,0.9856281280517578
1342678720,14364,dajac,2023-10-02T13:13:33Z,"nit: this one is also inconsistent. `+ ""retrying""` could be merged with the previous string. a space misses between `loading.` and `retrying`.",0,0.9847709536552429
1342681301,14364,dajac,2023-10-02T13:15:56Z,"i don't really understand how the error message is handled here. is it going to be added as the message of the exception later on? when i mentioned this in my earlier comment, i means doing this `errors.invalid_request.exception(errormessage)`. this uses the provided error message.",0,0.9640063643455505
1342682876,14364,dajac,2023-10-02T13:17:24Z,does the :thumbs_up_light_skin_tone: mean that you will add it?,0,0.9936813116073608
1342683440,14364,dajac,2023-10-02T13:17:54Z,should we also log something here?,0,0.9936908483505249
1342689429,14364,dajac,2023-10-02T13:23:06Z,i also wonder if having a tailored error message for each error is needed. an alternative would be to group errors and have a generic message for the fatal ones for instance. what do you think?,0,0.9697790145874023
1342694336,14364,dajac,2023-10-02T13:27:18Z,i also noticed that we have the following in the current implementation: [code block],0,0.9918042421340942
1342778930,14364,philipnee,2023-10-02T14:37:07Z,"the heartbeat request depends on the state of the state machine, so for most of the non-retriables, it should transition the state to a failure state to prevent additional requests being sent. the non-retriable also send an error to the handler (`nonretriableerrorhandler`) to send the error to the user to handle the failure case.",0,0.9935389161109924
1342781938,14364,philipnee,2023-10-02T14:39:25Z,"but we don't want errors like `coordinator_not_available` to be fatal, no?",0,0.9802314639091492
1342783380,14364,philipnee,2023-10-02T14:40:41Z,really? :grinning_face_with_sweat: most cases i see don't have an empty line. but i'll add a line anyway.,1,0.8082321882247925
1342785385,14364,philipnee,2023-10-02T14:42:21Z,yap - `this.heartbeatrequeststate.onfailedattempt(currenttimems);` basically markets the `lastreceivedms` as the response receive time. then it would trigger the backoff mechanism in the requeststate. i think expo backoff was tested in the test.,0,0.9934198260307312
1342899010,14364,philipnee,2023-10-02T16:14:38Z,yap that's a good idea to make the code easier to follow. we do want to provide some context such as group id or group instance id to group_authorization_failed and unreleased_instance_id respectively. so i'm grouping the following 4 errors [code block],1,0.9507302045822144
1342910020,14364,philipnee,2023-10-02T16:25:52Z,"added some comments directly above the var - is this enough or you actually want this to be presented in the ""javadoc"" of the class section?",0,0.9953449368476868
1342915079,14364,philipnee,2023-10-02T16:31:09Z,i understand the concern about inconsistency but different errors can put the member in a different state,0,0.9185633659362793
1342920121,14364,philipnee,2023-10-02T16:36:57Z,"yap i see the disconnectexception handling, it is implemented by all requests going to the coordinator. here we handle them independently in the request mangers. maybe we could modularize these reaction to make it more unified.",0,0.9871658682823181
1344205855,14364,dajac,2023-10-03T14:29:18Z,my point was that the `exception` received here may not be re-triable (e.g. unsupportedversionexception) and that we may have to take actions on them (e.g. disconnectexception). are you saying that we handle those in another component? my current understanding is that we don't update the state machine based on those exceptions at the moment because `onerrorresponse` is not called. do we understand all the exceptions that we could receive here? we need to handle them all appropriately.,0,0.9917287230491638
1344221907,14364,dajac,2023-10-03T14:36:18Z,it seems that we could get the following ones: [code block] + `timeoutexception`,0,0.9932482242584229
1344230989,14364,dajac,2023-10-03T14:38:36Z,"sorry, i was not clear. i was trying to say that we should just call `membershipmanager.transitiontofailed();` in the relevant errors in the switch.",-1,0.9739680886268616
1344232148,14364,dajac,2023-10-03T14:39:14Z,"do we want to backoff in this case though? it seems to me that we want to retry immediately when the new coordinator is discovered, no?",0,0.9847234487533569
1344236644,14364,dajac,2023-10-03T14:42:12Z,could we please file a jira for this?,0,0.9951053857803345
1344336463,14364,philipnee,2023-10-03T15:50:54Z,i see. sure we could certainly do that.,0,0.953922688961029
1344462484,14364,philipnee,2023-10-03T17:17:27Z,"i think we might want to refactor the coordinator requests per what you indicated above. a jira is filed: [a link] otherwise, in the onfailure() method, i added the logic to fail the state machine and propagate the error when the error is non-retriable",0,0.992206871509552
1344497810,14364,philipnee,2023-10-03T17:43:27Z,see `testheartbeatonstartup` in the test. the first poll returns a request.,0,0.995218813419342
1344512748,14364,philipnee,2023-10-03T17:56:32Z,here you go david: [a link],0,0.9941757917404175
1344515152,14364,philipnee,2023-10-03T17:58:41Z,"thanks - the seems like the right way to do this to only backoff for coordinator_load_in_progress error. onfailedattempt is removed. in the test `testheartbeatresponseonerrorhandling`: next heartbeat is verified ` assertequals(0, heartbeatrequeststate.nextheartbeatms(mocktime.milliseconds()));`",1,0.9483793377876282
1344560113,14364,lianetm,2023-10-03T18:40:40Z,duplicated above,0,0.9783943295478821
1344567777,14364,lianetm,2023-10-03T18:47:54Z,"i expect this will be the place where we'll need to make sure to release any assignment we may have, right? whenever a transitiontofailed/fence occurs, the hb manager should call the reconciler to trigger the onpartitionslost/revoked as needed. let's add a todo just as we did for the missing bit of triggering the hb before the interval.",0,0.9920696020126343
1344589907,14364,philipnee,2023-10-03T19:03:45Z,this is actually invalid because the response can be null in this case. i filed a jira kafka-15278 to propagate the time from the networkclientdelegate,0,0.9903919696807861
1344603478,14364,philipnee,2023-10-03T19:08:57Z,i added a test for the heartbeat timeout. see `testbackoffonheartbeattimeout`,0,0.9944140911102295
1345652576,14364,dajac,2023-10-04T11:38:27Z,i would add real javadoc to all attributes or none of them. this is what we have been doing for all the new java code recently.,0,0.9929379820823669
1345661869,14364,dajac,2023-10-04T11:46:16Z,nit: it would be good to be consistent in the log messages. they almost all start with `groupheartbeatrequest failed due...`. why don't we do the same here? i think that this is important to know that the groupheartbeatrequest failed in this case as well. the same applies to coordinator_load_in_progress. `groupheartbeatrequest failed because the group coordinator %s is incorrect. will attempt to find the coordinator again and retry`.,0,0.8577288389205933
1345662992,14364,dajac,2023-10-04T11:47:13Z,nit: `groupheartbeatrequest failed because the group coordinator %s is still in the process of loading state. will retry`.,0,0.9449882507324219
1345667909,14364,dajac,2023-10-04T11:51:33Z,it would be great to split those two in order to have separate error messages. fenced_member_epoch: `groupheartbeatrequest failed because member epoch %s is invalid. will abandon all partitions and rejoin the group` unknown_member_id: `groupheartbeatrequest failed because member id %s is invalid. will abandon all partitions and rejoin the group`,0,0.8680868744850159
1345669627,14364,dajac,2023-10-04T11:53:03Z,should we revert this? it seems that we don't need it anymore.,0,0.9858291745185852
1345670931,14364,dajac,2023-10-04T11:54:19Z,nit: constants are usually formatted as follow: `heartbeat_interval_ms`.,0,0.993895947933197
1345680555,14364,dajac,2023-10-04T12:01:21Z,nit: we can remove empty line here.,0,0.991962730884552
1345683631,14364,dajac,2023-10-04T12:03:20Z,so by default `heartbeatrequeststate` is a mock but we don't prefix it with `mock`. this is inconsistent...,0,0.9431392550468445
1345684050,14364,dajac,2023-10-04T12:03:37Z,could we use `createmanager()` here?,0,0.9944747090339661
1345687969,14364,dajac,2023-10-04T12:06:18Z,nit: bring back on previous line.,0,0.9922647476196289
1345688824,14364,dajac,2023-10-04T12:07:04Z,nit: final to be consistent with the others?,0,0.983460009098053
1345689109,14364,dajac,2023-10-04T12:07:21Z,nit: remove `this.` to be consistent with the others.,0,0.9929106831550598
1345692568,14364,dajac,2023-10-04T12:10:13Z,should we have a test which verifies that fatal errors update the state machine?,0,0.990872323513031
1345695035,14364,dajac,2023-10-04T12:12:10Z,should we add a unit which verifies the generated request? we have none doing this...,0,0.993158757686615
1345696189,14364,dajac,2023-10-04T12:13:08Z,nit: `manually...`. could you please verify all the other comments as well? i don't really care if they start with a capital letter or not but i do care about consistency...,0,0.9227460622787476
1345697251,14364,dajac,2023-10-04T12:14:00Z,nit: is this really needed? it seems that using `code` would work as well.,0,0.9856181740760803
1345703205,14364,dajac,2023-10-04T12:18:13Z,"it is a bit weird to statically import those two but not the others (also used in this class), no?",-1,0.9812012314796448
1345704121,14364,dajac,2023-10-04T12:18:58Z,nit: could we align `errorcode` on `errorcode`?,0,0.9907705783843994
1345704966,14364,dajac,2023-10-04T12:19:40Z,should we add unsupported version as well?,0,0.9911160469055176
1345951445,14364,philipnee,2023-10-04T14:55:54Z,pretty sure i reverted in the previous commit....hmm,0,0.9591079950332642
1346233433,14364,philipnee,2023-10-04T17:32:22Z,"thanks, i'll just get rid of the mock there. probably unnecessary.",0,0.5097424983978271
1346244285,14364,philipnee,2023-10-04T17:41:57Z,i refactored the if else block using switch. i think it should make it a bit more readable.,0,0.9619096517562866
1346245842,14364,philipnee,2023-10-04T17:43:22Z,see above - this section is refactored into swtich.,0,0.9948768019676208
1346258637,14364,philipnee,2023-10-04T17:54:40Z,`ensurefatalerror()` already ensure the transitiontofailed is invoked. `testtransitiontofailure` in the membershipmanagerimpltest also verifies the state transition.,0,0.9940316081047058
1346463825,14364,philipnee,2023-10-04T21:05:36Z,added `testvalidateconsumergroupheartbeatrequest` - which validate the fields in the the requestbuilder.build(version) - is that what do you mean?,0,0.9960591793060303
1347439165,14364,dajac,2023-10-05T13:38:54Z,nit: sorry but i missed those yesterday. could we also align those log messages to the other format used: `groupheartbeatrequest failed....`?,-1,0.9883469939231873
1347441115,14364,dajac,2023-10-05T13:40:12Z,nit: empty line.,0,0.9438178539276123
1347441582,14364,dajac,2023-10-05T13:40:31Z,nit: empty line.,0,0.9438178539276123
1347447016,14364,dajac,2023-10-05T13:44:05Z,hum... i don't follow. my point was that we don't have any tests verifying that we actually update the state machine when a fatal __exception__ is received [a link]. or did i miss it?,0,0.7391549944877625
1347448120,14364,dajac,2023-10-05T13:44:49Z,"yep, thanks.",1,0.7808536887168884
1347449738,14364,dajac,2023-10-05T13:45:50Z,should we verify all the fields? we also set others [a link].,0,0.9952421188354492
1347455966,14364,dajac,2023-10-05T13:49:46Z,nit: assure...,0,0.9390023946762085
1347728174,14364,philipnee,2023-10-05T16:57:22Z,done - i left a todo to verify client and server side assignors and pattern regex.,0,0.9896580576896667
1348690378,14364,dajac,2023-10-06T12:58:35Z,"i am not really satisfied by the logging on failures: * when there is a fatal error, it logs a warning follower by an error. * the messages don't really follow the format of the other messages. should we just drop the warning on top? could we update the remaining debug message to follow the structure of the other log messages?",-1,0.7571672797203064
1348885178,14364,philipnee,2023-10-06T15:35:26Z,"thanks, let's drop the warn. i also updated the debug message.",1,0.5726973414421082
1788067718,17373,mumrah,2024-10-04T17:36:06Z,these (and other similar `testruntimeonly`) should be put into the `runtimetestlibs` definition,0,0.9949476718902588
1788068473,17373,mumrah,2024-10-04T17:36:26Z,what's this dependency for?,0,0.9571608901023865
1788082764,17373,mumrah,2024-10-04T17:47:01Z,"this could break some existing kafka installations. if users are extracting in place or copying previous config files to a new installation directory, they will be expecting the log4j.properties to still work.",0,0.9239760637283325
1788846414,17373,frankvicky,2024-10-06T03:28:54Z,hi i add this to fix the warning during build: [code block],0,0.9935351610183716
1810596051,17373,showuon,2024-10-22T12:04:05Z,"we should remove this file, right?",0,0.9878426790237427
1810598884,17373,showuon,2024-10-22T12:06:12Z,"is this right? it's still possible it runs with log4j 1.x, right?",0,0.9901662468910217
1810600249,17373,showuon,2024-10-22T12:07:15Z,we still need reload4j here?,0,0.9936808347702026
1810616327,17373,showuon,2024-10-22T12:18:04Z,"in[a link], we also set the pattern to connectappender, right?",0,0.9951452612876892
1810618105,17373,showuon,2024-10-22T12:19:08Z,should we remove them?,0,0.985713005065918
1810618615,17373,showuon,2024-10-22T12:19:30Z,should we remove them?,0,0.985713005065918
1810625227,17373,showuon,2024-10-22T12:23:44Z,i don't understand the changes in the file. we move a log4j.properties in `connect/runtime` to `connect/mirror`? why?,0,0.9372843503952026
1810705740,17373,frankvicky,2024-10-22T13:13:55Z,"yes, there are still some modules (like `tools`) that directly depend on `reload4j`, which we can't remove at the moment. removing it would cause build errors. [code block]",0,0.9921144247055054
1810711392,17373,frankvicky,2024-10-22T13:17:09Z,"yes, we should. however, i'm thinking that removing the zk configurations might be better handled as a follow-up pr, since this one is already quite large. wdyt ?",0,0.9854275584220886
1810722170,17373,frankvicky,2024-10-22T13:23:19Z,hmm... i think it's just an issue with github detection. i modified these two files in place. :thinking_face:,1,0.9078403115272522
1810744889,17373,frankvicky,2024-10-22T13:35:57Z,"yes, i think the `connectappender` setting in log4j1 is equivalent to the following, if i haven't misunderstood: [a link]",0,0.9914148449897766
1811786044,17373,showuon,2024-10-23T03:53:04Z,"it looks like it's our test depends on reload4j. in this case, we should try to fix it.",0,0.9904006123542786
1811787630,17373,frankvicky,2024-10-23T03:54:44Z,i see. i will try to deal with this issue.,0,0.9682639241218567
1811789962,17373,showuon,2024-10-23T03:57:47Z,"oh, i missed that! thanks.",1,0.993117094039917
1811959867,17373,showuon,2024-10-23T06:31:13Z,"i'm not familiar with log4j2, so i don't understand the empty name here. why can't we use `getrootlogger` as above?",0,0.9371721148490906
1811961770,17373,showuon,2024-10-23T06:33:03Z,is this behavior change expected?,0,0.9873962998390198
1811968367,17373,showuon,2024-10-23T06:39:10Z,this is for which method?,0,0.9946830868721008
1811977005,17373,showuon,2024-10-23T06:45:28Z,we don't need `resolvelevel` now because log4j2 will do that for us? do we have test for it?,0,0.9926350712776184
1811982931,17373,showuon,2024-10-23T06:48:50Z,this change is for zk removal?,0,0.99433833360672
1811990279,17373,showuon,2024-10-23T06:53:19Z,why can't we change the root log level now?,0,0.98800128698349
1811993482,17373,showuon,2024-10-23T06:54:51Z,"ok, this is replaced with `reconfigure()`, right?",0,0.9935054779052734
1811996534,17373,showuon,2024-10-23T06:56:07Z,"i think our goal in this pr, is to remove the reload4j above. thanks for looking into how we can completely remove it!",1,0.9797601103782654
1812025899,17373,showuon,2024-10-23T07:12:23Z,"i'm not familiar with log4j2, just want to confirm will it confuse the setting?",0,0.9852474927902222
1812137033,17373,frankvicky,2024-10-23T08:08:49Z,"yes, exactly. `reconfigure()` provides a more convenient way to hot reload log4j configurations. :grinning_cat:",1,0.9568593502044678
1812147748,17373,frankvicky,2024-10-23T08:14:04Z,"yes, the name `r` might be confusing. my intention was to purely transform from log4j1 to log4j2 without making any further unnecessary changes. however, it can definitely be renamed if needed.",0,0.9731606841087341
1812168338,17373,frankvicky,2024-10-23T08:23:53Z,"yes, i intentionally made this change to align with the removal of zk tests.",0,0.9909789562225342
1812209524,17373,frankvicky,2024-10-23T08:40:17Z,"we could, but to make the test more precise, we should avoid having the test depend on the root logger. we are now focusing on changing the log level of the `kafka` logger, which acts as the top-level logger for the `kafka.server.controllerserver`, `kafka.log.logcleaner`, and `kafka.server.replicamanager` components. this change ensures that we can still control kafka's logging behavior without relying on the root logger.",0,0.9922541379928589
1812297584,17373,frankvicky,2024-10-23T09:12:49Z,"in this test case, we focus on setting the level for the root logger. imho, it would be ideal if we could have a ""clean"" configuration to conduct this test case. if i understand correctly, we can create a new configuration programmatically at the beginning in this way to ensure that the test case is not affected by existing log4j configurations.",0,0.9329608082771301
1812309503,17373,frankvicky,2024-10-23T09:17:09Z,"yes. in log4j2, the `getlevel` method returns either the explicitly set level or the effective level. we can roughly think of it as a combination of two methods (`getlevel` and `geteffectivelevel`) from log4j1.",0,0.99327152967453
1812370163,17373,showuon,2024-10-23T09:49:10Z,i see. but i still want to see if we can change the root logger to make sure we didn't break existing behavior. maybe we can create one more test for it?,0,0.9766929745674133
1812371827,17373,frankvicky,2024-10-23T09:50:14Z,"yes, log4j2 will do it for us. in log4j2, when we retrieve a logger instance from the `loggercontext`, the `getlevel` method returns the effective log level, which includes any levels inherited from parent loggers up to the root logger. this means that if a logger doesnt have an explicit level set, `getlevel` will provide the inherited level, so we dont need to manually traverse the logger hierarchy as we did in the `resolvelevel` method.",0,0.99111407995224
1812372018,17373,showuon,2024-10-23T09:50:22Z,"ok, could we add some comments for these changes?",0,0.9948410391807556
1812372375,17373,frankvicky,2024-10-23T09:50:36Z,"sadly, we don't have a test for it",-1,0.9615357518196106
1812372794,17373,frankvicky,2024-10-23T09:50:55Z,"oops, i will do some clean-up",0,0.7431356906890869
1812374332,17373,frankvicky,2024-10-23T09:51:54Z,"sure, i will do that.",0,0.9052426815032959
1812375243,17373,frankvicky,2024-10-23T09:52:28Z,sure. :grinning_cat:,1,0.9897027611732483
1812406378,17373,showuon,2024-10-23T10:10:40Z,let's add some tests for this class. thanks.,1,0.8700016140937805
1812696648,17373,frankvicky,2024-10-23T12:54:26Z,"ah, i have just found that we already have test cases for it. [a link]",0,0.9836108684539795
1813031963,17373,frankvicky,2024-10-23T15:24:28Z,"[a link] since `log4j-appender` is depending on `clients`, we will need to delete `log4j-appender` module if we want to entirely get rid of `log4j`. [a link] cc.",0,0.9943469166755676
1813405127,17373,mimaison,2024-10-23T19:17:30Z,the link also needs updating (as well as the line number),0,0.9951035976409912
1813427142,17373,mimaison,2024-10-23T19:36:09Z,"i'm not convinced we need that dependency. also it seems to complain about an annotation so at least we should not need it at runtime, so we should not include it in our distribution package. currently it's included in the artifact generated by `releasetargz`.",0,0.8745101094245911
1813429859,17373,mimaison,2024-10-23T19:38:40Z,let's keep the newline,0,0.9921257495880127
1813430705,17373,mimaison,2024-10-23T19:39:25Z,we probably don't need this zookeeper logger,0,0.9693910479545593
1814229869,17373,frankvicky,2024-10-24T04:31:35Z,"fair enough, i will try to solve this one.",0,0.8640167117118835
1814232672,17373,frankvicky,2024-10-24T04:36:33Z,"yes, we need to clean up the zk-related configurations. i plan to split this into a separate jira and pr, as previously discussed with . wdyt ? [a link]",0,0.9934493899345398
1814233350,17373,frankvicky,2024-10-24T04:37:34Z,i have opened a pr for it #17588,0,0.9920532703399658
1814236919,17373,frankvicky,2024-10-24T04:43:17Z,"since this line is directly linked to a file in the `trunk` branch, a better solution might be to modify the document after this pr gets merged. i can file a jira to track this modification if you agree. wdyt?",0,0.9929947257041931
1819719894,17373,ppkarwasz,2024-10-28T20:35:35Z,"the bnd annotations are intentionally in the `provided` maven scope of all log4j artifacts, so that these annotations with `class` retention do not end up in the runtime classpath. you can do the same and add them as `compileonly` in gradle. the compiler warnings should disappear once [a link] is fixed. untile then we will remove the outdated ones (see apache/logging-log4j2#3133) in the next log4j release, which should remove the warning on `level`.",0,0.9928867220878601
1819769400,17373,ppkarwasz,2024-10-28T21:12:45Z,the switch from the legacy to the new configuration format can be based on the presence of specific files: [code block],0,0.99444180727005
1819834263,17373,ppkarwasz,2024-10-28T22:07:16Z,"have you considered switching to a structured configuration format like xml or yaml? the properties configuration format is not the default one and is not even one of the original ones (it appeared in version 2.4). it has [a link] to make it easier to read, but also harder to understand. the xml format does not require additional dependencies. yaml only requires [a link] that will only take an additional 400 kib in kafka's distribution. in yaml the configuration file would look like: [code block]",0,0.9896356463432312
1820021534,17373,frankvicky,2024-10-29T03:08:13Z,"hi , thanks for your feedback! :grinning_face_with_smiling_eyes: as you mentioned, the `.properties` file format indeed has a drawback of understand. i actually struggled when trying to transform the `.properties` file from log4j1 to log4j2 -- it was really painful to understand its meaning and transform them at same time. the yml format looks nice and is more readable, but changing the configuration format might require further discussion, especially since it would introduce additional dependencies to the project. i will file a jira to initiate a discussion on this.",1,0.9946021437644958
1820025144,17373,frankvicky,2024-10-29T03:14:32Z,[a link] c.c.,0,0.9937654733657837
1820029662,17373,frankvicky,2024-10-29T03:22:31Z,thanks for the information. i have already changed its scope to compile time. ptal :grinning_face_with_smiling_eyes:,1,0.9950363039970398
1820546264,17373,mimaison,2024-10-29T10:36:02Z,"as long as we still support the old properties format, we can consider switching to a new format if users provide a log4j2 configuration file. i think it's worth starting a thread on the dev list to explain our options and gather some feedback.",0,0.9776188135147095
1820760649,17373,ppkarwasz,2024-10-29T13:06:21Z,", to be precise, users will **always** be able to use the configuration format of their choice, regardless of the format adopted by kafka. the choice of the configuration file format mostly concerns the **default** configuration files shipped in the `*.tar.gz` archive. if kafka ships with a `log4j2.properties` file, users will feel forced to use that one and that is imho a terrible format to work with. i have opened a [a link] to start a discussion about the subject. **ps**: there is currently a primitive [a link] that allows users to automatically convert a `log4j.properties` files into a `log4j2.xml` file. i am currently working on extending the list of formats that can be automatically converted (cf. [a link] but i will probably not have time to support the quirky `log4j2.properties` format.",-1,0.9403189420700073
1820849781,17373,mimaison,2024-10-29T13:52:44Z,"i understand what you mean. my point was that some users may have built custom `log4j.properties` files and run clusters with those, and we want that to continue working. for the new log4j2 files, then yes it makes sense to evaluate the different formats. thanks for opening a thread, it's very useful to get input from an apache logging pmc member to help us make decisions.",1,0.9859041571617126
1820856701,17373,frankvicky,2024-10-29T13:55:50Z,i have file a jira for it. [a link],0,0.9948897361755371
1824026165,17373,ppkarwasz,2024-10-31T07:51:37Z,"this looks pretty much as a maintenance headache for the apache kafka team. what will happen if the user switches logging implementation (at least 3 logging implementations are supported by the log4j api, see [a link]? it looks to me that you only use this for jmx. if that is the case, log4j core provides an [a link]. you just need to enable it, since jmx is a potential source of security problems and is disabled by default. if you need to get and set the levels for other reasons, please open a thread on `dev`. users like to change logger levels programmatically so often, that we'd better offer an implementation independent api for that.",-1,0.8005328178405762
1824185851,17373,mimaison,2024-10-31T10:00:05Z,this is used by kafka connect. we have a rest api that allows changing the log level of all instances in a kafka connect cluster. see [a link] for the details.,0,0.9944027066230774
1824901568,17373,ppkarwasz,2024-10-31T17:41:09Z,"we can probably reach a consensus in the logging pmc to release a new log4j configuration api, that you can use to abstract from the internals of the logging implementation (see [a link]. what is the planned release date for kafka 4.x? if you wait until the end of the year, this class might not be necessary.",0,0.993984043598175
1825368063,17373,frankvicky,2024-11-01T02:42:16Z,"hi currently, ak 4.0 release is scheduled at january 29th 2025. for further details, you can refer to the release plan: [a link]",0,0.985554039478302
1832983990,17373,ppkarwasz,2024-11-07T16:26:28Z,"[code block] by default log events are mutable and bound to one thread. they are cleared as soon as the logging call exits. there is a [a link] that you can store in a [a link] on the test classpath, but it is easier to just take an immutable snapshot. you can also replace `logcaptureappender` with [a link] from the [a link]. you can set it up with a config like: ```xml",0,0.9906750321388245
1833659727,17373,frankvicky,2024-11-08T03:51:30Z,"very appreciate! i have applied it and tested it locally; it works like a charm. as for replacing `logcaptureappender`, i think it's a great idea. imho, leveraging an existing tool is better than building our own. i will file a jira to initiate a discussion on this.",1,0.9970331192016602
1843386874,17373,showuon,2024-11-15T08:39:46Z,nit: i thought we'll honor log4j2.properties when both log4j2.properties and log4j.properties exist. no?,0,0.9173361659049988
1843393551,17373,frankvicky,2024-11-15T08:45:31Z,"make sense. yes, we can change the order of the if-case to achieve that. i will update it in a follow-up pr.",0,0.9893139004707336
1843491362,17373,ppkarwasz,2024-11-15T09:44:53Z,"i think that `log4j.properties` should have a higher priority than `log4j2.properties`: - fresh installations of kafka 4.x will only have a `log4j2.properties` file. - if we find a `log4j.properties` file, it means that it is either an upgraded installation of kafka or the user copied their customized configuration.",0,0.9867204427719116
1843502542,17373,showuon,2024-11-15T09:51:16Z,"hmm... it makes sense. already, let's keep the log4j.properties as the highest priority. thanks.",1,0.9635087847709656
1843597095,17373,mimaison,2024-11-15T11:01:29Z,why do you want to do it in a separate pr? if we merge as is we instruct users to go check `clients/src/test/resources/log4j2.properties` but instead link to another file. if we update the comment we need to update the link.,0,0.9922515749931335
1843599782,17373,mimaison,2024-11-15T11:04:00Z,why do we recommend creating an xml file? should we point to the migration guide and to the log4j2 example file kafka will have under `config`,0,0.9936797618865967
1843600763,17373,mimaison,2024-11-15T11:05:00Z,same in the other scripts,0,0.9899835586547852
1843603382,17373,mimaison,2024-11-15T11:07:32Z,would `connectconfig` be a better name?,0,0.9905452728271484
1843606711,17373,mimaison,2024-11-15T11:10:35Z,we since removed zookeeper from the existing log4j properties files in trunk ([a link] so let's not re-add zookeeper stuff to remove it again later.,0,0.9943547248840332
1843610478,17373,mimaison,2024-11-15T11:14:24Z,let's keep the newline,0,0.9921257495880127
1843613244,17373,mimaison,2024-11-15T11:17:00Z,we can remove this new line to make it clearer the comment applies to both `org.apache.kafka.consumer` and `org.apache.kafka.coordinator.group`,0,0.9948931932449341
1843628839,17373,mimaison,2024-11-15T11:26:47Z,why are we adding this method? this looks like a rebase issue.,0,0.9902320504188538
1843629078,17373,mimaison,2024-11-15T11:27:02Z,let's keep the new line.,0,0.98689866065979
1843630758,17373,mimaison,2024-11-15T11:28:36Z,is this file still used?,0,0.9943909049034119
1843631728,17373,mimaison,2024-11-15T11:29:38Z,can we import `logmanager`?,0,0.995417594909668
1843633651,17373,mimaison,2024-11-15T11:31:29Z,nit: i know dependencies are not fully ordered but can we insert it roughly where it should be in the list instead of appending at the end.,0,0.9924537539482117
1843640613,17373,mimaison,2024-11-15T11:38:23Z,let's keep the new line. same in a few other files,0,0.9946727156639099
1843652254,17373,mimaison,2024-11-15T11:50:16Z,do we really need this as `implementation`? this is make it part of our release artifact.,0,0.9909976720809937
1843962004,17373,mimaison,2024-11-15T15:02:54Z,"this effectively changes the behavior of the `/admin/loggers` endpoint of the connect rest api. the endpoints accept the logger name in the path `/admin/loggers/{name}`. if the root logger is the empty string, it's not possible to query it anymore. i wonder if we should still expose the root logger as `root` (i assume it's possible to rename it somewhere here or in `loggingresource`). cc wdyt",0,0.9921947717666626
1843981241,17373,frankvicky,2024-11-15T15:14:27Z,i will see if we could avoid it be included in release artifact,0,0.9889911413192749
1844010558,17373,frankvicky,2024-11-15T15:24:06Z,"yes, it looks have a module name prefix is a little bit silly.",-1,0.9312840104103088
1844089662,17373,frankvicky,2024-11-15T15:51:09Z,make sense. i will apply it in next commit,0,0.9775141477584839
1844097109,17373,frankvicky,2024-11-15T15:56:43Z,yes... it seems that this method has been removed in `trunk`. i will remove it in next commit.,0,0.9885940551757812
1844099567,17373,frankvicky,2024-11-15T15:58:30Z,it seems that it's not in use based on ide hint. i will remove it and build to see if we could remove this one.,0,0.9896653294563293
1845315012,17373,dongjinleekr,2024-11-17T07:20:30Z,"**we should retain the root logger's name as `root`, against log4j2's naming change.** here is the comment from [a link]: to maintain compatibility with kafka connect's rest api, we need to use `root` to indicate the root logger. since the log4j2 logger names are generally `{package}.{class}` form, defining a `root` named logger is almost not reasonable. so, we don't need to be concerned about it. long time no see :smiley: since it is not mentioned in the [a link], so i will add a subsection explaining this design decision. i got some vacation this week! :smiling_face_with_halo:",1,0.7635826468467712
1845315796,17373,frankvicky,2024-11-17T07:24:38Z,very appreciate your explanation. i will modify it in the next commit. :grinning_cat:,1,0.9963139891624451
1846332278,17373,mimaison,2024-11-18T10:31:56Z,should we remove connect-log4j.properties?,0,0.9946505427360535
1846332506,17373,mimaison,2024-11-18T10:32:07Z,should we remove log4j.properties?,0,0.9941838383674622
1846355549,17373,frankvicky,2024-11-18T10:43:48Z,i think it's fine now since our script has sufficient protection. it should work well when upgrading from the old version. i will delete these two configurations in the next commit.,1,0.6090408563613892
1846417125,17373,mimaison,2024-11-18T11:20:49Z,yes because otherwise we default to the log4j file so you get the warning everytime you run a command: [code block],0,0.993255615234375
1846550136,17373,chia7712,2024-11-18T13:04:11Z,we don't need to recreate collection - [code block],0,0.995200514793396
1846556605,17373,chia7712,2024-11-18T13:09:17Z,"why don't we keep the `root` compatibility here? after this pr, users can't set 'root=warn' to change the root level.",0,0.989332914352417
1846632146,17373,chia7712,2024-11-18T13:55:54Z,we need to keep the null handle to avoid npe,0,0.9930199980735779
1847704612,17373,chia7712,2024-11-19T06:20:06Z,do they use the same reference? or we should use `!equals` instead of `!=`?,0,0.9923095703125
1847704673,17373,chia7712,2024-11-19T06:20:11Z,ditto,0,0.9754701256752014
1847752728,17373,chia7712,2024-11-19T07:11:00Z,please fix the `connect.py` [a link] [a link],0,0.9956113696098328
1847767385,17373,chia7712,2024-11-19T07:24:24Z,`compileonly` is good enough i think as we don't use the annotation in runtime,0,0.9631183743476868
1847776149,17373,chia7712,2024-11-19T07:28:48Z,could you please remove this method also?,0,0.9940369129180908
1847864958,17373,chia7712,2024-11-19T08:12:33Z,`replicationquotastestrig` has similar code [a link] could we delete it in this pr too?,0,0.9953599572181702
1847870812,17373,chia7712,2024-11-19T08:17:09Z,do we really need `log4j1bridge2api`?,0,0.9945671558380127
1847872407,17373,chia7712,2024-11-19T08:18:21Z,please remove it from [a link] too,0,0.9890663623809814
1847873077,17373,chia7712,2024-11-19T08:18:50Z,ditto [a link],0,0.9932494163513184
1847874109,17373,chia7712,2024-11-19T08:19:37Z,please add it to `license-binary` file,0,0.9952186942100525
1847964777,17373,frankvicky,2024-11-19T09:21:34Z,"some apis rely on it, such as `propertyconfigurator`. however, since we are removing it, we might not need the log4j bridge anymore. i will test this locally.",0,0.9934490323066711
1848323271,17373,dongjinleekr,2024-11-19T13:03:22Z,"when i worked on this issue last, it was required to support the log4j 1.x configuration file.",0,0.9930018782615662
1848672753,17373,chia7712,2024-11-19T16:23:18Z,"in the e2e we could run kafak on different version, so we must check the version before applying the config file.",0,0.9916872382164001
1848672880,17373,chia7712,2024-11-19T16:23:22Z,ditto,0,0.9754701256752014
1848672960,17373,chia7712,2024-11-19T16:23:25Z,ditto,0,0.9754701256752014
1850373880,17373,chia7712,2024-11-20T14:02:53Z,"it seems connect e2e does not run different version for workers, so you can just change them to `connect_log4j2.yaml`. however, please change the `-dlog4j.configuration` to `-dlog4j2.configurationfile`",0,0.9923579096794128
1850375006,17373,chia7712,2024-11-20T14:03:41Z,please noted that the previous version should use `-dlog4j.configuration` and trunk version should use `-dlog4j2.configurationfile`,0,0.9930484294891357
1850378575,17373,chia7712,2024-11-20T14:05:59Z,please add `filepattern`,0,0.9958797693252563
1850514477,17373,ppkarwasz,2024-11-20T15:21:56Z,"since there is only one triggering policy, there is no need to wrap it in a [a link]. btw: there is a typo in the plugin name: it should be `policies`, instead of `polices`.",0,0.9943270087242126
1850545236,17373,frankvicky,2024-11-20T15:35:32Z,thanks for information :grinning_face_with_smiling_eyes:,1,0.9930192828178406
1850570634,17373,frankvicky,2024-11-20T15:50:47Z,it seems that tons of code needs to apply this change. i will prepare it asap.,0,0.9841576218605042
1860858017,17373,mimaison,2024-11-27T15:23:24Z,"with the current code, updating connect loggers does not work. for example, i get: [code block] we should not return an unmodifiablelist here. in the `loggers()` method above we call `add()` on the `list`. here is the stack trace: [code block]",0,0.993435263633728
1864432648,17373,chia7712,2024-11-30T18:52:38Z,"`get_log4j_config_for_connect(node)` does not point to the ""full"" path, so all related services can't start up as it fails to find the log4j2 config. please use `os.path.join(self.persistent_root, get_log4j_config_for_connect(node))` instead",0,0.9940447211265564
1864432755,17373,chia7712,2024-11-30T18:53:07Z,"ditto. `get_log4j_config_for_connect(node)` is a file name rather than full path. please use `os.path.join(self.persistent_root, get_log4j_config_for_connect(node))` instead",0,0.9932776093482971
1864432782,17373,chia7712,2024-11-30T18:53:14Z,ditto,0,0.9754701256752014
1864435374,17373,chia7712,2024-11-30T19:03:51Z,i don't think those configs file are existent. please remove it,0,0.982956051826477
1864435870,17373,chia7712,2024-11-30T19:06:10Z,"ditto. use `os.path.join(self.persistent_root, get_log4j_config(node))` instead",0,0.9929341077804565
1864435899,17373,chia7712,2024-11-30T19:06:25Z,"ditto. use `os.path.join(self.persistent_root, get_log4j_config(node))` instead",0,0.9929341077804565
1864456124,17373,chia7712,2024-11-30T19:42:15Z,why do we override the config path? it breaks all e2e since the custom log4j config can't be used.,0,0.9810556769371033
1864456149,17373,chia7712,2024-11-30T19:42:24Z,ditto,0,0.9754701256752014
1864456157,17373,chia7712,2024-11-30T19:42:27Z,ditto,0,0.9754701256752014
1864457267,17373,chia7712,2024-11-30T19:46:59Z,"im not sure why we override the `kafka_log4j_opts` here. we typically allow users to define custom `kafka_log4j_opts`. moreover, overriding `kafka_log4j_opts` can break many end-to-end tests, as they often create log4j configurations dynamically and pass them through `kafka_log4j_opts` noted that we do not require users to strictly use the path `$base_dir/../config/log4j2.xml`.",0,0.9150212407112122
1864898855,17373,chia7712,2024-12-01T13:45:14Z,please update it as well. the path is incorrect,0,0.9915224313735962
1893936536,17373,ijuma,2024-12-20T13:23:56Z,why did we do this in many files instead of kafka-run-class?,0,0.9893385171890259
1893938757,17373,ijuma,2024-12-20T13:25:55Z,how come these are `implementation` while `slf4jlog4j` is `testimplementation`?,0,0.9801156520843506
1893939705,17373,ijuma,2024-12-20T13:26:48Z,why is this needed?,0,0.9825694561004639
1893947193,17373,ijuma,2024-12-20T13:34:14Z,"two questions: 1. have we tested that this log configuration results in the same output as the previous one? in particular, we should avoid anything that requires collecting a stacktrace to log (we made sure of that for the previous configuration). 2. have we benchmarked the system to make sure there aren't any regressions due to the new logging library? i saw a jira/pr saying that log4j2 has a particularly costly `getlogger` implementation.",0,0.9835991859436035
1894092841,17373,chia7712,2024-12-20T15:45:05Z,[a link] needs it to configure the log level at runtime,0,0.9944753050804138
1894121803,17373,frankvicky,2024-12-20T16:12:03Z,"i added `spotbugs` to address the compiler warnings. while we could suppress these warnings using `-xlint:all,-classfile`, i prefer not to relax compiler checks. ideally, we should avoid depending on core-specific methods altogether. however, that would require thorough pass to our code. i suggest we create a separate jira ticket to track this architectural improvement as a future enhancement. for further details: [a link]",0,0.986777126789093
1894124425,17373,chia7712,2024-12-20T16:14:07Z,"`jacksondatabindyaml` is required to parse yaml config - see [a link] however, it seems we can do a bit cleanup for `jacksondatabindyaml` as not all modules need to add explicit reference",0,0.9935948252677917
1894164970,17373,chia7712,2024-12-20T16:50:29Z,"i will use log4j-2 transform tool to check the config later ([a link] could you please share the commit to me? i trace the history ([a link] and fails to see the fix about ""avoid anything that requires collecting a stacktrace"". according to official docs ([a link] the performance of ""logging"" has no obvious regression. it seems the story is about `getlogger` - [a link] and [a link] - there is already a pr to fix it #17896 - we can discuss the improvement on it.",0,0.9763274192810059
1894238151,17373,ppkarwasz,2024-12-20T18:05:23Z,"at apache logging we had several other issue reports regarding our usage of annotations in the `provided` scope (see [a link] for example). regarding the [a link] that causes this particular problem: - imho the compiler should not issue any warnings if it is missing, since the annotation has a retention of `class` and is totally invisible at runtime. i submitted [a link] to change the compiler's behavior. - log4j core could theoretically move spotbugs annotations from the `provided` to the `compile` scope, but this could cause legal problems, since the annotation library is licensed under lgpl and this can not be changed (see [a link] this is one of the reasons we keep the library in the `provided` scope, so it does not propagate to consumers.",0,0.9808847904205322
1894553541,17373,ijuma,2024-12-21T04:35:02Z,"yeah, the licensing issue is the reason i wanted to avoid using this library at all. can we use a different library for annotations, one that is apache licensed?",0,0.9763374328613281
1894553658,17373,ijuma,2024-12-21T04:36:54Z,"we should perhaps bite the bullet and just make the slf4jlog4j choice for the server (i.e. include it as `implementation`). after all, unless you choose this, some functionality won't work.",0,0.9828853607177734
1898304621,17373,ppkarwasz,2024-12-27T06:48:34Z,"imho the `kafka_ ` artifact should not have these dependencies, these dependencies should be added **only** to the binary kafka distribution. otherwise kafka will leak the log4j core dependencies to its consumers, similarly to what was happening with zookeeper (see [a link]. to add dependencies only to the binary distribution, you could use something similar to apache/eventmesh#4719, i.e. a separate `distonly` gradle configuration. `log4jcontroller` can be rewritten to use log4j core if present or a no-op implementation otherwise, so the log4j core can be declared as an [a link]. **note**: i am working on a `org.apache.logging:logging-admin` artifact (see [a link] that would provide the same functionality as `log4jcontroller`, but in a logging implementation independent way. unfortunately i have a long todo list before i can publish it, so probably it won't be ready for kafka 4.",0,0.985163152217865
1898313661,17373,chia7712,2024-12-27T07:06:32Z,"`log4jcontroller` is used exclusively by the server, so exposing its dependencies should be acceptable.",0,0.9949571490287781
1898356316,17373,ppkarwasz,2024-12-27T08:27:49Z,"in kafka 3.9.0, the dependency on `ch.qos.reload4j:reload4j` is declared `compileonly`: [a link] the dependency is added to the binary distribution in a separate task: [a link] these dependencies should probably be handled in a similar way.",0,0.9934784173965454
1898357031,17373,ppkarwasz,2024-12-27T08:29:30Z,"**note**: no modern library uses log4j 1 in code (they use jcl, slf4j or log4j api), so my guess is that `libs.log4j1bridge2api` could be dropped entirely.",0,0.9914581179618835
1898365578,17373,chia7712,2024-12-27T08:44:31Z,"yes, we can declare them as compileonly and then add them to the distribution. however, the flexibility of replacing the slf4j provider at runtime may break the functionality of log4jcontroller (similar to [a link]. kip-1064 is attempting to use slf4j2's system variable to choose the provider more effectively. pardon me, in the #18290 we decide to allow users to use log4j.properties - so we still need `log4j-1.2-api`, right?",0,0.9928624033927917
1898478552,17373,ppkarwasz,2024-12-27T12:16:27Z,"as far as i can tell, this is the way `log4jcontroller` worked in kafka 3.x: if the optional `ch.qos.reload4j` dependency was absent, the class didn't work. sorry, my mistake.",-1,0.9849409461021423
1898534270,17373,chia7712,2024-12-27T14:12:27Z,"yes, you're right. perhaps we should consider offering similar functionality for other popular slf4j providers, such as logback and jul. wdyt?",0,0.9828435182571411
1898950768,17373,ijuma,2024-12-28T16:39:13Z,"it is true that we previously tried hard to avoid making the logging choice for the maven artifact while making it for the distributed binaries. however, this is brittle and only worked partially. when i tried to fix it in #12148, it caused problems and it was partially reverted (#16260, #16559). also, it's actually bad to silently not support the dynamic logging functionality for the broker (this is _incredibly_ useful in production). so, i think the simplest thing is to make the logging choice explicit for the server modules (the rare user who doesn't want that can still override it with exclusions via their build file) and leave it up to the applications for the client modules. in the future, if there is a way to address these issues, we can change it again. there are two promising and complementary paths: 1. your logging admin library. 2. slf4j2 makes it possible to choose the logging library dynamically instead of via classpath tricks.",0,0.5177157521247864
1898983229,17373,ppkarwasz,2024-12-28T20:04:38Z,"i pushed the draft to apache logging ([a link] and i'll start to actively work on it. probably you can expect a release by end of january/february. in the meantime i can make a pr for kafka, so that `log4jcontroller` fails softly if log4j core is not present. note that choosing the slf4j implementation does not really tell you which logging implementation is being used: except logback, all the other slf4j implementation are bridges between logging apis. if you use `slf4j-jdk14` you don't know which jul implementation is being used and if you use `log4j-slf4j2-impl` you don't know which log4j api implementation is being used.",0,0.9407511949539185
1899049780,17373,chia7712,2024-12-29T02:16:54Z,"yes, it would be great to display accurate error messages!",1,0.9816924333572388
1166622209,13561,divijvaidya,2023-04-14T09:56:51Z,"should this operation be performed in a separate thread pool which can have a defined quota? (similar to how we perform cleaning for local log using separate cleaner/background threads). i am concerned that this may impact the rate of copy to remote if amount of cleaning is large. also, it's perhaps better to have different scaling characteristics for cleaning from remote vs. copying. copying maybe considered urgent since slowness in copying can potentially fill up disk whereas cleaning from remote may be a lower priority activity.",-1,0.536925733089447
1166661016,13561,divijvaidya,2023-04-14T10:28:00Z,"the current logic may cause deletion of more data than anticipated. this is because it is possible to have remote segments satisfying this condition which are not part of the current leadership epoch chain. calculation of totalsizeearliertolocallogstartoffset may include these segments as well and hence, the calculation of totalsize will include local segments + all remote segments (< local log start offset). the calculated totalsize will be actually larger than the actual total size (where actual total size = size of remote + local log for the active epoch chain). this will lead to higher value of remainingbreachedsize than actual and hence, more data gets deleted than necessary. is this making sense? else i can provide an example to explain it better.",0,0.9901257753372192
1166767890,13561,divijvaidya,2023-04-14T12:20:05Z,"we don't need to calculate this for time based retention. right? if yes, can we refactor the code here so that we perform size calculation (since it requires a full scan over all log segments) only when it's required i.e. for size based retention.",0,0.9936918020248413
1166839800,13561,divijvaidya,2023-04-14T13:30:56Z,we are only interested in segments in state copy_segment_finished or delete_segment_started here. right? (delete_segment_started to clean up any stragglers) can we make this more explicit by filtering on them?,0,0.9940046668052673
1166850232,13561,divijvaidya,2023-04-14T13:40:18Z,could we check for `if (iscancelled() || !isleader())` here again please to short circuit this expensive loop during shutdown.,0,0.9913693070411682
1166854317,13561,divijvaidya,2023-04-14T13:44:11Z,"`iscancelled() || !isleader()` also, please add a log which can help operator understand that this was actually cancelled.",0,0.9947110414505005
1166856223,13561,divijvaidya,2023-04-14T13:45:51Z,please guard this update with `isleader()`,0,0.9958997368812561
1166868212,13561,divijvaidya,2023-04-14T13:56:20Z,"unreferenced segments are not only the ones which have a lower epoch that earliest known epoch, they could also be ones which have an epoch that is not part of active epoch chain. how are we handling that?",0,0.9919829964637756
1166876777,13561,divijvaidya,2023-04-14T14:03:57Z,"i would appreciate your response on [a link] where we discussed that even with caching mechanism, warm up of the cache is going to slow down the copying. i agree that this can be discussed outside the scope of this pr but adding the above thread as fyi.",1,0.8318521976470947
1166892667,13561,divijvaidya,2023-04-14T14:13:29Z,do we need this at a warn level?,0,0.9903000593185425
1166896440,13561,divijvaidya,2023-04-14T14:17:00Z,i would suggest to have address local retention in a separate pr. we can limit this pr to handling remote log retention only.,0,0.9919054508209229
1167074461,13561,Hangleton,2023-04-14T16:53:04Z,"hmm, i don't think it is enough to evict the data for epochs < than the current leader's smallest epoch. with unclean leader election, it is possible to have divergence in-between a log prefix and suffix shared by two replicas.",0,0.9775300025939941
1167086128,13561,Hangleton,2023-04-14T17:01:09Z,"hmm, it seems we are iterating over all remote segment metadata every time the expiration task is executed. this could become costly if the rlmm implementation does not cache the said metadata. that could be an explicit implementation constraint for plugin providers. maybe we could also add a small layer a memoization here to avoid traversing the log metadata every time.",0,0.9855839014053345
1180118575,13561,showuon,2023-04-28T08:50:56Z,"good suggestion. but we don't include this part in the original kip, we need another kip to improve it.",1,0.9642030596733093
1180121259,13561,showuon,2023-04-28T08:53:12Z,"we might need to add logs here to describe why we need to update highest offset in remote storage for followers. i think that's for fetch from follower replica feature, right?",0,0.9940235018730164
1180123353,13561,showuon,2023-04-28T08:55:09Z,nit: assume that segments contain size >= 0,0,0.9942169189453125
1180137735,13561,showuon,2023-04-28T09:06:15Z,i agree this could be costly if the rlmm implementation doesn't cache the metadata. but i don't think there's an implementation constraint for plugin providers. they can always cache them in the plugin. i'm thinking it should be enough if we add something about it in the rlmm#listremotelogsegments javadoc.,0,0.9795172214508057
1180254846,13561,divijvaidya,2023-04-28T10:41:45Z,"that is fair. as i mentioned in the [a link], i am fine (and would actually prefer) with creating jiras and tackling the perf related comments outside this pr. with this comment, i wanted to make sure we are aware and are tracking things that need fixing in this code.",0,0.9260064363479614
1181520975,13561,satishd,2023-05-01T11:24:07Z,"this is different from local log deletion. it requires the deletion of segments from local storage which need to really delete the files. but incase of remote storages, it does not wait for the data to be deleted but it marks the file or object for deletion in their respective metadata stores. respective garbage collectors in those storages will take care of deleting the data asynchronously. there is no perf impact for these delete calls as they take a much shorter time than copying segments. it is very unlikely that copying segments get affected because of the deletion of segments. deletion checks are happening in every iteration so there will not be many segments that need to be deleted. anyways, we can discuss this separately in a separate jira. on another note, all this logic will go to unifiedlog in future.",0,0.9687533974647522
1181526976,13561,satishd,2023-05-01T11:41:52Z,"log.retention.<> configs indicate the total amount of log segments that can be stored in remote storage. so, it is not just about the segments only related to the current leader epoch lineage. we need to be careful of removing any unreferenced segments and also should not have any segment leaks in the remote storage incase of unclean leader elections. so, it cleans up any unreferenced segments beyond the earliest leader epoch that are also available for retention checks.",0,0.9824638962745667
1181527119,13561,satishd,2023-05-01T11:42:21Z,we do not need any specific check here as we want to clean up any segment that is not yet deleted including copy_segment_started,0,0.9949623346328735
1181528820,13561,satishd,2023-05-01T11:46:37Z,unreferenced segments within the current leader epoch chain will eventually move earlier to the earliest epoch of the current leader epoch chain after a few retention checks. that will take care of those kinds of segments.,0,0.9919024109840393
1181529149,13561,satishd,2023-05-01T11:47:19Z,"sure, let us discuss this out side of this pr.",0,0.989150881767273
1181532348,13561,satishd,2023-05-01T11:56:03Z,unreferenced segments within the current leader epoch chain will eventually move earlier to the earliest epoch of the current leader epoch chain after a few retention checks. that will take care of those kinds of segments.,0,0.9919024109840393
1181545427,13561,showuon,2023-05-01T12:31:09Z,"it's confusing we update `_locallogstartoffset` twice with different value. i think the one in l982 should be removed, right?",-1,0.7296122312545776
1182338603,13561,Hangleton,2023-05-02T09:53:16Z,"hmm, i am not sure this is the right thing to do, because including segments which are not part of a log yields a size which is not truly that of the log. it is possible to design scenarios with a log chronology which allows for premature deletion of data under size-based retention. while i understand that deleting unreferenced segments is consistent with the local log use case, where some data can be lost too, a key difference here between this approach and the current retention semantics applied for local logs is that in the latter case, all segments belong to the current log when the log size is calculated, so that the size-based retention policy always apply to the current log. eviction of unreferenced segments/data in the local case happens via truncation separately from the enforcement of retention policies. but here, both are retention-based and truncation-driven eviction are _de facto_ combined. what are the benefits of diverging from these semantics with tiered segments?",0,0.6033363342285156
1197648143,13561,Hangleton,2023-05-18T10:16:16Z,"i see, yes that's right those segments will eventually fall out of the range of active leader epochs. that should be fine, as long as users know there is no specific enforcement on the time those unreferenced segments will be cleaned up.",0,0.9830033183097839
1203191600,13561,junrao,2023-05-24T00:10:33Z,unnecessary semicolon. ditto in kafkaserver.,0,0.5476835370063782
1203192234,13561,junrao,2023-05-24T00:11:04Z,missing javadoc for new param.,0,0.9707103371620178
1203194554,13561,junrao,2023-05-24T00:12:15Z,should we exit the loop the first time a remote segment offset passes locallogstartoffset?,0,0.994146466255188
1203195682,13561,junrao,2023-05-24T00:12:59Z,what about overlapping segments between remote and local? do we double count them?,0,0.9888047575950623
1203196737,13561,junrao,2023-05-24T00:13:53Z,are we iterating the same remote segment multiple times since a segment could have multiple epochs?,0,0.9898646473884583
1203197683,13561,junrao,2023-05-24T00:14:43Z,"loggering uses $ notation, which is for scala.",0,0.9922851324081421
1203198445,13561,junrao,2023-05-24T00:15:23Z,"hmm, not sure that i follow the comment.",0,0.7698861360549927
1203200216,13561,junrao,2023-05-24T00:16:50Z,"hmm, logstartoffset could be larger than base offset of the first local segment. so, it seems that we can't just switch to the base offset of the first local segment if remote log is not enabled.",0,0.9857743978500366
1203200822,13561,junrao,2023-05-24T00:17:24Z,should we return here to actually ignore?,0,0.9834167957305908
1203201676,13561,junrao,2023-05-24T00:18:10Z,"yes, agreed. not sure why we need to update _locallogstartoffset here again.",0,0.9888678193092346
1203202960,13561,junrao,2023-05-24T00:19:13Z,"hmm, local retention needs to be bound by last tiered offset, right?",0,0.9796534776687622
1203204099,13561,junrao,2023-05-24T00:20:07Z,"retention time depends on remote storage being enabled, right? ditto in line 2284.",0,0.9920437932014465
1205425110,13561,showuon,2023-05-25T12:13:00Z,"debug(""update {} with remotelogstartoffset: {}"", topicpartition, remotelogstartoffset)",0,0.9929285645484924
1205437354,13561,showuon,2023-05-25T12:20:51Z,additional `$` sign: remote log segment [$]{} ...,0,0.9949199557304382
1209013637,13561,showuon,2023-05-29T07:33:46Z,nit: less than,0,0.9752089381217957
1213100593,13561,satishd,2023-06-01T12:47:30Z,`listremotelogsegments(topicidpartition topicidpartition)` are not returned in any specific order.,0,0.9938441514968872
1213102668,13561,satishd,2023-06-01T12:49:15Z,"`totalsizeearliertolocallogstartoffset` computes only the log segments in remote storage beyond local-log-start-offset. the remaining local log segments size is computed separately. so, there will be no overlapping segments.",0,0.9929322004318237
1213107255,13561,satishd,2023-06-01T12:51:17Z,"no, it is taken care of. when we remove a remote log segment, it also updates that entry in rlmm in synchronous manner. so, rlmm store will remove the entry from respective epoch states.",0,0.9917026162147522
1213107956,13561,satishd,2023-06-01T12:51:51Z,updated the comment to make it more clear.,0,0.9908517003059387
1213112946,13561,satishd,2023-06-01T12:55:34Z,"we already set the locallogstartoffset as max of passed logstartoffset and the first segment's base offset. when remote log is not enabled, `logstartoffset` is set as `locallogstartoffset` as computed above.",0,0.9949028491973877
1213113458,13561,satishd,2023-06-01T12:56:00Z,this is addressed with the latest commits.,0,0.9933335185050964
1222183059,13561,junrao,2023-06-07T21:12:47Z,extra new line,0,0.9933451414108276
1222183119,13561,junrao,2023-06-07T21:12:51Z,extra new line,0,0.9933451414108276
1222183188,13561,junrao,2023-06-07T21:12:57Z,extra new line,0,0.9933451414108276
1222189063,13561,junrao,2023-06-07T21:20:34Z,"let's say there is a remote segment with startoffset 100 and endoffset 200. if the locallogstartoffset is 150, we exclude the remote segment. this means that we are undercounting the size, right?",0,0.990368127822876
1222205974,13561,junrao,2023-06-07T21:43:25Z,"hmm, why do we need a separate retention based on leader epochs? is that not already covered by size/time/startoffset based retention?",0,0.9772909283638
1222283938,13561,junrao,2023-06-07T23:42:27Z,this is already done in `updatelogstartoffset`. do we need to do it here again?,0,0.9955446124076843
1222315217,13561,junrao,2023-06-08T00:38:00Z,we already log the completion of the load loading in logmanager. could we fold this there to avoid double logging?,0,0.9953327775001526
1223300322,13561,junrao,2023-06-08T16:35:58Z,"hmm, this logic doesn't look right. if a client calls `deleterecords`, we call `maybeincrementlogstartoffset` with onlylocallogstartoffsetupdate=false. so, we will go through this branch and update _locallogstartoffset. this will be incorrect if remote log is enabled.",0,0.9399672746658325
1223303905,13561,junrao,2023-06-08T16:39:51Z,is highestoffsetinremotestorage inclusive or exclusive? it would be useful to document that.,0,0.9926174283027649
1223312004,13561,junrao,2023-06-08T16:47:45Z,extra new line,0,0.9933451414108276
1224374293,13561,divijvaidya,2023-06-09T14:22:38Z,please add a debug log here (and other places where we are exiting this function) so that we know while debugging where did we exit the function from.,0,0.9937763214111328
1224420683,13561,divijvaidya,2023-06-09T14:57:29Z,please add an info log on why we exited the function prior to it's completion. it greatly helps debugging when we don't have to guess where the return point was.,0,0.9803903698921204
1226259513,13561,divijvaidya,2023-06-12T08:15:09Z,please add the following check. we don't want to construct an object for retentionsizedata if not required. [code block],0,0.9961853623390198
1226261499,13561,divijvaidya,2023-06-12T08:16:47Z,"please perform an argument validation here. if retentionsize < remainingbreachedsize, then illegalargumentexception. same for retentiontimedata",0,0.9907482266426086
1226268535,13561,divijvaidya,2023-06-12T08:21:09Z,this comment has been addressed in the latest code,0,0.9940748810768127
1226280821,13561,divijvaidya,2023-06-12T08:31:03Z,nit unnecessary else,-1,0.9638580679893494
1226315828,13561,divijvaidya,2023-06-12T08:53:45Z,we need to restore the original value of remainingbreachedsize when remainingbreachedsize < 0? may i suggest re-writing this entire predicate here as: [code block] note that remainingbreachedsize is a member of the class and you don't need to do `retentionsizedata.get().remainingbreachedsize`. also the earlier `if (retentionsizedata.get().remainingbreachedsize > 0) {` is made redundant by the code i suggested.,0,0.9944685697555542
1226433742,13561,divijvaidya,2023-06-12T10:25:03Z,nit s/log size after deletion/local log size after deletion asking so that the reader can disambiguate between log size (which is tiered + local) and local log size.,0,0.9945577383041382
1226467554,13561,divijvaidya,2023-06-12T10:50:38Z,should we ensure that we have acquired the partition `lock` first?,0,0.9943935871124268
1226471102,13561,divijvaidya,2023-06-12T10:53:59Z,this should probably be a error level log because we don't expect to call this method when remote storage is disabled. isn't that right?,0,0.9900031089782715
1226517527,13561,divijvaidya,2023-06-12T11:33:37Z,"we are assuming that the state of local log will remain same from this point to the time we use the information computed here (i.e. totalsizeearliertolocallogstartoffset ) to delete the segments. but that is not true since local retention threads are running concurrently and might have moved the locallogstartoffset by the time we use the `totalsizeearliertolocallogstartoffset` computed here. as an example: ### time instant: t1 locallso = 10 lso = 0 lse = 20 tieredeo = 15 in this case we will calculate `totalsizeearliertolocallogstartoffset` as the size from 0-10. ### time instant: t2 local log retention thread deletes some stuff and updates the locallso=14 ### time instant: t3 when we calculate `long totalsize = log.validlocallogsegmentssize() + totalsizeearliertolocallogstartoffset;` at `buildretentionsizedata`, validlocallogsegmentssize returns data from 14-20 and we say that the total size = totalsizeearliertolocallogstartoffset ( i.e. 0-10) + validlocallogsegmentssize (i.e. 14-20). this leads to data from 11-13 not being counted anywhere. this looks like a bug! we need to re-use the values stores at the beginning of the retention calculation otherwise other threads (local retention threads) may change the values behind the scenes. thoughts?",0,0.992453396320343
1226536841,13561,divijvaidya,2023-06-12T11:50:51Z,"sorry, i am a bit confused here. earlier in the comment [a link] you mentioned that retention size/time configuration applies across all epochs. i.e. if i say retention is 3gb and the total log as per current epoch is 2 gb, but the total data stored in remote +local = 7gb, then i will delete (7-3) = 4gb of data as part of this cleanup. is my understanding correct? if yes, then we seem to be deleting only the current leadership chain here but we are using the breached size from all the epochs calculated earlier. isn't this contradictory?",-1,0.9737508893013
1226538752,13561,divijvaidya,2023-06-12T11:52:40Z,"even if we are not the leader at this stage, we have deleted the logs in remote. shouldn't we still update the metadata?",0,0.9905067682266235
1234978872,13561,satishd,2023-06-20T09:12:40Z,"it is inclusive, updated with the doc describing about the variable.",0,0.9943206310272217
1234980098,13561,satishd,2023-06-20T09:13:45Z,i guess that is fine as retention size is more about the minimum size available in the topic partition. that segment will be deleted when the local-log-start-offset moves in later cycles.,0,0.9795351624488831
1234980957,13561,satishd,2023-06-20T09:14:25Z,"it was updated based on log-start-offset with `updatelogstartoffset`, but local-log-start-offset can be more than that and it will be updated if needed.",0,0.9954861998558044
1246792402,13561,jeqo,2023-06-29T15:29:31Z,"i also find it strange to repeat the mutations of hwm and local log recovery point in both updates, we can pull those two updates into a single method and call it once?",0,0.5093895792961121
1246831654,13561,jeqo,2023-06-29T15:52:44Z,"is it correct to update locallogstartoffset directly, but use updatelogstartoffset method to also update related values (hwm and local log recovery)?",0,0.9938264489173889
1247609605,13561,jeqo,2023-06-30T08:46:28Z,"found this a bit confusing. in main operation `onlylocallogstartoffsetupdate` is false by default, but here we are overriding with `onlylocallogstartoffsetupdate` as true, and methods signature are mainly the same. wouldn't be clearer to use the default method with `onlylocallogstartoffsetupdate=true` instead of creating this private method?",-1,0.7413550019264221
1247799637,13561,jeqo,2023-06-30T12:19:02Z,nit: [code block],0,0.9919844269752502
1247807726,13561,jeqo,2023-06-30T12:28:17Z,"if i'm reading the call path correctly, this is not the case. `handlelogstartoffsetupdate` function is called only at the end of `cleanupexpiredremotelogsegments` that filters out calls from followers. i guess we could either remote the `isleader` validation here, or move this logic within the lambda itself?",0,0.9891132116317749
1247839591,13561,jeqo,2023-06-30T13:03:12Z,maybe worth adding a log message here stating why cleanup is not happening? or maybe just a comment explaining why this scenario may never happen given the low prob that recordversion < 2 is used.,0,0.987506628036499
1247868877,13561,jeqo,2023-06-30T13:30:32Z,could we add a log info here similar to copy? [code block],0,0.9962322115898132
1247878833,13561,jeqo,2023-06-30T13:40:08Z,", could you elaborate a bit more what do you mean by ? is this relying on some specific storage backend implementation?",0,0.9925305247306824
1281564595,13561,showuon,2023-08-02T08:20:58Z,", what satish meant, is in most remote storage case, the deletion api won't wait until data deleted in remote storage, instead, it'll mark file as deleted and return immediately. and run background gc in remote storage to delete the deleted flagged file.",0,0.987453281879425
1281568519,13561,showuon,2023-08-02T08:24:15Z,"i agree with 's suggestion. in this scenario: 1. replica 1 is the leader, and doing remote log segment deletion 2. leadership changed to replica 2 3. replica 1 entering this `handlelogstartoffsetupdate` method under current implementation, we won't update log start offset since it is not the leader anymore. but we should update it! , thoughts?",1,0.7267030477523804
1281575922,13561,showuon,2023-08-02T08:30:07Z,"+1, or at least a debug level.",0,0.9722623825073242
1281648556,13561,showuon,2023-08-02T09:28:21Z,"as commented above, there might be chances that the leadership change during the segment deletion, i think we should update the log start offset before exiting the `cleanupexpiredremotelogsegments` method since if there's no deletion happened, the `logstartoffset` will be empty. wdyt?",0,0.9923564195632935
1281657244,13561,showuon,2023-08-02T09:35:36Z,should we log partition info as below did here?,0,0.9951170682907104
1281660832,13561,showuon,2023-08-02T09:38:41Z,"the comment is not clear: `// segment's first epoch's offset [should] be more than or equal to the respective leader epoch's offset.` the log is not correct: `""[{}] remote segment {}'s first epoch {}'s offset is [less] than leader epoch's offset {}."",`",0,0.9896344542503357
1281664514,13561,showuon,2023-08-02T09:41:56Z,+1,0,0.9816582202911377
1281667417,13561,showuon,2023-08-02T09:44:36Z,why don't we log `reason` here?,0,0.9916799664497375
1281671130,13561,showuon,2023-08-02T09:47:59Z,nit: it's weird to see `local log retention size` when user is not enabled the tiered storage. could we add a if check to see if remote storage is enabled or not and print the log accordingly?,-1,0.9879036545753479
1281672320,13561,satishd,2023-08-02T09:48:59Z,"all the size/time/startoffset handlers run based on the current leaders leader epochs. here, we are removing the segments which have leader epochs earlier to the lowest leader epoch on this broker(partition leader).",0,0.9943219423294067
1281675518,13561,showuon,2023-08-02T09:51:35Z,nice test!,1,0.992967963218689
1281844159,13561,satishd,2023-08-02T12:37:14Z,good point! addressed in the latest commits to keep the logic simpler.,1,0.9911037683486938
1283024088,13561,satishd,2023-08-03T10:50:15Z,it is not mandatory to update it when this node becomes a follower as the existing follower fetch protocol makes sure that the follower truncates their log-start-offset based on the leader's log-start-ffset.,0,0.994259238243103
1284241897,13561,satishd,2023-08-04T10:10:50Z,this is not required as the updated code does not use this method.,0,0.9947649240493774
1284278935,13561,satishd,2023-08-04T10:54:02Z,good catch.,1,0.9776482582092285
1284280124,13561,satishd,2023-08-04T10:55:05Z,replied in the [a link].,0,0.9954043626785278
1287757841,13561,junrao,2023-08-08T22:37:26Z,identation doesn't match other places in this file.,0,0.9763645529747009
1287764297,13561,junrao,2023-08-08T22:50:50Z,"since newlocallogstartoffset is larger than locallogstartoffset(), could we just assign newlocallogstartoffset to _locallogstartoffset?",0,0.9937280416488647
1288778006,13561,junrao,2023-08-09T15:52:12Z,"hmm, i still don't quite understand this part. the leader's epoch chain only gets trimmed from the beginning when segments are deleted due to retention or the advancement of the startoffset by `deleterecord()` call. these are covered by the size/time based retention and logstartoffset based retention. so what additional cases does the following code cover?",0,0.7757911682128906
1288852233,13561,junrao,2023-08-09T16:18:28Z,"here is a corner case. let's say remote log is enabled, but there is no remote segment (all have been deleted due to retention). the new logic will do retention based on `localretentionbytes`, but it should actually do the retention based on `retentionsize`. if that happens, we need to advance logstartoffset, in addition to locallogstartoffset.",0,0.9848862290382385
1288860833,13561,junrao,2023-08-09T16:25:57Z,"hmm, this should be false, right? do we have a test case to cover that?",0,0.9716330766677856
1288884433,13561,junrao,2023-08-09T16:41:47Z,this is an existing issue. but there is one direct reference to `_locallogstartoffset` in `fetchoffsetbytimestamp()`. should we change that to use `locallogstartoffset()` instead?,0,0.9942388534545898
1288898898,13561,junrao,2023-08-09T16:54:23Z,"this doesn't look right. if remote log is not enabled, it seems that we should delete based on logstartoffset, not locallogstartoffset.",-1,0.5345958471298218
1289488513,13561,satishd,2023-08-10T03:08:13Z,"no, this should be true if the remote storage is not enabled as this segment should be eligible based on other checks like `highwatermark >= upperboundoffset && predicate(segment, nextsegmentopt)`. existing tests in `unifiedlogtest`, `logoffsettest`, `logloadertest`, `logcleanertest` already cover those scenarios.",0,0.9936153888702393
1289566534,13561,satishd,2023-08-10T05:25:05Z,local log size is based on the local retention configs and those are always less than or equal to the complete log retention. i'm unclear about the rationale behind retaining data in local storage using an overall retention size where there are no remote log segments. please provide clarification.,0,0.9774811267852783
1289577612,13561,satishd,2023-08-10T05:42:01Z,nice catch! missed it while merging the conflicts.,1,0.9953203797340393
1289595441,13561,satishd,2023-08-10T06:03:07Z,"this covers scenarios where unclean leader election happens and the remote storage contains segments that are earlier to the current leader's leader-epoch-lineage. for ex: the current leader has the current leader-epoch-cache. [code block] but the earlier broker which got replaced with a new broker which has the current leader's leader-epoch lineage. [code block] but these segments did not expire retention and they were not deleted in the remote storage. but these leader epochs are not there in the current leader's leader epoch as it was chosen with unclean leader election. in this case, we need to remove the segments, that exist beyond the current leader epoch lineage. otherwise, they will never be cleaned up and will continue to accumulate in remote storage.",0,0.991524338722229
1291679491,13561,junrao,2023-08-11T18:47:15Z,"while you are here, could you also add the missing javadoc for brokertopicstats?",0,0.9957140684127808
1291681393,13561,junrao,2023-08-11T18:49:53Z,thanks for the explanation. it makes sense to me. could you add a comment that this is needed for unclean leader election?,1,0.9603782296180725
1291690729,13561,junrao,2023-08-11T19:02:54Z,"here is what i mean. ideally, the retention behavior should be unchanged with remote storage. consider the following case without remote storage. let's say retentionsize is 100mb and we have only 1 segment of 90mb. the retention logic won't trigger the deletion of the last segment. now, consider the same situation with remote storage enabled, but no remote segments. if localretention is 20mb, the retention logic will delete last segment of 90mb. since the data is not in remote storage. we have deleted the data a bit earlier than expected. a similar issue exists for time-based retention. if remote storage is enabled, but no remote segments, the time-based retention is now based on localrentiontime, not retentiontime. since the former can be smaller than the latter, it means that we could delete the data earlier than expected.",0,0.9712439775466919
1291693299,13561,junrao,2023-08-11T19:06:35Z,"in that case, the name `issegmenttieredtoremotestorage` is a misnomer. if remote storage is disabled, there shouldn't be any segment tiered to remote storage, yet we are setting this val to true.",0,0.9778525829315186
1291698612,13561,junrao,2023-08-11T19:14:23Z,"space after `if`. also, this logic still doesn't look quite right. if remote log is enabled, it seems that we still want to delete local segments whose offset is smaller than logstartoffset.",0,0.9793344736099243
1292935520,13561,showuon,2023-08-14T03:23:22Z,nice catch!,1,0.9932061433792114
1292967294,13561,satishd,2023-08-14T04:41:20Z,"when remote log is enabled, it deletes the local segments whose offset is <= local-log-start-offset. the existing condition without tiered storage is to delete the local log segments <= log-start-offset.",0,0.9948877692222595
1292967405,13561,satishd,2023-08-14T04:41:39Z,it was implicit from the condition that it is relevant only when remote storage is enabled. i removed the value and added a condition and the respective comments for better clarity.,0,0.9939624667167664
1293066497,13561,showuon,2023-08-14T07:23:37Z,good point! i think it's worth filing a bug in jira. wdyt ?,1,0.9956532716751099
1293071660,13561,showuon,2023-08-14T07:29:21Z,"so you mean, all the segment deletion will happen again in the new leader, and update the log start offset there. ok, make sense.",0,0.991179883480072
1293081560,13561,kamalcph,2023-08-14T07:39:13Z,"in the fetch response, the leader-log-start-offset will be piggy-backed. but, there can be a scenario: 1. leader deleted the remote log segment and updates it's log-start-offset 2. before the replica-2 update it's log-start-offset via fetch-request, the leadership changed to replica-2. 3. there are no more eligible segments to delete from remote. 4. the log-start-offset will be stale (referring to old log-start-offset but the data was already removed from remote) 5. if the consumer starts to read from the beginning of the topic, it will fail to read. i realised the case mentioned by and this one is different. both of them can be handled by the new leader gracefully. we can take this task in a follow-up pr if required.",0,0.9934524297714233
1293086543,13561,kamalcph,2023-08-14T07:44:56Z,"to ensure consistency, similar to local, which marks the segment for deletion (renames the file to .delete) and deletes it after 1 minute. (segment.delete.delay.ms). should we move the log-start-offset before the remote log segment deletion? one way to do this is not to delete the remote log segments in `deleteretentiontimebreachedsegments` and `deleteretentiontimebreachedsegments` and only move the `logstartoffset`. in the next iteration, those remote-log-segments will be removed via `deletelogstartoffsetbreachedsegments`. wdyt?",0,0.9941368103027344
1293158752,13561,kamalcph,2023-08-14T08:31:22Z,statements in l1065 and l1057 are same. typo error?,0,0.9878377914428711
1293179175,13561,satishd,2023-08-14T08:50:26Z,the case mentioned by you can be addressed in a followup pr. please file a jira.,0,0.9954307079315186
1293185679,13561,kamalcph,2023-08-14T08:56:07Z,nit: [code block],0,0.9919844269752502
1293189650,13561,kamalcph,2023-08-14T08:58:39Z,`optional` is not recommended as parameter in java: [a link],0,0.9957962036132812
1293224397,13561,divijvaidya,2023-08-14T09:28:33Z,can you please address this comment. multiple folks have asked me why this code of line exists which makes me believe that a comment explaining the purpose here would be nice.,0,0.8830850720405579
1293244517,13561,divijvaidya,2023-08-14T09:46:56Z,could we please store the value of log.logendoffset() at the beginning of clean up process and use the stored value for all calculations? asking because endoffset may move behind the scenes while we are processing cleaning. the overall idea is that this cleanup should be executing on a snapshot of log state.,0,0.9937446713447571
1293286722,13561,divijvaidya,2023-08-14T10:26:10Z,"isn't it possible for older epoch chain to become the current chain after another unclean election? for example: time t1: leader epoch chain [code block] time t2: unclean leader election occurs where the new leader loses all existing data and starts with new leader epoch [code block] time t3: unclean leader election occurs again but the old leader from t1 becomes new leader (epoch 8). in this case, the current epoch chain will be 0->1->2->8. but we have deleted data from remote already pertaining to 0,1 and 2, even if it was not eligible for deletion based on retention. to remedy this situation, may i suggest that we delete the unreferenced segments ""only"" if we definitely know that they can be cleaned i.e. when they have exceeded the retention time or when the size in remote itself is greater than retention size. i have to check but i believe that local log solves it in a similar manner.",0,0.9912757873535156
1293305304,13561,divijvaidya,2023-08-14T10:43:56Z,"note that same segment may span across multiple epochs. hence, same segment id will be returned multiple times here and we will count it's size multiple times. may i suggest: [code block] also, if you agree that this was a bug, please add a unit test that should have failed.",0,0.9943401217460632
1293325721,13561,divijvaidya,2023-08-14T11:06:09Z,you need to use this to correctly filter out segments at `findoffsetbytimestamp` method as well please.,0,0.9951554536819458
1293327365,13561,divijvaidya,2023-08-14T11:08:05Z,"i believe we already have public accessor functions in logconfig for these. see logconfig.localretentionms(), logconfig.localretentionbytes() and logconfig.remotestorageenable()",0,0.9929888844490051
1293329291,13561,divijvaidya,2023-08-14T11:10:27Z,you can instead use similar methods already present in logconfig. see logconfig.localretentionbytes() and logconfig.localretentionms() (you will probably have to modify them to add new case of `if (config.remotelogconfig.remotestorageenable)`,0,0.9954046010971069
1293332177,13561,divijvaidya,2023-08-14T11:14:01Z,the code in this pr still uses this method. no? what am i missing?,0,0.947036862373352
1293336126,13561,divijvaidya,2023-08-14T11:19:06Z,the current code uses the leader epoch chain to calculate the size. this comment is resolved in latest code.,0,0.9948090314865112
1293345266,13561,satishd,2023-08-14T11:29:59Z,"let me rephrase what you mentioned here retention.bytes= 100mb segment1 - 90mb when remote storage is not enabled, then this segment is not deleted from local log segments becuas eof the retention size check. retention.bytes= 100mb local.retention.bytes= 20mb segment1 - 90mb when remote storage is enabled, and there are no segments uploaded to remote storage. that means it will not allow this segment to be deleted as it is not yet copied to remote storage based on the introduced check in this pr. if it is copied to remote storage, that means it is not an active segment and there are one or more local segments after this segment. this segment will be eligible for deletion based on the local retention policy as it is already copied to remote storage earlier. am i missing anything here?",0,0.9929008483886719
1293402836,13561,nikramakrishnan,2023-08-14T12:36:13Z,+1. we should add this check to [a link] to ensure we select the segment with correct leader lineage.,0,0.9900907278060913
1293823449,13561,junrao,2023-08-14T18:24:26Z,should we do the same for retentionmsbreach to log whether the retention time is for local retention or not?,0,0.9924225211143494
1293851913,13561,junrao,2023-08-14T18:55:48Z,"we want to be a bit careful of using this method. leaderepochcache is mostly derived from the data in the log. however, on new leader epoch from a leader change, the new leader also appends the new epoch to leaderepochcache before any record is appended for the epoch. this could cause a slight mis-match between the epoch chain in the remote segment and leaderepochcache. for example, it's possible for a leaderepochcache to have 10 100 11 200 //no record appended for epoch 11 12 200 where a segment's epoch chain only has 10 100 12 200 we don't want to prevent the remote segment from being deleted through the retention logic because of this slight mismatch on leader epoch chain. does the code allow for this?",0,0.956039309501648
1293857043,13561,junrao,2023-08-14T19:00:04Z,"yes, it just means that the segment won't be deleted until it's uploaded to the remote store. but this is probably ok.",0,0.9604625701904297
1293857107,13561,junrao,2023-08-14T19:00:09Z,": sorry, i didn't give the right example. this is the case. without remote storage, retention.bytes= 100mb segment1 - 200mb we will delete segment1 (even if it's the active segment). with remote storage, retention.bytes= 100mb local.retention.bytes= 20mb segment1 - 200mb if segment1 is the active segment, it won't be deleted until it rolls and is uploaded to the remote store. it's a very subtle difference.",-1,0.9530215263366699
1294602887,13561,satishd,2023-08-15T13:33:11Z,"i do not find a strong reason not to use optional as an argument. :) in the same so link, few other opinions on why it is a weak argument. optional as an argument is used in several other places within this project. i do not have strong opinions and i am fine if we decide to go with that rule across the project when there is a consensus. we can revisit it when we do that.",1,0.9941573143005371
1294603142,13561,satishd,2023-08-15T13:33:25Z,good catch!,1,0.9941828846931458
1294604024,13561,satishd,2023-08-15T13:34:15Z,what is the rationale for this suggestion?,0,0.9891775250434875
1294618085,13561,jeqo,2023-08-15T13:45:28Z,"could we elaborate what's the purpose of this validation? iiuc `(totalsize - retentionsize) > retentionsize`, are we validating that totalsize is not higher than 2 times `retentionsize`?",0,0.9928992986679077
1294843843,13561,satishd,2023-08-15T16:25:07Z,this method is used only from `locally` block and it does not require taking any lock. we moved this method inside the locally block to avoid any confusion and future usage outside of that.,0,0.9947524070739746
1295387916,13561,satishd,2023-08-16T05:15:50Z,"good catch! it was changed while refactoring, added uts to cover that in the latest commits.",1,0.9956607222557068
1295394486,13561,kamalcph,2023-08-16T05:28:16Z,filed kafka-15351 and kafka-15352 to track the cases.,0,0.9916228652000427
1295402786,13561,kamalcph,2023-08-16T05:42:48Z,"for clean code, it creates an anonymous extra class at every usage and we should try to avoid this pattern. [a link]",0,0.990429162979126
1295607067,13561,satishd,2023-08-16T09:09:02Z,"thanks for the clarification. in the above case with remote storage enabled, it will eventually be deleted from local and remote storages, and updates log-start-offset and local-log-start-offset respectively.",1,0.929192841053009
1295670320,13561,satishd,2023-08-16T10:02:58Z,"thanks for the clarification, good to know about that.",1,0.9694448113441467
1295701347,13561,satishd,2023-08-16T10:33:17Z,"thanks jun for pointing it out. currently, segment epochs are created from leader epoch cache truncated with start and end offsets. but i added defensive checks to filter the epoch with empty records as they will not have any records/messages in the segments. these changes with uts added in the latest commits.",1,0.9457865953445435
1295713103,13561,satishd,2023-08-16T10:45:11Z,follower replicas do truncation based on leader epoch lineage and catch up with the leader. it is hard to know whether a particular lineage can exist in any of the replicas as replicas can fail and it is hard to say whether a particular replica can come back with in a specific duration. that may cause leakages in remote storage. follower replicas can not delete the remote segments as these may be part of the current leader and it may delete the data that is expected by the leader. the tradeoff taken in case of unclean leader election here is to clean up the epoch lineage earlier to the current leader epoch instead of creating segment leakages in remote storage.,0,0.9872792959213257
1296218455,13561,junrao,2023-08-16T17:19:11Z,this can be simplified a bit to `.foreach{ log => ...}`. ditto for the same code in brokerserver.,0,0.9940904974937439
1296221075,13561,junrao,2023-08-16T17:22:01Z,"yes, i agree that it's not a large and common issue. so, we can leave it as it is for now.",0,0.9729962944984436
1296264710,13561,divijvaidya,2023-08-16T18:04:46Z,"correct, that is why we should not be deleting data that we are unsure about. it's a durability loss! in a trade-off situation, wouldn't we want to trade-off in favour of durability instead of remote storage leak (which can be gc'ed by rsm implementation for such cases). one way to solve is it is to delete the data that we know for sure is ready for deletion, e.g. if we have 10mb of data in remote store for non-active lineage and retention size is 2mb, then we can safely delete the rest of the 8mb. this is because even if this leadership chain becomes active, it will adhere to retention size. in other words, i am not saying that we should not delete non-active lineage data in remote store. i am saying that the non-active lineage data should only be deleted if it when it is violating the retention policies. if we have time based retention, this will ensure that there are no leaks. if we have size based retention, then we can do what you are suggesting. i will not consider this comment as blocking to merge this pr since this is in early access but we should document this risk of data loss as part of release notes and try to arrive at a conclusion before production release. thoughts ?",0,0.9657085537910461
1296731885,13561,satishd,2023-08-17T06:27:15Z,it is hard or impossible to find the non-active lineage deterministically as the failed host can have any subset of the non active lineage. determining which epoch/segments can be marked for deletion under such circumstances is not feasible.,0,0.9711158871650696
1296732476,13561,satishd,2023-08-17T06:27:58Z,"in case of unclean leader election, there is already a durability loss when a non in-sync replica needs to be chosen as a leader and given preference to availability. the approach taken in this pr uses the current tradeoff of durability loss and avoids remote log segment leaks. this is slightly different from local log cleanup which we can clarify in the release notes. retention/cleanup logic spread across multiple layers(outside of kafka) poses significant risks and could lead to more extensive problems. so, it is better that to be handled by kafka's retention mechanism. we will discuss further on finalizing the approach before we make this feature production ready.",0,0.9859069585800171
1297576757,13561,junrao,2023-08-17T18:11:51Z,"hmm, should we use `remotelogenabled()` instead of `config.remotelogconfig.remotestorageenable`? ditto for `localretentionsize`.",0,0.9812114238739014
1297580311,13561,junrao,2023-08-17T18:15:41Z,"has a good point. when doing unclean leader election, the new leader (even if unclean) should still have access to the remote data. so, it probably should never lose that portion of the data?",1,0.7200224995613098
1298029817,13561,satishd,2023-08-18T05:47:39Z,"that is a fair point. if we want to take that approach, we should not delete any segments beyond the current leader's leader epoch lineage. we need to take the risk of rsm plugins having cleanup mechanisms for the segment leaks in the remote storage. these leaks may accumulate over time and create operational issues. it is hard even for rsm plugin owners to deterministically find out whether a segment is unreferenced when there are out-of-sync/offline replicas. i filed [a link] to continue the discussion and take a final call later before productionizing it.",0,0.8799681663513184
1298640349,13561,junrao,2023-08-18T16:25:11Z,what's the impact to 3.6.0? do we need to outline any limitation with unclean leader election in the release notes?,0,0.9787319898605347
1299184981,13561,satishd,2023-08-19T13:09:53Z,this is only applicable with tiered storage enabled topics. we will add that in the release notes of tiered storage section about the change in the behavior.,0,0.9941860437393188
1299185257,13561,satishd,2023-08-19T13:12:33Z,good point. added the required filtering check `findoffsetbytimestamp` api.,1,0.9786931276321411
1299221576,13561,junrao,2023-08-19T16:58:45Z,what's the behavior of unclean leader election when tiered storage is enabled?,0,0.9774218797683716
1299640804,13561,satishd,2023-08-21T05:55:11Z,"the remote storage retention cleanup mechanism considers cleaning up the remote log segments that have all the records that are created with a leader epoch precedes to the earliest leader epoch in the current leader's leader epoch lineage. in case of unclean leader election, the earlier leader replica may delete the segments that are copied to remote storage but those are not part of its leader epoch lineage but they may be part of out-of-sync or offline follower replicas and they will not be available for consumption.",0,0.9938018918037415
1299988151,13561,jeqo,2023-08-21T11:33:03Z,"similar to the previous comment on rentetionsizedata: `cleanupuntilms` represents a point in time (`now - retentionms`), while `retentionms` represents a duration (e.g. 1 week in millis). is this comparison correct/needed? if i'm reading this right, this will always be true.",0,0.9908583760261536
1300055517,13561,divijvaidya,2023-08-21T12:39:26Z,"this takes an assumption that the partition has continuous monotonically increasing offsets. but it is not true for a topic that was historically compacted (i.e. compaction is turned off now, that is why ts is enabled). i would suggest to read the next segment and set the startoffset as the start offset of the next segment.",0,0.9927495718002319
1300176481,13561,satishd,2023-08-21T14:16:28Z,good point. i think we discussed this earlier also. let us address this in a followup pr covering topics changing their retention from compaction to delete only retention. filed [a link],1,0.9378544092178345
1300178242,13561,satishd,2023-08-21T14:17:49Z,this check will be true when using system time. but added this defensive check if we have tests setting the mock time to set any long values.,0,0.9951435327529907
1300199098,13561,divijvaidya,2023-08-21T14:32:48Z,sure. we can address this separately but i think that should be a blocker jira for 3.6. otherwise we are shipping this pr with a known bug which i am not very comfortable with. this bug is also not very edge case-y as others for which we have started jira items such as bugs related to performance instead this bug impacts correctness. do you agree?,0,0.5006818175315857
1300279331,13561,satishd,2023-08-21T15:23:52Z,"yes, this is planned for 3.6.0. i did not want to block this pr with that as we want to unblock other dependent prs, especially integration test prs.",0,0.9932348132133484
1300314011,13561,jeqo,2023-08-21T15:52:59Z,"yeah, but the part i'm missing is why should we throw an exception when this is true. if retention is 1 hour, and `cleanupuntil` is at any point in system time, we are throwing an exception.",0,0.9727727174758911
1300372620,13561,junrao,2023-08-21T16:40:19Z,"hmm, i was just asking about how unclean leader election with tiered storage is handled in 3.6.0. it seems that this pr has removed the logic for retention by leader epoch. in that case, when an unclean leader is elected, does it just use its logendoffset to start writing new data? in that case, do we just hide those remote segments with offsets higher than the new leader's starting logendoffset? will those hidden remote segments be cleaned up eventually?",0,0.9658335447311401
1301361619,13561,satishd,2023-08-22T09:38:39Z,"right, i fixed the validation check. thanks.",1,0.9766793251037598
1304597735,13561,satishd,2023-08-24T16:34:49Z,"syncedup with jun to understand the comment here and clarified them. the retention logic deletes the segments with leader epochs preceding the earliest leader epoch in the current leader. any epochs/offsets which are not there in the current leader epoch lineage but they are within the range, those will be eventually deleted when the current leader's earliest leader epoch moves beyond that. right, it will start writing with its logendoffset with the new epoch. right, they will be eventually removed.",0,0.9941273927688599
1307788374,13561,dopuskh3,2023-08-28T18:52:30Z,"it seems i'm reaching that codepath when running reassignments on my cluster and segment are deleted from remote store despite a huge retention (topic created a few hours ago with 1000h retention). it seems to happen consistently on some partitions when reassigning but not all partitions. my test: i have a test topic with 30 partition configured with 1000h global retention and 2 minutes local retention i have a load tester producing to all partitions evenly i have consumer load tester consuming that topic i regularly reset offsets to earliest on my consumer to test backfilling from tiered storage. my consumer was catching up consuming the backlog and i wanted to upscale my cluster to speed up recovery: i upscaled my cluster from 3 to 12 brokers and reassigned my test topic to all available brokers to have an even leader/follower count per broker. when i triggered the reassignment, the consumer lag dropped on some of my topic partitions: later i tried to reassign back my topic to 3 brokers and the issue happened again. both times in my logs, i've seen a bunch of logs like: [code block] looking at my s3 bucket. the segments prior to my reassignment have been indeed deleted.",0,0.9071381092071533
1308148879,13561,showuon,2023-08-29T03:14:54Z,", thanks for reporting this issue. i've created [a link] for this issue. let's discuss it in jira.",1,0.9841983318328857
1308153773,13561,satishd,2023-08-29T03:26:59Z,thanks for bringing the observed issue here. there are a few more pending changes to be merged which are in review/planned related to this change. i will followup on [a link].,1,0.9562470316886902
1433944692,13561,iit2009060,2023-12-21T11:26:05Z,"i gone through the specific code and realised this is actually not impacting the logic 1. while copying the remote segments , remotelogsegmentmetadata stores endoffset using value from the nextsegment base offset. [a link] 2. in my understanding it will be safe to use same logic for historically compacted topics. let me know if my analysis is correct or not ?",0,0.9486265778541565
1434040959,13561,divijvaidya,2023-12-21T12:52:59Z,yes that is correct. copying functionality is not impacted as discussed in [a link] it's only the read-from-remote that is impacted for the historically compacted topic.,0,0.9924692511558533
194783912,5201,bbejeck,2018-06-12T15:27:28Z,"this class is created to contain common information for repartition operations. there are two types of repartitioning currently. when changing a key in a `kstream`s method (`map`, `flatmap` `selectkey` etc) or when performing a `ktable.groupby` operation. the former is eligible for optimization, while the `ktable.groupby` is not.",0,0.9907755255699158
194784561,5201,bbejeck,2018-06-12T15:28:57Z,there are 2 difference between the repartition operations the first is the `serializer` and `deserializer` required,0,0.9948186278343201
194784918,5201,bbejeck,2018-06-12T15:29:54Z,the second difference between repartition operations is the name used to wire up the repartitioning processor.,0,0.9934983253479004
194785793,5201,bbejeck,2018-06-12T15:32:15Z,this class was created to represent the _**non optimizable**_ repartition resulting from a `ktable.groupby` operation,0,0.9936224818229675
194786010,5201,bbejeck,2018-06-12T15:32:50Z,same class just moved to `graph` package,0,0.9947388768196106
194786478,5201,bbejeck,2018-06-12T15:33:53Z,this class represents a repartition operation that _**is eligible**_ to get optimized away.,0,0.9924119114875793
194787418,5201,bbejeck,2018-06-12T15:36:26Z,"the class is the same just moved to a new package. this is the same for all graph objects, so i won't continue to repeat this comment.",0,0.9907442927360535
194790053,5201,bbejeck,2018-06-12T15:43:10Z,"created to represent `ktable` operations (`filter`, `transformvalues`, `mapvalues`)",0,0.995201826095581
194791681,5201,bbejeck,2018-06-12T15:47:39Z,"for now, this includes the recent changes from (pr #5163) for optional re-use of source topic as changelog topic. this optimization will get folded into this pr in a follow-up push.",0,0.9935883283615112
198283461,5201,vvcephei,2018-06-26T20:18:55Z,it seems like this is happening twice; once inside `addchildnode` and once outside it. (also applies to other occurrences),0,0.9909761548042297
198285554,5201,vvcephei,2018-06-26T20:26:02Z,nit: could be final ;),0,0.95778888463974
198287289,5201,vvcephei,2018-06-26T20:31:43Z,i think these are never referenced. is there still more to do?,0,0.9814731478691101
198289563,5201,vvcephei,2018-06-26T20:39:02Z,"this is a bit beside the point, but do we actually need this? it's unused in our codebase. do we expect users to subclass `abstractstream`? i think the question is applicable; i'm still hoping we could finish disentangling the internaltopologybuilder from the streamsgraph and internalstreamsbuilder.",0,0.9706921577453613
198289936,5201,vvcephei,2018-06-26T20:40:14Z,"also, on line 76, we're taking note of which nodes need to be copartitioned. do we need to capture this information in the streamsgraph as well?",0,0.9948758482933044
198290842,5201,vvcephei,2018-06-26T20:43:08Z,"aside from these two usages, the only other purpose that the internaltopologybuilder serves in the streamsbuilder hierarchy is to add state stores. i think that if we add this to the logical plan first, then we could completely decouple the internaltopologybuilder from the internalstreamsbuilder.",0,0.9904306530952454
198291738,5201,vvcephei,2018-06-26T20:45:53Z,"might be nice to throw an exception if this check fails. it would clearly be a mistake, and it might be nicer for it to break than to do nothing. (i'm specifically thinking if the builder is created, built, modified, and built again; the second modification would just be lost.)",0,0.8967082500457764
198293629,5201,vvcephei,2018-06-26T20:52:24Z,nit: many variables in here can be final.,0,0.985981822013855
198294005,5201,vvcephei,2018-06-26T20:53:34Z,this field is never used.,0,0.989831805229187
198294951,5201,vvcephei,2018-06-26T20:56:39Z,"i wasn't sure why the `nodeidcomparator` implements `serializable`. if it doesn't need to, then you can get rid of that class and that field and just do: [code block]",0,0.9761650562286377
198294955,5201,mjsax,2018-06-26T20:56:39Z,"if we remove the `null` check, should we add one in the constructor?",0,0.9940553903579712
198295985,5201,mjsax,2018-06-26T21:00:04Z,why remove `final`?,0,0.9837685227394104
198297056,5201,mjsax,2018-06-26T21:04:17Z,nit: add `final`,0,0.9956295490264893
198298276,5201,mjsax,2018-06-26T21:08:19Z,don't understand the log statement? something missing there?,0,0.912426233291626
198298348,5201,mjsax,2018-06-26T21:08:34Z,nit: add `final`,0,0.9956295490264893
198298794,5201,mjsax,2018-06-26T21:10:23Z,nit: add `final` (seems some more in the next lines),0,0.9957839846611023
198299478,5201,mjsax,2018-06-26T21:12:21Z,nit: move after the following `if` (we not' need to get the `keychangingnode` if we `continue`,0,0.9946897029876709
198299936,5201,mjsax,2018-06-26T21:14:03Z,"which ""streamsgraphnode"" ?",0,0.995144248008728
198301439,5201,vvcephei,2018-06-26T21:19:52Z,super minor nit: i thought the code style says to always put arguments on a new line when splitting args over multiple lines. i only bring this up because i've been doing it that way...,0,0.5774352550506592
198302388,5201,vvcephei,2018-06-26T21:23:31Z,final?,0,0.9858836531639099
198304292,5201,mjsax,2018-06-26T21:30:43Z,why do we need this here?,0,0.9809044003486633
198306976,5201,mjsax,2018-06-26T21:41:28Z,nit: can we use variable instead of getting the names multiple times?,0,0.987728476524353
198307864,5201,mjsax,2018-06-26T21:45:01Z,why this renaming?,0,0.9664271473884583
198308379,5201,mjsax,2018-06-26T21:47:18Z,"nit: simplify `multipleparentnames` -> `parentnames` (`names` is already plural, should be good enough). im wondering, it it might be better to track the parents in `streamsgraphnode` ?",0,0.9934565424919128
198308755,5201,mjsax,2018-06-26T21:49:00Z,when could this be `null`?,0,0.9929526448249817
198308922,5201,mjsax,2018-06-26T21:49:33Z,when would this be not empty?,0,0.9871008396148682
198310099,5201,mjsax,2018-06-26T21:54:40Z,"why doe we assume, that a stateful operator has always one parent? what about a materialized table-table join?",0,0.9866744875907898
198310662,5201,mjsax,2018-06-26T21:57:09Z,nit: remove empty line,0,0.9923680424690247
198311099,5201,mjsax,2018-06-26T21:59:19Z,nit: introduce variable to get name only once?,0,0.986140251159668
198311844,5201,mjsax,2018-06-26T22:02:37Z,"this is done for both join, right? (ie, update comment?)",0,0.9946278929710388
198312036,5201,mjsax,2018-06-26T22:03:28Z,nit: `steam - table join [only]`,0,0.9950149655342102
198312756,5201,mjsax,2018-06-26T22:06:45Z,"why do we need this check? it seem that `parentnode` cannot be `null`, and that it would be `this` always, too? (assuming one parent node, what is not generic)",0,0.9896349310874939
198312832,5201,mjsax,2018-06-26T22:07:10Z,as above.,0,0.9881609678268433
198313052,5201,mjsax,2018-06-26T22:08:18Z,"why not extend `statefulprocessornode` ? why remove the generic type? can't it be windowed, too? what about custom stores in `transform()` ?",0,0.9926583170890808
198313486,5201,mjsax,2018-06-26T22:10:19Z,nit: add `final`,0,0.9956295490264893
198314691,5201,mjsax,2018-06-26T22:15:52Z,"would it be better to put a generic ` ` her and change to `tablesourcenode `? also, should we take `builder.windowedtable()` into account already? pretty sure the kip will be accepted.",0,0.9693874716758728
198319640,5201,mjsax,2018-06-26T22:40:51Z,nit: `final`,0,0.9944268465042114
198320164,5201,mjsax,2018-06-26T22:43:53Z,as above,0,0.9888283014297485
198368837,5201,guozhangwang,2018-06-27T05:14:07Z,"this is added for users that want to extend `abstractstream`, one use case of it is [a link] regarding `internaltopologybuilder` and `internalstreamsbuilder`: we need to pass in `internaltopologybuilder` into the `streamsgraphnode` because their `writetotopology` (this is the one that translates the logical node into one or more physical nodes) needs it, and those graph nodes are accessed from the `internalstreamsbuilder`, so i think we still need to let it hold a reference of the `internaltopologybuilder` anyways.",0,0.9938226938247681
198368989,5201,guozhangwang,2018-06-27T05:15:10Z,+1,0,0.9816582202911377
198369331,5201,guozhangwang,2018-06-27T05:18:00Z,"if they are used for the optimization rules that are to be added later, we should remove them from this pr. i'm now not so sure if wants to add the optimizations in this pr, but i'd suggest we do it in a forth one given the current pr is pretty large already.",0,0.9610884785652161
198369849,5201,guozhangwang,2018-06-27T05:22:25Z,"if users call `streamsbuilder#build()` multiple times, which we cannot forbid programmatically, we should still only call this function once; on the other hand, if users add a few more operations into the streams topology and then call `build()` again we should probably re-run optimization and generate a new topology, i.e.: [code block]",0,0.9915453791618347
198369989,5201,guozhangwang,2018-06-27T05:23:37Z,"+1, if we are not going to write / serialize the logical plan anywhere we do not need to do that.",0,0.9675614833831787
198370646,5201,guozhangwang,2018-06-27T05:29:03Z,kgroupedtableimpl also have a duplicated `createrepartitionnode`.,0,0.9930500984191895
198370821,5201,guozhangwang,2018-06-27T05:30:05Z,may need some more explanation of this optimization rule.,0,0.9811129570007324
198370939,5201,guozhangwang,2018-06-27T05:31:08Z,"meta comment: if we are going to add more optimization rules in `optimize()`, should we keep this pr as a plain one that do not enforce any optimizations, so that we can then consider each function separately, that helps more concentrated reviews and reduce large pr burdens.",0,0.9930054545402527
198371994,5201,guozhangwang,2018-06-27T05:38:31Z,this is nice cleanup.,1,0.9572017788887024
198372212,5201,guozhangwang,2018-06-27T05:40:13Z,meta comment: seems we have migrated the node classes in a previous pr so could you update the description of this pr to remove the statement that we changed the package here?,0,0.995354413986206
198372226,5201,guozhangwang,2018-06-27T05:40:20Z,+1,0,0.9816582202911377
198372742,5201,guozhangwang,2018-06-27T05:44:19Z,should we override this for all the subclasses so that we can have a more informative intermediate logical plan representation for debugging purposes?,0,0.9938648343086243
198372787,5201,guozhangwang,2018-06-27T05:44:40Z,+1.,0,0.9864034652709961
198372943,5201,guozhangwang,2018-06-27T05:45:50Z,"i cannot tell how this includes the source topic reuse logic, could you explain a bit?",0,0.9824278950691223
198933994,5201,bbejeck,2018-06-28T18:04:46Z,ack,0,0.9149930477142334
198937951,5201,bbejeck,2018-06-28T18:18:14Z,ack,0,0.9149930477142334
198938045,5201,bbejeck,2018-06-28T18:18:33Z,ack merge mistake,-1,0.6066552400588989
198938944,5201,bbejeck,2018-06-28T18:21:36Z,ack. removed for now as part 3 is for writing physical plan using graph. part 4 will contain optimization only,0,0.9620563387870789
198939184,5201,bbejeck,2018-06-28T18:22:19Z,same as above will clean up in part 4,0,0.9935991764068604
198939337,5201,bbejeck,2018-06-28T18:22:47Z,same as above,0,0.9918335676193237
198939460,5201,bbejeck,2018-06-28T18:23:08Z,"ack, will clean up in part 4",0,0.9818211197853088
198940600,5201,bbejeck,2018-06-28T18:26:37Z,"the repartition node just created, will clarify in part 4",0,0.9951261281967163
198941179,5201,bbejeck,2018-06-28T18:28:21Z,ack removed,0,0.8774589896202087
198942912,5201,bbejeck,2018-06-28T18:33:21Z,ack,0,0.9149930477142334
198944739,5201,bbejeck,2018-06-28T18:39:12Z,"during work on this pr, i started to consider this name was a better fit if you insist i can revert.",0,0.9846218824386597
198945962,5201,bbejeck,2018-06-28T18:43:21Z,"ack on the name. for now, i'd prefer to leave `parentnames` in the `processornode` as we specifically add multiple parent names in `kstream#merge`. or maybe refactor always to take a list `parentnames` that would simplify the logic edit: i take that back, we want to rely on getting the parent name for the current graph node by calling `parentnode.name()` the multiple parent names comes from the case mentioned above and are needed for the `internalstreamsbuilder` to complete the merge processor, so i'll leave as is for now.",0,0.965297281742096
198950446,5201,bbejeck,2018-06-28T18:57:39Z,"i've removed this line, left over from a previous refactoring.",0,0.9912488460540771
198951509,5201,bbejeck,2018-06-28T19:00:48Z,"only used for merge node, so it's empty most of the time. i'll look to see if i can refactor internally.",0,0.9891340136528015
198952083,5201,bbejeck,2018-06-28T19:03:02Z,"table-table joins are represented in a separate node, `ktablektablejoinnode`. i used a specific node for this case imho there is too much information needed in the table-table join to generalize.",0,0.9628604650497437
198952415,5201,bbejeck,2018-06-28T19:04:17Z,ack,0,0.9149930477142334
198954002,5201,bbejeck,2018-06-28T19:10:24Z,ack,0,0.9149930477142334
198955006,5201,bbejeck,2018-06-28T19:14:43Z,ack,0,0.9149930477142334
198955044,5201,bbejeck,2018-06-28T19:14:52Z,ack,0,0.9149930477142334
198955718,5201,bbejeck,2018-06-28T19:17:29Z,"since the optimization is pushed out to a 4th pr, this method is removed. i'll clean up in 4th pr. the original idea was to prevent any errors by calling `clearchildren` _*after*_ the children of a given parent node have migrated to another parent. probably better to eliminate the checks and document the calling order when updating the graph.",0,0.993452787399292
198955766,5201,bbejeck,2018-06-28T19:17:40Z,same comment from above,0,0.9940935969352722
198960187,5201,bbejeck,2018-06-28T19:33:56Z,ack,0,0.9149930477142334
198963636,5201,bbejeck,2018-06-28T19:47:40Z,"i removed the generic type from the class definition and changed the `materializedinternal` from `s` to `keyvaluestore<bytes, byte[]` as it matches the `materializedinternal` parameter used in `ktable#filter`, `ktable#mapvalues`, `ktable#transformvalues`. i can revert that if you want. looking at `statefulprocessornode` it's only used from `kstream` for `process` and `transform`, but those methods never pass a strore builder or materialized, just store names. what makes sense to me is to refactor `statefulprocessornode` to remove the store builder then have `tableprocessornode` extend `statefulprocessornode` . wdyt? i'm not sure what you mean custom stores in `transform()`, `kstream#transform` takes a list of store names which is captured in the `statefulprocessornode` is that what you are referring to?",0,0.9909849166870117
198964111,5201,bbejeck,2018-06-28T19:49:32Z,ack,0,0.9149930477142334
198970765,5201,bbejeck,2018-06-28T20:14:03Z,"ack, required some other minor changes, you'll have to let me know what you think",0,0.9265812635421753
198972710,5201,bbejeck,2018-06-28T20:20:48Z,"edit: i've put the generic type back, but requires a cast internally, you have to let me know what you think",0,0.9881939888000488
198976922,5201,bbejeck,2018-06-28T20:35:09Z,removed from this pr and delayed to 4th pr with optimization,0,0.9920856356620789
198977076,5201,bbejeck,2018-06-28T20:35:46Z,ack,0,0.9149930477142334
198977160,5201,bbejeck,2018-06-28T20:36:09Z,removed until 4th pr with optimization,0,0.9943174719810486
198977315,5201,bbejeck,2018-06-28T20:36:42Z,this is required by findbugs.,0,0.9952316880226135
198977471,5201,bbejeck,2018-06-28T20:37:15Z,ack,0,0.9149930477142334
198981153,5201,bbejeck,2018-06-28T20:49:36Z,"that was the intent, build once then subsequent calls return the same physical plan from rebuilding. as for updates, i'm thinking the use case would be to build the topology incrementally and call build at the end versus incremental calls to build, in which case the current approach still works.",0,0.9922803640365601
198982348,5201,bbejeck,2018-06-28T20:53:43Z,"this is intentional. today, when a repartition is required, the `internaltopologybuilder` creates a repartition operation and immediately writes it to the physical plan. so we need to capture the repartition as a graph node and pass the new node to the `internalstreamsbuilder` for possible metadata collection for optimization. in other cased graph nodes are created in classes that don't subclass the `abstractstream`.",0,0.9913014769554138
198982978,5201,bbejeck,2018-06-28T20:56:08Z,ack removed optimization in favor of pushing a 4th pr with optimizations only once 3rd pr is merged.,0,0.9594969153404236
199006843,5201,bbejeck,2018-06-28T22:31:33Z,"ack will try to collapse the two in 4th pr, but for now, the `createreparitionnode` is removed from `internalstreamsbuilder` until 4th pr",0,0.974821150302887
199012496,5201,guozhangwang,2018-06-28T23:02:02Z,"hmm.. for step 4) / 5), now the `topologybuilt` would still be true and hence we would return the same topology, but that is incorrect right?",0,0.9472926259040833
199014145,5201,guozhangwang,2018-06-28T23:12:05Z,"could you explain to us a bit more? i'm still scratching my head now on when do we call `abstractstream#addgraphnode` v.s. `parentnode.addchildnode; builder.maybeaddnodeforoptimizationmetadata(repartitionnode);` because their logic are just the same, right?",-1,0.7026395797729492
199272791,5201,mjsax,2018-06-29T20:30:11Z,"i am 51:49 to keep the old name (so, i don't insist in reverting). \cc wdyt?",0,0.9851753115653992
199274082,5201,mjsax,2018-06-29T20:36:06Z,ack. makes sense that `transform` does not apply here as this is a `*table*processornode`.,0,0.9698967337608337
199282205,5201,bbejeck,2018-06-29T21:16:21Z,"yep, i'll have to put some thought into what's relevant without being too spammy",0,0.8107427954673767
199286587,5201,bbejeck,2018-06-29T21:40:26Z,ack updated,0,0.975744366645813
199288962,5201,bbejeck,2018-06-29T21:53:38Z,"what i was thinking of was the developer would build an initial topology with the last statement being the `builder.build()...` then at that point execute the program and observe the printed topology. then go back and update the topology again and run the program a separate time and watch the results. but thinking about it more, that is an opinionated/subjective view of how to develop, and we should not restrict to one style. i'll put something to detect if the topology has changed then rebuild if true.",0,0.9778752326965332
199289400,5201,bbejeck,2018-06-29T21:56:25Z,"i try to follow that as well, but maybe i'm missing something because i thought the args were all on one line here.",0,0.9735988974571228
199291907,5201,bbejeck,2018-06-29T22:11:22Z,"yes, the logic is the same. but `groupedstreamaggregatebuilder` does not subclass `abstractstream` so we need to make those two calls separately. secondly, in the example above we are building 2 graph nodes. the repartition node and the stateful processor node for the aggregation. today when we need to repartition for an aggregation, the `internaltopologybuilder` creates a repartition operation and it becomes the parent of the aggregation operation. so the repartition node needs to be a child of the current `streamsgraphnode` in the `groupedstreamaggregatebuilder` but it must be the parent of the aggregation graph node. does this make sense?",0,0.9895053505897522
205591823,5201,bbejeck,2018-07-26T20:28:02Z,"for removing the restriction of only building topology once, i've decided on the ""traditional"" approach when traversing a graph to only visit (in this case write its contents to the `internaltopologybuilder`) graph nodes not already visited. i feel a similar approach should work with optimization. but since this pr does not include the optimization, i'd prefer to defer any discussions on what will and won't work for multiple `build()` calls until we have the pr for applying the optimization pushed.",0,0.9865173101425171
206391213,5201,guozhangwang,2018-07-31T04:22:32Z,nit: you can configure the ide to turn auto-newline-beyond-column-limit off :),0,0.8969882130622864
206392683,5201,guozhangwang,2018-07-31T04:36:58Z,nit: this.streamsgraphnode can be replaced with parentnode.,0,0.9952216744422913
206393083,5201,guozhangwang,2018-07-31T04:40:49Z,why change collection to set? the former is more generalized right?,0,0.9853412508964539
206393265,5201,guozhangwang,2018-07-31T04:42:32Z,the `streamsgraphnode#internalstreamsbuilder()` seems not used anywhere?,0,0.9947496056556702
206393456,5201,guozhangwang,2018-07-31T04:44:33Z,"ack, lgtm.",0,0.9801328182220459
206395841,5201,guozhangwang,2018-07-31T05:06:50Z,"i know it is cherry-picked from 's pr, but it seems we drops this type information in the logical streamsgraphnode anyways. maybe can comment whether we still need this?",0,0.9913827776908875
206395968,5201,guozhangwang,2018-07-31T05:07:45Z,why we pass `null` before and now we need to pass in the `transformnode`? was it a bug before and we fixed it here?,0,0.9914188385009766
206396093,5201,guozhangwang,2018-07-31T05:08:34Z,nit: `processnode`.,0,0.9913783073425293
206397008,5201,guozhangwang,2018-07-31T05:16:05Z,"the comments here are a bit confusing: line 63 is for both globaltable-stream join and table-stream join, and line 66 is for table-stream join only.",-1,0.6832878589630127
206397146,5201,guozhangwang,2018-07-31T05:17:28Z,nit: selectkeymapnode.,0,0.9948912858963013
206397274,5201,guozhangwang,2018-07-31T05:18:43Z,"we did not add a new logical node here anymore in this pr, is this intentional?",0,0.9940485954284668
206397509,5201,guozhangwang,2018-07-31T05:20:37Z,nit: rename to `parentgraphnode`.,0,0.9928544163703918
206398136,5201,guozhangwang,2018-07-31T05:26:19Z,"these four graph nodes: thiswindowedstreamsnode, thisstreamsgraphnode, otherwindowedstreamsnode, otherstreamsgraphnode, seems not needed any more since we now use an ""umbrella"" joingraphnode that contains all the information, right? ditto for other join implementations. if it is indeed the case, then i'm wondering why our unit test does not fail, as it will unnecessarily add more processor nodes, and hence should cause some unit test to fail.",0,0.9372645616531372
206399370,5201,guozhangwang,2018-07-31T05:36:22Z,nit: groupbymapnode.,0,0.9945535659790039
206399786,5201,guozhangwang,2018-07-31T05:39:58Z,should be `optimizablerepartitionnode{ + super.tostring() + }`?,0,0.9946645498275757
206400130,5201,guozhangwang,2018-07-31T05:42:46Z,ditto here.,0,0.9877910614013672
206400597,5201,guozhangwang,2018-07-31T05:46:48Z,nit: since we have another class named `processornode` already could we still name it `statelessprocessornode`?,0,0.9883341789245605
206401093,5201,guozhangwang,2018-07-31T05:50:22Z,"the `streamsgraphnode#parentname` and here `parentnames` relationship is a bit awkward, as the only difference is for `merge`. could we just use `parentnames` on the `list streamsgraphnode` directly, and replace `setparentnode` with `addparentnode`. and in all other nodes we just call `addparentnode` only once, while for `merge` we call it twice for each fo the merging streams.",-1,0.5171643495559692
206401149,5201,guozhangwang,2018-07-31T05:50:49Z,see my other comment above: we can replace this logic with the `addparentnode`.,0,0.9948358535766602
206401318,5201,guozhangwang,2018-07-31T05:52:07Z,i think this coding restyle is really not necessary.,0,0.9586918354034424
206401445,5201,guozhangwang,2018-07-31T05:53:16Z,"just to be general enough, we should just loop over all parent nodes from the list and add all their node names here.",0,0.9898734092712402
206401533,5201,guozhangwang,2018-07-31T05:53:56Z,why changing collection to list?,0,0.9882735013961792
206401753,5201,guozhangwang,2018-07-31T05:55:37Z,for line 35 above: see my other comment: `internalstreamsbuilder` seems not used anywhere.,0,0.9929158687591553
206402166,5201,guozhangwang,2018-07-31T05:58:28Z,"ditto above: if we take the underlying `streamsgraphnode` to have `list of parentnodes`, then for all such callers we will generalize to loop over all parent nodes and add their node names. although for now we will only have two parents for `merge`, and one parent for any other types.",0,0.9926119446754456
206402321,5201,guozhangwang,2018-07-31T05:59:35Z,the `storebuilder` should be templated as `storebuilder `. ditto elsewhere.,0,0.9938315153121948
206402481,5201,guozhangwang,2018-07-31T06:00:44Z,same here.,0,0.9916109442710876
206402673,5201,guozhangwang,2018-07-31T06:02:11Z,should we just do `final processortopology topology = builder.build();` and remove the line below? same elsewhere.,0,0.9945534467697144
206402910,5201,guozhangwang,2018-07-31T06:03:58Z,nit: add final.,0,0.9954712390899658
206566399,5201,vvcephei,2018-07-31T15:06:46Z,nit: alignment is off.,-1,0.9422924518585205
206566569,5201,vvcephei,2018-07-31T15:07:13Z,nit: alignment is off.,-1,0.9422924518585205
206567717,5201,vvcephei,2018-07-31T15:10:00Z,nit: alignment is off.,-1,0.9422924518585205
206567780,5201,vvcephei,2018-07-31T15:10:10Z,nit: alignment is off.,-1,0.9422924518585205
206571206,5201,vvcephei,2018-07-31T15:18:46Z,nit: alignment is off.,-1,0.9422924518585205
206571401,5201,vvcephei,2018-07-31T15:19:13Z,nit: alignment is off.,-1,0.9422924518585205
206574955,5201,bbejeck,2018-07-31T15:28:16Z,ack,0,0.9149930477142334
206575220,5201,vvcephei,2018-07-31T15:28:59Z,"yeah, in this case, the type parameter is unused, and we're also suppressing warnings. i think we can either ditch the parameter or remove the suppression. fwiw, i have a todo after this pr is merged to make another pass to eliminate warnings and unnecessary suppressions, so feel free to just drop the type parameter, and i'll figure out whether the suppression is necessary later on. so as to not expand this pr further.",0,0.9630354642868042
206576264,5201,vvcephei,2018-07-31T15:31:34Z,"we were never actually using the graph before, right? so a missed node might go unnoticed until now, when we actually build the topology from the graph.",0,0.9775962829589844
206576886,5201,vvcephei,2018-07-31T15:33:19Z,this is (and was) a weird line break.,-1,0.9897514581680298
206577284,5201,vvcephei,2018-07-31T15:34:10Z,`notnullkeypredicate`?,0,0.9949447512626648
206586295,5201,bbejeck,2018-07-31T15:57:32Z,ack,0,0.9149930477142334
206586526,5201,bbejeck,2018-07-31T15:58:11Z,"can't recall, i think it was related to changes for optimization implementation, i'll revert for now.",0,0.9504268169403076
206587699,5201,bbejeck,2018-07-31T16:01:11Z,"ack, removed edit: put back for now to avoid findbugs error.",0,0.9816468358039856
206591585,5201,bbejeck,2018-07-31T16:13:05Z,looking from the history looks like it was a bug but fixed here.,0,0.9741408228874207
206591870,5201,bbejeck,2018-07-31T16:14:02Z,ack,0,0.9149930477142334
206596270,5201,bbejeck,2018-07-31T16:27:39Z,"ack, updated",0,0.9736286401748657
206597007,5201,bbejeck,2018-07-31T16:29:54Z,ack,0,0.9149930477142334
206597490,5201,vvcephei,2018-07-31T16:31:23Z,"if so, then this comment would apply to all the other nodes as well.",0,0.9930680990219116
206599239,5201,vvcephei,2018-07-31T16:37:04Z,"i thought it was a little weird previously that `statefulprocessornode` extends `statelessprocessornode`, since subclassing is generally an ""is a"" relationship. so it was previously saying ""statefuprocessornode is a statelessprocessornode"", which is silly of course. maybe we can call it `processorgraphnode` to avoid a collision?",-1,0.9167512655258179
206600066,5201,vvcephei,2018-07-31T16:39:49Z,:+1: i think this was from my misinterpretation of the code style.,0,0.8056627511978149
206601158,5201,bbejeck,2018-07-31T16:43:32Z,"yes, it's intentional. what i found during testing is that we don't need to create a node here. i initially had a logical node at this point, but it never rendered any details for the physical plan, as it's methods on the `kgroupedstreamimpl` that provide details for the next operation of the physical plan, thus we only need to create a new logical node when one of those operations are specified. when i did create a new logical plan node here, it contained no details to render, so i needed to put in checks for `null` `processorparameters`. having a placeholder node was somewhat probalmatic, so instead of a ""dummy"" node which i found to be confusing as well, i removed creating a new node at this point, and imho is better off this way.",0,0.9844321012496948
206603371,5201,vvcephei,2018-07-31T16:50:47Z,duplicate test line?,0,0.9903766512870789
206613580,5201,bbejeck,2018-07-31T17:21:48Z,ack,0,0.9149930477142334
206616617,5201,bbejeck,2018-07-31T17:30:27Z,ack,0,0.9149930477142334
206620359,5201,bbejeck,2018-07-31T17:41:30Z,"ack, reverted",-1,0.5726009011268616
206620751,5201,bbejeck,2018-07-31T17:42:42Z,ack,0,0.9149930477142334
206640577,5201,guozhangwang,2018-07-31T18:41:11Z,"actually, my point is that the private `internalstreamsbuilder` field is not used anywhere either, so we can remove both this field as well as the getter function.",0,0.9923434853553772
206640980,5201,guozhangwang,2018-07-31T18:42:26Z,thanks for confirming :) just want to make sure it is not a regression.,1,0.9961068034172058
206641195,5201,guozhangwang,2018-07-31T18:43:13Z,thanks!,1,0.8631753921508789
206672496,5201,bbejeck,2018-07-31T20:28:50Z,"hmm, i'm not sure. while i agree with you that the `streamsgraphnode#parentname` and here `parentnames` relationship is a bit awkward but i think changing `setparentnode` to `addparentnode` can be equally as awkward. while i'm up for changing this in some way i'd prefer to leave how we establish the parent-child relationship the same, as we'd be making a cross-cutting change for just the `merge` case, and here it's isolated for just `merge`. edit: i get what you are saying, i'll try to change and see if i can get it to work. edit part ii: updated and implemented as you suggested, good call.",-1,0.49568071961402893
206672618,5201,bbejeck,2018-07-31T20:29:12Z,replied above,0,0.9916898012161255
206674028,5201,bbejeck,2018-07-31T20:33:46Z,ack. but i think we need to come together on this as a team.,0,0.7778400182723999
206729312,5201,bbejeck,2018-08-01T01:15:36Z,"ack, done",0,0.5583019256591797
206729719,5201,bbejeck,2018-08-01T01:19:01Z,"out of convenience, reverted",0,0.7086852192878723
206729744,5201,bbejeck,2018-08-01T01:19:15Z,"ack, updated",0,0.9736286401748657
206730023,5201,bbejeck,2018-08-01T01:21:47Z,"i think it's needed for optimization pr, but i'll remove here and will add back if necessary",0,0.9923807978630066
206731569,5201,bbejeck,2018-08-01T01:34:23Z,ack,0,0.9149930477142334
206732565,5201,bbejeck,2018-08-01T01:41:57Z,"actually, we still need both the `streamsbuilder.build()` call returns a `topology` while the `internaltopologybuilder.build()` returns a `processorytopology`. while the method names seem to be a bit overloaded, the terminology and methods pre-date this pr, so maybe we can do a follow-up pr to look at renaming and clarifying things some.",0,0.9884345531463623
206733189,5201,bbejeck,2018-08-01T01:47:36Z,ack,0,0.9149930477142334
206737233,5201,bbejeck,2018-08-01T02:20:55Z,"the graph node is indeed required, and the tests are passing correctly. implementing the join for optimization was possibly the most ""intricate"" detail to get correct. previously when we generated the entire physical plan upfront, the parent names for the two `kstreamjoinwindow` instances were generated inside the `kstreamimpljoin.join` method and passed to the internalstreamsbuilder to wire up the processors. the first pass of the `streamstreamjoinnode` followed this approach, and everything was wired together in one operation. but the problem is with that approach we lose the ability to optimize any join nodes much for the same reason as before, we write everything required for the join to the `internaltopologybuilder` and lose any concept if optimization has occurred and what the new parent node is. either stream involved in a join can be eligible for optimization concerning repartitioning. in that case, we need to be able to use the updated parent node names for either or both of the `kstreamjoinwindow` instances involved in the join. so what has been done here is to add the two `kstreamjoinwindow` instances explicitly as child nodes of the two `kstream` instances passed as parameters from the `dojoin` method. the key point here is that one or both of the original `kstream` instances may have required a repartitioning. this fact requires us to explicitly attach the `kstreamjoinwindow` as a child node of the passed in `kstream` instance so if a repartition optimization does occur; the correct parent name is used by the `kstreamjoinwindow` when the physical plan is written. as for your question of adding too many processors, when traversing the graph the nodes representing the `kstreamjoinwindow` processors have their details written, but in the `streamstreamjoinnode` the previous calls writing the details for the `kstreamjoinwindow` processors out for the physical plan have been removed. thus the number of processors written out in the physical plan is correct.",0,0.9809340834617615
206737456,5201,bbejeck,2018-08-01T02:22:56Z,ack,0,0.9149930477142334
206737468,5201,bbejeck,2018-08-01T02:23:04Z,ack,0,0.9149930477142334
206737593,5201,bbejeck,2018-08-01T02:24:13Z,ack,0,0.9149930477142334
206737755,5201,bbejeck,2018-08-01T02:25:41Z,ack,0,0.9149930477142334
206737805,5201,bbejeck,2018-08-01T02:26:04Z,ack,0,0.9149930477142334
206737992,5201,bbejeck,2018-08-01T02:27:35Z,ack,0,0.9149930477142334
206738254,5201,bbejeck,2018-08-01T02:29:41Z,"ack fixed, need to update intellij formatting",0,0.9597755074501038
206738426,5201,bbejeck,2018-08-01T02:30:29Z,ack,0,0.9149930477142334
206739044,5201,bbejeck,2018-08-01T02:33:00Z,ack,0,0.9149930477142334
206750808,5201,guozhangwang,2018-08-01T04:13:11Z,"ack, thanks for clarifying.",1,0.6852518320083618
206751900,5201,guozhangwang,2018-08-01T04:24:07Z,"my question is that, in this function we call the following `addgraphnode` calls: [code block] and in the returned `kstreamimpl` we passed in `joingraphnode`. note the `parentgraphnode` is passed as the latest node added to the topology for now, and hence it looks like although `thisstreamsgraphnode` and `otherstreamsgraphnode` each added a child, they do not have any parents, and hence these two ""branches"" are sort-of dangling as they are not connected to the topology graph at all.. could you maybe explain a bit more on this logic?",0,0.9779490232467651
206930443,5201,bbejeck,2018-08-01T15:38:42Z,"great question. in building the topology graph, it's not possible for a graph node to not have a parent. it is easier for me to explain the logic best with some examples. first, let's consider no repartitioning [code block] in this case we a repartition did not occur in `dojoin`, so the `thisstreamsgraphnode` and `otherstreamsgraphnode`, from the `lhs` and `other` `kstream` instances respectively, represent the graph nodes for `streama` and `streamb` and the parent node is `root`. anything created directly from the `streambuilder` always has the parent node of `root`. if a `kstream` instance is created by another upstream operation like `builder.stream(""topicb"").filter(...)` , then its parent would be the graph node representing the `filter` operation. in this case in the `thisstreamsgraphnode` and `parentgraphnode` are the same instance, and it ends up with two child nodes, the `thiswindowedstreamsnode` and the `joingraphnode`. i prefer to keep these two nodes separate as we don't need to keep track of repartitioning, i find the logic more clear to use the graph nodes from the `lhs` and `other` `kstream` instances. next repartitioning is required: [code block] now a repartition occurred in `dojoin` and the `thisstreamsgraphnode` is now a repartition graph node, with its parent being the `selectkey` graph node and the grandparent node is the original `streama` graph node. if `streamb` had required a repartition the parent-child structure would be the same, the `otherstreamsgraphnode` would be a repartition node with the parent being the graph node representing the key changing operation and the grandparent node representing the original `streamb` graph node. so at all times the `thisstreamsgraphnode` and `otherstreamsgraphnode` have parents of either `root` or some other upstream `kstream` operation and the `thisstreamsgraphnode` and `otherstreamsgraphnode` need to add the respective window stream processor graph nodes as children, so the physical plan is rendered correctly. does this make sense?",1,0.9731734395027161
1187976451,13639,jeffkbkim,2023-05-08T23:11:16Z,will this be changed to all groups once we begin implementing the old apis?,0,0.9931057095527649
1187980069,13639,jeffkbkim,2023-05-08T23:19:59Z,"nit: ""at least a subset""",0,0.9915441274642944
1187980194,13639,jeffkbkim,2023-05-08T23:20:15Z,"nit: ""the member""",0,0.9941080808639526
1187981608,13639,jeffkbkim,2023-05-08T23:23:38Z,i'm wondering if this would hide the fact that ownedtopicpartitions should not be null.,0,0.9533036947250366
1187987623,13639,jeffkbkim,2023-05-08T23:38:27Z,"nit: ""has a larger member epoch"" a bug in setting the member epoch in the client side or in storing the epoch in the server side would result in the consumer never finding a coordinator right? if the client is expected to update its member epoch only from server side response then it seems that a server side bug would be more likely.",0,0.9886159300804138
1187994938,13639,jeffkbkim,2023-05-08T23:56:47Z,(adding comment to this line since it's related) might be confusing things but shouldn't we include the partitions to revoke in the heartbeat response? i think i remember something along the lines that the consumer will calculate the diff from its view of the owned partitions vs. this heartbeat response and will try to revoke.,0,0.985727846622467
1188015174,13639,jeffkbkim,2023-05-09T00:50:17Z,aren't these thrown in `throwifconsumergroupheartbeatrequestisinvalid` if it's not the first heartbeat request?,0,0.9927712082862854
1188024098,13639,jeffkbkim,2023-05-09T01:14:37Z,"i think adding what reconciliation we're doing at this stage would be helpful. also to confirm, target assignment records are actual diffs from a previous state whereas current assignment record holds the entire state right?",0,0.9890627264976501
1190415641,13639,jolshan,2023-05-10T21:35:49Z,maybe we can explain the mapping here.,0,0.9773095846176147
1190416089,13639,jolshan,2023-05-10T21:36:34Z,(i guess it is just name and assignor though),0,0.9877437949180603
1190417026,13639,jolshan,2023-05-10T21:38:00Z,or will we have another method for generic groups?,0,0.9939002990722656
1190428691,13639,jolshan,2023-05-10T21:56:05Z,what happens if we send an unsupported assignor on any request besides the first?,0,0.9844777584075928
1190433019,13639,jolshan,2023-05-10T22:03:23Z,"maybe slightly off topic, but just for my understanding topicpartitions is a data structure that contains topic id + partitions for that topic? reading this name, it was not immediately clear that these all belonged to the same topic. not a huge deal, but maybe something in naming that we missed and can think about amending in the future.",0,0.8116627931594849
1190436747,13639,jolshan,2023-05-10T22:10:11Z,could we also say we don't match if there is one or more owned partition that is not in the target set?,0,0.9919258952140808
1190445435,13639,jolshan,2023-05-10T22:26:47Z,i'm also a bit concerned by saying this error because it assumes we got a bump from another coordinator and could obscure bugs. it's good the thrown error at least mentions the epoch though.,-1,0.8817864060401917
1190447106,13639,jolshan,2023-05-10T22:30:17Z,how do we continue from this state? do we eventually get a bumped epoch response?,0,0.9863799214363098
1190454574,13639,jolshan,2023-05-10T22:46:37Z,it should be null on every request besides the first one right? this method handles both the first heartbeat and future ones though right? so it needs to handle null and non null fields?,0,0.9911150932312012
1190455545,13639,jolshan,2023-05-10T22:48:44Z,do we expect these changes to happen fairly often? is info a bit high of a log level?,0,0.986778974533081
1190477811,13639,jolshan,2023-05-10T23:38:47Z,"is the incrementing on line 497 the only way groupepoch will be greater than the targetassignmentepoch? this is a little confusing to me since i would expect the target to be higher. i think saying generic ""groupepoch"" also confuses me about the source of the data.",-1,0.5071151852607727
1192164806,13639,clolov,2023-05-12T09:55:14Z,"i am most certainly missing a crucial piece of information, but the only mention i could find of a partition epoch is in the rejected alternatives of [a link]. has the need for this been discussed someplace else so i can have a further read?",0,0.863514244556427
1192170321,13639,dajac,2023-05-12T10:00:38Z,"in this case, i need a method which returns a consumergroup. if we can reuse it, i am fine with this. otherwise, we can use another method and extracts some logic from this one.",0,0.9601209163665771
1192173471,13639,dajac,2023-05-12T10:03:46Z,reworked the comment.,0,0.9920418858528137
1192174161,13639,dajac,2023-05-12T10:04:29Z,`ownedtopicpartitions` can be null.,0,0.9914836287498474
1192179523,13639,dajac,2023-05-12T10:10:14Z,"this scenario could happen if a zombie coordinator is kept around. the consumer could get a higher epoch from the new coordinator and end up talking to the zombie by mistake (based on stale metadata). we did something similar in the controller in the part so i used the same approach here. this seems safe to me as the consumer should only learn a new epoch from the coordinator. of course, in case of a bug, this could become an issue. the alternative would be to be defensive and to fence the member in this case and force it to restart at epoch 0. the benefits of this option is that it is more robust but also more disruptive. should we be conservative in this case?",0,0.9551181793212891
1192180394,13639,dajac,2023-05-12T10:11:09Z,"i think that providing the expected assigned partitions is actually more robust because it forces the consumer to revoke all the other partitions, even the ones that we would not know about on the server side.",0,0.9759977459907532
1192180723,13639,dajac,2023-05-12T10:11:31Z,correct. those could be `null` here as well.,0,0.9834852814674377
1192182531,13639,dajac,2023-05-12T10:13:24Z,reworked the comment.,0,0.9920418858528137
1192184441,13639,dajac,2023-05-12T10:15:39Z,good point. it should be checked there as well.,1,0.9783602952957153
1192188074,13639,dajac,2023-05-12T10:19:34Z,"correct. `topicpartitions` contains a topic id and a list of partition ids. sure, we could consider renaming this.",0,0.986263632774353
1192194658,13639,dajac,2023-05-12T10:27:10Z,right. the member will get a response with the correct epoch.,0,0.9929115176200867
1192195549,13639,dajac,2023-05-12T10:28:12Z,they should be occasional. we log similarly in the current protocol and those logs are really helpful. we can lower them down in the future if they become an issue.,1,0.9134529829025269
1192198495,13639,dajac,2023-05-12T10:31:30Z,"at the moment, this is the only way but other ways will come. i think that it is safe to trigger the computation whenever the group epoch is larger than the target assignment epoch. we bump the group epoch when the group has changed (e.g. new members, new subscriptions, etc.). then, we update the target assignment when we detect that it is older than the group metadata. however, the member epoch should always be lower or equals to the target assignment epoch. regarding ""groupepoch"", i am not sure to understand your point. are you saying that the name is confusing?",0,0.9347478151321411
1192204200,13639,dajac,2023-05-12T10:37:34Z,this is indeed not in the kip because this is an implementation detail. we need to track epoch of partitions in order to know if they are free or not. an epoch with an old epoch basically means that the partition has not been revoked yet.,0,0.9937887787818909
1194138883,13639,jeffkbkim,2023-05-15T17:24:33Z,that's a great point. thanks,1,0.9935368895530701
1194141365,13639,jeffkbkim,2023-05-15T17:27:01Z,maybe topicandpartitions? topic partitions generally is used to refer to topic-partition tuples,0,0.9884178042411804
1194145192,13639,jeffkbkim,2023-05-15T17:31:00Z,"maybe it would be good to include a comment on the relationship between the group, target assignment, and member epochs.",0,0.9837936758995056
1194151379,13639,jeffkbkim,2023-05-15T17:37:05Z,"actually the consumergroup fields, groupepoch and assignmentepoch, already have comments",0,0.9939186573028564
1194171285,13639,jeffkbkim,2023-05-15T17:55:33Z,is there a reason we use expectedsize = 1?,0,0.9944936037063599
1194188439,13639,jolshan,2023-05-15T18:10:17Z,i think the comment makes things a little clearer. but i guess my confusion was it seems like this should always cause the assignment to change. i think i also got a bit confused because on earlier prs i thought that the target assignment epoch was the epoch we get we at at when the assignment is complete. but maybe i am confused somewhere.,0,0.8617038130760193
1194189770,13639,jeffkbkim,2023-05-15T18:10:57Z,should we throw an illegal state exception if new member is null?,0,0.9769341349601746
1194198701,13639,jolshan,2023-05-15T18:17:35Z,is this still a todo? ditto to above.,0,0.9938352108001709
1194201125,13639,jolshan,2023-05-15T18:19:32Z,this method is a bit long and complicated. in the comments (and maybe the javadoc for the method) could we break it up into logical chunks.,0,0.6420348286628723
1194201173,13639,jeffkbkim,2023-05-15T18:19:34Z,"""an"" immutable map",0,0.9923650026321411
1194207204,13639,jeffkbkim,2023-05-15T18:24:06Z,"nit: ""or -1 if the partition does not exist.""",0,0.9841126799583435
1194218869,13639,jolshan,2023-05-15T18:36:19Z,could we be a bit more specific in what each of these replays do? ie. for this one we update or remove a member depending on if the value is null. others set subscription metadata etc. i don't think the class names are enough to explain what each is doing -- especially since the names are so similar.,0,0.9659878015518188
1194225263,13639,jolshan,2023-05-15T18:42:15Z,"when we are in the state between making the assignment and installing it, how do we guard against generating new assignments? is this part of the state transitions?",0,0.9917415380477905
1194246241,13639,jolshan,2023-05-15T18:58:27Z,nit: an,0,0.9782214760780334
1194249412,13639,jolshan,2023-05-15T18:59:35Z,"can we say ""keyed by __""",0,0.9945822358131409
1194251237,13639,jolshan,2023-05-15T19:01:20Z,"this is ""updated"" because the member had changes and we want to use the assignor to make a new assignment?",0,0.9939098358154297
1194252036,13639,jolshan,2023-05-15T19:02:16Z,"nit ""replaces""",0,0.9950822591781616
1194368824,13639,jolshan,2023-05-15T21:13:28Z,i thought the java doc for timelinehashmap doesn't allow null values.,0,0.9804041981697083
1194380191,13639,jolshan,2023-05-15T21:28:27Z,can we reuse computesubscriptionmetadata here?,0,0.9955110549926758
1194394646,13639,jeffkbkim,2023-05-15T21:47:43Z,nit: replaces,0,0.9909120798110962
1194394856,13639,jolshan,2023-05-15T21:48:02Z,are the topic partitions not empty here? (like empty is different than null?),0,0.9908989667892456
1194395409,13639,jeffkbkim,2023-05-15T21:48:58Z,"how's ""computes a new subscription metadata with a member's updated topic subscriptions""?",0,0.9918013215065002
1194397156,13639,jolshan,2023-05-15T21:51:41Z,i see we check for null or !empty.,0,0.9926528930664062
1194404457,13639,jeffkbkim,2023-05-15T21:58:32Z,nit: memberid is more readable for me. also from [a link] have we looked into this?,0,0.9913615584373474
1194427256,13639,jeffkbkim,2023-05-15T22:38:09Z,nit: javadoc on params,0,0.9942377805709839
1194427427,13639,jeffkbkim,2023-05-15T22:38:29Z,nit: javadoc on params,0,0.9942377805709839
1194427551,13639,jeffkbkim,2023-05-15T22:38:45Z,nit: javadoc on params,0,0.9942377805709839
1194427668,13639,jeffkbkim,2023-05-15T22:38:59Z,ditto on javadoc,0,0.9914590120315552
1194427886,13639,jeffkbkim,2023-05-15T22:39:21Z,nit: we can remove this,0,0.9936181306838989
1194430597,13639,jeffkbkim,2023-05-15T22:44:50Z,nit: does this have to be in its own line?,0,0.8864582777023315
1194432103,13639,jeffkbkim,2023-05-15T22:47:50Z,(not completely related) older record types i.e. groupmetadatavalue have camelcase field names. when did we change the format to upper camelcase?,0,0.9909237027168274
1194435189,13639,jeffkbkim,2023-05-15T22:54:06Z,"nit: ""it does not""",0,0.9497173428535461
1194437607,13639,jeffkbkim,2023-05-15T22:58:42Z,what happens if the member id is not empty but the member epoch is 0 to indicate it's a new member? does this mean that the client can choose its member id? i don't think it should right?,0,0.9896003007888794
1194440425,13639,jeffkbkim,2023-05-15T23:04:18Z,nit: i think we should differentiate the member from the memberepoch. the member points to the existing member stored in the consumer group whereas the memberepoch points to the epoch of the member from the heartbeat request,0,0.9856751561164856
1194446025,13639,jeffkbkim,2023-05-15T23:16:30Z,nit: can we add a newline between the if statement and updatedmember?,0,0.9953559637069702
1194447475,13639,jeffkbkim,2023-05-15T23:19:39Z,can we do `for (consumergroupmember member : members.values()) {`?,0,0.9941760301589966
1194449829,13639,jeffkbkim,2023-05-15T23:25:01Z,"more of a comment for `consumergroup.preferredserverassignor()`, but we're iterating through all members to get the preferred assignor, every time we need bump the target assignment epoch. have we considered saving the count?",0,0.9929025769233704
1194455250,13639,jeffkbkim,2023-05-15T23:37:27Z,"we don't perform a reconciliation phase on leave group because once the existing members heartbeat, the metadata manager will notice the bumped groupepoch (l619) and so targetassignmentepoch < groupepoch will trigger the reconciliation. is this correct? why do we need to create target assignment records here then?",0,0.9947423934936523
1194457005,13639,jeffkbkim,2023-05-15T23:41:03Z,"i think targetassignments size does represent the number of members but shouldn't this be ""assignments"" or ""target assignments""?",0,0.987337052822113
1194459578,13639,jeffkbkim,2023-05-15T23:46:13Z,i think we would want at least a way to detect that something is wrong since with the current approach the bug could go unseen.,0,0.9590820074081421
1194463847,13639,jeffkbkim,2023-05-15T23:56:59Z,"what's ""this""? that's right. the target assignment epoch is what every member will try to converge to by revoking/assigning partitions. once we build the target assignment, we bump the target assignment epoch (l532)",0,0.9935919642448425
1194464178,13639,jeffkbkim,2023-05-15T23:57:46Z,i also think that would be very helpful,1,0.8733583688735962
1194465375,13639,jeffkbkim,2023-05-16T00:00:46Z,david can correct me but the coordinator will continue to compute new target assignments even if we're in the process of installing an existing one and the group would try to converge to the latest assignment,0,0.9889780879020691
1194477394,13639,jolshan,2023-05-16T00:27:22Z,"when we bump the group epoch, it seems like we will also always reassign. so i guess i was just trying to figure out if there is a case where the group epoch is different from the assignment epoch.",0,0.981799840927124
1194479029,13639,jolshan,2023-05-16T00:31:08Z,ok. that's what i was expecting to happen. so if that's expected it is fine. i just wonder if it is extra work.,0,0.7633405923843384
1200087476,13639,dajac,2023-05-22T07:39:20Z,"yes, it is. this is part of another pr.",0,0.9908478260040283
1200129689,13639,dajac,2023-05-22T08:15:50Z,ack. let me expand the comments.,0,0.9858580231666565
1200134115,13639,dajac,2023-05-22T08:18:37Z,ack. i plan to rename those records but this will come when my main prs are merged.,0,0.9460002183914185
1200138816,13639,dajac,2023-05-22T08:22:14Z,that's correct.,0,0.9909399747848511
1200143037,13639,dajac,2023-05-22T08:25:37Z,"right. this is ""updated"" because the member may have been updated so we need to use the latest (non-persisted) information from the member to select the correct assignor.",0,0.9922810196876526
1200145207,13639,dajac,2023-05-22T08:27:19Z,right but `compute` gives you `null` if the key is not present.,0,0.988923192024231
1200149162,13639,dajac,2023-05-22T08:30:23Z,`computesubscriptionmetadata` is slightly different so i can't reuse it directly here.,0,0.9907916784286499
1200149897,13639,dajac,2023-05-22T08:30:59Z,the topic partitions should be an empty list when joining or re-joining.,0,0.9938133955001831
1200153306,13639,dajac,2023-05-22T08:33:53Z,i think that i should use `assignedpartitions.size()`.,0,0.9912103414535522
1200154967,13639,dajac,2023-05-22T08:35:12Z,we could.,0,0.9861844182014465
1200227960,13639,dajac,2023-05-22T09:12:37Z,`exist` is a bit misleading here as `-1` is returned if the partition does not have an epoch set.,0,0.9470365047454834
1200233059,13639,dajac,2023-05-22T09:16:45Z,i put it like this to follow the style of the other methods in this file.,0,0.9924606680870056
1200233985,13639,dajac,2023-05-22T09:17:32Z,i think that we have always been using upper camelcase in requests/responses. groupmetadatavalue is likely wrong here.,0,0.9812875390052795
1200235936,13639,dajac,2023-05-22T09:19:07Z,epoch equals to zero does not only indicate a new member. it also indicates a rejoining member. the member could indeed set the member id when it joins but it is not supposed to. it is a small quirk in the protocol.,0,0.9893905520439148
1200237262,13639,dajac,2023-05-22T09:20:08Z,that makes sense. let me use `receivedmemberepoch`.,0,0.9919974207878113
1200239503,13639,dajac,2023-05-22T09:21:58Z,let me put the condition on one line.,0,0.9910150170326233
1200293273,13639,dajac,2023-05-22T10:07:04Z,`memberid` is already used... let me check if keeping a map is worth it.,0,0.9924558401107788
1200402995,13639,dajac,2023-05-22T11:47:16Z,"i think that keeping a map of topicmetadata to member ids does not work because the content of topicmetadata could change as well. however, we could keep a map of topic name to number of subscribers. that would reduce the computation. i did the change. let me know what you think.",0,0.9554806351661682
1200415899,13639,dajac,2023-05-22T11:58:51Z,that's fair. we could remove it.,0,0.9791615009307861
1200462722,13639,dajac,2023-05-22T12:41:30Z,that makes sense. done.,0,0.9706873297691345
1200467372,13639,dajac,2023-05-22T12:45:37Z,it may be better to not do this after all. let me remove it for now in order to be on the safe side. we can always bring it back if we find it useful in the future.,0,0.9825724363327026
1202837929,13639,jolshan,2023-05-23T18:36:53Z,"so across all types of groups (generic, consumer) we can only have one type of group with a given name. we can't have a foo consumer group and a foo generic group. are we also enforcing this when we create groups? looks to be the case if we only create groups via getormaybecreateconsumergroup",0,0.9933503270149231
1202846284,13639,jolshan,2023-05-23T18:43:31Z,i see in the json comments for instance id: `null if not provided or if it didn't change since the last heartbeat; the instance id otherwise.` but this seems inconsistent with what we are saying here. it should only be provided in the first request?,0,0.9907938838005066
1202846585,13639,jolshan,2023-05-23T18:43:45Z,ditto for rack id,0,0.9946533441543579
1203077539,13639,jolshan,2023-05-23T22:08:38Z,"i'm not sure i follow `note the member is the persisted member anytime in this method` are we saying that the member is written to disk? or something else? i think the word ""anytime"" is confusing me.",0,0.5256179571151733
1203079411,13639,jolshan,2023-05-23T22:10:12Z,do we want a log message for the first time joining the group?,0,0.9942014813423157
1203083017,13639,jolshan,2023-05-23T22:13:51Z,do we add a newmembersubscriptionrecord when the member is updated (not new) too?,0,0.9955724477767944
1203084630,13639,jolshan,2023-05-23T22:15:36Z,"i suppose the naming here with ""new"" and the usage below for `newgroupsubscriptionmetadatarecord` confused me.",0,0.9663515686988831
1203119594,13639,jolshan,2023-05-23T22:52:09Z,"rereading this and the kip -- is the only time we have a different assignment epoch from the group epoch is when assignment fails? i also assume that other members should learn about this assignment. i think i'm missing how that is done -- is this through the records methods? so for the next heartbeat request of another member, line 552 would see updatedmember.nextmemberepoch() != targetassignmentepoch as true since the group epoch and assignment epoch would be equal, but the member epoch would still be behind?",0,0.9797250628471375
1203132909,13639,jolshan,2023-05-23T23:08:24Z,would it be useful to have a helper method to delete a member?,0,0.991417646408081
1203150079,13639,jolshan,2023-05-23T23:29:41Z,if the partition did not exist it would also be -1 though right? there's just two possible cases?,0,0.9790266752243042
1203152667,13639,jolshan,2023-05-23T23:32:36Z,"should we also mention in the java doc that we update the assignors here. i know we say in method, but maybe good to mention at the top too. (i was a little confused earlier why we needed both the new and the old members as parameters when this was called in the other class)",0,0.9860978126525879
1203158830,13639,jolshan,2023-05-23T23:40:12Z,is there a reason we use this method instead of put? shouldn't each topic name be absent?,0,0.9913355708122253
1203181594,13639,jolshan,2023-05-24T00:01:53Z,"if we compute and return null, isn't that trying to set null values? or am i missing something.",0,0.9787625670433044
1203184877,13639,jolshan,2023-05-24T00:04:45Z,i guess i'm also wondering why we don't use empty set. unless this is because we want to overload null as mentioned in the getepoch method.,0,0.9683065414428711
1203192959,13639,jolshan,2023-05-24T00:11:42Z,ok so null is not ok -- it must be explicitly empty.,0,0.9880544543266296
1203222949,13639,jolshan,2023-05-24T00:35:51Z,do we also test that the other members also update their assignments?,0,0.9944725632667542
1203224577,13639,jolshan,2023-05-24T00:37:10Z,nit: member 2?,0,0.976658284664154
1203225900,13639,jolshan,2023-05-24T00:38:17Z,i guess we sort of duplicate the code and test in testreconciliationprocess,0,0.9875144958496094
1203578132,13639,dajac,2023-05-24T07:17:06Z,that's right. we enforce this in `getormaybecreateconsumergroup`.,0,0.9916571378707886
1203601651,13639,dajac,2023-05-24T07:33:47Z,good catch. let me fix this.,1,0.9901858568191528
1203610206,13639,dajac,2023-05-24T07:39:48Z,i wanted to callout that `member` is different from `updatedmember` in this method but i think that the names are clear. let me remove that comment. it is more confusing than anything else.,-1,0.5055838823318481
1203610761,13639,dajac,2023-05-24T07:40:12Z,epoch 0 means that a new member joins or an existing member rejoins. let me update the log.,0,0.9932205677032471
1203611994,13639,dajac,2023-05-24T07:41:02Z,`new` means that a new record is created. a new record is created when the member is created or updated.,0,0.9911136031150818
1203615232,13639,dajac,2023-05-24T07:43:16Z,"we already have `consumergroup.removemember(memberid)` but it does not apply here. in this case, we really want to update the member with sentinel values.",0,0.9942029118537903
1203623275,13639,dajac,2023-05-24T07:46:37Z,i have clarified the javadoc.,0,0.9924029111862183
1203625806,13639,dajac,2023-05-24T07:47:54Z,it is a mistake. we can use `put` as you suggested.,0,0.7214706540107727
1203627084,13639,dajac,2023-05-24T07:48:37Z,that's right.,0,0.9873020648956299
1204465047,13639,jeffkbkim,2023-05-24T16:15:47Z,nit: the number of members supporting each server assignor name. is more readable to me,0,0.9915238618850708
1204467377,13639,jeffkbkim,2023-05-24T16:17:36Z,nit: the metadata associated with each subscribed topic name,0,0.99332594871521
1204468514,13639,jeffkbkim,2023-05-24T16:18:36Z,nit: the target assignment per member,0,0.9942153096199036
1204471728,13639,jeffkbkim,2023-05-24T16:21:27Z,"nit: it removes its partition epochs from this map. when a member gets a partition, it adds the epoch to this map.",0,0.9926565289497375
1204475716,13639,jeffkbkim,2023-05-24T16:25:01Z,"for this line and the following couple lines, does expected size of 0 create a hash table with size 1 as it's a power of 2? i'm confused because the expected size intuitively should not be 0.",-1,0.5050303339958191
1204477868,13639,jeffkbkim,2023-05-24T16:27:01Z,"i think justine or someone else may have mentioned in another pr but for getters, just having the ` the current group epoch` makes more sense. i'm not sure if this line adds much value as well as for other getter methods",0,0.9851566553115845
1204492401,13639,jolshan,2023-05-24T16:40:28Z,"ok -- so the idea is member stays the same from when it is first ""gotten"", but updatedmember is the one we change through the method?",0,0.9937445521354675
1204493167,13639,jolshan,2023-05-24T16:41:11Z,i slowly figured this out as i read the pr. :grinning_face_with_sweat: did we also say earlier we were changing the record names?,1,0.9456714391708374
1204494016,13639,jolshan,2023-05-24T16:42:05Z,"yeah, i suppose i was meaning a method to add the sentinel values. but if it is only done here, maybe it is not useful.",0,0.979923665523529
1204494893,13639,jeffkbkim,2023-05-24T16:42:57Z,nit: returns the existing,0,0.9943625926971436
1204509686,13639,jeffkbkim,2023-05-24T16:54:37Z,do you think we should log something if topicimage == null? can both the topicsimage and/or subscribed topic names be outdated here?,0,0.9926474094390869
1204522037,13639,dajac,2023-05-24T17:06:23Z,"yeah, let me try to re-explain it with my words. basically, we have three epochs: the group epoch, the assignment epoch, and each member has its own epoch. - when the group changes (e.g. new member, updated subscription, etc), the group epoch is bumped in order to note that the topology of the group has changed. - when the assignment epoch is smaller than the group epoch, it means that the assignment for the group is stable so we need to recompute it. we generate a new assignment with the epoch matching the group epoch in order to note that the assignment is for the latest group topology. - when a member has a smaller epoch than the assignment epoch, it means that its assignment is stale so we need to reconcile it to converge it to that epoch. all the epochs are equal when the group is stable. this means that all the members have converged to the desired assignment. so for the next heartbeat request of another member, line 552 would see updatedmember.nextmemberepoch() != targetassignmentepoch as true since the group epoch and assignment epoch would be equal, but the member epoch would still be behind? yeah, we could have a difference between the assignment epoch and the group epoch when the assignment is not computed immediately. in the current implementation, we almost never have this but keep in mind that we will support client side assignors. in this case, the computation will take some time so we will see it more. the member learn about their assignment when they heartbeat. this is when we do the reconciliation process. we reconcile a member in two cases: 1) the member is not stable; 2) the target assignment has changed since the last time we reconciled the member. this is done [a link].",0,0.9593720436096191
1204523103,13639,dajac,2023-05-24T17:07:24Z,that's right.,0,0.9873020648956299
1204523524,13639,dajac,2023-05-24T17:07:52Z,i will do this but only when all my code is merged. it will create a mess otherwise...,-1,0.8292766809463501
1204535515,13639,jolshan,2023-05-24T17:19:36Z,i assume if we just got member1's partitions we would still be in assigning state.,0,0.9876733422279358
1204538473,13639,jolshan,2023-05-24T17:22:14Z,or i guess can we just get member1's partitions while member2 is still revoking?,0,0.992827832698822
1204556978,13639,jolshan,2023-05-24T17:38:55Z,"just for my understanding, we will send the same request again when we receive the error. we will already have a group id and member id server side, and we will reuse them. ideally, the assignment works and we continue. is this correct?",0,0.9920231103897095
1204564082,13639,jolshan,2023-05-24T17:46:03Z,would it be helpful to use a new epoch here to see that it changes?,0,0.989870011806488
1204571671,13639,jeffkbkim,2023-05-24T17:52:01Z,"after updating member 1 in l315, we have [code block] in serverassignors. preferredserverassignor() in l317 decrements ""range"" so the copy should have [code block] shouldn't this be `asserttrue(assignor.equals(optional.of(""uniform"")));`?",0,0.9949705004692078
1204579244,13639,jolshan,2023-05-24T17:58:03Z,is there ever a time the next member epoch is not the same as the member epoch?,0,0.9910866618156433
1204582235,13639,jolshan,2023-05-24T18:00:53Z,"would it make sense to also check member states here? i know we had something similar in the other file, but we are also testing the group states here.",0,0.9918705224990845
1204597635,13639,jolshan,2023-05-24T18:17:53Z,"if we have more than one assignor with the same max value, we choose one randomly (based on map iteration order). is this intended?",0,0.9937453269958496
1204599222,13639,jolshan,2023-05-24T18:19:39Z,ah i see this below.,0,0.988528311252594
1204607029,13639,jolshan,2023-05-24T18:26:24Z,preferredserverassignor not modifying the state was really throwing me off here. not sure if comments will help.,-1,0.8464745879173279
1204613085,13639,jolshan,2023-05-24T18:32:41Z,we aren't actually removing member1 here but computing what would happen if we did. this is a bit confusing to follow.,-1,0.659744143486023
1204613762,13639,jolshan,2023-05-24T18:33:21Z,did we mean to have null instead of member3 here?,0,0.9854573607444763
1204623123,13639,jolshan,2023-05-24T18:43:16Z,we have member 2 as range and member 3 as uniform so that's why it is 50/50,0,0.987004816532135
1204872093,13639,jeffkbkim,2023-05-25T00:13:04Z,i am curious as well. i notice 3 places [code block] that both set member epoch and next member epoch to `targetassignmentepoch`,0,0.9657173156738281
1204874200,13639,jeffkbkim,2023-05-25T00:18:00Z,"i'm confused because i was referring to member 2 here: range: 1 (member 2) uniform: 1 (member ~~1~~ 3) after `consumergroup.updatemember(updatedmember1);` in l315. in l317, we call `preferredserverassignor()` which gets a copy, then will decrement the count of ""range"" since member1 (range) is passed in as the oldmember argument. so shouldn't the count for ""range"" be 0? i think i'm missing something",-1,0.5564955472946167
1204875457,13639,jeffkbkim,2023-05-25T00:21:10Z,are we using this variable?,0,0.9935441017150879
1204877037,13639,jeffkbkim,2023-05-25T00:25:13Z,are we using this?,0,0.9927943348884583
1204878528,13639,jeffkbkim,2023-05-25T00:29:01Z,"can we use `targetassignment` and explain the mapping of member id to its assignment? ""assignments"" is ambiguous since we also have current assignments throughout the new protocol.",0,0.9922371506690979
1204879910,13639,jeffkbkim,2023-05-25T00:32:29Z,"btw, i was wondering if we could name this targetassignmentepoch. similar to my comment on `assignments`.",0,0.9845676422119141
1204881034,13639,jeffkbkim,2023-05-25T00:35:20Z,i think we can use put here too right?,0,0.9928534626960754
1204882557,13639,jeffkbkim,2023-05-25T00:39:25Z,are we using this?,0,0.9927943348884583
1204882590,13639,jeffkbkim,2023-05-25T00:39:32Z,are we using this?,0,0.9927943348884583
1204883474,13639,jeffkbkim,2023-05-25T00:41:49Z,"should these be `epoch`s? to me, offset seems more partition related.",0,0.9829786419868469
1204883836,13639,jeffkbkim,2023-05-25T00:42:51Z,i'm noticing a bunch of unused methods. are we planning to use these in the following prs?,0,0.9361366033554077
1204885916,13639,jeffkbkim,2023-05-25T00:48:17Z,we use a record key's raw version in recordhelpers. should we choose a convention to follow?,0,0.9936822652816772
1204889028,13639,jeffkbkim,2023-05-25T00:56:16Z,i think adding a comment above this line to indicate we're now testing a non-new/rejoining member will be helpful. and maybe a comment when we first start testing new/rejoining member's heartbeat requests,0,0.9501451253890991
1204889641,13639,jeffkbkim,2023-05-25T00:57:56Z,this is `topicsimage.empty` right?,0,0.9948979020118713
1204903807,13639,jeffkbkim,2023-05-25T01:29:38Z,"curious, what happens if the member acknowledges but does not actually revoke i.e. a buggy client? would that member and the new owner of the partition fetch from the same partition? i'm guessing there's no guards against that",0,0.9433002471923828
1204907417,13639,jeffkbkim,2023-05-25T01:38:31Z,shouldn't the metadata manager respond with `assignedtopicpartitions`? what happens if the previous heartbeat respond was lost?,0,0.9936717748641968
1204909101,13639,jeffkbkim,2023-05-25T01:42:27Z,ditto on assignedtopicpartitions (and pendingtopicpartitions for member3),0,0.9923852682113647
1204909313,13639,jeffkbkim,2023-05-25T01:42:58Z,the revocation is acknowledging the new assigned partitions revoked from member 1 right?,0,0.9940073490142822
1204910503,13639,jeffkbkim,2023-05-25T01:45:42Z,why is the topic id ordering different here?,0,0.9820578098297119
1204914720,13639,jeffkbkim,2023-05-25T01:55:28Z,i think i'm getting confused here - do we create a new current assignment record whenever we respond back to a member? i might be remembering incorrectly but i thought the current assignment was created when the member transitions to stable (after revoking partitions and acknowledging assigned partitions),0,0.7301397323608398
1205093788,13639,dajac,2023-05-25T07:16:03Z,"from the javadoc of `compute`: [code block] we don't keep the empty set because we want to clean the map. otherwise, it would keep sets for non-existing partitions for instance.",0,0.9929192662239075
1205138023,13639,dajac,2023-05-25T07:57:02Z,right.,0,0.9789980053901672
1205155041,13639,dajac,2023-05-25T08:11:49Z,sure.,0,0.9824982285499573
1205155348,13639,dajac,2023-05-25T08:12:06Z,right.,0,0.9789980053901672
1205156348,13639,dajac,2023-05-25T08:12:57Z,that's correct. -1 is returned when the partition is not in the map. this could be because the partition does not exist or because the partition does not have an epoch yet.,0,0.9934659600257874
1205157172,13639,dajac,2023-05-25T08:13:38Z,"as it is used only once here, it is not worth it in my opinion.",0,0.9238725900650024
1205165820,13639,dajac,2023-05-25T08:21:08Z,"correct. yes, we can. member 3 gets member 1's partitions when the are available but it does not have to wait on member 2.",0,0.9914701581001282
1205169546,13639,dajac,2023-05-25T08:23:21Z,correct. the request will be retried with the group id and the member id (if the member already has one).,0,0.9902186989784241
1205178313,13639,dajac,2023-05-25T08:30:26Z,"that's right. there is only one case where it is not. when a member must revoke partitions, it stays in its current epoch so member epoch is different from the next epoch in this case. the rational of keeping track of the next epoch here is to basically prevent recomputing the state while the member is in revoking state. without it, we would have to recompute it on every heartbeat.",0,0.9889283180236816
1205203837,13639,dajac,2023-05-25T08:51:33Z,make sense.,0,0.9763523936271667
1205211076,13639,dajac,2023-05-25T08:57:20Z,the capacity will be 2 (the min capacity).,0,0.9909855127334595
1205218229,13639,dajac,2023-05-25T09:03:13Z,"i would not because it could be common to not have metadata about a topic yet. this will spam the logs. we will always use the latest topics image that we have got. the subscribed topic names is never outdated as it always represent the subscriptions provided by the consumer. however, it may not be known/exist yet.",0,0.9116010069847107
1205219753,13639,dajac,2023-05-25T09:04:28Z,correct.,0,0.9832404255867004
1205238390,13639,dajac,2023-05-25T09:20:29Z,updated the test. i had a mistake in these.,0,0.8235525488853455
1205239034,13639,dajac,2023-05-25T09:21:03Z,i have renamed it to `computepreferredserverassignor`. now `preferredserverassignor` only returns what the group has.,0,0.9939629435539246
1205239532,13639,dajac,2023-05-25T09:21:29Z,i have put more comments. i hope it helps.,1,0.9475716948509216
1205247698,13639,dajac,2023-05-25T09:25:36Z,nope. let me remove it.,0,0.9870265126228333
1205248818,13639,dajac,2023-05-25T09:26:06Z,nope. removed.,0,0.9702181220054626
1205252133,13639,dajac,2023-05-25T09:28:54Z,nope.,0,0.9715046882629395
1205252262,13639,dajac,2023-05-25T09:29:01Z,nope.,0,0.9715046882629395
1205253148,13639,dajac,2023-05-25T09:29:44Z,right but this is what they are in the end in our context. keeping offset is better here.,0,0.9808601140975952
1205254844,13639,dajac,2023-05-25T09:31:08Z,i have removed all of them but this one. i will use it in the future.,0,0.9813733696937561
1205256385,13639,dajac,2023-05-25T09:32:26Z,"using the constants is fine here. in recordhelpers, i did not use them in order to not change the version by mistake.",0,0.992760181427002
1205264178,13639,dajac,2023-05-25T09:39:07Z,added comments.,0,0.9919648170471191
1205264648,13639,dajac,2023-05-25T09:39:30Z,right.,0,0.9789980053901672
1205266764,13639,dajac,2023-05-25T09:41:24Z,"that's right. this is basically a violation of the protocol. note that the previous owner won't be allowed to commit offsets. we can't do much at this protocol level. however, we could imagine passing the member epoch while fetching so the leader could reject stale member epoch. that would strengthen the overall protocol.",0,0.9673118591308594
1205271089,13639,dajac,2023-05-25T09:45:14Z,"the assignment is only provided in the following cases: 1. the member reported its owned partitions; 2. the member just joined or rejoined to group (epoch equals to zero); 3. the member's assignment has been updated. in the case of a lost response, the client would hit a timeout/network error. in this case, the client is expected to send a ""full"" heartbeat with the owned partitions set so it will get a ""full"" response.",0,0.9944465160369873
1205271405,13639,dajac,2023-05-25T09:45:29Z,see my previous reply.,0,0.9916502237319946
1205273140,13639,dajac,2023-05-25T09:46:58Z,"member 3 has nothing to revoke here. this comment is wrong, let me update it.",0,0.9770658016204834
1205275881,13639,dajac,2023-05-25T09:49:21Z,hmm.. i don't know. let me check this.,0,0.7721275687217712
1205278404,13639,dajac,2023-05-25T09:51:27Z,it is the other way around. we persist the current assignment when it changes based on the reconciliation. we provide the assignment to the client when the current assignment change.,0,0.9940231442451477
1206048854,13639,jolshan,2023-05-25T22:10:08Z,clarified offline -- null returned in compute removes the entry.,0,0.9948099851608276
1206050414,13639,jolshan,2023-05-25T22:13:07Z,that's totally fair. just confirming :),1,0.9750093221664429
1206053946,13639,jolshan,2023-05-25T22:19:58Z,is nextmemberepoch a bit confusing here? it seems more like a target epoch.,0,0.9055944085121155
1206060783,13639,jeffkbkim,2023-05-25T22:33:47Z,nit: group size,0,0.98918217420578
1206063165,13639,jeffkbkim,2023-05-25T22:39:03Z,"do we have a test case for this? i expect that when we accept a request with the previous epoch, we compute the diff from the request's owned partitions and the target assignment and respond to the consumer (assignedtopicpartitions, pending assignment if exists). which would be identical to what we do for the expected member epoch.",0,0.9945576190948486
1206064411,13639,jolshan,2023-05-25T22:41:41Z,this and the server assignor test are much more readable. thanks!,1,0.9851441383361816
1206066309,13639,jeffkbkim,2023-05-25T22:45:49Z,nit: existing and the new target assignment,0,0.9899728298187256
1206317753,13639,dajac,2023-05-26T07:02:21Z,"yeah, i agree. let me use `targetmemberepoch`.",0,0.9792442917823792
1206322259,13639,dajac,2023-05-26T07:07:55Z,"this is covered in `testconsumergroupmemberepochvalidation`. if the member comes with the previous epoch and its owned partitions is a subset of its assigned partitions, we accept it and it goes through the regular process. if nothing has changed since the last heartbeat, it will just receive the current assignment/epoch.",0,0.994341254234314
178980194,4812,guozhangwang,2018-04-03T22:27:42Z,"i think you can still use the log4j format here, e.g. [code block] with four parameters, the last one is auto interpreted as the exception; maybe we can validate if this is the case.",0,0.9900341629981995
178981229,4812,guozhangwang,2018-04-03T22:32:42Z,"if it is a per-thread metric, i'd suggest we pre-register them at the beginning of the application. this way some other tools like `jmxtool` do not need to wait for the object name to show up. wdyt?",0,0.9920346140861511
179188828,4812,vvcephei,2018-04-04T15:42:45Z,"sounds good. i meant to make a comment before you read this to say that there had been a concern in the discussion about having metrics reported from processor nodes (when the proposal was at the node level) that would never actually skip records, thereby polluting the metrics. i thought i'd throw the lazy registration pattern in just to see what you all thought. i'll switch it back to pre-registration.",1,0.7002121806144714
179312182,4812,vvcephei,2018-04-04T23:24:35Z,"confirmed, switching to the variant you mentioned still prints: [code block]",0,0.9939171671867371
179586187,4812,guozhangwang,2018-04-05T20:09:33Z,"same here, we can get rid of `string.format`.",0,0.9935057163238525
179587232,4812,guozhangwang,2018-04-05T20:13:34Z,"we are stripping the prefix for this sensor: is it intentional? note that for jmx reporter, the sensor name would not be included in any fields.",0,0.9930608868598938
179587354,4812,guozhangwang,2018-04-05T20:13:59Z,"`skippedrecordssensor` should not be null, right?",0,0.9924072623252869
179589855,4812,guozhangwang,2018-04-05T20:24:03Z,"nit: flattening to a very long single line, is it intentional?",0,0.9446283578872681
179589896,4812,guozhangwang,2018-04-05T20:24:11Z,ditto below and in other tests like `testpauseresume`,0,0.9948301911354065
179590319,4812,guozhangwang,2018-04-05T20:25:54Z,nit: alignment.,0,0.9897598624229431
179590486,4812,guozhangwang,2018-04-05T20:26:32Z,ditto here.,0,0.9877910614013672
179590561,4812,guozhangwang,2018-04-05T20:26:52Z,ditto here.,0,0.9877910614013672
179590584,4812,guozhangwang,2018-04-05T20:26:58Z,here.,0,0.9713109135627747
179591415,4812,guozhangwang,2018-04-05T20:30:09Z,why do we remove this sensor?,0,0.9915722608566284
179592552,4812,guozhangwang,2018-04-05T20:34:32Z,should we record the thread-level `skipped record` sensor here?,0,0.9947551488876343
179592840,4812,guozhangwang,2018-04-05T20:35:43Z,"hmm.. i did not see we have recorded the sensor for deserialization error here, why this test passed?",0,0.9640689492225647
179626142,4812,vvcephei,2018-04-05T23:17:50Z,"heh, what a coincidence! i think so, and that's actually part of the motivation for this change i'm proposing to the metrics.",1,0.9794198870658875
179627246,4812,vvcephei,2018-04-05T23:26:31Z,"i disabled these tests because part of their function is to verify the number of metrics we register. this currently fails because we're registering a lot more metrics. if we decide to go with this overall strategy, i'll rethink these tests.",0,0.9690917134284973
179627503,4812,guozhangwang,2018-04-05T23:28:22Z,"just `implements internalstreamsmetrics` should be sufficient, since `internalstreamsmetrics` extends `streamsmetrics`?",0,0.9933926463127136
179771434,4812,bbejeck,2018-04-06T14:16:43Z,for `testlatencymetrics` and `testthroughputmetrics` maybe use `` instead ? not a big deal but by getting an `ignored` test count there's a better chance these two tests won't fall through the cracks.,0,0.9702076315879822
179774999,4812,bbejeck,2018-04-06T14:28:05Z,for the `task.addrecords` with a long list of `consumerrecord<>` seems like the only difference with each record is the offset. maybe create a method that takes an `int[]` with offsets and returns a `list `?,0,0.9891341328620911
179775146,4812,vvcephei,2018-04-06T14:28:31Z,"ah, yeah, in an earlier pass they were independent interfaces.",0,0.9822355508804321
179828056,4812,mjsax,2018-04-06T17:42:13Z,nit: remove `this`,0,0.9929719567298889
179828169,4812,mjsax,2018-04-06T17:42:41Z,nit: move `topology` to next line,0,0.9945350885391235
179830023,4812,mjsax,2018-04-06T17:49:58Z,"nit: add `final` to the parameters to cleanup code ""on the side""",0,0.9957141280174255
179830080,4812,mjsax,2018-04-06T17:50:08Z,nit: add `final`,0,0.9956295490264893
179830701,4812,mjsax,2018-04-06T17:52:31Z,"when would `skippedrecordssensor` be `null`? (i know this is just ""move"" code but still wondering why we need this)",0,0.7130725979804993
179831780,4812,vvcephei,2018-04-06T17:56:31Z,"ah, that's how you do it. i tried `(ignore=true)` like testng, but that obviously doesn't work...",0,0.873974084854126
179833851,4812,mjsax,2018-04-06T18:04:32Z,"because `info` level is default, should we remove `sensor.recordinglevel.info` in the above calls?",0,0.9939369559288025
179835194,4812,mjsax,2018-04-06T18:09:51Z,nit: is this suppression necessary? i don't think that gradle builds put a warning -- might be your local ide setting only?,0,0.9878405928611755
179835363,4812,mjsax,2018-04-06T18:10:36Z,nit: do we need this? (cf. my other comment about `suppresswarnings`),0,0.9873582124710083
179835676,4812,mjsax,2018-04-06T18:11:38Z,as above.,0,0.9881609678268433
179835819,4812,mjsax,2018-04-06T18:12:14Z,as above.,0,0.9881609678268433
179836521,4812,mjsax,2018-04-06T18:15:06Z,nit: `topic` -> `partitionsfortopic`,0,0.9931366443634033
179836693,4812,mjsax,2018-04-06T18:15:47Z,nit: `partitions` -> `partitionsforchangelog`,0,0.9920487999916077
179838008,4812,mjsax,2018-04-06T18:20:42Z,very nice!,1,0.9906699657440186
179872407,4812,vvcephei,2018-04-06T20:49:38Z,it won't. that's an artifact that i need to fix.,0,0.8908215165138245
179872830,4812,vvcephei,2018-04-06T20:51:34Z,"meh. i personally favor explicit settings, so if anything, i'd actually add it here, but i'm happy to do whichever you all prefer.",0,0.4894621670246124
179873240,4812,vvcephei,2018-04-06T20:53:25Z,"yeah, i have my ide set on paranoid mode. i can disable this inspection if you don't want to see supressions like this. or i can inline the parameter value, which is what the inspection was complaining about.",0,0.8087481260299683
179873711,4812,vvcephei,2018-04-06T20:55:39Z,"double-brace initialization is actually not great for a number of reasons. i've been terrraforming it whenever i encounter it, but for some reason i decided to suppress this one instead. i'll plan to remove the suppression and the double-brace initialization in the final draft.",0,0.5171234011650085
179873858,4812,vvcephei,2018-04-06T20:56:24Z,thanks!,1,0.8631753921508789
179885340,4812,vvcephei,2018-04-06T21:56:56Z,"during `thread.runonce(-1);`, it'll encounter an exception ""asdfasdfasdf"" as an integer and increment the metric.",0,0.9920755624771118
179885776,4812,vvcephei,2018-04-06T21:59:23Z,it was not. i've fixed it.,0,0.9891208410263062
179886374,4812,vvcephei,2018-04-06T22:03:30Z,fixed.,0,0.9905837774276733
179886390,4812,vvcephei,2018-04-06T22:03:38Z,it was when i made it lazy. i've fixed it.,0,0.9794350862503052
179893704,4812,mjsax,2018-04-06T22:56:44Z,"i am fine with removing the overload that has a default and add info explicitly here. (to me, it's more about consistency---i immediately assume that this sense is different to the others, even if it's not if the code pattern is different).",0,0.9774866700172424
179893837,4812,mjsax,2018-04-06T22:58:03Z,"i personally would prefer getting rid of the annotation -- to me, annotations are noise in the code and distracting.",0,0.6091668009757996
179893976,4812,mjsax,2018-04-06T22:59:10Z,for my own education: why? refactoring is fine with me.,0,0.9851590991020203
179929221,4812,mjsax,2018-04-07T22:12:01Z,why this change?,0,0.9828922748565674
179929312,4812,mjsax,2018-04-07T22:17:23Z,nit: do we need to `[]` around each value? `[]` is used for collections or list -- might be confusing to add them?,0,0.9592486023902893
179929318,4812,mjsax,2018-04-07T22:17:38Z,as above.,0,0.9881609678268433
179929326,4812,mjsax,2018-04-07T22:18:01Z,as above.,0,0.9881609678268433
179929377,4812,mjsax,2018-04-07T22:18:23Z,nit: remove space,0,0.9931873083114624
179929389,4812,mjsax,2018-04-07T22:19:24Z,nit: indention,0,0.9862814545631409
179929538,4812,mjsax,2018-04-07T22:26:03Z,"nit: move `new file` to new line for consistent formatting (note, that `processorstatemanager.checkpoint_file_name)` is second parameter of `file` constructor.",0,0.9946262240409851
179929549,4812,mjsax,2018-04-07T22:26:46Z,as above.,0,0.9881609678268433
179929590,4812,mjsax,2018-04-07T22:28:52Z,did this slip? or did you leave it intentionally?,0,0.9881510734558105
179929609,4812,mjsax,2018-04-07T22:29:56Z,did this slip?,0,0.9252215623855591
179929657,4812,mjsax,2018-04-07T22:33:29Z,"adding this implies, that we have to maintain the same code twice. should we extract this into some internal method that we can call here to avoid code duplication? what about other thread-level metrics?",0,0.9879798889160156
179929685,4812,mjsax,2018-04-07T22:35:09Z,for my own education: what is this? (btw: can we remove `this` below?),0,0.9861494302749634
180160009,4812,bbejeck,2018-04-09T16:50:49Z,"nit: i realize this was pre-existing in a single line, but since there are several parameters, maybe put each param on its own line.",0,0.9893592596054077
180167095,4812,bbejeck,2018-04-09T17:16:08Z,"super nit: what about `asserttrue((double)metrics.metric(skippedratemetric).metricvalue() > 0.0);` however, i don't have a strong opinion in this one.",0,0.8305081129074097
180172747,4812,vvcephei,2018-04-09T17:35:53Z,it's a private method with an unused return value. making it void helps the reader to understand the code without having to trace through usages.,0,0.9920275807380676
180176820,4812,vvcephei,2018-04-09T17:50:26Z,"good question. i have developed the habit of delimiting variables in log messages, as it disambiguates the structure of the message for the reader. without delimiters, there are several edge cases that would make the log message difficult to read. for example, if the key were `""value""` and the value were `""""` with the old format, you get: [code block] whereas, if the key were `""""` and the value were `""value""`, you get [code block] the only difference between these strings is where the extra space is. with delimiters, you have: [code block] it's the kind of thing that saves people from #1 making a bad assumption about the nature of the problem and burning hours before they realize their mistake, or #2 being unable to clearly understand the error message and having to load it in a debugger just to understand what the values of the arguments actually are. it sounds like your concern is about the ambiguity of `[]` as delimiters, since they already indicate a list. can we keep delimiters but pick a different character? other paired delimiters are `<>` and `{}`, and `""""` and `''` also come to mind. wdyt?",1,0.9485882520675659
180180359,4812,vvcephei,2018-04-09T18:02:43Z,"i've been mulling over the same thing, and that was part of what i was trying to achieve with my experiment before. i think i have a better solution now, so maybe you can take another look after my next update and see what you think.",0,0.5352160334587097
180183446,4812,vvcephei,2018-04-09T18:13:40Z,"that also works, but `assertnotequals` is a little nicer in that it'll print the actual value on failure, whereas `asserttrue` only tells you that it was `false` on failure. i suppose i could add a utility method `assertgreater` that prints the values on failure, but in this case, i'm really just making sure that the metric got moved. i don't care that much to assert what it got moved to, or i would override the time implementation and assert the exact expected value.",0,0.983906090259552
180183779,4812,vvcephei,2018-04-09T18:14:53Z,"we can remove `this` below. the weakeraccess inspection tells you that it's possible to restrict the access scope of `cancel()`. i think this particular case was warning me that `cancel()` could be package-private instead of public. but the static analyzer can only look at the code in the project. we know that we do want the method to be public, so i added a supression for this inspection. an alternative would be to write black-box tests in a different package (just like real user tests would be), and the static analyser wouldn't warn us anymore, since it would have an example of a usage requiring public access.",0,0.9878969192504883
180195011,4812,mjsax,2018-04-09T18:54:07Z,"i personally thank, that having `=` (without `[]`) is good enough as the `=` makes it clear: [code block] thus, it's not ambiguous to me (i agree that having no delimiter at all would be bad). it's just that i like uniform formatting, and this would introduce a new style -- i am fine with change to this style, but we should agree on one style and rewrite code (on the side) if it does not fit the 'style guide'. \cc",1,0.9181250333786011
180196390,4812,mjsax,2018-04-09T18:59:05Z,"will do, after you pushed an update :)",0,0.9855109453201294
180238210,4812,guozhangwang,2018-04-09T21:34:54Z,"i'm do not feel very comfortable to define the metrics name in scattered places, because it means whenever we'll update the name we have to remember to update all the places (for this sensor the other place we declared it is [code block] so which line gets called first, it will create the sensor, while keeping the other just as an no-op. ), and that's why i liked 's proposal for wrapping the sensor names in the leveled metrics, and passing those metrics across different modules than re-declaring the sensors in different places. this makes me feel more urgent to do the refactoring of the metrics hierarchy.",-1,0.5899364352226257
180239208,4812,guozhangwang,2018-04-09T21:39:14Z,"i tend to prefer `key=[value]`, but i do not have a scientific reason for that: i just feel it is more ""vivid"" :p",1,0.9814018607139587
180239876,4812,guozhangwang,2018-04-09T21:41:57Z,"again, if we could pass around the `threadmetrics` here, it will make the code more readable: we can make it very clear at which places we record some task metrics like `taskmetrics.sensora.record()` and where do we record thread-level metrics like `threadmetrics.skippedrecordssensor.record()`. but i think it is better to be left as a follow-up pr as this one is already pretty big.",0,0.9765421152114868
180240234,4812,guozhangwang,2018-04-09T21:43:20Z,nice improvement,1,0.9852399826049805
180243194,4812,vvcephei,2018-04-09T21:56:21Z,"yeah, i keep getting wrapped around the axle thinking about stuff like this. hopefully, i'll be able to deliver a reasonable implementation for this pr, and i'll continue to mull about a way to pass the right metric context around the code base.",-1,0.9274841547012329
180243791,4812,vvcephei,2018-04-09T21:59:20Z,"i'm about to push a commit to put the skipped-records sensor in particular in a common place, since it winds up getting accessed from so many different places in the code. i'm hoping that will be good enough for now, and we can seek an elegant enclosing-scope metrics implementation in the future.",1,0.5357978940010071
180246639,4812,vvcephei,2018-04-09T22:12:53Z,"i can dig the desire to have uniform style on log messages. i'll also point out that the logs are part of the public api, so we can't just go terraform them willy-nilly, but instead we'd have to change them only in scope of the relevant kips, which makes it difficult to change, or even establish, a log style. nevertheless, if we don't already have a clear style for streams logs, i'll advocate for some kind of enclosing delimiter on substitutions. i continue to agree that square brackets are confusing w.r.t. common `list#tostring()` formats, so i think we should agree on a different enclosing delimiter. i agree that `=` is better than nothing, but it's still ambiguous when the substitution is 0 or more whitespace characters, while `[]` vs `[ ]` gives you more of a clue. no choice here is going to be perfect, but my experience is that this format saves enough debugging time to be worth the visual noise.",0,0.9141830801963806
180576030,4812,guozhangwang,2018-04-10T21:39:40Z,"what's the purpose of keep track of the metric names? if it is for preventing double-registering, i think relying on maintaining the metrics name inside the sensor would not always work, since multiple sensors would be added into the `metrics` registry, and we still cannot prevent different sensors trying to register the same metrics.",0,0.9871231317520142
180576708,4812,guozhangwang,2018-04-10T21:42:38Z,we do not need the non-arg constructors since it will be defined by default.,0,0.9937905669212341
180577126,4812,guozhangwang,2018-04-10T21:44:29Z,no callers seem to provide any non-empty `tags`?,0,0.9905681014060974
180577282,4812,guozhangwang,2018-04-10T21:45:10Z,ditto here.,0,0.9877910614013672
180577454,4812,guozhangwang,2018-04-10T21:45:56Z,"if we always create the skipped record sensor upon creating the thread, then we should always get the sensor right? if that case, should we simply throw if the `getsensor` returns null?",0,0.9904620051383972
180578491,4812,guozhangwang,2018-04-10T21:50:26Z,"this is a meta comment: i think we have seen two approaches here: 1. pass along the metrics objects across different modules (in some classes, we will pass multiple metrics objects for different levels, like threadmetrics and taskmetrics) in order to record their sensors. 2. in the current pr: only pass alone the metrics registry (i.e. the `metrics` object) along different modules, but standardize the sensor name construction, and get the sensor by its raw name directly whenever necessary to record the sensor. i am slightly in favor of the second one since we could pass long fewer parameters, i.e. only a single `metrics` object which can be accessed 1) from processorcontext, 2) in multiple internal classes.",0,0.8656864166259766
180578769,4812,guozhangwang,2018-04-10T21:51:35Z,this is a detailed comment: what's the rantionale of naming it `commonstreamsmetrics`? is it for thread-level metrics only? i.e. should we just move this static function into `threadmetrics`?,0,0.9912589192390442
180607694,4812,mjsax,2018-04-11T00:47:33Z,"we never discussed this explicitly; it's just a matter of fact that we use `key=value` so far from what i can remember. the question is, how much we gain if we start to rewrite to a different format and how much work it it. with regard to ambiguity: you can always construct an (academic?) example for which any formatting strategy ""break"" and is ambiguous... if we agree on `key=[value]` i am fine with it. still not sure, if we gain much (but if you think we do, it's fine with me to change)",0,0.8472559452056885
180815261,4812,vvcephei,2018-04-11T16:20:42Z,"i have pulled this change into a separate pr: [a link] the intent is to make it a no-op if you add the same metric to the same sensor twice, as opposed to the current behavior, in which the `registry.registermetric(metric)` throws an exception if the metric is already registered. with this change, you'll still get an exception if the metric is already registered in another sensor, but if it's already in the same sensor, you just get a no-op success.",0,0.9929966330528259
180815535,4812,vvcephei,2018-04-11T16:21:38Z,"this privatizes the constructor, guaranteeing that the class cannot be instantiated. it's a way of enforcing that the class be used only for its static members.",0,0.9937466382980347
180815880,4812,vvcephei,2018-04-11T16:22:44Z,"it's laying the groundwork for a future change in callers can compose thread-level tags, task-level tags, etc.",0,0.9915607571601868
180816071,4812,vvcephei,2018-04-11T16:23:20Z,"to do this properly, though, the class should also be final. i'll make that change.",0,0.9873998165130615
180816181,4812,vvcephei,2018-04-11T16:23:38Z,same rationale.,0,0.9859768152236938
180817574,4812,vvcephei,2018-04-11T16:28:17Z,"this method is used to idempotently create or retrieve the sensor. in other words, the mechanism by which we create the sensor when we create the thread is that it calls this method, and the sensor is null, so it creates it. you're correct in that if we do that, then all other usages will just return the existing sensor. i'm not sure i see the value in separating creation from retrieval so that we can throw an exception if you retrieve it without creating it first.",0,0.985801637172699
180824861,4812,vvcephei,2018-04-11T16:51:39Z,"yeah, i'm still undecided on whether approach 1 or 2 is better. but i did decide that i don't want to make a call on it in this pr. if you'd like me to resolve this sooner rather than later, i can follow up immediately with another pr to reorganize the metrics. the reason i pulled skipped-records out into a commonstreamsmetrics class is that that metric is common across all components in streams. it's accessed by both our framework-level code and also by the user-space dsl-provided processors. thus, it needs to live in a spot where all those components have visibility on it. there's a distinction between metrics that are aggregated at the thread level and metrics that belong to `streamthread`. it'll be difficult to really do a good job in this pr with that distinction, though, without refactoring the whole metrics hierarchy. since we're already over 2,000 loc, i'd really like to move such a refactoring to another pr. what i have done in this pr is as minimal as i can manage to expose the skipped-records sensor to our processors.",0,0.8803289532661438
180866308,4812,bbejeck,2018-04-11T19:09:05Z,"i also prefer `key=[value]`, but can't say it's for any specific reason other than personal preference.",0,0.9823461174964905
180870195,4812,bbejeck,2018-04-11T19:23:52Z,is this line intentional?,0,0.9533103704452515
180870791,4812,bbejeck,2018-04-11T19:26:16Z,"the `hasitem` matcher is new to me, nice one!",1,0.9894340634346008
180876468,4812,bbejeck,2018-04-11T19:47:38Z,"do we need a separate class for this? we could add the `getmetricbyname` method to `streamstestutils` instead, additionally, it doesn't access anything package private so it should be fine to make the method public",0,0.9949658513069153
180878303,4812,bbejeck,2018-04-11T19:54:39Z,"meant to say this before, nice addition!",1,0.9914518594741821
180930916,4812,vvcephei,2018-04-11T23:50:42Z,oops. i put it there when i needed a place for a breakpoint. sorry!,-1,0.9955226182937622
180931250,4812,vvcephei,2018-04-11T23:53:06Z,"thanks! it's predicated on us using log4j as the implementation for slf4j in the unit tests, so if that changes, we'll have to put in a different log appender. but that seems unlikely, and it's handy to have this in the mean time.",1,0.9897446036338806
180932520,4812,vvcephei,2018-04-12T00:01:29Z,"i can move it to streamtestutils if you like. i made `getmetricbyname` package-private to prevent other code from calling it, since it's intended for these tests only. making it public would open this method up to be called beyond the intended scope. i'd rather defer that until we have a use case we think calls for broadening the scope.",0,0.9910950660705566
181250474,4812,guozhangwang,2018-04-12T23:26:24Z,"thanks for the explanation, that makes sense.",1,0.8550559282302856
181250828,4812,guozhangwang,2018-04-12T23:28:41Z,"i had another meta question while discussing offline, and i'll leave it here for discussion: since different meters belong to the different metrics levels, should we move these static functions to the corresponding `xxmetrics` instead? i'm thinking about that since we have some meters that exist in multiple levels, like commit rate. in the future if we move them all to this class then we need to get one function for each level as their tags naming conventions are different, and hence it is not really `common` streams metrics.",0,0.9534836411476135
181251041,4812,guozhangwang,2018-04-12T23:30:03Z,similar to my other comment on `commonstreamsmetrics`: could we move these static functions to the corresponding level metrics class?,0,0.9924679398536682
181252004,4812,guozhangwang,2018-04-12T23:36:39Z,"i'd suggest in the future try to only piggy-back different changes into the same pr if we think they are either correlated or if they are really trivial. having a single pr mingled with multiple changes has several drawbacks: 1. it makes git history a bit harder to trace: think, ""git blame"" would be tricker to reason. 2. it tends to generate bigger prs than necessary, making reviewer less willing to start working on them :p 3. if multiple rounds of reviews are needed, even requiring major code refactoring, it will surprisingly introduce regressions during those iterations as by-products of the multiple changes.",1,0.9251337647438049
181252540,4812,guozhangwang,2018-04-12T23:40:36Z,i'm not sure why we need to pass around `streamsmetricsimpl` from streamthread to everywhere else now?,0,0.9362891912460327
181410527,4812,vvcephei,2018-04-13T14:43:21Z,"previously, we passed around the interface only to cast it back to `streamsmetricsimpl` in line 80 of this file. all i did was make taskmetrics declare that it really does want a `streamsmetricsimpl` instead of a `streamsmetrics` explicitly. if we're going to cast it anyway, why not just use the type system?",0,0.9926362037658691
181412307,4812,vvcephei,2018-04-13T14:49:06Z,"i thought it would be nice if the metrics naming conventions were all in one place, to help us maintain consistency. right now, we have one (internal) naming convention enforced via our (public) metrics api: `streamsmetrics`, but we also have a bunch of metrics with no defined naming convention declared, e.g., in `streamsmetricsthreadimpl`. i think it'll be simpler for people to use the metrics if we maintain consistency throughout the whole streams code-base, and it'll be simpler to maintain consistency if we keep all the naming conventions in one file.",0,0.8156343102455139
181424139,4812,vvcephei,2018-04-13T15:25:18Z,"there are two different concepts of belonging in play here. 1. grouping: a metric ""belongs"" to the thread level if it's aggregated at that level 2. ownership: a metric ""belongs"" to the thread level if streamthread needs a reference to it. grouping and ownership are orthogonal here. there are several metrics that are aggregated at the thread level and are also owned by streamthread, like the committimesensor. grouping is easy to determine; all you have to do is look at the metric name. to tell that committimesensor is owned by streamthread, you can trace the references to the sensor. it's never passed outside of streamthread, so it's owned by streamthread. other metrics are still grouped by thread but owned by other classes, such as the taskcreatedsensor. all of streamthread, abstracttaskcreator, taskcreator, and standbytaskcreator have references to this metric, so they all share the ownership. now that i'm looking at it, streamthread never uses the reference, so it could be owned only by abstracttaskcreator and its children. finally, we get to the skippedrecordssensor. this metric is still grouped by thread, but ownership is shared among 14 classes. two of them are framework classes (globalstreamthread and streamthread), and 12 of them are user-space processor classes. since ownership for skippedrecordssensor is so dispersed, i decided to just make its ownership global, aka common. anything in the entire streams codebase can get a reference to the skippedrecordssensor. i wouldn't move all the metrics into the global ownership space just because i moved one, and i wouldn't give streamthread a reference to a metric just because that metric happens to be aggregated by thread. am i making sense?",0,0.9801314473152161
182273476,4812,guozhangwang,2018-04-17T23:43:48Z,"i understand the separation of ownerships of metrics, my question is: right now the `skippedrecordsmeter` assumes this metric is grouped at the thread-level, and hence the second parameter is a `threadname`. what if in the future we add a per-task level `skippedrecordsmeter(final metrics, final taskid)`? would that be put in this `commonstreamsmetrics` as well? practically speaking either is fine, and i think i was originally leaning towards not having a `commonstreamsmetrics` conceptually since that for each meter, it is going to be aggregated at a specific layer anyways. but if people think that it is better of having a `commonstreamsmetrics` where we put these metrics so that all dependent classes would just depend on `o.a.k.streams.processor.internal.metrics`, i'm fine with it as well.",0,0.9677212238311768
182274054,4812,guozhangwang,2018-04-17T23:47:54Z,ditto.,0,0.9384599328041077
182274130,4812,guozhangwang,2018-04-17T23:48:31Z,"since we will have a different kstreamwindowreduceprocessor for each topology, each task, each thread, the thread.currentthread() will always be the same; it is okay to get the meter at the constructor and cache it, than trying to search for it in the registry each time. ditto below.",0,0.9929516911506653
182274177,4812,guozhangwang,2018-04-17T23:48:46Z,ditto.,0,0.9384599328041077
182274189,4812,guozhangwang,2018-04-17T23:48:53Z,ditto.,0,0.9384599328041077
182274204,4812,guozhangwang,2018-04-17T23:49:00Z,ditto.,0,0.9384599328041077
182274440,4812,guozhangwang,2018-04-17T23:50:36Z,ditto.,0,0.9384599328041077
182274531,4812,guozhangwang,2018-04-17T23:51:12Z,ditto.,0,0.9384599328041077
182274558,4812,guozhangwang,2018-04-17T23:51:21Z,ditto.,0,0.9384599328041077
182275004,4812,guozhangwang,2018-04-17T23:54:24Z,ditto.,0,0.9384599328041077
182275021,4812,guozhangwang,2018-04-17T23:54:31Z,ditto.,0,0.9384599328041077
182275061,4812,guozhangwang,2018-04-17T23:54:41Z,ditto.,0,0.9384599328041077
182275088,4812,guozhangwang,2018-04-17T23:54:53Z,ditto.,0,0.9384599328041077
182275337,4812,guozhangwang,2018-04-17T23:56:46Z,do we need to pass the sensor all the way down here? could we fetch it from the `commonstreamsmetrics` directly as well? note that each thread will create its own `recorddeserializer` objects that are exclusively owned by the thread itself.,0,0.9925786852836609
182275382,4812,guozhangwang,2018-04-17T23:57:02Z,please see my comment in `recorddeserializer`,0,0.9957755208015442
182275534,4812,guozhangwang,2018-04-17T23:58:07Z,this import is not needed?,0,0.993296205997467
182275652,4812,guozhangwang,2018-04-17T23:58:50Z,"similar as above, do we still need to pass this sensor along, than getting it from `commonstreamsmetrics` directly?",0,0.9931787252426147
182275731,4812,guozhangwang,2018-04-17T23:59:27Z,as above in `recorddeserializer`.,0,0.9951757192611694
182275826,4812,guozhangwang,2018-04-18T00:00:09Z,ah right. thanks.,1,0.9638654589653015
182275969,4812,guozhangwang,2018-04-18T00:01:17Z,"same as above, could we just get it from `commonstreamsmetrics` now?",0,0.9951171875
182276400,4812,guozhangwang,2018-04-18T00:04:31Z,could you point to me where do we remove this sensor upon shutting down now?,0,0.9931784868240356
182276649,4812,guozhangwang,2018-04-18T00:06:46Z,why passing `threadclientid` twice?,0,0.9857709407806396
182277627,4812,guozhangwang,2018-04-18T00:14:01Z,actually i've been thinking .. could we move the construction of the `taskmanager` and its `taskcreators` into the constructor of `streamthread` directly from `create` call? then we can get the threadname from `currentthread.name()` directly and do not need to pass this parameter around any more.,0,0.9882133603096008
182278148,4812,guozhangwang,2018-04-18T00:18:07Z,"for test util classes, they are usually put in `org.apache.kafka.test` package. this allows a larger scope of utilization by non-streams unit tests.",0,0.9938178658485413
182278220,4812,guozhangwang,2018-04-18T00:18:37Z,and you can put them in `streams.test.o.a.k.test` folder.,0,0.9953867793083191
182278443,4812,guozhangwang,2018-04-18T00:20:20Z,this looks like a general test util function than a streams-specific test util function. how about moving it to `org.apache.kafka.test.testutils`?,0,0.9936631917953491
182826571,4812,vvcephei,2018-04-19T17:34:08Z,"using the interface is really only useful in our public processorcontext interface. using the streamsmetrics interface in our internals just forces us to cast it back to streamsmetricsimpl all over the place. i've changed it to s.m.i. here and elsewhere to cut down on the casting. the only things that should need to cast now are components that get the metrics via processorcontext, and they should always perform that cast as early as possible to prevent post-initialization runtime exceptions.",0,0.9826645255088806
182827178,4812,vvcephei,2018-04-19T17:36:18Z,override to refine the type from streammetrics to streammetricsimpl in support of internal usages.,0,0.9935013651847839
182829844,4812,vvcephei,2018-04-19T17:45:17Z,"it's used by the nodemetrics implementation (it might have been unused when you made this comment, though)",0,0.9940112233161926
182830330,4812,vvcephei,2018-04-19T17:46:54Z,"i've removed commonstreamsmetrics, so we need either to pass the sensor or the whole streamsmetricsimpl. the sensor is smaller scope, so i just did the sensor for now.",0,0.993583619594574
182830606,4812,vvcephei,2018-04-19T17:47:51Z,the same rationale from `recordcollectorimpl` applies.,0,0.9926064014434814
182834003,4812,vvcephei,2018-04-19T17:58:48Z,"this is an internal class, and this javadoc doesn't say anything that the method signature doesn't say. i added a new constructor and changed the existing one, so i just removed the doc rather than updating it.",0,0.9921715259552002
182834401,4812,vvcephei,2018-04-19T18:00:09Z,"this existed only so a test could override it. instead, i added a constructor arg for the test to pass and removed this method.",0,0.9949224591255188
182837476,4812,vvcephei,2018-04-19T18:10:55Z,"i refactored these to flatten the metric definition, since it was super hard to figure out what metrics were actually being created. maybe you can forgive me for this because i actually found a bug: the description of the total metrics say that it counts the number of calls, but it previously summed the recorded values. (was via createmeter -> new meter -> new total)",-1,0.7597782015800476
182840375,4812,vvcephei,2018-04-19T18:20:40Z,"i'd like to add tasklevel names and tags, but it doesn't work with the current way most of the corresponding sensors get created. ultimately, i'd like to flatten all the metrics definitions like i did with streamthreadmetricsimpl, which would make it possible to define the task and node level conventions here as well. but i don't want to do that in this pr.",0,0.9506635069847107
182840948,4812,vvcephei,2018-04-19T18:22:39Z,"defining and providing skippedrecordssensor here now, since it's now needed in contexts where the implementation is not a streamthreadmetricsimpl.",0,0.9934083223342896
182843117,4812,vvcephei,2018-04-19T18:30:00Z,"similar to the metrics in streamthread, by getting rid of the meter and flattening these metrics, i realized that the total computation was incorrectly a total rather than a count.",0,0.9897630214691162
182843558,4812,vvcephei,2018-04-19T18:31:36Z,these metrics never get removed. is that ok?,0,0.9744341373443604
182845636,4812,vvcephei,2018-04-19T18:38:54Z,"this is required per the docs, but we previously only added it in production code paths. now we add it in all code paths.",0,0.9944673776626587
182846028,4812,vvcephei,2018-04-19T18:40:13Z,"this is required per the docs, but we previously only added it in production code paths. now we add it in all code paths.",0,0.9944673776626587
182846606,4812,vvcephei,2018-04-19T18:42:13Z,"the skipped records metrics are now always present. rather than updating the hard-coded value, i did this to make the test less brittle.",0,0.993723452091217
182847809,4812,vvcephei,2018-04-19T18:46:25Z,"i can move them there. the reason i put them here was to restrict the scope in which log4j was an allowed import (i had to add an exception). co-locating this class in any other package will allow other code to accidently depend on log4j when it should depend on slf4j instead. i was also uncertain about whether it would be a good idea to expose this class for general use in kafka tests... wdyt? if you're not concerned about supporting this class for the whole project, maybe `o.a.k.test.log4jappender` package would be the best of both worlds?",0,0.9680559039115906
182849325,4812,vvcephei,2018-04-19T18:51:39Z,i replaced the override-with-capture strategy in this test with just a regular streamsmetrics and verifying the invocation by checking that the total metric is == 1.,0,0.9940217137336731
182850930,4812,vvcephei,2018-04-19T18:57:02Z,"""virtual"" just in case people go looking for the actual thread in the thread dump. i also thought about using `thead.currentthread()`, but it wouldn't necessarily be the same thread when the tests run.",0,0.9890688061714172
182851149,4812,vvcephei,2018-04-19T18:57:37Z,"same thinking regarding ""virtual""",0,0.9839950799942017
182914835,4812,guozhangwang,2018-04-19T23:45:56Z,"ah i see, overlooked `log4j` dependency; let's keep it as is then.",0,0.9872803092002869
182915655,4812,guozhangwang,2018-04-19T23:51:21Z,why this need to be public now?,0,0.9801273345947266
182915744,4812,guozhangwang,2018-04-19T23:52:01Z,"good point, let's add a todo marker and remove them in a follow-up pr: so we do not drag too long on this one.",1,0.8756323456764221
182916297,4812,guozhangwang,2018-04-19T23:56:06Z,sounds good!,1,0.9884929060935974
182916817,4812,guozhangwang,2018-04-20T00:00:03Z,"i guess my previous comment was a bit misleading :p actually i'm not against the `commonstreamsmetrics` and `threadmetricsconventions` classes, but i think we could have one such class for each different layer than having a `common` class, for the reason i mentioned before. but since you have removed it i'm also fine with passing along the sensors as well. we can consider which one is better in the near future and if we can do another code refactoring, but let's not block on this pr for too long.",1,0.9809866547584534
182917077,4812,guozhangwang,2018-04-20T00:02:10Z,sounds good!,1,0.9884929060935974
182917552,4812,guozhangwang,2018-04-20T00:06:12Z,good call!,1,0.99321448802948
182917825,4812,guozhangwang,2018-04-20T00:08:20Z,cool.,1,0.90013188123703
182918255,4812,guozhangwang,2018-04-20T00:11:55Z,"hmm.. why we create the sensor in `streamsmetricsmpl` while removing it in `streamsmetricsthreadimpl`? it seems a bit inconsistency.. could we still create in `streamsmetricsthreadimpl`, and let `streamsmetricsimpl` to get a hold of the sensor object assuming it is already created then (i.e. set `sensor == null` in constructor, and in `skippedrecordssensor(): if (sensor == null) try get it from the metrics`)?",0,0.9358142614364624
182918502,4812,guozhangwang,2018-04-20T00:14:29Z,not sure i understand this comment: it was indeed defined as a `count()` before as well right?,0,0.9043687582015991
183065396,4812,vvcephei,2018-04-20T14:18:25Z,"no, it was previously: [code block] but the `count` there is only used for updating the rate. here's the metric constructor: [code block] you can see that it's using `total` for the ""total"" metric, which i guess makes sense given the parameter name. but according to the description of our ""total"" metric, what we really wanted to do was keep a count of occurrences, which should be a `count` stat.",0,0.989400327205658
183075990,4812,vvcephei,2018-04-20T14:52:56Z,"ok, when i took another look, i found that `hitratiosensor` does get removed, but its parent doesn't. also neither sensors have scoped names, so every `record()` will actually update *all* hit ratio metrics for *all* caches. that seems like a bigger deal, so i've already prepared a follow-up pr. i'll send it next once this one is merged.",0,0.977101743221283
183081167,4812,vvcephei,2018-04-20T15:08:22Z,"because i moved streamsmetricsimpl to the `...internal.metrics` package, but i took a look, and it was only used (properly) by `processornode`. `streamtask` also used it, but only by specifically wrapping the operation in a `runnable` and passing it to the metric to immediately be run. i've added [a link] to simplify `streamtask`'s usage to not need this method, and move the method to `processornode`.",0,0.9930498600006104
183091285,4812,vvcephei,2018-04-20T15:40:35Z,"i tried that, but it wound up making things messier than i expected (because there are other callers to streamsmetricsimpl, and because it makes the ownership of this sensor ambiguous). instead, i added [a link] which gives smi the ability to remove its own sensors, and then i called to it from the two places (streamthread and globalstreamthread) that actually need to unload metrics when they shut down. wdyt?",0,0.9238640666007996
183114250,4812,guozhangwang,2018-04-20T17:09:29Z,"i see. that makes sense. i think it was not introducing any issue only because we only call that `sensor.record()` not `sensor.record(n)` so `count` and `total` are actually the same: `record()` is the same as `record(1)`, but i agree that it should really be `count`, to avoid any potential bugs.",0,0.9625693559646606
183114732,4812,bbejeck,2018-04-20T17:11:29Z,nit: just thinking if this change is necessary as `nodemetrics` is an internal class so a cast here from `processorcontext` to `internalprocessorcontext` should not be a big deal and keeps `processornode` more generic. edit: nm read a comment below about using type system and i agree.,0,0.9720078706741333
183116528,4812,bbejeck,2018-04-20T17:18:41Z,why remove this?,0,0.9803281426429749
183130635,4812,guozhangwang,2018-04-20T18:13:14Z,"i did not completely get your explanation re: `because there are other callers to streamsmetricsimpl, and because it makes the ownership of this sensor ambiguous`. could you elaborate a bit more?",0,0.9751102328300476
183161064,4812,bbejeck,2018-04-20T20:27:06Z,nit: `shouldlogandmeteronskippedrecords` -> `shouldlogandmeteronskippedrecordswithnullvalue` ?,0,0.9941847920417786
183164652,4812,bbejeck,2018-04-20T20:43:09Z,line 503 the javadoc should change as the constructor for `streamsmetricsimpl` only takes `metrics` and a `string` parameter.,0,0.9925865530967712
183166451,4812,bbejeck,2018-04-20T20:51:34Z,maybe consider replacing `stack` with `deque` as `stack` is synchronized and `ownedsensors` only adds in the constructor and removes values in `synchronized` block already.,0,0.987528383731842
183182512,4812,vvcephei,2018-04-20T22:29:21Z,"this is just used in one spot. it's easier to read the code if the log message is located at the spot where it gets logged rather than at the top of the file. in earlier versions of java, code like this was beneficial for performance, since the string is an object that can just get allocated and instantiated once statically, rather than dynamically on every invocation. but nowadays, the compiler and jit compiler are smarter than that, so there really no benefit to coding this way, and you still pay the comprehensibility cost of having to follow the indirection. i didn't want to make it a ""thing"", though, so i only inlined the message i needed to change.",0,0.915034294128418
183182785,4812,vvcephei,2018-04-20T22:31:55Z,"ah, good eye. i might just ditch the javadoc, since it's an internal class and its function is pretty obvious.",1,0.9510660767555237
183182905,4812,vvcephei,2018-04-20T22:33:10Z,"ooh, good call. i will do that and probably avoid using stack again.",1,0.9705285429954529
183185297,4812,vvcephei,2018-04-20T22:54:13Z,"sorry; i misread your suggestion. i thought you wanted the streamsmetricsimpl to take the sensor as a constructor argument. aside from the streamthread (via streamthreadmetricsimpl), several other classes directly invoke the streamsmetricsimpl constructor and thus obtain a streamsmetricsimpl that is not a streamthreadmetricsimpl. namely, globalstreamthread, mockprocessorcontext, and topologytestdriver. when the code paths downstream of these points need to record a skipped record, they will get a null sensor back. it wouldn't be possible to get it from the metrics registry at that point, though, because the skipped records sensor is scoped by thread (or ""virtual"" thread for the test-utils), and the sensor would never have been created for globalstreamthread, mockprocessorcontext, or topologytestdriver. so the only way to get it at that point is to have either the caller of the smi constructor or the smi itself create the sensor (either at construction or at call-time). the previous implementation with the public static getter was effectively saying that the one who wants it in a particular context first creates it, but it's problematic because no-one owns it. and indeed, in my implementation, the sensor never got destroyed. in practice i think it's not a huge deal because i'm sure it's rare for a streams app to shut down and start up again with the same metrics registry, and i think the threads live as long as the app. but still, we have this model of unloading metrics when they're out of scope, and i think it's a good one. so that brings us to the current implementation. in the current implementation, the skipped records metric is clearly owned by the streamsmetricsimpl, which it may as well be, since that is the smallest scope in which it's needed. it's the first metric to be owned by smi, so i had to create a removeall method, and make sure it's invoked in the right places. but that seems appropriate; every other scope that owns metrics has such a method.",-1,0.9514964818954468
329311213,7378,jukkakarvanen,2019-09-28T13:57:09Z,this is still using deprecated pipeinput because there is partition verification. can we drop here partition verification which is null here?,0,0.9928622841835022
329311302,7378,jukkakarvanen,2019-09-28T14:00:55Z,this is still using deprecated pipeinput because there is partition verification. can we skip partition assertion here or do we need some other way to get producerrecord?,0,0.9931174516677856
330105303,7378,vvcephei,2019-10-01T14:55:39Z,"yes, it seems to be not what this test is checking on. i think we can drop it here.",0,0.9891676902770996
330108688,7378,vvcephei,2019-10-01T15:01:12Z,"it seems like the purpose of this test class is to verify the test driver. since the partition is effectively not part of the test driver's (non-deprecated) api, i think we can drop it. technically, as long as the deprecated interface is still in the public api, we should still exercise it, but i think in this case it's extremely unlikely we would break the partition field in the future, and it's probably not that risky anyway. i'd vote just to skip the partition assertion here.",0,0.9587200880050659
330248099,7378,jukkakarvanen,2019-10-01T20:01:43Z,moved to use testoutputtopic and partition assertion removed.,0,0.9946361184120178
330248275,7378,jukkakarvanen,2019-10-01T20:02:10Z,moved to use testoutputtopic and partition assertion removed.,0,0.9946361184120178
330345901,7378,vvcephei,2019-10-02T01:55:47Z,"note: the unused suppression indicates that we're missing test coverage. if we want to add test coverage, we can at the same time address the weakeraccess warning by putting the test in a different package than this class. i.e., a true test of a class's public api should be located outside that class's package, so it wouldn't have access to package-private members.",0,0.9926202297210693
330346143,7378,vvcephei,2019-10-02T01:57:20Z,"it might be a good idea to note that this only advances the _stream_ time, not the wall-clock time, and therefore doesn't trigger punctuations.",0,0.9843616485595703
330346457,7378,vvcephei,2019-10-02T01:59:28Z,"would it be handy to also print out the other constructor argument fields here? (serializers in particular, not sure if the times are that interesting)",0,0.9676286578178406
330346561,7378,vvcephei,2019-10-02T02:00:05Z,should we also require non-null deserializers?,0,0.9932385683059692
330347517,7378,vvcephei,2019-10-02T02:07:04Z,"i'm curious why these suppressions were necessary. i'd have thought that the package-private members would all have been here because they were needed by the i/o topic classes. is it because idea thinks that protected is ""stronger"" than package-private?",0,0.9231604933738708
330347991,7378,vvcephei,2019-10-02T02:10:28Z,"you should double-check, but i think java will automatically do this in string concatenation. (it was news to me when i learned it a couple of months back)",0,0.9837881326675415
330348273,7378,vvcephei,2019-10-02T02:12:15Z,probably should use a (slf4j) logger instead of stdout here.,0,0.9888917803764343
330348480,7378,vvcephei,2019-10-02T02:13:29Z,these tests are beautiful,1,0.9950399994850159
330348611,7378,vvcephei,2019-10-02T02:14:17Z,there seems to be a lot of overlap between these and the input tests. could they just be one test class that covers both?,0,0.9832821488380432
330348785,7378,vvcephei,2019-10-02T02:15:25Z,[code block] thanks for keeping the test coverage for deprecated methods.,1,0.8240988850593567
330369097,7378,jukkakarvanen,2019-10-02T04:37:38Z,suppresswarnings removed and comment clarified,0,0.9922452569007874
330369142,7378,jukkakarvanen,2019-10-02T04:37:54Z,added,0,0.8435775637626648
330369166,7378,jukkakarvanen,2019-10-02T04:38:07Z,added,0,0.8435775637626648
330369686,7378,jukkakarvanen,2019-10-02T04:42:09Z,not sure the reason.,0,0.5147112011909485
330369748,7378,jukkakarvanen,2019-10-02T04:42:38Z,replaced with another style tostring,0,0.9931837916374207
330369769,7378,jukkakarvanen,2019-10-02T04:42:49Z,dobe,0,0.9737884402275085
330369794,7378,jukkakarvanen,2019-10-02T04:43:02Z,thanks,1,0.8643599152565002
330370023,7378,jukkakarvanen,2019-10-02T04:44:51Z,merged,0,0.9518769383430481
330370105,7378,jukkakarvanen,2019-10-02T04:45:29Z,typo fixed,0,0.991142749786377
331089257,7378,bbejeck,2019-10-03T14:59:10Z,"nit: i **_think_** that streams convention now is to mark methods as `` now vs. using ``. my reasoning for this is that these test methods will go away once the deprecated method under test is removed. this applies here and other deprecated tests below. however, this is a minor point. \cc",0,0.9782006740570068
331091087,7378,bbejeck,2019-10-03T15:02:10Z,super nit: `deprecatd` -> `deprecated` here and below,0,0.9875149726867676
331099773,7378,bbejeck,2019-10-03T15:18:38Z,nit: `configure topic` -> `configure the topic`,0,0.9942692518234253
331122381,7378,bbejeck,2019-10-03T16:02:51Z,why did we eliminate the partition check in the `assertnextoutputrecord` method?,0,0.9930261373519897
331124616,7378,bbejeck,2019-10-03T16:07:47Z,nit: `you need to have own testinputtopic object` -> `you need a testinputtopic object`,0,0.9940184354782104
331125926,7378,bbejeck,2019-10-03T16:10:37Z,as above,0,0.9888283014297485
331126553,7378,bbejeck,2019-10-03T16:12:02Z,nit: `send` -> `sent`,0,0.9931678175926208
331131776,7378,bbejeck,2019-10-03T16:23:46Z,"do we still need this comment? seems to me the other topic is expecting a `string` as well, but i could be missing something.",0,0.9893844723701477
331134784,7378,bbejeck,2019-10-03T16:30:39Z,"a minor point, but isn't this supposed to swap the key and value on output?",0,0.9438547492027283
331189754,7378,vvcephei,2019-10-03T18:33:18Z,"ah, yes, good catch, . adding the deprecation annotation will also satisfy the compiler, and it is indeed better. as you say, it documents that this method will also be removed when the other one is removed. it's not such a concern for a test, but the other big benefit is that it prevents ""deprecation laundering"": suppressing would make it ok for another method to call this one, whereas deprecating this method would also notify all callers that _this_ method is using deprecated functionality.",1,0.9305484890937805
331191034,7378,vvcephei,2019-10-03T18:36:17Z,"partitions are not part of the `testrecord` api in the kip, so it's not possible to make assertions on it in the new api. we can add the field later on if requested. i don't remember offhand why we didn't include it; maybe something to do with the symmetry of the api.",0,0.9904597997665405
331212689,7378,jukkakarvanen,2019-10-03T19:27:54Z,"ok, modified",0,0.9908686876296997
331212945,7378,jukkakarvanen,2019-10-03T19:28:27Z,fixed,0,0.920660674571991
331214169,7378,jukkakarvanen,2019-10-03T19:31:26Z,added,0,0.8435775637626648
331215421,7378,jukkakarvanen,2019-10-03T19:34:39Z,fixed,0,0.920660674571991
331215484,7378,jukkakarvanen,2019-10-03T19:34:49Z,fixed,0,0.920660674571991
331216194,7378,jukkakarvanen,2019-10-03T19:36:24Z,removed,0,0.9591778516769409
331225577,7378,jukkakarvanen,2019-10-03T20:00:01Z,there are two stream. this is using this: builder.stream(input_topic).to(output_topic); output_topic_map is where values are swapped,0,0.9954047203063965
331226741,7378,jukkakarvanen,2019-10-03T20:02:58Z,fixed,0,0.920660674571991
331233340,7378,jukkakarvanen,2019-10-03T20:19:25Z,"i removed all unnecessary field from testrecord compared to producerrecord and consumerrecord to keep it simple. this way we can utilize standard assertions and do not need to ignore the partition and use outputverifier kind of contructions. i don't see many use cases in normal stream application verification where partion is needed as we see here where this is only test class checking partition. if there are need to verify partition, i would add for example extra method readproducerrecord and use deprecated method until this is possible added if there is need for it.",0,0.9741050601005554
331344364,7378,mjsax,2019-10-04T05:22:30Z,nit: `inputtopic` -> `rightinputtopic`,0,0.9933580756187439
331344534,7378,mjsax,2019-10-04T05:23:36Z,"why do we need to pass `null` as third parameter? saw this in some other tests, too.",0,0.9873197078704834
331344660,7378,mjsax,2019-10-04T05:24:33Z,nit: `inputtopicright`,0,0.9946790933609009
331345200,7378,mjsax,2019-10-04T05:27:59Z,nit: add `asserttrue(outputtopic2.isempty());` (as done in the original test code),0,0.9954120516777039
331345336,7378,mjsax,2019-10-04T05:28:48Z,as above,0,0.9888283014297485
331345361,7378,mjsax,2019-10-04T05:28:57Z,as above,0,0.9888283014297485
331346249,7378,mjsax,2019-10-04T05:35:02Z,nit: `final instant initialwallclocktime = instant.ofepochmilli(0)`,0,0.9940630793571472
331346966,7378,mjsax,2019-10-04T05:39:36Z,nit: [code block],0,0.9919844269752502
331347564,7378,mjsax,2019-10-04T05:43:28Z,nit: `create [a new instance via]`,0,0.9945390820503235
331347785,7378,mjsax,2019-10-04T05:44:37Z,nit: `message` -> `record` nit: `{ keyvalue} pairs.` (not add `.` at the end.,0,0.9950042366981506
331347943,7378,mjsax,2019-10-04T05:45:33Z,"nit: `if you have multiple source topics, you need to create a { testinputtopic} for each.`",0,0.9921897053718567
331348093,7378,mjsax,2019-10-04T05:46:36Z,`kafka` -> `record` (same next line for value),0,0.9946135878562927
331348378,7378,mjsax,2019-10-04T05:48:14Z,nit: `messages` -> `records`,0,0.9941306710243225
331348642,7378,mjsax,2019-10-04T05:49:54Z,"we can omit javadocs for non-public methods -- similar below -- wondering if we need this constructor? it's internal and hence, topologytestdriver can always use the one with all parameters.",0,0.9942029118537903
331349765,7378,mjsax,2019-10-04T05:56:06Z,"topologytestdriver supports event/stream time punctuations -- hence, this comment is a little bit miss leading. i would suggest: [code block]",0,0.9927803874015808
331349882,7378,mjsax,2019-10-04T05:56:40Z,"in the kip, the method is still called `advancetimems` -- can you update the kip?",0,0.9957568049430847
331351096,7378,mjsax,2019-10-04T06:02:48Z,"nit `send input record to the topic and then commit the record.` (note, in kafkastreams we use the abstractions of records, that are typed, while messages are untyped lower lever `byte[]` arrays). similar below.",0,0.9925664663314819
331351274,7378,mjsax,2019-10-04T06:03:41Z,`key` -> `value`,0,0.990920901298523
331351440,7378,mjsax,2019-10-04T06:04:44Z,"should we add ""may auto advance topic time"" to the other methods?",0,0.9950425624847412
331351655,7378,mjsax,2019-10-04T06:05:49Z,nit: `{ keyvalue}` nit: remove double whitespace (2 times -- also more below),0,0.9943220615386963
331351999,7378,mjsax,2019-10-04T06:07:47Z,"`time will auto advance` -- well, only if the advance is not zero. should we be more precise?",0,0.9918179512023926
331352367,7378,mjsax,2019-10-04T06:09:56Z,`keyserializer.getclass().getsimplename()` (similar for value),0,0.9948101043701172
331352477,7378,mjsax,2019-10-04T06:10:34Z,nit: `{ testoutputtopic}` nit `from [a] topic`,0,0.993316113948822
331352569,7378,mjsax,2019-10-04T06:10:58Z,nit: `create [a new object via]`,0,0.9948697090148926
331352610,7378,mjsax,2019-10-04T06:11:17Z,nit: `message` -> `record`,0,0.9932832717895508
331352696,7378,mjsax,2019-10-04T06:11:46Z,same as for input topic,0,0.9943832159042358
331352981,7378,mjsax,2019-10-04T06:13:21Z,nit: [code block],0,0.9919844269752502
331353098,7378,mjsax,2019-10-04T06:13:57Z,nit: [code block],0,0.9919844269752502
331353157,7378,mjsax,2019-10-04T06:14:19Z,`kafka` -> `record` (same for value),0,0.9947382807731628
331353208,7378,mjsax,2019-10-04T06:14:39Z,we can omit javadocs here,0,0.9948776960372925
331353431,7378,mjsax,2019-10-04T06:15:48Z,nit `[r]ecord` nit `from [the] output topic and return the record's value.`,0,0.9927881360054016
331353468,7378,mjsax,2019-10-04T06:15:58Z,i think we can omit this,0,0.9877822995185852
331354197,7378,mjsax,2019-10-04T06:19:42Z,`read one record from the output topic and return its key and value as pair.`,0,0.9932200908660889
331354239,7378,mjsax,2019-10-04T06:20:00Z,nit: `{ keyvalue}`,0,0.9921852946281433
331355498,7378,mjsax,2019-10-04T06:26:03Z,`kafka` -> `{ topologytestdriver}`,0,0.9909526109695435
331355674,7378,mjsax,2019-10-04T06:26:53Z,"`a key/value pair, including timestamp and record headers, to be sent...`",0,0.9945059418678284
331355924,7378,mjsax,2019-10-04T06:28:09Z,`if [a] record does` `{ testinputtopic} will auto advance it's time when the record is piped.`,0,0.9951188564300537
331356123,7378,mjsax,2019-10-04T06:29:01Z,remove `with a specific instant` (unclear what this means).,0,0.9931600093841553
331356208,7378,mjsax,2019-10-04T06:29:26Z,the key of the record,0,0.9939914345741272
331356259,7378,mjsax,2019-10-04T06:29:38Z,the value of the record,0,0.9911090135574341
331356323,7378,mjsax,2019-10-04T06:29:55Z,the record headers,0,0.9948709011077881
331356516,7378,mjsax,2019-10-04T06:30:54Z,remove `as instant` (that is clear from the parameter type). nit `if { null}`,0,0.9941204190254211
331356647,7378,mjsax,2019-10-04T06:31:29Z,it's unclear when `now()` or internally tracked time is used -- we should be more specific?,0,0.9863046407699585
331357009,7378,mjsax,2019-10-04T06:33:10Z,`with specified timestamp` -> sounds is if there would not be anything else specified. simply to `create a new record.`?,0,0.9941658973693848
331357212,7378,mjsax,2019-10-04T06:34:07Z,nit: `timestampms` ? nit: `since [the beginning of the] epoch` ? nit: `{ null`},0,0.9943607449531555
331357301,7378,mjsax,2019-10-04T06:34:32Z,as above: explain when which case is used?,0,0.9950060248374939
331357761,7378,mjsax,2019-10-04T06:36:36Z,nit: add braces,0,0.9947916269302368
331357774,7378,mjsax,2019-10-04T06:36:40Z,nit: add braces,0,0.9947916269302368
331358003,7378,mjsax,2019-10-04T06:37:37Z,similar comments as above -- also applies to other constructors,0,0.9947156310081482
331358093,7378,mjsax,2019-10-04T06:38:00Z,`with { null} key`,0,0.9932723641395569
331358460,7378,mjsax,2019-10-04T06:39:30Z,should we add: `objects.requirenonnull(record)`?,0,0.9950810670852661
331358507,7378,mjsax,2019-10-04T06:39:43Z,as above,0,0.9888283014297485
331358629,7378,mjsax,2019-10-04T06:40:15Z,nit: `create a { testrecord} from a { consumerrecord}.`,0,0.9944932460784912
331358675,7378,mjsax,2019-10-04T06:40:26Z,as above.,0,0.9881609678268433
331359572,7378,mjsax,2019-10-04T06:44:10Z,"nit: `{ #createinputtopic(string, serializer, serializer) create}` (make `create` the link directly)",0,0.9949473142623901
331359756,7378,mjsax,2019-10-04T06:44:55Z,`and use the` -> `and use a` `to supply input records` (plural),0,0.994703471660614
331359883,7378,mjsax,2019-10-04T06:45:33Z,as above -> make `create` the link `and use a`,0,0.9947604537010193
331359975,7378,mjsax,2019-10-04T06:45:52Z,`any output records of the topology`,0,0.9949000477790833
331360311,7378,mjsax,2019-10-04T06:47:19Z,`outputtopic2`,0,0.9937852621078491
331361415,7378,mjsax,2019-10-04T06:52:06Z,"if `key == null`, size should be `consumerrecord.null_size` (same for value)",0,0.9951602816581726
331361500,7378,mjsax,2019-10-04T06:52:31Z,as above,0,0.9888283014297485
331362053,7378,mjsax,2019-10-04T06:54:47Z,seems we encoded the size incorrectly...,0,0.9578773379325867
331364079,7378,mjsax,2019-10-04T07:02:53Z,nit: add braces (preferred for all blocks),0,0.9953833222389221
331364419,7378,mjsax,2019-10-04T07:04:17Z,remove,0,0.9896913170814514
331365084,7378,mjsax,2019-10-04T07:06:48Z,"if `time == null && record.timestamp() == null` we pass `timestamp==0`; is this intended? sounds like an error case to me (should we throw an exception, or can this never happen anyway?)",0,0.9846938848495483
331365575,7378,mjsax,2019-10-04T07:08:41Z,why do we handle this case differently?,0,0.9731263518333435
331366050,7378,mjsax,2019-10-04T07:10:41Z,"i know the context of the kip, but i think it's hard to understand for users what this means. `this method can be used if the result is considered a stream. if the result is considered a table, the list will contain all updated, ie, a key might be contained multiple times. if you are only interested in the last table update (ie, the final table state), you can use { #readkeyvaluestomap()} instead.`",0,0.8215534687042236
331366098,7378,mjsax,2019-10-04T07:10:51Z,`map` ?,0,0.9923549890518188
331366171,7378,mjsax,2019-10-04T07:11:05Z,as above,0,0.9888283014297485
331367846,7378,mjsax,2019-10-04T07:17:13Z,"we should point out in the javadocs, that null-values don't have delete semantics! ie, if the last update to a key is a delete/tombstone, the key will still be in the map (with null-value). also, i think we should not allow `null` keys, but throw an exception for this case.",0,0.9886413216590881
331368233,7378,mjsax,2019-10-04T07:18:39Z,`keydeserializer.getclass().getsimplename()` (same for value),0,0.9949268102645874
331368853,7378,mjsax,2019-10-04T07:20:50Z,we can omit javadoc for non-public methods,0,0.9943363070487976
331368920,7378,mjsax,2019-10-04T07:21:02Z,we can omit javadoc for non-public methods,0,0.9943363070487976
331368970,7378,mjsax,2019-10-04T07:21:14Z,we can omit javadoc for non-public methods,0,0.9943363070487976
331369932,7378,mjsax,2019-10-04T07:24:27Z,use `final illegalargumentexception exception = assertthrows(...)` instead of try-catch,0,0.9936216473579407
331554734,7378,jukkakarvanen,2019-10-04T15:16:23Z,renamed,0,0.9768949747085571
331556004,7378,jukkakarvanen,2019-10-04T15:19:02Z,"reason for those null parameter in testrecord contructor is limited variation of constructors with long. it would not require header parameter (null) if instant would be used, which is the prefered way for the future.",0,0.9903450608253479
331557898,7378,jukkakarvanen,2019-10-04T15:23:07Z,renamed,0,0.9768949747085571
331559215,7378,jukkakarvanen,2019-10-04T15:25:51Z,fixed,0,0.920660674571991
331559316,7378,jukkakarvanen,2019-10-04T15:26:05Z,fixed,0,0.920660674571991
331560205,7378,jukkakarvanen,2019-10-04T15:28:05Z,fixed and order aligned,0,0.9913285374641418
331561533,7378,jukkakarvanen,2019-10-04T15:31:12Z,changed,0,0.7968646287918091
331562321,7378,jukkakarvanen,2019-10-04T15:33:02Z,changed,0,0.7968646287918091
331562657,7378,jukkakarvanen,2019-10-04T15:33:48Z,changed,0,0.7968646287918091
331568443,7378,jukkakarvanen,2019-10-04T15:47:06Z,done,0,0.8682363629341125
331568499,7378,jukkakarvanen,2019-10-04T15:47:14Z,done,0,0.8682363629341125
331568797,7378,jukkakarvanen,2019-10-04T15:47:54Z,fixed,0,0.920660674571991
331570268,7378,jukkakarvanen,2019-10-04T15:51:22Z,this is removed,0,0.993802547454834
331570450,7378,jukkakarvanen,2019-10-04T15:51:47Z,removed contructor and javadoc,0,0.9928379654884338
331571591,7378,jukkakarvanen,2019-10-04T15:54:24Z,changed,0,0.7968646287918091
331572126,7378,jukkakarvanen,2019-10-04T15:55:35Z,updated,0,0.7592994570732117
331573167,7378,jukkakarvanen,2019-10-04T15:57:47Z,replaced all messages,0,0.9883870482444763
331573595,7378,jukkakarvanen,2019-10-04T15:58:46Z,fixed,0,0.920660674571991
331578731,7378,jukkakarvanen,2019-10-04T16:11:15Z,changed,0,0.7968646287918091
331578775,7378,jukkakarvanen,2019-10-04T16:11:21Z,removed,0,0.9591778516769409
331578924,7378,jukkakarvanen,2019-10-04T16:11:44Z,removed,0,0.9591778516769409
331579069,7378,jukkakarvanen,2019-10-04T16:12:06Z,removed,0,0.9591778516769409
331580264,7378,jukkakarvanen,2019-10-04T16:14:56Z,changed,0,0.7968646287918091
331582622,7378,jukkakarvanen,2019-10-04T16:21:05Z,added,0,0.8435775637626648
331585568,7378,jukkakarvanen,2019-10-04T16:28:45Z,fixed,0,0.920660674571991
331585636,7378,jukkakarvanen,2019-10-04T16:28:58Z,clarified,0,0.991011381149292
331585726,7378,jukkakarvanen,2019-10-04T16:29:12Z,changed,0,0.7968646287918091
331587844,7378,jukkakarvanen,2019-10-04T16:34:56Z,to my understanding null can happen either topic does not exist or no input piped to that topic. this is to able to throw error if topic does not exist at all.,0,0.9869967699050903
331590978,7378,jukkakarvanen,2019-10-04T16:43:40Z,i needed to modify like that to get some old test to work. it might be some non valid test.,0,0.9631024599075317
331591058,7378,jukkakarvanen,2019-10-04T16:43:55Z,removed,0,0.9591778516769409
331591666,7378,jukkakarvanen,2019-10-04T16:45:28Z,added,0,0.8435775637626648
331592830,7378,jukkakarvanen,2019-10-04T16:48:43Z,fixed,0,0.920660674571991
331592861,7378,jukkakarvanen,2019-10-04T16:48:50Z,fixed,0,0.920660674571991
331593078,7378,jukkakarvanen,2019-10-04T16:49:29Z,", what this means, is actions needed from my side",0,0.9711586236953735
331593792,7378,jukkakarvanen,2019-10-04T16:51:26Z,changed record2 to read from outputtopic2,0,0.9935990571975708
331594180,7378,jukkakarvanen,2019-10-04T16:52:29Z,changed,0,0.7968646287918091
331596166,7378,jukkakarvanen,2019-10-04T16:57:43Z,done,0,0.8682363629341125
331596244,7378,jukkakarvanen,2019-10-04T16:57:54Z,done,0,0.8682363629341125
331596343,7378,jukkakarvanen,2019-10-04T16:58:10Z,done,0,0.8682363629341125
331596809,7378,jukkakarvanen,2019-10-04T16:59:24Z,done,0,0.8682363629341125
331596839,7378,jukkakarvanen,2019-10-04T16:59:29Z,done,0,0.8682363629341125
331598905,7378,jukkakarvanen,2019-10-04T17:05:12Z,added,0,0.8435775637626648
331598928,7378,jukkakarvanen,2019-10-04T17:05:16Z,added,0,0.8435775637626648
331599147,7378,jukkakarvanen,2019-10-04T17:05:53Z,replaced,0,0.9740249514579773
331600525,7378,jukkakarvanen,2019-10-04T17:09:46Z,changed,0,0.7968646287918091
331600579,7378,jukkakarvanen,2019-10-04T17:09:54Z,done,0,0.8682363629341125
331603570,7378,jukkakarvanen,2019-10-04T17:17:58Z,replaced in all places,0,0.9903529286384583
331604119,7378,jukkakarvanen,2019-10-04T17:19:22Z,"i removed time generator logic text, it is functionality of testinputlogic, not needed here.",0,0.9937354922294617
331604682,7378,jukkakarvanen,2019-10-04T17:20:59Z,done,0,0.8682363629341125
331604752,7378,jukkakarvanen,2019-10-04T17:21:08Z,done,0,0.8682363629341125
331604866,7378,jukkakarvanen,2019-10-04T17:21:25Z,same as above,0,0.9918335676193237
331604966,7378,jukkakarvanen,2019-10-04T17:21:43Z,same as above,0,0.9918335676193237
331605927,7378,jukkakarvanen,2019-10-04T17:24:12Z,changed,0,0.7968646287918091
331606011,7378,jukkakarvanen,2019-10-04T17:24:23Z,changed,0,0.7968646287918091
331606681,7378,jukkakarvanen,2019-10-04T17:26:01Z,changed multiple occurences,0,0.9636240005493164
331607233,7378,jukkakarvanen,2019-10-04T17:27:15Z,removed,0,0.9591778516769409
331608046,7378,jukkakarvanen,2019-10-04T17:29:11Z,replaced,0,0.9740249514579773
331608817,7378,jukkakarvanen,2019-10-04T17:31:05Z,changed,0,0.7968646287918091
331610034,7378,jukkakarvanen,2019-10-04T17:34:27Z,done,0,0.8682363629341125
331610133,7378,jukkakarvanen,2019-10-04T17:34:42Z,done,0,0.8682363629341125
331610298,7378,jukkakarvanen,2019-10-04T17:35:10Z,removed,0,0.9591778516769409
331610965,7378,jukkakarvanen,2019-10-04T17:36:58Z,changed,0,0.7968646287918091
331611197,7378,jukkakarvanen,2019-10-04T17:37:26Z,removed,0,0.9591778516769409
331611349,7378,jukkakarvanen,2019-10-04T17:37:50Z,done,0,0.8682363629341125
331612150,7378,jukkakarvanen,2019-10-04T17:39:42Z,changed,0,0.7968646287918091
331612202,7378,jukkakarvanen,2019-10-04T17:39:49Z,changed,0,0.7968646287918091
331612485,7378,jukkakarvanen,2019-10-04T17:40:27Z,replaced,0,0.9740249514579773
331613185,7378,jukkakarvanen,2019-10-04T17:42:15Z,instance as in inputtopic,0,0.9943925738334656
331613689,7378,jukkakarvanen,2019-10-04T17:43:33Z,done,0,0.8682363629341125
331613912,7378,jukkakarvanen,2019-10-04T17:44:03Z,done,0,0.8682363629341125
331614099,7378,jukkakarvanen,2019-10-04T17:44:31Z,done,0,0.8682363629341125
331615408,7378,jukkakarvanen,2019-10-04T17:47:52Z,clarified,0,0.991011381149292
331615881,7378,jukkakarvanen,2019-10-04T17:49:09Z,done,0,0.8682363629341125
331617799,7378,jukkakarvanen,2019-10-04T17:53:54Z,added,0,0.8435775637626648
331621072,7378,mjsax,2019-10-04T18:02:07Z,ack.,0,0.5866091847419739
331622341,7378,mjsax,2019-10-04T18:05:40Z,"no -- i just acknowledged that you basically move code that was already ""wrong"", so not your fault to use `0` instead of `consumer.null_size` :) -- no action needed.",1,0.9721126556396484
331623203,7378,mjsax,2019-10-04T18:08:08Z,ack.,0,0.5866091847419739
331634638,7378,mjsax,2019-10-04T18:36:08Z,this must be `output_topic_2`,0,0.9958862662315369
331638698,7378,jukkakarvanen,2019-10-04T18:46:45Z,i don't understand the original test. why it is checking output_topic_2 if it is not in topology at all.,-1,0.5745238065719604
331643505,7378,jukkakarvanen,2019-10-04T18:59:40Z,i pushed the version with outputtopic2 removed,0,0.9942228198051453
331648099,7378,mjsax,2019-10-04T19:12:52Z,"well. overwriting the timestamp is fine, however, if we don't pass in `final instant time`, we should just pass `record.timestamp()` into `piperecord()` -- i checked out the code applied the following change an run test (and they passed---hence, i think it fine to be more strict) [code block]",0,0.9717943072319031
331654063,7378,mjsax,2019-10-04T19:30:36Z,"the original intent of the test was to ensure, we don't write into non-exiting topics, ie, create a topic out of nowhere -- but with the new abstraction that cannot happen anyway i guess.",0,0.9656893014907837
331659853,7378,jukkakarvanen,2019-10-04T19:47:53Z,some tests failing if making change like this.,0,0.6003648042678833
221138500,5709,bbejeck,2018-09-28T04:25:41Z,added for access to contents of `grouped`. i added this class to follow the pattern we currently use for configuration classes.,0,0.9952713847160339
221138726,5709,bbejeck,2018-09-28T04:28:29Z,i did this to be consistent with `sessionwindowedkstreamimpl`,0,0.9948698282241821
221138924,5709,bbejeck,2018-09-28T04:30:40Z,needed to change the topology as we now use the topic name of the first merged/replaced repartition topic when performing repartition topic optimization.,0,0.9924782514572144
221138954,5709,bbejeck,2018-09-28T04:31:00Z,same as above,0,0.9918335676193237
221139121,5709,bbejeck,2018-09-28T04:32:38Z,same here and below needed to update the expected topology as now we use the topic name of the **_first_** merged repartition topic for the new optimized repartition topic.,0,0.9953469634056091
221139255,5709,bbejeck,2018-09-28T04:34:12Z,"most of the loc in this class are boilerplate to create the topologies for the tests, and the expected optimized and non-optimized topologies.",0,0.987837016582489
221141350,5709,bbejeck,2018-09-28T04:58:47Z,required to keep the merge nodes in the same order as they are added to the graph. they may be used later when performing an optimization if the merged node represents key-changing operations up-stream.,0,0.9931052327156067
221141409,5709,bbejeck,2018-09-28T04:59:37Z,keep `optimizablerepartitonnodes` in the same order as they are added.,0,0.9943886399269104
221141573,5709,bbejeck,2018-09-28T05:01:13Z,now grab the topic name from the first existing repartition topic that will get merged/replaced.,0,0.994748055934906
221142005,5709,bbejeck,2018-09-28T05:05:25Z,keep the key-changing parent nodes for the merge node in order.,0,0.9937294721603394
221142221,5709,bbejeck,2018-09-28T05:07:11Z,keep the `optimizablerepartitionnode`s in order as they are mapped to merge nodes,0,0.9947506785392761
221284385,5709,vvcephei,2018-09-28T15:03:18Z,"maybe a nit: you could alternatively return `return new grouped<>(name, keyserde, valueserde);` from this and the following methods and then make the three variables `final`. personally, i'd feel more comfortable making them `protected` (for `groupedinternal`'s access) if they were final.",0,0.9765627980232239
221284484,5709,vvcephei,2018-09-28T15:03:37Z,"i assume this is in reference to [a link] just jotting down some thoughts: if this were iface/impl, all the state would be private, and there'd be no need for the `protected` copy constructor. but if we decide we like kafka-7435, we'd apply it to all the config objects, and converting this one would be low incremental cost. i'm :+1: for defaulting to the common pattern.",1,0.970134437084198
221287987,5709,vvcephei,2018-09-28T15:13:45Z,nit: maybe just call this `name` for consistency?,0,0.9828765988349915
221288250,5709,vvcephei,2018-09-28T15:14:23Z,nit: formatting,0,0.9899442195892334
221288991,5709,vvcephei,2018-09-28T15:16:34Z,"hmm. i failed to notice this in the kip... should this be `named` like `grouped.named`? seems like a minor kip update that would be ok at this point, but valuable to establish consistency now.",0,0.8265960216522217
221289641,5709,vvcephei,2018-09-28T15:18:32Z,"nit: maybe just call the constructor. the other static method doesn't apply any defaults, so there's no benefit to the chained method call.",0,0.9558349251747131
221291992,5709,vvcephei,2018-09-28T15:25:33Z,"""xxx"" could also be configured via `grouped`, right?",0,0.9922210574150085
221293611,5709,vvcephei,2018-09-28T15:30:39Z,"did you mean to also insert a ` ` here, so the html would be formatted the same as this javadoc?",0,0.9940317273139954
221294337,5709,vvcephei,2018-09-28T15:32:58Z,"maybe we can also add note to the javadoc, like ` since 2.1. use { groupbykey(grouped)} instead.` ?",0,0.9910637140274048
221294537,5709,vvcephei,2018-09-28T15:33:25Z,ditto on the deprecation notice in the javadoc.,0,0.9901387691497803
221295115,5709,vvcephei,2018-09-28T15:35:12Z,i didn't follow: it seems like there's no restriction that `kr` is the same as `k`. or did you mean something else?,0,0.9805429577827454
221295243,5709,vvcephei,2018-09-28T15:35:40Z,similar question re: ` `,0,0.9933837056159973
221295702,5709,vvcephei,2018-09-28T15:36:53Z,"similar question re: ""xxx"" and `grouped.named`",0,0.9946308135986328
221296087,5709,vvcephei,2018-09-28T15:38:09Z,nit: missing the `` for `grouped`,0,0.9864110350608826
221296127,5709,vvcephei,2018-09-28T15:38:16Z,nit: missing the `` for `grouped`,0,0.9864110350608826
221296539,5709,vvcephei,2018-09-28T15:39:41Z,"this one should be ``, right?",0,0.993000864982605
221296735,5709,vvcephei,2018-09-28T15:40:24Z,similar comment re: ` `,0,0.9947578310966492
221296798,5709,vvcephei,2018-09-28T15:40:37Z,super nit: alignment ;),1,0.9139975905418396
221297424,5709,vvcephei,2018-09-28T15:42:48Z,similar question about:,0,0.9905800223350525
221299721,5709,vvcephei,2018-09-28T15:50:08Z,"similar questoin re ""xxx""",0,0.9950361847877502
221299939,5709,vvcephei,2018-09-28T15:50:52Z,similar question re: `` javadoc,0,0.9929375052452087
221301291,5709,vvcephei,2018-09-28T15:55:07Z,"sounds good. if this is an important semantic property of `mergenodes`, perhaps we should declare the variable as a `linkedhashset` as well?",0,0.7754234075546265
221301788,5709,vvcephei,2018-09-28T15:56:52Z,"similar to my question about `mergenodes`, should we go ahead and declare `keychangingoperationstooptimizablerepartitionnodes` as a `linkedhashmap >` to document that the insertion order is preserved at both levels?",0,0.9940491914749146
221303796,5709,vvcephei,2018-09-28T16:03:59Z,ditto,0,0.9754701256752014
221303825,5709,vvcephei,2018-09-28T16:04:07Z,ditto,0,0.9754701256752014
221304091,5709,vvcephei,2018-09-28T16:05:09Z,"would you be ok with renaming ""name"" to ""nodename"" to disambiguate?",0,0.9930001497268677
221304694,5709,vvcephei,2018-09-28T16:07:18Z,did we want to give priority to the explicitly named repartition topics?,0,0.9913861751556396
221304981,5709,vvcephei,2018-09-28T16:08:16Z,nit: alignment,0,0.9908159971237183
221305467,5709,vvcephei,2018-09-28T16:09:52Z,"nit: since the `groupedstreamaggregatebuilder` needs to know everything that's in `groupedinternal`, maybe we can just pass the whole config object in to cut down on the param list?",0,0.9876745343208313
221305778,5709,vvcephei,2018-09-28T16:10:58Z,"thanks! i just noticed this yesterday, and it did trip me up a little.",1,0.9905176758766174
221307699,5709,vvcephei,2018-09-28T16:18:09Z,what's the code path that leads to `repartitiontopicbasename.endswith(repartition_topic_suffix)`? i couldn't find it.,0,0.989078938961029
221309541,5709,vvcephei,2018-09-28T16:24:52Z,"i think if you mark this method as `` as well, it will also suppress the warnings, which might be better because it preserves the deprecation notice from the interface.",0,0.9803997278213501
221309956,5709,vvcephei,2018-09-28T16:26:13Z,ditto,0,0.9754701256752014
221310171,5709,vvcephei,2018-09-28T16:27:05Z,ditto to `kstreamimpl`,0,0.9946117401123047
221310476,5709,vvcephei,2018-09-28T16:28:07Z,ditto to `kstreamimpl`: it might be better to mark this class ``,0,0.994192898273468
221310586,5709,vvcephei,2018-09-28T16:28:31Z,thank you!,1,0.9448403120040894
221314587,5709,vvcephei,2018-09-28T16:44:00Z,should this be `shouldkeeprepartitiontopicnameforgroupbykeynowindows`?,0,0.9943647384643555
221353167,5709,bbejeck,2018-09-28T19:06:35Z,ack,0,0.9149930477142334
221356038,5709,bbejeck,2018-09-28T19:18:35Z,"i can but this change isn't specific to the semantics of merge nodes themselves, it's more about bookkeeping and keeping them in the same order as they are added when building the graph. since this is private variables i'll make the change.",0,0.9946098327636719
221356652,5709,bbejeck,2018-09-28T19:21:19Z,"ack, same as above",0,0.9855887293815613
221356700,5709,bbejeck,2018-09-28T19:21:33Z,"ack, same as above",0,0.9855887293815613
221356733,5709,bbejeck,2018-09-28T19:21:46Z,"ack, same as above",0,0.9855887293815613
221358640,5709,bbejeck,2018-09-28T19:29:32Z,ack,0,0.9149930477142334
221361859,5709,bbejeck,2018-09-28T19:43:47Z,ack,0,0.9149930477142334
221361903,5709,bbejeck,2018-09-28T19:43:55Z,ack,0,0.9149930477142334
221369563,5709,bbejeck,2018-09-28T20:15:44Z,"ack, copy-paste error",-1,0.6538105607032776
221369692,5709,bbejeck,2018-09-28T20:16:16Z,i'll add but i believe that was pre-existing,0,0.9929919242858887
221369921,5709,bbejeck,2018-09-28T20:17:13Z,ack,0,0.9149930477142334
221370454,5709,bbejeck,2018-09-28T20:19:29Z,ack,0,0.9149930477142334
221371198,5709,bbejeck,2018-09-28T20:22:39Z,"pre-existing, fixed",0,0.9933567643165588
221371933,5709,bbejeck,2018-09-28T20:25:25Z,"pre-existing, you'll notice the other java doc has the same thing, i'll update though",0,0.9945857524871826
221373333,5709,bbejeck,2018-09-28T20:30:45Z,fixed,0,0.920660674571991
221378081,5709,bbejeck,2018-09-28T20:51:02Z,ack,0,0.9149930477142334
221378533,5709,bbejeck,2018-09-28T20:52:52Z,ack,0,0.9149930477142334
221379140,5709,bbejeck,2018-09-28T20:55:35Z,ack,0,0.9149930477142334
221379486,5709,bbejeck,2018-09-28T20:57:04Z,ack,0,0.9149930477142334
221379642,5709,bbejeck,2018-09-28T20:57:43Z,ack,0,0.9149930477142334
221380525,5709,bbejeck,2018-09-28T21:01:54Z,"legacy comments, fixed",0,0.7363269925117493
221380620,5709,bbejeck,2018-09-28T21:02:14Z,ack,0,0.9149930477142334
221380780,5709,bbejeck,2018-09-28T21:03:07Z,ack,0,0.9149930477142334
221382112,5709,bbejeck,2018-09-28T21:09:24Z,ack,0,0.9149930477142334
221383257,5709,bbejeck,2018-09-28T21:15:18Z,"i had the same thought, but so far we've only discussed grabbing the first repartition topic name. i'm inclined to leave as is because 1) users don't care about the name as much as it doesn't change and break the topology and 2) imho will add some complexity without a significant benefit",0,0.777969241142273
221383379,5709,bbejeck,2018-09-28T21:15:47Z,"i had the same thought, i think this just slipped.",0,0.9538877606391907
221386486,5709,bbejeck,2018-09-28T21:32:45Z,"it comes from the `repartitiontopicnameprefix` passed as a parameter when calling `createrepartitionedsource`. since we may get an existing repartition topic name, we don't want to append `-repartition` at the end and change it. for example, we may get `kstream-aggregate-state-store-0000000005-repartition` for a repartition topic name resulting from an optimization operation and appending another `-repartition` would break the topology. as the java docs and our other docs state, we append as single `-repartition` to the repartition topic name we wouldn't want to double append. but i'll update this with a comment explaining why we do this check.",0,0.9931186437606812
221386734,5709,bbejeck,2018-09-28T21:33:53Z,ack,0,0.9149930477142334
221386797,5709,bbejeck,2018-09-28T21:34:13Z,ack,0,0.9149930477142334
221387336,5709,bbejeck,2018-09-28T21:36:49Z,ack,0,0.9149930477142334
221387515,5709,bbejeck,2018-09-28T21:37:46Z,"yeah, especially as `serialized` is deprecated, good catch!",1,0.9943048357963562
221388695,5709,bbejeck,2018-09-28T21:44:18Z,good catch actually `shouldkeeprepartitiontopicnameforgroupbynowindows`,1,0.8285738825798035
221431415,5709,vvcephei,2018-09-29T15:28:25Z,ack. it's probably also likely that the user who names some repartition topics names them all; another reason the extra complexity wouldn't buy anything.,-1,0.7101108431816101
221431492,5709,vvcephei,2018-09-29T15:31:49Z,i agree we shouldn't append multiple suffixes. it just wasn't clear where the pre-suffixed string could come from. thanks for the clarification!,1,0.9760766625404358
221442359,5709,mjsax,2018-09-29T23:12:46Z,"this is ok, because not part of 2.0, right?",0,0.9813207983970642
221442399,5709,mjsax,2018-09-29T23:15:37Z,"missing `, or ` and missing space before `operations`",0,0.9895686507225037
221442444,5709,mjsax,2018-09-29T23:18:45Z,`set the name` -- the specified name is part of the topic name -- think we should be more precise (note: i would not describe the used naming pattern in javadocs though) similar below in method javadocs.,0,0.9933618307113647
221442610,5709,mjsax,2018-09-29T23:30:15Z,nit: missing `.` at the end,0,0.9874536991119385
221442612,5709,mjsax,2018-09-29T23:30:21Z,nit: missing `.` at the end,0,0.9874536991119385
221442618,5709,mjsax,2018-09-29T23:30:47Z,"nit: missing `.` at the end oxford comma? nit: `{ name}, { keyserde}, and { valueserde}.` (similar below)",0,0.9941383600234985
221442626,5709,mjsax,2018-09-29T23:31:33Z,nit: `{ grouped}` similar below.,0,0.9935904741287231
221442659,5709,mjsax,2018-09-29T23:34:34Z,agreed with john. we should keep immutability. existing code also creates new objects. (similar below) also update javadocs `return this` above.,0,0.9889095425605774
221442678,5709,mjsax,2018-09-29T23:36:03Z,nit: fix indention,0,0.574457049369812
221442709,5709,mjsax,2018-09-29T23:38:20Z,return `new joined(...)`,0,0.9909294247627258
221442733,5709,mjsax,2018-09-29T23:40:00Z,nit: missing space,-1,0.6934642791748047
221442771,5709,mjsax,2018-09-29T23:43:03Z,nit: update `xxx` to ` ` (or `<name>` to be more precise),0,0.9949584603309631
221442809,5709,mjsax,2018-09-29T23:46:11Z,"`the name for a repartition topic`: it's not the name, but part of the name only",0,0.9858980178833008
221442824,5709,mjsax,2018-09-29T23:47:42Z,"nice catch! (can you double check other javadocs, too. could be c&p error.)",1,0.9966879487037659
221442832,5709,mjsax,2018-09-29T23:48:24Z,nit: missing space,-1,0.6934642791748047
221442841,5709,mjsax,2018-09-29T23:49:16Z,nit: missing space,-1,0.6934642791748047
221442855,5709,mjsax,2018-09-29T23:50:04Z,nit: remove one space before `and the name...`,0,0.992914080619812
221442858,5709,mjsax,2018-09-29T23:50:29Z,remove `<`,0,0.9879712462425232
221442872,5709,mjsax,2018-09-29T23:51:51Z,`maybe being` sounds a little odd to me... (not a native speaker though),0,0.5607872605323792
221442895,5709,mjsax,2018-09-29T23:54:38Z,nit: why does left hand side needs to specify classed instead of interface?,0,0.9636929631233215
221442905,5709,mjsax,2018-09-29T23:55:17Z,why is `set` not sufficient?,0,0.9799460768699646
221442912,5709,mjsax,2018-09-29T23:55:43Z,why not `set` left hand side?,0,0.9896475672721863
221442930,5709,bbejeck,2018-09-29T23:57:12Z,"yes, that's correct. i checked out the `2.0` branch to confirm.",0,0.9905669093132019
221442957,5709,mjsax,2018-09-29T23:59:41Z,"nit: this is the user specified name, that is part of the repartition topic name -- we should rename this",0,0.9941163063049316
221442960,5709,mjsax,2018-09-30T00:00:39Z,nit: the use specified name is part of the repartition topic only -- we should rename this to `name` or `username`?,0,0.9933302998542786
221443004,5709,mjsax,2018-09-30T00:04:03Z,could we set `name` instead of `null` here and simplify other code (cf. my comments below) ?,0,0.993779718875885
221443009,5709,mjsax,2018-09-30T00:04:28Z,remove `name` parameter ? (cf. comment above),0,0.9945631623268127
221443020,5709,mjsax,2018-09-30T00:05:18Z,i think we can remove `repartitiontopicbasename` entirely (cf. my comments from above),0,0.9864379167556763
221443050,5709,mjsax,2018-09-30T00:07:57Z,"cannot follow here... do you aim for existing topologies with generated names, and user update code to ""pin"" names? for this case, user would pass it name, without `-repartition` suffix? user, would also need to drop ` ` prefix in the name she passed to `grouped`.",0,0.989741325378418
221443054,5709,mjsax,2018-09-30T00:08:40Z,nit: remove empty lines,0,0.9926950931549072
221443072,5709,mjsax,2018-09-30T00:09:37Z,"do we need this annotation again? though we would need a `(""deprecation"")` here instead?",0,0.994347870349884
221443096,5709,mjsax,2018-09-30T00:10:07Z,nit: 4 space indention only,0,0.9889389276504517
221443107,5709,mjsax,2018-09-30T00:10:22Z,as above,0,0.9888283014297485
221443114,5709,mjsax,2018-09-30T00:10:54Z,nit: 4-space indention plus move `builder` down one line,0,0.9912785887718201
221443122,5709,mjsax,2018-09-30T00:11:19Z,as above,0,0.9888283014297485
221443126,5709,mjsax,2018-09-30T00:11:37Z,nit: 4-space indention,0,0.9872116446495056
221443137,5709,mjsax,2018-09-30T00:12:20Z,"no need to deprecate an internal class imho. maybe add `(""deprecation"")` instead?",0,0.9909975528717041
221443198,5709,mjsax,2018-09-30T00:16:18Z,should this not fail here in `groupbykey()` already? maybe use `try-fail-catch` pattern here.,0,0.9907826781272888
221443199,5709,mjsax,2018-09-30T00:16:39Z,nit: missing `t`,0,0.9858027696609497
221443236,5709,mjsax,2018-09-30T00:20:43Z,"not sure why this should not be allowed? to be more precise: i understand why the code fails, however, it's very unintuitive for the user why this would fail -- looks like valid code and imho, users should be allowed to write this code: both operations can reuse the same repartition topic anyway (and with optimization turned on, they will, if i don't miss anything). not sure if we can fix this easily to be honest, but accepting this as ""by design"" would not be user friendly. maybe we can merge both repartition topics into one for this case, too?",-1,0.8206131458282471
221461753,5709,vvcephei,2018-09-30T14:39:15Z,"i suggested this. while it is normally better to use an interface on the lhs, it should only be done if the interface provides the correct semantics. i.e., you should be able to swap out any two implementations of the interface and maintain correct behavior. normally, when we work with maps or sets, we do indeed need just the semantics they promise (i.e., a k/v mapping, or the set property), and we could in theory use any implementation without changing the correctness of the program. but in this case, it seemed like the correct behavior of this class depends on maintaining these collections in insertion order. unfortunately, java does not have an interface for an ordered map or set. therefore, the most general ""interface"" that provides the correct semantics is actually just the implicit interface of linkedhashmap/set itself.",0,0.9767925143241882
221461770,5709,vvcephei,2018-09-30T14:39:48Z,this is also my fault... see [a link],-1,0.9769483208656311
221461780,5709,vvcephei,2018-09-30T14:40:14Z,this is also my fault... see [a link],-1,0.9769483208656311
221462040,5709,vvcephei,2018-09-30T14:51:38Z,"imho, it's better to pass along the deprecation instead of suppressing it. they both cause the compiler not to issue warnings about the use of deprecated apis in the method body. this difference is that if we suppress it here, then any `groupby` calls on a `kstreamimpl` reference *will not* issue a warning, whereas calls on a `kstream` reference will issue the warning as desired.",0,0.9800336956977844
221462114,5709,vvcephei,2018-09-30T14:54:50Z,this is the same thinking as [a link] .,0,0.9896416068077087
221470735,5709,guozhangwang,2018-09-30T19:41:53Z,"also we should indicate that it is for setting the repartition topic ""if necessary: streams will not always create the repartition topic for grouped operation"".",0,0.9941055774688721
221470841,5709,guozhangwang,2018-09-30T19:44:56Z,this just occurred to me that `grouped.named()` is a bit weird when writing it down. could we rename it to `grouped.as()` or `grouped.for`? wdyt,0,0.5204310417175293
221471094,5709,guozhangwang,2018-09-30T19:51:00Z,`will be` -> `may need to be created in kafka if a later operator depends on the newly selected key.` ditto elsewhere.,0,0.9925103187561035
221471436,5709,guozhangwang,2018-09-30T20:00:14Z,"`repartitiontopicname` and `repartitiontopic` is a bit confusing. i'd suggest just keeping the `groupedinternal` as a field to replace key/valueserde and `repartitiontopicname` in the constructor and retrieve its fields later. ditto for other internal class's constructors (you already replaced serdes with the object in some classes, just trying to suggest consistency here).",0,0.6435989141464233
221471570,5709,guozhangwang,2018-09-30T20:03:37Z,"i cannot follow here too.. the `createrepartitionedsource` should always be called before the optimization kicks in, so the passed in name should always be the raw names right?",0,0.9905300736427307
221471689,5709,guozhangwang,2018-09-30T20:07:31Z,+1,0,0.9816582202911377
221471765,5709,guozhangwang,2018-09-30T20:09:21Z,not clear what is this test used for?,0,0.942409336566925
221471837,5709,guozhangwang,2018-09-30T20:11:46Z,"i think the reason is that we do not check for unique names at grouped / joined, and hence only when later when the repartition topics are indeed going to be created the exception will be thrown. this looks fine to me.",0,0.967698872089386
221471891,5709,guozhangwang,2018-09-30T20:14:32Z,"seems for joined we do not have a test to check for naming uniqueness yet, could we add one?",0,0.9926276803016663
221476261,5709,mjsax,2018-09-30T22:37:37Z,"i don't think that suppress works for any callers of `kstreamimpl#groupby` -- from my understanding, there will be a warning for all callers independently of a suppress annotation -- callers would need to add their own annotation to suppress the warning for them. a `suppresswarning` only suppressed warning from the body/implementation of this method (ie, if we would call any other deprecated method). i also don't think we need `` as this annotation is inherited anyway. however, this is an internal class anyway, and thus, not public. thus, i don't have a strong opinion on this.",0,0.9635409712791443
221476305,5709,mjsax,2018-09-30T22:39:26Z,ack. thanks for clarification.,1,0.9273879528045654
221476351,5709,mjsax,2018-09-30T22:41:33Z,that's a good point. `grouped.as()` sounds ok (`grouped.for()` sounds weird to me though).,1,0.9511949419975281
221476723,5709,bbejeck,2018-09-30T22:56:31Z,ack,0,0.9149930477142334
221477923,5709,bbejeck,2018-09-30T23:41:23Z,ack,0,0.9149930477142334
221477926,5709,bbejeck,2018-09-30T23:41:26Z,"ack, changed the suggested order a bit, but imho the message is the same.",0,0.5679880976676941
221477927,5709,bbejeck,2018-09-30T23:41:28Z,ack,0,0.9149930477142334
221477928,5709,bbejeck,2018-09-30T23:41:30Z,ack,0,0.9149930477142334
221477929,5709,bbejeck,2018-09-30T23:41:32Z,ack,0,0.9149930477142334
221477932,5709,bbejeck,2018-09-30T23:41:35Z,ack,0,0.9149930477142334
221477934,5709,bbejeck,2018-09-30T23:41:37Z,ack,0,0.9149930477142334
221477937,5709,bbejeck,2018-09-30T23:41:40Z,"ack, updated other methods as well.",0,0.983350396156311
221477940,5709,bbejeck,2018-09-30T23:41:43Z,ack,0,0.9149930477142334
221477941,5709,bbejeck,2018-09-30T23:41:46Z,ack,0,0.9149930477142334
221477959,5709,bbejeck,2018-09-30T23:41:52Z,ack,0,0.9149930477142334
221477965,5709,bbejeck,2018-09-30T23:41:55Z,ack,0,0.9149930477142334
221477967,5709,bbejeck,2018-09-30T23:41:57Z,ack,0,0.9149930477142334
221477968,5709,bbejeck,2018-09-30T23:42:01Z,ack,0,0.9149930477142334
221477969,5709,bbejeck,2018-09-30T23:42:03Z,ack,0,0.9149930477142334
221477999,5709,bbejeck,2018-09-30T23:43:22Z,"yeah i agree, updated.",0,0.9224082827568054
221478087,5709,bbejeck,2018-09-30T23:46:58Z,"additionally, i would in most circumstances agree with specifying the interface, but since these are private variables on an internal class, there is no ""leaking"" of an implementation.",0,0.9931706190109253
221478133,5709,bbejeck,2018-09-30T23:49:12Z,ack,0,0.9149930477142334
221478190,5709,bbejeck,2018-09-30T23:50:40Z,ack,0,0.9149930477142334
221482476,5709,bbejeck,2018-10-01T01:40:31Z,ack,0,0.9149930477142334
221482479,5709,bbejeck,2018-10-01T01:40:35Z,ack,0,0.9149930477142334
221483107,5709,bbejeck,2018-10-01T01:51:12Z,ack already done,0,0.971814751625061
221483292,5709,bbejeck,2018-10-01T01:54:33Z,ack,0,0.9149930477142334
221483725,5709,bbejeck,2018-10-01T02:02:28Z,ack,0,0.9149930477142334
221484247,5709,bbejeck,2018-10-01T02:11:42Z,ack,0,0.9149930477142334
221484591,5709,bbejeck,2018-10-01T02:17:43Z,ack,0,0.9149930477142334
221485045,5709,bbejeck,2018-10-01T02:24:39Z,"as pointed out, the error does not occur until we go to build the topology and the duplicate topic name is detected and at that point, the error is thrown. i can update with the `try-fail-catch` pattern, but have we established this as a convention of unit tests vs using the `(expected=...)` approach?",0,0.9932367205619812
221485076,5709,bbejeck,2018-10-01T02:25:06Z,ack,0,0.9149930477142334
221490175,5709,bbejeck,2018-10-01T03:40:05Z,"just asserting that the different repartition topic base names resulted in successfully building the topology, but this is covered from other tests, so i'll remove it",0,0.9931238293647766
221490839,5709,mjsax,2018-10-01T03:48:48Z,"i personally highly prefer the try-fail-catch pattern, because it allows to narrow down which operation throws the exception. the current test would pass if the same exception is thrown one line above. imho, the `expected` annotation should only be used, if no other part in the test code could potentially throw the same exception (what is rarely the case).",0,0.7150866985321045
221490975,5709,bbejeck,2018-10-01T03:50:34Z,ack,0,0.9149930477142334
221491369,5709,bbejeck,2018-10-01T03:55:57Z,"ack, i believe i've cleaned this up.",0,0.9731017351150513
221492650,5709,bbejeck,2018-10-01T04:14:00Z,"ack, `grouped.as` is better, i'll update.",0,0.9845404028892517
221496830,5709,bbejeck,2018-10-01T05:12:28Z,"i agree, but imho it's exposing some unintuitive behavior with respect to creating multiple repartition topics. and yes with optimizations turned on users will be able to write code in this form. but as it stands now, by explicitly naming a repartition i don't see how we can re-use a single `kgroupedstream` instance, as before we relied on the auto-generated names to handle the creation of multiple repartition topics. i'm not sure i follow, do you mean in this case we do an automatic optimization and merge repartition topics ""in-line""? if so, i'm inclined to say yes we can, but i'm thinking this may be done best in a follow-on pr. wdyt?",0,0.7706146836280823
221509793,5709,mjsax,2018-10-01T07:08:07Z,"something like this -- the idea would be to set a ""flag"" on the `kgroupedstream` (same for `kgroupedtable`?) after the first `count()/reduce()/aggregate()` is executed and to remember the created repartition topic. and for this case, consecutive `count()/reduce()/aggregate()` would skip creating a new changelog topic but reuse the already created one. for backward compatibility, we would only do this if `grouped.as` is specified. it might be a little bit hacky, but might be worth it... thoughts?",0,0.9668186902999878
221629926,5709,bbejeck,2018-10-01T14:29:31Z,"i like the idea; i'll try and implement that now edit: looking at this i have some more thoughts. why limit to just when people name the repartition topic? since we have a graph now, we can keep a reference to the repartition graph node and at this point in the code always re-use this node for repartitioning. but this could be tricky as this will still affect an existing topology. for example, consider a user with multiple `kgroupedstream` calls where a repartition is required. while this means we have created multiple repartition topics, this also means that we have incremented the processor counter n times (n being the number of repartition topics). if we adopt this approach, and the user names the repartition topic, and we reuse the first created repartition topic, we'll change the number of all downstream operations including changelog topics and any other repartition topics. this ""skipping incrementing"" is similar to what happened when re-using a source topic for source `ktable` changelogs. while i realize most users will probably name all repartition topics, by doing so, they'll have to ensure they name any changelog topics as well if we reuse the repartition topics in-line. with the current optimization approach the numbering isn't affected, we move the nodes around. additionally, i""m not sure how this will affect the current optimization approach (maybe change it, as i think if we keep repartition node references as we go we could have ""automatic"" partial merging ?) i'm thinking this approach is could worth looking into, but as an immediate follow-on pr to this one as this requires some thought. wdyt?",1,0.9537836313247681
221679349,5709,mjsax,2018-10-01T16:47:28Z,"for backward compatibility. for new topologies, we should not need to care, because i would assume that users turn on optimization.",0,0.9887071847915649
221817992,5709,mjsax,2018-10-02T03:36:39Z,nit: `create [a] repartition topic` -- or `create repartition topic[s] for`,0,0.9948967099189758
221818181,5709,mjsax,2018-10-02T03:38:51Z,nit `uses [as] part` ?,0,0.9932407140731812
221818570,5709,mjsax,2018-10-02T03:42:41Z,`for` -> `as` ?,0,0.9943166375160217
221818628,5709,mjsax,2018-10-02T03:43:25Z,`@{grouped}` -> `{ grouped}` or `{ grouped}`,0,0.9869411587715149
221818784,5709,mjsax,2018-10-02T03:45:18Z,`{ grouped}` and `{ grouped}` is mixed comparing different methods -- we should unify.,0,0.9913452863693237
221819043,5709,mjsax,2018-10-02T03:48:20Z,"comparing javadocs with `joined`: there we point out that `null` is ok for `serdes` and the usage from config `serdes` -- we should do this here, too.",0,0.9937501549720764
221819137,5709,mjsax,2018-10-02T03:49:40Z,"comparing javadocs with `joined`: there we point out that `null` is ok for `serdes` and the usage from config `serdes` -- we should do this here, too. also for `` docs -- check other methods, too, please.",0,0.9940431714057922
221819376,5709,mjsax,2018-10-02T03:52:36Z,nit: `..` -> `.`,0,0.9508033394813538
221819613,5709,mjsax,2018-10-02T03:55:02Z,`xxx` -> ` `,0,0.8856523633003235
221820266,5709,mjsax,2018-10-02T04:02:10Z,nit: remove var `newjoined` (also not used for left-hand-side code),0,0.9946708083152771
221820519,5709,mjsax,2018-10-02T04:05:01Z,"was this a bug, to pass in `null` as value serde? did guozhang's pr introduce this?",0,0.989328920841217
221820603,5709,mjsax,2018-10-02T04:06:08Z,similar here?,0,0.9924707412719727
221820654,5709,mjsax,2018-10-02T04:06:39Z,nit: remove `this.`,0,0.9926082491874695
222098442,5709,bbejeck,2018-10-02T20:22:58Z,ack,0,0.9149930477142334
222099260,5709,bbejeck,2018-10-02T20:25:29Z,ack,0,0.9149930477142334
222099946,5709,bbejeck,2018-10-02T20:27:48Z,ack,0,0.9149930477142334
222102316,5709,bbejeck,2018-10-02T20:35:30Z,ack,0,0.9149930477142334
222103740,5709,bbejeck,2018-10-02T20:40:05Z,"ack, going with `{ grouped}`",0,0.9771131277084351
222110689,5709,bbejeck,2018-10-02T21:01:45Z,ack,0,0.9149930477142334
222115262,5709,bbejeck,2018-10-02T21:16:56Z,ack,0,0.9149930477142334
222115412,5709,bbejeck,2018-10-02T21:17:29Z,ack,0,0.9149930477142334
222115625,5709,bbejeck,2018-10-02T21:18:15Z,ack,0,0.9149930477142334
222117740,5709,bbejeck,2018-10-02T21:26:03Z,"we need this right now to work with generics as the `repartitionforjoin` signature is ` repartitionforjoin(final joined ` but the right-hand side is ` ` and the left-hand side is ` `. i know it's a bit of a hack, but i think it's worth the trade-off for being able to pass a single `joined` parameter, vs. all of the required components of `joined`. having the single `joined` parameter was introduced from the serdes inheritance pr. if you insist i can revert to what it was before.",0,0.9022589325904846
222117869,5709,bbejeck,2018-10-02T21:26:26Z,introduced by the serdes inheritance pr,0,0.9932639598846436
222117907,5709,bbejeck,2018-10-02T21:26:35Z,same as above,0,0.9918335676193237
222118272,5709,bbejeck,2018-10-02T21:27:49Z,ack,0,0.9149930477142334
222129874,5709,mjsax,2018-10-02T22:15:53Z,ack. makes sense.,0,0.8211045861244202
51845565,812,xiaotao183,2016-02-04T09:11:53Z,sasl_callback_handler_class must be part of `addclientsaslsupport` in order to take effect,0,0.9906262159347534
52296579,812,rajinisivaram,2016-02-09T11:36:07Z,"yes, of course. thank you, will add the missing line.",1,0.7839497923851013
54384085,812,ijuma,2016-02-29T09:11:37Z,don't we have to update this to have a separate `loginmanager` per mechanism?,0,0.9940640330314636
54396485,812,rajinisivaram,2016-02-29T11:11:12Z,"the implementation uses a single login context with multiple login modules to support multiple mechanisms. since login is associated with login context rather than login module, one loginmanager per login type is sufficient.",0,0.9942736029624939
58483193,812,junrao,2016-04-05T03:44:57Z,could we just use configs.getstring and avoid casting? there are a few other places like that.,0,0.992572546005249
58483211,812,junrao,2016-04-05T03:45:09Z,"in the server mode, should we even check haskerberos since saslconfigs.gssapi_mechanism is for the client?",0,0.9948393702507019
58483235,812,junrao,2016-04-05T03:45:26Z,"it seems that we have an existing issue in the handling of case initial. if we can't completely write all bytes of the sasl token, we have to rely on the next call of authenticate() to finish writing the remaining bytes. however, when the write completes, we will go to the initial state and try to send the token again. it seems that we should be transitioning to the intermediate state after the write completes. the same issue seems to exist when transitioning from send_mechanism to receive_mechanism_response, if we can't write all bytes in saslmechanismrequest in one send call.",0,0.9793627262115479
58483242,812,junrao,2016-04-05T03:45:35Z,should we always return the enabled mechanism list?,0,0.9948199391365051
58483259,812,junrao,2016-04-05T03:45:51Z,could we handle an explicit exception due to the first packet not being a mechanismrequest? i was thinking that we can catch all exceptions from saslmechanismrequest(bytebuffer buffer) and convert that to a schemaexception.,0,0.9925008416175842
58483268,812,junrao,2016-04-05T03:46:00Z,"hmm, the client may not understand mechanismresponse if it doesn't send mechanismrequest in the first place.",0,0.9730534553527832
58483270,812,junrao,2016-04-05T03:46:09Z,"similar to saslclientauthenticator, it seems that we need to deal with the case that not all bytes in netoutbuffer can be sent in a single authenticate() call.",0,0.9913085699081421
58483294,812,junrao,2016-04-05T03:46:39Z,"could you update the security section of the documentation on the support of new mechanism, how to specify and plug in plainloginmodule, and what it takes to enable multiple mechanisms on the broker side?",0,0.995210587978363
58537309,812,ijuma,2016-04-05T13:30:28Z,"this is just a `map`, so we can't use `getstring`. i wanted to change `configure` to take a `config` type for this reason, but it would break api classes unfortunately.",0,0.633319616317749
58747063,812,rajinisivaram,2016-04-06T17:28:42Z,"you are right, server doesn't need to check the sasl mechanism. but it can disable kerberos if gssapi is not included in `enabledmechanisms`. have updated the check.",0,0.9915786981582642
58747189,812,rajinisivaram,2016-04-06T17:29:29Z,"thank you, i have fixed setting of sasl state.",1,0.9547604918479919
58747357,812,rajinisivaram,2016-04-06T17:30:17Z,have updated to include enabled mechanisms in response for successful response.,0,0.9584981203079224
58747425,812,rajinisivaram,2016-04-06T17:30:35Z,done.,0,0.9897913336753845
58747950,812,rajinisivaram,2016-04-06T17:33:26Z,"yes, i wasn't sure whether to send the response in this case. but i thought it would be useful to send it before the connection is closed since it may be useful if you are looking at the bytes returned for debugging purposes.",0,0.9850746393203735
58747999,812,rajinisivaram,2016-04-06T17:33:41Z,"done, same as before.",0,0.9929805994033813
58748697,812,rajinisivaram,2016-04-06T17:38:14Z,i have opened another jira (kafka-3517) to update the docs. will submit a pr.,0,0.9928511381149292
59741966,812,ijuma,2016-04-14T15:51:06Z,`apikeys.forid` (which is called by `getrequest` and by ourselves) throws `illegalargumentexception` if the api key is not within range. should we be catching that and throwing a more informative error?,0,0.9899308681488037
59842206,812,rajinisivaram,2016-04-15T08:30:30Z,"thank you for the review. since the first gssapi token starting with 0x60 (when handshake request is omitted) can also be an invalid api key (unlikely since `requestheader.parse` will probably throw `schemaexception`, but still possible i suppose), i changed the code to revert to gssapi for `illegalargumentexception` as well.",1,0.9423491954803467
60461201,812,junrao,2016-04-20T18:21:17Z,could we add the place-holder for those two error codes in errormapping?,0,0.9939985275268555
60461220,812,junrao,2016-04-20T18:21:22Z,should we also add the illegalsaslsate error code?,0,0.9927135109901428
60461542,812,junrao,2016-04-20T18:23:15Z,should we include throws kafkaexception in the signature of configure() and close()? it's uncaught exception anyway.,0,0.9919320940971375
60461708,812,junrao,2016-04-20T18:24:18Z,"it seems that for both client and server, login uses the same clientcallbackhandler. the existing code works like that. is that correct? if so, perhaps we should rename clientcallbackhandler to sth more generic?",0,0.9914699196815491
60461752,812,junrao,2016-04-20T18:24:33Z,"hmm, it's a bit weird that we instantiate a clientcallbackhandler here and also in defaultlogin. could we just create it once and reuse?",-1,0.917610228061676
60461827,812,junrao,2016-04-20T18:24:56Z,"hmm, should we do that? so for, we only guarantee old version of java client can talk to new version of server. but there is no guarantee that new version of java client can talk to old version of server. so, it seems simpler to always let the new client send saslhandshakerequest. this also makes it easier to add apiversionrequest in the future (kip-35).",0,0.9689885973930359
60461839,812,junrao,2016-04-20T18:25:02Z,would it be better to rename this to receiveresponseortoken()?,0,0.994698166847229
60461878,812,junrao,2016-04-20T18:25:14Z,"since we can receive both sasl tokens or a response, perhaps we should rename servertoken to sth more general?",0,0.9924881458282471
60461893,812,junrao,2016-04-20T18:25:19Z,"for consistency, should we rename clientcallbackhandler to saslclientcallbackhandler?",0,0.9946038126945496
60461901,812,junrao,2016-04-20T18:25:24Z,the comment seems obsolete.,0,0.936501681804657
60461930,812,junrao,2016-04-20T18:25:30Z,should we change init to sth like handshake_request to match what's in the client?,0,0.9939234852790833
60461969,812,junrao,2016-04-20T18:25:41Z,could we rename the above to plainsaslproducer and plainsaslconsumer to distinguish from plain text port?,0,0.9939854741096497
60499829,812,rajinisivaram,2016-04-20T22:37:50Z,done.,0,0.9897913336753845
60499881,812,rajinisivaram,2016-04-20T22:38:21Z,"yes, added.",0,0.9930596351623535
60499925,812,rajinisivaram,2016-04-20T22:38:42Z,removed exception from signature.,0,0.9931327700614929
60500580,812,rajinisivaram,2016-04-20T22:43:47Z,"yes, it was like that with kerberos, and i imagine the class was reused to avoid code duplication. but actually i think it is better to use a different class for login to make the logic clearer and more readable. i have added a different callback handler in defaultlogin with just the callbacks for login. there is some overlap with the client callback handler. let me know what you think.",0,0.9645907878875732
60500774,812,rajinisivaram,2016-04-20T22:45:22Z,see note above.,0,0.9943167567253113
60501307,812,rajinisivaram,2016-04-20T22:49:28Z,"we need this for rolling upgrade from 0.9.0.x to 0.10.0 when sasl is used for inter-broker communication. we can remove this in the release that follows (the next minor release perhaps), thus providing a non-disruptive upgrade path. will that be ok?",0,0.9917884469032288
60501331,812,rajinisivaram,2016-04-20T22:49:37Z,done.,0,0.9897913336753845
60501345,812,rajinisivaram,2016-04-20T22:49:46Z,done.,0,0.9897913336753845
60501397,812,rajinisivaram,2016-04-20T22:50:17Z,"renamed and moved to top-level class, consistent with saslservercallbackhandler.",0,0.9949933886528015
60501417,812,rajinisivaram,2016-04-20T22:50:28Z,removed comment.,0,0.9143213033676147
60501435,812,rajinisivaram,2016-04-20T22:50:34Z,done.,0,0.9897913336753845
60501449,812,rajinisivaram,2016-04-20T22:50:44Z,done.,0,0.9897913336753845
60517713,812,junrao,2016-04-21T02:13:03Z,"very good point. for backward compatibility, we can probably just guard that by inter.broker.protocol version. if the version is >= 0.10.0, we will use the new protocol. otherwise, use the old one.",1,0.9808114767074585
60558377,812,rajinisivaram,2016-04-21T10:25:56Z,"thank you, that makes sense. i have updated the code and the kip. since the version comparison code is in `core`, to avoid duplicating too much logic in `clients`, i am checking for 0.9.0 rather than 0.10.0. hope that is ok.",1,0.9903684854507446
60589714,812,junrao,2016-04-21T14:27:50Z,"hmm, we want to check inter.broker.protocol.version >= 0.10.0. this is easier if we can use the case object in core. since we only need to use the old protocol when saslclientauthethicator is used at the broker side. perhaps, we can check inter.broker.protocol.version in the broker code and pass a flag into inter.broker.protocol.version. the places where we use saslclientauthethicator are in replicafetcherthread, controllerchannelmanager, and kafkaserver (for controlled shutdown). when used in clients (producer/consumer), saslclientauthethicator will always use the new protocol.",0,0.9661381840705872
60611214,812,rajinisivaram,2016-04-21T16:16:29Z,thank you for the review. i have moved the version check to `core`.,1,0.9266200661659241
60831292,812,ijuma,2016-04-23T16:54:18Z,"i wonder if we should be adding server-only configs here, it doesn't seem like there is much benefit (although i understand that we may have done that for some configs in the past).",0,0.8603249788284302
60831331,812,ijuma,2016-04-23T16:55:54Z,is it worth mentioning the following as a reference for mechanism names in a comment? [a link],0,0.9948723912239075
60831526,812,ijuma,2016-04-23T17:06:02Z,"nevermind, we do actually need this because we use this property in `common` classes.",0,0.9533483982086182
60831568,812,ijuma,2016-04-23T17:10:29Z,why do we need these as fields?,0,0.9850152134895325
60831627,812,ijuma,2016-04-23T17:13:32Z,nit: is there a `the` missing between `supported` and `requested`?,0,0.9903325438499451
60831641,812,ijuma,2016-04-23T17:14:15Z,nit: replace `in` with `given`?,0,0.9938251972198486
60831687,812,ijuma,2016-04-23T17:17:28Z,nit: `the` missing before `mechanism`?,0,0.9904412031173706
60831696,812,ijuma,2016-04-23T17:17:52Z,this should be final.,0,0.9944940209388733
60831745,812,ijuma,2016-04-23T17:20:01Z,this should be final and the `arraylist` should be assigned only after it's fully constructed (this ensures thread-safety).,0,0.9942805767059326
60831757,812,ijuma,2016-04-23T17:20:46Z,nit: space missing before `:`,0,0.975006639957428
60831862,812,ijuma,2016-04-23T17:28:38Z,"would this not be slightly better if we used `errors.forcode` and then did a switch on the enum? also, we should not compare to `0`, we should use `errors.none`.",0,0.9919474720954895
60831892,812,ijuma,2016-04-23T17:30:51Z,this is the same code that is in `networkclient.correlate`. maybe we can make that a static public method and reuse it.,0,0.9906614422798157
60831968,812,ijuma,2016-04-23T17:34:26Z,can we please group final fields first and then the non final fields? it makes easier to understand what gets set during construction versus mutable fields.,0,0.9922359585762024
60832031,812,ijuma,2016-04-23T17:36:29Z,"i think suggested that we should send the enabled mechanisms in the successful case, but i don't understand the purpose. this bloats the response for the common case without any benefit that i can see. thoughts ?",0,0.9551737308502197
60832070,812,ijuma,2016-04-23T17:38:14Z,"nit: for fields that are initialised during `configure`, i think it's better to keep them `null` until `configure` is called. it makes it easier to debug if something goes wrong.",0,0.9768111705780029
60832315,812,ijuma,2016-04-23T17:54:52Z,i'm wondering if this is really necessary. could we instead add the sasl properties to the properties returned by this method via a utility method that added them only if necessary? it seems like we don't gain much by doing it this way and it adds one more parameter to a very large number of parameters already.,0,0.5904042720794678
60832411,812,ijuma,2016-04-23T18:02:18Z,did you really mean to have different indenting between lines? i think it would be nicer if these 3 lines were at the same indentation. we can change `jaassection.tostring` if it's relying on the current behaviour.,0,0.9868249297142029
60833139,812,ijuma,2016-04-23T18:50:31Z,maybe we don't need `option` here. `option` is useful when we want the behaviour of `none` to be different than the empty case.,0,0.9785866141319275
60833170,812,ijuma,2016-04-23T18:52:29Z,"it's more readable if we write this as `map { case (user, password) => (s""user_$user"" -> password }` or something like that.",0,0.9909165501594543
60833256,812,ijuma,2016-04-23T18:58:26Z,you can do something like [code block],0,0.9942060708999634
60833263,812,ijuma,2016-04-23T18:59:29Z,it's generally preferable to use `getorelse` with an appropriate message for the case when one passes a `none` when a `some` is expected.,0,0.9919203519821167
60833297,812,ijuma,2016-04-23T19:02:24Z,"hmm, maybe the way you did is better since subsequent lines are a continuation of previous lines.",0,0.958296000957489
60833355,812,ijuma,2016-04-23T19:07:30Z,it seems that this is used for inter-broker communication. shouldn't we be using the same pattern we used for `interbrokersecurityprotocol`?,0,0.9926477670669556
60833773,812,ijuma,2016-04-23T19:39:34Z,not worth having an empty `return` annotation.,0,0.940772294998169
60833788,812,ijuma,2016-04-23T19:40:57Z,i think it would be nicer if we had a separate `abstractlogin` that `kerberoslogin` inherits from. inheritance from concrete classes is good to avoid as it tends to be brittle.,0,0.9745930433273315
60834053,812,ijuma,2016-04-23T19:56:47Z,"because these tests take a while to run, would it make sense to only have `saslmultimechanismconsumertest`?",0,0.988643229007721
60834178,812,ijuma,2016-04-23T20:05:49Z,do we need some negative tests (eg clients connects with unsupported mechanism and client tries sasl handshake after connection is established).,0,0.9780188798904419
60847448,812,junrao,2016-04-24T16:37:46Z,"could we add some comments here and saslclientcallbackhandler to distinguish between the two (e..g, which callbacks are expected in each handler)? also, it seems that passwordcallback is never supposed to be called during login?",0,0.9945225715637207
60847587,812,junrao,2016-04-24T16:45:41Z,"my feeling is that always returning enabledmechanisms makes the protocol a bit simpler. also, the client can always know what the available mechanisms are.",0,0.9631995558738708
60852892,812,ijuma,2016-04-24T22:07:27Z,we have `auth` and `authenticator` packages. what's the thinking regarding when to use one versus the other?,0,0.9922888875007629
60853278,812,ijuma,2016-04-24T22:42:18Z,is the plan to allow users to provide their own `login`? is that why we have a `configure` method instead of passing the parameters via the constructor?,0,0.9945957064628601
60853355,812,ijuma,2016-04-24T22:46:25Z,nitpick: is it worth having this as a field? seems like we could just create it and pass it to the `logincontext` constructor.,0,0.9855867624282837
60853535,812,ijuma,2016-04-24T23:01:36Z,"this should be in the ""assigned in `configure`"" section of fields.",0,0.9951807260513306
60853576,812,ijuma,2016-04-24T23:05:17Z,i think i'd configure this right after creating the callback handler instead of in this method.,0,0.9903624653816223
60853631,812,ijuma,2016-04-24T23:09:48Z,we should use interpolation instead of string concat here.,0,0.992394208908081
60853650,812,ijuma,2016-04-24T23:11:20Z,"`send` is already doing this, right?",0,0.9928047060966492
60853663,812,ijuma,2016-04-24T23:13:41Z,"can you please add a comment on how the `pendingsaslstate` is used? it seems correct to me, but it will be helpful for others reading the code.",0,0.9662923216819763
60853704,812,ijuma,2016-04-24T23:16:52Z,i wonder if more of this code is generic and should be pushed somewhere else.,0,0.6488779187202454
60853743,812,ijuma,2016-04-24T23:21:02Z,this cast is redundant.,0,0.9162154793739319
60853821,812,ijuma,2016-04-24T23:25:22Z,"if the server is expecting gssapi, would it not disconnect the client? if we want to wrap any `schemaexception` into an `authenticationexception`, we should probably include the rest of the code in this method into the `try` block. and we would probably want to catch `illegalargumentexception` too.",0,0.993703305721283
60853909,812,ijuma,2016-04-24T23:32:00Z,is there some other information we can provide for the non kerberos case?,0,0.9941330552101135
60853932,812,ijuma,2016-04-24T23:33:39Z,calling `getprivatecredentials` and `getpubliccredentials` twice is a bit messy. not sure if we can make it better though.,-1,0.7965971827507019
60854042,812,ijuma,2016-04-24T23:39:23Z,this can still be final right?,0,0.9916746020317078
60854807,812,ijuma,2016-04-25T00:29:16Z,does this imply that we should not ship this with our production-ready code?,0,0.9848963022232056
60855186,812,ijuma,2016-04-25T00:51:30Z,it may be worth saying that only `plain` is supported.,0,0.9862122535705566
60855233,812,ijuma,2016-04-25T00:53:44Z,perhaps it would be good to include some more information (ie the number of tokens was not correct),0,0.9816766977310181
60855240,812,ijuma,2016-04-25T00:54:12Z,style nit: i think this should be `authorizationid`.,0,0.991081953048706
60855258,812,ijuma,2016-04-25T00:54:48Z,we should use `isempty` instead of `length == 0`,0,0.9943042397499084
60855285,812,ijuma,2016-04-25T00:55:58Z,is it worth concatenating the message given that we are passing the exception as the cause anyway?,0,0.9878232479095459
60855298,812,ijuma,2016-04-25T00:56:58Z,should we be returning `null` here?,0,0.9901913404464722
60855309,812,ijuma,2016-04-25T00:57:37Z,i guess it's ok to leave as is because the method that returns this needs to match the name provided by `saslserver`.,0,0.9888694286346436
60855865,812,ijuma,2016-04-25T01:12:23Z,it seems to me that this should be the other way around: [code block],0,0.9879403114318848
60856113,812,ijuma,2016-04-25T01:25:21Z,indenting.,0,0.9769666790962219
60856117,812,ijuma,2016-04-25T01:25:34Z,indenting.,0,0.9769666790962219
60856366,812,ijuma,2016-04-25T01:32:18Z,can we group final fields please?,0,0.9938451051712036
60856398,812,ijuma,2016-04-25T01:32:56Z,"as for the client, it would be good to have a comment explaining why we need a `pendingsaslstate`",0,0.9931710958480835
60856514,812,ijuma,2016-04-25T01:35:50Z,there's an extra space after `=`.,0,0.9927334785461426
60856547,812,ijuma,2016-04-25T01:37:35Z,i would configure the callback handler after creating it.,0,0.9927896857261658
60856567,812,ijuma,2016-04-25T01:38:38Z,"not sure about this magic, i don't think we do that for inter-broker communication. it may be better to add some validation to `kafkaconfig` for consistency.",0,0.9109215140342712
60856584,812,ijuma,2016-04-25T01:39:18Z,i think it would be better to leave this as `null` until it is initialised in `configure`.,0,0.9866229891777039
60856700,812,ijuma,2016-04-25T01:43:58Z,we should use interpolation instead of string concatenation.,0,0.991634726524353
60857015,812,ijuma,2016-04-25T01:55:44Z,do we actually need this `removeinterestops`? it seems to me that we remove it in `flushnetoutbufferandupdateinterestops` before we reach here.,0,0.9916386008262634
60857041,812,ijuma,2016-04-25T01:56:04Z,can you please explain why we need this now? it may be worth a comment.,0,0.976444661617279
60894701,812,rajinisivaram,2016-04-25T10:48:10Z,done.,0,0.9897913336753845
60894764,812,rajinisivaram,2016-04-25T10:48:51Z,removed fields.,0,0.987351655960083
60894790,812,rajinisivaram,2016-04-25T10:49:00Z,added.,0,0.9917559623718262
60894807,812,rajinisivaram,2016-04-25T10:49:10Z,added.,0,0.9917559623718262
60894823,812,rajinisivaram,2016-04-25T10:49:21Z,done.,0,0.9897913336753845
60894837,812,rajinisivaram,2016-04-25T10:49:33Z,done.,0,0.9897913336753845
60894885,812,rajinisivaram,2016-04-25T10:49:48Z,added space.,0,0.9865413904190063
60894913,812,rajinisivaram,2016-04-25T10:50:01Z,done.,0,0.9897913336753845
60895052,812,rajinisivaram,2016-04-25T10:51:30Z,couldn't find a good place for the common code. added a static method in `networkclient` for use in both `networkclient` and `saslclientauthenticator`.,0,0.9806979894638062
60895106,812,rajinisivaram,2016-04-25T10:52:03Z,leaving as is as-per jun's suggestion.,0,0.9919375777244568
60895309,812,rajinisivaram,2016-04-25T10:54:01Z,"agree that there are too many parameters already. but a similar pattern is used for producers and consumers as well. rather than change them all to call additional methods, leaving as-is for now. this keeps it consistent with the way ssl properties are set.",0,0.9870813488960266
60895385,812,rajinisivaram,2016-04-25T10:54:42Z,updated.,0,0.9768958687782288
60895402,812,rajinisivaram,2016-04-25T10:54:53Z,done.,0,0.9897913336753845
60895427,812,rajinisivaram,2016-04-25T10:55:06Z,done.,0,0.9897913336753845
60895436,812,rajinisivaram,2016-04-25T10:55:15Z,done.,0,0.9897913336753845
60895583,812,rajinisivaram,2016-04-25T10:56:36Z,"since the property is used by common code rather than broker-specific code, the same property is used for both clients and broker.",0,0.9928911924362183
60895608,812,rajinisivaram,2016-04-25T10:56:48Z,removed.,0,0.9612457156181335
60895633,812,rajinisivaram,2016-04-25T10:56:59Z,done.,0,0.9897913336753845
60895764,812,rajinisivaram,2016-04-25T10:58:19Z,i think it is useful to have at least one test for sasl/plain that doesn't use gssapi since some codepaths are not enabled when gssapi is disabled. i have removed one of the sasl/plain tests and left one in.,0,0.9500470757484436
60895960,812,rajinisivaram,2016-04-25T11:00:26Z,i have another changeset with unit tests for sasl in the `clients` project. i will rebase and submit that once this is committed.,0,0.9948476552963257
60896246,812,rajinisivaram,2016-04-25T11:03:27Z,"i have added comments. `passwordcallback` shouldn't be called with the standard login modules during login. but since you may want to plugin custom login modules, especially for plain, it makes sense to throw an appropriate exception if it was called.",0,0.9938492178916931
60896528,812,rajinisivaram,2016-04-25T11:06:31Z,"is probably the best person to answer the question. since `auth` already contained interfaces, i added interfaces to that package (the new ones are currently not exposed externally, but we may want to make these externally configurable at some point). `authenticator` contained sasl authentication implementation and it continues to hold the same.",1,0.6562490463256836
60896686,812,rajinisivaram,2016-04-25T11:07:58Z,"yes, the original kip was proposing to expose `login` to plugin new authentication mechanisms. the cut-down kip no longer needs that, but it made sense to keep it configurable for the future.",0,0.990341067314148
60896698,812,rajinisivaram,2016-04-25T11:08:13Z,removed.,0,0.9612457156181335
60896709,812,rajinisivaram,2016-04-25T11:08:22Z,done.,0,0.9897913336753845
60896753,812,rajinisivaram,2016-04-25T11:08:45Z,done.,0,0.9897913336753845
60896777,812,rajinisivaram,2016-04-25T11:08:54Z,done.,0,0.9897913336753845
60896799,812,rajinisivaram,2016-04-25T11:09:07Z,"yes, removed.",0,0.9915463328361511
60896815,812,rajinisivaram,2016-04-25T11:09:16Z,done.,0,0.9897913336753845
60896823,812,rajinisivaram,2016-04-25T11:09:26Z,removed.,0,0.9612457156181335
60896983,812,rajinisivaram,2016-04-25T11:11:18Z,"client would get disconnected, but i am not sure if gssapi includes an error response in that case. catching exception from the whole block now.",0,0.9710960984230042
60897075,812,rajinisivaram,2016-04-25T11:12:25Z,can't think of anything that is generic and useful for other mechanisms in this case.,0,0.9305701851844788
60897383,812,rajinisivaram,2016-04-25T11:15:28Z,"could move it into another variable, but it adds more code, so leaving as is.",0,0.9862074851989746
60897403,812,rajinisivaram,2016-04-25T11:15:38Z,"yes, updated.",0,0.9902389049530029
60897700,812,rajinisivaram,2016-04-25T11:18:42Z,"rewrote the comment. it is simlar to digest-md5 implementation in zookeeper where clear passwords are stored on disk. it can be used in production, but you may want to write your own.",0,0.994070827960968
60897719,812,rajinisivaram,2016-04-25T11:18:54Z,done.,0,0.9897913336753845
60897732,812,rajinisivaram,2016-04-25T11:19:03Z,done.,0,0.9897913336753845
60897762,812,rajinisivaram,2016-04-25T11:19:21Z,done.,0,0.9897913336753845
60897773,812,rajinisivaram,2016-04-25T11:19:30Z,removed.,0,0.9612457156181335
60898494,812,rajinisivaram,2016-04-25T11:27:33Z,empty response indicates to the client that the authentication has completed successfully. null response would possibly need changes to the client code.,0,0.9932829141616821
60898519,812,rajinisivaram,2016-04-25T11:27:51Z,updated.,0,0.9768958687782288
60898535,812,rajinisivaram,2016-04-25T11:28:01Z,done.,0,0.9897913336753845
60898552,812,rajinisivaram,2016-04-25T11:28:08Z,done.,0,0.9897913336753845
60898566,812,rajinisivaram,2016-04-25T11:28:17Z,done.,0,0.9897913336753845
60898573,812,rajinisivaram,2016-04-25T11:28:24Z,done.,0,0.9897913336753845
60898589,812,rajinisivaram,2016-04-25T11:28:34Z,removed space.,0,0.9827114939689636
60898751,812,rajinisivaram,2016-04-25T11:30:11Z,"it was written this way when callback handler class was configurable in the original kip. since it is no longer configurable, i have moved the construction to `createsaslserver` when the mechanism is known.",0,0.9952898025512695
60898799,812,rajinisivaram,2016-04-25T11:30:35Z,replaced with error check and validation in `kafkaconfig`.,0,0.9952606558799744
60898811,812,rajinisivaram,2016-04-25T11:30:44Z,done.,0,0.9897913336753845
60898835,812,rajinisivaram,2016-04-25T11:30:54Z,removed.,0,0.9612457156181335
60900182,812,rajinisivaram,2016-04-25T11:46:04Z,"have added a comment. `saslserverauthenticator.complete()` used to check `saslserver.iscomplete` earlier and didn't rely on the sasl state. it is useful to keep the state up-to-date for debug anyway, and now that it is kept uptodate, `saslserverauthenticator.complete()` can use it too.",0,0.9814404249191284
60916629,812,ijuma,2016-04-25T13:57:25Z,thanks.,0,0.5270382761955261
60916703,812,ijuma,2016-04-25T13:57:50Z,"ok, fine.",0,0.9833110570907593
60917166,812,ijuma,2016-04-25T14:00:30Z,thanks. i guess what i was trying to say is that i don't know if we will ever get the schema exception since the server will just disconnect us. but it would be good to verify that via tests. it can be done in a separate pr though.,1,0.9405502676963806
60917208,812,ijuma,2016-04-25T14:00:43Z,"ok, fine.",0,0.9833110570907593
60917226,812,ijuma,2016-04-25T14:00:49Z,ok.,0,0.980760931968689
60917392,812,ijuma,2016-04-25T14:01:46Z,ok.,0,0.980760931968689
60917610,812,ijuma,2016-04-25T14:03:10Z,"my comment was based on: [code block] however, if our code expects an empty byte array, it's fine to leave as is.",0,0.9924606680870056
60917684,812,ijuma,2016-04-25T14:03:45Z,sounds good.,1,0.857205867767334
60917800,812,ijuma,2016-04-25T14:04:27Z,sounds good.,1,0.857205867767334
60917907,812,ijuma,2016-04-25T14:05:16Z,thanks.,0,0.5270382761955261
60918260,812,ijuma,2016-04-25T14:07:32Z,"can you please file a jira for that and also think about system tests that we need? some of it is just a matter of using the plain mechanism in some tests. the other important case is testing upgrades and different broker/client versions. we already have many of these tests, so it may just be a matter of expanding them.",0,0.9935557246208191
60918411,812,ijuma,2016-04-25T14:08:23Z,the fact that it's common code is an implementation detail. we can pass the parameter via `channelbuilders` to deal with that. let's see what thinks.,0,0.9936071634292603
60918481,812,ijuma,2016-04-25T14:08:48Z,ok.,0,0.980760931968689
60918614,812,ijuma,2016-04-25T14:09:37Z,rajini did this.,0,0.92668217420578
60918664,812,ijuma,2016-04-25T14:09:55Z,"looks good, thanks.",1,0.9598045349121094
60919159,812,ijuma,2016-04-25T14:13:13Z,"this may seem a bit nitpicky, but it makes a difference from a java memory model perspective, the assignment to the final field should happen after the list has been populated.",0,0.8476188778877258
60919232,812,ijuma,2016-04-25T14:13:39Z,would it make sense to move this down to `defaultlogin`?,0,0.9916228652000427
60919291,812,ijuma,2016-04-25T14:13:57Z,maybe we don't need this here either (subclasses can implement it).,0,0.9728541374206543
60919588,812,ijuma,2016-04-25T14:16:03Z,nitpick: there should be a space before `{`.,0,0.9903524518013
60919616,812,ijuma,2016-04-25T14:16:13Z,nitpick: there should be a space before `{`.,0,0.9903524518013
60949617,812,ijuma,2016-04-25T17:06:25Z,this doesn't seem to be changed?,0,0.9881551265716553
60956336,812,rajinisivaram,2016-04-25T17:48:32Z,done,0,0.8682363629341125
60956492,812,rajinisivaram,2016-04-25T17:49:28Z,"sorry, there were two sets of code changes here, i had missed one, but have updated now.",-1,0.9886565208435059
60957054,812,rajinisivaram,2016-04-25T17:52:45Z,"agree. i suppose it depends on whether sasl mechanism is treated as a property of the sasl protocol or a higher level protocol itself. there are other instances of client-side properties (eg. service name) which don't have an ""inter.broker"" prefix when used in the broker. i am happy with either, so will wait and see what thinks.",0,0.8202064633369446
60957655,812,ijuma,2016-04-25T17:56:06Z,good point about service name.,1,0.9371190667152405
60957839,812,rajinisivaram,2016-04-25T17:57:03Z,will add a test in kafka-3617 along with the other unit tests.,0,0.9938311576843262
60958025,812,rajinisivaram,2016-04-25T17:58:09Z,done.,0,0.9897913336753845
60958055,812,rajinisivaram,2016-04-25T17:58:19Z,moved.,0,0.9599528908729553
60958076,812,rajinisivaram,2016-04-25T17:58:28Z,done.,0,0.9897913336753845
60958107,812,rajinisivaram,2016-04-25T17:58:40Z,done.,0,0.9897913336753845
60959856,812,rajinisivaram,2016-04-25T18:09:05Z,done.,0,0.9897913336753845
60963638,812,ijuma,2016-04-25T18:30:32Z,i asked offline about this and he suggested the `sasl.mechanism.inter.broker.protocol`. the reason why i think this is different than `sasl.kerberos.service.name` is that it's easy to be confused when one sees `sasl.mechanism` and `sasl.enabled.mechanisms`.,0,0.9890702962875366
60993752,812,rajinisivaram,2016-04-25T21:36:01Z,"ok, makes sense. i have added updated the pr.",0,0.989519476890564
61186244,812,harshach,2016-04-27T00:14:38Z,authenticator for pluggable authenticator that we use.,0,0.9942119717597961
37835370,165,onurkaraman,2015-08-25T06:09:30Z,`votes.maxby(_._2)._1`,0,0.9876285791397095
37835755,165,onurkaraman,2015-08-25T06:18:59Z,`allmembermetadata.tomap` converts to an immutable map,0,0.9940898418426514
37836136,165,onurkaraman,2015-08-25T06:27:03Z,"given that the session timeouts are defined per member, should this instead be: [code block]",0,0.9945577383041382
37836633,165,onurkaraman,2015-08-25T06:38:14Z,"another minor point, but i think it's cleaner to keep all group-specific checks in dojoingroup similar to how it was before.",0,0.9579800367355347
37842937,165,onurkaraman,2015-08-25T08:21:18Z,"i think we can replace collect with the less obscure map: `supportedprotocols.find{ case (p, d) => protocol == p }.map{ case (p, d) => d }`",0,0.9870054721832275
37890199,165,onurkaraman,2015-08-25T16:58:37Z,`return metadata != null ? metadata.equals(that.metadata) : that.metadata == null;`,0,0.9932523369789124
37895582,165,onurkaraman,2015-08-25T17:44:30Z,`def candidateprotocols = {`,0,0.9920967817306519
37895610,165,hachikuji,2015-08-25T17:44:46Z,"i was thinking that ""member"" at the root seemed a little vague in configuration.",0,0.9315491914749146
37895692,165,hachikuji,2015-08-25T17:45:28Z,agreed.,0,0.954565167427063
37895693,165,onurkaraman,2015-08-25T17:45:28Z,"same as above: `def currentmembermetadata: map[string, array[byte]] = {`",0,0.9951586127281189
37896333,165,hachikuji,2015-08-25T17:50:59Z,intellij generated this line! wonder why their template is so weird...,-1,0.993966281414032
37898046,165,onurkaraman,2015-08-25T18:05:02Z,"your addgroup change now takes in (groupid, protocoltype). it probably won't change the outcome of the tests, but better for clarity to match up with the intended usage.",0,0.9933274984359741
37901060,165,onurkaraman,2015-08-25T18:27:58Z,"github annoyingly picked the diff window for me. just to clarify, i was only suggesting you move the following check: `else if (group.protocoltype != protocoltype)`",-1,0.945295512676239
37904617,165,ewencp,2015-08-25T18:56:51Z,this confused me a bit since previously this class was purely additive wrt the set of topics. is there a case where you can actually lose a subscription by doing this? i'm thinking if the user does something to the subscriptions during a callback?,-1,0.5334694385528564
37904628,165,ewencp,2015-08-25T18:56:54Z,"nit, but since this is a nested class that will probably always be referred to by `metadata.metadatalistener`, `listener` would probably be more concise/less redundant.",0,0.9800170660018921
37904632,165,ewencp,2015-08-25T18:56:57Z,"i think this is the right default assignor, but just to be clear this is changing a default. we're still ok with this since we haven't released this yet, but are there any concerns with inconsistency with the old consumer?",0,0.5918821096420288
37904642,165,ewencp,2015-08-25T18:57:03Z,this comment doesn't seem useful...,-1,0.8448378443717957
37904654,165,ewencp,2015-08-25T18:57:07Z,we could make this private since the `success` and `failure` methods seem to be the preferred way of constructing these objects and ensure you construct a valid combination (i.e. guarantees the right fields are null depending on the value of `succeeded`).,0,0.9939016103744507
37904666,165,ewencp,2015-08-25T18:57:11Z,"can we may be document what `groupsubscription` is more clearly somewhere else, maybe even just on this class's javadoc? it took me a bit of digging to figure out what it was -- i was confused why we were getting (and using) something called group subscription when a join group had failed. maybe a bit of renaming could also help? aggregategroupsubscription or aggregaterequestedgroupsubscription?",0,0.7702074646949768
37904681,165,ewencp,2015-08-25T18:57:16Z,this doesn't currently build for me because iterator's `remove()` method is not implemented.,0,0.9912030696868896
37904688,165,ewencp,2015-08-25T18:57:21Z,"is there a reason for this extra level that just contains the subscription struct field? i get that other implementations might want subscription info + other metadata, but does abstractpartitionassignor need this?",0,0.9880196452140808
37904699,165,ewencp,2015-08-25T18:57:23Z,this could be a static final -- doesn't need to be a separate object for every call to `schema()`,0,0.994442880153656
37904706,165,ewencp,2015-08-25T18:57:25Z,"i'm not sure i understand how versioning will work for this data format. do we need to also include a schema version number as part of this `write()` call? otherwise, how would we introduce a v1? it doesn't look like this is handled in partitionassignmentprotocol since the version of the schema isn't exposed anywhere in this interface.",0,0.7959127426147461
37904713,165,ewencp,2015-08-25T18:57:29Z,why not just `subscription.toarray()`,0,0.9917586445808411
37904720,165,ewencp,2015-08-25T18:57:32Z,"same question, why not `topics.toarray()`",0,0.9932214021682739
37904726,165,ewencp,2015-08-25T18:57:36Z,"any other ideas besides controller for naming these classes? this is a different part of the code, but we've already got kafkacontroller on the broker.",0,0.9930643439292908
37916318,165,hachikuji,2015-08-25T20:38:44Z,"i don't think it's possible since we await all pending requests to the coordinator before sending a new join group request, but i'll have to look into it. this is definitely one of the messier aspects of this patch. it may get easier after kafka-2388 since subscriptions are no longer additive, but the hard part is ensuring that the metadata topic list matches the union of all topics subscribed by the group. one option might be to only update the metadata topic list based on the subscriptions defined in the join group response. that would mean we'd always need two rounds of the rebalance when subscriptions change, which seems unfortunate. i'll see if there are any nicer options.",0,0.7515637874603271
37917400,165,hachikuji,2015-08-25T20:47:58Z,"as long as we document the difference, it's probably fine. i can't imagine any cases where users would have a hard dependence on the range assignor. and since a lot of users probably won't override the default, i think we should have it set to the better strategy.",0,0.971839189529419
37917723,165,hachikuji,2015-08-25T20:50:41Z,"yep, i didn't catch it locally because java 8 provides a default implementation.",0,0.984055757522583
37918344,165,ewencp,2015-08-25T20:55:35Z,"not a big deal, but `collections.singletonmap` is a nice shortcut for building maps like this.",1,0.6200433969497681
37918767,165,hachikuji,2015-08-25T20:58:29Z,"initially i was trying to include a generic byte array in the protocol which extensions could provide a schema to support their own custom metadata. that got a little too complex to manage, so i decided to leave it up to custom assignors to define the full metadata schema (including subscriptions) that they depend on. in short, the extra level can be removed now.",0,0.9830830097198486
37919217,165,hachikuji,2015-08-25T21:02:08Z,manager?,0,0.9914402961730957
37919626,165,ewencp,2015-08-25T21:05:40Z,test for inconsistent metadata? or are we just assuming the other test is good enough since that's handled in abstractpartitionassignor?,0,0.988165020942688
37922433,165,ewencp,2015-08-25T21:32:02Z,"so this basically means that not only do we enable rolling upgrades where you add a new protocol, restart everything, and can then later remove the new protocol, but we actually require it (unless you shut down the entire group and then start again from scratch)?",0,0.9885731935501099
37922449,165,hachikuji,2015-08-25T21:32:13Z,"this has probably not been thought all the way through, but any version embedded in the metadata itself cannot really be leveraged in the protocol. new versions of an assignor can support old versions of the metadata, but the opposite won't generally work. if the user wants to have a change to the metadata without bringing the cluster down, then they'd have to provide separate assignors supporting the different metadata versions. the protocol allows each assignor to provide a single version which the coordinator can use to ensure compatibility. i think the question is whether this version should identify the version of the metadata, the version of the assignor, or whether we need an additional version field to be able to express both. in general, the only thing the coordinator can do with these versions is check that they match for all members, so it would seem a little unfortunate to have to add another. it is also possible to use the name of the assignor to communicate version differences. for example, instead of ""roundrobin,"" this should be ""roundrobin-v0."" then if we need to change the metadata, we would implement abstractpartitionassignorv1 and a roundrobinassignorv1 which uses the name ""roundrobin-v1.""",0,0.9832457304000854
37924821,165,hachikuji,2015-08-25T21:57:27Z,"that is right. if you attempt to upgrade the protocol without providing both versions, then the new group members (with the new protocol) would be rejected until all old members have left. this is consistent with the current implementation. i proposed previously to have the coordinator choose the protocol which the largest number of members support, but you seemed concerned that this would effectively halve the group's capacity for a short duration in a rolling upgrade. i still think that might be a more useful update mechanism in practice, but the implementation might be tricky since rejected members would have to retry at a later time which could lead to unnecessary (and costly) rebalancing. the advantage of the approach implemented here is that the code is simple.",0,0.9640325307846069
37927101,165,ewencp,2015-08-25T22:23:44Z,"i think this is fine -- the rolling upgrade with 2 protocols should be the common and suggested path if you need to do this anyway. since this is only an issue if you don't configure your consumers for a seamless upgrade, i actually don't think it's bad to have pretty harsh behavior like this. if someone screws up and misconfigures something, they'll figure it out a lot faster if they bounce consumers and they can't even get back into the group, whereas the majority vote would work but halve the capacity. i think either way is fine, but i agree this code is simpler and has reasonable results.",1,0.8298077583312988
37927178,165,ewencp,2015-08-25T22:24:43Z,"that works. we have a ton of xmanager classes on the broker, but it's a generic enough name component that it shouldn't be confusing.",0,0.9752271175384521
37927752,165,ewencp,2015-08-25T22:31:56Z,"sorry, i think we've already discussed this like 3 times and i just keep getting confused about it. the reason this code confused me is because we have `consumer_metadata_v0`, which implies at some point we could add `consumer_metadata_v1` to this class and support both/upgrading. i think i see now how we could actually still (potentially) only have `abstractpartitionassignor`, but then versioned concrete classes.",-1,0.987627387046814
37927905,165,ewencp,2015-08-25T22:33:48Z,do we even want the range assignor anymore then? is it needed for anything that the other assignors we'd want to implement wouldn't?,0,0.9866520166397095
37929097,165,hachikuji,2015-08-25T22:48:28Z,"haha, it still confuses me too. i think i sort of blindly applied the same pattern that was used for schema definitions in the protocol class. i can drop the v0, but the trouble with assignor versioning won't go away quite that easily. one concrete suggestion might be to make the protocol version a string instead of an int to allow more information to be embedded in the version. we could then use it to track both the protocol and metadata versions. i can also add some documentation on the groupprotocol and partitionassignor interfaces to try to make intended usage clearer.",1,0.7025023698806763
37929523,165,hachikuji,2015-08-25T22:53:56Z,"yeah, that's a good point. maybe we leave it for now and address it in a separate jira? i can default to rangeassignor for consistency with the current version.",1,0.8202060461044312
37932986,165,ewencp,2015-08-25T23:40:09Z,"yeah, i think that's fine. we probably need a jira for any other built-in assignors we want to ship with 0.8.3 anyway, e.g. i assume we'll have a copartitioning implementation for kstreams.",0,0.8230923414230347
38051685,165,guozhangwang,2015-08-27T00:29:55Z,which version did you use and which edit feature did you turn on? your intellij is definitely overly-smart ;),1,0.5354171395301819
38051966,165,guozhangwang,2015-08-27T00:35:56Z,"i would prefer defaulting to range just for consistency. we have seen similar cases in the producer where the behavior of partitioner's hashing function changes a bit, causing offset manager migrated for mirror-makers and hence resetting offset and data duplicates.",0,0.9840010404586792
38602589,165,ewencp,2015-09-03T00:32:28Z,"why are we splitting the handling of metadata between both `metadata` and `fetcher` now? is this just so that this topic-partition metadata is not persistent in `metadata` since calling `partitionsfor` doens't really imply anything about whether you'll continue to need updated metadata for the topics passed in here? even so, this split seems less than ideal...",-1,0.9286223649978638
38602592,165,ewencp,2015-09-03T00:32:32Z,"any reason for using an empty list here rather than `null` as a sentinel? the empty list approach seems like it could lead to confusing results if you have a programmatically generated list which can sometimes be empty. right now it's not a problem since we only expose `listtopics` and `partitionsfor(onetopic)`. but wasn't there a proposal for something like `partitionsfor(string... topics)`, in which case this could affect the public api.",0,0.9793074131011963
38602607,165,ewencp,2015-09-03T00:32:44Z,"does this really make sense? for this to occur, we'd need to have everyone agree on the metadata since that was checked above, but then they'd have to be missing metadata on one of those topics. wouldn't at least the one consumer that included that topic have metadata for it? is the goal here that we continue processing the ones we have metadata for so we can at least make progress? if we do this, is there anything that's forcing the metadata to be refreshed (like the inconsistentmetadata result does)? if not, wouldn't this cause us to sometimes knowingly ignore some topics which we might be able to make progress on immediately if we refreshed and rejoined the group?",0,0.9701153635978699
38602625,165,ewencp,2015-09-03T00:33:07Z,"you might want to rename this for clarity. i saw `hashsets` being passed into the `metadatasnapshot` constructor in `consumergroupcontroller` and since i knew `hash()` is called on that, i was worried the `hashsets` might have been a mistake. they're not, and that makes sense given the protocol we came up with, but the current method names aren't clear about what's being hashed. my first thought was `metadatahash()`, but that doesn't exactly help... maybe `topicmetadatahash()`?",0,0.9378489851951599
38602735,165,ewencp,2015-09-03T00:35:35Z,we can always go the `max.in.flight.requests.per.second` route with maximum verbosity and prefix with `group.member.`!,0,0.9858002662658691
38661233,165,hachikuji,2015-09-03T15:46:57Z,"since we depend on the metadata matching the subscription set in this patch, i wanted to remove any other calls which can affect it. the alternative would be to always intersect the subscription and metadata before computing the hash sent along in the join group. either way should work, but i actually think it's a good thing not having the persistent metadata state updated by partitionsfor(). can you explain a little more why this is less than ideal?",0,0.9299116134643555
38661343,165,hachikuji,2015-09-03T15:47:56Z,fair enough. i can use null instead.,0,0.9723243713378906
38664475,165,ewencp,2015-09-03T16:15:09Z,"it's just not great having multiple paths that make the same type of request if possible. but i see why we at least want different handling of this request/response, and there was another jira to make this exact change anyway.",-1,0.9319537281990051
38664724,165,hachikuji,2015-09-03T16:17:49Z,"the case i was trying to handle is non-existing topics. the current behavior of the consumer is to keep trying to fetch metadata for the non-existing topic in the hope that it will eventually be created, and to continue consuming from other subscribed topics. if one of the consumers does have metadata (perhaps because the topic was just created), then the metadata hash will be inconsistent and members will refetch. if the topic is later created, we will discover it when we update metadata and the consumers will rejoin.",0,0.988624095916748
38667583,165,ewencp,2015-09-03T16:46:31Z,"ok, that makes sense in that it allows consumers to make progress even if a topic needs to be created. if auto topic creation is not enabled, then this might be the only way to make progress if one of the topics doesn't yet exist. but doesn't this also mean that if you have auto topic creation enabled and the consumer group starts up before any producers, then it might have to wait an entire metadata refresh timeout before any data is consumed from that topic, even if producers start sending data to it immediately? i think this is fine (and it's a one-time delay, 5 or 10 minutes by default iirc), just want to make sure we understand the implications of doing this.",0,0.7491175532341003
38669112,165,hachikuji,2015-09-03T17:01:48Z,"yeah, that's right, and i agree it's a little unfortunate to have to wait the full refresh interval, though i assume most cases would have the topic already created or created by producers. probably the main case where this would be encountered is in testing. one thing we could try to do is stagger metadata refreshes randomly in the group so that they are not all synchronized around the join group completion. that would reduce the expected time to discover metadata changes in general. it might also make sense to set the default metadata refresh rate a little lower for client-side assignment since we can't depend any longer on the broker discovering changes for us anymore.",-1,0.6932626962661743
41659964,165,ewencp,2015-10-09T18:04:02Z,"this is out of date, right? no more metadatahashes in this version?",0,0.9826830625534058
41661913,165,ewencp,2015-10-09T18:20:56Z,"is this version for the consumer protocol itself? that can't be in the struct, can it? doesn't it need to prefix the struct so you can decide which schema to decode with?",0,0.994317352771759
41662735,165,ewencp,2015-10-09T18:28:24Z,"is this just temporary until we add better support in the configs for multiple assignors? i'd imagine we need to think through the exact semantics, if ordering matters at all, etc. is the plan to eventually just switch this to a comma-separated list of class names? one thing i found with copycat was that the more things that needed to be configured via the same config dictionary, the more problematic kafka's standard approach to configuration became because you could easily hit cases where there were conflicting settings. not sure if a) that'll be an issue here or b) if we even want to support assignors that have _that_ much config, but something worth thinking about before committing to this specific approach to specifying assignors.",0,0.8912829160690308
41664701,165,hachikuji,2015-10-09T18:45:40Z,"yes, you are right. i wrote it that way initially, but changed it several times as i was considering compatibility implications. assuming forward compatibility, for example, you just parse blindly even if the version is higher. however, newer versions would need to check the version before doing any parsing, so it should still be parsed separately. i'll update the patch. in general, the versioning problem is complex enough to merit its own discussion, so the goal here is to keep things as simple as possible.",0,0.9595566391944885
41664757,165,ewencp,2015-10-09T18:46:10Z,seems like this comment is not true now? intentional change or are we missing a check here?,0,0.9868529438972473
41664863,165,ewencp,2015-10-09T18:47:24Z,"agreed. as long as we address it in a blocker follow up patch, i'm happy to defer that discussion until after this patch.",0,0.6399886012077332
41665659,165,ewencp,2015-10-09T18:55:06Z,"nice. it took me a minute to figure out how the combination of join group and sync were working, but the futures made this work out very nicely. this is quite a bit cleaner than i thought it was going to be.",1,0.9876857995986938
41666054,165,ewencp,2015-10-09T18:58:56Z,can probably remove this comment since #290 is addressing this as part of kafka-1843.,0,0.992283046245575
41666648,165,ewencp,2015-10-09T19:05:01Z,"minor, but it'd be good to document the `m` and `s` type parameters. the current javadoc doesn't explain what ""state"" means here.",0,0.9866118431091309
41666750,165,ewencp,2015-10-09T19:06:01Z,"what does `gen` in `gentype` stand for? this is a very minor naming issue, but since i understand the generalized group functionality and am unsure what is trying to be communicated with this name, i imagine it might confuse others as well.",0,0.8054510951042175
41670166,165,hachikuji,2015-10-09T19:40:29Z,"haha, gen is short for generic. awful name, i know. i'll take any suggestions. basically i just wanted to have the type information ride along with the schema. maybe generictype? paramtype?",1,0.9047964811325073
41671402,165,ewencp,2015-10-09T19:54:43Z,"minor cleanup, but there seem to be a few cases like this where the response to two cases is identical and you could collapse them into one conditional block.",0,0.9844189286231995
41671988,165,ewencp,2015-10-09T20:00:59Z,"yeah, i was going to suggest `validatedtype`, but i see that validate is already part of `type` and you've just refined the return type. it's unfortunate that `type` isn't already generic. i'd just expand the name to `generictype`.",-1,0.9530868530273438
41674067,165,hachikuji,2015-10-09T20:23:43Z,"honestly, type could probably be made generic without a huge impact. the usage kind of suggests that intention anyway. that might be worthwhile refactoring for a follow-up patch, but probably not a good idea to jam in here. i'll change to generictype for now.",0,0.8283509612083435
41676221,165,guozhangwang,2015-10-09T20:46:53Z,nit: rename assignors to assignorsmap? it's a bit misleading to have two variables with the same name here.,-1,0.5016208291053772
41678401,165,guozhangwang,2015-10-09T21:10:21Z,is this indentation intentional?,0,0.9883418679237366
41678754,165,hachikuji,2015-10-09T21:14:18Z,"not intentional, just intellij getting a little aggressive trying to ""fix"" the indentation. i'll fix it in the next commit.",0,0.6737335920333862
41679809,165,guozhangwang,2015-10-09T21:26:55Z,why does consumers need to fetch the metadata for group subscription? if it is not subscribed to some topics their partitions will never to assigned to itself right?,0,0.9889410138130188
41680449,165,guozhangwang,2015-10-09T21:34:04Z,this class should be in clients/src/test instead of clients/src/main.,0,0.9935845732688904
41680691,165,hachikuji,2015-10-09T21:37:09Z,"the leader is the only member who sees the group subscription; for everyone else, groupsubscription() will just return that member's subscription. we depend on the leader's metadata in order to set assignments, so it must have metadata available for the full group's subscription. we could just issue one metadata request when the leader is preparing to do the assignment, but that opens the door to the leader missing metadata changes affecting topics it itself is not subscribed to. more concretely, suppose the leader is subscribed to [a], but one follower is subscribed to [a,b]. if the follower notices an increase in b's partitions, it can trigger a rebalance, but there's no guarantee that the partition change will be visible by the leader when it fetches topic metadata. therefore we register the leader to watch for changes to b as well. eventually, when the leader sees the change, it can rebalance. does that make sense?",0,0.9899360537528992
41682690,165,guozhangwang,2015-10-09T22:02:14Z,could this ever happen in the normal case? i think the key-set of consumerspertopic should always be a super-set of key-set of partitionspertopic?,0,0.9898880124092102
41682946,165,hachikuji,2015-10-09T22:05:44Z,"yeah, you are right.",0,0.9224543571472168
41683260,165,guozhangwang,2015-10-09T22:09:55Z,this can be private; also what is the benefit of making it templated instead of using string directly?,0,0.9945881366729736
41684230,165,guozhangwang,2015-10-09T22:24:14Z,there are some overlap between this gentype with org.apache.kafka.common.protocol.types.schema. but schema.validate() returns a struct instead of a generic t type. could we try to merge these two?,0,0.993549644947052
41685576,165,guozhangwang,2015-10-09T22:47:08Z,"a related question to ewen's comment above: how will this version() function be used, for both assignment and subscription?",0,0.9900820851325989
41687689,165,hachikuji,2015-10-09T23:34:03Z,"the leader provides compatible versions of assignments given the respective versions specified in member subscriptions. for this patch, i have assumed full forwards and backwards compatibility of the embedded group protocol, which allows any member to be elected leader during an upgrade scenario and still perform correctly. there are two cases to consider: 1. the leader is on the old version: in this case, forwards compatibility allows the leader to go ahead and parse subscriptions from all members (even those on newer versions) and generate assignments corresponding to its older version. backwards compatibility ensures that the newer members will be able to parse the assignments with older versions. for example, if the leader is on version 0 and a follower is on version 1, the leader will parse the version 1 subscription as a version 0 subscription and provide it a version 0 assignment. 2. the leader is on the new version: in this case, the leader can parse both new and old subscription versions. depending on the protocol, it can choose to send assignments to members corresponding to their respective subscriptions, or it can choose the oldest version and send assignments based on it. using a similar example as above, if the leader is on version 1 and the follower is on version 0, then the leader can parse the version 0 subscription and send a version 0 assignment. obviously this strict compatibility model might be challenging to implement in practice, depending in particular on the protocol format (it would be relatively straightforward if we chose json, for example). alternatively, if we exposed version information in the joingroup protocol, then the coordinator would be able choose the member with the highest version, which would let us weaken the compatibility assumption. the tradeoff is that we'd need to complicate the protocol a bit to carry version information from each member along with their respective subscriptions and assignments. this gets even trickier if you allow assignment strategies to include their own embedded data format, so i was hoping to get a simple approach in place first before having a more complete discussion. perhaps for now i can just add some documentation on the groupprotocol class to clarify the current compatibility assumptions?",0,0.9847257733345032
41709461,165,ijuma,2015-10-11T11:44:04Z,"this seems like a generic method and not specific to strings, so it seems right to me to do it generically (unless we can implement a faster version by making it specific, which doesn't seem to be the case here). a few questions: - should it be in `utils` instead of here? - `consumers` parameter name should be `collection` probably - would ` >` be a better bound? that's what `collections.sort` uses.",0,0.986804723739624
41724298,165,guozhangwang,2015-10-12T05:24:35Z,"that makes sense, could you rephrase the above a little bit as comments to groupsubscription?",0,0.9934797286987305
41724379,165,guozhangwang,2015-10-12T05:27:38Z,"the only place sorted() is called is in the above roundrobinassignor where t is string, so i am wondering if this function is specific to roundrobinassignor only or not; if it is general i agree with you that we should keep it with generics and move it to utils, otherwise we can just make it private to roundrobinassignor and with string only.",0,0.9906224608421326
41727098,165,guozhangwang,2015-10-12T06:49:25Z,add some explanations about generic m(etadata) and s(tate).,0,0.9943943023681641
41775541,165,guozhangwang,2015-10-12T16:39:54Z,i'm wondering if we can put the parse() function in a centralized place since their implementations are all similar?,0,0.9826462268829346
41778171,165,guozhangwang,2015-10-12T17:08:05Z,"could we avoid having two metadata.listener, one in kafkaconsumer and one here? if not, i would prefer to let coordinator have a variable field listener instead of letting itself implement the interface itself.",0,0.9919209480285645
41778848,165,guozhangwang,2015-10-12T17:15:34Z,what scenario would require leaderid in dosync?,0,0.9936544895172119
41781687,165,guozhangwang,2015-10-12T17:45:31Z,"a general comment: maybe we can rename groupcoordinator to coordinator, and coordinator to consumercoordinator, and the server-side consumercoordiantor to groupcoordinator. do you think the names are more clear that way?",0,0.9869815707206726
41783220,165,hachikuji,2015-10-12T18:00:32Z,"yeah, that sounds reasonable. maybe instead of coordinator, we can call it abstractcoordinator?",0,0.9682109951972961
41786233,165,guozhangwang,2015-10-12T18:29:47Z,update the comments for this function.,0,0.9947668313980103
41787479,165,guozhangwang,2015-10-12T18:41:13Z,"this metadatasnapshot is only written upon metadata update, but not read in dosync: we still use the above metadata object, and actually it seems not used anywhere. is this intentional?",0,0.9924181699752808
41791203,165,guozhangwang,2015-10-12T19:18:58Z,good catch.,1,0.9776482582092285
41791349,165,guozhangwang,2015-10-12T19:20:17Z,"if we are not assigning a different error code here, maybe we want to shift the rest error codes left? and same above for 23 / 24 / 25. edit: actually 23 and 25 are still used, scratch that part.",0,0.9916263818740845
41792646,165,guozhangwang,2015-10-12T19:36:12Z,is this still a possible error code? we may need to update the possible error codes for join / sync / commit / fetchoffset responses.,0,0.9932451844215393
41793002,165,guozhangwang,2015-10-12T19:39:52Z,add a comment pointing out this is for leader id.,0,0.9946075081825256
41793506,165,guozhangwang,2015-10-12T19:45:41Z,"this is not introduced in this patch, but why we are returning group_coordinator_not_available for offsetcommit if (!isactive.get), while return not_coordinator_for_group for offsetfetch for the same condition? do you know if there is any motivation?",0,0.9938264489173889
41793618,165,guozhangwang,2015-10-12T19:46:52Z,what are the possible error codes for this response? i ask this since moving forward we will move this into the protocol as well so it's better keep track of those for now.,0,0.9925673007965088
41797594,165,hachikuji,2015-10-12T20:27:34Z,i've added a commit to clarify current versioning assumptions of the embedded metadata/assignment format. let me know if that is sufficient for now. i think we'll still want to consider this in a little more detail in a follow-up issue after this is checked in.,0,0.9763594269752502
41801442,165,hachikuji,2015-10-12T21:07:40Z,"i think i had made it generic initially because the consumer had an object representation, but i agree it's a little silly here. since it is a general function, perhaps i'll go ahead and relocate it to utils.",0,0.8678739070892334
41802182,165,guozhangwang,2015-10-12T21:16:15Z,why do we remove the check on subscriptionlistener.revoked?,0,0.9936421513557434
41802812,165,guozhangwang,2015-10-12T21:22:55Z,generation id is not incremented here?,0,0.9914112091064453
41803001,165,guozhangwang,2015-10-12T21:24:49Z,why error code is 1 instead of 0? also we probably should use errors.offset_out_of_range.code() for readability.,0,0.9879194498062134
41804236,165,guozhangwang,2015-10-12T21:38:31Z,"when we receive a join group in this state from a single member, does that mean we will transit to preparingrebalance and then immediately back to awaitingsync?",0,0.9933534860610962
41804868,165,guozhangwang,2015-10-12T21:45:30Z,do we still have this event in the fsm diagram now?,0,0.9938859343528748
41805021,165,guozhangwang,2015-10-12T21:47:38Z,is syncerrorcode always none.code?,0,0.9922875165939331
41805157,165,guozhangwang,2015-10-12T21:49:32Z,update comments.,0,0.9932690262794495
41807478,165,guozhangwang,2015-10-12T22:19:36Z,"maybe we do not need to have the item here in the fsm, but just list for all possible ""input"": join, sync, heartbeat, offset-commit, offset-fetch, and events like ""member failed"", ""leader timed out while syncing""; and what are the possible ""output"" (i.e. the response) and the state-change (i.e. the transition). some input may not trigger state-change while some other may trigger, and the same input may also end in different state change (e.g. the last join-group request from the group or not). that will make the state machine diagram more clear.",0,0.9881094098091125
41808846,165,guozhangwang,2015-10-12T22:37:29Z,"i think we should, probably piggy-backing on load_balance_in_progress.",0,0.9849386215209961
41809554,165,guozhangwang,2015-10-12T22:47:44Z,"since maybepreparerebalance and proporgateassignment are all synchronized on the group, when the group is still in awaiting sync either all members still have their callback yet to trigger, or all of them should have sent the response in callback right? also the comments are not very accurate: if the group is in the awaiting sync, cancel the sync response for all of them if possible to have all its members rejoin.",0,0.9875719547271729
41809935,165,guozhangwang,2015-10-12T22:53:42Z,in the current implementation we can return the sync response multiple times to members' requests as long as they have the right generation-id and are within the group. i think it does not have any side-effects for now but just want to clarify with you.,0,0.9846606850624084
41810084,165,guozhangwang,2015-10-12T22:56:11Z,do we need to call completeandschedulenextheartbeatexpiration in both dojoin and dosync? why we need to reschedule in dosync?,0,0.994784414768219
41810875,165,guozhangwang,2015-10-12T23:08:04Z,"and with the fsm, we can write handlexxx in coordinator in a way that is aligned with the fsm as the following (personally i feel it may make future implementation and reviews easier): handlexxx: 1. check coordinator arability and group availability, 2. if group is available call doxxx. 3. otherwise proper error code, or create group first then call doxxx. doxxx: switch (group.state) case state1: this request should not be received in this state, return some error-code. case state2: do some actions based on the group metadata, and probably transit group to another state. case statex: ... etc and similarly for events like failed consumers, call onyyy: onyyy: switch (group.state) case state1: this event should not happen in this state, throw exception. case state2: do some actions based on the group metadata, and probably transit group to another state. case statex: ... etc",0,0.9888558983802795
41822373,165,hachikuji,2015-10-13T02:47:56Z,"it looks like the offset fetch is the only request where we return not_coordinator_for_group for that case. it's a little unclear which error code should be preferred, but i would tend to think that not_coordinator_for_group would be the right one since it would force the client to rediscover the coordinator, which is probably what we want when we're shutting down. on the other hand, when we're starting up, we'd want to use group_coordinator_not_available. what do you think?",0,0.9720333814620972
41822535,165,hachikuji,2015-10-13T02:53:23Z,"woops, i'll add the assertion back. i think at one point i had added code to only invoke the revocation callback when we were leaving a valid generation, so the expected revokecount was actually zero and the check on revoked was unneeded. later on, i removed the check to be consistent with the current code, but forgot this assertion.",0,0.9509234428405762
41822701,165,hachikuji,2015-10-13T02:58:23Z,"seems like it's just testing serialization, so 1 was probably chosen for convenience. i'll change to errors.none instead.",0,0.9847126007080078
41823037,165,hachikuji,2015-10-13T03:07:32Z,"if we already transitioned to awaitingsync, then the members of the current generation have already been sent to the leader and the other members have received the generationid. if a new joingroup arrives before the leader has sent syncgroup, then we can either reject the joingroup and continue waiting, or we can just transition to preparingrebalance and have all members rejoin. i chose the latter since there didn't seem much point in stabilizing the group only to have the rejected member force a rebalance anyway after we transitioned to stable.",0,0.9851802587509155
41823511,165,hachikuji,2015-10-13T03:21:59Z,i think this is a good idea. it is difficult in the existing implementation to check where each case fits and whether all cases have been covered.,1,0.9860631823539734
41895691,165,hachikuji,2015-10-13T17:14:07Z,"the transition from awaitingsync to stable happens when the leader submits the assignment for the generation in its syncgroup request. other members (followers) may submit syncgroup before or after this transition occurs. if before, we hold onto the request until the leader has synced; if after, we return immediately. an alternative would be to await all syncgroup requests before returning any of them, but that seems unnecessary since the group already synchronized in the joingroup barrier and the generation has been incremented. it is possible that some members will receive the assignment and others may crash before receiving anything, but the worst thing that happens in that case is that a rebalance is triggered. the generation protects us from inconsistent assignment.",0,0.9718457460403442
41901890,165,guozhangwang,2015-10-13T18:02:07Z,i am ok either way.,0,0.6703996062278748
41902685,165,guozhangwang,2015-10-13T18:08:32Z,"i think we would better return group_coordinator_not_available for (!isactive), and not_coordinator_for_group for (!iscoordinatorforgroup(groupid)) for all requests / conditions, but on the server side we should check the latter first before the former, so that consumers will get not_coordinator_for_group if it is ever the case and rediscover.",0,0.9869824647903442
41907724,165,guozhangwang,2015-10-13T18:46:55Z,"that is fine, then in preparingrebalance state we could get syncgroup requests from leader / followers, and need to return an error code to let them re-send the joingroup. is that the case?",0,0.9944407343864441
41908099,165,guozhangwang,2015-10-13T18:50:10Z,rep. first paragraph: yeah makes sense. rep. second paragraph: i am not favoring in adding another synchronization barrier unless we have to. let's sync up some time about the state transition again.,0,0.9743660688400269
42170845,165,guozhangwang,2015-10-15T19:45:25Z,"wondering if we can do the following: 1. assignment / subscriptions extend assignor.assignment / subscriptions interface and extend struct. 2. the schema object of assignment / subscriptions will be relying on consumer_protocol_header_schema, assignment_v0 and subscription_v0 (maybe we can move them to a consumerprotocol sub-class inside abstractpartitionassignor). 3. use schema.write / read to serialize / deserialize the assignment / subscriptions. 4. remove generictype class and subscriptionschema / assignmentschema functions. is there any blockers for that?",0,0.9806484580039978
42174780,165,hachikuji,2015-10-15T20:20:19Z,wouldn't it be a little restrictive to require all assignor implementations to use kafka structures for serialization?,0,0.9585397839546204
42175026,165,ewencp,2015-10-15T20:22:18Z,"isn't the drawback with that is that you _must_ use kafka's struct then? that seems pretty inconvenient if there's a chance your data format will change but you can guarantee compatibility, e.g. a resource-based assignor is likely to evolve the set of configs it has over time. in particular, i think this would mean that if you wanted to make any change that could be handled compatibly by your code but that doesn't fit into struct's compatibility rules, you would have to change assignor name/sub protocol name, which also means going through the multiple-assignors + 2 rolling bounces upgrade process.",0,0.5368808507919312
42175057,165,guozhangwang,2015-10-15T20:22:33Z,i feel it is general enough. what kind of serdes are not compatible with kafka structures?,0,0.9327095746994019
42176271,165,hachikuji,2015-10-15T20:32:23Z,we might be able to make that work if we change the format to something like this: [code block] then users can provide any metadata they need in the userdata field.,0,0.990627646446228
42178482,165,ewencp,2015-10-15T20:50:20Z,"what's the real benefit of requiring kafka's structs and doing so directly? it has the drawback i mentioned and it also keeps you from being able to manually handle multiple versions if you wanted to (you could check the version number before trying to decode, but only if you have control over the deserialization process). it looks to me like it just saves a few lines of code for us, and _maybe_ is a bit simpler for implementers of assignors since generictype will be removed.",0,0.9832426309585571
42179615,165,hachikuji,2015-10-15T20:58:41Z,"one benefit of having a common serialization for subscriptions/assignment is that admin tooling can then depend on it. i think it might not be too bad if we implemented the userdata suggestion above. then we could actually keep the struct serialization hidden from users and give them control over userdata, which lets them do whatever they want.",0,0.945085346698761
42180627,165,guozhangwang,2015-10-15T21:07:42Z,could this function ever be triggered? requestfuturecompletionhandler only have the oncomplete() api which will always trigger firesuccess().,0,0.9935954213142395
42181904,165,ewencp,2015-10-15T21:18:59Z,"i kind of buy that argument, but that tooling can't do anything useful with kafka structs that it doesn't already know the format of since the schema is only recorded in code. it might make writing the tooling simpler since it only has to deal with one format, but with kafka structs i don't think it actually enables anything that you couldn't get even with the more general form. i'm fine if we go with requiring schema/struct, i'm mostly wary because copycat is relying on this as well and i don't think we have as clear an idea of the exact requirements there as we do with a lot of the assignors -- right now its really simple, just the config topic offset that the worker is currently on, but i'm not sure what else might eventually make it in there. i personally like having the possibility to make certain incompatible schema changes without requiring config changes + rolling bounces (i.e. the possibility to keep those changes seamless for the user).",0,0.7590615749359131
42182802,165,hachikuji,2015-10-15T21:26:49Z,"this makes me want to add back the protocoltype field in the joingroup request. then if the protocol type is ""consumer,"" tools would be able to parse metadata directly by using consumerprotocol. they wouldn't be able to touch userdata, but that seems reasonable.",0,0.9897739291191101
42185251,165,hachikuji,2015-10-15T21:48:56Z,"consumernetworkclient does fail some requests before they are sent, but i don't think disconnectexception is possible.",0,0.9904488921165466
42189757,165,hachikuji,2015-10-15T22:34:12Z,"ok, so here's a summary of the changes i'm suggesting: 1. change consumer metadata schema to the following: [code block] assignment stays as it currently is (are there any cases where an assignor implementation would need to propagate additional information in the assignment)? 2. migrate the subscription/assignment schemas currently in abstractpartitionassignor back into consumerprotocol. 3. change the partitionassignor interface to look something like this: [code block] 4. add protocoltype field to joingroup request: [code block] for the consumer, the protocol type will be ""consumer"" and this will allow tools to use consumerprotocol to parse subscription/assignment metadata (assuming we will eventually expose it in describegroup or something similar). what do you think?",0,0.9880656003952026
42190485,165,ewencp,2015-10-15T22:42:19Z,"so then does that include the changes was talking about? the basic approach sounds fine, and the organization is similar to how i updated the copycat code when i rebased onto this code -- i kept a copycatprotocol class, though it ended up just holding a few static methods + inner classes. but this is a solution for making generic tooling for consumers possible. you could do all of this and still restrict the format to kafka structs as proposed, right?",0,0.9191933274269104
42193354,165,guozhangwang,2015-10-15T23:15:10Z,is this class needed?,0,0.9932491779327393
42195737,165,guozhangwang,2015-10-15T23:49:11Z,"i was originally mainly think about code simplicity, not about tooling connivence much. i am wondering for copycat, is a topics field always necessary and representative of the resource partitions? i get 's point that enforcing the whole protocol to be restricted to kafka structures would be less flexible in terms of compatibility, and if we only do that by extracting `topics` from subscriptions while keep `userdata` and `assignment` still generic types then it does not buy us much regarding code simplicity either. so i am now ok with the current approach of keeping `generictype`. the only other comment is as below: we probably can save the abstractpartitionassignor as its only `assign` function is more like a helper function, hence putting the schemas in a `consumerprotocol` class along with the helper functions, and only keep one `partitionassignor` interface for users to instantiate.",0,0.7588790059089661
42195884,165,hachikuji,2015-10-15T23:51:18Z,my suggestion is limited in scope to the new consumer. copycat can still implement metadata however it wants.,0,0.9926559925079346
42197214,165,ewencp,2015-10-16T00:11:39Z,"following up, i got a clearer explanation from offline. the change is specific to the consumer groups, copycat still has control over its serialization via its abstractcoordinator subclass since that class just deals with `byebuffer`s. so i think this plan with the extra user data makes sense.",0,0.9824172258377075
42197590,165,guozhangwang,2015-10-16T00:17:50Z,"talked to offline, my previous understanding was incorrect that other services like copycat and kafkastreams also need to implement `partitionassingor`, which is actually only gonna be used by the new consumer. hence for others they can always decide to implement their only schemas that is not restricted to kafka schema / struct.",0,0.9839766025543213
42278727,165,guozhangwang,2015-10-16T19:07:24Z,we can remove the package prefix.,0,0.9944958090782166
42281759,165,hachikuji,2015-10-16T19:40:04Z,"yes, that's right, since the generation is required, i think it should be ok. of course this implies that the coordinator keeps sync state around while in the stable state. one thing we've discussed is allowing the coordinator to discard this state some time after the group becomes stable (maybe after one session timeout). this would reduce the memory footprint of the group on the broker in the steady state. this is probably worth looking at once this patch is out of the way.",0,0.9602779746055603
42284440,165,guozhangwang,2015-10-16T20:08:39Z,totally agree.,0,0.9421791434288025
42426323,165,guozhangwang,2015-10-19T21:10:14Z,"could you also update the comments here according to the discussed fsm? basically we only need the responding logic for each event within a state, and the transit logic between across states.",0,0.9950542449951172
42427091,165,guozhangwang,2015-10-19T21:17:31Z,"i think we said in this case we will also return rebalance_in_progress, and hence we can remove unknown_member_id from possible error codes in syncresponse?",0,0.9916901588439941
42427602,165,guozhangwang,2015-10-19T21:21:52Z,"in the current protocol the leader should never submit the sync request twice, or in otherwords submit a sync group request without receiving a join group response; and if they do it would be due to a re-send upon ack failed, etc. hence i think in the stable state we should not distinguish leader with others any more and just treat everyone as the same.",0,0.9865908622741699
42428212,165,guozhangwang,2015-10-19T21:27:19Z,"i think it's better the follow the same pattern as we do in handlexxx here, e.g. move the checking such as `rebalancepurgatory.checkandcomplete()` if the state is in `reparerebalance``, or``maybepreparerebalance``if state is in``awaitingsync``or``stable``. also with the current implementation we will transit from awaitingsync to preparerebalance if any of the members failed, but with my proposed protocol we could only trigger that transition if the leader fails. is there any problem doing this?",0,0.979393720626831
42428592,165,guozhangwang,2015-10-19T21:30:37Z,"i forgot to add this event in the fsm before, it should be treated as similar to onconsumerfailure.",0,0.9504473209381104
42429156,165,guozhangwang,2015-10-19T21:36:07Z,move this condition after the first one as we want to send rebalance_in_progress before illegal_generation: they may not cause difference for now but just be careful for future updates. or just use `match case` on states and only do generation / member-id checks for `stable` state.,0,0.9913883805274963
42429312,165,guozhangwang,2015-10-19T21:37:34Z,if the state is in `preparerebalance` we can accept if generation is from the previous one?,0,0.9930921792984009
42429493,165,guozhangwang,2015-10-19T21:39:13Z,nit: onexpirerestablaize.,0,0.9938769936561584
42429521,165,guozhangwang,2015-10-19T21:39:31Z,nit: onexpireheartbeat.,0,0.8328028321266174
42429678,165,guozhangwang,2015-10-19T21:40:58Z,"also according to what we discussed offline, maybe we can rename ""restabilize"" to ""join"" since it is only for the first phase of rebalance.",0,0.9923966526985168
42437210,165,hachikuji,2015-10-19T23:02:31Z,"i think that is right. the generation is incremented after the join completes, so we allow commits from the current generation in preparerebalance.",0,0.9806265234947205
42437479,165,guozhangwang,2015-10-19T23:06:06Z,"ah right, my bad.",-1,0.9929441809654236
42469221,165,onurkaraman,2015-10-20T08:45:08Z,it may be more intuitive to return unknown_member_id when group == null.,0,0.9857248067855835
42531198,165,guozhangwang,2015-10-20T18:04:34Z,"i think i agree, it is also for consistency with hb and leave requests.",0,0.8580799698829651
42575975,165,becketqin,2015-10-21T01:50:05Z,should this be getconfiguredinstances()?,0,0.9951608777046204
42576026,165,becketqin,2015-10-21T01:51:12Z,"minor, kafka convention is not using brackets for single line statement.",0,0.9830053448677063
42576335,165,becketqin,2015-10-21T01:58:16Z,can we put some of the methods in a separate util class?,0,0.994775652885437
42576376,165,guozhangwang,2015-10-21T01:59:01Z,"currently our configs are still going to pass-in a single partitioner which is then be used as a singleton list, hence we use `getconfiguredinstance` here.",0,0.9934280514717102
42577420,165,hachikuji,2015-10-21T02:20:40Z,i think might be right. providing multiple instances is to support changes in a rolling upgrade scenario.,0,0.9816581010818481
42578537,165,becketqin,2015-10-21T02:44:19Z,"the name is a little bit misleading here. when rebalance occurs, no one actually leaves the group, right? also, according to the comments for this method: _invoked when the group is left (whether because of shutdown, metadata change, stale generation, etc.)_ at very least it looks metadata change actually will not kick anyone out of the group, but only trigger a rebalance.",0,0.9095048904418945
42578745,165,becketqin,2015-10-21T02:47:22Z,do we have any use case in mind for this method? it looks somewhat overlapping with consumerrebalancelistener.onpartitionsassigned().,0,0.9940274953842163
42578814,165,becketqin,2015-10-21T02:49:10Z,empty comments.,0,0.8785811066627502
42578959,165,hachikuji,2015-10-21T02:52:02Z,two potential use cases i know of. one is sticky partitioning where the partitioner sends the old assignment in the subscription for the next round so that the leader can keep partition movement minimal. the other is for kafka streams ( knows more about this use case).,0,0.9903436899185181
42642563,165,hachikuji,2015-10-21T15:52:10Z,"yeah, that's a fair point. perhaps beforerejoin would be more accurate?",0,0.9561229944229126
42643752,165,hachikuji,2015-10-21T16:01:01Z,actually i don't think it's too inaccurate since you are leaving the generation. perhaps onleavegeneration?,0,0.9773356914520264
42653027,165,becketqin,2015-10-21T17:15:33Z,"i'm not sure how it would work for sticky partition case. to make the leader honor the sticky partition (move as less partition as possible), the current leader needs to know the global assignment from the previous rebalance. but here we only have the assignment of this particular consumer. if we want to have sticky partition assignor perhaps we can let every consumer include their current assignment in the joingrouprequest and let the leader parse them.",0,0.9166127443313599
42653813,165,hachikuji,2015-10-21T17:21:38Z,"the idea is to have the local assignment returned in onassignment included in the user data of the next subscription. all subscriptions are forwarded to the leader, so it would be able to use the previous assignments found in the member's subscription userdata to compute the next assignments.",0,0.9927626252174377
42654165,165,guozhangwang,2015-10-21T17:24:16Z,"`onassignment` is only triggered after the syncing phase by everyone, not only by the leader. it is different from `consumerrebalancelistener.onpartitionsassigned()` such that the latter only gives the list of partitions, while the former contains extra userdata that can be associated with the assigned partitions. for kafka streams it is important to use this userdata to infer the further mapping from consumer's partitions to task's partitions.",0,0.9917590022087097
42683684,165,becketqin,2015-10-21T21:18:44Z,"i kind of think we should be careful about those terminologies. otherwise we can easily confuse people. another example is `dosync` and `performsync`, from the name it is hard to tell the difference. i suggest we do the following for abstractcoordinator: 1. rename `dosync` to `generateassignments`, and there is no need to pass in `leaderid` because it is always going to be itself. 2. separate `performsync` to `onelectedasgroupleader` and `oneelectedasgroupmemeber`. we can invoke them in joingroupresponsehandler.handle() 3. rename `onleave` to `ongroupjoinstart` 4. rename `onjoin` to `ongroupjoinfinish` 5. rename `sendjoingrouprequest` to `performgroupjoin` so the sequence becomes: 1. ongroupjoinstart 2. performgroupjoin 3. ongroupjoinfinish in performgroupjoin(): 1. sendjoingrouprequest 2. joingroupresponsehandler.handle() \* onassignedasgroupleader (only valid for leader) \* generateassignments \* sendsyncgrouprequest() with assignments or \* onassignedasgroupmember (only valid for member) \* sendsyncgrouprequest 1. syncgroupresponsehandler.handle() - getpartitionassignment and complete the future. except for that, the client side code structure looks good to me. i will continue to review the server side code.",0,0.9409943222999573
42685152,165,becketqin,2015-10-21T21:30:55Z,got it. thanks for the explanation.,1,0.985473096370697
42689244,165,hachikuji,2015-10-21T22:05:54Z,"thanks for the suggestions! a few notes: 1. i agree with renaming dosync. initially i was thinking of this phase as ""state synchronization,"" but in the end, it seemed that the assignment terminology was easier to understand, so i did some renaming, but didn't catch all. i think, however, that leaderid is needed in the general case because the member doesn't know its own id (the copycat patch is already depending on this). 2. yeah, we can do this. maybe more concisely, we can use `onbecomeleader` and `onbecomefollower`? 3. this suggestion is equally confusing in my mind. it seems more natural to phrase this in terms of the generation. instead of `onleave`, my suggestion would be `ongenerationend`. 4. similarly, `onjoin` becomes `ongenerationbegin`. 5. i guess that's fair since it's not only sending the join group.",1,0.9902971386909485
42718108,165,becketqin,2015-10-22T07:27:54Z,"about (3) and (4), i think the confusion comes from we are reusing the term **join** here while we already have a joingrouprequest. but i am also a little concerned about exposing the concept of **generation**. **generation** is a purely implementation detail so it would be nice not to expose that to user. my original thinking was `onrebalancebegin()` and `onrebalanceend()`. it is a precise description and avoids reusing joingroup, but it exposes the concept of **rebalance** to user. that was why i switched to `ongroupjoinbegin` and `ongroupjoinend` - because it is very easy for user to understand. people who overrides those two methods don't need to have ideas about internal details such as joingrouprequest, generation, rebalance, etc. they only need to know: 1. **ongropujoinstart** - do something before taking action to join/rejoin the group. 2. **generateassignments** - run the customized resource assigning algorithm. 3. **ongroupjoinfinish** - do something after you joined the group from user's point of view they are only doing a group join (it has nothing to do with joingroupreqeust). group join looks more intuitive than names related to rebalance or generation. i just want to reason a little bit on the names. because those method names are essentially public api that user will override, i feel making them easy to understand is important.",0,0.6853474974632263
42779406,165,hachikuji,2015-10-22T17:35:35Z,"yep, totally agree on the importance of naming. this issue is clearly related to the discussion on kafka-2674. i think there are two ways we can approach this: 1. the callbacks are used to indicate phases of rebalance. there is an initial call when the rebalance begins and another call when the rebalance ends. maybe we could change the names in this case to `onjoinbegin` and `onjoinfinish`. 2. the callbacks are used to indicate group membership. in this case, the first call would always be onjoin and every onjoin would be paired with a corresponding onleave. in this case, onleave would get invoked in close if there is an active group. i think you are favoring 1., while the current rebalancelistener used by the consumer and the abstractcoordinator is suggesting 2. to the user. whichever we decide, we need to make the naming consistent. i actually don't have a strong preference either way, but i think it comes down to the following question: are there any cases where the onpartitionsrevoked() function is going to do anything different than what would be done on close(). if they always do the same thing, then we should probably make user's life easier and implement 2. if not, then we should keep 1.",0,0.8231416940689087
42831631,165,becketqin,2015-10-23T04:03:50Z,"good point about the correlation with rebalance listener methods. you are right, we should make them consistent. it looks we are trying to address two different kinds of programmers: 1. people who are using kafkaconsumer. 2. people who are developing their clients(producer/consumer/processor, etc) and extending abstractcoordinator. majority of the programmers belongs to (1). what they need to provides today are: - consumerrebalancelistener - `onparitionsrevoked()` - `onparitionsassigned()` - partitionassignor - `assign()` - `onassignment()` - `subscription()` the programmers in case (2) need to think about: - `ongroupjoinstart()` - `generateassignment()` - `ongroupjoinend()` to make everything consistent, perhaps we can change the consumerrebalancelistener interface to: - consumerrebalancelistener - `ongroupjoinstart()` - `ongroupjoinend()` as said in kafka-2674, my only concern about this approach is that if later on we want to add a `beforecommittingoffset()` to rebalance listener, that's going to be a bit weird. but there is always a workaround to turn off auto commit and let user have full control over the state when `ongroupjoinstart` is called. so i guess this is less a problem. does this approach make sense? btw, wrt **leave**, here is my understandings about onleave() if we have one. if we have an onleave(), it should only be called when a consumer has been kicked out of the group, i.e. its generation id is no longer valid. otherwise, the consumer is technically still in the group. that means onleave() should not be called during a normal rebalance because the generation id is still valid.",1,0.9015713930130005
42897321,165,hachikuji,2015-10-23T18:21:35Z,"hey , can you have a look at #354? maybe we can continue discussion there? my current position is basically to make the naming consistent with the implementation. right now, the implementation of onleave is actually closer to ongroupjoinstart (or onjoinprepare as i named it in that patch). i think it's worth discussing whether onleave would be more useful in practice, but we need to think it through. it seems to me like onjoin and onleave, if implemented according to their naming, would be a more intuitive paradigm for developers to build off of, but it is a little inconsistent with prior usage of rebalance callbacks.",0,0.9498969912528992
43426682,165,becketqin,2015-10-29T18:35:45Z,what would happen if coordinator shuts down after this test passes?,0,0.9698935151100159
43427203,165,becketqin,2015-10-29T18:39:49Z,"minor, it might be slightly cleaner if we throw exception when some error occurs and catch the exception in handlejoingroup() and call responsecallback. we might also want to add error log message when exception is thrown.",0,0.9885622262954712
43428250,165,becketqin,2015-10-29T18:48:07Z,do we need to pass in member.memberid? can we simply pass in member?,0,0.9953252077102661
43442917,165,hachikuji,2015-10-29T20:54:28Z,"yep, good point.",1,0.9003447890281677
43444426,165,hachikuji,2015-10-29T21:07:18Z,"nod, i was following the pattern of the other handlers. throwing exceptions might let us remove a little boilerplate, but either approach works for me. and i agree on logging.",0,0.9803929924964905
43449219,165,becketqin,2015-10-29T21:50:26Z,it seems fine. we always shutdown socketserver and kafkaapis before shutting down coordinator.,0,0.9159486889839172
43451430,165,becketqin,2015-10-29T22:12:19Z,the comments here seems not accurate.,0,0.9367591738700867
43457097,165,becketqin,2015-10-29T23:24:31Z,what if the leader send syncgrouprequest late? should we start counting down after we send syncgroupresponse because the consumer only starts to heartbeat after syncgroupresponse is received.,0,0.9818591475486755
43664832,165,hachikuji,2015-11-02T18:50:00Z,"actually i think it's right. if the follower's metadata is different, then we force a rebalance.",0,0.9623704552650452
43665262,165,hachikuji,2015-11-02T18:53:14Z,"we start the clock after join group completion. if the leader fails to send syncgroup within one session timeout after the join group phase has completed, then we will transition to preparing rebalance (i think i have a test case for this). if the leader sends syncgroup after this transition, then it will be given a rebalance_in_progress error.",0,0.9937775135040283
1806596264,17539,apoorvmittal10,2024-10-18T14:25:57Z,"question for my understanding: do we need to this calculation? as i can see fetch params already has minbytes in request to replica manager hence isn't the response from replica manager should be empty if minbytes criteria is not satisfied? so the question arise that how do we differentiate between empty reponse from replica manager log read, if that's beacus of min bytes or there is no data in the log? in either case we should continue holding the request in purgatory? wdyt?",0,0.9753061532974243
1806619158,17539,adixitconfluent,2024-10-18T14:39:49Z,"hi , iiuc, minbytes is utilized in `replicamanager.fetchmessages` functionality [a link] not in `replicamanager.readfromlog`. the way it calculates the `accumulatedbytes` is the same way i have done it in my code ([a link]. i don't see the usage of `params.minbytes` in `readfromlog` functionality",0,0.9888834357261658
1806639708,17539,apoorvmittal10,2024-10-18T14:53:04Z,i think you are right. i also see only reference of param minbytes in fetchmessages and not in readfromlog. also the readfromlog says upto maximum in description and nothing about minbytes. then the pr change sounds good but i was wondering why do we accept complete fetchparams in readfromlog when we don't utilize something like minbytes there. not sure if we should have minbytes support in readfromlog itself. maybe out of scope of this pr. can help is with more context.,1,0.910947322845459
1806669871,17539,apoorvmittal10,2024-10-18T15:15:54Z,"hmmm, is this same for regular fetch operations as well?",0,0.9795631766319275
1806671945,17539,apoorvmittal10,2024-10-18T15:17:28Z,and why don't we want to release the partition locks from oncomplete?,0,0.9926631450653076
1806680209,17539,apoorvmittal10,2024-10-18T15:24:01Z,"in most scenarios the request might have minbytes, hence do you always want to initialize a hash map? mostly it will be overriden with `responsedata` map. so can't it be null? moreover can't it be simpy a boolean variable i.e. boolean minbytessatisfied = false if (accumulatedbytes.get() >= sharefetchdata.fetchparams().minbytes) replicamanagerfetchsatisfyingminbytes = responsedata; => if (accumulatedbytes.get() >= sharefetchdata.fetchparams().minbytes) minbytessatisfied = true; if (replicamanagerfetchsatisfyingminbytes.isempty() && !hasrequesttimedout) { => if (!minbytessatisfied && !hasrequesttimedout) { return replicamanagerfetchsatisfyingminbytes; => return collections.emptymap()",0,0.9925355911254883
1806682789,17539,apoorvmittal10,2024-10-18T15:26:07Z,now we can come to this code path getting no result from `replicamanagerfetchdata`. hence is the log line still correct?,0,0.9931336641311646
1806685722,17539,apoorvmittal10,2024-10-18T15:28:25Z,"do you need this extra variable or can just write later, if needed? and then no need of else block below. replicamanagerfetchdatafromtrycomplete = replicamanagerfetchdata(topicpartitiondata, true);",0,0.9958016276359558
1806689153,17539,apoorvmittal10,2024-10-18T15:31:10Z,"fetchresponsedata can still be empty, though processfetchresponse handles the empty check, is it intended? though no harm, just checking with you.",0,0.9777155518531799
1806690387,17539,apoorvmittal10,2024-10-18T15:32:10Z,what about if partitions were locked but no response in data aarived then will the lock be correctly released?,0,0.9906997084617615
1806716182,17539,adixitconfluent,2024-10-18T15:53:21Z,"in this case, we want to call `sharefetchutils.processfetchresponse(sharefetchdata, fetchresponsedata, sharepartitionmanager, replicamanager)` before we want to release the locks. that part is in `oncomplete`, hence we don't release the lock",0,0.9941535592079163
1806722986,17539,adixitconfluent,2024-10-18T15:59:04Z,"yeah, it makes sense. i'll make the change.",0,0.9593395590782166
1806725239,17539,adixitconfluent,2024-10-18T16:01:03Z,"now that i think again, i should return a map with key as topic partition and value as `fetchpartitiondata` object containing 0 records and since we have not been able to satisfy all the fetch request criterias. your thoughts?",0,0.9855369925498962
1806729605,17539,adixitconfluent,2024-10-18T16:04:48Z,"yeah, since `processfetchresponse` can handle it, that's why i didn't add any check here",0,0.9934808015823364
1806735371,17539,adixitconfluent,2024-10-18T16:10:17Z,"for that case, even when the data is not received from replica manager, the fetchresponsedata should still have keys as the locked topic partitions and values as empty data, so it should work. am i wrong in that understanding?",0,0.9552286863327026
1807312461,17539,adixitconfluent,2024-10-19T12:35:26Z,"i can get rid of it, but then the variable name `replicamanagerfetchdatafromtrycomplete` won't make sense if it is getting some values in `oncomplete`. i just feel that the code is more readable this way.",0,0.9771580696105957
1807413812,17539,adixitconfluent,2024-10-19T16:31:47Z,"hi , i went through the code for oncomplete of `delayedfetch` ([a link], it seems that it returns whatever it gets from `replicamanager.readfromlog`, so the current code is correct in that case. please let me know if i am wrong. cc -",0,0.6630634665489197
1809360360,17539,apoorvmittal10,2024-10-21T19:07:23Z,should it be atomiclong?,0,0.9893404841423035
1809365166,17539,apoorvmittal10,2024-10-21T19:10:32Z,"info seems to be too much here, how helpful this log would be in info mode? can we move it to debug please.",0,0.537663996219635
1809366048,17539,apoorvmittal10,2024-10-21T19:11:07Z,wouldn't this be too common? should we move it trace?,0,0.9859193563461304
1809378335,17539,apoorvmittal10,2024-10-21T19:17:15Z,will it not depend on `readfromlog` api response i.e. if you sent 3 partitions then is it guaranteed that replica manager will return all 3 partitions in response?,0,0.9938241243362427
1809417014,17539,apoorvmittal10,2024-10-21T19:44:11Z,should we maintain the order by `linkedhashmap` as earlier?,0,0.9948904514312744
1809422393,17539,adixitconfluent,2024-10-21T19:47:48Z,"reading `readfromlog` functionality, i don't see an indication where it doesn't return all the partitions sent to it, however i'll still make the change to use `topicpartitiondata` to be on the safe side.",0,0.9873943328857422
1809669520,17539,junrao,2024-10-21T23:53:47Z,"1. this approach is ok, but probably not the most efficient. `replicamanager.readfromlog` is relatively expensive. to avoid calling it on every hwm change, the delayedfetch maintains the file position of the fetch offset and compares it with the file position of hwm to estimate the fetchable bytes. we could potentially do the same thing here. this requires us to maintain the file position for sharepartition.endoffset. 2. ideally, we need to take into account the size of those non-acquirable batches in sharepartition when estimating the fetchable bytes.",0,0.949590265750885
1810373760,17539,apoorvmittal10,2024-10-22T09:40:25Z,thanks a lot for suggestion . this is good. i have aquestion on 2. though it's an ideal solution but the next fetch offset being prior to endoffset should be rare i.e. when some records are released or timedout. so i think we can avoid calculating non-acquirable and proceed to fetch anyways if our criteria from end offset to hwm meets. we can have the min bytes check after the fetch as currently in the pr. wdyt?,1,0.9945214986801147
1810810655,17539,adixitconfluent,2024-10-22T14:11:40Z,"hi , agreed this is a much better approach. just one clarification - you mean the file position of the latest offset that was fetched for the share partition, right?",1,0.6486835479736328
1811067709,17539,junrao,2024-10-22T16:44:46Z,"yes, this sounds reasonable. we can just ignore the non-acquirable records for now. basically, we need to maintain endoffset as a `logoffsetmetadata`, which contains segment position. we can then use `logoffsetmetadata.positiondiff` to calculate the available bytes.",0,0.9859359264373779
1812510188,17539,apoorvmittal10,2024-10-23T11:13:22Z,can it reside in share module under `fetch`?,0,0.9956912398338318
1812512229,17539,apoorvmittal10,2024-10-23T11:14:53Z,"isn't by default it will be null, do we need to define it here?",0,0.9907402992248535
1812513907,17539,apoorvmittal10,2024-10-23T11:16:09Z,"you made a new class for this, shouldn't we pass that here?",0,0.9927796721458435
1812514360,17539,apoorvmittal10,2024-10-23T11:16:29Z,is it need to be default scoped?,0,0.9916683435440063
1812516782,17539,apoorvmittal10,2024-10-23T11:18:26Z,"so in a fetch result of 10 batches we should store the last batch info, is that correct? if yes then shouldn't name of variable be appropriately defined?",0,0.9952776432037354
1812517165,17539,apoorvmittal10,2024-10-23T11:18:45Z,merge with previous line.,0,0.9860013723373413
1812518313,17539,apoorvmittal10,2024-10-23T11:19:39Z,why do we need this?,0,0.9423887133598328
1812520317,17539,apoorvmittal10,2024-10-23T11:21:10Z,will this log line print anything meaningful? i don't see tostring in `fetchpartitiondata`. should we return what's required here?,0,0.9927494525909424
1812521637,17539,apoorvmittal10,2024-10-23T11:21:49Z,should it be default scoped? if used for tests then please write // visible for testing.,0,0.9953098893165588
1812523220,17539,apoorvmittal10,2024-10-23T11:22:45Z,how the exception will be handled with this method? do we have a test case when exception is thrown by this replica manager call?,0,0.9941904544830322
1812747750,17539,adixitconfluent,2024-10-23T13:20:10Z,i've moved it to protected. it cannot be private since it is utilized in `delayedsharefetch`,0,0.9952993392944336
1812784514,17539,adixitconfluent,2024-10-23T13:36:51Z,"we store the last fetched offset's properties in `logoffsetmetadata` class like the message offset, file position etc. hence, naming it `latestfetchoffsetmetadata` makes more sense than `latestfetchbatchmetadata`. wdyt?",0,0.9917744994163513
1812833979,17539,AndrewJSchofield,2024-10-23T13:56:54Z,"nit: i hesitate to correct your greek, but the singular of ""criteria"" is ""criterion"". maybe ""isminbytessatisfied"" would be simpler than worrying about greek grammar.",0,0.9259942770004272
1812914606,17539,adixitconfluent,2024-10-23T14:33:31Z,i've added the handling and test case for this in my latest commit,0,0.9934936165809631
1813543008,17539,junrao,2024-10-23T20:50:30Z,"we need to check if the two offset metadata are on the same segment first before using `positiondiff`. also, we need to handle the case when hwm doesn't have offset metadata. we can just follow the logic in `delayedfetch`.",0,0.9935803413391113
1813549471,17539,junrao,2024-10-23T20:53:30Z,we need to check `sharefetchdata.fetchparams().isolation` to decide whether to use hwm or laststableoffset.,0,0.9953849911689758
1813657687,17539,junrao,2024-10-23T21:31:18Z,"it's kind of late to set the offset metadata here since we will acquire the fetch records and move the next fetch offset. this means the cached offset metadata doesn't match the next fetch offset. i was thinking of doing the following. in `trycomplete`, if the offset metadata doesn't exist, we call `replicamanager.readfromlog` to populate the offset metadata. we can then proceed with the minbyte estimation. if sharepartition.endoffset moves, we invalidate the offset metadata.",0,0.8974426984786987
1815509020,17539,junrao,2024-10-24T18:07:15Z,"the `acquire` call always comes after `delayedsharefetch.trycomplete`, which already updates `latestfetchoffsetmetadata`. so, it seems that we don't need to update `latestfetchoffsetmetadata` in `acquire`?",0,0.9933091402053833
1815510878,17539,junrao,2024-10-24T18:09:01Z,we need to reset `latestfetchoffsetmetadata` every time `endoffset` changes.,0,0.9945389628410339
1815515373,17539,junrao,2024-10-24T18:12:55Z,"it's possible that `maybeupdatefetchoffsetmetadatafortopicpartitions` calls `readfromlog`, which returns enough bytes. in that case, it's more efficient to reuse the fetched result instead of calling `readfromlog` again in `oncomplete`.",0,0.9914491772651672
1815520277,17539,junrao,2024-10-24T18:17:19Z,perhaps it's clearer to make sharepartition.latestfetchoffsetmetadata() an optional?,0,0.9892681241035461
1815531648,17539,junrao,2024-10-24T18:27:27Z,"in delayedfetch, if a partition no longer exists, we complete the operation immediately.",0,0.9915087223052979
1815542651,17539,junrao,2024-10-24T18:37:09Z,could this just be a `long`?,0,0.9725517630577087
1815548051,17539,junrao,2024-10-24T18:42:00Z,"hmm, we don't want to read all partitions if only one partition's offset metadata is missing, right?",0,0.9660620093345642
1815562399,17539,junrao,2024-10-24T18:55:14Z,"1. perhaps ""we maintain the latest fetch offset metadata to estimate the minbytes requirement more efficiently.""? 2. also, could we keep it together with `endoffset` since they are related.",0,0.9894996285438538
1815586235,17539,adixitconfluent,2024-10-24T19:18:47Z,"yeah, but in case there are multiple partitions for which offset metadata is missing, i thought that its better to make a single `readfromlog` call instead of multiple `readfromlog` calls. thus, using all the topic partitions in one call itself. wdyt?",0,0.9875778555870056
1815592778,17539,adixitconfluent,2024-10-24T19:25:07Z,"`updatelatestfetchoffsetmetadata()` is only called from `trycomplete` when we find that there is a share partition whose offset metadata is not present (because in that case only, we call `readfromlog`). however, for any other case, we can only update the `latestfetchoffsetmetadata` via `acquire` method only. else we'll have to call `readfromlog` from `trycomplete` in all scenarios to directly update share partition's `latestfetchoffsetmetadata`. anything wrong in that understanding?",0,0.9921865463256836
1815599413,17539,adixitconfluent,2024-10-24T19:31:09Z,"iiuc, everytime we fetch new records from `readfromlog`, i utilize the `logoffsetmetadata` object from the response to update the `latestfetchoffsetmetadata` object while doing the acquire. hence, this way i have the most recent fetched offset's metadata that i always update through `acquire` method. most of the time, it is going to be the endoffset's metadata itself, as soon as new data is produced to the topic partition. anything else that i need to do here?",0,0.9846010804176331
1815731593,17539,junrao,2024-10-24T21:50:37Z,"hmm, if a previously acquired batch times out, sharepartition will change endoffset. this means that the cached latestfetchoffsetmetadata no longer matches the next fetch offset, right?",0,0.9841857552528381
1815739504,17539,junrao,2024-10-24T21:56:47Z,"hmm, to me `acquire` seems to be the wrong place to update `latestfetchoffsetmetadata`. we update `latestfetchoffsetmetadata` with the fetch offset and then acquire a few batches after the fetch offset. this typically moves the next fetch offset, which makes `latestfetchoffsetmetadata` useless for the next fetch.",0,0.9498188495635986
1815741519,17539,junrao,2024-10-24T21:59:31Z,maybe we can first make a pass to collect all partitions missing offset metadata and then make a single `readfromlog` with those partitions?,0,0.9921920895576477
1816504391,17539,apoorvmittal10,2024-10-25T11:20:03Z,wouldn't `fetchoffsetmetadataupdateresult` be a better name?,0,0.9903619289398193
1816509367,17539,apoorvmittal10,2024-10-25T11:24:10Z,do we need the variable name to have suffix `trycomplete`? i don't find the suffix is any helpful.,0,0.9845191240310669
1816510686,17539,apoorvmittal10,2024-10-25T11:25:23Z,"why to have method names with such suffix, are they helping? [code block]",0,0.9834778904914856
1816519200,17539,apoorvmittal10,2024-10-25T11:33:01Z,is it handled?,0,0.9948703050613403
1816530978,17539,apoorvmittal10,2024-10-25T11:43:00Z,"how frequent it is to see missing fetch offset information, mostly at start only right? they why to initialize this variable, can't it be lazily loaded, if required?",0,0.9873948097229004
1816619673,17539,apoorvmittal10,2024-10-25T12:46:27Z,so the update should be safe with multiple threads as we have acquired the lock on share partition which guards us from 2 threads trying to update the offset metadata. but we should write comments on the share partition update method that the caller of the method should ensure that share partition fetch lock is acquired prior invoking the updatelatestfetchoffsetmetadata.,0,0.9947835803031921
1816620754,17539,apoorvmittal10,2024-10-25T12:47:18Z,can it be in a separate method i.e. divide methods.,0,0.9932751655578613
1816621221,17539,apoorvmittal10,2024-10-25T12:47:39Z,merge the lines.,0,0.986968994140625
1816657075,17539,apoorvmittal10,2024-10-25T13:09:30Z,"so this iteration will always be executed for every share fetch when the `missingfetchoffsetmetadatatopicpartitions` will rarely be true, only when a new sharepartition is created. hence, i was thinking why not to have such update only on sharepartition initialization. though i understand that current `readfromlog` api requires fethchparams but is there an api which can supply the logoffsetmetadata when requested with topic partition and specific offset(start offset of share partition)? wdyt?",0,0.9908671379089355
1816661560,17539,apoorvmittal10,2024-10-25T13:12:17Z,can it go in a method please.,0,0.9924575090408325
1816667130,17539,apoorvmittal10,2024-10-25T13:16:10Z,why do we satisfy the min byte criteria if share partition is null?,0,0.988980770111084
1816668262,17539,apoorvmittal10,2024-10-25T13:17:03Z,"should the varibale in sharepartition be optional? we always should have that, correct?",0,0.9938951134681702
1816670642,17539,apoorvmittal10,2024-10-25T13:18:48Z,"sorry, i didn't understand when we can have the offset in share partition > partition end offset?",-1,0.9904829263687134
1816678081,17539,apoorvmittal10,2024-10-25T13:22:04Z,again this will be rare hence shall we delay initiliazing linkedhashmap.,0,0.9911209940910339
1816687484,17539,apoorvmittal10,2024-10-25T13:25:21Z,can it be non-null and empty ever i.e. do you require your second condition?,0,0.9938218593597412
1816691162,17539,apoorvmittal10,2024-10-25T13:27:47Z,"can it ever occur that you have non-empty `logreadresponsefromtrycomplete` but `topicpartitiondata` came from fresh aquisition from line 98 (topicpartitiondata = acquirablepartitions();). i think never, can you just write comments for this.",0,0.9911919236183167
1816693860,17539,apoorvmittal10,2024-10-25T13:29:27Z,please correct the alignment of comments.,0,0.9857699871063232
1816695469,17539,apoorvmittal10,2024-10-25T13:30:31Z,why it's optional?,0,0.9873073101043701
1816703702,17539,apoorvmittal10,2024-10-25T13:35:20Z,so if we are fetching from offset 0 and gets response from log for 0-1000 offsets then `logresult.info().fetchoffsetmetadata` contains information for 0 offset or 1000th offset i.e. which offset metadata does it hold?,0,0.99294513463974
1816704806,17539,apoorvmittal10,2024-10-25T13:36:05Z,class comments please.,0,0.9914698004722595
1816705073,17539,apoorvmittal10,2024-10-25T13:36:17Z,empty line break please.,0,0.966040313243866
1816711409,17539,apoorvmittal10,2024-10-25T13:40:35Z,that's my queustion with this comment [a link] do we ever get the lastfetchoffsetmetadata or we always update with fetchoffsetmetadata?,0,0.9950650334358215
1816800887,17539,adixitconfluent,2024-10-25T14:34:41Z,i can confirm this will return information about 0th offset.,0,0.9942049384117126
1816813489,17539,apoorvmittal10,2024-10-25T14:41:03Z,so this suggestion is not apt as we need the refreshed information [a link],0,0.9919252991676331
1816818571,17539,adixitconfluent,2024-10-25T14:44:21Z,"hi , i understand your point now. here's my proposed solution changes- 1. remove update of `latestfetchoffsetmetadata` via `acquire` method 2. in `oncomplete`, after i complete the call of `sharefetchutils.processfetchresponse`(which internally completes the call of `acquire` method), i will do a `readfromlog` for `topicpartitiondata` with their latest fetch offset and update the share partition's `latestfetchoffsetmetadata`. note this call to `readfromlog` will always happen despite the `trycomplete` `readfromlog` happens or not. please let me know what you think of this approach.",0,0.5888268947601318
1816827231,17539,adixitconfluent,2024-10-25T14:49:08Z,"hi , understood, so if there is any calls to acknowledge/acquisition lock timeout/release acquired records on session close, i should update the latestfetchoffsetmetadata to `optional.empty()`. then when the next trycomplete call comes, it will update the `latestfetchoffsetmetadata` and we will have the most recent result. or is my understanding incorrect?",0,0.9867761731147766
1816829826,17539,adixitconfluent,2024-10-25T14:50:57Z,"i did it because the value can be null, so we thought it would be better to keep it as optional [a link]",0,0.9936700463294983
1816830605,17539,adixitconfluent,2024-10-25T14:51:32Z,"you're right, i don't need it.",1,0.5241040587425232
1816832978,17539,adixitconfluent,2024-10-25T14:52:57Z,"not necessary, it can be null as well. hence, we use optional here.",0,0.9937912821769714
1816851362,17539,adixitconfluent,2024-10-25T15:02:51Z,"it might not be true ever in case we are using `fetchisolation.high_watermark`, but i think it can be true in case we use `fetchisolation.log_end` and `fetchisolation.txn_committed` which might be used in the future in share fetch requests.",0,0.9902148246765137
1817193502,17539,junrao,2024-10-25T18:39:55Z,"i was thinking about an alternative approach by maintaining `latestfetchoffsetmetadata` every time we update `endoffset`. in the common case, we move `endoffset` to `lastoffset` of an acked batch. the file position in `latestfetchoffsetmetadata` can just be updated by adding the batch size to the file position of the previous `latestfetchoffsetmetadata`. this way, in the common case, we only need to call `readfromlog` once per fetch request, instead of twice (once for getting `latestfetchoffsetmetadata` and another for getting the data) in the current approach.",0,0.9832300543785095
1817933790,17539,adixitconfluent,2024-10-26T21:36:55Z,"hi , i am not sure if i understand the approach completely. iiuc, 1. i agree with the common case where during `oncomplete` we can update the file position by directly adding the batch size. but, there are cases where we return true from `isminbytessatisfied` if `fetchoffsetmetadata` was on a different segment than the `endoffsetmetadata` ([a link]. in those case, we don't know the number of bytes that got accumulated in the response. same goes for the case `fetchoffsetmetadata.messageoffset > endoffsetmetadata.messageoffset`, how do we know whta is the number of bytes to add? 2. i am assuming that with this approach, we do not need to do any handling during acquisition lock timeout/acknowledgements/release acquired records on session close. please correct me if i am wrong. ps - thanks a lot for taking out the time to explain me and reviewing this pr.",0,0.8456688523292542
1817943465,17539,junrao,2024-10-26T22:31:36Z,": here is the rough idea. 1. if endoffset advances forward, we incrementally update its file position by the size of batches going forwarded. 2. the tricky thing is how the offset metadata picks up a new segment being rolled. as we increase the file position, endoffset will eventually reach the baseoffset of the next segment. this means that the next fetch request will be satisfied immediately since the hwm is on a different segment. when we acquire the data (for batches at the beginning of the segment), we can check if the offset metadata in the fetch data has the same offset as endoffset but on a different segment. if so, we update the offset segment of endoffset. 3. if the endoffset goes backward (due to timeout/acknowledgements/release) or endoffset is being initialized for the first time, we just call readfromlog to get the offset metadata. 4. `trycomplete` will have the same logic to deal with the uncommon cases where the offset metadata is not available or the offset metadata is on the same segment. the only difference is that it won't update latestfetchoffsetmetadata any more since the update happens when endoffset changes.",0,0.9370482563972473
1818144589,17539,junrao,2024-10-27T17:18:30Z,"while this alternative approach is more efficient, it's probably also more complicated. so, it's also ok to just take the current approach to start with. in the current approach, (1) if any call moves `endoffset`, we reset the `latestfetchoffsetmetadata` to optional.empty(). in `trycomplete`, if `latestfetchoffsetmetadata` is empty, we call `readfromlog` and update `latestfetchoffsetmetadata`.",0,0.9813348054885864
1818157944,17539,adixitconfluent,2024-10-27T18:40:29Z,"yes, it is handled here [a link]",0,0.9930807948112488
1818158187,17539,adixitconfluent,2024-10-27T18:41:37Z,the explanation is present in this conversation thread [a link],0,0.9956640601158142
1818159160,17539,adixitconfluent,2024-10-27T18:47:48Z,"hi , agreed with the simpler approach. i have made the following changes in my latest commit- i reset the `latestfetchoffsetmetadata` to optional.empty() if - 1. `acquire()` results in non-empty acquired records in `sharefetchutils`. 2. acquisition lock timeout is called. 3. release acquired records on session close is called. i haven't made the change in `acknowledge()` method of `sharepartition`, since in the common case all the `acquired` records will moved to `acknowledged` state and endoffset doesn't change then. this functionality has been added in previous commits. please review my pr whenever you can. thanks!",0,0.8936983942985535
1819587266,17539,junrao,2024-10-28T18:52:02Z,could we make fetchoffsetmetadata optional instead of relying on `null`?,0,0.993901252746582
1819590569,17539,junrao,2024-10-28T18:54:40Z,this is getting a bit hard to track since we need to make this call in all places where endoffset changes. could we have a method for updating both `endoffset` and `latestfetchoffsetmetadata`? then we can replace all code that changes `endoffset` with this method.,0,0.7975542545318604
1819592494,17539,junrao,2024-10-28T18:55:41Z,latestfetchoffsetmetadata => fetchoffsetmetadata?,0,0.9931575655937195
1819610603,17539,junrao,2024-10-28T19:10:15Z,it's probably clearer to put those in an `else` clause?,0,0.9902235865592957
1819618734,17539,junrao,2024-10-28T19:16:42Z,we could just initialize `missingfetchoffsetmetadatatopicpartitions` with `new linkedhashmap<>()`. ditto in `combinelogreadresponse`.,0,0.9937763214111328
1819637938,17539,junrao,2024-10-28T19:27:56Z,"hmm, it would be better for `logreadresponse` to only be empty, but never `null`.",0,0.9698213934898376
1819645608,17539,junrao,2024-10-28T19:34:59Z,do we need this wrapper class `fetchpartitionoffsetdata`? it seems that it's simpler for `readfromlog` to `return map `. we can then convert `logreadresult` to `map ` in `oncomplete`.,0,0.9943134784698486
1819664109,17539,junrao,2024-10-28T19:48:44Z,"every passed in partition to `readfromlog` will be included in the response. so, there is no need to pass in both `missingfetchoffsetmetadatatopicpartitions` and `replicamanagerreadresponsedata`. we do want to check the error code for each partition. in regular fetch, if any partition has an error code, we send a response immediately. we can just do the same here.",0,0.9915388226509094
1819665350,17539,junrao,2024-10-28T19:49:52Z,i thought we agreed that we want to send a response immediately if a sharepartition can't be found. is that handled?,0,0.9931043982505798
1819666995,17539,junrao,2024-10-28T19:51:27Z,could we just make a single `sharepartitionmanager.sharepartition` call per `trycomplete` to avoid having to check null repeatedly?,0,0.9930649399757385
1819670828,17539,junrao,2024-10-28T19:54:58Z,"ideally, we need to handle the exception at the partition level in the caller.",0,0.9895528554916382
1819677154,17539,junrao,2024-10-28T20:01:02Z,"this condition seems unnecessary. we need to set `logreadresponse` as long as `fetchoffsetmetadataupdateresult.replicamanagerreadresponse` is not empty, right?",0,0.9904834032058716
1824747173,17539,adixitconfluent,2024-10-31T16:04:06Z,"hi , i had updated it at a different place but now i've added that as the first step in trycomplete ([a link]. as you had also mentioned, this prevents us from making multiple share partition null checks at different places in the code.",0,0.9911810159683228
1824903292,17539,junrao,2024-10-31T17:42:42Z,"we are still calling `sharepartitionmanager.sharepartition` in multiple places (`anysharepartitionnolongerexists`, `acquirablepartitions`, `isminbytessatisfied` and `maybeupdatefetchoffsetmetadatafortopicpartitions`), each of which needs to handle null sharepartition since the sharepartition could disappear any time. i was thinking that we could get all sharepartitions once at the beginning and pass them around to other methods. this way, the null handling is only done once.",0,0.9888471364974976
1824914771,17539,junrao,2024-10-31T17:52:44Z,maybeupdatefetchoffsetmetadatafortopicpartitions => maybereadfromlogandupdatefetchoffsetmetadata ?,0,0.99420565366745
1824931761,17539,junrao,2024-10-31T17:59:44Z,"could we just return an empty map? this way, the caller doesn't need to do the null check.",0,0.9888206124305725
1824937560,17539,junrao,2024-10-31T18:01:45Z,topicpartitiondatafromtrycomplete => partitionstocomplete ? logreadresponse => partitionsalreadyfetched ?,0,0.9921006560325623
1824959019,17539,junrao,2024-10-31T18:09:14Z,this code can be a bit more concise. [code block],0,0.9925743341445923
1826092331,17539,adixitconfluent,2024-11-01T17:19:18Z,"hi , i have changed the exception handling to a top level exception handling in `trycomplete` to combat with this scenario.",0,0.9875063896179199
1826157479,17539,junrao,2024-11-01T18:24:00Z,there is no need to pass in `fetchoffsetmetadata` since it's always empty. updateendoffsetandfetchoffsetmetadata => updateendoffsetandresetfetchoffsetmetadata?,0,0.9951208233833313
1826160028,17539,junrao,2024-11-01T18:26:20Z,let's be consistent with the usage of `this`. most other places don't use `this`.,0,0.9884054660797119
1826160780,17539,junrao,2024-11-01T18:27:06Z,all callers hold the lock. so we could remove the locking here and add a comment that the caller is expected to hold the lock when calling this method.,0,0.9945620894432068
1826166921,17539,junrao,2024-11-01T18:33:29Z,this problem is still there?,0,0.9783944487571716
1826169337,17539,junrao,2024-11-01T18:35:52Z,this check is unnecessary since partitionsalreadyfetched initializes to empty.,0,0.9943233728408813
1826174394,17539,junrao,2024-11-01T18:41:05Z,should we reset `partitionstocomplete` and `partitionsalreadyfetched` too when we release the locks?,0,0.9942857623100281
1826180030,17539,junrao,2024-11-01T18:47:20Z,should we just assign the return value to partitionstocomplete directly? we already acquired the locks for those partitions and partitionstocomplete is the only place to track them for releasing.,0,0.9902467727661133
1826183958,17539,junrao,2024-11-01T18:51:35Z,this code can be a bit simpler. [code block],0,0.9926798343658447
1826185041,17539,junrao,2024-11-01T18:52:48Z,updatefetchoffsetmetadataformissingtopicpartitions => updatefetchoffsetmetadata ?,0,0.9937794804573059
1826187006,17539,junrao,2024-11-01T18:54:51Z,perhaps do this in the caller? then the purpose of the method is simpler and the method name can just be `maybereadfromlog`.,0,0.9920582175254822
1826561286,17539,adixitconfluent,2024-11-02T12:32:50Z,"hi , we can do that but then once we are in the `else` of this check -` if (anytopicidpartitionhaslogreaderror(replicamanagerreadresponse) || isminbytessatisfied(topicpartitiondata))`, after we have release the partitions lock, we also need to do `partitionstocomplete.clear()`. hence, i've tried to avoid doing this by assigning `partitionstocomplete` once we are sure that we can do a `forcecomplete()`",0,0.9894523620605469
1826562798,17539,adixitconfluent,2024-11-02T12:43:59Z,"hi , i am not actually too sure if i definitely need this check. ideally, i don't think there can be any value in `sharepartitions` which can be null, but this [a link] in `sharepartitionmanager` is confusing me, plus there is this jira [a link] where we will be refactoring share partition initialization. so, this can act as a safety check for now, and i can remove this in a future pr once the refactor is complete, and we are sure we don't send null share partitions. what do you think? cc -",0,0.8378087878227234
1828181101,17539,junrao,2024-11-04T18:14:18Z,sharefetchdata => partitionstocomplete ? partitionstocomplete => partitionsacquired ?,0,0.99006187915802
1828190239,17539,junrao,2024-11-04T18:22:08Z,it's kind of weird for this method to return the input. it's more natural for this method to return nothing.,-1,0.9893130660057068
1828196542,17539,junrao,2024-11-04T18:26:13Z,"hmm, when we hit an exception, do we guarantee that `partitionstocomplete` has been set?",0,0.9858289957046509
1828254033,17539,junrao,2024-11-04T19:14:00Z,"we need to return an optional `fetchoffsetmetadata` if the value returned from `nextfetchoffset` changes. if `findnextfetchoffset` is false, `nextfetchoffset` returns a value based on endoffset. this case is already covered in this pr. if `findnextfetchoffset` is true, `nextfetchoffset` returns a value not depending on endoffset. so, we should return empty here if `findnextfetchoffset` is true.",0,0.99335116147995
1828280371,17539,junrao,2024-11-04T19:36:40Z,"it seems that sharepartitions is always a subset of sharefetchdata.partitionmaxbytes()? if that's the case, i agree that we don't need anysharepartitionnolongerexists. however, it would be useful to make sure that the caller passes in sharepartitions and sharefetchdata.partitionmaxbytes() with the same set of partition keys.",0,0.9893736243247986
1828303188,17539,junrao,2024-11-04T19:55:05Z,this comment doesn't match the code.,0,0.8701564073562622
1828307832,17539,junrao,2024-11-04T19:59:05Z,quite a long name. how about sth like testtrycompletereturnsfalsewhenminbytesnotsatisfied?,0,0.8461741805076599
1828314722,17539,junrao,2024-11-04T20:04:40Z,"hmm, not sure how this test is different from the next one. if this is testing fetching for the first time, sp0.fetchoffsetmetadata() should return empty, right?",0,0.8189219236373901
1828321808,17539,junrao,2024-11-04T20:10:46Z,"could we change `combinelogreadresponse` to also take `partitionsalreadyfetched`? this way, we can get rid of `delayedsharefetch.updatelogreadresponse`.",0,0.9931501746177673
1828532884,17539,apoorvmittal10,2024-11-04T23:28:40Z,we initialize the variable in constructor then re-assign while creating another linkedhashmap in acquirablepartitions() method. are we are initializing `partitionstocomplete` here to save null check? can't we re-use already initialized linkedhashmap()?,0,0.9946973323822021
1828533813,17539,apoorvmittal10,2024-11-04T23:30:01Z,again we reset `partitionsalreadyfetched` to response from `replicamanagerreadresponse`. why to have such instances created when anyways we have to re-assign?,0,0.9830833673477173
1828538998,17539,apoorvmittal10,2024-11-04T23:37:46Z,"we have now passed `sharepartitions` map which contains topicidpartition and sharepartition itself then why are we iterating on `sharefetchdata.partitionmaxbytes().keyset()` and doing a null check, why not to iterate in `sharepartitions` map itself? also make the map of `sharepartitions` in spm as of type linkedhashmap then.",0,0.9930611252784729
1828539471,17539,apoorvmittal10,2024-11-04T23:38:32Z,same elsewhere.,0,0.9923704862594604
1828542474,17539,apoorvmittal10,2024-11-04T23:43:20Z,"shouldn't we iterate on `sharepartitions` map passed in delayed share fetch which will guarantee that sharepartition cannot be null it can only be fenced (fenced handling has been separate), hence no null check is required. also no `anysharepartitionnolongerexists()` method call is required.",0,0.9950882792472839
1828547060,17539,apoorvmittal10,2024-11-04T23:50:42Z,"nit: i personally find the code hard to read with nested if/else blocks, same is the case here. though i leave it on you. ``` if (topicpartitiondata.isempty()) { log.trace(""can't acquire records for any partition in the share fetch request for group {}, member {}, "" + ""topic partitions {}"", sharefetchdata.groupid(), sharefetchdata.memberid(), sharefetchdata.partitionmaxbytes().keyset()); return false; } // in case, fetch offset metadata doesn't exist for one or more topic partitions, we do a // replicamanager.readfromlog to populate the offset metadata and update the fetch offset metadata for // those topic partitions. map replicamanagerreadresponse = updatefetchoffsetmetadata(maybereadfromlog(topicpartitiondata)); if (!anytopicidpartitionhaslogreaderror(replicamanagerreadresponse) && !isminbytessatisfied(topicpartitiondata)) { log.debug(""minbytes is not satisfied for the share fetch request for group {}, member {}, "" + ""topic partitions {}"", sharefetchdata.groupid(), sharefetchdata.memberid(), sharefetchdata.partitionmaxbytes().keyset()); releasepartitionlocks(topicpartitiondata.keyset()); return false; } partitionstocomplete = topicpartitiondata; partitionsalreadyfetched = replicamanagerreadresponse; .... ....",0,0.8371128439903259
1828550191,17539,apoorvmittal10,2024-11-04T23:56:01Z,there are 2 checks in the if condition (anytopicidpartitionhaslogreaderror and isminbytessatisfied) but the log says that minbytes criteria is not satified. i this correct log statement?,0,0.9947079420089722
1828552140,17539,apoorvmittal10,2024-11-04T23:59:15Z,we are re-assigning the already initalized variables in constructor. i would say we should have null check handling in `oncomplete` rather creating resources which never gets utilized.,0,0.9920459985733032
1828561128,17539,apoorvmittal10,2024-11-05T00:14:37Z,so did we not chose to implement [a link] rather initialize with linkedhashmap which will hardly be filled?,0,0.9941406846046448
1828563750,17539,apoorvmittal10,2024-11-05T00:18:54Z,shouldn't the name be `maybeupdatefetchoffsetmetadata` as it depends on the log read result?,0,0.9946780204772949
1828564729,17539,apoorvmittal10,2024-11-05T00:20:32Z,nit: will `foreach` be more convenient here then you don't need to call entry.getkey and entry.getvalue?,0,0.9891452789306641
1828566030,17539,apoorvmittal10,2024-11-05T00:23:01Z,isn't the log incorrect as it says the the log does not contain topicidpartition rather the response exists but it errored. also do you need to log `replicamanagerlogreadresult` or complete `replicamanagerreadresponsedata`? shouldn't we be logging former which corresponds to topic id partition?,0,0.992420494556427
1828571399,17539,apoorvmittal10,2024-11-05T00:31:55Z,seems an incorrect error handling of release acquired partitions to me. say line 155 acquires partitions and `topicpartitiondata` is set. and we get an exception in `isminbytessatisfied` method (which anyways call getpartitionorexception method) or elsewhere then the locks released at line 193 will not release any locks as they are invoked on `partitionstocomplete` which is not yet set. moreover if forcecomplete call is successful then the acquired partitions will anyways not be released.,0,0.9825846552848816
1828573589,17539,apoorvmittal10,2024-11-05T00:35:25Z,what meant was that it should not be a top level rather partition level error.,0,0.987122118473053
1828579315,17539,apoorvmittal10,2024-11-05T00:45:30Z,i understand there can't be concurrent calls to trycomplete but i didn't get this comment. though forcecomplete() cannot be called twice. but forcecomplete() on expiration can be on different thread and trycomplete() on different (that's my understanding as per delayedoperation code i have seen) can this change any behaviour here?,0,0.9921008944511414
1828580776,17539,apoorvmittal10,2024-11-05T00:47:59Z,"can be merged together. ``` sharefetchdata.future().complete(sharefetchutils.processfetchresponse(sharefetchdata, fetchpartitionsdata, sharepartitionmanager, replicamanager));",0,0.9926332831382751
1828758874,17539,adixitconfluent,2024-11-05T05:45:48Z,"my bad, i've corrected it.",-1,0.9945971965789795
1828775451,17539,adixitconfluent,2024-11-05T06:04:52Z,"my bad, you're right, i've adjusted the mock to return `optional.empty()` for the first time and `optional.of(new logoffsetmetadata(0, 1, 0))` for the second time (post `readfromlog` call)",-1,0.9867269396781921
1828820632,17539,adixitconfluent,2024-11-05T06:55:13Z,"hi , you're right, i've changed the line to `releasepartitionlocks(topicpartitiondata.keyset())`",0,0.9614608287811279
1828824435,17539,adixitconfluent,2024-11-05T06:59:40Z,"yes, there have been comments above where i left some variables as null, and it was pointed out that i need to initialize them to avoid null checks at different places, then we just need to do empty checks.. hence, i've implemented it in this manner.",0,0.9893057942390442
1828825732,17539,adixitconfluent,2024-11-05T07:01:05Z,"same reason as above, we are avoiding any null checks. we just check for empty scenarios by doing this.",0,0.9907733201980591
1828831006,17539,adixitconfluent,2024-11-05T07:06:21Z,"i have been asked to add else blocks in the above comments on this pr, hence i don' think i should change it again. [a link]",0,0.9917255640029907
1828836294,17539,adixitconfluent,2024-11-05T07:12:01Z,"now, we reset fetchoffsetmetadata everytime the `endoffset` changes (see the usages of function `updateendoffsetandresetfetchoffsetmetadata` in `sharepartition`). so, it can be frequent now that the fetchoffsetmetadata is empty. [a link]",0,0.9950867295265198
1828845131,17539,adixitconfluent,2024-11-05T07:20:53Z,"since, i am using `continue` in the loop, i prefer to do it using for instead of foreach.",0,0.993026614189148
1828852012,17539,adixitconfluent,2024-11-05T07:27:04Z,"yes, the log statement is correct because because `isminbytessatisfied` can run only if `anytopicidpartitionhaslogreaderror` returns false. we should only check `isminbytessatisfied` if `anytopicidpartitionhaslogreaderror` returns false. if `anytopicidpartitionhaslogreaderror` return true, then we do a `forcecomplete`.",0,0.9891183376312256
1828853882,17539,adixitconfluent,2024-11-05T07:28:50Z,"my bad, you're right about both.",-1,0.9936444759368896
1828860825,17539,adixitconfluent,2024-11-05T07:35:27Z,"you're right, i've changed the line to `releasepartitionlocks(topicpartitiondata.keyset())`. if the `forcecomplete` is successful, then the partition locks are released from `oncomplete` finally block and it doesn't concern here.",0,0.9933537244796753
1828877645,17539,adixitconfluent,2024-11-05T07:50:46Z,"what i mean is that `partitionsalreadyfetched` value can't be changed once we enter this point in `oncomplete` via `forcecomplete` either by expiration or by a `trycomplete` successful call. iiuc, `forcecomplete` uses this `atomicboolean` variable `completed` which is used as locking mechanism for `forcecomplete`. this should ensure atomicity of global variables between `trycomplete` and `forcecomplete` we use in `delayedsharefetch`. i'll change the comment to explain this better.",0,0.9927807450294495
1828902626,17539,adixitconfluent,2024-11-05T08:10:20Z,"yes, i'll remove `anysharepartitionnolongerexists()` and also iterate on `sharepartitions` rather than using `sharefetchdata.partitionmaxbytes()`. will remove the null checks from our code.",0,0.9943867921829224
1829020183,17539,adixitconfluent,2024-11-05T09:31:37Z,"hey , we are doing partition level error handling in `oncomplete` using `sharepartitionmanager.handlefetchexception`. when we get an exception in this line `replicamanager.getpartitionorexception`, we directly call `forcecomplete` (mentioned in above comments), and that does a partition level handling.",0,0.9930025935173035
1829235324,17539,apoorvmittal10,2024-11-05T12:03:46Z,"if the concern is with additional null check then i would recommend general helper methods. my concern is with creating additional maps when they are always re-referenced. ``` private void addtonullablemap(map map, k key, v value) { if (map == null) { map = new linkedhashmap<>(); } map.put(key, value); } private boolean ismapempty(map map) { return map == null || map.isempty(); }",0,0.9907855987548828
1829237621,17539,apoorvmittal10,2024-11-05T12:05:33Z,i leave it on to decide then.,0,0.9849202632904053
1829240438,17539,apoorvmittal10,2024-11-05T12:07:57Z,"it's missing yet, you can log a jira for me to fix as i am doing handling anyways.",0,0.9923266172409058
1829256794,17539,adixitconfluent,2024-11-05T12:19:58Z,logged a jira [a link] for the same.,0,0.9948680400848389
1830198129,17539,junrao,2024-11-05T23:15:54Z,why is this a linkedhashmap instead of just a hashmap?,0,0.9906820058822632
1830199934,17539,junrao,2024-11-05T23:18:33Z,"this is actually a super set of the partitions to complete. so, it's better to just keep the name sharefetchdata. it would be useful to add a comment that the partitions to be completed are given by sharepartitions and is a subset of sharefetchdata.",0,0.9943904280662537
1830201006,17539,junrao,2024-11-05T23:20:05Z,why is this a linkedhashmap instead of just a hashmap?,0,0.9906820058822632
1830203044,17539,junrao,2024-11-05T23:23:08Z,missingfetchoffsetmetadatatopicpartitions => partitionsmissingfetchoffsetmetadata?,0,0.9917993545532227
1830208462,17539,junrao,2024-11-05T23:31:16Z,this can be a bit simpler. [code block],0,0.9927478432655334
1830209083,17539,junrao,2024-11-05T23:32:13Z,anytopicidpartitionhaslogreaderror => anypartitionhaslogreaderror ?,0,0.9910017848014832
1830230584,17539,junrao,2024-11-06T00:06:59Z,"this part of the exception is still quite confusing to me. if we hit the exception, should we release the locks before calling forcecomplete()? otherwise, `forcecomplete` will try to acquire the same locks again, but can't. it will also help to narrow the try/catch to where the exception can be thrown.",-1,0.6658559441566467
1830231877,17539,junrao,2024-11-06T00:09:06Z,"we can skip clearing these two maps here since the operation is completed at this point. in `oncomplete()`, we don't clear these two maps. so, this will make the behavior more consistent.",0,0.993827760219574
1830238005,17539,junrao,2024-11-06T00:19:06Z,"this is an existing issue. in the line below, we are logging for each partition, but sharefetchdata contains the full request. [code block]",0,0.9944041967391968
1830242539,17539,junrao,2024-11-06T00:26:42Z,testtrycompletereturnsfalsewhenminbytesnotsatisfiedonfirstfetch => testtrycompletewhenminbytesnotsatisfiedonfirstfetch?,0,0.993777871131897
1830242838,17539,junrao,2024-11-06T00:27:17Z,testtrycompletereturnsfalsewhenminbytesnotsatisfiedonlatestfetch => testtrycompletewhenminbytesnotsatisfiedonsubsequentfetch ?,0,0.9929017424583435
1830269891,17539,junrao,2024-11-06T01:14:59Z,"hmm, apoorv had a good point in his comment ([a link] there seems to be a potential problem. it's possible that thread1 calls `trycomplete`, finds `completed` to be false, and is about to set `partitionsalreadyfetched`. the expiration thread then calls `forcecomplete` and sets `completed` to true and proceeds to here. now, thread1 continues and updates `partitionsalreadyfetched`. the expiration thread will pick up the wrong `partitionsalreadyfetched`.",0,0.5198983550071716
1830395752,17539,adixitconfluent,2024-11-06T05:07:55Z,"yes, i think changing the log line to below makes more sense. [code block]",0,0.9881640672683716
1830410313,17539,adixitconfluent,2024-11-06T05:31:34Z,"makes sense, i've changed the catch block to [code block]",0,0.9907406568527222
1830454251,17539,adixitconfluent,2024-11-06T06:27:58Z,"hi jun, reading online regarding the performance of linkedhashmap and hashmap - linkedhashmap offers better performance when iterating through elements since they maintain an ordered entry list, while a hashmap offers better performance when accessing large datasets. furthermore, when storing objects, linkedhashmap stores objects in key-value pairs, while hashmap stores them in hash table. the type of key used also affects performance. since now we are iterating over `sharepartitions` within the function `acquirablepartitions`, i thought it would be more efficient to use linkedhashmap over hashmap.",0,0.8890511393547058
1830461947,17539,adixitconfluent,2024-11-06T06:36:58Z,"hi , i've created a ticket [a link] to track this issue and if it fine to you, i would prefer to address the issue in a future pr.",0,0.9356997609138489
1830468964,17539,adixitconfluent,2024-11-06T06:44:58Z,"similar reason as [a link], i did it for performance efficiency. we are iterating over `partitionsacquired` in `releasepartitionlocks`, hence i thought it would be more efficient to use linkedhashmap over hashmap.",0,0.9866732358932495
1831062681,17539,apoorvmittal10,2024-11-06T13:56:10Z,the reason i suggested to use linkedhashmap was to maintain the fetch order of partitions. as per kip - [a link] i will add the rotation in sharepartitionmanager to ensure the behaviour.,0,0.9948510527610779
1831731314,17539,junrao,2024-11-06T21:26:53Z,"if ordering is important, should we explicitly define it as linkedhashmap in all the places?",0,0.9927655458450317
1831742440,17539,junrao,2024-11-06T21:37:58Z,should we reset partitionsacquired and partitionsalreadyfetched?,0,0.9937849044799805
1831747806,17539,junrao,2024-11-06T21:43:40Z,let's add a comment that the minbytes estimation currently assumes the common case where all fetched data are acquirable.,0,0.9950894713401794
1831878254,17539,apoorvmittal10,2024-11-07T00:08:42Z,"yeah, good point. we should.",1,0.9571503400802612
1832911918,17539,junrao,2024-11-07T15:47:22Z,"since the ordering is important, let's use linkedhashmap.",0,0.9936836957931519
1832912856,17539,junrao,2024-11-07T15:47:55Z,"since the ordering is important, let's use linkedhashmap.",0,0.9936836957931519
1832915380,17539,junrao,2024-11-07T15:49:24Z,"since the ordering is important, let's use linkedhashmap.",0,0.9936836957931519
1832921605,17539,junrao,2024-11-07T15:52:49Z,this means `trycomplete` will never get non-empty `fetchoffsetmetadata` and its calculation of minbytes will be off. we need to think through how to address this.,0,0.9912787079811096
111506681,2849,mjsax,2017-04-13T23:26:33Z,why not using validatetransactionalid here ?,0,0.9893575310707092
111517794,2849,junrao,2017-04-14T01:40:50Z,"every time the epoch advances, it seems that we need to write the transactionalid mapping message to the transactional log and we want to write that in epoch order since the transactional log is a compacted topic.",0,0.9908373355865479
111517806,2849,junrao,2017-04-14T01:41:01Z,"in the design, the epoch will wrap around.",0,0.9859479665756226
111517818,2849,junrao,2017-04-14T01:41:12Z,could we rename the method to sth like gettransactionstate?,0,0.9941359758377075
111517825,2849,junrao,2017-04-14T01:41:19Z,"hmm, we need to add the transactionalid -> pid mapping to the transactional log, right?",0,0.9809139370918274
111517832,2849,junrao,2017-04-14T01:41:26Z,a few unused imports such as kafkaexception and random.,0,0.9789891839027405
111517837,2849,junrao,2017-04-14T01:41:32Z,$error => errors: $error ditto for line in 1412.,0,0.9723283052444458
111528069,2849,junrao,2017-04-14T04:32:31Z,"hmm, how is transactionmetadata.timestamp used? if it's intended to expire a transaction, should we keep the time when the first partition is added? we probably also want to rename the field to sth like txnstarttime to make it clear.",0,0.9870343804359436
111528074,2849,junrao,2017-04-14T04:32:39Z,"hmm, is it intentional to use acks =1 instead of acks=-1? if so, could we add a comment how the potential data loss is dealt with?",0,0.9875682592391968
111528088,2849,junrao,2017-04-14T04:33:00Z,"hmm, in the design doc, the key for transactional status message is the following. is the doc outdated? is it true that we are combining the transactional status message and the transactionalid mapping message into a single one? key => version type pid version => 0 (int16) type => 1 (int16) pid => int64",0,0.9824349284172058
111528094,2849,junrao,2017-04-14T04:33:07Z,"in the design doc, the value for transactional status message is the following. is the doc outdated? value => version epoch status [topic [partition]] version => 0 (int16) epoch => int16 status => byte topic => bytes partition => int32",0,0.9953266382217407
111528102,2849,junrao,2017-04-14T04:33:14Z,"the comment in line 38 doesn't include txn_timestamp_field. also, could we add a doc for each field?",0,0.9947577118873596
111528120,2849,junrao,2017-04-14T04:33:41Z,"hmm, what's the default txntimeout in the producer? the server side default is 15 minutes, definitely too long for a timeout for the callback during log append.",0,0.9412161707878113
111653276,2849,junrao,2017-04-15T00:34:08Z,do we still need this object?,0,0.994005024433136
111653293,2849,junrao,2017-04-15T00:34:35Z,"hmm, it seems that if the connection is not ready, we should just wait until it's ready or until the request timeout has been reached, instead of sending an error back immediately.",0,0.9673981070518494
111653317,2849,junrao,2017-04-15T00:35:10Z,"hmm, i am wondering if checks like this are synchronized properly. for example, the following sequence seems possible. (1) handleaddpartitionstotransaction() is called and validatetransactionalid() check passes. (2) leader of the partition changes to a different broker and changes back. (3) now txnmanager.appendtransactiontolog() may succeed but transactionstatemanager may still be loading the transaction state.",0,0.947729229927063
111653333,2849,junrao,2017-04-15T00:35:27Z,"hmm, is it possible for txnmanager.gettransaction() to return none because leader change in the transaction topic?",0,0.9785995483398438
111653336,2849,junrao,2017-04-15T00:35:33Z,"map { case (topic, partitionids) .. } ?",0,0.9930809140205383
111653338,2849,junrao,2017-04-15T00:35:37Z,"""pid mapping message"" seems no longer valid",0,0.9890328645706177
111653340,2849,junrao,2017-04-15T00:35:40Z,pidmessageformatter => transactionlogformatter ?,0,0.9922634363174438
111653344,2849,junrao,2017-04-15T00:35:45Z,key => transactionalid ?,0,0.9935870170593262
111653357,2849,junrao,2017-04-15T00:35:56Z,"currently, there are a couple of cases when the following illegalstateexception is thrown. (1) a producer times out on a commit/abort request and resends the request on a different socket channel. (2) a different producer has initialized the pid on the same transactional id. it seems that in both cases, perhaps we want to send back a retriable error (e.g., coordinatorbusy) to that the client so that it can retry until successful?",0,0.9900655746459961
111653362,2849,junrao,2017-04-15T00:36:02Z,this is not the replica fetcher.,0,0.981086790561676
111653364,2849,junrao,2017-04-15T00:36:06Z,do we need this tag since we know this thread is from this broker.,0,0.9914261102676392
111653370,2849,junrao,2017-04-15T00:36:17Z,"since both the request and the response will be small, perhaps we could just use the default receive buffer.",0,0.9868518710136414
111653378,2849,junrao,2017-04-15T00:36:30Z,"not sure if this is needed, but should we ensure that we send writetxnmarkersrequest with a lower coordinatorepoch before a higher one?",0,0.967037558555603
111653405,2849,junrao,2017-04-15T00:36:48Z,"(1) the reason for the disconnect could be that the current leader is down and a new leader is elected. so, we should go through the path dealing with errors.not_leader_for_partition to rediscover a potential new broker to send the request to. (2) not sure if this truly needed, but do we need to ensure that the ordering of controller epoch is preserved during re-enqueue?",0,0.9824001789093018
111653412,2849,junrao,2017-04-15T00:36:58Z,"since there are different types of epochs now, could we name this coordinatorepoch to make it clear?",0,0.9932740926742554
111653448,2849,junrao,2017-04-15T00:37:22Z,partitionlock gives people the impression that this is a lock for a transaction topic partition. perhaps rename this to sth like statelock?,0,0.9910314083099365
111653453,2849,junrao,2017-04-15T00:37:30Z,there doesn't seem be a corrupted list?,0,0.98260098695755
111653475,2849,junrao,2017-04-15T00:37:53Z,"hmm, shouldn't we load up to log end offset instead of hw? the latter can be slightly smaller than log end offset and in that case, we may miss the portion of the log between log end offset and hw.",0,0.9852045774459839
111653484,2849,junrao,2017-04-15T00:38:10Z,"hmm, ownedpartitions is updated in the scheduler, which means when this method returns, there is no guarantee that ownedpartitions has been updated. then, a client could still update the transaction log even after handletxnemigration() is called? ditto in loadtransactionsforpartition(0.",0,0.9874200224876404
111653491,2849,junrao,2017-04-15T00:38:17Z,"hmm, invalid_fetch_size seems to be for fetch requests, will log append throw this?",0,0.9825780987739563
111653493,2849,junrao,2017-04-15T00:38:25Z,"not clear what "" since the metadata does not match anymore"" is.",0,0.85939621925354
111653508,2849,junrao,2017-04-15T00:38:56Z,"we synchronize on metadata in different classes like transactioncoordinator, transactionmarkerchannelmanager, transactionstatemanager and delayedtxnmarker. this makes a bit hard to reason about concurrency. would it be better to consolidate all concurrent accesses to transactionstatemanager or a new class and only do synchronization on methods inside that class?",0,0.8356788754463196
111653523,2849,junrao,2017-04-15T00:39:23Z,we need to add the acl check for each of the new request. this can be done in a separate pr if needed.,0,0.9957287907600403
111653527,2849,junrao,2017-04-15T00:39:32Z,we need to set transactionstopicreplicationfactor and transactionstopicminisr to 1 in config/server.properties so that local testing could work.,0,0.9953059554100037
111781296,2849,junrao,2017-04-17T17:40:42Z,"hmm, if polltimeout is maxlong, networkclient.poll() could be blocked for a long time waiting for the response to come back. this means if there are new requests for other brokers coming in, their processing will be delayed.",0,0.9836419820785522
111781327,2849,junrao,2017-04-17T17:40:51Z,"hmm, in general, it's useful not to reconnect on a failed connection, is setting reconnectbackoff to 0 intentional?",0,0.9810038208961487
111781351,2849,junrao,2017-04-17T17:40:59Z,"should we use metadatatowrite instead of metadata? also, could we just fold maybeaddpendingrequest() into addrequesttosend()?",0,0.9946722388267517
111781396,2849,junrao,2017-04-17T17:41:13Z,perhaps it's better to make transactionmetadata.topicpartitions a private val and expose methods for manipulation so that it's easier to track when the state is changed?,0,0.9889495372772217
111829832,2849,junrao,2017-04-17T21:49:29Z,"hmm, shouldn't we be using the transaction timeout in the producer config instead of integer.max_value?",0,0.973458468914032
111829857,2849,junrao,2017-04-17T21:49:40Z,"this may throw brokerendpointnotavailableexception and we probably need to handle this explicitly. otherwise, some request handler threads will fail unexpectedly.",0,0.9803311228752136
111829897,2849,junrao,2017-04-17T21:49:52Z,"we have to be a bit careful here. it's possible when a broker is restarted, it's ip and port have changed. so, we need to update the ip/port in brokerstatemap if needed.",0,0.9711965322494507
111830152,2849,junrao,2017-04-17T21:51:22Z,it seems that we need to call this during transactioncoordinator.handletxnemigration() as well?,0,0.9934212565422058
111830246,2849,junrao,2017-04-17T21:51:57Z,"here, we are draining the requests to every broker whether the broker channel is ready or not. it's probably better to only take requests from brokers whose connection is ready.",0,0.9730963110923767
111830264,2849,junrao,2017-04-17T21:52:04Z,max.transaction.timeout.ms => transaction.max.timeout.ms,0,0.9903512597084045
111932482,2849,dguy,2017-04-18T11:43:14Z,because this case is handled differently,0,0.9853512048721313
111933023,2849,dguy,2017-04-18T11:46:43Z,it will be used to expire the transactions from the `transactionmetadatacache` in `transactionmanager`. it was my understanding that the timestamp should be updated to the the current timestamp (at least is supposed to be in the endtxnrequest case),0,0.9944748282432556
111933363,2849,dguy,2017-04-18T11:48:48Z,according to point 2 [a link],0,0.994371771812439
111933574,2849,dguy,2017-04-18T11:50:12Z,yes - this was initially missing in the `initpidrequest` i've updated it so it does add it to the log,0,0.9932181239128113
111934136,2849,dguy,2017-04-18T11:53:42Z,?,0,0.9296892285346985
111966880,2849,dguy,2017-04-18T14:23:40Z,not sure i completely agree. it says in the javadoc for `requestcompletionhandler`: [code block],0,0.7656747102737427
111967313,2849,dguy,2017-04-18T14:25:15Z,"yep, i'm not sure what the thinking is/was behind that. ?",0,0.6668564677238464
111972450,2849,dguy,2017-04-18T14:43:30Z,"so, i think you are saying we need to always call `metadatacache.getaliveendpoint(...)` even if we have a node for the given brokerid already in `brokerstatemap`?",0,0.9917268753051758
111978219,2849,dguy,2017-04-18T15:03:43Z,i am not sure it is a retriable error in this case. once the previous `endtxnrequest` has completed then a subsequent `endtxnrequest` for the same transactionalid should also fail - right?,0,0.9494330286979675
111997154,2849,dguy,2017-04-18T16:13:24Z,"hmmm. interesting! i don't think we want to clear everything, but just those transactionalids where the partition has emigrated? though, that is not immediately clear to me based on the current design. also there may well be in-flight-requests corresponding to the emigrated partitions. not sure which error response should be sent back for those.",0,0.5076013207435608
111997381,2849,dguy,2017-04-18T16:14:27Z,not sure - ?,0,0.8677465915679932
112013590,2849,junrao,2017-04-18T17:23:17Z,"that sounds good. however, it seems that transactionmetadata needs 2 different timestamps. (1) the last timestamp when there is some activity from the pid. (2) the timestamp when the last open transaction is started. (1) will be used to expire pid and (2) will be used to abort a long transaction.",0,0.9109336733818054
112013865,2849,junrao,2017-04-18T17:24:25Z,"ok, could we add a comment. sth like ""it's possible for a complete message to be lost with acks=1 when the leader for the transaction coordinator changes. if so, we will re-add the complete message during handletxnimmigration()""",0,0.9946553707122803
112014229,2849,junrao,2017-04-18T17:25:53Z,"there are 2 cases when a channel is not ready: (1) the channel was ready and is disconnected now. (2) the channel is not ready and is being connected. in case (1), the callback will be called. in case (2), the current usage of networkclient is that the caller shouldn't send requests until the channel is ready. otherwise, we will be unnecessarily taking requests out of the queue, submitting it to networkclient and only to re-enqueue the failed requests.",0,0.9877591729164124
112014271,2849,junrao,2017-04-18T17:26:05Z,"yes, every time that we add a new request to a broker id, it's possible for the broker's ip/port to change. we need to update the cached ip/port in brokerstatemap.",0,0.9928268194198608
112014403,2849,junrao,2017-04-18T17:26:42Z,"yes, we should fail the subsequent endtxnrequest. but it seems that we want the client to backoff a bit and keep retrying until success. if we are not sending back a retriable error, the client will think the endtxnrequest actually permanently failed, which is not the case here.",0,0.989024817943573
112014452,2849,junrao,2017-04-18T17:26:54Z,"yes, only clearing transactionalids where the partition has emigrated. for in-flight-requests, we probably want to return a nottransactioncoordinator error.",0,0.9933024644851685
112138268,2849,dguy,2017-04-19T08:04:51Z,not sure - ?,0,0.8677465915679932
112138822,2849,dguy,2017-04-19T08:08:13Z,"so, i think in the second case we probably want to check if the broker is ready before it gets to this point. as we've already drained the queue and will need to re-enqueue?",0,0.9911502599716187
112142569,2849,ijuma,2017-04-19T08:27:58Z,"as long as the `networkclient` is instantiated with an appropriate request timeout, this code is fine. the actual timeout here will be `the minimum of timeout, request timeout and metadata timeout` (as specified in the docs for`networkclient.poll`)",0,0.9926129579544067
112143022,2849,ijuma,2017-04-19T08:30:17Z,"unless we want a timeout that's lower than `requesttimeout`, of course.",0,0.9821062088012695
112282085,2849,apurvam,2017-04-19T18:38:13Z,we synced up on this with jun offline. the doc is outdated. we havea ticket here to track updates we need to make to the doc: [a link],0,0.9936269521713257
112286609,2849,apurvam,2017-04-19T18:57:54Z,"i think would have the most context on that, but i don't think we should not set it to 0. this is the connection to the leaders to write the abort marker. if the connection is disconnected, there is little reason to try to establish it again. i think the default of 50ms is reasonable here.",0,0.982125997543335
112286690,2849,apurvam,2017-04-19T18:58:18Z,that makes sense to me.,0,0.9833141565322876
112286926,2849,apurvam,2017-04-19T18:59:24Z,"the comment is out of date. the original version of the patch had a notion of 'corrupted partitions', but the definition what is corrupted was not clear and we dropped the notion altogether.",0,0.9252457022666931
112287416,2849,apurvam,2017-04-19T19:01:30Z,the default on the producer as of now is 60 seconds. i think perhaps 120seconds on the broker is reasonable?,0,0.9918091893196106
112300739,2849,apurvam,2017-04-19T20:05:37Z,the config is being added as part of my patch. shall we introduce an overload of `initpidrequest.builder` which just takes a `transactionalid` and assigns some default timeout? my patch will use the two parameter builder and pass in the timeout from the producer config.,0,0.9952443242073059
112302162,2849,apurvam,2017-04-19T20:12:25Z,"we can avoid this by using the `networkclientutils.awaitready` method, as used in [a link] that will ensure that the destination node is ready before sending the initial request. so you could peek into the queue to get the destination, ensure that it is ready, and if so, send the request. however, if it is not ready after a particular time, you will have to rediscover the correct node to send the request to (presumably because the old broker is down and the leader has moved).",0,0.9921804666519165
112306365,2849,apurvam,2017-04-19T20:31:43Z,"yes, we have to do this across the board. i filed a jira so that we can make the change in one pr so that it is easier to make sure we are consistent. [a link]",0,0.9939391613006592
112311456,2849,junrao,2017-04-19T20:55:25Z,"the broker has a request timeout, but it's probably better for the client could pass along the timeout in the rpc request?",0,0.9918596148490906
112311549,2849,junrao,2017-04-19T20:55:48Z,"ideally, we only want to take requests off a queue when the channel to the corresponding broker is ready. however, if one broker's connection is not ready, we don't want to delay the sending of requests for other brokers. one way to achieve this is to have a separate queue per broker.",0,0.9904640913009644
112311627,2849,junrao,2017-04-19T20:56:05Z,"hmm, waiting for a 30 secs request timeout is still too long if there is another request in the queue ready to be processed.",0,0.8747790455818176
112317720,2849,apurvam,2017-04-19T21:25:58Z,"jun raises a good point. right we should have two timestamps in the messages we write to the transaction log. one is the `entrytimestamp` which is the current time and which is used to expire the transactionalid. the other is the `transactionstarttime` which is the timestamp of the first `addpartitionstotransaction` request for a transaction. this is used to expire transactions on the broker. as it stands, we have only the `entrytimestamp` and so a transaction could be open for ever if it gets updates very slowly. this would hold up the progress of the lso on all the partitions involved in the transaction, which is not a desirable outcome. would you be able to add the new timestamp and add a note to update doc on this ticket? [a link]",0,0.6742314696311951
112415717,2849,dguy,2017-04-20T10:05:21Z,seems to make sense to me. any reasoning behind this?,0,0.9738569259643555
112417500,2849,dguy,2017-04-20T10:14:35Z,"it seems so. it is handled like this in `groupmetadatamanager#preparestoregroup`, too",0,0.9905866980552673
112419986,2849,dguy,2017-04-20T10:28:20Z,"there already is an overload, but it also sets the timeout to `integer.max_value`",0,0.9949678778648376
112426248,2849,dguy,2017-04-20T11:05:31Z,"actually, i think this should be `producerepoch`? afaik `coordinatorepoch` is `partition.getleaderepoch`",0,0.9899747967720032
112462355,2849,dguy,2017-04-20T14:08:30Z,i'm not sure.,-1,0.5361419916152954
112472596,2849,dguy,2017-04-20T14:47:19Z,"we achieve that now as we just don't bother sending the request if the broker isn't ready. it gets re-enqueued, but it might need to be as the broker may now be down. i guess i'm missing something here, but i don't really see what.",0,0.969719409942627
112494867,2849,junrao,2017-04-20T16:09:46Z,"hmm, i don't see invalid_fetch_size or invalidfetchsizeexception being generated in the code base. if we don't want to clean this up in this patch, could we at least file a followup jira to track this?",0,0.9849083423614502
112498072,2849,junrao,2017-04-20T16:23:54Z,"my point is on efficiency. if a channel is not ready to begin with, keep re-enqueuing the same request again and again just adds overhead. so, it's better to wait until a channel is ready and then start processing the requests intended on that channel. on the other hand, if a channel is ready, we send a request to that channel and the channel is disconnected before the response is received, we need to re-enqueue the requests for reprocessing. but that's done in the callback in the clientrequest already.",0,0.9784238934516907
112554067,2849,apurvam,2017-04-20T20:33:47Z,"the transaction timeout is passed in in the initpidrequest. it will apply to all transactions in that session. on the producer, the default for this timeout is 60s.",0,0.99518883228302
112562609,2849,apurvam,2017-04-20T21:14:42Z,"so the transaction coordinator is colocated with the leader the topics in the transaction log which it owns. when we do a `txnmanager.appendtransactiontolog` and the coordinator has moved, the leader for the topic should also have moved. in that case, we will get a `not_leader_for_partition` error, and send back a `not_coordinator` error code, in which case the client will send another `findcoordinator` request.",0,0.9937544465065002
112572188,2849,apurvam,2017-04-20T22:13:35Z,"i agree with that this is inefficient. the producer model where we have a background sender thread and one queue per broker is more efficient, since it avoids busy waiting. however, we agreed that we can make this improvement in the future, after the initial integration is done. i filed this ticket to keep track of the work item: [a link]",0,0.9530113339424133
112572768,2849,apurvam,2017-04-20T22:17:41Z,"followed up with offline. the main case to guard against is when the partition moves to another broker, and then moves back between the call to `validatetransactionalid` an `txnmanager.appendtransactiontolog`. in this case, when the call back for `appendtransaction` executes, the coordinator may still be loading the cache, and it is unclear what we should do . we agreed that the best thing probably is that when a partitino emigrates, we should track down in flight operations (and requests sitting in the purgratory), and error them out with a `not_coordinator` code. is it feasible to do the latter in a simple fashion?",0,0.9896491765975952
112622713,2849,dguy,2017-04-21T07:09:13Z,"ok, so that is what we are already using.",0,0.9914200305938721
112623812,2849,dguy,2017-04-21T07:17:40Z,"yes it would be inefficient in the case that there is only a single broker or all brokers are not ready. in other cases it will not necessarily be so inefficient as the request will be re-enqued, but not immediately retried. other requests, to potentially, other brokers will be tried etc, before the requests for the not ready broker is retried. anyway, that said, having a queue per broker is better.",0,0.9790840148925781
112623904,2849,dguy,2017-04-21T07:18:24Z,so should we just default this to something much lower? what would be a reasonable timeout?,0,0.9893311262130737
112651788,2849,dguy,2017-04-21T09:44:05Z,thanks. yeah i should be able to do that,1,0.9608829617500305
112805167,2849,dguy,2017-04-22T08:05:58Z,", correct it doesn't look it is generated anywhere. i'll remove it from here and i've filed: [a link]",0,0.9894038438796997
112806295,2849,dguy,2017-04-22T09:31:16Z,"i already changed `handletxnemigration` to remove the inflight operations that we know about, i.e., the ones in purgatory. once they complete they will error with `not_coordinator`. however this is only useful for the case where we writing the txn markers. for the other cases, if the coordinator is still loading the cache and the `transactionalid` is not yet cached we will respond with `not_coordinator`. however, if the cache is is loading it may have an old record for the `transactionalid`. should we do a check in the callback, i.e., [code block]`",0,0.9910649061203003
113041521,2849,junrao,2017-04-24T19:59:12Z,be consistent on whether to use () when calling clientid() ?,0,0.9931414723396301
113042021,2849,junrao,2017-04-24T20:01:29Z,this still needs to be addressed. the loading in groupcoordinator has the same issue.,0,0.9883556365966797
113083208,2849,junrao,2017-04-25T00:00:43Z,"i am a bit worried about all those independent checks on transactional state w/o any coordinator level locking. for example, in theory, a coordinator emigration and immigration could have happened after the check in line 104. then, the appendmetadatatolog()/initpidwithexistingmetadata() call could mess up some state. i was thinking that another way of doing this is to maintain a read/write lock for the coordinator partition. immigration/emigration will hold the write lock while setting the state. other calls like initpid will hold the read lock, do the proper coordinator state check, initiate the process like appending to the log and then release the read lock (we already have such a partition level lock in partition, not sure if it's easily reusable). this will potentially give us better protection and make things easier to reason about.",-1,0.9168978929519653
113083220,2849,junrao,2017-04-25T00:00:50Z,"hmm, appendmetadatatolog() is not doing exactly the same as if the metadata has existed. it seems that we will be missing all those checks on metadata state in initpidwithexistingmetadata()?",0,0.9793969392776489
113083240,2849,junrao,2017-04-25T00:01:00Z,should we just do the eq check on reference instead?,0,0.9925354719161987
113083247,2849,junrao,2017-04-25T00:01:04Z,"i assume that entrytimestamp is used for expiring a transactional id if there is no activity. if so, this needs to be updated on any activity related to a transactional id such as addpartitions, abort/commit and initpid. also, could we rename this to sth like lastaccesstimestamp? it would also be useful to document the usage of the two timestamps in transactionmetadata.",0,0.9924308657646179
113083250,2849,junrao,2017-04-25T00:01:05Z,"hmm, transactionstarttime needs to be set when we add the first partition to the transaction.",0,0.9790315628051758
113083255,2849,junrao,2017-04-25T00:01:08Z,"hmm, in this case, the coordinator is not really in a loading state. it seems that we need a new error like concurrent_transactions?",0,0.970579981803894
113083261,2849,junrao,2017-04-25T00:01:11Z,"this can be tricky to handle completely. (1) should we also cancel any ongoing loading due to the previous immigration? (2) there could be outstanding transactional requests (e.g., initpid) waiting in producer purgatory after the log append call. ideally, we should mark the coordinator as not available, trigger a check on requests associated with the coordinator's partition in the purgatory so that they can responds with a coodinator_not_available error.",0,0.9223713874816895
113083269,2849,junrao,2017-04-25T00:01:17Z,"if we are doing this optimization, we need to make sure that the handleaddpartitionstotransaction() call first completes any pending transaction, i.e, the markers from a previous transaction must have been sent successfully and the complete transaction entry has been added to the transaction log. otherwise, the producer may start publishing the data for the next transaction before the transaction marker has been added for the previous transaction.",0,0.9915392994880676
113083272,2849,junrao,2017-04-25T00:01:18Z,it seems that we should just keep retrying until successful or the broker is no longer the transaction coordinator.,0,0.9866260290145874
113083277,2849,junrao,2017-04-25T00:01:22Z,good question. we could either keep retrying or mark the coordinator in a bad state.,1,0.6014377474784851
113083280,2849,junrao,2017-04-25T00:01:26Z,the only place that brokerstatemap is needed outside of this class is in transactionmarkerchannelmanager for draining events. perhaps we can make brokerstatemap private and expose a method like drainqueuedtxnmarkers() instead? this makes it a bit easier to track the accesses to the map.,0,0.9924071431159973
113083290,2849,junrao,2017-04-25T00:01:30Z,"hmm, what about those pending requests already in the selector()? ideally we need to drain them too. not sure what's the best way to do that.",0,0.8338233232498169
113083300,2849,junrao,2017-04-25T00:01:33Z,"hmm, not sure why we need to do flatmap instead of just map.",0,0.6916521191596985
113083312,2849,junrao,2017-04-25T00:01:36Z,metadatapartition can be a bit confusing. how about coordinatorpartition?,0,0.833145022392273
113083333,2849,junrao,2017-04-25T00:01:53Z,this can be in a future patch. it would be useful to record this in some metric so that we know the state of transaction coordinator.,0,0.9942654967308044
113083342,2849,junrao,2017-04-25T00:01:55Z,should we do the eq test to only test for reference equal?,0,0.992027223110199
113083350,2849,junrao,2017-04-25T00:02:00Z,"is that enough? for transactions in the prepare state, shouldn't we try to write the txn markers to added partitions and bring those transactions to the complete state too?",0,0.9928285479545593
113083356,2849,junrao,2017-04-25T00:02:03Z,should we clear out loadingpartitions and stop any ongoing loading on that partition?,0,0.9936079978942871
113083359,2849,junrao,2017-04-25T00:02:05Z,this method seems cheap. is there a reason for running this in the scheduler?,0,0.9704166054725647
113083367,2849,junrao,2017-04-25T00:02:09Z,the above issue is still not resolved.,0,0.9295335412025452
113083375,2849,junrao,2017-04-25T00:02:11Z,"hmm, do we need this check if we make sure all outstanding transactions are aborted on emigration and new transactions can only be started after the coordinator loading completes?",0,0.9839141368865967
113083384,2849,junrao,2017-04-25T00:02:16Z,inaccurate comment. internal topics are not just offset topic now.,-1,0.7894307374954224
113088713,2849,junrao,2017-04-25T01:01:00Z,"if the thread is blocked in networkclient.poll and some new requests are added to the queue, it seems that we need to wake up networkclient so that new requests can be processed immediately.",0,0.9898023009300232
113088732,2849,junrao,2017-04-25T01:01:10Z,we should just wait until the target broker is available.,0,0.990455687046051
113088785,2849,junrao,2017-04-25T01:01:42Z,"hmm, instead of throwing illegalstateexception, it seems that we should just keep retrying until successful?",0,0.97523432970047
113089004,2849,junrao,2017-04-25T01:04:11Z,"since the timeout in delayedtxnmarker is infinite. i am wondering if we really need a txnmarkerpurgatory. in transactionmarkerrequestcompletionhandler, we are already updating the pending partitions as the client response comes back. the response that removes the last pending partition can just trigger the calling of completioncallback.",0,0.9449897408485413
113090851,2849,junrao,2017-04-25T01:26:07Z,"if the broker's message format is < v2, currently, when appending to the log, we simply convert it to an old format. in this case, we want to error out and respond to the client with a transactionnotsupported error.",0,0.9937261939048767
113091081,2849,junrao,2017-04-25T01:28:07Z,"since we are sending new type of requests across the brokers, we need to check inter broker protocol and error out if the new request is not supported.",0,0.9917353987693787
113123510,2849,dguy,2017-04-25T07:28:27Z,yep any reason why we are using hw?,0,0.9947722554206848
113124537,2849,dguy,2017-04-25T07:34:51Z,it isn't clear to me what this is supposed to be saying either. ?,0,0.8807213306427002
113125360,2849,dguy,2017-04-25T07:40:11Z,yes. we need to do that. discussed this with offline yesterday and we thought it might be better to do in a follow up patch as this patch is already quite large. thoughts?,0,0.9424291253089905
113125813,2849,dguy,2017-04-25T07:43:13Z,i guess it is because `loadtransactions` is run in the scheduler. so they won't interleave. ?,0,0.9835258722305298
113127361,2849,dguy,2017-04-25T07:52:28Z,"ok. i can do that by adding a check in the while loop in `loadtransactionmetadata`, i.e, `while(curroffset < highwatermark && loadingpartitions.contains(partitionid) && ...)` will that be ok?",0,0.988767683506012
113127705,2849,dguy,2017-04-25T07:54:19Z,i'm not really sure what i'm supposed to be checking here?,-1,0.5705083012580872
113128786,2849,dguy,2017-04-25T08:00:21Z,i'm not sure how i can cancel all inflight requests. say for instance `transactionstatemanager.appendtransactiontolog(..)` is called and then on another thread `handletxnemigration` is called and removes the partition. how do i abort the inflight `transactionstatemanager.appendtransactiontolog(..)` call.,0,0.9336801171302795
113129466,2849,dguy,2017-04-25T08:04:29Z,"thanks - yeah that makes sense. i was thinking about locking, too, but wasn't sure of the correct level to do it at, but the partition level seems ok. will look into it. thanks for the suggestion",1,0.9908689260482788
113130366,2849,dguy,2017-04-25T08:09:55Z,"i'm not sure what was meant by the comment, but i think you are correct in that we should do `initpidwithexistingmetadata()` in the case that they aren't the same. any thoughts?",0,0.9481505155563354
113165211,2849,dguy,2017-04-25T11:03:40Z,in which case should i default it something like -1 here?,0,0.9924604296684265
113165318,2849,dguy,2017-04-25T11:04:22Z,true. any thoughts on this?,0,0.9806200265884399
113165961,2849,dguy,2017-04-25T11:08:10Z,i think we can handle (1) by: 1. in `removetransactionsforpartition` we remove the partition from `loadingpartitions` 2. in `loadtransactionmetatdata` we only perform the loop when `loadingpartitions.contains(partition) i have to think a bit more about 2,0,0.9849858283996582
113166353,2849,dguy,2017-04-25T11:10:21Z,i think this case is already handled by `handleinitpid()`,0,0.9897702932357788
113167929,2849,dguy,2017-04-25T11:19:30Z,they will error out with `not_coordinator` on completion. will that suffice? i'm not sure how we can cancel inflight requests in the `networkclient`,0,0.9851729869842529
113168889,2849,dguy,2017-04-25T11:25:14Z,i probably should just use flatten. my scala knowledge is not the best,-1,0.6697495579719543
113169486,2849,dguy,2017-04-25T11:28:53Z,in `initpidwithexistingmetadata` we also need to wait on the transaction to complete if there is an inflight transaction in the `prepareabort` or `preparecommit` phase.,0,0.9942345023155212
113172390,2849,dguy,2017-04-25T11:45:47Z,how would i do that?,0,0.9876160025596619
113173083,2849,dguy,2017-04-25T11:49:47Z,ok i guess i'll need todo that in `transactionmarkerchannel#addrequesttosend`,0,0.9903252124786377
113178448,2849,ijuma,2017-04-25T12:15:40Z,"`flatmap` is preferable to `map` and then `flatten`. i am guessing jun's question is because `txnmarkerentry` sounds like an element, but it's actually a `list`. maybe it should be renamed?",0,0.9897646903991699
113178626,2849,ijuma,2017-04-25T12:16:27Z,"also, you can write it a bit more concisely by doing `buffer.flatmap(_.txnmakerentry).asjava` (x doesn't add anything over the underscore).",0,0.9944890737533569
113195654,2849,dguy,2017-04-25T13:34:40Z,"the tc maintains multiple partitions, so we'd need to have a lock per partition. you mentioned that there is a read/write lock on partition - i believe you are referring to `leaderisrupdatelock`... i can't see any other locks in `partition`. anyway, do we want to expose this for other classes to use? i'd probably think not. if we maintain a lock per partition then perhaps it should be done by the `transactionstatemanager` and then we'd need to add/remove locks in the immigration/emigration. i think we'd also need to add another method on `transactionstatemanager`, say `partitionlock(partitionid)` that returns an `option[reentrantreadwritelock]`. the calls in `transactioncoordinator` to `iscoordinatorfor` could then be replaced with calls to `partitionlock(partitionid)` - if the lock exists they take a read lock. if it doesn't exist then respond with `errors.not_coordinator` does this seem sensible?",0,0.9876483678817749
113330271,2849,guozhangwang,2017-04-25T22:48:31Z,in that case do we really need this change in this pr? maybe we can just remove this change as it is actually doing the same still.,0,0.9878188371658325
113330372,2849,guozhangwang,2017-04-25T22:49:15Z,are these changes intentional? the original ordering seems ok to me.,0,0.9815700054168701
113331290,2849,guozhangwang,2017-04-25T22:55:50Z,"thinking about this a bit more, i wonder if the `coordinatorepoch` should also be in the internal entry as well, since different txn log partition leader's epoch hence the coordinator epoch would be different?",0,0.9829692244529724
113331531,2849,guozhangwang,2017-04-25T22:57:33Z,"edit: in the existing branch i have already made those changes a while back: [a link] the design doc however is not updated. i saw you did a groupby on the `coordinatorepoch` instead, so that each write marker request will only contain one `coordinatorepoch`, but since on the broker side, this coordinator epoch is checked inside the `log` layer anyways i felt it is better to change this field as a per-marker-entry field in the protocol.",0,0.992334246635437
113332359,2849,guozhangwang,2017-04-25T23:03:23Z,"i did this in the original commit but: since this thread is owned by the broker only, we do not need this tag. instead we can just pass an empty tag map.",0,0.9946001768112183
113347218,2849,guozhangwang,2017-04-26T01:15:54Z,nice catch. currently we do not have a broker-side `reconnect.backoff` config yet so different modules just hand-code different values. but moving forward i felt we may want to introduce a new config for inter-broker reconnect backoff.,1,0.925746738910675
113348424,2849,guozhangwang,2017-04-26T01:29:27Z,nit: indentation on the comment line 69.,0,0.9943378567695618
113348812,2849,guozhangwang,2017-04-26T01:33:43Z,sounds good to me.,1,0.9217013120651245
113351582,2849,guozhangwang,2017-04-26T02:00:13Z,nit: new line after condition,0,0.9943538904190063
113352248,2849,guozhangwang,2017-04-26T02:07:55Z,"yeah i was ""piggy-backing"" on this error code since this is the only retriable error code that the client recognizes in my incomplete patch. and i do agree that we should introduce another retriable error code here.",0,0.9623690247535706
113352808,2849,guozhangwang,2017-04-26T02:14:28Z,"since we return immediately after the `preparexx` marker is written. in both `initpid` and `addpartition` request handling the metadata state could be in `preparexx` or `ongoing`, so we need to handle them in both these two places, better in a consistent way. in the design doc we said the request will be held on the broker side indefinitely until the current transaction is rolled-forward or rolled back complete. we did this in `initpid`, but here we are directly returning a non-retriable error code. i was planning to do these handling on both places in a separate pr but since is already adding the logic for `initpid` now maybe we can discuss about that now: after thinking about it a bit more i felt maybe its better to return a retriable exception either immediately (with the new error code we need anyways for the above case) or after some timeout (with the `timeout` error code) on both places, and let the client to back-off and retry. doing this we can avoid ever increasing the in-memory structures like like the per-broker queues and the purgatory. thoughts?",0,0.9909031987190247
113353056,2849,guozhangwang,2017-04-26T02:17:12Z,"i'm wondering if we should bound the size of this blocking queue or it will cause tc-broker oom when some of the txn involved partition leaders are temporarily / permanently available. my feeling is that we do not and here is my reasoning (cc ): 1. we have two in-memory structures whose size is unbounded, this blocking queue and the txn purgatory. 2. when there are some partitions unavailable, hence the current preparexx transaction cannot be completed, they will take one slot on each of the above structures; 3. then when new request is coming from the same pid, either `initpid` or `addpartitions`, they will not proceed. hence the above structures will have at most one parked item for each producer. see my other comment about handling the `initpid` and `addpartitions` request while the previous txn has not completed.",0,0.8842127919197083
113353166,2849,guozhangwang,2017-04-26T02:18:28Z,"as long as we clear the txn purgatory, even if there are inflight request during the time. when they come back as responses, either succeeded or failed, since the corresponding delayed operation has already gone its callback will effectively be reduced to a no-op. so i think that is fine.",0,0.8875641822814941
113353266,2849,guozhangwang,2017-04-26T02:19:50Z,chatted with offline. i did this mainly to just mimic group coordinator's loading behavior. but after discussing with him i think it is safer to read up to leo (we probably need to do the same for gc as well),0,0.9811257123947144
113353374,2849,guozhangwang,2017-04-26T02:21:23Z,yup. let's do that in follow-up prs.,0,0.9863848090171814
113353582,2849,guozhangwang,2017-04-26T02:23:52Z,"the log entry was wrong, maybe just ""since the the appended log did not successfully replicate to all replicas"". does that sound better?",0,0.9773569703102112
113353750,2849,guozhangwang,2017-04-26T02:26:03Z,"since we now have one queue per broker, and 1) we drain all the elements in the queue whenever trying to send; 2) we wake up the client whenever we are adding new elements to the queue; i think it is not as critical to set lower values?",0,0.9890798926353455
113353816,2849,guozhangwang,2017-04-26T02:26:52Z,"agree, maybe we can have a read-write lock on the txn metadata cache and only release the read lock after the txn log has been appended locall?",0,0.9932867884635925
113354061,2849,guozhangwang,2017-04-26T02:29:31Z,i think 's comment is that we did some checking on the txn metadata's state in `initpidwithexistingmetadata` whereas we did not do such checking before calling `appendmetadatatolog`. have explained to him that it is because at line 129 we are assured that the metadata is just newly created and hence it's always `ongoing`. maybe the comment itself has been outdated after the addition of the `initpidwithexistingmetadata` logic.,0,0.9828479290008545
113354470,2849,guozhangwang,2017-04-26T02:33:57Z,"what's the motivation of trying to drain all the queued elements? since the max inflight request is only 1 in the network client, even if we construct multiple requests for a certain destination only the first request will succeed in sending right? in that case could just do the 1) peek-first 2) if-ready-send-and-pop pattern?",0,0.9883158802986145
113379063,2849,dguy,2017-04-26T07:07:11Z,we don't have one queue per broker yet. that was going to be in a follow up pr,0,0.9913299083709717
113379863,2849,dguy,2017-04-26T07:12:57Z,"actually, i don't think we need this debug message as the error cases are all logged previously. i'll just remove it.",0,0.989061713218689
113386204,2849,dguy,2017-04-26T07:51:34Z,per partition? or a global lock?,0,0.9894019961357117
113388847,2849,dguy,2017-04-26T08:05:39Z,will the kip need to be updated with the new error?,0,0.9915687441825867
113392736,2849,dguy,2017-04-26T08:26:59Z,"so this should change back to what you previously had? we originally had your code, but during the merge with other changes it was probably removed. that is why i did the groupby on `coordinatorepoch`.",0,0.9938004612922668
113395115,2849,dguy,2017-04-26T08:40:00Z,"question more for my own understanding than anything else: if `initpid` is holding on to the request on the broker until the transaction is completed, then i think `addpartitions` should never be called when the transactionid is in a `preparexx` state. is that correct?",0,0.9692028760910034
113395718,2849,dguy,2017-04-26T08:43:18Z,this is largely a refactoring of your code from here: [a link] :-p,1,0.9905806183815002
113454320,2849,dguy,2017-04-26T13:43:12Z,"on second thoughts, i'll add a single read/write lock in the coordinator as it is much simpler than having to maintain multiple. if that is not ok, we can revisit.",0,0.9850203990936279
113457671,2849,dguy,2017-04-26T13:55:37Z,i'm not sure i understand (2). when you refer to there being outstanding requests in the producer purgatory is that w.r.t `replicamanager.appendrecords(...)`?,0,0.8743076920509338
113499063,2849,apurvam,2017-04-26T16:22:42Z,we should probably have one or more jira's to track these.,0,0.9867148995399475
113501224,2849,guozhangwang,2017-04-26T16:32:02Z,"this is about the inter-broker protocol version. details are here: [a link] maybe just leave a todo marker and i can address it in a follow-up pr, so we would not drag too long for this one?",0,0.9931252002716064
113501426,2849,guozhangwang,2017-04-26T16:32:56Z,responded in another comment. let's do this incrementally in another pr and just leave a todo in this pr. otherwise we would be looking at a 10k diff,0,0.9932914972305298
113506336,2849,dguy,2017-04-26T16:53:53Z,ok i've filed: [a link],0,0.9950309991836548
113506744,2849,dguy,2017-04-26T16:55:31Z,i've filed [a link],0,0.9950680732727051
113510250,2849,junrao,2017-04-26T17:10:10Z,"yes, we can probably also just check if the partition is still in ownedpartitions.",0,0.9946540594100952
113511035,2849,junrao,2017-04-26T17:13:41Z,"if you set the coordinator state first and trigger a check in the purgatory, the checking of the iscomplete() logic should realize that the coordinator is no longer valid and error out.",0,0.9880313873291016
113512025,2849,junrao,2017-04-26T17:18:18Z,"most operations just need to hold a read lock. only emigration/immigration need to hold a write lock. so, perhaps having a single lock per broker is also fine as long as we don't hold the lock for too long (i.e., we should mostly be just setting critical states while holding the lock. any expensive stuff should be done outside the lock).",0,0.9872796535491943
113512989,2849,junrao,2017-04-26T17:22:29Z,"we can set it to -1, but it may not matter. transactionstarttime is only useful when aborting a transaction that's started. if the transaction is in empty state, transactionstarttime is probably not going to be used. it's more important to set transactionstarttime on adding the first partition.",0,0.991831362247467
113513257,2849,junrao,2017-04-26T17:23:39Z,"yes, we can remember this and update the kip with all the changes in a batch.",0,0.9933306574821472
113513973,2849,junrao,2017-04-26T17:26:53Z,"yes, i was referring to delayed events in the producer purgatory after the replicamanager.appendrecords(...) call. we can trigger a check of those delayed events and let them error out (since the check will find out that the broker is no longer the coordinator).",0,0.9935250282287598
113515117,2849,junrao,2017-04-26T17:31:52Z,"hmm, is it? handleinitpid() seems to just call appendmetadatatolog(). there is no guarantee that abort/commit marker from the previous transaction has been sent by the inter broker thread.",0,0.9762831926345825
113515688,2849,junrao,2017-04-26T17:34:14Z,"well, if the response fails because of disconnection, we shouldn't keep retrying right?",0,0.9808319211006165
113517731,2849,dguy,2017-04-26T17:42:47Z,in `handleinitpid` if metadata exists it calls `initpidwithexistingmetadata` that waits for the previous transaction to complete,0,0.9935351610183716
113537029,2849,dguy,2017-04-26T19:05:32Z,is calling `delayedproducepurgatory.checkandcomplete(topicpartitionoperationkey)` the correct thing to do in this case?,0,0.993466317653656
113538220,2849,dguy,2017-04-26T19:11:47Z,"yep, it does get set when the first partition is added.",0,0.9887741804122925
113550754,2849,guozhangwang,2017-04-26T20:12:19Z,"`initpid` is only called only for the lifetime of a producer, when the producer client completed the current txn and is about to start the next one, it will not call `initpid` but just `addpartitions` as the first request. only when producer client fails-over the new instance (i.e. in its next life) will send an `initpid` again.",0,0.9927016496658325
113594739,2849,apurvam,2017-04-27T00:45:09Z,"the code as it is seems correct to me. if you get `addpartitions`, you should be in an ongoing state. i also think the `empty` state is invalid in this case.",0,0.9843856692314148
113594825,2849,apurvam,2017-04-27T00:45:54Z,"or is `empty` just signally `no_ongoing_transaction`? if so, it is a valid state.",0,0.9933986663818359
113595652,2849,apurvam,2017-04-27T00:54:41Z,"i guess you mean [code block] (note the absence of the negation in my if). i think this is reasonable. more generally, if we don't find the transaction metadata in the `appendtotransactionlog` callback, or if the coordinatorepoch is different from what we expect, we should just return not_coordinator. the client will retry and eventually succeed.",0,0.9822162389755249
113595956,2849,apurvam,2017-04-27T00:57:49Z,"also, cc ..",0,0.9950546026229858
113596678,2849,apurvam,2017-04-27T01:06:30Z,"i guess current point was that a valid state here could also be `prepare`, if the previous transaction is still completing, in which case we should return `concurrent_transactions`, and have the client retry with backoff.",0,0.9854903221130371
113634970,2849,dguy,2017-04-27T07:54:21Z,"- cool makes sense now. so i guess we should do the same thing in `initpid` and `addpartitions`, i.e., respond with `concurrent_transaction` or block until the previous transaction has completed",1,0.9698225259780884
113831631,2849,guozhangwang,2017-04-28T00:32:12Z,this is already addressed.,0,0.9952501058578491
114487301,2964,ijuma,2017-05-03T07:46:13Z,there's no need to have the `errors` type parameter here. that check always succeeds.,0,0.9939849972724915
114488311,2964,ijuma,2017-05-03T07:53:55Z,this can be written more clearly as: [code block],0,0.9950785636901855
114488522,2964,ijuma,2017-05-03T07:55:26Z,"hmm, as discussed previously, it's preferable to use a case class instead of many unnamed parameters.",0,0.9783994555473328
114505601,2964,dguy,2017-05-03T09:40:51Z,"do we need to update these tuples to be `(error, null, null)`? i.e., we are expecting a triple as the result",0,0.9935219883918762
114507297,2964,dguy,2017-05-03T09:50:44Z,looks like this is not used anymore?,0,0.9903426170349121
114509240,2964,dguy,2017-05-03T10:02:25Z,why do we need to do this?,0,0.8802698254585266
114510129,2964,dguy,2017-05-03T10:07:39Z,should we not just retry in this case? we've already written `preparexx` to the log and i thought we need to complete the transaction? how will the transaction be completed?,0,0.9908407926559448
114510837,2964,dguy,2017-05-03T10:09:49Z,the comment is incorrect. i don't think we are returning anything to the client. if the transaction has been emmigrated than it the commit should be completed by the new partition leader,0,0.985042929649353
114511374,2964,dguy,2017-05-03T10:12:53Z,"i think we also need a check `case errors.not_coordinator` in which case we should just log an move on. also, in this case i think we need to retry?",0,0.9915920495986938
114512933,2964,dguy,2017-05-03T10:22:15Z,how are we cleaning up cases like this where it has failed? what are the implications for consumers etc?,0,0.9697270393371582
114513958,2964,dguy,2017-05-03T10:28:55Z,why do we need to update the `txnstarttimestamp` here and in the `completecommit` case?,0,0.9925321936607361
114514040,2964,dguy,2017-05-03T10:29:26Z,could this be `case prepareabort | preparecommit` ? i think they are identical,0,0.9917004704475403
114514118,2964,dguy,2017-05-03T10:30:00Z,`case completeabort | complete commit` ? i think they are identical,0,0.9902406930923462
114515680,2964,dguy,2017-05-03T10:41:41Z,"we have the situation here that when this method returns nothing has actually happened yet, i.e., the removal is done on a different thread. so what happens if we get a request at the same time for another transactionalid that is in the same partition? are we just relying/hoping it will eventually fail?",0,0.9807798266410828
114515990,2964,dguy,2017-05-03T10:44:02Z,is this an exceptional condition? could we just log it and move on?,0,0.9823325276374817
114516182,2964,dguy,2017-05-03T10:45:16Z,should we change this to have `coordinatorepochandtxnmetadata` as a param rather than the 2 separate params?,0,0.9945852160453796
114675298,2964,guozhangwang,2017-05-03T23:20:50Z,ack,0,0.9149930477142334
114675858,2964,guozhangwang,2017-05-03T23:24:58Z,"edit: the reason i made it as unnamed parameters is that the `sendtxnmarkers` function is not long used as a parameter but also directly called elsewhere. and it has been reduced from 8 params to 4, so i feel this is better cost-effective?",0,0.9916549921035767
114677405,2964,guozhangwang,2017-05-03T23:37:23Z,"ack. this needs to be tweaked a bit since the inner map is a `pool`, let me know if you like the new pattern or not.",0,0.9278280138969421
114677702,2964,guozhangwang,2017-05-03T23:40:09Z,ack.,0,0.5866091847419739
114677859,2964,guozhangwang,2017-05-03T23:41:42Z,ack,0,0.9149930477142334
114677949,2964,guozhangwang,2017-05-03T23:42:25Z,this is needed as `groupby` to generate the grouped map keyed by the node object.,0,0.9951853156089783
114678445,2964,guozhangwang,2017-05-03T23:46:55Z,"from `appendtransactiontolog` the only error codes we would pass in the callback are: [code block] and anything falling into `other` should be considered fatal as they should not happen (if they happen that should be a bug), and `unknown` comes from `message_too_large` or `record_list_too_large` which are also doomed as fatal.",0,0.9880173206329346
114678501,2964,guozhangwang,2017-05-03T23:47:30Z,ack. updating the comment.,0,0.9698160290718079
114678943,2964,guozhangwang,2017-05-03T23:51:37Z,"from `delayedtxnmarker` when we call `completioncallback` we will only return `none` and hence any other error codes would not be expected and considered as fatal right? note that the write-marker-response could contain error codes like `unknown_topic_or_partition`, but this is handled in the `transactionmarkerrequestcompletionhandler`, in which case we will retry.",0,0.9917145371437073
114679087,2964,guozhangwang,2017-05-03T23:53:00Z,"generally this default is just for any un-expected error codes (i.e. there is a bug in the protocol, that broker returns some error codes not defined) to fail-fast.",0,0.9888755083084106
114679260,2964,guozhangwang,2017-05-03T23:54:19Z,"good point, ack.",1,0.7379374504089355
114679267,2964,guozhangwang,2017-05-03T23:54:22Z,"good point, ack.",1,0.7379374504089355
114679565,2964,guozhangwang,2017-05-03T23:57:09Z,"i have not reviewed your expiration pr so my understanding might be inconsistent, but here is how i read the existing code: `txnstarttimestamp` is only set when there is an active txn ongoing, otherwise it should always be set to -1 (i.e. the above check on the new metadata). and expiration will simply skip the metadata when this field is -1.",0,0.9874516129493713
114680315,2964,guozhangwang,2017-05-04T00:03:32Z,"this will be in completed in another pr for the locking mechanism, and here is a sketch: 1. we will add a per-broker read-write lock on tc. 2. all request-handling logic need to grab the read lock before accessing the cache for checking state until appending to the local log call returns. 3. the loading / removing thread will grab the write lock when removing / adding the sub-map for that partition into the cache. 4. implementation-wise, we will modify `statelock` for that read-write lock. the main purpose is to avoid log appending out-of-order, e.g. consider the following order: [code block]",0,0.9918349981307983
114680536,2964,guozhangwang,2017-05-04T00:05:22Z,"hmm, that is a good point. i think it can happen that `onfollower` called twice but the second call's triggered thread gets executed before the first call. so yeah we could just log it and move on.",0,0.4955458343029022
114681378,2964,guozhangwang,2017-05-04T00:13:26Z,"edit: similarly for `addloadedtransactionstocache`, but slightly different: we only have one background thread inside `scheduler` and we are checking on `loadingpartitions` so that no requests will be handled while loading so no new entries will be appended to the log. so even we have two loading tasks scheduled, it is safe for the second loaded metadata to replace the first loaded sub-map via `put`, so if `isdefined` we can just log it.",0,0.9921180605888367
114682211,2964,guozhangwang,2017-05-04T00:22:34Z,"i have been thinking about it, the main reason that i keep it separately is that it can be called in two paths: handler thread call it directly and the callback from writemarkersender call it separately. in the latter case the two values are separate so i ended up keep them as is.",0,0.9749753475189209
114723919,2964,dguy,2017-05-04T08:41:09Z,"in step 2 isn't the log append callback happening on another thread? so how do we release the read lock? i guess i'm missing something but i'm reading it like this: [code block] which would mean the read lock would be given up as soon as the `appendtolog` call returns, but that doesn't mean the write to the log has actually completed as it might go into purgatory and be completed by another thread. i guess you have some other idea?",0,0.9862722158432007
114724163,2964,dguy,2017-05-04T08:42:42Z,my understanding is that it only needs to be set when we add the first partition to a new transaction.,0,0.9899633526802063
114724204,2964,hachikuji,2017-05-04T08:43:01Z,"why is it safe to access `transactionmetadatacache` without a lock? it seems we protect mutations with the state lock, but since it is not a concurrent collection, don't we need to protect reads as well?",0,0.9887789487838745
114724432,2964,dguy,2017-05-04T08:44:33Z,"ok - that makes sense. however, if this does happen how would we recover from it? we'd have uncommitted data in the logs which would block consumers using read committed. do we have any plans to deal with this?",0,0.9784875512123108
114724503,2964,dguy,2017-05-04T08:45:02Z,yeah - duh! i missed that!,1,0.9346317648887634
114724840,2964,hachikuji,2017-05-04T08:47:07Z,"not from this patch, but should this be `transactionstatemanager`?",0,0.9919500350952148
114725329,2964,hachikuji,2017-05-04T08:50:12Z,nit: this is not aligned.,0,0.8987562656402588
114726156,2964,hachikuji,2017-05-04T08:54:40Z,"hmm... it doesn't seem right to synchronize on the instance of `coordinatorepochandtxnmetadata`. we construct a new one in every call to `addtransaction`, right? also, we're still synchronizing on the metadata elsewhere in this file.",0,0.9242916703224182
114726879,2964,hachikuji,2017-05-04T08:58:33Z,"nit: `error`? in spite of the name of `errors`, there is only one error. a few more of these in this class if you're keen.",0,0.9200368523597717
114728807,2964,hachikuji,2017-05-04T09:09:58Z,"this is a comment throughout, but it seems we rarely check the result of `preparetransitionto`. perhaps that function should just raise an invalid state exception if the state transition is invalid? otherwise we should get in the habit of adding the checks.",0,0.9900834560394287
114729513,2964,hachikuji,2017-05-04T09:13:50Z,"nit: not from this patch, but should this be `responsecallback`? it's nice to keep naming consistent and we use this name in `handleinitpid` and `initpidwithexistingmetadata`. it's also helpful that the name expresses that this callback returns to the user.",1,0.7780752182006836
114730909,2964,hachikuji,2017-05-04T09:21:29Z,shouldn't we be using `newmetadata` somehow?,0,0.9918475151062012
114732285,2964,hachikuji,2017-05-04T09:28:44Z,"nit: not from this patch, but couldn't we add a couple constructors to `initpidresult` and remove these functions? or maybe just add default values for pid and epoch.",0,0.9920056462287903
114737164,2964,hachikuji,2017-05-04T09:57:30Z,the reuse of `transactionmetadata` here is super confusing. it seems we just need a struct to propagate the new state to the completion callback. maybe we could do this with an immutable case class instead? maybe `transactionstatetransition` or something.,-1,0.8906490206718445
114739243,2964,hachikuji,2017-05-04T10:09:36Z,"typo: ""competed""",0,0.994729220867157
114740699,2964,hachikuji,2017-05-04T10:18:53Z,"this is pretty confusing stuff. my understanding is that once this append completes, we'll invoke `transationmetadata.completetransitionto`. in this case, it will be the same `transactionmetadata` object passed to itself. might not be incorrect, but it's definitely weird. by the way, you can replace `epochandmetadata.transactionmetadata` with `metadata`.",-1,0.990456759929657
114749671,2964,ijuma,2017-05-04T11:19:41Z,"similar to a comment that i left in a different pr, adding type annotations here triggers a pattern match and it's brittle if there are cases where the match can fail, but the compiler can't prove it (any time there is a subclass involved). it's one of the cases where relying on type inference is safer (it will always infer a safe type).",0,0.9850842356681824
114750267,2964,ijuma,2017-05-04T11:24:05Z,"btw, a better way to represent this would be using `either[errors, (int, transactionmetadata)]`. even better would be to have a type for the tuple on the right, but even without it, it would make the flow way clearer imo.",0,0.953973114490509
114807366,2964,guozhangwang,2017-05-04T15:12:07Z,"when a transaction is completed, should we reset the starttimestamp to -1 again to avoid being expired?",0,0.9947232007980347
114807926,2964,guozhangwang,2017-05-04T15:14:05Z,ack.,0,0.5866091847419739
114877797,2964,guozhangwang,2017-05-04T20:20:46Z,when this happens usually ops people need to be involved to manually truncate the log before starting. but i think this code can also be improved a bit for a more graceful shutdown. do you have any ideas?,0,0.9752864837646484
114878149,2964,guozhangwang,2017-05-04T20:22:13Z,"as i said we only need to make sure the the log entry is appended to the local data segment (even not required to flushed on disk), not necessarily replicated complete.",0,0.9940022826194763
114879314,2964,guozhangwang,2017-05-04T20:27:35Z,"1. please see my previous comment: we will modify the `statelock` into a read-write lock and the only operations that could mutate the top-level map `transactionmetadatacache` will be covered (the checking / append-to-log will be covered in read lock). 2. for the lower-level map `pool[string, transactionmetadata]`, its operations are thread safe and any modifications to the inner `transactionmetadata` will be covered by the object `synchronized` itself and all modifications will be in-place than object override.",0,0.9899532198905945
114879417,2964,guozhangwang,2017-05-04T20:28:03Z,ack.,0,0.5866091847419739
114879969,2964,guozhangwang,2017-05-04T20:30:42Z,"i have also thought about that, e.g. having sth. like [code block] and call it without overriding defaults upon checking failure cases, but i found it is less readable. if you feel strong about it i can change.",0,0.9502198100090027
114880965,2964,guozhangwang,2017-05-04T20:35:07Z,"yeah that is a good question, ideally we should sycnrhonize on `txnmetadata` only, since coordinator epoch will only likely be changed during loading / removal of the metadata. will refactor on this part.",1,0.5422362685203552
114902795,2964,guozhangwang,2017-05-04T22:33:08Z,ack.,0,0.5866091847419739
114903066,2964,guozhangwang,2017-05-04T22:35:06Z,"we check it in `transactionmetadata`, that the new state is equal to the pending state.",0,0.9950364232063293
114903584,2964,guozhangwang,2017-05-04T22:38:28Z,"i just refactored the code a bit around `initpid`, since it is a special case compared with others: 1. in other cases, we first create a new metadata as a place holder of all the pending updates to the original object and then only update it in the callback after append / send marker completes; 2. in `initpid` case, we would try first inserting a dummy into the cache but set its pending state, as `empty -> empty`; if there is an existing entry already we would either a) abort its existing txn first b) return retriable error code or c) update epoch / txn timeout and do the same as case 1) above. the new code path looks better to me know. let me know what do you think.",0,0.9920948147773743
114903764,2964,guozhangwang,2017-05-04T22:39:39Z,ack.,0,0.5866091847419739
114903788,2964,guozhangwang,2017-05-04T22:39:51Z,done.,0,0.9897913336753845
114903866,2964,guozhangwang,2017-05-04T22:40:32Z,"not sure i understand this comment, could you elaborate a bit?",0,0.56781405210495
114904861,2964,guozhangwang,2017-05-04T22:47:50Z,ack.,0,0.5866091847419739
114905004,2964,guozhangwang,2017-05-04T22:48:54Z,ack.,0,0.5866091847419739
114906261,2964,hachikuji,2017-05-04T22:58:09Z,"but if we know the transition is invalid here, then we could skip appending to the log, right? i feel we should just make `preparetransitionto` raise an exception if the attempted transition is invalid.",0,0.9888363480567932
114916468,2964,guozhangwang,2017-05-05T00:32:04Z,discussed offline.,0,0.9925440549850464
114916529,2964,guozhangwang,2017-05-05T00:32:46Z,"edit: discussed offline, realized it is a different issue than i thought about. refactored this part a bit as well.",0,0.9605115056037903
114917535,2964,guozhangwang,2017-05-05T00:45:44Z,"edit: i realized that in many cases i would return a `null`, and it will cause the annotated type to be `any` at compilation time. so i think it is actually better to enforce type annotations in this case.",0,0.9693149924278259
114917644,2964,ijuma,2017-05-05T00:47:01Z,"yeah, you should never use `null` in scala generally. using an `either` here avoids all the issues.",0,0.9862633943557739
114920333,2964,junrao,2017-05-05T01:27:36Z,not sure checking coordinatorepoch here is enough since coordinatorepoch could change when we append the log.,0,0.7890069484710693
114921338,2964,guozhangwang,2017-05-05T01:42:57Z,"got it, thanks!",1,0.9923909306526184
114973551,2964,dguy,2017-05-05T11:06:35Z,ok - i missed the local bit. thanks,1,0.8990916609764099
115104932,2964,junrao,2017-05-05T23:36:30Z,"in scala, == tests object equality. i think we want to test reference equality here. if so, we should use eq for testing.",0,0.9901200532913208
115106324,2964,junrao,2017-05-05T23:57:42Z,"hmm, this means that in preparetransitionto(), we need to transition from one state to itself. not sure if all states are allowed to transition from itself.",0,0.9620488286018372
115106407,2964,junrao,2017-05-05T23:59:24Z,"since now there are different types of epoch, would it be better to name this prepareincrementproducerepoch?",0,0.993815541267395
115106983,2964,junrao,2017-05-06T00:10:02Z,should we include pendingstate in hashcode() and equals()?,0,0.9953488707542419
115107794,2964,junrao,2017-05-06T00:26:22Z,"hmm, when transitioning from empty to ongoing, it seems it's ok for newmetadata.txnstarttimestamp to be larger than current txnstarttimestamp. it's only when transitioning from ongoing to ongoing that we don't want txnstarttimestamp to change.",0,0.9765278697013855
115107921,2964,junrao,2017-05-06T00:29:38Z,"yes, it seems damian's understanding makes sense.",0,0.960019052028656
115108280,2964,junrao,2017-05-06T00:39:21Z,it seems the comment should be the same as in line 185: let client backoff and rety instead of retry immediately.,0,0.9889288544654846
115147118,2964,junrao,2017-05-07T16:09:38Z,highwatermark below should be renamed to logendoffset?,0,0.9935965538024902
115147657,2964,junrao,2017-05-07T16:32:52Z,"since removetransactions() is cheap, not sure if this needs to be run in a scheduler. also, perhaps it's useful to wait for the scheduler to have no pending task here before return? any pending loadtransaction task should be completed very quickly after removetransactions() is called.",0,0.983853816986084
115163421,2964,junrao,2017-05-08T02:03:38Z,does brokerrequestqueue.destination need to be volatile?,0,0.9932007193565369
115163433,2964,junrao,2017-05-08T02:03:50Z,"hmm, the while loop may tie up a request handler thread, which is not ideal.",0,0.8762809634208679
115163443,2964,junrao,2017-05-08T02:04:02Z,"since the timeout for delayedtxnmarker is infinite, do we need a purgatory or just a map?",0,0.9873403906822205
115163467,2964,junrao,2017-05-08T02:04:23Z,"hmm, in the disconnected case, shouldn't we check txnstatemanager.gettransactionstate as well in case an emmigration has happened?",0,0.9869397878646851
115163478,2964,junrao,2017-05-08T02:04:41Z,"since multiple immigration/emigration could have happened when the response comes back, a more reliable way is to check if the current coordinator epoch is still the same as what's in the request.",0,0.9853261709213257
115163488,2964,junrao,2017-05-08T02:04:51Z,should we also remove the entries keyed by transactionalid in purgatory?,0,0.9922630786895752
115163567,2964,junrao,2017-05-08T02:06:01Z,"structure wise, maybe it's better to do this as part of transactionmetadata.completetransitionto() so that we can limit the place where internals of transactionmetadata are modified?",0,0.9906644821166992
115163598,2964,junrao,2017-05-08T02:06:23Z,"hmm, is this right? we watch on transactionalid, not producerid. also, since txnmarkerpurgatory is passed around to different classes, it's bit hard to track who is calling checkandcomplete on this purgatory. an alternative way is to expose an access method to txnmarkerpurgatory in transactionchannelmanager and let all classes call that method.",0,0.9819497466087341
115294821,2964,hachikuji,2017-05-08T16:43:35Z,no strong preference if you already rejected the option.,0,0.879985511302948
115317861,2964,hachikuji,2017-05-08T18:23:05Z,nit: the `toshort` is not needed.,0,0.9919018149375916
115317895,2964,hachikuji,2017-05-08T18:23:14Z,maybe we could use the `ongoing` state explicitly?,0,0.986758291721344
115320070,2964,hachikuji,2017-05-08T18:32:24Z,nit: the whole body of `handleinitpid` is misaligned.,0,0.949533998966217
115321540,2964,hachikuji,2017-05-08T18:38:41Z,"hmm.. if the user is trying to add partitions before the previous transaction has completed, shouldn't that be invalid_txn_state?",0,0.9678787589073181
115322180,2964,hachikuji,2017-05-08T18:41:26Z,nit: i think this is more than an optimization: it is necessary for correctness because there is no guarantee that the client will receive the result of the endtxnrequest.,0,0.9848030805587769
115322387,2964,hachikuji,2017-05-08T18:42:17Z,"nit: comment misaligned. also, pity we can't merge this branch with `completecommit` somehow.",-1,0.9903457760810852
115323214,2964,hachikuji,2017-05-08T18:45:52Z,"hmm... isn't it possible that a client resends an endtxnrequest while we are still in `preparecommit` or `prepareabort`. as long as the outcome matches, it seems we should accept those requests and perhaps return concurrent_transactions? also, can we list the states we're catching here explicitly?",0,0.981952965259552
115323957,2964,hachikuji,2017-05-08T18:49:13Z,maybe we should log something in the else case?,0,0.9881000518798828
115324352,2964,hachikuji,2017-05-08T18:51:00Z,"could we check for the case explicitly with `txnmanager.iscoordinatorfor(transactionalid)`? if the transactionalid did not migrate, then maybe it should be an illegal state.",0,0.9926697015762329
115325045,2964,hachikuji,2017-05-08T18:53:47Z,nit: add newline,0,0.9951523542404175
115337072,2964,hachikuji,2017-05-08T19:51:23Z,this should be `epochandmetadata.transactionmetadata`?,0,0.9957990050315857
115337702,2964,hachikuji,2017-05-08T19:54:22Z,same here: `epochandmetadata.transactionmetadata`.,0,0.9954503178596497
115338461,2964,hachikuji,2017-05-08T19:57:45Z,seems this class doesn't depend on the containing instance of `transactionmarkerchannel`. can we move it outside or to the companion object?,0,0.9917957186698914
115339106,2964,hachikuji,2017-05-08T20:01:02Z,nit: `private[transaction]`?,0,0.9927273988723755
115339988,2964,hachikuji,2017-05-08T20:05:42Z,"might be worth noting that `size` is o(n). also, maybe `queued` is redundant given the name of the class. maybe it could just be `totalrequests`?",0,0.989884614944458
115340279,2964,hachikuji,2017-05-08T20:06:54Z,could this be `private[transaction]`? also i found the name a bit misleading: would `transactionmarkerqueue` or `transactionmarkeraccumulator` be closer?,0,0.9606224894523621
115340733,2964,hachikuji,2017-05-08T20:09:05Z,maybe `brokerrequestqueues`?,0,0.9926605224609375
115350244,2964,hachikuji,2017-05-08T20:51:55Z,"it would be nice to decouple `transactionstatemanager` from `transactionmarkerchannel`. one way to do this is to move the building of the `requestandcompletionhandler` objects into `requestgenerator`. you can let `drainqueuedtransactionmarkers` return something like `map[int, list[txnidandmarkerentry]]`. then `transactionmarkerchannel` would not need a reference to `transactionstatemanager`. also, the generator pattern is a little odd. could we just make `interbrokersendthread` an abstract class with an abstract method `generaterequests`? in that case, you could let `transactionmarkerchannelmanager` extend directly from `interbrokersendthread` and implement the request generation.",0,0.9300073981285095
115351637,2964,hachikuji,2017-05-08T20:58:10Z,kind of unfortunate that we have a dependence on `networkclient` only in order to invoke this `wakeup()`. i'm wondering if the callers could do it instead and we can remove the dependence? that will help to decouple the objects which will make testing easier.,-1,0.9440057873725891
115352392,2964,hachikuji,2017-05-08T21:01:56Z,why do we do this? maybe worth a comment.,0,0.9537320137023926
115353412,2964,hachikuji,2017-05-08T21:07:07Z,also it seems like a good idea to verify that the state of the transaction is still what we expect.,0,0.8990738391876221
115353802,2964,hachikuji,2017-05-08T21:09:02Z,i think `request_timeout` might be another possibility.,0,0.9899078607559204
115354587,2964,hachikuji,2017-05-08T21:13:06Z,i wonder if you can add a comment explaining when this case can happen.,0,0.9824448227882385
115356024,2964,hachikuji,2017-05-08T21:20:23Z,sounds good. will that be part of this patch?,1,0.8151865601539612
115356574,2964,hachikuji,2017-05-08T21:23:11Z,the cast to `filerecords` is not totally safe. i fixed the same problem in `groupmetadatamanager` recently.,0,0.9775444269180298
115356894,2964,hachikuji,2017-05-08T21:24:41Z,nit: pattern match?,0,0.9841293096542358
115359708,2964,hachikuji,2017-05-08T21:37:56Z,"a cache change due to emigration/immigration would be handled by the epoch check, right? are there any cases where `completetransitionto` itself could fail?",0,0.9926349520683289
115377273,2964,guozhangwang,2017-05-08T23:25:55Z,ack.,0,0.5866091847419739
115377857,2964,guozhangwang,2017-05-08T23:30:27Z,"we could be loading for partition x while removing for partition y in this case, so waiting for the removing to complete may still take long time right? another benefit to let all three operations (loading, removing-partition, expiring-txns) to be execute by the same back ground thread is that locking mechanism would be a bit easier to reason (this is not part of this pr): only background thread would grab the write lock, and the handler thread will only try to grab read lock, and handler thread would not add / remove any entries from the maps but just modify the objects in-place.",0,0.9900859594345093
115378256,2964,guozhangwang,2017-05-08T23:33:08Z,"not sure i understand your question? `coordinatorepoch` is the value passed from the caller, which is the epoch of the cached metadata object before append is called, and here we are checking if it is still the same epoch by reading from the cache again. plus inside `completetransitionto` we also check that other fields inside metadata are expected.",0,0.9284194111824036
115378411,2964,guozhangwang,2017-05-08T23:34:33Z,ack.,0,0.5866091847419739
115378474,2964,guozhangwang,2017-05-08T23:35:07Z,ack.,0,0.5866091847419739
115378959,2964,guozhangwang,2017-05-08T23:38:52Z,"we only allow `empty` -> `empty` transition, and it is a special case for adding a txnid for the first time, the inserted entry will be empty and its pending state also empty. only when the pending state is cleared after the txn log write returns it is considered ""created succesfully"". as for this function itself, it is only used when `initpid` is received while the current pid has an ongoing txn, i.e. it is `ongoing`, and later we check if it is `ongoing` we will abort the txn first and return `concurrent_txn` to let user retry.",0,0.9931865930557251
115378997,2964,guozhangwang,2017-05-08T23:39:07Z,ack.,0,0.5866091847419739
115379242,2964,guozhangwang,2017-05-08T23:41:29Z,"that is true: when the pid is first created, there is no txn yet, the starttime is set to ""-1"", when we received the first addpartitions we will update the starttime to `now`, and it will not be updated until it has completed, and then a new addpartition is received indicating the start of a new txn for this pid.",0,0.9928902387619019
115379741,2964,guozhangwang,2017-05-08T23:45:48Z,ack.,0,0.5866091847419739
115379921,2964,guozhangwang,2017-05-08T23:47:17Z,good point! ack.,1,0.9701915383338928
115380508,2964,guozhangwang,2017-05-08T23:51:53Z,"yeah i have thought about that too.. the approach is that if we cannot locate the broker to offer to its queue then in order for this thread to return we likely need to put it in an ""unknown broker"" queue first, and periodically we can check the queue and migrate to the found brokers. does that make sense?",0,0.9731791615486145
115381202,2964,guozhangwang,2017-05-08T23:57:25Z,"i have not made up my mind about infinite timeout, and would like to have another discussion with you (as i left some comments in damian's previous patch: [a link] for now i'll add a todo marker and do that in a follow-up once we have a conclusion.",0,0.9844956398010254
115381919,2964,guozhangwang,2017-05-09T00:02:41Z,"we check that in the `appendtologcallback` callback in `txnmarkerchannelmanager`. generally speaking here is the reasoning: 1. for the handler logic, the only error code that we should not retry is ""coordinatorepochnotvalid"", in which we should complete the delayed operation immediately with a meaningful error code (currently it is always `none` ). 2. then in `appendtologcallback`, we check the error code, and if it is due to received `coordinatorepochnotvalid` we can simply ignore the rest of the operations.",0,0.9924905896186829
115382316,2964,guozhangwang,2017-05-09T00:05:42Z,"ack. i have re-factored the handling logic here to cover all the error codes, please take a look at the modified file.",0,0.9859786629676819
115382553,2964,guozhangwang,2017-05-09T00:07:44Z,"not sure i understand the comment, we are indeed canceling for the transactionalid right?",0,0.8249898552894592
115382668,2964,guozhangwang,2017-05-09T00:08:47Z,ack.,0,0.5866091847419739
115388039,2964,guozhangwang,2017-05-09T00:57:01Z,ack.,0,0.5866091847419739
115388145,2964,guozhangwang,2017-05-09T00:57:55Z,ack.,0,0.5866091847419739
115388336,2964,guozhangwang,2017-05-09T00:59:38Z,"well, since we return to the user right after we have appended the log, in which case the state has updated to `preparexx`, the client code is possible to send another `addpartitions` while the sending markers are still on the flight. in this case we should not return a fatal error but let client retry.",0,0.9925317168235779
115388370,2964,guozhangwang,2017-05-09T01:00:07Z,"okay, will update the comments.",0,0.9934709072113037
115388416,2964,guozhangwang,2017-05-09T01:00:37Z,ack.,0,0.5866091847419739
115388582,2964,guozhangwang,2017-05-09T01:02:29Z,good point! ack.,1,0.9701915383338928
115388842,2964,guozhangwang,2017-05-09T01:05:18Z,"edit: actually i think for most cases this case should be covered in `txnmetadata.pendingtransitioninprogress`, the only edge case that we have migrated to `preparexx` but have not prepareto `completexx` (note they should happen fairly consecutively). anyways, will add them to cover it as well.",0,0.9897735714912415
115389069,2964,guozhangwang,2017-05-09T01:08:13Z,ack.,0,0.5866091847419739
115389114,2964,guozhangwang,2017-05-09T01:08:46Z,"good point, ack.",1,0.7379374504089355
115536083,2964,hachikuji,2017-05-09T16:28:18Z,"ack, makes sense.",0,0.8988975286483765
115614545,2964,guozhangwang,2017-05-09T22:09:10Z,ack.,0,0.5866091847419739
115614791,2964,guozhangwang,2017-05-09T22:10:33Z,ack.,0,0.5866091847419739
115614938,2964,guozhangwang,2017-05-09T22:11:25Z,ack. this will be part of the minor refactoring that exhausts all the possible error codes in the writetxnmarker responses.,0,0.9699293971061707
115616278,2964,guozhangwang,2017-05-09T22:20:04Z,"actually i just realized we do not need to check the coordinator epoch anymore, since it is already checked in `appendtransactiontolog#updatecachecallback`, which is executed before calling this callback, so the error code returned is already reflecting the fact if [code block] so we can directly go head with the error code here.",0,0.9922835230827332
115624264,2964,guozhangwang,2017-05-09T23:17:10Z,"ack. after thinking about this, i'm going to merge the `markerchannel` into `markerchannelmanager` since it is always a one-to-one mapping.",0,0.8425467014312744
115624364,2964,guozhangwang,2017-05-09T23:17:56Z,ack.,0,0.5866091847419739
115624544,2964,guozhangwang,2017-05-09T23:19:24Z,ack.,0,0.5866091847419739
115624880,2964,guozhangwang,2017-05-09T23:21:56Z,ack.,0,0.5866091847419739
115624941,2964,guozhangwang,2017-05-09T23:22:30Z,ack. let me know wdyt about the after-refactoring.,0,0.9851779341697693
115625053,2964,guozhangwang,2017-05-09T23:23:25Z,ack.,0,0.5866091847419739
115625404,2964,guozhangwang,2017-05-09T23:26:02Z,"i'm not sure either, it is from the old code. my understanding is that `networkclient` is only pollable from the `sendthread`, and hence `wakeup` is not required. but maybe i'm missing something here, cc",0,0.9616838693618774
115628649,2964,guozhangwang,2017-05-09T23:52:22Z,rebased this already.,0,0.9933162331581116
115628821,2964,guozhangwang,2017-05-09T23:53:43Z,could you elaborate a bit? we only have logic for the `if` condition?,0,0.99016934633255
115629030,2964,guozhangwang,2017-05-09T23:55:31Z,"good point, we could consider throw exception directly instead of returning false. there are a few of those suggestions that we can do in a follow-up pr. i have marked those places with `todo`s.",1,0.8422635197639465
115636450,2964,guozhangwang,2017-05-10T01:06:03Z,"i checked the source code, `timeoutexception` can only be thrown from producer / consumer internals, but they will never be returned from the broker side. so this should not be a possibility?",0,0.9930642247200012
115643581,2964,hachikuji,2017-05-10T02:26:46Z,did you also look for uses of `errors.request_timeout`?,0,0.9952219128608704
115647476,2964,guozhangwang,2017-05-10T03:21:13Z,you mean `request_timed_out`? there is no `request_timeout` in errors. for the latter case i searched the code and found no return errors from broker-side.,0,0.9936919212341309
116116648,2964,hachikuji,2017-05-11T22:25:56Z,"after we remove `transactionmarkerchannel`, maybe we can claim its name for this class?",0,0.9917442202568054
116124062,2964,hachikuji,2017-05-11T23:17:38Z,"can we mention the partition number? also, ""may likely has emigrated"" -> ""has likely emigrated""?",0,0.9931806325912476
116124812,2964,hachikuji,2017-05-11T23:23:57Z,"if the epoch has changed, is it still necessary or safe to continue with the logic below? in particular, we could still remove the partitions from `transactionmetadata`. maybe we should just return?",0,0.9908058047294617
116125417,2964,hachikuji,2017-05-11T23:28:33Z,we discussed offline changing this to assert a valid transition instead of returning a boolean. we could do this in a follow-up if you prefer.,0,0.9950239658355713
116125544,2964,hachikuji,2017-05-11T23:29:31Z,"should we return here? otherwise, the call to `completesendmarkersfortxnid` will be invoked below. not sure it's a problem, but seems odd. also, i'm not sure i fully understand the chain of operations that this should trigger. it seems that `removemarkersfortxnid` cancels the `delayedtxnmarker`, which means its callback won't get invoked. but what happens to the state of the `transactionmetadata`? it seems like it will just remain indefinitely in one of the prepare states. for coordinatorfenced, that seems ok; we rely on the partition to ultimately be evicted. how about producerfenced? i'm actually having a tough time imagining a scenario where we would hit that error. the only one that comes to mind is if the coordinator has become a zombie, in which case we should get blocked by the coordinator epoch. are there any others? in any case, i think it would be helpful to add some comments here clarifying the scenario and the handling expectation.",0,0.7917673587799072
116155904,2964,guozhangwang,2017-05-12T05:39:45Z,"it is done already, but was not pushed somehow, could you check again now?",0,0.9942091703414917
116156002,2964,guozhangwang,2017-05-12T05:40:42Z,this call is just for removing the delayed operation in the txn marker purgatory. i think it is still safe.,0,0.9663044810295105
116156202,2964,guozhangwang,2017-05-12T05:44:07Z,"`transactionmetadata` should be removed by the emmigration handler thread, and in the future the pid expiration scheduler's thread. other handling logic should never remove the entry, but just to update the entry in-place. and about returning here: good catch! yeah we should not call `completesendmarkersfortxnid` in this case. will fix now.",1,0.8601571917533875
116312856,2964,junrao,2017-05-12T20:00:37Z,reaperenabled doesn't seem be be used.,0,0.9768841862678528
116323993,2964,junrao,2017-05-12T21:03:33Z,is appending w/o synchronization on coordinator epoch safe? we don't want to write to the log if the coordinator epoch has changed. the most reliable way is probably to hold a read lock on transactionstatemanager.statelock() while doing the log append.,0,0.9933295249938965
116338170,2964,junrao,2017-05-12T22:54:25Z,"hmm, not sure if this is completely safe. in removetransactionsfortxntopicpartition(), we modify loadingpartitions in the scheduler and here, we modify loadingpartitions in the method directly. this means that if an emmigration is followed immediately by an immigration, the updating of loadingpartitions by emmigration could happen after the updating of loadingpartitions by immigration, which will leave the state incorrect.",0,0.7529195547103882
116339508,2964,junrao,2017-05-12T23:08:39Z,"the issue of changing the transaction states in the scheduler is that when this call returns, the new transaction states are not necessarily reflected. so, another request after this call may still see the old states?",0,0.9871030449867249
116340857,2964,junrao,2017-05-12T23:24:13Z,"txnmarkerpurgatory registers each item under transactionalid and txntopicpartition. we are only removing the item registered under transactionalid. so, which process will be removing the item registered under txntopicpartition, especially the reaper thread is not running in txnmarkerpurgatory?",0,0.9935630559921265
116342175,2964,junrao,2017-05-12T23:42:41Z,"since we always send none as error in delayedtxnmarker, it seems that we can just get rid of error?",0,0.9910106658935547
116343892,2964,junrao,2017-05-13T00:10:43Z,"yes, it's just that in the case that a transaction coordinator's epoch has changed, there is no need to keep resending the writemarker request to the brokers.",0,0.992421567440033
116638694,2964,guozhangwang,2017-05-16T01:44:41Z,ack.,0,0.5866091847419739
116638797,2964,guozhangwang,2017-05-16T01:46:02Z,"yup, it is going to be done in the locking pr that i'm also working on now. just trying to keep each pr small to make it easier for reviews.",0,0.986548125743866
116638956,2964,guozhangwang,2017-05-16T01:47:58Z,good catch! ack.,1,0.9963363409042358
116639242,2964,guozhangwang,2017-05-16T01:51:08Z,it is in the `transactionmarkerchannelmanager#removemarkersfortxntopicpartition`.,0,0.9955293536186218
116639395,2964,guozhangwang,2017-05-16T01:52:49Z,"hmm that is right, but i feel we will probably need to add other possible error codes as we as fixing various error cases under integration tests, so i'd rather keep it as is for now. if after exactly-once has been quite stable and we still do not have any other error code we can remove it. but let mw add a todo for now in case we forgot..",0,0.9249856472015381
116650638,2964,guozhangwang,2017-05-16T03:53:57Z,makes sense. i will add the check.,0,0.9875800013542175
116653014,2964,guozhangwang,2017-05-16T04:29:03Z,"got it. however, if we just do the removal in the handler thread, then the immigrate-then-emigrate issue may occur. on the other hand, we cannot depend on scheduler do not have pending request since we are periodically schedule txn-expiration and pid-expiration with that scheduler as well. so here is what i will do: add a removal partitions which will be modified in the handler thread, then get txn metadata will check if the txn partition is in the removal partitions set. then in the locking pr, i will add the read-write-lock so that checking will be monitored by the read lock. wdyt?",0,0.9114571809768677
79560389,1884,dguy,2016-09-20T08:35:42Z,private?,0,0.990565836429596
79560800,1884,dguy,2016-09-20T08:38:32Z,"delegate to the other constructor: `this(config, 0, window_change_log_additional_retention_default)`",0,0.9942743182182312
79562570,1884,dguy,2016-09-20T08:49:18Z,if the topic exists we need to make sure the number of partitions is the same. if it isn't the same then we should throw an exception.,0,0.9914695620536804
79563507,1884,dguy,2016-09-20T08:54:49Z,doesn't look like this method is used anywhere?,0,0.9895786643028259
79566464,1884,dguy,2016-09-20T09:12:18Z,is this needed? it is not used anywhere,0,0.9950946569442749
79566488,1884,dguy,2016-09-20T09:12:26Z,as above,0,0.9888283014297485
79566646,1884,dguy,2016-09-20T09:13:21Z,this doesn't need to be a field. could be a local in the constructor,0,0.9943557977676392
79566686,1884,dguy,2016-09-20T09:13:42Z,as above,0,0.9888283014297485
79566702,1884,dguy,2016-09-20T09:13:50Z,as above,0,0.9888283014297485
79567055,1884,dguy,2016-09-20T09:15:58Z,"nit: using an instance variable to reference a static. should be: `this.metadata = new metadata(streamsconfig.getlong(streamsconfig.retry_backoff_ms_config), streamsconfig.getlong(streamsconfig.metadata_max_age_config));`",0,0.9943978786468506
79568023,1884,dguy,2016-09-20T09:21:29Z,should this just use `streamsconfig.metric_reporter_classes_config`? and then i don't see why we need line 100,0,0.9913423657417297
79568120,1884,dguy,2016-09-20T09:22:09Z,`streamsconfig.connections_max_idle_ms_config`,0,0.993882417678833
79568305,1884,dguy,2016-09-20T09:23:19Z,"as above. next 4 lines should use the class to reference static fields, i.e., `streamsconfig.reconnect_backoff_ms_config`",0,0.995442271232605
79568817,1884,dguy,2016-09-20T09:25:55Z,`private static final max_iterations` ?,0,0.9948698282241821
79569302,1884,dguy,2016-09-20T09:28:55Z,nit: my preference is that all immutable parameters and fields are `final`. so: `streamskafkaclient(final streamsconfig streamsconfig)` and below: `final time time = ...` etc,0,0.9936297535896301
79569654,1884,dguy,2016-09-20T09:31:03Z,"should we make this into a final static field? i.e., `max_inflight_requests` or similar? i.e., what is 100?",0,0.9935458302497864
79569944,1884,dguy,2016-09-20T09:32:32Z,"what is the 0 for? can we make it into a static final field, so it has a name?",0,0.992198646068573
79570181,1884,dguy,2016-09-20T09:33:38Z,do we need this? don't think it is used anywhere,0,0.9909963607788086
79570479,1884,dguy,2016-09-20T09:35:10Z,"i don't currently see this being used anywhere. is it going to cause shutdown problems if this isn't closed properly? i.e., will there be non-daemon threads hanging around that cause the jvm to not shutdown?",0,0.9767296314239502
79570684,1884,dguy,2016-09-20T09:36:23Z,`if (...) { .. }`,0,0.9898003935813904
79570848,1884,dguy,2016-09-20T09:37:04Z,this should probably throw `streamsexception` as that is the top-level exception for streams,0,0.9921128749847412
79571533,1884,dguy,2016-09-20T09:40:52Z,we should change `internaltopicconfig.toproperties(...)` to return a `map ` then we won't need to copy the properties into the `topicconfig` map below,0,0.9946480393409729
79571804,1884,dguy,2016-09-20T09:42:36Z,"nit: as mentioned above. my preference is for params and locals to be final if possible. i know it i adds few extra characters, but it shows intent and can prevent unnecessary bugs",0,0.9395110011100769
79571936,1884,dguy,2016-09-20T09:43:23Z,move this down to line 149 and do the init and assignment on a single line,0,0.9938802719116211
79572482,1884,dguy,2016-09-20T09:46:38Z,i don't think you need this callback. you can just pass `null` if the callback isn't necessary,0,0.9891077280044556
79573826,1884,dguy,2016-09-20T09:53:54Z,it would be good if we could say why it failed. is there a mapping from the error code to a string we could use?,0,0.9803953766822815
79573949,1884,dguy,2016-09-20T09:54:37Z,do we need this method?,0,0.9944741129875183
79575520,1884,dguy,2016-09-20T10:02:57Z,i don't think this should be a field. it probably needs to be done before each request as 1. the least loaded node will change. 2. this node might not be up when the request is made.,0,0.972206711769104
79576598,1884,dguy,2016-09-20T10:08:42Z,perhaps maxiterations should be a timeout instead? also i think it reads cleaner like so: [code block],0,0.9890214800834656
79576919,1884,dguy,2016-09-20T10:10:44Z,as above we should probably change `maxiterations` for a timeout,0,0.9943530559539795
79577022,1884,dguy,2016-09-20T10:11:19Z,why not just re-use the `systemtime` from above?,0,0.987824559211731
79577074,1884,dguy,2016-09-20T10:11:44Z,do we need this? it isn't used anywhere.,0,0.9832005500793457
79577318,1884,dguy,2016-09-20T10:13:16Z,move this down to line 279,0,0.9942398071289062
79577973,1884,dguy,2016-09-20T10:17:14Z,nit: looks like the formatting has been unnecessarily changed.,-1,0.7574735879898071
79578001,1884,dguy,2016-09-20T10:17:27Z,nit: formatting?,0,0.9400174021720886
79578105,1884,dguy,2016-09-20T10:18:09Z,do we need this? i don't think we ever delete topics? also the test is commented out,0,0.991236686706543
79578334,1884,dguy,2016-09-20T10:19:20Z,test commented out. also we may not need this if we merge `streamskafkaclient` and `internaltopicmanager` into a single class.,0,0.9933504462242126
79650885,1884,hjafarpour,2016-09-20T16:16:12Z,"yes, made it private :)",0,0.9541619420051575
79650926,1884,hjafarpour,2016-09-20T16:16:26Z,removed this constructor.,0,0.9932168126106262
79652102,1884,hjafarpour,2016-09-20T16:22:05Z,added the check for the number of partitions.,0,0.9949377775192261
79652577,1884,hjafarpour,2016-09-20T16:24:21Z,made them local in the constructor.,0,0.9931179285049438
79652760,1884,hjafarpour,2016-09-20T16:25:17Z,"they were there from the previous iteration. not being used anymore, removed them.",0,0.9916704893112183
79655027,1884,hjafarpour,2016-09-20T16:35:23Z,i used the similar way of creating networkclient in kafkaconsumer. for the streamkafkaclient i can make it a constant as you mentioned. it would be good to update the kafkaconsumer too.,0,0.9915367364883423
79655809,1884,hjafarpour,2016-09-20T16:38:26Z,"yes, corrected them.",0,0.9872803092002869
79656213,1884,hjafarpour,2016-09-20T16:40:12Z,"good point, moved it to the request method as a local variable.",1,0.9150022268295288
79657266,1884,hjafarpour,2016-09-20T16:44:47Z,we were thinking about having streamskafkaclient available for other uses too. i'm removing this for now and we can add it later if we need it.,0,0.9928672313690186
79657548,1884,hjafarpour,2016-09-20T16:46:06Z,this was here from the previous version and i kept it. i'm going to remove it now since it is not being used.,0,0.988935649394989
79658172,1884,hjafarpour,2016-09-20T16:49:07Z,that's a good practice. made all of the params that won't change final.,1,0.9829943180084229
79659263,1884,hjafarpour,2016-09-20T16:54:20Z,made it null.,0,0.981295645236969
79659681,1884,hjafarpour,2016-09-20T16:56:25Z,i could get the error name or message. i am adding error name to the message.,0,0.99424147605896
79659793,1884,hjafarpour,2016-09-20T16:56:59Z,it's not being used but we can have it in the streamskafkaclient for future use.,0,0.9925156235694885
79666863,1884,hjafarpour,2016-09-20T17:28:40Z,changed them to timeouts.,0,0.9785705208778381
79667197,1884,hjafarpour,2016-09-20T17:30:15Z,needed for checking the partition number.,0,0.9893984794616699
79667509,1884,hjafarpour,2016-09-20T17:31:26Z,i'm removing these tests then.,0,0.9921029210090637
79777362,1884,dguy,2016-09-21T07:54:43Z,i'd probably use the same importance level as was used in the consumer or producer config,0,0.9913069605827332
79777945,1884,dguy,2016-09-21T07:58:22Z,"i know i said make this private... looking again it isn't actually used anywhere apart from the constructor, so it can be removed.",0,0.9841008186340332
79778569,1884,dguy,2016-09-21T08:02:37Z,"i have a pr to remove this method, [a link] as it is unused. if you want to remove it i'll close the pr? also, if you do remove it then you can also remove line 37. edit: sorry the pr was merged before i'd seen your update.",-1,0.9757264256477356
79779302,1884,dguy,2016-09-21T08:07:32Z,"a better way to do this would be to pass in the streamskafkaclient, i.e., `public internaltopicmanager(final streamskafkaclient streamskafkaclient, final int replicationfactor, final long windowchangelogadditionalretention)` why? well the `streamsconfig` is only used to construct the `streamskafkaclient` and it would mean in unit tests we can pass in a stub or mock for `streamskafkaclient`. we can then remove the no-arg constructor on line 60 (it is only used in `mockinternaltopicmanager`)",0,0.9932239055633545
79782495,1884,dguy,2016-09-21T08:27:12Z,"strictly not part of this pr, but might as-well make these params `final` :-)",1,0.5046637654304504
79783003,1884,dguy,2016-09-21T08:29:39Z,`final`,0,0.9897204041481018
79785267,1884,dguy,2016-09-21T08:42:57Z,"i'm thinking in `streamskafkaclient.gettopicmetadata(..)` we could just return the `metadataresponse.topicmetadata` regardless of the `error().code()`. so then i think we will never get `null` here as i believe we will always get a response. we can then throw an exception with a more meaningful message, i.e., based on the `error().code()` - rather than just ""topic metadata is corrupted""",0,0.9851188063621521
79785576,1884,dguy,2016-09-21T08:44:40Z,looks like this can be a local now?,0,0.9921663999557495
79785702,1884,dguy,2016-09-21T08:45:29Z,"again, i'd make all the immutable locals `final` - it is a good habit to get into. so, `metricstags`, `metadata`, `metricconfig`, `reporters`, `channelbuilder`, `selector`",0,0.971595048904419
79786661,1884,dguy,2016-09-21T08:50:25Z,"again, `final` for all locals. also, as per my previous comment on this. i think we should change `internaltopicconfig.toproperties(...)` to return `map ` and then we don't need to copy the props into another `map`",0,0.9935659766197205
79787573,1884,dguy,2016-09-21T08:55:18Z,i still think if this is not being used anywhere we should remove it. if we really want to keep it then we need a test for it.,0,0.9590027332305908
79787831,1884,dguy,2016-09-21T08:56:41Z,"""deleting topic {} from brokers ..."" ?",0,0.9935287833213806
79787999,1884,dguy,2016-09-21T08:57:38Z,we can make all of these locals `final`,0,0.9939249157905579
79788308,1884,dguy,2016-09-21T08:59:11Z,"maybe we should make this a better name, like `readytimeout` ?",0,0.9851099252700806
79788383,1884,dguy,2016-09-21T08:59:40Z,"same here, maybe sth like: `requesttimeout`",0,0.9944566488265991
79788859,1884,dguy,2016-09-21T09:02:16Z,"probably need a more descriptive message, i.e., ""timed out waiting for node="" + brokernode + "" to become available""",0,0.9865850210189819
79789101,1884,dguy,2016-09-21T09:03:54Z,"i think this is more like: ""failed to get response from node="" + brokernode + "" within timeout""",0,0.9839358329772949
79789452,1884,dguy,2016-09-21T09:06:15Z,we can remove this as the callback isn't required. we can also remove the `callback` param from `sendrequest(..)` as we don't need it.,0,0.9956955909729004
79789680,1884,dguy,2016-09-21T09:07:42Z,"private? is only used in this class, so there is no need to make it public. also, as per comment below, we can probably remove the `callback` arg as we don't really need it, i.e., we can just pass `null` for the callback.",0,0.9936502575874329
79790026,1884,dguy,2016-09-21T09:10:00Z,see my comment above in `internaltopicmanager`; we can probably just return the matching `metadataresponse.topicmetadata` instance here. as far as i know it will never be null. if we don't find one then we should probably throw an exception,0,0.9924564361572266
79790100,1884,dguy,2016-09-21T09:10:25Z,`final` locals...,0,0.9916748404502869
79790238,1884,dguy,2016-09-21T09:11:16Z,`final` param and locals,0,0.9944148063659668
79790517,1884,dguy,2016-09-21T09:13:01Z,"`props.put(consumerconfig.key_deserializer_class_config, serdes.string().deserializer().getclass())` same on next line",0,0.9939162135124207
79790921,1884,dguy,2016-09-21T09:15:01Z,nit: `new kafkaconsumer<>(props);`,0,0.9938483834266663
79791157,1884,dguy,2016-09-21T09:16:14Z,"nit: formatting i.e., `for (string topicnameinlist : topics.keyset())`",0,0.9938269257545471
80079829,1884,hjafarpour,2016-09-22T16:21:32Z,changed it to medium.,0,0.9782701730728149
80080356,1884,hjafarpour,2016-09-22T16:24:26Z,removed it.,0,0.9840505719184875
80080581,1884,hjafarpour,2016-09-22T16:25:36Z,"removed it, please close the pr.",0,0.9936684966087341
80081058,1884,hjafarpour,2016-09-22T16:28:15Z,"good point, made the change accordingly!",1,0.9893825054168701
80081221,1884,hjafarpour,2016-09-22T16:29:01Z,they are final now :),0,0.9865971207618713
80082570,1884,hjafarpour,2016-09-22T16:36:00Z,"made the change, include error code in the message.",0,0.9932946562767029
80082828,1884,hjafarpour,2016-09-22T16:37:24Z,"yes, after the previous changes it only is used in one method. changed it to local.",0,0.9942091703414917
80083158,1884,hjafarpour,2016-09-22T16:39:06Z,all are final now :),0,0.9767441749572754
80083950,1884,hjafarpour,2016-09-22T16:43:10Z,the method is being used in quite a few tests too. if i change it i should change those tests too. do you want me to go ahead and make the change?,0,0.9917998909950256
80084032,1884,hjafarpour,2016-09-22T16:43:33Z,removed it.,0,0.9840505719184875
80084885,1884,hjafarpour,2016-09-22T16:48:09Z,made the change!,0,0.9768004417419434
80200474,1884,dguy,2016-09-23T08:21:18Z,can remove this as it is no longer used,0,0.9950351715087891
80200580,1884,dguy,2016-09-23T08:22:06Z,`final` params?,0,0.9946451187133789
80204324,1884,dguy,2016-09-23T08:47:49Z,"i think we can remove this constructor now. it is only used in the constructor of `mockinternaltopicmanager`. so, we could change the `mockinternaltopicmanager` constructor to also take a `streamsconfig` as a param. the `streamsconfig` could be minimal, i.e, just `application_id_config` and `bootstrap_servers_config` would need to be set. then in `mockinternaltopicmanager` constructor we just do: `super(new streamskafkaclient(streamsconfig), 0, 0)` and then we can remove this constructor as it is not needed. also means we can mark `streamskafkaclient` on line 39 as `final`",0,0.9805086255073547
80204544,1884,dguy,2016-09-23T08:48:56Z,is there a mapping from the `short` code to a string somewhere?,0,0.9944661259651184
80204699,1884,dguy,2016-09-23T08:49:56Z,can remove this todo as we need these 2 config properties. all the others have been removed.,0,0.9956827163696289
80205835,1884,dguy,2016-09-23T08:57:19Z,can remove this as it is not used.,0,0.9947304725646973
80206000,1884,dguy,2016-09-23T08:58:35Z,`final`,0,0.9897204041481018
80206022,1884,dguy,2016-09-23T08:58:43Z,`final`,0,0.9897204041481018
80207103,1884,dguy,2016-09-23T09:06:04Z,`final`,0,0.9897204041481018
80207117,1884,dguy,2016-09-23T09:06:12Z,`final`,0,0.9897204041481018
80207158,1884,dguy,2016-09-23T09:06:30Z,`final`,0,0.9897204041481018
80207228,1884,dguy,2016-09-23T09:07:00Z,`final`,0,0.9897204041481018
80207325,1884,dguy,2016-09-23T09:07:37Z,`collections.singletonlist(topic)`,0,0.9935643076896667
80213799,1884,dguy,2016-09-23T09:48:38Z,"it would be great if you do, but we can probably do it as another pr if you'd prefer. up to you",1,0.9780687093734741
80285978,1884,hjafarpour,2016-09-23T17:10:59Z,removed it.,0,0.9840505719184875
80286072,1884,hjafarpour,2016-09-23T17:11:32Z,removed it.,0,0.9840505719184875
80288512,1884,hjafarpour,2016-09-23T17:25:49Z,"couldn't find it in the docs. in the code we have ""org.apache.kafka.common.protocol.errors"". i can also print message() or exceptionname() instead of the code. adding the message().",0,0.9880293011665344
80288656,1884,hjafarpour,2016-09-23T17:26:32Z,removed it.,0,0.9840505719184875
80295804,1884,dguy,2016-09-23T18:03:55Z,do we need to add the `jmxreporter` here? the `todo` suggest we should be doing something differernt,0,0.9943128824234009
80505313,1884,hjafarpour,2016-09-26T15:42:06Z,"in kafkastreams.java jmx_prefix is defined private: private static final string jmx_prefix = ""kafka.streams""; i could either make it public and use it here or define a new field here. which one would you suggest?",0,0.9934508800506592
80983996,1884,guozhangwang,2016-09-28T18:19:59Z,do we still need this since we already have `testcompile project(':core')` in line 704 which should bring in zkclient jars transitively?,0,0.9948668479919434
80986713,1884,guozhangwang,2016-09-28T18:32:04Z,"nit: instead of declaring a new doc variable, could we just refer to `commonclientconfigs.xxx_doc` in the `.define`?",0,0.9937703013420105
80987096,1884,guozhangwang,2016-09-28T18:33:35Z,we could use a smaller default value as this is only used for admin requests that are mostly small.,0,0.9913732409477234
80987442,1884,guozhangwang,2016-09-28T18:35:14Z,`final`,0,0.9897204041481018
80987926,1884,guozhangwang,2016-09-28T18:37:27Z,are these two props `cleanup_policy_prop` and `retention_ms` used anywhere any more?,0,0.9937688708305359
80990290,1884,guozhangwang,2016-09-28T18:48:09Z,also should we remove `zookeeper_connect_config` above as well?,0,0.9955814480781555
80990884,1884,guozhangwang,2016-09-28T18:50:49Z,"in there future we will have an `adminclient` as part of completing kip-4 which is used for all such admin requests, and that can be used in kstream, kconnect, replicator, mm, etc. and whoever is about to implementing it would be suggested to borrow from this class. so i think it is ok to keep it as is for internals, and replacing it with the `adminclient` in the future.",0,0.9743667840957642
80992348,1884,guozhangwang,2016-09-28T18:57:47Z,"currently the embedded client: producer, consumer, and admin, have their own metrics and reporters, and we are only correlating them with the `clientid` in the tags. it is better to be improved with hierarchical metrics moving forward. for now i think we can just follow this way but change the prefix in `jmxreporter` from `kafka.streams` to `kafka.admin`?",0,0.9876582026481628
80992958,1884,guozhangwang,2016-09-28T19:00:21Z,the comment is a bit misleading: `polls the request for a given number of iterations to receive the response.` isn't it `keep polling until the corresponding response is received`?,0,0.7621808052062988
80996029,1884,guozhangwang,2016-09-28T19:16:18Z,"if the broker node is not ready, should we consider picking a different broker instead of tie-ing up one thread doing the while loop here?",0,0.9909183979034424
80996757,1884,guozhangwang,2016-09-28T19:20:27Z,"is it a good behavior that we are simply dropping all other responses on the floor while waiting for the corresponding response? i think today we will not encounter such issues since we always send one request, and block on its response and then send another one. but this is less efficient since with n topics to create we have to go n round trips now, suppose moving forward we will do that in a more batched manner where multiple in-flight requests exist, then i this will be an issue. so instead of checking if the response, could we use the `requestcompletionhandler` interface with sth. similar to consumer where we poll until the handler set the `future` indicating it is received and processed?",0,0.9531236290931702
80996887,1884,guozhangwang,2016-09-28T19:21:07Z,"using another temporary consumer is very inefficient, could we just use `listoffsetrequest` with the admin client here?",0,0.9373130798339844
81010527,1884,guozhangwang,2016-09-28T20:33:33Z,"related to the comment below: since only one request is sent at a time, the `leastloadednode` function is not taking any load into consideration actually; so i think we could just iterate over the nodes and find one that is ready, and if all destination nodes are not ready, backoff based on the configured value and retry again.",0,0.9897513389587402
81013284,1884,dguy,2016-09-28T20:46:42Z,will sending `listoffsetrequest` result in creating the topic when `auto.topic.create` is true?,0,0.9941356182098389
81014530,1884,guozhangwang,2016-09-28T20:52:50Z,"sorry i meant `metadatarequest`, not `listoffsetrequest`. if you specify the topics to be the empty list (i.e. `all_topics_request`), then the broker will not create any topics even with `auto.topic.create` is true.",-1,0.9634218811988831
81044949,1884,mjsax,2016-09-29T00:22:36Z,"this class is still there. i did not follow the whole discussion, but i agree with that we might want to remove this class... what is the reason for keeping it?",0,0.9114146828651428
81047430,1884,guozhangwang,2016-09-29T00:47:43Z,"in `streampartitionassignor`, there is a while loop checking that the metadata has been refreshed with the right number of partitions: [code block] which is error-prone. could we remove that logic and check that the topic metadata has propagated to to the broker with the same `streamskafkaclient.topicexists(topic.name()`, i.e.: [code block]",0,0.9769317507743835
81047544,1884,guozhangwang,2016-09-29T00:48:38Z,just fyi and i found the original while-loop may be the culprit of the recent unit test hanging issue.,0,0.9904373288154602
81155529,1884,enothereska,2016-09-29T14:52:59Z,so we still need to connect to zookeeper directly to do this verification? we can't get rid of the zk dependency in tests?,0,0.992384135723114
81163558,1884,dguy,2016-09-29T15:25:40Z,it is a combination of that and auto topic creation,0,0.9929596781730652
84377963,1884,guozhangwang,2016-10-20T21:18:21Z,"can we merge these two functions `filterexistingtopics` and `gettopicstobedeleted` into a single one, or just in-line this logic in the `makeready` function as this seems specific in the internaltopicmanager, not in the kafkaclient.",0,0.992534875869751
84378019,1884,guozhangwang,2016-10-20T21:18:43Z,this function seems not used any more.,0,0.9898843765258789
84378082,1884,guozhangwang,2016-10-20T21:19:06Z,ditto below.,0,0.9935641884803772
84378389,1884,guozhangwang,2016-10-20T21:21:11Z,this can be private.,0,0.9921234250068665
84378437,1884,guozhangwang,2016-10-20T21:21:27Z,not used any more.,0,0.9685444235801697
84378526,1884,guozhangwang,2016-10-20T21:22:03Z,not used any more.,0,0.9685444235801697
84378580,1884,guozhangwang,2016-10-20T21:22:22Z,the function name needs to be updated to `createtopics`.,0,0.9952316880226135
84379587,1884,guozhangwang,2016-10-20T21:28:19Z,"do we want to use the same value for `networkclient.poll()` timeout, and as well as the timeout value of `create/deletetopic` requests? in addition the `max_wait_time_ms` is 30 seconds which is even lower than the default value of timeout, so it is likely that the `client.poll()` will not return even when `max_wait_time_ms` has elapsed.",0,0.9921823143959045
84737925,1884,hjafarpour,2016-10-24T17:24:12Z,pushed a new version with the updates you mentioned.,0,0.9940623641014099
94757625,1884,ijuma,2017-01-05T12:12:49Z,we should not add this file back. we removed it intentionally.,0,0.9891654849052429
94757650,1884,ijuma,2017-01-05T12:13:06Z,we should not add this file back. we removed it intentionally.,0,0.9891654849052429
94757707,1884,ijuma,2017-01-05T12:13:39Z,is this dependency still needed? the comment seemed to imply that it wasn't.,0,0.981052577495575
94758189,1884,ijuma,2017-01-05T12:17:50Z,"instead of instantiating `systemtime`, `time.system` should be used. same applies for other instances where we are creating `systemtime` instances.",0,0.9949371814727783
95036491,1884,guozhangwang,2017-01-06T23:04:12Z,i think `jackson` is not needed either since it was only for json parsing.,0,0.9884584546089172
95036696,1884,guozhangwang,2017-01-06T23:06:15Z,you mean we should just inline this class inside `streampartitionassignor`? personally i feel that class is already quite large and the functionalities in this class is self-contained.,0,0.9836384057998657
95036764,1884,guozhangwang,2017-01-06T23:06:53Z,can be private.,0,0.989679217338562
95036888,1884,guozhangwang,2017-01-06T23:08:00Z,better add a log entry here since otherwise the error message in `streamsexception` will never be shown anywhere.,0,0.991510272026062
95037077,1884,guozhangwang,2017-01-06T23:09:48Z,can we just inline this function in the other `makeready` since its only caller is the other function?,0,0.9948347806930542
95037147,1884,guozhangwang,2017-01-06T23:10:18Z,can be private.,0,0.989679217338562
95037232,1884,guozhangwang,2017-01-06T23:11:02Z,"why not catch exceptions thrown here as well? also we should move it as well as the metadata fetching requests (line 60 - 63) inside the retry block as well since each time we retry, the metadata may have changed, right?",0,0.9916336536407471
95037434,1884,guozhangwang,2017-01-06T23:13:04Z,nit: this line not needed.,0,0.9819594025611877
95038339,1884,guozhangwang,2017-01-06T23:22:14Z,"i think this is not a good pattern, since afaik unlike the other clients the only `throwable` is actually `ioexception` (your error message also indicates that doesn't it :p `kafkastreamclient`), and it is only thrown from the metricsreporter.close(), capturing all throwable may hide some issues. instead, we can just let `internaltopicmanager.close()` to capture and log if there is any `ioexception` and not throw it all the way here.",1,0.9078872799873352
95038406,1884,guozhangwang,2017-01-06T23:22:46Z,could you reply to this comment as well?,0,0.9940430521965027
95038495,1884,guozhangwang,2017-01-06T23:23:42Z,btw i think this class will eventually be merged into o.a.k.common admin package when kip-4 is completed. cc,0,0.9886444807052612
95039652,1884,hjafarpour,2017-01-06T23:35:28Z,deleted the file!,0,0.9892429113388062
95039666,1884,hjafarpour,2017-01-06T23:35:37Z,deleted the file.,0,0.9903954863548279
95039719,1884,hjafarpour,2017-01-06T23:35:59Z,"removed the line ""compile libs.jacksondatabind"".",0,0.9945600628852844
95039868,1884,hjafarpour,2017-01-06T23:37:29Z,replaced it with time.system.,0,0.994866132736206
95040218,1884,hjafarpour,2017-01-06T23:41:29Z,done!,1,0.6799882054328918
95040389,1884,hjafarpour,2017-01-06T23:43:19Z,good point! moved all in the try/catch block.,1,0.994874894618988
95040644,1884,ijuma,2017-01-06T23:46:09Z,", yeah, we will have to refactor it to make it more generic, but good to have non-test code using the protocol. :)",1,0.9912573099136353
95040864,1884,hjafarpour,2017-01-06T23:48:44Z,added a log message.,0,0.9949512481689453
95041682,1884,hjafarpour,2017-01-06T23:57:25Z,handling the io exception in internaltopicmanager.close() now.,0,0.9941055774688721
95678659,1884,xvrl,2017-01-11T21:42:16Z,"this breaks backwards compatibility. until now streams did not delete existing topics. until streams offers a way to configure partition count and min.isr for internal topics, it should never attempt to delete topics. even then it might be dangerous to delete existing topics without warning.",-1,0.6151716709136963
95980233,1884,enothereska,2017-01-13T11:34:33Z,i noticed this path is gone from the new code.,0,0.9878454804420471
96026577,1884,guozhangwang,2017-01-13T16:38:25Z,"i thought wrote it down on the kip wiki but seems he's not, we discussed about this issue while proposing kip-90. the problem is that even in the case that existing number of partitions is less than expected, we can not safely add partitions and reuse the existing ones for repartition topics or changelog topics, due to hashing.",0,0.9714367389678955
96035255,1884,mjsax,2017-01-13T17:27:38Z,this is an issue that we did miss. :(,-1,0.9960546493530273
203197427,5379,stanislavkozlovski,2018-07-17T22:08:12Z,"`scrammessages`'s value regex is `""[\\x01-\\x7f&&[^,]]+""`. i tried using it but could not get my tests to pass. to be frank, i don't understand it at all. specifically the `&&[^,]` part. [a link] says but i doubt that that is the case, otherwise i think scram would not work as well. is this some feature in the java regex engine i'm not familiar with?",-1,0.7033445835113525
203203016,5379,stanislavkozlovski,2018-07-17T22:34:53Z,"i kind of want to have this in a more general space where every saslclient will have this code. an idea could be extend the saslclient interface and provide this default method, or move it to some utils resource. i'm not sure if it is worth the effort.",0,0.530214786529541
204061226,5379,rondagostino,2018-07-20T14:23:35Z,"is the returned map supposed to be modifiable or unmodifiable? the default value (set via collections.emptymap) is unmodifiable. but if someone sets the map it isn't copied, so whether it will be modifiable or unmodifiable is non-deterministic. i think it would be best to state in the javadoc that the returned map is always unmodifiable, and when setting the map the input map should be copied and wrapped so as to be unmodifiable.",0,0.9893884062767029
204063618,5379,rondagostino,2018-07-20T14:30:45Z,"i would be careful to state that ""you can also add custom unsecured sasl extensions when using the default, builtin{ authenticatecallbackhandler} implementation using..."" because it is really the authenticatecallbackhandler instance that determines what kinds of callbacks are supported rather than this class itself.",0,0.9849061369895935
204066800,5379,rondagostino,2018-07-20T14:40:10Z,"the token and the extensions must not be added until commit() is called as per the jaas specification. i would add a field ""extensionsrequiringcommit"" to mirror how the token is handled between the login() and commit() methods. also, note that this loginmodule supports calling commit() when the subject is shared with another instance of this class associated with a separate logincontext and that other instance has not yet had its logout() method called (see the last paragraph of the javadoc for details). you will need to support this for the extensions as well as for the token. you can mirror the existing code for the token and treat the extensions the same way. failure to do this will result in the extensions being deleted from the subject when the original logincontext has its logout() method called.",0,0.9933592677116394
204068531,5379,rondagostino,2018-07-20T14:45:35Z,"also, i am wondering if maybe we shouldn't simply attach a map to the public credentials but should instead attach something more precise and fit-for-purpose. the reason is because once we attach a map we can't ever use a map on the public credentials again; if we wanted to attach something else in the future it could not implement map. map is very broad and limits flexibility in the future. i am wondering if we should make the saslextensions class part of the public api and make it immutable. then we can attach an instance of that class specifically rather than just a map and we don't constrain ourselves going forward. what do you think? saslextensionscallback would return a saslextensions instance instead of a map if we decide to do this, and it also removes the confusion about the modifiability/immutabililty of what saslextensionscallback actually returns -- it will always be immutable.",0,0.942912220954895
204070121,5379,rondagostino,2018-07-20T14:50:10Z,copy the map and store it immutably?,0,0.9948511719703674
204071530,5379,rondagostino,2018-07-20T14:54:20Z,don't need both properties and saslextension -- probably just saslextensions.,0,0.989717960357666
204073705,5379,rondagostino,2018-07-20T15:00:49Z,please update javadoc for the class to also state that the instance of { authenticatecallbackhandler} can optionally handle an instance of { saslextensionstokencallback} to return any extensions generated by the { login()} event on the { logincontext}.,0,0.9950082302093506
204074321,5379,rondagostino,2018-07-20T15:02:43Z,typically catch exception rather than throwable since error generally should not be caught as it denots an event that the code can't really do anything about.,0,0.9696545004844666
204074903,5379,rondagostino,2018-07-20T15:04:34Z,is there a reason to return the callback? i would think the calling code is interested in the extensions themselves rather than the callback.,0,0.9917036294937134
204075829,5379,rondagostino,2018-07-20T15:07:37Z,please update javadoc to state that this class also recognizes { saslextensionscallback} and retrieves any sasl extensions that were created when the { oauthbearerloginmodule} logged in by looking for an instance of { map} in the { subject}'s public credentials. (or an instance of saslextensions rather than a map if we decide to make saslextensions part of the public api),0,0.994752049446106
204076627,5379,rondagostino,2018-07-20T15:10:19Z,"can you name this in the same way as handlecallback(oauthbearertokencallback) -- i.e. handlecallback(saslextensionscallback)? unless there is a reason to do it differently? maybe you are foreshadowing a move of the method onto the oauthbearerloginmodule class at some point? if so, then maybe make the method static, name it handlecallback(), and make the handlecallback(oauthbearertokencallback) symmetric by also accepting a subject parameter? i think there is value in making the two methods look very much the same except for the type of callback they accept, so whichever you decide let's make them look the same as much as possible.",0,0.9871664643287659
204080059,5379,rondagostino,2018-07-20T15:21:26Z,"it is possible that the extensions could be set and then the process() method either returns an error response to the client or throws an exception. it probably isn't too much of an issue if this happens, but best to set the extensions at the same point where tokenfornegotiatedproperty is set, so probably should add the extensions as a new parameter on the process() call.",0,0.9905036091804504
204082009,5379,rondagostino,2018-07-20T15:27:35Z,"probably good to state above ""a { callbackhandler} that recognizes { oauthbearertokencallback} to return an unsecured oauth 2 bearer token and { saslextensionscallback} to return sasl extensions.""",0,0.9898708462715149
204088230,5379,stanislavkozlovski,2018-07-20T15:47:49Z,should be unmodifiable come to think of it. updated docs and code,0,0.9931920170783997
204088701,5379,stanislavkozlovski,2018-07-20T15:49:24Z,agreed,0,0.9598594307899475
204091548,5379,stanislavkozlovski,2018-07-20T15:59:31Z,that would be the best approach i think. i also found this way non-ideal but decided to stick with the implementation as with `scramextensions`,0,0.984020471572876
204093826,5379,stanislavkozlovski,2018-07-20T16:07:19Z,i see. thanks for the clarification,1,0.9374487400054932
204099967,5379,stanislavkozlovski,2018-07-20T16:29:38Z,"you're right, even the method name implies you get the extensions",0,0.9866914749145508
204100861,5379,stanislavkozlovski,2018-07-20T16:33:10Z,i wanted to document the code via more explicit names,0,0.9838826656341553
204101263,5379,stanislavkozlovski,2018-07-20T16:34:38Z,good catch,1,0.9915775060653687
204110927,5379,rajinisivaram,2018-07-20T17:11:42Z,"yes, it makes sense. we currently use `map` for delegation tokens extension for scram. since we are only adding custom extensions to oauth in this kip, perhaps we should add `saslextensionscallback` and `saslextensionscallbackhandler` in `org.apache.kafka.common.security.auth` and use it only for `oauth` for now. for scram, we should probably stick to the `map` for now, but we could have the interfaces extend the public interface. what do you think?",0,0.9581586122512817
204136508,5379,rondagostino,2018-07-20T18:43:20Z,"agreed, we can focus on oauthbearer for now, take the right steps (adding 2 classes to the public api instead of just the callback class), and start to leverage the added public api classes in other mechanisms (i.e. scram-related) if/when the time seems right. i am less familiar with the scram-related code, so i defer to whatever/whenever you feel is best.",0,0.9297476410865784
204138659,5379,stanislavkozlovski,2018-07-20T18:51:36Z,why should we not change scram? was the delegation token publicly accessible and that would break? i feel like we should change it outright if we can,0,0.980655312538147
204139145,5379,rondagostino,2018-07-20T18:53:16Z,"this is the only place where the separator field is used, and i'm not clear on the semantics of this method. i think maybe the separator field can be dropped and eliminate that parameter from the constructor that takes a map?",0,0.9880672693252563
204140072,5379,rondagostino,2018-07-20T18:56:56Z,make unmodifiable via collections.emptymap(),0,0.9942877888679504
204140395,5379,rondagostino,2018-07-20T18:58:19Z,javadoc on public api classes and their methods is very helpful,1,0.9878310561180115
204140849,5379,rondagostino,2018-07-20T19:00:23Z,should this constructor accept the same parameters as utils.parsemap()?,0,0.9945496916770935
204141019,5379,rondagostino,2018-07-20T19:01:03Z,probably remove separator parameter (and the field) as mentioned below,0,0.9934178590774536
204141410,5379,rondagostino,2018-07-20T19:02:49Z,might want to add an extensionentries() method that returns a map.entry,0,0.9942305088043213
204142058,5379,rondagostino,2018-07-20T19:05:23Z,"probably no need to make a copy since the map is unmodifiable; javadoc can say it returns an unmodifiable map view of the extensions. this raises the question of whether all of the map-related methods isempty(), extensionnames(), extensionentries(), and extensionvalue() are actually needed. if returning the map is cheap -- which it would be -- then all of those methods feel like clutter rather than good api additions. what do you think?",0,0.9754114747047424
204142539,5379,rondagostino,2018-07-20T19:07:43Z,i'm not sure this method needs to exist. if someone want to parse a string and get a map they can either call utils.parsemap() directly or they can construct an instance of this class and call extensionsmap() on it.,0,0.9430380463600159
204142913,5379,rondagostino,2018-07-20T19:09:31Z,i think this class should accept and return instances of saslextensions rather than a map now that saslextensions is part of the public api.,0,0.9858390688896179
204143400,5379,rondagostino,2018-07-20T19:11:45Z,is there a reason why we shouldn't always use saslextensions rather than map?,0,0.9902702569961548
204143672,5379,rajinisivaram,2018-07-20T19:13:00Z,"for this kip, i think we should do one of these: 1. implement custom extensions for oauthbearer alone, but add common callback classes to enable reuse for other mechanisms in future. this means leaving scram alone. 2. support custom extensions for both scram and oauthbearer, changing the delegation token mechanism to use the custom extensions code path treating `token` as a property in the map. i don't think we should do a half-change for scram, changing a public contract without actually providing a good reason to do so (i.e. change the way extensions are propagated without supporting custom extensions). does that make sense?",0,0.9837542176246643
204144544,5379,rondagostino,2018-07-20T19:16:39Z,i think this will end up being `extensions == mycommitedextensions` ?,0,0.9913783073425293
204144759,5379,rondagostino,2018-07-20T19:17:38Z,same -- use saslextensions instead of map?,0,0.994282603263855
204157244,5379,stanislavkozlovski,2018-07-20T20:11:28Z,nope - [a link],0,0.9892249703407288
204157659,5379,stanislavkozlovski,2018-07-20T20:13:12Z,actually - no. my bad,-1,0.9948622584342957
204158880,5379,stanislavkozlovski,2018-07-20T20:18:23Z,fair enough - i figured to have it there for the sake of completeness,0,0.9079292416572571
204159227,5379,stanislavkozlovski,2018-07-20T20:19:54Z,"is it bad to have it, even if unused in code (only tested)?",0,0.8885040879249573
204159567,5379,rondagostino,2018-07-20T20:21:20Z,"yeah, the use of == instead of .equals() is certainly unusual, but it is necessary in this case because we need to make sure we remove our instance as opposed to an instance put there via another logincontext. i did not comment it when i did it for the token but should have given that it is unusual.",0,0.9789124131202698
204160970,5379,stanislavkozlovski,2018-07-20T20:27:27Z,i find they're still useful to keep. it's always good to abstract away the implementation behind an interface in my opinion,1,0.9035996198654175
204164892,5379,rondagostino,2018-07-20T20:45:33Z,"good question. the biggest mistake i made in doing this oauthbearer implementation was trying to do too much. the community reigned me in over time :-) my guess would be to keep things as simple and minimalistic as possible; there is less that can go wrong, less to debate over/review/test/fix, and ultimately a shorter time to when the code actually gets merged. at least that's the lesson i took from the experience.",1,0.9935616254806519
204165198,5379,stanislavkozlovski,2018-07-20T20:47:07Z,agreed and done,0,0.9190543293952942
204165223,5379,stanislavkozlovski,2018-07-20T20:47:15Z,done,0,0.8682363629341125
204165380,5379,stanislavkozlovski,2018-07-20T20:48:02Z,that's true in general. i honestly believe this is a useful constructor to have though,1,0.9718846082687378
204165803,5379,stanislavkozlovski,2018-07-20T20:50:01Z,is there a need to explicitly make it unmodifiable since `extensionsmap()` returns an unmodifiable version? come to think of it - maybe the other constructors shouldn't make it unmodifiable as well,0,0.9908143877983093
204498442,5379,rondagostino,2018-07-23T17:55:21Z,"should be ""check whether your callback **handler** is explicitly...""",0,0.9951080679893494
204499789,5379,rondagostino,2018-07-23T17:59:35Z,"need to also state: ""the { oauthbearerloginmodule} instance also asks its configured { authenticatecallbackhandler} implementation to handle an instance of { saslextensionscallback} and return an instance of { saslextensions}. the configured callback handler does not need to handle this callback, though -- any { unsupportedcallbackexception} that is thrown is ignored, and no sasl extensions will be associated with the login.""",0,0.9945472478866577
204500558,5379,rondagostino,2018-07-23T18:02:11Z,"this method doesn't actually attach the token -- it identifies the token that should be attached if/when commit() is called. the method needs a better name. maybe ""identifytoken()""?",0,0.9942634701728821
204500716,5379,rondagostino,2018-07-23T18:02:31Z,same here -- need a better method name (and also update javadoc) to reflect the fact that it is identifying the extensions that should be attached if/when commit() is called.,0,0.9930344820022583
204501651,5379,rondagostino,2018-07-23T18:05:39Z,should be == so we know it is literally the instance we committed,0,0.9936078786849976
204502047,5379,rondagostino,2018-07-23T18:07:11Z,this check is unnecessary; extensionsrequiringcommit cannot be null if tokenrequiringcommit is non-null.,0,0.9939879179000854
204505373,5379,rondagostino,2018-07-23T18:17:50Z,"this isn't actually parsing the custom extensions; it is retrieving the ones that have already been parsed and stored somewhere. it needs a better name. maybe ""retrieveextensions()""?",0,0.9924604296684265
204506803,5379,rondagostino,2018-07-23T18:22:20Z,"we need to make sure the ""auth"" key isn't defined here since that is generated from the token's compact serialization. should also add to the javadoc above that all token keys that meet the regex criteria are valid except ""auth"".",0,0.995301365852356
204507438,5379,rondagostino,2018-07-23T18:24:12Z,attaches the first saslextensions (not map anymore),0,0.9938003420829773
204507634,5379,rondagostino,2018-07-23T18:24:52Z,can add static modifier since it doesn't refer to anything in the instance,0,0.9935992956161499
204509972,5379,rondagostino,2018-07-23T18:32:13Z,stylistically it is better to write it as `this.saslextensions = validateextensions(extensions)` (and of course make that method return the extensions passed in if an exception is not raised).,0,0.9891738891601562
204510197,5379,rondagostino,2018-07-23T18:32:52Z,"make it return the extensions as per above, and also throw an exception if the ""auth"" extension is specified.",0,0.9950510859489441
204512923,5379,rondagostino,2018-07-23T18:41:53Z,`this.saslextensions = validateextensions(new saslextensions(properties))`,0,0.9944250583648682
204513594,5379,rondagostino,2018-07-23T18:44:17Z,i actually think this method is no longer needed.,0,0.8349950313568115
204513736,5379,rondagostino,2018-07-23T18:44:43Z,can/should delete this method as per above.,0,0.9949709177017212
204514223,5379,rondagostino,2018-07-23T18:46:18Z,"is this constructor ever used? if not, probably best to eliminate it; if it is used, then it should invoke `extensionsmap = collections.emptymap()`",0,0.9937699437141418
204515380,5379,rondagostino,2018-07-23T18:49:54Z,this method is not needed since map() is an inexpensive call; anybody wanting an extension value can simply call `thesaslextensions.map().get(thename)`.,0,0.9950405955314636
204515582,5379,rondagostino,2018-07-23T18:50:28Z,same here -- unnecessary method due to the ability to invoke `thesaslextensions.map().keyset()`,0,0.9949222207069397
204515709,5379,rondagostino,2018-07-23T18:50:57Z,same here -- unnecessary method due to the ability to invoke `thesaslextensions.map().isempty()`,0,0.9948204755783081
204517898,5379,rondagostino,2018-07-23T18:58:09Z,"since the isgssapi variable is only used to determine if we should return, why not just this? `if (saslconfigs.gssapi_mechanism.equals(mechanism)) return; // extensions are not supported for gssapi`",0,0.9937679767608643
204518784,5379,rondagostino,2018-07-23T19:01:10Z,"""auth"" is not allowed.",0,0.9904935956001282
204532330,5379,stanislavkozlovski,2018-07-23T19:50:05Z,could you elaborate on why this should be the case? i tend to agree but cannot explicitly define why that's better - maybe it's just more obvious?,0,0.9829238057136536
204534985,5379,stanislavkozlovski,2018-07-23T20:00:08Z,should i? what do we win by that - it's private.,0,0.9755786657333374
204535795,5379,stanislavkozlovski,2018-07-23T20:03:04Z,sure,0,0.9422702193260193
204537047,5379,stanislavkozlovski,2018-07-23T20:07:42Z,"no, it's not. i kept it since i did not call `super(map)` in `scramextensions` which should not have been the case",0,0.9916020035743713
204542803,5379,stanislavkozlovski,2018-07-23T20:27:04Z,"i agree with the others but for this most common use case i propose we keep the method name. it is shorter and more concise to write. also reads better than `map().get(thename)`. glancing at `extensionvalue` you immediately understand what we're taking - in the other way, it's still obvious but not as much",0,0.9390233159065247
204545192,5379,stanislavkozlovski,2018-07-23T20:35:00Z,done,0,0.8682363629341125
204557034,5379,rajinisivaram,2018-07-23T21:18:22Z,`should be attached` => `may be added`,0,0.9946151375770569
204557800,5379,rajinisivaram,2018-07-23T21:21:10Z,why was this change made? i think the single `if` statement is better than returning here.,0,0.9875284433364868
204558311,5379,rajinisivaram,2018-07-23T21:23:16Z,"same as before - check the mechanism in the `if` statement below. also, i think we could check for scram mechanism in the check above and check for oauthbearer here.",0,0.9945683479309082
204562743,5379,rajinisivaram,2018-07-23T21:40:24Z,make this `private final`?,0,0.9954095482826233
204563236,5379,rajinisivaram,2018-07-23T21:42:27Z,personally i think we s should create a copy of the map.,0,0.9834792613983154
204563539,5379,rajinisivaram,2018-07-23T21:43:45Z,"personally, i would get rid of this and use `extensionvalue` and `extensionnames`. otherwise, as said below, we should remove `extensionvalue`.",0,0.9936022162437439
204564358,5379,rajinisivaram,2018-07-23T21:46:58Z,"i thought we weren't supporting `saslextensionscallback` for scram. we should either update `scramsaslclient` to process `saslextensions` and add tests for that or not deprecate this now. in any case, i am not sure why the javadoc was removed.",0,0.9669496417045593
204565761,5379,rajinisivaram,2018-07-23T21:52:51Z,make `final`?,0,0.9940924048423767
204567218,5379,stanislavkozlovski,2018-07-23T21:59:13Z,doesn't `new hashmap<>(extensionsmap)` do exactly that?,0,0.9939769506454468
204567896,5379,stanislavkozlovski,2018-07-23T22:02:02Z,"it would then require its initialized on the spot or in the constructor. the appropriate callback handler initializes it using `#extensions(...)`, so making it `final` wouldn't work",0,0.9943769574165344
204569668,5379,stanislavkozlovski,2018-07-23T22:10:29Z,"`oauthbearerclientinitialresponse` uses this to iterate over all values and build the extensions string using `utils.mkstring`. if we removed `map()`, we would need to iterate through `extensionnames`, fetch and validate each value one by one. we would also need to rebuild the map in `#extensionsmessage()` so that we could call `utils.mkstring`. this is all more complex to write and slower to execute, thus i believe we should keep `map()`. i do not understand what is inherently wrong with having an `extensionvalue` method. it keeps it consistent with `scramextensions`' usage, does not bloat the api (it's a single method) and offers a more concise and readable way to fetch a value from the extensions. can you elaborate why you believe we should remove `extensionvalue()` ?",0,0.9752349257469177
204570041,5379,stanislavkozlovski,2018-07-23T22:12:32Z,it's `protected` so `scramextensions` can have access to it. i made it `final` now,0,0.99481600522995
204570220,5379,stanislavkozlovski,2018-07-23T22:13:25Z,"come to think of it, i'll outright remove `extensionnames` and use `map().keyset()`. did not realize `scramextensions` is not a public class",0,0.9799064993858337
204571187,5379,stanislavkozlovski,2018-07-23T22:18:34Z,removing the javadoc was a mistake. i will look into making `scramsaslclient` work with `saslextensions`. last time i tried some tests kept failing for a reason i could not debug even after significant effort. if it happens to be the case again i'll simply remove the deprecated tag,-1,0.5316128730773926
204575201,5379,stanislavkozlovski,2018-07-23T22:39:32Z,personal preference. i find this more readable than a bigger if check. changed back to one `if` and now checking for the correct mechanism in each callback,0,0.9792162775993347
204575952,5379,stanislavkozlovski,2018-07-23T22:43:28Z,is this the correct way to check for the mechanism? i'm wondering why the previous code only checked for `!saslconfigs.gssapi_mechanism.equals(mechanism)` and not other mechanisms as well,0,0.9670494794845581
204583187,5379,rondagostino,2018-07-23T23:24:58Z,i agree with ; since we have map() there is no need to provide any shorthand methods for functionality that the return value of map() provides.,0,0.9791042804718018
204583275,5379,rondagostino,2018-07-23T23:25:33Z,probably a good idea to add tostring() as well.,0,0.8553318381309509
204584539,5379,rondagostino,2018-07-23T23:33:27Z,"the saslclient callback handler for the oauthbearer mechanism needs to handle oauthbearertokencallback as well as saslextensionscallback (with the last one optional, but the first one is definitely mandatory). if we are going to put this code here for oauthbearer then the only way the code is going to ever be invoked in a successful runtime scenario is if 1) we also add code to handle oauthbearertokencallback; and 2) somehow this class is set as the saslclient callback handler. (2) will happen if the config explicitly specifies this class, or, alternatively, we can delete the oauthbearersaslclientcallbackhandler class and make this class the default saslclient callback handler for the oauthbearer mechanism (that decision is made at line 330 of org.apache.kafka.common.network.saslchannelbuilder; that line would have to change). i'm okay with either migrating to a fully-functional (for oauthbearer) saslclientcallbackhandler class or deleting these lines; keeping them without also handling oauthbearertokencallback doesn't make sense, though.",0,0.9921066761016846
204585957,5379,rondagostino,2018-07-23T23:41:47Z,"sure. we want to remove the instance that we put there, so we use == instead of .equals(). the .equals() method may identify another instance rather than the one we added. frankly i don't think it would be a problem due to the existence of the `break` statement below, but if that `break` statement were to be removed for some reason then we would iterate through the entire collection and remove everything that satisfied .equals() -- and that could be multiple instances. so using `==` makes the semantics very clear and acts as an insurance policy at the same time.",0,0.9747991561889648
204586766,5379,rondagostino,2018-07-23T23:46:27Z,this needs to be `getpubliccredentials()` rather than `getpubliccredentials(saslextensions.class)` because the former returns the actual public credentials (see [a link] whereas the latter returns a new set that doesn't propagate changes through (see [a link].,0,0.995196521282196
204588760,5379,rondagostino,2018-07-23T23:59:28Z,need to invoke `extensions = null` here as well.,0,0.992398202419281
204589027,5379,rondagostino,2018-07-24T00:01:18Z,"need to state that the extension name must match th required regex but cannot be the reserved value ""auth"".",0,0.993623673915863
204589338,5379,rondagostino,2018-07-24T00:03:42Z,probably a good idea to wrap in a try {} catch (kafkaexception e) {} block as is done above for the oauthbearertokencallback.,0,0.976791262626648
204589592,5379,rondagostino,2018-07-24T00:05:17Z,"should be `extensions.put(extensionname, extensionvalue)`",0,0.9949405193328857
204595693,5379,stanislavkozlovski,2018-07-24T00:51:10Z,"i do not know what it should return, though",0,0.9459657073020935
204595909,5379,stanislavkozlovski,2018-07-24T00:52:52Z,"oops, yes. this should not be here at all",-1,0.7504148483276367
204596760,5379,stanislavkozlovski,2018-07-24T01:00:26Z,that is a big gotcha! thanks!,1,0.9961903095245361
204597201,5379,stanislavkozlovski,2018-07-24T01:04:00Z,and just swallow the exception? i guess it boils down to: do we want to stop authentication on invalid extension value or just not use extensions?,0,0.9752917289733887
204599621,5379,rondagostino,2018-07-24T01:23:20Z,no need to check instanceof and cast it since `==` will return false if it isn't an instanceof. see line 331-338 above for what this should look like.,0,0.9935706853866577
204599894,5379,rondagostino,2018-07-24T01:25:53Z,is there a reason why this is protected and not private?,0,0.9933958649635315
204599996,5379,rondagostino,2018-07-24T01:26:29Z,`extensionsmap.tostring()` seems appropriate,0,0.9942511320114136
204600596,5379,rondagostino,2018-07-24T01:31:44Z,lines 344-347 are unnecessary; the statement `if (mycommittedextensions == credential)` will be correct regardless. see lines 332-333 above.,0,0.9934990406036377
204601020,5379,rondagostino,2018-07-24T01:35:15Z,probably should use `{ oauthbearerclientinitialresponse.auth_key}` instead of `{ oauthbearerclientinitialresponse.auth_key}`,0,0.9936414361000061
204601155,5379,rondagostino,2018-07-24T01:36:22Z,"no, don't swallow, propagate it wrapped in an ioexception as is done a few lines up.",0,0.9894183278083801
204601217,5379,rondagostino,2018-07-24T01:36:48Z,`{` instead of `{`,0,0.9843183159828186
204601696,5379,rondagostino,2018-07-24T01:40:46Z,duplicate line,0,0.9833511710166931
204602098,5379,rondagostino,2018-07-24T01:44:07Z,why delete these comments?,0,0.9368554949760437
204602841,5379,rondagostino,2018-07-24T01:50:04Z,"i think what you want to do here is accept an array of saslextensions objects; if an array element is null then the handler would throw unsupportedcallbackexception on that iteration, otherwise it returns the element. this test is making sure the simultaneous login/logout functionality doesn't get confused. basically follow what is going on with the tokens and do the same thing with the saslextensions. you might need separate indexes for tokens and saslextensions (i.e. `tokenindex` instead of `index`, and then add `extensionsindex`)",0,0.9868242144584656
204603396,5379,rondagostino,2018-07-24T01:54:34Z,"same thing here; create an array of saslextensions mocks, one element of which should be null, etc.",0,0.990638017654419
204603442,5379,rondagostino,2018-07-24T01:54:57Z,"same thing here; create an array of saslextensions mocks, one element of which should be null, etc.",0,0.990638017654419
204603529,5379,rondagostino,2018-07-24T01:55:36Z,"same thing here; create an array of saslextensions mocks, one element of which should be null, etc.",0,0.990638017654419
204603724,5379,rondagostino,2018-07-24T01:57:11Z,this test becomes unnecessary after weaving saslextensions into the above tests.,0,0.9898841381072998
204604012,5379,rondagostino,2018-07-24T01:59:30Z,"create an array of saslextensions mocks, one element of which should be null, etc.",0,0.9917113780975342
204604217,5379,rondagostino,2018-07-24T02:01:00Z,this test becomes unnecessary after weaving saslextensions into the above tests as long as you include at least one null element in the array for each one.,0,0.9923856258392334
204604435,5379,rondagostino,2018-07-24T02:02:51Z,why delete these 2 lines? can you just call `response.extensions().map().get()` instead of `response.propertyvalue()`?,0,0.9910219311714172
204604726,5379,rondagostino,2018-07-24T02:05:33Z,why delete this test? can you just call `response.extensions().map().get()` instead of `response.propertyvalue()`?,0,0.9917780160903931
204605136,5379,rondagostino,2018-07-24T02:09:00Z,"indicate that ""auth"" is reserved and cannot be used.",0,0.9944684505462646
204672879,5379,rajinisivaram,2018-07-24T08:49:05Z,"sorry, my mistake.",-1,0.992030143737793
204673218,5379,rajinisivaram,2018-07-24T08:50:14Z,"sorry, i was looking at the `unmodifiablemap` and didn't see the copy.",-1,0.9870378971099854
204673925,5379,rajinisivaram,2018-07-24T08:52:31Z,we should make this `private`.,0,0.9948441982269287
204674806,5379,rajinisivaram,2018-07-24T08:55:08Z,`scrammechanism.isscram(mechanism)`,0,0.9863757491111755
204676556,5379,rajinisivaram,2018-07-24T09:00:47Z,"in this line and the similar one for retrieving tokens, could we says `an internal error occurred while doing xxx`? also, perhaps `log.error(""error occurred while doing xxx"", e)`.",0,0.993257999420166
204680030,5379,rajinisivaram,2018-07-24T09:11:57Z,looks like duplicate code. couldn't we just use one static `oauthbearerclientinitialresponse.validateextensions(map )` method for validation?,0,0.9872967004776001
204789092,5379,stanislavkozlovski,2018-07-24T14:54:13Z,i wrote a similar test (copied this one) to this that didn't make the pr. i must have deleted the comments from the wrong test in the end,0,0.9669173955917358
204795761,5379,stanislavkozlovski,2018-07-24T15:10:39Z,"no, we'd need this. the null element won't test out this backwards-compatible behavior",0,0.9879516959190369
204818374,5379,stanislavkozlovski,2018-07-24T16:09:58Z,i'll add the functionality and have one of the commit/login tests use it. i vote we keep the two tests i wrote - i don't see anything wrong with unit testing functionality in a more fine-grained way,0,0.9859429597854614
204819005,5379,stanislavkozlovski,2018-07-24T16:11:55Z,"yes. my bad, sorry",-1,0.9958509206771851
204821362,5379,stanislavkozlovski,2018-07-24T16:18:23Z,yes we can. this will result in a bit more complicated code in `oauthbearerunsecuredlogincallbackhandler#handleextensionscallback()` since it needs to unprefix the extensions first,0,0.9936198592185974
204907936,5379,rondagostino,2018-07-24T20:54:55Z,can mirror the way it is done for tokens just call `getpubliccredentials()` instead of `getpubliccredentials(saslextensions.class)`. this also eliminates the need to keep calling the method to calculate a new set -- the original set will always be accurate.,0,0.993341863155365
205113394,5379,rondagostino,2018-07-25T13:44:17Z,can remove this line after making the change mentioned in line 127 above,0,0.9952409267425537
205114012,5379,rondagostino,2018-07-25T13:45:52Z,can remove this line after making the change mentioned in line 127 above,0,0.9952409267425537
205114191,5379,rondagostino,2018-07-25T13:46:17Z,can remove this line after making the change mentioned in line 127 above,0,0.9952409267425537
205114596,5379,rondagostino,2018-07-25T13:47:15Z,can remove this line after making the change mentioned in line 127 above,0,0.9952409267425537
205114906,5379,rondagostino,2018-07-25T13:48:03Z,can remove this line after making the change mentioned in line 127 above,0,0.9952409267425537
205115117,5379,rondagostino,2018-07-25T13:48:34Z,can remove this line after making the change mentioned in line 127 above,0,0.9952409267425537
205115297,5379,rondagostino,2018-07-25T13:49:00Z,can remove this line after making the change mentioned in line 127 above,0,0.9952409267425537
205115775,5379,rondagostino,2018-07-25T13:50:16Z,same as above -- can mirror the way it is done for tokens just call getpubliccredentials() instead of getpubliccredentials(saslextensions.class). this also eliminates the need to keep calling the method to calculate a new set -- the original set will always be accurate.,0,0.9933753609657288
205116317,5379,rondagostino,2018-07-25T13:51:35Z,"saslextensions array length should be the same as token array length -- 2, not 3.",0,0.9945059418678284
205116655,5379,rondagostino,2018-07-25T13:52:19Z,can remove this line after making the change mentioned in line 230 above,0,0.9951217770576477
205116789,5379,rondagostino,2018-07-25T13:52:38Z,can remove this line after making the change mentioned in line 230 above,0,0.9951217770576477
205116910,5379,rondagostino,2018-07-25T13:52:57Z,can remove this line after making the change mentioned in line 230 above,0,0.9951217770576477
205117003,5379,rondagostino,2018-07-25T13:53:12Z,can remove this line after making the change mentioned in line 230 above,0,0.9951217770576477
205117091,5379,rondagostino,2018-07-25T13:53:28Z,can remove this line after making the change mentioned in line 230 above,0,0.9951217770576477
205117236,5379,rondagostino,2018-07-25T13:53:49Z,can remove this line after making the change mentioned in line 230 above,0,0.9951217770576477
205117560,5379,rondagostino,2018-07-25T13:54:33Z,same as above -- can mirror the way it is done for tokens just call getpubliccredentials() instead of getpubliccredentials(saslextensions.class). this also eliminates the need to keep calling the method to calculate a new set -- the original set will always be accurate.,0,0.9933753609657288
205118094,5379,rondagostino,2018-07-25T13:56:01Z,can remove this line after making the change mentioned in line 296 above,0,0.99522864818573
205118194,5379,rondagostino,2018-07-25T13:56:16Z,can remove this line after making the change mentioned in line 296 above,0,0.99522864818573
205118319,5379,rondagostino,2018-07-25T13:56:38Z,can remove this line after making the change mentioned in line 296 above,0,0.99522864818573
205118397,5379,rondagostino,2018-07-25T13:56:50Z,can remove this line after making the change mentioned in line 296 above,0,0.99522864818573
205118520,5379,rondagostino,2018-07-25T13:57:08Z,can remove this line after making the change mentioned in line 296 above,0,0.99522864818573
205118748,5379,rondagostino,2018-07-25T13:57:43Z,same as above -- can mirror the way it is done for tokens just call getpubliccredentials() instead of getpubliccredentials(saslextensions.class). this also eliminates the need to keep calling the method to calculate a new set -- the original set will always be accurate.,0,0.9933753609657288
205119069,5379,rondagostino,2018-07-25T13:58:29Z,can remove this line after making the change mentioned in line 353 above,0,0.9951560497283936
205119183,5379,rondagostino,2018-07-25T13:58:45Z,can remove this line after making the change mentioned in line 353 above,0,0.9951560497283936
205119367,5379,rondagostino,2018-07-25T13:59:11Z,can remove this line after making the change mentioned in line 353 above,0,0.9951560497283936
205119483,5379,rondagostino,2018-07-25T13:59:29Z,can remove this line after making the change mentioned in line 353 above,0,0.9951560497283936
205119824,5379,rondagostino,2018-07-25T14:00:16Z,can remove this line after making the change mentioned in line 353 above,0,0.9951560497283936
205119994,5379,rondagostino,2018-07-25T14:00:41Z,can remove this line after making the change mentioned in line 353 above,0,0.9951560497283936
205120125,5379,rondagostino,2018-07-25T14:00:59Z,can remove this line after making the change mentioned in line 353 above,0,0.9951560497283936
205120889,5379,rondagostino,2018-07-25T14:02:54Z,i believe this test adds no value and should be eliminated because the case is covered above.,0,0.9659979343414307
205122848,5379,rondagostino,2018-07-25T14:08:10Z,this test is checking the same thing that was checked via passing in raise_unsupported_cb_exception_flag (null) at line 133 and checking for empty_extensions at lines 191 and 200. this test should be deleted.,0,0.9942376613616943
205125175,5379,rondagostino,2018-07-25T14:14:12Z,`collections.emptymap()` instead of `new hashmap<>()`,0,0.9925801157951355
205125573,5379,rondagostino,2018-07-25T14:15:07Z,"oops, delete this unintended change",-1,0.8835372924804688
205178909,5379,stanislavkozlovski,2018-07-25T16:33:59Z,"hm, that is strange. i initially went with this approach (obviously sprinkling `getpubliccredentials()` before every assert is bad) but hit some problem. i assumed that the public credentials had another value in them and changed the test with what you just reviewed. the test passed afterwards so i didn't go into investigating what the problem was. now that i removed the calls, test still pass. i'm not sure what i initially missed there",-1,0.8274450302124023
205185439,5379,stanislavkozlovski,2018-07-25T16:55:30Z,"sorry about my initial comment of ""no, we'd need this. the null element won't test out this backwards-compatible behavior"". i unfortunately commented prematurely before completely understanding your suggestion. i acknowledge that this is verified in the above tests. it's just that from what i've read from tdd books, the overall approach experts recommend is to rely on single, small tests that test concrete functionality. this way, when a problem occurs you immediately know what the cause is - `commitpopulatesextensions` - oh, my extensions weren't populated. where as if you get an error in test `login1commit1login2abort2login3commit3logout3` you need to investigate the test well and figure out where the problem is. while such big tests are always useful, i believe a test suite comprised of more smaller tests is better. tests comprised of more methods serve as better documentation. you can then just read the method names and get a general feeling of what the tested subject should do. please share your thoughts on this",-1,0.9646507501602173
205185773,5379,stanislavkozlovski,2018-07-25T16:56:38Z,"take a look at my comment below for test `commitdoesnotthrowonunsupportedextensionscallback`. i do not feel as strongly about this test as i feel on the one below, but i also tentatively think it doesn't hurt to have one more test",0,0.9453158378601074
205197478,5379,rondagostino,2018-07-25T17:32:48Z,"still need this adjusted: saslextensions array length should be the same as token array length -- 2, not 3.",0,0.9920076131820679
205198355,5379,rondagostino,2018-07-25T17:35:34Z,"i agree with your point below about lots of simple tests being better than one big one. let's eliminate the null value here, replace it with a mock, and rely on your test below to verify that unhandledcallbackexception is ignored.",0,0.9669815897941589
205198824,5379,rondagostino,2018-07-25T17:37:01Z,"yes, let's eliminate this one and keep the one below.",0,0.9895141124725342
205199240,5379,rondagostino,2018-07-25T17:38:17Z,good point -- i agree. let's keep this test and eliminate the null value in `login1commit1login2abort2login3commit3logout3`.,1,0.9357225894927979
207815285,5379,rajinisivaram,2018-08-06T08:47:03Z,can you move the link to the next line and include the full name including package since that class has not been imported in this class: `{ org.apache.kafka.common.security.oauthbearer.internals.oauthbearerclientinitialresponse#auth_key}`,0,0.9955561757087708
207818595,5379,rajinisivaram,2018-08-06T08:58:44Z,"was like this earlier, but will be good to update anyway. `string.format` not required. could use: `log.info(""login failed {} : {} (uri={}"",....`",0,0.9938696622848511
207819149,5379,rajinisivaram,2018-08-06T09:00:41Z,"`log.info(""callbackhandler {} does not support..."", callbackhandler.getclass().getname())`?",0,0.993455708026886
207819502,5379,rajinisivaram,2018-08-06T09:02:03Z,we could have a constant like `empty_extensions` for this case?,0,0.9925445318222046
207820729,5379,rajinisivaram,2018-08-06T09:06:27Z,"now that we can use java8, we could use `removeif` here and in the block above for tokens? [code block]",0,0.995407223701477
207822201,5379,rajinisivaram,2018-08-06T09:12:06Z,`{ oauthbearerclientinitialresponse.auth_key}` => `{ oauthbearerclientinitialresponse#auth_key}`,0,0.9927612543106079
207822476,5379,rajinisivaram,2018-08-06T09:13:06Z,`get` => `containskey`?,0,0.9948541522026062
207824202,5379,rajinisivaram,2018-08-06T09:19:09Z,`oauthbearerclientinitialresponse.auth_key` => oauthbearerclientinitialresponse#auth_key,0,0.9931321740150452
207824332,5379,rajinisivaram,2018-08-06T09:19:34Z,`oauthbearerclientinitialresponse.auth_key` => `oauthbearerclientinitialresponse#auth_key`,0,0.9933159947395325
207827945,5379,rajinisivaram,2018-08-06T09:31:55Z,could just use `collections.emptymap()` here since type can be inferred?,0,0.992901623249054
207830135,5379,rajinisivaram,2018-08-06T09:39:45Z,`static final`?,0,0.9943278431892395
207841511,5379,rajinisivaram,2018-08-06T10:20:11Z,`values` => `value`?,0,0.9945186972618103
207842331,5379,rajinisivaram,2018-08-06T10:23:43Z,not used?,0,0.992996871471405
207842366,5379,rajinisivaram,2018-08-06T10:23:51Z,not used?,0,0.992996871471405
207859716,5379,stanislavkozlovski,2018-08-06T11:32:50Z,that is very cool,1,0.9900559186935425
38921717,191,ijuma,2015-09-08T12:59:25Z,"we should probably use 2.7.1, right?",0,0.9882533550262451
38921790,191,ijuma,2015-09-08T13:00:12Z,indenting doesn't look right in the new `allow` lines.,0,0.8485813140869141
38923719,191,ijuma,2015-09-08T13:20:24Z,is the current plan not to support `auth-int` and `auth-conf` qops?,0,0.9940807223320007
38924187,191,ijuma,2015-09-08T13:25:00Z,what is this change for? `maxfdlimit` seems to be a deprecated flag ([a link],0,0.9942792654037476
38924482,191,ijuma,2015-09-08T13:27:45Z,"instead of having one method per security protocol, why not just take the security protocol as a parameter? then 3 methods would become one. the implementation seems exactly the same apart from the security protocol passed to `boundport`.",0,0.9932339787483215
38924900,191,ijuma,2015-09-08T13:31:31Z,i agree that this is useful. i think there are a number of places where we use `milliseconds()` where we should really be using a method like this one (i noticed that recently). it may be worth thinking about the naming so that the differences are clear. maybe `milliseconds()` should be removed in favour of `currentwalltime()` introduced below?,1,0.6397596001625061
38925126,191,ijuma,2015-09-08T13:33:25Z,not sure whether we should be returning `java.util.date` as it's a somewhat deprecated class as of java 8. maybe we can return a long and the caller can decide to create a `java.util.date` or anything else?,0,0.950768232345581
39592806,191,junrao,2015-09-16T04:25:38Z,"could we document the handshake protocol in the comment? it seems that for each token, we first send a 4-byte size, followed by the bytes in the token itself?",0,0.9928597211837769
39592812,191,junrao,2015-09-16T04:25:48Z,it seems that we can just use one level of if/else.,0,0.986011266708374
39592816,191,junrao,2015-09-16T04:25:56Z,could we just use a bytebuffer instead of a networksend?,0,0.9916980266571045
39592823,191,junrao,2015-09-16T04:26:07Z,could we get that through the config property instead of a jvm system property?,0,0.9923581480979919
40359478,191,Parth-Brahmbhatt,2015-09-24T19:08:40Z,i think this could just be if(!securityprotocol.values().contains(securityprotocol)),0,0.9884552955627441
40359495,191,Parth-Brahmbhatt,2015-09-24T19:08:47Z,shouldn't this come from a config?,0,0.9871000051498413
40359539,191,Parth-Brahmbhatt,2015-09-24T19:09:12Z,is this needed?,0,0.9945470094680786
40359628,191,Parth-Brahmbhatt,2015-09-24T19:09:57Z,anyways to avoid this vendor spicific thing? can we just make this a config that defaults to sun.security.krb5.config?,0,0.9789358377456665
40362188,191,Parth-Brahmbhatt,2015-09-24T19:33:44Z,"let's also add ""socketchannel.socket().getinetaddress().gethostname() must match the hostname in principal/hostname""",0,0.9957571625709534
40375211,191,Parth-Brahmbhatt,2015-09-24T21:24:39Z,probably better to just create a method that returns the principal name and host. might be easier to extract all of it using a simple pattern matcher instead of going through bunch of indexofs and substrings.,0,0.9821676015853882
40375463,191,Parth-Brahmbhatt,2015-09-24T21:27:06Z,i am guessing this is all part of gss api magic but a link to doc or some explanation on what we are doing here might help with future maintenance.,0,0.957716703414917
40575583,191,ijuma,2015-09-28T16:52:14Z,that would not be right because of `securityprotocol.trace` (the fact that trace exists is the reason why we do the check in the first place).,0,0.9908189177513123
40575758,191,ijuma,2015-09-28T16:53:55Z,`sun.security.krb5.config` is also vendor-specific and it won't work in java 9 (see [a link] is there no way to avoid this?,0,0.9935378432273865
40669700,191,ijuma,2015-09-29T13:22:29Z,i think it would be more readable if `listeners` were a `seq` and we can build the `string` at the end with `mkstring`,0,0.9790329337120056
41590473,191,harshach,2015-10-09T01:48:04Z,enabling qop on sasl proven to cause lot of perf issues . it was discussed before hence the reason i went with proposal ssl+sasl.,0,0.9632900357246399
41590525,191,harshach,2015-10-09T01:49:06Z,the reason to use networksend is to have length encoded token . i can use bytebuffer have it encoded with length. let me know if you prefer that.,0,0.993878960609436
41627145,191,ijuma,2015-10-09T13:03:41Z,i removed it in my pr.,0,0.990718424320221
41627200,191,ijuma,2015-10-09T13:04:24Z,"ok, thanks. should the name of this be `sasl_plaintext` and `sslsasl` should be `sasl_ssl`? i guess this is a bit subjective, but seems a bit clearer to me.",1,0.9374841451644897
41628653,191,ijuma,2015-10-09T13:22:05Z,i removed this in my pr as it's not used anywhere.,0,0.9929189085960388
41628772,191,ijuma,2015-10-09T13:23:38Z,"i filed kafka-2607 to modify the `time` interface. in the meantime, maybe we can `nanoseconds` and `milliseconds` instead of introducing these methods? i can make the change if you agree.",0,0.988031268119812
41628927,191,ijuma,2015-10-09T13:25:12Z,do we have anything in kafka that does something similar to this?,0,0.9932184815406799
41629059,191,ijuma,2015-10-09T13:26:18Z,i changed this in my pr.,0,0.9900661706924438
41629081,191,ijuma,2015-10-09T13:26:33Z,i removed this change in my pr.,0,0.9938761591911316
41719366,191,junrao,2015-10-12T02:00:42Z,2 components -> 3 components ?,0,0.9884823560714722
41719367,191,junrao,2015-10-12T02:00:43Z,with out => without,0,0.9857962727546692
41719374,191,junrao,2015-10-12T02:00:50Z,would it be better to name this to sth like ticket_renew_window_factor?,0,0.9908210635185242
41719381,191,junrao,2015-10-12T02:01:01Z,should that be made configurable?,0,0.9935203194618225
41719400,191,junrao,2015-10-12T02:01:11Z,could we use utils.newthread() so that we can give it a proper name and register the uncaught exception handler?,0,0.9941046833992004
41719401,191,junrao,2015-10-12T02:01:15Z,should we test equals and after?,0,0.9929327964782715
41719402,191,junrao,2015-10-12T02:01:20Z,not be => not be able to,-1,0.5129523873329163
41719404,191,junrao,2015-10-12T02:01:24Z,newuntil => newuntil,0,0.9890235662460327
41719407,191,junrao,2015-10-12T02:01:32Z,"since we just want to exit, should we change break to return?",0,0.9914217591285706
41719410,191,junrao,2015-10-12T02:01:39Z,would it be better to get kafka.init from kafka_jaas.conf file instead of another system property?,0,0.9912753105163574
41719414,191,junrao,2015-10-12T02:01:47Z,"since we are waiting for this thread to finish during shutdown, it seem that it shouldn't be a daemon thread?",0,0.9887232780456543
41719415,191,junrao,2015-10-12T02:02:07Z,it seems that t is never null. so perhaps it's simpler to just start the thread after t is created.,0,0.9886122345924377
41719416,191,junrao,2015-10-12T02:02:19Z,is this test needed? it seems that logincontextname can never be null.,0,0.9943994879722595
41719421,191,junrao,2015-10-12T02:02:26Z,"could we make ""java.security.auth.login.config"" a constant and reuse?",0,0.9935765862464905
41719433,191,junrao,2015-10-12T02:03:00Z,"i am wondering how well this works when the broker is enabled to also authenticate to zk through sasl. will the global configuration be set twice (once here and another time potentially in zookeeper client)? will that affect the login logic? , do you know?",0,0.9520114660263062
41719435,191,junrao,2015-10-12T02:03:07Z,it seems that we need to set the login time during the initial login as well.,0,0.9911511540412903
41719438,191,junrao,2015-10-12T02:03:13Z,it seems that we should setlastlogin() in setlogin() instead of here.,0,0.9913835525512695
41719441,191,junrao,2015-10-12T02:03:20Z,it seems that both logincontext and mode can just be a local variable.,0,0.9903855323791504
41719446,191,junrao,2015-10-12T02:03:39Z,do we need to make servicename configurable? could that just be hardcoded as kafka?,0,0.9918935894966125
41719449,191,junrao,2015-10-12T02:03:44Z,it doesn't seem that the client needs principalbuilder.,0,0.982915997505188
41719453,191,junrao,2015-10-12T02:03:51Z,it seems that we need to pass in the config properties that may be specified in the jaas config file?,0,0.9939687252044678
41719460,191,junrao,2015-10-12T02:04:04Z,"we need to turn off op_write when sasl state is complete, right?",0,0.9922845363616943
41719461,191,junrao,2015-10-12T02:04:09Z,would it be enough to just check saslstate?,0,0.9864675998687744
41719464,191,junrao,2015-10-12T02:04:27Z,could you add some comments on when and what types of callbacks could be called?,0,0.9915359020233154
41719465,191,junrao,2015-10-12T02:04:31Z,this is a no op.,0,0.9856128096580505
41722182,191,junrao,2015-10-12T04:31:32Z,could you add a comment on why we need to exclude this?,0,0.9929248094558716
41722186,191,junrao,2015-10-12T04:31:45Z,should we specify those through kafka config file or just the jaas config file? it seems that the latter is more natural since it consolidates all sasl related stuff in one file?,0,0.9917656779289246
41722188,191,junrao,2015-10-12T04:31:56Z,need to add the new param configs.,0,0.9938300251960754
41722190,191,junrao,2015-10-12T04:32:03Z,is the test transportlayer.ready() necessary?,0,0.9953299760818481
41722191,191,junrao,2015-10-12T04:32:08Z,why does this need to be public?,0,0.9847736358642578
41722196,191,junrao,2015-10-12T04:32:19Z,do we need to pass in the config properties that may be specified in the jaas config file?,0,0.9952462315559387
41722202,191,junrao,2015-10-12T04:32:25Z,do we need to set op_read? it seems it's always on.,0,0.9915512800216675
41722205,191,junrao,2015-10-12T04:32:30Z,we need to turn off op_write when saslserver is complete.,0,0.9940938353538513
41731553,191,ijuma,2015-10-12T07:54:25Z,"i agree that it's not needed in its current state, but it makes sense with the code as it was before, that is: [code block] which version do we prefer?",0,0.9742600321769714
41735085,191,ijuma,2015-10-12T08:45:58Z,"it doesn't, i'll change this back.",0,0.9746658802032471
41752308,191,ijuma,2015-10-12T12:47:41Z,fixed locally.,0,0.989118218421936
41752351,191,ijuma,2015-10-12T12:48:16Z,"that's right, changed it locally.",0,0.99198979139328
41752705,191,ijuma,2015-10-12T12:53:31Z,done this locally.,0,0.9937532544136047
41752835,191,ijuma,2015-10-12T12:55:01Z,"i don't understand why we are doing this. we call this method if `authid.equals(authzid)` and set it to the value of `ac.getauthorizationid`, so it looks like a no-op?",0,0.8390793800354004
41752875,191,ijuma,2015-10-12T12:55:31Z,removed locally.,0,0.9808984398841858
41753910,191,ijuma,2015-10-12T13:08:19Z,"agreed. and we should handle parsing errors properly (at the moment we are ignoring the case where `indexof` returns -1). i haven't done this yet, but i added it to my list.",0,0.9700474143028259
41754232,191,ijuma,2015-10-12T13:12:02Z,fixed locally.,0,0.989118218421936
41754241,191,ijuma,2015-10-12T13:12:09Z,fixed locally.,0,0.989118218421936
41754749,191,ijuma,2015-10-12T13:17:33Z,maybe we can use `kerberosname` for this?,0,0.9911406636238098
41755037,191,ijuma,2015-10-12T13:21:11Z,done locally.,0,0.9908100366592407
41755928,191,ijuma,2015-10-12T13:31:32Z,changed it locally (and in one other similar place).,0,0.9874748587608337
41756215,191,ijuma,2015-10-12T13:34:58Z,"there is the following in the constructor, so the thread can be null. [code block]",0,0.9958392381668091
41756262,191,ijuma,2015-10-12T13:35:32Z,changed it locally.,0,0.989410400390625
41756269,191,ijuma,2015-10-12T13:35:39Z,changed it locally.,0,0.989410400390625
41756390,191,ijuma,2015-10-12T13:37:05Z,"i think so, changed it locally.",0,0.9892988204956055
41756657,191,ijuma,2015-10-12T13:39:56Z,changed it locally.,0,0.989410400390625
41756681,191,ijuma,2015-10-12T13:40:09Z,changed it locally.,0,0.989410400390625
41759052,191,ijuma,2015-10-12T14:05:12Z,done locally.,0,0.9908100366592407
41815169,191,harshach,2015-10-13T00:13:09Z,i've a config property in sasl will replace that with this.,0,0.9946979284286499
41815315,191,harshach,2015-10-13T00:15:47Z,yes. will change that.,0,0.9519025683403015
41815592,191,harshach,2015-10-13T00:20:18Z,"no its not needed. user needs to add another section kafka_jaas.conf with ""client"" section. here is the vagrant setup that i've for kafka kerberos. example here [a link]",0,0.9931833148002625
41817433,191,harshach,2015-10-13T00:57:11Z,this is not hardcoded. users need to come up with servicename and its equivalent to the principal name of the kafkaserver.,0,0.9943952560424805
41817530,191,harshach,2015-10-13T00:58:37Z,"didn't understand , are you saying we should pass jaas config file as part of client config properties?",0,0.9683826565742493
41817534,191,harshach,2015-10-13T00:58:46Z,yes. will fix it.,0,0.8695363998413086
41817553,191,harshach,2015-10-13T00:59:04Z,yes that should be enough.,0,0.985516369342804
41817601,191,harshach,2015-10-13T01:00:11Z,jaas config special file in that it needs a different syntax like sections that we define. so it should only need to have login details like keytab files not kafka specific configs.,0,0.94526207447052
41817692,191,harshach,2015-10-13T01:02:26Z,don't understand. what you mean by config properties in jaas config file. jaas should only contain sections and it has specific syntax to them we shouldn't be treating it as generic config file.,0,0.5591791272163391
41817707,191,harshach,2015-10-13T01:02:40Z,will take it out.,0,0.9880721569061279
41820027,191,junrao,2015-10-13T01:54:20Z,do we need the stringbuilder?,0,0.9940512776374817
41820042,191,junrao,2015-10-13T01:54:40Z,"could you add some examples of the rules and keberos names? in particular, how match, frompattern, topattern, etc are used to convert keberos names to user names?",0,0.9936631917953491
41820061,191,junrao,2015-10-13T01:54:51Z,it's a bit weird that # of params doesn't match numofcomponents. could you add a comment?,-1,0.9833939671516418
41820068,191,junrao,2015-10-13T01:55:03Z,should we get this from a system property or from the jaas conf file?,0,0.9942126870155334
41820075,191,junrao,2015-10-13T01:55:14Z,would it be better to pass in timeout through the constructor?,0,0.9868582487106323
41820084,191,junrao,2015-10-13T01:55:22Z,"what does it mean to have a negative interval? also, do we need to support interval? it seems that we have no use case to run a command periodically.",0,0.9863584637641907
41822597,191,harshach,2015-10-13T02:55:10Z,we initializing lasttime to negative of interval and in run method we are checking lasttime + interval > time.currentelapsedtime()) so it guarantees at least one execution of runcommand.,0,0.9942858815193176
41823048,191,harshach,2015-10-13T03:07:50Z,we've shellcommandexecutor in the same file that takes in timeout from constructor. let me know if you want to change this for shell as well.,0,0.9942377805709839
41833260,191,ijuma,2015-10-13T07:13:33Z,i fixed this in my pr that harsha merged some minutes before you made this comment.,0,0.9902762174606323
41875295,191,ijuma,2015-10-13T14:46:55Z,i agree that it's clearer to receive the parameter via the constructor instead of assigning it directly in the subclass (it also avoids initialisation ordering issues). i've changed this locally with a few other `shell` changes.,0,0.9790672659873962
41879955,191,ijuma,2015-10-13T15:16:57Z,"as far as i can see, we don't need to support interval. i have removed it locally as it simplifies the class.",0,0.9932000041007996
41881028,191,ijuma,2015-10-13T15:23:37Z,"harsha changed this to be: `transportlayer.removeinterestops(selectionkey.op_write);` i think this also addresses the ""turn off op_write"" comment.",0,0.9890157580375671
41881164,191,ijuma,2015-10-13T15:24:25Z,"harsha address this, i believe.",0,0.9756421446800232
41881443,191,ijuma,2015-10-13T15:26:12Z,changed it locally.,0,0.989410400390625
41883325,191,ijuma,2015-10-13T15:37:52Z,"that's right, changed it locally. with the current code, this doesn't make much of a difference in practice, but it could lead to bugs in the future.",0,0.9761136174201965
41884709,191,ijuma,2015-10-13T15:47:19Z,"there was this code in the constructor before the `login` call: `this.lastlogin = time.currentelapsedtime() - this.mintimebeforerelogin;` i've changed it to: `this.lastlogin = time.currentelapsedtime()` `mintimebeforerelogin` is only relevant for the relogin case. however, we are still setting the `lastlogin` time before we actually execute `logincontext.login` (in both the first and subsequent logins). do you think we should be updating that value after the `logincontext.login` call?",0,0.9937772750854492
41884856,191,ijuma,2015-10-13T15:48:21Z,harsha has done this.,0,0.955028772354126
41884906,191,ijuma,2015-10-13T15:48:42Z,it looks like we don't.,0,0.9621650576591492
41885077,191,ijuma,2015-10-13T15:49:55Z,we now create the appropriate one (plaintext or ssl) based on whether it's sslsasl or plaintextsasl.,0,0.9951514005661011
41886074,191,ijuma,2015-10-13T15:56:39Z,i removed this as it wasn't being used.,0,0.9917451739311218
41886456,191,ijuma,2015-10-13T15:59:25Z,"i don't understand what you mean, could you elaborate please?",-1,0.6544414162635803
41886529,191,ijuma,2015-10-13T15:59:57Z,this was fixed by harsha.,0,0.9929777979850769
41886544,191,ijuma,2015-10-13T16:00:05Z,i fixed this.,0,0.9055806994438171
41886627,191,ijuma,2015-10-13T16:00:34Z,i removed this.,0,0.9919763207435608
41886671,191,ijuma,2015-10-13T16:00:51Z,harsha did this.,0,0.8885002136230469
41887608,191,ijuma,2015-10-13T16:07:42Z,checked with jun and this is fine.,0,0.9510282278060913
41889019,191,ijuma,2015-10-13T16:18:02Z,"these new methods are only used in the `login` class, so i will move them there and make them private for now.",0,0.9940800070762634
41889636,191,ijuma,2015-10-13T16:22:52Z,will propose sasl_plain and sasl_ssl in a pr (checked with jun).,0,0.9940788745880127
41890445,191,ijuma,2015-10-13T16:30:14Z,harsha did this.,0,0.8885002136230469
41890652,191,ijuma,2015-10-13T16:31:39Z,harsha removed the check.,0,0.8936241269111633
41890663,191,ijuma,2015-10-13T16:31:50Z,harsha did this.,0,0.8885002136230469
41898819,191,ijuma,2015-10-13T17:38:35Z,i moved `transportlayer.removeinterestops(selectionkey.op_write);` from `case complete` to here in my latest pr.,0,0.9948163628578186
41907669,191,ijuma,2015-10-13T18:46:29Z,"i will add a comment explaining the `oid` line, which is particularly bizarre.",-1,0.9291439652442932
41922109,191,fpj,2015-10-13T20:43:32Z,"this class is surprisingly similar to org.apache.zookeeper.login, have we copied from the same source? ;-)",1,0.9818458557128906
41928675,191,rajinisivaram,2015-10-13T21:32:51Z,"sasl/plain is typically used to refer to sasl with mechanism plain. and sasl/plain is usually used with ssl as transport layer. since the protocols here are referring to the transport layer and the plain transport layer is called plaintext, it would be less confusing to have sasl_plaintext and sasl_ssl.",0,0.9906410574913025
41929181,191,rajinisivaram,2015-10-13T21:37:21Z,"can the mechanism be made a configuration option? i haven't looked through the code yet to see if the implementation relies on this mechanism, but it will be good if it was configurable.",0,0.9808268547058105
41929415,191,rajinisivaram,2015-10-13T21:39:25Z,same question as for client - can the sasl mechanism be made configurable?,0,0.9930485486984253
41929710,191,rajinisivaram,2015-10-13T21:42:15Z,"is there a reason why this isn't simply using `configuration.getconfiguration()` to get the default configuration since it is using the standard java property to get the jaas config file anyway? i think `javaloginconfig` is provided by the sun provider, dont think it is available with all vendors.",0,0.9899060130119324
41930386,191,ijuma,2015-10-13T21:47:53Z,"ok, i can change my pr to use that instead. to check: is the proposed name better than what we have at the moment (sslsasl and plaintextsasl).",0,0.9926227331161499
41930669,191,ijuma,2015-10-13T21:49:59Z,i think it would be good if we could do that in a separate pr. which other mechanisms are important for you?,0,0.9417142868041992
41931374,191,rajinisivaram,2015-10-13T21:55:36Z,i do prefer sasl_plaintext and sasl_ssl since it is clearer (more readable) than sslsasl and plaintextsasl.,0,0.9485086798667908
41931566,191,ijuma,2015-10-13T21:57:05Z,"ok, great.",1,0.8794912099838257
41937626,191,rajinisivaram,2015-10-13T23:00:31Z,"the one we are keen on is plain. we will be using sasl with ssl, so plain gives us the simplest secure authentication without having to distribute certificates for mutual client auth. yes, a separate pr makes sense so that this one can be committed soon. i will raise another jira.",0,0.9632629156112671
41948372,191,junrao,2015-10-14T02:03:31Z,"since this tests both the producer and consumer, probably this can be called saslintegrationtest. also, could we parameterize the test to test sasl_ssl port too?",0,0.9932559728622437
41948393,191,junrao,2015-10-14T02:03:58Z,perhaps it's clearer to also specify the param name for the third value (false).,0,0.9829111695289612
41948396,191,junrao,2015-10-14T02:04:04Z,"since we only use 1 consumer, do we need to create multiple consumers during setup?",0,0.9916362762451172
41948402,191,junrao,2015-10-14T02:04:10Z,probably better to use foreach instead map.,0,0.9803081750869751
41948404,191,junrao,2015-10-14T02:04:14Z,could we rename this to consumeandverifyrecords?,0,0.9950355291366577
41948407,191,junrao,2015-10-14T02:04:21Z,should we verify the content of the consumed messages too?,0,0.9938639402389526
41948415,191,junrao,2015-10-14T02:04:29Z,"it seems that saslconsumertest.scala covers what's being tested in this file. so, perhaps we don't need this test.",0,0.9887214303016663
41948446,191,junrao,2015-10-14T02:05:07Z,"could we make sun.security.jgss.native a property in the broker/client config file? in general, it seems that other than the jaas config file, it's better to specify other properties from config file instead of system properties.",0,0.9928499460220337
41948452,191,junrao,2015-10-14T02:05:21Z,"it seems that we need to turn off op_write after completing the send of each token. otherwise, the server will be busy looping over the selector while waiting for the next token to be received.",0,0.989776611328125
41979803,191,ijuma,2015-10-14T10:59:00Z,"i don't think so. i am adding the following comment to the codebase that should explain it: // as described in [a link] // ""to enable java gss to delegate to the native gss library and its list of native mechanisms, // set the system property ""sun.security.jgss.native"" to true"" // ""in addition, when performing operations as a particular subject, for example, subject.doas(...) // or subject.doasprivileged(...), the to-be-used gsscredential should be added to subject's // private credential set. otherwise, the gss operations will fail since no credential is found.""",0,0.9808527827262878
41995662,191,junrao,2015-10-14T13:56:11Z,"it is probably not enough to just turn off op_write at sasl completion time. after completely sending a challenge token, the client needs to turn off op_write. otherwise, while waiting to receive the next token from the server, the client will be busy checking in the selector.",0,0.9834623336791992
42009871,191,ijuma,2015-10-14T15:35:04Z,"looking at the documentation, this only needs to be called if the value passed to `setauthorizedid` is different than the value of `getauthorizationid` which is not the case here. having said that, hadoop does the same thing so i'll leave it in case it's needed due to non-compliant implementations (unless others disagree).",0,0.9903822541236877
42062496,191,harshach,2015-10-14T22:30:08Z,yes. i'll fix it.,0,0.8432662487030029
42062570,191,harshach,2015-10-14T22:30:57Z,it will be helpful in case of doas which we are not supporting int this case. but will be added in future. leaving as it is would be better.,0,0.9762068390846252
42062645,191,harshach,2015-10-14T22:31:37Z,yes. did take it from zookeeper.,0,0.9828619956970215
42063676,191,harshach,2015-10-14T22:43:28Z,yes will make it configurable we can implement additional callbacks and digest implementation as part of another pr.,0,0.994889497756958
42117788,191,ijuma,2015-10-15T12:33:14Z,is it right that we always set it to authorized here (instead of checking if authenticationid and authorizationid are the same like in the client)?,0,0.9942995309829712
42119040,191,ijuma,2015-10-15T12:47:05Z,i changed it to do as you say and it seems to work fine. will include it in my next pr so that harsha can integrate it if he agrees.,1,0.6636227369308472
42119247,191,ijuma,2015-10-15T12:49:12Z,"what is the reason that we log here, but don't throw an exception?",0,0.9898219108581543
42126516,191,ijuma,2015-10-15T13:55:38Z,"ok, looking deeper into this, there is a difference: if someone else had called `setconfiguration`, `getconfiguration` would return that while here we override the value of configuration with the jaas file. neither option is ideal, but that's because of the global nature of this setting. i think just using `getconfiguration` is probably better, but i thought i'd mention it here for completeness.",0,0.9717162847518921
42127823,191,ijuma,2015-10-15T14:05:24Z,", do you know a way of doing this without using proprietary classes?",0,0.9930873513221741
42134970,191,rajinisivaram,2015-10-15T14:59:25Z,"sorry, i don't know of a standard way of doing this,",-1,0.9924718141555786
42186791,191,ijuma,2015-10-15T22:03:44Z,", what is the reason that we refresh tgt ourselves instead of using `renewtgt=true` in the jaas file?",0,0.9909123182296753
42187629,191,rajinisivaram,2015-10-15T22:12:12Z,why is servicename a property inside jaas config? could this be made one of the kafka sasl configuration properties instead? presumably it is used only by kafka code and hence doesn't belong in jaas.conf? ibm jdk kerberos module throws an exception because it doesn't recognize this property.,0,0.9909937977790833
42198931,191,harshach,2015-10-16T00:42:28Z,renewtgt=true doesn't mean it does the renewal on its own. if its a keytab you don't set it to renewtgt but if its kinit and the tgt in cache than we need to do the renewal.,0,0.9905705451965332
42199039,191,harshach,2015-10-16T00:44:03Z,"servicename always been used in jaas config and it has to match the keytab prinicpal name . since keytab is configured in the jaas config and it makes sense to keep it there. and all other projects from zookeeper, hdfs to everywhere else uses servicename in jaas config. i don't want to make that as an exception.",0,0.9713522791862488
42200491,191,ijuma,2015-10-16T01:13:49Z,"ok, i read from the following that it did: particularly this part ""with this feature, if krb5loginmodule obtains an expired ticket from the ticket cache, then the tgt will be automatically renewed and be added to subject of the caller who requested the ticket"" [a link] you are saying that this doesn't actually happen and we have to provide the implementation that does the actual renewal?",0,0.9936935305595398
42230500,191,ijuma,2015-10-16T10:55:40Z,"if all those projects use this property and the ibm jdk fails when it sees it, are they doing something to make it work with the ibm jdk? i looked at the zookeeper codebase and i couldn't find any code that retrieves a `servicename` from a jaas configuration file: [a link]",0,0.9912604689598083
42259558,191,rajinisivaram,2015-10-16T16:08:24Z,shouldn't this be a daemon thread? otherwise it would prevent client applications from terminating.,0,0.9863661527633667
42261859,191,junrao,2015-10-16T16:31:51Z,"it seems that we need the logic to turn off op_write here too. suppose that the client tries to send a token, but couldn't completely flush the writes. we get in here and completely flush the output buffer. now, if the op_write is not turned off, the selector will be woken up all the time before the client receives the next token from the broker.",0,0.9910669922828674
42261864,191,junrao,2015-10-16T16:31:56Z,"this seems to have the same issue as in saslclient in that we need the logic to turn off op_write here too. suppose that the server tries to send a token, but couldn't completely flush the writes. we get in here and completely flush the output buffer. now, if the op_write is not turned off, the selector will be woken up all the time before the server receives the next token from the client.",0,0.9906492829322815
42262890,191,ijuma,2015-10-16T16:42:30Z,"to make sure i understand, if we completely flush here, we continue executing the method. there are a few code paths where we call `sendsasltoken` which will turn off `op_write`. however, if we are in the intermediate state and we read to the `netinbuffer` but it's not complete, we could end up returning with the op_write on even though it should be off. is that the case you are outlining?",0,0.9921741485595703
42263662,191,junrao,2015-10-16T16:50:07Z,"that's right. if we are still waiting for a new token to be completely received, we will need to turn off op_write.",0,0.9929304122924805
42343337,191,ijuma,2015-10-19T07:52:15Z,i believe this is fixed in my next pr.,0,0.9780755639076233
42343338,191,ijuma,2015-10-19T07:52:19Z,i believe this is fixed in my next pr.,0,0.9780755639076233
42343484,191,ijuma,2015-10-19T07:54:15Z,"suggested that it shouldn't be because we wait for it to terminate on `shutdown`. and if consumers are closed, then it won't prevent client applications from terminating. but it may cause this problem when consumers are not closed, so i am tempted to change it back to a daemon thread. what are your thoughts jun?",0,0.963962733745575
42366614,191,ijuma,2015-10-19T12:53:41Z,i added a comment explaining this in my latest pr.,0,0.9941165447235107
42366668,191,ijuma,2015-10-19T12:54:17Z,"i added a todo about this, we probably need to solve it in a subsequent release.",0,0.9919134378433228
42366763,191,ijuma,2015-10-19T12:55:21Z,", this is not actually used at the moment. can you please point me to where it should be used and i can quickly address it?",0,0.9744095206260681
573093783,10070,rondagostino,2021-02-09T17:42:50Z,"should the second check appear within the first `if` as it does below in `touch()`? and assuming yes, maybe refactor that common logic out into a `private void removefromactiveandunfenced(brokerheartbeatstate broker)` method?",0,0.9947265982627869
573094685,10070,rondagostino,2021-02-09T17:44:04Z,`public void remove(...)`?,0,0.994017481803894
573095059,10070,rondagostino,2021-02-09T17:44:38Z,`boolean hasvalidsession(...)`?,0,0.9939875602722168
573095621,10070,rondagostino,2021-02-09T17:45:26Z,`public void touch(...)`?,0,0.9939830899238586
573098075,10070,rondagostino,2021-02-09T17:48:45Z,"this seems to imply that it is impossible for a broker to be doing a controlled shutdown and be fenced. i guess that means any controlled shutdown gets cancelled? a comment explaining the implications would be helpful. actually, from further down in `shouldshutdown()` it appears it can shutdown immediately if it is fenced -- so i think it's about leaders moving away? again, a comment would help.",0,0.8443116545677185
573113436,10070,rondagostino,2021-02-09T18:03:42Z,"at first i was confused as to why these two operations were necessary, then i realized it is because the instance is mutable and its places in the ordered list and `treeset` are going to change. a comment here would be helpful to make this apparent (i know there is a comment in the list and set declarations, but a reminder here would be helpful nonetheless).",0,0.9621631503105164
573115965,10070,rondagostino,2021-02-09T18:07:27Z,"`public void beginbrokershutdown(...)`? javadoc would be helpful, especially to explain what `deferred` is about. or, if `private` rather than `public`, at least a comment.",0,0.992093026638031
573116733,10070,rondagostino,2021-02-09T18:08:34Z,what is supposed to happen if it is already shutting down and this is invoked? will it matter if `deferred` is different in the second call?,0,0.9862810373306274
573117364,10070,rondagostino,2021-02-09T18:09:30Z,`public` or `private`? same with methods below.,0,0.9947364926338196
573122112,10070,rondagostino,2021-02-09T18:16:01Z,"is this the case because fenced implies leadership is already moving away? if so, a comment to that effect (or some additional wording in the log line) would be helpful.",0,0.9890649318695068
573123473,10070,rondagostino,2021-02-09T18:17:45Z,you seem to sometime use `shutdown` and other times use `shutdown` -- not sure if that is on purpose or there is a lack of consistency?,0,0.9536541700363159
573125162,10070,rondagostino,2021-02-09T18:20:10Z,`currlowestactiveoffset` a better name?,0,0.9866814613342285
573146291,10070,rondagostino,2021-02-09T18:50:32Z,what's the difference between `beginbrokershutdown()` and `updateshutdownoffset()`? why would the offset at which it can shutdown change? a comment would be helpful.,0,0.9915265440940857
573234880,10070,cmccabe,2021-02-09T20:57:26Z,"hmm, are you suggesting that it should be public? i'd rather not make this public because it's only accessed from within the controller package",0,0.9715537428855896
573235167,10070,cmccabe,2021-02-09T20:57:55Z,"hmm, i'm not sure i understand the question....",0,0.5462198257446289
573235373,10070,cmccabe,2021-02-09T20:58:15Z,"hmm, are you suggesting that it should be public? i'd rather not make this public because it's only accessed from within the controller package",0,0.9715537428855896
573236986,10070,cmccabe,2021-02-09T21:01:06Z,"thanks... that is a good catch. yes, it's a bit more efficient if the statements are nested. i will refactor this out into a separate function.",1,0.9937062859535217
573238990,10070,cmccabe,2021-02-09T21:04:59Z,"good question. a fenced broker will not have leaders, so there should be no leaders to move away. more specifically, if any fenced broker tries to enter controlled shutdown, it will be shut down immediately. i'll add a comment.",1,0.9276334643363953
573239810,10070,rondagostino,2021-02-09T21:06:23Z,"ok, i was just checking. these are all fine then.",0,0.9547887444496155
573240204,10070,rondagostino,2021-02-09T21:07:00Z,"sorry, was asking if it should be public -- but i assume not. was just checking. it's fine now.",-1,0.9814960360527039
573254808,10070,cmccabe,2021-02-09T21:29:21Z,if it's already shutting down nothing happens,0,0.8526489734649658
573254866,10070,cmccabe,2021-02-09T21:29:28Z,package-private is ok,0,0.9898909330368042
573256321,10070,cmccabe,2021-02-09T21:32:00Z,"in general it doesn't make sense to wait for controlled shutdown if the broker is already fenced, because in that case its leaders have already been moved away. i will add a comment.",0,0.9899307489395142
573256612,10070,cmccabe,2021-02-09T21:32:32Z,i wanted to standardize on shutdown. i will fix the inconsistency.,0,0.9892293810844421
573256853,10070,cmccabe,2021-02-09T21:33:00Z,i'll switch to `lowestactiveoffset`,0,0.9937995076179504
573342973,10070,junrao,2021-02-10T00:08:53Z,typo hwne,0,0.9711353778839111
573345382,10070,junrao,2021-02-10T00:15:25Z,the returned map is not keyed on partition.,0,0.9930276274681091
573345428,10070,junrao,2021-02-10T00:15:31Z,the returned map is not keyed on partition.,0,0.9930276274681091
573931818,10070,junrao,2021-02-10T17:32:46Z,do we also need to update the metric for processing time?,0,0.9946731925010681
573934771,10070,junrao,2021-02-10T17:36:55Z,could we move those private methods after all the internal classes?,0,0.9930166006088257
573952836,10070,junrao,2021-02-10T18:01:33Z,the return type is not a tuple.,0,0.9930371642112732
574130720,10070,junrao,2021-02-10T22:42:20Z,could we log lastkey too?,0,0.9953113198280334
574142240,10070,junrao,2021-02-10T23:00:23Z,is this used only for test?,0,0.9938699007034302
574147362,10070,junrao,2021-02-10T23:09:32Z,could we add a bit comment explaining logmanagers and batches?,0,0.9950754046440125
574158801,10070,junrao,2021-02-10T23:34:34Z,could we add a comment for maxreadoffset? is it the committed offset?,0,0.9950073957443237
574162564,10070,junrao,2021-02-10T23:37:53Z,"we already replay the message when it's first appended to the log and here we replay the same message again after commit. this could temporarily revert the state. for example, the latest (uncommitted) config could be overwritten by a previously committed config.",0,0.9931991696357727
574202545,10070,junrao,2021-02-11T01:33:46Z,this can throw stalebrokerepochexception. it would be useful for kafkaeventqueue.run() to log the event associated with the exception.,0,0.9933373928070068
574204032,10070,junrao,2021-02-11T01:39:11Z,"in the zk case, we use the zk version to do conditional updates. in raft, could we associated each partitionstate with the offset in the raft log and use that as partitionepoch for conditional updates? this way, we don't need to explicitly maintain a separate partitionepoch field and the epoch is automatically bumped up for any change to the partition record, not just for leader and isr.",0,0.9943329095840454
574204838,10070,junrao,2021-02-11T01:42:24Z,i thought the raft leader epoch is an int since we store only int as leader epoch in the log?,0,0.9906892776489258
574208116,10070,junrao,2021-02-11T01:51:20Z,"currently, the follower never removes the leader out of isr. so, perhaps we should just throw an exception if this is not the case.",0,0.9901382923126221
574209960,10070,junrao,2021-02-11T01:56:44Z,"this is in response to a heartbeat request. so, it should generate a response in controllerresult?",0,0.9950142502784729
574213985,10070,junrao,2021-02-11T02:13:48Z,some of the replay (e.g. unregister_broker_record) could throw exceptions. we probably need to turn the exception into an error response. are we handling that already?,0,0.9905588626861572
574216140,10070,junrao,2021-02-11T02:23:07Z,we probably should name this sth like removefromisrandmaybechooseleader.,0,0.9834089279174805
574216583,10070,junrao,2021-02-11T02:25:19Z,we need to choose at least a live replica.,0,0.9856369495391846
574765157,10070,junrao,2021-02-11T19:22:01Z,is that temporary?,0,0.9804893732070923
574773300,10070,junrao,2021-02-11T19:35:06Z,"in the zk based code, we also take live brokers into consideration when selecting a new leader.",0,0.9940763711929321
574843007,10070,junrao,2021-02-11T21:35:53Z,"hmm, not all partitions with isr containing the shutting down need to change the leader.",0,0.9778982996940613
574845213,10070,junrao,2021-02-11T21:39:46Z,we already did this check and the one below in the caller through `clustercontrol.checkbrokerepoch`.,0,0.9946644306182861
574846943,10070,junrao,2021-02-11T21:43:04Z,this seems unnecessary.,-1,0.5352888703346252
574869742,10070,junrao,2021-02-11T22:26:32Z,"if we want to log the shutting down the broker, it seems it's more consistent if we always log it. now, it seems we log it only when leaders need to be moved.",0,0.9881793260574341
574872303,10070,junrao,2021-02-11T22:31:36Z,"it seems that we if the request wants to shut down, we should always remove the shutting down broker from isr, just like moving the leader off the shutting down broker?",0,0.9888525009155273
575409674,10070,junrao,2021-02-12T18:00:36Z,"when a broker is unfenced, some of the partitions without leader could have a new leader now. so, it seems that we need to trigger a leader election here.",0,0.9902273416519165
575433620,10070,junrao,2021-02-12T18:26:12Z,"this call generates a leader change record before the following fencedbroker record. ordering wise, it seems that we should record the fencedbroker first. also, i am wondering what's the best place to trigger leader election and removing from isr due to fenced broker. there are multiple cases when a broker can be fenced (e.g. broker controlled shutdown, broker fenced due to no heartbeat). instead of of doing leader election and isr removal in all those cases, another option is to tigger them in a single place when a fencedbroker record is replayed.",0,0.9873408675193787
575435491,10070,junrao,2021-02-12T18:28:10Z,"since we use isrchangerecord for changing the leader too, could we name it to sth more general?",0,0.9940704703330994
575451381,10070,junrao,2021-02-12T18:47:30Z,"should we also trigger leader elections here? also, should we allow broker decommission when it still has replicas?",0,0.9936849474906921
575459759,10070,junrao,2021-02-12T19:03:12Z,"this should tigger leader election too, right?",0,0.9624189138412476
575475691,10070,junrao,2021-02-12T19:35:05Z,"is the intention of `shouldshutdown` to wait until the metadata of the shutting down broker is received by other brokers? if so, not sure why `beginbrokershutdown` sets `broker.shutdownoffset` to either max_long or 0. also, if `shouldshutdown` returns false, when do we get another opportunity to mark the shutting down broker as fenced?",0,0.9903461337089539
575478386,10070,junrao,2021-02-12T19:40:05Z,"in the zk based logic, on receiving a controlled shutdown request, the controller tries to move the leaders off the broker. if this is successful, the controller sends a successful return for the broker to proceed with shutdown. here, it seems that the controller will initially return shouldshutdown as false to the broker if there are leaders moved off the broker and require the broker to heartbeat again to be able to shut down.",0,0.9910364151000977
575480618,10070,junrao,2021-02-12T19:44:40Z,i thought we want to allow topics to be created even when there is not enough live brokers now?,0,0.9887019395828247
575514366,10070,junrao,2021-02-12T20:55:11Z,do we need to use `this`? ditto below.,0,0.9941444993019104
575516660,10070,junrao,2021-02-12T20:59:54Z,"hmm, should we return the future from `appendwriteevent` ?",0,0.9876696467399597
575525508,10070,junrao,2021-02-12T21:20:15Z,"sometimes, we update the in-memory state after the record is appended to the log. here, it seems that we do the reverse. should we make that consistent?",0,0.9911478757858276
575527291,10070,junrao,2021-02-12T21:24:36Z,it seems the broker can shut down immediately if this is false?,0,0.9919918179512024
575535738,10070,junrao,2021-02-12T21:45:14Z,could we just update `partitions` in place?,0,0.9931994080543518
575541127,10070,junrao,2021-02-12T21:58:46Z,what triggers this on a hard controller failure?,0,0.9885263442993164
575542308,10070,junrao,2021-02-12T22:01:47Z,should we trigger the logic for leader election/isr removal since there could be unhandled fencedbroker records when the new controller takes over?,0,0.9933876991271973
575546009,10070,junrao,2021-02-12T22:11:02Z,should this be changed to unregisterbroker to match the kip?,0,0.9948230981826782
575547292,10070,junrao,2021-02-12T22:14:39Z,should we call this sth like waitforshutdowncomplete to match `beginshutdown`?,0,0.9922724962234497
575548758,10070,junrao,2021-02-12T22:18:13Z,is this still needed with raft metadata?,0,0.9945864677429199
575548839,10070,junrao,2021-02-12T22:18:24Z,this class seems unused.,0,0.9593842029571533
575549084,10070,junrao,2021-02-12T22:19:01Z,this class seems unused.,0,0.9593842029571533
575549246,10070,junrao,2021-02-12T22:19:28Z,inaccurate comment.,-1,0.8814839124679565
575549741,10070,junrao,2021-02-12T22:20:43Z,could we add some comment for this class?,0,0.9951701760292053
575552471,10070,junrao,2021-02-12T22:25:10Z,it might be useful to log both the old and the new value.,0,0.9889601469039917
575554284,10070,junrao,2021-02-12T22:28:11Z,are we deprecating the state-change log and the controller log that we had before?,0,0.9922814965248108
577117523,10070,cmccabe,2021-02-16T20:31:01Z,"yes, it is. i will move it to the test directory.",0,0.9894357919692993
577125115,10070,cmccabe,2021-02-16T20:45:16Z,this code is only executed by the followers. it is true that the leader already applied these log messages but these nodes are not the leader.,0,0.9929560422897339
577127231,10070,cmccabe,2021-02-16T20:48:46Z,`handleeventexception` handles logging exceptions thrown by events.,0,0.9910646677017212
577135430,10070,cmccabe,2021-02-16T21:02:02Z,"yes, i think that could work for partition epoch. let's do that once we have the initial code in, though...",0,0.9887847900390625
577136289,10070,cmccabe,2021-02-16T21:03:31Z,"it is an int and will be in 2.8, but i think that's a mistake (as discussed in the mailing list) and we should plan to make this 64 bit in the near future to avoid overflow issues. so the controller code treats it as a long... cc",0,0.9481443762779236
577143791,10070,cmccabe,2021-02-16T21:17:09Z,ok. we can make this an invalid request then.,0,0.9865929484367371
577146421,10070,cmccabe,2021-02-16T21:21:53Z,"hmm, this comment shows up for me as being left in the `decommissionbroker` function, which is called in response to the decomission broker rpc, not the heartbeat rpc. maybe this is a github ui issue? did you mean to leave this comment for a different function?",0,0.9814002513885498
577147155,10070,rondagostino,2021-02-16T21:23:19Z,i believe after this we need to invoke something to cover the case where a topic has this broker as its only isr member: [code block] the implementation might look like this: [code block],0,0.9920430779457092
577148107,10070,cmccabe,2021-02-16T21:25:13Z,if an exception is thrown here we will end up in `handleeventexception`. since the exception won't be a subclass of `apiexception` we will resign as controller and return an `unknownserverexception`.,0,0.9898982644081116
577148212,10070,rondagostino,2021-02-16T21:25:26Z,i believe we should surround this section of code with the following to be sure we never drop the last isr member: [code block],0,0.988652765750885
577163457,10070,cmccabe,2021-02-16T21:52:59Z,i changed it to `removefromisrandleaderships`,0,0.9948058724403381
577167409,10070,cmccabe,2021-02-16T21:58:24Z,"good point, will fix",1,0.9813339114189148
577167941,10070,cmccabe,2021-02-16T21:59:17Z,this has to be handled by the individual brokers. it's not persisted anywhere currently (currently it is not stored in zk i believe),0,0.9927156567573547
577176042,10070,cmccabe,2021-02-16T22:14:05Z,"in this function we are iterating only over the partitions that the given broker is a leader for. ( we obtained the iterator from `brokerstoisrs#iterator(brokerid=brokerid, leadersonly=true)` )",0,0.9943773150444031
577178197,10070,cmccabe,2021-02-16T22:18:19Z,ok,0,0.9233372807502747
577187004,10070,cmccabe,2021-02-16T22:34:34Z,"i will improve the logging a bit here. i agree that we should log when a broker is told it can shut down or be (un) fenced, since those are major events.",0,0.9766851663589478
577188202,10070,cmccabe,2021-02-16T22:36:59Z,"it seemed safer to leave it in the isr until it's ready to shut down for good. also, if we take it out, it might just get re-added if it catches up... ?",0,0.9739930629730225
577214559,10070,cmccabe,2021-02-16T23:36:58Z,"good point. the appropriate place to handle this will be in the broker heartbeat handling code, since that is where the active controller unfences brokers.",1,0.967029333114624
577217605,10070,cmccabe,2021-02-16T23:44:42Z,"hmm... it should be ok to remove the leaderships first. kip-500 controlled shutdown works this way, for example... the shutting-down broker is not actually fenced at all until all the other brokers have removed it as a leader. also, wouldn't it be a bit weird to be in a state where a broker is still marked as the leader for some partition, but doesn't show up in the list of brokers given in the metadataresponse? that would happen if we put the fencing record first. i don't think clients or brokers would handle this well. replaying a record cannot trigger the creation of any additional records. this would not work since the standby controllers can't create records, after all... only the active controller. i have created a `handlebrokerfenced` function in `replicationcontrolmanager` which does most of what needs to be done for fencing, though... aside from creating the actual fencing record.",0,0.610748291015625
577259797,10070,junrao,2021-02-17T01:23:48Z,sounds good. could we add a comment to make that clear?,1,0.8447631597518921
577262652,10070,junrao,2021-02-17T01:31:42Z,it seems that we are logging at the debug level. i am wondering if we should log at warn as before in zk based appoach. [code block],0,0.9771174192428589
577263866,10070,junrao,2021-02-17T01:35:14Z,"i thought the issue was that if changing leaderepoch to long requires a log format change for user data, it has significant performance impact such as down conversion.",0,0.9631685614585876
577268593,10070,junrao,2021-02-17T01:48:41Z,"sorry, i meant `decommissionbroker`. it seems that decommissionbroker request should we a response too, right?",-1,0.9694631695747375
577278241,10070,junrao,2021-02-17T02:16:16Z,"well, in zk based approach, in response to a controlled shutdown, the controller changes isr and the leader. here, it seems that `result.response().isfenced()` is not always true if the broker heartbeat indicates the intention to shut down?",0,0.9923644065856934
577865782,10070,cmccabe,2021-02-17T18:57:08Z,"i normally do group private methods after internal classes, but in this case, it seemed better to keep them together. otherwise you'd have to jump around a lot when reading the code. what do you think?",0,0.9638305902481079
577866850,10070,cmccabe,2021-02-17T18:58:41Z,added,0,0.8435775637626648
577868843,10070,cmccabe,2021-02-17T19:01:51Z,"we can get here just because the user made an invalid rpc, so i don't know if warn is appropriate. i'll change it to info for now.",0,0.9859241843223572
577879960,10070,junrao,2021-02-17T19:19:29Z,sounds good too.,1,0.889298141002655
577894071,10070,cmccabe,2021-02-17T19:42:26Z,"note: this has been changed to unregisterbroker as per the mailing list discussion. it's ok to have a future that returns void. that just means you either get success, or an error (there is no other result). which is consistent with unregisterbrokerresponse.json, etc.",0,0.9839492440223694
577895640,10070,cmccabe,2021-02-17T19:45:07Z,hmm... we only fence the broker once controlled shutdown has completed. if we fenced it immediately that would be disruptive to clients since they wouldn't be able to continue fetching from it until the leaderships have moved. basically immediate fencing is the non-controlled shutdown path....,0,0.9234375357627869
577914392,10070,cmccabe,2021-02-17T20:16:22Z,i have renamed it to `partitionchangerecord`,0,0.9954311847686768
577915565,10070,cmccabe,2021-02-17T20:18:09Z,"good catch. yes, this should be moving leaders. i fixed this in the latest version of the pr. yes, this is allowed.",1,0.989751935005188
577916179,10070,cmccabe,2021-02-17T20:19:10Z,"i restructured this code a bit. but yes, it does move leaders if needed (it's clearer in the new version i think)",0,0.9908599257469177
577916633,10070,cmccabe,2021-02-17T20:19:56Z,"this got refactored, hopefully the new version is clearer. the new version avoids the max_long / 0 hack and other ugliness that was in the initial version.",0,0.8824070692062378
577916988,10070,cmccabe,2021-02-17T20:20:33Z,that is correct. the broker must send another heartbeat before it is allowed to shut down.,0,0.9931749701499939
577918400,10070,cmccabe,2021-02-17T20:23:00Z,"good point. since we don't have much time for 2.8, i will add a todo for now.",1,0.9695138335227966
577919102,10070,cmccabe,2021-02-17T20:24:17Z,good catch.,1,0.9776482582092285
577919831,10070,cmccabe,2021-02-17T20:25:33Z,"the heartbeat manager is special because it stores soft state which is not in the metadata log (when each broker last heartbeated, for example).",0,0.9896085858345032
577920156,10070,cmccabe,2021-02-17T20:26:04Z,"this got refactored. hopefully it is clearer now. yes, a broker can shut down immediately in some cases",0,0.8414033651351929
577920610,10070,cmccabe,2021-02-17T20:26:52Z,since this is stored in a `timelinehashmap` it must be treated as immutable. we can't modify the past.,0,0.9922409057617188
577921275,10070,cmccabe,2021-02-17T20:27:54Z,this comes out of the raft layer and is invoked when the raft election has succeeded and produced a new leader node.,0,0.9946050047874451
577922334,10070,cmccabe,2021-02-17T20:29:46Z,"the standby controller must replay all the committed records before becoming active. so, there is no unfinished work to be done at this point.",0,0.9951576590538025
577922831,10070,cmccabe,2021-02-17T20:30:39Z,"the name close comes from `autocloseable`, which makes some of the tests nicer to write (because we can use the java try-with-resources syntax).",0,0.9885518550872803
577929118,10070,cmccabe,2021-02-17T20:41:57Z,"i don't think the state change log can scale to the number of partitions we need. it gets too verbose. also, this information is available in the metadata log itself.",0,0.8210969567298889
577929403,10070,cmccabe,2021-02-17T20:42:29Z,"thanks, . in the latest version, i do not remove brokers from singleton isrs.",1,0.9494513869285583
577961646,10070,rondagostino,2021-02-17T21:36:39Z,`mockcontrollermetrics` is a test class?,0,0.9940523505210876
577971959,10070,rondagostino,2021-02-17T21:54:59Z,"maybe it would be better to check for null and exit out if it is unset -- otherwise we see this, which is not ideal: [code block]",0,0.9602201581001282
577993008,10070,junrao,2021-02-17T22:34:45Z,"in the old controller, eventqueuetimems is used to measure the amount of time an event is sitting in the queue before being processed. there is a separate timer metric per controller state that measures the processing time per event type.",0,0.9939528107643127
578003900,10070,junrao,2021-02-17T22:58:11Z,it seems that using long for leaderepoch in the log requires a bigger discussion. could we use int for now?,0,0.9866340160369873
578014387,10070,junrao,2021-02-17T23:22:16Z,"if a broker wants to shut down and is only included in isr, we still want to remove the broker from isr before allowing it to shutdown. otherwise, a new published record needs to wait for the session timeout before it can be committed.",0,0.9906154870986938
578015133,10070,junrao,2021-02-17T23:24:13Z,what about the case when request.wantfence() is true?,0,0.9923008680343628
578019439,10070,junrao,2021-02-17T23:35:12Z,"(1) in zk-based approach, we do leader election a bit differently for controlled shutdown. if we can't select a leader from the remaining isr, we just leave the current leader as it is. this gives the shutting down broker a chance to retry controlled shutdown until the timeout. (2) in zk-based approach, we also remove the broker from isr for other partitions whose leader is not on the shutting down broker. that's true and is an existing problem. one way to address this is to include partitionepoch in the follower fetch request. the leader could then reject a follower request if the partitionepoch doesn't match. this can be done in a followup pr.",0,0.9787390828132629
578026068,10070,junrao,2021-02-17T23:52:30Z,could we add a todo for handling the preferred leader election?,0,0.9937649965286255
578028795,10070,junrao,2021-02-17T23:59:48Z,should this be named unregisterbroker?,0,0.9934660792350769
578047059,10070,junrao,2021-02-18T00:51:31Z,is this check already implied since we are iterating `brokerstoisrs`?,0,0.9943829774856567
578054305,10070,junrao,2021-02-18T01:08:09Z,is there any benefit/enough to only allow the broker to shutdown when all brokers have caught up to controlledshutdownoffset? the zk-based criteria is that a broker is allowed to shut down as long as all leaders have been moved off the shutting down broker.,0,0.9933881759643555
578062730,10070,junrao,2021-02-18T01:31:49Z,we are generating an unregisterbrokerrecord.,0,0.9946630001068115
578065045,10070,junrao,2021-02-18T01:36:55Z,are all records generated in a single controllerwriteevent appended to the metadata log atomically?,0,0.9950630068778992
578067236,10070,junrao,2021-02-18T01:43:22Z,"hmm, the comment seems to be the same as shouldshutdown.",0,0.9652805924415588
578071150,10070,junrao,2021-02-18T01:55:21Z,testfindstalebrokers ?,0,0.9910111427307129
578076422,10070,junrao,2021-02-18T02:09:31Z,could we make it private?,0,0.9929070472717285
578079100,10070,junrao,2021-02-18T02:17:13Z,testunregister?,0,0.9912484884262085
578080050,10070,junrao,2021-02-18T02:19:53Z,testplacereplicas ?,0,0.9938321113586426
578603931,10070,cmccabe,2021-02-18T17:19:36Z,"good point. i will fix it so that eventqueuetimems has its original meaning. for now, i have added a metric called eventqueueprocessingtimems which deals with processing time. i do want to do the per-state tracking but i don't think we have time right now",1,0.9597001075744629
578606545,10070,junrao,2021-02-18T17:23:17Z,an empty topic name currently results in an invalid_request error.,0,0.9853115081787109
578613805,10070,junrao,2021-02-18T17:32:32Z,an empty broker currently results in an invalid_request error.,0,0.9837856888771057
578619727,10070,cmccabe,2021-02-18T17:40:46Z,"ok, that makes sense. i will remove it from all non-singleton isrs as well as removing it from all leaderships.",0,0.9894164204597473
578621621,10070,cmccabe,2021-02-18T17:43:39Z,"good question. the broker doesn't currently request fencing once it is unfenced. but for completeness, it is simple to support this and it makes the code more intuitive, so i'll add it.",1,0.9751560091972351
578625531,10070,cmccabe,2021-02-18T17:49:18Z,"as i mentioned above, i changed it so that it now removes the broker from all non-singleton isrs, as well as removing it from leaderships. it seems like the remaining behavioral difference is that the new code will, if no other leader can be chosen, set the leader to -1 (offline). if we don't do this, controlled shutdown easily gets stuck if there are any partitions with replication factor = 1. maybe we can tune this a bit later? i like the idea of including the partition epoch in the follower fetch request.",0,0.8612436652183533
578627766,10070,cmccabe,2021-02-18T17:52:32Z,"hmm, i thought this already handles preferred leader election (there are only two options, preferred and unclean, so far...)",0,0.9255391955375671
578628736,10070,cmccabe,2021-02-18T17:53:57Z,good catch. this has been superseded by `replicationcontrolmanager#unregsiterbroker`.,1,0.9915394186973572
578629900,10070,cmccabe,2021-02-18T17:55:39Z,"we're iterating over the partitions with no leader, which may or may not have the newly activated broker in their isr.",0,0.9914064407348633
578630655,10070,cmccabe,2021-02-18T17:56:43Z,"basically it lets us know that the other brokers have successfully taken over as leader (where needed) which avoids having a period of unavailability, ideally",0,0.9882947206497192
578648887,10070,cmccabe,2021-02-18T18:23:21Z,fixed,0,0.920660674571991
578664492,10070,junrao,2021-02-18T18:47:22Z,do we allow a heartbeat request to set both the fence and wantshutdown flag?,0,0.9932685494422913
578667056,10070,junrao,2021-02-18T18:51:14Z,"it's fine to revisit that later. the tradeoff is that if we wait, it slightly increases the probability of availability since another replica could join isr.",0,0.9910936951637268
578669898,10070,junrao,2021-02-18T18:55:42Z,"i think we need to handle preferred leader election in a special way. for example, if the assigned replicas are 1,2,3, isr is 2,3 and the current leader is 3, when doing preferred leader election, we want to keep the leader as 3 instead of changing it to 2.",0,0.9850127696990967
578693886,10070,junrao,2021-02-18T19:35:29Z,"this can be revisited later. when finalizing a feature, should be consider other controller's supported features too?",0,0.9950364232063293
578696957,10070,junrao,2021-02-18T19:40:18Z,this class seems never used?,0,0.9892772436141968
578699530,10070,junrao,2021-02-18T19:44:45Z,could we add some comments for this class?,0,0.995048463344574
578700824,10070,junrao,2021-02-18T19:46:48Z,"to make this more intuitive, perhaps we could add a method isactive in quorumcontroller?",0,0.9931647181510925
578722110,10070,junrao,2021-02-18T20:23:39Z,"hmm, why is a replication factor of 1 invalid?",0,0.9618034362792969
578817527,10070,cmccabe,2021-02-18T23:24:41Z,a resource with type broker and an empty name represents a cluster configuration that applies to all brokers. i'll add a comment,0,0.9954665899276733
578817611,10070,cmccabe,2021-02-18T23:24:57Z,"yes, it can set both",0,0.9937410950660706
578850598,10070,cmccabe,2021-02-19T00:54:40Z,"hmm... right now, we don't have a good way of finding out what features the other controllers support. maybe we will have to think more about this when we support rolling upgrade in kip-500.",0,0.7545461058616638
578850804,10070,cmccabe,2021-02-19T00:55:21Z,it's used in unit tests,0,0.9939271807670593
578851481,10070,junrao,2021-02-19T00:57:07Z,"yes, that's the problem. from a consistency perspective, it seems that we should use the supported features from either all controller nodes or none.",0,0.89750736951828
578857828,10070,cmccabe,2021-02-19T01:15:22Z,"there are no unfenced brokers (as you mentioned earlier, we should change this so that it places on the fenced broker). i will add a todo",0,0.9956626296043396
578876029,10070,junrao,2021-02-19T02:10:09Z,could we add some comments to this class?,0,0.9950346946716309
578877349,10070,junrao,2021-02-19T02:14:23Z,"well, currently the contract is just that if every broker picks the preferred replica (i.e. 1st replica), the leaders will be balanced among brokers. if not, all other replicas are equivalent. moving leaders among non-preferred replicas just creates churns without benefiting the balance.",0,0.9701617956161499
578878282,10070,junrao,2021-02-19T02:17:34Z,"as jason pointed out, in zk based approach, the controller bumps up the leader epoch for removing replica from isr too. also, since the broker is no longer receiving the leaderandisr requests, we need some logic for the broker to ignore the new partition record (for follower fetching) once it starts the controlled shutdown process.",0,0.9931830763816833
579374802,10070,cmccabe,2021-02-19T18:04:52Z,"this is resolved in the latest version of the code, where we disable metadata updates on the shutting down broker before starting controlled shutdown, and bump the leader epoch of all partitions.",0,0.9944199919700623
579378306,10070,cmccabe,2021-02-19T18:10:42Z,"i changed this so that the leader epoch is bumped if and only if there is a leader present in the partitionchange record. (it is possible to bump the epoch without changing the leader by including the same leader again in the record.) we now use this during controlled shutdown to unconditionally bump the leader epochs. otherwise, we only bump the leader epochs if the leader changed.",0,0.9931210875511169
579403297,10070,junrao,2021-02-19T18:50:24Z,"hmm, does integer.min_value have any special meaning? if so, could we use a more intuitive constant?",0,0.9804791212081909
579406849,10070,junrao,2021-02-19T18:56:29Z,"hmm, if the leader is already -1 and we can't change isr, there is no need to generate a new partitionchangerecord just to bump up the leader epoch. it won't help controlled shutdown since there is already no leader.",0,0.9808371663093567
579410463,10070,junrao,2021-02-19T19:01:26Z,"currently, for controller initiated isr change (controlled shutdown or hard failure), we always bump up the leader epoch. also, the name alwaysbumpleaderepoch is a bit weird since the code in handlenodedeactivated() doesn't directly bump up leader epoch.",-1,0.9294599294662476
579411851,10070,junrao,2021-02-19T19:03:59Z,"currently, for leader initiated alterisr request, the controller doesn't bump up the leader epoch. if we change that, it will slightly increase unavailability since all clients have to refresh the metadata in this case.",0,0.9886038303375244
579414289,10070,junrao,2021-02-19T19:08:23Z,"if we do this, does `brokermetadatalistener.close() `still need to call `beginshutdown()`.",0,0.9902708530426025
579421318,10070,junrao,2021-02-19T19:21:16Z,"hmm, it seems that we should only do `newleader != partitioninfo.preferredreplica()` if this is a preferred leader election.",0,0.9761382341384888
579438984,10070,junrao,2021-02-19T19:54:01Z,"hmm, merge bumps up the leaderepoch. it seems that this needs to be persisted in the metadata log?",0,0.9849559664726257
579458466,10070,cmccabe,2021-02-19T20:31:19Z,no special meaning. it's just a constant that can't be a valid leader. we could use -2 if that seems nicer.,0,0.9637399315834045
579462462,10070,cmccabe,2021-02-19T20:38:40Z,hmm... i don't completely understand why we would want to bump the leader epoch when the controller removes a non-leader broker b but not when an alterisrrequest removes a non-leader broker b from the isr. it seems like we should either bump in both scenarios or neither. is the fact that we bump in the first scenario just an artifact of the fact that otherwise we could not send out a leader and isr request that had a new epoch and thereby caused a change?,0,0.8720771074295044
579463797,10070,cmccabe,2021-02-19T20:41:39Z,"hmm... replicationcontrolmanager should not allow this to happen during an alter isr request. there is some code that checks if the alter isr request is attempting to remove the current leader from the isr, and returns an error if so. so the leader should not be changed by an alter isr request and therefore the leader epoch will not be. [code block]",0,0.9686295390129089
579464755,10070,cmccabe,2021-02-19T20:43:43Z,it does need to be because there are some paths through the code that don't go through here. in general calling `beginshutdown` or `close` multiple times is harmless-- only the first time has an effect.,0,0.9886434674263
579496903,10070,junrao,2021-02-19T21:52:36Z,"yes, the alterisr doesn't change leader, but generates a partitionchangerecord. on replaying this record, the code following code bumps on leaderepoch? ` partitioncontrolinfo newpartitioninfo = prevpartitioninfo.merge(record);`",0,0.9935280680656433
579497748,10070,junrao,2021-02-19T21:54:30Z,"ok, maybe the check can be `record.leader()< -1`?",0,0.9945100545883179
579522201,10070,cmccabe,2021-02-19T22:47:15Z,"even in an unclean leader election, we don't want to change the leader unless we need to.",0,0.7376410365104675
579522827,10070,cmccabe,2021-02-19T22:48:43Z,"the leader epoch is managed implicitly -- every time a partitionchangerecord appears, the epoch is bumped if the leader is not no_leader_change.",0,0.9940482378005981
579536414,10070,junrao,2021-02-19T23:28:15Z,"hmm, we should set the leader to no_leader_change, right?",0,0.977627158164978
579538752,10070,junrao,2021-02-19T23:37:14Z,could you file a separate jira to follow up on partitionepoch post 2.8?,0,0.9952440857887268
579547098,10070,cmccabe,2021-02-20T00:07:59Z,that is the default so we don't need to set it unless we're changing it,0,0.9927299618721008
579547404,10070,cmccabe,2021-02-20T00:09:24Z,filed kafka-12349,0,0.9930476546287537
579547731,10070,cmccabe,2021-02-20T00:10:42Z,merge only bumps the epoch if the leader was set. [code block],0,0.9937928915023804
579547825,10070,cmccabe,2021-02-20T00:11:10Z,"as per our discussion outside github, let's just use the old behavior for now.",0,0.9927178621292114
579547910,10070,cmccabe,2021-02-20T00:11:40Z,i added a constant. i think it looks a little nicer...,1,0.8714035153388977
579553251,10070,junrao,2021-02-20T00:35:14Z,"we have no_leader_change as the default for the serialized data. however, the active controller replays the partitionchangerecord created in memory, which defaults leader to no_leader_change, right?",0,0.9935203194618225
579564268,10070,cmccabe,2021-02-20T01:15:01Z,let's revisit this after 2.8,0,0.9919695258140564
579564579,10070,cmccabe,2021-02-20T01:16:31Z,right now the answer is yes. eventually we plan on supporting multiple batches.,0,0.9815835356712341
579564654,10070,cmccabe,2021-02-20T01:17:04Z,"i do think we should harmonize this, but i think it would be better to do that when we get rid of metalogshim. we've had a plan to get rid of the shim layer for a while but we just didn't have time to do it this week. so let's plan to do it then, if that makes sense",0,0.9501715898513794
579565540,10070,cmccabe,2021-02-20T01:21:30Z,ack. i fixed this,0,0.7959722876548767
580411938,10070,junrao,2021-02-22T16:54:21Z,do we have a jira to track this?,0,0.9931195974349976
136670512,3765,junrao,2017-09-01T21:42:22Z,could you carry over the comments in replicastatemachine about the possible state changes and the corresponding actions? ditto for the new partitionstatemachine.,0,0.9943722486495972
136672966,3765,junrao,2017-09-01T22:00:28Z,"i am actually not sure if we need to read the partition state from zk in this case. the transition to newreplica is only used in 2 places: (1) starting a new replica in partition reassignment, (2) when a new topic is created. in (1), if there is a leader, it will already be cached by the controller. in (2), currently, it seems it's guaranteed there is not a leader at this point. a subsequent transition to onlinepartition in onnewpartitioncreation() will do the leader election part. so, it seems that we can (a) just read the cached leader info, (b) call brokerrequestbatch.addleaderandisrrequestforbrokers if leader is available and doesn't equal to current replica, (c) move the replica to newreplica state unless the leader equals to the current replica, (d) we probably also want to log an error if the new replica happens to be the leader.",0,0.9610615968704224
136675513,3765,junrao,2017-09-01T22:24:23Z,it will be useful to document the response since it is a bit complicated.,0,0.9745439291000366
136678656,3765,junrao,2017-09-01T22:59:27Z,"it seems that it may be possible for the response to have a sequence of connectionloss, followed by a sequence of ok when the session was disconnected and then reconnected again. so, we may want to just do filter instead of takewhile.",0,0.990487277507782
136679343,3765,junrao,2017-09-01T23:07:29Z,it will be useful to explicitly define the return type in each of the public methods to make it clear.,0,0.9927651286125183
136679765,3765,junrao,2017-09-01T23:13:11Z,"hmm, will kafkacontrollerzkutils.gettopicpartitionstates ever throw an exception?",0,0.971095085144043
136872413,3765,junrao,2017-09-04T21:52:57Z,"it seems that we only need to check the topic config if the isr is empty after replicaid is removed from isr, not before.",0,0.9901132583618164
136872700,3765,junrao,2017-09-04T22:00:02Z,"for those partitions whose isr can't be shrunk due to making isr empty, we simply keep the current isr. so, it seems in this case, we can just do an optimization by not sending the leaderandisrrequest for those partition since neither the leader nor the isr will change.",0,0.990884006023407
136873950,3765,junrao,2017-09-04T22:29:21Z,"hmm, do we need the logic here? it seems that we are refreshing the topic partition state when retrying doremovereplicasfromisr. so, reading the topic partition state here seems redundant.",0,0.9766939878463745
136874953,3765,junrao,2017-09-04T22:57:06Z,we will need to handle nonode error here by creating the missing parent path if needed.,0,0.9934410452842712
136875070,3765,junrao,2017-09-04T23:00:51Z,check the error code?,0,0.99196457862854
136875311,3765,junrao,2017-09-04T23:06:24Z,it seems that we should do this in a while loop since we do conditional update to the leaderandisr path in zk and need to retry on badversion.,0,0.9847099184989929
136875649,3765,junrao,2017-09-04T23:15:27Z,"partitionswithuncleanleaderelectionstate includes partitions that don't need unclean leader election. so, the name seems a bit miss-leading.",0,0.8036556839942932
136876376,3765,junrao,2017-09-04T23:35:34Z,"ideally, we want to select the preferred replica if it's alive, in-sync and not shutting down as controlledshutdownleaderselector does.",0,0.9917969703674316
136876429,3765,junrao,2017-09-04T23:36:33Z,unused import,0,0.9873000979423523
136876599,3765,junrao,2017-09-04T23:40:15Z,"if a create operation retries due to code.connectionloss, it's possible for the retry to receive a nodeexist error since the previous create may have succeeded. perhaps on nodeexist error during retry, we can read the value back and only return nodeexist error if the value is different from that to be created.",0,0.9914706349372864
136876729,3765,junrao,2017-09-04T23:44:05Z,do we need to add some general handling for errors like noauth?,0,0.9927800297737122
136903037,3765,onurkaraman,2017-09-05T06:23:29Z,yeah i noticed this as well. i mainly just wanted to keep the existing behavior the same and worry about tweaking the existing behavior in later patches. the only reason i can come up with for this zk lookup is to notice if another controller takes over while this current controller is in the process of doing this transition.,0,0.9762921929359436
136904968,3765,onurkaraman,2017-09-05T06:39:48Z,"it seems that in this scenario today, the leadership changes to leaderandisr.noleader (-1), the leader epoch increments, and the zkversion increments too. we send leaderandisrrequests to the full replica set (not just isr) and also send updatemetadatarequests to the whole cluster with this updated leaderandisr with leader = -1, isr = old isr with the single replica, the incremented leader epoch, and the incremented zkversion. in fact, whenever we send a leaderandisrrequest, we also broadcast updatemetdatarequests to the whole cluster. are you suggesting we do neither of these things? skipping these steps means that: 1. non-isr replicas will not be aware of the incremented leader epoch and zkversions. 2. the cluster will not receive the updated metadata.",0,0.9842839241027832
136905187,3765,onurkaraman,2017-09-05T06:41:27Z,"it's possible since it internally calls zookeeperclient.waituntilconnected, which can throw exceptions (zookeeperclientauthfailedexception and zookeeperclientexpiredexception).",0,0.9937518239021301
136906744,3765,onurkaraman,2017-09-05T06:53:16Z,it attempts to mimic the existing behavior in replicationutils.checkleaderandisrzkdata (which is called from replicationutils.updateleaderandisr). strictly speaking i don't think this logic is required. i think it just attempts to make progress on a version conflict (for instance if the partition leader concurrently updated isr) instead of starting over.,0,0.9893360137939453
137011097,3765,junrao,2017-09-05T14:53:43Z,"hmm, since we are fixing the issue with zk session expiration, there shouldn't be more than 1 controller accessing zk at the same time. in general, i agree that we don't want to make major changes to partition/replicastatemachine while refactoring zk accesses. however, if this simplifies how we use zk, it may be worth doing.",0,0.9694275856018066
137011133,3765,junrao,2017-09-05T14:53:51Z,"ah, ok. so, we did change the leader in this case.",0,0.9765036702156067
137011245,3765,junrao,2017-09-05T14:54:07Z,"hmm, for both zookeeperclientauthfailedexception and zookeeperclientexpiredexception, we probably don't want to retry forever in removereplicasfromisr(). it seems that we should just log an error and move on.",0,0.9523382782936096
137011321,3765,junrao,2017-09-05T14:54:22Z,"ok, that logic is just to handle the possibility that a previous write has succeeded on a connectionlossexception. it would be useful to document that.",0,0.9924132227897644
137052511,3765,onurkaraman,2017-09-05T16:58:18Z,it's not terribly clear but that's actually the behavior in the pr.,0,0.96347975730896
137159386,3765,onurkaraman,2017-09-06T02:34:25Z,this falls in the category of suggestions that differ in current behavior. again i'm not sure if we want to overload this pr with more than just porting existing behavior.,0,0.8296389579772949
137159912,3765,onurkaraman,2017-09-06T02:40:39Z,"in the case of `kafkacontrollerzkutils.createtopicpartitionstates`, we're creating the state znode for the first time, in which case the following parent znodes almost definitely will not exist: * /brokers/topics/\ /partitions * /brokers/topics/\ /partitions/\ * /brokers/topics/\ /partitions/\ /state so perhaps in this case, we should push the creation of these parent znodes into `kafkacontrollerzkutils.createtopicpartitionstates`.",0,0.9880262017250061
137160199,3765,onurkaraman,2017-09-06T02:43:52Z,"yeah as stated in one of my earlier pr comments, no effort has been put into partitionstatemachinev2 yet to do error handling and retries. the idea was to first validate that the overall strategy would work in replicastatemachinev2 and then apply error handling and retries to partitionstatemachinev2.",0,0.9883151054382324
137167391,3765,onurkaraman,2017-09-06T04:07:12Z,there was one typo in gettopicpartitionstatesfromzk: `val candidateisr = leaderisrandcontrollerepoch.leaderandisr.isr.filternot(_ != replicaid)` should be: `val candidateisr = leaderisrandcontrollerepoch.leaderandisr.isr.filter(_ != replicaid)` but otherwise we actually do the topic config checks only on the partitions whose isr is empty after removal. note that the `candidateleaderandisrs` returned is used to find `partitionswithemptyisr` which is what we pass into `leaderandisrbasedonlogconfigs`.,0,0.992195725440979
137349319,3765,junrao,2017-09-06T18:18:11Z,"yes, that sounds good.",1,0.5444263219833374
138211018,3765,junrao,2017-09-11T22:39:08Z,"it seems that we will need to set acl based on whether zk security is enabled or not, like what zkutils.defaultacls() does.",0,0.9873679280281067
138212390,3765,junrao,2017-09-11T22:47:47Z,this method can be private.,0,0.9950203895568848
138451688,3765,junrao,2017-09-12T20:06:03Z,perhaps we should also log an error for any other error code?,0,0.9905367493629456
138454615,3765,junrao,2017-09-12T20:19:12Z,"hmm, there is a bit of inconsistency here in how we deal with exceptions from zk calls. in general, it seems that exceptions (e.g. authorization error, session closed, etc) are not retriable. so, we probably should return them in a failed partition map as what we do in getlogconfigs().",0,0.9533592462539673
138478606,3765,junrao,2017-09-12T22:03:50Z,"i think we can simplify this logic a bit. badversion can happen because of updates from another client (e.g., leader) or retries from a connection loss. technically, for the latter, we can do a read and avoid updating the path again if the new value is already in place. however, it seems that it's simpler to just return any partition with badversion as updatestoretry and the let the caller retry. the caller already has the logic to read the latest value from zk on retry. since connection loss is rare, doing an extra write when it happens is probably ok.",0,0.9511236548423767
138480660,3765,junrao,2017-09-12T22:14:37Z,"hmm, it seems any other error is not really retriable and should be returned in a failed partition map.",0,0.9672882556915283
138489383,3765,junrao,2017-09-12T23:09:11Z,"""controller %d epoch %d initiated state change for partition %s from %s to %s failed"" => ""controller %d epoch %d failed to change state for partition %s from %s to %s"" ?",0,0.9880654215812683
138490985,3765,junrao,2017-09-12T23:20:44Z,"hmm, it seems the convention should be that any exception is a non-retriable error and we will just log an error on those partitions, and then move on w/o retry.",0,0.959047257900238
138495827,3765,junrao,2017-09-12T23:55:43Z,"we want to pick the preferred replica if possible. isr in general is not ordered. so, we want to go through assigned_replicas in order as controlledshutdownleaderselector does.",0,0.9944756627082825
138496088,3765,junrao,2017-09-12T23:57:37Z,would the code be easier to read if we just return failed partitions to electleaderforpartitions() and log the error there?,0,0.9891983866691589
138499176,3765,junrao,2017-09-13T00:23:11Z,same comment here. would the code be easier to read if we just return failed partitions to removereplicasfromisr() and log the error there?,0,0.994508683681488
138501599,3765,junrao,2017-09-13T00:46:26Z,it's a bit inconsistent to return currentleaderandisrs since it includes candidateleaderandisrs. it seems it's easier to understand if we return 4 disjoint sets. the first two parts could then be named partitionswithoutreplicainisr and partitionswithreplicainisr,0,0.9009963870048523
138502217,3765,junrao,2017-09-13T00:52:27Z,it seems that we should extract the topic set before passing into kafkacontrollerzkutils.getlogconfigs()?,0,0.993280827999115
138502301,3765,junrao,2017-09-13T00:53:17Z,could topics be a set?,0,0.9880884289741516
138505415,3765,junrao,2017-09-13T01:22:10Z,"the method name is a bit confusing. it sounds like that we are just reading the partition state from zk, but we actually also remove the isr here. so, we probably want to use a more accurate method name. also, would it be better to change the isr in leaderandisrbasedonlogconfigs() instead of here?",0,0.5624802708625793
138505545,3765,junrao,2017-09-13T01:23:35Z,"hmm, do we need those wrappers? could be just change controllerevent directly?",0,0.9832584857940674
138675875,3765,onurkaraman,2017-09-13T16:46:26Z,"anything with a v2 suffix is just temporary. it's there to make the diff easier to read. once we agree on the changes, i'll remove the suffix and make the new code replace the old.",0,0.9934632778167725
138677309,3765,onurkaraman,2017-09-13T16:52:16Z,this had also crossed my mind but decided to just try to replicate existing behavior in the first pass. however i agree that doing so simplifies the logic here quite a bit and agree that the change should be made in this pr.,0,0.9685803651809692
138684045,3765,onurkaraman,2017-09-13T17:20:35Z,"the behavior in the pr just tries to imitate `zkutils.conditionalupdatepersistentpath` which marks the update success as false when it receives any exception other than badversion. `zkutils.conditionalupdatepersistentpath` is called by `replicationutils.updateleaderandisr` which is called by `kafkacontroller.removereplicafromisr`. that update success value is what determines if we should retry in the while loop of `kafkacontroller.removereplicafromisr`. that being said, the existing behavior isn't necessarily right.",0,0.992099404335022
138807407,3765,onurkaraman,2017-09-14T06:35:39Z,suppose we collect all failed partitions and return it to `electleaderforpartitions`. how will `electleaderforpartitions` log relevant information? i think you'd basically have to return error messages or exceptions back to `electleaderforpartitions`. so the end result would just consolidate all the calls to `logfailedstatechange` into one place. is this what you had in mind?,0,0.9925519227981567
139002874,3765,junrao,2017-09-14T20:28:40Z,"yes, i was thinking of returning partition -> error_code map to the caller.",0,0.9939590692520142
139269156,3765,junrao,2017-09-15T23:39:22Z,should we do that in every test?,0,0.9896071553230286
139270862,3765,junrao,2017-09-16T00:01:44Z,"it will be useful to add a test for the controlled shutdown case, which involves setting controllercontext.shuttingdownbrokerids and making the state transition to online.",0,0.9937477111816406
139271124,3765,junrao,2017-09-16T00:05:51Z,could we consolidate all the logfailedstatechange() calls here?,0,0.9934877157211304
139271360,3765,junrao,2017-09-16T00:08:47Z,could this be private?,0,0.9816126227378845
139271478,3765,junrao,2017-09-16T00:10:43Z,could we add a comment on the return value?,0,0.9947362542152405
139271708,3765,junrao,2017-09-16T00:14:25Z,it seems that we should return failedupdates to the caller so that we can log the error.,0,0.9902269840240479
139272320,3765,junrao,2017-09-16T00:25:57Z,could we consolidate all the logfailedstatechange() calls here?,0,0.9934877157211304
139272482,3765,junrao,2017-09-16T00:29:45Z,"hmm, not sure that i really understand this comment. also, could we document the return value?",0,0.507115364074707
139273133,3765,junrao,2017-09-16T00:43:56Z,"i think this part of the logic could be simplified a bit from the original implementation. if isr only contains replicaid, it seems that we can just always leave the last replica in isr independent of the uncleanleaderelection config. this is because the leader will be set to noleader. so, no new data could be written to this partition and replicaid will remain in sync.",0,0.9618907570838928
139273316,3765,junrao,2017-09-16T00:48:15Z,leaderandisrs.keys.map(_.topic).toseq => leaderandisrs.keys.map(_.topic).toset ?,0,0.992741584777832
139298824,3765,onurkaraman,2017-09-17T00:54:22Z,"it doesn't seem like we should relax the easymock strictness in general. i only had to do it because i had issues specifying expectations on some scala methods with defaults (specifically, the isnew param for `mockcontrollerbrokerrequestbatch.addleaderandisrrequestforbrokers`).",0,0.9809834361076355
139298830,3765,onurkaraman,2017-09-17T00:55:08Z,your above earlier comment suggests we can get rid of this method entirely. so problem solved!,1,0.5065674185752869
139298835,3765,onurkaraman,2017-09-17T00:55:31Z,done.,0,0.9897913336753845
139298837,3765,onurkaraman,2017-09-17T00:55:38Z,agreed.,0,0.954565167427063
139298838,3765,onurkaraman,2017-09-17T00:55:46Z,done.,0,0.9897913336753845
139298862,3765,onurkaraman,2017-09-17T00:56:46Z,done.,0,0.9897913336753845
139298884,3765,onurkaraman,2017-09-17T00:58:58Z,"this ends up getting surprisingly ugly due to the option[int] return values of `partitionleaderelectionalgorithms` as well as the leader election helper methods, specifically `leaderforoffline` which also does its own logging.",-1,0.9284167885780334
139298901,3765,onurkaraman,2017-09-17T01:00:52Z,i agree that it should be logged. it's just a bit tricky to cleanly consolidate all of the logging in partitionstatemachinev2. i'll give it another try in a follow-up update to this pr.,0,0.9687247276306152
139299269,3765,onurkaraman,2017-09-17T01:37:07Z,done.,0,0.9897913336753845
139316087,3765,junrao,2017-09-17T17:20:41Z,"structure-wise, it's probably better to do line 234 to 238 in electleaderforpartitions()?",0,0.9924305081367493
139316113,3765,junrao,2017-09-17T17:22:09Z,could we add a comment on what will fail if this is not added?,0,0.9923110008239746
139317183,3765,onurkaraman,2017-09-17T18:07:56Z,"we could, but in doing so, we'd have to return more state to `electleaderforpartitions`. currently, `doelectleaderforpartitions` returns `(seq[topicandpartition], seq[topicandpartition], map[topicandpartition, exception])` where the successes are just that first `seq[topicandpartition]`. if we delegate the work to `electleaderforpartitions`, we'd have to pass back not only the successful partitions, but their leaderandisr as well as the intended recipients of that partition's share of leaderandisrrequest. the code could end up messier as a result.",0,0.9879369139671326
139318096,3765,onurkaraman,2017-09-17T18:48:30Z,"sure. alternatively, one option is to just get rid of scala default arguments in controllerbrokerrequestbatch. if we actually want to keep something resembling default arguments, we can just do it the java way. split the methods with default arguments into two: 1. one with all of the arguments 2. one without the default argument that fills in the default value for the user. i'm fine with either commenting why or converting to java-style default arguments.",0,0.9378191828727722
139323536,3765,junrao,2017-09-17T22:57:40Z,"ok, we can leave it as it is then.",0,0.9909913539886475
139323553,3765,junrao,2017-09-17T22:58:00Z,perhaps we can just do 2?,0,0.9817500114440918
140394457,3765,junrao,2017-09-22T01:14:39Z,"could we change p to case (tp, _) to get rid of ._1 for better readability? ditto in a few other places.",0,0.9940140843391418
140394568,3765,junrao,2017-09-22T01:15:53Z,this comment is probably not longer valid?,0,0.9713223576545715
140394943,3765,junrao,2017-09-22T01:19:44Z,could we explicitly define the return type for all methods in the class?,0,0.9933926463127136
143092927,3765,junrao,2017-10-06T01:14:59Z,"it's possible that the controllereventthread has just taken an event out of the queue before eventmanager.clearandput(expire) is called. so, it seems that we need to wait for controllereventthread to return back to idle state before creating a new zk session. otherwise, controllereventthread may use the newly create zk session to process an event that happens before the session expiration.",0,0.990070641040802
143096688,3765,junrao,2017-10-06T01:57:13Z,perhaps it's better to close kafkacontrollerzkutils before shutting down the controller to avoid it blocked on any zk operation.,0,0.9812978506088257
143225895,3765,junrao,2017-10-06T15:47:52Z,"hmm, not sure that we really need to read the controllerid from zk again. it seems that we could just always set activecontrollerid to -1, call oncontrollerresignation(), and then call elect.",0,0.879025399684906
143226529,3765,junrao,2017-10-06T15:50:36Z,i am wondering if we could just remove line 1242 to 1251 and alway try to create the controller path in zk.,0,0.9721363186836243
143230568,3765,junrao,2017-10-06T16:07:42Z,unused import org.i0itec.zkclient.izkstatelistener and org.apache.zookeeper.watcher.event.keeperstate,0,0.9932153224945068
143231117,3765,junrao,2017-10-06T16:10:22Z,"over time, other components will be using this class, should we name this sth more general that's not tied to controller?",0,0.9905650615692139
143232047,3765,junrao,2017-10-06T16:14:59Z,this line seems unnecessary since it's done in the previous line.,0,0.8935793042182922
143232631,3765,junrao,2017-10-06T16:17:57Z,could replicastatemachine.handlestatechanges() take a set of replicas instead of a sequence?,0,0.992186427116394
143234078,3765,junrao,2017-10-06T16:24:49Z,we probably don't intent to check code.ok again?,0,0.9884491562843323
143237031,3765,junrao,2017-10-06T16:38:57Z,"it's possible that the controller is still working on an event when expire() is called. in this case, it seems that we want to wait until the controller returns to idle state before we create a new zk session. otherwise, the controller may process an old event using the new session.",0,0.9917300343513489
143255144,3765,onurkaraman,2017-10-06T17:47:49Z,good catch. this must've been some leftover code while refactoring.,1,0.9884359836578369
143255167,3765,onurkaraman,2017-10-06T17:47:57Z,good catch.,1,0.9776482582092285
143262946,3765,junrao,2017-10-06T18:22:32Z,controllerstate.topicchange is incorrect.,0,0.9394446015357971
143263715,3765,junrao,2017-10-06T18:26:03Z,is v2 needed?,0,0.9945617318153381
143292558,3765,junrao,2017-10-06T20:56:33Z,is v2 needed?,0,0.9945617318153381
143316120,3765,onurkaraman,2017-10-07T00:20:06Z,"from an offline discussion, i think we agreed to leave this logic as is and change it in a later patch.",0,0.9848256707191467
143316125,3765,onurkaraman,2017-10-07T00:20:11Z,"from an offline discussion, i think we agreed to leave this logic as is and change it in a later patch.",0,0.9848256707191467
143318695,3765,onurkaraman,2017-10-07T01:17:23Z,good catch.,1,0.9776482582092285
143318696,3765,onurkaraman,2017-10-07T01:17:26Z,good catch.,1,0.9776482582092285
143318830,3765,onurkaraman,2017-10-07T01:21:51Z,"that's the current behavior and i think it's right. partitionmodifications is the event used for adding partitions to a topic. if you look at the other controllerstate states, it's the most accurate option.",0,0.9174448251724243
143319274,3765,onurkaraman,2017-10-07T01:38:52Z,"i was hoping to do a later ""cleanup"" pr that would contain: 1. renaming kafkacontrollerzkutils 2. removing state change logger entirely 3. doing your above suggestion of removing the ith tuple element notation ex: x._1",0,0.9908496141433716
143598970,3765,junrao,2017-10-09T23:14:27Z,"instead of exposing countdownlatch directly, perhaps it's better to add a waituntilprocessed() method in expireevent and call countdownlatch.await() there?",0,0.9906942248344421
143601978,3765,junrao,2017-10-09T23:38:37Z,i am not sure why replicas needs to be a seq instead of a set. it seems that all callers are converting a set to a seq.,0,0.8247090578079224
143604811,3765,junrao,2017-10-10T00:03:03Z,could we use case inside map to avoid unnamed reference _._2? ditto in the line below.,0,0.9942096471786499
143605920,3765,junrao,2017-10-10T00:12:17Z,"this matches the existing code. however, in this case, it seems that we probably want to throw an exception instead of proceeding w/o a new controller epoch.",0,0.9938676953315735
143607644,3765,junrao,2017-10-10T00:28:05Z,should we just pass the locally created brokerrequestbatch to both the replicastatemachine and partitionstatemachine?,0,0.9944115281105042
143611081,3765,junrao,2017-10-10T01:01:22Z,"this will be called when a topic is deleted. so, we probably want to make this a no-op instead of throwing an exception.",0,0.9887793064117432
143611266,3765,junrao,2017-10-10T01:03:36Z,"this will be called when the partition reassignment completes. so, we probably want to make this a no-op instead of throwing an exception.",0,0.9901652932167053
143611398,3765,junrao,2017-10-10T01:04:56Z,"this will be called when the preferred leader election completes. so, we probably want to make this a no-op instead of throwing an exception.",0,0.9835126996040344
143612243,3765,junrao,2017-10-10T01:14:49Z,could we use case inside filter to avoid unnamed reference p._2?,0,0.9940239787101746
143612493,3765,junrao,2017-10-10T01:17:19Z,could we use case inside partition to avoid unnamed reference _._2? there are a few other places like that.,0,0.9930578470230103
143612617,3765,junrao,2017-10-10T01:18:49Z,it seems that failedupdates.tomap can just be failedupdates.,0,0.9827597141265869
143612849,3765,junrao,2017-10-10T01:21:12Z,could we use case to avoid unnamed reference _._2? there are a few other places like that in this file.,0,0.9935507774353027
143613461,3765,junrao,2017-10-10T01:28:23Z,"could we explicitly define the return type in this and the following private method? otherwise, it's a bit hard to follow the logic.",0,0.9423670768737793
143613534,3765,junrao,2017-10-10T01:29:06Z,"the class is a bit harder to read now with the new zk wrapper. to make that a bit easier, could we add a comment to describe the return type and this method does? it may be worth doing that on a few other methods in this class as well.",0,0.9901162981987
143614244,3765,junrao,2017-10-10T01:37:17Z,add a new line above. could we explicitly define the return type of this method?,0,0.9948535561561584
143614282,3765,junrao,2017-10-10T01:37:44Z,could we explicitly define the return type explicitly of this method and describe a bit the return type and the method? ditto for the method below.,0,0.9950590133666992
143614860,3765,junrao,2017-10-10T01:44:35Z,could we add a comment to describe the return value?,0,0.9948050379753113
143614998,3765,junrao,2017-10-10T01:46:20Z,could we add a comment to describe the return value?,0,0.9948050379753113
143615041,3765,junrao,2017-10-10T01:46:52Z,could we explicitly specify the return type of this method?,0,0.9939060807228088
143615065,3765,junrao,2017-10-10T01:47:09Z,could we explicitly specify the return type of this method?,0,0.9939060807228088
143615317,3765,junrao,2017-10-10T01:50:48Z,"we probably want to wait for zookeeperclient to be connected within the connection timeout. otherwise, fail the restart of the broker.",0,0.9901576638221741
143621204,3765,onurkaraman,2017-10-10T03:04:22Z,sounds good. i'll make the change.,1,0.9228895306587219
143864242,3765,onurkaraman,2017-10-10T21:59:18Z,this is definitely something i've had in mind for a while now and i've mentioned it in the redesign doc. we agreed offline to do this change in a follow-up patch to minimize regressions.,0,0.9683266282081604
143867505,3765,onurkaraman,2017-10-10T22:16:03Z,"that's not quite right. topicdeletionmanager's `completedeletetopic` first unregisters the partitionmodificationshandler before deleting the topic znode. in addition to looking at the code, i did a topic deletion and didn't find any errors in any of the logs. i think there are 3 options here: 1. change unimplemented methods to be no-ops on a case-by-case basis. 2. change all of the controller's unimplemented handle methods to be no-ops. 3. change the traits themselves to make these methods no-ops by default. you'd only override if you need to. i am leaning towards option 3 since it'll make the code more concise but am okay with any option.",0,0.9791989922523499
143869274,3765,onurkaraman,2017-10-10T22:25:19Z,that's a good point. see my above comment describing several ways we can address this.,1,0.95725417137146
143870540,3765,onurkaraman,2017-10-10T22:32:38Z,that's a good point. see my above comment describing several ways we can address this.,1,0.95725417137146
143871821,3765,junrao,2017-10-10T22:39:53Z,"option 3 sounds reasonable. the thing with unregistering a watcher is that it only gets reflected during the next read. so, it may not happen immediately.",0,0.9851974844932556
143880980,3765,onurkaraman,2017-10-10T23:42:31Z,"watches are tricky with zookeeper. the key point is that zookeeperclient handler unregistration is not the same thing as watcher removal. prior to zookeeper 3.5, there actually [a link]. watchers can only get removed after they get triggered. however, from the zookeeperclient's perspective, handler unregistration is local and immediate. it's possible for the zookeeper ensemble to send you a notification for a watcher after you've unregistered that watcher's corresponding handler, but it won't have any effect. zookeeperclient maintains local mappings from paths to registered handlers and updates these mappings immediately upon handler registration and unregistration. when zookeeperclient receives a watcher notification, its zookeeperclientwatcher first looks up a handler in its local mappings and only if one exists does it actually trigger the corresponding handle method.",0,0.7466532588005066
143885696,3765,junrao,2017-10-11T00:17:20Z,"ok, then, it's probably covered in this case.",0,0.9873190522193909
143898041,3765,onurkaraman,2017-10-11T02:18:37Z,"this is already exactly what happens. the zookeeperclient constructor calls `waituntilconnected(connectiontimeoutms, timeunit.milliseconds)`.",0,0.9943501353263855
143908207,3765,onurkaraman,2017-10-11T04:07:48Z,made the change in the latest update.,0,0.9941990375518799
144068415,3765,junrao,2017-10-11T16:43:53Z,it seems this should really be called onreconnectiontimeout?,0,0.9925562739372253
144133096,3765,junrao,2017-10-11T20:54:11Z,i am not sure if we need to explicitly have this callback. it seems that this can just be fold into the logic of waiting for the connection to be ready during initial connect and reconnect?,0,0.978681743144989
144136815,3765,junrao,2017-10-11T21:08:57Z,we probably want to mention that the new leaders will be written to zk.,0,0.9899914264678955
144136971,3765,junrao,2017-10-11T21:09:28Z,identation,0,0.9887940287590027
144150290,3765,junrao,2017-10-11T22:13:41Z,this is redundant given what's in line 115.,0,0.9311460256576538
144151962,3765,junrao,2017-10-11T22:23:45Z,we probably want to document that new isr will be written to zk.,0,0.9913021326065063
144160128,3765,onurkaraman,2017-10-11T23:12:25Z,that indentation's actually what intellij suggested to me.,0,0.9901572465896606
144165799,3765,junrao,2017-10-11T23:54:29Z,this seems unnecessary since we log in the first statement in replicastatemachine.startup() already.,0,0.9683979749679565
144165817,3765,junrao,2017-10-11T23:54:44Z,this seems unnecessary since we log in the first statement in partitionstatemachine.startup() already.,0,0.973445475101471
144177295,3765,onurkaraman,2017-10-12T01:41:48Z,done.,0,0.9897913336753845
144177305,3765,onurkaraman,2017-10-12T01:41:53Z,done.,0,0.9897913336753845
144482045,3765,onurkaraman,2017-10-13T07:27:27Z,"`statechangehandler.onauthfailure` only gets used in our zookeeperclient's custom zookeeperclientwatcher: [code block] `statechangehandler.onauthfailure` would only get called when the raw zookeeper client transitioned from the connecting state to the auth_failed state as shown in the state transition diagram below: [a link] there are three scenarios that could have caused you to be in the connecting state in the first place: 1. initial zookeeperclient instantiation 2. transient disconnect from the zookeeper ensemble 3. zookeeperclientwatcher initializing a new session after session expiration if you get rid of `statechangehandler.onauthfailure`, then only 1 and 3 will react to the auth failure on their own: * for scenario 1, assuming you want to keep the thrown zookeeperclientauthfailedexception, then 1 will throw that exception in waituntilconnected. * for scenario 3, eventually the connection timeout will be hit and the `statechangehandler.onconnectiontimeout` will get called. * however for scenario 2, without `statechangehandler.onauthfailure`, a reaction to the auth failure for 2 can only occur if the user calls waituntilconnected or if they observe the return code from any requests that were in-flight or sent after the auth failure. so you now risk a scenario where the application is just sitting around indefinitely with a client in the auth_failed state.",0,0.9950118064880371
144585764,3765,ijuma,2017-10-13T15:29:17Z,"out of curiosity, what is the reasoning for the `listener` -> `handler` rename?",0,0.9801393747329712
144588126,3765,ijuma,2017-10-13T15:38:31Z,"btw, there are some really long lines in this pr. our convention is that lines should not be longer than the github review window.",-1,0.5450588464736938
144624196,3765,junrao,2017-10-13T18:18:07Z,"hmm, in case 2, wouldn't the zk session expire eventually?",0,0.9823789000511169
144668085,3765,junrao,2017-10-13T22:18:38Z,"we probably want to delete the log dir event first and then register the handler. otherwise, we may be processing those events triggered by deletion unnecessarily. ditto for deleteisrchange.",0,0.989212155342102
144669429,3765,junrao,2017-10-13T22:29:17Z,it seems that it's better to batch the call to handlestatechanges across all replicas like before?,0,0.9910064339637756
144669526,3765,junrao,2017-10-13T22:30:08Z,"we only need to do this on newtopics, right?",0,0.9912645816802979
144676732,3765,onurkaraman,2017-10-13T23:42:37Z,good catch.,1,0.9776482582092285
144677353,3765,onurkaraman,2017-10-13T23:50:05Z,done.,0,0.9897913336753845
144680808,3765,onurkaraman,2017-10-14T00:45:15Z,"the diagram seems to indicate that you can either hit auth failure or session expiration, but not both.",0,0.990429162979126
144681072,3765,junrao,2017-10-14T00:51:03Z,"hmm, that could be true. perhaps we could keep it and just log an error for now.",0,0.9736314415931702
144681238,3765,onurkaraman,2017-10-14T00:54:51Z,"1. it's more concise. 2. it's also easier to read and verbalize, for me at least. 3. it let me keep both version of the classes side-by-side as a reference. 4. they pretty much mean the same thing in programming.",1,0.8307368755340576
145007795,3765,junrao,2017-10-17T01:13:16Z,instead of duplicating the comment. we could just refer it to the one in handle(requests: seq[asyncrequest])?,0,0.994568943977356
145007985,3765,junrao,2017-10-17T01:15:05Z,"registerznodechildchangehandler(znodechildchangehandler: znodechildchangehandler) calls this method. so, it's better to put the detailed comments here and let the former refer it here.",0,0.9954018592834473
145008953,3765,junrao,2017-10-17T01:26:05Z,"it seems that in all state transitions, it's useful to know the assigned replica list, the leader and the isr. perhaps, we can just do a generic logging at the end of the method?",0,0.9902547001838684
145010777,3765,junrao,2017-10-17T01:44:39Z,i had a comment on this before. should onconnectiontimeout() be onreconnectiontimeout?,0,0.9942635893821716
145206369,3765,junrao,2017-10-17T17:57:40Z,could we explicitly define the return type of this method?,0,0.993812084197998
145206447,3765,junrao,2017-10-17T17:57:56Z,could we explicitly define the return type of this method?,0,0.993812084197998
145212540,3765,onurkaraman,2017-10-17T18:19:03Z,"now that we've decoupled handler registration from watcher registration, there's really no benefit to having `registerznodechangehandlers` and `registerznodechildchangehandlers` since these are now purely local operations and equivalent to registering one-at-a-time. i'm going to remove these methods.",0,0.9892488718032837
145215526,3765,onurkaraman,2017-10-17T18:29:16Z,"hmm not sure if this would actually work. some of these concepts don't even exist in certain states. - newpartition has no leader or isr. - nonexistentpartition has no replicas, leader, or isr.",0,0.6873528361320496
145215623,3765,onurkaraman,2017-10-17T18:29:38Z,sure.,0,0.9824982285499573
145215655,3765,onurkaraman,2017-10-17T18:29:47Z,makes sense.,0,0.9735017418861389
145227489,3765,junrao,2017-10-17T19:12:45Z,"ok. maybe in the case where we transition to onlinepartition, we can just log the whole leaderandisr instead of just the leader.",0,0.9875501990318298
145250912,3765,onurkaraman,2017-10-17T20:45:25Z,done,0,0.8682363629341125
145250947,3765,onurkaraman,2017-10-17T20:45:34Z,done.,0,0.9897913336753845
145250967,3765,onurkaraman,2017-10-17T20:45:40Z,done.,0,0.9897913336753845
145483014,3765,tedyu,2017-10-18T17:20:24Z,dowork() doesn't use putlock. is it possible that an event retrieved by dowork() is supposed to be cleared by this call ?,0,0.9930324554443359
145488953,3765,tedyu,2017-10-18T17:42:14Z,updatestoretry is not used.,0,0.9928833246231079
145489072,3765,tedyu,2017-10-18T17:42:39Z,partitionsleadbybroker -> partitionsledbybroker,0,0.987247109413147
145664130,3765,ijuma,2017-10-19T10:46:03Z,"i think it's a good point that we should document the expected behaviour even if there's no bug. , can we please do that in a follow-up?",1,0.8585149645805359
145664835,3765,ijuma,2017-10-19T10:49:39Z,fixed in [a link],0,0.9950093030929565
145664852,3765,ijuma,2017-10-19T10:49:45Z,fixed in [a link],0,0.9950093030929565
145820562,3765,junrao,2017-10-19T20:52:58Z,"the purpose of putlock is to make sure no other callers can put anything to the queue in the middle of a clearandput() call. it's ok for a reader to have taken an event out of the queue just before the queue is cleared since in kafkacontroller.expire(), we wait until the last event in the queue is processed before creating a new zk session. we can probably document this to make it clear.",0,0.9919543862342834
1104737066,13240,Hangleton,2023-02-13T16:38:01Z,"the sequence of validation chosen here reflects what is used on the fetch request path: - if topic ids are used and the given topic id cannot be resolved (and no fallback name is provided), send back `unknown_topic_id`; - if the topic name is valid but that name is not authorized, send `topic_authorization_failed`; - if the topic name is authorized but not present in the metadata cache (in which case, that topic will not have been resolved via its id because in this case, we expect it to be in the cache), send `unknown_topic_or_partition`.",0,0.9946243166923523
1104738082,13240,Hangleton,2023-02-13T16:38:36Z,note: topic id must not be null for a request/response version >= 9 to be serialized. `zero_uuid` means no topic id specified.,0,0.9929613471031189
1104738961,13240,Hangleton,2023-02-13T16:39:12Z,note: topic id must not be null for a request/response version >= 9 to be serialized. `zero_uuid` means no topic id specified.,0,0.9929613471031189
1104740902,13240,Hangleton,2023-02-13T16:40:29Z,"note 1: if the `topicname` is not null, we should also check if it resolves to the same uuid as we have cached locally.",0,0.9919445514678955
1104760648,13240,Hangleton,2023-02-13T16:53:38Z,note 2: we could fail partially - just for the given topic entry - rather than the entire response.,0,0.983761727809906
1105846605,13240,dajac,2023-02-14T13:48:17Z,"there is very likely a bug here. in this case, `topic.name` is `null` and the response builder uses a hashmap keyed by topic name. therefore, all the topics with an unknown topic id will end up together.",0,0.9676001071929932
1105854122,13240,dajac,2023-02-14T13:54:34Z,"we are calling `resolvetopicname` three times. i think that it would be better to iterate once over the topics to resolve the topic ids and build the list of topic names (if one was found) while doing this. then, we can check the authorization and do the rest.",0,0.9899225831031799
1105855843,13240,dajac,2023-02-14T13:55:54Z,i suppose that this check is not necessary if we are using topic ids. we already know that the name resolved based on the topic id is valid.,0,0.9888170957565308
1105985661,13240,Hangleton,2023-02-14T15:31:23Z,"apologies, you are right. this hints that perhaps we should reconstruct the list of `offsetcommitrequesttopic` and use it internally to avoid any such mistake?",0,0.9059939384460449
1105987099,13240,Hangleton,2023-02-14T15:32:31Z,"you are right, yes. let's make this explicit in the code.",0,0.9766811728477478
1106229439,13240,Hangleton,2023-02-14T18:36:47Z,"i replaced this approach with a single iteration over the list of topic data, resolving and populating the topic name in place (line 455). i am concerned though because this involved mutating the request's body. but i am also concerned about the cost of creating a new arraybuffer, sequence or another data structure to pre-filter. without falling into premature optimization, what do you think about in-place mutation? i think the problem here is that we have the instantiation of the `offsetcommitrequest` decoupled from the resolution of topic ids. it makes sense since the former corresponds to the request deserialization while the latter corresponds to added semantics unconveyed by the request itself. in responsibility chains on server request handlers, one pattern sometimes adopted is to decorate a request with extraneous information which fall beyond the scope of ser/de. i wonder if topic id resolution could happen before passing it to the business request handler.",0,0.610237181186676
1113132735,13240,dajac,2023-02-21T14:21:42Z,nit: we probably don't need to duplicate `data` here. i understand why you are doing it but in practice we assume that `data` is owned by the builder once it is given to it.,0,0.9861918687820435
1113142734,13240,dajac,2023-02-21T14:29:30Z,nit: invalidrequestexception would be more appropriate.,0,0.9640833735466003
1113146018,13240,dajac,2023-02-21T14:32:07Z,i just realized that this is only used in tests. i wonder if we should just get rid of it and use the auto-generated classes in tests as well.,0,0.9607585668563843
1113149061,13240,dajac,2023-02-21T14:34:29Z,nit: you could replace this by the following: [code block],0,0.9949524402618408
1113151869,13240,dajac,2023-02-21T14:36:46Z,nit: ditto.,0,0.5569967031478882
1113153482,13240,dajac,2023-02-21T14:37:59Z,nit: we could remove this empty line.,0,0.9807522892951965
1113156030,13240,dajac,2023-02-21T14:39:58Z,"i think that there is a bug here for the case where multiple topic ids are unknown in a single request. for those, the topic name will be null so they will be aggregated in the same offsetcommitresponsetopic and that one will have the topic id of the first unknown topic id seen.",0,0.9812823534011841
1113156632,13240,dajac,2023-02-21T14:40:25Z,nit: i think that we could remove this comment. it does not bring much.,0,0.9780349731445312
1113157135,13240,dajac,2023-02-21T14:40:49Z,the kip also specifies new errors for this version. could we mention them here?,0,0.9946423768997192
1113160687,13240,dajac,2023-02-21T14:43:33Z,"at l1361 in this file, we construct `topicpartition` based on the response data but we don't resolve the topic id. i think that we should add the resolution there as well, no? we probably need to extend tests to better cover this as well. regarding `unknown_topic_id`, would it make sense to place it after `unknown_topic_or_partition` as they are quite similar?",0,0.9890465140342712
1113164928,13240,dajac,2023-02-21T14:46:18Z,"i would prefer to inline `resolvetopicname` and avoid allocating an `option` which does not bring much here. in the mean time, i would directly construct the list of topic names for the authorizer at l461. this way, we could save re-iterating over the topics and the `filter`. what do you think? moreover, the kip states that an `invalid_request` should be return if both a topic id and a topic name are provided. we could also handle this here.",0,0.9806873202323914
1113175049,13240,dajac,2023-02-21T14:52:56Z,"this issue is still present. yeah, we definitely need to update the response builder to support this. one way would be to change the semantic of `addpartitions` to directly add to the response when it is called and to only put the topic in the hashmap when `addpartition` is used.",0,0.9564039707183838
1113176828,13240,dajac,2023-02-21T14:54:08Z,it would be great if we could extend the tests here. i think that we need to use multiple unresolvable topic ids in the same request and also check the different versions. i am not sure if we could extend this one or if we should add other ones.,1,0.5712937116622925
1113178848,13240,dajac,2023-02-21T14:55:25Z,"what's the reason for this change? if we refactor this, it may be better to directly go with the auto-generated data structures.",0,0.9909418225288391
1113183283,13240,dajac,2023-02-21T14:58:39Z,we also need tests to check if the response is handled correctly.,0,0.9937673807144165
1113220631,13240,dajac,2023-02-21T15:26:05Z,nit: could we add `.` at the end?,0,0.9899908304214478
1113220793,13240,dajac,2023-02-21T15:26:12Z,nit: could we add `.` at the end?,0,0.9899908304214478
1116196039,13240,Hangleton,2023-02-23T20:10:09Z,"sure, i used the auto-generated class in the unit test for the `offsetcommitrequest`. i moved this method to the unit test class as it is used from other unit tests in for the consumer coordinator, from where using the full-fledged request object would be less convenient.",0,0.9901906251907349
1116198012,13240,Hangleton,2023-02-23T20:12:23Z,"you are right, thanks for finding this bug (again!). i followed the approach you suggest here in the builder of the `offsetcommitresponse`, please let me know if the semantics make sense.",1,0.9631323218345642
1116200049,13240,Hangleton,2023-02-23T20:14:13Z,"that is right, thanks for pointing out. the resolution of topic name has been added to the response handler. if the topic is not defined, or the response topic is invalid because it contains neither an id or name, or contains both, that topic is ignored. the offset commit invocation is however not failed.",1,0.882530689239502
1116202452,13240,Hangleton,2023-02-23T20:16:23Z,"thanks, i built the list of resolved topics and pass it to the authorizer, inlining name resolution. if a topic has both a name and id defined, the broker fails fast the request and returns an `invalid_request`. is this what you had in mind? should we send more information to the client in that case?",1,0.7037563323974609
1116203414,13240,Hangleton,2023-02-23T20:17:14Z,"sure, i added another unresolvable topic to the request/response. i will add more cases covering more of the possible code paths.",0,0.9896146655082703
1116204122,13240,Hangleton,2023-02-23T20:17:54Z,"sure, i reverted this refactoring and use the response class instead.",0,0.9908219575881958
1116205901,13240,Hangleton,2023-02-23T20:19:26Z,"that is right, i added tests which invoke the sync and async offset commit method.",0,0.9946012496948242
1119248386,13240,dajac,2023-02-27T19:58:06Z,"i discussed offline with a few committers and the consensus is that having both the topic name and the topic id in the same version is not the right way. they share the same concerns that we discussed last week. could you update the pr to only have topicid from version 9? we can also remove the nullableversions for the name and set the versions to 0-8. i suppose that both fields could be ignorable. regarding the admin client, which does not support topic ids, it cannot use version 9 at the moment. we need to handle this in the builder (we can set the maximum allowed version). sorry for this late change.",0,0.938685417175293
1119798298,13240,Hangleton,2023-02-28T09:40:06Z,"hi david, thanks for the follow-up and clarifying. this is all good, i am working on adapting the pr. thanks!",1,0.9949477910995483
1121486904,13240,dajac,2023-03-01T10:29:55Z,"now that we can rely on the version, we should use it here and simplify all this logic.",0,0.9917906522750854
1121487731,13240,dajac,2023-03-01T10:30:29Z,it would be better to rely on the version of the request instead of the topic name here.,0,0.9893729090690613
1121488495,13240,dajac,2023-03-01T10:31:00Z,i would move this up and do it in the first iteration.,0,0.987036943435669
1121489116,13240,dajac,2023-03-01T10:31:23Z,you could use `resolvedtopics` instead of `offsetcommitrequest.data.topics` here.,0,0.9949266910552979
1121494379,13240,dajac,2023-03-01T10:35:07Z,i think that we could remove those checks now.,0,0.985671877861023
1121496085,13240,dajac,2023-03-01T10:36:34Z,i think that we could just set both the name and the id all the time as the fields are ignorable. the serialization framework will do the right thing based on the version. we could also remove `version` from the arguments.,0,0.983616054058075
1121499577,13240,dajac,2023-03-01T10:39:12Z,we could get this in the base class and always set both of them. the serialization framework knows what to do.,0,0.9902779459953308
1121501980,13240,dajac,2023-03-01T10:41:03Z,"is this change related to the pr? if not, i would rather do it in a separate pr.",0,0.992668867111206
1121502171,13240,dajac,2023-03-01T10:41:14Z,same question here.,0,0.9875255823135376
1121506569,13240,dajac,2023-03-01T10:44:43Z,"i am not a fan of all those attributes in test. one or two are fine if they are really re-used on all the tests. otherwise, it may be better to check define what you need in tests. i would also use `topicidpartition` when relevant so you can basically group the name, id, and partition together.",0,0.7486767172813416
1121510354,13240,dajac,2023-03-01T10:47:36Z,is this really needed?,0,0.9856132864952087
1121710275,13240,Hangleton,2023-03-01T13:14:50Z,note: is this ok to break message round trip between < 9 and >= 9?,0,0.9947237968444824
1121724366,13240,Hangleton,2023-03-01T13:24:49Z,"adding the version to the response seems to be an anti-pattern as i haven't seen any other similar use in other responses. semantically it should be ok because the response instance is supposed to be built against a given version. if another approach is advisable, i will remove it.",0,0.9790514707565308
1121724819,13240,Hangleton,2023-03-01T13:25:09Z,will add javadoc.,0,0.9944370985031128
1122096890,13240,Hangleton,2023-03-01T17:33:31Z,there is still a problem here if `topicname` and `topicid` are both undefined in which case we should do what was done before and add to the response without caching.,0,0.9733596444129944
1122097709,13240,Hangleton,2023-03-01T17:34:20Z,move the `topicresolver` in the `metadatacache` or create it without copying the map of topic ids as this is costly.,0,0.9660219550132751
1122175488,13240,Hangleton,2023-03-01T18:52:25Z,"this case shouldn't be reachable because once we have proceeded with constructing the response via `addpartition` all topic ids are supposed to have been resolved successfully. here, we choose to add the topic to the response with the error code `unknown_topic_id` if no error is already set. any existing error is not overwritten.",0,0.993441104888916
1122188628,13240,Hangleton,2023-03-01T19:06:41Z,"at this point, topic ids should be always resolvable. however if some aren't, we should fallback to adding the topic ""as is"" to the response to avoid caching `zero_uuid` with risk of overwrites.",0,0.9936703443527222
1122265994,13240,Hangleton,2023-03-01T20:27:38Z,adding more tests to this class.,0,0.992233157157898
1122271424,13240,Hangleton,2023-03-01T20:34:15Z,note - this duplicated invocation of the `builder` constructor is to allow the resolution of the parameter type as either `uuid` or `string`. not graceful but...,0,0.9907171130180359
1122830477,13240,Hangleton,2023-03-02T09:41:36Z,"thinking about it, it seems unnecessary to adopt a different classification for v >= 9 since topic names should always be resolved when calling `addpartition`. will remove all this logic and simplify.",0,0.9865919947624207
1124559198,13240,Hangleton,2023-03-03T14:48:12Z,not strictly needed. we can remove the condition and the logger as well.,0,0.9903022646903992
1125501983,13240,dajac,2023-03-04T16:59:02Z,should we add tests to cover this new logic?,0,0.9937217831611633
1125687390,13240,Hangleton,2023-03-05T15:35:04Z,sure! added the tests. thanks.,1,0.9944709539413452
1126511918,13240,Hangleton,2023-03-06T14:38:48Z,"hmm, we probably don't want to include a topic without id in the response version 9 here.",0,0.940613329410553
1128110858,13240,dajac,2023-03-07T16:01:47Z,nit: we usually don't leave such comment in our code base.,0,0.9730224013328552
1128111731,13240,dajac,2023-03-07T16:02:18Z,nit: should we use a boolean?,0,0.9866464138031006
1128113386,13240,dajac,2023-03-07T16:03:22Z,nit: i usually prefer to use `zero_uuid.equals(...` as it is safe for null values.,0,0.9911088943481445
1128117144,13240,dajac,2023-03-07T16:05:47Z,nit: we usually don't break long lines like this. i personally prefer the following: [code block] you can find other ways in the code base.,0,0.9537660479545593
1128122177,13240,dajac,2023-03-07T16:08:47Z,"is this really true? as we keep the `topicresolver` used to construct the request, all topics should be there. this case could happen if the server returns an unexpected topic id that was not in the request and that is not in the `topicresolver`. do i get this right?",0,0.9898577332496643
1128123974,13240,dajac,2023-03-07T16:09:50Z,"for my understanding, are we going to propagate this error back to the end user?",0,0.918876051902771
1128126364,13240,dajac,2023-03-07T16:11:15Z,we don't really use those in our code base at the moment. we usually just mention those characteristics in the java doc.,0,0.9855920076370239
1128126821,13240,dajac,2023-03-07T16:11:31Z,should this be an invalidstateexception?,0,0.9817550778388977
1128128673,13240,dajac,2023-03-07T16:12:33Z,i am not really happy with this name but i could not find a better one yet. my concern is that this class is really about resolving topic ids/names and not really topics per say. have you considered any alternatives?,-1,0.9876224398612976
1128130754,13240,dajac,2023-03-07T16:13:43Z,is this constructor still used?,0,0.9938613176345825
1128132186,13240,dajac,2023-03-07T16:14:32Z,"nit: when we break the line like this, we usually align the arguments on the first one. otherwise, you can use the style that i mentioned earlier.",0,0.9920303821563721
1128133377,13240,dajac,2023-03-07T16:15:16Z,nit: should we also add the other ones?,0,0.992009162902832
1128136075,13240,dajac,2023-03-07T16:16:52Z,did you check how we did this for the fetchrequest?,0,0.995834231376648
1128141284,13240,dajac,2023-03-07T16:19:55Z,i am not sure about passing the `topicresolver` here. my understanding is that we are doing this because topic ids are lost when we call the group coordinator. wouldn't it better to update the group coordinator to preserve those topic ids? we may be able to handle this in the groupcoordinatoradaptor or we could switch to using topicidpartitions. we could also consider doing this in a separate pr as this one is already quite large.,0,0.9587496519088745
1128148229,13240,dajac,2023-03-07T16:24:11Z,this does not look good. it would be better to place those helpers in `offsetcommitrequesttest` for instance or to keep them where they are used.,-1,0.6304023861885071
1128149528,13240,dajac,2023-03-07T16:24:56Z,nit: you can omit the `()` after `topics` as we usually don't put them for getters in scala. there are a few other cases in the pr.,0,0.9945730566978455
1128151493,13240,dajac,2023-03-07T16:26:10Z,i think that there is a race condition here. you have no guarantee that both maps are consistent with each others.,0,0.8027779459953308
1128154143,13240,dajac,2023-03-07T16:27:47Z,should we just throw an illegale state exception if we end up having a topic without id? ignoring it seems to be risky.,0,0.7501524686813354
1128157560,13240,dajac,2023-03-07T16:29:43Z,i wonder if using optional is necessary here given that we always use `ornull` and `ordefault`. what do you think?,0,0.9656414985656738
1129066723,13240,dajac,2023-03-08T07:41:32Z,i had a deeper look into this and it seems that we could get the version with `this.response.requestheader().apiversion()`. could you check if this would work?,0,0.9912911653518677
1129167871,13240,Hangleton,2023-03-08T09:26:49Z,"i agree with you and am not satisfied either with `topicresolver` but could not find a better name. `topicidresolver` would be misleading because this class treats topic ids and names symmetrically. one of the closest entity with similar purposes as this is in [a link] where `topicidinfo` is used to refer to the bidirectional mapping. the suffix `info` could be used here as well although it is not strictly aligned with other uses of that suffix such as in [a link]. interestingly another entity for which may have had to be assigned a generic name is [a link]. using another name to refer to the dual name/id reference such as `topicrefresolver` introduces yet another noun (_reference_) not used elsewhere in the codebase and which can be confusing. so, i am not sure about what could be a better name but maybe `topicinforesolver` or `topicidinforesolver` or `topicidinfo` or `topicidresolver` may sound better albeit still ambiguous and partially incorrect?",0,0.9391257166862488
1129194029,13240,dajac,2023-03-08T09:51:18Z,another way would be to implement a minimal and generic bimap that we could use here. would it be an option?,0,0.9924905896186829
1129266598,13240,Hangleton,2023-03-08T11:03:53Z,"with the synchronous api in the consumer, the error is not surfaced (only `true`/`false`). however, i added the missing tests to exercise the asynchronous api for this use case, and it did expose the `unknowntopicidexception` to the user. since it violates the api contract which exclusively relies on topic names, i raised the error `unknown_topic_or_partition` when an `unknown_topic_id` is returned in the offset commit response. do you think this is sensible? i added the corresponding unit tests for the consumer coordinator.",0,0.9926130771636963
1129267206,13240,Hangleton,2023-03-08T11:04:35Z,"yes, that is right. apologies, this is a fundamental misunderstanding/overlook.",-1,0.9695918560028076
1129272424,13240,Hangleton,2023-03-08T11:10:09Z,"i would tend to have a preference for a business type which conveys semantics versus a generic data structure, but that is not very important here especially since the entity exposing the bidirectional mapping is relatively short-lived when used in the code. one advantage of a generic ds is that it can be reused for other purposes. another thing is that there is no functionality provided outside that of a bimap and since no extension is foreseen, there is no need to expose a specialized type. very happy to expose it as a bimap. i could not find an existing implementation in the codebase or its dependencies, although there is a bidirectional multimap defined within restricted scope [a link].",1,0.9588532447814941
1129283573,13240,Hangleton,2023-03-08T11:22:44Z,"it was only used in tests, so best to have it removed.",0,0.9896031022071838
1129311477,13240,Hangleton,2023-03-08T11:51:54Z,"yes, this works. thanks for the call-out.",1,0.9799478054046631
1129371713,13240,Hangleton,2023-03-08T12:41:39Z,oops...,-1,0.94526207447052
1129407685,13240,Hangleton,2023-03-08T13:11:41Z,"yes, there is a code smell here.",0,0.9898321628570557
1129452978,13240,Hangleton,2023-03-08T13:46:03Z,"i see what you mean. i moved this logic in the callback of the future which merges the results from the coordinator with those created by the request handling method. i thought about extending the support id in internal layers (group coordinator) in a pr of its own. so, eventually, the coordinator will return results populated with topic ids when applicable. added [a link] to track this work, if that is ok?",0,0.9755149483680725
1129482786,13240,Hangleton,2023-03-08T14:05:41Z,"modified the pr so that the server now sends an `unknown_server_error` when this happens, in the code moved to the future handler in `kafkaapis`. would this behaviour be acceptable?",0,0.9938251972198486
1129710408,13240,Hangleton,2023-03-08T16:22:25Z,maybe `topicidandnamebimap`?,0,0.9938964247703552
1130670740,13240,dajac,2023-03-09T08:54:40Z,"i actually wonder if we should do it the other way around. we could do kafka-14793 first, merge it, and update this one accordingly. without kafka-14793, the contract of the not really respected and it feels a bit weird to work around it here instead of fixing the real issue. is kafka-14793 complicated? what do you think?",-1,0.9595581293106079
1130671265,13240,dajac,2023-03-09T08:55:06Z,both names are fine for me. i leave it up to you.,0,0.814851701259613
1130866578,13240,Hangleton,2023-03-09T11:36:23Z,"hi david, thanks for the insight. i think you are right that implementing support of topic ids in the functional layer before exposing it in the api makes sense as it provides the guarantee that offsets and metadata belong to the partitions of the right topic in case of homonyms. now, one question is how deep we go in the integration of ids in this layer. would you consider changing the data model authored by the group coordinator down to the `offsetcommitvalue ` as prescribed by kip 848?",1,0.9796344637870789
1130942769,13240,dajac,2023-03-09T12:18:21Z,the offsetcommitvalue part is not possible at the moment because we dont have a way to downgrade. my colleague works on a proposal for this. we could start by either migrating from using topicpartition to using topicidpartition or handling this in the groupcoordinatoradaptor layer. the former is likely simpler.,0,0.9927748441696167
1131047710,13240,Hangleton,2023-03-09T13:41:44Z,"thanks for the answer. if i understand correctly, we would then have a resolution of topic ids from topic-name-based persisted data, so this may not prevent offsets from a topic to be provided as those of another topic with the same name (defined at different point in time in the server)? the resolution can be done in the group coordinator layer, assuming it has access to the topic id resolved upstream by the request handler. because we want to preserve the same mapping used when request processing started, we need to ensure the right ids are used within the adaptor's `groupcoordinator#commitoffsets` method(). since the mapping returned from the metadata cache depends on the snapshot used at the time the mapping is requested, if the adaptor retrieves it from the metadata cache internally, at a different time from the request handler, there is no guarantee the metadata is the same hence that the topic ids registered with the broker are the same. this means that the topic ids need to be propagated from the request handler (`kafkaapis`) to the coordinator adaptor somehow. without a change in the method and contract implemented by the coordinator, these ids could be transferred via the `offsetcommitrequestdata` dto directly, which means a change in the api schema would be required prior to the change. alternatively, we may want to change the interface of the coordinator and change the signature of the offset commit method to allow for the propagation of topic ids. i may be missing the entire thing though?",1,0.9413173794746399
1131114261,13240,dajac,2023-03-09T14:33:59Z,"how about doing the following? we change the signature of `groupcoordinator.handlecommitoffsets` to the following: [code block] note the change from `topicpartition` to `topicidpartition` for `offsetmetadata` and `responsecallback`. then, we have to adapt the implementation of `handlecommitoffsets` to get the `topicpartition` from the `topicidpartition` where required. we can keep `pendingoffsetcommits` and `offsets` keyed by `topicpartition` for now in `groupmetadatamanager`. this allows the preservation of the topic ids provided to the groupcoordinator but it does not provide any stronger guarantee for the offsets yet (as you pointed out). with this approach, we don't depend on the resolver at all.",0,0.9938919544219971
1131139080,13240,Hangleton,2023-03-09T14:49:42Z,"sounds good. thanks for your guidance. as you mentioned, this pr is already quite large, so if you agree, i will go ahead and implement this change first, in a pr of its own. thanks!",1,0.9966217279434204
1131241761,13240,dajac,2023-03-09T15:56:05Z,sounds good to me. thanks!,1,0.996069073677063
1168410473,13240,dajac,2023-04-17T09:17:52Z,"it looks like `topicidandnames` is only used if version >= 9. should we move it that else branch? moreover, it seems that we don't need the bimap anymore here. should we just get the mapping that we need and revert the bimap think in the `metadatacache`?",0,0.992031455039978
1168412474,13240,dajac,2023-04-17T09:19:41Z,"just to be sure. the addition of `true` is the only real change here, right?",0,0.9897125959396362
1168414850,13240,dajac,2023-04-17T09:21:50Z,i think that `topicid` is optional so we could just set it here.,0,0.9895017743110657
1168415581,13240,dajac,2023-04-17T09:22:24Z,"is using `true` all the time correct here? i suppose that it should be `false` if `version` < 9, no?",0,0.9936695694923401
1168416665,13240,dajac,2023-04-17T09:23:22Z,nit: i think that we could set it all the time here as well.,0,0.9878244400024414
1168423960,13240,dajac,2023-04-17T09:29:54Z,"should this test be parameterized as well? with this change, it seems that we don't have any tests exercising the validation with topic names now.",0,0.9930486679077148
1168430856,13240,dajac,2023-04-17T09:35:45Z,nit: `true` should be derived from the `version`.,0,0.9950276017189026
1168433830,13240,dajac,2023-04-17T09:38:23Z,"changing the code structure like this is really annoying during reviews. it explodes the diff for no reasons and distracts the reviewing from the more important changes. it would be better to keep those for separate prs. in this case, we could just add the `true` and the `topicid` to the previous code.",-1,0.9715060591697693
1168454144,13240,dajac,2023-04-17T09:56:31Z,would you mind if we keep to keep those code refactoring in the tests for separate pr(s)? this pr is already extremely large and i would like to focus on getting the new code right. all those non-related changes are additional (unnecessary) distractions for now.,0,0.9499067068099976
1168456953,13240,dajac,2023-04-17T09:59:08Z,i think that you could pass config overrides to `createconsumer` directly.,0,0.9890009164810181
1168464261,13240,dajac,2023-04-17T10:05:22Z,i think that consumers created with `createconsumer` are closed automatically by the super class.,0,0.9843301177024841
1168468628,13240,dajac,2023-04-17T10:09:03Z,nit: this could be private.,0,0.9825672507286072
1168468929,13240,dajac,2023-04-17T10:09:20Z,nit: `topicnames.map(topic => {` -> `topicnames.map { topic => `,0,0.9925217032432556
1168469544,13240,dajac,2023-04-17T10:09:58Z,do we really need to use `nameandid` here? this does not seem necessary.,0,0.9919141530990601
1168470063,13240,dajac,2023-04-17T10:10:28Z,"nit: you could get `topicids` with `gettopicids(""topic1"", ""topic2"", ""topic3"")`.",0,0.9919459223747253
1168472971,13240,dajac,2023-04-17T10:13:06Z,i would rather prefer to use the request/response data objects here.,0,0.9820268750190735
1168473224,13240,dajac,2023-04-17T10:13:22Z,could we parameterize the test instead of doing this?,0,0.9905517101287842
1168473647,13240,dajac,2023-04-17T10:13:46Z,i wonder if we already have integration tests for the consumer covering this. do we?,0,0.9687672853469849
1168474784,13240,dajac,2023-04-17T10:14:55Z,this test does not seem to be at the right place. it seems to me that `offsetcommitrequesttest` is more focused on testing the offsetcommitrequest api.,0,0.8801681399345398
1168475048,13240,dajac,2023-04-17T10:15:09Z,nit: let's make all the private methods private.,0,0.9919539093971252
1168475457,13240,dajac,2023-04-17T10:15:32Z,nit: could we revert this change and just add the boolean?,0,0.9915599226951599
1168671042,13240,dajac,2023-04-17T13:11:41Z,nit: indentation seems to be off here.,0,0.9156262874603271
1168675481,13240,dajac,2023-04-17T13:14:40Z,nit: `topicidorzero`?,0,0.990171492099762
1168676628,13240,dajac,2023-04-17T13:15:01Z,nit: `topicnameornull` and get rid of the `optional`?,0,0.9936929941177368
1168677142,13240,dajac,2023-04-17T13:15:24Z,nit: should we remove ` `?,0,0.9867820739746094
1168678603,13240,dajac,2023-04-17T13:16:32Z,nit: should we replace `ofnullable` by a simple `if/else` statement? allocating an optional does not seem necessary here.,0,0.9800179600715637
1168679689,13240,dajac,2023-04-17T13:17:09Z,nit: this one is already in the list (l47).,0,0.9931992888450623
1168688432,13240,dajac,2023-04-17T13:23:02Z,"nit: could we try to combine those? `private static topicidpartition t1p = new new topicidpartition(uuid.randomuuid(), 0, topic1)`?",0,0.9910802245140076
1168689266,13240,dajac,2023-04-17T13:23:38Z,nit: `topicidandnamebimapping`?,0,0.9935531616210938
1168693500,13240,dajac,2023-04-17T13:26:00Z,nit: this empty line could be removed.,0,0.9941554069519043
1168694559,13240,dajac,2023-04-17T13:26:28Z,nit: this empty line could be removed.,0,0.9941554069519043
1168696909,13240,dajac,2023-04-17T13:28:15Z,"if the outcome of the test is different in this case, isn't it a bit weird to combine them in the same unit test?",-1,0.979621171951294
1168703280,13240,dajac,2023-04-17T13:33:05Z,this goes a bit too far in my opinion. we usually prefer to have simpler parameterized tests. could we simplify this somehow and bring stuck back in the main unit test?,-1,0.5537299513816833
1168735466,13240,dajac,2023-04-17T13:52:19Z,"this one made me think that we are probably not doing the right thing in the implementation. in this particular case, if we have only one committed offset and we don't have a response for it because the topic id is wrong, i think that `commitoffsetssync` should not succeed because we actually don't know if the offset was committed or not. what do you think? one way around this would be to verify that we have received a response for each topic-partitions.",0,0.9445210695266724
1168742716,13240,dajac,2023-04-17T13:57:02Z,i am not sure to follow why we need this `consumer` here. couldn't we just have a matcher which verifies what we want/need?,0,0.7296299934387207
1168815694,13240,dajac,2023-04-17T14:36:03Z,"this seems to be a quite complicated way to group `offsetcommitrequestpartition` or `offsetcommitresponsepartition` by `topicidpartition`, no? i would just write two methods to do just this.",0,0.9355915188789368
1185002319,13240,clolov,2023-05-04T13:17:25Z,i believe t1p is abstracted because it is being used in 175 other places in this test class for test setup and assertions.,0,0.9900403618812561
1185137613,13240,clolov,2023-05-04T14:51:40Z,"sorry, could you elaborate, because i am not certain i follow? `gettopicids(...)` will return a map but only if the topics requested have been created first. are you suggesting that since all tests create these three topics we move the creation to the setup method and then we use `gettopicids` everywhere else?",-1,0.9777527451515198
1185779424,13240,Hangleton,2023-05-05T07:29:21Z,"that is right. christo, maybe you can create two separate tests for these cases and factor in common code in a method?",0,0.9930304884910583
1185861417,13240,clolov,2023-05-05T09:04:20Z,"yup, i will get to this today",0,0.949278712272644
1197974839,13240,clolov,2023-05-18T15:36:59Z,"to be honest i would prefer if we leave it like this. if we parameterise it, this means we have to change `sendoffsetcommitrequest`. if we change `sendoffsetcommitrequest` then we need to come up with a different source for `testoffsetcommitwithunknowntopicid`. alternatively i can parameterise this test, but i would end up wrapping a single version in a seq. is the reason you want it parameterised here so that it breaks it down when running the tests in intellij?",0,0.9686000347137451
1197988726,13240,clolov,2023-05-18T15:49:27Z,from my reading of the code this consumer is a captor. we validate some of the things in this method and we validate the overall captured value elsewhere in individual tests. i am not too certain how this can be simplified to just a matcher to be honest.,0,0.7869762182235718
1203965540,13240,Hangleton,2023-05-24T11:46:23Z,"i think david probably hints at consolidating both in one defining object to ease future updates of topic-partition to topic ids. i updated the test class as per david's comment, i am happy to revert if this brings too many loc changes.",0,0.9129417538642883
1203992806,13240,Hangleton,2023-05-24T12:03:45Z,"i think i see what you mean, it is rather heavy-weight and lacks single scope which is preferable for unit tests. updating accordingly.",0,0.9235490560531616
1204079800,13240,Hangleton,2023-05-24T12:54:16Z,did the change to provide higher cohesion to the tests. i split the initial test method in two separated test methods.,0,0.9934005737304688
1204087015,13240,Hangleton,2023-05-24T12:58:43Z,that is true.,0,0.9901561737060547
1204151150,13240,Hangleton,2023-05-24T13:34:57Z,"sure, i removed the method `createtopics` and use `gettopicids` instead.",0,0.9904098510742188
1204162396,13240,Hangleton,2023-05-24T13:40:14Z,"yes, i think the idea of parameterizing the test by version of request is it is faster to identify version-specific failures.",0,0.9860087037086487
1204312762,13240,Hangleton,2023-05-24T14:52:34Z,added a commit to build the dtos directly. this removes the contingency on correctness of the test code which built these dtos.,0,0.9954055547714233
1204356253,13240,Hangleton,2023-05-24T15:12:20Z,"you are right, this is exercised in `offsetfetchrequesttest`, `plaintextconsumertest`, `groupcoordinatorintegrationtest` and `authorizerintegrationtest`. so, i removed this test to avoid duplication.",0,0.9924060702323914
1204361177,13240,Hangleton,2023-05-24T15:14:16Z,added parameterization as david suggested.,0,0.995537281036377
1204376110,13240,Hangleton,2023-05-24T15:20:43Z,"agreed, i thought to put it there because the underlying rpc is used, but you are right, it is a different client-level api.",0,0.9820044636726379
1204403475,13240,Hangleton,2023-05-24T15:33:49Z,i removed the test since this method is already exercised in `org.apache.kafka.clients.admin.kafkaadminclienttest#testoffsetcommitnumretries`.,0,0.9943938255310059
1205089112,13240,Hangleton,2023-05-25T07:11:05Z,"just to clarify, do you mean the commit offsets method should return false when at least 1 over n > 1 could not be committed due to topic id mismatch, or when n == 1 could not be committed for the same reason?",0,0.9930304884910583
1205119564,13240,Hangleton,2023-05-25T07:40:48Z,"sure, that makes sense to get rid of the consumer, since it is mixing test design pattern and overlaps the responsibilities of the matcher as you pointed out.",0,0.9881788492202759
1226607855,13240,dajac,2023-06-12T12:41:20Z,"as a second thought, i wonder if we should complete the future with an exception here. being defensive would help us to catch bugs early one. what do you think?",0,0.9303116202354431
1226610273,13240,dajac,2023-06-12T12:43:20Z,should we remove this one for now as it is not implemented yet?,0,0.9908456206321716
1226612028,13240,dajac,2023-06-12T12:44:42Z,should we remove stale_member_epoch and unknown_member_id for now?,0,0.9937100410461426
1226632779,13240,dajac,2023-06-12T13:00:26Z,"my understanding is that we don't retry when `commitoffsetsasync` is used. is it correct? if it is, it may be better to split the test in two. it is really misleading otherwise.",0,0.8816564083099365
1226634411,13240,dajac,2023-06-12T13:01:50Z,nit: it may be better to name this one `prepare....`.,0,0.7385470271110535
1226634534,13240,dajac,2023-06-12T13:01:56Z,nit: it may be better to name this one `prepare....`.,0,0.7385470271110535
1226636149,13240,dajac,2023-06-12T13:03:07Z,nit: i would inline this in the respective tests because it seems not related to what this method does.,0,0.9910048246383667
1226638371,13240,dajac,2023-06-12T13:04:55Z,is this used anywhere?,0,0.9940593242645264
1226638660,13240,dajac,2023-06-12T13:05:09Z,is this used anywhere?,0,0.9940593242645264
1226647441,13240,dajac,2023-06-12T13:12:15Z,"i think that the method should return false if any mismatched topic id. if i commit foo-topic-id and bar-topic-id, the method should not succeed if we don't get a response for any of them, right?",0,0.9871655702590942
1226648857,13240,dajac,2023-06-12T13:13:25Z,this case is not correct as well in my opinion. the caller should get an exception in this case.,0,0.7068830728530884
1226673880,13240,dajac,2023-06-12T13:32:08Z,nit: topicnameandid?,0,0.993105947971344
1226675517,13240,dajac,2023-06-12T13:33:23Z,it is a bit weird to have this class defined here but i cannot think of a better place for now. thoughts?,-1,0.9906358122825623
1226676007,13240,dajac,2023-06-12T13:33:43Z,nit: this seems to be misaligned.,0,0.8317585587501526
88262234,2140,ijuma,2016-11-16T15:45:33Z,is it intentional that this is `logbuffer` instead of `log_buffer`? same for the `tostring` implementation.,0,0.9923325777053833
88262970,2140,ijuma,2016-11-16T15:48:36Z,should this method be renamed as well?,0,0.9938196539878845
88285663,2140,hachikuji,2016-11-16T17:25:22Z,ack. there are probably a few of these. i'll do another pass and try to find others.,0,0.9398141503334045
89426622,2140,junrao,2016-11-24T02:13:36Z,should we assert record.magic() > 0?,0,0.9942981600761414
89426686,2140,junrao,2016-11-24T02:14:27Z,"to be consistent, perhaps this.size and this.channel should just be size and channel?",0,0.9899647831916809
89426710,2140,junrao,2016-11-24T02:14:45Z,"it seems that some of the changes are lost during rebase? for example, there was code in memoryrecords for setting the buffer limit according to length, and cast position to int instead of creating a long object.",0,0.9872047901153564
89426721,2140,junrao,2016-11-24T02:14:55Z,"this seems to be an existing issue. for uncompressed messages, do we double count messagesread since we already increased the count in line 98?",0,0.9934006929397583
89426736,2140,junrao,2016-11-24T02:15:05Z,this and line 144 don't seem to be correct. it seems that we should add the number of entries in retainedentries?,0,0.99001544713974
89426742,2140,junrao,2016-11-24T02:15:10Z,should we add slice.limit or slice.position?,0,0.9938415288925171
89426755,2140,junrao,2016-11-24T02:15:19Z,it seems that this is only used in test now?,0,0.9932904243469238
89680530,2140,junrao,2016-11-27T00:17:36Z,"in line 337, we get the deep iterator by constructing a logbufferiterator with shallow set to false. to be consistent, it seems that if we want to get a shallow iterator, we should construct a logbufferiterator with shallow set to true instead of call a separate static method?",0,0.9931923747062683
89680531,2140,junrao,2016-11-27T00:17:43Z,is this comment at the right place? the following code doesn't directly allocate any buffer.,0,0.990332305431366
89680539,2140,junrao,2016-11-27T00:17:57Z,"since logentries is a deque, perhaps it's clearer if we explicitly use addlast() ?",0,0.9891828894615173
89680541,2140,junrao,2016-11-27T00:18:03Z,recordsiterator.deeprecordsiterator is no longer valid.,0,0.9770871996879578
89698576,2140,junrao,2016-11-27T20:26:51Z,"instead of having shallowentries() and deepentries(), would it be better to combine them into a logentries(boolean isshallow)? this will make it consistent with how we get an iterator for records through abstractlogbuffer.records(boolean isshallow).",0,0.994281530380249
89698580,2140,junrao,2016-11-27T20:26:55Z,this can be private.,0,0.9921234250068665
89698584,2140,junrao,2016-11-27T20:27:07Z,"hmm, this seems like an existing issue. it seems that we should subtract the wrapper header and the record overhead from position() to get the compressed data size?",0,0.9790935516357422
89698589,2140,junrao,2016-11-27T20:27:17Z,could this be private since it seems to be only used within the class?,0,0.9843510389328003
89698592,2140,junrao,2016-11-27T20:27:35Z,"it seems that logentry.writeheader() is only used inside this class. perhaps we could just move the code from logentry to here as a private method. once we do that, it seems that we could also make putlong() and putint() private in this class.",0,0.990212619304657
89698597,2140,junrao,2016-11-27T20:27:41Z,it seems that we could just eliminate this line?,0,0.989100992679596
89931628,2140,junrao,2016-11-29T02:43:47Z,"with this change, it seems that we can make bufferpool.deallocate(bytebuffer buffer, int size) private?",0,0.9941441416740417
89931638,2140,junrao,2016-11-29T02:43:52Z,should we just remove the commented out code?,0,0.9927593469619751
89931661,2140,junrao,2016-11-29T02:44:09Z,perhaps we can make the comment clearer by saying that this can happen when there is no full log entry in the log buffer.,0,0.9844686388969421
89931696,2140,junrao,2016-11-29T02:44:35Z,would it be necessary to cache the record instance and reuse? it seems that a few methods like size() and setcreatetime() are calling record().,0,0.9919754862785339
89931716,2140,junrao,2016-11-29T02:44:46Z,this maybe a bit confusing since our default compression type to the user is none. could we let the callers use gzip directly?,0,0.7584336400032043
89931730,2140,junrao,2016-11-29T02:44:52Z,$targettimestamp can only be used in scala.,0,0.9941632151603699
89931765,2140,junrao,2016-11-29T02:45:09Z,could we just always load records lazily and get rid of eagerloadrecords? not sure if we lose any performance by doing that.,0,0.8289338946342468
89931793,2140,junrao,2016-11-29T02:45:18Z,"to be consistent, should we change record to message?",0,0.9899437427520752
89931855,2140,junrao,2016-11-29T02:45:53Z,could we rename shallowentries/deepentries to shallowlogentryiterator/deeplogentryiterator so that it's clear that we are not buffering all entries in the call?,0,0.9940134882926941
89931924,2140,junrao,2016-11-29T02:46:37Z,"the contract for loginputstream seems to be that a null value from calling nextentry() indicates normal completion of the iterator and any ioexception indicates an error. so perhaps we should capture eofexception in dataloginputstream since it's only expected there, and convert it to a null return value in nextentry(). then, here, we can just check null for ending the iterator like other places.",0,0.9906980395317078
89931932,2140,junrao,2016-11-29T02:46:43Z,do we want to add a separator between records?,0,0.9934870004653931
89931956,2140,junrao,2016-11-29T02:46:53Z,perhaps we could add a comment here that this class deals with the write path to memorylogbuffer while memorylogbuffer only deals with the read path?,0,0.9914628863334656
89931968,2140,junrao,2016-11-29T02:47:03Z,could this method just call appendunchecked() to avoid code duplication?,0,0.9887669682502747
89931980,2140,junrao,2016-11-29T02:47:09Z,it seems that estimatedbyteswritten() and numrecordswritten() can be private?,0,0.9935163259506226
89931983,2140,junrao,2016-11-29T02:47:11Z,bufferstream.buffer() can just be buffer().,0,0.993446409702301
89932016,2140,junrao,2016-11-29T02:47:36Z,"this also seems to be an existing issue. until memorylogbufferbuilder is closed, buffer().position() is not necessarily accurate since the compressor may not have flushed compressed data to the output stream. currently, recordaccumulator.drain() calls this method before closing memorylogbufferbuilder. so, if builtlogbuffer != null, perhaps it's better to use estimatedbyteswritten()?",0,0.9921133518218994
89932051,2140,junrao,2016-11-29T02:47:59Z,"this also seems to be an existing problem. it seems that when generating those internal messages (tombstone, groups, etc), we assume the message timestamp type is always create_time. however, the offset topic could be configured with log_append_time.",0,0.9902902245521545
89932067,2140,junrao,2016-11-29T02:48:08Z,it seems that we could get rid of ensurematchingmagic since no caller is setting it?,0,0.9922533631324768
90155476,2140,junrao,2016-11-30T01:52:30Z,"for compressed messageset, perhaps it's more consistent if we always return the lastoffset as offsetofmaxtimestamp regardless of the timestamp type? we only need that for timestamp indexing. indexing at the shallow offset level is good enough and will make the indexing logic consistent between the leader replica and the follower replica (which doesn't do decompression during log append).",0,0.9909013509750366
90155523,2140,junrao,2016-11-30T01:52:58Z,"to be future proof, should we pass in the timestamp in this record instead of no_timestamp?",0,0.9945923686027527
90155541,2140,junrao,2016-11-30T01:53:10Z,"since this is only used in memorylogbufferbuilder, perhaps it can be a private method there?",0,0.9911757707595825
90155548,2140,junrao,2016-11-30T01:53:14Z,it seems that this method can be private?,0,0.9936925172805786
90155558,2140,junrao,2016-11-30T01:53:18Z,it seems that this method can be private?,0,0.9936925172805786
90155589,2140,junrao,2016-11-30T01:53:35Z,"info.offsetofmaxtimestamp returns the deep offset of the message with max timestamp. to be consistent with the other code path, if compression is enabled, it seems that we want to return the shallow offset? it maybe clearer to also rename validationandoffsetassignresult.offsetofmaxtimestamp to sth like shallowoffsetofmaxtimestamp.",0,0.9920248985290527
90155602,2140,junrao,2016-11-30T01:53:42Z,it seems that toformatversion() is only used in test now?,0,0.9937403202056885
90155611,2140,junrao,2016-11-30T01:53:46Z,it seems that converttobuffer() is no longer used?,0,0.9939724802970886
90155619,2140,junrao,2016-11-30T01:53:50Z,unused import kafka.api.fetchresponsepartitiondata,0,0.992669939994812
90155632,2140,junrao,2016-11-30T01:53:58Z,"""message set size"" is bit ambiguous. perhaps we should say ""number of messages""?",0,0.9736708998680115
90155643,2140,junrao,2016-11-30T01:54:08Z,"not sure what's ""byte offset"".",0,0.8631283640861511
90155656,2140,junrao,2016-11-30T01:54:15Z,"hmm, why do we have to change the expected size?",0,0.9733269810676575
90155674,2140,junrao,2016-11-30T01:54:24Z,is there a reason that we only test non-compressed message conversion now?,0,0.9914383888244629
90361346,2140,hachikuji,2016-12-01T00:35:21Z,"hmm.. there was actually a reason for this. the static `shallowiterator` returns the more specific logentry type, which would not be possible if `shallow` is passed as an argument. having the more specific type in shallow iteration lets you do some operations to the shallow entries that are not possible with the deep entries (such as setting offsets or timestamps in-place).",0,0.9767728447914124
90363088,2140,hachikuji,2016-12-01T00:50:56Z,ack. i'll fix this and the one below and update the test cases.,0,0.9172459840774536
90377352,2140,hachikuji,2016-12-01T03:27:16Z,"to be honest, i'm not really sure why this comment is needed. it seems obvious that the key and value sizes in the inner messages are based on the uncompressed data (how could they be otherwise if we compress the inner message set as a whole?).",0,0.6568107008934021
90377503,2140,hachikuji,2016-12-01T03:29:28Z,"thanks, i like this idea.",1,0.9804078936576843
90378055,2140,hachikuji,2016-12-01T03:36:43Z,how about `shallowiterator` and `deepiterator`?,0,0.9921322464942932
90378753,2140,hachikuji,2016-12-01T03:45:52Z,"related to my comment above. the reason to separate them is so that we can return a more specific type in the shallow iterator. for `memorylogbuffer`, `shallowentries` returns `bytebufferlogentry`, which gives you hooks for writing over the offset and the timestamp. these methods do not make sense for the inner entries, so it is not desirable to add them to the general `logentry` interface. similarly, with `filelogbuffer`, we get shallow instances of type `filechannellogbuffer`, which provides its own custom hooks. the other thing i like about having the explicit names is that it makes the iteration type clear in the calling code (i don't have to remember whether `true` or `false` means shallow). for consistency, we could change `records(boolean isshallow)` to support two variants. i added this method mainly for testing, but still it would be nice to have a consistent approach.",0,0.9316487312316895
90378909,2140,hachikuji,2016-12-01T03:48:01Z,"as a matter of fact, the `shallow` option is unused for `records()`, so maybe i will change this to have it only return the deep records.",0,0.9899515509605408
90381994,2140,hachikuji,2016-12-01T04:34:16Z,"thanks for the suggestion. i modified `logentry.writeheader` to work with the `dataoutputstream`. after doing so, i found that i no longer needed `putlong` and `putint`.",1,0.9517832398414612
90382244,2140,hachikuji,2016-12-01T04:38:04Z,apologies... i often comment this out in testing and forget about it.,-1,0.8899165391921997
90382891,2140,hachikuji,2016-12-01T04:47:58Z,i think we can. the only cost is that we have to allow for the possibility of an exception thrown from `logentry.record()` instead of `loginputstream.nextentry()` (which already deals with io errors).,0,0.9605821371078491
90383775,2140,hachikuji,2016-12-01T05:02:32Z,"hmm.. i think the test was broken or at least incomplete since `message.toformatversion` only did shallow conversion. when i implemented this in the client code, i forbid shallow-only conversion because it results in bugs like we found in `logcleaner`. we'll probably end up dropping this code after we remove `message.toformatversion` as suggested above.",0,0.9084175229072571
90383989,2140,hachikuji,2016-12-01T05:06:19Z,"it puzzled me for a while when writing this code why the size was coming out different only for snappy, but it turns out that we've overridden the block size in the client code, instead of using the default as was done for the server code.",0,0.9666996598243713
90486643,2140,ijuma,2016-12-01T16:43:09Z,"also, in java, having named methods is clearer than using booleans since one cannot use named arguments. however, it can be a bit confusing to have both options.",0,0.9833939671516418
90487017,2140,ijuma,2016-12-01T16:44:50Z,`shallowiterator` and `deepiterator` sounds good to me.,0,0.7846119999885559
90487806,2140,ijuma,2016-12-01T16:48:26Z,good catch. we probably don't want the change the buffer size in the server to be the same as the client. we may consider changing the client to be the same as the server. see kafka-3704 for details.,1,0.9752933979034424
90805334,2140,guozhangwang,2016-12-05T05:23:18Z,did we get rid of the re-allocation logic as a whole? otherwise we cannot remove this additional check i think.,0,0.9919345378875732
90805786,2140,guozhangwang,2016-12-05T05:31:37Z,"is this private function better than previously in-lined, since it is private anyways?",0,0.9877150058746338
90806087,2140,guozhangwang,2016-12-05T05:36:06Z,"if we only deallocate the initial buffer, if re-allocation happens does that mean we will effectively have ""memory leaks""?",0,0.9784794449806213
90810199,2140,guozhangwang,2016-12-05T06:42:19Z,data -> memory?,0,0.994014322757721
90810687,2140,guozhangwang,2016-12-05T06:49:42Z,is there any rationale for this magic number?,0,0.9863277673721313
90813219,2140,guozhangwang,2016-12-05T07:22:36Z,"i'm following myself about renaming here: we could consider rename to recordentryinputstream, with t extends recordentry.",0,0.9910065531730652
90814254,2140,guozhangwang,2016-12-05T07:36:51Z,this is not introduced in this patch: since we get the exact number of bytes returned from `log.append` could we use that in the trace logging?,0,0.9947018027305603
90815062,2140,guozhangwang,2016-12-05T07:46:44Z,where is this function used?,0,0.9944743514060974
90978864,2140,hachikuji,2016-12-05T23:18:12Z,"this ended up a little ugly whichever way i cut it. i think i prefer the current location because it keeps the message format encapsulated in `record` a bit better, but it comes at the cost of leaking the write optimization which is only used in `memoryrecordsbuilder`. i could go either way here, so let me know if you feel strongly about moving it into `memoryrecordsbuilder`. for now, i'll add a javadoc which explains the usage better.",-1,0.9435569047927856
90979896,2140,guozhangwang,2016-12-05T23:24:38Z,i have a comment on this function and it seems squashed. my question was since it is a private function do we really need this rather than having it in-lined?,0,0.9331229329109192
90979998,2140,guozhangwang,2016-12-05T23:25:18Z,nit: data -> space?,0,0.9884979128837585
90980061,2140,guozhangwang,2016-12-05T23:25:42Z,what is the rationale for this magic number for compressed set?,0,0.9897778630256653
90981109,2140,guozhangwang,2016-12-05T23:32:53Z,we use `maxrecordsize` here and `maxmessagesize` in the other extended class.,0,0.9937469959259033
90981197,2140,guozhangwang,2016-12-05T23:33:27Z,+1.,0,0.9864034652709961
90986644,2140,guozhangwang,2016-12-06T00:12:47Z,"we are using `logentry` here for the message set wrapper, and in other places `logentry` is used for the internal message. we may need to update the javadoc on `logentry` accordingly in different extensions of `loginputstream` and `records` clarify if its `nextentry` and `iterator` returns shallow or deep iterations.",0,0.9942268133163452
90986838,2140,guozhangwang,2016-12-06T00:14:24Z,"this actually returns the message set as a `record`, right?",0,0.9937868118286133
90986917,2140,guozhangwang,2016-12-06T00:15:09Z,nit: also add the `filerecords` reference here?,0,0.9951646327972412
90987096,2140,guozhangwang,2016-12-06T00:16:37Z,nit: indicate that this needs shallow iterations on the entries.,0,0.9926856756210327
90987112,2140,guozhangwang,2016-12-06T00:16:45Z,nit: indicate that this needs deep iterations on the entries.,0,0.9890634417533875
90987175,2140,guozhangwang,2016-12-06T00:17:18Z,"this statement is a bit misleading, how about ""to the format indicated by the given magic value"".",0,0.5988436341285706
90987669,2140,guozhangwang,2016-12-06T00:21:56Z,nit: unnecessary new lines.,-1,0.9751732349395752
90988043,2140,guozhangwang,2016-12-06T00:24:42Z,we can reuse record_overhead_v0 and record_overhead_v1 here.,0,0.994752049446106
90988718,2140,guozhangwang,2016-12-06T00:30:03Z,"update the comment as well for `public`. also i'm wondering if we could rename `wrapperxx` just to `xx` and add comments indicating that they are only used for old formatted messages with magic number > 0, and also add a check in constructor that the `magic()` field is consistent with its values: if it is larger than 0 these two fields should never be null; if it is 0 then these two fields should always be null etc.",0,0.993821382522583
90989533,2140,guozhangwang,2016-12-06T00:36:26Z,is this function only used for unit tests?,0,0.9933338761329651
90989804,2140,guozhangwang,2016-12-06T00:38:51Z,is this function only used in tests?,0,0.993518054485321
90989898,2140,guozhangwang,2016-12-06T00:39:40Z,why we keep its reverse function as private static in `record` while making it in utils?,0,0.9891893863677979
90990467,2140,guozhangwang,2016-12-06T00:44:19Z,read from -> write to?,0,0.9932541251182556
90991673,2140,guozhangwang,2016-12-06T00:54:36Z,why we can use `integer.max_value` for deep iteration?,0,0.9907824397087097
90991785,2140,guozhangwang,2016-12-06T00:55:33Z,do we still need to override this function from `abstractrecords` since we already override its calling `shallowiterator`?,0,0.9931080341339111
90992078,2140,guozhangwang,2016-12-06T00:58:01Z,ditto above. we use `maxmessagesize` and `maxrecordsize` interleavingly.,0,0.9903910160064697
90992562,2140,guozhangwang,2016-12-06T01:02:27Z,hmm... not sure i understand this: if compression is not use we will simply ignore the `shallow` flag and always go shallow??,0,0.6248534917831421
90994228,2140,guozhangwang,2016-12-06T01:17:26Z,could you elaborate a bit why shallow iterator allows extensible `logentry` while deep iterator does not?,0,0.9930283427238464
90994615,2140,guozhangwang,2016-12-06T01:21:28Z,why we need to re-construct the `logentry` if its magic number is larger than 0? could we just set its corresponding record's timestamp directly?,0,0.9849973917007446
90995329,2140,guozhangwang,2016-12-06T01:28:44Z,good idea :),1,0.9881862998008728
90995731,2140,guozhangwang,2016-12-06T01:32:38Z,those java docs need to be updated with the new class names. ditto everywhere else.,0,0.9885860085487366
90996571,2140,guozhangwang,2016-12-06T01:41:11Z,nit: group kafka imports?,0,0.9906715154647827
90997090,2140,guozhangwang,2016-12-06T01:45:58Z,"i think we do not need to make `builderwithentries` public since this is the only caller here, and it is followed by a `build()` call immediately, so we can still use `withlogentries`.",0,0.986440122127533
90997888,2140,guozhangwang,2016-12-06T01:53:42Z,"it is not introduced in this patch: i think its more clear to use two vals here, one named `trimedrecords` and one named `validrecords`.",0,0.9928003549575806
90998010,2140,guozhangwang,2016-12-06T01:55:10Z,where is this object used?,0,0.9946411848068237
90998487,2140,guozhangwang,2016-12-06T02:00:39Z,"a meta clarification question: for all these classes, are we planning to get rid of them all at the same time when the old consumer is removed?",0,0.9917080998420715
90999554,2140,guozhangwang,2016-12-06T02:12:13Z,looks good :),1,0.9746956825256348
90999912,2140,guozhangwang,2016-12-06T02:16:23Z,private?,0,0.990565836429596
91007176,2140,hachikuji,2016-12-06T03:45:33Z,hmm... i may have misunderstood how this worked. i'll add it back.,0,0.8333612084388733
91008613,2140,hachikuji,2016-12-06T04:05:02Z,"""data"" is correct, but i'll clarify the comment since it does read a little awkwardly. we're trying to say that the client should raise an error if the size of the message exceeds the bytes returned in the response.",0,0.9882259964942932
91008790,2140,hachikuji,2016-12-06T04:07:51Z,it was copied from the server code: [a link] i think perhaps the 1024 comes from the minimum block size for snappy encoding. i can add a comment about that part at least.,0,0.994877815246582
91009212,2140,hachikuji,2016-12-06T04:13:44Z,it's used in this file. it may not show in the diff because i moved it from `filemessageset` (which was deleted).,0,0.9942389726638794
91009296,2140,hachikuji,2016-12-06T04:15:00Z,inside `logmanager.asyncdelete`.,0,0.9931157231330872
91009688,2140,hachikuji,2016-12-06T04:20:18Z,it's the maximum size of a record entry to read. i think the only place we use it is in `dumplogsegments`.,0,0.989340603351593
91010122,2140,hachikuji,2016-12-06T04:27:05Z,"the main reason for extension of `logentry` is to enable optimization tricks like overwriting the offsets in place (see `bytebufferlogentry`) or reading the magic byte without loading the record data (see `filechannellogentry`). these tricks are generally only possible for the shallow records. you can't modify the deep records in place since they have been decompressed, nor can you optimize which parts of the record to read (you have to read the whole thing). for the deep records, there's not much you can do aside from read the data, so extension seemed unnecessary.",0,0.9876729846000671
91010212,2140,hachikuji,2016-12-06T04:28:14Z,"haha, depends on whether it's compressed or not, right?",1,0.9452825784683228
91010306,2140,hachikuji,2016-12-06T04:29:41Z,i have a comment in `loginputstream` which attempts to make the distinction clear. let me know if more explanation is needed.,0,0.9911773204803467
91011143,2140,hachikuji,2016-12-06T04:41:47Z,"the wrapper values can be null if either the magic is 0 or if the record is uncompressed. i'll add an assertion for this, but i'd prefer to keep the current names since it's otherwise harder to explain.",0,0.9932214021682739
91011764,2140,hachikuji,2016-12-06T04:51:21Z,"it was necessary before because of the optimization in `filechannellogentry.magic()`, but since i've factored that into `logentry`, i was able to remove it.",0,0.9933991432189941
91011883,2140,hachikuji,2016-12-06T04:52:59Z,"if compression is not used, there are no deep entries.",0,0.9881614446640015
91012046,2140,hachikuji,2016-12-06T04:55:40Z,"i followed what the current code did. previously deep iteration was done here in `bytebuffermessageset.deepiterator`, which has no check for max message size.",0,0.9929028153419495
91012622,2140,hachikuji,2016-12-06T05:02:47Z,"hmm... seems worth exploring. we could add a `setwrappertimestamp(timestamptype, long)` or something like that, but i'm not sure it's a good idea to make those fields mutable.",0,0.9380087852478027
91012841,2140,hachikuji,2016-12-06T05:06:55Z,the public version of `builderwithentries` is used in `logvalidator` and `bytebuffermessageset`.,0,0.9948705434799194
91013183,2140,hachikuji,2016-12-06T05:12:28Z,"on second thought, doing so would change the behavior of this function.",0,0.9847918748855591
91013213,2140,hachikuji,2016-12-06T05:12:48Z,"yes, that is the hope. i've removed almost all other uses.",0,0.9823194146156311
91017536,2140,hachikuji,2016-12-06T06:12:35Z,"actually i had to remove these assertions. first, if the magic is 1, then we can't distinguish between a shallow uncompressed entry, and a deep entry, which would also not have its compression flag enabled. we could at least raise an error if magic is 0 and there is a provided wrapper timestamp., but we currently have test cases which allow us to create a record with only a valid crc (which means we can't check magic). we could probably be a little stricter: if there aren't enough bytes in the bytebuffer to read the record overhead, then obviously the record can't be valid, so maybe those test cases are kind of silly and should be removed.",0,0.986524224281311
91149520,2140,guozhangwang,2016-12-06T19:11:31Z,"aha, i was thinking about the new format :) nvm.",1,0.9941565990447998
91149711,2140,guozhangwang,2016-12-06T19:12:25Z,"i was thinking if we can save one object creation, but it seems less worth optimizing since we are not re-creating the underlying buffer anyways. so it's your call.",0,0.9818379878997803
91826419,2140,junrao,2016-12-10T02:22:04Z,deepentries => deepiterator ?,0,0.9912375211715698
91826423,2140,junrao,2016-12-10T02:22:10Z,"is ""file-backed log buffer."" still needed?",0,0.9932090640068054
91826431,2140,junrao,2016-12-10T02:22:21Z,"hmm, why do start and end need to be long?",0,0.9789095520973206
91826435,2140,junrao,2016-12-10T02:22:28Z,"""log buffer"" probably need to be changed?",0,0.9907982349395752
91826438,2140,junrao,2016-12-10T02:22:35Z,it seems that position should be int?,0,0.9877521991729736
91826441,2140,junrao,2016-12-10T02:22:40Z,could we just cast channel.size() to int?,0,0.9937533736228943
91826447,2140,junrao,2016-12-10T02:22:45Z,shallowentries in this and the next two methods should be shallowiterator?,0,0.9931814074516296
91826461,2140,junrao,2016-12-10T02:23:01Z,"is the reference to ""log buffer"" still valid?",0,0.9939728379249573
91826468,2140,junrao,2016-12-10T02:23:08Z,"it seems that the follower could call this more than once. so, perhaps it's worth caching.",0,0.9888662695884705
91826477,2140,junrao,2016-12-10T02:23:21Z,it doesn't seem that last offset is being maintained here.,0,0.9681504368782043
91826488,2140,junrao,2016-12-10T02:23:46Z,"hmm, we are getting the last offset, which is not necessarily the offset for message with the max timestamp.",0,0.9745997190475464
91826489,2140,junrao,2016-12-10T02:23:52Z,this and the next method probably should be deepiterator() too?,0,0.9937376976013184
91826492,2140,junrao,2016-12-10T02:23:59Z,"i had the following comment earlier. is that valid? this also seems to be an existing issue. until memorylogbufferbuilder is closed, buffer().position() is not necessarily accurate since the compressor may not have flushed compressed data to the output stream. currently, recordaccumulator.drain() calls this method before closing memorylogbufferbuilder. so, if builtlogbuffer != null, perhaps it's better to use estimatedbyteswritten()?",0,0.9915521144866943
91826501,2140,junrao,2016-12-10T02:24:05Z,are the references to log buffer still valid?,0,0.9942848086357117
91826508,2140,junrao,2016-12-10T02:24:13Z,"to be consistent, should we change entries to records?",0,0.9909103512763977
91826512,2140,junrao,2016-12-10T02:24:18Z,should logentries be records?,0,0.9926185011863708
91830966,2140,ijuma,2016-12-10T07:53:07Z,"btw, it's a bit of a shame to lose the enhanced foreach syntax. is there a reason not to expose a `deepiterable()` method instead?",-1,0.9827415347099304
91880865,2140,becketqin,2016-12-12T04:10:01Z,kafka-4497 reported an issue regarding this. there was a few other issues in `bytebuffermessageset.filterinto()` logic. i provided a patch in #2242 . we should probably fix the logic here as well.,0,0.9921410083770752
92014373,2140,hachikuji,2016-12-12T18:57:41Z,"yes, that makes sense. apologies for missing the comment before.",-1,0.8671329021453857
92020118,2140,hachikuji,2016-12-12T19:24:26Z,"ack. this goes back to logcleaner actually, but i'll go ahead and fix here.",0,0.9404104351997375
92072625,2140,junrao,2016-12-13T00:21:41Z,"a 4 byte size, an 8 byte offset => an 8 byte offset, a 4 byte size of the record",0,0.9928184747695923
92072954,2140,junrao,2016-12-13T00:24:22Z,"is the reference to ""log buffer"" still valid?",0,0.9939728379249573
92072967,2140,junrao,2016-12-13T00:24:27Z,"is the reference to ""log buffer "" still valid?",0,0.99383544921875
92195306,2140,ijuma,2016-12-13T15:42:32Z,"it's a bit annoying that we create so much indirection (dataloginputstream -> bytebufferinputstream -> underlyinginputstream -> bytebuffer -> byte[]). in an ideal world, we would not bother with `inputstream` at all and would just operate at the `bytebuffer` level. however, the gzip case is hard to do that way.",-1,0.9755231142044067
92216997,2140,junrao,2016-12-13T17:09:21Z,do we need to change the position of buffer? perhaps we could instead just change the position in the slice passed to record().,0,0.9940263032913208
92217186,2140,junrao,2016-12-13T17:10:13Z,"""a 4 byte size,"" needs to be removed.",0,0.9913697242736816
92225885,2140,hachikuji,2016-12-13T17:50:35Z,"haha, yeah. one of the layers is sort of fake (`datainputstream` should be a mixin), but the point is still valid.",1,0.9158762097358704
92227525,2140,hachikuji,2016-12-13T17:58:31Z,"currently `record` expects the position of the `bytebuffer` to be at 0. i was tempted to change this assumption, but decided to leave it for now (it's a bit annoying to change all the accessors to assume relative positioning). we could accomplish the same result using `mark()` and `reset()` if that seems any better.",-1,0.8558253049850464
563471404,2140,dengziming,2021-01-25T05:30:44Z,"should this be `math.min(length, size.get() - offset)`?",0,0.9940367937088013
563909128,2140,junrao,2021-01-25T17:32:58Z,: thanks for the comment. this does seem like a bug. would you be interested in submitting a separate pr to have this fixed?,1,0.968414306640625
179653282,4830,tedyu,2018-04-06T03:32:29Z,should this be kafka_1_1_iv0 ?,0,0.9940165281295776
179653551,4830,tedyu,2018-04-06T03:35:26Z,i think channelunmutingcallback would be better name,0,0.9906373620033264
179898815,4830,jonlee2,2018-04-06T23:49:03Z,"this was based on the comments in lines 31-36, which states ""when we change the protocol a second time while developing 0.10.0, we will add a new config value ""0.10.0-iv1"" and a corresponding case object kafka_0_10_0-iv1. we will change the config value ""0.10.0"" to map to the latest internal version object kafka_0_10_0-iv1."" following the example, i set 1.1 to the latest internal version, kafka_1_1_iv1.",0,0.9943761825561523
179919414,4830,lindong28,2018-04-07T15:22:58Z,`throttledelayms`?,0,0.9956231713294983
179919602,4830,lindong28,2018-04-07T15:30:06Z,"if connection state is connecting (i.e. connectiondelay = long.max_value) and throttledelay is 10 ms, should we poll this connection right after 10 ms, or should we wait until the state is connected?",0,0.993354320526123
179919811,4830,lindong28,2018-04-07T15:38:07Z,would it be more intuitive and consistent to let `clusterconnectionstates.isready()` return false if the connection is throttled?,0,0.984818696975708
179919877,4830,lindong28,2018-04-07T15:40:51Z,maybe `throttledelayms`?,0,0.9948002099990845
179919904,4830,lindong28,2018-04-07T15:41:38Z,"maybe `polldelayms`? also, can you update the param in the java doc?",0,0.9947016835212708
179919911,4830,lindong28,2018-04-07T15:41:53Z,maybe `polldelayms`?,0,0.9923954010009766
179920062,4830,lindong28,2018-04-07T15:47:04Z,"according to the java doc of log.trace(), it says `this form avoids superfluous string concatenation when the logger is disabled for the trace level`. thus we probably don't need to explicitly check `log.istraceenabled`.",0,0.9919615387916565
179920083,4830,lindong28,2018-04-07T15:48:11Z,nits: it may be simpler to just do `if (nodeswithclientsidethrottlingenabled.contains(nodeid) && throttletimems > 0)`,0,0.9934999346733093
179920227,4830,lindong28,2018-04-07T15:53:25Z,we probably don't need to explicitly check log.isdebugenabled(...) because `log.debug` will automatically check this before doing string operation.,0,0.9913488030433655
179920433,4830,lindong28,2018-04-07T16:00:33Z,"it seem a bit unintuitive -- if a node's apiversionresponse's version is smaller than 2, why would the node be in `nodeswithclientsidethrottlingenabled` in the first place? it maybe more intuitive to remove this `else` branch and instead remove the node from `nodeswithclientsidethrottlingenabled` in `handleconnections()`. what do you think?",0,0.8738738894462585
179920578,4830,lindong28,2018-04-07T16:04:56Z,"in order to be consistent with other comments, it may be better to say `introduced apiversionsrequest v2 via kip-219`. also, can you move `""1.1"" -> kafka_1_1_iv1` to the last entry?",0,0.9952800273895264
179920783,4830,lindong28,2018-04-07T16:13:09Z,can `throttledchannel` be `val` instead of `var`?,0,0.9937421679496765
179920867,4830,lindong28,2018-04-07T16:17:45Z,it seems that the return value of `tryunmuate` is only needed for trace level logging. can we move the trace level logging into this method and make this method void to simplify the implementation?,0,0.9921863079071045
179920958,4830,lindong28,2018-04-07T16:22:49Z,can `throttledchannel` be `val`?,0,0.9947598576545715
179920962,4830,lindong28,2018-04-07T16:22:56Z,can `throttledchannel` be `val`?,0,0.9947598576545715
179921259,4830,lindong28,2018-04-07T16:35:48Z,it is probably not necessary to check `throttletimems > 0` since `maybethrottle()` will check it anyway.,0,0.9908158779144287
179921295,4830,lindong28,2018-04-07T16:37:03Z,"it maybe more readable to keep the code style consistent by moving `quotas.request.maybethrottle(request, requestthrottletimems)` to a new line with `{` and `}`.",0,0.9842648506164551
179921553,4830,lindong28,2018-04-07T16:44:54Z,i think the word `maybe` in the original method name `mayberecordandthrottle` is mostly for `throttle`. it is probably more intuitive to name this method `getthrottletimems`.,0,0.9841803312301636
179921638,4830,lindong28,2018-04-07T16:48:10Z,it seems a bit redundant to check `quotasenabled` in both `mayberecord` and `maybethrottle`. it is probably more intuitive to check `quotasenabled` only in `mayberecord` such that `throttletimems` will be 0 if `quotasenabled` is false. then `maybethrottle` can act solely based on `throttletimems`.,0,0.9458590149879456
179921729,4830,lindong28,2018-04-07T16:51:06Z,"nits: it may be more readable to use math.max(bandwidththrottletimems, requestthrottletimems) to be consistent with other code and also to show that these two variables are treated equally.",0,0.989205002784729
180278955,4830,jonlee2,2018-04-10T02:01:50Z,done,0,0.8682363629341125
180286163,4830,jonlee2,2018-04-10T03:09:53Z,done,0,0.8682363629341125
180286169,4830,jonlee2,2018-04-10T03:09:57Z,done,0,0.8682363629341125
180286176,4830,jonlee2,2018-04-10T03:10:00Z,good point. i think throttledelay should make sense only when connected (either checking_api_versions or ready). updated the code to explicitly check the connection state to determine which delay to return.,1,0.9637829661369324
180286183,4830,jonlee2,2018-04-10T03:10:06Z,done. i also updated clusterconnectionstates.hasreadynodes() to take the throttling state into account. please review that change as well.,0,0.9799347519874573
180286188,4830,jonlee2,2018-04-10T03:10:08Z,done,0,0.8682363629341125
180286192,4830,jonlee2,2018-04-10T03:10:10Z,done,0,0.8682363629341125
180286207,4830,jonlee2,2018-04-10T03:10:20Z,done,0,0.8682363629341125
180286219,4830,jonlee2,2018-04-10T03:10:26Z,"based on your next comment, i think it still makes sense to call this mayberecord() (or mayberecordandgetthrottletimems?) because recording only happens when quotasenabled == true. and also rename maybethrottle() to throttle(). i made those changes. what do you think?",0,0.9408347606658936
180286234,4830,jonlee2,2018-04-10T03:10:32Z,"makes sense assuming that maybethrottle() always uses throttle time returned by mayberecord(), which is the case.",0,0.9877683520317078
180286244,4830,jonlee2,2018-04-10T03:10:34Z,done,0,0.8682363629341125
180286350,4830,jonlee2,2018-04-10T03:11:33Z,done,0,0.8682363629341125
180286480,4830,jonlee2,2018-04-10T03:12:56Z,this variant takes 3+ arguments after the format string and the comment says that it incurs a small overhead. looks like the same check is used for other places where 3+ arguments are taken. will keep unless you have other concerns.,0,0.9902652502059937
180286492,4830,jonlee2,2018-04-10T03:13:04Z,done,0,0.8682363629341125
180286561,4830,jonlee2,2018-04-10T03:13:38Z,"for this, i removed the check because it take 1 or 2 args.",0,0.9918795228004456
180286995,4830,jonlee2,2018-04-10T03:15:53Z,"it was to cover corner cases where a broker restarted with a lower version (like rollback). i am not entirely sure how this can be in handleconnections(), though. it looks like just initiating api version fetch. can you elaborate?",0,0.9905106425285339
180287026,4830,jonlee2,2018-04-10T03:15:59Z,done,0,0.8682363629341125
180287053,4830,jonlee2,2018-04-10T03:16:05Z,done,0,0.8682363629341125
180287077,4830,jonlee2,2018-04-10T03:16:10Z,done,0,0.8682363629341125
180287095,4830,jonlee2,2018-04-10T03:16:14Z,done,0,0.8682363629341125
180287122,4830,jonlee2,2018-04-10T03:16:20Z,done,0,0.8682363629341125
180671354,4830,lindong28,2018-04-11T08:22:18Z,is this method used only in test? it maybe unnecessary to add a method to a interface solely for test purpose.,0,0.9872122406959534
180673624,4830,lindong28,2018-04-11T08:30:23Z,`isthrottled()` is only called once in non-test code (i.e. `clusterconnectionstates.isready(...)`). it maybe simpler to just call `throttledelayms(...) > 0` in `isready()`. (similar to the code in `hasreadynodes()`),0,0.9901189804077148
180675326,4830,lindong28,2018-04-11T08:36:50Z,how about just call `isready()` here? i understand that existing code does not re-use the isready(). it maybe better to improve it.,0,0.9918028712272644
180678877,4830,lindong28,2018-04-11T08:49:44Z,it seems that we can remove `isconnected(..)` and replace it with `isready(...)` in `polldelayms(...)`. `isconnected()` will be different from `isready()` only when state is `checking_api_versions`. but we are sending apiversionrequest to broker in `handleinitiateapiversionrequests()` anyway without checking whether the connection is throttled. alternatively we can update `handleinitiateapiversionrequests()` so that it does not send `apiversionrequest` if the connection is throttled. personally i would not do this because i don't think the first version apiversionrequest would overload the broker and thus the extra code/logic in client-side implementation is probably not worthwhile.,0,0.9899730682373047
180679073,4830,lindong28,2018-04-11T08:50:31Z,"`throttledeadlinems` maybe be a bit ambiguous in how it is used -- does it mean the connection should be throttled or un-throttled after this deadline? how about `throttleuntiltimems`, `muteuntiltimems` or `earliestsendtimems`?",0,0.9864437580108643
180679291,4830,lindong28,2018-04-11T08:51:20Z,we probably don't need this method if we don't need `clusterconnectionstates.isconnected()`.,0,0.9912344217300415
180682137,4830,lindong28,2018-04-11T09:00:59Z,we can probably just use `now` without calling `time.milliseconds()` here.,0,0.9909847974777222
180682340,4830,lindong28,2018-04-11T09:01:36Z,we can probably call `time.milliseconds` only once and share it with the existing `now = time.milliseconds()`.,0,0.9921056032180786
180683981,4830,lindong28,2018-04-11T09:07:30Z,yeah `mayberecordandgetthrottletimems()` sounds better.,0,0.9836528301239014
180813450,4830,lindong28,2018-04-11T16:14:40Z,"previously the way we throttle a request is pretty extensible: we first throttle based on byte rate, and if that passes, then we throttle based on produce rate. if in the future we have another throttle mechanism, e.g. based on cpu, we can easily stack this on top of byte-rate-based and request-rate-based throttling mechanism. the way this patch implements throttling is kind of hard to extend (or appears to be difficult to read) due to the following reasons: - the number of throttling mechanisms is hard-coded to be 2 in throttlechannel.tryunmute() - instead of being able to distribute throttling mechanism in multiple places, now we have to determine the throttle time of all mechanism in one place (e.g. here) and use the one that has the largest throttle time. this will work for now. but it will be hard to extend and seems not-so-readable. - we pass around option[throttledchannel] and treats `none` separately from `some()`. it will be cleaner to just pass one non-option object. i am wondering if the following high-level solution would be better: in class `kafkachannel` we use an integer to keep track of the number of existing mechanisms that are throttling this channel. for example, if this request exceeds the byte-based quota, we increment this integer by one and enqueue an object into a delayed queue. after the corresponding throttle time is passed, we dequeue this object and decrement the value of this integer in the `kafkachannel`. if the value is 0 after it is decremented, we unmute the channel. this solution may be cleaner in the following sense: - we no longer needs to pass option[throttledchannel]. - we can implement byte-based and request-based throttling mechanism in the same manner as the existing kafka implementation without having to put them together. - the solution is more extensible since it does not assume there are exactly two throttling mechanisms. what do you think?",0,0.9657377004623413
182270273,4830,jonlee2,2018-04-17T23:21:30Z,done,0,0.8682363629341125
182270329,4830,jonlee2,2018-04-17T23:21:47Z,done,0,0.8682363629341125
182270349,4830,jonlee2,2018-04-17T23:21:58Z,done,0,0.8682363629341125
182270366,4830,jonlee2,2018-04-17T23:22:04Z,done,0,0.8682363629341125
182270438,4830,jonlee2,2018-04-17T23:22:32Z,renamed to throttleuntiltimems.,0,0.9904826879501343
182271668,4830,jonlee2,2018-04-17T23:31:08Z,"now that isready() checks for throttling status, i don't think it can be used directly for polldelayms(). polldelayms() needs to check if the state is ready and *throttled*. i can directly check if the state is ready, instead of isconnected(). will that work?",0,0.9904245734214783
182271745,4830,jonlee2,2018-04-17T23:31:44Z,see the comment above. i'll remove once we agree on what to do for polldelayms().,0,0.9955690503120422
182271764,4830,jonlee2,2018-04-17T23:31:52Z,done,0,0.8682363629341125
182271781,4830,jonlee2,2018-04-17T23:31:59Z,done,0,0.8682363629341125
182271956,4830,jonlee2,2018-04-17T23:33:16Z,"we discussed this offline and agreed to keep the current logic for using the max. as for option[throttledchannel], i used kafkachannel to keep the ref count as suggested and got rid of the use of option[throttledchannel].",0,0.9946125745773315
183115763,4830,lindong28,2018-04-20T17:15:27Z,"the java doc seems to be inconsistent with the implementation. if the connection has been established and the throttle delay is 0, we actually return `long.max_value` instead of 0. also, can this java doc follow the style of the existing java doc for `connectiondelay`. for example, `returns the number of milliseconds to wait, based on the connection state and the throttle time, before attempting to send data.`",0,0.9739998579025269
183115843,4830,lindong28,2018-04-20T17:15:45Z,the java doc seems to be inconsistent with the implementation.,0,0.8716147541999817
183145676,4830,lindong28,2018-04-20T19:16:12Z,"it seems that `decrementunmuterefcountandget` and `unmute` are always used together. would it be simpler to just modify the existing method `unmute` to be `maybeunmute`, which internally will decrement the reference count and umute the channel if the reference count is 0?",0,0.9904452562332153
183146203,4830,lindong28,2018-04-20T19:18:35Z,"would it be simpler to just modify the existing method `mute` to be `maybemute`, which internally will increment the reference count and mute the channel if the reference count is 1 after it is incremented?",0,0.9910891056060791
183147589,4830,lindong28,2018-04-20T19:24:59Z,should this be debug level logging?,0,0.9908248782157898
183150790,4830,lindong28,2018-04-20T19:40:01Z,"it maybe subjective. i am more inclined not to use super.*. can we keep the existing java method style, where we check `quotasenabled` in `mayberecordandgetthrottletimems`, and call `recordandgetthrottletimems` if `quotasenabled` is true. `mayberecordandgetthrottletimems` can be defined in both `clientrequestquotamanager` and `clientquotamanager`. `recordandgetthrottletimems` will be defined only in `clientquotamanager`.",0,0.9453274607658386
183152661,4830,lindong28,2018-04-20T19:49:15Z,"this method is in `clientrequestquotamanager` but not in `clientquotamanager`. and it kind of overlaps with `throttle` and `mayberecordandgetthrottletimems`. so the simplification of removing callback in kafkaapis.java comes at the cost of added methods and inconsistency in `clientrequestquotamanager` and `clientquotamanager`. i am usually conservative and prefer to keep the existing code style unless the code style is clearly superior. in this case there is pros and cons in the new code style. and since difference people may have different opinion, it may cause back-and-forth change in open source development. later the second reviewer can comment on this.",0,0.9693849086761475
183153259,4830,lindong28,2018-04-20T19:52:02Z,"previously the throttletimems in fetchresponse is `bandwidththrottletimems + requestthrottletimems`. now it is changed to `max(bandwidththrottletimems, requestthrottletimems)`.",0,0.9936400055885315
183153543,4830,lindong28,2018-04-20T19:53:30Z,"previously the throttletimems in produceresponse is `bandwidththrottletimems + requestthrottletimems`. now it is changed to `max(bandwidththrottletimems, requestthrottletimems)`.",0,0.9937790036201477
183155316,4830,lindong28,2018-04-20T20:00:37Z,i am wondering if there is specific reason for the previous method signature.,0,0.9635455012321472
183588951,4830,jonlee2,2018-04-24T02:20:45Z,we need to return max since we are not stacking throttling anymore.,0,0.9906812310218811
183588956,4830,jonlee2,2018-04-24T02:20:49Z,we need to return max since we are not stacking throttling anymore.,0,0.9906812310218811
183588969,4830,jonlee2,2018-04-24T02:20:54Z,this is because we don't need to pass this as a callback anymore.,0,0.993035614490509
183603418,4830,jonlee2,2018-04-24T04:43:04Z,done,0,0.8682363629341125
183603427,4830,jonlee2,2018-04-24T04:43:11Z,done,0,0.8682363629341125
183603515,4830,jonlee2,2018-04-24T04:43:59Z,i actually removed mayberecordthrottle() from clientrequestquotamanager. it is now consistent with clientquotamanager.,0,0.9946849346160889
183603548,4830,jonlee2,2018-04-24T04:44:21Z,done. thanks for catching this.,1,0.9719163179397583
183603566,4830,jonlee2,2018-04-24T04:44:33Z,updated,0,0.7592994570732117
183604255,4830,jonlee2,2018-04-24T04:50:13Z,"i thought about it and i actually prefer to keep it this way. the reason why is that the ref count is used by socketserver only and thus i want socketserver to be the only one that updates the count. in other words, whatever layer that uses this ref count should update it within that layer. if we expose this to selector, i am concerned that there may be some misuse. what do you think?",0,0.7771939039230347
183604277,4830,jonlee2,2018-04-24T04:50:29Z,please see the comment above.,0,0.9943179488182068
183916192,4830,lindong28,2018-04-25T00:19:45Z,nits: can we use math.max(...)?,0,0.9908115863800049
183917654,4830,lindong28,2018-04-25T00:33:09Z,it may be slightly better to share the code with the existing `setexpectedapiversionsresponse()`.,0,0.9932109713554382
183918381,4830,lindong28,2018-04-25T00:39:55Z,do we need this change?,0,0.9930158853530884
183919344,4830,lindong28,2018-04-25T00:48:28Z,"typo requoest. also, should the throttle time for request rate quota to be larger than 0, since the request rate quota is 0.01?",0,0.993306577205658
183919358,4830,lindong28,2018-04-25T00:48:39Z,typo requoest,0,0.990917980670929
183940157,4830,jonlee2,2018-04-25T04:27:12Z,done,0,0.8682363629341125
183940161,4830,jonlee2,2018-04-25T04:27:15Z,refactored the code to maximize code reuse.,0,0.9917460680007935
183940170,4830,jonlee2,2018-04-25T04:27:24Z,forgot to remove. updated.,0,0.62621009349823
183940176,4830,jonlee2,2018-04-25T04:27:28Z,"fixed. the test is instrumented so that both quotas are violated, but throttle time is recorded for the max of the two only. that's why throttle time metrics for request quota is supposed to be 0.",0,0.9835831522941589
183940180,4830,jonlee2,2018-04-25T04:27:31Z,fixed,0,0.920660674571991
184196347,4830,rajinisivaram,2018-04-25T20:30:58Z,"there are a lot of comments like this that refer to kip-219. typically, we don't include kip numbers and jiras in comments for code changes. it is preferable to have comments that are self contained so that developers don't have to find the kip to follow the code.",0,0.9903781414031982
184196826,4830,rajinisivaram,2018-04-25T20:32:58Z,"had a comment on the kip discuss thread about the approach to update only apiversions version. can you respond on the thread, please?",0,0.9934408068656921
184197543,4830,rajinisivaram,2018-04-25T20:35:47Z,"i haven't gone through the pr in detail, but i think this callback is invoked on a different thread when throttle time expires. `selector` is not thread-safe and we expect methods on the selector to be invoked from a single thread.",0,0.9883914589881897
184199595,4830,rajinisivaram,2018-04-25T20:43:28Z,"i am not sure about this. since quotas are calculated differently, not sure `max` gives the same result as the throttle times calculated separately as it was done earlier.",0,0.6926621198654175
184753260,4830,jonlee2,2018-04-27T17:25:02Z,"i removed kip-219 references, except for apiversion.scala.",0,0.9933757185935974
184753299,4830,jonlee2,2018-04-27T17:25:10Z,"yes, i replied to the vote thread for seeking comments. could you also respond to that thread since you were one of the original voters?",0,0.9910842180252075
184753337,4830,jonlee2,2018-04-27T17:25:17Z,"thank you for catching this. this is an important point. i made the following changes to address this. - removed the callback from socketserver to the api layer - when throttling starts and ends, the api layer will put responses using new responseactions to the request channel queue to notify socket server of start/end throttling - when socketserver receives responses with these new actions, it will update reference count and try to unmute the channel with these changes, reference count handling and mute/unmute channel will be handled in the same thread.",1,0.9829779267311096
184754840,4830,jonlee2,2018-04-27T17:30:50Z,"with this kip, a response needs to be sent out with a throttle time value before actually starting throttling, and thus we need to determine how long we should mute the channel first before sending out the response. in other words, if multiple quotas are violated, we can't really wait till throttling for one quota is over before computing throttle time for next quota. under this scenario, i thought using the max is reasonable. it will be same as before if only one quota is violated. if multiple quotas are violated, using max may not give the same throttle time in some cases but i am not sure what will be a better alternative. i am not entirely sure about how throttle times can be ""calculated separately"" with this kip. are you suggesting that on multiple quota violations, say, produce and request, we throttle for produce violation only and deal with any remaining request quota violation the next time the client sends another produce request after the initial throttling? but this is also different from the way it was and can be inefficient (in case we keep picking smaller throttle time).",0,0.9568785429000854
184950779,4830,rajinisivaram,2018-04-30T10:10:15Z,"no, i am not suggesting that we do only one at a time. i think we need to see if we can do a better calculation than `max` to combine the two (or potentially many in future).",0,0.9818275570869446
185120383,4830,jonlee2,2018-04-30T21:49:07Z,"i still think using max is reasonable. in my understanding, that is the minimum amount of time we need to throttle anyway for the traffic at the time of quota violation. there may be other connections using the same client id/user while the throttling is going on, but that will only add more load and thus will not improve the throttle time. i also discussed with and he agreed. would you let me know if you have any specific suggestions?",0,0.8202608823776245
186307847,4830,lindong28,2018-05-07T00:06:29Z,nits: can we replace `throttledeadlinems` with `throttleuntiltimems` for consistency?,0,0.9901410937309265
186308119,4830,lindong28,2018-05-07T00:14:46Z,nits: can we align the second line of parameters with the first line in the same manner as `sendinternalmetadatarequest()`?,0,0.9934419393539429
186308382,4830,lindong28,2018-05-07T00:21:40Z,"according to the java doc of org.slf4j.logger.trace, `this form avoids superfluous string concatenation when the logger is disabled for the trace level. however, this variant incurs the hidden (and relatively small) cost of creating an object[] before invoking the method`. so it is probably ok to skip checking `log.istraceenabled`. it will also be more consistent with the existing invocation of `log.trace()` in kafka.",0,0.9885425567626953
186308601,4830,lindong28,2018-05-07T00:28:08Z,"since this integer is decremented when `tryunmutechannel()` is called, would it be a bit more intuitive to name it `muterefcount()`? if so, we may want to also rename methods such as `incrementunmuterefcount()`, `decrementunmuterefcountandget()`, `getunmuterefcount()` and `incrementchannelunmuterefcount()`.",0,0.9919286966323853
186309712,4830,lindong28,2018-05-07T00:55:33Z,"for the same reason that this patch adds the throttletimems field to the leaderandisrresponse, should we also add this field to stopreplicaresponse?",0,0.9923192858695984
186313712,4830,lindong28,2018-05-07T02:03:46Z,"broker's handling of fetchrequest becomes stateful after kip-227 added support for incremental fetch response. it means that the state in broker will be inconsistent with the state in client if we replace a non-empty fetchresponse with an empty response. more specifically, in `cachedpartitions.updateresponsedata()`, state (e.g. highwatermark) will be updated if a partition is assumed to be included in the fetchresponse. in order to solve this problem, we probably need to change the implementation related to kip-227. currently `cachedpartitions.updateresponsedata()` will 1) determine the partitions to be included and 2) update the state for those partitions that are included. we probably need to split this into two separate functions. the the state for those partitions should be updated only if the fetchresponse is not throttled. another problem is that `clientsensors.quotasensor.record` has already been called in `recordandgetthrottletimems()` at this point. it means that we have already assumed that the resource is used to send the fetchresponse at this point. it will cause under-utilization if we only sends an empty fetchresponse after updating the quotasensor. the main motivation of this kip is to address problem caused by producerequest. fetchrequest is small and probably not a concern. if we don't have a simpler way to handle the above two problems, i would recommend not to touch the handlefetchrequest() logic in this patch, i.e. broker still sends the non-empty fetchresponse after the throttle time has passed.",0,0.9865217804908752
187203528,4830,jonlee2,2018-05-09T23:23:32Z,"per discussion with , i reverted the changes i made to cluster action responses.",0,0.9820895195007324
187203579,4830,jonlee2,2018-05-09T23:23:56Z,done,0,0.8682363629341125
187203589,4830,jonlee2,2018-05-09T23:24:01Z,done,0,0.8682363629341125
187203602,4830,jonlee2,2018-05-09T23:24:09Z,done,0,0.8682363629341125
187203618,4830,jonlee2,2018-05-09T23:24:15Z,done,0,0.8682363629341125
187204068,4830,jonlee2,2018-05-09T23:27:20Z,"thanks for catching this. i made the following changes to address these points: 1. added getresponsesize() to fetchcontext to get the response size (for calculating throttle time) without updating the internal states 2. in case of fetch throttling, unrecord the recorded usage value by recording a negative value of the same quantity. i added comments stating more details about these changes.",1,0.965759813785553
187911027,4830,rajinisivaram,2018-05-14T10:59:10Z,"`atomicinteger` suggests that this field is updated from multiple threads. since we rely on this to be updated and accessed only from a single thread, it would be better to make it an `int` (like the other fields in this class). also, it is confusing to have a field `muted` and another `muterefcount` and separate methods to go with each. can we combine these two? possibly even just have `mute/unmute` methods in `kakachannel` and make the reference count internal rather than managed by `socketserver`?",0,0.8929578065872192
187913359,4830,rajinisivaram,2018-05-14T11:09:53Z,this response as well as others without a throttle time don't need version bump.,0,0.9885665774345398
187913661,4830,rajinisivaram,2018-05-14T11:11:03Z,i think it would be better to add a `throttletimems()` method to `abstractresponse` that returns throttle time for responses which contain the time and zero for others.,0,0.9857073426246643
187914030,4830,rajinisivaram,2018-05-14T11:12:40Z,should just return zero for this response as well as other responses which don't contain throttle time.,0,0.9706357717514038
187924822,4830,rajinisivaram,2018-05-14T11:54:47Z,we don't usually use `get` prefix for getters.,0,0.9864131212234497
187925371,4830,rajinisivaram,2018-05-14T11:56:57Z,hmm.. this is not ideal. metrics are externally visible entities that are used for monitoring. recording and unrecording can be confusing. but agree that it is hard to fix. we should at least record using the same time (will also avoid an extra `system.currenttimemillis()` per fetch request).,0,0.5395082235336304
187925735,4830,rajinisivaram,2018-05-14T11:58:28Z,"this is the request quota manager, so it is always request processing time.",0,0.9942392110824585
188146295,4830,jonlee2,2018-05-15T01:53:39Z,done,0,0.8682363629341125
188146303,4830,jonlee2,2018-05-15T01:53:44Z,done,0,0.8682363629341125
188146314,4830,jonlee2,2018-05-15T01:53:49Z,done,0,0.8682363629341125
188146336,4830,jonlee2,2018-05-15T01:53:56Z,done,0,0.8682363629341125
188146689,4830,jonlee2,2018-05-15T01:56:58Z,"i agree that it is not ideal, but the current implementation couples the reporting and quota checking a little too tightly. i used the same time for both record/unrecord as suggested.",0,0.6743841171264648
188149319,4830,jonlee2,2018-05-15T02:21:38Z,"i changed atomicinteger to int. as for your other comments, the ref count is used by socketserver and thus i think it should be updated by socketserver only. i am concerned that the ref count combined with the existing kafkachannel mute/unmute may cause some issues when misused by other kafkachannel users. for example, what if someone calls mute() twice? the second mute() is supposed to be a no-op, but if we decide to increase the ref count as part of mute(), it is not actually a no-op. also, socketserver still needs to call some method to increase the count when startthrottlingaction is received, so it won't be completely transparent. another point is that unmute() will be effectively tryunmute() because it only unmutes when the ref count is 0. with these reasons, i initially decided to separate the ref count from the existing mute/unmut logic. but i do agree that it is confusing to have both in kafkachannel. having said that, would it make more sense if i maintain the ref count in socketserver (by using a per-processor map from channel id to ref count) instead of kafkachannel? what do you think?",0,0.8688652515411377
188299694,4830,rajinisivaram,2018-05-15T14:04:47Z,"the problem with mute is that we already have too many different ways of controlling and tracking it, making the code really confusing. there is `kafkachannel.muted`, `kafkachannel.muterefcount`, `kafkachannel.isinmutablestate()`, `selector.explicitlymutedchannels` and the actual interest ops of the selection key in the transport layer. i don't think we want a per-processor map containing channel ids in `socketserver` since managing two lists of channels is just more work and could result in inconsistencies. the particular problem with `kafkachannel.muterefcount` is that if you are looking at `kafkachannel`, then that field and the methods that go with it make no sense since you can have `muted=true, refcount=0`. would it be possible to convert `kafkachannel.muted` to `kafkachannel.mutestate` with enum states like `not_muted`, `muted`, `response_pending`, `throttled`, `throttled_response_pending` or something along those lines with clear state transitions?",0,0.5814570188522339
188508062,4830,jonlee2,2018-05-16T05:42:19Z,thank you for the suggestion. makes a good sense. i replaced kafkachannel.muted with kafkachannel.mutestate and remove the ref count. transition of the mutestate of each channel will be controlled by mute-related events reported by socketserver (details mentioned in the comments).,1,0.9879868626594543
188706191,4830,tedyu,2018-05-16T17:21:10Z,what if mute state becomes channelmutestate.muted after the above call ? should unmute still be carried out ?,0,0.9919730424880981
188729990,4830,jonlee2,2018-05-16T18:35:52Z,"yes. this is a noop response case, so if the mute state transitions to muted after the above call (meaning that there's no throttling in progress), we should unmute the channel.",0,0.9887278079986572
189442592,4830,lindong28,2018-05-19T19:17:08Z,nits: return the number ...,0,0.9943708777427673
189442599,4830,lindong28,2018-05-19T19:17:19Z,nits: return the number ...,0,0.9943708777427673
189442674,4830,lindong28,2018-05-19T19:21:24Z,can you make it private?,0,0.9939182996749878
189442716,4830,lindong28,2018-05-19T19:23:11Z,nits: personally i feel the string can be in the same line.,0,0.9888063669204712
189448493,4830,lindong28,2018-05-20T01:10:34Z,"it seems that we will mute a channel after receiving request from client, and maybe unmute a channel after sending the response to client. so should the first two entries be renamed to `request_received` and `response_sent` (with updated docs) respectively?",0,0.9930400848388672
189448703,4830,lindong28,2018-05-20T01:27:00Z,is this change in the leaderandisrresponse needed?,0,0.9933282136917114
189448829,4830,lindong28,2018-05-20T01:36:54Z,is this change needed?,0,0.9939659237861633
189448832,4830,lindong28,2018-05-20T01:37:28Z,is this change needed?,0,0.9939659237861633
189448835,4830,lindong28,2018-05-20T01:37:43Z,is this change needed?,0,0.9939659237861633
189448844,4830,lindong28,2018-05-20T01:38:49Z,is this change needed?,0,0.9939659237861633
189448845,4830,lindong28,2018-05-20T01:39:00Z,is this change needed?,0,0.9939659237861633
189448878,4830,lindong28,2018-05-20T01:41:22Z,nits: it maybe slightly simpler to skip the `if ` statement,0,0.9863355159759521
189448885,4830,lindong28,2018-05-20T01:41:27Z,nits: it maybe slightly simpler to skip the `if ` statement,0,0.9863355159759521
189448890,4830,lindong28,2018-05-20T01:41:48Z,nits: it maybe slightly simpler to skip the `if ` statement,0,0.9863355159759521
189448893,4830,lindong28,2018-05-20T01:41:52Z,nits: it maybe slightly simpler to skip the `if ` statement,0,0.9863355159759521
189449055,4830,lindong28,2018-05-20T01:57:35Z,nits: `${quotatype}` can be replaced with `$quotatype`,0,0.9940696954727173
189449166,4830,lindong28,2018-05-20T02:09:07Z,"since we only unrecord quota sensor if the request is throttled, it may be better to skip checking `quotasenabled` (or throw exception if quotasenabled = false) and rename this method to `unrecordquotasensor`.",0,0.9926120638847351
189449289,4830,lindong28,2018-05-20T02:20:40Z,it could be `val`.,0,0.992551326751709
189449309,4830,lindong28,2018-05-20T02:22:42Z,nits: it seems that we typically put the the body of the if statement in a new line?,0,0.9917817711830139
189449419,4830,lindong28,2018-05-20T02:34:35Z,`shouldbeincludedinresponse ` name may be a bit confusing because it does not tell whether this method can change state or not. can we name it `maybeupdateresponsedata`?,0,0.9470522403717041
189449460,4830,lindong28,2018-05-20T02:39:48Z,"can we make this class private? and would it be better to add `type resp_map_iter = iterator[util.map.entry[topicpartition, fetchresponse.partitiondata]]` in fetchsession object, and replace the first parameter with `val iter: resp_map_iter`. this seems to be more consistent with the existing code patter and make it more obvious that the new class is a wrapper around the original iterator.",0,0.9933172464370728
189450020,4830,lindong28,2018-05-20T03:11:43Z,would it make the code a bit more readable by initializing unconvertedfetchresponse to an empty map here. by doing this we initialize unconvertedfetchresponse in roughly the same place and createresponse() does not need to do `if (throttletimems > 0)`.,0,0.9919547438621521
189450100,4830,lindong28,2018-05-20T03:18:04Z,nits: can we move `2.0-iv0` to be after `2.0`?,0,0.9927787184715271
189474811,4830,jonlee2,2018-05-20T23:55:52Z,done,0,0.8682363629341125
189474816,4830,jonlee2,2018-05-20T23:55:58Z,done,0,0.8682363629341125
189474821,4830,jonlee2,2018-05-20T23:56:02Z,done,0,0.8682363629341125
189474823,4830,jonlee2,2018-05-20T23:56:06Z,done,0,0.8682363629341125
189474841,4830,jonlee2,2018-05-20T23:56:53Z,"hmm.. i thought i already removed it here and other cluster action responses, but obviously not. done.",0,0.8837202787399292
189474845,4830,jonlee2,2018-05-20T23:56:59Z,done,0,0.8682363629341125
189474848,4830,jonlee2,2018-05-20T23:57:05Z,done,0,0.8682363629341125
189474850,4830,jonlee2,2018-05-20T23:57:11Z,done,0,0.8682363629341125
189474855,4830,jonlee2,2018-05-20T23:57:17Z,done,0,0.8682363629341125
189474857,4830,jonlee2,2018-05-20T23:57:22Z,done,0,0.8682363629341125
189474864,4830,jonlee2,2018-05-20T23:57:29Z,done,0,0.8682363629341125
189474865,4830,jonlee2,2018-05-20T23:57:35Z,done,0,0.8682363629341125
189474868,4830,jonlee2,2018-05-20T23:57:41Z,done,0,0.8682363629341125
189474869,4830,jonlee2,2018-05-20T23:57:48Z,done,0,0.8682363629341125
189474873,4830,jonlee2,2018-05-20T23:57:57Z,done,0,0.8682363629341125
189474877,4830,jonlee2,2018-05-20T23:58:03Z,done,0,0.8682363629341125
189474880,4830,jonlee2,2018-05-20T23:58:10Z,done,0,0.8682363629341125
189474885,4830,jonlee2,2018-05-20T23:58:15Z,done,0,0.8682363629341125
189474890,4830,jonlee2,2018-05-20T23:58:22Z,done,0,0.8682363629341125
189474891,4830,jonlee2,2018-05-20T23:58:27Z,done,0,0.8682363629341125
189475769,4830,jonlee2,2018-05-21T00:23:40Z,done,0,0.8682363629341125
189476185,4830,jonlee2,2018-05-21T00:34:28Z,"request/response in this enum and the previous one refer to request/response between socketserver and the api layer, not between the client and socketserver. one reason why i chose this way was because we don't send out a response to the client when acks = 0. but you are right that we try unmuting after sending out to the response to the client, so i updated as suggested. i still use response_sent for acks=0 case, but i think it should not be confusing (mentioned that in the comments).",0,0.9902661442756653
462738230,9103,abbccdda,2020-07-30T05:07:29Z,you commented on the previous pr about the style here. the reasoning is that this is a more common style than having period at the end in our codebase.,0,0.9941296577453613
463919020,9103,abbccdda,2020-08-01T04:11:47Z,moved to `alterconfigsutil`,0,0.9950971007347107
464029227,9103,abbccdda,2020-08-02T04:18:20Z,moved to `alterconfigsutil`,0,0.9950971007347107
464029411,9103,abbccdda,2020-08-02T04:21:07Z,"this is the new test, the rest of changes in this file are just side cleanups.",0,0.9933352470397949
464241946,9103,dajac,2020-08-03T07:34:55Z,could we use optional for these two as they are not always provided?,0,0.9920005798339844
464242434,9103,dajac,2020-08-03T07:36:02Z,nit: i would actually keep the callback as the last argument as it is a bit more natural to have the callback last.,0,0.9899077415466309
464244756,9103,dajac,2020-08-03T07:41:05Z,nit: empty line could be removed.,0,0.9938644766807556
464245796,9103,dajac,2020-08-03T07:43:25Z,"i personally prefer the previous indentation which is, i believe, more common in our code base. or do we plan to adopt a new formatting?",0,0.9798516631126404
464246880,9103,dajac,2020-08-03T07:45:52Z,nit: could we move it after `clientinformation` to keep the order inline with the order in the constructor?,0,0.9923896193504333
464247255,9103,dajac,2020-08-03T07:46:42Z,shall we use optional here as well?,0,0.994620680809021
464247740,9103,dajac,2020-08-03T07:47:47Z,"actually, we will also use it for quota. i think that we could say that both `initialprincipalname` and `initialclientid` will be used for logging and quota purposes.",0,0.9945117235183716
464248637,9103,dajac,2020-08-03T07:49:43Z,"as 2.7 has not be release yet, we don't need to introduce a new version. we can reuse `kafka_2_7_iv0`.",0,0.9882875084877014
464248862,9103,dajac,2020-08-03T07:50:12Z,shall we use option here?,0,0.995549201965332
464249275,9103,dajac,2020-08-03T07:51:05Z,nit: that was already present before your change but could we remove the extra space before the colon?,0,0.9933531284332275
464255551,9103,dajac,2020-08-03T08:04:21Z,the usage of the square brackets and the colon looks weird here. the audit log does not look like a sentence anymore. i wonder if we could go with something like this instead: `principal = a on behalf of principal = b is allowed...`. we could also put the initial principal name only if it is set.,-1,0.9758926033973694
464260158,9103,dajac,2020-08-03T08:14:21Z,nit: remove extra space before `authorizedresources`.,0,0.9947364926338196
464271174,9103,dajac,2020-08-03T08:36:17Z,* i presume that this does not work if we use the same listener for bother the control plane and the data plane. * i also wonder if it is a good thing to have this extension here as it applies to all the authorization in the api layer. i think that we should be cautious and only do this for forwarded requests.,0,0.9425928592681885
464271735,9103,dajac,2020-08-03T08:37:25Z,i presume that this does not work if the broker uses the same listener for the control plane and the data plane.,0,0.9853015542030334
464274377,9103,dajac,2020-08-03T08:42:43Z,"nit: `as admin client doesn't know how to find the controller` is not relevant anymore. what about the following: `when ibp is smaller than xyz, forwarding is not supported therefore requests are handled directly`?",0,0.9887346625328064
464276809,9103,dajac,2020-08-03T08:47:21Z,"it looks like that we will propagate the `not_controller` error back to the client. is it intentional? as clients don't send this request to the controller (and new ones won't get the controller id anymore), it sounds weird to return them this error. we could perhaps return another generic error.",-1,0.9632533192634583
464277479,9103,dajac,2020-08-03T08:48:34Z,have we considered using scala functions as callbacks? it would be more aligned with the other callbacks that we have in scala and also would avoid having to define classes for each handler that support forwarding. what do you think?,0,0.9801396131515503
464292019,9103,dajac,2020-08-03T09:15:10Z,"for my understanding, i suppose that we don't verify that redirection is enabled here to ensure that the controller can accept forwarded requests as soon as one broker in the cluster is configured with ibp 2.7. am i getting this right?",0,0.9909583330154419
464567004,9103,abbccdda,2020-08-03T17:44:56Z,it is not necessary as we don't check nulls for these fields.,0,0.9923607707023621
464569040,9103,abbccdda,2020-08-03T17:48:54Z,"not necessary, as explained.",0,0.9929700493812561
464570322,9103,abbccdda,2020-08-03T17:51:19Z,"i don't think we need initial client id for audit logging, is there some other logging you have in mind?",0,0.9909013509750366
464582897,9103,abbccdda,2020-08-03T18:16:19Z,will requests only flow to data plane if they use the same listener?,0,0.9921592473983765
464583310,9103,abbccdda,2020-08-03T18:17:08Z,not this is propagating to the sender broker.,0,0.9857410192489624
464584005,9103,abbccdda,2020-08-03T18:18:30Z,"yes, the purpose is to always handle a forwarding request even if ibp is not 2.7 yet. this is because some brokers may already upgrade their ibp and they start sending forwarding requests, which is totally legitimate.",0,0.9883743524551392
464585176,9103,abbccdda,2020-08-03T18:20:47Z,sg!,0,0.5324066877365112
465272340,9103,dajac,2020-08-04T19:16:28Z,"yeah, i was actually thinking about the request log. i thought that it may be useful to print them out there as well: [a link]",0,0.9865888953208923
465273597,9103,dajac,2020-08-04T19:18:54Z,"sorry, i was not clear. if the control plane listener is not configured, control requests will go to the data plane listener. based on your last commits, it seems that you have figured that out.",-1,0.9562458992004395
465273903,9103,dajac,2020-08-04T19:19:35Z,ack. i have missed the handling of `not_controller` in the `brokertocontrollerchannelmanager`.,0,0.9082484245300293
465274018,9103,dajac,2020-08-04T19:19:49Z,ack. this is what i thought.,-1,0.9528700709342957
465275440,9103,dajac,2020-08-04T19:22:33Z,"actually, we check nulls for these two in `isforwardingrequest` method. i don't feel strongly about this but i usually better to use optional when such values are not always present.",0,0.8281089663505554
465908873,9103,dajac,2020-08-05T18:05:16Z,"i wonder if this is correct. usually, we use `cluster_action` action with the `cluster` resource. for instance, this is how we authorize control requests: [code block] i thought that we would do the same in this case. don't we?",0,0.9611427783966064
466582281,9103,abbccdda,2020-08-06T17:45:49Z,"i'm not sure either, cc",0,0.7793686985969543
466714423,9103,abbccdda,2020-08-06T22:14:07Z,"actually i think you are right, will change here.",0,0.7403357625007629
467214507,9103,cmccabe,2020-08-07T18:54:46Z,"can we get rid of whitespace-only changes like this, or at least move them to another pr?",0,0.9908967614173889
467215647,9103,abbccdda,2020-08-07T18:56:53Z,let me check around.,0,0.9857863187789917
473158779,9103,abbccdda,2020-08-19T16:26:12Z,add equality check for the sake of easymock verification,0,0.9944775700569153
475710400,9103,cmccabe,2020-08-24T15:43:18Z,need to include: [code block],0,0.9952616691589355
475712573,9103,cmccabe,2020-08-24T15:46:38Z,"how about: ""a broker failed to authorize itself to another component of the system. this indicates an internal error on the broker cluster security setup"". this isn't specific to forwarding... there might be other reasons why a broker would need to authorize itself and fail",0,0.9884342551231384
475714230,9103,cmccabe,2020-08-24T15:49:13Z,in general we don't define equals or hashcode on these builders. why are we defining it here?,0,0.9907572865486145
475725389,9103,cmccabe,2020-08-24T16:06:10Z,just as a note the alter isr pr may also have an object like this. so maybe we want a name which is more specific to redirection.,0,0.9926169514656067
476860796,9103,abbccdda,2020-08-25T23:33:02Z,the purpose is for the mock tests to compare the expected builder in `kafkaapistest`,0,0.9949944019317627
476864248,9103,abbccdda,2020-08-25T23:36:10Z,"interesting, why does the `authorizationexception` have no `serialversionuid`? is it because we never use that error code explicitly?",0,0.9571157097816467
489875283,9103,abbccdda,2020-09-17T01:59:50Z,i'm still trying to decide how to make sure we could turn off the redirection in 2.7. having a separate ibp for 3.0 may not work.,0,0.9189494252204895
493160927,9103,hachikuji,2020-09-23T02:31:05Z,"nit: might be useful to document the expectation that `resources` is a subset of the key set of `configs`. the signature surprised me a little bit. as an aside, this kind of convenience conversion seems more appropriate for `incrementalalterconfigsrequest.builder` rather than a static class.",0,0.9556100964546204
493165520,9103,hachikuji,2020-09-23T02:48:53Z,typically responses are immutable after construction. it seems kind of a brittle pattern to rely on being able to mutate the response we receive from the other broker. for example we inherit the throttle time which is a bit weird. are we saving that much by not creating a new response?,-1,0.884780764579773
493168061,9103,hachikuji,2020-09-23T02:58:59Z,"in general, the forwarded request may have a different version than the client request. i'm wondering if we should keep the version the same in case there are semantic differences. as an example, a newer version of the api may introduce unexpected error codes. unless we have logic to convert those error codes, then we might break compatibility unexpectedly.",0,0.9561657905578613
493168697,9103,hachikuji,2020-09-23T03:01:28Z,get rid of this todo. we do not need to remove ibp internal versions.,0,0.9932118654251099
493169192,9103,hachikuji,2020-09-23T03:03:34Z,"nit: why don't we add a case class and make this optional. for example: [code block] in addition to reducing parameters, that makes the expectation that both are provided explicit.",0,0.9792460203170776
493169273,9103,hachikuji,2020-09-23T03:03:54Z,nit: space after `if`,0,0.9935740828514099
493169694,9103,hachikuji,2020-09-23T03:05:42Z,can you explain why this change is needed?,0,0.9926602840423584
493170132,9103,hachikuji,2020-09-23T03:07:28Z,the comment doesn't seem to make sense here. seems like the logic doesn't have anything to do with the controller?,0,0.9379429221153259
493170494,9103,hachikuji,2020-09-23T03:09:02Z,this function has 3 callbacks... it would be nice if we could figure out how to pass through the `forwardrequesthandler` directly.,0,0.9889014959335327
493170831,9103,hachikuji,2020-09-23T03:10:24Z,nit: this is misaligned,0,0.6613627672195435
493171357,9103,hachikuji,2020-09-23T03:12:42Z,"we can't guarantee that this broker will still be the controller when we call `process` or that the broker we're forwarding to will still be the controller when it receives the request. in these cases, we need to return some retriable error to the client. can you help me understand how this is implemented?",0,0.9920157194137573
493171799,9103,hachikuji,2020-09-23T03:14:28Z,"nit: this is subjective, but this style is a bit ugly. i would prefer the following: [code block] that makes it easier visually to separate the return type and the function logic (again, in my opinion).",-1,0.9839878678321838
493172457,9103,hachikuji,2020-09-23T03:17:08Z,nit: seems `handle` doesn't really need to be part of `forwardrequesthandler`. instead we could pull it out: [code block] the advantage of this is that it allows us to pull the type out of `kafkaapis` without inheriting all of the dependencies that are needed by `handle`.,0,0.9873999357223511
493173723,9103,hachikuji,2020-09-23T03:22:14Z,it would be helpful to have a comment explaining this. it does not seem obvious.,0,0.9856022000312805
493174084,9103,hachikuji,2020-09-23T03:23:45Z,"good to see the unit tests in here. i think we also need at least a couple integration tests. for example, could we add something to `createtopicsrequesttest` to ensure that forwarding works as expected?",1,0.946990430355072
493206068,9103,abbccdda,2020-09-23T05:28:51Z,the primary reason is that we would trigger the disallowed import if we do it in the request builder: [code block] let me check if we could make exceptions here,0,0.9940462112426758
493209974,9103,abbccdda,2020-09-23T05:41:23Z,"but in case we release ak 2.7, wouldn't this flag give user the confidence to upgrade to, which we don't want to happen?",0,0.9696403741836548
493518004,9103,rajinisivaram,2020-09-23T12:15:37Z,nit: `ssl` => `ssl`,0,0.9939687252044678
493518728,9103,rajinisivaram,2020-09-23T12:16:25Z,does this get reset somewhere or will we keep adding `/`?,0,0.994371235370636
493519587,9103,rajinisivaram,2020-09-23T12:17:26Z,`ssl` => `ssl`,0,0.9935675263404846
493520160,9103,rajinisivaram,2020-09-23T12:18:05Z,"this means update was requested, but not necessarily that file has changed?",0,0.9922025203704834
493520165,9103,rajinisivaram,2020-09-23T12:18:05Z,"this means update was requested, but not necessarily that file has changed?",0,0.9922025203704834
493522186,9103,rajinisivaram,2020-09-23T12:20:21Z,can't we put this logic in `dynamicbrokerconfig`?,0,0.9953435063362122
493742677,9103,hachikuji,2020-09-23T16:50:32Z,i'm not sure i follow. do you not want redirection to be part of 2.7?,0,0.701626718044281
493751026,9103,abbccdda,2020-09-23T17:03:58Z,"the rational is to trigger a reload of ssl store file by the zk notification. came out this idea to augment the path to [code block] when a reload is requested on the receiver broker, and by propagating such a path other brokers would see a difference and thus reload their corresponding store files as well. in the meantime, we need to trim the path back to single slash after handling the notification: [code block]",0,0.9920377731323242
493752855,9103,abbccdda,2020-09-23T17:07:06Z,"the logic is needed when there is an alterconfigrequest targeting at a specific broker. since the non-controller node will no longer handle alterconfigs, it is possible to see a redirected changing request with a broker.id different than the controller broker.id.",0,0.9948371648788452
493771144,9103,abbccdda,2020-09-23T17:37:09Z,"yes, we would trim it in `trimsslstorepaths`",0,0.9953984618186951
493771267,9103,abbccdda,2020-09-23T17:37:24Z,yea,0,0.9237021803855896
493773324,9103,abbccdda,2020-09-23T17:41:05Z,"i feel it's more explicit to do it in here, as zk notification is the only target case.",0,0.9732987880706787
493782410,9103,abbccdda,2020-09-23T17:56:03Z,i guess we could get rid of it and do the merge in caller level.,0,0.9805660247802734
493795436,9103,abbccdda,2020-09-23T18:17:46Z,"it's a bit hard since we are passing requestbuilder all the way to networkclient, so if we want a designated version to build the request, that may involve some non-trivial changes.",0,0.8777413964271545
493823776,9103,hachikuji,2020-09-23T18:56:42Z,"as discussed offline, we can pass the expected version down to the builder. the abstract builder already supports an explicit range of versions. in any case, it doesn't seem like we have a choice. by the way, one potential edge case here is that the broker receiving the request has upgraded to a later version than the controller. this would be possible in the middle of a rolling upgrade. i don't think there's an easy way to handle this. we could return unsupported_version to the client, but that would be surprising since the client chose a supported api based on apiversions and is not aware of the controller redirection. one idea to address this problem is to gate version upgrades to redirectable apis by the ibp. basically all of these apis have become inter-broker apis through redirection so they need the safeguard of the ibp. feels like we might have to do this.",0,0.9557312726974487
504286524,9103,hachikuji,2020-10-13T22:08:10Z,nit: why don't we call it `requestdata` to be consistent with the name used in the api spec?,0,0.9888529777526855
504287723,9103,hachikuji,2020-10-13T22:10:46Z,nit: i think it might be better to pull this out of the request class. the direction we're moving is toward dumber request/response classes. eventually `enveloperequest` will go away and we'll just use `enveloperequestdata`.,0,0.9565625786781311
504288659,9103,hachikuji,2020-10-13T22:12:59Z,not sure why we need this change. i think the convention is to include `none` in error counts.,0,0.8798315525054932
504293144,9103,hachikuji,2020-10-13T22:24:33Z,i'm wondering if we really need the ibp to leak into the common library. it should really only be a broker concern. seems like the only point is so that we can continue to use the factory methods defined below from the broker code. is that right? could we instead move the factories to the broker?,0,0.9347952604293823
504295024,9103,hachikuji,2020-10-13T22:29:23Z,"in a similar vein, i think it's better to not include serialization logic in the response object. it tends to hide some of the details like byte buffer allocation that we might want to control at another level.",0,0.9821786284446716
504295874,9103,hachikuji,2020-10-13T22:31:40Z,same here. we can return `bytebuffer` and leave parsing to higher layers.,0,0.9936095476150513
504298663,9103,hachikuji,2020-10-13T22:39:21Z,"it is strange to couple the serialization of the principal with the version of the envelope request. this might help us in the case of default principal builder, but users with their own custom builder are on their own, right? i think it is better to be consistent and always leave versioning to the principal builder.",-1,0.5662975907325745
504298879,9103,hachikuji,2020-10-13T22:39:55Z,nit: maybe print `forwardingprincipal` only if it is defined,0,0.9921194314956665
504300234,9103,hachikuji,2020-10-13T22:43:56Z,do we have a use case for this yet? i don't see that it gets used anywhere.,0,0.9821924567222595
504327985,9103,abbccdda,2020-10-14T00:12:51Z,i guess there are some inconsistency between different rpcs as i spotted cases excluding none. i would initiate a separate jira for the cleaning and revert the change here.,0,0.987355649471283
504345664,9103,abbccdda,2020-10-14T01:19:44Z,"not yet, could be removed.",0,0.9875055551528931
504408633,9103,abbccdda,2020-10-14T05:23:43Z,"the tricky thing here is that if we handle the api version constraints on the broker side, it means we need to either make changes directly to the returned apiversionsresponse or spawn a new instance with applied constraints. that means leaking of the internal architecture of apiversionsresponse to the broker level and redundant conversions imho. the current approach makes sure the broker level logic is clean with only the necessity of passing the ibp number.",0,0.7155022025108337
505765664,9103,hachikuji,2020-10-15T18:47:39Z,what is the benefit of using a different error code instead of `cluster_authorization_failure`?,0,0.9895735383033752
505768901,9103,hachikuji,2020-10-15T18:53:21Z,"i believe we need to set `requiresdelayedallocation` for this api. typically we will release the underlying buffer allocated for a request when `requestchannel.request` is constructed. however, since we are using ""zerocopy,"" we need to hold onto the `bytebuffer` reference until the api has been handled.",0,0.9918779134750366
505798234,9103,hachikuji,2020-10-15T19:47:58Z,"it seems like we're trying to reuse this handler from the previous patch, but i'm not sure it still makes as much sense. a simpler structure might be something like the following: [code block]",0,0.9705232381820679
505842904,9103,abbccdda,2020-10-15T20:56:55Z,"`cluster_authorization_failure` normally indicates a client side security configuration error. we intentionally define a separate error code to let admin know that there is some security config trouble with the brokers, not the clients.",0,0.9896119236946106
505852939,9103,abbccdda,2020-10-15T21:08:41Z,i think we do have that logic enforced by setting `zerocopy` to true for request data field in the rpc json.,0,0.9885151982307434
509528009,9103,hachikuji,2020-10-21T18:01:43Z,not sure i follow. all current inter-broker apis are gated by `clusteraction` and will return `cluster_authorization_failure` if the principal does not have access. there is no distinction between clients and brokers. it's not clear to me why we need something different here.,0,0.7968112230300903
509533968,9103,hachikuji,2020-10-21T18:06:33Z,"rather than assuming highest supported version, we should include the version in the serialized data. the simple thing would be to write the version first, then write the payload.",0,0.9937618374824524
509537587,9103,hachikuji,2020-10-21T18:09:44Z,nit: can we move this back to where the request parsing logic is. otherwise it becomes a bit hidden.,0,0.9679994583129883
509538545,9103,hachikuji,2020-10-21T18:10:43Z,"nit: add braces to all of these methods. even though they are not required, braces make it easier to see the scope",0,0.9920037388801575
509540617,9103,hachikuji,2020-10-21T18:12:56Z,nit: use `match`,0,0.994807779788971
509541377,9103,hachikuji,2020-10-21T18:13:43Z,nit: use `match`,0,0.994807779788971
509545893,9103,hachikuji,2020-10-21T18:19:31Z,nit: this is misaligned. it might be better to pull the body here into a separate method (e.g. `parseenveloperequest`),0,0.7746069431304932
509550124,9103,hachikuji,2020-10-21T18:24:02Z,"we should have a check at the beginning of `handle` to restrict the ""forwardable"" apis.",0,0.9945470094680786
509550802,9103,hachikuji,2020-10-21T18:24:48Z,"we use 'forward' and 'redirect' interchangeably throughout the pr, but the names do suggest different behavior. in my mind 'redirection' suggests that we are telling the client to go somewhere else, while 'forward' suggests that the broker is passing the request through to its destination. so maybe we can stick with 'forward' consistently (e.g. `isforwardingenabled`)?",0,0.9896105527877808
509553533,9103,hachikuji,2020-10-21T18:28:14Z,"as mentioned above, you can see the rest of the cases in this class where we check cluster_action and they all return `cluster_authorization_failure`.",0,0.9938866496086121
509555177,9103,hachikuji,2020-10-21T18:29:41Z,nit: you can just use `channel.principalserde.asscala`,0,0.99354088306427
509562013,9103,hachikuji,2020-10-21T18:35:40Z,"we want to avoid this serialization since it introduces the possibility for the request to be altered by the forwarding broker. the `requestchannel.request` object retains the reference to the original buffer, which we can use here, but we need to tell the channel to delay releasing the buffer using `apikeys.requiresdelayedallocation` for all of the ""forwardable"" apis.",0,0.993083119392395
509565018,9103,hachikuji,2020-10-21T18:38:58Z,use `defineinternal`,0,0.9956556558609009
509565555,9103,hachikuji,2020-10-21T18:39:36Z,how about `enable.metadata.quorum`?,0,0.9943681359291077
509645115,9103,abbccdda,2020-10-21T20:09:07Z,had a try but it seems java optional doesn't have an `asscala` option,0,0.9864670634269714
509670268,9103,abbccdda,2020-10-21T20:31:29Z,sounds good.,1,0.857205867767334
510533897,9103,hachikuji,2020-10-23T00:37:04Z,you probably need the following: [code block],0,0.994407057762146
510536894,9103,hachikuji,2020-10-23T00:49:41Z,"i was thinking a little bit about this and trying to decide if the envelope request should have a more literal representation of the client ip address. the way it is working right now, it looks like the following: 1) use `socket.getinetaddress` to populate `requestcontext.clientaddress`. 2) use `inetaddress.gethostname` to populate the `clienthostname` field in the envelope request. this will do a reverse dns lookup based on the ip address from 1). 3) now we send `clienthostname` over the wire. it gets unpacked here by doing a dns lookup to get to the `inetaddress` object. so it seems we should be skipping the dns translation and just using the ip address from 1). the `inetaddress` class gives us `getaddress` and `gethostaddress`. the first provides the raw byte representation of the ip address, while the latter provides a textual representation. i am thinking we should use `getaddress` and let this field be represented as bytes. what do you think?",0,0.9468222856521606
510540720,9103,hachikuji,2020-10-23T01:06:42Z,"can we move some of the checks from `maybeforward` here? this is the flow i'm thinking about: 1. first check authorization => cluster_authorization_failure 2. verify forwarding is enabled => invalid_request 3. verify the api is forwardable => invalid_request if all of these pass, then the request continues down the normal handling path.",0,0.9944480657577515
510552124,9103,hachikuji,2020-10-23T01:56:06Z,"quotas are one aspect of this work that need more consideration. what we don't want is for the inter-broker channel to get affected by the individual client throttle, which is what will happen with the current patch. what i'd suggest for now is that we allow the broker to track client quotas and pass back the throttle value in the underlying response, but we set the envelope throttle time to 0 and ensure that the inter-broker channel does not get throttled. for this, i think we we will need to change the logic in `kafkaapis.sendresponsemaybethrottle`. if it is a forwarded request, we still need to check `mayberecordandgetthrottletimems`, but we can skip the call to `clientquotamanager.throttle`. when the response is received on the forwarding broker, we will need to apply the throttle, which i think the patch already handles. one challenging aspect is how this will affect quota metrics. currently quota/throttling metrics are relatively simple because they are recorded separately by each broker. however, here the controller is the one that is tracking the throttling for the client across multiple inbound connections from multiple brokers. this means that the broker that is applying a throttle for a forwarded request may not have actually observed a quota violation. other than causing some reporting confusion, i am not sure whether there are any other consequences to this. cc",0,0.9367475509643555
510554587,9103,hachikuji,2020-10-23T02:06:38Z,"one challenge we have here is that there are two levels of errors. the current patch seems to conflate the two, which makes it confusing. i think we need a structure which allows us to separate the errors possible at the envelope level and those possible at the request level. what i'm thinking is this: 1. for cluster auth and principal serde errors, we should return the envelope error and null response body. 2. for everything else, we return envelope error none and just pass through whatever error is in the response. does that make sense?",0,0.8623319268226624
510568706,9103,abbccdda,2020-10-23T03:06:57Z,"the question would be how the forwarding broker should do the error handling for auth & principal serde exceptions. to me we should get a vanilla error response with `unknown_server_error` and get back to the original client? besides that, i think we could add a differentiation here to avoid passing the serde-type errors to the client.",0,0.9904228448867798
511007228,9103,abbccdda,2020-10-23T16:39:28Z,"for pt2, if the forwarding is not enabled on the active controller, but it has the capability, should we just serve the request?",0,0.9914559721946716
511012913,9103,abbccdda,2020-10-23T16:49:50Z,so the proposal is simply for saving the unnecessary dns translation? not sure if representing as bytes would also serve the security purpose as well.,0,0.9636134505271912
511872018,9103,rajinisivaram,2020-10-26T10:52:19Z,"i guess the only quota that is affected for the rpcs we currently forward is request quotas. totally agree that we shouldn't throttle inter-broker connections. there are a few other things to consider here: 1) every forwarded request uses network thread and request handler time on two brokers. are we saying that we can ignore the time spent on the forwarding broker because that is negligible? in a deployment with ssl on the external listener and plaintext on the inter-broker listener, there may be more network thread time used on the forwarding broker rather than the controller. do we record these, but use the controller throttle time for throttling? 2) are we changing the semantics of quotas? for example, if a client sends a request1 to leastloadednode a which mutes the connection and then sends request2 to leastloadednode b that happens to be the controller, we would mute that connection too. another client with the same principal would get muted on b, but not a because a's quota hasn't been violated. i think this should be ok, though a bit confusing. 3) are these measures good enough to protect the controller? this is the one that needs some more thought. request quotas are configured to allocate a percentage of thread usage to each principal. our quotas aren't very good at protecting against dos attacks, but they help to limit usage for normal clients using the apis. so if we can make sure the implementation for forwarded requests can handle this case, it would be good enough. in the old world, a client doing a lot of config updates would have just distributed the load across brokers as each node was throttled. now, we distribute the iniital request across brokers as controller decides to throttle. total rate for these requests across the cluster is dramatically reduced because all load is now on the controller. but from the controller broker's point of view, we are now allowing more requests through for the same quota from every client because a client can forward through `n` brokers. may have more context on whether these request types actually hit request quotas in real deployments.",0,0.9748165011405945
513608319,9103,hachikuji,2020-10-28T16:56:18Z,"hmm.. it looks like we do not serialize the response header, but i think we probably should. today it only includes the correlationid, but who knows how it will evolve in the future? since we do serialize the request header, it seems better to be consistent.",0,0.9198299050331116
513612935,9103,hachikuji,2020-10-28T17:02:38Z,"since this is a public api, it's worth documenting that these apis should raise a consistent error, such as `serializationexception`, in case of an error.",0,0.9929053783416748
513613435,9103,hachikuji,2020-10-28T17:03:23Z,nit: for the the purpose of inter-broker forwarding,0,0.9947553873062134
513614262,9103,hachikuji,2020-10-28T17:04:30Z,we may as well add a check here for the version so that we get a useful error in case we receive a version that we do not support.,0,0.9927873015403748
513615916,9103,hachikuji,2020-10-28T17:06:37Z,nit: use upper-case `tokenauthenticated` for consistency with other fields,0,0.9949656128883362
513616503,9103,hachikuji,2020-10-28T17:07:26Z,might be worth mentioning `org.apache.kafka.common.security.authenticator.defaultkafkaprincipalbuilder` explicitly.,0,0.9904693961143494
513617300,9103,hachikuji,2020-10-28T17:08:33Z,perhaps add a little more detail?,0,0.9895002245903015
513619656,9103,hachikuji,2020-10-28T17:11:52Z,"since principals should be small, it is tempting to just use simple byte arrays for this interface. this is typically simpler for users and gives us a stronger boundary between plugin and broker code.",0,0.9876347184181213
513635843,9103,hachikuji,2020-10-28T17:34:28Z,"it looks like these changes made it to 2.7. we need to revert them before the release or it will not be safe to remove them. the danger is that we might use these tag ids for another purpose in the future, which will break the request parsing.",0,0.9759353995323181
513645474,9103,hachikuji,2020-10-28T17:48:22Z,i guess this shows an inconsistency between the envelope and the other inter-broker apis. the throttle time field is only useful if we actually expect the forwarding broker to respect it and backoff. i wonder if we should just be consistent for now and leave this out.,0,0.9638236165046692
513646769,9103,hachikuji,2020-10-28T17:50:11Z,"would it make sense to add a default rule? if the api is forwardable, then we can assert it requires delayed deallocation.",0,0.9913852214813232
513647237,9103,hachikuji,2020-10-28T17:50:49Z,"in fact, the schema doc says that the response header should be included.",0,0.9945764541625977
513648122,9103,hachikuji,2020-10-28T17:52:10Z,it's not clear to me why we need to do this now since we are not enabling forwarding yet.,0,0.8110338449478149
513659883,9103,hachikuji,2020-10-28T18:09:37Z,"hmm.. the request logging will not be too useful if we cannot see what is in the embedded request and response. i think we should print the envelope structures separately. longer term, we should figure out how to incorporate the envelope into [a link]",0,0.9720621705055237
513662914,9103,hachikuji,2020-10-28T18:14:32Z,not sure why this was resolved. i don't see the check. basically the first thing we should do in `handle` is check whether we have an envelope request and if it is authorized.,0,0.9139164686203003
513667101,9103,hachikuji,2020-10-28T18:21:14Z,"unless the internal config is present, i think we should treat the envelope as non-existing. once we are ready to enable it in the ibp, then we will accept the envelope request even if the local ibp is not high enough.",0,0.991928219795227
513743473,9103,abbccdda,2020-10-28T20:35:38Z,i think it's ok to remove this flag for now.,0,0.9698876738548279
513750141,9103,abbccdda,2020-10-28T20:48:19Z,"i was under the impression that byte buffer provides more information such as a read position and capacity/limits, which makes the deserialization easier. if given a byte[], i'm afraid they need to convert to byte buffer internally eventually.",0,0.5543839335441589
513757978,9103,abbccdda,2020-10-28T21:02:19Z,"sounds good, will remove the throttle time field from the envelope",1,0.7904969453811646
513759802,9103,abbccdda,2020-10-28T21:05:21Z,"sg, but i guess we need to keep it as is for now to try using the correct api version.",0,0.9868972897529602
513826471,9103,abbccdda,2020-10-28T23:44:21Z,"sg, will initiate a pr for that.",0,0.9930654764175415
515212449,9103,hachikuji,2020-10-30T16:11:00Z,"probably the first thing we should check is `isforwardingenabled`. if it is not, i suggest we close the connection, which is basically the broker's way of saying ""i don't know how to handle this.""",0,0.9827658534049988
515215364,9103,hachikuji,2020-10-30T16:16:02Z,can we add a description explaining what this is for?,0,0.9953241944313049
515219198,9103,hachikuji,2020-10-30T16:22:25Z,we should duplicate the buffer instead of modifying it directly.,0,0.9920090436935425
515219726,9103,hachikuji,2020-10-30T16:23:22Z,"we can leave this for a follow-up, but it would be nice if we could avoid this deserialization (and the subsequent re-serialization).",0,0.9872322082519531
515220480,9103,hachikuji,2020-10-30T16:24:37Z,probably useful to explain why we do this. a debug log message with the original error would be helpful as well.,0,0.9827356338500977
515229180,9103,hachikuji,2020-10-30T16:39:03Z,"i think this was one of my initial questions, but do we have a timeout for the request? looking at the current logic in `handleresponse`, it seems like we will just retry indefinitely. that is probably what we want for requests generated by the broker (e.g. `alterisr`), but it is not so useful for client requests since the client itself will eventually give up and send a new request.",0,0.9822580218315125
515230020,9103,hachikuji,2020-10-30T16:40:21Z,nit: can we create a helper for `request.envelopecontext.isempty`? perhaps we can write this as `!request.isforwarded`?,0,0.9899625182151794
515231023,9103,hachikuji,2020-10-30T16:42:03Z,"hmm.. i had assumed we would be using the same channel manager. can you explain why we need two? in the end, i think all of the requests get serialized on the controller, so i'm not sure we're buying much.",0,0.9264272451400757
515245665,9103,hachikuji,2020-10-30T17:04:46Z,"as far as i can tell, the `callback` here is unused. tracing this back to `kafkaapis`, the callback passed to `sendresponsemaybethrottle` also appears to be unused. i think we can remove it from both apis and simplify this a bit.",0,0.9897996187210083
515276738,9103,abbccdda,2020-10-30T17:48:18Z,"i agree we don't have a prioritization system on the controller yet, but in long term having two separate managers mean we don't block alterisr unnecessarily, which seems to be definitely a higher priority message. cc",0,0.9691755771636963
515377453,9103,abbccdda,2020-10-30T20:51:51Z,sg,0,0.7695395946502686
515388258,9103,abbccdda,2020-10-30T21:20:47Z,"yea, i think this could be done as a follow-up. filed: [a link]",0,0.9900819659233093
515389068,9103,abbccdda,2020-10-30T21:23:12Z,filed: [a link],0,0.9947322607040405
515395403,9103,abbccdda,2020-10-30T21:41:50Z,got a follow-up ticket as well: [a link],0,0.9898747205734253
515413173,9103,hachikuji,2020-10-30T22:44:52Z,can we use `closeconnection`. we do not want to even acknowledge that the api exists unless forwarding is enabled.,0,0.9864507913589478
515414500,9103,hachikuji,2020-10-30T22:50:24Z,nit: drop parenthesis for simple getter,0,0.9948378205299377
515417787,9103,hachikuji,2020-10-30T23:05:00Z,"this begs the question whether the api should even be advertised from non-privileged listeners if users cannot access it. i am thinking we can make this case similar to the behavior if forwarding is not enabled. here we can use this logic: [code block] similarly, we can change the check in `apiversion.apiversionsresponse` so that it skips the envelope api if the request is not from a privileged listener.",0,0.9894990921020508
515418503,9103,hachikuji,2020-10-30T23:08:15Z,not sure i follow the point about the correct api version.,0,0.7357689738273621
515421189,9103,hachikuji,2020-10-30T23:21:24Z,"i think this logic still conflates the envelope error and the inner response error. we might catch an exception raised from `validateforwardrequest` or from the request handler in `kafkaapis.handle`. both paths flow through `kafkaapis.handleerror`, so we do not have a way to distinguish the two cases. this means that an uncaught error from the underlying request will get sent back to the forwarded broker as an error in the envelope, which will cause us to translate it to unknown_server_error. i think we should handle envelope errors explicitly through a separate method. we can define a method here such as `buildfailedenvelope` which can be used inside `validateforwardrequest`. then inside `buildresponse` here, we can always return `errors.none` as the envelope error.",0,0.9738636016845703
515421553,9103,abbccdda,2020-10-30T23:23:16Z,"it's a bit tricky to do it here since we rely on exception catching to skip all the rest of handling logic, not sure it is worth to add this special case and do `if-else` to incur a large code change.",0,0.5026170015335083
515427912,9103,hachikuji,2020-10-30T23:57:37Z,"perhaps it is obvious, but this logic does not give us any tight guarantees that the request will actually be handled by the broker that is currently the controller. for example, a new controller might get elected between the check in `validateforwardrequest` and the handler here. that is probably fine at the moment, because the zk logic in `adminmanager` can execute on any broker. if we imagine instead how this will work with the kip-500 controller, i think the incoming request will get put on the controller's queue. by the time the request gets dequeued, we will be able to know for sure whether this node is the controller or not, so we will be able to have a much better guarantee. the only reason i bring this up is that we are currently assuming that the not_controller gets propagated in the envelope error field. we'll have to keep this in mind when we adapt this logic for the new controller.",0,0.9573374390602112
515428385,9103,hachikuji,2020-10-31T00:00:26Z,perhaps we could return a boolean to indicate whether the handling logic should execute. i think it is important to avoid exposing this api until we're ready for it.,0,0.9878978133201599
516344965,9103,hachikuji,2020-11-02T23:57:03Z,nit: seems this change was not needed,0,0.9235634803771973
516349664,9103,hachikuji,2020-11-03T00:06:25Z,"nit: i feel `failureexception` is redundant. can we just call it `principaldeserializationexception`? also, i am not sure about this extending `authorizationexception`. i would consider it more of an invalid request than an authorization failure, though the effect is the same. i think it's probably better to avoid categorizing it and just let it extend `apiexception`.",0,0.9675464034080505
516356565,9103,hachikuji,2020-11-03T00:21:28Z,nit: every other property name uses a capital first letter,0,0.9740141034126282
516363883,9103,hachikuji,2020-11-03T00:37:20Z,"it is quite expensive to parameterize these test cases. i am not sure it is worthwhile. if forwarding works for one of these cases, why would the others be different? since we are not planning to enable this feature yet, i think unit tests in `kafkaapistest` and maybe one integration test are good enough.",-1,0.8365634083747864
516364497,9103,hachikuji,2020-11-03T00:38:40Z,i think it would be simpler to short-cut return. [code block],0,0.9850844740867615
516365803,9103,hachikuji,2020-11-03T00:41:17Z,nit: `validatedforwardedrequest`,0,0.9940915703773499
516366191,9103,hachikuji,2020-11-03T00:42:10Z,"nit: we are doing more than building the response here, we are sending it. how about `sendfailedenveloperesponse`?",0,0.9901824593544006
516372020,9103,hachikuji,2020-11-03T00:54:27Z,"nit: instead of `original`, could we use `forwarded` in these names?",0,0.9901093244552612
516373262,9103,hachikuji,2020-11-03T00:56:55Z,nit: define return type,0,0.9949872493743896
516375303,9103,hachikuji,2020-11-03T01:00:58Z,can you add a javadoc for these methods and mention ` serializationexception`?,0,0.9956337809562683
516378459,9103,hachikuji,2020-11-03T01:09:12Z,"hmm, not sure i get your point. nothing is simpler than a byte array. the main question is whether we want to expose the actual request buffer to the plugin, especially since we still plan on using it afterwards. the plugin is treated as a trusted component in any case, so it might not make a big difference. probably we should optimize here for simplicity. that may or may not be true. if it is, users can just use `bytebuffer.wrap`.",0,0.826781690120697
516381090,9103,hachikuji,2020-11-03T01:19:18Z,nit: `network` prefix is not needed since we are already in this package,0,0.995324969291687
516933194,9103,hachikuji,2020-11-03T20:20:55Z,"this inherits all tests from `dynamicbrokerreconfigurationtest`, which doesn't look to be intended. can we just remove it? we can add it back once we get to testing the ssl path changes. for now i think the simple integration test for createtopics is good enough. (by the way, it's curious that `testtruststorealter` still passes even after we have removed the path update logic.)",0,0.8810206055641174
516933962,9103,hachikuji,2020-11-03T20:22:34Z,do we need this change anymore?,0,0.9860129952430725
516934696,9103,hachikuji,2020-11-03T20:24:08Z,i don't think we want to make this the default until we are ready to enable it. i would suggest we create a new `forwardrequesttest` which extends `baserequesttest`. then we can move the test case from `createtopicsrequesttest`.,0,0.9866966605186462
516938814,9103,hachikuji,2020-11-03T20:32:19Z,nit: is this change needed?,0,0.9890590310096741
516942223,9103,hachikuji,2020-11-03T20:39:33Z,is this change needed? i am not sure i follow the comment about the privileged listener. that shouldn't affect acls i think.,0,0.9355772137641907
516950684,9103,abbccdda,2020-11-03T20:56:53Z,seems ok to remove,0,0.9897923469543457
516951766,9103,abbccdda,2020-11-03T20:59:06Z,"yea, that's weird, let's move to the next pr for a discussion.",-1,0.9901599287986755
37318079,132,hachikuji,2015-08-18T16:09:35Z,"4,2,0?",0,0.9865412712097168
37320190,132,hachikuji,2015-08-18T16:28:11Z,it might make this code a little easier to follow if you split the rack-aware and default assignments into separate functions. what do you think?,0,0.9745258092880249
37323035,132,hachikuji,2015-08-18T16:52:26Z,maybe getinversemap instead?,0,0.9908344745635986
37441970,132,allenxwang,2015-08-19T17:24:41Z,"it will be difficult to separate them out as they actually share quite a lot of common logic, specifically around choosing the leader of the partition. the code change may seem a lot but actually very little for the default assignment algorithm other than changing the name of `brokerlist` to `arrangedbrokerlist`. i can try separate out the logic of choosing followers into different functions for default vs. rack aware assignment and see how it looks like.",0,0.9674836993217468
37442156,132,allenxwang,2015-08-19T17:26:15Z,that's correct. will fix.,0,0.9708687663078308
37442594,132,allenxwang,2015-08-19T17:30:10Z,sure.,0,0.9824982285499573
37448769,132,hachikuji,2015-08-19T18:19:45Z,"yep, there would probably be some redundancy, but at least the default path would be uncluttered with all the rack-aware logic. i don't think it's too bad as it is, but clearer separation would be nice if possible.",0,0.7976279258728027
49287039,132,joestein,2016-01-11T02:48:05Z,"can you add some negative testing please, folks do weird and odd things in their properties by accident and we want to guard against that too, etc",-1,0.863787829875946
49287098,132,joestein,2016-01-11T02:50:07Z,"something about the scala of this makes me want to say it should be an implicit, that is a much bigger topic and change so i would say maybe not introduce that now but here is one of a lot of places we could without losing readability or performance reduce code. maybe even try it with this change as your converting type only in raclocator",0,0.9799787998199463
49287153,132,joestein,2016-01-11T02:52:34Z,rack-locator might be a bit confusing to the user when just coming and looking at the new command / api changes in a release. why not rack-aware or rack-placement-class (keep the simplaracklocator class as is) and then rack-placement-properties? or something of the sort?,0,0.9825572371482849
49287181,132,joestein,2016-01-11T02:53:34Z,what/why are we ignoring here? not looking at entire class just seeing the diff hard to say if this makes sense or not to ignore,0,0.8566709160804749
54477992,132,hachikuji,2016-02-29T21:08:46Z,nitpick: maybe should be rack_key_name for consistency?,0,0.9915703535079956
54478309,132,hachikuji,2016-02-29T21:10:57Z,"also, the comment doesn't add much. maybe you can just relocate under ""endpoint key name""?",0,0.9890551567077637
54489948,132,allenxwang,2016-02-29T22:26:45Z,"i don't think rack belongs to endpoint. it is the same level as ""endpoint"" as indicated in the json format of broker in zookeeper and updatemetadatarequest protocol. a broker can have multiple endpoints but only one rack.",0,0.9881964325904846
54490437,132,hachikuji,2016-02-29T22:30:12Z,"yep, you are right. guess it would make sense for it to go under broker key names then?",0,0.9879077076911926
54498311,132,allenxwang,2016-02-29T23:28:28Z,sounds good.,1,0.857205867767334
54592298,132,granthenke,2016-03-01T16:26:46Z,do we need to support null? would empty string work well enough and avoid null checks throughout the code?,0,0.9913312196731567
54592311,132,granthenke,2016-03-01T16:26:50Z,related to my protocol question above. would defaulting to empty string work?,0,0.9891315698623657
54592316,132,granthenke,2016-03-01T16:26:51Z,could use the constructor that doesn't take a rack.,0,0.9910165071487427
54592322,132,granthenke,2016-03-01T16:26:53Z,could use the constructor that doesn't take a rack.,0,0.9910165071487427
54592337,132,granthenke,2016-03-01T16:26:58Z,is brokerlist used here?,0,0.9950900077819824
54592349,132,granthenke,2016-03-01T16:27:03Z,seams i may need to use this in kip-4. which means it would need to live in the clients library under the common package. could this be a java enum there?,0,0.9934832453727722
54592380,132,granthenke,2016-03-01T16:27:09Z,is this includerack boolean used anywhere?,0,0.9940529465675354
54592390,132,granthenke,2016-03-01T16:27:10Z,is this includerack boolean used anywhere?,0,0.9940529465675354
54592404,132,granthenke,2016-03-01T16:27:15Z,are there unsafe characters that could be in the rack string that would break the json read/write?,0,0.9870144128799438
54624794,132,hachikuji,2016-03-01T19:52:38Z,is this only public for testing? would protected or default also work?,0,0.9917044639587402
54627527,132,hachikuji,2016-03-01T20:10:36Z,"would ""safe"" be a better default? looks like the default is only used in test cases, so maybe it would be better to always require the argument?",0,0.9867132902145386
54645170,132,allenxwang,2016-03-01T22:13:58Z,"broker.sizeinbytes() and broker.writeto() was used for serialization and deserialization of updatemetdatarequest when i started the pr. that's why i have to add includerack parameter for version compatibility. it was recently changed to use the java code in kafka.common for this. but broker.readfrom and broker.writeto remain in the code. so i am not sure if they are still needed. if not, we can delete this part of code all together.",0,0.9772495031356812
54645719,132,allenxwang,2016-03-01T22:17:44Z,"i am not sure. this is only used when replica assignment is needed. if the only change in client library is to be able to access rack in topicmetadatarequest/response, then this can stay in scala in kafka.admin.",0,0.9518547058105469
54645900,132,allenxwang,2016-03-01T22:18:59Z,i would think any character is fine.,0,0.8628064393997192
54646069,132,granthenke,2016-03-01T22:20:14Z,topiccommand is taking this as a parameter when creating a topic. assuming the options is important. when createtopic calls go through the broker i will need to pass this option in the request.,0,0.994541347026825
54646230,132,allenxwang,2016-03-01T22:21:21Z,"no, it is used in controllerchannelmanager and has to be public.",0,0.9933618307113647
54648019,132,allenxwang,2016-03-01T22:33:44Z,"""safe"" is only used in auto topic creation. in command line tools, we would like to be strict about using rack (to catch mis-configured rack) unless the user wants to disable it. this was discussed in kip process. the reason to make this argument optional is that in most cases, user would supply rack for all brokers or no rack for any broker which can be handled automatically in ""enforced"" mode. then createtopic can remain the same signature so that caller of this method does not need to be concerned about rack aware.",0,0.9915140271186829
54648159,132,allenxwang,2016-03-01T22:34:44Z,sure.,0,0.9824982285499573
54649101,132,allenxwang,2016-03-01T22:43:27Z,i discussed this in kip discussion. nullable_string was recommended in the discussion. i think it makes sense as rack itself is designed to be nullable (option[string]). it is legal to define rack as an empty string. there isn't really any null checks in the code as far as i can tell. null just means no rack is defined.,0,0.9343478083610535
54649841,132,hachikuji,2016-03-01T22:49:22Z,"is that because we're depending on this constructor for version 1? i know we depend on choosing the right constructor in other request objects to get the right version, but i wonder if it would be better to have explicit static factory methods (e.g. `updatemetadatarequest.createv0()`)?",0,0.9832543730735779
54649887,132,allenxwang,2016-03-01T22:49:41Z,it's not. i will remove it.,0,0.9875943660736084
54650027,132,granthenke,2016-03-01T22:50:37Z,"i checked the java doc for `json.encode`. it says `this method does not properly handle non-ascii characters.` i am not sure how ""bad"" it fails. some basic limitations/validation on available rack characters and length might help prevent unforeseen issues. something similar to the limitations for a topic name maybe.",0,0.8633082509040833
54663838,132,allenxwang,2016-03-02T00:57:52Z,"if topic creation is available from clients, then we need to pass rackawaremode in the request. in that case i agree this class should be in common package as enum. do you want me to make this change? does the protocol support enum?",0,0.9884582161903381
54664542,132,allenxwang,2016-03-02T01:06:12Z,"we depend on this constructor to create version 1 and 2 updatemetadatarequest, and possibly for future versions as well.",0,0.9944854378700256
54667264,132,hachikuji,2016-03-02T01:39:53Z,fair enough. i was only wondering if there was a way to keep the version better encapsulated (like all of the other requests). perhaps at least there should be a check on the version to make sure it is greater than 1? i might even enforce only version 1 and 2 since we'll almost certainly have to touch this code anyway if there is another version bump.,0,0.8855727314949036
54668363,132,hachikuji,2016-03-02T01:53:29Z,"makes sense, thanks.",1,0.5818662643432617
54807092,132,allenxwang,2016-03-02T22:53:29Z,"i will add the check for version. i believe 0 is still supported so 0, 1 and 2 should be allowed.",0,0.994470477104187
54811738,132,hachikuji,2016-03-02T23:30:47Z,"actually it's probably fine as it is since we would raise an error in `protoutils.requestschema()`. i didn't notice that this also supports version 0, so would it make sense change controllerchannelmanager to use this constructor for all cases. (and apologies for all this nitpicking)",-1,0.9584459066390991
54812799,132,ijuma,2016-03-02T23:39:22Z,"by the way, for a bit of history, i initially proposed having a single constructor with a version when i introduced this class. however, preferred having separate constructors with all, but the most recent version deprecated.",0,0.9861443042755127
54813357,132,hachikuji,2016-03-02T23:44:08Z,i think my preference would probably be to have static factory methods with the versions included in the name. using constructors is kind of annoying because you have to check the comment to make sure you get the right one.,-1,0.9270548820495605
54813814,132,ijuma,2016-03-02T23:48:37Z,"yeah, we should use more static factories and less overloaded constructors in kafka.",0,0.9662762880325317
54815295,132,allenxwang,2016-03-03T00:02:35Z,"i don't really know what would be the valid characters or length limit for rack. looking at the implementation of json.encode() there is nothing suspicious how characters are handled. note that in some cases, rack can be a logical name and used for grouping brokers for fault tolerance. so any character is possible. apache cassandra does not seem to do any validation on rack name for their property file based configuration. if there is no specification or usual convention for the rack name, i suggest we leave it unchecked.",0,0.9758997559547424
54817202,132,allenxwang,2016-03-03T00:22:24Z,would you mind if i leave this code refactoring of constructors to you guys?,0,0.9892767667770386
54817893,132,ijuma,2016-03-03T00:28:21Z,fine by me.,0,0.8335161209106445
54817929,132,hachikuji,2016-03-03T00:28:39Z,ditto,0,0.9754701256752014
54838116,132,junrao,2016-03-03T05:41:11Z,could we fix the alignment?,0,0.9918121099472046
54838129,132,junrao,2016-03-03T05:41:23Z,alignment,0,0.9887444972991943
54838137,132,junrao,2016-03-03T05:41:37Z,we should probably mark this as deprecated.,0,0.8848091959953308
54838143,132,junrao,2016-03-03T05:41:40Z,an -> a,0,0.9849672913551331
54838189,132,junrao,2016-03-03T05:42:43Z,"by leader, do you mean preferred leader? the first replica is not always the leader. perhaps it's clearer to just refer to them as 1st replica, the rest of replicas, etc.",0,0.98897385597229
54838197,132,junrao,2016-03-03T05:42:53Z,would it be better to combine brokerlist and rackinfo and pass in a seq of brokermetadata that includes id and rack?,0,0.9935067892074585
54838204,132,junrao,2016-03-03T05:43:00Z,can reversemap(rack).toiterator just be list.toiterator?,0,0.9934733510017395
54838213,132,junrao,2016-03-03T05:43:13Z,could we use case instead of tuple to make it clearer? ditto below.,0,0.9940600991249084
54838217,132,junrao,2016-03-03T05:43:17Z,should we sort the broker list per rack?,0,0.9922055602073669
54922060,132,allenxwang,2016-03-03T18:16:50Z,"rackinfo here can be different from the actual broker-rack mapping. in case some brokers have rack and some brokers do not have rack, adminutils.getbrokersandrackinfo() will modify the mapping depending on how strict we want to be rack aware. it will also return empty map if user does not want rack aware. i think it is better to have higher level api (like createtopic()) to be influenced by the rack aware mode depending on the situation and user input and leave this assignment api free of that influence.",0,0.9848782420158386
54928901,132,junrao,2016-03-03T18:59:57Z,"we will still need a separate constructor for v1 of updatemetadatarequest since in controllerchannelmanager, we may need to send a v1 request depending on inter.broker.protocol.",0,0.9944445490837097
54928926,132,junrao,2016-03-03T19:00:07Z,"now that we are returning the assignment, it's a bit weird to print the assignment to stdout. perhaps we should let the caller do that.",-1,0.9280712008476257
54928999,132,junrao,2016-03-03T19:00:36Z,"it seems that readfrom and broker.writeto are only used in tests now since the serialization of updatemetadatarequest is based on the one in o.a.k. instead of maintaining the logic here, could we just remove readfrom and broker.writeto and the corresponding test code?",0,0.9924530386924744
54929005,132,junrao,2016-03-03T19:00:38Z,unused import,0,0.9873000979423523
54929073,132,junrao,2016-03-03T19:01:01Z,we will need to construct v1 and v2 request using different constructors. see comment in updatemetadatarequest.,0,0.9955356121063232
54929083,132,junrao,2016-03-03T19:01:05Z,unused import,0,0.9873000979423523
54929093,132,junrao,2016-03-03T19:01:10Z,unused import,0,0.9873000979423523
54929109,132,junrao,2016-03-03T19:01:19Z,could we add the new params in the comment above?,0,0.9953030347824097
54929134,132,junrao,2016-03-03T19:01:27Z,this seems to be an expensive way to test auto topic creation since it needs to start a cluster. could we just test adminutils.assignreplicastobrokers() directly?,0,0.8938100934028625
54929143,132,junrao,2016-03-03T19:01:32Z,do we need to start zk for this test?,0,0.9947015643119812
54929192,132,junrao,2016-03-03T19:01:42Z,is this useful since none of the 3 verifications are enabled by default. ditto below.,0,0.9939475059509277
54929198,132,junrao,2016-03-03T19:01:45Z,unused import,0,0.9873000979423523
54929228,132,junrao,2016-03-03T19:01:50Z,"should those comments starting with ""ensure"" be here?",0,0.9925536513328552
54929246,132,junrao,2016-03-03T19:01:56Z,do we need to start zk in this test? it seems that we can just test adminutils.assignreplicastobrokers() directly?,0,0.9934711456298828
54929251,132,junrao,2016-03-03T19:02:00Z,similar to the above. do we need to start zk in this test? it seems that we can just test adminutils.assignreplicastobrokers() directly?,0,0.9905643463134766
54937233,132,allenxwang,2016-03-03T19:51:18Z,do you suggest using a case class to represent the tuple?,0,0.9945383667945862
54937680,132,granthenke,2016-03-03T19:54:04Z,i think just like you did in the map above is good: [code block],1,0.9253779053688049
54954835,132,ijuma,2016-03-03T21:54:00Z,"the kip says: `case class broker(id: int, endpoints: map[securityprotocol, endpoint], rack: option[string] = none)` i prefer how you have it here, but we should update the kip.",0,0.9935059547424316
54955136,132,ijuma,2016-03-03T21:55:52Z,yes and the kip should be updated to remove the point about updating `broker.writeto`.,0,0.9931687116622925
54971611,132,allenxwang,2016-03-04T00:15:15Z,"i think we can use the same constructor for both v1 and v2 except for the version number. when the request is serialized, the rack in v1 request is ignored according to protocol. in other words, regardless v1 or v2, we can have rack in updatemetadatarequest.broker and have it handled differently only at serialization. see the updated test requestresponsetest where i added the test for v1 request to make sure it still works.",0,0.9788720011711121
54971962,132,allenxwang,2016-03-04T00:19:06Z,this may not be necessary. see my comment in controllerchannelmanager.,0,0.9951944947242737
54972661,132,junrao,2016-03-04T00:26:36Z,"yes, you are right.",0,0.9548653960227966
54974078,132,allenxwang,2016-03-04T00:41:59Z,the only caller is main(). i feel it is little bit over stretched to print from main or create another function just to print the result.,0,0.8534712791442871
54974433,132,allenxwang,2016-03-04T00:45:54Z,will update the kip,0,0.9950384497642517
54974451,132,allenxwang,2016-03-04T00:46:04Z,will update the kip,0,0.9950384497642517
54977110,132,allenxwang,2016-03-04T01:10:56Z,"we have unit tests for adminutils.assignreplicastobrokers() that does not require starting a server. however, since the logic that governs the rack aware mode is separate from adminutils.assignreplicastobrokers(), we need to have tests to make sure the right api is called from kafkaapi. the behavior we need to test is - if all brokers have rack, rack aware assignment will be generated - if some brokers have rack and some do not, it will be treated as none of the brokers have rack",0,0.990059494972229
54978198,132,allenxwang,2016-03-04T01:24:05Z,there is a test case (testgetbrokersandracks) testing the behavior of what broker-rack mapping should be used under different rack aware mode.,0,0.9942089319229126
54980762,132,allenxwang,2016-03-04T01:54:08Z,it is a bug that by default the three verifications are disabled. i will fix it.,0,0.9724736213684082
54981583,132,allenxwang,2016-03-04T02:06:34Z,"it ensures that user can disable rack aware in the command line in topiccommand and the reassignpartitioncommand can generate the assignment which is rack aware, if user does not disable rack aware when running reassignpartitioncommand.",0,0.9937238097190857
54981885,132,allenxwang,2016-03-04T02:11:04Z,"this covers the situation where replica assignment is rack aware for alter operation. again, i added this test since user input in the command line can change how rack aware is enforced.",0,0.993122398853302
54983632,132,allenxwang,2016-03-04T02:38:55Z,"given the comment from that the old constructor should be deprecated, i think it is better to use the new constructor.",0,0.9848092198371887
54996851,132,granthenke,2016-03-04T07:08:34Z,works for me,0,0.9870917797088623
54997151,132,granthenke,2016-03-04T07:13:12Z,the way protocols support enum is via some id field. examples can be seen in existing enums and my kip-4 prs: [permissiontype.java ]([a link],0,0.9949063062667847
55029807,132,ijuma,2016-03-04T13:35:25Z,note that this constructor is only used in tests. does it even make sense to keep it?,0,0.9919129610061646
55030014,132,ijuma,2016-03-04T13:37:23Z,"this constructor is only used in tests, does it make sense to keep it? i guess the question is whether the request classes are api. as i understand, they are not, but i would like to get 's take.",0,0.9923949241638184
55031610,132,ijuma,2016-03-04T13:52:14Z,"can you please elaborate why you think it's not good to move the println to `main`? in fact, that is exactly what was done in the following pr that adds some tests to the reassign partitions command: [a link]",0,0.9955631494522095
55032389,132,ijuma,2016-03-04T14:00:22Z,"i think it would be good if we could elaborate a little more on the purpose of this property (with some brief examples, maybe).",0,0.9631934762001038
55033837,132,ijuma,2016-03-04T14:14:35Z,"we say that we register the v3 format including rack, but the code only adds the rack if `apiversion >= 3`. if we follow the same approach as what we did with v2, we should always add the rack as it will simply be ignored if `version < 3`, right?",0,0.9919525980949402
55033946,132,ijuma,2016-03-04T14:15:36Z,"also, the documentation here isn't accurate as we may register `v2` depending on the value of `apiversion`.",0,0.9824320673942566
55075041,132,allenxwang,2016-03-04T19:16:21Z,"do you really need to serialize rackawaremode from the client side? if you want to send a request to broker to create topic, the only thing related to rack aware is whether you want to disable it. and you can send a string for this purpose like the ''--disable-rackaware"" command line option, right?",0,0.9915661811828613
55075472,132,granthenke,2016-03-04T19:19:51Z,"why send a string and translate it in 2 places, with 2 pieces of logic, if instead i can have 1 common enum that lets me send a small byte and ensure translation is the same on both sides. my understanding is this is not a boolean choice but there are 3 values to pick from. i have not spent enough time digging into rackawaremode and if its really required, but if i need to use it to communicate to a broker it should be in the clients code.",0,0.9545025825500488
55076734,132,allenxwang,2016-03-04T19:29:16Z,it is more of a style issue. i noticed that most of the command class' `main` does not have println. the above pr refactored the `generatedassignement` function into two and there is no println in main. i am fine with this approach.,0,0.812366783618927
55082237,132,ijuma,2016-03-04T20:09:58Z,"that's fine too. the main aim is to keep the method that returns a value without `println` so that it can be tested without polluting the logs, for example.",0,0.9763357043266296
55082518,132,ijuma,2016-03-04T20:12:28Z,"are you suggesting that `safe` mode would not make sense in this context? if so, then i agree that this enum would not make sense in `common`.",0,0.9912647604942322
55083450,132,allenxwang,2016-03-04T20:20:07Z,i will update the document. i think it is safer not to register the rack when version < 3 and having rack in v2 violates the specification anyway which might be confusing to users.,0,0.9912488460540771
55084318,132,ijuma,2016-03-04T20:27:37Z,"ok, i think this has been discussed before and i apologise for asking again. why do we need to write v2 at all? with the exception of 0.9.0.0, the parsing code reads any version and ignore fields that it doesn't know about, right? is it to make it possible to upgrade from 0.9.0.0 (even if that will break old clients anyway)?",-1,0.9748817682266235
55088095,132,junrao,2016-03-04T21:00:54Z,"i think the reason that we have to design the broker registration json in a backward compatible way is that the old consumer and admin tools still read the json directly. once we deprecate the old consumer and move the admin tools to the admin api, only the brokers need to read the json. then, potentially we can make non compatible json changes as long as the broker writes the json according to inter.broker.protocol. for example, we make want to clean up the redundant host field in the future. so, it is true that at this moment, we can always write the latest version of the json that the broker understands since the change is backward compatible. however, following the inter.protocol convention is probably what we want to do in the future. so, we may want to just start doing this now.",0,0.9709373116493225
55088361,132,allenxwang,2016-03-04T21:03:37Z,safe mode is currently only used for auto topic creation. it is not used for command line tools. i think it is better for you guys to do the necessary changes when implementing the client side code since i cannot verify the changes i make here will work for clients in the future. and it will be more efficient to do this later since there might be unforeseen problems or design changes arise when client code is implemented.,0,0.9557948708534241
55088556,132,granthenke,2016-03-04T21:05:20Z,i am okay with that.,0,0.8920497894287109
55095191,132,ijuma,2016-03-04T22:00:10Z,"thanks for explaining. if we want to do it this way, i think we need to add a comment explaining it because it's not obvious and it's inconsistent with how we did the v1 to v2 change. having said that, i am not sure if it's worth doing this now for the following reasons: - it will probably be a long time before we can actually drop support for the old consumer and admin tools in the broker (i think 3 non-bug fix releases is the absolute minimum, but it will probably be longer) - it's inconsistent with how the parser code works (for compatibility as you mentioned). without changing the parser code, older brokers will break if we suddenly remove fields. - it doesn't seem to buy us anything in terms of what gets stored (people will bump inter.broker.protocol as part of the upgrade and then v3 will be stored anyway) for the time when we want to delete fields. it seems to me that when we have a concrete plan to clean this up, we can add the necessary code for both writing and parsing. it will probably take a few releases before we can actually delete the fields, but that's probably ok.",1,0.9341710209846497
55098730,132,junrao,2016-03-04T22:27:05Z,": yes, we can probably just write the v3 json for now and clean things up later.",0,0.989946186542511
55102385,132,allenxwang,2016-03-04T23:02:57Z,one thing i want to add is that we have to write v2 when protocol is 0.9.0.x because of kafka-3100. having rack in v2 version is probably fine but i don't see any benefit of doing that.,0,0.9024375081062317
55103536,132,ijuma,2016-03-04T23:16:52Z,"right, so that was my original question, this helps with people who want to upgrade brokers from 0.9.0.0 to 0.10.0.0, right? that's a fair argument and worth mentioning in the code. with this approach, only old clients have to go to 0.9.0.1 before the 0.10.0.0 upgrade. brokers can go straight from 0.9.0.0 to 0.10.0.0 (provided that they do the inter.broker.protocol dance).",0,0.9242674708366394
55106909,132,allenxwang,2016-03-05T00:00:19Z,ok. i like that approach too and it will simply my junit tests. i will borrow that in this pr. you still need to resolve the conflict through in the future.,1,0.8768079280853271
55107138,132,ijuma,2016-03-05T00:03:20Z,sounds good.,1,0.857205867767334
55187222,132,ijuma,2016-03-07T10:47:20Z,", if we use something like the following, we can still handle the scenarios you describe, right? [code block] i am happy to try this out on a branch to see how it looks. thoughts?",1,0.9686017036437988
55188628,132,ijuma,2016-03-07T11:00:54Z,i think we should also update the text around: `there are 2 goals of replica assignment` either we need to add a third goal or we should make it clear that that description is for rack unaware and then explain what the goals are for the rack-aware case.,0,0.9849001169204712
55402888,132,allenxwang,2016-03-08T18:24:57Z,updated the doc. please take a look.,0,0.9679452180862427
55404378,132,ijuma,2016-03-08T18:33:53Z,"looks good, thanks.",1,0.9598045349121094
55487522,132,ijuma,2016-03-09T08:52:56Z,"""notes to clients"" maybe?",0,0.9893496036529541
55488300,132,ijuma,2016-03-09T09:00:44Z,"maybe: ""clients with a zookeeper dependency (old scala high-level consumer and mirrormaker if used with the old consumer) will not work with 0.10.0.x brokers. therefore, 0.9.0.0 clients should be upgraded to 0.9.0.1 before brokers are upgraded to 0.10.0.0.""?",0,0.9902161359786987
55532555,132,granthenke,2016-03-09T15:15:02Z,this is a big deal right? it breaks kafka's backwards compatibility guarantee. it should probably be moved from the performance impact section to the breaking section. is there anything else we can do to fix this? are we sure it does not break 0.8 clients? cc,-1,0.8142646551132202
55534413,132,granthenke,2016-03-09T15:26:22Z,"i went back and looked. i see why its only an issue for 0.9.0.0. its because a change went in that throws an exception for any version > 2 ([a link], where in 0.8.x version isn't even used ([a link]. can we leverage the fact that we are only adding a field, therefore this is a ""compatible"" update that does not require a version bump? that way we stay at version 2, 0.9.0.0 ignores the rack field, and everything works? this should work because all of our json parsing just uses a map[a link] anyway.",0,0.9535963535308838
55536850,132,ijuma,2016-03-09T15:41:09Z,", yes, it is a big deal. your suggestion was discussed in the kip thread, but said that we need to increase the version when we change the format. as i understand it, the idea is to move away from being limited to just adding fields once we stop supporting old clients (but that is a while away in my opinion). thinking more about this, we could also add a new version field and deprecate the old one (which can stay at `2` until we no longer support `0.9.0.0` many years from now) if we really care about having an incrementing version each time we change the format. thoughts?",0,0.6140204668045044
55538191,132,granthenke,2016-03-09T15:49:05Z,"i agree, we don't want to be limited to just adding fields, but when we are just adding fields a version bump may not be required. this patch assumes anything over version 1 will be compatible in the else statement, so even though our goal is being able to remove fields, this patch does not do that. i don't think adding another version makes sense, thats just adding another field to (old) version 2. we can just add the rack field and achieve the same goal.",0,0.9698249697685242
55539640,132,ijuma,2016-03-09T15:57:16Z,"i don't agree that we achieve the same goal. from a storage format documentation perspective, it's easier to track format changes if there is a version associated with them (even when doing compatible changes like adding fields). it is still useful to know when a particular set of fields was added ((in this case it's just a single field, but in others there will be more). yet another way to handle that is to tie the format with `apiversion`. this can be done implicitly or explicitly.",0,0.919830322265625
55541167,132,granthenke,2016-03-09T16:05:41Z,"i completely agree. versioning the the format is important. it acts as valuable documentation and (when used correctly) can help improve compatibility. let me be clear about my intentions. i am making no comment on the future of zookeeper json compatibility, just this change and its impact to the upcoming release. given that we still, even in this patch, don't support removing fields in future versions. changing the version for that reason is a moot point. therefore the only value the version has is documentation. if we weigh documentation and compatibility for 0.10 and choose documentation, then we can bump the version. if we think compatibility is the most important thing to maintain. that can be solved by keeping the version at 2.",0,0.5761322975158691
55604952,132,junrao,2016-03-09T22:50:20Z,": yes, we could keep version 2 in json. but the the drawback is the following. if we want to support upgrading form 0.9.0.0 to any future releases post 0.10.0, we can't bump the version in json forever. given that (1) versioning the json in zk is useful and (2) the issue in 0.9.0.0 is a bug and relatively few people are using 0.9.0.0 yet, i think it's probably better to change the zk version now, but require people to upgrade from 0.9.0.1.",0,0.9611803293228149
55631206,132,granthenke,2016-03-10T03:57:23Z,"in future releases we expect to remove the old scala clients. this means only the brokers will talk directly to zookeeper and this should not longer be an issue. my understanding is the goal of 0.10.0 is to be a ""compatible"" release. future releases may remove other deprecated things and choose to be breaking. i think that's the best time to break here as well. i don't want to push the issue too much. in the end, i am okay with either choice. i just want to be sure we are consciously choosing to break and for good reason.",0,0.6891914010047913
55909377,132,junrao,2016-03-12T00:37:13Z,"this doesn't seem to be 100% safe in that we can potentially assign 2 replicas to the same broker. consider the following example. rack : a b a a broker: 0 1 2 3 at some point, we assign the 1st replica to broker 1. suppose that nextreplicashift is 0. we then assign 2nd replica to broker 2. when assigning the 3rd replica, we will be skipping 3 and 0 and assign broker 2 to the 3rd replica again. before we don't have this issue since when assigning replicas other than the 1st, we cycle through the brokers sequentially without skipping. the new logic allows skipping. so, it's possible for us to hit the same broker.",0,0.9748746156692505
55909620,132,junrao,2016-03-12T00:41:32Z,"i still think that this test and adminrackawaretest (except for testgetbrokermetadatas) can still be simplified. for example, if we restructure the code a bit by wrapping assignreplicastobrokers in another helper method that takes the following signature, then we should be able to test all kinds of rack/rackawaremode combinations w/o needing to start broker/zk, right? (brokermetadatas: seq[broker], rackawaremode: rackawaremode, npartitions: int, replicationfactor: int, fixedstartindex: int = -1, startpartitionid: int = -1)",0,0.968281626701355
55909641,132,junrao,2016-03-12T00:41:38Z,"hmm, what does notenoughpartitions mean?",0,0.9752358198165894
55909658,132,junrao,2016-03-12T00:41:48Z,is filling the same value expensive? would it be more efficient to just iterate each size and do a check?,0,0.9770328998565674
55909701,132,junrao,2016-03-12T00:42:30Z,should we also verify that no two replicas from the same partition are assigned to the same broker?,0,0.9931954145431519
55909718,132,junrao,2016-03-12T00:42:41Z,is there anything special with 12 partitions?,0,0.99085533618927
55910465,132,ijuma,2016-03-12T00:56:40Z,this is really cheap compared to other things we do in our tests and it gives better error messages.,1,0.8660637140274048
55911136,132,allenxwang,2016-03-12T01:07:54Z,"i don't think that will help from test's perspective. even if we add rackawaremode here, we still need to make sure that for auto topic creation and command line tools (where you can disable rack aware) the right rackawaremode is used. the tests that have dependency on broker/zk make sure no matter how underlying api is structured, the end result is correct. so i think there are values in the tests.",0,0.96383136510849
55911374,132,allenxwang,2016-03-12T01:12:35Z,i will fix the confusing name. the test makes sure the algorithm works when the number of partition is not multiple of brokers.,0,0.9886046648025513
55911537,132,allenxwang,2016-03-12T01:15:43Z,"probably not. :) in general, these tests run very fast since all they do is operate on collections in memory. so i have not thought about reducing the number of tests.",1,0.993466317653656
55915045,132,allenxwang,2016-03-12T03:23:17Z,that's a very good point. i will address this in my next update.,1,0.9812300205230713
55917767,132,allenxwang,2016-03-12T07:16:04Z,"thinking a little bit more on this, i think this situation is actually covered by the algorithm. in this case, there are three replicas and only two racks. once replicas are assigned to 1 and 2, we know that all racks have replicas for the partition and skipping behavior will stop.",0,0.9826153516769409
55922985,132,junrao,2016-03-12T15:49:24Z,"right, this example actually works. but the following won't. consider the following broker to rack mapping. rack : a b c a a broker: 0 1 2 3 4 let's say you want to have 4 replicas and the first replica is assigned to broker 2. then you assign 2nd replica to 3. then you skip broker 4 and 0 since both are on rack a and not all racks are filled yet. then you assign 3rd replica to 1. finally, you will assign 4th replica to broker 3 again.",0,0.9868565201759338
55929323,132,allenxwang,2016-03-12T23:09:16Z,"yes, i will add that check.",0,0.9918525815010071
55929568,132,allenxwang,2016-03-12T23:31:03Z,excellent example. added the logic to prevent assigning replica twice to the same broker for the same partition.,1,0.9924123883247375
55933791,132,ijuma,2016-03-13T08:37:22Z,"nitpick: we don't really need this `assertequals` or the `brokerlist` val since that is checking that `tobrokermetadata` works correctly, which is not the purpose of this test.",0,0.9882680773735046
55933813,132,ijuma,2016-03-13T08:39:50Z,this was probably an accidental reformatting by intellij.,0,0.9660353064537048
55933814,132,ijuma,2016-03-13T08:39:55Z,this was probably an accidental reformatting by intellij.,0,0.9660353064537048
56015924,132,junrao,2016-03-14T15:12:39Z,"only this test needs zk. could we pull this test to a different class and remove the zk dependency from this class? otherwise, each test will unnecessarily start a zk server, which will slow down the test.",0,0.9706129431724548
56016010,132,junrao,2016-03-14T15:13:09Z,could we add an error message in assertequals? ditto in the assertequals below.,0,0.9950300455093384
56053157,132,allenxwang,2016-03-14T18:40:06Z,will do.,0,0.9465230703353882
56054757,132,allenxwang,2016-03-14T18:50:00Z,"i think there is value in checking this to make sure test set up is correct. otherwise if `tobrokermetadata` is changed, there are two possibilities: - test fails and it is difficult to debug why it fails - test passes but is actually weakened",0,0.9706619381904602
56095654,132,ijuma,2016-03-14T23:45:37Z,", we use `tobrokermetadata` in many other tests and we don't check its behaviour in the other cases, so it looks a bit inconsistent. in my opinion, if we want to be sure about its behaviour, we should write a test for it instead of checking its behaviour inside other tests. in any case, this is a very minor point and i'm fine if we leave as is.",0,0.7827733755111694
220379749,5693,vvcephei,2018-09-25T22:47:11Z,"this change (and similar changes below) are to make sure the serdes we need for suppression are available. i sort of thought that we already merged a pr to do this, but perhaps it was only partial.",0,0.9907435774803162
220380552,5693,vvcephei,2018-09-25T22:51:38Z,"i realized belatedly that i missed this (internal) interface when i renamed ""maxkeys"" to ""maxrecords"" in part 1.",0,0.8003085851669312
220380693,5693,vvcephei,2018-09-25T22:52:29Z,this wraps the value so that the buffer can store the whole record context for later forwarding.,0,0.994737446308136
220381174,5693,vvcephei,2018-09-25T22:55:02Z,"since we don't actually store the value serialized in the in-memory impl, we annotate the value with its size so we can maintain the current footprint of the buffer. alternatively, we could serialize it again on removal to idempotently re-compute its size, but this seemed cheaper.",0,0.9905961751937866
220383032,5693,vvcephei,2018-09-25T23:04:56Z,"this could be configurable in the future, but for now, we enforce the time limit in the following fashion: * start a timer when a key first enters the buffer * that key and its most recent value will be emitted when the time limit expires, regardless of how recently it has been updated the primary advantage of this implementation is that we guarantee that if you set a 5-minute limit, we delay emitting the key for no more than five minutes. if we instead re-set the timer on each update, you might never see a record that gets consistently updated more frequently than the time limit. my judgement was that this is the most intuitive default and starting point for the feature. if people want to configure it, we can easily add that option later.",0,0.957883358001709
220383454,5693,vvcephei,2018-09-25T23:07:36Z,"as demonstrated by part 1, we don't always need the buffer, so i thought it best to avoid allocating it and scheduling the associated punctuator until we first discover we need to buffer something.",0,0.9913346171379089
220384765,5693,mjsax,2018-09-25T23:15:03Z,why do we need this in `process` -- seem like moving it to `init()` should be sufficient?,0,0.975226104259491
220385505,5693,vvcephei,2018-09-25T23:19:53Z,"this was the punctuation concern brought up. i haven't optimized this yet because i wanted to discuss the available options first. i'm thinking: 1. store the min timestamp in the buffer to make this function cheap when there's nothing to do 2. schedule just one punctuator for all the buffers. this would require more coordination in the topology builder, and i'm not sure if it would actually yield any benefit. is iterating over buffers any better than iterating over an equal number of punctuators? 3. schedule the punctuator less frequently. this would improve performance for high-frequency topics, but not for medium to low frequency topics. on the downside, it would sacrifice resolution and make the tests a little tricky to reason about. 3a. we could probably make a reasonable approximation of the appropriate resolution based on the suppression time limit, like `min( max(1, suppressduration / 10), 30 seconds)`, or even tie it to the commit interval. 3b. to mitigate the testing problem, we could add a private mechanism to directly set the resolution. (not sure this is needed; would like to see how awkward it is in practice once we decide on some optimizations)",0,0.9059175252914429
220385584,5693,mjsax,2018-09-25T23:20:27Z,`suppress.gettimedefinition()` should return the same thing each time? should we put it into a member variable?,0,0.9914440512657166
220385995,5693,vvcephei,2018-09-25T23:22:55Z,"come to think of it, this is probably insufficient to catch the wrong serde (due to erasure). i probably need to relocate this error message to the actual call to de/serialize",0,0.9695452451705933
220386097,5693,vvcephei,2018-09-25T23:23:35Z,oops. i'll take these out.,-1,0.513205885887146
220386172,5693,mjsax,2018-09-25T23:23:58Z,"i am wondering about this: as we compute the byte-size later, and already pay the cost to serialize the record, should we not store `byte[]/byte[]` in the buffer? of course, still will imply that we need to deserialize later, however, the keeping the actual deserialized objects around would haver more storage overhead and would not obey the buffer size imho. thoughts?",0,0.9129899144172668
220386402,5693,mjsax,2018-09-25T23:25:24Z,we should resolve this before merging imho.,0,0.990016758441925
220386480,5693,vvcephei,2018-09-25T23:25:55Z,"oh yeah, i was meaning to figure out the right exception to throw to achieve a nice shutdown (i think any runtime exception will do it, but is there a semantically best one?)",0,0.8804449439048767
220386796,5693,mjsax,2018-09-25T23:28:01Z,do we need this check?,0,0.9950881600379944
220387020,5693,vvcephei,2018-09-25T23:29:25Z,this is specifically for storing the keys sorted by timestamp in the buffer. i wasn't sure whether a more general or more specific name like `bufferkey` is better...,0,0.986562967300415
220387145,5693,mjsax,2018-09-25T23:30:17Z,nit: remove `this`,0,0.9929719567298889
220387246,5693,vvcephei,2018-09-25T23:31:02Z,"aka, ordering of keys that share a timestamp is arbitrarily. if anyone cares, we can do ""better"" by requiring k to be comparable (but i don't think anyone should care, so i kept it simple)",0,0.9334579110145569
220387263,5693,mjsax,2018-09-25T23:31:07Z,should we check for `last == null` and set `last = null` ?,0,0.9947063326835632
220387414,5693,mjsax,2018-09-25T23:31:56Z,guess this should be removed?,0,0.9736999273300171
220387906,5693,mjsax,2018-09-25T23:35:08Z,not sure about this. see my other comment. would be good to get input from and about this.,0,0.8865573406219482
220387946,5693,vvcephei,2018-09-25T23:35:24Z,aha. i was thinking of [a link] which just isn't merged (yet).,1,0.9287651777267456
220390443,5693,mjsax,2018-09-25T23:50:35Z,"imho, scheduling a `1ms` punctuation would cause quite some overhead. alsw, we only need this for ""time based"" eviction, not for buffer size (num records, num bytes), right? we should also know, *when* we need to evict earliest -- thus, it should be sufficient to schedule accordingly? i think, we can also exploit cancellation to scheduled punctuation to be more flexible. also note, that during runtime, we don't check for punctuation execution after each record, but do this only after n records are processed (with n being adjusted dynamically during runtime). we also need to consider, that we fire a lot of punctuations if we ""jump ahead"" in time what seems to be inefficient.",0,0.9417031407356262
220390754,5693,mjsax,2018-09-25T23:52:28Z,i agree with the described semantics.,0,0.975999116897583
220390935,5693,mjsax,2018-09-25T23:53:39Z,"forgot to add this to my review: this seems to have large runtime overhead and imho, we should try to find a better way to handle this.",-1,0.9350093007087708
220391498,5693,mjsax,2018-09-25T23:57:09Z,do we need to use punctuations to enforce record/byte limit? might be better to check for record/byte limit on put and use punctuations only to evict time based?,0,0.9929676055908203
220402141,5693,vvcephei,2018-09-26T01:19:05Z,"ah, ok. i was hoping this is not how punctuations work (i'm ashamed to say i haven't looked at it yet). what i was hoping is that if i start at stream-time 0ms and then get a record at time 100ms, then my 1ms punctuator would be invoked just once, at time 100ms. i.e., i was thinking it would ""jump ahead"" (i thought i observed this, but maybe it was using the `topologytestdriver`). one alternative is to ""brew my own"" schedule exactly as i described, checking during `process` if there are any old-enough records. this could be done in the same loop that evicts if we're over capacity. this implementation would be very cheap. the tradeoff is that the punctuator will be fired on any advancement in stream time, whether or not that record actually reaches the buffer. but the hack i described would only ""tick"" when `process` is invoked. i *think* this would probably be satisfactory semantics.",-1,0.5182297229766846
220403434,5693,vvcephei,2018-09-26T01:29:19Z,"regarding: this is true, but it's slightly tricky (or at least it took me a while to realize it's not sufficient to trigger every `suppressduration` ms). i guess that each time we have a new min buffered timestamp `m`, we'd schedule a punctuation, we could cancel the previous punctuation and schedule a punctuation for `m + suppressduration` time from now. the punctuation schedule doesn't let you schedule in the form of ""`x` ms from now"", (i'm guessing it's epoch aligned like the windows), so we'd do a little math to compute a punctuation interval that would next fire at the correct time. i said ""each time we have a new min timestamp"". this can happen when we buffer new records or when we evict records. is this what you had in mind?",0,0.9798555374145508
220405269,5693,vvcephei,2018-09-26T01:44:03Z,"it's not so easy to tell when we really need to buffer records until we actually get some records. this is a consequence (maybe a downside) of my choice to use `timedefinition` to use the window-end time as ""now"" and the grace period as the `suppressduration`. because of this, within the buffering context, even with a `suppressduration` of 0, we might still need to buffer, as the effective timestamp is in the future. thinking through this, we could try instead using the window start as ""now"" and using the window size + grace period as the suppress duration, but offhand it seems this wouldn't work too well with sessionwindows (or other variable-sized windows). so instead what i chose to do is just do a lightweight check when i need the buffer and initialize it if it hasn't already been. i could even move the `if buffer == null` to right here, and jit branch prediction would ensure this lazy check is almost zero after buffer gets initialized. some alternatives: 1. discard the optimization and just always initialize it, in case i need it. 2. junk the (maybe unnecessarily) flexible `timedefinition` function and instead just use a ""time strategy"" enum that tells the processor whether it should use record time or window-end time: in the former case, if the duration is zero, we know we'll never need a buffer. if it's > zero, we'll probably need one. in the latter case, we'll probably need a buffer, regardless of the suppression duration. wdyt?",0,0.9554976224899292
220413716,5693,vvcephei,2018-09-26T02:54:39Z,"yeah, i think this is a reasonable thing to do. i've been going back and forth on it. the downside of storing it serialized is then we need to deserialize it to emit it. this is a moot point for the (planned) on-disk implementation, but for in-memory it saves some cpu and possibly some gc pressure not to round-trip it through a byte array. as is, we serialize it just once instead of serialize + deserialize. plus we currently discard the produced array immediately, so it's easy on the gc, whereas if we keep it, then we have 3 medium-to-long term objects: the incoming record, the serialized array, and the (deserialized) outgoing record. is this premature optimization? possibly. some other factors to consider: when we send to the changelog, we'll need to serialize it anyway. but i'm planning to send only on `flush` and to keep the changelog buffer compact with a linkedhashmap, so records that get updated or retracted several times within a commit interval would only get serialized once. plus, for this purpose, we still only need the `serialize` side; we could hang onto the produced array after computing the size long enough to send it to the changelogger. for changelogging purposes, we'd only need to deserialize when we recover on startup, not in steady-state operations, so i think it's still more economical to store the records as objects instead of serialized. it is true that there's really no tight correlation between the heap used by an object and the heap used by its serialized form. so at the moment, we're only roughly obeying the size limit. for primitive data, it's probably pretty close, though. i'm open to either way of doing it, but that was my thinking. what say you?",0,0.6672478318214417
220413812,5693,vvcephei,2018-09-26T02:55:41Z,"definitely. should it just be a `kafkaexception`, or something more specific?",0,0.9864407181739807
220415961,5693,vvcephei,2018-09-26T03:16:24Z,"good idea, setting it to null after i use it will make it available for gc. i can guard against null also, but fwiw, i'm not sure how that situation could arise. it's an `illegalstateexception` to invoke `delegate.remove` without an intervening call `delegate.next`. or to call it before `next`. `delegate.next` could return null, but in that case, we'd get an exception in line 69... which i should check for there.",1,0.8380146622657776
220416468,5693,vvcephei,2018-09-26T03:21:03Z,"probably not. i don't think this can happen unless this buffer is used across threads (which shouldn't happen), or unless we screw up the implementation in the future (which we could do in any number of ways, it doesn't mean we need guards everywhere). wdyt?",0,0.9511240720748901
220416859,5693,vvcephei,2018-09-26T03:24:51Z,i think you're spot on. i'll check it out.,1,0.9740440845489502
220424615,5693,vvcephei,2018-09-26T04:38:31Z,i think i like this better than my ideas 2 and 3 above. i'm on the fence about this vs just doing it as a part of `process`. i think we'll probably want to do idea 1 regardless.,1,0.9025759100914001
220435089,5693,mjsax,2018-09-26T06:06:25Z,"compare [a link] and the corresponding pr for more details about punctuation semantics. `topologytestdriver` should not work differently (if it does, it's a bug in the test driver -- behavior must be the same to allow for unit testing -- would be bad if it would behave differently). about the second point: yes, something like this. i did not think this through. maybe it's also ""good enough"" to have something more coarse grained for first release. going with ""manual punctuation"" with ""process"" might also be a good first approach -- might still be better than `1ms` punctuation from an overhead point of view (of course, depends on the throughput... 1ms == 1000 records/second/task...)",0,0.9748550057411194
220435537,5693,mjsax,2018-09-26T06:09:25Z,hard to say -- jit branch prediction might make my concern invalid -- it's just because it's on the hot code path. would be good to get input from and,0,0.8397484421730042
220435742,5693,mjsax,2018-09-26T06:10:44Z,"also, we should avoid pre-mature optimization...",0,0.9926103949546814
220436580,5693,mjsax,2018-09-26T06:16:03Z,"agree with all trade-offs you mention. for ktable caches, we also went to storing `byte[]` to obey the size config. also note, we don't need to deserialize all byte[] arrays, but only on eviction -- if we have a lot of suppression. many byte[] arrays would never the deserialized but overwritten. depending on throughput and number if unique keys, this might happen quickly enough to still be young gen. hard to say. again, more input from and would be helpful. and as above, pre-mature optimization should be avoided. could we do some prototyping and benchmarking of both approaches? not sure if there is enough time. also, it's an internal implementation and if performance becomes an issue, we ca also improve on it in 2.2.",0,0.8466452956199646
220436698,5693,mjsax,2018-09-26T06:16:42Z,i guess `streamexception` or maybe a new sub-class would be a good idea.,0,0.9844802021980286
220437021,5693,mjsax,2018-09-26T06:18:42Z,"i tend to think, that we don't need this guard because a bug that gives multi-threaded access seems to be very unlikely. but it's a personal opinion... my concern again is because this is the hot code path. but i am also ok to keep the check if somebody insists.",0,0.8091474771499634
220437726,5693,mjsax,2018-09-26T06:22:08Z,"ack. see your point that `delegate` does the check for us. i was aware that it would imply incorrect api usage (ie, wrong call order or similar). just wanted to make sure we catch a bug like this -- but seems it would crash anyway even if we don't add a check for `null`.",-1,0.8960403800010681
220585715,5693,vvcephei,2018-09-26T14:26:29Z,"ok, i think the in-`process` approach sounds simple and low-overhead, so i'll do that for starters, and we'll see what we think.",0,0.9723650813102722
220586765,5693,vvcephei,2018-09-26T14:28:52Z,"this is very true: i won't do anything with it right now, but wait for more input (and take care of the other things we discussed)",0,0.9694690108299255
220587434,5693,vvcephei,2018-09-26T14:30:28Z,i also think it's unlikely to be useful. i'll remove it.,0,0.8176116347312927
220675913,5693,bbejeck,2018-09-26T18:32:37Z,i also agree with the semantics for enforcing the time limit.,0,0.9777508974075317
220687788,5693,vvcephei,2018-09-26T19:08:12Z,"ok, i just confirmed that `treemap#entryset().iterator().next()` can never return `null`, but we could theoretically store a null value in the map, which could still throw an npe on this line. i'll guarded against it.",0,0.9914518594741821
220689349,5693,bbejeck,2018-09-26T19:13:22Z,"while i also agree with the trade-offs mentioned by , we can't say exactly what the better approach will be without testing. to me, the bigger savings potential would be in cpu but again we can't say without testing. but we do need to serialize for sending to the changelog, and even if we only send on `flush` and couple that with the fact that a `byte[]` coming in does not always get deserialized due to updates by key. so i'm starting to think to go with either approach will be a wash. so, for now, i'm leaning towards storing `byte[]` 1. that's what we currently use for `ktable`, while that by itself is not enough of a reason, imho we need to be careful about having different approaches for similar issues without a clear, demonstratable reason for doing so. 2. benchmarking will really give us the answers we are looking for, but time is something we don't have right now for getting this into 2.1 3. i could be wrong about this but i think the biggest users of suppression are going to have several updates per key, so as mentions, many of the `byte[] arrays` are going get overwritten.",0,0.9106206893920898
220695412,5693,bbejeck,2018-09-26T19:33:58Z,left over debugging?,0,0.9767894148826599
220695672,5693,bbejeck,2018-09-26T19:34:51Z,+1 for a sub-class of `streamexception`,0,0.5211409330368042
220701301,5693,bbejeck,2018-09-26T19:54:12Z,i think doing it in `process` is a good start as well.,0,0.5279969573020935
220703951,5693,vvcephei,2018-09-26T20:02:12Z,"yeah, i noticed it late. it's gone now.",0,0.9711227416992188
220707349,5693,vvcephei,2018-09-26T20:13:40Z,"ok, it sounds like no one has a super strong performance intuition. i think 's point about uniformity is a good one. if anyone wants to insist on this, i'll change it right now. otherwise, if we're all comfortable making a performance-based decision, i think i'll propose to implement change-logging first and then do a comparative benchmark to make the final call.",1,0.622859001159668
220777672,5693,vvcephei,2018-09-27T02:29:33Z,"i've been mulling this over... it seems like byte arrays is the more normal choice in the code base, so it should be the default until proven otherwise by a performance test. the fact that i made the opposite choice in development is irrelevant. so i'll go ahead and swap it out for byte arrays tomorrow.",0,0.8555818796157837
220953221,5693,bbejeck,2018-09-27T14:44:59Z,can we add two cases to `ktablesuppressprocessortest` to hit this branch? one for the `emit` case and another for the `shut_down`,0,0.9948883652687073
220954471,5693,bbejeck,2018-09-27T14:48:13Z,"we could use a test to hit this branch as well, but imho it's a lower priority than the others mentioned above.",0,0.7384531497955322
220989558,5693,vvcephei,2018-09-27T16:21:32Z,"this line is actually gone now. but if it were still there, i'd agree with you.",0,0.9719430208206177
221031086,5693,bbejeck,2018-09-27T18:31:04Z,"nit: this can be simplified to: `testutils.waitforcondition(() -> driver.state() == kafkastreams.state.error, timeout_ms, ""streams didn't shutdown in error state"");`",0,0.99303138256073
221046943,5693,vvcephei,2018-09-27T19:21:55Z,"ah, right. i looked for something like that, but i was looking in `integrationtestutils`. thanks.",1,0.9442511200904846
221048082,5693,vvcephei,2018-09-27T19:26:00Z,"ok, i've updated it.",0,0.9932894110679626
221336195,5693,guozhangwang,2018-09-28T18:04:25Z,"could we merge #5521 (i think it is in pretty good shape) and rebase this pr on that? i felt a couple of the changes blew are a bit redundant, e.g. passing in the materializedinternal object as well as its serde fields.",0,0.8871098160743713
221346202,5693,guozhangwang,2018-09-28T18:41:04Z,"could we move this function to a single class, e.g. `windowedserdes` to avoid duplicates (we have the same function in `sessionwindowedkstreamimpl.java`). btw in #5521 i just inlined each call, but i think extracting it is also fine.",0,0.9932739734649658
221346600,5693,guozhangwang,2018-09-28T18:42:16Z,"why only passing the windows object (for its length) here, but not in other callers below?",0,0.9841501116752625
221347082,5693,guozhangwang,2018-09-28T18:44:00Z,this reminds me of the `lrucacheentry` class used for caching.. could we consolidate these two?,0,0.9935635328292847
221348235,5693,guozhangwang,2018-09-28T18:48:15Z,"can we just use `org.apache.kafka.streams.processor.internals.stamped`? they seem very similar (feel free to rename the class if you like other names better: since it is internal classes, we can change it whenever we want.)",0,0.9911710619926453
221350777,5693,guozhangwang,2018-09-28T18:57:17Z,do we assume we will only remove the head of the iterator? if not i'm not clear why we can simply set the mintimestamp as the next key's timestamp.,0,0.9768155813217163
221351979,5693,guozhangwang,2018-09-28T19:01:31Z,edit: it seems the above assumption is true from the other classes. in this case could we guard against the unexpected case if there are un-deleted entries before the current position?,0,0.9904246926307678
221352155,5693,guozhangwang,2018-09-28T19:02:14Z,nit: i'd suggest putting the size calculation of `contextualrecord` inside the `contextualrecord` class instead of in this class.,0,0.9906761646270752
221376160,5693,guozhangwang,2018-09-28T20:42:21Z,do we ever expect the passed in not-null valueserde is a `fullchangeserde` already? if not we should wrap it with `fullchangeserde` still.,0,0.9928070306777954
221377817,5693,guozhangwang,2018-09-28T20:49:51Z,"we've encountered some issues related to the ordering of this before: [a link] could you read that ticket and double check if flush-first-remove-later would not cause any issues for re-entrant puts on the same buffer (say, if we have a loop in the topology)?",0,0.99220871925354
221378172,5693,guozhangwang,2018-09-28T20:51:25Z,"should we clear the buffer upon closing? maybe it does not make a difference on correctness, but would it worthy for performance?",0,0.9840003848075867
221380146,5693,vvcephei,2018-09-28T21:00:17Z,"the one in sessionwindowedkstreamimpl is actually different (wraps it with a sessionwindowedserde). fwiw, i think inlining it is actually preferable to extracting it to a ""common"" location if it's actually just going to have one use.",0,0.9895179867744446
221380482,5693,vvcephei,2018-09-28T21:01:45Z,this was an oversight. thanks for the catch!,1,0.9865227341651917
221381920,5693,vvcephei,2018-09-28T21:08:17Z,"it is similar, but the lrucacheentry tracks `isdirty` that would be confusing in this context, so i wouldn't use lrucacheentry here, but we could go the other way and make lrucacheentry wrap contextualrecord instead of storing the value + context itself. let me know if this sounds good to you... i'll go ahead and optimistically code it up.",0,0.9245739579200745
221382215,5693,vvcephei,2018-09-28T21:10:01Z,"yeah, this sounds good.",1,0.8054335117340088
221384089,5693,vvcephei,2018-09-28T21:19:35Z,"hmm. actually, stamped has unusual implementations of equals, hashcode, and compareto. they all disregard the stamped value and are only determined by the timestamp... so, stamped won't provide the semantics we need from timekey, and i'm afraid to change the equals/hashcode/compareto of stamped and messing up _its_ semantics... wdyt?",-1,0.9303574562072754
221384963,5693,vvcephei,2018-09-28T21:24:08Z,"aaah, yes. this min-timestamp update does depend on always removing the head of the iterator. i'll fix it. thanks.",1,0.980496346950531
221386195,5693,vvcephei,2018-09-28T21:31:16Z,"this computation makes use of the fact that this reference is a `contextualrecord `, the value type is generic in contextualrecord. of course, this is the only usage of that class, so, i could just build the `byte[]` value type into contextualrecord. but i'm slightly in favor of keeping it as-is so we can use contextualrecord in other contexts where we need both the value (not serialized) and the context in the future. wdyt?",0,0.9800630807876587
221387849,5693,vvcephei,2018-09-28T21:39:38Z,"this would mean that they have configured the `default.value.serde` as a fullchangeserde, which is in the `internals` package. nevertheless, it doesn't hurt to guard it. will do.",0,0.9938480257987976
221389162,5693,guozhangwang,2018-09-28T21:46:57Z,"i meant to have `contextualrecord` contains its only computesize() function which caluclates the size of bytes ""except"" the value size, which can then be called by this function, and here we only need to calculate the key size and value size plus whatever returned from `contextualrecord#computesize`. anyways, it is a nit comment and i do not feel strong about it.",-1,0.9480806589126587
221389407,5693,guozhangwang,2018-09-28T21:48:17Z,"yeah i point is that is seems ""impossible"" that the passed in serde will be a `fullchangeserde` but just the inner serde used for `fullchangeserde`, so we should always wrap (either the default one from config, or the inherited one) with the `fullchangeserde`, right?",0,0.9821975827217102
221390374,5693,guozhangwang,2018-09-28T21:54:10Z,"do we need to require value ordering for `timekey` here? i thought it is not required as they are not following offset ordering to break ties anyways, right?",0,0.9888153672218323
221390459,5693,guozhangwang,2018-09-28T21:54:38Z,`make lrucacheentry wrap contextualrecord` yeah that sounds good.,0,0.9212037920951843
221390529,5693,guozhangwang,2018-09-28T21:55:07Z,ack.,0,0.5866091847419739
221391967,5693,vvcephei,2018-09-28T22:03:46Z,"interesting! that issue seems to be cache-specific: that two subsequent processors can be backed by the same cache (as in the join case). i don't think loops are generally allowed in the subtopology, are they? if so, this code would indeed result in an infinite loop or possibly a concurrent modification exception. i was concerned that the remove might be sent to the buffer's changelog record collector and maybe sent to the broker, and then some exception might happen before the forward, resulting in the record being forgotten upon restart. i looked at some other processors, and they tend to do (logged) store operations first and then forward last. but then again, normal operations are forwarding a value that's a direct consequence of processing the _current_ record, which wouldn't have been committed and would therefore get re-processed upon restart. but the buffer is forwarding some older record, which has already been committed. reprocessing the new record (which caused the eviction the first time) won't cause us to remember the old record, which we were supposed to emit. under eos, if we crash after the changelog update but before the forward, we'll be fine because the changelog update won't be visible (it'll be in an aborted transaction) on restart, so the buffer will go back to it's correct starting point for reprocessing the new record. if we can't be sure that streams subtopologies are acyclic, then i reckon we'd better swap these two lines and tell people they'd better use eos if they want to be protected from all crash corruption (which i think is true anyway). otherwise, if subtopologies are acyclic, then i think it's better to leave it as is. wdyt?",1,0.5140933394432068
221392110,5693,vvcephei,2018-09-28T22:04:40Z,"yeah, i wasn't sure. i'll go ahead and do it.",0,0.9674569964408875
221392505,5693,vvcephei,2018-09-28T22:07:08Z,"actually, let's defer this to part 4, where the buffer becomes a proper store, and has its own `close()` method.",0,0.9909515380859375
221393704,5693,vvcephei,2018-09-28T22:15:25Z,"i don't _think_ that will work... `comparable` requires a total ordering and also specifies that `a.compareto(b) == 0` iff `a.equals(b)`, which in turn requires that `a.hashcode() == b.hashcode()`. but this would prevent us from inserting two different keys with the same time into our buffer map. it doesn't seem like `stamped` is suitable for map keys or set entries for this reason.",0,0.9535143375396729
221405676,5693,vvcephei,2018-09-28T23:59:18Z,"ok, this is done now.",0,0.9883745908737183
221408442,5693,vvcephei,2018-09-29T00:41:29Z,"ok, i put in a guard. i also refactored the interface to purely evict the head of the buffer while a condition holds, which cleans up the usage quite a bit. let me know what you think.",0,0.9454151391983032
221408530,5693,vvcephei,2018-09-29T00:43:01Z,"since the part of the contextualrecord that isn't the value is just the processorcontext, i just added a `sizebytes()` method there. wdyt?",0,0.9945940375328064
221408651,5693,vvcephei,2018-09-29T00:45:27Z,"oh, i gotcha. the type of valueserde is already a fullchangeserde. in the case of an inherited serde, it gets wrapped in the constructor. the types ensure that the constructor arg is not already a fullchangeserde.",0,0.9454011917114258
221412551,5693,vvcephei,2018-09-29T02:23:50Z,"yes, i think that's a good plan. i agree on the reduncancy, but i wanted to keep the serde-related perturbations to a minimum so we wouldn't distract from the pr.",1,0.8991122841835022
221478048,5693,mjsax,2018-09-30T23:44:40Z,just reviewed #5521 again -- left some more comments.,0,0.9904751181602478
221478098,5693,mjsax,2018-09-30T23:47:24Z,"i actually think that forward before delete is correct. compare: [a link] and the corresponding pr, that we never finished.",0,0.9843155741691589
221492758,5693,mjsax,2018-10-01T04:15:54Z,nit: `castorwrap`,0,0.9944570064544678
221492805,5693,mjsax,2018-10-01T04:16:41Z,why this change? (just for my own education.),0,0.9827572107315063
221493048,5693,mjsax,2018-10-01T04:19:29Z,could we extend `wraporcast` to add a `null` check and return `null` for this case and use it here to make code more readable?,0,0.9930029511451721
221493375,5693,mjsax,2018-10-01T04:24:31Z,"i think we need to call `put` only if `previouskey == null`? ie, we could merge l103 ad l105 into an if-then block? might be more readable?",0,0.9905005097389221
221493496,5693,mjsax,2018-10-01T04:26:03Z,"this check for `previouskey == null` could be merged with the check from above? (it's hot code path, so might be worth to unify.)",0,0.9942139983177185
221493640,5693,mjsax,2018-10-01T04:28:03Z,different thought: why do we need to call `remove` above explicitly? `put` would return the old/replace value anyway if there is any -- would avoid one tree-traversal?,0,0.9839099645614624
221493984,5693,mjsax,2018-10-01T04:32:40Z,"i don't see the advantage of using generics in `contextualrecord` is it's only used once with `byte[]` types. as generic types are lost after compilation, i would prefer to remove the generic if not needed (afaik, generics have some runtime overhead as the compiler needs to insert casts that are evaluate during runtime.)",0,0.9738035798072815
221494361,5693,mjsax,2018-10-01T04:38:14Z,"this value should only be `0` or `1` -- maybe use a boolean instead? also wondering, if we need this at all? have the gut feeling, that `last != null` and `nextcount != 0` is the same thing?",0,0.9809454679489136
221494851,5693,mjsax,2018-10-01T04:45:43Z,"if `next()` is called twice in a row without `remove()` in between, `nextcount` could be larger than 1 and thus we should throw -- seems that the current code enforces a `next-remove-next-remove...` pattern? if yes, why?",0,0.9918993711471558
221494894,5693,mjsax,2018-10-01T04:46:12Z,should this be set to `1` instead of incrementing?,0,0.9921999573707581
221495017,5693,mjsax,2018-10-01T04:48:07Z,"see my other comments -- it's still unclear from the code that we want to enforce `next-remove-...` pattern -- might also be worth to add a javadoc to the iterator about correct usage, even if it's an internal class only.",0,0.9920552372932434
221496039,5693,mjsax,2018-10-01T05:02:37Z,"i am wondering, if `suppressdurationmillis` is a valid config? i had problem to understand this part in the original pr already. can you explain once more? (maybe it's an indicator that we should add a comment explaining the cases we are handling here?)",0,0.9688711762428284
221496235,5693,mjsax,2018-10-01T05:05:34Z,`and` -> `or` or `and/or` ?,0,0.9899505376815796
221496719,5693,mjsax,2018-10-01T05:11:06Z,"should we inline this method? also, i am wondering if we could/should call this unconditionally? if `overcapacity()` is true, we might or might not expire records here (same if called unconditionally). if `overcapacity()` is false, but `buffer.mintimestamp() <= expirytime` is true, we would expire record (same if called unconditionally). if both are false, `drainexpriredrecords()` would not expire anything if called either, because it passed in the corresponding boolean predicate anyway? ie, i _think_ we can just remove the `if` condition and execute the `then` part always",0,0.9891670942306519
221496860,5693,mjsax,2018-10-01T05:13:00Z,nit: `next` -> `evictedrecord` or just `record` ?,0,0.9912381768226624
221497240,5693,mjsax,2018-10-01T05:17:31Z,nit: `deserializedkey` -> `key` and `key` -> `rawkey` ?,0,0.9926974177360535
221497342,5693,mjsax,2018-10-01T05:18:50Z,should we cast here and keep `bufferconfig bufferconfig` as member type?,0,0.9952577948570251
221497656,5693,mjsax,2018-10-01T05:22:47Z,"while i think, it's semantically fine, it might be nice to get the same eviction behavior for a reprocessing use-case... i am also realizing, that `timekey` is actually always used with `bytes` -- thus, i would recommend to remove the generic type, and exploit that `bytes` implements `comparable` already.",0,0.9537103176116943
221498033,5693,mjsax,2018-10-01T05:27:24Z,"`key` is always `bytes()`, thus, this output is not very useful. can we can hold on the deserialized for human readable output here?",0,0.9911627769470215
221498255,5693,mjsax,2018-10-01T05:30:19Z,"each java object has a natural overhead -- might be worth to add this here? would need to search the internet how many bytes, however, we would have it for `processorrecordcontext` itself, as well as `topic`, `headers` (including it's nested `header` objects).",0,0.9927585124969482
221498409,5693,mjsax,2018-10-01T05:32:06Z,"a `string` also store the length (it's a `char[]` internally) -- should we add 4 more bytes here? also, has a `char[]` similar overhead than a regular object?",0,0.9940140843391418
221498827,5693,mjsax,2018-10-01T05:36:55Z,`value` is always `byte[]` -- can we get a handle on the deserializer to get human readable output here? (one more reason to avoid generic if not necessary -- those issues slip easily with missing type information).,0,0.9941562414169312
221498993,5693,mjsax,2018-10-01T05:39:01Z,"should we add 4 byte to store array size? also, do we have object overhead for an array type?",0,0.9940580129623413
221499058,5693,mjsax,2018-10-01T05:39:49Z,should we add object overhead for `context` itself? (might be included in `sizebytes()` if we update is accordingly thought),0,0.9944778680801392
221640642,5693,vvcephei,2018-10-01T14:55:34Z,"it's just evidence of my mental slowness... in the prior pr, guozhang pointed out that my calling `buffer.array()` was incorrect, since the backing array isn't guaranteed to be exactly within the bounds we allocated. i fixed it at the time by delegating to the `bytebufferserializer`, which handles this. later on i realized that there is a more efficient solution available. by pre-creating the backing array and wrapping it, we know that `buffer.array()` returns what we needed. no need for the more general handling logic in `bytebufferserializer`.",0,0.6899178624153137
221640973,5693,vvcephei,2018-10-01T14:56:22Z,i can and will.,0,0.9464218020439148
221642753,5693,vvcephei,2018-10-01T15:00:59Z,"i've added that check because `context.valueserde()` (called elsewhere) could return null. if it's ok with you, though, i prefer the current code right here. this code ensures that `valserde` is of the correct type (notice that no casting is necessary). in general, i think we should avoid casting unless we actually need it, as it makes regressions harder to catch.",0,0.9805338382720947
221646019,5693,vvcephei,2018-10-01T15:09:46Z,"this is true about `put`, but we still need to choose a key to insert into `sortedmap`. if i don't declare the `nextkey` variable, i need to have a bunch of redundant code in the if and else blocks: [code block] imho, this is less readable than the linear version where we just reuse or construct the key in line 103.",0,0.7322206497192383
221646437,5693,vvcephei,2018-10-01T15:10:56Z,"but if, after looking at it, you prefer the branching version, i'll change it.",0,0.9923192858695984
221648943,5693,vvcephei,2018-10-01T15:17:41Z,"please see my comment above. i agree it's more efficient to have just one branch, but i do think this version is easier to follow. regardless, you have a fresher perspective. if you prefer the branching version above, i'm happy to change it.",1,0.9536225199699402
221650193,5693,vvcephei,2018-10-01T15:21:04Z,"ok, apparently the way to convince me is to point out three reasons... i'll switch it out for the branching version.",0,0.9813960194587708
221655192,5693,vvcephei,2018-10-01T15:34:50Z,i didn't consider this runtime overhead. i'll go ahead and inline the generic type.,0,0.9855822920799255
221655988,5693,vvcephei,2018-10-01T15:37:06Z,"it is ok to call next multiple times, but if you do, you can't subsequently call remove. i don't think that we can learn whether next has been called twice by looking at any of the other fields we're maintaining.",0,0.9883109927177429
221661624,5693,vvcephei,2018-10-01T15:52:56Z,"yes. this is an optimization to support maximal efficiency in: * removing some unknown number records, each of which is currently the minimum in the buffer when it gets removed * maintaining a correct value of `mintimestamp`. as far as we know right now, we will only ever need to remove the min records from the buffer. i.e., i don't think we need to iterate for a while and *then* remove. but we may need to remove more than one record, and we won't know if we need to remove the *next* record until after we remove *this* record. previously, i didn't have this guard, but in that case, we can't just set `mintimestamp` to the buffer time of the next record upon removing. because we don't know whether the record we just removed is the leftmost record in the tree without traversing it again. because of that, i had to avoid updating `mintimestamp` until you close the iterator (and therefore it had to be a `closeableiterator`). this means that the ktablesuppressprocessor couldn't just keep popping records while the mintimestamp was less than the desired boundary, it had to get the ""buffer time"" from the timekey and make its decision from that. all in all, it's way cleaner this way, with the expense of that one extra guard. i could go one step further and make it like a ""predicated, consuming iterator"", which just pops records out as long as the predicate condition is true. do you think this would be more straightforward?",0,0.9634965062141418
221661740,5693,vvcephei,2018-10-01T15:53:15Z,no; see the reply above.,0,0.9834095239639282
221662088,5693,vvcephei,2018-10-01T15:54:14Z,"from your later comments, it seems like you would say it would be more straightforward. i'll go ahead and simplify it.",0,0.9848769903182983
221667743,5693,vvcephei,2018-10-01T16:11:01Z,i think the complexity is due to my over-flexible time definition. i'll drop it and then we'll see if it's still non-obvious what's going on here.,0,0.9782990217208862
221690047,5693,mjsax,2018-10-01T17:22:54Z,i guess it's personal taste -- don't insist on a change.,0,0.8415504693984985
221690536,5693,mjsax,2018-10-01T17:24:31Z,"think, even without the branching, this `remove` and the `put` below should be merged.",0,0.9900627732276917
221690691,5693,vvcephei,2018-10-01T17:25:03Z,"ok, i've decided that this optimization is premature and complex, so i've gone ahead and simplified it. (i'll let you know when i push the update). i've also updated the timedefinition class to be less flexible (although it doesn't really simplify this particular method). fwiw, though i think that ""suppress for 0ms"" is a perfectly valid way to disable a suppression operation. note that this is also what we wind up with when you use final-results on a windowed stream with graceperiod set to 0ms, which also seems perfectly fine.",0,0.885918140411377
221691013,5693,vvcephei,2018-10-01T17:26:10Z,i added the missing punctuation instead.,0,0.9888995289802551
221691019,5693,mjsax,2018-10-01T17:26:11Z,this breaks the iterator contract and should be well documented,0,0.9925803542137146
221692098,5693,vvcephei,2018-10-01T17:29:27Z,"i wanted to save on setting up the iterator, but your comment made me realize we can and should do that with an initial `if (predicate.get())` inside `evictwhile`. i did this and removed the condition as you recommended.",0,0.9906651973724365
221692337,5693,vvcephei,2018-10-01T17:30:09Z,good point. i called it `toemit`.,1,0.9848628640174866
221693619,5693,vvcephei,2018-10-01T17:34:29Z,"this made me realize that i named them `impl` when i meant to name them `internal`. in other words, both `suppressedinternal` and `bufferconfiginternal` to indicate that these are the internal interfaces.",0,0.9914560914039612
221694264,5693,vvcephei,2018-10-01T17:36:43Z,i didn't notice that. that is handy.,1,0.9583826065063477
221696756,5693,vvcephei,2018-10-01T17:44:39Z,"i agree that this is an under-estimate, but i don't think there's much point in being exact. the overhead is dependent on the jvm implementation, so we'd have to detect the jvm and maintain a mapping for each different implementation. even then, we don't know how much extra memory we're using in the various garbage collectors, of which there are now three different implementations in the oracle jdk alone... i'd rather just make the best effort we reasonably can to live more-or-less within the desired boundary. for example, storing the `byte[]` value is much closer than storing the object. but beyond that, we get into diminishing returns for quickly increasing complexity.",0,0.8904759883880615
221697255,5693,vvcephei,2018-10-01T17:46:16Z,"i believe arrays also store their types. but again, we are getting into jvm implementation details. there are too many jvm implementations for us to be expected to worry about this, imho.",0,0.9162808656692505
221698960,5693,vvcephei,2018-10-01T17:51:38Z,"i didn't consider this overhead, and agree it would be good to get rid of it.",0,0.8984859585762024
221699155,5693,vvcephei,2018-10-01T17:52:12Z,"i don't think the record needs to know how to deserialize itself. since `tostring` is only for debugging, i'm fine printing out the `arrays.tostring` summary of the value. if we wanted to print out the value in a log message, we would format it more specifically (including a deserialization if desired). that said, i will go ahead and get rid of the generic type.",0,0.9759445190429688
221701912,5693,vvcephei,2018-10-01T18:00:46Z,as above.,0,0.9881609678268433
221702092,5693,vvcephei,2018-10-01T18:01:16Z,"it would be the responsibility of the context to account for its own overhead, but see my comments above.",0,0.9857041239738464
221756263,5693,vvcephei,2018-10-01T21:04:23Z,"roger that. it's moot now, since i've removed this iterator entirely.",0,0.967860996723175
221757521,5693,vvcephei,2018-10-01T21:09:03Z,"i think in sum, your points elevate it beyond personal taste. i've gone ahead and done the branching. after a little cleanup, it's not too shabby anyway.",1,0.8949543833732605
221792731,5693,vvcephei,2018-10-02T00:01:39Z,"i had to add these so that suppress doesn't ""forget"" the window end time when it round-trips the record.",0,0.9804698824882507
221793798,5693,mjsax,2018-10-02T00:08:26Z,ack. that's fair. the existing caches also use rough estimates only. (might be interesting how much we are off though... but this could be a follow up improvement.),0,0.7781053185462952
221794070,5693,mjsax,2018-10-02T00:10:24Z,"my point is, that even for debugging it's not useful to print `byte[]` -- my argument is, to either ""fix this"" or don't overwrite `tostring()` at all.",0,0.9832658767700195
221794878,5693,mjsax,2018-10-02T00:16:14Z,is this mentioned in the kip? it's a public api change.,0,0.9946646690368652
221795634,5693,mjsax,2018-10-02T00:21:39Z,not sure if this is the best way to tack it? requires public api change.,0,0.888786792755127
221796847,5693,mjsax,2018-10-02T00:29:57Z,i guess we can remove this generics?,0,0.9859602451324463
221797359,5693,mjsax,2018-10-02T00:33:39Z,`nextkey.time()` -> `time`,0,0.9919326901435852
221797795,5693,mjsax,2018-10-02T00:37:11Z,"should we compute `buffertime` within `buffer()` -- no need to pass it in, as both `internalprocessorcontext` and `key` are available there, too?",0,0.9941123127937317
221797893,5693,mjsax,2018-10-02T00:38:08Z,so we need this here? no need to pass it into `enforceconstraints()` imho.,0,0.9789777994155884
221798063,5693,mjsax,2018-10-02T00:39:28Z,should this be `<` instead of `<=` ?,0,0.9923784732818604
221798280,5693,mjsax,2018-10-02T00:41:14Z,guess we can remove variable `key` (only used once).,0,0.9879574179649353
221798347,5693,mjsax,2018-10-02T00:41:45Z,`key1` -> `key` and `key.get()` -> `toemit.key.get()`,0,0.9917795062065125
221798908,5693,mjsax,2018-10-02T00:46:05Z,"similar argument as for `byte[]` value: of course, here we still get the `time` information, but the `bytes` `key` is useless.",0,0.990233302116394
221800768,5693,mjsax,2018-10-02T01:00:20Z,why remove this comment? seems to be valid?,0,0.9893364906311035
221800971,5693,mjsax,2018-10-02T01:01:37Z,"the change makes sense -- test was bubby before, but we did not notice at it threw anyway?",0,0.9887508749961853
221801525,5693,mjsax,2018-10-02T01:06:01Z,what was the original intend of this part? and why don't we need it?,0,0.9906989932060242
221802094,5693,mjsax,2018-10-02T01:10:39Z,why `timestamp - 1l` ?,0,0.9914793372154236
221805529,5693,vvcephei,2018-10-02T01:38:54Z,"ah, no. when i did this before, i did it differently to keep it private. i thought this was a better way, but overlooked the public-ness of it. i'll go back to private mode.",0,0.9085209369659424
221805956,5693,vvcephei,2018-10-02T01:43:11Z,"ah, yeah, it was previously used also here, but it's not needed anymore. good catch.",1,0.9880377054214478
221805975,5693,vvcephei,2018-10-02T01:43:21Z,same here. thanks!,1,0.986280083656311
221806806,5693,vvcephei,2018-10-02T01:49:57Z,"it wouldn't be wrong, but i think `<=` is also right, and it's a tighter bound. let's say we have buffered an event with time 10 at stream time 10 and the suppressduration is 1. the expiry time is `10-1 = 9`. mintimestamp is 10, and `10 <= 9` is false, so we don't evict. then, we get an event with time 11 at stream time 11. now, the expiry time is `11-1=10`. mintimestamp is still 10, but now the check is `10 <= 10`, so we evict that first event. i think this matches up to the intention of saying ""suppress for 1 ms"".",0,0.9801944494247437
221807188,5693,vvcephei,2018-10-02T01:52:48Z,"it's not anymore. now, we buffer the new event before we enforce the buffer constraints, so we return the more intuitive most recent state of `""v1"", 1l, 2l` right away, instead of later on.",0,0.9912137389183044
221808272,5693,vvcephei,2018-10-02T02:01:52Z,"we didn't throw it away before, just emitted it later on. this is what the comment i removed was explaining.",0,0.9917574524879456
221808394,5693,vvcephei,2018-10-02T02:02:54Z,"when we enforced constraints before buffering, we needed one extra tick to flush everything out. now that we buffer first, everything happens more promptly, so we don't need this last cycle to witness all the results we're looking for.",0,0.9845976829528809
221808532,5693,vvcephei,2018-10-02T02:04:09Z,"it doesn't matter for anything, it just seemed weird to have window start == window end. the window end is the time that matters for this test, which is why i made it the baseline.",-1,0.976560652256012
221811667,5693,mjsax,2018-10-02T02:34:28Z,ack,0,0.9149930477142334
221812576,5693,mjsax,2018-10-02T02:44:07Z,"we set record timestamp to `timestamp` -- thus, the record will be put in window `[timestamp, timestamp+1)`, right? seems weird to use the wrong window imho. or do i miss something?",-1,0.9843571782112122
221813111,5693,vvcephei,2018-10-02T02:49:17Z,"ok, i wasn't thinking about it like this. it makes sense.",0,0.9685630202293396
221813409,5693,mjsax,2018-10-02T02:52:09Z,i see. the comment focus on the second `v1` -- i applied it to the third `v1`. seems the comment was ambiguous :),1,0.9715248346328735
221813838,5693,vvcephei,2018-10-02T02:56:43Z,good thing it's gone!,1,0.975138783454895
221821211,5693,guozhangwang,2018-10-02T04:13:10Z,makes sense.,0,0.9735017418861389
231290134,5821,lindong28,2018-11-06T20:58:29Z,exception and its corresponding error code is part of public interface. can you update design doc as appropriate and reply to the email thread with this change?,0,0.9955280423164368
231292242,5821,lindong28,2018-11-06T21:05:09Z,"currently all epoch fields (e.g. controller epoch, leader epoch) uses int32. would it be more consistent and space efficient to use int32 for broker epoch as well? max int32 value is more than 2 billion which seems large enough for broker epoch. if we change the type of broker epoch from int64 to int32, can you also update the design doc and reply to the email thread?",0,0.9929470419883728
231294160,5821,lindong28,2018-11-06T21:11:32Z,"since we are modifying the schema here, it may be a good time to use the new way of specification as shown in fetchrequest for consistency. then we can use `struct.getorelse(...)` here. it is specifically preferred to make this refactor together with the change in this pr if the existing code footprint is small (e.g. `stopreplicarequest.java`).",0,0.9924131035804749
231294372,5821,lindong28,2018-11-06T21:12:14Z,nits: can you add an empty line between these two methods?,0,0.994030773639679
231300243,5821,lindong28,2018-11-06T21:30:41Z,nits: it seems a bit more consistent with the existing style (e.g. `produce_response_v4 = produce_response_v3` in produceresponse.java) to do `leader_and_isr_response_v2 = leader_and_isr_response_v1`. it is probably more readable as well since we typically want to see how the new schema compares with the previous version.,0,0.9768154621124268
231304928,5821,lindong28,2018-11-06T21:45:58Z,"nits: for consistency with the exiting style, can we use `update_metadata_response_v5 = update_metadata_response_v4`?",0,0.9946849346160889
231306661,5821,lindong28,2018-11-06T21:51:11Z,"it seems that even if we do this filter, the broker may still go offline after this step and before controller sends the request to the broker. so we still need to have this filter logic later. could you explain the benefit of having this logic here?",0,0.9921776652336121
231319305,5821,lindong28,2018-11-06T22:33:29Z,would this be more consistent and readable to move this logic to the class `controlledshutdown`? this can also ensure that the `brokerepochscache` is accessed only by the controller event thread after controller is initialized.,0,0.992948055267334
231323345,5821,lindong28,2018-11-06T22:48:40Z,nits: there is one extra space after `=`,0,0.9933379888534546
231329438,5821,lindong28,2018-11-06T23:13:47Z,"currently `brokerepoch` is a `var` and its internal state is also immutable. it is generally preferred to allow mutation in only one way. since `brokerepoch` has its initial value from `kafkaserver.startup()` and it can be updated multiple times in `registerbrokerandreelect`, would it make sense to define ` var brokerepoch: int` in `kafkacontroller` similar to the existing `brokerinfo` field. `kafkaserver.startup()` can get the initial value of the broker epoch as integer and passes it to the `kafkacontroller` constructor as `initialbrokerepoch`. this approach seems much simpler and we would not need the helper class `brokerepoch`.",0,0.9923756718635559
231332131,5821,lindong28,2018-11-06T23:26:01Z,"i am wondering if it will be more intuitive and cleaner to move the logic of checking broker epoch from replicamanager to kafkaapis. currently there is already logic such as `controller.isactive` in kafkaapis which is similar to the logic of checking broker epoch. and if we do that, we can keep replicamanager unchanged. kafkaapis can first compare the epoch from the stoprepliarequest with the epoch in `controller.brokerepoch` before invoking e.g. `replicamanager.stopreplicas(...)`. controller can have api such as `controller.isactivebrokerepoch(epoch)` to make the logic more explicit.",0,0.9589740037918091
231339976,5821,lindong28,2018-11-07T00:02:54Z,"nits: `zookeepr` has typo. would the message `s""$request does not need controller epoch check""` be more appropriate here?",0,0.982644259929657
231343743,5821,lindong28,2018-11-07T00:23:49Z,"now we have three methods named `retryrequestsuntilconnected(...)`. i am wondering if it would be more readable to keep the number still as two, one for single request and the other for sequence of requests. one thing that may be confusing to the reader is that, `retryrequestsuntilconnected[req <: asyncrequest](requests: seq[req])` does not take `expectedcontrollerzkversion` as parameter and thus it is not clear what is the expected behavior with controller epoch check in this method.",0,0.9386151432991028
231344408,5821,lindong28,2018-11-07T00:27:31Z,"can we also throw `illegalstateexception` if `zkopresults` does not match the pattern `seq(zkopresult(checkop: checkop, checkopresult), zkopresult)`?",0,0.9939351677894592
231348543,5821,lindong28,2018-11-07T00:50:29Z,"now the patch is not longer using zookeeper transaction, will there be issue if e.g. controller znode is created but the controller epoch is not incremented?",0,0.9934252500534058
231352782,5821,hzxa21,2018-11-07T01:14:05Z,the reason why we use int64 for broker epoch is that the `czxid` we get back from zookeeper is of int64 type. i think it is not a good idea to convert it into int32 because we may lose the globally unique and monotonically increasing guarantee.,0,0.972274661064148
231365666,5821,hzxa21,2018-11-07T02:45:38Z,"after introducing broker epoch, we need to fill in the broker epoch we want to use for the control request we send out. only brokers in `controllercontext.liveorshuttingdownbrokerids` will have a entry in the `controllercontext.brokerepochscache`. the benefit of this change is to ensure that we can always get back the broker epoch from the cache in controller context when constructing the control requests. we can instead add extra logic in `controllerchannelmanager.sendrequeststobrokers` to check the existence of the broker epoch when constructing the request but i think it is cleaner and easier to reason about the code with this change because we will not send out requests to brokers that are not in `controllercontext.liveorshuttingdownbrokerids` anyway. it is true that the broker can become offline and this will cause requestsendthread to fail to send out the request if controller doesn't process the broker change event before requestsendthread sending out the request to the offline broker. this change will not affect this behavior and does not aim to solve this race condition. this change only acts as a pre-filter to ensure we can always construct the control request with broker epoch. whether we can actually send out the request is a separate issue.",0,0.9351283311843872
231397289,5821,lindong28,2018-11-07T06:58:52Z,"sounds good. i am not sure when brokerid in the `brokerids` will be negative. since we don't expect any brokerid in `liveorshuttingdownbrokerids` to be negative, can we just do `brokerids.filter(controllercontext.liveorshuttingdownbrokerids.contains)` to simplify the code here? same for `addstopreplicarequestforbrokers()` and `addupdatemetadatarequestforbrokers()`.",1,0.8137935996055603
231397355,5821,lindong28,2018-11-07T06:59:11Z,yeah i forgot this reason. sounds good.,0,0.6366318464279175
231609250,5821,hzxa21,2018-11-07T17:47:41Z,that is a good point. i think we can simplify it.,1,0.9230231642723083
231624498,5821,hzxa21,2018-11-07T18:28:48Z,thanks for the suggestion. it makes sense and i will move it.,1,0.9815171360969543
231629225,5821,hzxa21,2018-11-07T18:42:53Z,"currently `brokerepoch` can be updated in `kafkaserver.startup()` as well as `registerbrokerandreelect` in the controller, and it can be read by `replicamanager` in order to reject outdated control requests. if we store `brokerepoch` in `kafkacontroller`, it requires passing the `kafkacontroller` object to `replicamanager` just for reading `brokerepoch`. i think use a helper class is simpler in this case. what do you think?",0,0.9854527115821838
231629808,5821,hzxa21,2018-11-07T18:44:39Z,"miss your next comment. if we do the check in `kafkaapis`, then you are right. please ignore the comment i just wrote down.",0,0.9506528377532959
231629969,5821,hzxa21,2018-11-07T18:45:06Z,makes sense. that is a good point.,1,0.9859955906867981
231713300,5821,hzxa21,2018-11-07T23:09:38Z,"i am a little bit confused about your concern. there is no controller epoch check in `retryrequestsuntilconnected[req <: asyncrequest](requests: seq[req])` because this is the raw method that only does send requests as well as receive responses, and the epoch check happens outside of this method when calling `wraprequestwithcontrollerepochcheck` and `unwrapresponsewithcontrollerepochcheck`. maybe i understand you wrong, i think there is little confusion here. do you suggest only have `retryrequestsuntilconnected[req <: asyncrequest](requests: seq[req], expectedcontrollerepochzkversion: int)` and `retryrequestsuntilconnected[req <: asyncrequest](request: req, expectedcontrollerepochzkversion: int)`?",0,0.7992901802062988
231724344,5821,hzxa21,2018-11-08T00:02:31Z,it is fine because we are using the zookeeper multi op directly right now. it is essentially the same as using zk transaction so we still provide the same guarantee.,0,0.9794537425041199
232446499,5821,hzxa21,2018-11-10T08:53:01Z,done.,0,0.9897913336753845
232446521,5821,hzxa21,2018-11-10T08:54:07Z,sure. i have adopted the new pattern in all control requests.,0,0.9844791293144226
232446524,5821,hzxa21,2018-11-10T08:54:13Z,fixed.,0,0.9905837774276733
232446526,5821,hzxa21,2018-11-10T08:54:17Z,fixed.,0,0.9905837774276733
232446530,5821,hzxa21,2018-11-10T08:54:22Z,fixed.,0,0.9905837774276733
232446539,5821,hzxa21,2018-11-10T08:54:30Z,done.,0,0.9897913336753845
232446540,5821,hzxa21,2018-11-10T08:54:34Z,done.,0,0.9897913336753845
232446542,5821,hzxa21,2018-11-10T08:54:38Z,fixed.,0,0.9905837774276733
232446547,5821,hzxa21,2018-11-10T08:54:45Z,fixed.,0,0.9905837774276733
232446550,5821,hzxa21,2018-11-10T08:54:49Z,done.,0,0.9897913336753845
232446551,5821,hzxa21,2018-11-10T08:54:54Z,fixed.,0,0.9905837774276733
232446554,5821,hzxa21,2018-11-10T08:55:02Z,sure. done.,0,0.9720492362976074
232477712,5821,lindong28,2018-11-11T08:02:17Z,"the exception name is inconsistent with name specified in kip-380. i feel that it is better to use the `stale_controller_epoch` which suggests that the broker epoch in the request is smaller than the expected value. since we do not expect the epoch in the request to be larger than the expected value, it would be illegalstateexception if the epoch in the request is larger than the expected value.",0,0.98055499792099
232477749,5821,lindong28,2018-11-11T08:04:01Z,nits: can we follow the existing code style and move `brokerepochmismatchexception::new` to a new line?,0,0.9926928281784058
232477941,5821,lindong28,2018-11-11T08:11:11Z,"unlike updatemetadatarequest, this field is named `live_leaders` rather than `live_brokers`.",0,0.9928319454193115
232478024,5821,lindong28,2018-11-11T08:13:45Z,nits: there is an unnecessary space.,0,0.8507452607154846
232479092,5821,lindong28,2018-11-11T08:50:14Z,nits: there is an unnecessary space.,0,0.8507452607154846
232479565,5821,lindong28,2018-11-11T09:07:05Z,"can we do `struct.setifexists(offline_replicas, offlinereplicas.toarray())` here? also, it seems that `setifexists(field.array def, object[] value)` and `setifexists(field.complexarray def, object[] value)` in `struct.java` should only set value if the field exists. can you help fix that?",0,0.9940628409385681
232479847,5821,lindong28,2018-11-11T09:15:25Z,nits: would it be simpler to just do `brokerids.filter(controllercontext.liveorshuttingdownbrokerids.contains)`? the extra variable name does not seem useful here.,0,0.9892320036888123
232480199,5821,lindong28,2018-11-11T09:25:44Z,"we currently uses `controllercontext.brokerepochscache` in `sendrequeststobrokers()` under the assumption that the `leaderandisrrequestmap`, `updatemetadatarequestpartitioninfomap` and `stopreplicarequestmap` only includes brokerid that is defined in `brokerepochscache`. however, the logic to guarantee this is in other methods such as `addupdatemetadatarequestforbrokers`. would it make the code more readable to put these logics closer together in `sendrequeststobrokers()`? we can make the logic even more explicit by filtering the brokerid using `brokerepochscache` rather than `controllercontext.liveorshuttingdownbrokerids` in `sendrequeststobrokers()`.",0,0.9928470253944397
232480419,5821,lindong28,2018-11-11T09:32:08Z,would it be more readable to have method `isbrokerepochstale`? `iscurrentorunknownbrokerepoch` is a bit verbose and it feels a bit weird to look for unknown broker epoch. `isbrokerepochstale` would better match the name of `stalebrokeepochexception`.,-1,0.9205865263938904
232480534,5821,lindong28,2018-11-11T09:34:41Z,would it be simpler to just name the method `brokerepoch`? the variable can be named `_brokerepoch` similar to `_lastcaughtuptimems` in `replica.scala`.,0,0.9927051663398743
232480834,5821,lindong28,2018-11-11T09:42:29Z,currently most variables (e.g. `livebrokersunderlying`) in `controllercontext` provide cached information. it will be a bit inconsistent and confusing if we just put the word `cache` for brokerepoch. can we just name it `brokerepochs`?,0,0.9565944075584412
232480935,5821,lindong28,2018-11-11T09:44:54Z,nits: can we rename `bid` to `brokerid`? `bid` is an english word and currently the existing code does not use `bid` as shortcut for broker id.,0,0.9932492971420288
232481318,5821,lindong28,2018-11-11T09:55:51Z,"the log message itself raises concerns for user/developer without explaining why it is at warning rather than error level. can we add comment that says why this is ok? and since we expect this to happen normally when broker is restarted quickly, i am not sure we need to log it at warning level. we can ask other reviewer to comment on this later.",0,0.8521263003349304
232481594,5821,lindong28,2018-11-11T10:04:18Z,the code can probably be more readable with less nested if/else by doing this: [code block] same for other methods.,0,0.9931040406227112
232481972,5821,lindong28,2018-11-11T10:17:56Z,"the code here is comparing the zkversion with epoch, which seems misleading. also, `expectedcontrollerzkversion < 0`, will `expectedcontrollerzkversion` be anything other than `matchanyversion`? if not, it seems better to explicitly check `expectedcontrollerzkversion == zkversion.matchanyversion`. and if they are not equal, we can throw illegalstateexception if `expectedcontrollerzkversion` is negative.",0,0.9840490818023682
232482145,5821,lindong28,2018-11-11T10:24:33Z,nits: it seems that intellij complains here. can you change it to `getsortedbrokerlist()`.,0,0.9916463494300842
232482175,5821,lindong28,2018-11-11T10:25:54Z,"do we expect `brokeridznode.decode(...).broker` to return null? if not, it may be simpler to just do `some(brokeridznode.decode(brokerid, getdataresponse.data).broker, getdataresponse.stat.getczxid)`.",0,0.9925589561462402
232482475,5821,lindong28,2018-11-11T10:36:38Z,nits: can you add space between `case class` to be consistent with the existing code style?,0,0.9935457110404968
232482769,5821,lindong28,2018-11-11T10:46:07Z,"right, that is what i would suggest to reduce the overloaded methods number from 3 to 2. now looking at it again, the current way also looks good.",0,0.8282884359359741
232516981,5821,hzxa21,2018-11-12T01:37:08Z,that is a good point. i have changed it back to `stale_broker_epoch`. i also move the broker epoch check helper function from `kafkacontroller` to `kafkaapis` and throw `illegalstateexception` when the broker sees the broker epoch in the request larger than the current epoch.,1,0.8425289392471313
232516997,5821,hzxa21,2018-11-12T01:37:19Z,sure. done.,0,0.9720492362976074
232517017,5821,hzxa21,2018-11-12T01:37:31Z,good catch. fixed.,1,0.9934197068214417
232517029,5821,hzxa21,2018-11-12T01:37:37Z,fixed.,0,0.9905837774276733
232517036,5821,hzxa21,2018-11-12T01:37:42Z,fixed.,0,0.9905837774276733
232517050,5821,hzxa21,2018-11-12T01:38:00Z,sure. fixed.,0,0.9815690517425537
232517068,5821,hzxa21,2018-11-12T01:38:20Z,yes. fixed.,0,0.9165666699409485
232517104,5821,hzxa21,2018-11-12T01:38:45Z,good suggestion. done.,1,0.9875546097755432
232517335,5821,hzxa21,2018-11-12T01:41:16Z,i have renamed it and moved this helper function to `kafkaapis` because it will only be called in `kafkaapis` and we will need to throw `illegalstateexception` when the epoch is larger than the expected one. i think it is more readable this way.,0,0.978870153427124
232517345,5821,hzxa21,2018-11-12T01:41:21Z,fixed.,0,0.9905837774276733
232517357,5821,hzxa21,2018-11-12T01:41:28Z,sure. done.,0,0.9720492362976074
232517373,5821,hzxa21,2018-11-12T01:41:38Z,sure. done.,0,0.9720492362976074
232517606,5821,hzxa21,2018-11-12T01:44:49Z,"comments added. when the broker sees stale controller epoch in the request, we also log the message at warning level. so i think it is better to do the same thing for stale broke epoch to keep it more consistent.",0,0.9784749746322632
232517635,5821,hzxa21,2018-11-12T01:45:15Z,that is a good point. thanks for the suggestion. done.,1,0.9911862015724182
232517651,5821,hzxa21,2018-11-12T01:45:23Z,"fixed. btw, i think it is better to throw `illegalargumentexception` if `expectedcontrollerzkversion` is negative.",0,0.989676296710968
232517736,5821,hzxa21,2018-11-12T01:46:39Z,fixed.,0,0.9905837774276733
232517759,5821,hzxa21,2018-11-12T01:46:51Z,good catch. fixed.,1,0.9934197068214417
232517773,5821,hzxa21,2018-11-12T01:46:57Z,done.,0,0.9897913336753845
232555865,5821,lindong28,2018-11-12T07:37:31Z,"it will be practically very rare to have `broker` that is not found in `controllercontext.brokerepochs`. so this trace level logging is probably not useful. my understanding is that we only use trace level logging for something that is almost always triggered. if we do not have good use-case for this trace level logging, can we simplify the code change here by just adding one line (relative to the original code) to filter the key for `leaderandisrrequestmap`. more specifically, we can change the code from [code block] to [code block] same for `updatemetadatarequestpartitioninfomap` and `stopreplicarequestmap`.",0,0.98125159740448
232557832,5821,lindong28,2018-11-12T07:47:19Z,nits: `not equal to current broker epoch` => `smaller than the current broker epoch`. same for other logs.,0,0.9904560446739197
232562259,5821,lindong28,2018-11-12T08:08:05Z,"according to the zookeeper client javadoc, the name in `createresponse` is expected to be `the name of the znode that was created`. also, it is mentioned that `on success, name and path are usually, equal, unless a sequential node has been created`. on the other hand, the javadoc for `createresult` says that, `a result from a create operation. this kind of result allows the path to be retrieved since the create might have been a sequential create`. we need to make sure that the `createresult.path` has the same value as the original value of the `name` in `createresponse` when a sequential node is created. the javadoc `createresult` suggests this is the case but the name of its variable, i.e. `path`, suggests they are different. can you double check this by creating a sequential znode?",0,0.987608015537262
232566446,5821,lindong28,2018-11-12T08:27:51Z,"should we also update `controllercontext.brokerepochs` properly in `brokermodifications.process()`? to reduce the chance of missing such update in the future, it is probably good to make `brokerepochs` a private variable. and expose a single method in `controllercontext` to update `brokerepochs`, `livebrokersunderlying` and `livebrokeridsunderlying` together. this method can replace the existing method `livebrokers_=(brokers: set[broker])` in `controllercontext`.",0,0.9924901127815247
232567122,5821,lindong28,2018-11-12T08:30:51Z,"thinking about this more, it may be better to do the following to explicit show that we want to keep only broker ids that are in `liveorshuttingdownbrokerids`. [code block]",0,0.9911708235740662
232764958,5821,hzxa21,2018-11-12T18:25:36Z,"both zookeeper `createrequest` and `createresponse` use the field `path` to represent the resulting path (can handle the sequential create case). i think what you think it is confusing is that when we are using zookeeper async create, the `processresult` methond in `stringcallback` has a `path` field to represent the path included in the request and has a `name` field to represent the resulting path. i double check zookeeper source code and zookeeper client (to be more specific, in `clientcnxn.java`). the logic to invoke the callback is: [code block] the 2nd argument in `processresult` is `path` and the 4th argument is `name`. this confirms that we use `rsp.getpath()` for the `name` in `processresult`.",0,0.9899002909660339
232767009,5821,hzxa21,2018-11-12T18:32:10Z,"i actually think of what you have suggested at the very beginning and the reason i didn't do that is that the only place we can update the broker epoch is in brokerchange event. broker epoch will only change when the broker ephemeral znode gets deleted and re-created so that is why we use czxid (create transaction id). czxid will only change when we create the broker znode, not when we modify it, so in `brokermodification` event the czxid will not change. the only place we will capture the czxid change is in `brokerchange` evnet because we are listening on the children nodes change.",0,0.9861509203910828
232772273,5821,hzxa21,2018-11-12T18:49:51Z,agree. done.,0,0.9774162173271179
232772296,5821,hzxa21,2018-11-12T18:49:56Z,fixed.,0,0.9905837774276733
232782780,5821,lindong28,2018-11-12T19:25:52Z,sounds good. thanks for the explanation.,1,0.9865726232528687
232782818,5821,lindong28,2018-11-12T19:25:59Z,sounds good. thanks for the explanation.,1,0.9865726232528687
233259207,5821,junrao,2018-11-13T23:11:36Z,could we fix the javadoc above?,0,0.9932788014411926
233260194,5821,junrao,2018-11-13T23:15:47Z,"it would be useful to avoid _1/_2 for better readability. we could do foreach { case (broker, epoch) => ...}",0,0.9936091899871826
233278007,5821,junrao,2018-11-14T00:43:32Z,it would be useful to avoid _1/_2 for better readability.,0,0.989574134349823
233278057,5821,junrao,2018-11-14T00:43:47Z,it would be useful to avoid _1 for better readability.,0,0.9888789653778076
233279558,5821,junrao,2018-11-14T00:52:38Z,"instead of bouncedbrokerids(broker.id), it might be clearer to do bouncedbrokerids.contains(broker.id).",0,0.9921797513961792
233281539,5821,junrao,2018-11-14T01:03:18Z,"hmm, could we just change livebrokersunderlying to a map[broker, long] instead of introducing a separate val?",0,0.9881365299224854
234024398,5821,junrao,2018-11-15T21:59:47Z,could this be debug?,0,0.9887786507606506
234025608,5821,junrao,2018-11-15T22:04:07Z,this probably should be info since we handle it as expected.,0,0.9884214401245117
234028770,5821,junrao,2018-11-15T22:15:45Z,"normally, when we call onbrokerfailure(), the passed in deadbrokers won't be in controllercontext.livebrokers, which is used by onbrokerfailure() through partitionstatemachine/replicastatemachine. with this change, this may not be true. will that have any impact?",0,0.9893181920051575
234029553,5821,junrao,2018-11-15T22:18:43Z,should we log the broker epoch in addition to the broker id?,0,0.9941619038581848
234033660,5821,junrao,2018-11-15T22:34:33Z,could we use case for e to avoid _1/_2?,0,0.9925918579101562
234055778,5821,junrao,2018-11-16T00:24:48Z,"this may be an existing problem. if a zk multi fails because of one of the operations, does that error get reflected in the rc in the top level response or in individual zkopresult?",0,0.9905397891998291
234057258,5821,junrao,2018-11-16T00:34:27Z,"do we need to add ()? in general, we only need () for methods with side effects.",0,0.9922312498092651
234059863,5821,junrao,2018-11-16T00:50:39Z,this logic needs to be done after the response.resultcode match block as before the patch since getafternodeexists() can return code.ok too.,0,0.9949489831924438
234061971,5821,junrao,2018-11-16T01:04:43Z,is it still useful to log in the above line since codeafterrecreate hasn't changed?,0,0.9940821528434753
234062220,5821,junrao,2018-11-16T01:06:25Z,typo abstarct,0,0.9876284599304199
234064469,5821,junrao,2018-11-16T01:21:21Z,perhaps those warn should be info since there is nothing for the user to act on this.,0,0.968814492225647
234065021,5821,junrao,2018-11-16T01:25:20Z,epoch => brokerepochinrequest ?,0,0.9655992984771729
234065222,5821,junrao,2018-11-16T01:26:51Z,there is logging in zkclient.registerbroker(). we could just log the broker epoch there.,0,0.9946891069412231
234067161,5821,junrao,2018-11-16T01:40:40Z,are leader_and_isr_request_topic_state_v0 and leader_and_isr_request_partition_state_v1 still valid? perhaps it's simpler to just say we normalized partitions under each topic.,0,0.9918639659881592
234069244,5821,junrao,2018-11-16T01:54:52Z,this is unnecessary since shutdown() is blocking.,0,0.9801283478736877
234069643,5821,junrao,2018-11-16T01:56:25Z,"since the propagation of the zk event is async, we may need to put the checking logic in a waituntiltrue() block. ditto below.",0,0.9942264556884766
234069804,5821,junrao,2018-11-16T01:57:13Z,the comment seems out of place.,0,0.5278897881507874
234070541,5821,junrao,2018-11-16T02:02:40Z,outdated comment?,0,0.9614076018333435
234070606,5821,junrao,2018-11-16T02:03:07Z,we are not sending stale epoch anymore?,0,0.9929317235946655
234070761,5821,junrao,2018-11-16T02:04:24Z,does this need to be volatile?,0,0.9817500114440918
234071333,5821,junrao,2018-11-16T02:08:28Z,the code in this method is quite similar to that in testcontrolrequestwithcorrectbrokerepoch(). should we merged them somehow?,0,0.9944341778755188
234071751,5821,junrao,2018-11-16T02:11:44Z,should this be volatile?,0,0.9800366759300232
234073100,5821,junrao,2018-11-16T02:21:50Z,this is unnecessary. great test!,1,0.9953122138977051
234073572,5821,junrao,2018-11-16T02:25:08Z,indentation,0,0.9911677837371826
234073709,5821,junrao,2018-11-16T02:26:06Z,indentation,0,0.9911677837371826
234144660,5821,hzxa21,2018-11-16T09:48:12Z,"this is a very good point. i think it is fine because the bounced broker will reject the control requests anyway because the cached broker epoch has not been updated yet. however, this brings up another question: do we actually need to call `onbrokerfailure()` for bounced brokers? after a second thought, i think the answer is no because the end goal of controller handling bounced brokers in brokerchange event is to make sure the quickly bounced brokers will be initialized correctly and the end partition/replica states will be the same with and without calling `onbrokerfailure` for the bounced brokers (if there are no new brokers and dead brokers). in this case, only calling `onbrokerstartup` is sufficient. invoking `onbrokerfailure` first is a correct and safe option but it comes with some overhead because we need to perform leader election and send out the stopreplica/leaderandisr/updatemetadata, which are not necessary. previously i thought that missing `onbrokerfailure` will cause correctness issue because we might miss some state clean up but looks like it is not the case. also note that if we use controlled shutdown to shutdown and restart the broker, the leadership election actually happens before processing the brokerchangeevent. tl;dr: to be more specific for your original question (why updating the live brokers first then invoke `onbrokerfailure` is fine), there are three places where we use the live brokers informartion in `onbrokerfailure`: 1. determine whether we need to transition partition states to offlinepartition: since at the time of the brokerchange event processing, the bounced brokers are alive so there will not be offline partitions. 2. determine which brokers we want to consider when performing leader election in `partitionstatemachine.triggeronlinepartitionstatechange()`: since the bounced brokers are online at that time so we should consider them. 3. determine which brokers we need to send out control requests and which brokers we need to include in the live brokers field in updatemetadatarequest: since the bounced brokers will not accept control requests anyway so the first point doesn't matter. for the second point, the bounced brokers are live so we don't want to exclude them in the updatemetadatarequest.",1,0.9756951332092285
234152612,5821,hzxa21,2018-11-16T10:13:25Z,"code from zookeeper (clientcnxn.java): [code block] this suggests that if we can get back the opresult from zookeeper (no connection_loss), rc represents the first error in the operations. so using the rc in the top level response after unwrapping the multi response is fine becuase the first error will also be the actual error for create/setdata/delete if we pass the controller epoch check. this also suggests that list[opresult] can be null in the callback and i don't handle this in our zookeeperclient so i will fix it.",0,0.9908878803253174
234307011,5821,lindong28,2018-11-16T18:36:20Z,"regarding info vs. warn, i usually follow the summary in [a link] which says that info level is for `generally useful information to log (service start/stop, configuration assumptions, etc)`, and warn level is for `anything that can potentially cause application oddities, but for which i am automatically recovering`. in this case the `brokerepoch < cachedbrokerepoch` can happen only under rare scenario when controlledshutdownrequest is re-sent due to disconnection between broker and controller. this is similar to the scenarios captured in `networkclient.processdisconnection(...)` which are currently logged in warn level. and it is unlike all other info level logging in kafka for normal broker start/stop. so it seems that warn level is appropriate here?",0,0.9864795804023743
236885202,5821,junrao,2018-11-27T23:14:43Z,"yes, the question is whether rare == odd. to me, odd should be unexpected. brokerepoch < cachedbrokerepoch is rare, but is not unexpected.",0,0.9866561889648438
236902108,5821,junrao,2018-11-28T00:36:16Z,": overall, i agree with your assessment that the onbrokerfailure() call seems redundant. the only thing is that it can force a leader epoch change. suppose that broker 1 is a bounced broker and is the current leader. if we skip onbrokerfailure(), the controller just keeps broker 1 as the leader w/o bumping the leader epoch. this means that the follower won't go through leader epoch based log truncation, which maybe needed since broker 1 may not have all the data in its local log after the bounce. so, perhaps we can't skip onbrokerfailure(). the next question is should the live broker list exclude the bounced brokers when we call onbrokerfailure(). it seems that we should since live broker list influences which broker is the new leader. if the bounced brokers are still in the live broker list and are the current leaders, those leaders' epoch won't change. so, in summary, it seems that we should still call onbrokerfailure() but excluding bounced brokers from live broker list first. we then add the bounced brokers to live broker list and call onbrokerstartup().",0,0.9117367267608643
236906085,5821,hzxa21,2018-11-28T00:57:13Z,"i agree. also after an offline discussion with dong, we agree that the benefit of optimizing for quickly bounced brokers is minor and since in normal scenario we will go through onbrokerfailure and then onbrokerstartup for the bounce brokers, it is better to do the same thing here ( invoke onbrokerfailure() and then update live brokers). thanks for the comment. i will update the pr accordingly.",1,0.9789620041847229
236907622,5821,junrao,2018-11-28T01:05:33Z,"thanks. since the code still uses the rc in the individual ops, it seems that we need to change it to check the top level rc?",1,0.916924238204956
237354671,5821,hzxa21,2018-11-29T05:09:40Z,fixed.,0,0.9905837774276733
237354685,5821,hzxa21,2018-11-29T05:09:45Z,fixed.,0,0.9905837774276733
237354693,5821,hzxa21,2018-11-29T05:09:49Z,fixed.,0,0.9905837774276733
237354698,5821,hzxa21,2018-11-29T05:09:52Z,fixed.,0,0.9905837774276733
237354713,5821,hzxa21,2018-11-29T05:10:02Z,done.,0,0.9897913336753845
237354811,5821,hzxa21,2018-11-29T05:10:53Z,"good suggestion. i have changed livebrokeridsunderlying to a map[int, long] to avoid introducing the val.",1,0.9862202405929565
237355006,5821,hzxa21,2018-11-29T05:12:19Z,i think it is better to keep it info because the broker epoch information is as informative as the broker ids. we als log the broker ids in info log so we should keep it consistent.,0,0.9727129936218262
237355104,5821,hzxa21,2018-11-29T05:13:13Z,i think info is fine. i have changed it to info. thanks you guys for sharing the guideline.,1,0.9926961660385132
237355138,5821,hzxa21,2018-11-29T05:13:31Z,done.,0,0.9897913336753845
237355290,5821,hzxa21,2018-11-29T05:14:32Z,the broker epoch is already logged at the end of the broker change event: [a link],0,0.9960475564002991
237355315,5821,hzxa21,2018-11-29T05:14:43Z,sure. done.,0,0.9720492362976074
237357526,5821,hzxa21,2018-11-29T05:27:45Z,"we need to use the rc in the individual ops (check and create/delete/set) because we need to differentiate whether the error happened in the controller epoch znode zkversion check or in create/delete/set. the opresut for the check op will reflect whether it has succeeded or not. if it succeeds, the top level rc will reflect the error happened in create/delete/set and we do use top level rc when constrcuting the response for create/delete/set. if the check op fails, we will throw exception accordingly.",0,0.9920176267623901
237357668,5821,hzxa21,2018-11-29T05:28:58Z,i don't think we need to add () here. the problem is we have () in the function definition which exists before this patch. i remove the () in the updated pr.,0,0.9907951951026917
237357712,5821,hzxa21,2018-11-29T05:29:19Z,good catch. thanks for pointing it out. fixed.,1,0.9952783584594727
237357743,5821,hzxa21,2018-11-29T05:29:33Z,no. my bad. i have removed the log.,-1,0.9938940405845642
237357752,5821,hzxa21,2018-11-29T05:29:38Z,fixed.,0,0.9905837774276733
237357777,5821,hzxa21,2018-11-29T05:29:48Z,sure. done.,0,0.9720492362976074
237357789,5821,hzxa21,2018-11-29T05:29:52Z,done.,0,0.9897913336753845
237357805,5821,hzxa21,2018-11-29T05:30:03Z,yes. done.,0,0.9106190204620361
237357830,5821,hzxa21,2018-11-29T05:30:15Z,thanks for the suggestion. done.,1,0.8816729187965393
237357840,5821,hzxa21,2018-11-29T05:30:23Z,removed.,0,0.9612457156181335
237357856,5821,hzxa21,2018-11-29T05:30:30Z,good point. fixed.,1,0.9819728136062622
237357868,5821,hzxa21,2018-11-29T05:30:35Z,removed.,0,0.9612457156181335
237357874,5821,hzxa21,2018-11-29T05:30:39Z,removed.,0,0.9612457156181335
237357953,5821,hzxa21,2018-11-29T05:31:19Z,fixed.,0,0.9905837774276733
237358000,5821,hzxa21,2018-11-29T05:31:37Z,yes. fixed.,0,0.9165666699409485
237358049,5821,hzxa21,2018-11-29T05:32:02Z,sure. i have merged them into a single function.,0,0.9876912832260132
237358057,5821,hzxa21,2018-11-29T05:32:07Z,yes. fixed.,0,0.9165666699409485
237358075,5821,hzxa21,2018-11-29T05:32:14Z,remove. thanks!,1,0.987337589263916
237358087,5821,hzxa21,2018-11-29T05:32:17Z,fixed.,0,0.9905837774276733
237358092,5821,hzxa21,2018-11-29T05:32:21Z,fixed.,0,0.9905837774276733
237710891,5821,junrao,2018-11-30T00:33:25Z,could initialbrokerepoch be right after initialbrokerinfo?,0,0.9894365072250366
237716547,5821,junrao,2018-11-30T01:07:40Z,indentation,0,0.9911677837371826
237718706,5821,junrao,2018-11-30T01:21:33Z,control request => controlled shutdown request,0,0.9934436082839966
237719353,5821,junrao,2018-11-30T01:26:07Z,the controller part is not right. non-controllers are registered through this api too.,0,0.9393438100814819
237719687,5821,junrao,2018-11-30T01:28:31Z,it seems that this logging is redundant since registerbroker() logs the same info already?,0,0.9908267855644226
237721321,5821,junrao,2018-11-30T01:40:07Z,perhaps it's better to return a map instead of a sequence of pairs?,0,0.9849051833152771
237723919,5821,junrao,2018-11-30T01:58:10Z,normalize => normalizes,0,0.988430380821228
237724317,5821,junrao,2018-11-30T02:01:06Z,perhaps add a comment on how v1 differs from v0?,0,0.9928431510925293
237724569,5821,junrao,2018-11-30T02:02:47Z,normalize => normalizes,0,0.988430380821228
237725390,5821,junrao,2018-11-30T02:08:58Z,unused import,0,0.9873000979423523
237725957,5821,junrao,2018-11-30T02:13:03Z,typo reuest,0,0.9896196722984314
237799160,5821,hzxa21,2018-11-30T09:42:03Z,sure. done.,0,0.9720492362976074
237799446,5821,hzxa21,2018-11-30T09:43:00Z,fixed.,0,0.9905837774276733
237799723,5821,hzxa21,2018-11-30T09:43:54Z,"i mean leaderandisr/updatemetadata/stopreplica requests here, not controlled shutdown request. i have updated the comment to avoid confusion.",0,0.9936850666999817
237799747,5821,hzxa21,2018-11-30T09:44:00Z,fixed.,0,0.9905837774276733
237799890,5821,hzxa21,2018-11-30T09:44:27Z,thanks for pointing out. i have removed the log here.,1,0.9397934675216675
237799946,5821,hzxa21,2018-11-30T09:44:39Z,agree. fixed.,0,0.9858681559562683
237799968,5821,hzxa21,2018-11-30T09:44:42Z,fixed.,0,0.9905837774276733
237799996,5821,hzxa21,2018-11-30T09:44:48Z,sure. added.,0,0.9894619584083557
237800040,5821,hzxa21,2018-11-30T09:44:53Z,fixed.,0,0.9905837774276733
237800071,5821,hzxa21,2018-11-30T09:44:58Z,removed.,0,0.9612457156181335
237800090,5821,hzxa21,2018-11-30T09:45:02Z,fixed.,0,0.9905837774276733
238013840,5821,junrao,2018-11-30T21:53:05Z,could we put return after param ?,0,0.9945592284202576
238013931,5821,junrao,2018-11-30T21:53:30Z,could we change the comment accordingly?,0,0.9938691258430481
238020317,5821,hzxa21,2018-11-30T22:20:31Z,sure. done.,0,0.9720492362976074
238020331,5821,hzxa21,2018-11-30T22:20:36Z,done.,0,0.9897913336753845
238021750,5821,junrao,2018-11-30T22:26:43Z,it seems that you fixed a different line?,0,0.9926707744598389
238069509,5821,hzxa21,2018-12-01T16:57:44Z,ah. my bad. i mislooked this one. fixed.,-1,0.995360791683197
205630399,5428,guozhangwang,2018-07-26T23:23:28Z,this is a bug found in mockproducer: we should never throw producerfenced in send() call as it should only be returned in the future callback.,0,0.9819728136062622
205630643,5428,guozhangwang,2018-07-26T23:24:49Z,"this is the optimization on commit: we only execute commit when some processing has been done since last commit, either some records processed, or punctuation triggered. for standby task commit will be triggered only when some update has been applied to the state store.",0,0.9942832589149475
205630742,5428,guozhangwang,2018-07-26T23:25:28Z,this is the optimization we have done for partition stream time update.,0,0.9949377775192261
205912746,5428,guozhangwang,2018-07-27T22:19:59Z,this is not intended and will be removed when rebasing on part ii merged.,0,0.9936894178390503
207436880,5428,guozhangwang,2018-08-03T04:17:16Z,this test is invalid (see the above comment).,0,0.9022877216339111
207436995,5428,guozhangwang,2018-08-03T04:18:12Z,"if a producer is fenced, its producerfencedexception is wrapped in the kafkaexception.",0,0.9931790828704834
207437074,5428,guozhangwang,2018-08-03T04:18:47Z,this function should only be called once within each iteration after records enqueued.,0,0.9942176342010498
207437109,5428,guozhangwang,2018-08-03T04:19:08Z,inline this function since it only have one caller.,0,0.9933412671089172
207437286,5428,guozhangwang,2018-08-03T04:21:09Z,"this flaky test is found while working on the pr, so i'm piggy back the fix here. but itself is really independent of the pr, so if people wants to put it into a separate one i can also do that.",0,0.9656328558921814
208295539,5428,bbejeck,2018-08-07T16:16:47Z,i think we could simplify this block like so [code block] wdyt?,0,0.9885066747665405
208346664,5428,bbejeck,2018-08-07T18:54:08Z,"in trunk, the ordering of calls for the `producer` during a commit was broken up, but now they are all grouped together. it seems ok to do this and is cleaner to follow, i just wanted to double check the change of ordering doesn't matter. maybe we should run system tests to confirm?",0,0.817669689655304
208347652,5428,bbejeck,2018-08-07T18:56:53Z,nit: we could return `commitneeded` and get rid of `else` and return `false` directly if no punctuation occurred.,0,0.9891323447227478
208347752,5428,bbejeck,2018-08-07T18:57:10Z,same as above,0,0.9918335676193237
208354835,5428,bbejeck,2018-08-07T19:20:47Z,nice addition!,1,0.9902989864349365
208727056,5428,guozhangwang,2018-08-08T20:37:54Z,"good point, i will run the system test accordingly.",1,0.962921679019928
208728232,5428,guozhangwang,2018-08-08T20:41:28Z,yup! :),1,0.9928843975067139
208741696,5428,mjsax,2018-08-08T21:27:14Z,should we check the root cause?,0,0.9903879761695862
208745329,5428,mjsax,2018-08-08T21:41:04Z,"isn't this a behavior change? iirc, we had a discussion to do this change, or to maybe make it configurable if we want to interleave processing with recovery.",0,0.9913500547409058
208745919,5428,mjsax,2018-08-08T21:43:28Z,should this be `timesincelastpoll >= maxpolltimems / 2` ?,0,0.9944894313812256
208747346,5428,mjsax,2018-08-08T21:49:19Z,"we set poll interval to integer.max_value by default. thus, if user does not change the default (most won't i assume), the condition will never be met. should we rather consider to set a different default value (note, there is already a jira for this)?",0,0.9906472563743591
208749613,5428,mjsax,2018-08-08T21:58:16Z,isn't `timesincelastpoll < maxpolltimems` covered via `if (timesincelastpoll / 2 >= maxpolltimems) { break; }` and redundant?,0,0.9919596314430237
208761166,5428,mjsax,2018-08-08T22:55:11Z,could we actually remove this guard? we don't call `time. milliseconds()` as below.,0,0.9906156063079834
208761888,5428,mjsax,2018-08-08T22:59:09Z,"why do we need this? wouldn't it be easier to remove `else` block and just call `return committed > 0;` after the `if`? if i understand correctly, we want to return `true` if committing happen, and currently, even if we commit we could return `false`",0,0.9776781797409058
208771114,5428,guozhangwang,2018-08-08T23:55:56Z,good point!,1,0.9930058121681213
208771638,5428,guozhangwang,2018-08-08T23:59:02Z,"ah good point! i was actually not intentionally changing the behavior, i will revert it back to the old manner.",1,0.9955774545669556
208772074,5428,guozhangwang,2018-08-09T00:01:52Z,"yes, that was my plan. i'm aware that this line is basically a no-op because max.poll is integer.max_value, and want to do it in another pr. if people feel that we should reverse the ordering, i.e. change the default value first, then do this pr, i'm fine too.",0,0.797980785369873
208772154,5428,guozhangwang,2018-08-09T00:02:28Z,"gosh, my bad.",-1,0.9921082854270935
208772446,5428,guozhangwang,2018-08-09T00:04:17Z,"yes. in an old commit the code structure was a bit different and hence we may run over the check (assuming the maxpolltimems is not integer.max_value), but in this format we will always check for `timesincelastpoll >= maxpolltimems / 2` anyways in each loop, and hence we can remove this.",0,0.9918279647827148
208772726,5428,guozhangwang,2018-08-09T00:06:00Z,"the intention is to save calling `taskmanager.activetaskids(), taskmanager.standbytaskids()` etc and pass them as parameters. it may not really introduce significant differences, but no harm to still keep them?",0,0.9919203519821167
208772966,5428,guozhangwang,2018-08-09T00:07:45Z,"you're right, and actually i should changed the above line to `committed += taskmanager.commitall();`.",0,0.9820922613143921
208773153,5428,mjsax,2018-08-09T00:08:52Z,"i would personally prefer, to keep the condition in the `while` conditions instead of using `if() break` construct.",0,0.9772927761077881
208773238,5428,mjsax,2018-08-09T00:09:30Z,"i see. fine with my both ways -- as long as it's intentional and we know about it, it's ok.",0,0.6751802563667297
208997552,5428,guozhangwang,2018-08-09T16:33:28Z,this is also a flaky test that i discovered here.,0,0.6024588346481323
209042674,5428,mjsax,2018-08-09T18:56:36Z,fine with me to keep the guard. was just double checking.,0,0.9754329323768616
209293245,5428,vvcephei,2018-08-10T15:13:11Z,i didn't follow why we need this now. can you explain?,0,0.9461821913719177
209300543,5428,vvcephei,2018-08-10T15:36:16Z,"just checking my understanding: we are planning to replace this counter with a wall-clock timer in kip-353. i think that once we do that, we can actually move this logic into `isprocessable()` because the condition would no longer be dependent on the number of calls.",0,0.9894211292266846
209300893,5428,vvcephei,2018-08-10T15:37:31Z,"it seems like it might be worth actually putting your remark ""this function should only be called once within each iteration after records enqueued."" in a comment so we can remember during refactoring later.",0,0.984714686870575
209310471,5428,vvcephei,2018-08-10T16:09:53Z,is this just because punctuations might result in context.forwards?,0,0.9884659051895142
209313656,5428,vvcephei,2018-08-10T16:20:51Z,"i believe that java (or the alu) will do exactly the same thing whether you say `maxpolltimems >> 1` or `maxpolltimems / 2`, but your human colleagues might appreciate the latter ;)",1,0.819908618927002
209336733,5428,vvcephei,2018-08-10T17:47:21Z,"nice! now that the condition is no longer dependent on the number of invocations, i think you can move it into `isprocessable()` and not need to call this method outside of this class.",1,0.9894043207168579
209338385,5428,vvcephei,2018-08-10T17:53:27Z,"actually, we should re-set the timer whenever we process, right? imagine we have the following sequence: [code block]",0,0.9912518858909607
209339003,5428,vvcephei,2018-08-10T17:55:50Z,"i think there's a risk of forcing processing on the very first iteration if too much time passes between construction and processing (like if the startup protocol takes a while). maybe we can initialize it to `long.max_value` instead, which should cause us never to force processing the first time.",0,0.9782705307006836
209344830,5428,vvcephei,2018-08-10T18:16:44Z,"i take it this was the source of the flakiness. can you explain why, for my education?",0,0.9629129767417908
209405125,5428,guozhangwang,2018-08-10T23:23:23Z,"this is following the same pr that had: [a link] the point is that when a xxxconfig is created, by default it will print `logall` and hence swamped the logs (we can see the same lists to be printed multiple times whenever it is created). this function is to disable `log` for such cases.",0,0.9943021535873413
209405232,5428,guozhangwang,2018-08-10T23:24:16Z,actually it is because users can call `context.commit()` in either ` punctuate()` or `process()` calls.,0,0.9936774373054504
209405249,5428,guozhangwang,2018-08-10T23:24:32Z,ack :),0,0.5039835572242737
209405308,5428,guozhangwang,2018-08-10T23:25:07Z,"yup, good point.",1,0.8937575221061707
209405511,5428,guozhangwang,2018-08-10T23:27:15Z,"that's a good catch, but if we move `isprocessable()` inside the iteration, it will mean that we will only enforce-process one record for every `max.idle.ms` right? my original thought is that once we've decided to enforce process, we'll enforce for that whole thread iteration.",0,0.9165641069412231
209405561,5428,guozhangwang,2018-08-10T23:27:49Z,"hmm, good point, i'll see what can be done here.",1,0.8809443116188049
209405825,5428,guozhangwang,2018-08-10T23:30:47Z,"the flakiness is actually that for this dedup integration test, we should check that ""for each key, the last record is the expected value"", while previously we just check that ""we retrieve n records, and check that these n records are exactly the expected values"". however even with dedup based on caching, it may not be the case that we only produce n final records. this pr increases the likelihood that we do not only produce n final records, and hence i updated the check logic accordingly.",0,0.9597499370574951
209406887,5428,guozhangwang,2018-08-10T23:42:22Z,i will set the enforced process in the `inittopology` which will be triggered when the task transits to running state.,0,0.9931204319000244
209757140,5428,vvcephei,2018-08-13T21:00:25Z,ah! i misread this as turning `logall` *on* instead of *off*. now i get it :),1,0.9579382538795471
210646404,5428,bbejeck,2018-08-16T15:43:04Z,nit: can be package private,0,0.9951083064079285
210646473,5428,bbejeck,2018-08-16T15:43:19Z,nit: can be package private,0,0.9951083064079285
210689155,5428,bbejeck,2018-08-16T18:02:59Z,why did this go from 2 to 1? other than not passing an arg to `runonce` the test logic to this point hasn't changed,0,0.9860974550247192
211453536,5428,guozhangwang,2018-08-21T01:16:54Z,"the logic does have changed: in the old code we will commit twice on producer, one during the rebalance and one from the elapsed time. in the new code, the optimization i added will realize that nothing has been generated since the last commit, and hence we will skip committing in this case. thinking about it, this does have a side-effect though since for eos if commit was not called in a long time then txn will be aborted, and if producer does not talk to txn coordinator even longer it could be removed as well. but personally i think it is okay for such scenario to happen, since really no data was generated, and hence committing an empty txn does not really make sense, and we should rather increase the txn expiration time in this case. wdyt?",0,0.7356665134429932
211764912,5428,vvcephei,2018-08-21T21:23:35Z,"i guess that we always have a transaction open, not just when we have something to commit. it seems like one solution is to open a transaction only when we have data to process. although this might complicate things. alternatively, is there a way to periodically send a ""keep alive"" message to let the broker know we do still intend to use that transaction? it seems like either this or just abort/close the empty txn and re-open is better than a super-long expiration time. otherwise, why is there even an expiration time? is there any tradeoff between having one transaction open for a super long time, vs periodically closing empty transactions and starting new ones?",0,0.9556900858879089
211773323,5428,guozhangwang,2018-08-21T21:57:21Z,"completing a txn and starting a new one come with some cost, and hence is what we want to avoid generally. on the other hand, we do not yet have a mechanism for ""keep alive"": with that, i think keeping a long lived empty txn is okay, note that if the txn is not empty, then not committing it in time will increase the latency. hence i'm only trying to optimize the case when the txn is empty.",0,0.9775308966636658
211775968,5428,mjsax,2018-08-21T22:09:46Z,"i just talked to about this. not committing is actually fine. note, that begintx() is a client local state transition -- nothing is written to the log (there are no ""begin tx markers"") and the tc state is also not modified. this implies, that the transaction timeout is not started on begintx() -- the timeout only starts after the first record was written to the log. thus, we don't need ""keep alive heartbeats"" and don't need to tell users to increase the tx timeout for low traffic topics that might have longer periods with no data.",0,0.9192136526107788
212116777,5428,mjsax,2018-08-22T21:30:07Z,nit: `out-of-ordering` -> `out-of-order`,0,0.9916803240776062
212120236,5428,mjsax,2018-08-22T21:44:01Z,nit: can be limited to be package private,0,0.9945235252380371
212120925,5428,mjsax,2018-08-22T21:46:59Z,nit: `failed to commit streamtask {} due` -- to distinguish active and standbys as before.,0,0.9635491967201233
212121159,5428,mjsax,2018-08-22T21:47:55Z,why do we remove `tasktypename` for the log statement?,0,0.9930859804153442
212121272,5428,mjsax,2018-08-22T21:48:21Z,why do we remove `tasktypename` for the log statement?,0,0.9930859804153442
212121781,5428,mjsax,2018-08-22T21:50:33Z,"i think we should increase `committed` after `task.commit()` returns -- otherwise, we over count if committing fails?",0,0.9898712038993835
212121812,5428,mjsax,2018-08-22T21:50:42Z,"i think we should increase `committed` after `task.commit()` returns -- otherwise, we over count if committing fails?",0,0.9898712038993835
212122618,5428,mjsax,2018-08-22T21:54:04Z,nit: `lastenforcedprocess[ingtime[stamp]]` ?,0,0.9931180477142334
212122704,5428,mjsax,2018-08-22T21:54:20Z,nit: `enforedprocess[ing]`,0,0.9951066970825195
212123252,5428,mjsax,2018-08-22T21:56:36Z,should we change the order of the order? not sure atm if this has a semantic impact due to potential partial evaluation? just want to double check.,0,0.96251380443573
212123631,5428,mjsax,2018-08-22T21:58:06Z,"also, it seems that we might want to rename `enforcedprocess` to `enforceprocessing` (without `d`) ?",0,0.9933725595474243
212123911,5428,mjsax,2018-08-22T21:59:11Z,this comments seems not to be addressed?,0,0.9913486838340759
212125423,5428,mjsax,2018-08-22T22:05:14Z,"both good points. basically, we should reset the timer when there is data for all input partitions. thus, we should check after poll() if we can reset the timer (ie, in `streamtask#addrecords()` each time all partitions have data)?",1,0.876201868057251
212125967,5428,mjsax,2018-08-22T22:07:43Z,nit: formatting -> more `}` to next line,0,0.9916774034500122
212126272,5428,mjsax,2018-08-22T22:09:07Z,why do we not check `if(commitneeded)` any longer?,0,0.9900175929069519
212127138,5428,mjsax,2018-08-22T22:13:22Z,"it was broken apart because we checked if there is anything to commit in the first place (ie, do the check on one place)-- if we did not process any data, we don't need to commit. this check now happens outside of `streamtask` as pointed out by guozhang [a link] thus, regrouping makes sense. code is cleaner this way.",0,0.986850917339325
212128396,5428,mjsax,2018-08-22T22:19:04Z,"meta comment: not sure if this is a good argument for inlining in general---code might be more readable if it's broken apart is smaller pieces and calling methods (with good names) actually self-documents the code. also, shorter methods are easier to understand. for this particular case, inlining is ok imho, as with `if (commitneeded)` check, we don't loose anything.",0,0.7792716026306152
212129095,5428,mjsax,2018-08-22T22:21:57Z,"hmmm... if there is nothing to commit, it might also be fine to ignore the user commit request? it's a tricky question what to do for this case. just follow what the user demands, or be smart? from a correctness point of view, it should not make a difference, would it? also, we set flag `commitrequested` for this case -- thus, it might be better to put this logic somewhere else? eg: `abstracttask` or overwrite in `streamtask`: [code block] (an alternative, that i like less would be to add a check if `commitrequested==true`)?",0,0.8690854907035828
212131579,5428,mjsax,2018-08-22T22:33:34Z,nit: remove `this`,0,0.9929719567298889
212133194,5428,mjsax,2018-08-22T22:41:50Z,nit: `maybeenforceprocess[ing]` ?,0,0.9927588701248169
212133245,5428,mjsax,2018-08-22T22:42:10Z,nit: `maybeenforceprocess[ing]`?,0,0.993137776851654
212133339,5428,mjsax,2018-08-22T22:42:41Z,nit: `maybeenforceprocess[ing]`?,0,0.993137776851654
212134225,5428,mjsax,2018-08-22T22:46:58Z,"why this? the condition checks for `activerunningtasks` -- why would we need to punctuate if there are not active tasks? also, should we `maybeupdatestandbytasks()` before we do `maybecommit()` to include the data that is processed by standbys in the commit?",0,0.9909948706626892
212135789,5428,mjsax,2018-08-22T22:55:13Z,this seems to contradict that we set `commitneeded` after punctuations (cf. my comments below).,0,0.9823695421218872
212136165,5428,mjsax,2018-08-22T22:57:17Z,"should we move this into the and `else` branch of `if (committimems >= 0 && lastcommitms + committimems < now)` -- if the condition is true, we call `taskmanager.commitall()` and thus `taskmanager.maybecommitactivetasks()` seems to be redundant here?",0,0.9937260746955872
212386802,5428,guozhangwang,2018-08-23T17:09:26Z,good point!,1,0.9930058121681213
212387543,5428,guozhangwang,2018-08-23T17:12:06Z,"no specific reasons, i should add it back.",0,0.9926682114601135
212387559,5428,guozhangwang,2018-08-23T17:12:11Z,ditto.,0,0.9384599328041077
212387745,5428,guozhangwang,2018-08-23T17:12:44Z,yes!,1,0.4961845874786377
212388642,5428,guozhangwang,2018-08-23T17:15:44Z,"the ordering thing: my old-school instinct is to put ""cheapest"" condition first for an `or` operator, but in modern compiler / cpu it really not matter at all :) renaming: ack.",1,0.9735791087150574
212389112,5428,guozhangwang,2018-08-23T17:17:20Z,my bad...,-1,0.9961431622505188
212395430,5428,guozhangwang,2018-08-23T17:37:20Z,"we check this in the assignedtasks now: if no commit is needed, we skip the whole committing function, including commit offsets, flushing stores, etc.",0,0.9949171543121338
212398936,5428,guozhangwang,2018-08-23T17:47:42Z,"not sure i follow your comment here.. let me elaborate a bit on my logic: we have two commits in places: commitall (periodic) and maybecommit (for user requested): the latter checks [code block] while the former only checks: [code block] i.e. the logic for the latter is that ""only if user have requested, and it is indeed needed to commit"": for example, if we have actually committed from the commit interval, and then user requested it as well, the second will be omitted. i intentionally separated ""commitrequest"" (this is only set by user) and ""commitneeded"" (this is determined by the library) because this way looks cleaner to me.",0,0.8459596633911133
212399201,5428,guozhangwang,2018-08-23T17:48:27Z,i've removed this function as whole and only reset upon `addrecords` as you suggested.,0,0.9954681396484375
212399262,5428,guozhangwang,2018-08-23T17:48:38Z,ditto below.,0,0.9935641884803772
212400548,5428,guozhangwang,2018-08-23T17:52:24Z,"good catch. the deliberation was that even though ""there is no data processed"", not ""there is no active tasks"" as the original check is `state == running` :) note that although `taskmanager.hasactiverunningtasks()` returns true, we may still not process any data (i.e. `totalprocessed` == 0 and we break the loop immediately). but with the new condition, we will always execute `if (maybepunctuate() || maybecommit())` anyways, so we only need to do `maybeupdate` followed by a `maybecommit` again.",1,0.9958307147026062
212401916,5428,guozhangwang,2018-08-23T17:56:27Z,"actually thinking about this, i feel it is better to separate the standby tasks from active tasks in maybecommit as otherwise we are doomed to waste some cpus doing either one of them. will refactor the code a bit more.",0,0.9596509337425232
212402352,5428,guozhangwang,2018-08-23T17:57:37Z,still not sure if i follow.. we do `maybepunctuate` before `maybecommit` so this should be fine?,0,0.8947261571884155
212402578,5428,guozhangwang,2018-08-23T17:58:25Z,"yes we can, as i mentioned i felt it is better to separate committing for standby tasks and for active tasks.",0,0.9901424646377563
212404222,5428,mjsax,2018-08-23T18:03:45Z,"so setting `commitneeded` is a conservative approach, because we don't know what the user did within punctuation call? might be better to set `commitneeded` if user calls `context.forward` or `state.put()` -- not sure how hard this would be -- would also be out-of-scope for this pr. if we think it might be worth it, we should create a jira for this optimization.",0,0.9922256469726562
212405498,5428,mjsax,2018-08-23T18:07:36Z,i think i miss understood the logic before. please ignore this comment.,0,0.889900803565979
212779553,5428,mjsax,2018-08-25T00:05:14Z,"nit: the naming always confuses me -- maybe we could rename this to `checkforusercommitrequest` or similar? the name should reflect that this method should be called to ""commit on user request only"" -- not for commit-interval purpose.",-1,0.6926513314247131
212779739,5428,mjsax,2018-08-25T00:07:31Z,seems you missed this one :),0,0.9635134339332581
212779906,5428,mjsax,2018-08-25T00:09:27Z,wondering if this is redundant to [code block],0,0.8194452524185181
212780227,5428,mjsax,2018-08-25T00:14:15Z,thought on my last comment?,0,0.9901354908943176
212780732,5428,mjsax,2018-08-25T00:22:19Z,"it seem we rely on `computelatency()` above to advance `now` -- it seems ""dangerous"" to rely on a ""side effect"" for this. should we advance time explicitly here? or at least put a check if `now < lastpollms || now > timesincelastpoll` ?",-1,0.845406711101532
212780848,5428,mjsax,2018-08-25T00:24:17Z,nit: should we rename to `taskmanger.maybepunctuate()` as well as `assignedstreamtasks#maybepunctuate()` to align naming?,0,0.9924384951591492
212780939,5428,mjsax,2018-08-25T00:26:00Z,nit: add comment `// visible for testing`,0,0.9957563281059265
212781336,5428,mjsax,2018-08-25T00:33:14Z,"`taskmanager#commitall()` still commits both, active and standby tasks. what kind of separation do you mean? and even if we separate both, it seems to be orthogonal to my comment. if we commit all tasks because commit time elapses, we don't need to check for user requested commits any longer. atm, we might iterator over all tasks twice. first iteration is checking for user requested commits, and if commit interval is passed, we iterate over all tasks again. however, if we commit time passed, we commit all tasks anyway and thus can avoid checking for user requested commits (ie, we can put `int committed = taskmanager.maybecommitactivetasks();` into the `else` of `if (committimems >= 0 && lastcommitms + committimems < now)` ? or maybe i miss understood your comment?",0,0.9864031076431274
212781601,5428,mjsax,2018-08-25T00:38:36Z,"note, that we call `waituntilfinalkeyvaluerecordsreceived` now instead of `waituntilminkeyvaluerecordsreceived`. not sure why we need to update the commit interval? isn't `auto.commit=false` anyway? if not, should we set `auto.commit=false` instead of setting commit interval to ""infinite""?",0,0.9937574863433838
212781654,5428,mjsax,2018-08-25T00:39:41Z,nit: move `consumerproperties` to next line,0,0.9951594471931458
212781954,5428,mjsax,2018-08-25T00:45:26Z,"simplify both lines to `finalaccumdata.putifabsent(kv.key, new arraylist<>()).add(kv);`",0,0.9947540760040283
212781963,5428,mjsax,2018-08-25T00:45:35Z,as above,0,0.9888283014297485
212782085,5428,mjsax,2018-08-25T00:47:20Z,seem so to duplicate line above?,0,0.9918295741081238
212782144,5428,mjsax,2018-08-25T00:48:36Z,"what do you mean by ""respect"" -- don't understand the test name",0,0.9785082340240479
212782288,5428,mjsax,2018-08-25T00:51:28Z,"shouldn't commitrequest not be false by default? also, did you intent to call `task.requestcommit()` above?",0,0.9945642948150635
212782318,5428,mjsax,2018-08-25T00:52:23Z,i think we need to initialize this with `false`? (compare my comment in the tests above),0,0.9922337532043457
212782384,5428,mjsax,2018-08-25T00:54:07Z,"if commit interval is 100ms, we might want to test the edge case 100 and 101 -- the test does not cover that we would force processing at 70l already.",0,0.9910348057746887
212782504,5428,mjsax,2018-08-25T00:56:48Z,"why 202l? i cannot inver from the test, to what time the timer get's reset?",0,0.9841545820236206
212782744,5428,mjsax,2018-08-25T01:02:32Z,why do we remove this test?,0,0.9927880167961121
213046088,5428,vvcephei,2018-08-27T17:10:02Z,"yeah, i can confirm that i just now got confused about the names. can we maybe call this (and up the chain) `commitifrequestedandneeded` or similar? specifically, the thing that confused me was differentiating the periodic commits on any dirty task vs. the on-demand commit driven by `processorcontext#commit`.",0,0.901383101940155
213052103,5428,vvcephei,2018-08-27T17:30:25Z,"overall, the enforced-processing algorithm is unclear to me. * following on 's comment, it seems strange to set this right before we return true anyway. note that this is currently the only place we set `enforceprocessing` to true. * also, it still seems to me that `maxtaskidlems` should count from the last time we process at all, not the last time we forced processing (same basic scenario i pointed out last time). is this right?",0,0.9077361226081848
213140235,5428,guozhangwang,2018-08-27T22:55:46Z,"oops, my bad.",-1,0.9921339750289917
213140554,5428,guozhangwang,2018-08-27T22:57:20Z,ack.,0,0.5866091847419739
213141057,5428,guozhangwang,2018-08-27T22:59:59Z,"we still need to commit even if no records are processed: consider a topology which only contains a single source node, then no data processed at all, but we still want to commit so that we would not re-process them right?",0,0.9874733686447144
213152609,5428,guozhangwang,2018-08-28T00:15:02Z,"it is not: once `enforceprocessing` is set, we want to continue in that state until the next batch of records are enqueued and we not have all partitions buffered. note that once we set the flag we update `lastenforcedprocessingtime = now;` as well, but we do not want to disable enforce processing in the next run immediately.",0,0.9927137494087219
213152646,5428,guozhangwang,2018-08-28T00:15:30Z,"it is not: once `enforceprocessing` is set, we want to continue in that state until the next batch of records are enqueued and we not have all partitions buffered. note that once we set the flag we update `lastenforcedprocessingtime = now;` as well, but we do not want to disable enforce processing in the next run immediately.",0,0.9927137494087219
213153611,5428,guozhangwang,2018-08-28T00:24:58Z,"the motivation of advancing `now` in `computelatency` is to save on `milliseconds()` call. i admit it is not ideal, if we want to change it to a different way, say: passing `now` along the calls than using a variable at all, then i'd suggest we do it in a separate pr as this pr has been dragging too long. regarding the check: that is a good idea, but i guess you mean `now - lastpollms > timesincelastpoll` right? i will add that check.",0,0.9732862114906311
213154023,5428,guozhangwang,2018-08-28T00:28:20Z,"i think `commit()` and `punctuate()` in taskmanager is okay, as they return the number of actual number of punctuation / commits triggered, while the `maybexx` returns true or false.",0,0.8364328742027283
213154784,5428,guozhangwang,2018-08-28T00:34:22Z,"i left a general comment before, copying here: [code block] regarding your question: yes i think switching the checking for time-based commits and then user-requested commits for now makes sense, i will update the code accordingly.",0,0.9889674782752991
213155160,5428,guozhangwang,2018-08-28T00:37:36Z,"i think this is not needed, will remove this.",0,0.9859220385551453
213156091,5428,guozhangwang,2018-08-28T00:44:52Z,"note sure what do you mean? `task.needcommit()` sets the flag, `commitrequested()` checks the flag. do you suggest renaming `needcommit` to `requestcommit`?",0,0.9917412996292114
213156299,5428,guozhangwang,2018-08-28T00:46:21Z,"the default init value should be `false` anyways, but yeah i can make it explicit.",0,0.9925417900085449
213156684,5428,guozhangwang,2018-08-28T00:49:15Z,"note we are testing for max idle time as `now - lastenforcedprocessingtime > maxtaskidlems` so 101 is necessary, ditto for below `202`.",0,0.9935417175292969
213157946,5428,guozhangwang,2018-08-28T00:59:03Z,"here is the rationale of this logic: 1. once we decide to `enforceprocessing`, we will continue enforcing until we got new data enqueued and all the buffer become full, in this case we will in `normalprocessing` state. 2. but we will update the `lastenforcedprocessingtime` the last time we decide to start enforce processing. 3. we know that once we decide to enforce processing, we will always process immediately as there are indeed some data buffered already. so the logic above sets `lastenforcedprocessingtime` at the time we decide to ""turn it on"", and only ""turn it off"" during records enqueuing and all buffers contain some data. and hence we will first check `enforceprocessing`: if it is true we just continue enforce processing. lgty?",0,0.9822342991828918
213162972,5428,guozhangwang,2018-08-28T01:39:44Z,note that `putifabsent()` will return null if it does not contain the key previously. i can try to use `computeifabsent` though.,0,0.9928926229476929
213173389,5428,mjsax,2018-08-28T03:11:36Z,fair enough. thanks for pointing it out.,1,0.9730460047721863
213173805,5428,mjsax,2018-08-28T03:15:49Z,"good point. now i am wondering, if we should set `lastenforcedprocessingtime = long.max_value`, too, when we set `enforceprocessing == false` when adding records to the buffers?",1,0.9599080681800842
213174290,5428,mjsax,2018-08-28T03:19:57Z,"renaming helps -- `needscommit` implies ""there is something to commit"" while `requestcommit` implies ""user request committing"" -- it's too different things and we need to keep naming separated to avoid confusion.",0,0.9884706735610962
213800151,5428,vvcephei,2018-08-29T19:09:54Z,"i see. thanks for explaining. it still seems like the `enforceprocessing` variable isn't strictly necessary, it just saves calls to `partitiongroup.allpartitionsbuffered()`, `partitiongroup.numbuffered()`, and the comparison `now - lastenforcedprocessingtime > maxtaskidlems`. these are all just cached field lookups, though, so i don't know if the performance boost is worth the algorithmic complexity. regarding `lastenforcedprocessingtime`, consider this scenario. [code block] two things to note here: 1. the expression should probably be `now - lastenforcedprocessingtime >= maxtaskidlems` (with `>=` instead of `>`), otherwise you'll wait at least one extra ms _beyond_ the purported ""max task idle time"". 2. in the scenario above, we said we want to wait *2 ms* before forcing processing, but we actually force processing *immediately*. to fix this, we should be comparing against `lastprocessingtime`, which we should set every time we process.",1,0.9256623983383179
213814276,5428,guozhangwang,2018-08-29T19:59:30Z,"good point, i will try to address this along with 's other comment:",1,0.9737128019332886
213815807,5428,vvcephei,2018-08-29T20:04:51Z,"thanks. one final thought about whether the `enforceprocessing` optimization is worth it. it might be a good idea to benchmark it without the optimization, since branch prediction *should* eliminate any overhead from the checks on rarely used branches.",1,0.9635159969329834
214207271,5428,guozhangwang,2018-08-30T23:10:55Z,"this turns out to be harder than i thought. the tricky thing is that we originally want to 1) record the sensor only for the first time when we transit to ""enforced processing"" state, and 2) start the idleness timer only for the first time when we do not have all buffered but some buffered. i tried to even implement a streamtask state just like kafkastreams and streamthread, but that turns out to not be so elegant as well. so what i ended up now is this: we will record the sensor whenever we enforce processing, either for the first time or not, and hence we will only update idlestarttime once, and reset it whenever we have all buffered. lmk wdyt.",0,0.5036384463310242
215719543,5428,mjsax,2018-09-06T17:52:03Z,not sure if i understand this. why is a commit only required if we did not restore all records that were passed in? don't we need to commit if we did a restore and updated `lastoffset` ?,0,0.6376793384552002
215734428,5428,mjsax,2018-09-06T18:38:24Z,nit: should it be `>` instead of `>=` ?,0,0.9776012897491455
215734587,5428,mjsax,2018-09-06T18:38:58Z,nit: `not_known` -> `unknown` ?,0,0.9900652766227722
215735099,5428,mjsax,2018-09-06T18:40:40Z,"nit: `fatal` is not a good name (was named like this before, no not introduced in this pr) -- this exception is not fatal but we can recover from it.",0,0.9685665965080261
215737734,5428,mjsax,2018-09-06T18:49:08Z,"why not just: `timesincelastpoll = now - lastpollms` ? if we assume that `now` never goes backwards, i don't see the need for calling `math.max`? and if we need the `math.max` guard, why do we need both? or do i miss something?",0,0.9812224507331848
215738983,5428,mjsax,2018-09-06T18:53:09Z,"should we check for `timesincelastpoll < maxpolltimems / 2`, too? according to the comment above, if we break the while-loop, we want to half `numiterations`, too. ie, instead of checking in the `while` condition, add a check here and call `break` after reducing `numiterations`?",0,0.9933252334594727
215741170,5428,mjsax,2018-09-06T18:59:52Z,"nit: `lastcommitms + committimems < now` -> `now - lastcommitms > committimems` imho, easier to read this way.",0,0.9095929265022278
215741742,5428,mjsax,2018-09-06T19:01:48Z,why another `if`? i thought this would be an `else` to the condition above?,0,0.9786408543586731
215803459,5428,mjsax,2018-09-06T23:02:09Z,sounds good to me.,1,0.9217013120651245
216033050,5428,guozhangwang,2018-09-07T17:32:21Z,there was an early comment on the test code that suggests `>=`. personally i think it does not make a big difference at all.,0,0.9577667713165283
216033754,5428,guozhangwang,2018-09-07T17:35:11Z,"again, this comes from a previous comment that it is safer to make sure `timesincelastpoll` does not go backwards, in case `now` is reduced.",0,0.9896650910377502
216037853,5428,guozhangwang,2018-09-07T17:49:27Z,good point!,1,0.9930058121681213
216039375,5428,guozhangwang,2018-09-07T17:54:27Z,"`!restorerecords.isempty()` means we have non-empty records that are applied inside `statemgr.updatestandbystates` call, note it does not remove records that are applied after the call.",0,0.9929627776145935
216067026,5428,vvcephei,2018-09-07T19:38:19Z,"i am to blame for this suggestion. i agree it doesn't make a big difference. the reasoning was that if it's the ""maximum idle time"", then you shouldn't idle longer than it, otherwise, it's not really a maximum.",-1,0.9799527525901794
216141583,5428,mjsax,2018-09-08T21:50:01Z,"i agree that it does not matter too much :) (that why it's a nit) however, i think that the maximum is inclusive, and only if we exceed it, we should force processing. from my understanding, ""maximum idle time"" is actually a lower bound (-> don't force processing until this time passed) because we cannot guarantee anyway to not exceed this threshold. i see your point why the name might be counter intuitive (even if i think the name is correct). if you interpret the name strictly, we would be allowed (or actually we would be required) to force processing before the time passed. this interpretation would make the parameter useless (ie, user tells us to idle max 5 minutes and we obey by forcing processing after 1 minute). to me, the right interpretation is, ""wait until this time passed and force processing asap if the time is exceeded"". chaning the name to `min.idle.time.ms` would be more precise, but i think it would be more confusing to users.",1,0.9813616871833801
216141611,5428,mjsax,2018-09-08T21:51:27Z,how could this happen? seems to be impossible to me.,-1,0.9203608632087708
216141645,5428,mjsax,2018-09-08T21:53:28Z,ack. i confused it with `remainingrecords`. all good :),1,0.9837051033973694
216399814,5428,guozhangwang,2018-09-10T17:05:51Z,"quoting your comment: [code block] the above change is for addressing this comment. again i'd admit it is not ideal to rely on the side effect of `computelatency()` to advance `now` but at the same time i want to avoid calling system time necessarily. if you feel strong about it, i can just go ahead and explicitly advance `now`, does it sound better to you?",0,0.980880618095398
216400887,5428,guozhangwang,2018-09-10T17:09:01Z,"okay guys, i'm going to make a final call here to end the discussion: i'm staying with `max.idle..` since i feel it is easier to understand for users, and be aware that this is not strictly respected in practice unless it is set to `0`. also i'm staying with `>=` since again, it is easier to understand though not strictly sound mathematically.",0,0.9187570214271545
216403879,5428,mjsax,2018-09-10T17:17:35Z,:) fair enough.,1,0.9899876713752747
216404303,5428,mjsax,2018-09-10T17:18:48Z,i see. i did not make the connection to the other discussion. i think we can leave as-is.,0,0.9836283922195435
216520595,5428,guozhangwang,2018-09-11T01:14:46Z,"to make it clear, i 1) renamed the function, and 2) explicitly called it outside the `sensor.record` call.",0,0.99519944190979
216550162,5428,mjsax,2018-09-11T05:37:09Z,"should we compute this, before we call `taskmanager.updatenewandrestoringtasks()` ? also, do we need to update `now` after `updatenewandrestoringtasks()` to compute `processlatency` correctly, below?",0,0.99428790807724
216551625,5428,mjsax,2018-09-11T05:48:59Z,nit `stays at 2` seems to be correct -- it's `equalto(2)` below.,0,0.9900021553039551
216829644,5428,guozhangwang,2018-09-11T21:30:35Z,ack.,0,0.5866091847419739
216853354,5428,guozhangwang,2018-09-11T23:15:27Z,ack,0,0.9149930477142334
108246948,2743,hachikuji,2017-03-27T18:38:12Z,sorry for the drive-by comment. maybe this could be `partitionleaderepoch` so there's no potential confusion with the producer epoch?,-1,0.9907572865486145
108319243,2743,junrao,2017-03-28T01:50:05Z,"to follow the existing convention, partition_id and error_id should be partition and error_code?",0,0.9944309592247009
108319252,2743,junrao,2017-03-28T01:50:11Z,epochs => leader epochs ?,0,0.9931568503379822
108319291,2743,junrao,2017-03-28T01:50:33Z,"to follow the convention in other requests like fetchrequest, perhaps we can store map , where int is for leaderepoch?",0,0.9935300946235657
108319308,2743,junrao,2017-03-28T01:50:44Z,could we consolidate the log here and in line 173 into a single one? perhaps it's also useful to log the leo at this point.,0,0.9906812310218811
108319315,2743,junrao,2017-03-28T01:50:50Z,"it seems that during log recovery, we should recover the leader epoch cache as well?",0,0.9929326772689819
108319326,2743,junrao,2017-03-28T01:50:55Z,entry => batch,0,0.9926393032073975
108319349,2743,junrao,2017-03-28T01:51:11Z,"map { case (tp, state) => ...} ?",0,0.9934247732162476
108319571,2743,junrao,2017-03-28T01:53:41Z,"currently, in abstractfetcherthread, we try not to hold the partitionmaplock while making an rpc call. otherwise, if an rpc call takes long for some reason, the becomingleader/follower call will be delayed while waiting for the partitionmaplock. perhaps, we can structure the code like the following. [code block] in processleaderepochrequest(), we can do sth similar to processfetchrequest: send the leaderepochrequest w/o holding partitionmaplock; then hold onto partitionmaplock and do log truncation.",0,0.9895601272583008
108319584,2743,junrao,2017-03-28T01:53:48Z,merge 218-220 into the state line in 217?,0,0.9915391802787781
108319612,2743,junrao,2017-03-28T01:54:02Z,"the reason for calling partitionmapcond.signalall() is to wake up the abstractreplicathread. if the method is only called within abstractreplicathread, we know the thread is awake when making the call. so, there is no need to call signalall().",0,0.9928909540176392
108319622,2743,junrao,2017-03-28T01:54:09Z,handlehandleoffsetforleaderepochrequest => handleoffsetforleaderepochrequest,0,0.9928531050682068
108319626,2743,junrao,2017-03-28T01:54:15Z,it seems that offsetsforleaderepoch.getresponsefor() should be a method in replicamanager?,0,0.9930793642997742
108319633,2743,junrao,2017-03-28T01:54:19Z,missing license header,0,0.9829095602035522
108319657,2743,junrao,2017-03-28T01:54:30Z,"we probably only want to resort to hw if the error is noleaderepoch. otherwise, we should probably just backoff a bit and then retry.",0,0.9819689393043518
108319674,2743,junrao,2017-03-28T01:54:40Z,"if epochoffset.endoffset() is unsupported_epoch_offset, which can happen during the transition phase, we should fall back to hw?",0,0.9905181527137756
108319712,2743,junrao,2017-03-28T01:55:10Z,"if epochoffset.endoffset() >= replica.logendoffset.messageoffset, perhaps we could avoid log truncation.",0,0.992419421672821
108319722,2743,junrao,2017-03-28T01:55:17Z,perhaps we should change the file name to offsetcheckpointfile?,0,0.9908270239830017
108319742,2743,junrao,2017-03-28T01:55:31Z,"if epoch is < latestepoch(), it might be useful to log a warning. we probably also want to assert that offset is > the offset of the last epoch.",0,0.9916300177574158
108319753,2743,junrao,2017-03-28T01:55:36Z,is epochs.last() of o(1) cost? it will be called on every request.,0,0.9947289824485779
108319812,2743,junrao,2017-03-28T01:56:21Z,"we want to be a bit careful here, especially during the transition phase when some existing messages may not have a leader epoch. so, if requestedepoch is < the first epoch in epochs, we probably want to return unsupported_epoch_offset so that the follower can fall back to hw.",0,0.9872522354125977
108319839,2743,junrao,2017-03-28T01:56:39Z,"do we need retainmatchingoffset? it seems that in both log.truncateto() and log.truncatefullyandstartat(), we want the offset to be inclusive, i.e., an epoch with offset will be removed.",0,0.9931300282478333
108319862,2743,junrao,2017-03-28T01:56:53Z,"could we log the topic/partition too? also, does this need to be info? seems more like debug level. ditto below in clearoldest().",0,0.9943916201591492
108319865,2743,junrao,2017-03-28T01:56:55Z,is the comment accurate?,0,0.9898896217346191
108319919,2743,junrao,2017-03-28T01:57:20Z,not sure if we need retainmatchingoffset here either. it seems the caller always wants this to be inclusive.,0,0.9445651173591614
108379720,2743,benstopford,2017-03-28T09:52:12Z,"yes, i'm using a listbuffer: [a link]",0,0.994888961315155
108408756,2743,benstopford,2017-03-28T12:41:13Z,have changed to: `offset >= the offset of the last epoch.` as epoch can increment on the leader when the offset does not change.,0,0.994850218296051
108652909,2743,benstopford,2017-03-29T11:31:33Z,"i've pulled the logic up into abstractfetcherthread. what i've done is somewhat similar to your snippet, but it includes a lock around the truncation step. [code block]",0,0.9945555925369263
109215784,2743,junrao,2017-03-31T17:54:40Z,"it seems that $leaderepoch is the same as ${partitionstateinfo.leaderepoch}? perhaps we can change the logging to ""$topicpartition starts leader epoch $leaderepoch from offset ${getreplica().get.logendoffset.messageoffset}""?",0,0.9939329028129578
109216215,2743,junrao,2017-03-31T17:56:39Z,"given the logging in partition.makeleader(), it seems that we don't need the logging here.",0,0.9921486377716064
109217691,2743,junrao,2017-03-31T18:03:39Z,indentation,0,0.9911677837371826
109219494,2743,junrao,2017-03-31T18:12:35Z,"this needs to be logged before line 80? otherwise, the new epoch is already the last epoch.",0,0.9920152425765991
109225083,2743,junrao,2017-03-31T18:38:38Z,"we only want to return the offset for the epoch if the replica is still the leader. we probably want to call replicamanager.getleaderreplicaiflocal(), catch exceptions like not_leader_for_partition and unknowntopicorpartitionexception and convert it to an error code like what's in replicamanager.readfromlocallog().",0,0.9933803081512451
109225474,2743,junrao,2017-03-31T18:40:24Z,"hmm, if requestedepoch == undefined_epoch, it seems that we should return undefined_epoch_offset so that the follower can fall back to hw.",0,0.9920135140419006
109225572,2743,junrao,2017-03-31T18:40:50Z,inaccurate comment.,-1,0.8814839124679565
109225580,2743,junrao,2017-03-31T18:40:52Z,inaccurate comment.,-1,0.8814839124679565
109226958,2743,junrao,2017-03-31T18:48:03Z,it seems that we should call leaderepochcache.clear() in this case since all data is gone.,0,0.9904589653015137
109227964,2743,junrao,2017-03-31T18:53:24Z,"in this case, we are removing all data starting at startoffset. so, we want to call leaderepochcache.clearlatest instead. even if there is no log recovery, it will be useful to make sure that leaderepochcache is consistent with what's in the log. so, instead of doing it here, we could just call leaderepochcache.clearlatest(nextoffset) immediately after loadsegments().",0,0.9908255934715271
109229094,2743,junrao,2017-03-31T18:59:10Z,"legacy messages will have epoch < 0 and we don't want to flood the logging. so, we can probably only log a warning if epoch is >= 0?",0,0.9797460436820984
109230643,2743,junrao,2017-03-31T19:07:19Z,"not sure if it matters, but we probably want to define leaderepochcache before loadsegments() is called since log recovery needs access to leaderepochcache.",0,0.9506683349609375
109231519,2743,junrao,2017-03-31T19:12:46Z,"i think this also needs to be called during log recovery in logsegment.recover(). also, during this process, it's possible for an older epoch to be assigned again. to avoid the unnecessary logging in maybewarn, on way is for the caller can only call assign() from latestoffset().",0,0.9889601469039917
109256482,2743,junrao,2017-03-31T21:47:17Z,the comment seems inaccurate. deletesegment only clearoldest.,0,0.9673252701759338
109256659,2743,junrao,2017-03-31T21:48:39Z,could we add epochcache to the comment above?,0,0.9948850274085999
109256943,2743,junrao,2017-03-31T21:50:55Z,clearearliest to match clearlatest?,0,0.990912914276123
109261174,2743,junrao,2017-03-31T22:26:58Z,no need for this logging?,0,0.9935210347175598
109261760,2743,junrao,2017-03-31T22:33:01Z,indentation,0,0.9911677837371826
109262199,2743,junrao,2017-03-31T22:37:36Z,allpartitions no longer used.,0,0.9892848134040833
109263288,2743,junrao,2017-03-31T22:48:18Z,this can be private.,0,0.9921234250068665
109264654,2743,junrao,2017-03-31T23:02:45Z,consumerid not used.,0,0.9902178645133972
109265484,2743,junrao,2017-03-31T23:12:15Z,"we should probably add a new tag kafka_0_11_0_iv2 which corresponds to the introduction of leaderepoch request, and use it here.",0,0.9944814443588257
109265507,2743,junrao,2017-03-31T23:12:29Z,"""fetch from the leader"" can be a bit confusing. ""issue leaderepochrequest to the leader""?",0,0.745839536190033
109265520,2743,junrao,2017-03-31T23:12:34Z,remove ?,0,0.9910047054290771
109268030,2743,junrao,2017-03-31T23:45:31Z,perhaps we can also change the line 945 from if(targetoffset > logendoffset) { to if(targetoffset >= logendoffset) {,0,0.9918280839920044
109269015,2743,junrao,2017-03-31T23:58:16Z,this is the case the leader returned an offset >= leo. it would be useful to log the topic/partition as well.,0,0.994081437587738
109269023,2743,junrao,2017-03-31T23:58:20Z,it would be useful to log the topic as well.,0,0.992436945438385
109269093,2743,junrao,2017-03-31T23:59:19Z,could we add override?,0,0.9948447942733765
109269313,2743,junrao,2017-04-01T00:02:35Z,this can be private.,0,0.9921234250068665
109269322,2743,junrao,2017-04-01T00:02:44Z,this can be private.,0,0.9921234250068665
109269876,2743,junrao,2017-04-01T00:11:25Z,it doesn't seem this method and the trait are used.,0,0.9699864983558655
109311609,2743,junrao,2017-04-02T15:27:22Z,"could we remove todo? if we just want to test corrupted messages, there is no need to set includepartitioninitialisation to true.",0,0.9936062097549438
109312409,2743,junrao,2017-04-02T15:58:38Z,this is because we bounce the leader epoch when the controller changes the isr too so that the latest isr can be updated in the broker's cache.,0,0.9935070276260376
109312786,2743,junrao,2017-04-02T16:17:18Z,"hmm, there is a subtle question here, which is should the new epoch be added to epoch cache when the leader epoch advances or when there is actually a message added in the new epoch. the latter means that epoch will be more consistent after log recovery and be more consistent between the leader and the follower. so, perhaps it's better to do the latter. then the flow will be (1) we remember the latest epoch in partition.leaderepoch when receiving leaderandisrrequests, but not updating the leader epoch cache yet; (2) we pass partition.leaderepoch to log.append() and only update the leader epoch cache when there is a new message produced. this will also make the test a bit easier to understand since the epoch will always be consistent btw the leader and the follower.",0,0.9613938927650452
109313719,2743,junrao,2017-04-02T16:54:09Z,this can be done using testutils.waituntiltrue(() ?,0,0.9954336285591125
109313817,2743,junrao,2017-04-02T16:58:00Z,"since we have a large linger and batch size in the producer, does it matter whether we send those 100 messages in batches? it seems that all of them will be in the same batch after the flush() call.",0,0.9906762838363647
109314127,2743,junrao,2017-04-02T17:10:49Z,unused method.,0,0.9858924746513367
109314585,2743,junrao,2017-04-02T17:31:46Z,put two statements in different lines and remove ;,0,0.99335116147995
109314603,2743,junrao,2017-04-02T17:32:27Z,remove ;,0,0.9890912175178528
109314622,2743,junrao,2017-04-02T17:33:15Z,remove ; in the above 2 statements. ditto in a few other places.,0,0.9900630116462708
109315673,2743,junrao,2017-04-02T18:11:09Z,"deletecorrespondingleaderepochs should only be set to true when we are deleting a prefix of the log segments. the only caller for that is def deletesegments(deletable: iterable[logsegment]). also, segment.nextoffset() needs scanning the log and can be a bit expensive. so, perhaps, we can call leaderepochcache.clearoldest() in deletesegments(deletable: iterable[logsegment]) with the recomputed logstartoffset, which is much cheaper.",0,0.99122554063797
109316101,2743,benstopford,2017-04-02T18:27:47Z,"this was a pretty big change, but the final one of your first round of comments. committed now.",0,0.9222674369812012
109316191,2743,junrao,2017-04-02T18:32:06Z,"the error message seem inaccurate. here, we are just verifying the log for broker 0, not for broker 1.",0,0.9178293943405151
109316509,2743,junrao,2017-04-02T18:47:39Z,do we need testsender or could we just reuse replicafetcherblockingsend?,0,0.9948782920837402
109320017,2743,junrao,2017-04-02T21:05:12Z,"when clearearliest() is called, it means that the first offset of the log starts at offset. so we want to (1) preserve an entry whose startoffset == offset; (2) if the last entry whose startoffset is < offset and the next entry's offset is > offset or is not present, we want to preserve that last entry and just set its startoffset to offset. we want to change the comment accordingly.",0,0.992645263671875
109320018,2743,junrao,2017-04-02T21:05:14Z,oldest => earliest?,0,0.9910945892333984
109320084,2743,junrao,2017-04-02T21:07:48Z,is this needed?,0,0.9945470094680786
109320101,2743,junrao,2017-04-02T21:08:16Z,should we use just use createproducer()?,0,0.9944012761116028
109320117,2743,junrao,2017-04-02T21:08:55Z,a few methods like that can be made private.,0,0.9926795959472656
109320127,2743,junrao,2017-04-02T21:09:21Z,"hmm, why do we need to create a new producer here? if so, should we close the old one first?",0,0.986047625541687
109320169,2743,junrao,2017-04-02T21:11:39Z,this is because we have to first change leader to -1 and then change it again to the live replica.,0,0.9917190074920654
109320452,2743,junrao,2017-04-02T21:24:48Z,a few methods like that in this file can be private.,0,0.9901418089866638
109320567,2743,junrao,2017-04-02T21:29:44Z,is this needed? it seems that we create the dir when initializing log in loadsegments().,0,0.9945152401924133
109320709,2743,junrao,2017-04-02T21:34:25Z,the second param should be offset + 3 too?,0,0.9932852983474731
109321139,2743,junrao,2017-04-02T21:50:17Z,this can be private.,0,0.9921234250068665
109321508,2743,junrao,2017-04-02T22:04:12Z,"hmm, if we are only deleting one segment, shouldn't the first offset be 5 and we should preserve epochentry(1,5)?",0,0.9812819957733154
109321591,2743,junrao,2017-04-02T22:06:53Z,this is actually not truncating the first segment. ditto in line 1478.,0,0.9898051023483276
109321653,2743,junrao,2017-04-02T22:09:46Z,"hmm, we are already testing multiple lines in the previous test. is this testing multiple partitions in the same topic?",0,0.9788373708724976
109321773,2743,junrao,2017-04-02T22:14:26Z,should this be removed now that leader epoch is at the set level?,0,0.9939417839050293
109321789,2743,junrao,2017-04-02T22:15:07Z,unused import,0,0.9873000979423523
109321997,2743,junrao,2017-04-02T22:24:47Z,the code is for 3 times.,0,0.9936258792877197
109322753,2743,junrao,2017-04-02T22:54:58Z,the part of calling assign() during log recovery still needs to be addressed.,0,0.9888894557952881
109322961,2743,junrao,2017-04-02T23:02:18Z,"this probably can be done in a followup patch. if there is an error, we probably want to add a bit of delay to the partition before retrying the offsetsforleaderepoch request (like what we do when the fetch request has an error).",0,0.9942995309829712
109333196,2743,junrao,2017-04-03T02:45:44Z,should we uncomment this?,0,0.9945304989814758
109447563,2743,benstopford,2017-04-03T15:29:09Z,"(2) is a good point. thank you. have altered and added appropriate tests. in a bit of a rush, coding this in the airplane lounge.",1,0.9902312159538269
109447763,2743,benstopford,2017-04-03T15:29:50Z,i need this to get tests to pass locally. feel free to remove as i have a pr to change these running separately.,0,0.9908605813980103
109448157,2743,benstopford,2017-04-03T15:31:17Z,hmm. this is covering a chicken/egg situation around the initialisation of log (i.e. where we initialise leaderepochcache). needs changing.,0,0.9748570919036865
109547558,2743,junrao,2017-04-03T23:24:20Z,epochsbytopic => epochsbytopicpartition?,0,0.9936822652816772
109547577,2743,junrao,2017-04-03T23:24:27Z,this doesn't seem to be used.,0,0.9637539386749268
109547593,2743,junrao,2017-04-03T23:24:34Z,this doesn't seem to be used.,0,0.9637539386749268
109547736,2743,junrao,2017-04-03T23:25:33Z,-1l = > epochendoffset.undefined_offset ?,0,0.9803312420845032
109547743,2743,junrao,2017-04-03T23:25:39Z,the method is not used.,0,0.9924141764640808
109547807,2743,junrao,2017-04-03T23:26:02Z,"at this point, the log dir may not have been created. so, we probably need to make sure the log dir exists first.",0,0.9861853718757629
109547834,2743,junrao,2017-04-03T23:26:16Z,we can set the deleteepoch flag to false here since we call clearlatest() after loading the log.,0,0.9951270818710327
109547857,2743,junrao,2017-04-03T23:26:26Z,could we move line 943 to after line 949?,0,0.9925519227981567
109547889,2743,junrao,2017-04-03T23:26:37Z,"could we remove the todo? also, could we move this line to before line 960?",0,0.9951796531677246
109548130,2743,junrao,2017-04-03T23:28:14Z,"hmm, if the broker is on a version before kafka_0_11_0_iv2 and we don't let the partition go through the initialization phase, then the followers won't be doing any truncation based on hw. we can probably always set the partition to need initialization. if the broker is on a version before kafka_0_11_0_iv2, in fetchepochsfromleader(), we don't do the actual leader epoch request, but simply set the response to unknown_offset. then the maybetruncate() logic will just fall back to hw.",0,0.9884811639785767
109548156,2743,junrao,2017-04-03T23:28:20Z,it would be useful to log the topic/partition as well.,0,0.9928175210952759
109548176,2743,junrao,2017-04-03T23:28:27Z,do maybewarn() in else?,0,0.9959121942520142
109548190,2743,junrao,2017-04-03T23:28:33Z,"it will be useful to log the topic/partition as well. also, could this just be debug level logging?",0,0.9945080876350403
109548206,2743,junrao,2017-04-03T23:28:42Z,"if earliestoffset() == offset, it seems that we don't need to do anything.",0,0.9911907911300659
109548223,2743,junrao,2017-04-03T23:28:49Z,"similar here, we want to find entries with entry.startoffset < offset.",0,0.9932592511177063
109548234,2743,junrao,2017-04-03T23:28:54Z,not sure if we need the if test here.,0,0.8511692881584167
109548266,2743,junrao,2017-04-03T23:29:09Z,"this should say ""epoch < latestepoch"". an partitionleaderepoch => a partitionleaderepoch",0,0.9952307343482971
109548287,2743,junrao,2017-04-03T23:29:19Z,it seems that we only append messages of format v2 and newer. so epoch is never expected to be <0 ?,0,0.9915688633918762
109548308,2743,junrao,2017-04-03T23:29:29Z,"hmm, it seems that only the first segment will be removed according to the retention policy?",0,0.9722508788108826
109548322,2743,junrao,2017-04-03T23:29:35Z,it's no longer doing this in batches.,0,0.9751646518707275
109548330,2743,junrao,2017-04-03T23:29:39Z,this can be private.,0,0.9921234250068665
109548343,2743,junrao,2017-04-03T23:29:47Z,put two statements in different lines and remove ; there are quite a few other places using ;.,0,0.992782711982727
109651046,2743,benstopford,2017-04-04T12:42:53Z,"oh, it's used by one of the tests. authorizerintegrationtest. all the request/response classes have it.",0,0.9903094172477722
109651092,2743,benstopford,2017-04-04T12:43:09Z,as above,0,0.9888283014297485
109651463,2743,benstopford,2017-04-04T12:45:10Z,see authorizerintegrationtest,0,0.9933276176452637
109781747,2743,benstopford,2017-04-04T21:26:54Z,"i think this is ok, but can remove if you feel strongly.",0,0.56122887134552
109795882,2743,benstopford,2017-04-04T22:43:51Z,hmm. i think this actually correct. i would like a better way to express it but i can't see one. i'd encourage you to look at the tests in leaderepochfilecachetest to see if you disagree with any of them.,0,0.8698164224624634
109967050,2743,junrao,2017-04-05T16:41:06Z,"yes, i agree that it's needed.",0,0.9617729783058167
124910746,2743,lindong28,2017-06-29T20:55:49Z,it seems that the method's java doc is inconsistent with its behavior if requestedepoch is < the first epoch in epochs. i am wondering if we should update the java doc or comment in this code to explain this. i only realized it is intentional after reading this 's comment in this pull request.,0,0.9589501023292542
124923278,2743,junrao,2017-06-29T22:01:02Z,: we can clarify that in the comment. could you file a jira?,0,0.9945032596588135
124927503,2743,lindong28,2017-06-29T22:27:39Z,sure. i filed [a link] and assigned it to .,0,0.9847951531410217
1890534015,18240,jsancio,2024-12-18T16:37:36Z,can we try moving this to the internal module? anything public in this package can be used outside the `raft` module.,0,0.9950714111328125
1890534655,18240,jsancio,2024-12-18T16:38:08Z,can we explicitly mark private any method that is not used outside of this class?,0,0.9943320751190186
1890535623,18240,jsancio,2024-12-18T16:38:49Z,please write java doc for all public methods.,0,0.9949786067008972
1890542820,18240,jsancio,2024-12-18T16:43:51Z,`illegalargumentexception` seems like a better exception type.,0,0.9793213605880737
1890544866,18240,jsancio,2024-12-18T16:45:11Z,let's write java doc for all public methods.,0,0.9944878220558167
1890552560,18240,jsancio,2024-12-18T16:50:45Z,"this is not a warning. this is a valid state or condition. we should be able to log this message at info level. it should be rare because there are backoff/timeout logic in candidate, follower and unattached which limit how quickly a replica transitions to prospective. what do you think?",0,0.9793733358383179
1890554341,18240,jsancio,2024-12-18T16:52:04Z,let's use the same word you used in the `nomineestate`: `isnomineestate()` and `nomineestateorthrow()`.,0,0.9944333434104919
1890660800,18240,ahuang98,2024-12-18T18:22:03Z,"|i see your point here, there's nothing 'incorrect' about this happening. but i'm wondering about the case where a controller quorum is left partially upgraded on accident. would having a warning log make this situation more discoverable?",0,0.9411438703536987
1890678659,18240,jsancio,2024-12-18T18:37:30Z,"yeah. this would be interesting to monitor but cluster are not really monitored by looking at the log. clusters are monitored by collecting and comparing metrics. this is an issue beyond kraft and should be solved holistically. kafka could have a metrics that fires if the api versions and supported features don't match across all of the replicas. this metric would require a kip to implement. having said that, we should keep this message but it should not be logged at warn. it should be logged at info.",0,0.8778212070465088
1894260795,18240,ahuang98,2024-12-20T18:28:20Z,"it might not be expected that a state has both leader and voted key state, but i think it's better not to lose the state if it does happen to exist. not an issue for backwards compatibility, older version would lose votedkey state but would have leader state and will reject standard votes correctly because of that.",0,0.9742028117179871
1895898210,18240,ahuang98,2024-12-23T15:52:47Z,"open to what you think, this definitely isn't necessary but i thought this could help reduce the complexity of handlevoteresponse (this is called in a 3rd level of conditional statements)",0,0.9218603372573853
1895926505,18240,ahuang98,2024-12-23T16:24:52Z,"found existing test which checks that observers with ids can vote - [a link] which was added in kafka-16526, so i've removed `voted` for now (vs translating to `unattachedvoted`)",0,0.993762195110321
1896920647,18240,jsancio,2024-12-24T18:52:19Z,the type should be `candidatestate`. let's add the field `retries` back to the message. how about replacing `voterstates` with `epochstate` and implementing a `tostring` method for `epochstate`?,0,0.9950101375579834
1896921039,18240,jsancio,2024-12-24T18:53:27Z,let's move this method so that it doesn't show in the diff.,0,0.9919513463973999
1896921206,18240,jsancio,2024-12-24T18:53:57Z,let's move this method so that it doesn't show in the diff.,0,0.9919513463973999
1896921449,18240,jsancio,2024-12-24T18:54:31Z,let's move this method so that it doesn't show in the diff.,0,0.9919513463973999
1896921655,18240,jsancio,2024-12-24T18:54:53Z,let's move this method so that it doesn't show in the diff.,0,0.9919513463973999
1896923862,18240,jsancio,2024-12-24T19:01:12Z,let's revert this change. we should make it clear that this pr is not changing the persisted `quorum-state`.,0,0.9942671656608582
1896926243,18240,jsancio,2024-12-24T19:07:42Z,nice code removal! thanks.,1,0.995540201663971
1896926826,18240,jsancio,2024-12-24T19:09:03Z,"i got the impression that you don't use this in `src/main`. if so, let's remove it.",0,0.9881296157836914
1896930978,18240,jsancio,2024-12-24T19:21:53Z,"let's just remove this method and have the tests use `transitiontounattached(int, optionalint)`. also update the java doc to match the new signature and parameters.",0,0.9944447875022888
1896932468,18240,jsancio,2024-12-24T19:26:02Z,"let's remove this and update the callers to use `transtitiontounattached(int, optionalint)`.",0,0.9946660995483398
1896934629,18240,jsancio,2024-12-24T19:32:12Z,how about: [code block],0,0.9942854046821594
1896935574,18240,jsancio,2024-12-24T19:35:15Z,let's fix the indentation. in the raft module we using this formatting style: [code block],0,0.994478702545166
1896936282,18240,jsancio,2024-12-24T19:37:26Z,let's fix this formatting. see my under examples on how we try to format code in the raft module.,0,0.9935413599014282
1896936776,18240,jsancio,2024-12-24T19:39:06Z,this code only have one caller. how about just manually inline it at the call site.,0,0.9909892678260803
1896939688,18240,jsancio,2024-12-24T19:47:01Z,same here. let's fix the indentation since you are already changing this part of the code.,0,0.9939273595809937
1896941400,18240,jsancio,2024-12-24T19:52:07Z,i think this is too relax. the previous code assumed that if `leaderid.ispresent()` then `!leaderendpoints.isempty()`. that should not change in this pr.,0,0.8303341865539551
1896944012,18240,jsancio,2024-12-24T20:00:05Z,when would raft hit this case?,0,0.9818525910377502
1896944517,18240,jsancio,2024-12-24T20:01:45Z,"minor but you can just inline the expression: `quorum.isprospective()`. also, the call site that calls this knows the `nomineestate` so it can use that information to determine if the request is a prevote request. no need to query `quorumstate` for this information. for example, you can add `isprevote` to the `nomineestate` interface and update the signature of this method to `buildvoterequest(replicakey, boolean)`.",0,0.9864329695701599
1896952514,18240,jsancio,2024-12-24T20:29:38Z,this handle when the majority of the voters rejected the candidate. this needs to also handle when the majority of the voters reject the prospective candidate.,0,0.9905333518981934
1896953461,18240,jsancio,2024-12-24T20:33:17Z,this code shouldn't check `isvoterejected` if it is handled in `handlevoterespose`. i left a comment about this in that method. this is an event driven programming model. the event that cause the majority of the voters to reject the prospective state is received in the vote response. and not when polling the prospective state.,0,0.9891719222068787
1896955782,18240,jsancio,2024-12-24T20:40:24Z,i see. retries is only preserved when the prospective transition from prospective to candidate. the retries are lost if it transitions to unattached. i think we should file a jira to remove this exponential backoff. i am convinced that it is starting to lose its value with this implementation and if we make the election timeout improvements you highlight in the kip,0,0.9581491351127625
1896957160,18240,jsancio,2024-12-24T20:44:47Z,let's also include the epoch election and add a `tostring` method to the `epochelection` type.,0,0.9950544834136963
1896957660,18240,jsancio,2024-12-24T20:46:39Z,let's write a comment explaining why this expression is needed.,0,0.9938217401504517
1896958513,18240,jsancio,2024-12-24T20:49:40Z,should this check that the epoch is not decreasing?,0,0.9931625127792358
1896958745,18240,jsancio,2024-12-24T20:50:28Z,let's fix this formatting. [code block],0,0.9943424463272095
1896958960,18240,jsancio,2024-12-24T20:51:19Z,this should check that the epoch is not decreasing.,0,0.99439936876297
1896959037,18240,jsancio,2024-12-24T20:51:36Z,fix formatting.,0,0.9661014676094055
1896960167,18240,jsancio,2024-12-24T20:55:06Z,how about this formatting: [code block],0,0.9928118586540222
1896961481,18240,jsancio,2024-12-24T21:00:19Z,let's add a java doc comment to this method.,0,0.9951049089431763
1896962158,18240,jsancio,2024-12-24T21:02:46Z,let's undo this change. it is good to keep the existing invariant to avoid persisting both `leaderid` and `votedkey`.,0,0.994148850440979
1896962727,18240,jsancio,2024-12-24T21:04:56Z,let's add a `tostring` method to this type so that its value is included in log messages.,0,0.9942231774330139
1896962935,18240,jsancio,2024-12-24T21:05:52Z,this is a publicly visible change. let's update the kip if it doesn't include this change.,0,0.9934966564178467
1897006321,18240,ahuang98,2024-12-25T00:07:15Z,"this method is solely for the case of adding voted state to unattached in the same epoch (if higher epoch, we take the path of transitiontounattached) the transitiontounattached method has the following comment, i will duplicate it for this method too [code block]",0,0.9955582618713379
1897013977,18240,ahuang98,2024-12-25T00:36:05Z,"i think i had convinced myself this was arguably not an invariant since it is not enforced (and perhaps just an unintentional quality of kraft today). i know we chatted earlier about how kraftversion=2 should enforce that both votedkey and leaderid are persisted if they exist, which i agree with. i guess what we're not on the same page about is if we can start to persist all the information we have, now. i would argue it is fine to do now because it is backwards compatible, the additional info isn't necessary for correctness, and losing that additional information also doesn't affect correctness (e.g. currently, if unattached with leaderid grants a standard vote, it transition to unattachedvoted w/o leaderid. unattachedvoted w/o leaderid and unattachedvoted w/ leaderid behave the same way in rejecting votes. if unattached has both leaderid and votedkey in electionstate and then downgrades, it would only retain the votedkey and transition to unattachedvoted w/o leader, which is the same transition that would have been taken in the past for an unattached w/ leaderid that grants a vote)",0,0.9404481053352356
1897014715,18240,ahuang98,2024-12-25T00:39:01Z,"retaining both leaderid and votedkey also can help other replicas find the leader faster (though not needed for correctness) - unattachedvoted w/ leader will reject vote requests w/ a leaderid unattachedvoted w/o leader will reject vote request w/o a leaderid if we only persist one, then on startup a replica just doesn't have all the information it _could_ have",0,0.9915834069252014
1899044657,18240,ahuang98,2024-12-29T01:12:26Z,fixed. i added this because i thought it was an oversight not to check for empty endpoints given that we can initialize in unattachedstate when the leaderendpoints are not known. but i see now that `maybetransition` is only called in places where the leaderendpoints are expected to be populated,0,0.9788891077041626
1899071006,18240,ahuang98,2024-12-29T06:28:07Z,fixed,0,0.920660674571991
1899072269,18240,ahuang98,2024-12-29T06:41:32Z,we can use this jira to track - [a link],0,0.9958900809288025
1899074255,18240,ahuang98,2024-12-29T06:59:55Z,i could also remove `epoch` as one of the params (method can use state.currentepoch instead of parameter value). but i would prefer to keep `epoch` as a param so we can validate the method is being used correctly (without any unintentional epoch change).,0,0.9942398071289062
1899074463,18240,ahuang98,2024-12-29T07:01:25Z,"same as above, this is meant to be called only to transition from prospectivenotvoted in epoch x to prospectivevoted in epoch x",0,0.9943011999130249
1899076157,18240,ahuang98,2024-12-29T07:16:33Z,"this is called within the third level of a conditional statement, adding this back violates checkstyle's cyclomatic complexity check",0,0.9942613840103149
1899077542,18240,ahuang98,2024-12-29T07:27:49Z,"for now, i've kept the helper but increased its scope to handle the case when prospective loses the election. i've renamed it as `maybehandleelectionloss`",0,0.9936796426773071
1899341945,18240,ahuang98,2024-12-30T07:39:52Z,"the existing raft event simulation tests picked up on a new bug in pollresigned - if we simply replace the transitiontocandidate(currenttimems) with transitiontoprospective(currenttimems), a cordoned leader in epoch 5 could resign in epoch 5, transition to prospective in epoch 5 (with leaderid=localid), fail election and then attempt to become follower of itself in epoch 5. so far, these are the alternatives which seem reasonable to me: - resigned voter in epoch x should transition to prospective in epoch x+1 - cons: need to create a special code path just for this case to allow becoming prospective in epoch+1 (would also add trivial complexity for determining if votedkey or leaderid should be kept from prior transition). transitioning to prospective in epoch + 1 is almost as disruptive as transitioning directly to candidate since it involves an epoch bump - pro: probably the option which follows intentions of past logic most closely - resigned voter in epoch x should simply transition to unattached in epoch x+1 (current version) - con: resigned replica has to wait two election timeouts after resignation to become prospective - pro: simplified logic. unless this is the only replica eligible for leadership in the quorum (e.g. due to network partitioning), the impact of waiting two election timeouts after resignation is small - all other replicas should be starting their own elections within a single fetch timeout/election timeout - resigned voter in epoch x instead waits a smaller backofftimems before transitioning to unattached in epoch x+1 - con: scope creep - what should this backoff be? additional changes to resignedstate - pro: resigned voter waits less time before becoming eligible to start a new election.",0,0.9920036196708679
1899579689,18240,jsancio,2024-12-30T14:26:34Z,yes. this is correct. observers can vote for candidate (kip-853) and prospective (kip-996). this was changed as part of kip-853 as documented [a link].,0,0.9877839684486389
1899610803,18240,jsancio,2024-12-30T15:11:33Z,"got it. thanks. i see now that kraft doesn't check if both the leader and voted field are set during iniialization. during initialization, it does check the voted field first before checking the leader field. i think we should switch that order. if the leader and the leader endpoints are known, the replica should transition to follower immediately instead of needing to rediscover the leader. let's change this comment too as it is slightly inaccurate. there are many reason why the replica may not send the leader endpoints. using an old version for the rpc is not the only reason why the replica may send the leader id but not the leader endpoint: [code block]",1,0.9880197644233704
1899633981,18240,jsancio,2024-12-30T15:47:39Z,what is the exact error? let's add an unittest to one of the `kafkaraftclient*test` suite that shows the bug. let's add a check to `transtitiontofollower` that checks that `leaderid` is not equal to `localid`. it makes sense to me that after the resign state the replica should always increase its epoch. the replica resigned from leadership at epoch x so eventually the epoch will be at least x + 1. did you consider transitioning to candidate and relaxing the transition functions to allow both resigned and prospective to transition to candidate?,0,0.9939473867416382
1899726228,18240,ahuang98,2024-12-30T18:37:26Z,"discussed offline, transitiontounattached has existing logic for assigning election timeouts which we can borrow - we can just add an additional if clause that if we came from resignedstate, assign electiontimeout to resignedstate.electiontimeout which is effectively 0",0,0.9933950304985046
1899726857,18240,ahuang98,2024-12-30T18:38:54Z,discussed offline that this method is only used for adding voted state to unattached (in same epoch),0,0.9935978651046753
1899727021,18240,ahuang98,2024-12-30T18:39:15Z,discussed offline,0,0.975737988948822
1899773951,18240,jsancio,2024-12-30T20:22:57Z,sounds good to keep the epoch parameter and validating it against the current epoch.,1,0.5791210532188416
1899778973,18240,jsancio,2024-12-30T20:34:54Z,let's add an else case and throw an illegal state exception.,0,0.9761679768562317
1899780274,18240,jsancio,2024-12-30T20:38:21Z,"how about passing the `nomineestate` object, checking the subtype of that object and casting to the appropriate subtype.",0,0.9917782545089722
1899782793,18240,jsancio,2024-12-30T20:44:33Z,how about just printing the entire `epochelection`? it may be useful to know the state of the entire voter set not just the rejecting voters.,0,0.990528404712677
1899783114,18240,jsancio,2024-12-30T20:45:25Z,how about just printing the entire `epochelection`? it may be useful to know the state of the entire voter set not just the rejecting voters.,0,0.990528404712677
1899783839,18240,jsancio,2024-12-30T20:47:12Z,"i think you can join these lines. if not, there should be a newline before `);`",0,0.9903602600097656
1899783973,18240,jsancio,2024-12-30T20:47:36Z,add a newline before `);`.,0,0.993627667427063
1899785061,18240,jsancio,2024-12-30T20:50:11Z,remove this line. let's not have commented code.,0,0.9919281005859375
1899785505,18240,jsancio,2024-12-30T20:51:24Z,let add a comment that summarizes our discussion and conclusion. it is good to document and explain this decision.,1,0.9733875393867493
1899790092,18240,jsancio,2024-12-30T21:03:06Z,"as we discussed offline, the resigned state also transitions to unattached with a greater epoch. let's document that. having said that, let's also update the comment at the top of this file that documents the transitions from resigned: let's also update the kip.",0,0.9937949180603027
1899791694,18240,jsancio,2024-12-30T21:07:39Z,missing new line between these two lines.,0,0.9785758852958679
1900259204,18240,jsancio,2024-12-31T20:30:38Z,let's keep the previous pattern of using static methods to construct `electionstate`. you can add `optional ` parameter to `withelectedleader`.,0,0.9936182498931885
1900264788,18240,jsancio,2024-12-31T20:55:16Z,"why do you need to call `maybefireleaaderchange`? based on the inputs and since prospective doesn't increase the epoch, i would assume that the leader and epoch doesn't change when transitioning to prospective.",0,0.9915972352027893
1900278415,18240,jsancio,2024-12-31T22:01:43Z,"`quorumstate` already logs all transitions. it logs the ""from"" and ""to"" state. not sure this add any information.",0,0.9718031883239746
1900278536,18240,jsancio,2024-12-31T22:02:33Z,same here. quorumstate already logs all state transitions.,0,0.9944860339164734
1900279911,18240,jsancio,2024-12-31T22:09:59Z,"transitioning to prospective is not really a durable transition since no persisted data should have changed, right? you can see this is the case since the function `transitiontoprospective` doesn't take any inputs and it doesn't increase the epoch. in other words, the information that is persisted is information that quorum state already knows and has already been persisted.",0,0.9902387857437134
1900448685,18240,jsancio,2025-01-01T19:17:21Z,"you don't need this method, right? this method is declared by `epochstate`.",0,0.9941962957382202
1900449219,18240,jsancio,2025-01-01T19:22:56Z,can you remove this if it is not needed anymore?,0,0.9950252175331116
1900449269,18240,jsancio,2025-01-01T19:23:30Z,can you remove this if it is not needed?,0,0.9949091076850891
1900451851,18240,jsancio,2025-01-01T19:45:23Z,offline you mentioned that you added this because you didn't want to lose information when transitioning states. i agree with this goal but the voted key is lost when the replica transitions to the `leaderstate`. do you agree? if so can you file a jira to fix this after this pr.,0,0.9890628457069397
1900452510,18240,jsancio,2025-01-01T19:50:09Z,minor but let's just remove the `=` sign. [code block],0,0.9915447235107422
1900453595,18240,jsancio,2025-01-01T19:59:59Z,state transition changes are already logged at `info` level.,0,0.9945088028907776
1900455665,18240,jsancio,2025-01-01T20:18:33Z,"isn't this the same [code block] if so, you can remove the variable `retainvotedkey`. similar to the unattached implementation, let's document why this is done.",0,0.9950190782546997
1900458506,18240,jsancio,2025-01-01T20:42:39Z,"you should be able to remove the check for if it is the only voter by making that case transition to prospective instead. when the replica transitions to prospective, it already short-circuits that transition. when the replica transitions to prospective it checks if it can immediately transition to candidate.",0,0.9939821362495422
1900460957,18240,jsancio,2025-01-01T21:04:44Z,looks like this doesn't need to be public. looks like this method can be removed since it is not used.,0,0.9870675206184387
1900461371,18240,jsancio,2025-01-01T21:08:36Z,why not just print the map? [code block],0,0.9932326078414917
1900540449,18240,ahuang98,2025-01-02T04:59:01Z,"it felt redundant to print the keys given that the replica ids are also contained in the values. since this is would only be used for debugging though, i'll take your suggestion and just print the entire map",0,0.9836317300796509
1900541138,18240,ahuang98,2025-01-02T05:01:16Z,"replicakey's tostring method contains the class name so i didn't want to be redundant - `string.format(""replicakey(id=%d, directoryid=%s)"", id, directoryid);`",0,0.9945492148399353
1900546362,18240,ahuang98,2025-01-02T05:17:15Z,like the following? [code block] is the intention of the additional parameter to make it clear this method should be called on nomineestate? this seems a bit redundant with the existing quorumstate helpers (e.g. iscandidate() and candidatestateorthrow()).,0,0.9847723245620728
1900571487,18240,ahuang98,2025-01-02T06:24:14Z,i'll also change prospective and unattached's election() to use the static methods.,0,0.9944484233856201
1900580715,18240,ahuang98,2025-01-02T06:46:34Z,replacing with code comments instead,0,0.9949051141738892
1900583997,18240,ahuang98,2025-01-02T06:54:06Z,:exploding_head:,0,0.9825962781906128
1900614259,18240,ahuang98,2025-01-02T07:53:35Z,thanks! i'll add the logic for short-circuiting transitions for only-voters. this also allows our invariant - only prospective can transition to candidate - to remain simple w/o edge cases.,1,0.9819914698600769
1900648700,18240,ahuang98,2025-01-02T08:43:45Z,are you perhaps confusing `epochelection` with `electionstate` (the latter is what epochstate has declared),0,0.9650279879570007
1900951176,18240,jsancio,2025-01-02T14:48:09Z,"if the quorum has a size of one and since the replica votes for itself when transitioning to prospective, `isvotegranted()` should always return true. if so, the replica doesn't need to check if it is the only voter. let's confirm we have a test for this in kafkaraftclienttest. if not, let's add a test. let's also confirm that we have a test for this in prospectivestatetest and candidatestatetest. if not, let's add tests for these cases.",0,0.9928703904151917
1900954282,18240,jsancio,2025-01-02T14:51:23Z,why do you check that is not leader? in kraft a replica should never start as a leader. kraft throws and illegal state exception if it starts as leader. see line 545 above. [code block],0,0.9769028425216675
1901113187,18240,jsancio,2025-01-02T17:43:07Z,yes. we discussed this offline.,0,0.9898779392242432
1901117479,18240,ahuang98,2025-01-02T17:48:39Z,discussed,0,0.979872465133667
1901142655,18240,ahuang98,2025-01-02T18:17:36Z,"discussed offline, technically the replica can transition to leader due to the above conditional. we can improve this conditional by directly checking if the replica is unattached or follower, and merge this conditional into the above conditional",0,0.9931557774543762
1901235462,18240,ahuang98,2025-01-02T20:27:29Z,"added four tests for this, starting at `testinitializeasonlyvoterwithemptyelectionstate` confirmed!",0,0.8085984587669373
1902113084,18240,ahuang98,2025-01-03T19:49:45Z,"i've organized quorumstatetest in the following way - misc tests were pulled to the front. all other tests are organized under banners (e.g. initialization tests, tests of transitions from state x)",0,0.9933337569236755
1902114352,18240,ahuang98,2025-01-03T19:51:26Z,the diff is misleading here. this test was just removed because i found it was a duplicate of `testinitializeasresignedleaderfromstatestore`,0,0.9363299608230591
1902116235,18240,ahuang98,2025-01-03T19:54:13Z,the hw drops to -1l after candidate transitions to leader - if you agree this is a bug i'll file a jira for this,0,0.9907139539718628
1915345255,18240,jsancio,2025-01-14T17:48:56Z,this feels like it needs a comment explaining what and why.,0,0.9116532802581787
1915429555,18240,ahuang98,2025-01-14T18:45:41Z,clobbered `unattachedstatewithvotetest.java` into `unattachedstatetest.java`. i didn't think it was necessary to have a separate file (both having votedkey state and leaderid state are tested in this one file). i wanted to prevent introducing a separate withvotetest for prospectivestate as well,0,0.9910988211631775
1916914867,18240,jsancio,2025-01-15T15:55:11Z,okay. i went through all of the possible combination of quorum state and this change seem to be backward compatible and correct.,0,0.9855359196662903
1917004191,18240,jsancio,2025-01-15T16:43:54Z,"please make sure that all of the constructors delegate to this constructor. there is at least one constructor (`this(optionalint, uuid)`) that doesn't delegate construction to this constructor. that may mean that the tests should not specify the voters through the constructor but instead use the `with...` methods. in general the `builder` constructor should be as small as possible and the user can override the configuration using the builder's methods before calling `build()`. i think that means that ideally we should delete this method or it should have this signature: `builder(replicakey)`.",0,0.9891191720962524
1917022963,18240,jsancio,2025-01-15T16:55:41Z,can we avoid this? can we let the caller makes this decision? it is technically possible for the replicas to support new rpc (protocols) but their voter configuration to be static.,0,0.9901381731033325
1917031492,18240,jsancio,2025-01-15T17:00:48Z,let's create a followup jira to remove this method.,0,0.9947015047073364
1917037427,18240,jsancio,2025-01-15T17:05:00Z,"we are very close to being able to remove this method, `initializedasleader`. do you want to do the honor and fix the last remaining test?",0,0.9941204190254211
1917046168,18240,jsancio,2025-01-15T17:11:28Z,please use `electionstae.withelecterdleader`.,0,0.9946075081825256
1917046679,18240,jsancio,2025-01-15T17:11:51Z,did you mean `votedkey`?,0,0.9933710098266602
1917055500,18240,jsancio,2025-01-15T17:16:05Z,this looks like a `static` method. it doesn't use any object fields or methods.,0,0.9933525323867798
1917062525,18240,jsancio,2025-01-15T17:19:48Z,can we use `isreconfigsupported()`? this will break when we add a new kraft.version.,0,0.9930970072746277
1917064565,18240,jsancio,2025-01-15T17:21:20Z,should this version check that the `prevote` field is `false`?,0,0.9942112565040588
1917068135,18240,jsancio,2025-01-15T17:24:10Z,hmm. how about having `raftprotocol` implement `voterpcversion()`?,0,0.9792568683624268
1917072892,18240,jsancio,2025-01-15T17:27:47Z,this is too relax. it should return 0 only for kip_595_protocol and throw an illegal argument/state exception for the `else` case.,0,0.59922856092453
1917074839,18240,jsancio,2025-01-15T17:29:18Z,do you want to update the exception messages to reference `withraftprotocol` instead?,0,0.9950093030929565
1917096432,18240,jsancio,2025-01-15T17:44:56Z,do you need this since you are using begin_quorum_epoch to propagate the leader and epoch.,0,0.9956052899360657
1917097458,18240,jsancio,2025-01-15T17:45:46Z,the prospective candidate is the same as the leader. was this done on purpose?,0,0.9930177927017212
1917114855,18240,jsancio,2025-01-15T17:57:18Z,is there a reason why you used 2 instead of 1 (like the other cases) for the leo?,0,0.9928280711174011
1917116456,18240,jsancio,2025-01-15T17:58:37Z,same here. why was the leo changed to 2 in this case?,0,0.9920147657394409
1917117528,18240,jsancio,2025-01-15T17:59:30Z,same here. why was the leo changed to 2 in this case?,0,0.9920147657394409
1917136327,18240,jsancio,2025-01-15T18:12:05Z,"i see. this actually depends on the kraft.version. for kraft.version 1 the local log will have an leo of 3 (leader change message, kraft version record and voter set record). for kraft.version 0 the local log will have an leo of 1, no?",0,0.9849742650985718
1917149169,18240,jsancio,2025-01-15T18:20:32Z,is it intentional that this response has a leader for the epoch but the other one does not?,0,0.9836949110031128
1917155747,18240,jsancio,2025-01-15T18:24:30Z,interesting that unattached waits for election timeout to transition to prospective while follower waits for fetch timeout to transition to prospective. it is okay for now but maybe they should both wait for fetch timeout since unattached now sends fetch requests.,0,0.7056796550750732
1917168666,18240,jsancio,2025-01-15T18:35:32Z,"you can just call `polluntilrequest` since it calls poll at least once, no?",0,0.9945670366287231
1917177912,18240,jsancio,2025-01-15T18:43:51Z,the most informative comparison in case of a failures is: [code block],0,0.9922204613685608
1917185173,18240,jsancio,2025-01-15T18:49:48Z,does it need to sleep for 1 ms? why? is calling `poll` enough?,0,0.989486813545227
1917187753,18240,jsancio,2025-01-15T18:52:02Z,in other tests you sleep for `electiontimeoutms * 2` why the difference?,0,0.9871357083320618
1917190771,18240,jsancio,2025-01-15T18:54:11Z,same here. is calling poll enough since the remaining time is 0?,0,0.9938158988952637
1917203942,18240,jsancio,2025-01-15T19:04:24Z,"technically possible but it is odd that the replica is using a static voter set, with kip_595_protocol and an elected leader or voted candidate that is not in the voter set. maybe it is less confusing if you limit these tests to kip_853_protocol. minor but technically the protocol configuration is not needed since the replica doesn't need to send or handle rpcs to become leader.",0,0.7690112590789795
1917213839,18240,jsancio,2025-01-15T19:13:37Z,is this used? i couldn't find a caller for this method.,0,0.9876234531402588
1917216983,18240,jsancio,2025-01-15T19:16:37Z,checking the leader is not enough. it should also check that the epoch match.,0,0.9912540316581726
1917220113,18240,jsancio,2025-01-15T19:19:21Z,"let remove the ""todo"". how about: [code block]",0,0.9947740435600281
1917231251,18240,jsancio,2025-01-15T19:29:13Z,how about this formatting: [code block],0,0.9928118586540222
1917235613,18240,jsancio,2025-01-15T19:33:19Z,okay. i think it is fair to file a bug but assign it to yourself or me.,0,0.9707435965538025
1917246184,18240,jsancio,2025-01-15T19:43:16Z,not sure if idempotent is the correct description. i would just call this test: `testconsecutivegrant`.,0,0.8357736468315125
1917246675,18240,jsancio,2025-01-15T19:43:47Z,not sure if idempotent is the correct description. i would just call this test: testconsecutivereject.,0,0.7884676456451416
1917255498,18240,jsancio,2025-01-15T19:52:23Z,what about the non-empty case?,0,0.9893817901611328
1917258238,18240,jsancio,2025-01-15T19:54:56Z,we should have done this in a different pr. it is difficult for me to see what has change and what has move so i have to review almost the entire file.,-1,0.6720136404037476
1917365519,18240,ahuang98,2025-01-15T21:36:42Z,i'll change the other variations of this method to do the same,0,0.9923921823501587
1917376912,18240,ahuang98,2025-01-15T21:46:22Z,"sorry, i wish github was a bit smarter with diffs :( it was difficult for me to figure out what coverage we were missing without the tests being more ordered (and i thought it would be difficult for you to tell what we might be missing as well) so i ended up deciding the re-order was worth it. we discussed this briefly before, but ideally each state will have its own file in the end - i decided not to make that change in this pr since it would make it even harder to tell what had changed.",-1,0.9947022795677185
1917380871,18240,ahuang98,2025-01-15T21:50:33Z,same with all the other `xyzrpcversion()` methods?,0,0.9947698712348938
1917398669,18240,jsancio,2025-01-15T22:08:40Z,you could but i didn't suggest it for the sake of keeping the diff smaller. you can file a jira to fix this if you want.,0,0.9927594661712646
1917398687,18240,ahuang98,2025-01-15T22:08:41Z,"yes, i had considered allocating a different node for local to make its voted candidate, but rationalized that the behavior won't change and that this is also a valid/common state for a follower to be in (votedcandidatekey=leaderid)",0,0.9914246797561646
1917401126,18240,jsancio,2025-01-15T22:11:13Z,i take it back. this implementation is fine if you want to keep it. maybe just make it `else if (raftprotocol.isreconfigsupported()) {`.,0,0.9935804605484009
1917404175,18240,jsancio,2025-01-15T22:14:51Z,"i think i miss spoke. how about moving this out of the constructors and adding a configuration method like `withstartingvoter(voterset, kraftversion)`. the implementation delegates to `withstaticvoters` or `withbootstrapsnapshot`.",0,0.9861445426940918
1917419710,18240,ahuang98,2025-01-15T22:29:46Z,"hm, can't think of a reason. i'll standardize",0,0.6115458011627197
1917424027,18240,ahuang98,2025-01-15T22:35:05Z,"yep, i decided to just use an leo of 3 for both cases as to not overcomplicate since it's valid for othernodekey to have a larger leo than local anyways. the difference in leo after gaining leadership between kraftversion 0 and 1 is also highlighted and tested in other kafkaraftclienttests which focus more on fetch/offset validation. i'll just add the conditional since it's easy enough",0,0.9808128476142883
1917434854,18240,ahuang98,2025-01-15T22:48:44Z,"yes, it was just for variation (since both could be valid responses)",0,0.9915758967399597
1917454524,18240,ahuang98,2025-01-15T23:10:33Z,i think i wanted to be more explicit with what happens when - i'll replace `polluntilrequest()` with the necessary `poll()` calls,0,0.9900692105293274
1917456559,18240,ahuang98,2025-01-15T23:13:38Z,yes!,1,0.4961845874786377
1917459804,18240,ahuang98,2025-01-15T23:17:02Z,"no strong reason, i'll standardize",0,0.9733384251594543
1917512126,18240,ahuang98,2025-01-16T00:38:50Z,"ah, this actually clears the mock send queue (otherwise the following check `raftrequest.outbound fetchrequest = context.assertsentfetchrequest();` fails due to unexpected number of requests in send queue) it works to remove the poll and clear the expected fetch later in the test, so i'll do that instead.",0,0.9906134605407715
1917518120,18240,jsancio,2025-01-16T00:48:53Z,"well, it is good to have self documented test (or code). you can make this connection clear by using the local log end offset if you expect the logs to match. e.g. `context.log.endoffset()`.",0,0.9720058441162109
1917525983,18240,jsancio,2025-01-16T01:01:45Z,missing newline between parenthesis: [code block],0,0.9932591915130615
1917526225,18240,jsancio,2025-01-16T01:02:10Z,missing newline between parenthesis: [code block],0,0.9932591915130615
1917526506,18240,ahuang98,2025-01-16T01:02:35Z,"i introduced this constructor to remove some of the redundancy and conditionals i was seeing with test parameterization. factoring in your next comment as well, maybe it makes more sense to remove this constructor and have a helper method do something similar instead in kafkaraftclientprevotetest.",0,0.9931105375289917
1917539718,18240,ahuang98,2025-01-16T01:25:06Z,i missed your last response with your suggestion about `withstartingvoter`. i'll leave this as is for now and we can discuss tomorrow,0,0.9869259595870972
1918724919,18240,jsancio,2025-01-16T15:06:33Z,can we make this an annotation that suppresses that check?,0,0.9945681095123291
1918748224,18240,jsancio,2025-01-16T15:20:38Z,given this implementation it is also correct to just store it as `endpoints leaderendpoints` and changing the constructor to accept an `endpoints` instead of an `optional `. it looks like in the raft module we never use `optional ` since `endpoints.empty()` is a valid value.,0,0.9936791062355042
1918750392,18240,jsancio,2025-01-16T15:22:06Z,this type doesn't write any log messages. we don't need to pass the log context to the object.,0,0.993357241153717
1918761915,18240,jsancio,2025-01-16T15:29:05Z,i think we use this formatting in this case: [code block],0,0.9895036220550537
1918763846,18240,jsancio,2025-01-16T15:30:18Z,okay but i would like us to standardize on using `string.format`. i think his should be formatted as: [code block],0,0.9902774691581726
1918795087,18240,jsancio,2025-01-16T15:50:02Z,some code duplication can be removed with: [code block] or [code block],0,0.9952303767204285
1918812401,18240,jsancio,2025-01-16T16:01:09Z,"why would the replica send another request since it already sent a request [a link]? or is the issue that the replica change state from unattached (with voted) to follower [a link] and reset its connection and request manager? which means that it will send another fetch request when it becomes a follower? if this is the case, maybe the test structure you had earlier is better where you assert a fetch request is sent while in the unattached stated.",0,0.99111407995224
1918822107,18240,jsancio,2025-01-16T16:07:41Z,let's use this formatting: [code block],0,0.9953269958496094
1918823415,18240,jsancio,2025-01-16T16:08:31Z,missing newline character. [code block],0,0.9740758538246155
1918831481,18240,jsancio,2025-01-16T16:13:56Z,let's use this formatting: [code block],0,0.9953269958496094
1918838919,18240,jsancio,2025-01-16T16:19:08Z,if just one of the voter doesn't support pre-vote this replica needs to transition to candidate. that because that voter that doesn't support pre-vote may be need to establish quorum with the majority. i would change this working to: [code block],0,0.9928312301635742
1918852989,18240,jsancio,2025-01-16T16:28:12Z,"fyi, this shows the issue you highlighted in the metrics test. the known hwm is lost when transitioning to leader. this is odd from the client's (users of raftclient) point of view. this semantic turns out to be correct because the new hwm established by the leader is guarantee to be greater than the previous hwm. this is true because the leader first commits the current epoch before establishing the new hwm.",0,0.979596734046936
1918931718,18240,ahuang98,2025-01-16T17:24:19Z,it's needed for `unattachedorprospectivecangrantvote`,0,0.9948216676712036
1918935598,18240,ahuang98,2025-01-16T17:27:18Z,i'll convert,0,0.9932265877723694
1918980033,18240,ahuang98,2025-01-16T18:02:58Z,"english is hard :face_with_tongue: i meant ""not the entire quorum"" vs ""entire quorum does not""",-1,0.9834099411964417
1918980139,18240,ahuang98,2025-01-16T18:03:04Z,i'll add more details to the jira - we can decide if it's worth changing this behavior,0,0.9926831126213074
1919002962,18240,ahuang98,2025-01-16T18:22:42Z,"locally, checkstyle seems to take issue w/ this particular check. i'll give it a shot and see if it builds w/ ci",0,0.9141860604286194
1919024139,18240,ahuang98,2025-01-16T18:40:17Z,"ci doesn't like the change either :( [code block] i recall spending some time trying to debug the issue, and the potential fix (suppressioncommentfilter) seemed a bit more work than it was worth javancss is mentioned in the existing jira for addressing these raft suppressions though - [a link]",-1,0.99395751953125
1919031445,18240,jsancio,2025-01-16T18:45:36Z,got it. thanks.,1,0.9930570125579834
92508146,2244,mjsax,2016-12-14T22:49:16Z,nit: either `kafka streams` or `{ kafkastreams}` (more ofter farther down),0,0.9913653135299683
92508580,2244,mjsax,2016-12-14T22:51:46Z,nit: `{ org.apache.kafka.streams.state.readonlykeyvaluestore readonlykeyvaluestore}` applies to all links with package prefix,0,0.9946710467338562
92508710,2244,mjsax,2016-12-14T22:52:35Z,` ktable`,0,0.9863553643226624
92509183,2244,mjsax,2016-12-14T22:55:15Z,"just a view, i.e., it is not materialized in a state store, on top",0,0.9822049736976624
92509708,2244,mjsax,2016-12-14T22:57:47Z,javadoc missing `replicatedtable` -> `globalktable`,0,0.9895380735397339
92509786,2244,mjsax,2016-12-14T22:58:12Z,`table` -> `globalktable`,0,0.9927402138710022
92510046,2244,mjsax,2016-12-14T22:59:34Z,"an exception? seems to align with `ktable` so not part of this pr -- but should we change this and just skip/drop those records? if we apply an aggregation to compute a ktable, we do the same, ie, just dropping those records. so there is an gap between aggregation and join -- even if for aggregation the input is a kstream... nevertheless, we should think about this (\cc )",0,0.9861754775047302
92514204,2244,mjsax,2016-12-14T23:27:03Z,nit. indention.,-1,0.5601203441619873
92514591,2244,mjsax,2016-12-14T23:30:05Z,nit `kstreamglobalktablejoin`,0,0.9938520193099976
92514897,2244,mjsax,2016-12-14T23:32:20Z,"can we unify this with inner class of `kstreamktablejoin` (ie, extract both inner classes and make top level class)? if not, maybe rename to `kstreamglobalktablejoinprocessor`.",0,0.9941160678863525
92515229,2244,mjsax,2016-12-14T23:34:50Z,nit: rename `thejoinprocessor ` ->`ktableglobalktablejoinprocessor`,0,0.9949040412902832
92515479,2244,mjsax,2016-12-14T23:36:32Z,nit: rename `thevaluegettersupplier` -> `ktableglobalktablejoinvaluegettersupplier`,0,0.9950024485588074
92516392,2244,mjsax,2016-12-14T23:44:07Z,i just compared with `ktablektablejoinprocessor` and the logic there is less nested thus easier to read. maybe we can break this down into smaller pieces similar to `ktablektablejoinprocessor`,0,0.9896194338798523
92517207,2244,mjsax,2016-12-14T23:50:10Z,"if we can reuse `ktablektableleftjoinprocessor` why not the inner join processor, too?",0,0.9918729662895203
92517353,2244,mjsax,2016-12-14T23:51:16Z,why renaming?,0,0.9705294370651245
92518822,2244,mjsax,2016-12-15T00:02:57Z,comment does not apply anymore -- nodegroup will never be null now (maybe empty though),0,0.9920855164527893
92573799,2244,dguy,2016-12-15T09:41:02Z,"yeah, i think that is a discussion worth having.",0,0.7824667096138
92574547,2244,dguy,2016-12-15T09:45:15Z,"thanks, i'll remember that going forward. you are my javadoc hero ;-)",1,0.9969519376754761
92577752,2244,dguy,2016-12-15T10:03:30Z,looks like a mistake.,-1,0.7559982538223267
92578027,2244,dguy,2016-12-15T10:05:14Z,should be `topicgroupid` is null,0,0.9913416504859924
92583292,2244,dguy,2016-12-15T10:36:26Z,yep - thought i did that already.,0,0.9504701495170593
92712542,2244,mjsax,2016-12-15T22:18:49Z,nit: root -> statestore,0,0.9929389953613281
92712675,2244,mjsax,2016-12-15T22:19:21Z,nit: name -> viewname,0,0.9874381422996521
92713058,2244,mjsax,2016-12-15T22:21:49Z,should we check for `key == null` -- or is this checked before the call already? we should start using assertions... would avoid those questions. (\cc ),0,0.9949672818183899
92714906,2244,mjsax,2016-12-15T22:32:40Z,"state stores are added via an supplier -- a suppliers is not required here, but it might be confusing for users if there are different method signature -- i think we should align both. wdyt?",0,0.9914109706878662
92716639,2244,mjsax,2016-12-15T22:42:58Z,"i am just wondering what abstraction we want to provide at papi level -- we never discussed this in detail -- and it's not part of the kip either. we only talked about globalktable. for globalktable we have the requirement that it is always populated from a source topic. thus, this method mimics this -- but it this a papi concept? should we have a method like this? and if it is a papi concept, should global stores always be used like this? if yes, we might want to drop `addglobalstore(final statestore store)`. not sure about the answers. we should discuss this.",0,0.5641093254089355
92719445,2244,mjsax,2016-12-15T23:00:21Z,"i am still not sure about this design. actually, the global part shout use a singleton pattern. it is kinda weird that we have two `processortopology` ""types"" -- the global one and the regular one. as the kip is still under discussion, we might want to think about this once more. also from an papi vs dsl point of view -- i think, we need a better separation between both and not ""pollute"" papi with dsl concepts.",-1,0.951399028301239
92719996,2244,mjsax,2016-12-15T23:03:55Z,should we implement singleton pattern here?,0,0.9930912256240845
92720200,2244,mjsax,2016-12-15T23:05:21Z,should we release the lock here?,0,0.9942042231559753
92720829,2244,mjsax,2016-12-15T23:09:57Z,why not `.endoffsets()`? could replace the whole method.,0,0.9903982877731323
92723075,2244,mjsax,2016-12-15T23:26:58Z,not strictly required -- only suppresses the log message. is this intended?,0,0.9922978281974792
92723476,2244,mjsax,2016-12-15T23:30:19Z,are checkpoint files delete somewhere else? or should be do this here?,0,0.9925124645233154
92726236,2244,mjsax,2016-12-15T23:52:21Z,"as the restore consumer is shared, can we make sure no parallel restore operation messes with global state thread here? applies to the whole class... also -- if we change partitions assignment -- would we need to restore a previous assignment or maybe better just extend the current assignment (instead or replacing it)? or does every ""user"" of the consumer restores its own assignment each time it uses the consumer (this might also imply that doing the assignment in `initialize` is wrong)? btw: how does state recovery work today? single threaded?",0,0.9911804795265198
92773817,2244,dguy,2016-12-16T08:59:13Z,hmm - i'm don't think viewname really describes it any better. the class is already named `keyvaluestorejoinview` - name seems appropriate,0,0.9612271189689636
92773828,2244,dguy,2016-12-16T08:59:20Z,as above,0,0.9888283014297485
92773952,2244,dguy,2016-12-16T09:00:20Z,this is what it is on the interface and is consistent with every other `statestore`,0,0.9937112331390381
92774161,2244,dguy,2016-12-16T09:02:15Z,it is worth adding a null check here. though i will probably just return null rather than throwing exceptions etc. i'm not convinced that calling `get(null)` is worthy of raising an exception.,0,0.9519441723823547
92774515,2244,dguy,2016-12-16T09:05:28Z,i don't think we should use a suppler here. we want a single instance of a `statestore` and this shows that intent. a supplier indicates that there may be multiple instances.,0,0.9854167103767395
92774899,2244,dguy,2016-12-16T09:08:42Z,"this is in the kip. anyway, this method has been added so that the joins generated by `globalktables` can be queried etc. as they are just views on top of other `globalktables` they don't have their own source as such. also, from a users point of view - why shouldn't they be able to add a global store of whatever type they like? they might have a pre-populated table or something that they'd like available in all of there processors.",0,0.9930379986763
92775816,2244,dguy,2016-12-16T09:15:00Z,"i'm not 100% happy with this either, but as you know, the dsl just builds on the papi and the concepts are already mixed. i don't like this, but this is where we are at the moment. i'd much prefer that `kstreambuilder` didn't extend `topologybuilder` - imo there should be another class, lets say `papibuilder` (name sucks), `topologybuilder` becomes package private. `kstreambuilder` and `papibuilder` are standalone classes, they don't inherit from `topologybuilder` they just use it to build the topology. then we have no mixing of dsl and papi concepts at the api layer. anyway, i don't want to do that as part of this task!",-1,0.9945736527442932
92776262,2244,dguy,2016-12-16T09:18:21Z,no. not a fan of singletons at all. we just create a single instance of it.,0,0.8765971064567566
92777615,2244,dguy,2016-12-16T09:28:09Z,didn't know it existed!,0,0.648871123790741
92778385,2244,dguy,2016-12-16T09:33:36Z,it probably should be deleted after it is first loaded. at least that is what we do elsewhere.,0,0.981635332107544
92780091,2244,dguy,2016-12-16T09:44:14Z,"this consumer is not the restore consumer. it is a consumer just for this thread so it isn't shared at all. there are no parallel operations on it. when the `statestores` are restored, in `globalstatemanagerimpl`, they each `assign` their own partitions, fetch the data up to the hw, then un-assign their partitions. during this process all of the `topicpartition` for global stores are collected and that is what is assigned here. this is the set of partitions we need to consume to keep all global stores up-to-date. yes, recovery of statestores is always single threaded.",0,0.9686840176582336
92882610,2244,mjsax,2016-12-16T20:42:27Z,agreed: this should definitely not be done in this pr! i am just afraid that this pr makes reworking and separating papi and dsl even harder.,-1,0.9850589036941528
92883151,2244,mjsax,2016-12-16T20:46:28Z,hmmm... weird naming. should we rename all?,-1,0.983677864074707
92883382,2244,mjsax,2016-12-16T20:48:16Z,sounds opinion based :) what's the problem with singletons?,1,0.8341023921966553
92888694,2244,mjsax,2016-12-16T21:24:39Z,"i understand that argument. my point is more about api design -- we break an api pattern and thus reveal something to the user, that you can consider an implementation detail. the user does not care how ofter we do instantiate a store. if i write code for a store, and hand it in, i don't care about it -- i want to same api for regular and global stores. why should i care about the number of instantiation as a user? i personally dislike the whole handing in factories instead of stores from a user perspective completely -- even if i understand why it is necessary for streams. (flink for example has a very nice api for this and it's not a concern there.) as a user, i want to implement a store -- i don't want to bother with a store factory (i don't want to change this pattern because we have good reasons to enforce is, and one more wrapper for the store is an acceptable burden for the user imho). so we educate the user to implement factories and suddenly we change our mind and say -- ""not for global store"".",-1,0.8707705140113831
92889320,2244,mjsax,2016-12-16T21:29:12Z,"understood. but than, we should maybe only keep `addglobalstore(final statestore store)` and remove the second (this) `addglobalstore` method -- it's a dsl concept again -- i understand the ""i don't care, papi legacy"" argument, but everything we introduce in hard to remove later on. we could just add a global store, and do the wiring with a topic in kstreambuilder instead of topologybuilder?",0,0.9574154615402222
92890189,2244,dguy,2016-12-16T21:35:22Z,not in this pr,0,0.9910053014755249
93021658,2244,dguy,2016-12-19T12:24:23Z,everything in software development is opinion based! singletons are ok for simple objects with no dependencies. as soon as you start adding dependencies in to the mix you end up with tightly coupled code. that is hard to test.,-1,0.9249473214149475
93022514,2244,dguy,2016-12-19T12:31:19Z,"we could do that if we make some of the fields in `topologybuilder` protected, i.e., so they can be accessed from `kstreambuilder`. i'm not a big fan of doing this, but i agree with your point about making things harder to remove later",0,0.888514518737793
94648336,2244,mjsax,2017-01-04T19:28:48Z,"i had a discussion about when to set the state to running with and we agreed that it is better to change the state before we start the threads -- can't remember the details of our discussion though. however, i would keep it as is. maybe can elaborate on it.",0,0.9662010669708252
94648979,2244,mjsax,2017-01-04T19:32:16Z,"joins with other globalktable got removed, right?",0,0.9884918928146362
94649387,2244,mjsax,2017-01-04T19:34:30Z,nit: better markup would be [code block],0,0.7514539361000061
94650151,2244,mjsax,2017-01-04T19:38:23Z,"weather [or] not seem like c&p error -- would you mind fixing the other typos in all javadocs, too?",0,0.9803101420402527
94650667,2244,mjsax,2017-01-04T19:41:14Z,"remove this paragraph -- we did removed it for other javadocs, too.",0,0.9927887320518494
94650786,2244,mjsax,2017-01-04T19:41:51Z,as above,0,0.9888283014297485
94651214,2244,mjsax,2017-01-04T19:44:01Z,"i would prefer to use `gk` (like global key), `gv`, and `rv` (result value) instead of `k1`, `v1`, and `r` to have somewhat more meaningful names instead of numbering. (`rv` is used in other methods, too)",0,0.9904734492301941
94651248,2244,mjsax,2017-01-04T19:44:13Z,as above.,0,0.9881609678268433
94675135,2244,mjsax,2017-01-04T22:05:41Z,"should we not do this in ``? if test fails and `` is never executed, next test run might fail.",0,0.9748077988624573
94676111,2244,mjsax,2017-01-04T22:11:28Z,"i think that join result should not depend of other values being null or not. line 102/103 might hit a race condition if global table get altered between both calls. thus we might end up with wrong results imho. not 100% sure, but i think it's worth thinking about it.",0,0.9317134022712708
94676192,2244,mjsax,2017-01-04T22:11:51Z,as above.,0,0.9881609678268433
94679715,2244,mjsax,2017-01-04T22:33:41Z,"this test is only sufficient for stream-globaltable join imho, but not for table-globalktable join for which we need to test `null` tombstone input record for ktable input. furthermore, i think we need a test that updates globalktable in the background while processing -- this might be a separate test though (it's about the race condition i mentioned that we should test for).",0,0.990816593170166
94686399,2244,mjsax,2017-01-04T23:18:45Z,does this test anything that is not already covered by `globalktableintegrationtest` -- or the other way round?,0,0.9935104250907898
94688157,2244,mjsax,2017-01-04T23:32:34Z,"the test behavior is ok, but i think the name is wrong. -> `shouldnotforwardifoldvalueisnull` we should also have one more test, that test if `null` is emitted if `oldvalue != null`",0,0.9634305238723755
94688915,2244,mjsax,2017-01-04T23:38:53Z,i think we should expect `a.newvalue == null` because input `oldvalue != null` -- we cannot know if globaltable was updated in between and thus previous oldvalue might have joined.,0,0.9861008524894714
94689054,2244,mjsax,2017-01-04T23:40:09Z,"imho, this test is redundant with my suggested version of `shouldnotforwardifdeleteandoldkeynotinotherstoreandsendoldvalues`",0,0.6461480259895325
94689208,2244,mjsax,2017-01-04T23:41:40Z,"from my understanding, if old and new value is `null` nothing should be forwarded -- independent of the content of globalktable.",0,0.9896350502967834
94689292,2244,mjsax,2017-01-04T23:42:27Z,i guess similar comments as above apply -- skipping this class for now.,0,0.978234589099884
94689865,2244,mjsax,2017-01-04T23:47:10Z,we should use `lockexception` instead of `streamsexception` imho.,0,0.9757314324378967
94690456,2244,mjsax,2017-01-04T23:52:15Z,why not just one test for `shouldinitializestatestores` and `shouldreturninitializedstorenames` ? both test the same method.,0,0.9837855100631714
94690596,2244,mjsax,2017-01-04T23:53:24Z,"remove try-catch and fail and add `(expected = illegalargumentexception.class)` (same below) or could `statemanager.initialize(context);` throw `illegalargumentexception`, too?",0,0.9940844178199768
94691732,2244,mjsax,2017-01-05T00:03:39Z,:),1,0.9915001392364502
94692341,2244,mjsax,2017-01-05T00:09:17Z,"nit: ""kaboom!"" ;)",1,0.9642271995544434
94692983,2244,mjsax,2017-01-05T00:15:15Z,should we apply a test timeout to check if `join()` got stuck because it did not stop running on `close()` ?,0,0.9910846948623657
94693136,2244,mjsax,2017-01-05T00:16:40Z,unify `shouldstoprunningwhenclosedbyuser` and `shouldclosestatestoresonclose` ? both do test `close()`,0,0.9945327043533325
94695940,2244,mjsax,2017-01-05T00:43:44Z,isn't this test covering `shouldupdatestatewithreceivedrecordsforpartition` ?,0,0.9949907660484314
94696136,2244,mjsax,2017-01-05T00:45:47Z,unify `shouldflushstorewhenflushintervalhaslapsed` and `shouldnotflushoffsetswhenflushintervalhasnotlapsed` ?,0,0.9935965538024902
94727438,2244,dguy,2017-01-05T08:17:54Z,sure - i'll put it back. didn't really make sense to me to set the state to running before the threads have started. but whatever,0,0.9697712063789368
94728105,2244,dguy,2017-01-05T08:24:48Z,next test wont fail as it will use a different state directory.,0,0.9856614470481873
94729425,2244,dguy,2017-01-05T08:37:42Z,"we should have both tests. they cover some of the same things, but this is much easier to write and debug issues. it runs much quicker. however, it doesn't cover the more end-to-end scenario that the integration tests cover.",0,0.9690836668014526
94730687,2244,dguy,2017-01-05T08:49:00Z,"i don't agree with the name you have suggested, but i also think the name of the test is not completely correct",-1,0.5371825098991394
94734155,2244,dguy,2017-01-05T09:15:44Z,"yep. i was thinking that a direct key mapping could result in the join, but that was incorrect.",0,0.9752461314201355
94735025,2244,dguy,2017-01-05T09:22:02Z,"sure, but `lockexception` didn't exist when i wrote this!",0,0.9750941395759583
94735566,2244,dguy,2017-01-05T09:25:54Z,"yes, you could test them both in the same method. however, i prefer to have single focused tests where the test names describe what is happening. there is nothing wrong with having multiple tests for the same method and params, in-fact i'd encourage it.",0,0.9714943766593933
94735880,2244,dguy,2017-01-05T09:28:02Z,"it doesn't now, but it, or something, it uses might in the future. i prefer this approach for these sort of scenarios as it guarantees that the exception was raised from the code i am trying to test",0,0.9857321381568909
94736396,2244,dguy,2017-01-05T09:31:37Z,nope - they are testing different things that happen on close. i prefer it this way as it is easier to just read the test names to see what should be happening rather than have to read through the assertions.,0,0.9797159433364868
94736604,2244,dguy,2017-01-05T09:33:14Z,not quite - this is checking the multiple topic case. the other is just checking a single topic,0,0.9832916855812073
94736696,2244,dguy,2017-01-05T09:33:57Z,see my other comments. this is how i'd prefer to see the tests written,0,0.9929719567298889
94739678,2244,dguy,2017-01-05T09:53:44Z,"the `null` tombstone cases are already covered by `ktableglobalktablejointest` and `ktablektableleftjointest` - i don't think they need to be covered here again. i'm not sure about the background thread. yes there could be a race condition (i've updated the code as suggested below), but i'm not 100% sure how we could/should handle it.",0,0.9747589826583862
94823111,2244,mjsax,2017-01-05T18:27:56Z,"if you apply this argument, you can never use `(expected = ...)` as it would apply to all tests using this pattern. wouldn't it?",0,0.9939329028129578
94823260,2244,mjsax,2017-01-05T18:28:47Z,"yes. but if multi-topic works, single topic works, too. or not?",0,0.9819827079772949
94829084,2244,mjsax,2017-01-05T19:00:26Z,i just thought about this once more. to me it seems that the race condition is because of sending oldvalues. why do we actually need this? or could we just disable sending old values?,0,0.98231041431427
94832919,2244,mjsax,2017-01-05T19:22:06Z,"what is the different from this test to `shouldnotsendanythingifchangeisnullnullandkeymapstonullinothertable`? furhtermore, why do you setup a new `ktableglobalktableleftjoin` ? if i did not miss anything, it is the same setup as the global member `join` variable.",0,0.993579626083374
94919202,2244,dguy,2017-01-06T09:23:13Z,yeah they do look the same. brain fade!,-1,0.501539409160614
94919538,2244,dguy,2017-01-06T09:26:11Z,"it is a question of how you write tests. i write tests and code starting from the simplest things and working out from that. so the test for the single topic comes first, and then the test for multiple topics. in this case the test for multiple topics might be enough, but maybe it isn't, maybe the code assume there is always >1 topic? it is good to have both",0,0.5823436379432678
94920231,2244,dguy,2017-01-06T09:32:06Z,"no, i disagree. most tests i'd use `(expected = ....)` in would either have a single method call in them, so you know that is the only method that can throw the exception. or, it would be a `new blah(..)` followed by testing the single method. of course the `new ..` could throw an exception, but hopefully most ctors are side-effect free.",0,0.9689266085624695
94930979,2244,enothereska,2017-01-06T11:01:39Z,"""weather"" typo",0,0.9862774014472961
94931159,2244,enothereska,2017-01-06T11:03:28Z,would be good to be consistent at least with the ktable.,0,0.9814692735671997
94931291,2244,enothereska,2017-01-06T11:04:46Z,currently we always materialize though.,0,0.973212718963623
94939282,2244,dguy,2017-01-06T12:29:21Z,hmmm - maybe we don't need to get the old value from the other table at all. as in `ktablektableleftjoin` we get the current value from the other table and then if `sendoldvalues` we join `change.oldvalue` with the value from the other table. thoughts?,0,0.9762901067733765
94950774,2244,enothereska,2017-01-06T14:16:25Z,i agree with both of you.,0,0.8876357674598694
94980385,2244,mjsax,2017-01-06T17:04:46Z,"i would not send old value whatsoever -- because of async updates of globalktable we cannot guarantee any semantical meaning -- we might miss multiple update from globalktable and thus, me might send an ""old value"" that was never emitted as ""new value"" before.",0,0.9776116609573364
94981984,2244,dguy,2017-01-06T17:14:29Z,"i've been looking a bit more and i'm still not certain what the correct thing to do in this situation is. we need to send an old value for the subtractors of the aggregators/reducers, but the old value may not be the same value as previously seen. an example that doesn't work properly. [code block] if i initialize g1 with: (1, green) (2, blue) (3, yellow) (4 red) then send to t1 (1, 1) (2, 1) (3, 1) and flush state i get (green, 3) all good so far. however if i then send to g1 (1, orange) and then to t1 (1, 4) and flush state i get (green, 3) (orange, -1) (red, 1) which is obviously incorrect. the oldvalue of green never gets sent so the count for green doesn't reduce by 1, rather the oldvalue is orange, hence orange with a count of -1. hmmmm!",0,0.834316611289978
95020150,2244,mjsax,2017-01-06T21:06:45Z,"that is exactly what i had in mind with my previous comment... i just thought we might be able to not send the old value at all -- but your example shows that we need to send it. one way to fix it, is to remember the old value on the triggering ktable side (i guess we need another store for this...). thus, instead of looking up old value in globalktable, we look it up the the new store. not sure if there is a better way to do it.",0,0.8618786334991455
95133661,2244,dguy,2017-01-09T10:49:03Z,would appreciate your thoughts on this.,1,0.5227001905441284
95287565,2244,guozhangwang,2017-01-10T01:57:06Z,not sure if this interface is usefeul with `processorstatemanager`? should it be in the extended `globalstatemanager` only?,0,0.9837939143180847
95287972,2244,guozhangwang,2017-01-10T02:01:50Z,why we want to maintain an interface of `globalstatemaintainer`? is it because of mocking in unit tests? otherwise its only impl is `globalstateupdatetask`.,0,0.9883185625076294
95288306,2244,guozhangwang,2017-01-10T02:05:03Z,"my gut feeling is that we do not need to mimic a `processortopology` and `internalprocessorcontext` interface for this task, as it is a very special task whose topology will just be a list of source topics and a list of state stores, making them as generic interfaces would just introduce one-time classes like `globalprocessorcontext` in which lots of its functions will not be required at all. instead we can just e.g. pass into it a list of source topics, a map between topics to state stores, etc and let it run its only loop for fetching + updating stores, etc.",0,0.9522976279258728
95288621,2244,guozhangwang,2017-01-10T02:09:14Z,"the usage of `sourcenodeandserializer` is a bit awkward to me here: we have wrapped the source node in order to get its corresponding deserializer in this class, and we again keep a map from topic name to this deserializer; so why don't we just use a map from topics to deserializer directly?",-1,0.8345782160758972
95319354,2244,dguy,2017-01-10T08:42:06Z,it is used by `processorcontextimpl` it is needed on the interface,0,0.9952656030654907
95319810,2244,dguy,2017-01-10T08:44:51Z,"using interfaces is good oo design practice. it facilitates loose coupling, flexibility, better design of roles. yes, it also helps with testing.",1,0.757326066493988
95324378,2244,dguy,2017-01-10T09:16:20Z,"because we need both the sourcenode and the deserializer when we receive data from the topic. i.e., we need to deserialize the data and the `sourcenode` to process it",0,0.9908921122550964
95327582,2244,dguy,2017-01-10T09:35:35Z,"i disagree. firstly it isn't mimicing a `processortoplogy` - it is one! we have various classes in place already that do the the work needed to keep the table up-to-date, i.e, `soucenode` and `ktablesourceprocessor`. they need a `processcontext`. if we don't go down this path then we will be duplicating the code in those classes as we need to do the same thing. further `globalprocessorcontext` is as one-time as `standbycontextimpl`. i don't see any difference here. i also abstracted out all of the common `processorcontext` methods to `abstractprocessorcontext` to avoid having to avoid duplication and implementing of some unnecessary methods.",0,0.8945131301879883
95420343,2244,guozhangwang,2017-01-10T17:56:25Z,"this is a meta comment about `change<>`, not sure if my thoughts are correct: currently we propagate the need to send old values in any aggregate operators back-wards all the way to source nodes: if a ktable aggregate operator is observed it will be propagated to all its ancestors; with materialized results of ktable-ktable join, this propagation can be stopped at such operations. in this case, ktablektablexxjoin do not need to expect a `change<>` at all as it will never need the old value any more. i'm not sure if we can immediately change its type from `change ` to `v`, but i think technically it should be the case.",0,0.9784250259399414
95420796,2244,guozhangwang,2017-01-10T17:58:32Z,nit: rename to `globalcontextimpl` to be consistent?,0,0.9923704862594604
95422432,2244,guozhangwang,2017-01-10T18:07:24Z,"it is a subjective thing, but i usually find such oo design most useful when the interface is public and the impl has some separate functions to be used in other internal classes (e.g. the refactoring are doing to separate topologybuilder user-facing apis from its internal functions used by `streamthread`, etc). while this class is pure internal we can always just extend / override for testing.",0,0.9802600741386414
95424323,2244,guozhangwang,2017-01-10T18:16:58Z,"okay, make sense.",0,0.9740179777145386
95425307,2244,guozhangwang,2017-01-10T18:22:24Z,"instead of adding this interface, could we let `processorcontextimpl` to contain two `statemanagers`, while `standbycontextimpl` and `globalcontextimpl` each contain one? i know it is an internal interface so maybe it's not that important at all, but just wanted to throw my ideas here.",0,0.9845614433288574
95425732,2244,guozhangwang,2017-01-10T18:24:39Z,this is not about this pr: in #1446 we are removing specific cache sensors since we are adding sensors for generic purposes already. there will be some major conflicts between these two.,0,0.9702534079551697
95428000,2244,enothereska,2017-01-10T18:36:30Z,"there will be a conflict, but hopefully not major.",0,0.8279284834861755
95428041,2244,dguy,2017-01-10T18:36:39Z,yep :-(,-1,0.995922327041626
95428151,2244,dguy,2017-01-10T18:37:14Z,sure,0,0.9422702193260193
95429909,2244,dguy,2017-01-10T18:45:57Z,i'm not sure i follow. not immediately clear to me how `ktablektablexxjoin` can't expect a `change<>`. that is what is will be sent from the previous `ktablexxxprocessor`,0,0.5650436282157898
95455229,2244,dguy,2017-01-10T20:57:11Z,if we did that i think we'd need another `statemanager` implementation. as we wouldn't want the one used by `processorcontextimpl` to go through the initialization and restoration of global stores.,0,0.985231876373291
95455897,2244,dguy,2017-01-10T21:01:01Z,we'll have to agree to disagree on this one!,-1,0.6007393598556519
95475213,2244,mjsax,2017-01-10T22:44:29Z,created [a link] for this.,0,0.9951540231704712
85607023,2074,vahidhashemian,2016-10-28T20:44:23Z,"this is where the bug was introduced. if `state` is `none`, there is a possibility that the old consumer based group does not have any active members; so we need to check whether new consumer is used or not, and then proceed accordingly.",0,0.9911890029907227
85607062,2074,hachikuji,2016-10-28T20:44:33Z,was there a kip for this that i missed?,0,0.9896711707115173
85607674,2074,vahidhashemian,2016-10-28T20:48:28Z,"thanks for bringing this up. i wasn't totally sure what to process is for changing the protocol, and whether i'm actually correct to assume that the protocol has to be changed for this jira. i haven't opened a kip yet, if you think that's eventually going to be needed for i'd be happy to create one. thanks in advance for clarifying this.",1,0.9880087375640869
85608617,2074,hachikuji,2016-10-28T20:54:01Z,"yeah, protocol changes definitely need a kip. probably makes sense then to split the bug fix into a separate patch.",0,0.9774962663650513
85608849,2074,vahidhashemian,2016-10-28T20:55:44Z,"thanks. i'll submit the bug fix separately, and then work on creating a kip.",1,0.9300331473350525
86647580,2074,vahidhashemian,2016-11-04T23:11:13Z,"i was hoping you could take a look at an issue i'm running into if and when you get a chance. while kip-88 is open for discussion i spent some time creating some unit tests for this pr. this particular unit test simply mocks two consumers that consume from the same 1-partition topic and belong to the same consumer group. a similar unit test on old consumers exists earlier in the same file and runs fine. there are also other unit tests above using the new consumer that run fine but they mock only one consumer. the problem i'm running into is this line that mocks the second consumer and takes a long time to run (i believe for the consumer to join the group that eventually times out) and the consumer group gets corrupted somehow. when i debug and check the status of the group down in the `waituntiltrue` check, sometimes it is `empty`, or `dead`, or even `stable` with only one of the consumers and it never gets into the expected state (`stable` with two members). where it gets stuck in a loop i think is [a link] (after [a link]. i'm not sure if i'm doing something wrong with the unit test or if i'm hitting some bug. i thought you might know by just looking at it. thanks.",0,0.5618914365768433
92458550,2074,hachikuji,2016-12-14T18:34:17Z,nit: the `offsetfetchrequest` suffix seems redundant. how about this `offsetfetchrequest.forallpartitions()`?,0,0.9648500680923462
92458890,2074,hachikuji,2016-12-14T18:36:11Z,"don't we need a null check in the loop above? also, should we return a null array in the response if the requested partitions are null?",0,0.9936157464981079
92459503,2074,hachikuji,2016-12-14T18:39:37Z,one thing i'm realizing is that this schema gives us no way to indicate that a group doesn't exist when you fetch all partitions. that may be ok since we usually know ahead of time whether or not a group _should_ exist (e.g. by using listgroups).,0,0.9695382714271545
92460753,2074,hachikuji,2016-12-14T18:46:06Z,seems like we could do these two lines with a `map` and `getorelse` combo.,0,0.9877281188964844
92461437,2074,hachikuji,2016-12-14T18:49:42Z,this is a little hard to follow. maybe we could create two vals and do the append at the end?,0,0.7719129323959351
92461907,2074,hachikuji,2016-12-14T18:52:02Z,can we cover the error case also for a request for all partitions?,0,0.9936162233352661
92462186,2074,hachikuji,2016-12-14T18:53:15Z,"maybe we can just say ""versions 1 and above""?",0,0.9853046536445618
92462799,2074,hachikuji,2016-12-14T18:56:21Z,is the version check necessary?,0,0.9949055910110474
92463197,2074,hachikuji,2016-12-14T18:58:13Z,maybe we could wrap the `some` at the end to remove one level of nesting?,0,0.9893009066581726
92463905,2074,hachikuji,2016-12-14T19:02:05Z,hmm... i don't think we should be accessing the group directly at this layer. it's probably better to either overload `groupcoordinator.handlefetchoffsets` or expose a new method.,0,0.9561504125595093
92468547,2074,vahidhashemian,2016-12-14T19:24:18Z,"sure, that sounds reasonable. i'll update the method name.",0,0.9809509515762329
92477069,2074,hachikuji,2016-12-14T20:01:48Z,"thinking about this a little more.. there is an edge case around coordinator failover. we may lookup the coordinator for some group, find that it is broker a, and then send the offsetfetch for all partitions. before the request arrives, it could happen that broker b becomes the coordinator (it may have already begun the transition even before we did the initial coordinator lookup), but we won't have a way to detect it. this will cause us to mistakenly report that there are no offsets for the group.",0,0.9676658511161804
92478985,2074,vahidhashemian,2016-12-14T20:11:55Z,"yes, i missed that. thanks. i'll try to fix it in the next update.",1,0.983242392539978
92495078,2074,vahidhashemian,2016-12-14T21:39:40Z,"could you please clarify your first comment above? with this change, i can still see the `error: consumer group '...' does not exist.` message if 1) the consumer group is never created. 2) the consumer group is created but its offsets are all expired. regarding the second comment, are you referring to double `findcoordinator(...)` calls in this use case (through [a link] and [a link]? if so, one improvement would be to somehow preserve the `coordinator` value found in `describeconsumergroup(...)` for use in `listgroupoffsets(...)`. please advise if i misunderstood the issue. thanks.",0,0.9907659292221069
92501254,2074,hachikuji,2016-12-14T22:10:14Z,"the basic issue is that the error codes are in the partition data of the response schema. if we have no partitions to return, then we cannot return any errors either. this is fine for most cases because we should already know if the group exists or not. however, there are (at least) two problematic edge cases: 1. the case i mentioned above. to use the offsetfetch api, we must first lookup the coordinator for the group. it could happen that when we do so, we happen to get a stale coordinator. this is possible because it takes some time for metadata changes to propagate to all the brokers. 2. when the coordinator first is started, it must read through the `__consumer_offsets` topic to populate the offset cache. usually we return a `coordinator_not_available` error in this situation which lets the consumer know it needs to retry a bit later. so if we happen to send an offset fetch for all partitions in either of these cases, then we could mistakenly believe that there are no offsets for the group.",0,0.9695902466773987
92674520,2074,vahidhashemian,2016-12-15T18:52:08Z,"thanks for explaining the issue. if i'm not mistaken, the first edge case (stale coordinator) could occur with the current code too ([a link] that leads to [a link]. so the main issue is that with the current protocol we cannot report error codes when there is no partition in the response. to me the options are 1. making further changes to the protocol to address this issue too. 2. rethinking how to solve the problem of kafka-3853 (with another option than proposed in kip-88). 3. accepting that limitation for now and continue with the current solution. is there another option? which option do you recommend we take?",1,0.8889665007591248
92679066,2074,vahidhashemian,2016-12-15T19:14:10Z,sounds good. i'll refactor the whole block a little bit.,1,0.8117238283157349
92679685,2074,hachikuji,2016-12-15T19:17:13Z,"adding an `error_code` at the top level in the response object seems like the cleanest solution. this error code could be used to communicate group-related errors, which is arguably a bit nicer than writing those errors into all the individual partition data. it's a bit painful to reopen a kip that has passed, but i don't think we can ignore this problem. perhaps send a comment to the kip-88 discussion thread explaining the problem and what you think the best option to fix it is?",0,0.542678713798523
92680619,2074,vahidhashemian,2016-12-15T19:21:36Z,sounds good. i'll do that. thanks for your feedback and advice.,1,0.9950957894325256
92697405,2074,vahidhashemian,2016-12-15T20:51:52Z,one more question before i re-open the kip. the issue doesn't seem to be a side-effect of the suggested protocol change in kip-88 (we are not modifying the response in kip-88) and it would surface whenever there is no partition in the response. do you think it can be addressed in a separate kip? or i am missing something here?,0,0.9851943850517273
92702988,2074,hachikuji,2016-12-15T21:25:16Z,"i think it is a consequence of the changes to the request from this kip though, right? before we would always have at least one partition in the request, so we always had somewhere to pack an error code in the response. now that's no longer true.",0,0.9869371056556702
92706549,2074,vahidhashemian,2016-12-15T21:43:42Z,"ok. i see. thanks. so before, it was guaranteed that whatever partition is in the request will be in the response. with the new protocol we could end up getting back an empty list if the group has no offset data. what about passing an empty array in the request with current protocol? wouldn't this cause the same problem?",1,0.9106903076171875
92707749,2074,hachikuji,2016-12-15T21:50:10Z,"that is true, but the impact is different. if you request offsets for an empty list of partitions, the correct response, regardless of the state of the group or the coordinator, is to return an empty partition list.",0,0.9907676577568054
92710994,2074,vahidhashemian,2016-12-15T22:08:45Z,this makes it clear ( hopefully :) ). thanks a lot. i'll work on that email and updating the kip.,1,0.9970904588699341
92729320,2074,vahidhashemian,2016-12-16T00:21:06Z,"a quick follow-up question: is it possible for the current api to return an offset fetch response with various error codes associated with the partitions? i'm trying to think if we can remove the internal ""error_code"" from the schema. thanks.",1,0.9002217054367065
92730823,2074,hachikuji,2016-12-16T00:35:52Z,"i was wondering about this also. unfortunately, it seems we can't remove the per-partition error code since we do authorization on the topics separately.",0,0.9163618087768555
92861504,2074,vahidhashemian,2016-12-16T18:30:06Z,"i guess not, since in previous versions it's not possible to pass in a null array. thanks.",1,0.9173482060432434
92876208,2074,vahidhashemian,2016-12-16T19:58:21Z,"sure. i think i'll expose a new method (something like `groupcoordinator.getpartitions(groupid)`), since the partitions have to go through authorization check and, after a quick look, i don't see a clean way of overloading `handlefetchoffsets` for this purpose that fits well with how `kafkaapis.handleoffsetfetchrequest` is implemented. unless we want to refactor that method more extensively.",0,0.9732216596603394
94959538,2074,ijuma,2017-01-06T15:14:34Z,this should be `kafka_0_10_2_iv0`.,0,0.993990957736969
94994319,2074,vahidhashemian,2017-01-06T18:30:04Z,thanks for catching this. i'll fix it shortly.,1,0.977700412273407
95102027,2074,ewencp,2017-01-09T04:36:55Z,"is this still supposed to be included? it's not in the kip (i can't remember if it existed in a previous version.) if it is supposed to be included, presumably it'd be an override of an interface method from `consumer`?",0,0.9917336702346802
95103021,2074,ewencp,2017-01-09T05:08:34Z,style nit: normally we'd use braces around blocks unless they're a single line,0,0.9311432242393494
95103761,2074,ewencp,2017-01-09T05:30:01Z,"aren't you still missing setting the error code field on the struct in this case though? the pattern that seems to be used elsewhere, e.g. in `metadataresponse`, is to make the constructor that takes the version contain all the fields as arguments as well as the version. then all the decoded fields are kept as member variables and written regardless of whether that version contains them, but only written to the struct conditionally. for example, `metadataresponse` has some code that looks like this in its constructor: [code block] (after having constructed the `struct` with the correct schema). i think if the current code is working, it's just lucking out on `none`'s error code being `0` or something. i wouldn't think it would work as is since the field doesn't have a default value defined.",0,0.9863296151161194
95104096,2074,ewencp,2017-01-09T05:38:53Z,"shouldn't some of these change to remove the topic partition data since the v2 version will just include an empty list in that case? also, might be worth checking in on the patch(es) for [a link] to see how this will be impacted. i'd imagine you actually want to test both versions.",0,0.9925429821014404
95104149,2074,ewencp,2017-01-09T05:40:32Z,"since the is specific to v2+, the constructor used doesn't even really need the `responsedata` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `offsetfetchresponse`.",0,0.9919558763504028
95106780,2074,ewencp,2017-01-09T06:43:47Z,comment can be cleaned up,0,0.9920321702957153
95106900,2074,ewencp,2017-01-09T06:46:14Z,"also, i noticed when reviewing this that `offsetfetchrequest.handleerror` doesn't use the request version when constructing the `offsetfetchresponse`. this seems broken, but even more so now that the format differs between versions. (strictly speaking i think it was already broken and a strict client could have potentially caught the issue.)",0,0.9538857936859131
95108544,2074,ewencp,2017-01-09T07:10:51Z,"i think you need to be careful about listing unauthorized topics. if `offsetfetchrequest.isallpartitions()` is `true`, then you shouldn't reveal the existence of unauthorized topics. see `handletopicmetadatarequest` for an example of what i mean.",0,0.9817997217178345
95235045,2074,vahidhashemian,2017-01-09T20:06:14Z,thanks for catching this. this method is not required anymore as it's part of rejected alternatives 1 and 2. i'll remove it.,1,0.9751281142234802
95239706,2074,vahidhashemian,2017-01-09T20:32:26Z,that's fair. i can modify the condition of the `if` block before this `switch` statement to skip building `responsedata` for version 2 and beyond.,0,0.9837237596511841
95273042,2074,vahidhashemian,2017-01-09T23:43:03Z,you're right. i'll try to follow a similar pattern for `offsetfetchresponse` in the next update.,0,0.9336053133010864
95294702,2074,vahidhashemian,2017-01-10T03:25:11Z,"i'll update the expected responses as you suggested. regarding supporting both versions it seems that work would conflict with what is being implemented for kip-97. not sure what's the best way to handle it, wait for that to merge first, or move forward with this as is (assuming the latest api version), and then update as part of or after kip-97.",0,0.9082826375961304
95297660,2074,ewencp,2017-01-10T04:10:35Z,"yeah, tbh i wasn't sure either since i hadn't reviewed those patches yet and wasn't sure of the state. i mentioned this to today as well. his thought was that since [a link] (which is actually only 1 of a couple of patches for kip-97) is quite large, it might make sense to get it merged first. we're pretty sure this is the only kip that will potentially be affected by it. has also taken a pass at that one, so if we merge it and you need guidance on updating the patch, he can probably give direction pretty easily. i just checked and there are some minor merge conflicts, but nothing too crazy, so my guess would be that it'd only be a bit more work to layer on the extra bit of compatibility work.",0,0.9291067123413086
95298064,2074,vahidhashemian,2017-01-10T04:17:08Z,sounds good to me. i'll work on the rest of items you found in the meantime that pr gets merged. then we can revisit this piece.,1,0.9103721976280212
95298512,2074,vahidhashemian,2017-01-10T04:24:36Z,another good catch. will try to address this it in the next update.,1,0.9896161556243896
95431126,2074,vahidhashemian,2017-01-10T18:51:35Z,you're right. i'll try to fix this in the next update.,0,0.7455396056175232
95485200,2074,hachikuji,2017-01-10T23:54:00Z,kind of annoying that the response doesn't give us an instance of `errors` directly.,-1,0.9805244207382202
95485372,2074,hachikuji,2017-01-10T23:55:28Z,comment is out of date.,0,0.8559600710868835
95488199,2074,hachikuji,2017-01-11T00:17:09Z,nit: not really sure we need two separate constants even though they are separate fields in the struct.,0,0.8533124923706055
95488264,2074,hachikuji,2017-01-11T00:17:48Z,perhaps useful to break down which of these are partition errors?,0,0.9889967441558838
95489296,2074,hachikuji,2017-01-11T00:26:36Z,"this will be a little annoying to handle when we incorporate the client compatibility kip since we'll have to check for the presence of these errors at both levels. one option might be to enhance the parsing of the response to check for the presence of one of the top-level errors in the partition data. if it is there, we could insert it at the top level as well. currently i think we just put `errors.none` at the top level for old versions.",-1,0.9556194543838501
95491518,2074,hachikuji,2017-01-11T00:45:18Z,"couldn't we push this logic into the response constructor? perhaps if the version is equal to 1, we take the top level error code and insert it into the partition data?",0,0.9924752116203308
95497258,2074,vahidhashemian,2017-01-11T01:40:34Z,i'll add a method to `offsetfetchresponse` that returns the actual `errors` value.,0,0.9946698546409607
95497341,2074,vahidhashemian,2017-01-11T01:41:27Z,no problem. i'll use the same constant.,0,0.7639346718788147
95498385,2074,vahidhashemian,2017-01-11T01:52:46Z,"sure, i also used a constant below this comment to define and use that in the code.",0,0.9913524389266968
95501741,2074,vahidhashemian,2017-01-11T02:24:15Z,sure. and i think it would be safe to insert one top level error in case there are more than one.,0,0.9820166230201721
95650676,2074,vahidhashemian,2017-01-11T19:20:32Z,"i think i'm missing something here. we are already iterating over all partitions here (for version 1) and injecting the proper error code. if we want to do the injection in `offsetfetchresponse` constructor, we need to iteration over them again, which wouldn't be very efficient. could you please clarify? thanks.",1,0.7815771102905273
95652522,2074,hachikuji,2017-01-11T19:29:38Z,"mainly what i'm trying to achieve is keeping version handling logic out of `groupcoordinator` as much as possible. so what i had in mind is a constructor or a factory which accepts a top-level error code and a list of the partitions. in the case of the old version, we take the top-level error code and override the partition-level errors. in the case of the new version, we can ignore the partition data and just return the top-level error code.",0,0.9829965233802795
95659959,2074,vahidhashemian,2017-01-11T20:04:47Z,thanks for clarifying. so the signature of this `groupcoordinator` method would likely need to be modified to return a `offsetfetchresponse` instance.,1,0.9174749255180359
95660614,2074,hachikuji,2017-01-11T20:07:41Z,true. i'm not sure that's better or worse. it doesn't seem too bad given that we already return `offsetfetchresponse.partitiondata` though.,0,0.8284267783164978
95669374,2074,vahidhashemian,2017-01-11T20:52:43Z,"yes, the only thing is after building the offset response here we'll have to later add response data for unauthorized topics.",0,0.9890215992927551
95672186,2074,hachikuji,2017-01-11T21:08:28Z,"good point... one option that comes to mind is to use exceptions to propagate top-level errors. this would rely on `offsetfetchrequest.geterrorresponse` to build the response. but we don't do that for any of the other coordinator apis, so i'd rather not make this case exceptional. so how about this: in addition to returning the top-level error code directly in the tuple, we also use it to fill the partition-level error code. then we don't need to pass the version into `groupcoordinator` at all and we can let the handler in `kafkaapis` decide how to do the serialization. basically if the top-level error code is not none, then ignore the partitions.",1,0.8311507105827332
95672359,2074,hachikuji,2017-01-11T21:09:24Z,can we use `errors` instead of `short` in the return type?,0,0.9936514496803284
95673432,2074,hachikuji,2017-01-11T21:15:04Z,"or perhaps even simpler: we could always return the error code and an empty map, and we could let `kafkaapis` expand the error code into the partition data when required by the fetch version?",0,0.9885416030883789
95677478,2074,vahidhashemian,2017-01-11T21:36:08Z,thanks. i also like your last suggestion.,1,0.9847562909126282
95700427,2074,hachikuji,2017-01-11T23:58:36Z,could we just use `errors` throughout? you can always get the code from `errors` if you really need it.,0,0.9934437274932861
95719434,2074,hachikuji,2017-01-12T03:17:37Z,i wonder if we ought to just assume that the error goes at the top-level. it's a little weird to receive a partition-specific error code here and then assume that it should be used for _all_ partitions.,-1,0.9634392857551575
95719458,2074,hachikuji,2017-01-12T03:18:01Z,"this is `errorcodethrown`, right?",0,0.9921147227287292
95719646,2074,hachikuji,2017-01-12T03:20:34Z,maybe we can remove this and force the use of `error()`?,0,0.9905036091804504
95721130,2074,hachikuji,2017-01-12T03:43:01Z,nit: braces for multi-line branches,0,0.9936767220497131
95721250,2074,hachikuji,2017-01-12T03:43:54Z,nit: i think this could be replaced by `offsets.get(topicpartition).map(_.offset)`,0,0.9889823794364929
95721791,2074,hachikuji,2017-01-12T03:51:41Z,nit: right-hand side could be replaced by `new topicandpartition(offset._1)`,0,0.9951351284980774
95722080,2074,hachikuji,2017-01-12T03:56:23Z,"a little easier to follow this if you deconstruct the tuple (i.e. use `case (topicpartition, partitiondata)`.",0,0.9864019751548767
95722163,2074,hachikuji,2017-01-12T03:57:36Z,"where do we check errors in the response? if we push the error checking into `listgroupoffsets`, maybe this api could return `map[topicpartition, long]` as you would probably expect.",0,0.9936803579330444
95722389,2074,hachikuji,2017-01-12T04:00:57Z,same as comment above: maybe we always treat this as a top-level error?,0,0.9895721673965454
95722449,2074,hachikuji,2017-01-12T04:01:54Z,nit: the `case` is unneeded.,0,0.9907998442649841
95722624,2074,hachikuji,2017-01-12T04:04:27Z,"nit: slightly more natural if `errors` is the first entry? also, we don't need `apiversion` anymore, right?",0,0.9822302460670471
95722933,2074,hachikuji,2017-01-12T04:08:46Z,we need to synchronize on the group to access its state.,0,0.9923087358474731
95723097,2074,hachikuji,2017-01-12T04:10:06Z,not sure about the name. how about `partitionswithcachedoffsets`?,0,0.9805590510368347
95723245,2074,hachikuji,2017-01-12T04:12:45Z,"alternatively, we could allow `handlefetchoffsets` to return all offsets for the group, and we could filter out the partitions that the principal is not authorized to access. that seems a little bit better than exposing a new method in `groupcoordinator`.",0,0.991058349609375
95723440,2074,hachikuji,2017-01-12T04:15:42Z,"if there should be a member, perhaps we should assert it?",0,0.9909451007843018
95723511,2074,hachikuji,2017-01-12T04:17:00Z,"nit: easy to miss the `&&` with this alignment. perhaps this could go on the previous line? also we can use `contains`. for example: `state.contains(""dead"")` instead of `state == some(""dead"")`.",0,0.9694643020629883
95723657,2074,hachikuji,2017-01-12T04:19:41Z,nit: replace with `contains`,0,0.9951956868171692
95723677,2074,hachikuji,2017-01-12T04:20:05Z,nit: we could use `count` here.,0,0.9896008372306824
95723736,2074,hachikuji,2017-01-12T04:21:01Z,maybe this should be in a `finally`? similar below,0,0.9835277795791626
95724623,2074,hachikuji,2017-01-12T04:36:09Z,"you can use `==` instead of `equals` for all of these. as it is, intellij is complaining that the types are unrelated.",0,0.9869208335876465
95725601,2074,hachikuji,2017-01-12T04:54:05Z,nit: pretty sure we shouldn't need this if we're throwing an exception above. more of these below.,0,0.6990649104118347
95847224,2074,vahidhashemian,2017-01-12T17:55:09Z,so you mean if there is a top-level error code it should not be partition error? i'm okay with that. in that case the second check on this line would be redundant. please advise if i misunderstood. thanks.,1,0.9523637890815735
95849478,2074,vahidhashemian,2017-01-12T18:06:20Z,and perhaps later we should remove this method from other `response` classes.,0,0.9934496283531189
95854631,2074,vahidhashemian,2017-01-12T18:32:55Z,sounds good. i had missed the error check after the latest api change. thanks.,1,0.9933070540428162
95855842,2074,hachikuji,2017-01-12T18:39:06Z,"haha, i'm not sure whether we're saying the same thing. my suggestion was to blindly treat the exception as a top-level error. in other words, take the error code from the exception and use it as the top-level error code for new versions, and as the partition-level error code for old versions.",1,0.9448272585868835
95855851,2074,vahidhashemian,2017-01-12T18:39:08Z,"right, and with the change to return type of `listgroupoffsets` this will become `offsets.get(topicpatition)`. thanks.",1,0.6245930194854736
95859684,2074,hachikuji,2017-01-12T18:57:39Z,definitely. this is one of my favorite gripes. using more specific types whenever possible allows the compiler to do more work for us.,1,0.9170420169830322
95869619,2074,vahidhashemian,2017-01-12T19:45:04Z,so even the older versions will have an error code at the top level? this would change it to [code block],0,0.9924914240837097
95875608,2074,vahidhashemian,2017-01-12T20:17:31Z,"sure, this is a better approach. thanks.",1,0.9653505086898804
95886293,2074,vahidhashemian,2017-01-12T21:16:06Z,`contains` seems to be not supported in scala 2.10. and builds are failing locally for me because of that. don't we still support 2.10? is there a way to get around it?,0,0.6095324754714966
95891116,2074,vahidhashemian,2017-01-12T21:41:53Z,"sure, i'm using eclipse and it doesn't complain about `equals`.",0,0.9852041006088257
95912504,2074,hachikuji,2017-01-12T23:54:49Z,don't worry about it if it's not supported.,0,0.5731126666069031
95913606,2074,vahidhashemian,2017-01-13T00:04:00Z,"well, this actually breaks the unit test, because we don't want to run the `try` block only once. we want to keep trying until the group stabilizes. if we move the `close` to `finally` we close the command after the first try and run into an error on the next try.",0,0.8953105807304382
95937690,2074,vahidhashemian,2017-01-13T04:51:32Z,"so if we want to just check the top level error for any error in the response for partition level errors we lose the specific partitions that are erroneous. also, if there are different partition level error types present we'll report only one. this just limits the error reporting but shouldn't affect the functionality. i hope i did not misunderstand your point.",0,0.9614191651344299
95937720,2074,vahidhashemian,2017-01-13T04:52:12Z,"also, do you happen to know why out of the 5 possible errors we just check only 3 here?",0,0.987136721611023
95938741,2074,hachikuji,2017-01-13T05:09:43Z,maybe we should enforce a minimum version number when querying all partitions? you can look at `listoffsetrequest` for an example of this.,0,0.9896690249443054
95939088,2074,hachikuji,2017-01-13T05:16:00Z,nit: add a space before the `:`.,0,0.993719220161438
95939338,2074,hachikuji,2017-01-13T05:20:11Z,wonder if there's any harm retaining the top-level error regardless of the version. seems more consistent with how we handle the case of constructing from a `struct`.,0,0.9762157201766968
95939575,2074,hachikuji,2017-01-13T05:23:09Z,probably worth a comment explaining why we do this.,0,0.9637266397476196
95939801,2074,hachikuji,2017-01-13T05:25:39Z,"related to above comment. this method only makes sense for version 2, so maybe we should remove `version` and use 2 directly.",0,0.991845428943634
95939909,2074,hachikuji,2017-01-13T05:27:50Z,do we need to check the partition errors also?,0,0.9942523837089539
95939988,2074,hachikuji,2017-01-13T05:29:04Z,nit: space after comma.,0,0.9803071618080139
95940177,2074,hachikuji,2017-01-13T05:31:54Z,you could also use `new topicandpartition(topicpartition)`,0,0.9954208731651306
95940449,2074,hachikuji,2017-01-13T05:36:09Z,"instead of using `null` as the sentinel, we could use an `option`.",0,0.9938147068023682
95940542,2074,hachikuji,2017-01-13T05:37:41Z,another option would be to push the handling of all offsets into `getoffsets`. one small advantage is that you would only need to acquire the lock once instead of twice.,0,0.993497371673584
95942547,2074,hachikuji,2017-01-13T06:11:25Z,you could do these assignments at once: [code block] we use this pattern just below.,0,0.9940193891525269
95942666,2074,hachikuji,2017-01-13T06:13:31Z,"seems like this and the other call to `handlefetchoffsets` below needs to go to the `else` case after the check for version 0. for version 0, we pull offsets from zookeeper. i'm wondering if your first approach, which collected all partitions from the coordinator first, may have been a little cleaner. another option to consider, perhaps you could do the post-filtering for the `isallpartitions` case separately, and continue doing pre-filtering when we are provided the partition list.",0,0.9817309379577637
95942941,2074,hachikuji,2017-01-13T06:17:07Z,"i was thinking we could handle both of these cases in the same constructor. the constructor would take a single error code and the list of requested partitions. if the version is greater than or equal to 2, the partitions are ignored; otherwise, the error code is written into the partition errors.",0,0.9864251613616943
96034941,2074,vahidhashemian,2017-01-13T17:25:50Z,i think it should be okay to do that. will update.,0,0.9125427603721619
96036429,2074,vahidhashemian,2017-01-13T17:34:41Z,will there be any partition error? in the case of all offsets unauthorized partitions are excluded and there won't be any unknown topic partition. do you think we should throw an exception if there is any?,0,0.9907090663909912
96042948,2074,hachikuji,2017-01-13T18:12:16Z,seems safer (and more future-proof) to check and throw an exception.,0,0.9781000018119812
96043181,2074,vahidhashemian,2017-01-13T18:13:33Z,great idea because `getoffsets` already gives us what we want ([a link].,1,0.9743253588676453
96057467,2074,vahidhashemian,2017-01-13T19:29:20Z,good idea. thanks.,1,0.9949343800544739
96058029,2074,vahidhashemian,2017-01-13T19:32:19Z,"would it also work if one assignment depends on the other one? `partitions` uses `groupoffsets`. also, it may not read easily since there is a big type definition for `groupoffsets`.",0,0.9876876473426819
96059742,2074,hachikuji,2017-01-13T19:40:46Z,does type inference not work? i was thinking something like this: [code block],0,0.9740066528320312
96060015,2074,hachikuji,2017-01-13T19:42:08Z,nit: unneeded parenthesis.,0,0.865545392036438
96062247,2074,vahidhashemian,2017-01-13T19:53:46Z,"yes, it works perfectly. sorry for the premature question!",-1,0.9948057532310486
96085672,2074,vahidhashemian,2017-01-13T22:21:35Z,still not too sure about this. did you want to move this error check up in the first `if` block?,0,0.574257493019104
96088422,2074,hachikuji,2017-01-13T22:41:45Z,i'm not sure i see the problem. would we ever see this at the top level?,0,0.665062427520752
96089207,2074,hachikuji,2017-01-13T22:46:58Z,"actually i guess we could make this a little simpler. we know we need version 2, so maybe we can use it directly and remove `minversion`?",0,0.9858300089836121
96089229,2074,vahidhashemian,2017-01-13T22:47:07Z,"i'm referring to [a link], and i'm not sure if it implied modifying this method too.",0,0.9839942455291748
96089343,2074,vahidhashemian,2017-01-13T22:48:03Z,"sure, i thought about it too, but thought to keep it in sync with `listoffsetrequest`. i'll update.",0,0.9883792400360107
96090049,2074,hachikuji,2017-01-13T22:53:44Z,"i was mainly concerned that we'd need to check errors in both places, but i think we're good now since we ensure that top-level error codes will always appear at the top level (even for older versions).",1,0.5392225980758667
96090198,2074,hachikuji,2017-01-13T22:54:55Z,"yeah, we're still feeling out the best patterns for handling older versions.",0,0.9793501496315002
96090442,2074,vahidhashemian,2017-01-13T22:56:45Z,"great, thanks for clarifying.",1,0.9912808537483215
96091324,2074,hachikuji,2017-01-13T23:04:02Z,could we mention that we do this so that the client can depend on the top-level error code regardless of the offset fetch version?,0,0.9939017295837402
96091481,2074,hachikuji,2017-01-13T23:05:30Z,do we need another field if the errors are already contained in `partitiondata`?,0,0.9940213561058044
96092241,2074,hachikuji,2017-01-13T23:10:41Z,"talked to about this, and i don't think we need to bump the internal version number since the brokers do not use offset fetches themselves.",0,0.9912302494049072
96092616,2074,vahidhashemian,2017-01-13T23:13:53Z,i added this to keep track of partition errors that is needed by `adminclient` [a link]. unless it's okay to process `partitiondata` on the fly?,0,0.9955535531044006
96092684,2074,vahidhashemian,2017-01-13T23:14:22Z,sounds good. i'll remove the internal version.,1,0.7680206298828125
96092918,2074,hachikuji,2017-01-13T23:16:39Z,"seems just as efficient to me, especially since we only throw the first error.",0,0.9725224375724792
96093935,2074,vahidhashemian,2017-01-13T23:24:50Z,"sure, then i think we perhaps need to at least have another `errors` member for that first partition error. so we don't have to process `partitiondata` multiple times for checking the existence and actually retrieving the error (in `haspartitionerrors` and `partitionerrors`).",0,0.987261950969696
96094359,2074,hachikuji,2017-01-13T23:28:38Z,"i think this is close, but it's a bit annoying that we have to call `handlefetchoffsets` in two places, right? wouldn't it be better to delay the check for `isallpartitions` and the filtering until after the call to `handlefetchoffsets` below. that gives us a clean separation of the kafka and zookeeper offset handling. so maybe the logic can be something like this: 1. filter unauthorized partitions 2. check if this is version 0 a. fetch from zk for version 0 b. check from kafka for versions 1 and above. after receiving the fetched offsets, check if `isallpartitions` is set. if so, additionally filter out the fetched offsets for topics we are not authorized for. does that make sense?",-1,0.46934422850608826
96094652,2074,hachikuji,2017-01-13T23:31:17Z,hmm.. it just doesn't seem worth optimizing for. processing the partition data means what? looping over it and checking if error is none? does it matter if we do that twice? we could also just leave off the `haspartitionerrors` and do a single iteration and raise the error on the first exception.,0,0.565941572189331
96095174,2074,vahidhashemian,2017-01-13T23:36:50Z,would something like this work? [code block],0,0.9940260648727417
96095469,2074,hachikuji,2017-01-13T23:40:03Z,"sure, that would work. maybe `getfirstpartitionerror` is a clearer name? or you could bundle the exception throwing as well into a single `maybethrowfirstpartitionerror`? either way is fine with me, but i'd prefer not to additional fields without a clear case that they're needed.",0,0.9531140327453613
96096333,2074,vahidhashemian,2017-01-13T23:48:54Z,"if i understand this correctly, for version 1 and above, to receive the fetched offsets we already need to check `isallpartitions` to determine if `none` or `some(partitions)` should be passed to `handlefetchoffsets`.",0,0.9937997460365295
96096521,2074,hachikuji,2017-01-13T23:50:38Z,"yeah, that's fair. the point is that it should happen in the kafka branch of that `if` and not before.",0,0.9661248326301575
96097187,2074,vahidhashemian,2017-01-13T23:58:29Z,i think we need to call `isallpartitions` upfront anyway because we need to make sure `offsetfetchrequest.partitions` is not null before starting to filter.,0,0.9851300716400146
96097302,2074,hachikuji,2017-01-13T23:59:40Z,ack,0,0.9149930477142334
96099907,2074,vahidhashemian,2017-01-14T00:28:49Z,i hope this is now closer to what you described.,1,0.7995782494544983
138698389,3849,becketqin,2017-09-13T18:15:47Z,it seems better to say producer.send() instead of send.,0,0.9895725846290588
138699047,3849,becketqin,2017-09-13T18:18:06Z,we are passing `now` everywhere else. maybe we can just keep the argument name the same.,0,0.9878732562065125
138726608,3849,tedyu,2017-09-13T20:14:46Z,should <= be used ?,0,0.9911707639694214
138726989,3849,tedyu,2017-09-13T20:16:27Z,deliverytimeoutms should be mentioned,0,0.9950317144393921
138787782,3849,becketqin,2017-09-14T03:06:17Z,should we validate the delivery.timeout.ms is greater than request.timeout.ms?,0,0.9943482279777527
138789918,3849,becketqin,2017-09-14T03:31:27Z,it is probably cleaner to have an explicit `expired` state.,0,0.9842261672019958
138791125,3849,becketqin,2017-09-14T03:46:07Z,"the logic here probably needs more comments. we may have the following three cases that the state of a batch has been updated before the produceresponse returns: 1. a transaction abortion happens. the state of the batches would have been updated to `aborted`. 2. the producer is closed forcefully. the state of the batches would have been updated to `aborted`. 3. the batch is expired when it is in-flight. the state of the batch would have been updated to `expired`. in the other cases, we should throw illegalstateexception.",0,0.987544059753418
138791482,3849,becketqin,2017-09-14T03:50:16Z,"the batches still needs to be expired in order if `max.in.flight.requests.per.connection` is set to 1. so we probably still want to check if the partition is muted or not. that said, if we guarantee that when `recordaccumulator.expiredbatches()` returns non-empty list, all the earlier batches have already been expired, we can remove the muted check here. btw, i did not see the logic of expiring an in-flight batch in the current patch. am i missing something?",0,0.9876746535301208
138791524,3849,becketqin,2017-09-14T03:50:53Z,isfull is no longer used.,0,0.9086669683456421
138977901,3849,sutambe,2017-09-14T18:40:05Z,agreed,0,0.9598594307899475
139014083,3849,sutambe,2017-09-14T21:19:24Z,"the actual argument is `now`. however, i like the formal argument name to be `createtime` because it's an immutable value while constructing a batch. `now`, is by definition, changing.",0,0.9908863306045532
139014648,3849,sutambe,2017-09-14T21:22:07Z,i did some digging around. an expired batch's final state is `failed`. i don't feel great about adding yet another `finalstate`. we already have `aborted` and `failed`. the `producerbatch.done` will get even more complicated.,-1,0.9151309132575989
139246402,3849,sutambe,2017-09-15T20:45:56Z,please review the updated method documentation.,0,0.9937176704406738
139768240,3849,tedyu,2017-09-19T17:53:22Z,this variable can be dropped.,0,0.9943189024925232
139842619,3849,tedyu,2017-09-19T23:24:22Z,in not -> is not,0,0.49834969639778137
139843016,3849,tedyu,2017-09-19T23:27:37Z,the check 'if (deliverytimeoutms <= (now - this.createdms))' inside maybeexpire() would be true. looks like another method can be created inside producerbatch which expires the batch.,0,0.9942945837974548
139851577,3849,sutambe,2017-09-20T00:34:32Z,`maybeexpire` has a side-effect of setting `errormessage` internally. hence calling it again in `if`.,0,0.9916859269142151
139852241,3849,tedyu,2017-09-20T00:40:18Z,understand. that part can be refactored - goal is to reduce unnecessary comparison.,0,0.9906452894210815
139852661,3849,sutambe,2017-09-20T00:43:47Z,those test don't even compile or run on my machine. what's up with those tests?,-1,0.9084042310714722
139853479,3849,apurvam,2017-09-20T00:51:42Z,they can't construct a kafka producer with the changes made in this pr.,0,0.98115473985672
139871039,3849,becketqin,2017-09-20T04:01:43Z,is this comment accurate? the new state is not necessarily succeeded.,0,0.9892953038215637
139871499,3849,becketqin,2017-09-20T04:04:58Z,"maybe it's not a big deal but just want to call out that this is a behavior change. currently the producer will throw exception when transition from failed state to another state due to some reason other than expiration. if we change this logic, we may miss those cases which are not failed by expiration but still got state update twice. it may not be that important if we do not have programming bugs. personally i think it is better to clearly define the states of the batches even if additional complexity is necessary. the comments should probably also cover the force close case for completeness.",0,0.9123786091804504
139873674,3849,becketqin,2017-09-20T04:33:40Z,"some typos in this comments. ""expire the batch if no outcome is known within delivery.timeout.ms""",0,0.8428994417190552
139874459,3849,becketqin,2017-09-20T04:44:01Z,does this have to be a per partition map? intuitively we just need a `treeset ` with a comparator?,0,0.9895463585853577
139874583,3849,becketqin,2017-09-20T04:45:39Z,"assuming `nflightbatches` is a treeset suggested above, this code can be simplified to: [code block]",0,0.994279146194458
139874633,3849,becketqin,2017-09-20T04:46:09Z,`tp` is not used anymore.,0,0.9925464987754822
139874861,3849,becketqin,2017-09-20T04:49:12Z,no longer used.,0,0.9484594464302063
139874980,3849,becketqin,2017-09-20T04:50:43Z,this logic would become `inflightrequests.remove(batch)` when a `treeset` is used for this.,0,0.9942003488540649
139875140,3849,becketqin,2017-09-20T04:52:44Z,this would be just `inflightbatches.add(batch)`,0,0.9953792095184326
139875288,3849,becketqin,2017-09-20T04:54:13Z,we usually just use `earliestdeliverytimeout` in kafka.,0,0.9941734671592712
139875598,3849,becketqin,2017-09-20T04:58:47Z,it seems we don't need the `deliverytimeoutms` in the sender. it is only used as an argument passed to the accumulator. but the accumulator already has the config.,0,0.9911544322967529
139876175,3849,becketqin,2017-09-20T05:06:51Z,it seems an existing issue. when we expire the batches here. the memory of those batches will be deallocated. it seems that we will deallocate the same batch again when the produceresponse returns?,0,0.9912859797477722
140056222,3849,becketqin,2017-09-20T18:37:07Z,"apparently the my understanding of `treeset` is not accurate. it uses the comparator to decide whether the entries are the same or not. we can use a treemap > then. we may also want to bucket the timestamp a little bit, say one second to avoid huge amount of sets created for each ms in the `treemap`.",0,0.981751024723053
140087965,3849,tedyu,2017-09-20T20:45:59Z,"i was thinking about this too. using millisecond as unit for map key is not prudent. after the switch to second as unit, we may need to check the two adjacent buckets keyed by ts-1 (sec) and ts+1 (sec).",0,0.9777968525886536
140133571,3849,becketqin,2017-09-21T01:50:36Z,this test has nothing to do with linger.ms anymore...,0,0.9701270461082458
140133681,3849,becketqin,2017-09-21T01:51:43Z,similar to above we should rename this.,0,0.9918640851974487
140133773,3849,becketqin,2017-09-21T01:52:35Z,typo: timeout,0,0.9832100868225098
140133809,3849,becketqin,2017-09-21T01:53:02Z,typo: timeout,0,0.9832100868225098
140136188,3849,becketqin,2017-09-21T02:19:02Z,"should we still expire the batches when they are expired instead of expiring all the bucket? having a second granularity bucket does not prevent us from doing that, right?",0,0.9878537654876709
140303384,3849,sutambe,2017-09-21T17:11:05Z,"as we discussed, `treeset` does not cut it. the naming is consistent. a `treeset` is a set. it's just that equality criterion is different.",0,0.9893137812614441
140304267,3849,sutambe,2017-09-21T17:14:47Z,it's there now,0,0.9922553300857544
140367934,3849,hachikuji,2017-09-21T21:47:38Z,"hmm.. might not be too important, but it doesn't seem necessary to include the retry backoff in this check. if the user sets retries=0, then the backoff shouldn't matter.",0,0.9668794274330139
140370206,3849,hachikuji,2017-09-21T21:58:50Z,"we are using the creation time of the batch to check for expiration. that will tend to expire some records which were added to the batch after creation earlier than the delivery timeout (by as much as linger.ms). alternatively, we could use the time that the batch was closed, which will tend to expire records later than the delivery timeout (by as much as linger.ms), but maybe expiring late is bit safer than expiring early? this is equivalent to saying that the delivery timeout excludes linger time.",0,0.9910616278648376
140371334,3849,hachikuji,2017-09-21T22:05:06Z,"checking my understanding. with this change, it should no longer be possible to expire a batch before linger.ms has completed and the batch has been closed. if so, do we still need the logic to abort appends on expiration? (it might be safer to have it anyway, just checking if it is still needed for correctness)",0,0.9885357022285461
140373989,3849,hachikuji,2017-09-21T22:21:29Z,"after we reset `earliestdeliverytimeoutms`, it seems that we do not take into account the expiration times of in-flight batches.",0,0.9914332628250122
140375038,3849,hachikuji,2017-09-21T22:29:00Z,do we have any microbenchmarks that show this (potential) optimization is justified?,0,0.9937049746513367
140377235,3849,hachikuji,2017-09-21T22:44:15Z,why do we need this check? a comment would be helpful.,0,0.9805082678794861
140392052,3849,sutambe,2017-09-22T00:47:58Z,batch close may be arbitrrily delayed in some cases. see 's explanation: [a link],0,0.9885334372520447
140394635,3849,sutambe,2017-09-22T01:16:46Z,fixed. take a look.,0,0.9917654395103455
140395587,3849,sutambe,2017-09-22T01:26:49Z,`recordaccumulator.maybeupdateearliestdeliverytimeout`,0,0.9939383268356323
140560836,3849,apurvam,2017-09-22T18:10:06Z,"shouldn't we also be removing the batches from the inflight set when the batch is completed (failed or successfully)? i might be missing something, but i don't see that code here.",0,0.9862516522407532
140571976,3849,sutambe,2017-09-22T18:59:40Z,"right. cleanup of `soontoexpireinflightbatches` happens in two places (1) if a batch gets reenqueued and (2) when `sender` looks for `expiredbatches`. in the second case, we cleanup the batches whose final state is known (success or failure) and there by ""removing"" them.",0,0.9910416007041931
140590998,3849,hachikuji,2017-09-22T20:35:40Z,"as far as i can tell, it shouldn't be possible to abort a batch after it has been completed. is this correct? if so, i think it might be better to continue to raise `illegalstateexception`. it's preferable to keep the allowable state transitions as narrowly defined as possible since it ensures faster failure for unexpected paths.",0,0.9886481165885925
140591599,3849,hachikuji,2017-09-22T20:38:58Z,this is still not used,0,0.9930567741394043
140591635,3849,hachikuji,2017-09-22T20:39:10Z,still not used,0,0.9095432162284851
140592411,3849,hachikuji,2017-09-22T20:43:10Z,"nit: ""for quick **access** to the oldest batch""?",0,0.8978927731513977
140594775,3849,hachikuji,2017-09-22T20:55:31Z,"if you are not implementing this, can you please remove it?",0,0.9911243319511414
140596621,3849,hachikuji,2017-09-22T21:05:43Z,the name is a little misleading given its proximity to similarly named fields. maybe something like `nextexpirationtimestampms` would be clearer?,0,0.6702398657798767
140597138,3849,hachikuji,2017-09-22T21:08:29Z,thanks. i synced with jun and it seems reasonable. it would help to document somewhere why we use create time.,1,0.9731054902076721
140603555,3849,hachikuji,2017-09-22T21:45:41Z,i think the answer to this question is that it is possible to expire while the batch is still being built because closing the batch can be arbitrarily delayed by inflight fetches.,0,0.9830718636512756
140604152,3849,hachikuji,2017-09-22T21:49:42Z,please respond to this. is it necessary to include retry_backoff in this check?,0,0.9943231344223022
140604457,3849,hachikuji,2017-09-22T21:51:32Z,do we want to mention the other case where a record is expired early because it was added to a batch which was already nearing expiration?,0,0.9889296889305115
140606225,3849,hachikuji,2017-09-22T22:04:24Z,"the logic for updating this field seems to assume that the batch at the front of the deque will always be the next to expire, but i'm not sure that is true in the case of retries.",0,0.9844804406166077
140608227,3849,hachikuji,2017-09-22T22:21:05Z,"to be honest, this lazy expiration seems like overkill. it should be a rare case where we actually have entries in `soontoexpireinflightbatches` because of the other optimization to only add to it when the delivery timeout will expire prior to the request timeout. and if the producer is in a situation where batches are being expired, then the performance of removal for a particular batch is probably not a major concern. maybe some benchmarking would show whether it is a worthwhile optimization.",-1,0.6161782145500183
140608868,3849,hachikuji,2017-09-22T22:26:51Z,inadvertent commit i assume.,0,0.9809003472328186
140609030,3849,hachikuji,2017-09-22T22:28:14Z,"if we're just returning `true` for `matches`, we don't need to provide a `requestmatcher` at all.",0,0.9893071055412292
140614799,3849,sutambe,2017-09-22T23:24:16Z,i think `retrybackoff` can be dropped. perhaps we can do two tests based on whether `retries` is set or not.,0,0.9877882599830627
140617891,3849,tedyu,2017-09-22T23:59:57Z,i don't see bucketing,0,0.9388079047203064
140619943,3849,becketqin,2017-09-23T00:30:02Z,"i agree in most case we probably do not need this. it is probably only useful for large producers (e.g. mirror maker which has thousands of partitions to send). there may still be value to have this: 1. since delivery.timeout.ms and request.timeout.ms are both user configurations. it would be good to guard against some configurations. (e.g. request.timeout.ms=delivery.timeout.ms, linger.ms=0). 2. it seems that in some scenarios this would help. for example, when the brokers are being rolling bounced, there will be a lot of retried batches. those batches may have `remainingdeliverytimeoutms` < `request.timeout.ms`. we may have even more than one batches per partition to insert if max.in.flight.request is greater than 1. a benchmark would be useful. but in general i think it is safer to have this optimization given it does not increase too much complexity.",0,0.8994975686073303
140625298,3849,becketqin,2017-09-23T04:01:04Z,i had a comment earlier that it seems we should still expire the batch at exact createtime + deliverytimeoutms even if we bucket them by seconds.,0,0.9911780953407288
140625337,3849,becketqin,2017-09-23T04:04:48Z,"i agree with that using retry backoff is a little weird here. `retries` means that ""at most retry that many times within delivery.timeout.ms"". so even if `retries` is greater than 0, it does not mean there must be a retry. so we should probably just check the `delivery.tiemout.ms` is at least `linger.ms` + `request.timeout.ms`.",0,0.6139545440673828
140625355,3849,becketqin,2017-09-23T04:06:58Z,i also think we should mention the scenario that a record is added to a batch that is about to expire.,0,0.9859043955802917
140625458,3849,becketqin,2017-09-23T04:14:29Z,can we update the java doc to explain the return value?,0,0.9951698184013367
140625583,3849,becketqin,2017-09-23T04:24:43Z,personally i still think a clear expired state would be clearer. we can let batch.done() method take a finalstate argument instead of inferring the state from the exception.,0,0.9766232967376709
140625869,3849,becketqin,2017-09-23T04:46:59Z,"good point. it would work if max.in.flight.requests.per.connection=1, or when we enable idempotence. but otherwise the first batch may not be the first to expire. since we do not even have callback order guarantee in that case, maybe it is fine? but we should definitely document this.",1,0.9604429602622986
140626273,3849,becketqin,2017-09-23T05:15:12Z,this test will pass whether line 76 throws illegalstateexception or not. should we add a fail() statement after line 76?,0,0.9936449527740479
140626284,3849,becketqin,2017-09-23T05:16:11Z,is this needed? in what case could e be null?,0,0.9938350915908813
140626361,3849,becketqin,2017-09-23T05:21:32Z,we should change the test name to something like testbatchexpiration. and the test below to testbatchexpirationafterreenqueue.,0,0.9951323866844177
140626370,3849,becketqin,2017-09-23T05:22:08Z,the typo is still there.,0,0.9425710439682007
140626470,3849,becketqin,2017-09-23T05:23:40Z,"testsoontoexpire... (upper case ""to"")",0,0.985325813293457
140626641,3849,becketqin,2017-09-23T05:25:13Z,do you mean it should not be included...,0,0.9850466251373291
140626811,3849,becketqin,2017-09-23T05:38:05Z,typo in the test name.,0,0.9887879490852356
140626831,3849,becketqin,2017-09-23T05:39:42Z,request1 and request 2 are not used.,0,0.9908932447433472
140626885,3849,becketqin,2017-09-23T05:43:03Z,should we check the completeness of request1?,0,0.994355320930481
140626907,3849,becketqin,2017-09-23T05:44:46Z,we may need to call sender.run() one more time to ensure the message is not reenqueued. the reqenqueued message won't be sent out again in the same sender.run().,0,0.9938749670982361
140646338,3849,tedyu,2017-09-24T03:32:38Z,createtime -> creationtime,0,0.9923068881034851
140646367,3849,tedyu,2017-09-24T03:35:40Z,nit: 'else' can be dropped,0,0.9915804266929626
140671368,3849,sutambe,2017-09-24T23:48:00Z,restored the test as it was before.,0,0.9915435314178467
140864460,3849,sutambe,2017-09-25T18:47:43Z,just added a test to ensure that we don't do double deallocation. `sendertest.testnodoubledeallocation`,0,0.9946393370628357
140880631,3849,sutambe,2017-09-25T19:55:16Z,the batch is expired at exact time but not removed from the `soontoexpireinflightbatches`. based on some earlier comments grouping them to avoid pointer chasing?,0,0.9940586090087891
140881985,3849,becketqin,2017-09-25T20:00:59Z,"this method either throw exception or return true, which indicates there is no need to have a return value.",0,0.99367755651474
140884890,3849,apurvam,2017-09-25T20:13:30Z,"hmm. this seems a bit off. what this means that in the 'normal' case when responses are successful and there is no backlog in the accumulator, we will hang on to batches (and not garbage collect them) until the delivery timeout. indeed, if you add the following at the end of sender tests where there are no more inflight requests (ie. all requests have completed and will never be retried) ` asserttrue(accumulator.soontoexpireinflightbatches().isempty());` all the tests fail. i think this should be fixed. we should clear the `soontoexpireinflightbatches` as soon as the batch is completely resolved (ie. failed or completed) so that we don't hang on to the reference unnecessarily.",0,0.8660616278648376
140888794,3849,sutambe,2017-09-25T20:29:28Z,added the muted check back,0,0.9939151406288147
140910557,3849,becketqin,2017-09-25T22:00:14Z,the method never returns false. we can keep it as void if so.,0,0.9924193024635315
140914352,3849,becketqin,2017-09-25T22:20:07Z,should probably add an expire case?,0,0.9924404621124268
140918001,3849,becketqin,2017-09-25T22:41:20Z,the map is not used.,0,0.9886511564254761
140918233,3849,becketqin,2017-09-25T22:42:40Z,should we assert the pool is not deallocated after the expiration but before the response returns?,0,0.9927501678466797
140918761,3849,becketqin,2017-09-25T22:46:05Z,how could the order be violated if we only append the first batch after the first one is expired?,0,0.9834587574005127
140919067,3849,becketqin,2017-09-25T22:47:55Z,the map is not used.,0,0.9886511564254761
140919353,3849,becketqin,2017-09-25T22:49:39Z,nit: can we avoid reusing the argument name?,0,0.9905154705047607
140927438,3849,becketqin,2017-09-25T23:46:36Z,"actually, it seems we may release the memory before the the response returns?",0,0.9939448237419128
140928325,3849,apurvam,2017-09-25T23:53:15Z,"as i mentioned in my other comment, the memory utilization itself is not the issue as much as the fact that we are retaining the reference to `producerbatch` for at least `deliverytimeoutms`. this probably won't cause too much memory pressure, but is still an undesirable behavior.",0,0.8949913382530212
140935275,3849,becketqin,2017-09-26T00:53:48Z,"got it. good catch. yes, we should remove the completed batch.",1,0.9947116374969482
142276754,3849,sutambe,2017-10-02T22:55:37Z,return type restored to `void`,0,0.9938860535621643
142484042,3849,sutambe,2017-10-03T18:29:10Z,can some please clarify what suggestion is made here? remove completed batch from where?,0,0.9913281798362732
150616359,3849,sutambe,2017-11-13T17:56:25Z,fixed the test,0,0.9924823641777039
151183810,3849,sutambe,2017-11-15T16:45:17Z,the new code seems to deallocate the batch right away. i'm not changing the behavior for now.,0,0.9874019026756287
151194892,3849,sutambe,2017-11-15T17:21:41Z,added,0,0.8435775637626648
151195752,3849,sutambe,2017-11-15T17:24:58Z,right,0,0.9678029417991638
151571211,3849,becketqin,2017-11-16T23:56:46Z,`verifyandgetdeliverytimeout()`?,0,0.9954212307929993
151572566,3849,becketqin,2017-11-17T00:06:55Z,this check is a little flaky. what if deliverytimeoutms is `long.max_value - 1`?,0,0.5502891540527344
159586946,3849,becketqin,2018-01-04T06:27:34Z,still not used.,0,0.9004883170127869
159587416,3849,becketqin,2018-01-04T06:34:00Z,we don't need a priorityqueue for this because the batches in the recordaccumulator is already in order. so we just need to keep the draining order.,0,0.9944398403167725
159587789,3849,becketqin,2018-01-04T06:39:32Z,"if we always insert the batch to the inflightbatches queue and there is no bug, the batch to be removed should always be the first batch. can we assert on that?",0,0.9941391944885254
159588151,3849,becketqin,2018-01-04T06:44:30Z,"the original reason we have this optimization is because we used to have a big sorted data structure. so avoiding inserting elements to it makes sense. given that now the batch order in the recordaccumulator is already guaranteed. it seems we can just put all the drained batches to the inflightbatches queue, which is simpler.",0,0.9879305362701416
159593877,3849,becketqin,2018-01-04T07:41:33Z,the while loop may break if the request size has reached. so there is no guarantee that it will iterate over all the partitions. one alternative is to find the nextbatchexpirytimems in the expirebatches.,0,0.9888980984687805
159594768,3849,becketqin,2018-01-04T07:50:21Z,it seems intuitively this should be the earliest batch in the entire record accumulator?,0,0.9880814552307129
159600209,3849,becketqin,2018-01-04T08:36:38Z,"it seems we may release the memory for the expired batches before the response is returned. this means the underneath bytebuffer is still referred by the producerbatch instance in the inflightrequests. i am not sure if this would cause any problem, but it seems a little dangerous.",0,0.6990928649902344
159602229,3849,becketqin,2018-01-04T08:50:18Z,is the response preparation needed in this case?,0,0.9938415288925171
67447081,1336,junrao,2016-06-17T00:34:31Z,"reporting both owner and member-id can be a bit confusing. also, for zk based consumer, we get the following output. the member-id part is repeated in the owner part. perhaps instead, we can report 3 fields: member-id, client-id, and client-ip. for kafka-based consumer, we can fill in all 3 fields. for zk-based consumer, we can just fill in member-id. we can leave the client-id and client-ip part empty since that are not stored explicitly. [code block]",0,0.9575178623199463
67447089,1336,junrao,2016-06-17T00:34:33Z,could all those scala.collection.mutable.map be just mutable.map?,0,0.9833890795707703
67447119,1336,junrao,2016-06-17T00:34:51Z,could we rename this to describemembertopicpartitions() to make it clear?,0,0.9946101903915405
67447129,1336,junrao,2016-06-17T00:35:00Z,"in this case, since the member has no associated partitions, do we need to pass in topic at all? could we just pass in none?",0,0.9916664958000183
67566895,1336,vahidhashemian,2016-06-17T19:59:57Z,sure. will do in the next update.,0,0.9825937151908875
67566945,1336,vahidhashemian,2016-06-17T20:00:20Z,"yes, none should work too. will update the pr.",0,0.9926572442054749
67567026,1336,vahidhashemian,2016-06-17T20:00:57Z,i'll make this change too in the next update.,0,0.9937718510627747
67567292,1336,vahidhashemian,2016-06-17T20:03:09Z,"that's fair. i'll update the code to return the output in the format you suggested. i'm thinking of always returning an empty string for client id and ip for zk-based consumer (as you suggested), and returning ""none"" for member id when no active consumer exists for the group.",0,0.9742531776428223
67725952,1336,junrao,2016-06-20T17:00:35Z,"it doesn't seem that topic is being used. also, could we fix the indentation?",0,0.9870136380195618
67725986,1336,junrao,2016-06-20T17:00:48Z,"could we change getowner and getownerhost to getclientid and getmemberhost accordingly? also, i am not sure why we getmemberid, getowner and getownerhost need to be a function. could we just pass in an option and get rid of ""get""?",0,0.9878050088882446
67726057,1336,junrao,2016-06-20T17:01:15Z,could we change owner to client-id? could owner-host be member-host since not every member owns a partition?,0,0.9929772019386292
67726065,1336,junrao,2016-06-20T17:01:19Z,"could we change owneropt and ownerhostopt to clientidopt and memberhostopt, respectively?",0,0.9940595626831055
67726085,1336,junrao,2016-06-20T17:01:27Z,"if topicpartition doesn't exist, should we really pass in offsetopt? it seems it's more intuitive to pass in none.",0,0.981981098651886
67726141,1336,junrao,2016-06-20T17:01:51Z,"not sure why we need to use ephemeral owner here. it seems that topicpartition->owner gives us the mapping from topic partition to group member id directly. consumergroupdir + ""/ids gives us all members. from these two, we know members that don't own any partitions.",0,0.9646244049072266
67726172,1336,junrao,2016-06-20T17:02:03Z,"this is the case for members not owning any topic partitions, right? if so, could we just set topicpartitions and partitionoffsets to empty?",0,0.9939311742782593
67750840,1336,hachikuji,2016-06-20T19:27:44Z,it seems weird to let this function accept `none` for either of these fields (why would i ever try to get the leo if i don't have a topic or a partition?). maybe the function can accept an instance of `topicandpartition` and the caller can make sure they have an instance prior to calling?,-1,0.9708998799324036
67753873,1336,hachikuji,2016-06-20T19:47:38Z,basically the same comment as above: it's weird to have a function `describepartition` where the partition is optional. could we take the logic for handling that case out of this function?,-1,0.9454687237739563
67763714,1336,hachikuji,2016-06-20T20:50:42Z,minor: would it be helpful to echo the group back to the user in quotes (so that formatting errors are apparent)?,0,0.9863372445106506
67780260,1336,vahidhashemian,2016-06-20T22:42:58Z,you're right. i'll remove the `topic` parameter and fix indentation.,0,0.9758327603340149
67780312,1336,vahidhashemian,2016-06-20T22:43:19Z,"sure, i'll update in the next patch.",0,0.9902042150497437
67780332,1336,vahidhashemian,2016-06-20T22:43:27Z,sure.,0,0.9824982285499573
67780472,1336,vahidhashemian,2016-06-20T22:44:31Z,"yup, and i'm going to switch the last two parameters so member related parameters are next to each other. i hope that's fine.",1,0.6565128564834595
67780508,1336,vahidhashemian,2016-06-20T22:44:48Z,"right, will change to `none`.",0,0.9891999959945679
67781246,1336,vahidhashemian,2016-06-20T22:51:20Z,"i think i had tried that combination before to extract the info. the issue is when i try `get /consumers/group1/owners/test/0` the output looks like this: `cgroup1_kafka-1466461259713-759adaaa-0`. however, when i try `ls /consumers/group1/ids` the output is like `[cgroup1_kafka-1466462141465-ff19e1a5, cgroup1_kafka-1466461259713-759adaaa]`. it seems the first call returns a client id, and the second one a list of member ids, and that's why the outputs do not quite match (`cgroup1_kafka-1466461259713-759adaaa-0 != cgroup1_kafka-1466461259713-759adaaa`). that's why i did not use this approach as i wasn't sure if there is anything further i can assume to connect the two outputs. if there is, please let me know.",0,0.983029305934906
67784301,1336,vahidhashemian,2016-06-20T23:18:06Z,that's correct and makes sense. will do.,0,0.7072473168373108
67787649,1336,vahidhashemian,2016-06-20T23:52:01Z,i understand the concern. will make some changes to fix the issue.,0,0.93067467212677
67787692,1336,vahidhashemian,2016-06-20T23:52:27Z,i'll try to fix this as suggested.,0,0.9886656999588013
67788112,1336,vahidhashemian,2016-06-20T23:56:46Z,that's a good suggestion. will update this one and the one a few lines below to return the group name as part of the output message.,1,0.9652714729309082
71457060,1336,hachikuji,2016-07-20T02:28:50Z,minor: maybe we could just debug log the stack trace?,0,0.9868610501289368
71457421,1336,hachikuji,2016-07-20T02:34:23Z,nit: maybe something like `partitionassignmentstate` would be more accurate?,0,0.9859880805015564
71457470,1336,hachikuji,2016-07-20T02:35:35Z,"another small nit: the ""opt"" suffix is kind of annoying. could we drop it?",-1,0.9465351104736328
71457574,1336,hachikuji,2016-07-20T02:37:37Z,maybe we could change this to something like this: [code block] that might make testing easier.,0,0.9798465967178345
71458065,1336,hachikuji,2016-07-20T02:45:11Z,or maybe we keep the current name and just change the argument type since this is `outputwriter`.,0,0.9919319748878479
71458303,1336,hachikuji,2016-07-20T02:49:45Z,i'm wondering if we can collapse these bottom 3 methods into a single `printassignment(assignment: array[consumergroupassignment])`. doesn't seem like we're saving that much with the abstract for loop.,0,0.873521625995636
71458830,1336,hachikuji,2016-07-20T02:58:36Z,nit: the name `describegroup` no longer seems quite right. maybe `assignmentstate` would be more accurate since that's what the method returns.,0,0.8744770884513855
71459346,1336,hachikuji,2016-07-20T03:07:25Z,maybe `describegroup` could be `collectgroupassignment` and this method could be `collectmemberassignment`?,0,0.9903924465179443
71459524,1336,hachikuji,2016-07-20T03:10:07Z,suggestion: `getalltopicpartitions`?,0,0.9952427744865417
71459607,1336,hachikuji,2016-07-20T03:11:43Z,is this used anywhere?,0,0.9940593242645264
71459749,1336,hachikuji,2016-07-20T03:14:11Z,"actually i see that we print some context-specific error messages, so maybe we need to allow the message to come through. but perhaps we could pass the exception in an optional argument so that we can have a common place to log the stacktrace.",0,0.992374837398529
71580318,1336,vahidhashemian,2016-07-20T18:28:28Z,i believe this is being handled in [a link]. if it's okay i would let it come through that pr. one of the two prs would have to be rebased depending on which one goes in first.,0,0.9895037412643433
71581180,1336,vahidhashemian,2016-07-20T18:32:45Z,both sound good. will update in the next commit.,1,0.8876013159751892
71592461,1336,vahidhashemian,2016-07-20T19:38:48Z,"sure, i'll make necessary changes for this.",0,0.9883584380149841
71592754,1336,vahidhashemian,2016-07-20T19:40:44Z,"that's fair. would it make sense to use `assignments`/`assignments` to imply all assignments, and `assignment`/`assignment` to imply a single assignment row?",0,0.9878621101379395
71593221,1336,vahidhashemian,2016-07-20T19:43:45Z,sure. i was wondering if we should use a `get` prefix (e.g. `getgroupassignment`) to indicate there is some return value. but i don't see that respected as a convention everywhere in the code.,0,0.9792386889457703
71593255,1336,vahidhashemian,2016-07-20T19:43:57Z,sounds good.,1,0.857205867767334
71593302,1336,vahidhashemian,2016-07-20T19:44:19Z,no. thanks for catching this. will be removed.,1,0.9716693162918091
71604687,1336,hachikuji,2016-07-20T20:54:15Z,not sure i understand the question. i was thinking that a single `printassignment` method could accept the complete assignment for the full group. then printing assignment rows or whatever is just an implementation detail. does that make sense or not?,0,0.6676845550537109
71606434,1336,vahidhashemian,2016-07-20T21:04:26Z,"i agree with merging those three methods. i was just curious about naming convention for the method and the variables used to implement them. maybe [a link] helps, where i use `assignments` as the full list of assignments, and then each individual member is an `assignment`. i thought i could use this convention across the board. this is very minor and not a big deal though if it's confusing.",0,0.8408675193786621
71608339,1336,hachikuji,2016-07-20T21:16:23Z,"ah i see. maybe we could use `groupassignment` and `memberassignment`? as long as it's clear in its context, either way seems ok to me.",0,0.9699049592018127
71609719,1336,vahidhashemian,2016-07-20T21:25:15Z,"yeah, that works too, and would probably be more descriptive. thanks.",1,0.9723758697509766
72295665,1336,hachikuji,2016-07-26T17:19:46Z,"minor: if we use debug(), do we need to extract the stack trace? maybe you could do something like this: [code block]",0,0.9904882907867432
72296396,1336,hachikuji,2016-07-26T17:23:50Z,"it's a little weird to have describe() return the partition state. in the test case below using the mock of `outputwriter`, could you replace the assertions on the result of describe() with `easymock.expect()` assertions?",-1,0.9558078050613403
72317288,1336,hachikuji,2016-07-26T19:14:02Z,seems like the only thing this method is contributing is the computation of lag. maybe we could replace it with a method like this: [code block] what do you think?,0,0.9847534894943237
72317749,1336,hachikuji,2016-07-26T19:16:39Z,"based on the usage below, would `printmessage` be a more accurate name?",0,0.9908979535102844
72318145,1336,hachikuji,2016-07-26T19:19:00Z,would it make sense to default `excludeinternaltopics` to true?,0,0.9896482825279236
72321388,1336,vahidhashemian,2016-07-26T19:37:48Z,"this is what i originally wanted to do, but struggled with how to verify the actual result (what would be printed as a result of `describe()` call) against how i call `easymock.expect(...)`, which is something like `easymock.expect(outputwritermock.printerror(""the consumer group 'missing.group' does not exist""))` for the first unit test (`testdescribenonexistinggroup`). how do i make sure that a call to `consumergroupcommand.describe()` would actually make the call identified in `easymock.expect`?",0,0.9130393862724304
72321525,1336,vahidhashemian,2016-07-26T19:38:35Z,"sure, i'll make this change.",0,0.9847899079322815
72324174,1336,vahidhashemian,2016-07-26T19:53:35Z,"yup, that makes sense.",0,0.9535172581672668
72324734,1336,vahidhashemian,2016-07-26T19:56:57Z,"yes, it would be more appropriate. i'll change it. thanks.",1,0.9682585000991821
72325636,1336,vahidhashemian,2016-07-26T20:02:19Z,i guess it would. there is an existing method before this one (`getconsumerspertopic`) that also takes `excludeinternaltopics` and assumes no default value for it. i wanted to make the new method consistent with that one.,0,0.9910818338394165
72375727,1336,hachikuji,2016-07-27T03:29:00Z,"that's kind of unfortunate. so here's another idea (feel free to dismiss it if it doesn't make sense). maybe having `describe()` return the assignment is actually heading in the right direction. what if we get rid of `outputwriter` and move the printing logic into the main method. then the `consumergroupservice` becomes more functional (and testable). for `list()`, you can have it return the list of groups instead of printing them. the trickier one seems to be `delete()`. maybe you can leave it as it is.",-1,0.9501969814300537
72523263,1336,vahidhashemian,2016-07-27T21:03:42Z,"sure, i'll try that. having `describe()` return the assignment would make testing much easier.",0,0.9857457876205444
72666749,1336,hachikuji,2016-07-28T17:38:28Z,this is looking promising. maybe we could rename `list` to `listgroups` and `describe` to `describeassignment`?,0,0.7374109625816345
72688365,1336,vahidhashemian,2016-07-28T19:40:09Z,sounds good. wouldn't `describegroup` (singular) be more self-explanatory than `describeassignment`?,1,0.7827827334403992
72688649,1336,hachikuji,2016-07-28T19:41:51Z,"yeah, that sounds good to me.",1,0.5480513572692871
72688751,1336,vahidhashemian,2016-07-28T19:42:32Z,and we could also rename `delete` to `deletegroups`?,0,0.9952592253684998
72691457,1336,hachikuji,2016-07-28T19:58:55Z,makes sense to me.,0,0.9770739674568176
72722638,1336,vahidhashemian,2016-07-28T23:43:33Z,i was wondering what your opinion is about the response above to your comment. this pr has gone through a few more rounds of reviews thanks to and this currently is the only outstanding item. thanks in advance for looking into this.,1,0.9887191653251648
72728458,1336,hachikuji,2016-07-29T00:53:38Z,looks like we would print this twice: once here and once in main. i'm wondering if we could remove `consumergroupoutputwriter` from this class and do all the output in main. maybe we just need to move the empty check that you have below in main?,0,0.98296058177948
72839362,1336,vahidhashemian,2016-07-29T18:28:54Z,"thanks for catching this. i'll fix in the next update. and we can remove `consumergroupoutputwriter` from that class, as you suggested.",1,0.9742591381072998
83920039,1336,hachikuji,2016-10-18T18:28:43Z,"is this needed for a consumer group? i think protocol type will always be ""consumer.""",0,0.9916632175445557
83920161,1336,hachikuji,2016-10-18T18:29:15Z,"for consumer groups, the protocol is really the assignment strategy.",0,0.9886387586593628
83921286,1336,hachikuji,2016-10-18T18:34:09Z,"as far as i can tell, the return type of this method doesn't need to be mutable. maybe something like this would be a little nicer? [code block] (note i used `keys` instead of `keyset` since we throw away the set anyway.)",0,0.989849328994751
83922730,1336,hachikuji,2016-10-18T18:41:08Z,would it make a big difference if this method accepted `topicpartition` instead of `topicandpartition` since it seems that's what we need anyway?,0,0.9806163311004639
83923001,1336,hachikuji,2016-10-18T18:42:34Z,is this intentional? same for the couple doc changes below.,0,0.9834324717521667
83924024,1336,hachikuji,2016-10-18T18:47:48Z,"since we didn't end up needing this for testing, maybe we can just get rid of it and keep its methods one level up?",0,0.9855679273605347
83924432,1336,hachikuji,2016-10-18T18:49:47Z,"nit: since you're using `map`, we don't need this check.",0,0.9913164377212524
83924865,1336,hachikuji,2016-10-18T18:51:46Z,could we let this function handle the empty assignment case as well?,0,0.9928197264671326
83925389,1336,hachikuji,2016-10-18T18:54:23Z,"i'm not actually sure this message is still correct. in kafka-2720, we introduced an `empty` state for the group, which basically persists until all the offsets for the group have expired. in this case, the assignment will be empty, but it will not be rebalancing.",0,0.8751797080039978
83925578,1336,hachikuji,2016-10-18T18:55:21Z,should this be `private`?,0,0.9918557405471802
83926233,1336,hachikuji,2016-10-18T18:58:31Z,similar to other comment: maybe we could use `topicpartition` here.,0,0.9912734627723694
83926524,1336,hachikuji,2016-10-18T18:59:55Z,why not use `map`?,0,0.9871100187301636
83932002,1336,hachikuji,2016-10-18T19:28:41Z,seems like this is another case where we don't actually need a mutable collection if we use `flatmap`.,0,0.9846432209014893
83933934,1336,hachikuji,2016-10-18T19:39:34Z,"it seems the node of the partition owner includes the threadid. the pattern is always ""{consumerid}-{threadid}"", so checking the prefix of the partition owner would always get us the right id. maybe it's a little nicer to use that than the ephemeral owner?",0,0.9846361875534058
83934306,1336,hachikuji,2016-10-18T19:41:21Z,"maybe change this to `map`, then i think `flatmap` as suggested above would work nicely.",0,0.987592875957489
83934935,1336,hachikuji,2016-10-18T19:44:51Z,this looks odd. we create an option just so we can call `map`? could we replace this with: [code block] same for the loop below.,-1,0.5941291451454163
83935126,1336,hachikuji,2016-10-18T19:45:44Z,using `map` would be nicer?,0,0.9901071786880493
83948295,1336,vahidhashemian,2016-10-18T20:52:35Z,"yes, it'll be `consumer`, but there is a check [a link] to verify that the protocol type os valid. if we remove this, i think that check has to be removed too. should i still go ahead and remove it?",0,0.9915708303451538
83948616,1336,vahidhashemian,2016-10-18T20:54:22Z,"sure, i'll rename this field to `assignmentstrategy`.",0,0.9915323853492737
83952330,1336,vahidhashemian,2016-10-18T21:14:02Z,makes sense. thank you for the suggestion. i'll update the method.,1,0.9842840433120728
83955679,1336,vahidhashemian,2016-10-18T21:33:13Z,you're right. would it be ok to change this message to `consumer group ... has no active member or is rebalancing`?,0,0.9858890175819397
83957107,1336,hachikuji,2016-10-18T21:42:04Z,"i would probably move that check into `describegroup`. now that i'm thinking about it, we should probably either rename `describegroup` to `describeconsumergroup`, or we should let `describegroup` return a generic `groupsummary` while `describeconsumergroup` returns `consumergroupsummary`.",0,0.9911620616912842
83957355,1336,hachikuji,2016-10-18T21:43:17Z,it would be more ideal if we could tell the user which is the case. maybe we need to propagate the state of the group down to this method.,0,0.9870994687080383
83960147,1336,vahidhashemian,2016-10-18T22:00:51Z,"thanks. with the first suggestion, there already is a `describeconsumergroup` method. unless you prefer this suggestion (using a different method name) i'll go ahead with your second suggestion.",1,0.9201607704162598
83963057,1336,vahidhashemian,2016-10-18T22:20:09Z,"upon further consideration, i think i'm going to adopt your first suggestion, because i need the current `describegroup` method to return the coordinator as part of its output; so i can report the coordinator's broker id. i'm going to use the method name `getconsumergroupsummary` instead.",0,0.9882904291152954
83973106,1336,vahidhashemian,2016-10-18T23:35:51Z,"yup, will try to do this in the next patch.",0,0.9890467524528503
83973553,1336,vahidhashemian,2016-10-18T23:39:43Z,"this `case class` is used in other classes in the same file. since it's defined outside the scope of those classes `private` wouldn't work, but `protected` would. i hope i didn't misunderstood your point.",0,0.9591211676597595
83974748,1336,vahidhashemian,2016-10-18T23:49:50Z,"sure, sounds good.",0,0.8011474013328552
83974783,1336,vahidhashemian,2016-10-18T23:50:11Z,thanks for catching this.,1,0.582872211933136
83975322,1336,vahidhashemian,2016-10-18T23:55:12Z,"we could, but we would need to pass more arguments now that we want to distinguish between empty group and rebalancing group. plus, in the case of an empty assignment we are using the `printerror` method, instead of actually printing assignments. do you still think we should change it?",0,0.9874442219734192
84141950,1336,vahidhashemian,2016-10-19T18:55:49Z,i'll try to make use of `flatmap`.,0,0.991510808467865
84143779,1336,vahidhashemian,2016-10-19T19:05:03Z,sure i'll try to use that (by ignoring the threadid part) instead of ephemeral owner.,0,0.987375020980835
84150277,1336,vahidhashemian,2016-10-19T19:39:35Z,this section will be removed now that we decided to use the owner info directly.,0,0.9946488738059998
84157718,1336,vahidhashemian,2016-10-19T20:17:48Z,i'll give it a try in the next patch.,0,0.9715757369995117
84164530,1336,vahidhashemian,2016-10-19T20:53:37Z,"to be honest, it's been so long that i don't recall why i made these changes. but when i try the current command, i can't tell what the meaning of ""new consumer being the default"" is. it seems to me that we need to either provide `--zookeeper` or `--bootstrap-server`; it's not like if we use `--new-consumer` we don't have to provide `--bootstrap-server`. the only restriction around `--new-consumer` seems to be that it cannot be used along with `--zookeeper`. the descriptions in parenthesis are not very clear to me. but it might be just me. your thoughts?",0,0.8883258700370789
84167217,1336,hachikuji,2016-10-19T21:07:13Z,"i agree it's not super clear. maybe we should just avoid saying it's required since it saves us from needing to qualify? you can try to fix this if you want, but i'd be ok just leaving it as it is since it seems orthogonal to the rest of this.",0,0.9345448017120361
84173733,1336,vahidhashemian,2016-10-19T21:42:52Z,"sure, i'll revert these changes. i'm ok with leaving the ""required"" text in since other tools have it too, but we need to better qualify them, as you mentioned. i may work on it separately later.",0,0.9429562091827393
84191293,1336,hachikuji,2016-10-19T23:53:22Z,"if we had `consumergroupsummary` include a list of `consumersummary` objects instead of `membersummary`, would we still need this function?",0,0.9900126457214355
84192091,1336,hachikuji,2016-10-20T00:00:45Z,seems like this method isn't giving us much anymore. maybe it's ok to use `println` directly?,0,0.9818409085273743
84192990,1336,hachikuji,2016-10-20T00:10:00Z,it's a little weird to locate this in `kafka.coordinator` since the coordinator is technically agnostic to group internals. the best alternative i can think of is maybe to put it in tools with `adminclient`. what do you think?,-1,0.9411203861236572
84193326,1336,hachikuji,2016-10-20T00:13:17Z,"nitpick: since it's a simple statement, maybe parenthesis in `map` would be a little nicer than braces?",0,0.9757456183433533
84193423,1336,hachikuji,2016-10-20T00:14:14Z,nitpick: we usually don't put a space before the ':'.,0,0.9893575310707092
84193800,1336,hachikuji,2016-10-20T00:18:18Z,nitpick: i think parenthesis are a little nicer for simple one-liners like this.,0,0.8999908566474915
84194583,1336,hachikuji,2016-10-20T00:26:11Z,there are few other places in the patch where we could also change this.,0,0.9920347332954407
84194947,1336,vahidhashemian,2016-10-20T00:30:38Z,i'm not sure if i follow. could you please elaborate a bit?,0,0.7082340717315674
84195024,1336,hachikuji,2016-10-20T00:31:31Z,"since the zookeeper service has no notion of consumer state, should we return `option[string]` instead?",0,0.9921703934669495
84195092,1336,vahidhashemian,2016-10-20T00:32:12Z,"sure, it makes sense. i'll move it.",0,0.8676729202270508
84195261,1336,vahidhashemian,2016-10-20T00:34:17Z,i'll remove the space. there are a few other occurrences in this file that i'll fix too.,0,0.9937325119972229
84195305,1336,hachikuji,2016-10-20T00:34:51Z,"currently `consumergroupsummary` has a field for the group members, which are represented as instances of `membersummary`. i'm wondering if it would make sense to use `consumersummary` instead. then we might only need a single method returning `consumergroupsummary`.",0,0.981661319732666
84195485,1336,hachikuji,2016-10-20T00:36:58Z,"if we use normal `map` instead of `flatmap`, does this need to be a `seq` anymore?",0,0.9924997687339783
84195843,1336,hachikuji,2016-10-20T00:41:19Z,could this one be a `flatmap` like the one just above?,0,0.9856862425804138
84195844,1336,vahidhashemian,2016-10-20T00:41:20Z,"no, it doesn't. thanks for catching it.",1,0.9833011627197266
84196169,1336,hachikuji,2016-10-20T00:44:54Z,looks like we're missing the 's' at the start of the string. another few of these below.,0,0.9858566522598267
84196393,1336,hachikuji,2016-10-20T00:47:07Z,nitpick: i think the braces are unnecessary if it is a simple variable.,0,0.9701823592185974
84196615,1336,vahidhashemian,2016-10-20T00:49:59Z,"thanks, i noticed there were a few more.",1,0.8571489453315735
84196895,1336,hachikuji,2016-10-20T00:53:01Z,looks like another case where we might be able to change the `foreach` to a `map` with a `toarray` at the end.,0,0.9882056713104248
84197069,1336,hachikuji,2016-10-20T00:55:32Z,nitpick: maybe we could destructure on assignment? [code block],0,0.9920187592506409
84197288,1336,vahidhashemian,2016-10-20T00:58:28Z,"do you mean merging `getconsumergroupsummary` and `describeconsumergroup` into one method that returns a `consumergroupsummary` object? if so, i thought about it when i was making the recent changes, and noticed that `getconsumergroupsummary` is being used in a few other places. that's why i hesitated to make the unnecessary change. but i guess they could be merged and all calls to `getconsumergroupsummary` would become calls to `describeconsumergroup`. please correct me if i'm misunderstood. thanks.",0,0.9075992703437805
84197311,1336,hachikuji,2016-10-20T00:58:45Z,"nitpick: should 'member' be plural? also, a little surprising we don't have a variable for the groupid. maybe we could add one above to make these messages a little easier to read.",0,0.8295038938522339
84197388,1336,hachikuji,2016-10-20T00:59:50Z,"yeah, that's what i meant. don't bother if it's a ton of additional work, but seems like a nice cleanup.",1,0.8709076642990112
84198268,1336,vahidhashemian,2016-10-20T01:08:24Z,good suggestion.,1,0.9697386622428894
84198564,1336,vahidhashemian,2016-10-20T01:12:50Z,"no problem, i'll give it try in the next patch.",0,0.8295780420303345
84349940,1336,hachikuji,2016-10-20T18:42:27Z,"nit: shouldn't need parenthesis for most of these getters, i think. there are a bunch of these around the patch.",0,0.9841316342353821
84350479,1336,hachikuji,2016-10-20T18:45:11Z,nit: might be nice to add a `require` to validate that the group assignment is not empty.,0,0.9876070618629456
84352489,1336,hachikuji,2016-10-20T18:55:19Z,this check needs to be updated since `state` is now an `optional`.,0,0.9958308339118958
84352847,1336,hachikuji,2016-10-20T18:57:03Z,this should probably be `foreach` since we don't need any the return type.,0,0.9925450682640076
84363117,1336,hachikuji,2016-10-20T19:55:17Z,nit: no need for `new`.,0,0.9896309971809387
84363280,1336,hachikuji,2016-10-20T19:56:14Z,nit: maybe this could be [code block],0,0.9632012248039246
84363729,1336,hachikuji,2016-10-20T19:58:46Z,nit: maybe this could be a `foreach`?,0,0.982439398765564
84364647,1336,hachikuji,2016-10-20T20:04:04Z,nit: no need for `new`,0,0.9926784038543701
84364950,1336,hachikuji,2016-10-20T20:06:07Z,nit: unneeded `tolist`.,0,0.9933944344520569
84365278,1336,hachikuji,2016-10-20T20:08:04Z,nit: unneeded import,0,0.9908455014228821
84365476,1336,hachikuji,2016-10-20T20:09:08Z,could this be `consumers`. the `summaries` suffix seems a tad verbose.,0,0.9428271055221558
84366002,1336,hachikuji,2016-10-20T20:12:08Z,"nit: since we've converted most of these to use string interpolation, maybe we could do the same here? i noticed a couple others.",0,0.9826571345329285
84369348,1336,vahidhashemian,2016-10-20T20:30:13Z,"sure, sounds fair.",0,0.9804586172103882
84369482,1336,vahidhashemian,2016-10-20T20:30:56Z,i'll try to remove them. i see that their occurrences are beyond what's in this patch.,0,0.991392970085144
84379640,1336,vahidhashemian,2016-10-20T21:28:38Z,you're right. thanks. i'll fix this in the next patch.,1,0.9911383986473083
84388805,1336,vahidhashemian,2016-10-20T22:28:24Z,not sure if i follow this one?,0,0.5695458650588989
84390074,1336,vahidhashemian,2016-10-20T22:38:02Z,never mind. i think you mean something like [code block],0,0.9535607099533081
84391557,1336,hachikuji,2016-10-20T22:49:38Z,"yeah, something like that. kind of hard to tell sometimes when you're trying to get a little too cute, but using `map` and `foreach` seems to generally be preferred over an explicit check for `isdefined` or `isempty`.",0,0.9340597987174988
84391755,1336,hachikuji,2016-10-20T22:51:12Z,"the general rule is to omit the parenthesis if the function does not mutate any state. no need to catch all such cases, it just stood out a bit on this line.",0,0.991538941860199
84513550,1336,hachikuji,2016-10-21T16:45:27Z,"i may have missed it, but how do we know this `get` is safe? should we match using the option instead?",0,0.9858002662658691
84520691,1336,vahidhashemian,2016-10-21T17:53:51Z,"i believe for the zookeeper-based consumers the `describegroup` returns either `none` for `assignments` or some array (and the array cannot be empty because as soon as a group starts there is an assignment row). therefore, this line would not be reached in that case. and for java based consumer groups as far as i can tell `state` always has some value, and it cannot be `none`. so this line would be safe to call. having said that i'm ok with checking `state` here instead of `state.get`. one more question. i tried creating a new topic and starting an old consumer consuming from that topic belonging to a new consumer group. when i tried `describe` with this patch i get this output for a few seconds, and then the error vanishes as the initializations are done. are we ok with this behavior? [code block]",0,0.9638765454292297
84525026,1336,vahidhashemian,2016-10-21T18:36:18Z,this is the refactored code for `state` check. please let me know if you see issues with it. thanks.,1,0.956913411617279
84536951,1336,hachikuji,2016-10-21T20:15:14Z,nit: you can use `nonempty`.,0,0.9946687817573547
84536970,1336,hachikuji,2016-10-21T20:15:23Z,"couple naming suggestions: 1. `member-id` -> `consumer-id` 2. `member-host` -> `host` what do you think? also, it seems neither of these options are available for the old consumer. maybe it would reduce the noise if we leave them out of the output in that case? not sure if there's a clean way to do that though.",0,0.9812589287757874
84539540,1336,vahidhashemian,2016-10-21T20:33:45Z,"i can make the name changes. regarding availability for old consumer, it's actually `member_host` and `client_id` (the last two) that will be blank in the output. i think i can leverage the `node` variable (that i introduced to report the coordinator broker id for new consumer option) and based on that decide whether the last two column should be printed or no. i'll submit an update shortly and you can take a look and let me know what you think. thanks.",1,0.95771723985672
84542689,1336,vahidhashemian,2016-10-21T20:54:10Z,i don't feel very happy about this repeating check. to me it was either this or totally separate print statements for old and new consumers in the `match` block of line 114 above. what do you think?,-1,0.9841691255569458
84543875,1336,hachikuji,2016-10-21T21:00:56Z,it might be a little less annoying if you put the result in a val (e.g. `usenewconsumer`). maybe you could even pass `opts.useoldconsumer` into this function to avoid the need to check the coordinator.,0,0.9614324569702148
84544537,1336,vahidhashemian,2016-10-21T21:05:24Z,"btw, i'm thinking printing ""-"" instead of """" when data is not available or does not apply would look better and more readable (especially when there are multiple rows with blank columns). compare [code block] with [code block]",0,0.9776719212532043
84545114,1336,hachikuji,2016-10-21T21:09:20Z,good idea.,1,0.9783411622047424
84545242,1336,vahidhashemian,2016-10-21T21:10:22Z,passing `opts.useoldconsumer` sounds good; but that doesn't avoid the need for this repeating `if` block. or i misunderstood?,0,0.9881786704063416
84545937,1336,hachikuji,2016-10-21T21:15:37Z,"yeah, you still need it. seems not too bad to me. you could move it outside the loop, but then you'd need to repeat the loop in both arms of the `if`, which seems worse.",0,0.7795929312705994
84546160,1336,vahidhashemian,2016-10-21T21:17:00Z,"right, i'll keep it as is then. thanks.",1,0.96406090259552
84551578,1336,hachikuji,2016-10-21T21:58:36Z,"really sorry to keep adding comments... did we print this before? it seems unnecessary given that we require the group to be passed on the command line. one downside to having this line and the one below is that it's a little tougher to parse the output. on the other hand, having a way to get the coordinator seems useful for debugging. i wonder if it would make sense to add that to the `--list` option in a separate patch. what do you think?",-1,0.9926039576530457
84552130,1336,vahidhashemian,2016-10-21T22:03:39Z,that's fine with me. i added these two lines (along with [a link] and [a link] because there was a request on the corresponding jira asking for some clarification on the printed output. i'm fine with removing them and have the `--list` option report the coordinator broker id. should i also leave out the other two lines i linked to above?,0,0.8468111753463745
84553085,1336,hachikuji,2016-10-21T22:12:24Z,"looked back at the jira. maybe you could print the warning messages to stderr? i also saw jun's comment about printing the coordinator. it's a little odd to print it as a column in the table as you suggested (since it will be the same for all members), but that might be a better choice. i'd be ok with either doing that or adding it to the `--list` option separately. the latter might be a little nicer since this already has a lot of columns and i think we should have the coordinator information already when using `--list`.",0,0.8502278327941895
84553913,1336,vahidhashemian,2016-10-21T22:18:00Z,"i also think using `--list` to report the coordinator id is better for the same reasons you mentioned. i'll submit another update shortly, and open a jira for reporting the coordinator.",0,0.9491633772850037
108825282,2744,junrao,2017-03-30T01:39:13Z,"hmm, not sure if this is accurate to capture the network thread utilization. what we are recording is essentially the responsesendtime, which includes the time for waiting for the socket to be writable. that portion of the time actually doesn't tie up the network threads and shouldn't be accounted for in the request time. also, this seems to only cover the network thread time for sending responses, not for reading requests (which could be significant for produce requests). i was thinking that we may need to do the following. in selector.pollselectionkeys(), we will measure the time spent for reading/writing each kafkachannel and propagate the time back to the caller. then, we can account for both request/response time in network threads in socketserver.",0,0.8255340456962585
108825299,2744,junrao,2017-03-30T01:39:22Z,quotathreadpercentdefault => quotarequestpercentdefault ?,0,0.9907953143119812
108825310,2744,junrao,2017-03-30T01:39:26Z,it seems that toint is redundant.,0,0.8936129212379456
108825313,2744,junrao,2017-03-30T01:39:29Z,it seems that tolong is redundant.,0,0.854978084564209
108825331,2744,junrao,2017-03-30T01:39:39Z,do we need to make this protected? it doesn't seems to be customized in the subclass and it doesn't seem that we can change it to anything other than rate().,0,0.9942080974578857
108825337,2744,junrao,2017-03-30T01:39:42Z,unused import,0,0.9873000979423523
108825350,2744,junrao,2017-03-30T01:39:48Z,utilizationthrottletimems => requestthrottletimems?,0,0.9942565560340881
108825356,2744,junrao,2017-03-30T01:39:52Z,remove space after trace( ?,0,0.9947132468223572
108825402,2744,junrao,2017-03-30T01:40:17Z,"hmm, i am wondering if we really need to subtract bandwidththrottletimsms from the throttle time. while the response is delayed for bandwidththrottletimsms, some time has passed, which should bring down the value of the metric when we check the request quota. then, naturally, this request will be delayed less for request quota violation.",0,0.9606744050979614
108826148,2744,junrao,2017-03-30T01:49:43Z,we throttle leaderandisrrequest if it's unauthorized. should we do the same thing here?,0,0.9895907044410706
108916491,2744,rajinisivaram,2017-03-30T12:49:37Z,done.,0,0.9897913336753845
108916544,2744,rajinisivaram,2017-03-30T12:49:54Z,removed.,0,0.9612457156181335
108916572,2744,rajinisivaram,2017-03-30T12:50:00Z,removed.,0,0.9612457156181335
108916610,2744,rajinisivaram,2017-03-30T12:50:13Z,reverted.,0,0.9197385907173157
108916623,2744,rajinisivaram,2017-03-30T12:50:18Z,removed.,0,0.9612457156181335
108917372,2744,rajinisivaram,2017-03-30T12:53:19Z,in this case `authorizeclusteraction` method throws an exception and the response is sent from the exception handler in `handle`. all responses sent from the exception handler are throttled.,0,0.9930241107940674
108917401,2744,rajinisivaram,2017-03-30T12:53:29Z,done.,0,0.9897913336753845
108917419,2744,rajinisivaram,2017-03-30T12:53:34Z,done.,0,0.9897913336753845
108917772,2744,rajinisivaram,2017-03-30T12:55:10Z,"yes, i wasn't sure which way to go. either way, i think the throttle times will correct themselves over time. i have removed the subtraction.",0,0.980830192565918
108919055,2744,rajinisivaram,2017-03-30T13:00:59Z,"thank you, i have reworked the code for recording network thread time as you suggested. at the moment, ssl/sasl handshake time is included in the time for the first request. is that reasonable? i can clear the time after authentication if it is confusing.",1,0.8723809719085693
108923119,2744,rajinisivaram,2017-03-30T13:19:36Z,"sorry, had to revert that since `toint` was required for newer versions of scala.",-1,0.9907422661781311
109046976,2744,junrao,2017-03-30T21:53:07Z,"could we add a comment somewhere so that people know that if they want to add a non-internal request in the future, they would need to include the throttle time field?",0,0.9941601753234863
109047035,2744,junrao,2017-03-30T21:53:31Z,this takes care of the time spent on receiving requests. we will need to do the same thing to track the time on sending responses.,0,0.9932152032852173
109049180,2744,junrao,2017-03-30T22:05:52Z,"the approach in the patch works. but one issue is that the implementor of all future requests will have to deal with throttling the responses directly. another approach is to do the throttling early in handle(). if a request needs to be delayed, we first throttle it and then hand it over to the specific request handler. this way, we just need to implement the request throttling logic in one place and all future requests don't have to be aware of it. we probably need to mark whether a request is at the cluster level so that we can throttle unauthorized internal requests too. also, not sure if there is an easier way for the request handler thread to pick up the requests after throttling is done. if there is, this may be a simpler approach?",0,0.9641313552856445
109049691,2744,junrao,2017-03-30T22:08:59Z,that seems fine for now. perhaps we could add a comment in case we need to revisit in the future?,0,0.9275291562080383
109146033,2744,rajinisivaram,2017-03-31T12:09:54Z,i have added unit test in `apikeystest` that checks that all responses except those explicitly excluded contain a field named `throttle_time_ms`. there is a comment in the test as well to ensure that new requests either contain the field or are manually added to the test's exclusion list.,0,0.9939145445823669
109146742,2744,rajinisivaram,2017-03-31T12:15:02Z,"the time is accumulated in `selector` and includes the full time spent for each channel in `pollselectionkeys`. for each request, the accumulated time is used and the value is reset. this time includes the time for write of the previous response and the time for read of the current request. i have added a comment in the code.",0,0.9934681057929993
109149032,2744,rajinisivaram,2017-03-31T12:30:54Z,"thank you for the review. it will be nice to handle throttling in a single place. however, handling of all new requests need to be aware of throttling, so that they add the throttling time to the response. the bigger issue is the exclusions. we need to authorize in a central place for `clusteraction`. and worse, we need to handle `produce` differently since we don't want to throttle until after the request is processed and the memory can be released. we probably want to throttle later for `fetch` as well since we are relying on the bandwidth throttle time to reduce the request throttle time. we will need to record two more timestamps to take into account time spent before throttle in some cases and after throttle in others. and as you mentioned, we still want the request to be processed after throttling on the request handler thread. taking all that into account, i am not sure it is worthwhile to restructure the code to centralize the throttling logic. i have updated `requestquotatest` to ensure that unauthorized requests of all types are throttled. and also to check that all requests not explicitly excluded are throttled and return throttle time in response. this should catch any missing throttling in new requests. let me know if this is sufficient or whether i should try out the centralized approach.",1,0.9577777981758118
109149244,2744,rajinisivaram,2017-03-31T12:32:32Z,added comment in `socketserver`.,0,0.9955235719680786
109189436,2744,rajinisivaram,2017-03-31T15:42:41Z,"after writing the comment above, i realized that it sounds rather odd. so i have updated the code to record network thread time when request metrics are updated, so that receive+send are recorded together. this does also ensure that the last network time on each connection is recorded and it would work even if requests on a connection use different clientids. throttling is still performed only on subsequent requests.",0,0.6764150261878967
110187347,2744,ijuma,2017-04-06T15:08:36Z,why is this an `atomiclong` instead of a plain long?,0,0.9881033301353455
110188076,2744,ijuma,2017-04-06T15:11:24Z,"hmm, it seems a bit unfortunate that we need to do a `system.nanotime` per selection key. have we done any measurements on the overhead?",-1,0.8090311884880066
110188616,2744,ijuma,2017-04-06T15:13:33Z,i think we'd want to override `parseresponse` for `api_versions` only.,0,0.9853464365005493
110189171,2744,ijuma,2017-04-06T15:15:19Z,i wonder if there's a way to add this to `responseheader` in a compatible way. it seems a bit annoying to have to add that to every response.,-1,0.9809404015541077
110189630,2744,ijuma,2017-04-06T15:17:01Z,"since we use `ms`, should we not be using `ns` instead of `nanos`?",0,0.9914495348930359
110190164,2744,ijuma,2017-04-06T15:19:12Z,"nit: the logic inside this catch has become a bit complicated. can we perhaps extract methods? also, something i was thinking about recently is that methods like `geterrorresponse` could throw an exception due to bugs. it would be nice for us not to leak connections in such cases.",0,0.8501520752906799
110190689,2744,ijuma,2017-04-06T15:20:48Z,"if we could somehow add the throttle time in the response header, it would be easier to handle it in a generic way for the typical cases.",0,0.9893690347671509
110422348,2744,rajinisivaram,2017-04-07T15:52:11Z,"there are a few requests which don't have throttle time (controlledshutdown, stopreplica etc. used for inter-broker and not by producer/consumer). so it made sense to add throttle time to individual requests. error codes seem to be handled this way. but my main concern was compatibility. even if we looked at request version to determine the response header version, there is still the issue of `apiversionsresponse` which needs to be handled. according to kip-35, `apiversionresponse.errorcode is guaranteed to be the first int16 of the response for all future versions of apiversionrequest`. i didn't want to break that assumption.",0,0.9811781644821167
110422668,2744,rajinisivaram,2017-04-07T15:53:33Z,i couldn't see any way around it. i will kick off system test runs to see the impact.,0,0.9451317191123962
110422700,2744,rajinisivaram,2017-04-07T15:53:42Z,done.,0,0.9897913336753845
110423058,2744,rajinisivaram,2017-04-07T15:55:21Z,"both `ns` and `nanos` are already used in the code. i chose `nanos` everywhere in the pr since it stands out better from `ms`, especially since i was changing some measurements from millis to nanos. but i am ok with switching to `ns` if that is preferable.",0,0.9669651985168457
110423731,2744,rajinisivaram,2017-04-07T15:58:29Z,"have moved to a method. i think errors are propagated and logged. we won't close acks=0 connections if `geterrorresponse` threw an exception, but perhaps that is ok since that would still not be a leaked connection?",0,0.9926119446754456
110425748,2744,rajinisivaram,2017-04-07T16:08:22Z,because the value is updated on the network thread and read-and-reset on the request handler thread. i have added a comment.,0,0.9954232573509216
110442824,2744,junrao,2017-04-07T17:39:04Z,our system test currently doesn't do perf validation well. it would be useful to just run producerperformance and consumerperformance and see if there is any noticeable degradation.,0,0.9659541845321655
110478783,2744,rajinisivaram,2017-04-07T20:42:21Z,i ran `producerperformance` and `consumerperformance` on my laptop and didn't see any noticeable difference. this is the throughput in mb/s (average of three runs): test (message size) | trunk | with pr -------------------------|--------------|------------ producer (100 bytes) | 158.68 | 160.18 producer (1000 bytes) | 355.43 | 350.36 consumer (100 bytes) | 376.20 | 378.52 consumer (1000 bytes) | 559.45 | 559.45,0,0.9526986479759216
112594508,2744,junrao,2017-04-21T01:43:24Z,"perhaps we should only fall back to version 0 of the request if the error is unsupported_version? for other kinds of error, just disconnect?",0,0.9898159503936768
112594514,2744,junrao,2017-04-21T01:43:29Z,"instead of returning atomiclong, could we just reset to 0 and return a long?",0,0.9915505647659302
112594523,2744,junrao,2017-04-21T01:43:37Z,"hmm, not sure why we need this. it seems that the client should always use the requested version to parse the response of api_versions?",0,0.8966519832611084
112594538,2744,junrao,2017-04-21T01:43:44Z,"this makes things a bit more complicated. i was thinking of the following. in updaterequestmetrics(), we remember networkthreadtime as previousnetworkthreadtime. in kafkaapis, we can just add previousnetworkthreadtime to the throttler. that way we don't need this callback. will that be better?",0,0.952000081539154
112594555,2744,junrao,2017-04-21T01:43:54Z,it seems that we should update the instance level localcompletetimenanos instead of a local one?,0,0.9928668737411499
112594610,2744,junrao,2017-04-21T01:44:36Z,apikey in the comment needs to be changed accordingly.,0,0.9863104820251465
112594983,2744,junrao,2017-04-21T01:49:17Z,will subsequently used => will subsequently be used,0,0.9888685941696167
112726629,2744,rajinisivaram,2017-04-21T16:23:31Z,done.,0,0.9897913336753845
112726925,2744,rajinisivaram,2017-04-21T16:24:55Z,atomiclong is returned so that the the value can be updated from the i/o thread when a request is complete without propagating `kafkachannel` to the request handling code.,0,0.9932112097740173
112727184,2744,rajinisivaram,2017-04-21T16:26:18Z,"if client sends apiversionsrequest with a higher version that client supports, broker responds with a version 0 response that indicates unsupported version.",0,0.9924949407577515
112729035,2744,rajinisivaram,2017-04-21T16:36:20Z,"hmm... network thread time needs to be accumulated against the (user, client-id) and needs to include the time for the sending the response. the callback avoids having to propagate (user, client-id).",0,0.9788398742675781
112729071,2744,rajinisivaram,2017-04-21T16:36:30Z,done.,0,0.9897913336753845
112729097,2744,rajinisivaram,2017-04-21T16:36:38Z,done.,0,0.9897913336753845
112729130,2744,rajinisivaram,2017-04-21T16:36:46Z,done.,0,0.9897913336753845
112791899,2744,junrao,2017-04-21T23:13:34Z,could we consistently add newthrottletimefield() as the first field?,0,0.994236946105957
112791907,2744,junrao,2017-04-21T23:13:41Z,"offset_for_leader_epoch_response is an inter broker request. so, we shouldn't add a throttle field.",0,0.9928339719772339
112791941,2744,junrao,2017-04-21T23:14:08Z,"it might be useful to report all the time still as ms, but up to micro sec level accuracy now that we track with nanosec.",0,0.9893583059310913
112791964,2744,junrao,2017-04-21T23:14:21Z,"for request quota, since we are collecting request time in nanosecs already, it will be useful to create a rate with nanosec as the time unit. this will make the measurement more accurate.",0,0.9920170307159424
112791985,2744,junrao,2017-04-21T23:14:32Z,"hmm, in this case, we probably only want to throttle if the exception is related to authorization. for any other exceptions, we should send an error immediately?",0,0.9733994007110596
112791992,2744,junrao,2017-04-21T23:14:40Z,"hmm, this can be a bit tricky. fetch requests from the follower are considered internal and shouldn't be throttled.",0,0.7436795830726624
112792013,2744,junrao,2017-04-21T23:14:57Z,"hmm, when there is no data, the consumer will wait for the timeout. so, not sure if this is enough to trigger the throttling. we probably need to either set a low maxwait in consumer config and set the quota to be really low.",0,0.9101628661155701
112792018,2744,junrao,2017-04-21T23:15:02Z,"hmm, not sure where the test is.",0,0.7347162365913391
112792036,2744,junrao,2017-04-21T23:15:18Z,"why is the replicaid 5000? that indicates it's from a follower. also, i am wondering if 100 maxwait is enough to trigger throttling.",0,0.9765873551368713
112792083,2744,junrao,2017-04-21T23:15:48Z,"got it. an alternative is to call networkthreadtimenanos() in socketserver.processnewresponses() and processcompletedsends(). then we can just reset and return the value, which is easier to understand?",0,0.9676641821861267
112792089,2744,junrao,2017-04-21T23:15:53Z,thanks for the explanation. could we add that as comment in the code?,1,0.8861965537071228
112792094,2744,junrao,2017-04-21T23:15:56Z,got it. this is fine then.,1,0.6725760698318481
112908803,2744,rajinisivaram,2017-04-24T10:06:26Z,"according to kip-35, the java clients don't rely on this, but just in case some other clients do, i have left `error_code` as the first field for `apiversionsresponse`.",0,0.9944614171981812
112908831,2744,rajinisivaram,2017-04-24T10:06:36Z,fixed.,0,0.9905837774276733
112909448,2744,rajinisivaram,2017-04-24T10:09:51Z,the yammer metrics `histogram` class that tracks time only takes long and not double. hence the millisecond value is used.,0,0.9933571219444275
112910225,2744,rajinisivaram,2017-04-24T10:14:24Z,"for request quota, values are recorded as double, so even though they use millisecond as unit to be consistent, they have higher precision. isn't that sufficient?",0,0.9922481775283813
112910635,2744,rajinisivaram,2017-04-24T10:16:49Z,"yes, `authorizeclusteraction` takes care of throttling for unauthorized request and all other paths including error path goes through this `sendresponseexemptthrottle` which does not perform throttling.",0,0.9937325119972229
112910724,2744,rajinisivaram,2017-04-24T10:17:22Z,"oops, you are right. fixed.",-1,0.8522974252700806
112911096,2744,rajinisivaram,2017-04-24T10:19:27Z,consumers in this test are configured with `fetch.max.wait.ms=0`. the quota is set very small as well to trigger throttling.,0,0.9938993453979492
112911132,2744,rajinisivaram,2017-04-24T10:19:36Z,"oops, fixed.",-1,0.9114224314689636
112911223,2744,rajinisivaram,2017-04-24T10:20:09Z,copy-paste error. fixed and set maxwait to zero.,0,0.9620331525802612
112911309,2744,rajinisivaram,2017-04-24T10:20:38Z,done.,0,0.9897913336753845
112911522,2744,ijuma,2017-04-24T10:21:59Z,i think the atomiclong comment should be moved to the field.,0,0.9782578349113464
112912615,2744,ijuma,2017-04-24T10:28:34Z,is there a reason why we don't replace the 4 lines above with: [code block],0,0.9935712814331055
112917077,2744,rajinisivaram,2017-04-24T10:55:44Z,done.,0,0.9897913336753845
112917164,2744,rajinisivaram,2017-04-24T10:56:08Z,"thank you, done.",0,0.5747800469398499
112965720,2744,junrao,2017-04-24T14:46:06Z,"ok, could we add a comment that error_code has to be the first field in apiresponse?",0,0.9945200085639954
112965772,2744,junrao,2017-04-24T14:46:20Z,i was actually referring to line 169 where we log the time components in trace logging. it's useful to see more precise time there since sometimes the time may take less than 1ms.,0,0.9907863140106201
112965811,2744,junrao,2017-04-24T14:46:30Z,thanks. that should be enough then.,1,0.882696270942688
112969979,2744,junrao,2017-04-24T15:00:57Z,"here, we throttle independent of the exception type. perhaps, it's better to only engage in throttling if the exception is clusterauthorizationexception?",0,0.9923976063728333
113048200,2744,rajinisivaram,2017-04-24T20:30:53Z,fixed to throttle only for `clusterauthorizationexception` for broker-only requests.,0,0.9927863478660583
113595344,2744,junrao,2017-04-27T00:51:18Z,this is an inter-broker request as well and clusteraction should be true.,0,0.9942337870597839
113596378,2744,junrao,2017-04-27T01:02:52Z,"this is an inter-broker request. so, no throttling needed.",0,0.9944772124290466
113597310,2744,junrao,2017-04-27T01:13:52Z,perhaps it's better to pass the networkthread time to request.updatemetrics() and call the recordnetworkthreadtimecallback there?,0,0.9898853302001953
113597451,2744,junrao,2017-04-27T01:15:46Z,"hmm, we probably don't want to call recordnetworkthreadtimenanos here since it will be called in processcompletesends() again. instead, it seems that we want to call recordnetworkthreadtimenanos() in all places where we call request.updaterequestmetrics().",0,0.9824375510215759
113598851,2744,junrao,2017-04-27T01:31:19Z,it's actually read and reset by the broker's network thread.,0,0.9902978539466858
113599869,2744,junrao,2017-04-27T01:42:13Z,"for the trace logging in line 177, could we report all the time still as ms, but up to micro sec level accuracy?",0,0.9921472668647766
113600212,2744,junrao,2017-04-27T01:45:55Z,"given this, should we just remove line 65?",0,0.9896723031997681
113694991,2744,ijuma,2017-04-27T13:29:57Z,"sorry for the delay on this one. so, one way to do this would be the following: 1. add two fields to responseheader _if_ the request version is higher than the version before this pr: error_code, throttle_time_ms (in this order) 2. remove any top-level error_code in the new version of all affected responses 3. remove throttle_time_ms from fetchresponse and produceresponse in the new version 4. throttle_time_ms is always 0 for requests that are never throttled as part of this, we would also solve the issue that we currently have no way to return generic errors via the protocol. since we are bumping the protocol version for so many requests, it seems like it would be a good opportunity to fix both issues at the same time. is there a reason why this is a bad idea or would not work?",-1,0.98008793592453
113730628,2744,ijuma,2017-04-27T15:38:43Z,"discussed this with . the main challenge with this option is having the top level error field for every response. this would probably affect a lot of code: 1. we would need to handle this top level error code everywhere. 2. a bunch of protocols that currently have a top level error code would no longer have them, so a bunch of code would have to be updated as well. so, it doesn't seem appropriate to do this as part of this kip.",0,0.9585344195365906
113731419,2744,rajinisivaram,2017-04-27T15:42:10Z,thank you for looking into this.,1,0.7321790456771851
113735595,2744,junrao,2017-04-27T15:58:07Z,could we make this and a few other methods in the class private?,0,0.9931861162185669
113736431,2744,junrao,2017-04-27T16:01:12Z,"hmm, is the test added? i don't see the code for submittest that checks the throttling field in the response.",0,0.9752305150032043
114028254,2744,rajinisivaram,2017-04-28T22:05:14Z,fixed.,0,0.9905837774276733
114028270,2744,rajinisivaram,2017-04-28T22:05:25Z,fixed.,0,0.9905837774276733
114028303,2744,rajinisivaram,2017-04-28T22:05:39Z,fixed.,0,0.9905837774276733
114028317,2744,rajinisivaram,2017-04-28T22:05:47Z,done.,0,0.9897913336753845
114028402,2744,rajinisivaram,2017-04-28T22:06:32Z,"yes, you are right. replaced with `long` and updated comment.",0,0.9873375296592712
114028417,2744,rajinisivaram,2017-04-28T22:06:39Z,done.,0,0.9897913336753845
114028438,2744,rajinisivaram,2017-04-28T22:06:52Z,done.,0,0.9897913336753845
114028518,2744,rajinisivaram,2017-04-28T22:07:28Z,"sorry, had forgotten the tests, fixed now.",-1,0.9894760847091675
114028539,2744,rajinisivaram,2017-04-28T22:07:37Z,done.,0,0.9897913336753845
511148601,9487,wcarlson5,2020-10-23T20:48:43Z,this will call closetoerror but i am testing if that has a problem. so far it does not,0,0.9904347658157349
511149017,9487,wcarlson5,2020-10-23T20:49:47Z,moved into stream thread because of a concurrent operation exception that appeared,0,0.984635055065155
512320447,9487,wcarlson5,2020-10-26T23:03:45Z,method was a few lines too long,0,0.8223011493682861
514527605,9487,lct45,2020-10-29T19:57:51Z,is this spacing on purpose?,0,0.9869323372840881
514531597,9487,lct45,2020-10-29T20:03:00Z,is this section going to be re-added after the other thread handling stuff gets figured out?,0,0.9905493855476379
514535353,9487,lct45,2020-10-29T20:07:44Z,supposed to be here?,0,0.9788423180580139
514535737,9487,lct45,2020-10-29T20:08:33Z,two new lines in a row,0,0.9804839491844177
514536366,9487,lct45,2020-10-29T20:09:41Z,extra line,0,0.9940018057823181
514536509,9487,lct45,2020-10-29T20:09:56Z,extra line (:,0,0.9950600266456604
514538306,9487,lct45,2020-10-29T20:13:34Z,extra line,0,0.9940018057823181
514540200,9487,lct45,2020-10-29T20:17:02Z,line!,0,0.8466634750366211
514566700,9487,wcarlson5,2020-10-29T21:05:19Z,it will. i don't know if we should merge as comment or just add it later,0,0.9765031337738037
514567028,9487,wcarlson5,2020-10-29T21:05:43Z,same as the other use in ks,0,0.9928814172744751
516994424,9487,vvcephei,2020-11-03T22:32:35Z,"[code block] in l389, we say that we throw an exception if the handler is null, which sounds like a more reasonable api to me.",0,0.9912716746330261
516995632,9487,vvcephei,2020-11-03T22:35:32Z,what's up with the `` on this line? i don't think i've seen that before.,0,0.7663886547088623
516996830,9487,vvcephei,2020-11-03T22:38:42Z,"it's normally kinda weird to merge commented-out code. i'd either delete it or instead have a todo, like `// todo kafka-xxxx: add case replace_stream_thread once kip-? is implemented`, where `kafka-xxxx` is a follow-up ticket you create to implement this feature.",-1,0.9685482382774353
516998180,9487,vvcephei,2020-11-03T22:41:56Z,"[code block] just a little extra information, so we don't always have to pull up this code block to remember what exact response action this message corresponds to.",0,0.9919571876525879
517009538,9487,vvcephei,2020-11-03T23:11:46Z,[code block] didn't follow the prior message. is this what you meant?,0,0.9931381344795227
517009778,9487,vvcephei,2020-11-03T23:12:30Z,[code block] similar confusion here...,0,0.984776496887207
517012283,9487,vvcephei,2020-11-03T23:20:08Z,"this doesn't look like an ""error"". at best it's a ""warn"" log, but only if we think that this combination definitely looks like a misconfiguration. even then, why wouldn't we check for the misconfiguration in kafkastreams, since both the new and old handlers would be set over there?",0,0.970714271068573
517012839,9487,vvcephei,2020-11-03T23:21:52Z,[code block] this looked a bit off...,0,0.7180911302566528
517013547,9487,vvcephei,2020-11-03T23:24:09Z,it doesn't look like this needs to be shared outside of this thread. it seems like it just needs to be shared between the streamthread and its consumer?,0,0.990291178226471
517464968,9487,cadonna,2020-11-04T16:19:46Z,could you please also add the needed changes to system test `streams_upgrade_test.py::streamsupgradetest.test_version_probing_upgrade` to this pr.,0,0.9952449202537537
517474129,9487,cadonna,2020-11-04T16:32:17Z,"i guess this should be 2.8.0, shouldn't it?",0,0.9817989468574524
517481718,9487,wcarlson5,2020-11-04T16:43:03Z,i don't remember putting it there so it was probably a mistake,0,0.6470451354980469
517485257,9487,wcarlson5,2020-11-04T16:48:10Z,that works,0,0.97747802734375
517486135,9487,cadonna,2020-11-04T16:49:27Z,i would also remove the commented-out code.,0,0.9906858801841736
517505173,9487,cadonna,2020-11-04T17:18:01Z,wouldn't it also be possible to start a shutdown thread here which closes the client without timeout? i think the other shutdown thread in close is rather useless (or i do simply not get its value).,0,0.9372235536575317
517507950,9487,cadonna,2020-11-04T17:22:26Z,"imo, it would be better to extract code to methods instead of removing some lines.",0,0.9794189929962158
517543638,9487,ableegoldman,2020-11-04T18:22:10Z,can you also leave a comment here reminding us to fix the version probing system test whenever this protocol number is bumped? since we apparently always forget,0,0.9932829141616821
517576758,9487,wcarlson5,2020-11-04T19:20:51Z,i think it is simpler to check in the stream thread because we don't in kafkastreams if the handlers have been set so we would have to check the stream thread a global thread so it would be much easier to just check in the thread. i do agree that it should be bumped down to warn through.,0,0.9719036221504211
517621757,9487,wcarlson5,2020-11-04T20:47:05Z,you are right it seems that it is not necessary,0,0.9215413928031921
517627843,9487,wcarlson5,2020-11-04T20:59:16Z,"thanks for the reminder. i think i i under stood the test ad incrementing to the next version, as the version is now 9",1,0.9631487727165222
517909467,9487,cadonna,2020-11-05T09:32:23Z,is this comment correct? in this code path we do not check that all threads have been stopped.,0,0.9923133254051208
517910538,9487,cadonna,2020-11-05T09:34:07Z,could you also remove the commented-out code here.,0,0.9941462278366089
517916345,9487,cadonna,2020-11-05T09:43:22Z,the name is a bit ambiguous. i would go for `streamsuncaughtexceptionhandlerintegrationtest`,0,0.9629133343696594
517993498,9487,cadonna,2020-11-05T11:51:47Z,"what is the benefit of using a latch versus simply sleeping here? actually, you should use `streamstestutils.startkafkastreamsandwaitforrunningstate()` to avoid flakiness coming from the kafka streams client not being in state running before the verifications.",0,0.9921175837516785
517995934,9487,cadonna,2020-11-05T11:55:58Z,[code block] an application is actually a group of kafka streams clients (or instances).,0,0.9916244149208069
518008710,9487,cadonna,2020-11-05T12:19:08Z,you could wait for this flag to become true with `testutils.waitforcondition()` before you verify the other criteria.,0,0.9948422312736511
518010780,9487,cadonna,2020-11-05T12:23:05Z,why do clean the state twice?,0,0.9595305919647217
518014119,9487,cadonna,2020-11-05T12:29:10Z,why do you need to set all these properties?,0,0.9886835217475891
518021251,9487,cadonna,2020-11-05T12:41:57Z,i would remove these comments.,0,0.982978880405426
518033723,9487,cadonna,2020-11-05T13:03:05Z,"i had a hard time to understand this. we write just one record to the topic, but we end up processing two records. this is true, because we use two stream threads and there is no commit between the processing of the record of the first stream thread and the processing of the second stream thread. why do you use two stream threads here?",-1,0.9134981632232666
518035301,9487,cadonna,2020-11-05T13:05:41Z,most of the above comments also apply to the other tests.,0,0.9923892617225647
518039024,9487,cadonna,2020-11-05T13:11:58Z,"why are those fields all package-private instead of private? we usually define string constants as `private static final string idempotent_topic = ""idempotenttopic""`.",0,0.9911013841629028
518042865,9487,cadonna,2020-11-05T13:18:06Z,i do not understand the motivation behind this topic. could you clarify?,-1,0.7166195511817932
518044472,9487,cadonna,2020-11-05T13:20:37Z,unit tests for this case are missing.,0,0.9600426554679871
518263368,9487,wcarlson5,2020-11-05T18:14:44Z,yes,0,0.9686408638954163
518263937,9487,wcarlson5,2020-11-05T18:15:40Z,it might be but i do not think that it is necessary,0,0.9778257608413696
518264927,9487,wcarlson5,2020-11-05T18:17:21Z,i don't think we actually need it either way so i will just remove it,0,0.9759686589241028
518265803,9487,wcarlson5,2020-11-05T18:18:47Z,sure,0,0.9422702193260193
518267956,9487,wcarlson5,2020-11-05T18:22:27Z,"thats a good idea, i didn't see that option",1,0.9792512655258179
518269493,9487,cadonna,2020-11-05T18:25:11Z,"why not? it would be much cleaner. we would close all stuff like admin client and the metrics, remove the client metrics and set the state to not_running which is not necessarily done with timeout zero (probably not because of the death lock). additionally, we would get an nice info debug saying `streams client stopped completely` instead of `streams client cannot stop completely within the timeout`. ;-)",1,0.9877554774284363
518271215,9487,wcarlson5,2020-11-05T18:28:06Z,good idea,1,0.9905905723571777
518271918,9487,wcarlson5,2020-11-05T18:29:17Z,we probably don't need all of them. i will trim them down,0,0.9734100103378296
518274359,9487,wcarlson5,2020-11-05T18:33:24Z,i use 2 threads there to make sure the old behavior is being followed. just one thread dies and then the next thread is tries. the second thread makes sure that the new path is not closing the client unintentionally.,0,0.9917397499084473
518283539,9487,cadonna,2020-11-05T18:49:19Z,my last comment is not true! sorry! everything alright!,-1,0.9958742260932922
518326776,9487,wcarlson5,2020-11-05T19:55:10Z,actually the latch ensures the rebalance gets processed,0,0.9946461319923401
518335631,9487,wcarlson5,2020-11-05T20:11:16Z,it can be removed,0,0.9929192662239075
518371511,9487,wcarlson5,2020-11-05T21:17:19Z,added unit test,0,0.9936838150024414
518371722,9487,wcarlson5,2020-11-05T21:17:33Z,good questions,1,0.983376681804657
518478117,9487,ableegoldman,2020-11-06T01:55:29Z,"i had a little trouble following the `handler` class. some trivial things -- eg the handler in the streamthread is named `streamsuncaughtexceptionhandler` but it's actually _not_ a `streamsuncaughtexceptionhandler`. also the usage of the return value; iiuc it's supposed to indicate whether to use the new handler or fall back on the old one. to me it sounds like if `handle` returns `true` that means we should handle it, ie we should _not_ rethrow the exception, but this looks like the opposite of what we do now. honestly either interpretation is ok with me, as long as it's documented somewhere do we really need the `handler` in the first place though? it's already pretty confusing that we have to deal with two types of handlers (old and new) so i'd prefer not to add a third unless it's really necessary. it seems like we can just inline the logic of whether to invoke the new handler or rethrow the exception, which would also clear up the confusion around the meaning of the return value. but i might be missing something here -- wdyt?",0,0.7139956951141357
518479524,9487,ableegoldman,2020-11-06T01:59:50Z,seems like we can just pass in a runnable with `kafkastreams::closetoerror` instead of adding a whole `shutdownerrorhook` functional interface,0,0.9844627380371094
518483194,9487,ableegoldman,2020-11-06T02:12:42Z,should this be logged at error?,0,0.988836407661438
518484271,9487,ableegoldman,2020-11-06T02:16:48Z,"looks like we call `setstate(error)` three times in this method, is that intentional?",0,0.9915208220481873
518485280,9487,ableegoldman,2020-11-06T02:20:24Z,"it probably doesn't matter too much since `handlerebalancecomplete` doesn't do anything that important at the mometn, but it seems like we should call it before shutting down, not after.",0,0.966971218585968
518485749,9487,ableegoldman,2020-11-06T02:22:02Z,this should probably stay `final` so we don't accidentally change it ever,0,0.9858149290084839
518488577,9487,ableegoldman,2020-11-06T02:32:29Z,"this cast makes me kind of uncomfortable...either the `assignmenterrorcode` that we have in the assignmentinfo is conceptually the same as the one we're adding to the subscriptioninfo (in which case it should be the same type), or it's not the same, in which case we should use a different variable to track it. personally i think it's probably simpler to keep them the same, and just add an `int` errorcode field to the subscription instead of a `byte` shutdownrequested field. but it's your choice",-1,0.975002646446228
518489261,9487,ableegoldman,2020-11-06T02:35:01Z,"i think we should mirror the `errorcode` in the assignmentinfo here, both in terms of naming and type. if we're going to use the same assignorerror for both, then they should really be the same. and we may want to send other kinds of error codes in the subscription going forward: better to just encode a single `int` than a separate `byte` for every logical error code. i don't think we'll notice the extra three bytes since subscriptions aren't sent that frequently",0,0.9762563705444336
518837250,9487,wcarlson5,2020-11-06T15:46:47Z,we could do the logic inline how ever this does make it slightly simpler. also we only expose the `streamsuncaughtexceptionhandler` to the user and had a problem with the wrapping that again with the same type. so we introduced a wrapper class. if we renamed it from `handler` to `streamsuncaughtexceptionhandlerwrapper` would that make it more clear?,0,0.9931924939155579
518838421,9487,wcarlson5,2020-11-06T15:48:45Z,in the normal close method the corresponding log is also info. as multiple thread will be calling this at once i would rather not flood the logs with error unnecessarily.,0,0.9704743027687073
518838586,9487,wcarlson5,2020-11-06T15:49:01Z,"no, i hadn't seen that",0,0.969538152217865
518840121,9487,wcarlson5,2020-11-06T15:51:21Z,"we can do that, it doesn't seem make difference which order it is called. however if it is not called it will get stuck continually rebalancing. we return because setting the state to partitions assigned will cause an error",0,0.987888753414154
518840602,9487,wcarlson5,2020-11-06T15:52:00Z,i was changing it intentionally but i think i can get away with not,0,0.9354341626167297
518842747,9487,wcarlson5,2020-11-06T15:55:21Z,yes we can,0,0.9868863224983215
518850419,9487,wcarlson5,2020-11-06T16:08:05Z,"i think i agree on the name, i am not sure about the type. we should be able to fit thousands of different error code into the byte so we should not run out of space. the reason the errorcode. is an integer in the first place is because there is not `atomicbyte` that i know of.",0,0.9752547740936279
518913514,9487,ableegoldman,2020-11-06T17:57:36Z,"gotcha. in that case maybe we shouldn't log anything here at all? or just reword it to clarify that this is expected (eg `""skipping shutdown since we are already in error""`) since ""can not transition..."" kind of sounds like something went wrong",-1,0.9581218957901001
518938852,9487,wcarlson5,2020-11-06T18:47:09Z,"that is a good idea, ill change the log",1,0.9678249359130859
520077048,9487,ableegoldman,2020-11-09T19:47:31Z,"i'm not really worried that we'd run out of space, i just think it sends a signal that the assignment and subscription error codes are semantically distinct and don't refer to the same underlying concept. so it seems better to go with the simpler approach than over-optimize to save an occasional three bytes",0,0.8132835030555725
520104884,9487,wcarlson5,2020-11-09T20:38:03Z,"[a link] i originally had it at int32, but suggested int16, now it is int8. would you be good with int16 or do you think int32 is the way?",0,0.9842706322669983
522596527,9487,ableegoldman,2020-11-13T03:51:22Z,this wording is a little difficult to parse,0,0.7543630003929138
522597486,9487,ableegoldman,2020-11-13T03:55:34Z,"just curious, what's the motivation for doing it like this vs just immediately throwing the exception?",0,0.9664771556854248
522598008,9487,ableegoldman,2020-11-13T03:57:50Z,nit: parameters unaligned,0,0.9918079972267151
522598142,9487,ableegoldman,2020-11-13T03:58:34Z,that's a lot of line breaks :upside-down_face:,-1,0.9946059584617615
522598707,9487,ableegoldman,2020-11-13T04:00:50Z,is everything after this line the same as the code in the regular `close()`? might be a good idea to move it to a separate method so we don't accidentally forget to update one of them if we ever need to make changes to how we close,0,0.9890514016151428
522613334,9487,ableegoldman,2020-11-13T04:26:45Z,"it seems like we shouldn't both handle the exception in the catch block and shut down the client in the finally block. if the new handler is used, then we've already shut down the client or possibly started to shut down the whole application. it's tricky, though, because if the old handler was used then we _do_ want to make sure that the global thread is all cleaned up before rethrowing the exception. seems like we need some way to detect whether we're using the old or the new handler after all. but i think you can do it without too many changes, since basically the rule is ""if they set a new handler at all or didn't set either handler, then use the new one"". so maybe you can just make the `streamsuncaughtexceptionhandler` a local field instead of the `consumer<>`, and leave it as `null` to indicate that the old handler should be used and therefore this shutdown logic should be invoked. otherwise just call the new handler directly. or something like that...you'd know this code better than me, wdyt?",0,0.9479870796203613
522616515,9487,ableegoldman,2020-11-13T04:30:37Z,"hmm...this one seems like it should be a fatal error, so is it safe to just pass it along to the user and let them potentially just keep replacing the thread? (i know that option doesn't exist yet, but it will). there are some instances where we interpret errors as permanently fatal and choose to shut down the entire application, eg some errors during assignment. should we do the same here? cc or for more context on this error",0,0.8595985174179077
522622229,9487,ableegoldman,2020-11-13T04:37:49Z,i think we should add the `errorcode` parameter to the existing constructor rather than add a new one. it shouldn't be possible to construct a version 9 subscription that doesn't have an `errorcode`,0,0.9871626496315002
522622882,9487,ableegoldman,2020-11-13T04:38:35Z,"nice, thanks for the comment. btw anytime we bump this protocol version we should add the corresponding unit tests, eg `subscriptioninfotest#shouldencodeanddecodeversion8()`",1,0.9898539185523987
522626697,9487,ableegoldman,2020-11-13T04:43:11Z,"does the comment relate to the `` suppression? either way this probably makes more sense as a comment on the pr than in the code. given how bad we are about updating comments, i'd try to avoid anything that describes a change and reserve code comments for describing what's currently going on (or better yet, ""why"")",0,0.955353856086731
522627296,9487,ableegoldman,2020-11-13T04:43:39Z,"same here, what is the comment referring to? also what does it mean for a test to be deprecated :thinking_face:",0,0.8530798554420471
522635059,9487,ableegoldman,2020-11-13T04:49:40Z,ditto here,0,0.9882494211196899
522639947,9487,ableegoldman,2020-11-13T04:55:41Z,"is the latch ever being counted down anywhere? you might want to take a look at some of the test utils, there's a lot of useful stuff so you don't have to implement everything from scratch. if you just want to make sure that the client gets to `closed` within 15s then i'd recommend `testutils#waitforcondition`",0,0.9840477108955383
522641072,9487,ableegoldman,2020-11-13T04:57:10Z,is this the only property that changed? might be clearer if you just override what you need to here,0,0.9917309880256653
522650704,9487,ableegoldman,2020-11-13T05:09:14Z,"we should probably use an actual handler here to make sure it works with the globalthread. actually maybe we should add a few unit tests here to make sure that it closes down and rethrows when the old handler is used, but handles the exception internally when the new handler is used, etc",0,0.9902737736701965
522654080,9487,ableegoldman,2020-11-13T05:13:23Z,why set the exception handler in this test and no others?,0,0.9675359129905701
523028163,9487,cadonna,2020-11-13T15:35:28Z,"nit: usually we indent 4 spaces, not 8.",0,0.9889051914215088
523034271,9487,cadonna,2020-11-13T15:45:11Z,"are you sure this is the correct method to call? as far as i understand the the javadocs and the decompiled code, this method does not return the handler you can set on a `thread` with `setuncaughtexceptionhandler()`.",0,0.993636965751648
523041454,9487,cadonna,2020-11-13T15:56:14Z,"i guess, you wanted to do this [code block]",0,0.9839907884597778
523041842,9487,cadonna,2020-11-13T15:56:53Z,please use a more meaningful parameter name.,0,0.9933352470397949
523044111,9487,cadonna,2020-11-13T16:00:23Z,"i still have a question here. since the stream thread is alive when it calls `close()` there will not be a deadlock anymore. so, why do we call `close()` with duration zero?",0,0.949368417263031
523069611,9487,wcarlson5,2020-11-13T16:40:19Z,changed to ` in order to get the thread uses use thread.currentthread()` does that work better?,0,0.9947323799133301
523070844,9487,wcarlson5,2020-11-13T16:42:18Z,we have to do the casting in order to throw the exception. otherwise the compiler complains about checked vs unchecked exceptions,0,0.9861487150192261
523072781,9487,wcarlson5,2020-11-13T16:45:31Z,yes good catch,1,0.9884586930274963
523073595,9487,wcarlson5,2020-11-13T16:46:49Z,that is a lot of line breaks,0,0.7896873354911804
523079456,9487,wcarlson5,2020-11-13T16:56:05Z,everything except the state we leave it in. we can move most of it to a helper,0,0.9943209886550903
523079965,9487,wcarlson5,2020-11-13T16:56:55Z,we should be able to change it to `close()`,0,0.9949039220809937
523080590,9487,cadonna,2020-11-13T16:57:57Z,"the name is a bit confusing. the best i could come up is `handlestreamsuncaughtexceptionbydefault()`, but i am sure there is a better name.",-1,0.7552733421325684
523089743,9487,vvcephei,2020-11-13T17:06:49Z,"if that's the case, then we really should just set a flag on kafkastreams to indicate whether that handler has been set.",0,0.9903786182403564
523090161,9487,wcarlson5,2020-11-13T17:07:04Z,there is a logic to use the old handler if the conditions you laid out are true. the odd series of casts of exception types in `handlestreamsuncaughtexceptiondefaultwrapper` are what makes this happen. this is a bit tricky but i think we want to close the client either way. as we don't have plans to replace the global thread and shutting down the application is best effort. we talked about this a while back and we decided the global handler was mainly for information and the return type we would try to follow but we need to make sure we at least close the client.,0,0.9666233658790588
523095231,9487,wcarlson5,2020-11-13T17:10:31Z,i think this is fine for now. when we add replace thread as an option we can include overrides when handling the response that prevent the thread from being restarted in certain error cases.,0,0.8123034238815308
523103147,9487,wcarlson5,2020-11-13T17:21:13Z,when we remove the old handler we either need to remove the test or remove the suppression. that is what i am hoping the comment will do,0,0.9900233149528503
523109393,9487,wcarlson5,2020-11-13T17:28:41Z,"i'll add that to the comment, and add a test",0,0.994819700717926
523136568,9487,wcarlson5,2020-11-13T18:14:59Z,how about `defaultstreamsuncaughtexceptionhandler`?,0,0.9955788254737854
523138325,9487,wcarlson5,2020-11-13T18:17:29Z,we can just set a flag through to be safe,0,0.9904797673225403
523141998,9487,wcarlson5,2020-11-13T18:21:29Z,same as above,0,0.9918335676193237
523230140,9487,wcarlson5,2020-11-13T21:01:25Z,"so the problem that i am facing is that many tests are set up to work with the old handler. i was able to adapt most to use the new handler but not all. some, like a few eos tests, require one thread to die at a time. so i either suppress the deprecation or tag the test as deprecated, thus indicating it should be removed when the old handler is. another problem is that a few tests rely on the threads dying one at a time or they test behavior in this case but they do not set an old handler. so i can either 1) set an old handler and mark for deletion or 2) adapt for the new out come. for the ones i could, i changed to the new flow but i could not do that with all of them. how would you suggest updating these tests?",0,0.6977924108505249
523277374,9487,wcarlson5,2020-11-13T23:04:52Z,because otherwise the task migrated exception sends it into a endless rebalance,0,0.9689982533454895
523280093,9487,wcarlson5,2020-11-13T23:14:47Z,that is useful thanks. i went with `waitforapplicationstate`,1,0.981349766254425
523280707,9487,wcarlson5,2020-11-13T23:17:00Z,agree,0,0.8991182446479797
523288678,9487,wcarlson5,2020-11-13T23:49:17Z,for the same reason i had to add to the other cases as the close from the new handler will not finish otherwise,0,0.9858618974685669
523296833,9487,ableegoldman,2020-11-14T00:16:51Z,is there an extra `uses` in there or am i not looking at this sentence from the right angle?,0,0.9776309132575989
523302976,9487,ableegoldman,2020-11-14T00:47:17Z,"ah ok i thought we executed this cleanup logic in the globalstreamthread's `shutdown` method but now i see that's not true. sorry for the confusion there. i do see some minor outstanding issues here, mainly around the state diagram. let's say the user opts to `shutdown_client` in the new handler: the intended semantics are to end up in `not_running` but i think what would happen is that from the global thread we would immediately call `kafkastreams#close` , which kicks off a shutdown thread to wait for all threads to join and then sets the state to `not_running`. then when the handler returns, it would transition the global thread to `pending_shutdown` and then finally to `dead`. and during the transition to `dead`, we would actually end up transitioning the kafkastreams instance to `error`, rather than `not_running` as intended. so probably, we just need to update the `onchange` method in kafkastreams. this also reminds me of another thing, we need to update the fsm diagram and allowed transitions in kafkastreams to reflect the new semantics we decided on for error (which iirc is basically just to make it a terminal state). does that sound right to you?",-1,0.9845289587974548
523303062,9487,ableegoldman,2020-11-14T00:47:52Z,"i suspect the tests didn't catch this because we would still transition out of error to pending_shutdown and finally not_running in this case. but really, we shouldn't transition to error in the first place",0,0.9448041319847107
523311219,9487,ableegoldman,2020-11-14T01:05:18Z,"what happens if we try to read the error code of an earlier subscription version? i genuinely don't know what the generated code does, but we should make sure it doesn't throw an npe or something. could you add a unit test for this case?",0,0.9730349183082581
523319677,9487,ableegoldman,2020-11-14T01:15:05Z,"i think any test that's trying to verify some unrelated behavior and just using the ""one thread dies at a time"" paradigm as a tool to do so should not be deleted. i'm sure in most if not all cases, there's some way to modify the test to verify that specific behavior either using the new handler or multiple apps or rewriting it altogether. but, there are a lot of tests that do this and a lot of them are pretty tricky, so i wouldn't want to stall this pr on waiting for all of these tests to be updated/adapted. i think we should file tickets for all of these tests and just try to pick up one or two of them every so often. maybe that's being overly optimistic about our inclination to pick up small tasks even over a long period, but it's better than losing track of them altogether. wdyt?",0,0.9015329480171204
523322776,9487,ableegoldman,2020-11-14T01:18:45Z,but taskmigratedexception should never be thrown all the way up to the exception handler. is that what you're seeing?,0,0.9929803013801575
523327104,9487,wcarlson5,2020-11-14T01:23:46Z,i appreciate the benefit of the doubt :) but you are right there is an extra `uses`,1,0.9918158650398254
523327338,9487,ableegoldman,2020-11-14T01:24:03Z,"well it's not exactly a default, technically this method is always used to decide which handler to invoke (which may or may not invoke a default handler). any of these would be fine by me but i'll throw one more idea out there: `invokeoldornewuncaughtexceptionhandler`",0,0.9914969801902771
523334335,9487,wcarlson5,2020-11-14T01:32:21Z,"i don't think it will actually transition to `error` because the handler will call close before the global thread is dead, which will transition to peding_shutdown, there is no transition to error from either pending_shutdown or not_running. the fsm will be part of the add thread work as it doesn't really make sense to remove the change to error until we can add threads",0,0.9783409237861633
523334732,9487,wcarlson5,2020-11-14T01:35:22Z,i agree we shouldn't remove the valid test cases. maybe the ones that are more complicated i can just set an idempotent old handler and mark as deprecated and we can file tickets to update. either we work them down or when we go to remove the old handler they will fail and we need to fix them then.,0,0.9782966375350952
523337226,9487,wcarlson5,2020-11-14T01:52:07Z,not quite. if i remove the handler and just run it there is an illegal state exception which runs endlessly until the handler can exit the loop. it looks like the thread hadn't started all the way before the taskmigratedexcpetion is thrown `info state transition from starting to pending_shutdown (org.apache.kafka.streams.processor.internals.streamthread:223) [`,0,0.9792172908782959
523337785,9487,wcarlson5,2020-11-14T01:56:35Z,good idea. it does not seem to do anything. but good to have a test for it,1,0.9926503300666809
523372464,9487,ableegoldman,2020-11-14T04:08:25Z,"ah ok so there's some other illegalstateexception that would get swallowed if we just used `e -> {}` like in the other tests, so we need to explicitly rethrow it? that seems fine, although it makes me think that we should go ahead and use a ""real"" handler in _all_ of the tests, not just this one. otherwise there could be some bug which causes an unexpected exception, but the test would just swallow it and silently pass. can we just use the default handler wrapper for all of these tests so they reflect realistic scenarios?",0,0.9620876908302307
523375614,9487,ableegoldman,2020-11-14T04:45:56Z,"oh you're totally right, sorry for letting my paranoia start spreading conspiracy theories here :slightly_smiling_face: given all this i'd still claim that the fsm is in need to being cleaned up a bit (or a lot), but if you'd prefer to hold off on that until the add thread work then i'm all good here. thanks for humoring me and explaining the state of things. i just wanted/want to make sure we don't overlook anything, since there's a lot going on. for example in the current code, if the global thread dies with the old handler still in use then we'll transition to error. however the user still has to be responsible for closing the client themselves, and it will ultimately transition from error to not_running. whereas if we transition to error as the result of a shutdown_application error code, the user should not try to invoke close themselves, and the error state will be terminal. that's pretty confusing eg for users who use a state listener and wait for the transition to error to call close(). we should make sure that error has the same semantics across the board by the end of all this work. anyways i'm just thinking out loud here, to reiterate i'm perfectly happy to merge this as-is. but for reasons like the above, i think it's important to tackle the fsm in the next pr and make sure it all gets sorted out by the next ak release",-1,0.966471254825592
524433881,9487,wcarlson5,2020-11-16T17:11:38Z,it's actually not always used. it is only used until a new handler is set in which it is over written. once that happens we don't want the old handler to be set so we do not wrap a user provided handler with this method,0,0.9931870698928833
524435241,9487,wcarlson5,2020-11-16T17:13:23Z,"the default is in kafkastreams, but i see your point. we can make all of them rethrow then we will not have to worry about swallowing",0,0.9770081043243408
524437940,9487,wcarlson5,2020-11-16T17:17:31Z,"+1 to sorting out fsm before next release, i have a ticket to track the work. i started to change it and it ballooned out to be much more expansive than i thought. this pr is already complicated enough, so we can add is later.",0,0.7258480787277222
524447256,9487,vvcephei,2020-11-16T17:30:29Z,i think i'd personally still prefer the non-blocking version. it seems better to avoid blocking indefinitely when a thread is trying to shut itself down due to some unknown exception (or error).,0,0.9235729575157166
524448160,9487,vvcephei,2020-11-16T17:31:54Z,"likewise, here, it seems better to do a non-blocking close.",0,0.9815099239349365
524475389,9487,vvcephei,2020-11-16T18:14:59Z,"personally, as long as users have the information available to understand the nature of the error, it's fine to let them make their own decision about how to handle it. maybe another team is in the middle of a broker upgrade, for example, and the owner of this app would like to just keep trying until the broker team gets it together.",0,0.9758363366127014
524478717,9487,vvcephei,2020-11-16T18:20:34Z,i think i'd like to re-raise sophie's concern here. it doesn't compute for me why we are casting an int to a byte here..,0,0.9255175590515137
524487609,9487,wcarlson5,2020-11-16T18:35:22Z,"that is probably fine. we can really get into it when we add the replace option, as now all calls to the handler are fatal.",0,0.9826211333274841
524490211,9487,wcarlson5,2020-11-16T18:39:34Z,"it doesn't really matter to me, though i think that non blocking is probably preferable.",0,0.9340177774429321
524540416,9487,wcarlson5,2020-11-16T20:06:47Z,i guess i must have misunderstood your earlier comment. i thought you wanted it to stay a byte so that is why i pushed back. but if you have no objections i will just change it,0,0.8631797432899475
524814932,9487,ableegoldman,2020-11-17T00:56:33Z,"that's a fair point about broker upgrades, but don't we require the brokers to be upgraded to a version that supports eos _before_ turning on eos-beta? anyways i was wondering if there was something special about this exception such that ignoring it could violate eos or corrupt the state of the program. i'll ping the eos experts to assuage my concerns",0,0.9315503239631653
524817135,9487,ableegoldman,2020-11-17T01:03:03Z,"can you clarify? i thought we would still be in danger of deadlock if we use the blocking `close()`, since `close()` will not return until every thread has joined but the streamthread that called `close()` would be stuck in this blocking call and thus never stop/join",0,0.9889406561851501
524819063,9487,ableegoldman,2020-11-17T01:08:55Z,"just to clarify i think it's ok to leave this as-is for now, since as walker said all handler options are fatal at this point",0,0.9813612103462219
524824649,9487,ableegoldman,2020-11-17T01:25:57Z,"mm ok actually i think this should be fine. i was thinking of the handler as just ""swallowing"" the exception, but in reality the user would still let the current thread die and just spin up a new one in its place. and then the new one would hit this unsupportedversionexception and so on, until the brokers are upgraded. so there shouldn't be any way to get into a bad state",0,0.712446391582489
525161434,9487,cadonna,2020-11-17T13:41:49Z,"ok, i think you are right. i focused too much on [code block] without considering that before the stream threads are shutdown which makes them not running. in the meantime, i understood a bit better the motivation of the shutdown thread in `close()`. the shutdown thread ensures that the timeout is still consiered in case `close()` is called by a stream thread. i think we should revisit it. but that is outside the scope of this pr. to unblock this pr, i am fine with `close(duration.zero)`, but i have the feeling we could do better.",0,0.8009677529335022
525169791,9487,cadonna,2020-11-17T13:52:01Z,there is something wrong in this sentence.,-1,0.8991358876228333
525170922,9487,cadonna,2020-11-17T13:53:37Z,`oldhanlder` -> `oldhandler`,0,0.9899763464927673
525194549,9487,cadonna,2020-11-17T14:26:06Z,nit: remove line,0,0.9879302978515625
525442248,9487,wcarlson5,2020-11-17T19:41:19Z,oops,0,0.6581283807754517
525444958,9487,wcarlson5,2020-11-17T19:43:34Z,need to remove `use`,0,0.9931835532188416
525636554,9487,ableegoldman,2020-11-18T01:32:09Z,i think it makes more sense to transition to error in this case than to not_running. but let's put this on file with the other fsm-related work planned for following prs,0,0.9862586259841919
525640088,9487,ableegoldman,2020-11-18T01:43:12Z,"why do we shut down the global thread only after all stream threads have completed their shutdown? seems like it would be more efficient to send the shutdown signal to everyone first, and then wait for all the threads to join. can you try this out in the followup pr?",0,0.9889473915100098
525650632,9487,ableegoldman,2020-11-18T02:14:15Z,"i just realized that this is going to be a problem with the way the error state is being used. if we `closetoerror` then we transition to error and shut down, however `error -> pending_shutdown` is still an allowed transition so there's nothing to prevent the shutdown from being triggered again when a user calls `close()`. and note that a lot of users most likely have a state listener at the moment which does exactly that, ie when it sees a transition to error it immediately invokes close (because that's what you should do with the current semantics) just another thing that i think we can fix with some minor rewiring of the fsm.",0,0.9584784507751465
525658639,9487,ableegoldman,2020-11-18T02:23:10Z,"hm ok this might be a problem. since this is thrown from another catch block and not from the try block, it won't be caught by the catch block below and will slip through the exception handler.",0,0.8401874303817749
525663640,9487,ableegoldman,2020-11-18T02:28:30Z,we should remember to update the wording here when we add the replace_thread functionality,0,0.9944729208946228
525678234,9487,wcarlson5,2020-11-18T02:44:07Z,you are right i think. i just copied from the normal close method because i knew it worked. in a follow up we can maybe change both of these. do you think that there should be a ak ticket to track it?,0,0.8970892429351807
525680874,9487,wcarlson5,2020-11-18T02:46:55Z,i am on the fence about this. i do think its would be consistent to be not running but also it did shutdown cleanly. we made this choice when error still meant all threads had died and that is not true now. in the end i just went with what we had in the kip rather than try to change it. though i could be swayed to leave this in error.,0,0.6029232144355774
525681642,9487,wcarlson5,2020-11-18T02:47:48Z,this is currently the plan to remove that transition. it is pretty much the only change we plan to make to the fsm.,0,0.991524875164032
525686843,9487,wcarlson5,2020-11-18T02:53:20Z,like in stream thread we can just add a call to the handler,0,0.991940975189209
525692960,9487,ableegoldman,2020-11-18T02:59:37Z,"eh, i wouldn't bother with an ak ticket if this will be tackled in the next pr. i'll just make a list of all the minor followup work somewhere to keep track",0,0.9786221385002136
525701691,9487,ableegoldman,2020-11-18T03:06:40Z,"that's fair. i guess i was thinking less about the inherent meaning of error vs not_running, and more about not behaving differently in this special case. ie if there _are_ still streamthreads running when a user selects shutdown_application, then we ultimately transition to error. so it strikes me as a bit odd to transition to not_running just because we didn't happen to have any threads left.",0,0.8709751963615417
525734417,9487,ableegoldman,2020-11-18T03:30:18Z,"wdyt about having both not_running and error go through pending_shutdown, rather than just transitioning directly and permanently to error? at a high level i think it just makes sense for error and not_running to be symmetric. also any benefit to having an intermediate pending_shutdown for the not_running case presumably applies to the error case as well. eg, it indicates whether streams has completed its shutdown or not: users know that an app in pending_shutdown should never be killed, its only safe to do so once it reaches not_running. we should provide the same functionality and only transition to error after the shutdown is complete",0,0.967401921749115
526211409,9487,wcarlson5,2020-11-18T16:08:54Z,"i do think that error should not have direct transition. however i don't like using `pending_shutdown` , mostly because we can already distinguish between the two states and it would be best to inform right away. also it could be a problem if we went to set error and some how it went from pending_shutdown to not_running. i am in favor of adding something like `pending_error` just to be more precise.",0,0.9410845041275024
526477258,9487,ableegoldman,2020-11-18T22:53:15Z,sounds reasonable,0,0.987473726272583
665553313,10851,vlsi,2021-07-07T17:00:34Z,i guess it would be better to move the assignment to the field declaration to avoid duplication among constructors.,0,0.9773690700531006
665561377,10851,vlsi,2021-07-07T17:12:31Z,can you please clarify why `treemap ` is used here? would `map ` suffice?,0,0.9944748282432556
669473299,10851,cadonna,2021-07-14T10:05:18Z,i was wondering whether we can simply standby assignment if `configs.numstandbyreplicas == 0`. here or as first step in the method body of `assignstandbyreplicatasks()`. in this way we can remove `noopstandbytaskassignor`.,0,0.9855519533157349
669496452,10851,cadonna,2021-07-14T10:41:19Z,"as far as i can see, this map is only used in `clienttagawarestandbytaskassignor` and it is only used to iterate over pairs (taskid, uuid). that can also be accomplished by iterating over the client states and for each client state iterate over the assigned active tasks. i do not think that we need to modify the signature of `assignactivestatefultasks()`. or am i missing something?",0,0.9893105030059814
669500118,10851,cadonna,2021-07-14T10:47:36Z,i think it should be `sortedmap` instead of `treemap`. i also saw that we sometimes missed to use `sortedmap` instead of `treemap` in some signatures. it needs to be a sorted map because the assignments should be stable otherwise it could happen that we compute different assignments for the same input which could lead to unnecessary state migrations.,0,0.9872671961784363
669504412,10851,cadonna,2021-07-14T10:54:30Z,why do we need this internal class? wouldn't it be simpler to structure the code with methods directly under `clienttagawarestandbytaskassignor`?,0,0.9900364875793457
669849371,10851,lkokhreidze,2021-07-14T18:20:28Z,"thanks for the feedback bruno. i reasoned that, since internal states like `clientspertagvalue`, `standbytaskclientsbytaskload`, etc., have to be allocated per invocation of `assignstandbytasks` method, it felt easier and more readable to create one single internal object rather than invalidating local caches in `clienttagawarestandbytaskassignor`.",1,0.961816668510437
669851397,10851,lkokhreidze,2021-07-14T18:23:36Z,"i tried to avoid unnecessary iterations. with that we would have to do separate iteration in the `clienttagawarestandbytaskassignor`, which felt redundant, since `assignactivestatefultasks` can return necessary mapping since it has to iterate over client states either way.",0,0.8803888559341431
669853519,10851,lkokhreidze,2021-07-14T18:26:40Z,i didn't give it much thought to be honest. `treemap` for the `clientstates` was already used in the `highavailabilitytaskassignor` and went with the same signature here. i think it makes sense to change the contract to be a `sortedmap`. will do that.,0,0.950694739818573
669865915,10851,lkokhreidze,2021-07-14T18:45:48Z,sure! done. personal preference. having all the strategies of standby task assignment implementations in a single class makes unit testing a bit easier. but i do agree that removing one extra class is indeed good idea.,1,0.9608909487724304
670294370,10851,cadonna,2021-07-15T09:27:04Z,"yes, the `treemap` in the signatures has been already there before this pr. thank you for fixing this!",1,0.9780414700508118
670309425,10851,cadonna,2021-07-15T09:47:08Z,"as far as i can see, we would iterate only over the active tasks in both cases. the difference is that in case we have one loop and in the other we have two nested loops. in the nested loop case, the code in the innermost loop is executed the same number of times as in the one loop case. that is, as many times as the number of active tasks. in general, i would not change too much code for a performance improvement before we hit a performance issue. you know, as donald e. knuth stated ""premature optimization is the root of all evil"". :slightly_smiling_face:",0,0.8108742833137512
670332282,10851,cadonna,2021-07-15T10:18:49Z,"method `assignstandbytasks()` is only invoked once per assignment, as far as i can see. i do not see the need to avoid invalidating caches. or am i missing somethings?",0,0.9930207133293152
670333813,10851,cadonna,2021-07-15T10:20:54Z,"i would prefer to have an interface instead of an abstract class. in the past, it turned out to be cleaner and easier maintainable even if we need to duplicate the `configs` field in the implementations of this interface.",0,0.9800650477409363
670336504,10851,cadonna,2021-07-15T10:24:46Z,i think a factory method as used [a link] should suffice instead of an entire class.,0,0.9837099313735962
671829899,10851,lkokhreidze,2021-07-18T11:47:01Z,"that is correct. currently, `standbytaskassignor` implementations are created once per `taskassignor#assign` method call, and `assignstandbytasks` is called only once. i just didn't want to assume how and how many times `assignstandbytasks` is called as i didn't want to leak the implementation details to the caller. however, if you feel strongly that it's better to have the implementation in the `clienttagawarestandbytaskassignor`, i can refactor the code. since it's internal contract of the assignment, maybe it's okay.",0,0.9791204929351807
672023300,10851,lkokhreidze,2021-07-19T06:38:07Z,"fair enough, done.",0,0.9082126617431641
672023438,10851,lkokhreidze,2021-07-19T06:38:26Z,done,0,0.8682363629341125
672023741,10851,lkokhreidze,2021-07-19T06:39:04Z,moved factory method in `standbytaskassignor` interface itself. hope it addresses your comment.,0,0.8977869749069214
685807795,10851,cadonna,2021-08-10T08:31:19Z,"i see your point, but i do also not see the need for an internal state for which we need to avoid invalidation. variables `numstandbyreplicas` and `numstandbyreplicas` are configs that can be stored as member fields of `clienttagawarestandbytaskassignor` or passed along to the methods that need them. variables `tagkeytotagvaluesmapping`, `clientspertagvalue`, `standbytaskclientsbytaskload`, and `clientstates` can also be passed to the methods that need them. avoiding state makes reasoning about code simpler and here it seems possible to avoid state. see `highavailabilitytaskassignor`, it does not have any state.",0,0.9790027737617493
685816278,10851,cadonna,2021-08-10T08:42:05Z,"i would prefer to make this interface independent of its implementations. if you put the factory method here, the interface is not independent anymore. i would prefer a factory method named `createstandbytaskassignor()` in `highavailabilitytaskassignor` similar to the existing factory method `createtaskassignor()` in `streamspartitionassignor`.",0,0.9916738867759705
685822324,10851,cadonna,2021-08-10T08:49:41Z,"minor: you could extend interface `taskassignor` and remove `assignstandbytasks()` from this interface since `assign()` in `taskassignor` has almost the same signature. the difference is parameters `configs` and `alltaskids`. you will need `configs` if you will not keep the config as a member variable as mentioned in my other comment. you will not need `alltaskids`, but that would be ok, i guess.",0,0.9905968904495239
685824044,10851,cadonna,2021-08-10T08:51:51Z,"i guess the initialization in the constructor on line 79 is only temporary. this will change in one of the next prs. nevertheless, i agree that it would also be fine to move the initialization to the field declaration for now. i would even propose to pass the client tags to the constructor, since those are kind of constants coming from the config.",0,0.9795865416526794
685865965,10851,cadonna,2021-08-10T09:48:09Z,i would prefer to just add two parameters -- `source` and `destination` -- to the `isvalidmovement()` method in `standbytaskassignor` and get rid of this class.,0,0.9889799356460571
685867438,10851,cadonna,2021-08-10T09:50:08Z,the task id is never used. could we remove it?,0,0.9925984144210815
685871631,10851,cadonna,2021-08-10T09:56:06Z,could you move the second condition to the `canmove` assignment on line 166? i think the condition is logically a part of `canmove`.,0,0.9935141801834106
685872701,10851,cadonna,2021-08-10T09:57:39Z,nit: i think `isallowedtaskmovement()` reflects better the meaning of this method.,0,0.9793776869773865
685877129,10851,cadonna,2021-08-10T10:03:55Z,would it be possible to integrate the tag constraint as part of the constraint on the priority queue?,0,0.9927651286125183
693133897,10851,lkokhreidze,2021-08-20T18:14:16Z,"it's already part of the poll constraint of the priority queue. example: [code block] i don't think it will be doable with constructor constraint, because we need to update constraint on each poll.",0,0.9925559163093567
693150166,10851,lkokhreidze,2021-08-20T18:44:21Z,good point about client tags being constant. added it as constructor parameter.,1,0.9422617554664612
693163634,10851,lkokhreidze,2021-08-20T19:09:26Z,addressed with 9841d25,0,0.9947128891944885
695463229,10851,lkokhreidze,2021-08-25T07:11:43Z,this method is needed in `clienttagawarestandbytaskassignor` and `defaultstandbytaskassignor`. was thinking to create `standbytaskassignmentutils` and extract this logic in there. wdyt ?,0,0.9930586814880371
695630930,10851,cadonna,2021-08-25T10:49:00Z,"yes, i think that makes sense. in this way you can also directly test the method. btw, you can simply pass `statefultaskids` to this method instead of `statefultaskswithclients`. the keys in `statefultaskswithclients` should be the task ids in `statefultaskids` and the values in `statefultaskswithclients` are never used.",0,0.9425960183143616
695640768,10851,cadonna,2021-08-25T11:03:15Z,isn't this the same as: [code block],0,0.9918728470802307
695642889,10851,cadonna,2021-08-25T11:06:10Z,isn't this the same as: [code block],0,0.9918728470802307
695669488,10851,cadonna,2021-08-25T11:41:52Z,why is the map from tag key to tag values computed for each active task? they should not change during the assignment and we can just compute it once in `assign()`. do you agree?,0,0.9929722547531128
695690393,10851,cadonna,2021-08-25T12:12:07Z,"imo, the code is easier readable if you name the variables consistently like `tagvaluetoclients` and `tagkeytotagvalues` or `clientsfortagvalue` and `tagvaluesfortagkey`. i prefer the former because it better visualises the mapping, but that is a matter of taste, i guess.",0,0.9694439172744751
695717497,10851,lkokhreidze,2021-08-25T12:48:31Z,"good catch. i missed it during refactoring, you're correct.",1,0.9919795989990234
695735723,10851,lkokhreidze,2021-08-25T13:10:03Z,done,0,0.8682363629341125
695735854,10851,lkokhreidze,2021-08-25T13:10:15Z,pushed changes,0,0.9853689074516296
695735942,10851,lkokhreidze,2021-08-25T13:10:21Z,fixed,0,0.920660674571991
695736026,10851,lkokhreidze,2021-08-25T13:10:27Z,fixed,0,0.920660674571991
700864299,10851,cadonna,2021-09-02T08:25:40Z,"although we never use the returned value from a standby task assignor, i would return `false` since a standby task assignment will never require a follow-up probing rebalance.",0,0.9927338361740112
700905553,10851,cadonna,2021-09-02T09:18:37Z,map `statefultaskswithclients` is only used to iterate over its entries. i think it would be better to use the following nested loops and remove `statefultaskswithclients`: [code block],0,0.9920986890792847
700910355,10851,cadonna,2021-09-02T09:25:03Z,i do not understand why you re-add `clientsonalreadyusedtagdimensions`. those clients were not modified and not polled for sure due to line 140.,0,0.8719902634620667
700917243,10851,cadonna,2021-09-02T09:33:57Z,"i think this map does not work for distinct tag keys that have overlapping tag values. for example, `key1` contains one of `{value1, value2}` and `key2` contains one of `{value2, value3}`.",0,0.9824435710906982
701068792,10851,cadonna,2021-09-02T13:12:40Z,"are you sure, because i cannot confirm the failure of the test on my side?",0,0.9841216802597046
701137236,10851,lkokhreidze,2021-09-02T14:26:05Z,"yeah, sorry. you're right. this is not needed.",-1,0.9916269779205322
701141903,10851,lkokhreidze,2021-09-02T14:30:51Z,"sorry, can you elaborate more on this? currently, when deciding the distribution, algorithm takes into account both, tag key, as well as tag value. so it will treat `key1: value2` and `key2: value2` as different dimensions. do you think it's something that has to be addressed?",-1,0.8867508172988892
701142976,10851,lkokhreidze,2021-09-02T14:32:05Z,pushed the changes.,0,0.9373136162757874
701143273,10851,lkokhreidze,2021-09-02T14:32:26Z,i've removed this line and pushed the changes.,0,0.9952488541603088
720193502,10851,cadonna,2021-10-01T12:12:59Z,"let's assume you have two clients. `clientx` has tags `keya:value1` and `keyb:value2` and `clienty` has tags `keya:value2` and `keyb:value3`. notice that `keya` and `keyb` share `value2`. with your code, we will end up with a `tagvaluetoclients` map that looks like this: [code block] now, let's assume that an active task is assigned to `clientx`. it would be totally fine if we assign the standby task to `clienty` since each tag key of both clients do not share a value. however, your algorithm does not allow it, because on line 198 it also adds `clienty` to the clients that are not allowed to get the standby. the reason is that `tagvaluetoclients` only looks for clients that contain value `value2` and not for clients that contain it as a value for `keya`. the following test fails because of this: [code block]",0,0.9850786924362183
720196549,10851,cadonna,2021-10-01T12:17:41Z,could you please use `tagvaluetoclients` and `tagkeytovalues` here as in the rest of the class?,0,0.9952151775360107
720214125,10851,cadonna,2021-10-01T12:46:53Z,"currently the code iterates over the active tasks and assigns all standby tasks for each active task. if the standby tasks cannot all be assigned, we might end up with all standby tasks assigned for some active task but none for others. what do you think about to assign one standby task for all active task and then assign the second standby task for all active task, and so on. in this way, it is more likely that at all active tasks have at least one standby task assigned. i am aware that the default standby assignor has the same drawback.",0,0.9770541787147522
741840561,10851,lkokhreidze,2021-11-03T11:18:42Z,"thanks, good catch.",1,0.9565211534500122
741896976,10851,lkokhreidze,2021-11-03T12:41:17Z,"makes sense . should i update default standby task assignor, or prefer to leave it out of scope of this pr?",0,0.9877344965934753
741897677,10851,lkokhreidze,2021-11-03T12:42:16Z,solved by storing tuple of tag key and value as map key instead of just tag value.,0,0.994222104549408
741923941,10851,lkokhreidze,2021-11-03T13:15:03Z,"also wondering if it's better to do this as a separate task altogether. since, as you've mentioned, it's the same behaviour as with default standby task assignor. but if you feel it's better to do it in current pr, happy to do so.",1,0.9541610479354858
765909088,10851,cadonna,2021-12-09T15:39:09Z,for each standby of a single active task the set `clientsonalreadyusedtagdimensions` is computed from scratch. i think this is not necessary since the clients on already used tag dimensions that we found for the first standby are still valid for the second standby and the clients on already used tag dimensions found for the second standby are still valid for the third standby and so on. this is true because we only add clients to the set `usedclients` but we never remove any. i think we can compute `clientsonalreadyusedtagdimensions` incrementally for each standby of a single active task instead of computing it from scratch each time.,0,0.9867181181907654
766104130,10851,cadonna,2021-12-09T19:48:26Z,"something does not work as expected in this algorithm. according to this doc, the assignor should fall back to distributing tasks on least-loaded clients. however, the following test case fails: [code block] the standby task for active task 0_0 can be put on client uuid_2 and the standby task for active task 0_1 can be put on client uuid_1 without breaking rack awareness constraints. standby tasks for active tasks 0_2 and 1_0 cannot be put on any client without breaking rack awareness, so they should be distributed on least-loaded clients. however, that does apparently not happen, because client uuid_3 and uuid_4 are not assigned any standby.",0,0.8959354758262634
789057202,10851,lkokhreidze,2022-01-20T18:46:16Z,fixed with e3aff39c7687a358cc8672accd5bbf6a27193a04. algorithm will try to achieve partial rack awareness as there are different `cluster` tag dimensions.,0,0.9945149421691895
789057904,10851,lkokhreidze,2022-01-20T18:47:15Z,fixed with e3aff39. now we only create `clientsonalreadyusedtagdimensions` once and populate it for the each standby task assignment instead of re-creating it.,0,0.9929096102714539
789060382,10851,lkokhreidze,2022-01-20T18:50:46Z,"hi would appreciate your feedback on this. as of now, algorithm ignores a case when client has reached capacity and it will try to assign the standby task to it as long as it satisfies the rack awareness. there's a even test for it `shoulddistributeclientsondifferentzonetagsevenwhenclientsreachedcapacity`. for me it makes sense that rack awareness, if configured, takes precedence in this case. added log to inform the user, just want to make sure if you think this is a valid approach. it is not a lot of work to take capacity into account, so we can redo algorithm if you think that makes more sense.",1,0.9439923763275146
789687365,10851,lkokhreidze,2022-01-21T14:09:22Z,"i reworked things a bit, check out this comment [a link]",0,0.9910138249397278
789687883,10851,lkokhreidze,2022-01-21T14:10:01Z,"no longer relevant, i reworked things a bit, check out this comment [a link]",0,0.9798038005828857
795434808,10851,lkokhreidze,2022-01-31T08:32:34Z,"answering why do we need this: i think with client tag aware standby task assignment, there's a much higher chance that we will overload some clients without this check. i think it's better to not to overload the clients and instead log the warning so users can do the needful of increasing the capacity in order to satisfy the rack awareness.",0,0.9907558560371399
805156426,10851,showuon,2022-02-12T12:31:47Z,could we add some java doc to this assign to briefly mention about the algorithm used in the assignor? thanks.,0,0.5389139652252197
805156641,10851,showuon,2022-02-12T12:34:04Z,"i know there was no any java doc for the default least load assignor. but do you think we can add some comments to it, just like in `clienttagawarestandbytaskassignor`? i believe not everyone knows default assignor algorithm is least loaded assignor.",0,0.9910206198692322
805157124,10851,showuon,2022-02-12T12:40:02Z,i'm wondering could we keep the original constructor and pass empty map into the new one? so that we don't have to make changes to the old caller. that is: [code block] wdyt?,0,0.9773979783058167
805199777,10851,cadonna,2022-02-12T20:12:02Z,"i see what you want to do. however, the capacity is the number of consumers on the streams client, i.e., the number of stream threads running on the streams client. with this check, you only allow to assign standby tasks to clients that have less tasks assigned as stream threads running. that is actually rather an unlikely case. normally, you have more tasks assigned to a streams client than the number of stream threads running on the client. i would keep it simple and ignore the balance for now.",0,0.9725874662399292
805203233,10851,cadonna,2022-02-12T20:51:21Z,would it be possible to decrement the numbers in `taskstoremainingstandbys` to maintain the remaining standbys to distribute instead of using `pendingstandbytasktonumberremainingstandbys`?,0,0.9935716390609741
805571500,10851,showuon,2022-02-14T07:43:02Z,maybe add a comment here to mention we need to make sure the sourceclient tag matches to destinationclient tag if rack tag is enabled...something like that.,0,0.986570417881012
805641183,10851,showuon,2022-02-14T09:19:10Z,is it normal when this happened? should we do anything to it? or at least log something here?,0,0.9873954057693481
805642565,10851,lkokhreidze,2022-02-14T09:20:51Z,"thanks for the feedback. no objections from my side. the reason why i avoided that was to make sure that client tags are always passed. to emphasise that it's mandatory parameter when constructing the `clientstate` object. please note that we have made `clientstate#clienttags` immutable; so there're no setters for the client tags. but if you feel like it's better to default to empty map, happy to change it. will wait for your response on this.",1,0.9849093556404114
805646942,10851,showuon,2022-02-14T09:25:59Z,"the variable name `polledclient` is unreadable. i think the variable is the client not having the same tag key/value, right? could we give it a more meaningful name, ex: `clientuuidnotonusedtagdimension`, or other better one if you have.",0,0.9669068455696106
805656409,10851,showuon,2022-02-14T09:36:51Z,"when reaching this point, we have tried our best to assign standby tasks with rack awareness to all clients. i think we should have a debug log here, to log some current status, like current assignment, `pendingstandbytasktonumberremainingstandbys`, `pendingstandbytasktoclientid`, and mention we're going to distribute the remaining tasks with least loaded assignor...etc, for better troubleshooting.",0,0.9892634749412537
805659384,10851,showuon,2022-02-14T09:40:16Z,"tbh, i don't understand this method well before i read into the implementation. i think the method is trying to assign standby tasks to those clients without using the same tag key/value, right? if so, maybe we can change the name to `assignstandbytaskstoclientswithoutsametag`, or others you can think of. wdyt?",0,0.8988813757896423
805663941,10851,showuon,2022-02-14T09:45:26Z,"looks like the `findclientsonusedtagdimensions` method keeps finding duplicated `usedclients`. that is, if we have 10 `numremainingstandbys`, we'll run `findclientsonusedtagdimensions` with 1 `usedclients` at first. and then, add one more, to have 2 `usedclients` at 2nd run, and add one to 3, 4, 5, ... 10. is my understanding correct? if so, could we improve it?",0,0.9833186864852905
805668921,10851,showuon,2022-02-14T09:50:57Z,"this is an internal class, so i think it won't be changed/used many times. i think change to my previous suggestion is better. thanks.",1,0.9835186004638672
805782141,10851,lkokhreidze,2022-02-14T12:13:21Z,i think having a warn log is a good call. we can add validation rules (if necessary) when doing last part of this kip - updating streams configuration.,1,0.7579079270362854
805830410,10851,lkokhreidze,2022-02-14T13:16:51Z,good call. i don't know how i missed that...,1,0.99320387840271
807660376,10851,lkokhreidze,2022-02-16T08:24:19Z,thanks! renamed to `clientonnotusedtagdimensions` to be consistent with the rest of the codebase. since we refer to client uuids as just `client` in the codebase. hope this works.,1,0.9954647421836853
807663879,10851,lkokhreidze,2022-02-16T08:28:41Z,makes sense. renamed to `assignstandbytaskstoclientswithdifferenttags`. hope this works too.,1,0.8887336850166321
807738730,10851,lkokhreidze,2022-02-16T09:50:45Z,refactored javadocs a bit. moved some content from class level javadoc to the `assign` method. hope this works.,1,0.9229415059089661
807810480,10851,lkokhreidze,2022-02-16T11:07:20Z,good call. improved the code in a latest commit.,1,0.9887661337852478
809711301,10851,showuon,2022-02-18T06:35:57Z,ok,0,0.9233372807502747
809773328,10851,showuon,2022-02-18T08:29:41Z,nit: the algorithm will fall back to the least-loaded clients without **taking** rack awareness constraints into consideration.,0,0.9740747213363647
809797947,10851,showuon,2022-02-18T09:02:01Z,"i checked the use of `tagkeytovalues`. it is only used for total value count of each key. is that right? if so, could we just store the `map tagkeytovaluecount` only?",0,0.9927103519439697
809798766,10851,showuon,2022-02-18T09:03:03Z,"sorry, i didn't understand the reason why we can't filter out clients located on that tag when `alltagvalues.size() <= countofusedclients`. could you help explain to me? thanks.",-1,0.978157103061676
809972865,10851,showuon,2022-02-18T12:54:02Z,nit: ` clienttagawarestandbytaskassignor` (no need the package name),0,0.9952409267425537
809980650,10851,showuon,2022-02-18T13:04:58Z,nit: close this bracket in the same line. that is: `private standbytaskassignmentutils() {}`,0,0.993931770324707
809983790,10851,showuon,2022-02-18T13:09:18Z,nit: indent issue. could we add comment in front of `empty_rack_aware_assignment_tags`?,0,0.9887414574623108
809984233,10851,showuon,2022-02-18T13:09:53Z,same as above.,0,0.9922299981117249
810003432,10851,lkokhreidze,2022-02-18T13:35:38Z,"can do, but also `set` makes it easier to handle duplicate values as we are looking for distinct count values here. not sure if refactoring is worth it though.",0,0.9537584781646729
810019916,10851,lkokhreidze,2022-02-18T13:54:59Z,"consider the following example [code block] with the above we have following number of unique tag values: [code block] now lets say we have standby replica count as `2` and we want to active task is located on `client 1` `usedclients=1` (because of the active task) ### 1st standby assignment during 1st standby takes assignment, we will exclude clients on following dimensions: [code block] used clients will get incremented since we can allocate the client on different `zone` and `cluster`. `usedclients=2` ### 2nd standby assignment we will have to exclude `zone: eu-central-1a and (eu-central-1b || eu-central-1c)` tag values. we can do that, because after we exclude clients on the new tag, we still have clients on the one free tag value we can assign the next standby to. we can't exclude `cluster` because we have already used two clients, and we just have two unique values for the `cluster` tag, so it's impossible to get the ideal distribution with this configuration and number of instances. so we can only achieve partial distribution. so idea of this check is to ignore tags where we have less unique values than the clients we have already used. if we don't have this check, for the 2nd standby task assignment we would have excluded all the clients located on `k8s-cluster1` and `k8s-cluster2`, and there wouldn't be any client left to assign the standby task to. we would fall back to the least loaded client, but there will be no guarantee that least loaded client assignment would honor partial rack awareness. hope this makes sense.",0,0.9925615191459656
810020380,10851,lkokhreidze,2022-02-18T13:55:34Z,i added `shoulddothepartialrackawareness` test to verify this behaviour.,0,0.994707465171814
810462108,10851,showuon,2022-02-19T07:58:08Z,"nit: could we be consistent with other tests that make the uuid_seq in order? it makes me a little confused when reading this test. that is, [code block]",-1,0.7683619260787964
810462515,10851,showuon,2022-02-19T08:02:43Z,"i can understand what you tried to assert here. but i think we should also assert that the standby tasks count in each client is as what we expected, because under current verification, we only focus on the tasks distributed with rack awareness. however, there is still possibility that standby tasks don't distribute evenly, right? the following tests should also update. thanks.",1,0.9657868146896362
810462817,10851,showuon,2022-02-19T08:06:49Z,"a ha, you're right! we only need the distinct count values. no need to refactor it then. thanks for the explanation.",1,0.9910520911216736
810464460,10851,showuon,2022-02-19T08:27:03Z,"in 1st standby assignment: usedclients=2 i think this used client should be 5 or 6, right? but i got your idea. thanks for the explanation. makes sense to me.",1,0.9839667677879333
810465176,10851,showuon,2022-02-19T08:35:58Z,"i'm thinking, we can make it much clear by adding comments, though i know this is hard to explain in simple words. how do you think we add comments like this: // if we have used more clients than all the tag's unique values, // we can't filter out clients located on that tag, because it'll excluded all the clients. // please check clienttagawarestandbytaskassignortest#shoulddothepartialrackawareness test for more info. and we can make more description in `shoulddothepartialrackawareness` test.",0,0.9467500448226929
810485747,10851,showuon,2022-02-19T12:29:59Z,"we can add comments here like: // we need 2 standby tasks (+ 1 active task) to distribute, but we only have 2 cluster tag, so we will won't exclude all clients when 2nd standby tasks assignment, and will try to distribute the 2nd standby tasks with taking partial rack tag into consideration. wdyt?",0,0.9927006959915161
810487017,10851,showuon,2022-02-19T12:43:36Z,"after your explanation of partial rack awareness, i can understand the distribution will be `uuid_5, uuid_6`. but i don't know why it's possible with the result `uuid_5, uuid_3`? i thought after 1st standby task assignment, we'll exclude `cluster_1` and `zone_1` tags clients. so the remaining clients will be `uuid_5, uuid_6`. therefore, the only possible results will be `uuid_5, uuid_6`. is my understanding correct? anything i missed? thanks.",1,0.9055125117301941
810487139,10851,showuon,2022-02-19T12:44:46Z,"and i think we should add some comments here, to have a simple explanation like we i did above to explain why we have these results. thanks.",1,0.9585573673248291
810857967,10851,lkokhreidze,2022-02-21T07:59:25Z,"`uuid_5` is essentially ""ideal"" distribution because it has both different cluster and zone compared to an active task. however, when we assign 2nd standby, we can only choose client on different `zone`. `cluster` tag is excluded as we don't have enough unique values to exclude the `cluster`. so for the 3rd standby task, both `cluster1` and `cluster2` are valid. that means that clients with `uuid_3` (`cluster1`, `zone3`) and `uuid_6` (`cluster2`, `zone3`) are valid destinations. on the high level, idea is that, if any of the values of the `cluster` tag goes offline, no matter on which `cluster` we distribute the 2nd standby `cluster1` or `cluster2`, we either way will loose two clients at the same time. so from availability perspective it doesn't make difference where the 2nd standby will be assigned. one may argue that it would be better to always distribute to a different tags compared to an active task, but this will complicate algorithm even further, so i guess it's better to keep it simpler in a first iteration. hope this makes sense, i will add more info as a comment.",0,0.9904038906097412
810894883,10851,lkokhreidze,2022-02-21T08:48:51Z,added more explanation in `shoulddothepartialrackawareness` test.,0,0.9940604567527771
811551306,10851,showuon,2022-02-22T03:33:07Z,nice tests!,1,0.9941598176956177
811556641,10851,showuon,2022-02-22T03:50:06Z,"nit: we can directly break the while when `numremainingstandbys == 0`, so that we don't need to run the redundant `findclientsonusedclienttagdimensions` in the last run. ex: [code block]",0,0.9927763938903809
811559765,10851,showuon,2022-02-22T03:59:48Z,"thanks for the explanation for partial rack awareness assignment. i think that algorithm makes sense. however, i don't think the implementation matches what you described. you said in the `shoulddothepartialrackawareness` test, in 2nd standby assignment for task_0_0, we will only consider `zone`, but in current implementation, we will also consider `cluster`. that is, when entering the `while (numremainingstandbys > 0) {` loop, the `clientsonalreadyusedtagdimensions` already excluded the `cluster_1` and `zone_1`. and in the 1st standby assignment, `uuid_5` will be chosen, we'll exclude `zone_2` only, and not exclude `cluster_2`. so , the only client left is `uuid_6`. that's the current design, isn't it? i don't see where we only consider `zone` in 2nd assignment. could you help elaborate more? thank you.",1,0.9674622416496277
811645496,10851,lkokhreidze,2022-02-22T07:30:21Z,"ah, you're absolutely right! i'm very sorry for the confusion. it's been a while and got lost myself. i will update comments to reflect this. do you think it makes sense to leave the implementation as is, or we should re-work it based on what i described before? either is fine with me.",-1,0.991550087928772
811651144,10851,showuon,2022-02-22T07:39:28Z,i think we should re-work the `assignstandbytaskstoclientswithdifferenttags` method to match what you described. that makes more sense. thanks.,1,0.9149194955825806
811652014,10851,lkokhreidze,2022-02-22T07:40:50Z,will get it done asap.,0,0.9498001933097839
811918321,10851,lkokhreidze,2022-02-22T12:58:07Z,updated implementation in [a link],0,0.9957082271575928
811964104,10851,cadonna,2022-02-22T13:48:33Z,wouldn't this be equivalent and maybe a bit more concise? [code block],0,0.9917556047439575
811981794,10851,cadonna,2022-02-22T14:06:40Z,"that is quite challenging to understand. after reading it a couple of times i understood that if we've used a number of clients that is equal to or greater than the number of unique values of the tag, we cannot guarantee that each standby is on a different tag value than the active and other standbys. so the rack-awareness becomes partial. is that correct? could you reformulate it, so that it states that the rack-awareness guarantee does not hold anymore. and why ""more clients than all tag's unique values""? when the number of used clients is equal to the unique tag values, we are already in the partial rack-awareness situation, right? maybe you should give here an example as in the mentioned test. i find referencing the test is a bit cumbersome, because if the test gets renamed this comment becomes useless.",-1,0.5560309886932373
812018771,10851,cadonna,2022-02-22T14:41:55Z,"i could not find where you decrement the number of remaining standbys. if you get a value from this map and put it into an `int` variable, you do not have a reference to the `integer` value in the map anymore. this might become a problem in `standbytaskassignmentutils#pollclientandmaybeassignremainingstandbytasks()`.",0,0.989693820476532
812081768,10851,lkokhreidze,2022-02-22T15:41:22Z,"thanks bruno, i'll add the example to the comment.",1,0.9179573059082031
812519265,10851,showuon,2022-02-23T02:42:38Z,nit: lastusedclient -> lastusedclient,0,0.991940438747406
812525667,10851,showuon,2022-02-23T03:03:49Z,"since we will remove tags, i think we can rename to `updateclieintsonalreadyusedtagentries`. wdyt?",0,0.9915115237236023
812527382,10851,showuon,2022-02-23T03:09:25Z,nice catch! and maybe we should add a test to address this.,1,0.9946293234825134
812527749,10851,showuon,2022-02-23T03:10:30Z,good suggestion!,1,0.991567075252533
812626201,10851,cadonna,2022-02-23T07:48:45Z,"yes, a test is absolutely necessary!",0,0.985004186630249
812720897,10851,lkokhreidze,2022-02-23T09:54:23Z,pushed the changes. i added detailed explanation with an example. also tests have the similar example. hopefully this change makes logic more clear.,0,0.616114616394043
812722151,10851,lkokhreidze,2022-02-23T09:55:49Z,"updated tests for the `standbytaskassignmentutils#pollclientandmaybeassignandupdateremainingstandbytasks` and also added separate test for the `clienttagawarestandbytaskassignor`. for the `clienttagawarestandbytaskassignor` i decided to make few things package private to be able to test this logic. as otherwise, there was no easy way to test if `taskstoremainingstandbys` was getting updated properly. hope this is okay.",1,0.9554611444473267
812884587,10851,showuon,2022-02-23T13:22:03Z,nit: additional space between `the` and `2nd`,0,0.9945861101150513
817629787,10851,cadonna,2022-03-02T12:08:36Z,"i think info log would also be ok here. i imagine users that are wondering why their standbys are not distributed as they would expect. with this information they can at least try to fix it on the config level. this log message should only happen at rebalance time, which should usually be rather seldom. if we decide to put the log message on info level, you should also change a bit the wording and not use variable names in it. maybe some hints what the users can do to fix this would also be nice. is it possible to separate the concerns of this log message and the one on line 135? something along the lines of here the rack-aware standby assignment did not work due the tag config and on line 135 the assignment did not work due to too low number of instances. we can then put both on warn or info (do not forget to also check the related log message in the default standby assignor).",1,0.7039505243301392
817650626,10851,cadonna,2022-03-02T12:37:25Z,this can be done in a follow-up pr: i am not a big fan of `// visible for testing` because it often means that we missed to extract code to separate classes. here i would definitely extract this code to a factory class.,0,0.9901561737060547
38823999,195,junrao,2015-09-06T17:45:05Z,it seems that it will be cleaner if we split this into getacls and getaclsfromzk. the former will just read from the cache and the latter always read from zk. only the zk listener will use the latter.,0,0.9855870008468628
38824003,195,junrao,2015-09-06T17:45:32Z,"hmm, this may not work well if two acl changes happen quickly. the second one will override the the resource of the previous one. if a broker hasn't finished processing the previous change, it will miss it after the override. i thought we wanted to use the same approach as in configchangelistener where the updates are written as a sequential zk node.",0,0.9596518874168396
38824005,195,junrao,2015-09-06T17:45:44Z,could we document the format of values used in the new zk paths in the comment?,0,0.9948081374168396
38824017,195,junrao,2015-09-06T17:46:19Z,"hmm, do we need this? it's simpler if we always rely on zk watchers to propagate the changes. zkclient will handle all the reconnects for us. if we lose a session, we probably have to read the aclchangedzkpath in case we missed a zk notification.",0,0.9790071249008179
38925968,195,ijuma,2015-09-08T13:40:40Z,"you can use `_` if you want a value to be initialised to the default one (eg `null`, `false`, `0`, etc.)",0,0.9948068261146545
38926011,195,ijuma,2015-09-08T13:41:01Z,type annotation is redundant in cases like this.,0,0.9740134477615356
38926146,195,ijuma,2015-09-08T13:42:22Z,"a less verbose and more idiomatic way to write this: `import scala.collection._` ... `private val aclcache = mutable.map.empty[resource, set[acl]]`",0,0.9833176136016846
38926413,195,ijuma,2015-09-08T13:44:50Z,"what if `str` is not a `string`? that case is not being handled. nicer code can be written if you use the scala version of the map (ie `config`). then `get` will return an `option` and you can use methods like `filter`, `map`, etc. that applies to the other code that is reading from the config.",0,0.9919306635856628
38926589,195,ijuma,2015-09-08T13:46:19Z,unnecessary type annotation,0,0.9069740176200867
38926656,195,ijuma,2015-09-08T13:46:52Z,"in scala, one should use `==` not `equals`.",0,0.9928312301635742
38926768,195,ijuma,2015-09-08T13:47:41Z,"instead of doing this, you should replace the for comprehension with `find`.",0,0.9937166571617126
38926812,195,ijuma,2015-09-08T13:47:57Z,"no `var` needed, `inreadlock` returns a value.",0,0.9943588376045227
38926927,195,ijuma,2015-09-08T13:49:10Z,`acljson.map(acl.fromjson).getorelse(set.empty)`,0,0.9942096471786499
39098212,195,Parth-Brahmbhatt,2015-09-09T21:22:02Z,done.,0,0.9897913336753845
39098585,195,Parth-Brahmbhatt,2015-09-09T21:25:46Z,"i am confused. i thought you said a watch notification will never be missed or it will only be missed when a reconnection happens which is handled by zkclient, which is why we don't need the sync thread. if client-a updated the /kafka-acl-chaged and set its data to ""topic-1"" (this should go throught zkquorum) and then client-b updated the /kafka-acl-changed and set its data to ""topic-2"" are you saying we will only get notification for ""topic-2"" depending on how fast the change occurs? doesn't that violate the first guarantee which led us to delete the hourly sync? i would like to point out that in the watch notification we are just relying on data sent as part of notification and not really reading /acl-changed one more time.",-1,0.9009444117546082
39099520,195,Parth-Brahmbhatt,2015-09-09T21:33:56Z,done.,0,0.9897913336753845
39099854,195,Parth-Brahmbhatt,2015-09-09T21:37:13Z,done.,0,0.9897913336753845
39100044,195,Parth-Brahmbhatt,2015-09-09T21:39:00Z,removed the whole scheduler.,0,0.9902613759040833
39100138,195,Parth-Brahmbhatt,2015-09-09T21:39:47Z,"as soon as i add that import all the other places that expect set starts complaining that ""set[x] can not be converted to set[x]"" which i am guessing is just scala compiler complaining that they expect the unmutable scala set but with the new import now they are all assumed to be mutable set. did i mention scala is amazing :-).",1,0.9894038438796997
39100385,195,Parth-Brahmbhatt,2015-09-09T21:41:58Z,fixed.,0,0.9905837774276733
39100572,195,Parth-Brahmbhatt,2015-09-09T21:43:37Z,done.,0,0.9897913336753845
39103033,195,Parth-Brahmbhatt,2015-09-09T22:06:08Z,"apart from returning true , given i also want to log the debug statement as a side effect, the version with find looks less redable imo.",0,0.9714199900627136
39103099,195,Parth-Brahmbhatt,2015-09-09T22:06:51Z,function is deleted given jun has recommended to assume that zkclient will handle reconnects and guarantee all the watchers are always delivered.,0,0.9943087697029114
39103189,195,Parth-Brahmbhatt,2015-09-09T22:07:41Z,done.,0,0.9897913336753845
39104580,195,Parth-Brahmbhatt,2015-09-09T22:21:52Z,removed and added listener for reconnection handler.,0,0.9942858815193176
39105224,195,Parth-Brahmbhatt,2015-09-09T22:29:24Z,handled the case where its not string by just adding another case.,0,0.993664026260376
39107202,195,junrao,2015-09-09T22:55:07Z,"parth, zk watchers are actually one-timer watchers ([a link] when a watcher fires, the client has to register the watcher again (typically through a read) to get notification for future changes. between the time that a watcher fires and the client does a read, multiple changes could have happened. the read will return the latest value and leave a watcher there. so, in general, there is no guarantee that every change triggers the firing of a watcher. in particular, if you update the value of a zk path multiple times in between, only the latest value will be seen by the reader. one way to capture all changes is to follow how we propagate the config changes (configchangelistener). whenever we change an acl, we write the acl under /kafka-acl and also write a sequential zk node under /kafka-acl-changed. the value of the sequential zk node indicates the resource for which the acl has changed. the sequential zk nodes are guaranteed to be unique and have a number suffix that's ever growing. the acl manager registers a child change listener on /kafka-acl-changed and remembers the last number suffix that it has processed. when the watcher fires, the acl manager reads all child nodes under /kafka-acl-changed (the read may pick up multiple acl changes) and process new nodes after the last remembered number suffix. the processing will involve reading the latest acl associated with the corresponding resource. since every sequential node is unique, the acl manager won't miss any acl change. on initialization, the acl manager will first register the watcher and read all existing acls. finally, we need a way to garbage collect old sequential nodes. this can be done by just removing sequential nodes that are say, more than 15 mins old (assuming every broker would have picked up the acl changes by then).",0,0.9761990308761597
39112549,195,Parth-Brahmbhatt,2015-09-10T00:08:18Z,thanks for the explanation and it makes perfect sense. will update the pr.,1,0.9925434589385986
39349577,195,junrao,2015-09-13T17:06:25Z,typo immeditatly,0,0.9877948760986328
39349578,195,junrao,2015-09-13T17:06:32Z,need to either remove those pirintlns or convert them to logging.,0,0.9866127967834473
39349582,195,junrao,2015-09-13T17:06:39Z,perhaps we can include path and notifications in the error message.,0,0.9869502186775208
39349583,195,junrao,2015-09-13T17:06:47Z,we probably should rename this to /kafka-acl-changes.,0,0.9880080223083496
39349584,195,junrao,2015-09-13T17:06:50Z,"perhaps rename this to ""acl_changes_""?",0,0.9931407570838928
39349586,195,junrao,2015-09-13T17:07:03Z,probably rename this as javaconfigs. then we can define the scala one as configs.,0,0.9911892414093018
39349587,195,junrao,2015-09-13T17:07:08Z,perhaps it's better to explicitly assign the initial values than using _.,0,0.9871537089347839
39349588,195,junrao,2015-09-13T17:07:13Z,"to be consistent, use set.empty[kafkaprincipal] instead of set.empty?",0,0.995165228843689
39349592,195,junrao,2015-09-13T17:07:27Z,perhaps we can allow zkconnectiontimeout and zksessiontimeout to be configured explicitly for simpleauthorizer and default to those in kafkaconfig if not specified.,0,0.9850897789001465
39349604,195,junrao,2015-09-13T17:08:01Z,"i had a comment in the jira. it seems that in socketserver, when creating the session object, it's better to create a kafkaprincipal instead of using kafkachannel.principal(). the type in kafkaprincipal should always be user and the name should be kafkachannel.principal().getname(). then, we can just get the kafkaprincipal from session and don't need to create a new one.",0,0.987920880317688
39349608,195,junrao,2015-09-13T17:08:24Z,"this is useful for things like auditing. perhaps we can log this in the end together with the decision on wether the operation is granted on not. also, could we put that into a separate authorization log4j logger (take a look at the request logger in log4j.properties)? that way, if people want auditing, they can just enable the authorization logger.",0,0.9795485734939575
39349609,195,junrao,2015-09-13T17:08:29Z,should this be removed?,0,0.991104006767273
39349610,195,junrao,2015-09-13T17:08:32Z,can this be private?,0,0.9927625060081482
39349611,195,junrao,2015-09-13T17:08:35Z,can this be private?,0,0.9927625060081482
39349613,195,junrao,2015-09-13T17:08:38Z,can this be private?,0,0.9927625060081482
39349614,195,junrao,2015-09-13T17:08:39Z,can this be private?,0,0.9927625060081482
39349615,195,junrao,2015-09-13T17:08:46Z,this needs to be removed.,0,0.9498100876808167
39349616,195,junrao,2015-09-13T17:08:54Z,"since these two are accessed from different threads, do they need to be volatile?",0,0.9889208078384399
39349633,195,junrao,2015-09-13T17:10:50Z,"ideally, we want to reuse this class in dynamicconfigmanager. if that's too much to do in this jira, could you file a follow-up jira to address this?",0,0.994840681552887
39439189,195,Parth-Brahmbhatt,2015-09-14T19:58:22Z,i like the idea of changing type of principal in session as kafkaprincipal. i dont agree with the type being always user as different authentication schemes may want to change that and different authorizer implementations may actually use the values differently. does that sound ok?,0,0.6596073508262634
39445926,195,Parth-Brahmbhatt,2015-09-14T20:56:26Z,fixed,0,0.920660674571991
39445928,195,Parth-Brahmbhatt,2015-09-14T20:56:27Z,was planning to do the same. filed kafka-2547,0,0.9952688813209534
39445934,195,Parth-Brahmbhatt,2015-09-14T20:56:30Z,removed debug statement.,0,0.9920921921730042
39445938,195,Parth-Brahmbhatt,2015-09-14T20:56:32Z,done.,0,0.9897913336753845
39445952,195,Parth-Brahmbhatt,2015-09-14T20:56:37Z,done,0,0.8682363629341125
39445961,195,Parth-Brahmbhatt,2015-09-14T20:56:39Z,done,0,0.8682363629341125
39445971,195,Parth-Brahmbhatt,2015-09-14T20:56:41Z,done.,0,0.9897913336753845
39445975,195,Parth-Brahmbhatt,2015-09-14T20:56:43Z,done.,0,0.9897913336753845
39445980,195,Parth-Brahmbhatt,2015-09-14T20:56:45Z,done.,0,0.9897913336753845
39445984,195,Parth-Brahmbhatt,2015-09-14T20:56:47Z,done,0,0.8682363629341125
39446002,195,Parth-Brahmbhatt,2015-09-14T20:56:55Z,"any time we allow or deny we already log the decision and the reasoning behind it, the trace is actually just to mark the entry point. modified log4j but i have set the default level at warn which will disable audit logging by default. let me know if you want it to be enabled by default.",0,0.9943767786026001
39446007,195,Parth-Brahmbhatt,2015-09-14T20:56:58Z,done.,0,0.9897913336753845
39446014,195,Parth-Brahmbhatt,2015-09-14T20:57:01Z,done,0,0.8682363629341125
39446020,195,Parth-Brahmbhatt,2015-09-14T20:57:03Z,done,0,0.8682363629341125
39446024,195,Parth-Brahmbhatt,2015-09-14T20:57:05Z,done,0,0.8682363629341125
39446032,195,Parth-Brahmbhatt,2015-09-14T20:57:06Z,done,0,0.8682363629341125
39446038,195,Parth-Brahmbhatt,2015-09-14T20:57:09Z,done,0,0.8682363629341125
39446049,195,Parth-Brahmbhatt,2015-09-14T20:57:14Z,done,0,0.8682363629341125
39468051,195,junrao,2015-09-15T02:06:53Z,"since we return early in a few places, it seems that not all accesses are logged.",0,0.9898186326026917
39468196,195,junrao,2015-09-15T02:10:07Z,"hmm, how do we get the type from the authentication layer? currently, authenticator only returns a principal, which just has a name?",0,0.9806293249130249
39538158,195,Parth-Brahmbhatt,2015-09-15T17:19:17Z,"i rechecked to assure it is logged in all cases (superuser, no acls, deny acl match(as part of matching function), allow acl match(as part of matching function), no acl found). if we want it to be logged at the end, i can change the logic so it does not return in middle. may be its just me, i think the current way looks cleaner.",0,0.8353158831596375
39543626,195,Parth-Brahmbhatt,2015-09-15T18:00:01Z,"i was saying we change the type in authenticator interface to kafkaprincipal. then each authenticator implementation can add its own type (ssl can set principaltype=certificate, and kerberos based sasl can set type= user) as long as the authorizer they use can handle different types they will be fine. this will specifically useful when there are multiple listeners. i guess we can just do what you are suggesting for now and if we encounter a real use case we can change the type in authenticator at that time. i have made the changes you suggested for now.",0,0.9727033376693726
39591781,195,junrao,2015-09-16T03:54:26Z,"getacls should be getaclsfromzk, right? could we add a unit test to test the initial loading?",0,0.994827926158905
39630946,195,ijuma,2015-09-16T13:48:46Z,why not import `javaconverters._` along with other imports at the top of the file and then simply do `changes.asjava` here and delete all local imports?,0,0.9931085109710693
39631044,195,ijuma,2015-09-16T13:49:34Z,we normally include `()` for side-effecting changes.,0,0.9921958446502686
39631152,195,ijuma,2015-09-16T13:50:24Z,it's generally better to do `notifications.nonempty` because it's o(1) even if the underlying implementation has a o(n) `size` (like scala.list).,0,0.9910545945167542
39632552,195,ijuma,2015-09-16T14:00:47Z,early return inside a closure (and a for comprehension desugars to `foreach`) actually involves throwing a `nonlocalreturncontrol` exception. you don't think the following is more readable? [code block],0,0.9902567863464355
39633336,195,ijuma,2015-09-16T14:06:56Z,`unit.` should not be part of package name.,0,0.9892851710319519
39633374,195,ijuma,2015-09-16T14:07:14Z,`unit` should not be part of package name,0,0.9941291809082031
39683091,195,Parth-Brahmbhatt,2015-09-16T20:48:48Z,done. sorry about missing this in first place. added the test for load cache.,-1,0.9941626191139221
39683115,195,Parth-Brahmbhatt,2015-09-16T20:48:54Z,done.,0,0.9897913336753845
39683121,195,Parth-Brahmbhatt,2015-09-16T20:48:56Z,done,0,0.8682363629341125
39683126,195,Parth-Brahmbhatt,2015-09-16T20:48:58Z,done,0,0.8682363629341125
39683134,195,Parth-Brahmbhatt,2015-09-16T20:49:03Z,may be i am missing it but where do you see the side effect?,0,0.9714193344116211
39683137,195,Parth-Brahmbhatt,2015-09-16T20:49:07Z,done.,0,0.9897913336753845
39683204,195,Parth-Brahmbhatt,2015-09-16T20:49:40Z,added a consistent audit log message in addition to the other logging statements.,0,0.9947755336761475
39683466,195,Parth-Brahmbhatt,2015-09-16T20:51:45Z,"the original version is more readable to me, may be its just my java brain. i have assumed scala idioms make it more redable with your approach so changed it as you suggested. still had to use a return inside the map as acl is not an option but type acl.",0,0.9709627032279968
39684697,195,ijuma,2015-09-16T21:02:19Z,"`milliseconds()` returns a different result every time, so it's a side-effecting method (it gets data from the system clock typically). side-effect free methods always return the same result given the same arguments, so a method that takes no parameters and doesn't return a constant result is a side-effecting method.",0,0.9898514747619629
39769987,195,Parth-Brahmbhatt,2015-09-17T16:55:54Z,my understanding of what side effect is different than what you described. i have added the () anyways given i don't really think it affects readability one way or another.,0,0.9796262383460999
39771350,195,ijuma,2015-09-17T17:08:07Z,it is true that the terminology would be clearer if we used pure versus impure functions. thanks for making the change anyway.,1,0.942405104637146
39778562,195,Parth-Brahmbhatt,2015-09-17T18:06:46Z,"i actually had to remove the bracket for compilation to succeed. with the beackets i get ""/users/pbrahmbhatt/repo/kafka/core/src/main/scala/kafka/common/zknodechangenotificationlistener.scala:80: long does not take parameters val now = time.milliseconds()""",0,0.9942805767059326
39779399,195,ijuma,2015-09-17T18:13:07Z,sorry for this. the reason is that the scala version of `time` has a method called `milliseconds` so you can't use `()` at the end. the java version of `time` doesn't have this issue.,-1,0.9902488589286804
39812216,195,junrao,2015-09-17T23:45:04Z,"it seems that we don't need both imports on javaconversions? import scala.collection.javaconversions._ seems enough. also, i think the previous version you had to just do the import inside processallnotifications() is better since it makes it clear where the implicits are used.",0,0.9743709564208984
39812243,195,junrao,2015-09-17T23:45:18Z,": i actually find the ""for-loop"" version that parth wrote earlier easier to understand. map() is supposed to convert one collection to another and it seems it's weird to return from inside a map().",-1,0.950874388217926
39812253,195,junrao,2015-09-17T23:45:25Z,why are we looping through resourcenames twice?,0,0.9826704859733582
39812263,195,junrao,2015-09-17T23:45:32Z,could we put addacls() and waituntiltrue() in a private method and reuse?,0,0.9937506318092346
39812389,195,ijuma,2015-09-17T23:47:33Z,i agree that this version looks worse. it's not what i suggested. :) a `getorelse` after the map is what i would do. do you still prefer the previous version in that case?,1,0.9937558174133301
39812505,195,ijuma,2015-09-17T23:49:14Z,", why not simply use import javaconverters._? it's the recommended way since it was introduced years ago. the main advantage is that it is both explicit (one has to use `asscala` or `asjava`) and you don't need scoped imports everywhere (which are quite verbose).",0,0.9755510091781616
39813672,195,ijuma,2015-09-18T00:08:46Z,"to elaborate a bit, `return` is discouraged in scala because it's not composable which makes it harder to refactor code safely. once `return` is used, it is no longer safe to extract code into reusable functions. another problem with `return` is that it uses exceptions for control flow once used inside closures (which are everywhere in scala) as it is the only way to implement the specified behaviour in the jvm. unfortunately, return is used quite a lot in this pr. i'd be willing to submit a pr to this branch that removed all usages of `return` for comparison if there is interest.",0,0.9136160612106323
39813673,195,junrao,2015-09-18T00:08:46Z,using explicit javaconverters will be fine.,0,0.9919963479042053
39813766,195,junrao,2015-09-18T00:10:24Z,could you post the exact syntax you had in mind?,0,0.993902325630188
39814098,195,ijuma,2015-09-18T00:16:15Z,[code block] or [code block] the latter is more concise although we don't use it much in kafka yet.,0,0.9876176714897156
39862295,195,junrao,2015-09-18T14:46:40Z,"it would be better to move this inside processallnotifications() so that we know exactly where the implicits are used. alternatively, we can use the explicit conversion through javaconverters as isamel suggested.",0,0.9930030703544617
39862320,195,junrao,2015-09-18T14:46:48Z,could we just return boolean here?,0,0.9926043748855591
39862560,195,junrao,2015-09-18T14:48:44Z,"it seems that if filteredacls is empty, we want to remove the corresponding acl path. could we add a unit test for that? also, we probably only need to update zk if filteredacls is different from existingacls.",0,0.9915533661842346
39862611,195,junrao,2015-09-18T14:49:15Z,"could we make this more general to sth like the following? then we can remove all individual usage of waituntiltrue(). // return the new acl set after applying the changes to the original acl. changeaclandverify(originalacl: set[acl], addedacl: set[acl], removedacl: set[acl]): set[acl]",0,0.9952341914176941
39862755,195,ijuma,2015-09-18T14:50:22Z,is this used anywhere?,0,0.9940593242645264
39863387,195,ijuma,2015-09-18T14:55:29Z,`exists` is probably better than `find` here as you are not using the value. maybe something like [code block],0,0.992849588394165
39863729,195,ijuma,2015-09-18T14:58:33Z,"a number of typing annotations that could be removed as they are easily inferred (`string`, `set[acl]`, `acl`). it's ok to keep them if you think they help readability (as opposed to just java habits ;)).",1,0.8080847263336182
39864202,195,ijuma,2015-09-18T15:02:28Z,"remove type annotation on the left-hand side? also, you can replace `hashmap` with `map` which is the static factory method.",0,0.9944369792938232
39864888,195,ijuma,2015-09-18T15:08:31Z,`aclcache.values.flatmap(_.filter(_.principal == principal)).toset` should do the same as all of the lines above. the following is a bit more readable though: `aclcache.values.flatmap(aclset => aclset.filter(_.principal == principal)).toset`,0,0.9920869469642639
39884655,195,Parth-Brahmbhatt,2015-09-18T18:15:57Z,done,0,0.8682363629341125
39884657,195,Parth-Brahmbhatt,2015-09-18T18:16:00Z,done.,0,0.9897913336753845
39885138,195,Parth-Brahmbhatt,2015-09-18T18:20:36Z,we were not deleting the zookeeper path until an explicit call to remove(resource was made). i have changed that and added unit test. to read the zookeeper path i made the method toresourcepath public.,0,0.9946973323822021
39885146,195,Parth-Brahmbhatt,2015-09-18T18:20:41Z,done,0,0.8682363629341125
39885153,195,Parth-Brahmbhatt,2015-09-18T18:20:47Z,in the initialize we register this zkclient so in case a reconnection happens zkclient will invoke this method and as part handling a new session it will process any missed notifications during the reconnection.,0,0.9948871731758118
39885157,195,Parth-Brahmbhatt,2015-09-18T18:20:49Z,done.,0,0.9897913336753845
39885181,195,Parth-Brahmbhatt,2015-09-18T18:21:03Z,"java habits, nothing really to do with readability :-). guess it's going to take me sometime before i stop doing this.",1,0.9693921804428101
39885186,195,Parth-Brahmbhatt,2015-09-18T18:21:08Z,removed the type. trying to convert to map actually gives compilation error.,0,0.9705259203910828
39885345,195,Parth-Brahmbhatt,2015-09-18T18:22:42Z,"i actually realized one thing, given acl class itself does not have resource as acls are suppose to be attached to a resource, this method is pretty useless unless it returns a map[resource, set[acl]]. i have made the changes to both the interface and the implementation to reflect that.",0,0.9358646869659424
39893276,195,junrao,2015-09-18T19:42:14Z,empty set => empty map,0,0.990817666053772
39893280,195,junrao,2015-09-18T19:42:17Z,space after if,0,0.9908820390701294
39893304,195,junrao,2015-09-18T19:42:36Z,has a valid point. it doesn't seem reconnection is ever used? the handling of the reconnection logic is all in handlenewsession().,0,0.9886442422866821
39893656,195,Parth-Brahmbhatt,2015-09-18T19:46:58Z,sorry i though he was referring to zkstatechangelistener object itself. removed.,-1,0.9851109385490417
39893666,195,Parth-Brahmbhatt,2015-09-18T19:47:01Z,done.,0,0.9897913336753845
39893669,195,Parth-Brahmbhatt,2015-09-18T19:47:03Z,done.,0,0.9897913336753845
39931619,195,junrao,2015-09-20T16:30:51Z,"startup() implies this class will have internal threads, but it doesn't. would it be better to rename this to init()?",0,0.9895076155662537
39931623,195,junrao,2015-09-20T16:31:00Z,"to be consistent with the line in 86, set.empty => set.empty[kafkaprincipal]?",0,0.9949883222579956
39931626,195,junrao,2015-09-20T16:31:27Z,"the ordering can be a bit subtle here. in order not to miss a session expiration event, we should probably use the following ordering. zkclient = zkutils.createzkclient(zkurl, zkconnectiontimeoutms, zksessiontimeoutms) zkutils.makesurepersistentpathexists(zkclient, simpleaclauthorizer.aclzkpath) [code block]",0,0.9906001091003418
39931632,195,junrao,2015-09-20T16:31:36Z,"we should add the acl to aclcache, right? could we add a unit test to cover this?",0,0.9941592216491699
39931641,195,junrao,2015-09-20T16:32:10Z,"it seems that we expect notificationmessage to be non-empty. so, perhaps we can change the type of processnotifications to be just string and in zknodechangenotificationlistener.processnotifications(), log a warning (with the path) if the data read from zk is empty.",0,0.9908588528633118
39931644,195,junrao,2015-09-20T16:32:21Z,"simpleaclauthorizer should be authorizer? also, we should add a loadcache() tests where all the nodes in /acl_changes are gone.",0,0.9922709465026855
40006553,195,Parth-Brahmbhatt,2015-09-21T18:24:46Z,done.,0,0.9897913336753845
40006570,195,Parth-Brahmbhatt,2015-09-21T18:24:52Z,done.,0,0.9897913336753845
40006588,195,Parth-Brahmbhatt,2015-09-21T18:25:01Z,done.,0,0.9897913336753845
40006914,195,Parth-Brahmbhatt,2015-09-21T18:27:34Z,"originally i did that but i figured given we havent added add,remove apis in reality add/remove calls will be made from cli so modifying cache did not make much sense. also it seemed cleaner to just have a single path (notification) that updated the cache and also made it easy to test. i have made changes to update the cache as you suggested but i don't see given the same state can be modified by 2 components there is any easy way to add unit test to ensure which component actually made the state change.",0,0.9776521325111389
40006927,195,Parth-Brahmbhatt,2015-09-21T18:27:42Z,done.,0,0.9897913336753845
40006945,195,Parth-Brahmbhatt,2015-09-21T18:27:51Z,done.,0,0.9897913336753845
40020498,195,junrao,2015-09-21T20:20:35Z,"this can just be private def loadcache() { ... } there are a few other places that we can get rid of "": unit ="".",0,0.9953604340553284
40020520,195,junrao,2015-09-21T20:20:49Z,"we shouldn't be accumulating in acls, right?",0,0.971278965473175
40020555,195,junrao,2015-09-21T20:21:04Z,could we set up two resources with acl to cover the new issue identified in loadcache()?,0,0.9944559931755066
40020567,195,junrao,2015-09-21T20:21:09Z,space after if,0,0.9908820390701294
40022804,195,Parth-Brahmbhatt,2015-09-21T20:40:13Z,done.,0,0.9897913336753845
40022808,195,Parth-Brahmbhatt,2015-09-21T20:40:14Z,done,0,0.8682363629341125
40022814,195,Parth-Brahmbhatt,2015-09-21T20:40:18Z,"yes, done.",0,0.9739049077033997
40022826,195,Parth-Brahmbhatt,2015-09-21T20:40:24Z,done.,0,0.9897913336753845
40027139,195,junrao,2015-09-21T21:16:44Z,"remove "": unit =""",0,0.9946587681770325
40027169,195,junrao,2015-09-21T21:17:02Z,"if a method has no return value, we need to define it as the following w/o =. otherwise, it will pick up the value in the last statement as the return value. ditto in a few other places. def loadcache() { }",0,0.994045615196228
40028686,195,Parth-Brahmbhatt,2015-09-21T21:28:35Z,done.,0,0.9897913336753845
40028689,195,Parth-Brahmbhatt,2015-09-21T21:28:37Z,done.,0,0.9897913336753845
40035419,195,junrao,2015-09-21T22:35:14Z,remove =,0,0.9911230802536011
40035425,195,junrao,2015-09-21T22:35:20Z,remove =,0,0.9911230802536011
40035432,195,junrao,2015-09-21T22:35:25Z,remove =,0,0.9911230802536011
40035437,195,junrao,2015-09-21T22:35:29Z,remove =,0,0.9911230802536011
40035443,195,junrao,2015-09-21T22:35:33Z,remove =,0,0.9911230802536011
40035455,195,junrao,2015-09-21T22:35:40Z,testprocessnotification(),0,0.9933499693870544
40035464,195,junrao,2015-09-21T22:35:47Z,def testtopicacl() {,0,0.9915845394134521
40035473,195,junrao,2015-09-21T22:35:52Z,def testdenytakesprecedence() {,0,0.9928351044654846
40035480,195,junrao,2015-09-21T22:35:55Z,def testallowallaccess() {,0,0.9921561479568481
40035489,195,junrao,2015-09-21T22:36:01Z,def testsuperuserhasaccess() {,0,0.9911372661590576
40035496,195,junrao,2015-09-21T22:36:05Z,def testnoaclfound() {,0,0.9917717576026917
40035506,195,junrao,2015-09-21T22:36:13Z,def testnoaclfoundoverride() {,0,0.992021381855011
40035514,195,junrao,2015-09-21T22:36:19Z,def testaclmanagementapis() {,0,0.9918501973152161
40035523,195,junrao,2015-09-21T22:36:24Z,def testloadcache() {,0,0.9911080598831177
113242905,2910,ijuma,2017-04-25T16:19:38Z,seems like passing `isolationlevel` explicitly is a good idea anyway. maybe we don't need this comment.,0,0.9444455504417419
113243316,2910,ijuma,2017-04-25T16:21:24Z,"if we don't use `buffer` in this path, do we still want to allocate it eagerly?",0,0.989680826663971
113244042,2910,ijuma,2017-04-25T16:24:27Z,you could use `map` instead of pattern matching.,0,0.994421660900116
113244445,2910,ijuma,2017-04-25T16:26:03Z,maybe this block should be in a separate method.,0,0.9738019108772278
113244887,2910,ijuma,2017-04-25T16:27:41Z,nit: just use `filechannel.open` directly?,0,0.9913130402565002
113244991,2910,ijuma,2017-04-25T16:28:05Z,how do we go about deciding whether to use schema classes or writing to the buffer directly?,0,0.9904412031173706
113246179,2910,ijuma,2017-04-25T16:32:39Z,"a general comment about default values: we should consider carefully when to use them as they are a common source of bugs. when we use them, the compiler no longer ensures that we think about what the value should be.",0,0.9785745143890381
113247921,2910,hachikuji,2017-04-25T16:39:33Z,ack. was thinking the same thing when i was looking over this.,-1,0.566322386264801
113248857,2910,hachikuji,2017-04-25T16:43:30Z,"sure, we can push allocation into the other branch. this is technically a bug fix, by the way, since `log.read` can return `memoryrecords.empty`.",0,0.9906609654426575
113249530,2910,hachikuji,2017-04-25T16:46:28Z,"yeah, it was a tough call. there's only a handful of use cases for `isfromclient = false`, and the default is the more restrictive option, so i thought it was reasonable.",-1,0.5424594283103943
113253193,2910,hachikuji,2017-04-25T17:01:32Z,"kind of a subjective call, but since we scan the abort index when handling fetches and the schema is so simple, i thought we could skip the need to go through the `struct` object when reading and writing.",0,0.9624413251876831
113829442,2910,junrao,2017-04-28T00:08:43Z,"during append, perhaps it's useful to assert that abortedtxn are inserted in ascending lastoffset order?",0,0.9929856657981873
113830001,2910,junrao,2017-04-28T00:13:54Z,"we don't set the position of channel after channel.truncate(), which seems ok. for consistency, we probably want to do the same in filerecords.truncateto()?",0,0.9923685193061829
113830270,2910,junrao,2017-04-28T00:16:40Z,"it seems that we can just allocate a single buffer and reuse, instead of reallocating?",0,0.9890276193618774
113831097,2910,junrao,2017-04-28T00:25:40Z,we throw an exception in the iterator below. should we do the same thing here?,0,0.992833137512207
113832544,2910,junrao,2017-04-28T00:42:38Z,could we add some comments on what's stored in this index?,0,0.9943379759788513
113833158,2910,junrao,2017-04-28T00:49:14Z,it would be useful to document whether firstoffset and lastoffset are inclusive or exclusive.,0,0.9923977255821228
113834767,2910,junrao,2017-04-28T01:05:00Z,it seems that we are missing the logic to fence off the request based on coordinatorepoch?,0,0.9883936047554016
113834965,2910,junrao,2017-04-28T01:07:18Z,we can probably use requesttimeoutms.,0,0.9944816827774048
113836150,2910,junrao,2017-04-28T01:21:01Z,could we document the new field in the java doc above?,0,0.9943565726280212
113838187,2910,junrao,2017-04-28T01:47:43Z,could we add the new field to the comment above? ditto for line 485.,0,0.9956921935081482
113838217,2910,junrao,2017-04-28T01:48:05Z,"now that we have a few different types of epoch, could we change epoch to producerepoch?",0,0.9925971031188965
113972136,2910,junrao,2017-04-28T16:44:41Z,"could we add a method in recordbatch to indicate whether the batch is a controlled batch or not? also, it seems that we use a special sequence number to indicate whether a batch is controlled or not. would it be better to use another bit in the attribute for that?",0,0.993278443813324
114010900,2910,junrao,2017-04-28T20:14:09Z,epoch => producerepoch? ditto in line 54.,0,0.990915834903717
114013479,2910,junrao,2017-04-28T20:29:42Z,"there can only be one opening transaction from a pid, right? if so, does startedtxns need to be a set?",0,0.9941498041152954
114016660,2910,junrao,2017-04-28T20:48:04Z,"hmm, it seems because of this, we could be sending multiple responses for the same writetxnmarkersrequest, which won't be right?",0,0.9650707244873047
114018063,2910,junrao,2017-04-28T20:56:00Z,the spec says the value of the control record contains the coordinatorepoch.,0,0.9951913356781006
114018154,2910,junrao,2017-04-28T20:56:28Z,could we be calculate the buffer size more precisely?,0,0.9905266761779785
114035995,2910,junrao,2017-04-28T23:22:43Z,"hmm, when this is called on the leader side, we haven't assigned the offset for the record yet. it seems that this means the offset returned in appendinfo.completedtransactions will be incorrect when we try to use it?",0,0.9830657243728638
114036286,2910,junrao,2017-04-28T23:25:54Z,"when firstoffset is set to controlrecord.offset, it seems that lastoffset could be smaller than firstoffset. should we guard that?",0,0.9933806657791138
114038106,2910,junrao,2017-04-28T23:50:45Z,do we need to call this here given that we are calling the same method in onhighwatermarkincremented()?,0,0.9943629503250122
114039345,2910,junrao,2017-04-29T00:09:55Z,could we add isolationlevel to the comment above?,0,0.994143545627594
114039715,2910,junrao,2017-04-29T00:16:26Z,"we probably want to use the offset in fetchinfo instead of startoffset, which can be larger than startoffset?",0,0.9926735758781433
114040200,2910,junrao,2017-04-29T00:25:52Z,should we call updatefirstunstableoffset() in truncateto() too?,0,0.9944695234298706
114362367,2910,hachikuji,2017-05-02T16:29:01Z,i think we already do. it is in the call to `buildandrecoverpidmap`.,0,0.9889100193977356
114367045,2910,hachikuji,2017-05-02T16:48:37Z,the responses are accumulated and only sent after all callbacks have been received. i can change the name to clarify this.,0,0.9956804513931274
114367825,2910,hachikuji,2017-05-02T16:52:00Z,hmm.. yes that sounds right.,0,0.9223528504371643
114400313,2910,hachikuji,2017-05-02T19:11:25Z,i've fixed this. we always use the offset of the control record as the last offset.,0,0.9881536364555359
114460760,2910,junrao,2017-05-03T01:33:01Z,"getting the position requires index lookup and may be a bit expensive. do we really need to maintain position? it seems that when using firstunstableoffset, we only need the offset, not the position?",0,0.9748714566230774
114461895,2910,junrao,2017-05-03T01:49:48Z,"hmm, log.firstunstableoffset is only advanced after the completemarker has been fully replicated, which suggests that log.firstunstableoffset is always going to be < highwatermark?",0,0.9792706966400146
114614159,2910,hachikuji,2017-05-03T18:08:06Z,"i realized that we need all started transactions in order to ensure that the lso is updated correctly. we take all the started transactions from an append, add them to a sorted collection, and then remove the completed transactions in order of completion. this ensures that the lso is always correct.",0,0.9839836359024048
114662697,2910,junrao,2017-05-03T21:54:11Z,could we add a comment whether fetchoffset and upperboundoffset are inclusive or exclusive?,0,0.9948603510856628
114678287,2910,junrao,2017-05-03T23:45:30Z,"when we call roll(), the base offset of the new segment could actually be larger than logendoffset. so, in that case, the snapshot offset may not match the base offset of the next segment. since in flush(), we delete snapshots based on the baseoffset of the active segment, we may delete the last snapshot by accident. one way to fix this is to call producerstatemanager.updatemapendoffset(newoffset) before taking the snapshot.",0,0.98857182264328
114679141,2910,junrao,2017-05-03T23:53:23Z,"hmm, the comment in line 72 says completed txns are sorted by last offset, which seems to be what we want?",0,0.9734845757484436
114680532,2910,junrao,2017-05-04T00:05:19Z,the warn in line 312 now needs to include the tnx index.,0,0.9928011894226074
114681599,2910,junrao,2017-05-04T00:15:57Z,"this can be done later. but reloading the snapshot when recovering every segment can be expensive. since segments are recovered in order, it seems that we just need to load the snapshot on recovering the first segment.",0,0.9864650964736938
114683318,2910,junrao,2017-05-04T00:35:04Z,"hmm, in theory, it seems that we could have an abort marker with no open records before it?",0,0.9730994701385498
114685936,2910,junrao,2017-05-04T01:05:34Z,"hmm, instead of using hard-coded read_uncommitted, shouldn't we use the isolation_level in the fetcher?",0,0.9795225858688354
114688209,2910,junrao,2017-05-04T01:37:56Z,"hmm, not sure about the comment on hw. with kip-101, typically the truncation point is >= the local hw.",0,0.95355224609375
114882654,2910,hachikuji,2017-05-04T20:42:54Z,"ah, good catch. forgot to update this after the transactional client patch was merged.",1,0.9826689958572388
114899888,2910,hachikuji,2017-05-04T22:13:47Z,"sorting by the first offset is what we want. this is used to find the first unstable offset which will always be the minimum first offset of all transactions. i couldn't find the comment you were referring to since the patch was updated. if it still exists, can you point me to it?",0,0.9895646572113037
114900931,2910,hachikuji,2017-05-04T22:20:48Z,"hmm... good point. i had thought it was necessary since the first unstable offset could be lower than the high watermark, but we wouldn't be able to advance it any further from this write because any appended transaction markers could not have been replicated yet.",1,0.8658354878425598
114904376,2910,junrao,2017-05-04T22:44:15Z,"hmm, this logic may not be quite right for the follower. the follower could append batches for different pids in a single append call, if we reject all batches because a single batch is duplicated, the follower will miss records from other pids. in theory, duplicates should never happen in the follower. if duplicates somehow already leaked into the leader, it's kind of hard to not take the duplicates in the follower since the follower's log is supposed to be identical with the leader. so, perhaps we can only return on duplicates if the append is on the leader. if duplicates are detect in the follower, just log a warning but proceed with the append?",0,0.9249192476272583
114906482,2910,junrao,2017-05-04T22:59:59Z,"it's a bit inconsistent that we serialize the value here, but the key inside appendcontrolrecord(). perhaps it's better to serialize the value inside appendcontrolrecord() too?",0,0.9581579566001892
114916532,2910,junrao,2017-05-05T00:32:48Z,fetching up the the => fetching up to the,0,0.9908294677734375
114918036,2910,hachikuji,2017-05-05T00:52:14Z,"the intent was to return a duplicate only if `isfromclient` is set (which would never be the case for the follower), but it looks like i left that out. i'll fix in the next commit.",0,0.9913713932037354
114918859,2910,hachikuji,2017-05-05T01:04:36Z,"i was trying to keep `appendcontrolrecord` generic for future control record types. that said, it seems reasonable to add an `appendendtxnmarker` which handles serialization of both the key and value.",0,0.9897975921630859
115065007,2910,junrao,2017-05-05T18:51:10Z,do we need to get position from segment.append()? we could also just get the size of the segment before appending.,0,0.9936432838439941
115079600,2910,junrao,2017-05-05T20:17:21Z,it seems that undecidedfirstoffset should never be < unreplicatedfirstoffset?,0,0.9898567199707031
115080853,2910,junrao,2017-05-05T20:24:56Z,do we need to do this under lock since we are updating the state in producerstatemanager?,0,0.9940914511680603
115082326,2910,junrao,2017-05-05T20:33:58Z,are the callers all properly synchronized on log.lock?,0,0.9950167536735535
115088857,2910,junrao,2017-05-05T21:14:23Z,epoch => producerepoch ?,0,0.9928112626075745
115090409,2910,junrao,2017-05-05T21:24:45Z,should we print out an error in the else clause?,0,0.9904576539993286
115094046,2910,hachikuji,2017-05-05T21:50:01Z,"i think it is possible. you may have something like this: w1, w2, c2, c1 (where w1 is a write from producer 1, and c1 is a commit from producer 1). say the high watermark has reached c1 (which means the transaction from producer 1 is not yet visible). in this case, the first undecided offset will be w1 while the first unreplicated offset will be w2.",0,0.9750990867614746
115097120,2910,hachikuji,2017-05-05T22:15:31Z,i added some code to print the unknown type id in the else case. let me know if that seems reasonable.,0,0.9936913251876831
115099271,2910,hachikuji,2017-05-05T22:35:37Z,"the example was a little wrong. the proper scenario is this: w1, w2, c2 say the high watermark is at c2. the first undecided offset will be w1, but the first unreplicated offset will be w2. once the high watermark reaches c2+1, the first undecided offset will still be w1 and the first unreplicated offset will be empty.",0,0.9630711674690247
634023546,10579,satishd,2021-05-18T04:06:08Z,`config` definition will be moved to `kafkaconfig` later when default rlmm is integrated with the broker.,0,0.9947702288627625
640140543,10579,junrao,2021-05-26T21:40:19Z,"if the producer/consumer are configured incorrectly, we want to fail faster instead of retrying.",0,0.9626411199569702
640140766,10579,junrao,2021-05-26T21:40:51Z,"since producermanager and consumermanager are updated in a separate thread without holding lock, do they need to be volatile?",0,0.9924578666687012
640142495,10579,junrao,2021-05-26T21:44:24Z,should we pass in time through the constructor?,0,0.9932512640953064
640147224,10579,junrao,2021-05-26T21:54:14Z,do we need this since it's in the caller already?,0,0.9942732453346252
640148086,10579,junrao,2021-05-26T21:55:54Z,waiting for each event to be consumed reduces throughput. could we handle the expected metadata load with this?,0,0.9705673456192017
640154886,10579,junrao,2021-05-26T22:08:46Z,remotelogmetadatacontext => remotelogmetadata?,0,0.9940651655197144
640157247,10579,junrao,2021-05-26T22:12:05Z,no need to cast to kafkaexception.,0,0.9933089017868042
640158657,10579,junrao,2021-05-26T22:15:25Z,sending one event at a time reduces the batching benefit in the producer. could this handle the expected metadata load?,0,0.9913015961647034
640158995,10579,junrao,2021-05-26T22:16:09Z,could we add a comment for this class?,0,0.9953994154930115
640979693,10579,junrao,2021-05-27T21:28:06Z,typo ard,0,0.9723825454711914
640996146,10579,junrao,2021-05-27T21:56:15Z,"hmm, shouldn't we start with assignedmetapartitions?",0,0.9842521548271179
640997181,10579,junrao,2021-05-27T21:57:24Z,"hmm, assignedmetapartitions may not change if assignedtopicpartitions changes. should we still update assignedtopicpartitions in that case?",0,0.9855939745903015
641001043,10579,junrao,2021-05-27T22:04:49Z,from which offset does the consumer start fetching?,0,0.9931241869926453
641029590,10579,junrao,2021-05-27T23:10:00Z,should we only process events corresponding to assignpartitions?,0,0.9921903014183044
641030221,10579,junrao,2021-05-27T23:11:42Z,"if a partition is moved to a different broker, we will need to bootstrap the remote state for the partition by consuming from the beginning of the remote metadata partition. how is that handled?",0,0.9943984150886536
641031767,10579,junrao,2021-05-27T23:15:58Z,the tostring() method could change over time. perhaps it's safer to compute a customized hashcode for topicidpartition here.,0,0.9923468828201294
641034498,10579,junrao,2021-05-27T23:24:16Z,"bootstrap_servers_config should be prefixed with remote_log_metadata_client_prefix, right?",0,0.9936309456825256
641035399,10579,junrao,2021-05-27T23:26:54Z,do we need this? it seems that it's easier to just duplicate the property for producer and consumer.,0,0.9880742430686951
641093708,10579,junrao,2021-05-28T01:17:10Z,what's the purpose of waiting for consumption up to partitiontotargetendoffsets?,0,0.9916427135467529
642095193,10579,satishd,2021-05-30T15:53:03Z,making volatile makes sense to me.,0,0.948788583278656
642095217,10579,satishd,2021-05-30T15:53:14Z,done.,0,0.9897913336753845
642095239,10579,satishd,2021-05-30T15:53:34Z,removed the check as you suggsted.,0,0.9953990578651428
642095245,10579,satishd,2021-05-30T15:53:40Z,this method is invoked from multiple threads for different topic partitions. this will not be a bottleneck as each partition's segments will be uploaded in a sequential manner.,0,0.9944209456443787
642095258,10579,satishd,2021-05-30T15:53:47Z,it is needed as the method is declared with throws kafkaexception. i am also fine with removing it as it is a rte.,0,0.9852830171585083
642095262,10579,satishd,2021-05-30T15:53:51Z,multiple events are published by multiple threads and batching will occur in the producer.,0,0.9911879301071167
642095305,10579,satishd,2021-05-30T15:54:06Z,i will add that.,0,0.9894947409629822
642095309,10579,satishd,2021-05-30T15:54:11Z,are you saying it should be initialized with `updatedassignedmetapartitions = new hashset<>(assignedmetapartitions);`. this is not needed as we are recomputing that set based on updatedreassignedpartitions.,0,0.9934189915657043
642095314,10579,satishd,2021-05-30T15:54:14Z,"nice catch, updated.",1,0.9851020574569702
642095350,10579,satishd,2021-05-30T15:54:28Z,we have not yet added the code to store the consumed offset and start from those offsets whenever the consumer starts fetching from those partitions. we plan to add that in a subsequent pr.,0,0.9942261576652527
642095355,10579,satishd,2021-05-30T15:54:33Z,"right, i will add that check.",0,0.9939688444137573
642095359,10579,satishd,2021-05-30T15:54:36Z,this is not addressed in this pr. i planned to have a followup pr for these changes. i may use a different consumer for the newly subscribed partitions to build the state.,0,0.9942171573638916
642095367,10579,satishd,2021-05-30T15:54:44Z,"remote_log_metadata_client_prefix is just a prefix for generating client-ids for producer and consumer. if you are talking about the remote log metadata property prefix, it is assumed that the caller would have already removed those prefixes and sent the config. these prefixes are defined [a link]",0,0.9940166473388672
642095371,10579,satishd,2021-05-30T15:54:47Z,"this is to avoid duplicate entries for both the producer and consumer. we added that in the kip earlier. if duplicating is the way we use at other places if any, i am fine with that.",0,0.967610239982605
642095384,10579,satishd,2021-05-30T15:54:49Z,this is leftover code for other changes that i was working on for handling partition moving to a new broker in another branch. i will remove it.,0,0.9921446442604065
642095431,10579,satishd,2021-05-30T15:55:05Z,good point. i will add that.,1,0.9802748560905457
643693257,10579,kowshik,2021-06-02T06:40:28Z,s/set in close state/closed,0,0.9828316569328308
643693431,10579,kowshik,2021-06-02T06:40:47Z,s/metadatapartitionno/metadatapartition,0,0.9905908703804016
643694704,10579,kowshik,2021-06-02T06:43:10Z,it appears you could eliminate the additional `topicidpartition` parameter and instead use the value returned by `remotelogmetadata.topicidpartition()` api.,0,0.9933050274848938
643695433,10579,kowshik,2021-06-02T06:44:35Z,it appears this class does not have unit tests currently. is there a plan to add unit tests?,0,0.9902039766311646
643698596,10579,kowshik,2021-06-02T06:50:35Z,could you pls add a comment for this class?,0,0.9954113364219666
643698781,10579,kowshik,2021-06-02T06:50:55Z,s/millis/ms,0,0.9915932416915894
643705660,10579,kowshik,2021-06-02T07:02:30Z,i had the same question. it appears better to just duplicate the properties.,0,0.9895911812782288
643707051,10579,kowshik,2021-06-02T07:04:58Z,"it seems that we have internal topics specified in `org.apache.kafka.common.internals.topic` class. don't we want this new internal topic to be defined in the `topic` class, together with other internal topics?",0,0.9924922585487366
643709758,10579,kowshik,2021-06-02T07:09:25Z,"hmm, why do you need this exclusion to be true?",0,0.972797155380249
643715269,10579,kowshik,2021-06-02T07:17:49Z,"is this the timeout for how long you'd want the client to wait to consume the message that it produces to `__remote_log_metadata` topic? if yes, then don't we want this timeout to be unlimited i.e. we wait as long as it takes to consume the published event?",0,0.9946764707565308
643716426,10579,kowshik,2021-06-02T07:19:37Z,"`consumerprops` and `producerprops` are of type `map`, therefore the `.tostring()` is probably not readable. so you'd need to convert these into a comma-separated list sth like `k1=v1,k2=v2,...kn=vn`.",0,0.9907556176185608
643725247,10579,kowshik,2021-06-02T07:32:18Z,"for readability, it'll be useful to place the positive case under `if` and negative case under `else`, such as: [code block]",0,0.991972804069519
643726313,10579,kowshik,2021-06-02T07:33:51Z,could you pls document the state does this boolean represents?,0,0.9937746524810791
643728635,10579,kowshik,2021-06-02T07:37:21Z,could you pls mention what state does this boolean represent?,0,0.993351936340332
643730668,10579,kowshik,2021-06-02T07:40:20Z,is it useful to assert that `record.key()` is empty before the key is ignored below?,0,0.9939601421356201
643731568,10579,kowshik,2021-06-02T07:41:36Z,"hmm, should you be setting `close` to true here? (it depends on the meaning of `close`, which i don't fully understand....)",0,0.8617109656333923
643736256,10579,kowshik,2021-06-02T07:48:14Z,"it appears that once this logic is implemented, there is probably no need to wait for `maybewaitforpartitionsassignment`. the reason is that whenever a partition is assigned, we will bootstrap the remote state by consuming from the beginning.",0,0.9896951913833618
643738304,10579,kowshik,2021-06-02T07:51:00Z,"do you really need this explicit lock? it seems you could just use `wait()` and `notify()` apis on the `consumertask` object instead, combined with `synchronized` keyword.",0,0.9912416934967041
643740157,10579,kowshik,2021-06-02T07:53:28Z,s/noofmetadatatopicpartitions/nummetadatatopicpartitions,0,0.9489759802818298
643740418,10579,kowshik,2021-06-02T07:53:46Z,s/partitionno/partition,0,0.9886638522148132
643740610,10579,kowshik,2021-06-02T07:54:02Z,s/no of.../num of... also it feels overkill to me to log this message for each call.,-1,0.8797847032546997
643742067,10579,kowshik,2021-06-02T07:55:59Z,"is topic necessary here, when uuid and partition is already sufficient input for the hash?",0,0.9930909872055054
643745043,10579,kowshik,2021-06-02T08:00:02Z,it seems these 2 attributes can be marked final if you call `map.clear()` in `close()` instead of replacing the reference.,0,0.9904266595840454
643746007,10579,kowshik,2021-06-02T08:01:17Z,s/logs/log ?,0,0.9916380047798157
643749217,10579,kowshik,2021-06-02T08:05:53Z,i agree with the question here. this can become more expensive than it seems. the alternative is to pursue an asynchronous notification model to improve the throughput.,0,0.9699735641479492
643754935,10579,kowshik,2021-06-02T08:14:07Z,could you pls add a comment on what state does `close` represent?,0,0.9944602251052856
648927106,10579,satishd,2021-06-10T07:36:25Z,"as we discussed offline, we see the benefit of keeping several common client config like security to be shared across producer and consumer props avoiding any copy/paste mistakes. user has an option not to use common client configs and use the respective producer and consumer configs.",0,0.982926607131958
649387317,10579,satishd,2021-06-10T17:30:15Z,i plan to add this once rlmm is called from remote log layer classes. i wanted this change to be self contained for now.,0,0.9929563999176025
649387744,10579,satishd,2021-06-10T17:30:37Z,we do not want this to be completely blocked as we want to release the remote log thread after a specific timeout in case of any intermittent issues so that other partitions tiring can proceed.,0,0.9864248037338257
649387805,10579,satishd,2021-06-10T17:30:40Z,"we are using hashmap for these instances and it prints k,v format. are you suggesting that this map implementation may change as it is of type map and need to put the right tostring. we can change the reference type to hashmap for clarity if needed.",0,0.9951704144477844
649388017,10579,satishd,2021-06-10T17:30:51Z,i do not think that check is really needed here.,0,0.9724887013435364
649388066,10579,satishd,2021-06-10T17:30:53Z,"it indicates whether the closing process has been started or not. if it is set as true, consumer will stop consuming messages and it will not allow partition assignments to be updated. updated the java doc of close.",0,0.9952452778816223
649388122,10579,satishd,2021-06-10T17:30:57Z,i wanted to have a separate lock instance specifically for the assignments and the respective processing. it gives better clarity and separations even if we add any other logic by taking lock on this instance.,0,0.9879677295684814
649388430,10579,satishd,2021-06-10T17:31:13Z,good point. we can skip topic as topic-id is sufficient here.,1,0.9609577059745789
649388497,10579,satishd,2021-06-10T17:31:16Z,i went with assigning empty map as map.clear() needs to go through all the entries and dereference them. another way is to leave the map as it is and set the cose state and do not allow any operation when it is closed but it will have a check for each call.,0,0.9916619062423706
649390143,10579,satishd,2021-06-10T17:32:50Z,done,0,0.8682363629341125
649390214,10579,satishd,2021-06-10T17:32:56Z,done,0,0.8682363629341125
649390292,10579,satishd,2021-06-10T17:33:03Z,done,0,0.8682363629341125
649390516,10579,satishd,2021-06-10T17:33:26Z,done.,0,0.9897913336753845
649390677,10579,satishd,2021-06-10T17:33:41Z,done,0,0.8682363629341125
650456266,10579,satishd,2021-06-13T01:49:18Z,done,0,0.8682363629341125
656734732,10579,ccding,2021-06-23T03:38:22Z,can we avoid making the variable name the same as the function name?,0,0.9933266639709473
656735781,10579,ccding,2021-06-23T03:42:06Z,"why is the variable name `partitions`, while the one above for `addassignmentsforpartitions` is `allpartitions`? also why one is `set` and the other is `hashset`?",0,0.992052435874939
656737032,10579,ccding,2021-06-23T03:46:28Z,i think in the codebase we use `ms` more often than using `millis`,0,0.9824364185333252
656737294,10579,ccding,2021-06-23T03:47:23Z,should this be fixed or configurable in `rlmmconfig`?,0,0.9941483736038208
656737888,10579,ccding,2021-06-23T03:49:16Z,`id` -> `if`,0,0.9926263689994812
656738264,10579,ccding,2021-06-23T03:50:38Z,"we may want a better variable name here. e.g., `isclosing` or `closed` or something else.",0,0.9881249666213989
656740556,10579,ccding,2021-06-23T03:57:00Z,"multiple threads are reading and writing `close`, which is not thread safe",0,0.670486569404602
656740892,10579,ccding,2021-06-23T03:58:12Z,"why is this set to 30, rather than another number like 10, 50, 100?",0,0.9799975156784058
656741851,10579,ccding,2021-06-23T04:01:33Z,is the check necessary?,0,0.9942346215248108
656743129,10579,ccding,2021-06-23T04:06:13Z,can you explain what this variable means?,0,0.9934300780296326
656744938,10579,ccding,2021-06-23T04:12:18Z,also here. why are the variable names different? one is `updatedpartitions` and the other is `partitions`,0,0.9946435689926147
656747158,10579,ccding,2021-06-23T04:19:48Z,what is the cost of consuming from the beginning if the remote metadata partition grows huge?,0,0.9835207462310791
656748094,10579,ccding,2021-06-23T04:22:44Z,"the function name is a little confusing with variable names in the same class, e.g., `assignpartitions`, `assignedtopicpartitions`. i am not sure if it would be better to rename `assignedpartition` to `isassignedpartition`.",0,0.6527733206748962
656748535,10579,ccding,2021-06-23T04:24:11Z,not good to use the same name for a variable and a function.,-1,0.8178712129592896
656749199,10579,ccding,2021-06-23T04:26:28Z,greater than or equal to?,0,0.9744174480438232
656749604,10579,ccding,2021-06-23T04:27:45Z,will the exception be caught by your own catch in line 74? maybe move it out of the `try` block?,0,0.9897680878639221
656751271,10579,ccding,2021-06-23T04:32:53Z,out of curiosity: why we don't do the check within the `new kafkaexception(...)` call,0,0.9767296314239502
656751707,10579,ccding,2021-06-23T04:34:24Z,is the check necessary?,0,0.9942346215248108
656752286,10579,ccding,2021-06-23T04:36:07Z,new line at the end of the file,0,0.9947496056556702
656761165,10579,ccding,2021-06-23T05:03:18Z,"function names `addremotelogsegmentmetadata`, `updateremotelogsegmentmetadata`, and `putremotepartitiondeletemetadata` don't seem very consistent. is there a way to improve it?",0,0.9839396476745605
656764820,10579,ccding,2021-06-23T05:13:51Z,"here has a race condition. it is possible `close=false` before calling `ensureinitializedandnotclosed()` and the `close()` function call by another thread has completed before calling `remotepartitionmetadatastore.listremotelogsegments(topicidpartition, leaderepoch)`. i think we should always grab a read lock before calling `ensureinitializedandnotclosed();`, or do some other fancy things.",0,0.9809784889221191
657655419,10579,satishd,2021-06-24T06:16:27Z,"`close/closing` is already volatile and its state is immediately reflected in other threads. in `close()` method, the consumer is invoked with `wakeup()`, and the other thread may receive `wakeupexception` if it is executing `poll()` or earlier than that. if it is after `poll` then the next check of `close/closing` allows to come out and finally close the consumer. `updateassignmentsforpartitions` and `close()` methods can not be called concurrently as it is alreadyhandled by `topicbasedremotelogmetadatamanager`.",0,0.9909845590591431
657655825,10579,satishd,2021-06-24T06:17:20Z,"when the code was refactored, it went with the caller method arg names. thanks for catching these.",1,0.9261519312858582
657655966,10579,satishd,2021-06-24T06:17:37Z,"what about `must be less than the partition count`, conveys the intent clearly.",0,0.9886080026626587
657656102,10579,satishd,2021-06-24T06:17:55Z,"if you are asking about the earlier catch block, that will not cover the exceptions like receiving from broker etc. the earlier catch block is applicable only until the record is added to the accumulator.",0,0.9932505488395691
657657314,10579,satishd,2021-06-24T06:20:42Z,i did not add the checks for these methods as they will not be invoked in parallel when close is called. but i agree to have the guards here with read lock.,0,0.9948657155036926
657670757,10579,satishd,2021-06-24T06:47:34Z,this is a temporary change. i plan to have a config with a default value.,0,0.9842798709869385
657671527,10579,satishd,2021-06-24T06:48:51Z,what about `ispartitionassigned`?,0,0.9934513568878174
657674359,10579,satishd,2021-06-24T06:53:57Z,"javadocs explain the behaviorr in detail. `addremotelogsegmentmetadata` - adds a new entry. `updateremotelogsegmentmetadata ` - updates an existing entry. `putremotepartitiondeletemetadata ` - adds or updates an existing entry, put is generally used for that purpose. if this is not so clear, another option can be `addorupdateremotepartitiondeletemetadata`.",0,0.9880218505859375
657683814,10579,satishd,2021-06-24T07:10:29Z,"as we discussed offlime, this may not become a bottleneck but we will make respective rlmm apis asynchronous so that the apis are extensible and implementors can provide async behavior.filed [a link] to track this issue.",0,0.9943172335624695
658361692,10579,satishd,2021-06-24T23:58:23Z,i plan to have a config with a default value in a follow-up pr.,0,0.9930965304374695
660802584,10579,junrao,2021-06-29T16:58:25Z,"hmm, why is this a daemon thread? it seems that we want to coordinate the shutdown of the thread.",0,0.973016083240509
660810740,10579,junrao,2021-06-29T17:10:21Z,"hmm, should we throw an exception in this case so that the caller knows the operation has failed?",0,0.98089200258255
660812883,10579,junrao,2021-06-29T17:13:31Z,"similar to the above, should we throw an exception in this case so that the caller knows the operation has failed?",0,0.9932283759117126
660836440,10579,junrao,2021-06-29T17:45:05Z,we need to unblock the wait if we are closing the consumer.,0,0.9902212619781494
660975970,10579,junrao,2021-06-29T21:28:57Z,"is this necessary since immediately after this check, the consumer task could be closed. ditto in other places.",0,0.993247389793396
660980922,10579,junrao,2021-06-29T21:37:50Z,"is this necessary? once producer is closed, send() will throw an exception.",0,0.9935024380683899
660990345,10579,junrao,2021-06-29T21:54:51Z,how is this different from remotelogmetadatacache? it seems that it's just a wrapper over remotelogmetadatacache?,0,0.9906664490699768
660991871,10579,junrao,2021-06-29T21:58:01Z,could we add a comment for this class?,0,0.9953994154930115
661000698,10579,junrao,2021-06-29T22:17:24Z,why do we need to initialize in a separate thread?,0,0.9885596632957458
661002879,10579,junrao,2021-06-29T22:22:17Z,"since we have a lock, could we just make closing a boolean?",0,0.9933376312255859
661629252,10579,junrao,2021-06-30T16:20:30Z,millis => ms to be consistent with other places. ditto in a few other places.,0,0.9920393228530884
661641738,10579,junrao,2021-06-30T16:36:54Z,is this needed since we log all configs when creating kafkaconfig already?,0,0.994574785232544
661642633,10579,junrao,2021-06-30T16:38:10Z,"other plugins on the broker may also need a bootstrap_server config. to distinguish them, it would be useful to add a prefix that's specific to remote storage.",0,0.992658793926239
661672097,10579,junrao,2021-06-30T17:20:36Z,"it seems that we need to automatically create metadata topic in rlmm implementation, not just in tests.",0,0.9900643229484558
661673976,10579,junrao,2021-06-30T17:23:08Z,120s seems quite long. do we need to wait that long?,0,0.9179355502128601
661687251,10579,junrao,2021-06-30T17:42:56Z,typo nto,0,0.9892784953117371
661687392,10579,junrao,2021-06-30T17:43:09Z,this sentence doesn't read well.,-1,0.8633100986480713
661693600,10579,junrao,2021-06-30T17:52:25Z,this should be for consumer?,0,0.9928779006004333
661698279,10579,junrao,2021-06-30T17:59:31Z,why are we testing against -1 here but 0 above?,0,0.9793200492858887
663808257,10579,satishd,2021-07-05T10:06:16Z,"good catch, updated it.",1,0.9880959987640381
663809083,10579,satishd,2021-07-05T10:07:34Z,there are two implementations about this class for both `remotelogmetadatacache` and `topicbasedremotelogmetadatamanager`. there are common tests in `remotelogsegmentlifecycletest `that we want to run for both of them.,0,0.9926209449768066
663809683,10579,satishd,2021-07-05T10:08:27Z,it was required to be retried until the topic is successfully created. i added the logic to check for topic creation too.,0,0.9953089356422424
663811753,10579,satishd,2021-07-05T10:11:33Z,i was planning to add that later as mentioned earlier. i updated with the required changes in latest commit.,0,0.9940595626831055
663813208,10579,satishd,2021-07-05T10:13:40Z,updated with a comment in the code.,0,0.9950847029685974
663818344,10579,satishd,2021-07-05T10:21:39Z,updated with a comment.,0,0.9940916895866394
663819484,10579,satishd,2021-07-05T10:23:26Z,"i guess 60s may be sufficient, updated with that.",0,0.9765403866767883
663821465,10579,satishd,2021-07-05T10:26:46Z,`closing` is accessed in `initializeresources` and we do not need to take a lock there. i would like to keep this as `atomicboolean` which addresses that and it is easy to understand the semantics.,0,0.9936383366584778
664630725,10579,ccding,2021-07-06T14:53:56Z,is it possible two threads call `close()` concurrently?,0,0.9910905361175537
664632598,10579,ccding,2021-07-06T14:55:56Z,our of curiosity: why we have `l` here but not [a link],0,0.9524137377738953
664866782,10579,junrao,2021-07-06T20:45:42Z,the test for closing seem unnecessary since closing can't change while synchronized on assignpartitionslock.,0,0.9775607585906982
664868563,10579,junrao,2021-07-06T20:49:01Z,"is remotelogsegmentlifecyclemanager used for tests only? if so, could we move it under tests?",0,0.9951192140579224
664905089,10579,junrao,2021-07-06T22:00:41Z,"i am still not sure why we need to initialize in a separate thread. if we can't create the metadata topic or instantiate the producer/consumer due to wrong configurations, we want to fail fast by throwing an error to shut down the broker.",-1,0.5490971803665161
664907494,10579,junrao,2021-07-06T22:06:20Z,should we verify that the number of partitions in the existing topic matches the configuration?,0,0.9941258430480957
664908297,10579,junrao,2021-07-06T22:08:11Z,"hmm, we don't want to retry forever. if there is a configuration error, we want to fail fast.",0,0.7459311485290527
664911197,10579,junrao,2021-07-06T22:14:50Z,"hmm, why is this needed since initializeresources() does this already?",0,0.9814514517784119
664912870,10579,junrao,2021-07-06T22:19:02Z,it seems producer credentials are closer for the admin client.,0,0.9882806539535522
664913921,10579,junrao,2021-07-06T22:21:34Z,is this comment addressed?,0,0.9930742979049683
664914536,10579,junrao,2021-07-06T22:22:55Z,createmetadatatopic() is no longer used.,0,0.9900087118148804
664970217,10579,satishd,2021-07-07T01:11:27Z,`remotelogsegmentlifecyclemanager` is already under tests.,0,0.9941033720970154
664976317,10579,satishd,2021-07-07T01:32:10Z,"this loop can run after `assignpartitionslock.wait()` call which might have been notified from `close()` method, we should have a `closing` check to get out of the loop. we can have a more aggressive check to return from here when `closing` is true, i will add that.",0,0.9945656061172485
664980913,10579,satishd,2021-07-07T01:46:58Z,`close()` will not be called concurrently here.,0,0.9903873801231384
664983511,10579,satishd,2021-07-07T01:53:00Z,"i prefer adding l for longs, which i missed at other declaration. afaik, that does not cause any issues as it gets automatically converted via a widening conversion to a `long`. the compiler takes care of not allowing numbers that may get truncated from `int` to `long` widening. thanks for catching it, i will make it consistent by adding it.",1,0.9753309488296509
665259927,10579,satishd,2021-07-07T10:50:18Z,"the reason why we need to initialize in a different thread here is that rlmm will be created and `configure()` will be called before the broker starts accepting the requests. so, we can not call topic creation requests in the same thread as the brokers are not yet up. another way to do this is to have this topic as an internal topic and it will be auto created whenever it is accessed. afaik, creating producer and consumer instances can be done without the brokers up and running and they will not trigger a request to auto creation of remote log metadata topic. consumer assignment will send a metadata request which will trigger auto creation of topics. this assignment on consumer is done only when rlmm receives callback thorough the broker about leader and isr updates from the controller. this is what we had in pre-2.7 implementation but we saw an intermittent deadlock issue but i do not see that happening on trunk. in the current pr, i will make the existing producer manager and consumer manager in configure() and have the topic creation done in the tests. i will have a quick follow-up pr with internal topic changes and remove the topic creation code from tests.",0,0.9924055933952332
665299398,10579,satishd,2021-07-07T11:54:00Z,"`remotelogmetadatamanager.configure(map configs)` is always invoked with stripping the rlmm prefix. ""bootstrap.servers"" property is sent as part of the configs here and any registered rlmm plugin will receive this property.",0,0.9945453405380249
665531236,10579,satishd,2021-07-07T16:29:41Z,i made the mentioned changes for this pr in the latest commit.,0,0.9934099316596985
665544995,10579,kamalcph,2021-07-07T16:48:33Z,this condition should be inverted.,0,0.9899628758430481
665555878,10579,satishd,2021-07-07T17:04:26Z,"good catch, we do not really need this check here as it is already guarded in `topicbasedremotelogmetadatamanager`.",1,0.9772614240646362
666372073,10579,junrao,2021-07-08T17:03:35Z,": to create a topic, you don't need a particular broker to be up. you just need to be able to access the bootstrap brokers. auto creating this topic on access is a bit weird since it's not truly an internal topic and it is just an implementation detail of rlmm. so, it makes more sense for topic-based rlmm to create it.",-1,0.8157094717025757
666697373,10579,satishd,2021-07-09T06:15:00Z,"as i mentioned earlier, rlmm is created before broker starts accepting the requests. so, when rlmm is getting initialized and tries to create a topic in the same thread, then none of the brokers(including the brokers related to the bootstrap-servers config) will be available for taking any admin client requests for topic creation. that is why i was doing this in a different thread as it allows the broker/controller to comeup and accept the admin client request for topic creation.",0,0.9886653423309326
667102624,10579,junrao,2021-07-09T17:21:12Z,": my understanding is that when we enable remote storage, we will do that through a rolling upgrade. so, at any given time, there is at most a single broker being down. therefore, as long as the bootstrap broker list contains more than one broker, operations like creating topics can still be done while a single broker is starting.",0,0.9866451621055603
667427888,10579,satishd,2021-07-11T06:04:21Z,": that is a good point. but that is valid only for upgrade scenario. there are two scenarios here. 1) upgrade path 2) fresh install/deploy with the release containing this feature. what you said makes sense for upgrade path. but ""bootstrap.servers"" list is configured with the local broker endpoint only in which rlmm is getting initialized. so, if we try to initialize rlmm in the same thread, it wont be able to connect to the local broker as it is not yet started to accept the broker api requests. one way to address this is to give `bootstrap.servers` with more than one broker's endpoint. this will also put a limitation to create a cluster with one broker instance for test/demo environments. when users install/deploy a fresh environment with the release containing this feature, there should not be a restriction to do rolling restarts with the configuration enabled. please let me know if i am missing anything here.",1,0.9345521330833435
670800796,10579,junrao,2021-07-15T20:58:17Z,should halt the jvm in this case? ditto below when the partition count doesn't match.,0,0.9917386174201965
670820515,10579,junrao,2021-07-15T21:34:47Z,"since bootstrap_servers is used for the internal producer/consumer, should bootstrap_servers be defined with a prefix of remote_log_metadata_common_client_prefix, remote_log_metadata_common_client_prefix or remote_log_metadata_consumer_prefix?",0,0.994754433631897
670823373,10579,junrao,2021-07-15T21:40:10Z,does pendingassignpartitions need to be synchronizedset since it's accessed under a lock?,0,0.9954293966293335
670947570,10579,satishd,2021-07-16T03:59:51Z,"yes, we are already doing that [a link] whenever this class is accessed with/for remote log metadata operations.",0,0.9937708973884583
671094510,10579,satishd,2021-07-16T09:13:18Z,it is needed because `pendingassignpartitions` is updated in both `onpartitionleadershipchanges` and `onstoppartitions` methods which can happen concurrently as both of them take read lock.,0,0.993685781955719
671367565,10579,satishd,2021-07-16T16:04:32Z,"no, it is not needed to be sent with any prefix(like common_client, producer or consumer) because ""bootstrap.servers"" property is sent for any registered rlmm plugin but not only limited to the default rlmm. i will update the kip with these details.",0,0.9938691854476929
671381765,10579,junrao,2021-07-16T16:27:07Z,"since producermanager is initialized asynchronously, how do we deal with the case when the producermanager is not ready when an event needs to be published?",0,0.9917245507240295
671383087,10579,junrao,2021-07-16T16:29:09Z,"hmm, ""bootstrap.servers"" makes sense for a topic based rlmm since it depends on kafka. why do we require ""bootstrap.servers"" in other rlmm implementations?",0,0.9907761216163635
671415369,10579,satishd,2021-07-16T17:25:57Z,"that is a good point. we plan to improve the semantics here. earlier, we plan to introduce retriableexception for rlmm and rsm so that callers can have an option to know whether they can retry or not. in the case of initialization is not yet complete, retriableexception can be thrown caller can retry based on backoff. rlmm can send non retriable exception if it is in closing state and there will not be any retries. another way to handle this is to take these events and store them in in-memory queue and return future. these futures will be considered successful if initialization is successful and the events are published to the topic. i plan to address these in a followup pr while these apis are integrated with rlm, filed [a link]",1,0.908216655254364
671419080,10579,satishd,2021-07-16T17:32:24Z,i am not sure about usecases with other rlmm but it allows them to connect to the broker.,0,0.9809331893920898
671516460,10579,junrao,2021-07-16T20:46:16Z,"what about client security related properties? it's weird that we pick up ""bootstrap.servers"" from one prefix, but the corresponding security properties under a different prefix. if we do provide the security related properties in the same prefix, they seem to be duplicated from those under prefix remote_log_metadata_common_client_prefix, remote_log_metadata_common_client_prefix or remote_log_metadata_consumer_prefix.",-1,0.9187934398651123
125019733,3325,dguy,2017-06-30T11:38:49Z,this is unused,0,0.9928995370864868
125019734,3325,dguy,2017-06-30T11:38:50Z,this is unused too. we should have a test for this.,0,0.9858853816986084
125019810,3325,dguy,2017-06-30T11:39:29Z,this is in a public package so we should provide some javadoc,0,0.9943115711212158
125020051,3325,dguy,2017-06-30T11:41:18Z,same as above - needs javadoc. i guess it is intended for users? we should at least have some tests that use it.,0,0.9900060296058655
125020092,3325,dguy,2017-06-30T11:41:40Z,nit: extra space between `abstract` and `class`,0,0.9937263131141663
125020150,3325,dguy,2017-06-30T11:42:07Z,javadoc,0,0.9682533144950867
125020184,3325,dguy,2017-06-30T11:42:20Z,javadoc,0,0.9682533144950867
125020664,3325,dguy,2017-06-30T11:45:39Z,this should probably default to `noopstaterestorelistener` otherwise i think it is going `nullpointerexception` if the user doesn't add a listener,0,0.9904981255531311
125020841,3325,dguy,2017-06-30T11:46:45Z,i think we should probably do a null check here and throw. setting the listener to null doesn't seem valid to me,0,0.9832506775856018
125021380,3325,dguy,2017-06-30T11:49:56Z,rather than setting this to `null` if it isn't an instance of `batchingstaterestorecallback` perhaps you could set it to an instance of an internal class that implements `batchingstaterestorecallback`. the benefit being that the `null` check is then only done once here and not also in `restoreall`,0,0.9910624027252197
125021406,3325,dguy,2017-06-30T11:50:09Z,see comment above in ctor,0,0.9946809411048889
125021525,3325,dguy,2017-06-30T11:50:57Z,unit tests for this class?,0,0.9928459525108337
125022092,3325,dguy,2017-06-30T11:54:42Z,again i think we could use an internal implementation (probably the same one) for `batchingstaterestorecallback`. so here we always have a `batchingstaterestorecallback` and we can get rid of the `if(...){...}else{...}` and the extra `if(!restorerecords.isempty)` i think that would make the code easier to follow.,0,0.9870016574859619
125022610,3325,dguy,2017-06-30T11:58:16Z,pass this in as a ctor param rather than constructing it? the `staterestorecallback` is only used to create the `compositerestorelistener`,0,0.9928380846977234
125036770,3325,dguy,2017-06-30T13:20:23Z,do we need to synchronize access to `staterestorelistener`? it can be set by a user thread and used by the `streamthread`,0,0.994890570640564
125037238,3325,dguy,2017-06-30T13:22:33Z,nit: `private`,0,0.994669497013092
125037487,3325,dguy,2017-06-30T13:23:46Z,nit: keep fields with the same access level together,0,0.9936820268630981
125040681,3325,dguy,2017-06-30T13:38:20Z,nit: `collections.singletonlist(...)` or `utils.mklist(..)`,0,0.9948756098747253
128017007,3325,bbejeck,2017-07-18T15:51:41Z,"ack, removed not needed as it's passed through to `streamthread`",0,0.9920439124107361
128018122,3325,bbejeck,2017-07-18T15:55:41Z,"don't think so, the `staterestorelistener` set by user is passed through to the `streamthread`. javadoc in `staterestorelistener` states that it expects operations to be stateless.",0,0.9814531803131104
128018683,3325,bbejeck,2017-07-18T15:57:34Z,"ack, added integration test",0,0.9833784699440002
128018746,3325,bbejeck,2017-07-18T15:57:47Z,ack,0,0.9149930477142334
128018769,3325,bbejeck,2017-07-18T15:57:51Z,ack,0,0.9149930477142334
128236093,3325,dguy,2017-07-19T12:53:08Z,nit: my preference is to mark all method params as `final`,0,0.9939485788345337
128250446,3325,dguy,2017-07-19T13:47:18Z,`final` and there is an extra space,0,0.9939637780189514
128251187,3325,dguy,2017-07-19T13:50:01Z,nit: extra line,0,0.8243594765663147
128251819,3325,dguy,2017-07-19T13:52:27Z,i think we should probably add a unit test in `rocksdbstoretest` to prove that this works.,0,0.986034095287323
128253384,3325,dguy,2017-07-19T13:58:04Z,"i'd prefer to see these broken down into multiple smaller tests, i.e, you are effectively testing 4 different methods in each test. ideally a unit test is only testing a single method.",0,0.9792200326919556
128254391,3325,dguy,2017-07-19T14:01:35Z,nit: `final` + next line and might as well do the previous while you are at it ;-),1,0.9779307842254639
128256200,3325,dguy,2017-07-19T14:07:39Z,"could we extract these 3 lines into a method, say `verifycallbackstatescalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok",0,0.9898276329040527
128303773,3325,bbejeck,2017-07-19T16:51:49Z,ack - agreed,0,0.9750009775161743
128303812,3325,bbejeck,2017-07-19T16:51:55Z,ack,0,0.9149930477142334
128414835,3325,guozhangwang,2017-07-20T02:48:34Z,"the javadoc may read a bit hard for end users since 1) `internal threads assignment` is not known to them at all, 2) `conclusion of restoring a statestore` is also a mess up. from their pov (not familiar with concept of task, etc) we can just state that `... set the listener which is triggered whenever a state is being restored in order to resume processing..`.",0,0.5879806876182556
128415004,3325,guozhangwang,2017-07-20T02:50:14Z,"same as above, do not need to mention ""all internal threads"". just emphasize it is triggered whenever a state is being restored is fine.",0,0.9849704504013062
128415203,3325,guozhangwang,2017-07-20T02:52:04Z,"nit: `not supported, please use...`",0,0.8975117802619934
128415747,3325,guozhangwang,2017-07-20T02:58:16Z,i think we can use the following as part of javadoc: [code block] as a reference see `kafkaproducer` and `producer` in clients.,0,0.9890531897544861
128415932,3325,guozhangwang,2017-07-20T03:00:12Z,i did not catch it in the kip wiki but.. the class names are a bit inconsistent here: [code block] better be either [code block] or [code block] wdyt?,0,0.9083075523376465
128415948,3325,guozhangwang,2017-07-20T03:00:30Z,"ditto as above, we can refer to the javadocs of the base interface here.",0,0.9946863651275635
128416068,3325,guozhangwang,2017-07-20T03:01:46Z,"seems in the library, if it is determined a `batchingstaterestorecallback` at runtime we then would never call the `restore` function ever. is this true and will be future forever? if yes we should state it in the java doc.",0,0.9934346675872803
128416128,3325,guozhangwang,2017-07-20T03:02:26Z,does this need to be in `o.a.k.streams.state` or this package? i'm just wondering..,0,0.9898985028266907
128416252,3325,guozhangwang,2017-07-20T03:03:55Z,"better state ""when calling `setstate...` in \ kafkastreams, the passed instance is expected to be stateless since.."" because not everyone understand what does ""... for reporting all state store recovery.."" means, stating from the api point of view would be easier to understand. ditto elsewhere.",0,0.9902552962303162
128416789,3325,guozhangwang,2017-07-20T03:10:02Z,`in this case the size of the batch is whatever the value of the max_poll_records is set to.` is this really the case?? it is an upper bound but not necessary the exact value right?,0,0.9908883571624756
128603596,3325,bbejeck,2017-07-20T19:00:07Z,ack,0,0.9149930477142334
128603630,3325,bbejeck,2017-07-20T19:00:15Z,ack,0,0.9149930477142334
128607545,3325,bbejeck,2017-07-20T19:18:41Z,"agreed, i think the second option is best.",0,0.9306697845458984
128607578,3325,bbejeck,2017-07-20T19:18:51Z,ack,0,0.9149930477142334
128607619,3325,bbejeck,2017-07-20T19:19:00Z,ack,0,0.9149930477142334
128607645,3325,bbejeck,2017-07-20T19:19:09Z,ack,0,0.9149930477142334
128607671,3325,bbejeck,2017-07-20T19:19:16Z,ack,0,0.9149930477142334
128607701,3325,bbejeck,2017-07-20T19:19:25Z,ack,0,0.9149930477142334
128607714,3325,bbejeck,2017-07-20T19:19:30Z,ack,0,0.9149930477142334
128611709,3325,bbejeck,2017-07-20T19:37:21Z,"maybe, we could also move `statestore`, `statestoresupplier`, `statestorecallback` as well. let's see what others think.",0,0.9864447712898254
128612612,3325,bbejeck,2017-07-20T19:41:59Z,ack,0,0.9149930477142334
128614536,3325,bbejeck,2017-07-20T19:51:06Z,ack,0,0.9149930477142334
128642317,3325,guozhangwang,2017-07-20T22:05:53Z,"if we start from scratch then maybe these would be better be in `state`, but they have been added to `processor` and moving them would be incompatible changes. so i'm more concerning about the newly added classes.",0,0.913823664188385
128642627,3325,guozhangwang,2017-07-20T22:07:36Z,maybe the parameter descriptions are not needed as well? ditto elsewhere.,0,0.9852526783943176
128643629,3325,guozhangwang,2017-07-20T22:13:58Z,we can define two static variables of `noopstaterestorelistener` and `noopstaterestorecallback` instead of creating a new instance multiple times.,0,0.9933197498321533
128646844,3325,guozhangwang,2017-07-20T22:34:54Z,"for `reportingstorelistener`, better rename it to `globalstorelistener` as it is the instance-level listener, but it is not necessarily used for reporting only.",0,0.9934896230697632
128647685,3325,guozhangwang,2017-07-20T22:40:22Z,also code structure wise i'm wondering if it is easier to keep the per-store callback/listener and the global listener in two separate classes than keeping them in this `composite` class? then we can do: [code block] i feel this null-check would be more performant than the no-op function call?,0,0.9894735217094421
128648024,3325,guozhangwang,2017-07-20T22:42:40Z,"as mentioned above, i'm wondering if it is better to not use the `set` function of global listener in this composite class but keep it in a separate class? also since the global listener could be accessed by concurrent threads of the instance, does it need to be synchronized?",0,0.9869667291641235
128648103,3325,bbejeck,2017-07-20T22:43:09Z,ok fair enough i can move it over. my only concern is that it could be slightly confusing.,0,0.8806805610656738
128648481,3325,guozhangwang,2017-07-20T22:45:19Z,hmm... should we ever expect the passed in callback to ever be `null`? if it is really null then no data will ever be restored right?,0,0.9543356895446777
128649545,3325,guozhangwang,2017-07-20T22:52:52Z,"instead of using this separate class and do the `instanceof` check on each call (which maybe expensive), maybe we could just have a `wrappedbatchingstaterestorecallback` which only takes the non-batching `staterestorecallback` in constructor and then in `restoreall` always do the for-loop, and in places that we need it (seems we only have two callers) we can do sth. like [code block] just once.",0,0.9844135046005249
128651168,3325,guozhangwang,2017-07-20T23:04:14Z,"i'm thinking that we can simply this logic a bit: 1) in line 124 above, when `needsrestoring.put(topicpartition, restorer);` call `restorer.restorestarted`. 2) then we can remove the `restorestarted` boolean in `storerestorer` and also the line here.",0,0.9862998127937317
128652257,3325,guozhangwang,2017-07-20T23:12:47Z,"this logic seems a bit complex to me, and also if we return at line 229 `restorebatchcompleted` is not called as well. is this correct? how about: [code block]",0,0.8544832468032837
128652963,3325,guozhangwang,2017-07-20T23:17:34Z,"following my comments above, we can rename to `setglobalstaterestorelistener` to make it clear.",0,0.995352029800415
128653176,3325,guozhangwang,2017-07-20T23:19:29Z,these two functions can be merged into one? [code block] see my other comments on the `storechangelogreader.java` class.,0,0.9948040843009949
128653276,3325,guozhangwang,2017-07-20T23:20:19Z,ditto above: `setglobalstaterestorelistener`,0,0.994796097278595
128653708,3325,guozhangwang,2017-07-20T23:23:42Z,"one caveat of letting users to set it via code is that, we cannot forbid users to call this function after calling `streams.start()`, in which case the behavior would be bad. also people can set it multiple times which is also not suggested. i'm now thinking maybe we should enforce users to set this global listener via configs? cc wdyt.",0,0.9819104075431824
128654031,3325,guozhangwang,2017-07-20T23:26:02Z,"`prepareforbulkload` will always be true here, right?",0,0.9915112853050232
128654227,3325,guozhangwang,2017-07-20T23:27:35Z,"i do not think we need this variable at all, since as mentioned above when initiating it will always be true, and that is the only place this variable is ever read.",0,0.9829074740409851
128654443,3325,guozhangwang,2017-07-20T23:29:00Z,we do not need to set `open = true` here again.,0,0.9926727414131165
128655290,3325,guozhangwang,2017-07-20T23:36:26Z,"personally i'm not a big fan of this integration test, since i felt that the its coverage has already been subsumed by unit tests. we should only consider integration tests for some end-to-end behavior that involves multiple modules to interact with each other, otherwise unit tests should be used per-module.",-1,0.6118213534355164
128656227,3325,guozhangwang,2017-07-20T23:44:14Z,actually i was really just asking for people's opinions :) the cons are that these classes will be in different packages which may looks a bit weird.,1,0.9884887337684631
128700639,3325,dguy,2017-07-21T07:33:05Z,if we put it in config then they lose the ability to use capture any objects/state etc in their application. we could always only allow the listener to be set when kafkastreams is in the `created` state and throw an exception if it isn't.,0,0.9792713522911072
128779376,3325,bbejeck,2017-07-21T14:44:10Z,:thumbs_up:,1,0.9533231854438782
128800005,3325,bbejeck,2017-07-21T16:05:22Z,ack,0,0.9149930477142334
128800078,3325,mjsax,2017-07-21T16:05:43Z,"in javadoc this markup is not needed 1. between the text and the parameter list, it will insert some space automatically 2. ` ` is just use to start new paragraphs (but javadoc is not html, there is no closing ` `)",0,0.9927674531936646
128800519,3325,mjsax,2017-07-21T16:08:08Z,"we could do a small kip and move the classes (preserving the old ones as deprecated). overall, i don't have a strong opinion.",0,0.9070834517478943
128800688,3325,mjsax,2017-07-21T16:09:03Z,nit: why `code` but not `link` ?,0,0.986823558807373
128800950,3325,mjsax,2017-07-21T16:10:23Z,nit: `.` missing at end of sentence,0,0.9851374626159668
128800998,3325,mjsax,2017-07-21T16:10:41Z,nit: remove unnecessary blank.,0,0.9849048852920532
128802000,3325,bbejeck,2017-07-21T16:16:03Z,ack on the name. i think we should keep `composite` class as it keeps implementation details out of the `staterestorer` class which doesn't need to know the details of restoring notification. as for synchronizing we can do that from within the `composite` class as well. although we specify in the javadoc it's expected the `globbalstorelistener` is stateless and implementors will need to provide synchronization if needed. if you insist i can remove the composite class and/or synchronize the calls on the `globalstorelistener`,0,0.9651352167129517
128802185,3325,bbejeck,2017-07-21T16:17:00Z,ack,0,0.9149930477142334
128807922,3325,bbejeck,2017-07-21T16:46:35Z,"ack, but i thinking some more we should replace the default value with `objects.requirenonnull`",0,0.838159441947937
128809089,3325,bbejeck,2017-07-21T16:52:30Z,updated the set method to reflect the new name. comments on the `composite` class and synchronization same as above.,0,0.9952698349952698
128815139,3325,bbejeck,2017-07-21T17:22:11Z,ack,0,0.9149930477142334
128829007,3325,guozhangwang,2017-07-21T18:22:36Z,"re synchronization: enforcing users to do sync themselves inside the function is fine, i did not see `implementors will need to provide synchronization if needed` so there may be a mis-understanding. could you make that statement more clear in javadocs? re separating classes: one motivation i had is that, currently we did one ""instanceof"" for each call, and if the global listener is not set we still call a `no-op` listener; this does not seem optimized for me. instead we can do a `null` check or even a boolean flag indicating if a global listener is ever set already. that would be more performant? if you can do that inside this composite class i think we could keep it centralized.",0,0.9781961441040039
128843230,3325,bbejeck,2017-07-21T19:27:35Z,"ack, good catch.",1,0.9759413003921509
128847495,3325,bbejeck,2017-07-21T19:49:37Z,ack,0,0.9149930477142334
128849307,3325,bbejeck,2017-07-21T19:59:39Z,ack,0,0.9149930477142334
129029991,3325,bbejeck,2017-07-24T13:10:02Z,leaving as is based on offline-conversation,0,0.9900357127189636
129030050,3325,bbejeck,2017-07-24T13:10:17Z,ditto from above,0,0.9907984733581543
129030086,3325,bbejeck,2017-07-24T13:10:26Z,ditto from above,0,0.9907984733581543
129030265,3325,bbejeck,2017-07-24T13:11:13Z,"ok, i'll take it out.",0,0.9895051121711731
129090134,3325,bbejeck,2017-07-24T16:45:27Z,ack,0,0.9149930477142334
129090501,3325,bbejeck,2017-07-24T16:46:54Z,"oversight on my part, changing.",0,0.8501014113426208
129091268,3325,bbejeck,2017-07-24T16:50:16Z,ack,0,0.9149930477142334
129606674,3325,mjsax,2017-07-26T15:27:05Z,nit `{ staterestorerlistener}`,0,0.9916712045669556
129608628,3325,mjsax,2017-07-26T15:33:46Z,can't this `extend abstractnotifyingrestorecallback` to save all the boiler plate from below?,0,0.9943435192108154
129617878,3325,mjsax,2017-07-26T16:05:20Z,"can we introduce a global ""one parameter per line"" code style? i think it would help to make diffs cleaner. we can do this incrementally. if yes, please do for all newly introduced code of this pr. also, should be add `final` all over the place?",0,0.9806350469589233
129618333,3325,mjsax,2017-07-26T16:07:06Z,"nit: parameter descriptions are no sentences, thus no `.` at the end (on many other places, too). if we say they are sentences, they it should start with upper case `[t]he topicpartition`",0,0.9900673627853394
129620426,3325,mjsax,2017-07-26T16:13:55Z,as above?,0,0.9936766028404236
129623215,3325,mjsax,2017-07-26T16:24:35Z,can you elaborate?,0,0.9921838641166687
129624489,3325,mjsax,2017-07-26T16:28:29Z,we should not `expect` here and use `fail` within try-catch,0,0.9915736317634583
129626342,3325,mjsax,2017-07-26T16:35:25Z,as above.,0,0.9881609678268433
129629040,3325,bbejeck,2017-07-26T16:44:40Z,ack,0,0.9149930477142334
129664724,3325,bbejeck,2017-07-26T18:54:03Z,ack,0,0.9149930477142334
129667712,3325,bbejeck,2017-07-26T19:05:08Z,"actually this class won't be used anymore, so removed.",0,0.9760321378707886
129670240,3325,bbejeck,2017-07-26T19:15:34Z,"sure thing, can you add to the steams guidelines?",0,0.9926201701164246
129677466,3325,bbejeck,2017-07-26T19:46:19Z,"will still have one no-op method, but i guess it's worth it as it does reduce the boilerplate some.",0,0.9363446831703186
129692869,3325,bbejeck,2017-07-26T20:52:12Z,"there was some confusion over the number of times we open and close the `rocksdbstatestore` for handling optimized bulk loads, once that was clarified the comments pertaining to setting `prepareforbulkload` and `open` didn't need to be addressed.",0,0.9921382069587708
129963670,3325,guozhangwang,2017-07-27T21:26:05Z,nit: rename this function to `restorestarted` to be consistent with other names. such will help other code readers to understand these functions are for the same code granularity and semantics.,0,0.9942329525947571
129964281,3325,guozhangwang,2017-07-27T21:28:46Z,is this comment missed somehow? i think line 42 above could be `storerestorelistener = no_op_state_restore_listener`.,0,0.992259681224823
129964947,3325,guozhangwang,2017-07-27T21:32:21Z,nit: space after `//` and we do not need capitalize the in-function comments.,0,0.9923319816589355
129965165,3325,guozhangwang,2017-07-27T21:33:28Z,ditto for in-function and simple top function comments.,0,0.9897692203521729
129965459,3325,guozhangwang,2017-07-27T21:34:51Z,nit: new lines are generally not recommended to break object type declaration with object name. for this specific line i think we can still make them in one line.,0,0.9895261526107788
129965596,3325,guozhangwang,2017-07-27T21:35:38Z,ditto: newline after keywords are generally not recommended.,0,0.9879440069198608
129965850,3325,guozhangwang,2017-07-27T21:37:04Z,ditto for new line rules. could you make a pass over all the newlines and see if they can be improved?,0,0.9920180439949036
129966240,3325,guozhangwang,2017-07-27T21:39:04Z,we can use the `wrappedbatchingstaterestorecallback` here?,0,0.9955320358276367
129966522,3325,guozhangwang,2017-07-27T21:40:35Z,`org.apache.kafka.streams.processor.internals.noopstaterestorelistener` can be used here?,0,0.9941904544830322
129970463,3325,bbejeck,2017-07-27T22:01:09Z,ack,0,0.9149930477142334
129970523,3325,bbejeck,2017-07-27T22:01:27Z,"ack, must have overlooked",0,0.5609285831451416
129970837,3325,bbejeck,2017-07-27T22:03:18Z,ack,0,0.9149930477142334
129970870,3325,bbejeck,2017-07-27T22:03:26Z,ack,0,0.9149930477142334
129970957,3325,bbejeck,2017-07-27T22:03:53Z,"ack, need to adjust intellij settings",0,0.9808602333068848
129971207,3325,bbejeck,2017-07-27T22:05:25Z,"ack, same as above",0,0.9855887293815613
129971290,3325,bbejeck,2017-07-27T22:05:57Z,ack,0,0.9149930477142334
129974506,3325,bbejeck,2017-07-27T22:26:26Z,ack,0,0.9149930477142334
129974595,3325,bbejeck,2017-07-27T22:26:54Z,ack,0,0.9149930477142334
589867244,10218,junrao,2021-03-09T01:16:23Z,"it's a bit weird to include this in the client module. since this is implemented in java, we could potentially create a new java module for it (like the raft module). this reduces the size of the client jar and also avoids the inter-dependencies between java and scala. also, is this for testing? if so, it needs to be in the test directory.",-1,0.983353853225708
589867914,10218,junrao,2021-03-09T01:17:56Z,"is this for testing? if so, it needs to be in the test directory.",0,0.9951258301734924
590723978,10218,junrao,2021-03-09T21:14:18Z,typo imemory,0,0.9602187275886536
590739158,10218,junrao,2021-03-09T21:40:00Z,"hmm, it's possible for a segment to transition to delete_segment_started here. should those segments still be added?",0,0.9829041361808777
590740461,10218,junrao,2021-03-09T21:42:19Z,"once a segment is in delete_segment_started state, the corresponding segment could be gone any time after that. so, it seems that we should remove the segment from leaderepochtooffsettoid once it's in delete_segment_started?",0,0.9925438165664673
590742564,10218,junrao,2021-03-09T21:46:15Z,could we just get the segment list from `idtosegmentmetadata.values()`?,0,0.9946972131729126
590744034,10218,junrao,2021-03-09T21:48:28Z,highestlogoffset => highestsegmentstartoffset ?,0,0.9931569695472717
590745670,10218,junrao,2021-03-09T21:50:53Z,could we add a comment to this class?,0,0.9953730702400208
590748558,10218,junrao,2021-03-09T21:55:55Z,we are not returning null here.,0,0.9775267839431763
591585302,10218,satishd,2021-03-10T14:49:20Z,the plan was to use the related classes in the default rlmm implementation and move any class which is relevant only for tests to test dir later. i am +1 to have this as a separate module. i will update with those changes.,0,0.8531703352928162
591588474,10218,satishd,2021-03-10T14:52:49Z,"this behavior was kept to be the same as local log cleanup behavior, in which leader epoch is truncated only after local log is moved/deleted. ideally, it is good not to consider the segments available that are being deleted as you said.",0,0.9918410778045654
591595247,10218,satishd,2021-03-10T15:00:08Z,there may be few segments with state as `copy_segment_started` and they will be part of `remotelogsegmentidinprogress` only but not `idtosegmentmetadata`. that is why we need to add them to the list.,0,0.9932475090026855
591603442,10218,satishd,2021-03-10T15:09:34Z,"no, it is not highestsegmentstartoffset but it is the highest log offset for the given leader epoch. nice catch! we need to give the max endoffset of all the segments for the given leader epoch.",1,0.986690878868103
591905906,10218,kowshik,2021-03-10T22:05:03Z,this c'tor can be removed in exchange for the default generated c'tor.,0,0.9955403208732605
591912017,10218,kowshik,2021-03-10T22:15:55Z,it seems like we allow for an entry already existing with the same id to be replaced with a different entry. would that happen in practice?,0,0.9911907911300659
591915104,10218,kowshik,2021-03-10T22:21:41Z,"can `offsettoid` be empty if it is not null? i understand it is right to check for emptiness here, but i was just curious to learn if it could happen in practice.",0,0.9806695580482483
591919624,10218,kowshik,2021-03-10T22:30:10Z,"looking at the implementation, it appears we maintain some rules on when a `remotelogsegmentid` exists in one of these data structures versus all of them. it would be useful to briefly document those rules, and mention invariants (if any). for example, when an upload is in progress it is not (yet) added to this map.",0,0.9880375862121582
591921511,10218,kowshik,2021-03-10T22:33:57Z,can `metadata` be a better variable name over `rlsm`?,0,0.993868887424469
592012860,10218,kowshik,2021-03-11T02:02:41Z,should we move this log message before l51? so that the message conveying the intent is logged first before any possible errors.,0,0.9941293001174927
592015659,10218,kowshik,2021-03-11T02:11:02Z,hmm... it seems like the only allowed state in `rlsmupdate` is `copy_segment_finished`. should we validate for that instead?,0,0.9645951986312866
592016707,10218,kowshik,2021-03-11T02:13:35Z,s/resource/entry ?,0,0.9941858053207397
592022166,10218,kowshik,2021-03-11T02:28:08Z,"it seems like we want to add more protections here. 1. if `remotepartitiondeletemetadata.state()` is `delete_partition_finished`, then should there have been a prior entry with `delete_partition_started` or `delete_partition_marked`? 2. imagine there exists an entry in `partitiontoremotelogmetadatacache` while the partition is also being deleted. is that a valid state, or if not should we assert against it?",0,0.990704357624054
592022431,10218,kowshik,2021-03-11T02:28:56Z,sorry i don't understand what does this comment refer to?,-1,0.9926361441612244
592024533,10218,kowshik,2021-03-11T02:35:18Z,"hmm, any reason to not implement these methods? is it that they don't serve any purpose in the in-memory implementation?",0,0.980983316898346
592070871,10218,satishd,2021-03-11T05:10:50Z,this can happen in race condition when this method is queried while it was getting added in `addremotelogsegmentmetadata`. it may not happen in practice but it is good to have these checks.,0,0.9680504202842712
592071729,10218,satishd,2021-03-11T05:13:59Z,"right, it is not applicable for inmemory implementation.",0,0.9916236996650696
592074962,10218,satishd,2021-03-11T05:24:46Z,"""no resource metadata found for partition: ""?",0,0.994519054889679
592075662,10218,satishd,2021-03-11T05:26:51Z,it may not occur in practice.,0,0.9645171165466309
592096637,10218,satishd,2021-03-11T06:28:40Z,"it allows any state other than `copy_segment_started`, that is why we are checking only for this state.",0,0.9937591552734375
592123658,10218,kowshik,2021-03-11T07:32:25Z,is it useful to add a check against it?,0,0.9945665597915649
592124191,10218,kowshik,2021-03-11T07:33:38Z,sure,0,0.9422702193260193
592173915,10218,satishd,2021-03-11T08:56:03Z,"other states include `copy_segment_finished`, `delete_segment_started`, and `delete_segment_finished`.",0,0.9953991770744324
592248245,10218,satishd,2021-03-11T10:37:36Z,"i meant there will be an external trigger based on delete partition marker, that is responsible for deleting the segments in a partition and updating the metadata. i will remove it as it looks to create confusion.",0,0.9921247363090515
592437366,10218,satishd,2021-03-11T15:05:20Z,1 -> added more assertions. 2 -> is a valid case.,0,0.9871455430984497
592577341,10218,satishd,2021-03-11T17:55:01Z,"sure, will add comments.",0,0.9884387850761414
594509836,10218,junrao,2021-03-15T16:51:52Z,delete_partition_marked is not part of remotelogsegmentstate.,0,0.9926267266273499
594510134,10218,junrao,2021-03-15T16:52:11Z,this seems to be an internal implementation and is not part of the public api? ditto for the same method in remotepartitiondeletestate.,0,0.9928210377693176
594550095,10218,junrao,2021-03-15T17:41:48Z,"this method updates idtosegmentmetadata, which seems redundant since it's done in line 107 already.",0,0.9869530200958252
594554053,10218,junrao,2021-03-15T17:47:01Z,"it's possible that after this, there is no segment associated with a leader epoch. should we remove the entry with that leader epoch from leaderepochtooffsettoid?",0,0.9920227527618408
594560602,10218,junrao,2021-03-15T17:55:35Z,it's kind of inefficient to have to iterate through the whole segment list. could we make leaderepochtooffsettoid an ordered map and then do highentry on that?,0,0.5092609524726868
594562408,10218,junrao,2021-03-15T17:57:34Z,highestlogoffset => highestoffsetforepoch?,0,0.9940436482429504
594564204,10218,junrao,2021-03-15T17:59:44Z,"it seems that there is a semantic difference between this method and the next one. while this one exposes all segments (including in progress ones), the latter only exposes segments that are completed. it would be useful to document this clearly in the public api.",0,0.9879471659660339
594567815,10218,junrao,2021-03-15T18:04:22Z,"hmm, it seems that we add the in-progress segment to idtosegmentmetadata in addtoinprogress? it would be useful to add a comment for idtosegmentmetadata.",0,0.9851418733596802
594577274,10218,junrao,2021-03-15T18:17:25Z,"for the local log, we first schedule the segment for async deletion and then take it out of leaderepochcache. so, the equivalent of that for remote storage seems to require taking the segment out of leaderepochcache once the segment deletion is initiated.",0,0.9915817379951477
594578101,10218,junrao,2021-03-15T18:18:32Z,inmemory => in-memory,0,0.9938357472419739
595492577,10218,kowshik,2021-03-16T19:49:18Z,"1. will it be useful to place the implementation of this validation in a separate module, so that it can be reused with `rlmmwithtopicstorage` in the future? 2. suggestion from the standpoint of code readability/efficiency: would it make sense to replace the `if-else` logic by looking up from a `map< remotelogsegmentstate, set< remotelogsegmentstate>>` where key is the source state and value is a set of allowed target states?",0,0.989664614200592
595493561,10218,kowshik,2021-03-16T19:50:55Z,i have the same suggestions from `remotelogsegmentstate` for this as well. please refer to this comment: [a link],0,0.9947458505630493
595500039,10218,kowshik,2021-03-16T20:00:45Z,really minor comment/discussion: any reason to call this prefixed with `add` as `addremotelogsegmentmetadata` vs calling the deletion one prefixed with `put` as `putremotepartitiondeletemetadata` i.e. instead can these 2 methods both start with the same prefix either `add` or `put`?,0,0.9696722030639648
595505146,10218,kowshik,2021-03-16T20:09:07Z,"we may want to think more about the locking semantics for this class and `remotelogmetadatacache`. are we sure there would _not_ be use cases where we need to serialize mutations across the individually thread-safe attributes? if the answer is no, then using a fine-grained `object` lock makes more sense because we can use it to guard critical sections. should we evaluate this upfront? cc",0,0.9896767735481262
595506748,10218,kowshik,2021-03-16T20:11:49Z,in the comment: s/putremotelogsegmentmetadata/addremotelogsegmentmetadata,0,0.9936649799346924
595954157,10218,satishd,2021-03-17T12:05:42Z,this is not really an internal implementation but it validates the state transition and it is the same for any implementation.,0,0.9934182167053223
596032415,10218,satishd,2021-03-17T13:46:26Z,i will update the javadoc of the apis to make this clear.,0,0.9915903210639954
596055570,10218,satishd,2021-03-17T14:12:17Z,good point! it will clear the values which are empty maps.,1,0.9961119294166565
596203582,10218,satishd,2021-03-17T16:48:25Z,`add` -> adding a new entry. `put` -> add or update. `putremotepartitiondeletemetadata` is used for both add or update the `remotepartitiondeletemetadata`.,0,0.9933704137802124
596204864,10218,satishd,2021-03-17T16:49:52Z,it was deliberate not to add locking semantics for now. we will add them once we have the respective changes using these classes.,0,0.9908231496810913
596247752,10218,satishd,2021-03-17T17:41:19Z,"1 -> imho, this validation method should be part of the state enum and it can be used by any implementation including default rlmm. 2 -> i would have preferred the suggested approach if there are many complex transitions but the transitions here are few and simple.",0,0.9740990400314331
598964030,10218,kowshik,2021-03-22T18:13:16Z,you can drop `it` and start with `indicates the state...`.,0,0.9937179088592529
598971940,10218,kowshik,2021-03-22T18:24:49Z,"imho, we can simplify this to say: [code block]",0,0.9877960681915283
598974632,10218,kowshik,2021-03-22T18:28:26Z,could we call this `idtoremotelogmetadatacache` to align with the naming of the other attribute thats called `idtopartitiondeletemetadata` ?,0,0.9938641786575317
598981046,10218,kowshik,2021-03-22T18:37:34Z,can this be checked inside `remotelogmetadatacache.addtoinprogress()` instead of here?,0,0.9949278831481934
598982742,10218,kowshik,2021-03-22T18:40:00Z,it seems to me that `srcstate` is never null in practice. where does this check come into play in practice?,0,0.9906936287879944
598984916,10218,kowshik,2021-03-22T18:43:16Z,this is defined to be not thread safe unlike the other maps. is there any reason?,0,0.9925917387008667
598990605,10218,kowshik,2021-03-22T18:51:29Z,can we add a 1-line doc for this similar to other attributes below?,0,0.9957108497619629
599000060,10218,kowshik,2021-03-22T19:05:29Z,"before we insert into the map/set, we should check if the provided `remotelogsegmentmetadata.state()` is `copy_segment_started`.",0,0.9943873286247253
599001851,10218,kowshik,2021-03-22T19:08:20Z,"in this method, we allow for existing entries in `idtosegmentmetadata` to be replaced, even if the state of the existing and new entries are the same. is that intentional?",0,0.9919205904006958
599003846,10218,kowshik,2021-03-22T19:11:32Z,"hmm, the entry for `existingmetadata` gets overwritten in the call to `addremotelogsegmentmetadata` in l110. should we be accounting for the same here?",0,0.9829720854759216
599006691,10218,kowshik,2021-03-22T19:16:01Z,"similar to above comment, why not check this inside `remotelogmetadatacache.updateremotelogsegmentmetadata()`?",0,0.9940460920333862
599008337,10218,kowshik,2021-03-22T19:18:33Z,typos: 1. s/wwe/we 2. s/gettign/getting,0,0.9922277331352234
599009374,10218,kowshik,2021-03-22T19:20:12Z,"can we improve the local variable names? for example `segidfootp0s0e100`, `segmetfootp0s0e100` etc. is not easy to read. we can use simpler names.",0,0.9869561195373535
599013040,10218,kowshik,2021-03-22T19:26:18Z,"the implementation compromises on the ordering, since it converts the iterator to a set. is that intentional?",0,0.9714127779006958
599014824,10218,kowshik,2021-03-22T19:29:04Z,"this particular test checks a number of things together in one test. instead, could sections (1) to (4) from below each be defined as a separate unit test? especially since each section seems to operate on a different segment, so it seems logically independent.",0,0.9873759746551514
599016901,10218,kowshik,2021-03-22T19:32:49Z,could we add test(s) for `highestlogoffset` api?,0,0.9956132173538208
599018475,10218,kowshik,2021-03-22T19:35:22Z,could we assert just before this line that `seg3s350` is not empty? this will simplify the `seg3s350.orelse(null)` argument to `seg3s350.get()`. (same comment applies for other places in this test),0,0.9947237968444824
599021005,10218,kowshik,2021-03-22T19:39:17Z,"should we alter the other arguments too, for example `broker_id` and `eventtimestamp`? it appears that we expect `remotelogmetadatacache` to [a link], and this may include the other fields as well.",0,0.9939295053482056
599021666,10218,kowshik,2021-03-22T19:40:23Z,can we remove this c'tor in exchange for the default generated c'tor?,0,0.9954466223716736
599024909,10218,kowshik,2021-03-22T19:45:33Z,"as per the interface we [a link] the caller to ensure unique id, but is it useful to add a guard that disallows replacing existing values?)",0,0.9942979216575623
599026440,10218,kowshik,2021-03-22T19:47:57Z,"we could add a c'tor overload to [a link] that takes a `throwable` as argument, it would the need to pass 2 args here.",0,0.9934188723564148
599027282,10218,kowshik,2021-03-22T19:49:15Z,probably better to say `...must be greater than or equal to...` ?,0,0.986160397529602
599029284,10218,kowshik,2021-03-22T19:52:27Z,"hmm, do we need to explicitly check if `endposition` < `segment.length`?",0,0.984514594078064
599029805,10218,kowshik,2021-03-22T19:53:16Z,is this intentionally left empty?,0,0.9906490445137024
606249948,10218,satishd,2021-04-02T13:59:30Z,"it takes `math.min(endposition, segment.length)`. so, no need to have that check.",0,0.9933518171310425
606249998,10218,satishd,2021-04-02T13:59:36Z,right.,0,0.9789980053901672
606250883,10218,satishd,2021-04-02T14:01:49Z,"yes, it can happen to generate an event with the same state incase of retries.",0,0.9919304251670837
606251255,10218,satishd,2021-04-02T14:02:48Z,good catch. this is addressed in the latest commit.,1,0.989221453666687
606253220,10218,satishd,2021-04-02T14:07:45Z,"i thought earlier about having different methods, but it checks `listallsegments/listsegment(leaderepoch)` apis that return earlier segments. but i will have a separate test for that and extract as suggested.",0,0.9943055510520935
606253804,10218,satishd,2021-04-02T14:09:07Z,we can add that.,0,0.9943116903305054
606257469,10218,satishd,2021-04-02T14:17:46Z,"sure, i will add that.",0,0.9872575402259827
606343187,10218,junrao,2021-04-02T17:40:10Z,indicate => indicates ditto in a few other places.,0,0.9946564435958862
606348092,10218,junrao,2021-04-02T17:52:27Z,"the following table is a bit hard to read for developers. since this is not meant for a public interface, could we make it more readable for developers?",0,0.64418625831604
606348477,10218,junrao,2021-04-02T17:53:24Z,i guess this is an internal class. will this be exposed in javadoc since currently it includes **/org/apache/kafka/server/log/remote/storage/* ?,0,0.9886518120765686
607191843,10218,junrao,2021-04-05T16:41:07Z,could we include remotelogsegmentmetadata in the exception message?,0,0.9942025542259216
607196509,10218,junrao,2021-04-05T16:49:33Z,should we include metadataupdate in the message of the exception?,0,0.9941015839576721
607205642,10218,junrao,2021-04-05T17:05:49Z,this comment is confusing since there is no update here.,-1,0.6702069640159607
607211862,10218,junrao,2021-04-05T17:17:23Z,"hmm, during unclean leader election, some of the old segments may need to be added to unreferenced segment id list but may not have the exact offset of the new segment. how are those segments handled here?",0,0.9881598949432373
607225040,10218,junrao,2021-04-05T17:40:58Z,it's weird to reference offsettoid here since it's in a separate class.,-1,0.9891563653945923
607226551,10218,junrao,2021-04-05T17:43:59Z,is the test for remotelogsegmentstate.copy_segment_finished necessary since it seems that only segments with remotelogsegmentstate.copy_segment_finished exist in offsettoid.,0,0.9943729639053345
607241348,10218,junrao,2021-04-05T18:10:59Z,updatehighestlogoffset => maybeupdatehighestlogoffset ?,0,0.9942992925643921
607247458,10218,junrao,2021-04-05T18:22:28Z,when are entries in leaderepochentries removed?,0,0.9947801828384399
607249504,10218,junrao,2021-04-05T18:26:13Z,"since existingstate can be null, we want to handle it properly.",0,0.992235004901886
607250466,10218,junrao,2021-04-05T18:27:51Z,should we requirenonnull for topicidpartition here too?,0,0.9929541945457458
607255605,10218,junrao,2021-04-05T18:37:31Z,this is an existing issue. but is `>` in line 37 expected?,0,0.9920239448547363
607256604,10218,junrao,2021-04-05T18:39:31Z,is this constructor needed?,0,0.9948399662971497
607546803,10218,satishd,2021-04-06T06:19:42Z,no. javadoc is generated for clients module with the package `/org/apache/kafka/server/log/remote/storage/ `. but this class is in `remote-storage` module.,0,0.9907248616218567
607546852,10218,satishd,2021-04-06T06:19:45Z,"sure, i will make it as simple ascii text.",0,0.9907576441764832
607551710,10218,satishd,2021-04-06T06:27:06Z,it prints null. i may be missing something here. what needs to be handled here?,0,0.9823878407478333
607556778,10218,satishd,2021-04-06T06:33:21Z,looks like autoformatter changed it.,0,0.9859544634819031
607559905,10218,satishd,2021-04-06T06:38:20Z,"good point, this check is no more needed.",1,0.9759864211082458
607561788,10218,satishd,2021-04-06T06:40:35Z,not really needed for now.,0,0.8104738593101501
607562925,10218,satishd,2021-04-06T06:41:59Z,updated the comment.,0,0.9901649355888367
607580027,10218,satishd,2021-04-06T07:07:24Z,"yes, in the case of unclean leader election, the leader will remove the old segments for the respective leader epochs. the removal process involves removing the actual segment and updating the respective metadata of the segments.",0,0.9910901784896851
607597875,10218,satishd,2021-04-06T07:30:13Z,one way to do that is to clear the entry when the respective `remotelogleaderepochstate` is empty. that means all the segments reached `delete_segment_finished` state. this is not currently addressed. i plan to look into it when we integrate these apis with remotelogmanager by exploring other options too.,0,0.9908246397972107
607959239,10218,kowshik,2021-04-06T15:34:20Z,nit: remove empty ``,0,0.9929834604263306
607959314,10218,kowshik,2021-04-06T15:34:24Z,nit: remove empty ``,0,0.9929834604263306
607972558,10218,kowshik,2021-04-06T15:50:20Z,should we call this map as `idtoleaderepochstate` or `idtoepochstate` similar to the naming for the other map?,0,0.9928038716316223
608025473,10218,kowshik,2021-04-06T16:58:53Z,"same comment as before: [a link] can srcstate be null in practice? if not, this can be defined as an instance method.",0,0.9950180053710938
608820288,10218,satishd,2021-04-07T16:40:30Z,the key is not really `id` but `epoch num`. what about `remotelogleaderepochstateentries` or `leaderepochtostate` or any other better name?,0,0.9913528561592102
608822419,10218,satishd,2021-04-07T16:43:31Z,"yes, it can be null. it is called from [a link]",0,0.9933701753616333
609073411,10218,junrao,2021-04-07T21:13:57Z,it would be useful to add a comment on whether the methods in this class are thread-safe or not.,0,0.9927688837051392
609083684,10218,junrao,2021-04-07T21:32:55Z,it seems that it's inconsistent that we update highest log offset here but not in handlesegmentwithcopysegmentstartedstate(). could we comment on whether highestlogoffset reflects the segments that have reached copy_segment_finished or not?,0,0.9897226095199585
609089991,10218,junrao,2021-04-07T21:45:33Z,it would be useful to document the meaning of the following table.,0,0.9926010966300964
609093303,10218,junrao,2021-04-07T21:52:28Z,could we make it clear this is for offset range?,0,0.993202805519104
609095034,10218,junrao,2021-04-07T21:56:11Z,"at this point, rlmm hasn't cleared all its internal state yet.",0,0.9732014536857605
609097289,10218,junrao,2021-04-07T22:00:24Z,is this logging needed? does it need to be in info level?,0,0.9943997263908386
609100380,10218,junrao,2021-04-07T22:05:53Z,could we make it clear this is for offset range?,0,0.993202805519104
609103486,10218,junrao,2021-04-07T22:11:25Z,is this logging needed? ditto below.,0,0.9948205947875977
609104878,10218,junrao,2021-04-07T22:14:31Z,it's kind of weird that the segment with epoch 0 is already deleted and yet we still expect the highest offset for epoch 0 to be returned.,-1,0.9860854148864746
609107657,10218,junrao,2021-04-07T22:21:00Z,listremotelogsegments(0) => listremotelogsegments(1),0,0.9944080114364624
609351020,10218,satishd,2021-04-08T06:32:43Z,we may have this as debug level by default. it will be helpful to see for which entry the test is failed.,0,0.9933631420135498
609352593,10218,satishd,2021-04-08T06:35:08Z,we may have this as debug level by default. it will be helpful to see for which `epochoffset` the test is failed.,0,0.9932283759117126
609369185,10218,satishd,2021-04-08T06:57:19Z,"sure, i will add the doc. they are currently not thread safe. but we want to address them when we integrate these apis.",0,0.9896405339241028
609369253,10218,satishd,2021-04-08T06:57:24Z,"after thinking through this more, we need to update this only when the segment reaches copy_segment_finished. this is effectively used to find out up to which offset the segments are already copied. i will remove the call here and keep the call only in handlesegmentwithcopysegmentfinishedstate. wdyt?",0,0.9905598759651184
609369434,10218,satishd,2021-04-08T06:57:37Z,added a note.,0,0.9937124848365784
609369536,10218,satishd,2021-04-08T06:57:42Z,done,0,0.8682363629341125
609369903,10218,satishd,2021-04-08T06:58:06Z,updated.,0,0.9768958687782288
609372137,10218,satishd,2021-04-08T07:01:06Z,`highestlogoffset` can contain the deleted segments. `highestlogoffset` means the highest offset up to which the segments have been copied. pl take a look at the [a link].,0,0.9946359992027283
609372257,10218,satishd,2021-04-08T07:01:14Z,done,0,0.8682363629341125
609387061,10218,satishd,2021-04-08T07:20:04Z,updated.,0,0.9768958687782288
609882620,10218,junrao,2021-04-08T16:29:27Z,this is redundant.,0,0.5116507411003113
609891200,10218,junrao,2021-04-08T16:38:55Z,could we move this to debug level then?,0,0.993925154209137
609895193,10218,junrao,2021-04-08T16:44:18Z,could we add a todo comment here so that we don't forget about it?,0,0.9941527247428894
609896011,10218,junrao,2021-04-08T16:45:25Z,sounds good. could you make the change in the pr?,1,0.7558379173278809
609998576,10218,kowshik,2021-04-08T18:45:30Z,`leaderepochtostate` sounds good.,0,0.8943455219268799
610286497,10218,kowshik,2021-04-09T02:14:20Z,here is a slightly simpler version: [code block],0,0.993881344795227
610293058,10218,kowshik,2021-04-09T02:26:22Z,"hmm here we assume that `id` should be present in the provided `idtosegmentmetadata`. due to programming error, or other reasons, the caller may not be able to ensure this. would it be safer if we instead threw whenever `id` is absent in `idtosegmentmetadata` to catch that case?",0,0.980933666229248
610298531,10218,kowshik,2021-04-09T02:37:36Z,"the add call won't replace an existing element with the same `remotelogsegmentid`. is that expected? for example, what happens if `addcopyinprogresssegment` is called twice but this line doesn't replace the existing entry?",0,0.9923606514930725
610302012,10218,kowshik,2021-04-09T02:44:27Z,"nit: add one whitespace at the end after ""...state""",0,0.9952906370162964
610305248,10218,kowshik,2021-04-09T02:50:25Z,is this method expected to be idempotent? note: this comment is related to my other comment: [a link],0,0.9954734444618225
610454559,10218,satishd,2021-04-09T08:42:52Z,"imho, existing code looks easy to read/comprehend, and no multiple calls to hasnext(). how about the below code after removing inline variables in the existing code? [code block]",0,0.8604635000228882
610462859,10218,satishd,2021-04-09T08:55:44Z,it already replaces the existing entry [a link].,0,0.9947423934936523
610464252,10218,satishd,2021-04-09T08:57:54Z,addressed in the above [a link].,0,0.994979202747345
610491754,10218,kowshik,2021-04-09T09:40:59Z,sounds good,1,0.8904690742492676
610494457,10218,kowshik,2021-04-09T09:45:34Z,"ok, i think this is fine then.",0,0.8571202754974365
610494694,10218,kowshik,2021-04-09T09:45:53Z,sounds good,1,0.8904690742492676
610517070,10218,satishd,2021-04-09T10:23:25Z,"good point, i will add a check for that.",1,0.969848096370697
610809710,10218,junrao,2021-04-09T17:53:19Z,typo epty,0,0.9729658365249634
610940157,10218,satishd,2021-04-09T22:50:50Z,"yes, it is done.",0,0.7432959079742432
610940434,10218,satishd,2021-04-09T22:51:56Z,"yes, i updated the pr.",0,0.9936544895172119
610944855,10218,satishd,2021-04-09T23:07:59Z,fixed.,0,0.9905837774276733
611267145,10218,kowshik,2021-04-12T00:13:25Z,typo: the title of the last column should be `delete_segment_finished`.,0,0.9951268434524536
611305646,10218,satishd,2021-04-12T03:25:13Z,"thanks, addressed it in the latest commit.",1,0.6724210381507874
1335136107,14432,vamossagar12,2023-09-24T07:16:06Z,i have taken the liberty and updated the log line to use an argument based loggers instead of the string concatenation based pattern that existed before.,0,0.9893823862075806
1338285360,14432,vamossagar12,2023-09-27T08:53:33Z,this is not necessarily needed but added to avoid situations when a non static member tries to send a member epoch -2.,0,0.9947633147239685
1338844884,14432,kirktrue,2023-09-27T16:04:11Z,"this is for the case where the static member is leaving temporarily, right? would it be possible to add more detail to these error messages to aid in troubleshooting/debugging on the client when this condition is hit?",0,0.993735134601593
1338849515,14432,kirktrue,2023-09-27T16:07:34Z,nice! can we add the group id to the 'static member' log message?,1,0.9847258925437927
1338895795,14432,vamossagar12,2023-09-27T16:34:12Z,"yes, that's correct. i have added some debugging information (like groupid etc). let me know if that makes sense.",0,0.9156641364097595
1338895972,14432,vamossagar12,2023-09-27T16:34:19Z,done.,0,0.9897913336753845
1338900198,14432,vamossagar12,2023-09-27T16:37:16Z,"also, `memberid can't be empty.` string is used in other places as well (when member epoch is > 0 or equal to -1. should we look to change those as well?",0,0.9940066337585449
1344754813,14432,kirktrue,2023-10-03T21:19:41Z,"it's just my preference, so if there's precedent for how you have it, i wouldn't hold up this pr in an effort to change the other places. thanks!",1,0.9856939911842346
1345450086,14432,vamossagar12,2023-10-04T08:57:24Z,"makes sense. i think i updated that one comment. but yeah the rest of the loggers, i won't be touching them, as that would be noisy to review.",0,0.9722073078155518
1348694911,14432,dajac,2023-10-06T13:02:39Z,nit: indentation should be 4 spaces.,0,0.9914741516113281
1348699907,14432,dajac,2023-10-06T13:07:25Z,i suppose that this must be a `timelinehashmap`.,0,0.9902358651161194
1348700266,14432,dajac,2023-10-06T13:07:46Z,nit: indentation should be four spaces.,0,0.9913485646247864
1348701917,14432,dajac,2023-10-06T13:09:15Z,the state should not be updated like this. all the updates are handled in the `replay()` methods.,0,0.9934192299842834
1348845154,14432,dajac,2023-10-06T15:03:46Z,could we add custom message to all the exceptions raise in this method?,0,0.9935745596885681
1348855163,14432,dajac,2023-10-06T15:11:38Z,i wonder if we really need the second part of the condition here. what was your thinking about it?,0,0.9557411670684814
1348858332,14432,dajac,2023-10-06T15:14:12Z,this is a bit weird because you pass `existingmember` to the builder and then you still have to override other fields. would it be better to do `new consumergroupmember.builder(existingmember)` and then override the fields? i think that we only need to set the new member id. nit: the indentation should be four spaces.,-1,0.9326899647712708
1348858959,14432,dajac,2023-10-06T15:14:33Z,"as said previously, the state should not be updated here but in replay.",0,0.9902772903442383
1348859279,14432,dajac,2023-10-06T15:14:48Z,nit: indentation.,0,0.9926022887229919
1348861003,14432,dajac,2023-10-06T15:15:53Z,i wonder if we could log something here as well when a static member is replaced.,0,0.9722421169281006
1348864154,14432,dajac,2023-10-06T15:18:25Z,this does not seem correct because we will write a record whenever the member is not updated and we have an instance id. i think that it would be better to capture the fact that we have a new static member in the condition at l801.,0,0.9856173396110535
1348866036,14432,dajac,2023-10-06T15:19:51Z,"i just thought about something else. when a static member is replaced, we need to write records to erase the state of the previous member.",0,0.9808419942855835
1348872341,14432,dajac,2023-10-06T15:24:47Z,i would rather prefer to have a separate method for the static leave group.,0,0.9521484971046448
1348872557,14432,dajac,2023-10-06T15:24:57Z,nit: indentation.,0,0.9926022887229919
1348873017,14432,dajac,2023-10-06T15:25:14Z,nit: should we introduce a constant for -2 as well?,0,0.9877809286117554
1348874306,14432,dajac,2023-10-06T15:26:16Z,we don't need to use getormaybecreatestaticmember here as we only want to look up the member by its id.,0,0.993564784526825
1348875180,14432,dajac,2023-10-06T15:26:59Z,"in there, we need to update the static id mapping in updatemember and removemember, i think.",0,0.9931946992874146
1354486658,14432,vamossagar12,2023-10-11T09:00:09Z,done.,0,0.9897913336753845
1354487016,14432,vamossagar12,2023-10-11T09:00:16Z,done.,0,0.9897913336753845
1354488025,14432,vamossagar12,2023-10-11T09:00:44Z,"makes sense, i have removed this direct update of states and moved it to `replay()`",0,0.9919822812080383
1354491971,14432,vamossagar12,2023-10-11T09:02:44Z,actually this is no longer required. have removed it.,0,0.9938458800315857
1354492275,14432,vamossagar12,2023-10-11T09:02:53Z,ack.,0,0.5866091847419739
1354505609,14432,vamossagar12,2023-10-11T09:06:55Z,yes that was a miss. i have added relevant tombstone records for the replaced static member and also cancelled it's timers.,0,0.9889051914215088
1354506320,14432,vamossagar12,2023-10-11T09:07:07Z,added.,0,0.9917559623718262
1354506847,14432,vamossagar12,2023-10-11T09:07:17Z,done,0,0.8682363629341125
1354507878,14432,vamossagar12,2023-10-11T09:07:33Z,done,0,0.8682363629341125
1354516913,14432,vamossagar12,2023-10-11T09:10:20Z,this method is no longer being used. i added custom messages in the other method which is now being called.,0,0.9954512715339661
1354518973,14432,vamossagar12,2023-10-11T09:10:51Z,"yes, that didn't quite make sense. it's not needed anymore. fixed indent as well.",0,0.9870781898498535
1354520295,14432,vamossagar12,2023-10-11T09:11:12Z,this bit of code has changed now.,0,0.9928961396217346
1362101057,14432,dajac,2023-10-17T13:19:21Z,nit: we tend to use a single line for getters. eg. ` the member id corresponding to the given instance id or null if it does not exist`.,0,0.9911500215530396
1362102003,14432,dajac,2023-10-17T13:20:03Z,nit: we don't prefix getters with `get`. let's add javadoc as well.,0,0.9891979098320007
1362105275,14432,dajac,2023-10-17T13:22:21Z,nit: would it make sense to have a method like the others? i would also do this before calling `maybeupdategroupstate`.,0,0.9722654223442078
1362105499,14432,dajac,2023-10-17T13:22:30Z,ditto.,0,0.9384599328041077
1362106636,14432,dajac,2023-10-17T13:23:12Z,let's add unit tests for the new or changed methods to the corresponding file.,0,0.9946507811546326
1362197123,14432,dajac,2023-10-17T14:13:31Z,i think that the old member will be in `members` so the computed target assignment is incorrect. we need to remove it with `removemember` and we also need to set the target assignment of the new member from the old one.,0,0.9894188046455383
1362197956,14432,dajac,2023-10-17T14:14:04Z,we have similar code somewhere else. could we add a method for this and reuse it?,0,0.9938181042671204
1362198218,14432,dajac,2023-10-17T14:14:15Z,same for this one. it would be great to have a method.,0,0.5067263245582581
1362200665,14432,dajac,2023-10-17T14:15:44Z,"i am not sold on this. is it too difficult to reuse the main logic? there are a few issues with this approach. for instance, the member's assignment is not reconciled like we do in the main logic. another one is that the subscription metadata must be updated as well if the subscriptions have changed.",-1,0.5396908521652222
1362215540,14432,dajac,2023-10-17T14:23:59Z,i don't fully get this one. could you please elaborate?,0,0.6122457385063171
1363301832,14432,vamossagar12,2023-10-18T06:22:35Z,"the main reason for extracting this out was that while using the main logic, there always always a group epoch bump even when a new static member replaces an older one. when i debugged it further, it seems to be because of this logic [a link] . more specifically, the issue at hand is that `subscriptionmetadata` has partition racks info while the currently stored metadata doesn't have it. this is with regards to the test `teststaticmembergetsbackassignmentuponrejoin`. i wasn't totally sure if this is an issue with the test itself but since this led to a group epoch bump, i thought we shouldn't do it. actually when i think about it now, maybe it makes sense to have a group epoch bump in this case as well. while it might go against no rebalance during static member rejoin but the reason for rejoin is a change in subscription metadata and not a static member re-join. the latter seemed harder to replicate via tests though because it always bumped up the group epoch due to the above mentioned issue. please let me know your thoughts.",0,0.9732022285461426
1363322519,14432,vamossagar12,2023-10-18T06:35:12Z,"i missed the `removemembers` part. thanks for pointing it out. regarding i assumed, this [a link] should take care of it. was my assumption wrong?",1,0.9709314703941345
1363327084,14432,vamossagar12,2023-10-18T06:38:42Z,"this is mainly needed for the static member rejoin case. let's say a static member with instance id `id` departed. when it departs, we would write a member epoch value of -2 against it. now, if a new static member joins with the same instance id `id` and a member epoch value of 0, then without this condition, the rejoin would always fail with `fencedmemberepochexception`. this condition was added to avoid the same.",0,0.9917397499084473
1363408245,14432,dajac,2023-10-18T07:51:33Z,"well, at the moment, a new target assignment will be computed for the new static member and that block of code will indeed create the record for it. what i meant is that the new static member should actually reuse the target assignment of the previous member (vs computing a new one). then we only need to recompute the assignment if there is a group epoch bump.",0,0.9940192699432373
1363414003,14432,dajac,2023-10-18T07:55:20Z,hum... i am not sure to fully follow. the subscription metadata should not be different if the subscriptions and the metadata image have not changed. does the new static member has the same subs as the previous one in your case?,0,0.5853793621063232
1363419939,14432,dajac,2023-10-18T07:58:37Z,"i see. would it make sense to put this condition first in the method, before `if (receivedmemberepoch > member.memberepoch())`? i got confused by the fact that it is within the if branch.",0,0.9580506086349487
1370523697,14432,vamossagar12,2023-10-24T16:47:34Z,"yeah, that makes sense as well. i placed it inside the if condition because this condition at hand shows up only when received epoch > current member epoch. but it should be ok to have it outside as you said. i have made the change.",0,0.9733215570449829
1370523927,14432,vamossagar12,2023-10-24T16:47:47Z,done.,0,0.9897913336753845
1370524066,14432,vamossagar12,2023-10-24T16:47:54Z,done.,0,0.9897913336753845
1370531600,14432,vamossagar12,2023-10-24T16:52:34Z,"i got around the issue by explicitly setting the rack info in the subscription metadata like [a link]. i guess so far this wasn't apparent because all the tests expected a group epoch bump happening. in this case, we didn't want a group epoch bump and hence i could notice the discrepancy.",0,0.9909895062446594
1370532536,14432,vamossagar12,2023-10-24T16:53:25Z,that makes sense and thanks for the explanation. i have now changed the code to remove the existing static member and add the new static member. rest of the state would remain as is.,1,0.9755481481552124
1370532706,14432,vamossagar12,2023-10-24T16:53:34Z,done.,0,0.9897913336753845
1370533114,14432,vamossagar12,2023-10-24T16:54:00Z,done.,0,0.9897913336753845
1370533226,14432,vamossagar12,2023-10-24T16:54:07Z,done.,0,0.9897913336753845
1370538866,14432,vamossagar12,2023-10-24T16:55:35Z,"also, regarding given that now we will have a group epoch bump whenever a static member re-joins with a different subscription, should this be mentioned in the kip? as we noticed, this is a deviation from how the static member rejoining with a different subscription case as of today. wdyt?",0,0.9922440648078918
1370539621,14432,vamossagar12,2023-10-24T16:55:51Z,done.,0,0.9897913336753845
1370539793,14432,vamossagar12,2023-10-24T16:55:59Z,done.,0,0.9897913336753845
1370542261,14432,vamossagar12,2023-10-24T16:58:01Z,", i realised that even in the static member re-joining case, while the group epoch doesn't bump, the partitions would be in pending assignment state. i believe, eventually the member would get it's assignments. in that case, this state seems correct to me. wdyt?",0,0.9602720141410828
1377556564,14432,dajac,2023-10-31T13:05:28Z,"i wonder if we could simplify it even more. for instance, would it be possible to have something like the following: [code block]",0,0.9574495553970337
1377557816,14432,dajac,2023-10-31T13:06:15Z,if we rely on `member` and `updatedmember` then we don't need this because `!updatedmember.equals(member)` will catch the new member.,0,0.9934199452400208
1377567890,14432,dajac,2023-10-31T13:14:15Z,i don't fully understand how this would work because the members and the target assignment are not set.,0,0.7205199003219604
1377571172,14432,dajac,2023-10-31T13:16:47Z,"when the `targetassignmentbuilder` builds the spec for the assignor, it must use the target assignment of the previous static member for the new static member. how do we ensure this? we may have to update the `targetassignmentbuilder` to understand that a static member is replaced.",0,0.9923256635665894
1377572235,14432,dajac,2023-10-31T13:17:39Z,"don't we need to also force the step 3.? if we don't do it, we don't write the current assignment record for the new member and we don't reconcile him.",0,0.9806713461875916
1377575023,14432,dajac,2023-10-31T13:19:44Z,nit: removememberandcanceltimers? the logic is not tight to static members. i would also directly pass the groupid and the memberid as this is all it needs.,0,0.9943371415138245
1377614473,14432,dajac,2023-10-31T13:46:48Z,"this is actually executed twice. once here and once in `consumergroupstaticmembergroupleave`. i also wonder if we need to full validation here. i suppose that ensuring that the member id is correct would be enough, no?",0,0.988681435585022
1377615301,14432,dajac,2023-10-31T13:47:21Z,nit: we check this twice. once here and once earlier to lookup the member. could we combine them?,0,0.992883563041687
1377616732,14432,dajac,2023-10-31T13:48:07Z,"nit: `""[groupid {}] static member {} with member id {} left the consumer group.""`? i would also use a similar logging structure for the other log messages.",0,0.9940953254699707
1377617256,14432,dajac,2023-10-31T13:48:25Z,nit: let's align the description of the params.,0,0.994239330291748
1377617520,14432,dajac,2023-10-31T13:48:35Z,nit: `member`?,0,0.9926477670669556
1377619412,14432,dajac,2023-10-31T13:49:40Z,nit: the `addall` does not seem necessary here. could we avoid it?,0,0.9890176057815552
1377621712,14432,dajac,2023-10-31T13:50:48Z,nit: we can reduce the space between the name and the desc.,0,0.9928869605064392
1377623260,14432,dajac,2023-10-31T13:51:46Z,"nit: let's use `""memberid can't be empty.""` to be consistent with the previous errors.",0,0.992525577545166
1377624326,14432,dajac,2023-10-31T13:52:27Z,i think that the instance id cannot be null and cannot be empty as well. then let's use `instanceid can't be null or empty.`,0,0.9904277324676514
1377625954,14432,dajac,2023-10-31T13:53:36Z,could we add something to the exception?,0,0.9931271076202393
1383610866,14432,vamossagar12,2023-11-06T16:27:59Z,i have updated the logic in line with your suggestion.,0,0.9940798878669739
1383611138,14432,vamossagar12,2023-11-06T16:28:11Z,"yes, that makes sense.",0,0.9811934232711792
1383612141,14432,vamossagar12,2023-11-06T16:28:57Z,i have added members and target assignment.,0,0.995062530040741
1383612935,14432,vamossagar12,2023-11-06T16:29:33Z,i think i got it now. i added some state tracking to the `targetassignmentbuilder` so that it doesn't compute assignments for a replacing static member.,0,0.9594680666923523
1383615616,14432,vamossagar12,2023-11-06T16:30:58Z,"yes, i am now building the replacing static member with the same set of assignments (target/pending). this forces it directly to have the current assignment record for the new member.",0,0.9946293234825134
1383616531,14432,vamossagar12,2023-11-06T16:31:09Z,done.,0,0.9897913336753845
1383617107,14432,vamossagar12,2023-11-06T16:31:17Z,removed.,0,0.9612457156181335
1383617522,14432,vamossagar12,2023-11-06T16:31:25Z,done.,0,0.9897913336753845
1383617966,14432,vamossagar12,2023-11-06T16:31:31Z,done.,0,0.9897913336753845
1383618637,14432,vamossagar12,2023-11-06T16:31:41Z,done.,0,0.9897913336753845
1383620879,14432,vamossagar12,2023-11-06T16:32:19Z,added.,0,0.9917559623718262
1397018204,14432,dajac,2023-11-17T10:00:25Z,i would just use `instanceid can't be null.` here. i think that we should also verify that the instance id is not empty.,0,0.9908532500267029
1397269098,14432,dajac,2023-11-17T13:01:00Z,nit: it seems that we could declare this one only when we use it at l948.,0,0.9919101595878601
1397287511,14432,dajac,2023-11-17T13:14:27Z,i still find this logic quite complex to follow. i wonder if we could be a little more explicit. i think that the complexity comes from `throwifstaticmembervalidationfails` which hide quite a lot of the logic. i wonder if something as follow would be better. i am not sure... what do you think? [code block] note that i just wrote this without testing it so the code is likely not 100% correct :).,1,0.9638622403144836
1397290332,14432,dajac,2023-11-17T13:16:47Z,i would say `[groupid {}] static member {} with instance id {} joins the consumer group.`,0,0.9938040971755981
1397291443,14432,dajac,2023-11-17T13:17:55Z,"i was thinking about this a little more and i actually wonder if we need this after all. if we don't see it, i think that the reconciliation will kick in and compute the current assignment. what do you think?",0,0.874160647392273
1397321543,14432,dajac,2023-11-17T13:35:23Z,is the condition really correct? it seems to me that we must remove the previous member whenever staticmemberreplaced is true. how about the following? [code block],0,0.9945547580718994
1397322222,14432,dajac,2023-11-17T13:35:48Z,nit: let's keep this log message where it was.,0,0.7701568603515625
1397350631,14432,dajac,2023-11-17T13:54:43Z,how about the following? [code block],0,0.9959434866905212
1397353174,14432,dajac,2023-11-17T13:56:52Z,"instead of doing this, could we just pass the mapping from the consumergroup?",0,0.9919373393058777
1397356292,14432,dajac,2023-11-17T13:59:21Z,"it is a tad annoying that we have to build this mapping here because we usually only need it for one member. instead of doing this, i wonder if we could lookup the member id from the instance id mapping and then get the target assignment of the member id. the mapping will contain the previous member or nothing.",-1,0.9894612431526184
1397360473,14432,dajac,2023-11-17T14:02:39Z,should we remove this as the member is not there anymore?,0,0.9932485818862915
1397363828,14432,dajac,2023-11-17T14:05:27Z,nit: let's put this comment before `consumergroupmember member2updatedepoch = ...`.,0,0.9480367302894592
1397366414,14432,dajac,2023-11-17T14:06:46Z,"if i recall correctly, we automatically do this in `consumergroupheartbeat()`.",0,0.9923027753829956
1397366873,14432,dajac,2023-11-17T14:06:58Z,nit: `member...`.,0,0.9866794943809509
1397367189,14432,dajac,2023-11-17T14:07:11Z,nit: `member...` and `.` at the end.,0,0.9920699000358582
1397368692,14432,dajac,2023-11-17T14:08:31Z,i suppose that this is not required as it don't be called.,0,0.9825396537780762
1397369747,14432,dajac,2023-11-17T14:09:29Z,nit: let's remove this empty line.,0,0.9770078659057617
1397373074,14432,dajac,2023-11-17T14:11:28Z,nit: we can remove this empty line.,0,0.9919142723083496
1397376607,14432,dajac,2023-11-17T14:14:25Z,should we also verify that the timers are cancelled correctly?,0,0.9945631623268127
1397378393,14432,dajac,2023-11-17T14:15:52Z,"do we test all possible error cases? thinking of fenced instance id, unknown member id, fenced member epoch, etc.",0,0.989496648311615
1397379496,14432,dajac,2023-11-17T14:16:50Z,"this is true if the member leaves with -2. if it leaves with -1, it should be removed immediately. should we test this as well?",0,0.9942354559898376
1397382111,14432,dajac,2023-11-17T14:18:37Z,i wonder if we could add a few more tests. thinking about the following ones: * the leaving static member should disappear if the new one does not rejoin with the session timeout. * the new data structures should be updated correctly on replay.,0,0.9709294438362122
1397383047,14432,dajac,2023-11-17T14:19:27Z,"should we simplify a bit this test? we only need on member in the group to verify what we want here. we could also use one topic only, etc.",0,0.9904091358184814
1397383490,14432,dajac,2023-11-17T14:19:50Z,we could also simplify this one.,0,0.9922628402709961
1397383760,14432,dajac,2023-11-17T14:20:04Z,this one as well.,0,0.9908092021942139
1399522392,14432,vamossagar12,2023-11-20T17:22:47Z,sure. `instance id should not be empty` check is already happening [a link],0,0.9874322414398193
1402215662,14432,vamossagar12,2023-11-22T15:12:10Z,"actually, `groupepoch == targetassignmentepoch` is not needed. i was just trying to ensure that the group epoch and target member epoch are the same which is what will happen when static member is replaced. so, in a way it's redundant. i will remove it.",0,0.9919993281364441
1402217667,14432,vamossagar12,2023-11-22T15:13:39Z,"if i don't set `setassignedpartitions`, then the replacing static member doesn't get it's assignments back. the pending assignments bit, i added just to ensure all assignments from previous member are assigned to the new member. the reason that happens is that it lands up [a link] and if there are no partitions assigned, it gets back empty assignments.",0,0.9922375082969666
1404037483,14432,dajac,2023-11-24T07:50:21Z,i would rather use `instanceid can't be null.` here in order to be consistent with the other error messages.,0,0.9830401539802551
1404037631,14432,dajac,2023-11-24T07:50:33Z,i suppose that we could remove this one now. could we?,0,0.9892917275428772
1404037934,14432,dajac,2023-11-24T07:50:54Z,is it still necessary with the last implementation?,0,0.9921122789382935
1404038516,14432,dajac,2023-11-24T07:51:40Z,nit: `leave` -> `leave`.,0,0.9858325719833374
1404039007,14432,dajac,2023-11-24T07:52:16Z,should we also log something in this case?,0,0.9942650198936462
1404039730,14432,dajac,2023-11-24T07:53:14Z,nit: i would put `member` as the first argument to be consistent with the other helpers.,0,0.9939735531806946
1404042879,14432,dajac,2023-11-24T07:57:03Z,"* could we move those helpers next to `throwifmemberepochisinvalid`? could we also add some javadoc to each of them? * i wonder if we could also find better names for the params because it is not clear whether `memberid` and `instanceid` are the ones of the existing member or the ones received in the request. we could perhaps use `receivedmemberid`, etc. what do you think? this also applies to the other helpers.",0,0.9829825758934021
1404047713,14432,dajac,2023-11-24T08:02:56Z,i wonder if we could follow the structure of the other log messages here: `[groupid {}] static member {} with instance id {}....`.,0,0.9715122580528259
1404047826,14432,dajac,2023-11-24T08:03:06Z,should we also log something here?,0,0.9936908483505249
1404050011,14432,dajac,2023-11-24T08:05:46Z,nit: `.` at the end.,0,0.9906408190727234
1404050141,14432,dajac,2023-11-24T08:05:56Z,nit: `.` at the end.,0,0.9906408190727234
1404051525,14432,dajac,2023-11-24T08:07:38Z,"nit: could we also use `records = ` here? with this, we could remove `new arraylist<>()` when `records` is declared, i think.",0,0.9840556383132935
1404058043,14432,dajac,2023-11-24T08:15:26Z,nit: let's revert this change as it is not necessary.,0,0.9837403893470764
1404062478,14432,dajac,2023-11-24T08:20:30Z,"i am not sure to follow this one. my understanding is that we populate `staticmembers` only when `addorupdatemember` is called. in the main flow, we basically call this only once with the new or updated member. let's imagine that a new static member joins. we will add its static id with its member id to `staticmembers`. therefore here, we basically get back its member id and end up with no assignment. did i get this right? i think that this could work but we would need to pass the `staticmembers` mapping from the `consumergroup` to the builder, like we pass the members. if we have this, we could use it here to find the previous member with the static id if the member is new and has a static id.",0,0.9274924397468567
1404070683,14432,dajac,2023-11-24T08:29:42Z,nit: `instance id {} is unknown.`?,0,0.9921361207962036
1404071502,14432,dajac,2023-11-24T08:30:30Z,nit: `static member {} with instance id {} cannot join the group because the instance id is owned by member {}.`?,0,0.9930504560470581
1404072143,14432,dajac,2023-11-24T08:31:17Z,nit: `static member {} with instance id {} was fenced by member {}.`?,0,0.9922389984130859
1404124114,14432,dajac,2023-11-24T09:22:48Z,"to close on this one, it is indeed correct to set the assigned partitions here. without it, the reconciler checks if the partitions in the target assignment are still owned and they are effectively still owned until the previous member is removed. this only happens when the records are processed.",0,0.9943215847015381
1404125908,14432,dajac,2023-11-24T09:24:32Z,i think that we could also `setpartitionspendingrevocation` to empty because we know that the member has revoked all its partitions when it leaves.,0,0.9874944090843201
1404157968,14432,dajac,2023-11-24T09:52:34Z,"this should not be here. i think that you mix in two different things. `addgroupmember` is basically what is used to build what will be passed to `withmembers` and `withtargetassignment` whereas `updatemembersubscription` is for `addorupdatemember`. therefore, the test does not reproduce how we use it.",0,0.9879653453826904
1404158564,14432,dajac,2023-11-24T09:53:07Z,this one is incorrect as well because the newly added member is not added via `withmembers`.,0,0.9898070693016052
1404163349,14432,dajac,2023-11-24T09:57:41Z,nit: indentation seems off here. i think that it should be 4 spaces earlier.,0,0.8771096467971802
1404164525,14432,dajac,2023-11-24T09:58:45Z,nit: indentation is incorrect.,0,0.8056420683860779
1404165368,14432,dajac,2023-11-24T09:59:30Z,nit: indentation.,0,0.9926022887229919
1404167570,14432,dajac,2023-11-24T10:01:35Z,let's replace `-2` with the relevant constant. there are other cases in this file.,0,0.9947136044502258
1404168570,14432,dajac,2023-11-24T10:02:31Z,nit: temporarily leave?,0,0.7234814167022705
1404172073,14432,dajac,2023-11-24T10:05:48Z,we already have `testconsumerheartbeatrequestvalidation` so i wonder if we could just add the new case there. what do you think?,0,0.9885004758834839
1404172650,14432,dajac,2023-11-24T10:06:25Z,nit: indentation.,0,0.9926022887229919
1405732004,14432,vamossagar12,2023-11-27T07:18:31Z,no it is not. removed it.,0,0.9877076745033264
1405732141,14432,vamossagar12,2023-11-27T07:18:43Z,added a log line,0,0.9947222471237183
1405732647,14432,vamossagar12,2023-11-27T07:19:24Z,"done, moved the methods next to `throwifmemberepochisinvalid`, added javadocs and updated the argument names.",0,0.9945118427276611
1405733434,14432,vamossagar12,2023-11-27T07:20:28Z,done.,0,0.9897913336753845
1405737202,14432,vamossagar12,2023-11-27T07:25:42Z,"yes, your understanding is correct. i see what you are saying about how this won't work when a new static member joins. i have updated the group to expose the current set of static members in the group.",0,0.9821237921714783
1405737404,14432,vamossagar12,2023-11-27T07:26:02Z,thank you for the confirmation.,1,0.6571263074874878
1405738152,14432,vamossagar12,2023-11-27T07:27:02Z,"i see. thanks for the explanation, i hadn't understood the usage of these methods correctly. i have removed these unwanted calls to `updatemembersubscription`",1,0.9598933458328247
1405739030,14432,vamossagar12,2023-11-27T07:28:09Z,ok.. i am slightly confused by this comment. the new member is being added using `addgroupmember` which internally invokes `withmembers`. i had an unwanted call to `updatemembersubscription` which i have removed. probably i am missing something here.,0,0.6529591083526611
1405785516,14432,dajac,2023-11-27T08:13:45Z,i think that we should call `updatemembersubscription` instead of calling `addgroupmember` here because `updatemembersubscription` is what is used to eventually call `addorupdatemember`.,0,0.9861749410629272
1331125886,14408,dajac,2023-09-20T07:24:58Z,nit: you could use `foreach` which is a bit more concise.,0,0.989916980266571
1331127964,14408,dajac,2023-09-20T07:26:29Z,"nit: let's put `delete-group` on a new line as well. could you also ensure that the format conforms to the existing code? e.g. where the closing parenthesis is, the indentation (4 spaces), etc.",0,0.9931879043579102
1331129777,14408,dajac,2023-09-20T07:27:57Z,it may be better to use `join` instead of `get`. i think that you would be able to remove the try..catch if you use `join`.,0,0.9916486740112305
1331132885,14408,dajac,2023-09-20T07:30:11Z,"let's assume that one of the write operation fails with `coordinator_load_in_progress`, this would result in failing `allfutures` even though some write operations may have been successful. it seems to me that we should handle exceptions for each write operation future before we combine them, no?",0,0.9912077188491821
1331133058,14408,dajac,2023-09-20T07:30:21Z,nit: indentation.,0,0.9926022887229919
1331134867,14408,dajac,2023-09-20T07:31:13Z,nit: indentation. there are other cases in this pr. i won't mention them all.,0,0.9665679335594177
1331141079,14408,dajac,2023-09-20T07:36:09Z,"i have a few comments regarding this piece of code: 1. i think that we should write the tombstones for the offsets before the ones for the group. 2. it is a bit strange to return a coordinatorresult from `deletealloffsets` and to ignore it. it would be better to pass the list of records to the method and to let the method populate it if the deletion is accepted. i would also remove the response as we don't need it. 3. the `validgroupids` is a bit weird. how about iterating over the group ids here? then, you can call the various methods from the manages to validate, delete offsets and finally delete the group. if there is an error, you can directly populate the response with it.",-1,0.5723336338996887
1331143758,14408,dajac,2023-09-20T07:37:23Z,"`newgroupmetadatatombstonerecord` only works for generic groups. for consumer groups, we need to write other tombstones.",0,0.9923880100250244
1331145296,14408,dajac,2023-09-20T07:38:32Z,we should not write the record if subscribedtotopic is true because it will effectively delete the offset.,0,0.9895349144935608
1331146404,14408,dajac,2023-09-20T07:39:23Z,"as i said earlier, i think that returning coordinatorresult is not appropriate here because we don't need a response in this case. we basically build for the response to ignore it right after.",0,0.9806878566741943
1331958841,14408,dongnuo123,2023-09-20T17:19:03Z,"yeah, it makes sense. i'm not sure what to return if there's an exception in the write operation, since we can't set an error code for a `deletablegroupresultcollection`.",0,0.9732077717781067
1331960774,14408,dongnuo123,2023-09-20T17:20:56Z,done,0,0.8682363629341125
1331961151,14408,dongnuo123,2023-09-20T17:21:20Z,done,0,0.8682363629341125
1331961609,14408,dongnuo123,2023-09-20T17:21:49Z,done,0,0.8682363629341125
1331969154,14408,dongnuo123,2023-09-20T17:29:14Z,"i rearranged this part. now we loop over the group ids and process them one by one -- validate, populate record list with offset tombstones, add group tombstone, and add response.",0,0.9938589930534363
1331969312,14408,dongnuo123,2023-09-20T17:29:25Z,done,0,0.8682363629341125
1332009903,14408,dongnuo123,2023-09-20T18:08:40Z,fixed.,0,0.9905837774276733
1332010169,14408,dongnuo123,2023-09-20T18:08:59Z,fixed,0,0.920660674571991
1332010328,14408,dongnuo123,2023-09-20T18:09:11Z,fixed,0,0.920660674571991
1332057781,14408,dajac,2023-09-20T18:59:25Z,`deletablegroupresultcollection` contains `deletablegroupresult` which has an error code. therefore i think that we should create a `deletablegroupresult` per group id in the `grouplist` when there is an exception.,0,0.9914088845252991
1332069169,14408,dajac,2023-09-20T19:11:34Z,i think that we need to generate the above records here. * newtargetassignmentepochtombstonerecord * newgroupsubscriptionmetadatatombstonerecord * newgroupepochtombstonerecord,0,0.9905996918678284
1332072625,14408,dajac,2023-09-20T19:15:21Z,do we need this coordinatorresult?,0,0.9952432513237
1332073736,14408,dajac,2023-09-20T19:16:28Z,"this is the same as newgroupepochtombstonerecord, no?",0,0.9947085380554199
1332632377,14408,dajac,2023-09-21T07:53:22Z,"nit: i wonder if we should use `topicpartitionfor` here. with this, we could directly have the topicpartition as the key in the map and we would not need to create `new topicpartition(topic.group_metadata_topic_name, partition)` later on. what do you think?",0,0.9438430666923523
1332633082,14408,dajac,2023-09-21T07:53:58Z,nit: we could specify the size of the array when we allocate it.,0,0.992183268070221
1332637192,14408,dajac,2023-09-21T07:56:43Z,nit: you could do the following to avoid having to put the list again into the map. [code block],0,0.9904183745384216
1332637739,14408,dajac,2023-09-21T07:57:13Z,nit: `res.addall(future.join())` to reduce the code?,0,0.9937096834182739
1332656181,14408,dajac,2023-09-21T08:12:15Z,"it is interesting to point out that, in the current implementation, all these errors are swallowed. this is definitely not ideal because it tells to the user that the deletion is successful even if was not. should we apply the same error handling to the deletegroups?",0,0.9717690944671631
1332661430,14408,dajac,2023-09-21T08:16:25Z,nit: we can remove this empty line.,0,0.9919142723083496
1332661944,14408,dajac,2023-09-21T08:16:51Z,"nit: `deletealloffsets`? i also wonder if the context is required. if not, we could remove it.",0,0.9909492135047913
1332664716,14408,dajac,2023-09-21T08:18:59Z,the coordinatorresult is a bit annoying here. how about passing `records` to the method as well? then we could construct the response here. we could also remove the context if it is not needed. how about naming it `deletegroup` to be consistent with `deleteoffsets`?,-1,0.7229831218719482
1332665059,14408,dajac,2023-09-21T08:19:14Z,nit: we could remove this empty line?,0,0.985602855682373
1332667219,14408,dajac,2023-09-21T08:20:58Z,"i have a question regarding the error handling. could `groupdelete` thrown an exception? if it can, we would need to handle records a bit differently because we don't want to delete the offsets if the group cannot be delete. the operation should be atomic.",0,0.9827287793159485
1332667737,14408,dajac,2023-09-21T08:21:23Z,nit: the indentation is incorrect.,0,0.8192443251609802
1332670356,14408,dajac,2023-09-21T08:22:52Z,nit: let's remove this empty line and add javadoc to the method.,0,0.9934822916984558
1332672724,14408,dajac,2023-09-21T08:23:41Z,nit: indentation is incorrect.,0,0.8056420683860779
1332679503,14408,dajac,2023-09-21T08:28:21Z,"let's do the validation before allocating response, records, etc. we don't have to allocate them if the request is invalid. `group` could also be `final`.",0,0.9934738278388977
1332679648,14408,dajac,2023-09-21T08:28:28Z,nit: final?,0,0.9827909469604492
1332680359,14408,dajac,2023-09-21T08:29:01Z,"i think that the try..catch is not needed here because we handle the exceptions in the group coordinator service, no?",0,0.990574061870575
1332682319,14408,dajac,2023-09-21T08:30:30Z,nit: `response = ` is not needed here as `settopics` mutates the response directly.,0,0.9938200116157532
1332689518,14408,dajac,2023-09-21T08:35:32Z,i wonder if we need to verify if there is actually an offset for the topic/partition. we don't need to write a tombstone if there is not. what do you think?,0,0.96622234582901
1332692288,14408,dajac,2023-09-21T08:37:43Z,i think that a consumer group will actually never transition to dead. we could actually remove this state.,0,0.969440221786499
1332692487,14408,dajac,2023-09-21T08:37:52Z,ditto.,0,0.9384599328041077
1332693494,14408,dajac,2023-09-21T08:38:40Z,i wonder if using a switch would be better here. what do you think?,0,0.9363503456115723
1332694686,14408,dajac,2023-09-21T08:39:31Z,this does not seem correct to me because this exception does not apply to consumer groups.,0,0.9766951203346252
1332695102,14408,dajac,2023-09-21T08:39:47Z,"as mentioned earlier, we have to generate other tombstones.",0,0.9913312196731567
1332697684,14408,dajac,2023-09-21T08:41:20Z,throwing an exception does not seem to be the right approach to me because we still want to delete the group and the exception will stop the process. my understanding is that we could just skip generating the tombstone if the generation <= 0.,0,0.9644966125488281
1333162337,14408,dajac,2023-09-21T14:32:57Z,"actually, what i said is wrong here. i think that we should generate the tombstone in any cases to ensure that the group is removed from the timeline hashmap.",0,0.8970164656639099
1333326880,14408,rreddy-22,2023-09-21T16:24:11Z,"nit: can we add a tab space and capitalize ""the"" -> topic the topic name.",0,0.9935123324394226
1333327696,14408,rreddy-22,2023-09-21T16:24:52Z,"also i thought we had decided to use topicids instead of topic names throughout the new protocol, are we using topic names for this api?",0,0.9924357533454895
1333329945,14408,rreddy-22,2023-09-21T16:26:53Z,"nit: same with this, tab spaces to align both param descriptions",0,0.9939093589782715
1333331492,14408,rreddy-22,2023-09-21T16:28:22Z,nit: extra line,0,0.8243594765663147
1333348886,14408,rreddy-22,2023-09-21T16:42:49Z,nit: period is missing,0,0.9745963215827942
1333554676,14408,jeffkbkim,2023-09-21T20:11:58Z,"let's say that for some of the topic partitions, the deletegroups write operations were successful. for others, let's say that there was a timeout. this would return a request timeout to the clients indicating that the request failed. i think this is fine, but it could be confusing to the user. what are your thoughts?",0,0.8550657629966736
1333558630,14408,jeffkbkim,2023-09-21T20:16:28Z,we can use collections.singletonlist(),0,0.9940755367279053
1333583218,14408,jeffkbkim,2023-09-21T20:45:18Z,this can be null right? if there are no offsets for the given group id,0,0.992900013923645
1333600423,14408,jeffkbkim,2023-09-21T21:01:38Z,"nit: handles ""a"" maybe we can reword this to ""deletes offsets as part of a deletegroups request.""",0,0.993024468421936
1333601100,14408,jeffkbkim,2023-09-21T21:02:28Z,"nit: `(partition, __) ->`",0,0.9921846985816956
1333615622,14408,jeffkbkim,2023-09-21T21:20:16Z,should it be `offsetsbytopic.get(topic.name())`?,0,0.9950705766677856
1333615893,14408,jeffkbkim,2023-09-21T21:20:40Z,should this be `containskey(partition.partitionindex())`?,0,0.9953517913818359
1334471084,14408,dajac,2023-09-22T14:37:24Z,i made the same comment earlier and updated the code to handle exceptions for each write operation.,0,0.9865402579307556
1334519906,14408,dajac,2023-09-22T15:15:50Z,offsets apis still use topic names...,0,0.9930346012115479
1336162536,14408,rreddy-22,2023-09-25T16:56:06Z,got it okie!,1,0.9812915325164795
1336165006,14408,rreddy-22,2023-09-25T16:58:32Z,nit: can we add new lines between the tests,0,0.9940382242202759
1336165306,14408,rreddy-22,2023-09-25T16:58:52Z,nit: line,0,0.9381727576255798
1336168777,14408,rreddy-22,2023-09-25T17:02:31Z,nit: line,0,0.9381727576255798
1336348269,14408,jeffkbkim,2023-09-25T20:18:12Z,i wonder if creategrouptombstonerecords() makes more sense,0,0.9590954184532166
1336363313,14408,jeffkbkim,2023-09-25T20:36:10Z,"nit: ""deletegroups"" request. this should reflect the actual apikeys#delete_groups name",0,0.9958459734916687
1336441437,14408,jeffkbkim,2023-09-25T22:24:33Z,"can we add a test with three __consumer_offsets topic partitions where one finishes immediately, another takes a while, and the last coordinator throws an exception?",0,0.9928330183029175
1336446270,14408,jeffkbkim,2023-09-25T22:33:21Z,"nit: testdeletegroups also, can we verify the number of method invocations and also test that we append records correctly for multiple groups?",0,0.9949609041213989
1336446500,14408,jeffkbkim,2023-09-25T22:33:44Z,nit: testdeletegroupsinvalidgroupid can we also add a valid group id and verify the first stores invalid group id error and the second stores none?,0,0.9954527616500854
1336449678,14408,jeffkbkim,2023-09-25T22:38:58Z,should this be a static method?,0,0.9898423552513123
1336451305,14408,jeffkbkim,2023-09-25T22:42:01Z,we can inline this to l380,0,0.9939363598823547
1336461743,14408,jeffkbkim,2023-09-25T23:01:52Z,this can be removed,0,0.9951673746109009
1336461886,14408,jeffkbkim,2023-09-25T23:02:11Z,we can do `consumergroup::validategroupdelete` for this along with the other invocations in the test,0,0.9947137236595154
1336465543,14408,jeffkbkim,2023-09-25T23:10:02Z,should we add empty test case? also for testvalidategroupdelete,0,0.9946542978286743
1339019021,14408,jeffkbkim,2023-09-27T18:13:35Z,should these be deletegroup?,0,0.9908714890480042
1339020329,14408,jeffkbkim,2023-09-27T18:14:44Z,whether,0,0.9542939066886902
1339025948,14408,jeffkbkim,2023-09-27T18:19:28Z,"should this be ""delete-groups""?",0,0.9886168837547302
1339176820,14408,jeffkbkim,2023-09-27T20:29:44Z,"validations are done in `{ groupcoordinatorshard#deletegroups(requestcontext, list)}`",0,0.9955670237541199
1339182547,14408,jeffkbkim,2023-09-27T20:34:35Z,ditto on link can we add a comment on why we don't expect an exception to be thrown here?,0,0.9951340556144714
1339194498,14408,jeffkbkim,2023-09-27T20:45:50Z,the id of the group to be deleted.,0,0.9888728260993958
1339198942,14408,jeffkbkim,2023-09-27T20:50:06Z,"in the existing implementation, we transition to dead if the group is empty so that even if the write operation fails we delete the group in the next purge cycle. we don't need to do this here since if the write operation fails we revert to the previous state and return an error so the client knows that the operation failed. is this correct?",0,0.99347984790802
1339201386,14408,jeffkbkim,2023-09-27T20:52:23Z,the current implementation logs how many groups and offsets were removed. should we add something similar? [code block],0,0.9957203269004822
1339216413,14408,jeffkbkim,2023-09-27T21:06:07Z,can we move this check outside of the foreach block? we perform this check for every partition of the topic,0,0.99498051404953
1339228792,14408,jeffkbkim,2023-09-27T21:17:29Z,don't we also need to check whether the stable group is using the consumerprotocol.protocol_type? from [code block],0,0.9951189756393433
1339232259,14408,jeffkbkim,2023-09-27T21:21:07Z,"should this be ""delete-offsets""?",0,0.9877368211746216
1339234027,14408,jeffkbkim,2023-09-27T21:22:59Z,do we need this?,0,0.9930108189582825
1339235261,14408,jeffkbkim,2023-09-27T21:24:20Z,can we follow the same line break as in l1101-1102? same for result2,0,0.995218813419342
1339255544,14408,jeffkbkim,2023-09-27T21:46:00Z,"in general, it's not a good practice to use thread.sleep in tests. also, i don't think this tests what we actually want to test. we want to confirm that the final future is not completed until this operation completes. so i propose: 1. have this thread wait 2. confirm future did not complete 3. unblock this thread 4. confirm future completes something like the following: [code block]",0,0.9010124802589417
1340712345,14408,dajac,2023-09-28T22:14:06Z,nit: could we refactor `geterrorresponse` to use this new method as well? should we also add a unit test for this one?,0,0.9920591115951538
1340712743,14408,dajac,2023-09-28T22:14:53Z,i wonder if we should rather pass the list of records as an argument in order to avoid having to copy the records afterwards. have you considered this?,0,0.9690492749214172
1340716345,14408,dajac,2023-09-28T22:22:06Z,nit: should we set the expected size here?,0,0.991144597530365
1340716744,14408,dajac,2023-09-28T22:22:57Z,"good question. in my opinion, this log line is useful for the expiration case. i am not sure if it really is in this one.",1,0.9809905290603638
1340717283,14408,dajac,2023-09-28T22:24:01Z,nit: let's remove this empty line.,0,0.9770078659057617
1340717524,14408,dajac,2023-09-28T22:24:31Z,nit: should we just add this to the document of the groupid field?,0,0.9924345016479492
1340720235,14408,dajac,2023-09-28T22:29:11Z,"do we ever transition to dead? if not, i wonder if we should just remove this and remove the dead state. what do you think?",0,0.9296808838844299
1340720555,14408,dajac,2023-09-28T22:29:51Z,nit: i wonder if using a switch would be better here. have you considered it?,0,0.9619302749633789
1340720632,14408,dajac,2023-09-28T22:30:01Z,nit: ditto for the switch.,0,0.9853680729866028
1340744802,14408,dajac,2023-09-28T23:20:18Z,nit: could we put `setgroupid` on a new line as well?,0,0.9929156303405762
1340745968,14408,dajac,2023-09-28T23:23:13Z,nit: the `null` here is not ideal. could we put a string instead? or you could also use coordinator_load_in_progress.exception().,0,0.9704524874687195
1340747829,14408,dajac,2023-09-28T23:27:23Z,"i am not sure to understand what you are trying to achieve here. could you elaborate? if you want to delay the completion of the future, the best would be to create a completablefuture, use thenreturn(future), and then complete the future at l1149.",0,0.6962732076644897
1340749921,14408,dajac,2023-09-28T23:33:00Z,is there a reason why you don't use when().thenanswer(...)?,0,0.9934779405593872
1340750286,14408,dajac,2023-09-28T23:33:55Z,could we also use `groupids` to generate the list here?,0,0.9941072463989258
1340750616,14408,dajac,2023-09-28T23:34:52Z,ditto for those two.,0,0.972556471824646
1340750923,14408,dajac,2023-09-28T23:35:44Z,nit: could we put an empty line before this one? i find the code a bit hard to read because all the lines are all together.,0,0.685563325881958
1340752025,14408,dajac,2023-09-28T23:38:51Z,"small nit: it may be a bit easier to read if we create the expected response as follow? what do you think? if you find it better, we could also update the other test cases. [code block]",0,0.9645175933837891
1340752304,14408,dajac,2023-09-28T23:39:37Z,should we at minimum verify the group ids here?,0,0.9929474592208862
1340753404,14408,dajac,2023-09-28T23:42:35Z,"in the groupmetadatamanagertestcontext, we actually moved this to the replay method. see [a link]. it may be better to do the same here. what do you think?",0,0.9904271364212036
1340753611,14408,dajac,2023-09-28T23:43:06Z,nit: indentation should be 4 spaces.,0,0.9914741516113281
1340753971,14408,dajac,2023-09-28T23:44:05Z,should we move this method to the test context?,0,0.9942442774772644
1340754157,14408,dajac,2023-09-28T23:44:38Z,we could also apply my formatting suggestion here.,0,0.9950881600379944
1340754965,14408,dajac,2023-09-28T23:46:50Z,"this block is really hard to parse. [code block] would it be better like this? otherwise, i would use a regular if statement.",-1,0.9825655221939087
1340756205,14408,dajac,2023-09-28T23:50:13Z,what does `invalidoffset` mean here?,0,0.9858300089836121
1340756359,14408,dajac,2023-09-28T23:50:43Z,ditto.,0,0.9384599328041077
1340757038,14408,dajac,2023-09-28T23:52:20Z,could we use `grouptype` instead? then you could use a switch based on the enum.,0,0.994342565536499
1340757258,14408,dajac,2023-09-28T23:52:59Z,nit: could we put an empty line here?,0,0.9868254065513611
1340783686,14408,jeffkbkim,2023-09-29T01:11:23Z,"the current [a link] transitions groups to dead once a group is empty && offsets are gone. the current behavior for generic groups is the above, and i copied the same behavior for consumer groups. then once the group is dead, it will be considered for expiration in the next cycle.",0,0.9940859079360962
1340783926,14408,jeffkbkim,2023-09-29T01:12:09Z,should we at least log the number of groups that were deleted from the deletegroups request?,0,0.9924700260162354
1340788752,14408,jeffkbkim,2023-09-29T01:27:40Z,"this was my suggestion. your suggestion is much simpler, thanks!",1,0.9773564338684082
1341653044,14408,dajac,2023-09-29T17:49:06Z,"i am not sure to understand why we need to do this. couldn't we just delete the group when it is empty and offsets are gone instead of transitioning to dead and then deleting it? my understanding is that we use dead in the old code because we can't remove the group from the map before the change is committed to the log. during this time, the group is in the dead state. in our world, the group is remove from the map immediately and the change is reverted if the write fails.",0,0.7941336035728455
1341917129,14408,yangy0000,2023-09-30T06:16:35Z,error handling codes in lines 555-586 and 797-816 are very similar. an alternative implementation is create a util method: [code block] within deletegroups : [code block] within deleteoffsets: [code block],0,0.9946948885917664
1341918630,14408,yangy0000,2023-09-30T06:34:17Z,nit: the else braces can be simplified to [code block],0,0.995011568069458
1341919233,14408,yangy0000,2023-09-30T06:42:12Z,"no check on ""issubscribedtotopic"" in here? is this expected?",0,0.9919840693473816
1342599402,14408,dajac,2023-10-02T12:02:33Z,nit: given that there is only one test. i would rather move everything into that test.,0,0.8962651491165161
1342610382,14408,dajac,2023-10-02T12:13:55Z,"i am +1 for bringing the definition of `offsetsbypartition` within the `else` clause. however, we have to keep using `topic.partitions().foreach(` to iterate over the partitions. however, i don't like `if(offsetsbypartition ==null) {continue};`. how about using `offsetsbypartition != null`?",1,0.7022567987442017
1342611067,14408,dajac,2023-10-02T12:14:42Z,"no, we don't need it here because the group is completely removed in this case.",0,0.9902746677398682
1342627317,14408,dajac,2023-10-02T12:31:57Z,i wonder if we should rather log this within the shard in order to have it logged per shard (with the shard context). what do you think?,0,0.9675933718681335
1342628078,14408,dajac,2023-10-02T12:32:46Z,nit: how about `return allfutures.thenapply...`?,0,0.9904002547264099
1342632075,14408,dajac,2023-10-02T12:36:58Z,"nit: would it make sense to use? we don't really need `response` except here. ``` return new coordinatorresult<>( records, new offsetdeleteresponsedata().settopics(responsetopiccollection) );",0,0.9861195087432861
1342635373,14408,dajac,2023-10-02T12:40:21Z,nit: could we use `state() != empty`? this would be more robust.,0,0.9865795969963074
1342640395,14408,dajac,2023-10-02T12:45:34Z,i wonder if we should test all the exceptions that we re-map. i did something similar in `testconsumergroupheartbeatwithexception`. what do you think?,0,0.9763225317001343
1342641976,14408,dajac,2023-10-02T12:47:11Z,ditto about the error mapping verification.,-1,0.5150080323219299
1342642294,14408,dajac,2023-10-02T12:47:29Z,can't we use `assertequals`?,0,0.994010329246521
1342643914,14408,dajac,2023-10-02T12:48:59Z,it would be better to use the other way in order to remain consistent with the other tests. is this possible?,0,0.9922775030136108
1342645279,14408,dajac,2023-10-02T12:50:17Z,nit: expectederror?,0,0.9796852469444275
1342647294,14408,dajac,2023-10-02T12:51:42Z,"nit: should we define an helper method in the context (e.g. hasoffset(groupid, topic, partition))? i would also bring `error == errors.none` back on the previous line because it fits there.",0,0.9931017160415649
1342851207,14408,yangy0000,2023-10-02T15:33:32Z,any chance deletealloffsets will get invoked before the group is completely removed?,0,0.9905111193656921
1343253093,14408,jeffkbkim,2023-10-02T23:24:28Z,was this addressed?,0,0.9949475526809692
1343255509,14408,jeffkbkim,2023-10-02T23:30:33Z,"also, we can remove the `v`",0,0.994744062423706
1343257434,14408,jeffkbkim,2023-10-02T23:34:56Z,nit: an,0,0.9782214760780334
1343258721,14408,jeffkbkim,2023-10-02T23:38:09Z,"""at this point, we have already validated the group id so we know that the group exists and that no exception will be thrown."" how's this?",0,0.9917575716972351
1343258959,14408,jeffkbkim,2023-10-02T23:38:35Z,"nit: can we change all usages of ""id"" to ""id""?",0,0.9883989095687866
1343259306,14408,jeffkbkim,2023-10-02T23:39:31Z,we can move these into the test as well,0,0.9929006099700928
1343259404,14408,jeffkbkim,2023-10-02T23:39:45Z,"we can remove the ""v""",0,0.9944813251495361
1343260319,14408,jeffkbkim,2023-10-02T23:41:35Z,what's the benefit of using final variables here?,0,0.9886259436607361
1343262352,14408,jeffkbkim,2023-10-02T23:46:19Z,we can use [code block],0,0.9963578581809998
1343263220,14408,jeffkbkim,2023-10-02T23:48:18Z,nit: newline,0,0.987245500087738
1343263632,14408,jeffkbkim,2023-10-02T23:49:12Z,?,0,0.9296892285346985
1343266197,14408,jeffkbkim,2023-10-02T23:54:55Z,can we use [code block] and remove the helper method?,0,0.99580317735672
1343267277,14408,jeffkbkim,2023-10-02T23:57:24Z,can we assert true that the future is done?,0,0.9897990226745605
1343267559,14408,jeffkbkim,2023-10-02T23:57:57Z,can we use [code block] and remove the helper?,0,0.9957888722419739
1343269222,14408,jeffkbkim,2023-10-03T00:01:47Z,can we change all of the `dosomething...when...` to `when().dosomething`?,0,0.995119571685791
1344182771,14408,dajac,2023-10-03T14:14:31Z,"i think that we should be careful with this. the change is not 100% equivalent to the previous implementation here because the error message is not set for all errors whereas it was only set of a sub set before. while i agree that we could do better, i would suggest to tackle this in a separate pr.",0,0.9412554502487183
1344185641,14408,dajac,2023-10-03T14:16:09Z,"nit: if we keep it, the method could be static and we usually don't prefix methods with `get`. `normalizeexception` maybe an alternative name.",0,0.987785816192627
1344186369,14408,dajac,2023-10-03T14:16:40Z,why do we need an atomicinteger here?,0,0.9884291887283325
1344187568,14408,dajac,2023-10-03T14:17:30Z,nit: `... removed.`.,0,0.9192649722099304
1344188289,14408,dajac,2023-10-03T14:17:57Z,"i guess that they don't hurt, isn't it?",0,0.842674732208252
1344189933,14408,dajac,2023-10-03T14:19:04Z,"if you look at the usage in `[a link]`, all offsets are removed before deleting the group.",0,0.993883490562439
1344192203,14408,dajac,2023-10-03T14:20:23Z,i agree. i mentioned this a few times a well.,0,0.9644573330879211
1344192583,14408,dajac,2023-10-03T14:20:34Z,ditto.,0,0.9384599328041077
1344192793,14408,dajac,2023-10-03T14:20:41Z,ditto.,0,0.9384599328041077
1344192915,14408,dajac,2023-10-03T14:20:45Z,ditto.,0,0.9384599328041077
1344193032,14408,dajac,2023-10-03T14:20:50Z,ditto.,0,0.9384599328041077
1344498860,14408,dongnuo123,2023-10-03T17:44:07Z,"if we use int, we'll get error `variable used in lambda expression should be final or effectively final`. lambda expressions do not allow any external variable operation within itself. i can add a small comment here.",0,0.993032693862915
1344502310,14408,dongnuo123,2023-10-03T17:47:11Z,when(method).dosomething requires method to return a non-void value. i can add a comment here for explanation.,0,0.9958000779151917
1344523685,14408,dongnuo123,2023-10-03T18:06:47Z,rolled back,0,0.9347694516181946
1344524665,14408,dongnuo123,2023-10-03T18:07:42Z,comment added,0,0.9801390171051025
1344524782,14408,dongnuo123,2023-10-03T18:07:49Z,comment added,0,0.9801390171051025
1344524966,14408,dongnuo123,2023-10-03T18:07:59Z,comment added,0,0.9801390171051025
1344525094,14408,dongnuo123,2023-10-03T18:08:08Z,comment added,0,0.9801390171051025
1344554094,14408,dajac,2023-10-03T18:34:48Z,ack. i wonder if we should use `for (string groupid : groupids) ....` then. what do you think?,-1,0.5292425751686096
464705276,9100,hachikuji,2020-08-03T23:00:19Z,probably reasonable to handle it the same way other inter-broker rpcs are handled.,0,0.9792523980140686
464708303,9100,hachikuji,2020-08-03T23:10:04Z,"good question. might be fair to assume the controller is correct and use stale_broker_epoch. once kip-500 is all done, it would be totally fair since the controller will be guaranteed to have the latest state. the other question is what the broker should do if it sees stale_broker_epoch...",1,0.9598350524902344
464709341,9100,hachikuji,2020-08-03T23:13:24Z,"hmm.. this adds a delay of 2.5s to every isr change, which is a bit annoying. i guess the point is to allow batching? i think a better approach might be to send requests immediately on arrival, but set a limit on the maximum number of in-flight requests (maybe just 1) and let the changes accumulate when there is a request in-flight. then we can still get a big batching benefit when there are a large number of isr changes that need to be sent in a hurry.",-1,0.9726323485374451
464710258,9100,hachikuji,2020-08-03T23:16:19Z,hmm.. not sure it's worth doing these validations up-front. these checks could fail between the time that the event is enqueued and the time it is processed.,0,0.5904409289360046
464716040,9100,mumrah,2020-08-03T23:35:25Z,that makes sense. i'll change that (this was pulled in from the previous isr notification code in replicamanager),0,0.9926546812057495
464717171,9100,mumrah,2020-08-03T23:39:05Z,"the main rationale for validating in the request handler is so we can return meaningful partition-level errors to the broker (fenced leader, not leader or follower, etc). although, i'm not sure the broker could do anything useful with these errors since it probably has stale metadata in these cases. the kip calls out four partition-level errors. do we actually need them?",0,0.9841618537902832
464718819,9100,hachikuji,2020-08-03T23:44:49Z,"to be clear, i'm not questioning the need for the validation, just the fact that it is done before enqueueing the event instead of when the event is processed.",0,0.9552295207977295
465029352,9100,mumrah,2020-08-04T12:56:33Z,"ah, i see what you mean. initially, i was concerned about blocking for too long while waiting for a response, but it looks like there is precedent for this pattern for some requests (reassignment, leader election, controlled shutdown). i'll move this validation and the callback down into the event processor method",0,0.9462135434150696
465708837,9100,cmccabe,2020-08-05T13:00:48Z,"it seems like we need to set the `insyncreplicaids` here, since we don't do it in `shrinkisr`.",0,0.9894886612892151
465711962,9100,cmccabe,2020-08-05T13:06:08Z,this is also a concurrency bug since you can't access stuff like the controllercontext except from the controller thread itself (it would be multi-threaded access without a lock),0,0.9542279243469238
465712943,9100,cmccabe,2020-08-05T13:07:48Z,this also needs to call `networkclient#wake` in case we are blocking inside `networkclient#poll`,0,0.9948287606239319
465715770,9100,cmccabe,2020-08-05T13:12:19Z,"it would be good to find a better name for this. when i read ""alterisrchannelmanager"" i assumed it had its own separate channel, rather than using the controllerchannelmanager.",0,0.9589925408363342
465743922,9100,mumrah,2020-08-05T13:54:54Z,good to know about `controllercontext` :thumbs_up:,1,0.9952186942100525
465746162,9100,mumrah,2020-08-05T13:58:00Z,"it might be simpler just to use alterisrrequestdata and alterisrresponsedata throughout this code (rather than converting to `map[topicpartition, leaderandisr]` and `map[topicpartition, errors]`)",0,0.9890769720077515
465748120,9100,mumrah,2020-08-05T14:00:36Z,"i think we need to send leaderandisr for all the given partitions whether we updated the isr or not. in cases where we failed due, the leaders likely have stale metadata. this way we can proactively send them the latest state.",0,0.9837822318077087
465748504,9100,mumrah,2020-08-05T14:01:11Z,"yea, maybe just ""alterisrmanager""?",0,0.9882059097290039
465749546,9100,mumrah,2020-08-05T14:02:38Z,should probably get rid of this and change the method to [code block],0,0.9915669560432434
465750445,9100,mumrah,2020-08-05T14:03:55Z,remove this,0,0.9827263355255127
465750632,9100,mumrah,2020-08-05T14:04:10Z,newline,0,0.9851014614105225
465888182,9100,abbccdda,2020-08-05T17:28:23Z,nit: could move these operations to the `alterisrrequest` as helpers.,0,0.9946408271789551
469372344,9100,hachikuji,2020-08-12T16:03:52Z,"with kip-500, i imagine we could end up with other cases where we end up using optimistic concurrency control. does it make sense to make this error a little more generic? maybe `invalid_update_version` or something like that..",0,0.9892790913581848
469373339,9100,hachikuji,2020-08-12T16:05:24Z,nit: maybe drop the parameters if they do not need to be documented,0,0.986657440662384
469379488,9100,hachikuji,2020-08-12T16:14:57Z,nit: info feels a bit high for a message like this,-1,0.9720281958580017
469382729,9100,hachikuji,2020-08-12T16:20:13Z,we might need to be careful about performance here since this would get called on every follower fetch.,0,0.9080222249031067
469383572,9100,hachikuji,2020-08-12T16:21:34Z,"the usage is a bit surprising given the ""pending"" name. i wonder if it would be clearer if we used a type of `option[set[int]]` so that we could use `none` when there is no pending isr change. one more thing. it's worth double-checking the threading assumptions here. it looks like `updateassignmentandisr` is only called while holding the write side of `leaderisrupdatelock`. on the other hand, i don't see any lock held in `updatefollowerfetchstate`. it's worth stepping through that logic to make sure that we do not depend on `insyncreplicaids` and `pendinginsyncreplicaids` getting set atomically.",0,0.8585340976715088
469385374,9100,hachikuji,2020-08-12T16:24:32Z,"i think the answer is no. the pending isr set is not guaranteed, so we cannot depend on it to enforce min.isr.",0,0.9770793318748474
469388095,9100,hachikuji,2020-08-12T16:29:06Z,"related to the other comment, but we need to be careful with the min.isr check below. i think it is correct to wait for `effectiveinsyncreplicaids` before acknowledging the produce request, but we should probably use the size of `insyncreplicaids` in the min.isr check since that is the only set we can guarantee.",0,0.9894216656684875
469399037,9100,hachikuji,2020-08-12T16:47:34Z,"there is a ""classic"" edge case in kafka which goes as follows: 1. leader is 1, isr is [1, 2, 3] 2. broker 3 begins controlled shutdown. while awaiting shutdown, it continues fetching. 3. controller bumps epoch and shrinks isr to [1, 2] and notifies replicas 4. before controlled shutdown completes and 3 stops fetching, the leader adds it back to the isr. this bug was fixed by kip-320 which added epoch validation to the fetch api. after shrinking the isr in step 3, the controller will send `leaderandisr` with the updated epoch to [1, 2] and `stopreplica` to [3]. so 3 will not send any fetches with the updated epoch, which means it's impossible for the leader to add 3 back after observing the shrink to [1, 2]. i just want to make sure whether above is correct and whether `alterisr` changes it in any way. i think the answer is no as long as isr expansion is _only_ done in response to a fetch request, but it's worth double-checking.",0,0.9878519773483276
469406972,9100,hachikuji,2020-08-12T17:00:32Z,i think it's worth adding a comment in the cases we rely on `effectiveinsyncreplicaids` to explain why.,0,0.986527144908905
469412587,9100,hachikuji,2020-08-12T17:10:15Z,"i think the implementation here is actually different than what was in the model. consider the following case: 1) initial state: isr=[1, 2], pendingisr=[1, 2] 2) leader expands isr. isr=[1, 2], pendingisr=[1, 2, 3] 3) leader shrinks isr. isr=[1, 2], pendingisr=[1, 2] we don't know which of the updates in 2) or 3) will be accepted, but after 3), we will not assume that broker 3 could be in the isr, which could lead to a correctness violation if the update in 2) is accepted by the controller. in the model, we always assumed the maximal isr across _any_ potential update to protect from this edge case. maybe in the end it is simpler to not allow multiple in-flight updates.",0,0.9802062511444092
469413205,9100,hachikuji,2020-08-12T17:11:21Z,nit: remove parenthesis for simpler getters like `code`. a few more of these,0,0.9914007782936096
469413455,9100,hachikuji,2020-08-12T17:11:47Z,missing license header in this file.,0,0.9767772555351257
469414718,9100,hachikuji,2020-08-12T17:13:57Z,"nit: avoid loaded terminology like ""blackout"" (see [a link] do we actually need this or `isrchangepropagationinterval` below?",0,0.978975236415863
469415543,9100,hachikuji,2020-08-12T17:15:14Z,we should use `time`,0,0.9939953684806824
469417613,9100,hachikuji,2020-08-12T17:18:30Z,probably need to reduce the log level here and below.,0,0.9800455570220947
469419452,9100,hachikuji,2020-08-12T17:21:31Z,"i think the basic approach here is to ignore successful responses and wait for the `leaderandisr` update. i am wondering how we should handle the case when the update failed. say for example that our update fails with the invalid_version error. inside `partition`, we will still have the pendingisr set. do we need to clear it? how about other errors?",0,0.9685648083686829
469421031,9100,hachikuji,2020-08-12T17:24:17Z,nit: more useful as a debug if we add request details to the message,0,0.9881783127784729
469421800,9100,hachikuji,2020-08-12T17:25:29Z,the broker epoch is not a constant. it gets reinitialized whenever the broker has to create a new session.,0,0.9926003813743591
469423834,9100,hachikuji,2020-08-12T17:28:57Z,"the term ""pending"" again is a little unclear. perhaps ""unsentisrupdates"" would make the usage clearer.",0,0.9624254703521729
469425898,9100,hachikuji,2020-08-12T17:32:22Z,removal from this set won't prevent `brokertocontrollerrequestthread` from retrying in-flight requests. i'm considering whether we should have a way to cancel requests that we are still awaiting.,0,0.9792746901512146
469460462,9100,mumrah,2020-08-12T18:33:11Z,"we don't, these were copied over from the replicamanager's isr propagation logic. i'll clean this up",0,0.9922771453857422
469467881,9100,mumrah,2020-08-12T18:46:27Z,"i'm currently looking at the effective isr to find new out of sync replicas. this can include new isr members which haven't made it into the ""true"" isr via leaderandisr yet (like broker=3 in your example). maybe we should only consider removing isr members iff they are in the true isr. iow changing from [code block] to [code block] also, i wonder if the batching that's happening in alterisrchannelmanager violates the model. it sends the request asynchronously with a small delay, so multiple isr changes can be batched into one alterisr.",0,0.9768533706665039
469516375,9100,abbccdda,2020-08-12T20:20:11Z,nit: new line,0,0.9900916814804077
470053173,9100,mumrah,2020-08-13T15:51:39Z,"yea, lots of these will be lowered, was just doing this during development",0,0.9853608012199402
470063833,9100,mumrah,2020-08-13T16:08:16Z,"i don't think alterisr changes anything since we're now just sending the async isr update where we were previously directly updating zk. looking at the usages, `updatefollowerfetchstate` is only called following a read (`partition#readrecords`). these reads only happen on fetch requests and from the alter log dirs fetcher. i'm not sure about the alter log dirs flow, but as long as it sends the leader epoch, it should be safe.",0,0.9607527256011963
470673412,9100,mumrah,2020-08-14T14:51:00Z,fixed this by adding getbrokerepoch to kafkazkclient,0,0.9934460520744324
470675300,9100,mumrah,2020-08-14T14:54:10Z,"with the latest changes to prevent multiple in-flight requests, i don't think this should happen for a given partition. even if it did, the retried in-flight request from brokertocontrollerrequestthread would fail on the controller with an old version. i'm wondering if we even need this clearpending behavior. since i changed the alterisr request to fire at most after 50ms, it's a narrow window between enqueueing an isr update and receiving a leaderandisr.",0,0.8143700957298279
470678123,9100,mumrah,2020-08-14T14:58:58Z,"since we are now only allowing one in-flight alterisr, i changed the semantics of pendinginsyncreplicaids to be the maximal ""effective"" isr. this way we don't need to compute it each time.",0,0.9939358830451965
473515635,9100,abbccdda,2020-08-20T01:36:09Z,"should we move the startup logic to `kafkaserver`? note the channel is shared between different modules, so it makes sense to start and close inside the server.",0,0.9942822456359863
474106591,9100,mumrah,2020-08-20T16:17:31Z,"i found a race during the system tests when a follower is shutting down. the controller handles the shut down before it handles an alterisr. if the proposed isr includes the now-offline replica, the controller refuses to update that isr change and returns an error for that partition. it then sends out the current leaderandisr. the problem is that the broker ignores this leaderandisr since it has the same leader epoch. this is easy enough to fix, we can bump the leader epoch in the controller (and zk) before sending it out. however, there's still the case of failing to update zk. i think we should probably treat this the same way as an offline replica. if we simply return an error in alterisr response and let the leader reset the pending isr state, the leader will just retry with stale metadata and the update will fail again. i think in all these error cases we must bump the leader epoch to force the leader to accept the new leaderandisr. thoughts?",0,0.9481827616691589
474930329,9100,mumrah,2020-08-21T20:15:17Z,it's a little tricky since leaderandisr isn't visible to alterisrrequest.,0,0.7591272592544556
474934833,9100,mumrah,2020-08-21T20:20:56Z,"update: after some discussion and looking over failed system tests, we ended up with the following error handling: * replica_not_available and invalid_replica_assignment will clear the pending isr to let the leader retry. this covers a case where a leader tries to add a replica to the isr which is offline because it (the follower) just finished shutdown. * invalid_update_version will not clear the pending isr since the broker has stale metadata. * fenced_leader_epoch, not_leader_or_follower, unknown_topic_or_partition will _not_ clear the pending state and therefor will not retry. we presume here that the controller is correct and the leader has old metadata. by not clearing the pending isr, the leader will await leaderandisr before attempting any further isr changes * other unspecified errors: clear the pending state and let the leader retry. not sure what cases could cause other errors, but it is probably better to be in a retry loop than to be completely stuck",0,0.9820906519889832
474959176,9100,mumrah,2020-08-21T20:50:34Z,continued in [a link],0,0.9945420622825623
475625111,9100,mumrah,2020-08-24T13:53:27Z,this error message should be less specific,0,0.968942403793335
475626573,9100,mumrah,2020-08-24T13:54:36Z,"need to revert this stuff, didn't mean to commit",-1,0.8765350580215454
475627290,9100,mumrah,2020-08-24T13:55:09Z,rename to alterisrmanager,0,0.99409419298172
475629593,9100,mumrah,2020-08-24T13:57:02Z,expand on this comment to discuss the maximal isr,0,0.9948417544364929
475630695,9100,mumrah,2020-08-24T13:57:55Z,fix comment to refer to correct variable,0,0.9918878674507141
475632719,9100,mumrah,2020-08-24T13:59:34Z,newline,0,0.9851014614105225
477616910,9100,hachikuji,2020-08-26T22:08:38Z,we may as well add flexible version support for the request and response.,0,0.9933630228042603
477618083,9100,hachikuji,2020-08-26T22:11:44Z,"nit: i think `alterisrresponsetopics` should be singular (similarly for other arrays in both of these schemas). also, i wonder if it's reasonable to leave off the `alterisr` prefix. we could access it as `alterisrresponse.topicdata` or something like that.",0,0.9881340861320496
477618646,9100,hachikuji,2020-08-26T22:13:13Z,nit: unneeded newline,0,0.9753468632698059
477620548,9100,hachikuji,2020-08-26T22:18:02Z,do we need this message? it seems the one on line 537 below has more detail already. it would be useful to include the zkversion in the message on 537 as well.,0,0.9943715333938599
477625772,9100,hachikuji,2020-08-26T22:32:18Z,"i am wondering if we can split this into two separate methods: - `effectiveisr`: takes into account any pending changes which may or may not have happened (i could probably also be convinced to call this `maximalisr`) - `confirmedisr`: the latest known value from zookeeper (or the controller) that makes the code easier to follow since we wouldn't have to interpret this flag. some high-level comments might be helpful as well. for example, it's useful to mention somewhere that the high watermark is always treated with respect to the effective isr.",0,0.9605590105056763
477629764,9100,hachikuji,2020-08-26T22:41:43Z,can we move this check earlier in the flow so that we can skip acquiring the write lock if there is an inflight alterisr? maybe it can be part of `needsexpandisr` and `needsshrinkisr` for example.,0,0.9929420948028564
477748433,9100,hachikuji,2020-08-27T00:16:03Z,"i have been thinking a little bit about the semantics of min.isr. basically i am wondering if should be treated as a guarantee on the state of the isr at the time the high watermark is reached (i.e. how many replicas are in the isr), or instead should it be a guarantee on the state of progress of replication (i.e. some number of replicas have reached a given offset)? we may not have ever formally decided this, but here we are taking a stance that it is the latter because we are using the effective (uncommitted) isr. one of the consequences of this view is that a leader may continue to accept appends satisfying min.isr even if the true isr never reaches min.isr. for example, imagine we have the following state: replicas: (1, 2, 3) isr: (1) leader: 1 suppose that replica 2 has caught up to the leader, but the leader is unable to expand the isr because the controller is unavailable or unreachable. with the logic here, we will nevertheless continue to satisfy acks=all requests with a min.isr of 2. i am not sure there is much choice about it to be honest. if instead we used only the ""confirmed"" isr, then we would have sort of an opposite problem. for example, consider this state: replicas: (1, 2, 3) isr: (1, 2) leader: 1 suppose the leader wants to remove 2 from the isr. the alterisr is received by the controller and the state is updated, but the controller fails to send the corresponding leaderandisr. then committing on the basis of the confirmed isr would lead to a similar problem. here is the current documentation for the config: [code block] even though it is named in terms of the isr, the documentation only discusses acks from other replicas, so it seems like the implementation here is consistent even if potentially surprising in some cases.",0,0.9411242008209229
477785759,9100,hachikuji,2020-08-27T00:35:59Z,maybe trace would be better? this could get verbose while we have an inflight alterisr.,0,0.9727395176887512
477786630,9100,hachikuji,2020-08-27T00:36:26Z,i still think we need a better name for `pendinginsyncreplicaids` since it is misleading in this case. maybe we could call it `overrideinsyncreplicaids` or something like that?,0,0.9361003041267395
477787350,9100,hachikuji,2020-08-27T00:36:50Z,nit: maybe `sendalterisrrequest`?,0,0.9927600622177124
477811336,9100,hachikuji,2020-08-27T00:49:30Z,"hmm.. i am not sure it is safe to reset `pendinginsyncreplicaids` in any case except `invalid_update_version`. for example, imagine the following sequence: 1. broker sends alterisr 2. controller writes new isr and crashes before sending response 3. broker hits session expiration 4. broker retries alterisr on new controller with old broker epoch 5. controller responds with stale_broker_epoch in this case, the isr was updated, but the broker is going to revert to the old state. i think the _only_ time we can reset `pendinginsyncreplicaids` is when we know the change could not have been applied.",0,0.8827459812164307
477817624,9100,hachikuji,2020-08-27T00:52:47Z,"the conversion logic is a tad annoying, but it makes the rest of the code nicer. i'm ok with it. that said, could we use scala conventions, e.g.: [code block]",1,0.42925959825515747
477832161,9100,hachikuji,2020-08-27T01:00:46Z,don't forget the todo!,0,0.9564478397369385
477876231,9100,hachikuji,2020-08-27T01:32:23Z,"should we try to make `alterisr` an idempotent operation? i think currently if we retry an update that was successfully applied, then we will see invalid_version. in general, i'm a bit concerned about the number of errors that are possible through this api and how the leader is supposed to handle them. i am thinking it might make our lives easier if we return some additional information in the response about what the current state really is. let's say that we always try to add the full state tuple to the response: (leaderid, epoch, isr, zkversion). then we can go through a simple process of reconciliation? - am i still the leader? - do i have the latest epoch? - has the zkversion been bumped? - did the isr change get applied? basically i'm looking for a reliable way to determine whether we should continue retrying the request and whether it is safe to clear the pending replica set. at the same time, i'm feeling a bit on-the-fence about relying exclusively on leaderandisr for state changes. if we need to return the current state in the response anyway to properly handle errors, then perhaps we may as well allow the state to be updated as well? this would actually be closer to the flow that we have today, which is the following: 1. leader changes state in zookeeper and updates current isr directly. 2. after some delay, it posts the isr update to isr_change_notifications. 3. controller picks up the notification and sends updatemetadata to all the brokers. notice that the controller does not send leaderandisr to the followers in this flow. what we could do is something more like the following: 1. leader sends alterisr to controller. 2. controller applies the change and returns the updated state. 3. leader receives the response and applies the state change. 4. after some delay, the controller sends updatemetadata to the brokers with the change. if we did this, then we wouldn't need to have the controller bump the epoch when handling alterisr. just as we do today, we can reserve epoch bumps for controller-initiated changes. then we might be able to simplify the error handling to the following: - if the epoch is the same and we are still the leader, then apply the update - if the epoch is higher, leave pendingisr set and do not bother retrying - otherwise just keep retrying what do you think?",-1,0.8332977294921875
477889557,9100,hachikuji,2020-08-27T01:43:00Z,probably not a useful log message,-1,0.8183797001838684
477892802,9100,hachikuji,2020-08-27T01:45:16Z,not sure about this. do we really want to put zk in the path to sending to the controller?,0,0.5298277139663696
477902972,9100,hachikuji,2020-08-27T01:52:41Z,this should be fixed,0,0.993543267250061
477904479,9100,hachikuji,2020-08-27T01:53:43Z,"as far as i can tell, we don't have any logic which tells us whether there is an inflight request. i am considering whether we should as a mechanism for batching/flow control. it might be simpler if we just allow one inflight request. while we are waiting for it to return, we can collect additional pending updates. in case we need to retry the request, we could coalesce the new updates into the request. note that currently `brokertocontrollerchannelmanagerimpl` currently sets max inflight requests to 1 anyway.",0,0.9827098846435547
477911757,9100,hachikuji,2020-08-27T01:59:01Z,"we seem to be losing some of the value of having a top-level error code here. as far as i can tell, the following top-level errors should be possible: 1. not_controller: should be retried (handled in `brokertocontrollerchannelmanagerimpl`) 2. stale_broker_epoch: should be retried (could we do that here?) 3. cluster_authorization_failed: probably should be fatal (can we handle that here?) seems like it might simplify the error handling if we can handle them at a corresponding granularity.",0,0.9718359708786011
477912314,9100,hachikuji,2020-08-27T01:59:22Z,nit: misaligned,0,0.6711727380752563
477916564,9100,hachikuji,2020-08-27T02:02:29Z,any particular reason to change the order here?,0,0.9895173907279968
477918557,9100,hachikuji,2020-08-27T02:03:54Z,we should probably have a try/catch in here somewhere for the unhandled errors to make sure that the callback always gets applied.,0,0.9899137020111084
477920314,9100,hachikuji,2020-08-27T02:05:17Z,maybe debug is more suitable?,0,0.9785202145576477
477921396,9100,hachikuji,2020-08-27T02:06:04Z,could be debug perhaps?,0,0.9912732243537903
478067221,9100,mumrah,2020-08-27T03:55:53Z,"i think that sounds pretty reasonable. would we need any kind of timeout at this layer, or just rely on the underlying channel to provide timeouts?",0,0.6176819801330566
478069145,9100,mumrah,2020-08-27T03:57:52Z,"i wasn't too happy about this. is there another way to get the current broker epoch? as i understand it, the broker epoch can change during the lifecycle of a broker.",-1,0.9707009196281433
486521810,9100,mumrah,2020-09-10T17:43:05Z,"i think this sounds good, explict over implicit and all that. if we have two methods like this, should we then make `insyncreplicaids` a private member?",1,0.9529074430465698
486535166,9100,mumrah,2020-09-10T18:05:57Z,"yea, good idea. i'll leave the check here since we actually acquire and release the lock when checking if we should expand/shrink. it's possible that pendinginsyncreplicaids is cleared by a leaderandisr before we acquire the write lock to do the update",1,0.8775016665458679
486535868,9100,mumrah,2020-09-10T18:07:08Z,how about `uncommittedinsyncreplicaids`?,0,0.9922826886177063
486535964,9100,mumrah,2020-09-10T18:07:20Z,"nope, will revert",0,0.980721116065979
489569400,9100,hachikuji,2020-09-16T16:29:34Z,"i know we've gone back and forth on including some of these fields. this is one i'm inclined to get rid of since we already include ""brokerid"" at the top level and `alterisr` can only be sent by leaders.",0,0.9817611575126648
489571330,9100,hachikuji,2020-09-16T16:32:40Z,nit: shall we call this `leaderid` in line with `brokerid` in the request?,0,0.9926281571388245
489572418,9100,hachikuji,2020-09-16T16:34:32Z,"can we revert this change? i think the trace logging is intended, if a bit odd.",0,0.9661980867385864
489572745,9100,hachikuji,2020-09-16T16:35:06Z,we probably need another version since we bumped the fetch protocol version yesterday.,0,0.9875507950782776
489577394,9100,hachikuji,2020-09-16T16:42:48Z,"nit: we use ""maximal"" and ""effective"" interchangeably in this pr. maybe we can choose one term and use it consistently. i do sort of like ""maximal"" since it is more suggestive of the semantics.",0,0.8459833264350891
489579590,9100,hachikuji,2020-09-16T16:46:31Z,nit: maybe `hasinflightalterisr` so that it's clearer what the return value indicates?,0,0.9922851324081421
489580384,9100,hachikuji,2020-09-16T16:47:54Z,nit: maybe we could rename `curinsyncreplicaids` to `cureffectiveisr`,0,0.9866682291030884
489582879,9100,hachikuji,2020-09-16T16:52:06Z,nit: probably need to reword mention of `leaderandisr` since the `alterisr` response is now used.,0,0.9897818565368652
489593301,9100,hachikuji,2020-09-16T17:09:49Z,nit: maybe we can check in-flight requests first (same in `needsexpandisr`). otherwise it's a little odd that `getoutofsyncreplicas` may be based on the maximal isr while we have an in-flight.,0,0.9458988904953003
489593650,9100,hachikuji,2020-09-16T17:10:29Z,nit: redundant comment,-1,0.9770928621292114
489594684,9100,hachikuji,2020-09-16T17:12:13Z,nit: you can take the topic partition out of this message since it is already included in `logident`. same on line 1262 below.,0,0.9940549731254578
489604587,9100,hachikuji,2020-09-16T17:29:38Z,"the problem is that it is a sort of worst-case isr and not the intended isr update itself. tough to come up with a good name to describe that. just for the sake of having an alternative, what if we used case classes to represent the current isr state and pending update? for example: [code block] then we can get rid of `effectiveisr`, `insyncreplicaids`, and `pendinginsyncreplicaids`.",-1,0.6474097371101379
489606127,9100,hachikuji,2020-09-16T17:32:22Z,"nit: ""... doesn't know about this **topic** or partition""?",0,0.9192010760307312
489607165,9100,hachikuji,2020-09-16T17:34:25Z,"hmm... why do we reset `pendinginsyncreplicaids` if we are retrying? unless we are guaranteed that the update failed, then i think we need to continue assuming the worst-case isr. maybe we could just could call `enqueueisrupdate` again to explicitly retry?",0,0.9488085508346558
489608511,9100,hachikuji,2020-09-16T17:36:44Z,"nit: we don't need topic partition here, but it would be nice if we could include the intended update.",0,0.9874088764190674
489608740,9100,hachikuji,2020-09-16T17:37:10Z,"nit: as long as we're updating this, can we use `$` substitutions? also can we mention that this update came from `alterisr`?",0,0.9940271377563477
489609866,9100,hachikuji,2020-09-16T17:39:09Z,"maybe helpful if these messages indicate that this `leaderandisr` can from an `alterisr` response. also, it may be useful to include the current (stale) leader epoch.",0,0.9845589995384216
489610509,9100,hachikuji,2020-09-16T17:40:19Z,"nit: similarly, we can include current `zkversion`",0,0.9948742985725403
489612385,9100,hachikuji,2020-09-16T17:43:38Z,nit: maybe we could shorten this name to just `enqueue` since the fact that it is an isr update is already implied by the argument and the name of the trait itself.,0,0.9890252947807312
489614105,9100,hachikuji,2020-09-16T17:46:39Z,nit: usually we write this as `foreach { topic =>`. avoids the extra parenthesis.,0,0.9901694655418396
489614732,9100,hachikuji,2020-09-16T17:47:43Z,nit: maybe split this into two separate methods?,0,0.9803239107131958
489617709,9100,hachikuji,2020-09-16T17:52:57Z,the use of a queue is a tad odd here. we could use `listbuffer`? also nit: use type inference.,-1,0.7391318678855896
489619376,9100,hachikuji,2020-09-16T17:55:53Z,still not super keen on this propagation delay. at least it would be nice if we did not have to wakeup the thread every 50ms when there's nothing to do. this is potentially something we can save for a follow-up since coming up with a good solution might require some experimentation and analysis.,-1,0.5982614755630493
489619767,9100,hachikuji,2020-09-16T17:56:37Z,nit: use type inference,0,0.9935489296913147
489621121,9100,hachikuji,2020-09-16T17:59:00Z,nit: can we include the broker epoch that was sent in this message?,0,0.9943406581878662
489621168,9100,hachikuji,2020-09-16T17:59:06Z,"hmm.. where does this exception get caught? since it is in the response handler, i guess that `networkclient` just eats it. perhaps we should just continue retrying so that the problem remains visible in the logs.",0,0.9646629691123962
489621815,9100,hachikuji,2020-09-16T18:00:08Z,nit: this message would be more useful if we include the response. perhaps it would be better to log each partition update separately?,0,0.9897124767303467
489622001,9100,hachikuji,2020-09-16T18:00:29Z,nit: unneeded parenthesis,0,0.9796062111854553
489623549,9100,hachikuji,2020-09-16T18:03:18Z,maybe we could log a warning and let the partition remain in `unsentisrupdates` so that it is retried until we get a response?,0,0.9895508885383606
489623929,9100,hachikuji,2020-09-16T18:04:01Z,nit: may as well convert to `errors` since we do so below anyway,0,0.855653703212738
489624854,9100,hachikuji,2020-09-16T18:05:34Z,i think authorization should probably be the first thing we do.,0,0.9784932732582092
489625184,9100,hachikuji,2020-09-16T18:06:09Z,nit: remove these lines,0,0.9909375905990601
489625611,9100,hachikuji,2020-09-16T18:07:02Z,do we still need this change? i think we are trying to keep the current approach where the controller bumps the leader epoch for any controller-initiated change.,0,0.9900296330451965
489625836,9100,hachikuji,2020-09-16T18:07:25Z,i guess we don't need this anymore.,0,0.7530348300933838
489703810,9100,mumrah,2020-09-16T19:27:49Z,"i think this has been a long-standing bad assumption on my part in this pr. i've been (mis)treating `pendinginsyncreplicaids` as a mechanism for initiating a retry along with its other semantics. you're right though, explicitly re-sending the isr is definitely better.",0,0.6003237962722778
489720971,9100,mumrah,2020-09-16T20:00:38Z,"yup, my mistake, shouldn't have been committed",-1,0.9636847972869873
489721316,9100,mumrah,2020-09-16T20:01:18Z,"""maximal"" works for me :thumbs_up:",1,0.9948658347129822
489730265,9100,mumrah,2020-09-16T20:19:09Z,"ah, missed one ;)",0,0.7150508165359497
489740479,9100,mumrah,2020-09-16T20:39:05Z,currently we impose a 2.5s delay for the old zk based isr propagation method. we could probably increase this 50ms up to a few hundred without any ill-effects. we still benefit from fact that we assume the maximal isr immediately. how about 200ms? longer term we can look into having a single thread invocation that sits in a while loop trying to consume from a linkedblockingqueue or maybe even a synchronousqueue. but agreed we should leave this for later.,0,0.985430121421814
489744561,9100,mumrah,2020-09-16T20:47:19Z,how about we raise this to an error log with the exception?,0,0.9929470419883728
489745539,9100,mumrah,2020-09-16T20:49:17Z,should we drop it to trace in that case?,0,0.9930316209793091
489747101,9100,mumrah,2020-09-16T20:52:28Z,good idea. another case not covered is if partitions are included in the response but weren't sent out. these will be ignored as things currently stand -- maybe that's ok,1,0.9617899656295776
489753946,9100,mumrah,2020-09-16T21:05:59Z,this is actually a really good point. i filed a jira to fix this in other places in kafkaapis [a link],1,0.9876032471656799
489756083,9100,mumrah,2020-09-16T21:10:09Z,"no, we don't need this anymore. this was added so a leaderandisr could update the partition state without a leader epoch bump, but we don't have that flow anymore so we can revert this.",0,0.9922613501548767
490464756,9100,hachikuji,2020-09-17T18:20:10Z,nit: `hasinflight`?,0,0.9861121773719788
490465180,9100,hachikuji,2020-09-17T18:20:54Z,nit: it's surprising to have a side effect like this in a function like this. i think it would be better to include this logging at the caller when we are considering a specific change. that way we can also include in the log message information about the change that we were intending to make.,-1,0.926191508769989
490469252,9100,hachikuji,2020-09-17T18:28:13Z,another possibility is that the replica is pending removal in which case another `alterisr` will be needed. i think it might be more intuitive to make this check: [code block],0,0.9908507466316223
490488626,9100,hachikuji,2020-09-17T19:03:35Z,i think we can refactor this a little bit to avoid some duplication and inconsistency. we have the following logic above when updating follower state: [code block] this is a little inconsistent because here we are checking `isrstate.isr`. i'd suggest splitting this method into something like the following: [code block] then we can change the logic in `maybeexpandisr` to the following: [code block],0,0.9672719836235046
490492340,9100,hachikuji,2020-09-17T19:10:10Z,seems like we do not have a check for inflight alterisr after the write lock has been acquired.,0,0.9864732027053833
490492780,9100,hachikuji,2020-09-17T19:10:50Z,"this is related to my comment above for the isr expansion case, but it is a bit confusing to use maximal isr when the expectation is that we will not shrink as long as we have a pending update inflight. would it be better to check for inflights and document that this method will return an empty set as long as there is a pending alterisr request?",0,0.8666660189628601
490494777,9100,hachikuji,2020-09-17T19:14:38Z,it might be a little more intuitive to change the order here. something like this: [code block],0,0.9840834736824036
490494975,9100,hachikuji,2020-09-17T19:14:57Z,nit: can probably rework this as `exists` [code block],0,0.9932073950767517
490527627,9100,hachikuji,2020-09-17T20:00:06Z,"since `invalid_update_version` is one of the expected errors at this level, can we add a separate case for it? for unexpected errors, we might want to log at warn level.",0,0.9931935667991638
490528339,9100,hachikuji,2020-09-17T20:01:27Z,shall we include some details about the failed request?,0,0.993956446647644
490528744,9100,hachikuji,2020-09-17T20:02:13Z,nit: rewrite with `$`,0,0.9902053475379944
490529253,9100,hachikuji,2020-09-17T20:03:19Z,i think `warn` might be too high here. we should expect to see some of these even if the cluster is working properly. how about debug?,0,0.978813648223877
490530496,9100,hachikuji,2020-09-17T20:05:35Z,nit: can we avoid using `_1` and `_2`? it's a lot easier to follow if they are named.,0,0.9836967587471008
490531814,9100,hachikuji,2020-09-17T20:08:12Z,nit: use type inference. it's conventional to write this as [code block],0,0.9922925233840942
490532481,9100,hachikuji,2020-09-17T20:09:31Z,nit: i think we can get rid of this. the logging in `controllerchannelmanager.sendupdatemetadatarequests` is probably good enough.,0,0.9560592174530029
490534060,9100,hachikuji,2020-09-17T20:12:36Z,"nit: it's subjective, so feel free to ignore, but i find this a little easier to read if we handle the error cases first. so.. [code block] basically we're discarding the error cases so that the successful path continues flowing downward and we're avoiding extra nesting. like i said, it's subjective.",0,0.8781591057777405
490534274,9100,hachikuji,2020-09-17T20:13:00Z,nit: unneeded newline,0,0.9753468632698059
490534954,9100,hachikuji,2020-09-17T20:14:26Z,nit: not sure it makes sense to include this change any longer,-1,0.6246228814125061
490536839,9100,hachikuji,2020-09-17T20:17:56Z,"i wonder if we should be exposing this. would it be enough to have a `def insyncreplicaids = isrstate.isr`? one thing we need to be a little careful of is the fact that we now have a volatile variable with multiple fields. so if you try to access two fields through the `isrstate` reference, you could see inconsistent data.",0,0.9554906487464905
490539522,9100,hachikuji,2020-09-17T20:23:10Z,need to address the todos in this class.,0,0.9909919500350952
490540789,9100,hachikuji,2020-09-17T20:25:23Z,"i may have missed it, but do we have tests which verify error handling? i see tests which verify requests get sent, but at a quick glance i didn't see tests of responses.",0,0.9656835198402405
490541557,9100,hachikuji,2020-09-17T20:26:45Z,nit: sort of conventional to use a name like `mockalterisrmanager`,0,0.9878010749816895
490542749,9100,mumrah,2020-09-17T20:29:02Z,yea i was thinking we should move the isr to a separate public accessor. i'll change this,0,0.9895411133766174
490561028,9100,mumrah,2020-09-17T21:04:05Z,"makes sense, that will also satisfy your other comment about not checking for inflight requests within the write lock",0,0.9874888062477112
490562630,9100,mumrah,2020-09-17T21:07:24Z,"also, yes it's confusing to refer to `maximalisr` here even though it should always equal the committed isr at this point (assuming we check for inflight first).",0,0.9539294838905334
490594335,9100,mumrah,2020-09-17T22:21:46Z,yea checking the maximal set isn't needed anymore since adding the sealed trait. i'll just update this to simply call `maybeexpandisr` which will do the check you propose here,0,0.9937487840652466
494480847,9100,hachikuji,2020-09-24T17:13:35Z,"consider the following scenario: 1) broker sends alterisr 2) the update succeeds but the response is lost 3) broker retries alterisr currently the leader will be stuck after 3) because it has no way to get the latest leaderandisr state if the first attempt fails. to handle this, i think we need to add an idempotence check here. after we have validated the leader epoch, if the intended state matches the current state, then we can just return the current state.",0,0.9841399192810059
494483808,9100,hachikuji,2020-09-24T17:18:40Z,"it might make more sense to handle this case similarly to fenced_leader_epoch. retrying won't help since we know our version will be rejected come to think of it, this would be kind of a strange error to hit in the current implementation which only allows one request inflight at a time. for controller-initiated changes, we'd expect to hit fenced_leader_epoch. anyway, i think it's still worth keeping the error.",0,0.9612090587615967
494486578,9100,hachikuji,2020-09-24T17:23:03Z,"is there any way that we could end up retrying after the pending isr state had already been reset? i know we have `alterisrmanager.clearpending`, but that only removes the partition from the unsent queue. how do we handle inflight `alterisr` requests after the state has been reset. seems like it might be worth adding a check here to validate whether the request is still needed.",0,0.9898062348365784
494520245,9100,mumrah,2020-09-24T18:21:33Z,"i was trying to think some kind of race with a zombie leader trying to update the isr, however this would get fenced by the leader epoch. this should be pretty easy to add",0,0.9721278548240662
494523773,9100,mumrah,2020-09-24T18:26:13Z,"true, we could see a new isr from controller initiated changes via leaderandisr while our request is in-flight. we have a check for this on successful responses, but we should also check here. since our request failed, we don't have a leaderepoch to check against so i think the best we can do is see if `isrstate` is still pending before re-sending the request",0,0.9884599447250366
494660084,9100,hachikuji,2020-09-24T23:13:45Z,"nit (for follow-up): fix grammar ""since due""",0,0.9916961789131165
494660983,9100,hachikuji,2020-09-24T23:16:38Z,"nit: conventionally we prefer ""retriable""",0,0.9923145174980164
494661344,9100,hachikuji,2020-09-24T23:17:43Z,it might be worth mentioning that this could happen in the case of a retry after a successful update.,0,0.9869935512542725
494661583,9100,hachikuji,2020-09-24T23:18:19Z,nit: leave off parenthesis after `exception`,0,0.9942532181739807
99288458,2472,norwood,2017-02-03T07:44:06Z,should probably make this ` `,0,0.9845362305641174
99288467,2472,norwood,2017-02-03T07:44:07Z,if you are going to do this check then why not make `newtopics` a `set`? if we'd rather do this check here then we can use `collection` instead,0,0.9938699007034302
99288478,2472,norwood,2017-02-03T07:44:16Z,should include a `listtopics` that takes a `collection ` of topics to query,0,0.9941091537475586
99288485,2472,norwood,2017-02-03T07:44:20Z,is it possible that this masks errors in `partitionmetadata`? e.g. if we have a topic level error and an error on a specific partition.,0,0.9913133978843689
99406097,2472,cmccabe,2017-02-03T19:30:13Z,agree,0,0.8991182446479797
99406308,2472,cmccabe,2017-02-03T19:31:20Z,i didn't make it a set because i didn't want to have to worry about hashcode and equals. i think you're right; it should just be a collection.,0,0.9375388026237488
99406744,2472,cmccabe,2017-02-03T19:33:33Z,"hmm, i'm not sure i follow. all the errors in the rpc response are faithfully reproduced in the return values... what else can we do to improve it?",-1,0.505027174949646
99407725,2472,norwood,2017-02-03T19:38:50Z,"you have a `continue` in this block. my question is related to if you end up with a `topicmetadata` that looks like: [code block] also, in writing this up, i realize that in line 487 you are checking `topic.error()` instead of `partition.error()`",0,0.9946690201759338
99410119,2472,cmccabe,2017-02-03T19:51:06Z,i added a function which allows you to get information for one topic,0,0.9820892810821533
99687358,2472,norwood,2017-02-06T21:23:13Z,"i still really think that we should have a `listtopics(set topics, enumset flags)`, e.g. one thing i've had to do is write code that is basically waits until i have seen our topics replicated/etc. it would be nice to not have to get all if i dont have to, and also nice to batch for me :) sample code [code block]",1,0.9919186234474182
112326031,2472,ijuma,2017-04-19T22:10:04Z,"this package doesn't currently contain public api classes. if we want `clients` to be a public package, we need to move all the classes that are there at the moment to `clients.internals`.",0,0.9912073016166687
112326124,2472,ijuma,2017-04-19T22:10:41Z,"as per our conversation today, maybe we should say that this will implement `completionstage` once we require java 8. also, i think we should just expose an interface to users and have the implementation under an internal package. we can then only expose methods that users should use (`complete` and `completeexceptionally` should never be used by users, for example).",0,0.9902770519256592
112326754,2472,ijuma,2017-04-19T22:14:38Z,we need to complete this.,0,0.9880901575088501
112326863,2472,ijuma,2017-04-19T22:15:23Z,is it intentional that we mention `kafkaadminclient` here? the idea behind a `create` method like this is to avoid mentioning an implementation.,0,0.9899186491966248
112327164,2472,ijuma,2017-04-19T22:17:26Z,we should flesh out the documentation for these methods. important details about what success means should be mentioned (in the same way we did for `deletetopics`).,0,0.9928905963897705
112327310,2472,ijuma,2017-04-19T22:18:30Z,i think this is unused.,0,0.9851463437080383
112327572,2472,ijuma,2017-04-19T22:20:22Z,this default doesn't seem to make sense for the `adminclient`.,0,0.9622631669044495
112327616,2472,ijuma,2017-04-19T22:20:39Z,i wonder if we should be sharing these values in `commonclientconfigs`.,0,0.9779346585273743
112327840,2472,ijuma,2017-04-19T22:22:20Z,seems like we sometimes have a constant field for `doc` and sometimes we don't. we should choose a pattern and stick to it.,0,0.9673200249671936
112328054,2472,ijuma,2017-04-19T22:23:49Z,i wonder if we should be using such magic values for public classes. it that using `null` to indicate an unset value is a bit safer and there's some indication by the type system.,0,0.9194526672363281
112328352,2472,ijuma,2017-04-19T22:24:42Z,we can use a rule to avoid repeating this in every test? same for other tests.,0,0.9907938838005066
112328439,2472,ijuma,2017-04-19T22:25:29Z,we typically use `*integrationtest` to indicate integration tests and simply `*test` for unit tests.,0,0.9934700727462769
112328490,2472,ijuma,2017-04-19T22:25:50Z,nit: this method seems unnecessary.,0,0.6821423172950745
112328573,2472,ijuma,2017-04-19T22:26:23Z,we can use `testutils.waituntiltrue` to simplify this a little?,0,0.994636595249176
112328632,2472,ijuma,2017-04-19T22:26:50Z,this is not a junit assert method.,0,0.9924202561378479
112328873,2472,ijuma,2017-04-19T22:28:16Z,i was thinking we should put this class in an `internals` package.,0,0.9838510155677795
112329026,2472,ijuma,2017-04-19T22:29:20Z,this block formatting is a bit weird and we don't usually use it in kafka.,-1,0.9738320708274841
112329873,2472,ijuma,2017-04-19T22:35:14Z,we close the selector in `networkclient` and `channelbuilder` in the `selector`. do we really need to close them separately?,0,0.9935592412948608
112336265,2472,cmccabe,2017-04-19T23:22:51Z,"yeah, implementing `completionstage` is probably a good idea, once we have jdk8 support. i don't see what's so bad about users calling `complete` or `completeexceptionally`. it just means that if the `kafkaadminclient` attempts to call those methods, the future will already be completed and it will have no effect. that seems pretty harmless?",0,0.7681145071983337
112336354,2472,cmccabe,2017-04-19T23:23:32Z,"oops, let me replace that with something descriptive.",0,0.5510179996490479
112336940,2472,cmccabe,2017-04-19T23:28:12Z,"ok, i will remove the reference to `kafkaadminclient`.",0,0.9949020147323608
112337328,2472,cmccabe,2017-04-19T23:31:36Z,it's used by the metadata object. although the rate-limiting is not implemented by the adminclient for normal requests yet.,0,0.9944349527359009
112337741,2472,cmccabe,2017-04-19T23:35:00Z,"ok. i suppose i'll just have the constant, then, even if it just maps back to `commonclientconfigs`.",0,0.9810747504234314
112338241,2472,ijuma,2017-04-19T23:38:55Z,those methods are racy and that's why they are not present in completionstage or scala futures. is there a use case where it's useful for users to call these methods? the scenario you outlined does not seem harmless since it seems like a clear user error to cause the adminclient values to be ignored.,0,0.9839795827865601
112338335,2472,cmccabe,2017-04-19T23:39:46Z,"i agree that the text doesn't make sense, since we don't care about `max.poll.ms` here. i'll set 2 minutes (a high default is good here to avoid test failures and so forth.)",0,0.9698083996772766
112338407,2472,ijuma,2017-04-19T23:40:18Z,i'm referring to the doc field...,0,0.9884698390960693
112338643,2472,cmccabe,2017-04-19T23:41:58Z,"i'm not sure there's a huge amount of utility in sharing this particular config value with the producer and consumer-- it is a different application, after all. we should probably shorten the idle time a bit",0,0.8094984889030457
112339193,2472,cmccabe,2017-04-19T23:47:10Z,fair enough. i'll change it to use integer.,0,0.9635716080665588
112340310,2472,cmccabe,2017-04-19T23:57:41Z,"that seems like a lot of churn. does it make sense to do it in a separate jira, either beforehand or after this one?",0,0.733448326587677
112340400,2472,cmccabe,2017-04-19T23:58:33Z,"hmm, you mean the javadoc indentation?",0,0.9800944924354553
112340956,2472,cmccabe,2017-04-20T00:03:32Z,"i didn't realize that networkclient closed the selector... but i looked at the code again, and indeed it does. so we don't need to worry about that in `kafkaadminclient#close`. however, we do need to handle the case where the various constructors throw exceptions (pretty much all of them can.) for example, the selector constructor could fail and leave our channelbuilder dangling, and etc.",0,0.9377665519714355
112358759,2472,cmccabe,2017-04-20T03:26:35Z,i removed the tracking of the selector in kafkaadminclient. i kept the close in the factory function so that error handling is bulletproof...,0,0.9766969680786133
112358902,2472,cmccabe,2017-04-20T03:28:22Z,"hmm, retry_backoff_ms_doc is used later down... unless i'm looking at the wrong thing...",0,0.9522541761398315
112359050,2472,cmccabe,2017-04-20T03:30:11Z,"so, the unfortunate thing about moving this into a separate namespace is that it means a bunch of other methods need to be public. the api surface and potential for api breaks increases a lot because stuff like constructors for all the public helper classes kafkaadminclient uses needs to be public. java doesn't yet have any concept of package-private like scala does. i wonder if it might be better to just put an annotation or comment saying that kafkaadminclient is public on the class.",-1,0.9365740418434143
112362257,2472,cmccabe,2017-04-20T04:10:56Z,"one use-case i can think of is cancelling a future. in `completablefuture` this is essentially equivalent to a call to `completablefuture#completeexceptionally(new cancellationexception(...))` cancellation isn't an optional operation for us since it's part of java's original `java.util.concurrent.future` api, which we need to implement. i agree that it's a bit nicer conceptually to separate the ""listen for stuff happening"" api from the ""signal that stuff has happened"" api. it makes sense that scala did this with `scala.concurrent.future`. java's `completablefuture` muddies the waters a bit by combining them into one concrete class. i don't know if this is something that is really likely to trip users up, though...",0,0.9367464184761047
112444553,2472,ijuma,2017-04-20T12:54:01Z,"yes, we should do the move separately if we think making `clients` public is the way forward (instead of having a separate package for shared classes). this class doesn't seem specific to `clients` though so maybe we should move it to `common`?",0,0.992294192314148
112444774,2472,ijuma,2017-04-20T12:55:05Z,"`cancel` is exposed via the `future` interface, so it doesn't seem like we need to expose `completeexceptionally` even if we use it internally for that?",0,0.9871587753295898
112445364,2472,ijuma,2017-04-20T12:57:48Z,i wonder if there's a better name for this than `kafkafuture`. can't think of anything that's not already taken. but maybe you have some ideas. :),1,0.9929609894752502
112445599,2472,ijuma,2017-04-20T12:59:03Z,we should probably make these interfaces and move them to top level in their own package. maybe `clients.function` or `common.function` (java uses `java.util.functions`).,0,0.9931371212005615
112446037,2472,ijuma,2017-04-20T13:01:08Z,"nit: make this final. also, it seems like not all tests have been updated to use rule.",0,0.9940376281738281
112446276,2472,ijuma,2017-04-20T13:02:18Z,"if we want `vals` to always have two values, then we should just make the method take two parameters?",0,0.9911587834358215
112446649,2472,ijuma,2017-04-20T13:04:07Z,"hmm, not sure about this. can we not avoid using reflection for this?",0,0.6932157874107361
112447470,2472,ijuma,2017-04-20T13:07:59Z,"i think that was changed in a subsequent commit. before the define was doing `commonclientconfigs.retry_backoff_ms_doc`. on that point, it makes it harder to review if history is rewritten (i.e. additional changes are squashed into the existing commit). i have no way to tell what changed. :) can you please just add separate commits instead?",1,0.9887582063674927
112449184,2472,ijuma,2017-04-20T13:15:17Z,yes. there is huge amounts of whitespace. i suspect it's that way because there's an attempt at having alignment across all methods. but the value of that doesn't seem worth it.,0,0.8549654483795166
112449330,2472,ijuma,2017-04-20T13:15:50Z,nit: remove `get` from this and other similar methods.,0,0.9937465190887451
112449528,2472,ijuma,2017-04-20T13:16:44Z,"why not use `utils.closequietly`? we can change the signature to take an `autocloseable` instead of `closeable`, if that's the issue.",0,0.9905843734741211
112449930,2472,ijuma,2017-04-20T13:18:35Z,"hmm, we should probably have a config for metric reporters and add the jmxreporter by default like other clients.",0,0.9806888103485107
112450736,2472,ijuma,2017-04-20T13:22:13Z,should this be `admin-client`? or is the idea that the prefix should be whatever comes before the first `-`?,0,0.9940828680992126
112451618,2472,ijuma,2017-04-20T13:24:26Z,we should probably use `kafkathread` here. naming convention should be consistent with other client threads. for the producer we do: [code block],0,0.9946945309638977
112452024,2472,ijuma,2017-04-20T13:26:06Z,"generally, it's good to have consistent terminology to avoid confusion. the kafka code typically just says `requests` instead of `rpcs`.",0,0.9857661724090576
112453789,2472,ijuma,2017-04-20T13:33:24Z,"starting a new comment thread about the closing we do here since github is not allowing me to add a comment to the existing one. since this is an issue for all clients, maybe we should ensure that the constructors close things in case of exceptions in the constructor?",0,0.9857723116874695
112491693,2472,cmccabe,2017-04-20T15:57:23Z,"yeah, i'll just add separate commits",0,0.9923849105834961
112514535,2472,cmccabe,2017-04-20T17:36:00Z,i moved it to `org.apache.kafka.common`.,0,0.9932392835617065
112514652,2472,cmccabe,2017-04-20T17:36:22Z,"ok, i have split them. we'll see how this looks.",0,0.9896237254142761
112516162,2472,cmccabe,2017-04-20T17:41:01Z,"hmm, i'm not sure if there's anything better. i think `kafkafuture` is short and clearly expresses the concept that it's our `future` class.",0,0.9126824736595154
112516461,2472,cmccabe,2017-04-20T17:42:30Z,"well, they are abstract classes so that we can add more methods without breaking compatibility in java 7. remember that user code has to implement these. as to making them top-level... i'm not sure. they are stopgap classes until we can use the real classes from java 8...",0,0.8987002968788147
112517345,2472,cmccabe,2017-04-20T17:46:35Z,"it's not that it always has two parameters, it is that it always has an even number of parameters. it's used to create a map from key1, value1, key2, value2, key3, value3, ...",0,0.9935262203216553
112520218,2472,cmccabe,2017-04-20T17:58:35Z,"i don't feel strongly about it either way. it gets used in selector.java to build the metric group name as follows: `string metricgrpname = metricgrpprefix + ""-metrics"";` i'm not aware of any convention that says we can't have a hyphen here, so i guess i'll put it in...",0,0.5390417575836182
112523477,2472,cmccabe,2017-04-20T18:12:15Z,"ok, i'll reduce the indentation where i can.",0,0.989042341709137
112527847,2472,cmccabe,2017-04-20T18:29:54Z,"the constructor is private and can't be called from outside this class. even the create methods are package-private and only used by the public interface in adminclient and by unit tests. putting a lot of logic in the constructor doesn't work very well because the logic needs to be different for the unit tests (which don't use networkclient, selector, or channelbuilder, for example)",0,0.9898361563682556
112655250,2472,ijuma,2017-04-21T10:02:07Z,seems better to update the `import-control.xml` file.,0,0.9911052584648132
112972103,2472,ijuma,2017-04-24T15:07:55Z,"will we eventually retry the request, return an error to the user or something else?",0,0.9853894114494324
113934868,2472,ijuma,2017-04-28T13:52:13Z,we should add a class comment stating that this tests the internal scala adminclient that will be replaced by the java one eventually.,0,0.9947806000709534
113935275,2472,ijuma,2017-04-28T13:53:58Z,this should probably use `messagewithfallback`.,0,0.9945043325424194
113943073,2472,ijuma,2017-04-28T14:29:05Z,nit: `public` not needed.,0,0.9937986731529236
113943764,2472,ijuma,2017-04-28T14:31:56Z,"hmm, should we not just throw an error here? something would have to be very wrong for this to happen.",0,0.8013268709182739
113944479,2472,ijuma,2017-04-28T14:35:12Z,this seems more informative than what's in the abstract class.,0,0.9766426086425781
113944854,2472,ijuma,2017-04-28T14:36:56Z,nit: `!isempty` instead of `length() > 0`.,0,0.9929706454277039
113945142,2472,ijuma,2017-04-28T14:38:14Z,this comment doesn't seem accurate.,0,0.7071340084075928
113948024,2472,ijuma,2017-04-28T14:49:27Z,`commonclientconfigs.metrics_num_samples_doc` should just be `metrics_num_samples_doc`.,0,0.9943174719810486
113948175,2472,ijuma,2017-04-28T14:50:05Z,we should either do this for all of the configs or none.,0,0.9888460040092468
113948212,2472,ijuma,2017-04-28T14:50:15Z,the doc configs should be private.,0,0.9928644895553589
113948629,2472,ijuma,2017-04-28T14:52:01Z,seems like we're missing `metrics_recording_level_config`.,0,0.9858893156051636
113950116,2472,ijuma,2017-04-28T14:58:27Z,the consumer default is 64k while the producer default is 32k. was it intentional that you picked the same default as the producer?,0,0.9945864677429199
113950557,2472,ijuma,2017-04-28T15:00:27Z,this comment needs to be updated since you reduced the max_idle value to 5 minutes.,0,0.9952527284622192
113965338,2472,ijuma,2017-04-28T16:08:22Z,do we need something like the producer's `max_request_size_config` or are we ok to just rely on the broker if someone creates a batch that is too large somehow?,0,0.992637038230896
113967006,2472,ijuma,2017-04-28T16:16:37Z,nit: maybe this should simply be `testclose()`?,0,0.9654181599617004
113967166,2472,ijuma,2017-04-28T16:17:33Z,seems like we always create an adminclient and close it at the end. maybe we can do that in `setup` and `teardown`? that way we don't leak resources if the test fails.,0,0.9860950708389282
113967578,2472,ijuma,2017-04-28T16:19:43Z,"it would be good to run these tests with security enabled. maybe a variant with sasl_ssl would do the job. it's reasonably straightforward, see `saslsslconsumertest`.",0,0.980107843875885
113970289,2472,ijuma,2017-04-28T16:34:24Z,"oh, the result type of `createtopic` and `createtopics` is the same? that makes the non batch method less useful, no? may as well let the user use `collections.singleton` (with a static import)`.",0,0.9872888326644897
114015243,2472,cmccabe,2017-04-28T20:39:23Z,"since `kafkafuture#completedfuture` returns a completed future, we need access to the `kafkafutureimpl#complete` method. normally, `org.apache.kafka.common.kafkafuture` accessing `org.apache.kafka.common.internal.kafkafuture` would be blocked. this exception allows it to be called.",0,0.9921482801437378
114015511,2472,cmccabe,2017-04-28T20:41:00Z,"hmm. i was following the example of `producer.java`, whose javadoc has a link to `kafkaproducer.java`. i will add a little more javadoc to the `adminclient.java` class, though.",0,0.9559859037399292
114016199,2472,cmccabe,2017-04-28T20:45:37Z,"we don't know what request the response corresponds to, because its correlation id is invalid. of course, requests that don't receive a response will time out after enough time.",0,0.9548762440681458
114016438,2472,cmccabe,2017-04-28T20:47:06Z,"it's kind of awkward because other futures might have been completed successfully at this point. assuming that there is a bug where the server is responding with an incorrect topic name, this will be caught by means of the sanity check at the bottom that fails futures which haven't been completed by the response.",-1,0.9725515246391296
114022797,2472,cmccabe,2017-04-28T21:26:19Z,"i didn't think about it that much. i suppose 64k might be a better default, though, since some messages have large responses (larger than those the producer normally gets, at least).",0,0.9176777601242065
114023074,2472,cmccabe,2017-04-28T21:28:06Z,i don't think that we need a config like that here. the size of messages should come naturally out of the batch size which the client chooses. the rpc system will catch it if it gets too big (although there are probably other performance problems when admin requests get that big).,0,0.9734189510345459
114024595,2472,cmccabe,2017-04-28T21:38:18Z,good idea. i will add a close to an cleanup function.,1,0.9883257150650024
114024764,2472,cmccabe,2017-04-28T21:39:29Z,let's revisit this later once we have more experience with use-cases,0,0.9900667667388916
114024818,2472,cmccabe,2017-04-28T21:39:54Z,i updated this to 64k.,0,0.9919672608375549
114025089,2472,cmccabe,2017-04-28T21:41:54Z,good idea. i added some javadoc here and also on the scala adminclient with that info,1,0.9838190674781799
114025911,2472,cmccabe,2017-04-28T21:47:28Z,"hmm, good catch. i think it makes more sense to add the fallback logic into `errors#exception`, though. if null is passed to that method, it should return an exception with the default message for that error code.",1,0.933565080165863
114026050,2472,cmccabe,2017-04-28T21:48:31Z,"note: i did add an entry to the `import-control.xml` for the `org.apache.kafka.clients.admin` namespace, which was previously missing. that entry is useful for allowing imports between classes in the same package. but it doesn't affect this issue in `org.apache.kafka.common`.",0,0.9887748956680298
114029206,2472,ijuma,2017-04-28T22:13:01Z,"when is later though, the feature freeze is pretty soon. as you know, in api design, adding methods is easy, removing them is hard. our experience so far in the consumer is that the batch version is enough so it seems to make sense to start that way. also, are we adding the unstable annotation to this class?",0,0.9882424473762512
114029207,2472,ijuma,2017-04-28T22:13:02Z,"when is later though, the feature freeze is pretty soon. as you know, in api design, adding methods is easy, removing them is hard. our experience so far in the consumer is that the batch version is enough so it seems to make sense to start that way. also, are we adding the unstable annotation to this class?",0,0.9882424473762512
114037965,2472,cmccabe,2017-04-28T23:48:49Z,"i suppose it is easier to add new methods than to remove them. i will remove the singular methods for now, and add the \ annotation to the api classes.",0,0.9875812530517578
114044708,2472,ijuma,2017-04-29T03:06:43Z,"we should just allow `common` to access `common.internals`, there's no good reason not to allow that. it's a simple addition: in general, `import-control.xml` is the right place to make these changes, i don't think we should be using suppressions for this.",0,0.9879465699195862
114044716,2472,ijuma,2017-04-29T03:08:18Z,"`producer` and `consumer` are a bit weird because the implementation classes are what people typically use (due to the constructor). for the adminclient, the abstract class is what people will be exposed to most probably.",-1,0.9589791893959045
114044732,2472,ijuma,2017-04-29T03:09:21Z,i would have thought that we would fail all the requests for that connection.,0,0.5873713493347168
387427500,8218,mjsax,2020-03-04T03:11:27Z,"this is not really relevant for this pr, but we need to add it for kip-447 eventually, thus i just include it in this pr.",0,0.9909313917160034
387427638,8218,mjsax,2020-03-04T03:12:04Z,we moved this to `taskmanager`,0,0.9956538677215576
387427823,8218,mjsax,2020-03-04T03:12:59Z,"on `suspend()` and `preparecommit()` we don't commit yet, but return the offsets that need to be committed",0,0.9905250668525696
387427911,8218,mjsax,2020-03-04T03:13:24Z,we don't commit and thus don't throw any longer,0,0.8655726909637451
387428416,8218,mjsax,2020-03-04T03:15:41Z,"frankly, not sure if this is correct any longer. what do we want to record with this sensor exactly? flushing can be expensive and we might want to record it as part of committing -- but i am not sure.",-1,0.8749809861183167
387428786,8218,mjsax,2020-03-04T03:17:11Z,"i am not happy with this rewrite (but as i know that john did some changes in this class in another pr, i just did this hack her for now -- needs some cleanup after a rebase)",-1,0.9850025773048401
387429067,8218,mjsax,2020-03-04T03:18:27Z,"we could also do a second loop over all tasks, _after_ calling `commit(..)` below -- not sure if this is ok as-is?",0,0.9912136197090149
387430556,8218,mjsax,2020-03-04T03:25:43Z,moved both tests to `taskmanagertest`,0,0.9951412677764893
387430633,8218,mjsax,2020-03-04T03:26:02Z,move all 4 tests to `taskmanagertest`,0,0.9957289099693298
387983590,8218,abbccdda,2020-03-04T22:54:42Z,did you already update the kip for the new config?,0,0.9954150915145874
387984270,8218,abbccdda,2020-03-04T22:56:19Z,what's the benefit of building this as a static helper?,0,0.9887373447418213
387994001,8218,mjsax,2020-03-04T23:23:13Z,we need to allow committing in `suspended` state now as we first suspend all tasks and than commit. cf. `taskmanager#handlerevocation()`,0,0.9951918125152588
387994269,8218,mjsax,2020-03-04T23:23:59Z,minor improvement: we include writing the checkpoint and the caller can indicate if it should be written or not.,0,0.9855471849441528
387994697,8218,mjsax,2020-03-04T23:25:15Z,this issues was introduced in the pr that introduced `streamsproducer` -- we forgot to close them. fixing this on the side.,0,0.9851240515708923
387995044,8218,mjsax,2020-03-04T23:26:10Z,"we call `closeclean` below -- just fixing the comment here for now (\cc ) note that we don't commit offsets for this case any longer -- previously, committing offsets ""might"" have been done with `closeclean()` (even if i believe that the task would be marked as ""commitneeded == false""). we don't let the taskmanager commit offsets here, as it should not be required.",0,0.9947740435600281
387995875,8218,mjsax,2020-03-04T23:28:26Z,similar to above: this issue was introduced in the `streamsproducer` pr. we nee to close the producer when we remove it.,0,0.9926955699920654
387995961,8218,mjsax,2020-03-04T23:28:44Z,as above,0,0.9888283014297485
387996132,8218,mjsax,2020-03-04T23:29:16Z,not sure why we use an iterator here. simplifying the code with a `for`-loop,0,0.9616084694862366
387996797,8218,mjsax,2020-03-04T23:31:16Z,"we need to commit explicitly in ttd now to mimic the taskmanger. hence, we need access to the `consumer` and `streamsproducer`",0,0.9945236444473267
388015857,8218,abbccdda,2020-03-05T00:33:39Z,why do we start to suppress warnings?,0,0.9781794548034668
388016523,8218,abbccdda,2020-03-05T00:35:52Z,"sounds good, just mark that depending on john's fix, we probably don't need to handle this.",1,0.7504687309265137
388018015,8218,abbccdda,2020-03-05T00:41:10Z,add a comment describing the new return statement.,0,0.9928460717201233
388019423,8218,abbccdda,2020-03-05T00:45:58Z,i would prefer a second loop to guarantee a consistent reflection on the task committed state.,0,0.9772835373878479
388019820,8218,abbccdda,2020-03-05T00:47:32Z,"in eos beta, we should be able to send out a batch commit instead of individual ones?",0,0.993713915348053
388022132,8218,abbccdda,2020-03-05T00:55:25Z,i don't think we need to test `assertfalse(task.commitneeded()` as its outcome is controlled by `task.markcommitted`. so we only need to do it once.,0,0.9855162501335144
388022419,8218,abbccdda,2020-03-05T00:56:24Z,why do we no longer have the mock verification?,0,0.9880780577659607
388026690,8218,abbccdda,2020-03-05T01:11:22Z,should we do `expectlastcall` here?,0,0.9934677481651306
388028665,8218,abbccdda,2020-03-05T01:18:20Z,we should also verify the thrown cause,0,0.9933779835700989
388028820,8218,abbccdda,2020-03-05T01:18:46Z,"same here, for verifying the thrown cause",0,0.9943854808807373
388029164,8218,abbccdda,2020-03-05T01:20:06Z,"what's the reasoning her for only wrapping the consumer offset commit case here, not for eos case?",0,0.9893800616264343
388029471,8218,abbccdda,2020-03-05T01:21:10Z,always feels better for one less parameter :),1,0.8653404712677002
388029958,8218,abbccdda,2020-03-05T01:22:58Z,makes sense to me.,0,0.9770739674568176
388030250,8218,abbccdda,2020-03-05T01:23:57Z,checkmark for proving the 6 tests are all migrated.,0,0.9942756295204163
388030837,8218,abbccdda,2020-03-05T01:25:58Z,probably need to change after rebase,0,0.9826852083206177
389051551,8218,mjsax,2020-03-06T17:50:27Z,"we should have done this from the beginning on... (it's just a ""side fix"")",0,0.9279784560203552
389052130,8218,mjsax,2020-03-06T17:51:29Z,we will need this later (ie follow up pr) and it reduced code duplication,0,0.9874256253242493
389052956,8218,mjsax,2020-03-06T17:53:26Z,correct. unifying the commit logic as done is this pr allows us to do this in a follow up pr that actually enable producer per thread -- the whole purpose of this pr is to prepare/refactor for this.,0,0.9862948060035706
389053599,8218,mjsax,2020-03-06T17:54:52Z,"you mean exception handling? for the producer all exception handling is done within `streamsproducer` (note that `threadproducer` above is a `streamsproducer`, not a `kafkaproducer`)",0,0.9922744631767273
389054695,8218,mjsax,2020-03-06T17:57:11Z,"we remove `recordcollector#commit()` method in this pr and thus we remove the expected call to commit at the beginning of this test -- thus, there is nothing to be verified any longer and we don't call `commit()` with `preparecommit()` any longer.",0,0.9945188164710999
390712211,8218,mjsax,2020-03-11T02:20:42Z,"this is an open question: we don't want to remove this sensor however it was unclear to me how to handle this metric after we split ""task committing"" into three steps (preparecommit; taskmanager#commit; postcommit).",0,0.9790652990341187
390712571,8218,mjsax,2020-03-11T02:22:13Z,simplification to avoid passing in `eosenabled` and reducing constructor parameter list -- we just piggy back on the `application.id` that shall be `null` for non-eos.,0,0.9930959343910217
390712665,8218,mjsax,2020-03-11T02:22:35Z,avoid redundant logging.,0,0.9444577693939209
390712770,8218,mjsax,2020-03-11T02:23:06Z,side cleanup: all those method can actually be package private.,0,0.9924271106719971
390712971,8218,mjsax,2020-03-11T02:23:55Z,removing this state -- this is an open question if i did this correctly. \cc,0,0.9748842716217041
390714027,8218,mjsax,2020-03-11T02:27:59Z,"after we addressed the question how we want to do metrics, we can update this tests",0,0.9943795800209045
390714488,8218,mjsax,2020-03-11T02:29:59Z,because we make app method in `streamsproducer` package private but need access to `commit()` we add `testdriverproducer` to get access.,0,0.9933397173881531
390714741,8218,mjsax,2020-03-11T02:31:09Z,just added to give public access to `committransaction()` to ttd (it's more elegant than making `streamsproducer#committransaction` public imho),0,0.953787624835968
390727409,8218,abbccdda,2020-03-11T03:27:07Z,nit: we could log thread-id here for easier log search.,0,0.9928379654884338
391162808,8218,vvcephei,2020-03-11T18:01:56Z,"it seems a bit roundabout to have to remember we should send a `null` `application.id` as the constructor argument to indicate that eos is enabled. what's wrong with saying ""eos is enabled"" when you want eos to be enabled?",0,0.6385151743888855
391233773,8218,abbccdda,2020-03-11T20:05:06Z,could we internalize this state check inside the task to simplify the logic here?,0,0.9928969740867615
391234248,8218,abbccdda,2020-03-11T20:05:36Z,"similarly here, this state check could be internalized.",0,0.9912074208259583
391236509,8218,abbccdda,2020-03-11T20:07:57Z,nit: let's order the functions as [code block],0,0.9941410422325134
391237078,8218,abbccdda,2020-03-11T20:08:36Z,prepare to uncleanly close a task that we may not own.,-1,0.7823294997215271
391241528,8218,abbccdda,2020-03-11T20:13:52Z,"having a `prepareclosedirty` makes the calling of `closedirty` a bit cumbersome as we always need to call `prepareclosedirty` first. to simplify or just do a reminder, i have two suggestions: 1. internally create a task state called prepare_close or just a boolean like `closedirtyprepared` as the state check, so that closedirty will throw illegal state if the flag is false 2. following #1, instead of throw, if we don't see the prepareclose is being called, the `closedirty` will invoke `prepareclosedirty` first internally.",0,0.9581402540206909
391243910,8218,abbccdda,2020-03-11T20:17:03Z,"for my own education, why we do `and` here instead of just checking `commitrequested`?",0,0.9865498542785645
391244729,8218,abbccdda,2020-03-11T20:18:43Z,:thumbs_up:,1,0.9533231854438782
391260243,8218,abbccdda,2020-03-11T20:50:44Z,"comment here for no better place: standby task always returns an empty `committableoffsetsandmetadata`, then why do we still need to check `commitneeded` for it? shouldn't it always set to false?",0,0.9894165396690369
391261158,8218,abbccdda,2020-03-11T20:52:34Z,`logcontext ` is not used.,0,0.9932720065116882
391261929,8218,abbccdda,2020-03-11T20:54:06Z,should we attempt to add more fine-grained metrics for 3 stages then?,0,0.9920279383659363
391265711,8218,abbccdda,2020-03-11T21:01:37Z,could we add a `` for this method? also we should comment about the different indications when we return an empty map vs null.,0,0.9947598576545715
391267109,8218,abbccdda,2020-03-11T21:04:39Z,remove `if`,0,0.9935339689254761
391286988,8218,abbccdda,2020-03-11T21:47:16Z,i feel a bit weird here as we don't need `preparecloseclean` anymore. this api usage is a little complicated upon when we should do it and we don't.,-1,0.9754602313041687
391287132,8218,abbccdda,2020-03-11T21:47:37Z,similarly for `closedirty` and `prepareclosedirty`,0,0.9943715333938599
391289786,8218,abbccdda,2020-03-11T21:54:04Z,nit; 228 - 229 could be merged.,0,0.9930663108825684
391291102,8218,abbccdda,2020-03-11T21:57:16Z,"also the above step #4 is no longer correct, the commit is done on taskmanager now.",0,0.9948240518569946
391295221,8218,abbccdda,2020-03-11T22:08:20Z,do we need to keep a task once it is failed to clean close? why couldn't we just close it dirty immediately after we see the exception?,0,0.9873098731040955
391296895,8218,abbccdda,2020-03-11T22:11:16Z,why do we need to move these tests?,0,0.9883911609649658
391298785,8218,abbccdda,2020-03-11T22:13:39Z,looks like we lack test coverage for timeoutexception and kafkaexception cases,0,0.971152126789093
391301678,8218,abbccdda,2020-03-11T22:17:34Z,we don't have unit test coverage for this exception case,0,0.9793745875358582
391302227,8218,abbccdda,2020-03-11T22:18:14Z,we lack unit test coverage for this case,0,0.9645218849182129
391303712,8218,abbccdda,2020-03-11T22:20:40Z,"could we verify the assignment stack and lost stack separately, by doing `handleassignment` verify first before calling `handlelost`",0,0.9943885207176208
391337786,8218,mjsax,2020-03-12T00:07:25Z,the `threadid` is already added to the log prefix when the `log` object is created in `streamsthread`,0,0.9953664541244507
391338238,8218,mjsax,2020-03-12T00:09:08Z,not sure if i can follow. we don't check `commitneeded` in `postcommit()`? can you elaborate?,0,0.9376369118690491
391338530,8218,mjsax,2020-03-12T00:10:18Z,"frankly, i have no good idea atm... also, if we change metrics, we need to update the kip and it's getting more complicated. if possible, i would prefer to not change any metric, but not sure if it is possible...",-1,0.9777107834815979
391338712,8218,mjsax,2020-03-12T00:10:57Z,"yeah, this pr does not yet add all required test...",0,0.9889671206474304
391339213,8218,mjsax,2020-03-12T00:13:04Z,"why do we need to document this in the method javadoc? it's an internal method? internal comment outdate quickly if code is changed and comments are not updated accordingly (what happens 99% of the time). hence, i would prefer to limit comments if possible. in doubt, we should document at `task` level anyway.",0,0.9890031218528748
391339463,8218,mjsax,2020-03-12T00:13:57Z,you see -- that is may point from above... the code should be written in a way that explains itself... updating comments always slips...,0,0.976769208908081
391340439,8218,mjsax,2020-03-12T00:17:53Z,i am actually wondering about point (5) -- why do we need to checkpoint the state manager if we wipe out the store later anyway for the unclean eos case?,0,0.9573575258255005
391342962,8218,mjsax,2020-03-12T00:28:08Z,"i actually had a similar though, but was not sure if it's worth it. would like to hear from what they think? if we do this, we might want to do it for ""commit"" and ""suspend"", too. for suspend() adding a state suspend_prepared is not helpful as suspend() does different things depending on the previous state. (for commit and close an additional state would work). for consistency reasons, an internal flag might be better though. not sure ate if calling ""prepare"" automatically would actually be correct for all cases?",0,0.9074729084968567
391344437,8218,mjsax,2020-03-12T00:33:24Z,"`preparecloseclean()` already does a state check and returns `emptymap` if state is `created`. the point of this check is, that we don't add anything to the `consumedoffsetsandmetadatapertask` map -- this is important for the corner case for which all tasks are in state created and thus no transaction was initialized. for this case we cannot call `producer.addoffsetstotranscation()` and must skip this step entirely. note, that we have a corresponding check below to not call `commitoffsetsortransaction` if the map is empty.",0,0.9902182221412659
391344863,8218,mjsax,2020-03-12T00:35:23Z,we need to call `preparecloseclean` (as done in l196 above) _before_ we call `commitoffsetsortransaction` (l215 above).,0,0.9942964911460876
391344936,8218,mjsax,2020-03-12T00:35:38Z,some comment as above.,0,0.9939206838607788
391344967,8218,mjsax,2020-03-12T00:35:44Z,i know...,0,0.9741809368133545
391345982,8218,mjsax,2020-03-12T00:40:13Z,"to avoid the overhead to commit offset that are already committed, ie, the previous commit committed offset 5 and now we would commit offset 5 again.",0,0.9920387268066406
391346285,8218,mjsax,2020-03-12T00:41:22Z,i think it's easier to read if it's split.,0,0.9602237939834595
391347114,8218,mjsax,2020-03-12T00:44:22Z,"i try to keep ""order"" and group test methods to keep an overview if test coverage is complete. [code block]",0,0.9936349391937256
391348100,8218,mjsax,2020-03-12T00:48:34Z,"not sure if i can follow? the comments just mark which setup calls belongs to which test call, nothing more. all setup is done upfront before we call the actually methods under test.",0,0.9480570554733276
391348586,8218,mjsax,2020-03-12T00:50:19Z,good catch.,1,0.9776482582092285
391361243,8218,mjsax,2020-03-12T01:47:39Z,good idea!,1,0.9935575127601624
391809790,8218,guozhangwang,2020-03-12T18:22:32Z,nit: add a check that taskid exists in `taskproducers` to make sure we do not return null.,0,0.9942928552627563
391812242,8218,guozhangwang,2020-03-12T18:27:10Z,subjectively i'd +1 that adding one more parameter to avoid piggy-backing on the applicationid is better.,0,0.9669163227081299
391829473,8218,guozhangwang,2020-03-12T18:59:20Z,"actually on a second thought, i'm wondering if the following inside taskmanager is cleaner: [code block] instead of: [code block] my gut feeling is that it is cleaner to not access the task creator for its created stream-producers (and hence here we need to change the task-producer map to streamsproducers), but just access each task's record collector and call its `commit` --- today we already have a `streamtask#recordcollector` method.",0,0.9793916344642639
391829854,8218,guozhangwang,2020-03-12T19:00:10Z,"please see my other comment above --- i think it is cleaner to just call `foreach(active-task) task.recordcollector.commit` inside the task-manager; and inside recordcollectorimpl we check that eosenabled is always true, otherwise illegal-state thrown. in the next pr where we have the thread-producer, we could then only create a single `recordcollector` object that is shared among all active tasks and wraps the thread-producer, and then the caller `taskmanager` code then can just get one active task and call its record-collector's commit function knowing that is sufficient to actually commit for all tasks since everyone is using the same record-collector. wdyt?",0,0.9917830228805542
391838078,8218,guozhangwang,2020-03-12T19:16:48Z,"this is a meta comment: i think we can consolidate `preparecommit` and `prepareclose` and `preparesuspend` here by introducing the clean parameters to the function, since their logic are very similar (for the part that they diffs a bit, it can be pushed to post logic), and on task-manager during commit: 1) for each task -> task.preparecommit(true) 2) commit 3) for each task -> task.postcommit(true) during close: if (clean) 1) for each task -> task.preparecommit(true) 2) commit() 3) for each task -> task.postcommit(true) else 1) for each task -> task.preparecommit(false) // do not commit 3) for each task -> task.postcommit(false) 4) tasks.close(flag) and the same for suspension.",0,0.9910098314285278
391838707,8218,guozhangwang,2020-03-12T19:18:06Z,"i actually think that we can remove this debug-level per-task commit metrics, since we already have the info-level per-thread commit metric and this one does not provide much more additional information?",0,0.9888631105422974
391974508,8218,mjsax,2020-03-13T00:39:06Z,"i think it's unclean to let the recordcollector commit (note that this pr removes `recordcollector` not at side refactoring but on purpose) -- to me the recordcollector has the responsibility to bridge the gap between the runtime code (that is typed), and the producer that uses ` ` (ie, it serialized the data and manages errors from `send`) -- why would a **_collector_** know anything about committing (for which it also needs a handle to the consumer)? about accessing the `activetaskcreator`: we could also expose the `streamsproducer` via the `recordcollector` though (or directly via the task)? that would be cleaner i guess.",0,0.8356346487998962
391993410,8218,mjsax,2020-03-13T02:06:16Z,it's a personal preference i guess. but seems you don't like it. will revert it.,0,0.503017246723175
392017955,8218,guozhangwang,2020-03-13T03:50:05Z,"this is not introduced in this pr, but: while thinking about it, i realized for restoring state we do not need to rely on eosdisabled to checkpoint, in fact we can always checkpoint during restoring here.",0,0.9923031330108643
392783249,8218,mjsax,2020-03-16T04:59:42Z,will do this in a follow up pr.,0,0.9951390027999878
392783415,8218,mjsax,2020-03-16T05:00:28Z,ack,0,0.9149930477142334
392783859,8218,mjsax,2020-03-16T05:02:44Z,covered via `shouldcommitnextoffsetfromqueueifavailable` and `shouldcommitconsumerpositionifrecordqueueisempty`,0,0.9941099286079407
392784308,8218,mjsax,2020-03-16T05:05:18Z,we can address this in a follow up pr.,0,0.993725597858429
392794910,8218,mjsax,2020-03-16T05:56:23Z,added test `shouldthrowwhenhandlingclosingtasksonproducercloseerror`,0,0.9951234459877014
393132558,8218,abbccdda,2020-03-16T16:00:20Z,we need a unit test for this function.,0,0.9917984008789062
393136595,8218,abbccdda,2020-03-16T16:06:09Z,"we could just do one log in front: `log.info(""prepare suspending {}"", state());`",0,0.993699312210083
393139575,8218,abbccdda,2020-03-16T16:10:32Z,do we have unit test to check the checkpoint status after `postcommit()`?,0,0.9956419467926025
393180380,8218,abbccdda,2020-03-16T17:06:41Z,"i couldn't fully follow this idea, just playing devil advocates here, if we think meta code comments actually hinder the readability of internal class, why not just remove all the internal function meta comments, as they would get outdated anyway? for me the return type comment is still valuable for understandability. if the comment gets outdated, we should just update it. cc if the idea here makes sense, or we could get a consensus on what needs to be done in internal class comments, and what's not.",0,0.9010451436042786
393183310,8218,abbccdda,2020-03-16T17:11:13Z,nit: { could be reduced.,0,0.8128566741943359
393195455,8218,abbccdda,2020-03-16T17:31:51Z,"yea, a todo is also ok.",0,0.9595716595649719
393336160,8218,guozhangwang,2020-03-16T22:07:16Z,"`for the next pr` (all other comments with this tag means no changes required for this pr): my understanding is that we would make the thread-producer also a `streamsproducer` instead of a `kafkaproducer` which would be used to `committransaction` under `eosbeta`, is that right?",0,0.9949101805686951
393336618,8218,guozhangwang,2020-03-16T22:08:31Z,"nit: we can have a wrapped streamsproducer#close / metrics, and then #kafkaproducer would be for testing-only.",0,0.9925689101219177
393336934,8218,guozhangwang,2020-03-16T22:09:16Z,"after syncing offline about this, i think i'm convinced now that moving this logic into taskmanager is better.",0,0.921572208404541
393339067,8218,guozhangwang,2020-03-16T22:14:56Z,"i think we should just let the preparexx function to return the map of partitions -> partition-timestamp to indicate if it should be included in the map of committing offsets, so that we do not need to leak the state into task-manager here. also we only need to call `mainconsumer.position` once for all tasks -- please see my other comment above. also: we should not try to commit state if we are in restoring but only flushing store and writing checkpoints (i think this is already the behavior in trunk), since the partitions are paused from the main-consumer before restoration is done --- maybe it is partly causing some unit test flakiness.",0,0.9842681288719177
393339213,8218,guozhangwang,2020-03-16T22:15:23Z,sg. i think in this pr we still can do the change to let `preparexx` to return the map of partitions -> partition-timestamp to indicate whether this task should be included in committing.,0,0.992117702960968
393341972,8218,guozhangwang,2020-03-16T22:23:14Z,"in either eos-alpha or eos-beta or non-eos, we can just loop over all the ""committable partitions"" and call `mainconsumer#position` once, so this function can be extracted out of the task as a per-task call. more specifically, in the preparexx calls, we know based on the state of the task and clean flag whether or not we should commit the source topic offsets for this task, so we can let the preparexx function to return `map partitiontimes` encoding the extracted timestamps for each partition instead of void --- when we decided not to commit we return an empty map. and then inside taskmanager we just use the `mainconsumer` to call position once and then pass that to the `commitoffsetsortransaction` call.",0,0.9937629103660583
393344611,8218,guozhangwang,2020-03-16T22:28:40Z,nit: we can do `if / else if / else` here still and move the `closetasksensor.record(); / transitionto(state.closed);` to avoid duplication.,0,0.9928888082504272
393345037,8218,guozhangwang,2020-03-16T22:29:26Z,"ditto here, i think if / else if / else is more readable.",0,0.9825472235679626
393350516,8218,mjsax,2020-03-16T22:43:50Z,"well, we log ""skip"" for state created and we throw for invalid states. note sure how to do this?",0,0.9908169507980347
393350827,8218,mjsax,2020-03-16T22:44:47Z,"yes, `shouldrespectcommitneeded()` check this already.",0,0.9935269355773926
393371781,8218,guozhangwang,2020-03-16T23:47:56Z,"`for the next pr`: as i mentioned in the last commit i feel `preparesuspend` and `prepareclose` can be consolidated with `preparecommit` but in the next pr these logic would be changed again for eos-beta so maybe we cannot do that any more, so i'm fine with keeping as-is and we can revisit to see if we can really do this refactoring or not in the next pr when we did the eos-beta.",0,0.9833127856254578
393373023,8218,guozhangwang,2020-03-16T23:52:01Z,yes we are unnecessarily checkpointing here --- the reason is that eos flag was original striped out of task and only processor-state-manager knows about it; now since we get this eos flag back to task (sigh.. :) we can add this additional check.,1,0.655724287033081
393374466,8218,guozhangwang,2020-03-16T23:57:18Z,"i would suggest not restricting ourselves to some specific rules about comments :) personally i tried to avoid the `one line comment explaining one line code` type of comments inside a function since it should be obvious, rather i'd add some comments for a block or several blocks if i fear it maybe hard to read by itself. i think you guys should just make your best judgement here. and for internal functions, i agree that we do not necessarily need to write java-docs, and this one, for example, i wrote the java-doc as part of the tech debt cleanup just to remind what operations must be considered here inside closing / suspending etc so that later on when we change the function itself by other contributors, they would use it as a reference to check if they mistakenly missed some steps or re-ordered some steps. however if we are going to split this function into multiple, instead of just re-structuring the function as a whole, then although i have my preference i'd leave to you guys if you want to add the javadoc for both pre/post of you feel now it is too obvious to bother :)",1,0.9831363558769226
393377256,8218,guozhangwang,2020-03-17T00:07:51Z,"`for the next pr`: i see the reason i return the checkpoint is that we are now extracting the committing out of the task and i need to remember if we need to checkpoint and if yes which offsets after we've flushed and before we checkpoint, but since the state of the task would not change before / after the commit during close. more specifically we only have three cases: 1) to not write checkpoint, 2) write checkpoints for written offsets (changelogs) only, 3) write checkpoint for written and consumed offsets. and no matter which case it is during the `preclose`, it would always be the same in the `post`, so why do we need to return it to task-manager, book-keep there, and then after commit to pass it back to tasks?",0,0.9896326065063477
393378779,8218,guozhangwang,2020-03-17T00:14:27Z,nit: we should emphasize that prepareclose and close calls should be implemented idempotent since we may call it multiple times if a task close clean first and then fail and then close dirty.,0,0.9895078539848328
393384266,8218,guozhangwang,2020-03-17T00:37:48Z,"`for the next pr`: i think we can save prepareclose (or more accurately, merge prepareclose and close together again) if we make a state diagram change that only suspended state can transit to closed state, i.e. at task-manager level whenever we want to close a task we call its `suspend` function first, which would, depending on its state, be a no-op, or flushing, or closing topology etc, and then after that the task is always in suspended state, and then we call ""commit"" if necessary, and then we call close (a minor thing is that today when the state is in suspended we would omit committing inside task, and we need to lift this restriction; and also the transition actions to transit to suspended need to rely on the clean flag, hence we need `suspend(clean-flag)`). and we can further merge preparesuspend and suspend as well by just making the checkpointing logic as part of post-commit instead of post-suspend, since as i mentioned above you only have three cases: 1) do not need to checkpoint: if you are in created. 2) checkpoint written and consumed offsets: if you are in running, in which you need to commit offsets as well. 3) checkpoint only store offsets: if you are in restoring, and in which case you do not need to commit offsets. in fact, if we are not in the running state yet, the `consumedoffsets` as well as `recordcollector#offsets()` are always going to be empty, so it is always safe to call `statemgr.checkpoint(checkpointableoffsets())` and not condition on the state and call `statemgr.checkpoint(emptyset())`. and if we now allow committing in suspended state as part of closing (i.e. suspend -> commit -> close), similar rules apply: if we are suspending from a restoring state, then in `postcommit` while we ``statemgr.checkpoint(checkpointableoffsets())` the `checkpointableoffsets` would always be empty; if we are suspending from a running state it would contain some offsets.",0,0.9892834424972534
393385438,8218,guozhangwang,2020-03-17T00:41:49Z,"see my other comments: we should not commit in created, restoring and suspended state, and it's better just to let the preparexx function to indicate if there's anything to commit based on its state internally than letting task-manager to branch on the task state -- more specifically, here the prepareclose call should not return the map of checkpoints but the map of partition -> partition-timestamps (if empty it means nothing to commit), since the checkpoint map are not needed at task-manager at all and post commit, if the offsets should be empty it would still be empty.",0,0.9922594428062439
393387491,8218,guozhangwang,2020-03-17T00:50:23Z,"same here: not only created, but also restoring and suspended tasks should not be included in `consumedoffsetsandmetadatapertask` and we should not let the task-manager to peek its state.",0,0.9901304841041565
393387840,8218,guozhangwang,2020-03-17T00:51:31Z,"""as above"" :)",1,0.9798792600631714
393389583,8218,mjsax,2020-03-17T00:58:53Z,correct. for eos-beta there will be one `streamsproducer` that is shared over all tasks.,0,0.9863205552101135
393389903,8218,mjsax,2020-03-17T01:00:30Z,"we could, but the idea was that `activetaskcreator` creates the producer via `new kafkaproducer()` and thus it should call `kafkaproducer#close()`, too, and not delegate it to `streamsproducer`. thoughts?",0,0.9885717034339905
393392898,8218,mjsax,2020-03-17T01:12:55Z,"well, we can, but we get an empty ""than block"" what is weird: [code block]",-1,0.9794062972068787
393418010,8218,mjsax,2020-03-17T02:58:33Z,"within `maybecommitactivetasksperuserrequested` we know that we are in state `running` and thus, no need to check what `committableoffsetsandmetadata()` returns but we can ""blindly"" commit.",0,0.9890528321266174
393792511,8218,abbccdda,2020-03-17T16:05:29Z,"by `next pr`, you mean the one after we finish the eos-beta commit feature right?",0,0.9939028024673462
393884343,8218,guozhangwang,2020-03-17T18:25:59Z,i mean the next pr when we add the eos-beta feature --- please see the first comment i have with this tag.,0,0.9936351776123047
393885815,8218,guozhangwang,2020-03-17T18:28:21Z,"hmm, i think moving forward we would create and maintain both the single thread-producer and task-producers as streamsproducer objects right?",0,0.9819970726966858
393887170,8218,guozhangwang,2020-03-17T18:30:28Z,"i'd say we can always log a debug there saying ""doing nothing in this function since we are in this state"" :) the main concern i had, is that if in the future we want to add more steps in addition to `recording sensor` etc, we may forget adding it in one place or the other. removing duplicated code helps us to be less vulnerable.",1,0.985994815826416
393898999,8218,mjsax,2020-03-17T18:50:49Z,sgtm,0,0.9894869327545166
393905732,8218,guozhangwang,2020-03-17T19:03:16Z,thanks for the cleanup!,1,0.870184600353241
393906971,8218,guozhangwang,2020-03-17T19:05:38Z,why we have to transit to suspended before prepare-closing? originally we want to check that created state can still trigger close.,0,0.982052743434906
393907754,8218,guozhangwang,2020-03-17T19:07:06Z,not introduced in this pr: could we add test checking closed state should not commit as well? also checking suspended state close-call is no-op.,0,0.9916298985481262
393911532,8218,guozhangwang,2020-03-17T19:14:37Z,"why making `committransaction` is less elegant? i thought that was fine since `streamsproducer` is inside the internals package anyways? in fact, in ttd we have access to internaltopologybuilder accessing it functions (we used to also have a wrapper of internaltopologybuilder which we removed later) so i thought that was the agreed pattern.",0,0.9856833815574646
393917156,8218,guozhangwang,2020-03-17T19:25:38Z,"this is a meta comment: since we moved the commit logic out of the tasks into task-manager already, we should add the check that: 1) inside the task manager, if the commit failed with fatal errors, the corresponding follow-up steps (postcommit, suspend, closeclean) should be skipped, and the exception is thrown out of the task-manager to thread 2) if commit failed with fenced errors, follow-up steps are also skipped (tasks state should be un-changed) and the task-migration exception is thrown out of the task-manager.",0,0.9938068389892578
393963708,8218,mjsax,2020-03-17T20:53:23Z,ack. we can remove this.,0,0.9671823978424072
393964723,8218,mjsax,2020-03-17T20:55:19Z,ack,0,0.9149930477142334
393966087,8218,mjsax,2020-03-17T20:57:46Z,but in `close()` if state is suspended we might still wipe out the state store -- it's not a no-op,0,0.9898881316184998
393968843,8218,mjsax,2020-03-17T21:03:00Z,"it's obviously subjective -- personally, even if something is internal, we should not just declare stuff as `public` but try to keep it to a minimum to follow the idea of encapsulation (not always possible). if you want me to remove this class and make the method `public` i can do it in a follow up pr. not sure if we have an agreed pattern, though.",0,0.8745720982551575
393979041,8218,guozhangwang,2020-03-17T21:23:47Z,"cool, in that sense let's just keep it then -- do not add it in one pr and remove it immediately in the next.",1,0.8725414276123047
56714551,1095,granthenke,2016-03-18T20:05:32Z,"not sure if this is the best way to do this. i need a different constructor for requesting a `null` list because `null` matches both the list and struct constructors with the same ""specificity"". i am open to ideas for a better way to support requesting no topic metadata.",0,0.8100868463516235
56716409,1095,gwenshap,2016-03-18T20:20:17Z,"you mean other.rack? also, i'm wondering whether we want to consider a node to be a different node when the rack changed. i guess it depends on how it is used - except it isn't used...",0,0.9756274819374084
56716786,1095,granthenke,2016-03-18T20:23:02Z,good catch. i just maintained equals meaning all fields match. i suspect thats the safest path to go right now.,1,0.992028534412384
56717383,1095,gwenshap,2016-03-18T20:27:12Z,"i noticed you keep using broker_v0 anywhere except metadata, and i think thats the plan going forward as well. if my understanding is correct, broker_v1 is not really a ""newer"" broker definition (which implies that eventually we'll move everything to use that) but rather a broker definition specific for metadata request or just a more detailed broker definition. maybe rename to something less misleading?",0,0.9735703468322754
56717758,1095,gwenshap,2016-03-18T20:29:50Z,and on similar topic (but should be separate jira) - the protocol has few different places with broker definitions - maybe more consolidation is possible?,0,0.9924155473709106
56717859,1095,granthenke,2016-03-18T20:30:38Z,"yes, my understanding is these ""sub-schemas"" are supposed to tie directly to single api/protocol to allow them to change independently. i think the fact that a broker_v0 was shared was a mistake. i had left the old one being shared just to minimize change. i can break-out and rename a bit to prevent an accidental sharing in the future.",0,0.9673925638198853
56718714,1095,granthenke,2016-03-18T20:37:26Z,"i am of the impression that we are not consolidating so that the wire protocols can change independently. however, we want to represent that in java or scala object is up to the parser. this decouples protocol from implementation. though even in implementation we have chosen to duplicate in the past too.",0,0.979850172996521
56768466,1095,ijuma,2016-03-20T17:47:15Z,would it make sense to use a bitset for these booleans?,0,0.9882810711860657
56892437,1095,granthenke,2016-03-21T20:38:10Z,"yeah, that could save a byte for each topic. i will mention it during the wire protocol discussion on the next kip call, since this needs to be reviewed/voted.",0,0.9867393970489502
57952993,1095,hachikuji,2016-03-30T19:57:34Z,"i've been wondering if it would be better to use static factory methods instead of relying on constructors. in that case, you could use something like `metadatarequest.alltopics()` or something like that.",0,0.9733734130859375
57953330,1095,granthenke,2016-03-30T19:59:43Z,"good suggestion. i like the builder pattern as well. the implementation can be a bit verbose in java, but it can do validation at build time and prevent the telescoping constructor problem. it may also be able to provide simplified api compatibility.",1,0.9909815192222595
57967577,1095,hachikuji,2016-03-30T21:31:43Z,"i also like the builder pattern. it reads nicely and you don't have to care about argument order. on the other hand, it's also easier to forget necessary arguments and it feels kind of silly when the number of arguments is small. one nice thing about factory methods is that you can give them convenient names (e.g. metadatarequest.alltopicsv1()). both options are probably better than using the constructors, but i don't think it would be too bad to stick with the current convention for this patch. another option would be to include an explicit flag in the constructor. for example: [code block] we could then have the other constructor which accepts the topic list use the ""empty means empty"" semantics, and users would have to call this method to get all topics.",1,0.9056509137153625
58056988,1095,granthenke,2016-03-31T13:55:48Z,"i do like the idea of a flag to make it explicit. the challenge that poses is compatibility. i think any existing constructor needs to continue to function the way it used to. so empty list would need to continue to signify ""all topics"", at least for existing constructors.",1,0.6002848148345947
58058004,1095,ijuma,2016-03-31T14:02:16Z,"request classes are not api so i am not sure why it has to be like that? the official position is that we generate javadoc for classes that are api: [a link] (yes, i know it's confusing, i hope to change that so internal classes are all in internal packages).",0,0.8445540070533752
58060325,1095,granthenke,2016-03-31T14:15:24Z,i didn't realize compatibility wasn't a concern on these classes. then we can do whatever we would like here.,0,0.7166010737419128
58221673,1095,granthenke,2016-04-01T15:24:57Z,i updated the constructor to take an `alltopics` boolean. i think the changes required to do so may also solve [a link]. it worked nicely with `metadata.needmetadataforalltopics` in the `networkclient`.,0,0.9871172308921814
58239805,1095,SinghAsDev,2016-04-01T17:36:14Z,"in current proposal, we are saying a null indicates all topics. would it be possible to use that here as well?",0,0.9933019876480103
58240259,1095,granthenke,2016-04-01T17:39:41Z,"the proposal is to use null on the wire protocol, not in the api. in the discussions it was mentioned that being more explicit in the api was favored. beyond that, if you specify `metadatarequest(null)` java wont know which constructor to use between `metadatarequest(list topics)` and `metadatarequest(struct struct)`.",0,0.9937617182731628
58243837,1095,SinghAsDev,2016-04-01T18:04:58Z,"got it, thanks for the explanation .",1,0.9757130146026611
58245304,1095,granthenke,2016-04-01T18:14:51Z,thanks for the review !,1,0.8464915752410889
58536600,1095,ijuma,2016-04-05T13:26:17Z,just noting that this is no longer relevant given the current implementation (for other people reading the pr).,0,0.9894261360168457
60636130,1095,gwenshap,2016-04-21T18:55:09Z,don't we usually add new arguments at the end?,0,0.990747332572937
60638297,1095,gwenshap,2016-04-21T19:08:35Z,do we need to validate if this is nullable before writing?,0,0.9921302199363708
60638460,1095,gwenshap,2016-04-21T19:09:40Z,do we want to throw an exception with appropriate message if item if null but shouldn't be?,0,0.9871424436569214
60638661,1095,gwenshap,2016-04-21T19:11:02Z,"not sure if it matters, but we will get the exact same hash for empty and null arrays?",0,0.9045392870903015
60641282,1095,granthenke,2016-04-21T19:28:51Z,"since this was in internals and i needed to update all usages regardless, i located ""related"" parameters close to each other. i can move to the end if you prefer.",0,0.9935094714164734
60642147,1095,granthenke,2016-04-21T19:35:12Z,i think all of the other types assume validate will be called before calling write and that the written object would be the one returned by the validate call. here is a code snippet from `schema.write(...)`: [code block],0,0.9906600117683411
60642638,1095,granthenke,2016-04-21T19:39:10Z,it fails further down during the cast the same way it would before nulls were allowed. that exception is caught and re-thrown as a schemaexception. this behavior is validated by `protocolserializationtest.testnulls`.,0,0.9925244450569153
60645983,1095,granthenke,2016-04-21T20:02:39Z,"good point. we don't have `hashcode` or `equals` defined for `schema`, `field` or `type`...perhaps we should.",1,0.8904501795768738
60660381,1095,gwenshap,2016-04-21T21:45:10Z,"yeah, i saw that. i'm suggesting a separate schemaexception with message specific for nulls, to make troubleshooting/debugging a bit easier. not a big deal though.",1,0.532384991645813
60660437,1095,gwenshap,2016-04-21T21:45:34Z,want to create a followup jira?,0,0.9923599362373352
60660863,1095,granthenke,2016-04-21T21:48:48Z,created [a link] to track that.,0,0.9958441853523254
60661081,1095,ijuma,2016-04-21T21:50:27Z,"personally, i'd introduce a `arrayof.nullable` static factory method as i think that would be more readable than the `true` here (since we don't have named arguments in java).",0,0.9924471378326416
60661303,1095,gwenshap,2016-04-21T21:52:16Z,i don't think we can do a fall-through here? since v1 error response is not a valid v0 response?,0,0.9850279092788696
60661511,1095,granthenke,2016-04-21T21:53:47Z,i can do that. it should probably be done for all types that don't accept null. i opened [a link] to track that.,0,0.9939731955528259
60662604,1095,gwenshap,2016-04-21T22:03:00Z,"i am bit confused about the use of controller node vs controllerid. the protocol requires sending controllerid, which is what we have in most places. but you also find the actual node and provide an api (which isn't used anywhere? not even in tests?) to get the node. wondering what was the the plan here.",-1,0.8270421028137207
60672248,1095,gwenshap,2016-04-21T23:41:16Z,thanks!,1,0.8631753921508789
60672977,1095,gwenshap,2016-04-21T23:49:55Z,i'm wondering if we can push down the work of figuring out if a topic is internal to topicmetadata constructor. it will clean up the api and topicmetadata has all the information it needs to find out.,0,0.9792532920837402
60673350,1095,gwenshap,2016-04-21T23:54:39Z,"mind adding a comment here, something along the lines of: ""in version 0, we returned an error when brokers with replicas were unavailable, while in higher versions we simply didn't include the broker in the list we returned"" (or is it vice-versa? anyway, its non-obvious and need a comment imo)",0,0.9532398581504822
60673675,1095,SinghAsDev,2016-04-21T23:58:50Z,nit: i think broker or broker_info or broker_metadata would be better.,0,0.9814730286598206
60673775,1095,gwenshap,2016-04-22T00:00:03Z,not 100% sure about changes to this test. random cleanup or related to kip-4?,0,0.694628894329071
60673904,1095,SinghAsDev,2016-04-22T00:01:23Z,should we mention effect of a null string as rack here?,0,0.9892947673797607
60673918,1095,gwenshap,2016-04-22T00:01:35Z,aren't we adding a test for the results with errorunavailableendpoints = false?,0,0.9943864345550537
60673941,1095,gwenshap,2016-04-22T00:01:52Z,love it!,1,0.9965997338294983
60674080,1095,gwenshap,2016-04-22T00:03:44Z,"ok, i saw we are testing both request versions below. i still find it a bit weird it is missing from the cache tests, since it is added functionality for the cache - but up to you.",-1,0.9350435733795166
60674146,1095,gwenshap,2016-04-22T00:04:31Z,do you want to also validate that v0 request with null still returns all topics?,0,0.9949119687080383
60674190,1095,gwenshap,2016-04-22T00:05:11Z,i also don't see us checking for v1 all-topics explicitly. do you want to add something?,0,0.9928200840950012
60674223,1095,gwenshap,2016-04-22T00:05:38Z,not sure how this is related.,0,0.7170701622962952
60674299,1095,gwenshap,2016-04-22T00:06:13Z,its fine. just checking :),1,0.9201273918151855
60674310,1095,gwenshap,2016-04-22T00:06:26Z,got it. thanks.,1,0.9930570125579834
60674321,1095,gwenshap,2016-04-22T00:06:34Z,thanks!,1,0.8631753921508789
60674337,1095,gwenshap,2016-04-22T00:06:52Z,+1,0,0.9816582202911377
60674619,1095,SinghAsDev,2016-04-22T00:10:09Z,"just thinking it loud here, it seems we follow getter convention here, we really do not have a common convention across the codebase. however, it is not too bad, as this is not end-user. i think user facing classes/interfaces do not follow getter convention though.",0,0.6717068552970886
60675033,1095,SinghAsDev,2016-04-22T00:15:12Z,shouldn't we check something like `topics != null && !topics.isempty()` or maybe we just want to rename the method to indicate we are indeed checking for topics to be non-null.,0,0.9886182546615601
60675649,1095,SinghAsDev,2016-04-22T00:23:11Z,"would it make sense to be consistent with other key names? have something like ""controller_id"".",0,0.9880027770996094
60676104,1095,gwenshap,2016-04-22T00:29:20Z,kafka-3603 seems to be for something else?,0,0.9843394756317139
60676663,1095,SinghAsDev,2016-04-22T00:36:36Z,+1,0,0.9816582202911377
60676892,1095,SinghAsDev,2016-04-22T00:40:19Z,nit: maybe we can leave this file out if there are no other changes?,0,0.9897133111953735
60755927,1095,ijuma,2016-04-22T15:19:50Z,this should be `byte` instead of `byte`.,0,0.9933195114135742
60756062,1095,ijuma,2016-04-22T15:20:48Z,"what is the reasoning for accepting any non-zero value as `true`? it seems more error-prone imo. if any value outside of `0` or `1` are used, it's probably a mistake.",0,0.8818032741546631
60756385,1095,ijuma,2016-04-22T15:22:59Z,do we want to ignore or it would it be better to validate it (ie `topics` must be empty or null for that case).,0,0.9896754622459412
60757857,1095,ijuma,2016-04-22T15:31:46Z,"you can just return the controller here and then you don't need the `controller` variable or break (in scala, i don't like to use `return`, but if one is using `break` already, then it's at a similar level imo).",0,0.9907171130180359
60758124,1095,ijuma,2016-04-22T15:33:37Z,"if possible, jun generally suggests that we have one constructor per version with older version constructors deprecated. seems like we could do that here right? the older version would not have `controllerid`.",0,0.992520809173584
60758473,1095,ijuma,2016-04-22T15:35:40Z,"i think it would be useful to add a comment here and when we set other new fields (`rack_key_name`, `is_internal_key_name`, etc.) saying stating the version they were added in (we do that in other request/response classes).",0,0.9872781038284302
60758863,1095,ijuma,2016-04-22T15:38:05Z,"hmm, if we don't have that field, then we don't know if it's internal or not, right?",0,0.967995822429657
60761238,1095,granthenke,2016-04-22T15:53:41Z,i had maintained the old constructor for compatibility in an older version of the patch. but in previous reviews i was told i did not need to maintain it: [a link],0,0.9944171905517578
60761858,1095,granthenke,2016-04-22T15:57:30Z,i am okay with that.,0,0.8920497894287109
60762586,1095,granthenke,2016-04-22T16:01:17Z,this is left over from changes required when leveraging zookeeper to track deletes. i left it because it looks like its closer to what was actually trying to be mocked based on the comment. i can keep it or leave it.,0,0.9856981635093689
60762636,1095,granthenke,2016-04-22T16:01:35Z,sure i will add some more test cases.,0,0.9863998889923096
60762667,1095,granthenke,2016-04-22T16:01:52Z,i can add those tests here too.,0,0.9951842427253723
60762756,1095,granthenke,2016-04-22T16:02:28Z,this is left over from changes required when leveraging zookeeper to track deletes. i left it because it looks like its closer to what was actually trying to be mocked based on the comment. i can keep it or leave it.,0,0.9856981635093689
60762885,1095,granthenke,2016-04-22T16:03:00Z,will add the comment.,0,0.9935917258262634
60762972,1095,granthenke,2016-04-22T16:03:33Z,thats an interesting idea. let me take a look and report back.,1,0.957668125629425
60763255,1095,granthenke,2016-04-22T16:05:26Z,"this is challenging because we use the same class for both v0 and v1 responses. in the common case if you have the new version of the class you would be using v1 protocol, but thats not always true. in the case of new fields i tried to pick a safe default. since v0 is not aware of internal topics i defaulted to false. do you have thoughts on a better approach?",0,0.6102767586708069
60763550,1095,ijuma,2016-04-22T16:07:18Z,"sorry for the confusion. if we don't need to use the older version, we can remove it. however, if we still need to use it, then it's better to keep a constructor for the older version instead of having a version parameter. that's based on jun's previous reviews, i actually prefer the current approach as we don't need to call deprecated constructors. anyway, if gwen is fine with this, maybe we can leave as is.",-1,0.9819860458374023
60763729,1095,ijuma,2016-04-22T16:08:38Z,do we need to check `false` twice?,0,0.9916485548019409
60763932,1095,ijuma,2016-04-22T16:10:07Z,shall we add a topic where the boolean is `true`?,0,0.9952894449234009
60764088,1095,ijuma,2016-04-22T16:11:07Z,should we just pass `null` instead of empty list (like in `requestresponsetest`)?,0,0.9938085675239563
60764126,1095,granthenke,2016-04-22T16:11:23Z,"whenever a broker id is used on the wire protocol, logically this class looks up the broker by id in the brokers list and represents it to the user as a node. this is very similar logic to how replicas ids are handled in this class. i am not saying its my favorite, but i chose to maintain the existing pattern. the controller node is not used yet, but in kip-4 it may be used to route messages.",0,0.9483662843704224
60764164,1095,ijuma,2016-04-22T16:11:39Z,nitpick: no need for braces.,0,0.9865459203720093
60764416,1095,ijuma,2016-04-22T16:13:41Z,not sure about that. the request classes shouldn't really have any logic imo. they should just be a way to serialize/deserialize to the kafka protocol. we could have a util method somewhere that does this. or at least a static factory method (instead of constructor) in the request classes as a pragmatic compromise.,0,0.8189672827720642
60764750,1095,granthenke,2016-04-22T16:16:09Z,"its a bit of a gray area. we introduced the boolean to be explicit and be the single deciding factor for all topics. if we have this validation, its actually the topics list that really matters again and we essentially have 2 toggles to enable all topics. when validating would we require null & true to get all topics and fail in all other cases in order to match closely to the wire protocols behavior?",0,0.7650405168533325
60764789,1095,granthenke,2016-04-22T16:16:25Z,will fix.,0,0.9901540875434875
60764921,1095,ijuma,2016-04-22T16:17:34Z,"we are using this `tostring` in a number of log statement, not sure the rack information is that relevant (the fact that `tostring` is used for both debug and more user-facing string is a pain). , you cleaned up the logs, what do you think?",-1,0.9702302813529968
60765137,1095,ijuma,2016-04-22T16:19:07Z,"ok, maybe add a comment in this case as it's not obvious.",0,0.9883325695991516
60765466,1095,granthenke,2016-04-22T16:21:18Z,"i implemented it this way to match the existing behavior of stopreplica requests delete_partitions boolean. that way this type could be used there as well without a version bump, and all the ""booleans"" would behave the same. i planned to update stopreplicarequest after this patch based on the decisions here. here is the relevant code: [a link]",0,0.9761497378349304
60765571,1095,granthenke,2016-04-22T16:22:00Z,this class uses get for all other methods so i followed that.,0,0.9940270185470581
60765672,1095,granthenke,2016-04-22T16:22:56Z,"apologies, copy and paste error. its [a link].",-1,0.6361147165298462
60765811,1095,granthenke,2016-04-22T16:24:02Z,what message would you suggest?,0,0.9891911745071411
60766018,1095,granthenke,2016-04-22T16:25:38Z,the idea is that this is the broker used with the metadata response. all objects tied to the metadata response are prefixed with metadata. there are other broker objects in this file that i would not want to be confused.,0,0.9928868412971497
60766035,1095,granthenke,2016-04-22T16:25:43Z,will do.,0,0.9465230703353882
60766571,1095,granthenke,2016-04-22T16:29:49Z,these constructors are generally only used in the broker. i like passing in the version because then one constructor can handle all versions and the broker is guaranteed to send the correct version back without a bunch of if/switch logic. there could be a case in the future where a separate constructor is required to maintain compatibility. but if i can avoid many constructors i would prefer it.,0,0.9483016133308411
60766711,1095,granthenke,2016-04-22T16:31:05Z,sure. will remove.,0,0.9894423484802246
60766886,1095,ijuma,2016-04-22T16:32:03Z,"`boolean` is a keyword, that's why.",0,0.9925318360328674
60766905,1095,granthenke,2016-04-22T16:32:18Z,no. will fix.,0,0.9886912107467651
60767008,1095,granthenke,2016-04-22T16:33:08Z,sure we can.,0,0.9709534049034119
60767033,1095,ijuma,2016-04-22T16:33:23Z,"i know what you mean, i did the same in a previous pr, but jun made me change it. ;) as i said, let's see what gwen thinks.",1,0.9941006302833557
60767100,1095,granthenke,2016-04-22T16:33:56Z,i can do that. i will include explanation in the version comments suggested earlier.,0,0.9946491122245789
60767154,1095,granthenke,2016-04-22T16:34:22Z,i think it depends on the choice in earlier comments here: [a link],0,0.9853707551956177
60767558,1095,granthenke,2016-04-22T16:37:27Z,"this is related to this discussion too: [a link] right now some these classes have quite a bit of logic and don't expose the ""raw"" information. i agree that it would be nice to have some layering here where the logic is handled/exposed elsewhere. i don't want to impose to much change on existing logic in this patch though either.",0,0.9723150134086609
60767635,1095,granthenke,2016-04-22T16:38:04Z,that too.,0,0.9814220666885376
60769396,1095,ijuma,2016-04-22T16:52:26Z,"this is a bit different. there are 3 levels, in a sense: 1. wire protocol 2. wrapping the wire protocol into domain model classes 3. having business logic like what topics are internal in the request classes (or calling helper methods for that from within the request classes) as we discussed previous , i think we should really do `1`, but we do `2` in a number of places. this suggestion is `3`. in any case, i'm ok if we do it in a static factory method as a starting point (and we can move it elsewhere in the future in a separate pr maybe).",0,0.9694101214408875
60770343,1095,SinghAsDev,2016-04-22T16:59:21Z,"ok, thanks for the explanation.",0,0.5746984481811523
60770562,1095,SinghAsDev,2016-04-22T17:00:59Z,"something that would capture the following, need not be this verbose though.",0,0.9842634797096252
60770887,1095,ijuma,2016-04-22T17:03:39Z,"generally, i'm against adding unused methods until we actually need to use them. i agree that this may make sense here from a consistency perspective, but even then i would lean towards not having it. if we do have it, then we should use it from a test, at least.",0,0.9706783294677734
60771090,1095,SinghAsDev,2016-04-22T17:05:24Z,"yea, i was just curious about reasoning, not specifically for the method.",0,0.9777347445487976
60771140,1095,ijuma,2016-04-22T17:05:55Z,legacy code is annoying. ;),-1,0.9747965931892395
60776015,1095,ijuma,2016-04-22T17:42:03Z,"the idea is to avoid mistakes. so, if someone gets the boolean logic inverted and passes some topics, then the validation would find that.",0,0.9917072653770447
60776076,1095,ijuma,2016-04-22T17:42:34Z,"by the way, i agree that this is a bit subjective.",0,0.9107609391212463
60776472,1095,granthenke,2016-04-22T17:45:18Z,i will play around with some options and run it by you.,0,0.9886196851730347
60776680,1095,granthenke,2016-04-22T17:46:41Z,that information is useful for rack configuration on the broker. i am not sure if it needs to be in the protocol documentation for the metadata response.,0,0.9894779324531555
60776722,1095,ijuma,2016-04-22T17:46:58Z,"this method is the main hotspot when it comes to the performance of metadata requests, so we need to be careful about adding additional logic here. i should have added a comment saying that, maybe you could do that. under the assumption that unavailable nodes are rare, it seems like this change is safe.",0,0.9852223992347717
60776919,1095,ijuma,2016-04-22T17:48:21Z,why don't we return `option[int]` here?,0,0.9937108755111694
60776992,1095,ijuma,2016-04-22T17:48:51Z,is there a reason why we don't check that the value is the same as `no_controller_id`?,0,0.9938594698905945
60777018,1095,granthenke,2016-04-22T17:49:00Z,"this is used in `metadatarequesttest.testcontrollerid`. i will look at keeping it around or not. if i do, i will make sure hascontroller is tested too.",0,0.9910879731178284
60777028,1095,ijuma,2016-04-22T17:49:05Z,formatting nit: this could be on the previous line.,0,0.9916025996208191
60777369,1095,ijuma,2016-04-22T17:51:32Z,i agree that these changes (and also in the other file) are weird to include here.,-1,0.9799023866653442
60777637,1095,ijuma,2016-04-22T17:53:39Z,seems unnecessary since the superclass already defines it?,0,0.9756245017051697
60778171,1095,gwenshap,2016-04-22T17:57:17Z,"i actually like the deprecated constructors because we get explicit compile warnings when we bump versions and don't accidentally forget to update some of the places where they are called. if you are not convinced that having warnings to help with bumps is useful, i won't make you change it ;)",1,0.9820612668991089
60786052,1095,gwenshap,2016-04-22T18:51:22Z,"has the full scope of kip-4 though, if he knows it will be used, it is best to add it now (since the whole point was to add the lower-level apis now)",0,0.9925242066383362
60787278,1095,ijuma,2016-04-22T18:59:32Z,"this is an internal class, so methods can be added at any time though. the point was to update the wire protocol now as far as i know.",0,0.9919409155845642
60788788,1095,gwenshap,2016-04-22T19:09:55Z,"i don't think it is internal? it isn't in an ""internals"" package... it is a public class in ""common"". afaik, this makes it public? obviously it isn't as widely used as kafkaproducer, but my understanding was that anything not in a package called ""internals"" is public?",0,0.9760909676551819
60789535,1095,ijuma,2016-04-22T19:14:58Z,"today the only public classes are the ones we generate javadoc for (this was confirmed by jay and neha). we don't generate the javadoc for the request classes. as you know, i think this is very confusing and i want to change it so that we use internals packages across the board.",-1,0.7402954697608948
60801036,1095,ijuma,2016-04-22T20:49:31Z,this is doing the same thing as the `controllerid` line. i think you meant to get the controller id from `metadataresponse`.,0,0.9947422742843628
60801175,1095,ijuma,2016-04-22T20:50:37Z,don't you mean to use `controllerserver2` and `metadataresponse2`?,0,0.9951289892196655
60801224,1095,ijuma,2016-04-22T20:51:00Z,"typo, `what's`.",0,0.9927480816841125
60801286,1095,ijuma,2016-04-22T20:51:25Z,nitpicks: `()` not needed in `brokers` and `rack`.,0,0.994834303855896
60801527,1095,ijuma,2016-04-22T20:53:21Z,there's a few other examples in this file.,0,0.9927746057510376
60801878,1095,ijuma,2016-04-22T20:55:59Z,can we rely on the ordering of the metadata in the response and of the partition metadata?,0,0.9926142692565918
60802099,1095,ijuma,2016-04-22T20:57:50Z,"nitpick: for cases like this, i think it's more readable to have the opening brace after `=>`. for cases where the opening brace can replace the opening parenthesis, it makes sense to position the brace like this case. a bit subjective though.",0,0.9562561511993408
60802287,1095,ijuma,2016-04-22T20:58:51Z,same question for a couple of other cases like this below.,0,0.9886293411254883
60802721,1095,ijuma,2016-04-22T21:02:08Z,how do we know that there are always 3 brokers? i guess the intent is that subclasses will use this in `generateconfigs` but that seems easy to miss. we could define this as a def and let the subclasses define it. or we could implement `generateconfigs` here and call an abstract method `generateconfig(brokerid)` or something.,0,0.9841485619544983
60802854,1095,ijuma,2016-04-22T21:03:19Z,the 3 methods above seem to be used in many tests. would it make sense to have a utility class or trait that people can mix-in?,0,0.9915629625320435
60802895,1095,ijuma,2016-04-22T21:03:40Z,nitpick: `correlationid += 1`,0,0.994407057762146
60802936,1095,ijuma,2016-04-22T21:04:09Z,this seems to be unused?,0,0.9920908212661743
60809216,1095,gwenshap,2016-04-22T22:03:27Z,"got it. thanks for clarifying. if we can modify it at any time, there's really no point in including ""may need"" features.",1,0.9903935790061951
60939173,1095,granthenke,2016-04-25T16:01:04Z,"it is unused, i just need to call parse to ensure it parses correctly and moves the buffer forward. i can remove the val assignment though.",0,0.9946735501289368
60940329,1095,granthenke,2016-04-25T16:08:16Z,"there is definitely a better way to share this test code across other tests. i would like to do this cleanup, but would you mind if i open a separate jira to track that and do it shortly after this patch?",0,0.9904106855392456
60940596,1095,ijuma,2016-04-25T16:09:48Z,"sounds good to me. also, please add a comment as side-effects like that are not obvious.",1,0.9093154668807983
60940760,1095,ijuma,2016-04-25T16:10:53Z,sure.,0,0.9824982285499573
60943982,1095,granthenke,2016-04-25T16:30:16Z,i moved the configuration to the baserequesttest and provided a way to override the properties in the subclass.,0,0.9944459199905396
60944350,1095,granthenke,2016-04-25T16:32:36Z,since i am asking for only 1 topic and that topic has only 1 partition it shouldn't matter here.,0,0.9679094552993774
60946083,1095,granthenke,2016-04-25T16:44:19Z,since any negative value is invalid i map it to none.,0,0.9848150014877319
60946121,1095,granthenke,2016-04-25T16:44:37Z,yeah i should return the option here and use `metadataresponse.no_controller_id` kafkaapis.,0,0.991905927658081
60946477,1095,granthenke,2016-04-25T16:46:54Z,i will add the comment.,0,0.9907878041267395
60948003,1095,granthenke,2016-04-25T16:55:56Z,i have added comments that they only exist in v1+,0,0.9946251511573792
60948570,1095,granthenke,2016-04-25T16:59:26Z,"i think it actually ends up being a bit of ""crying wolf"" since the brokers would be required to use the old constructors to support the old versions. we would throw, and likely suppress, the deprecation warnings in that case. i think unit tests are the best way to verify this behavior. i will work on increasing the version coverage on this patch and consider updating other apis at a later time.",0,0.930690348148346
60951090,1095,granthenke,2016-04-25T17:15:52Z,i would like to leave it for use in unit tests and also with the expectation that it will be used shortly. i will remove any method that is not being used or tested.,0,0.9915233850479126
60963008,1095,granthenke,2016-04-25T18:26:59Z,this can fall through because the constructor supports version 0 and 1. the version is passed as the last parameter. this is related to the discussion here: [a link],0,0.995126485824585
60963844,1095,gwenshap,2016-04-25T18:31:45Z,sounds good!,1,0.9884929060935974
60963946,1095,ijuma,2016-04-25T18:32:19Z,"the issue with this approach is that we accept instead of failing when we receive invalid values. in some cases, this can lead to bugs being missed.",0,0.9016467928886414
61162466,1095,ijuma,2016-04-26T20:54:58Z,we can call `isalltopics` on `request` and remove the comment about `null`,0,0.9948546886444092
61163654,1095,ijuma,2016-04-26T21:01:33Z,"i think it's important to be clear about the expected usage of methods like this. either we return a new instance or we mutate the passed instance. given how `properties` are generally used, isn't it better to just not return `properties`?",0,0.9808598756790161
61163744,1095,ijuma,2016-04-26T21:02:09Z,shall we add a helpful message via `getorelse`?,0,0.9951578974723816
61164103,1095,ijuma,2016-04-26T21:04:35Z,the second argument to `assertequals` could be `controllerid` right?,0,0.9936720132827759
61164205,1095,ijuma,2016-04-26T21:05:17Z,"this is kind of weird, we should probably get the broker id from the config (ie `controllerserver.config.brokerid`) or add a method to `kafkaserver` that returns the broker id.",-1,0.9698147773742676
61164585,1095,ijuma,2016-04-26T21:07:39Z,it's a bit weird that we assert that failover happened and then we wait until failover happens. shouldn't the `waituntiltrue` be before anything else?,-1,0.9781017899513245
61165412,1095,ijuma,2016-04-26T21:13:00Z,we should also include an assert for the field we can use to know that a replica is down.,0,0.9939770698547363
61178157,1095,granthenke,2016-04-26T22:50:00Z,this is because the failover is basically immediate when looking up the servers directly via: [code block] but propagating that state to the metadatacache and therefore the metadataresponse could take a bit of time and requires the `testutils.waituntiltrue`,0,0.990813672542572
61178707,1095,granthenke,2016-04-26T22:55:27Z,will add a check to confirm the downed broker is not in the brokers list,0,0.9933587908744812
61178731,1095,granthenke,2016-04-26T22:55:41Z,will change to config,0,0.9923787117004395
61182686,1095,ijuma,2016-04-26T23:36:29Z,thanks for the explanation.,0,0.5594896078109741
341684130,7629,mjsax,2019-11-01T17:53:06Z,"`application`? the operator are named, not the application?",0,0.994515061378479
341686787,7629,mjsax,2019-11-01T17:59:30Z,"should this be a paragraph, ie, wrapped with ` ... ` tags? same below.",0,0.9923738837242126
341687086,7629,mjsax,2019-11-01T18:00:12Z,"this is not the upgrade section, hence, i would remove the reference to `2.4` and the word `now`.",0,0.9936782717704773
341687746,7629,mjsax,2019-11-01T18:01:54Z,"`prefixed` -> the ""suffix"" is ""prefixed"" -- quite hard to read. also, are the details of the `number-suffix` format relevant?",0,0.6012609004974365
341689152,7629,mjsax,2019-11-01T18:05:23Z,"we should be a little bit more clear. at papi level, there are `processors` and `statestores` and people need to name the explicitly. at the dsl, we have operators, and an operator may compile down to multiple `processors, `statestores`, and `repartition-topic`, and all those are name automatically, and there is a relationship between the processor-name and the store/changelog topic name and repartition topic names.",0,0.9904124140739441
341695265,7629,mjsax,2019-11-01T18:20:38Z,nit: remove version reference,0,0.990075409412384
341695374,7629,mjsax,2019-11-01T18:20:56Z,nit: remove `now`,0,0.9935938715934753
341696372,7629,mjsax,2019-11-01T18:23:29Z,"should this be formatted with ""single line per operator"" to make it easier to read (and to align with the formatting of the other code snippets?",0,0.9910594820976257
341696731,7629,mjsax,2019-11-01T18:24:23Z,"does this render correctly? i think, ` ` does not remove ""indenting whitespaces"" and thus this would render the indention...",0,0.9922502636909485
341707445,7629,mjsax,2019-11-01T18:52:05Z,nit: ` before ` ?,0,0.9858613014221191
341707858,7629,mjsax,2019-11-01T18:53:20Z,"`with the joined, streamjoined, or grouped classed`",0,0.9903913736343384
341708595,7629,mjsax,2019-11-01T18:55:01Z,`even though you've added processors before your state store` -> `with or without the filter operation`,0,0.9935744404792786
341709276,7629,mjsax,2019-11-01T18:56:52Z,"nit: `:` should be on line above `topolog:` -- otherwise it will be rendered as `topolog :` (ie, with a ws in between)",0,0.9909049868583679
341709757,7629,mjsax,2019-11-01T18:58:08Z,"for `kstream-ktable` joins, it's still `joined`, right? so we need to add one line to the column?",0,0.9930904507637024
341710210,7629,mjsax,2019-11-01T18:59:16Z,for aggregations and ktables-ktable joins right? to distinguish the `kstream-kstream` join case?,0,0.9941551089286804
341881771,7629,ableegoldman,2019-11-04T00:02:03Z,"how about ""naming operators in a streams dsl application""?",0,0.9915022850036621
341881852,7629,ableegoldman,2019-11-04T00:03:23Z,nit: remove comma after 'dsl',0,0.9949164390563965
341882038,7629,ableegoldman,2019-11-04T00:07:16Z,"i agree it's not necessary to mention the details here, but i do think it's appropriate to briefly explain where the compatibility or ""name shifting"" issue comes from in the `changing names` section below",0,0.973648190498352
341882125,7629,ableegoldman,2019-11-04T00:08:57Z,"have you considered any alternative names for this section/trade-off? ""cognitive issues"" seems to have a weird connotation, what about just `readability` or `readability problems`?",-1,0.9470266699790955
341882260,7629,ableegoldman,2019-11-04T00:11:22Z,"are you referring to repartition topics, or users failing to name their topics meaningfully? we should definitive make it clear they are encouraged to name things meaningfully, and it seems weird to expect users to choose meaningful names for their operators but not for their topics",-1,0.9842529892921448
341882442,7629,ableegoldman,2019-11-04T00:15:10Z,"i personally find it more readable when everything is in its own section, eg the section beginning ""but there's another reason..."" was moved to the `changing names` section whose topic it's actually referring to. but feel free to leave as-is if you or anyone else disagrees",0,0.7946661710739136
341882738,7629,ableegoldman,2019-11-04T00:20:47Z,"i'm finding the comment about **most** processors existing in memory only a bit confusing -- maybe just use the term ""stateless"" instead? also, i think it's a bit misleading to say that ""because most are stateless, this shifting presents no issue"" -- maybe rephrase to something like ""many processors are stateless and therefore exist in memory only, so this name shifting on topology change presents no issue to applications built entirely of such operators."" ?",-1,0.5098776817321777
341883192,7629,ableegoldman,2019-11-04T00:29:55Z,"""give the state store a constant user-defined name instead of relying...""",0,0.9898985028266907
341883257,7629,ableegoldman,2019-11-04T00:31:12Z,nit: replace `--` with `such as`,0,0.994439959526062
341883357,7629,ableegoldman,2019-11-04T00:33:07Z,"nit: `transient` --> `stateless` ? i think it's good to be consistent in our terminology throughout the docs -- it might be obvious to us that ""stateless"", ""in-memory"", and ""transient"" all refer to the same thing, but i think users will find this confusing.",0,0.956966757774353
342141293,7629,bbejeck,2019-11-04T16:24:57Z,ack,0,0.9149930477142334
342150101,7629,bbejeck,2019-11-04T16:41:15Z,ack,0,0.9149930477142334
342151782,7629,bbejeck,2019-11-04T16:44:25Z,"i'll clean this up some, but i'd prefer to leave this here to set the stage for the `changing names` section.",0,0.9873265624046326
342186088,7629,bbejeck,2019-11-04T17:54:38Z,ack,0,0.9149930477142334
342269064,7629,bbejeck,2019-11-04T21:04:28Z,ack,0,0.9149930477142334
342270140,7629,bbejeck,2019-11-04T21:07:09Z,ack,0,0.9149930477142334
342270257,7629,bbejeck,2019-11-04T21:07:28Z,ack,0,0.9149930477142334
342271483,7629,bbejeck,2019-11-04T21:10:33Z,ack,0,0.9149930477142334
342271670,7629,bbejeck,2019-11-04T21:11:03Z,"that's what i wanted, but is the indentation not correct?",0,0.9884864091873169
342271794,7629,bbejeck,2019-11-04T21:11:24Z,ack,0,0.9149930477142334
342271936,7629,bbejeck,2019-11-04T21:11:45Z,ack,0,0.9149930477142334
342272114,7629,bbejeck,2019-11-04T21:12:11Z,ack,0,0.9149930477142334
342272560,7629,bbejeck,2019-11-04T21:13:14Z,ack,0,0.9149930477142334
342272791,7629,bbejeck,2019-11-04T21:13:51Z,ack,0,0.9149930477142334
342273114,7629,bbejeck,2019-11-04T21:14:45Z,ack,0,0.9149930477142334
342273794,7629,bbejeck,2019-11-04T21:16:27Z,my point here is that most users won't have control over topic names. they'll build a streams application to work with existing topics.,0,0.9822147488594055
342274069,7629,bbejeck,2019-11-04T21:17:07Z,ack,0,0.9149930477142334
342274140,7629,bbejeck,2019-11-04T21:17:17Z,ack,0,0.9149930477142334
342274425,7629,bbejeck,2019-11-04T21:18:03Z,ack,0,0.9149930477142334
342274497,7629,bbejeck,2019-11-04T21:18:14Z,ack,0,0.9149930477142334
342274660,7629,bbejeck,2019-11-04T21:18:39Z,ack,0,0.9149930477142334
342275213,7629,bbejeck,2019-11-04T21:19:53Z,ack,0,0.9149930477142334
342275977,7629,bbejeck,2019-11-04T21:21:43Z,ack,0,0.9149930477142334
342276210,7629,bbejeck,2019-11-04T21:22:18Z,ack,0,0.9149930477142334
342276356,7629,bbejeck,2019-11-04T21:22:41Z,ack,0,0.9149930477142334
342276577,7629,bbejeck,2019-11-04T21:23:13Z,ack,0,0.9149930477142334
342658799,7629,bbejeck,2019-11-05T16:24:07Z,"i think it fits where i had it originally, but you are correct about it being in the same section as well. if i kept it in the original location, i should at least repeat the information in the `changing names` section. but i opted to take your suggestion and just move it there altogether",1,0.5565547943115234
342659633,7629,bbejeck,2019-11-05T16:25:33Z,ack,0,0.9149930477142334
342659990,7629,bbejeck,2019-11-05T16:26:08Z,ack,0,0.9149930477142334
342662764,7629,bbejeck,2019-11-05T16:30:36Z,ack,0,0.9149930477142334
342664122,7629,bbejeck,2019-11-05T16:32:41Z,ack,0,0.9149930477142334
342664196,7629,bbejeck,2019-11-05T16:32:50Z,ack,0,0.9149930477142334
342665851,7629,bbejeck,2019-11-05T16:35:39Z,ack,0,0.9149930477142334
342667608,7629,bbejeck,2019-11-05T16:38:49Z,ack,0,0.9149930477142334
342668807,7629,bbejeck,2019-11-05T16:41:02Z,ack,0,0.9149930477142334
342669710,7629,bbejeck,2019-11-05T16:42:28Z,ack,0,0.9149930477142334
342670496,7629,bbejeck,2019-11-05T16:43:43Z,ack,0,0.9149930477142334
342676589,7629,bbejeck,2019-11-05T16:54:24Z,"ack, i used something similar",0,0.9864524602890015
342676930,7629,bbejeck,2019-11-05T16:55:01Z,ack,0,0.9149930477142334
342678646,7629,bbejeck,2019-11-05T16:58:12Z,ack,0,0.9149930477142334
342680311,7629,bbejeck,2019-11-05T17:01:20Z,ack,0,0.9149930477142334
342682536,7629,bbejeck,2019-11-05T17:05:33Z,ack,0,0.9149930477142334
342683837,7629,bbejeck,2019-11-05T17:08:03Z,ack,0,0.9149930477142334
342684647,7629,bbejeck,2019-11-05T17:09:43Z,ack,0,0.9149930477142334
342685100,7629,bbejeck,2019-11-05T17:10:34Z,ack,0,0.9149930477142334
342686001,7629,bbejeck,2019-11-05T17:12:14Z,ack,0,0.9149930477142334
342686440,7629,bbejeck,2019-11-05T17:13:06Z,ack,0,0.9149930477142334
342687361,7629,bbejeck,2019-11-05T17:14:50Z,ack,0,0.9149930477142334
342687629,7629,bbejeck,2019-11-05T17:15:23Z,ack,0,0.9149930477142334
342688024,7629,bbejeck,2019-11-05T17:16:06Z,ack,0,0.9149930477142334
342688356,7629,bbejeck,2019-11-05T17:16:40Z,ack,0,0.9149930477142334
342689620,7629,bbejeck,2019-11-05T17:19:10Z,ack with a slight tweek,0,0.956786036491394
342690110,7629,bbejeck,2019-11-05T17:20:11Z,good point,1,0.9818260669708252
342690641,7629,bbejeck,2019-11-05T17:21:20Z,ack,0,0.9149930477142334
342690865,7629,bbejeck,2019-11-05T17:21:42Z,ack,0,0.9149930477142334
342691755,7629,bbejeck,2019-11-05T17:23:21Z,good catch!,1,0.9941828846931458
342693339,7629,bbejeck,2019-11-05T17:26:23Z,ack,0,0.9149930477142334
342694351,7629,bbejeck,2019-11-05T17:28:30Z,"i'd prefer to keep this as is, but if you have a strong opinion on this, i'll make the change.",0,0.9599453210830688
342696400,7629,bbejeck,2019-11-05T17:32:41Z,ack,0,0.9149930477142334
342787455,7629,ableegoldman,2019-11-05T20:43:20Z,"q: what do you mean by `the generated processor-name state store`? and which topic names, changelog or input/output? i'm not sure i follow this sentence",0,0.9661934971809387
342819399,7629,ableegoldman,2019-11-05T21:58:57Z,"prop: i still find this sentence confusing but if others disagree i'll hold my peace...but how about something like ""...this name shifting presents no issue for many topologies"" or ""for any stateless topologies"" ?",0,0.6302711367607117
342852018,7629,ableegoldman,2019-11-05T23:34:27Z,"prop: sentence reads a bit awkward, how about `...the state store (and changelog topic) names...` or `...the state store names (and changelog topics as well) have changed` ?",-1,0.9616518020629883
342854854,7629,ableegoldman,2019-11-05T23:44:54Z,"req: does it make sense for this section to go after the ""testing a streams application"" section? i would keep it together with the other dsl operators prop: do you think we should include a quick line about why you'd want to name things here? just wondering if we should protect against people who won't want to read the full manual, and won't realize that naming is essential for compatibility",0,0.9686273336410522
344388199,7629,bbejeck,2019-11-08T22:16:06Z,"i think it's a bit subjective. imho it should come after all the other operations are described as this is a ""meta-operation"". at any rate, i've moved it up closer, so it's the first item in the list after describing the other operations. i'm inclined to leave this as-is, it's just one click, and users can read the first paragraph.",0,0.6394479274749756
344393729,7629,bbejeck,2019-11-08T22:36:56Z,clarified some (i think). if it's still unclear i'll just remove it altogether.,0,0.9854167103767395
344401859,7629,bbejeck,2019-11-08T23:12:02Z,updated,0,0.7592994570732117
344403668,7629,bbejeck,2019-11-08T23:20:50Z,ack,0,0.9149930477142334
344404824,7629,ableegoldman,2019-11-08T23:27:03Z,fair enough,0,0.9672778844833374
344405137,7629,ableegoldman,2019-11-08T23:28:37Z,:thumbs_up: this is a good point to drive home,1,0.9922730326652527
344406892,7629,ableegoldman,2019-11-08T23:38:02Z,"hm. is this roughly what you mean here: ""the processor name generated for a state store (and hence changelog topic name) will also be used in generating the repartition topic name"" or something to that affect? or even replacing `generated processor-name state store` with `state store's generated processor name` or `generated processor-name of a state store`?",0,0.9855769276618958
344474564,7629,mjsax,2019-11-10T06:22:20Z,"this example has a similar issue: [a link] note that the first block of the code example has a larger indention as the last two lines. if you compare with the docs files, the first block has whitespace: [a link] the last two lines don't have and render correctly: [a link] the example i picked uses ` ` tag but i think ` ` work the same way.",0,0.9913532137870789
344474629,7629,mjsax,2019-11-10T06:25:06Z,nit: remove whitespace in ` repartition...`,0,0.9917336702346802
344474691,7629,mjsax,2019-11-10T06:27:05Z,"-> `processor names, state store names (and hence changelog topics names), and repartition topic names` if you don't repeat `names` (note plural) it's hard to read -- and not `-` in `processor names`.",0,0.9798460602760315
344474755,7629,mjsax,2019-11-10T06:29:58Z,"why `but`? maybe better, `note, that the names of state stores and changelog/repartition topics are ""stateful"" while processor names are ""stateless"".` i would not use ` ` but put into quote -- a name is not really stateful, but i understand what you want to say. again, no `-` in `processor names`",0,0.9891886711120605
344474790,7629,mjsax,2019-11-10T06:31:45Z,"i think, ` ` tag has similar indentation issue as ` ` tag -- compare my other comment. (there are more ` ` tags below -- won't comment on them but please fix all)",0,0.9833154678344727
344474827,7629,mjsax,2019-11-10T06:33:58Z,missing ` ` tag,0,0.9873102903366089
344474843,7629,mjsax,2019-11-10T06:34:20Z,missing ` ` tag,0,0.9873102903366089
344474850,7629,mjsax,2019-11-10T06:34:31Z,missing ` ` tag,0,0.9873102903366089
344474854,7629,mjsax,2019-11-10T06:34:36Z,missing ` ` tag,0,0.9873102903366089
344474856,7629,mjsax,2019-11-10T06:34:44Z,missing ` ` tag,0,0.9873102903366089
344474861,7629,mjsax,2019-11-10T06:35:07Z,missing ` ` tag (there seems to be more below; please fix),0,0.988100528717041
345833885,7629,bbejeck,2019-11-13T15:43:14Z,ack,0,0.9149930477142334
345833978,7629,bbejeck,2019-11-13T15:43:23Z,ack,0,0.9149930477142334
345834082,7629,bbejeck,2019-11-13T15:43:33Z,ack,0,0.9149930477142334
345834190,7629,bbejeck,2019-11-13T15:43:43Z,ack,0,0.9149930477142334
345834273,7629,bbejeck,2019-11-13T15:43:51Z,ack,0,0.9149930477142334
345834384,7629,bbejeck,2019-11-13T15:44:01Z,ack,0,0.9149930477142334
418108095,8589,abbccdda,2020-04-30T15:45:14Z,could we pass the members into the context?,0,0.993466317653656
420339593,8589,abbccdda,2020-05-05T19:03:29Z,remove print statements,0,0.9928181171417236
420340211,8589,abbccdda,2020-05-05T19:04:30Z,"curious why we are still continuing in this case, as the member lookup already fails.",0,0.9293191432952881
420341894,8589,abbccdda,2020-05-05T19:07:17Z,could we just make members to be `optional >` so that we don't need a separate removeall parameter?,0,0.993429958820343
420344946,8589,abbccdda,2020-05-05T19:12:50Z,style error here. i would recommend doing a self style check like: `./gradlew checkstylemain checkstyletest spotbugsmain spotbugstest spotbugsscoverage compiletestjava` otherwise we still need to fix those failures after we do jenkins build.,0,0.9747757315635681
420568190,8589,feyman2016,2020-05-06T06:23:45Z,"thanks for the advice, will fix it in the next commit.",1,0.8827475905418396
420806232,8589,feyman2016,2020-05-06T13:50:14Z,"sure. taking a step further, can we just keep the the type `set ` for `members` unchanged and treat it as `removeall` if the `members` is empty set?",0,0.9915044903755188
420824271,8589,feyman2016,2020-05-06T14:13:08Z,"my initial thought was to put the `members` in the context, but hesitated to do so because the `consumergroupoperationcontext` seems to be for generic usage. so i just refer to `kafkaadminclient#getalterconsumergroupoffsetscall` and make the members as a separate input param. anyway, i'm glad to make the change if we think it's preferred to put the `members` in context.",1,0.8973448872566223
420824572,8589,feyman2016,2020-05-06T14:13:32Z,fixed~,0,0.9740610718727112
420848223,8589,feyman2016,2020-05-06T14:43:57Z,"thanks, will fix this .",1,0.924448549747467
421216617,8589,feyman2016,2020-05-07T03:24:17Z,fixed,0,0.920660674571991
421216746,8589,feyman2016,2020-05-07T03:24:43Z,updated~,0,0.9743568301200867
421216977,8589,feyman2016,2020-05-07T03:25:42Z,"i reran the self style check, but didn't capture any error. i assume the error would be the missed `final` in for loop, updated.",0,0.9917466640472412
424198050,8589,abbccdda,2020-05-13T06:23:08Z,nit: space before `:`,0,0.985025942325592
424510483,8589,abbccdda,2020-05-13T15:04:03Z,"yes, i feel this is more consistent for internal calls not to do a second round of interpretation for which `members` set to use.",0,0.9872638583183289
424512993,8589,abbccdda,2020-05-13T15:07:20Z,nit: remove extra line,0,0.9926522374153137
424516058,8589,abbccdda,2020-05-13T15:11:24Z,should be collection.emptylist(),0,0.9947104454040527
424517564,8589,abbccdda,2020-05-13T15:13:24Z,"why do we blindly put `allmembers`? i believe we base on context to interpret, but like discussed earlier, this is easy to make mistake, we should rely on one source for members.",0,0.9729062914848328
424518540,8589,abbccdda,2020-05-13T15:14:40Z,"and to be clear, i'm not suggesting we have to put stuff into the context, just always passing in the intended removal list and do not depend on `context.removeall` again inside internal function.",0,0.9922637939453125
424522056,8589,abbccdda,2020-05-13T15:19:18Z,not necessary change,0,0.9917939305305481
424522792,8589,abbccdda,2020-05-13T15:20:13Z,nit: space after `empty_group_instance_id`,0,0.9940266609191895
424524146,8589,abbccdda,2020-05-13T15:22:05Z,could we specify the return type?,0,0.9943532943725586
424525171,8589,abbccdda,2020-05-13T15:23:22Z,"i don't think we really need this struct, could we just put `null` in `groupinstanceset`?",0,0.9812705516815186
424525436,8589,abbccdda,2020-05-13T15:23:44Z,nit: space,0,0.787409245967865
424525798,8589,abbccdda,2020-05-13T15:24:16Z,why do we suppress here?,0,0.9701943397521973
424527021,8589,abbccdda,2020-05-13T15:25:51Z,remained -> remaining,0,0.9781721830368042
424529767,8589,abbccdda,2020-05-13T15:29:16Z,do we also want to edit the `usage` info on top to mention the force delete option?,0,0.9951342940330505
428579361,8589,feyman2016,2020-05-21T10:47:11Z,"i think so, updated",0,0.9711721539497375
428580805,8589,feyman2016,2020-05-21T10:50:37Z,fixed~,0,0.9740610718727112
428581576,8589,feyman2016,2020-05-21T10:52:32Z,fixed,0,0.920660674571991
428583883,8589,feyman2016,2020-05-21T10:58:19Z,"fixed, now we explicitly pass in the members to be deleted to the private `getremovemembersfromgroupcall`",0,0.9934925436973572
428585120,8589,feyman2016,2020-05-21T11:01:17Z,reverted,0,0.9763132929801941
428585373,8589,feyman2016,2020-05-21T11:01:53Z,fixed,0,0.920660674571991
428585617,8589,feyman2016,2020-05-21T11:02:29Z,refactored,0,0.9915287494659424
428586730,8589,feyman2016,2020-05-21T11:05:08Z,"i feel like this is more informative, so didn't update it, but yeah, i can update if we really not prefer this~",0,0.7092422246932983
428587018,8589,feyman2016,2020-05-21T11:05:49Z,fixed,0,0.920660674571991
428588172,8589,feyman2016,2020-05-21T11:08:27Z,fixed,0,0.920660674571991
428589350,8589,feyman2016,2020-05-21T11:11:16Z,"didn't change the exception handling logic here, just extract the thread creation logic to reuse~",0,0.9935991764068604
428745517,8589,abbccdda,2020-05-21T15:51:55Z,i think we should catch `exception` here: [a link],0,0.9894497990608215
428748938,8589,abbccdda,2020-05-21T15:56:31Z,"this indentation is a bit weird, let's just merge l3625-3626",-1,0.9685578942298889
428751049,8589,abbccdda,2020-05-21T16:00:08Z,let's get back the original indentation.,0,0.9906272888183594
428752600,8589,abbccdda,2020-05-21T16:02:44Z,nit: we could merge l3666-3667,0,0.9923719167709351
428753012,8589,abbccdda,2020-05-21T16:03:26Z,nit: we could name it `members` now,0,0.9849931001663208
428756738,8589,abbccdda,2020-05-21T16:09:52Z,i could see this doesn't hold true for a plain static member removal. let's discuss why skipping the individual member check in `removemembersfromconsumergroupresult` makes sense over there.,0,0.9912007451057434
428757676,8589,abbccdda,2020-05-21T16:11:25Z,collections.emptyset() makes more sense since it is immutable.,0,0.9858915209770203
428758681,8589,abbccdda,2020-05-21T16:13:16Z,"in `removeall()` mode, why could we skip the individual member removal results? i guess although we don't need to verify against the original member list (because they don't exist for `removeall`), going throw the sub error list is still valuable to make sure there is no unexpected failure.",0,0.9847785830497742
428758798,8589,abbccdda,2020-05-21T16:13:27Z,remove print statement.,0,0.9903836846351624
428762047,8589,abbccdda,2020-05-21T16:19:03Z,"this test looks good, but it seems that we didn't test the case where some members get deleted successfully while some are not?",0,0.8955071568489075
428763784,8589,abbccdda,2020-05-21T16:22:10Z,"should we check the member removal result here before proceeding? if that call failed, the whole operation should fail with error message containing the result imho.",0,0.9798070192337036
428764977,8589,abbccdda,2020-05-21T16:24:15Z,fair enough,0,0.9672778844833374
428767771,8589,abbccdda,2020-05-21T16:28:56Z,does this check duplicate l1103? also i think it makes sense to check all the members' clientid as they should all equal to `testclientid`,0,0.9935356378555298
428769255,8589,abbccdda,2020-05-21T16:31:25Z,"i prefer `testinstanceidone = ""test_instance_id_1""` and `testinstanceidtwo = ""test_instance_id_2""`",0,0.9945722222328186
428770028,8589,abbccdda,2020-05-21T16:32:48Z,size - 1,0,0.9865946769714355
428770176,8589,abbccdda,2020-05-21T16:33:09Z,we could remove this comment for now,0,0.9908815622329712
428770601,8589,abbccdda,2020-05-21T16:33:50Z,nit: format i'm pretty surprised this wasn't caught in my previous template. let me check how to cover this in style test as well.,-1,0.7415441870689392
428771346,8589,abbccdda,2020-05-21T16:35:08Z,"what does `"""" + ` mean?",0,0.9876188039779663
428772089,8589,abbccdda,2020-05-21T16:36:25Z,nit: parameters are not aligned.,0,0.9396790862083435
428772936,8589,abbccdda,2020-05-21T16:37:52Z,"like said earlier, i think we could just return `return new streamsresetter().run(parameters, cleanupconfig) == 0`",0,0.9928721785545349
428773173,8589,abbccdda,2020-05-21T16:38:16Z,"we could add meta comment for the return value here, and instead of returning an exit code, i feel a boolean is suffice to indicate whether the clean operation was successful or not.",0,0.9918278455734253
429070319,8589,feyman2016,2020-05-22T06:43:25Z,"indeed, updated as suggested",0,0.9935784339904785
429070411,8589,feyman2016,2020-05-22T06:43:39Z,updated,0,0.7592994570732117
429071232,8589,feyman2016,2020-05-22T06:46:07Z,fixed,0,0.920660674571991
429082038,8589,feyman2016,2020-05-22T07:16:49Z,"without the `"""" +` to convert the value to string, we will get exception like: it is because `streams_consumer_timeout = 2000l`, `""""+` is widely used in this test, just follow it here without any change to not enlarge the scope of this pr, i can help to create a jira to enhance it if we think this workaround is not quite intuitive~ [code block]",0,0.9934050440788269
429082487,8589,feyman2016,2020-05-22T07:18:01Z,"thanks, but i wonder what does the **template** refer to here?",1,0.6811376214027405
429083564,8589,feyman2016,2020-05-22T07:20:46Z,"removed, but curious about the reason :)",1,0.6106941103935242
429083611,8589,feyman2016,2020-05-22T07:20:54Z,fixed,0,0.920660674571991
429083674,8589,feyman2016,2020-05-22T07:21:04Z,fixed,0,0.920660674571991
429083960,8589,feyman2016,2020-05-22T07:21:45Z,"thanks, all members' clientid are checked now",1,0.8667640089988708
429084219,8589,feyman2016,2020-05-22T07:22:22Z,"agreed, fixed",0,0.9324583411216736
429084559,8589,feyman2016,2020-05-22T07:23:04Z,good catch! added the test for partial failure,1,0.9962235689163208
429084786,8589,feyman2016,2020-05-22T07:23:40Z,"make sense, fixed",0,0.9817054271697998
429086933,8589,feyman2016,2020-05-22T07:28:59Z,"yeah, just as you surmised, but you are right, we should scan the removal results as well. slightly updated, followed the convention of `non-removeall` scenario, just return with the first exception",0,0.9914030432701111
429087051,8589,feyman2016,2020-05-22T07:29:17Z,"yeah, fixed",0,0.9527626037597656
429087133,8589,feyman2016,2020-05-22T07:29:27Z,updated,0,0.7592994570732117
429087216,8589,feyman2016,2020-05-22T07:29:38Z,fixed,0,0.920660674571991
429087282,8589,feyman2016,2020-05-22T07:29:48Z,fixed,0,0.920660674571991
429087492,8589,feyman2016,2020-05-22T07:30:17Z,"make sense, fixed~",0,0.9550281167030334
429133442,8589,feyman2016,2020-05-22T09:11:18Z,fixed,0,0.920660674571991
429145185,8589,feyman2016,2020-05-22T09:35:24Z,"for removing static members, this still true because we put memberid as `""""` in the request, and the server will also response with the same request field. (verified `groupcoordinator#handleleavegroup`) for removing dynamic members, we need this change to know the memberid for the caller. i suppose the `individual check` here is just to check the response against the members to be removed(for `removeall` scenario)? previously i thought of putting all members got from `kafkaadminclient#getmembersfromgroup` in the removemembersfromconsumergroupresult for checking, but in `removeall` scenario, we get members as `memberidentity` which cannot be converted back to `membertoremove`, so i'm hesitate to do in this way",0,0.9922577142715454
429276600,8589,feyman2016,2020-05-22T14:22:23Z,wrap to let the failed member info available for caller like `streamsresetter`. only capture the first found member error like in the non `removeall` scenario.,0,0.9909101128578186
429329313,8589,abbccdda,2020-05-22T15:57:04Z,nit: extra semi-colon,0,0.9939050078392029
429333199,8589,abbccdda,2020-05-22T16:11:06Z,"let's put the exception in the cause so that we could verify the cause in `kafkaadminclienttest`, as: [code block]",0,0.9944688081741333
429333355,8589,abbccdda,2020-05-22T16:11:21Z,"nit: we could set `""0""` to `joingrouprequest.unknown_member_id` if we don't want to test it out. having all members use the same member.id is a bit weird.",-1,0.9832659959793091
429333999,8589,abbccdda,2020-05-22T16:12:30Z,nit: space after `*`. also i feel we could make the context more concrete by: [code block],0,0.9820417165756226
429338025,8589,abbccdda,2020-05-22T16:20:11Z,"i see, this is indeed weird, please file a jira so that we could clean in a follow-up pr if others feel the same way.",-1,0.9868490695953369
429404004,8589,abbccdda,2020-05-22T18:50:06Z,this is no longer used.,0,0.9890861511230469
429504184,8589,feyman2016,2020-05-23T01:57:09Z,"cool, updated",1,0.9904088973999023
429504532,8589,feyman2016,2020-05-23T02:01:24Z,no existing help method to assert the cause of exception throw by `all()`. also i think it's more straight forward in this way.,0,0.9846620559692383
429504600,8589,feyman2016,2020-05-23T02:02:25Z,removed,0,0.9591778516769409
429504705,8589,feyman2016,2020-05-23T02:04:05Z,"indeed, updated",0,0.9895870685577393
429504725,8589,feyman2016,2020-05-23T02:04:26Z,"yeah, updated",0,0.9819090366363525
429507189,8589,feyman2016,2020-05-23T02:44:53Z,"created [a link] for tracking, thanks!",1,0.9431326985359192
430828662,8589,mjsax,2020-05-27T02:51:46Z,why do we need this part? seems sufficient to end the test here?,0,0.9917786717414856
430828933,8589,mjsax,2020-05-27T02:52:49Z,"with `cleanglobal` and `--force` the consumer group could be empty when `cleanglobal` returns, right? hence, we should do this assertion without timeout or retries?",0,0.9931733012199402
430830840,8589,mjsax,2020-05-27T03:00:33Z,"if `option.members()` is empty, it implies that we do a `removeall()` -- hence, should we pass in `members` into the `removemembersfromconsumergroupresult` instead of `options.members()` ?",0,0.9943881630897522
430831033,8589,mjsax,2020-05-27T03:01:24Z,nit: fix formatting: [code block],0,0.9804646968841553
430832010,8589,mjsax,2020-05-27T03:05:21Z,not sure if i understand the change. also not sure if i can follow the comments. can you elaborate?,0,0.6016355156898499
430832423,8589,mjsax,2020-05-27T03:07:09Z,"as we have different semantics for an empty collection (it was ""remove nothing"" originally, and we change it to ""remove all""), i am wondering if we should do a check if `members` is empty or not and throw an exception if empty? or at least log a warning that empty implies ""remove all"" now?",0,0.9734798073768616
430833520,8589,mjsax,2020-05-27T03:12:09Z,not sure why the `removeall()` case needs to be handled differently? can you elaborate?,0,0.9778497219085693
430833928,8589,mjsax,2020-05-27T03:13:55Z,"why that? i understand that we expect that users don't know the memberid if the so a ""remove all""; however, i don't see why we need to disallow this call? can you elaborate?",0,0.9829992651939392
430834203,8589,mjsax,2020-05-27T03:15:16Z,nit: formatting [code block],0,0.9928217530250549
430835656,8589,mjsax,2020-05-27T03:21:36Z,nit: formatting: move `new newtopic(...)` to next line,0,0.9946749210357666
431247169,8589,feyman2016,2020-05-27T15:48:10Z,"this is to verify that after the `successfully force removal of active members`, the stream application re-run can send exactly the same records again to the output topics",0,0.994378387928009
431266629,8589,feyman2016,2020-05-27T16:11:11Z,"--- if option.members() is empty, it implies that we do a removeall() => yes, that is correct. --- hence, should we pass in members into the removemembersfromconsumergroupresult instead of options.members() => the members is of type `list ` and `memberidentity` contains field: `memberid` which supports the removal of dynamic members, while `options.members()` is of type: `set `, membertoremove only supports static member removal specification, in removemembersfromconsumergroupresult we treat similarly like in `removemembersfromconsumergroupoptions`, empty `members` implies `removeall`, we handle it in this way because we think in `non removeall` scenario we would only remove static members, while in `removeall` scenario we may remove both static and dynamic members.",0,0.988930881023407
431302352,8589,feyman2016,2020-05-27T17:02:53Z,"because in non `removeall` scenario, we have put the members to be deleted in the `removemembersfromconsumergroupresult#memberinfos`, while in the `removeall` scenario, we don't do so(members to be deleted are decided in the private method: `kafkaadminclient#getmembersfromgroup` of `kafkaadminclient`).",0,0.9932602047920227
431305795,8589,feyman2016,2020-05-27T17:08:53Z,"since in the `removeall` scenario, we don't save the members to be deleted in `removemembersfromconsumergroupresult`, so i think calling `memberresult` doesn't seem applicative.",0,0.9888179302215576
431312462,8589,feyman2016,2020-05-27T17:20:23Z,fixed,0,0.920660674571991
431313074,8589,feyman2016,2020-05-27T17:21:25Z,make sense. it will throw exception if empty members provided now.,0,0.9881390929222107
431313236,8589,feyman2016,2020-05-27T17:21:43Z,fixed,0,0.920660674571991
431313242,8589,feyman2016,2020-05-27T17:21:44Z,fixed,0,0.920660674571991
431322560,8589,mjsax,2020-05-27T17:37:06Z,"seems redundant as tested somewhere else. and the purpose of the test is to verify `--force` itself. this additional checks have nothing to do with `--force` imho. it seems best to keep test to a ""minimum"".",0,0.9793208837509155
431323350,8589,mjsax,2020-05-27T17:38:31Z,thanks for clarifying.,1,0.5278410911560059
431327264,8589,mjsax,2020-05-27T17:45:07Z,"well, while `memberinfo` is empty for the `removeall` case, i am still wondering if the code for `removeall` would not work for the other case, too?",0,0.9813063740730286
431329158,8589,mjsax,2020-05-27T17:48:14Z,i see. makes sense.,0,0.9646947383880615
431341731,8589,feyman2016,2020-05-27T18:04:07Z,"yes, updated",0,0.9888269901275635
431345466,8589,feyman2016,2020-05-27T18:10:45Z,"i'm not sure i understand the question, could you elaborate more?",-1,0.6366414427757263
431352788,8589,feyman2016,2020-05-27T18:23:50Z,"yeah, i totally agree with: `it seems best to keep test to a ""minimum"".` not sure if my understanding is correct, but i still think the tests for `resetter` should compare the first run and re-run results, from the test's perspective, it cannot assume that `--force` option won't do something underneath that make the re-run produce different results. but i'm ok to remove the re-run part if we do think it's redundant.",0,0.8418488502502441
431354284,8589,mjsax,2020-05-27T18:26:19Z,"can we just do for both cases? [code block] the ""issue"" with using `memberinfos` is, that for the removeall() case it's empty and we cannot use it. however, `membererrors` should have an entry for all members for both cases?",0,0.9931836724281311
431355573,8589,mjsax,2020-05-27T18:28:43Z,fair enough. let's leave it as-is.,0,0.93952876329422
431372024,8589,feyman2016,2020-05-27T18:58:10Z,"i'm afraid not because, in the non `removeall` scenario, caller specify the members(`memberinfos`) to be deleted, and according to `maybecompleteexceptionally`, the `memberinfos` is used because it might sometimes happen that certain member in `memberinfos` cannot be found in `membererrors `, that's the reason i didn't use the `removeall` logic for all cases.",-1,0.8596085906028748
431373621,8589,mjsax,2020-05-27T19:00:58Z,thanks for explaining!,1,0.8937667012214661
199933294,5322,vvcephei,2018-07-03T19:59:28Z,"i think we did it this way on purpose, so we wouldn't automatically assume that later versions would have this data. but now that i'm looking at it again, it seems like this boolean expression will become silly. also, the risk of breakage is low. if we choose not to include this stuff in later versions, it'll be pretty obvious that we have to put an upper bound on this condition. so i think this change is good.",1,0.9639611840248108
199934416,5322,vvcephei,2018-07-03T20:04:10Z,"i don't think we need to move this field. when you use it, you return immediately after assigning it, so you could just make it a local variable in that block for return. then the uninitialized field won't be in scope for everything else in this method.",0,0.9873764514923096
199935554,5322,vvcephei,2018-07-03T20:08:46Z,"maybe we can introduce a method to build this assignment and save some vertical space in this super-long method. then you could just return it, such as `return errorassignment(clientsmetadata, errorcode)`. in fact, we could ditch this variable entirely, and just return directly in all three spots we currently set it.",0,0.9840436577796936
199938505,5322,vvcephei,2018-07-03T20:20:24Z,"it seems like it would be nice also to have a constant for the ""no error"" value (0). i'm wondering if namespacing the error codes would be beneficial. minimally, we could prefix the constant like ""err_unknown_partition"". or we could use an enum: [code block] then, we could encode with `out.writeint(errcode.getcode());` and decode with `assignmentinfo.errcode = error.fromcode(in.readint());` just an idea... what do you think?",0,0.8518685102462769
199939219,5322,vvcephei,2018-07-03T20:23:17Z,i guess we'll need one of these for version 4.,0,0.9688619375228882
199940084,5322,vvcephei,2018-07-03T20:26:38Z,"it seems like this new constructor only supports the ""error assignment"" code path. can we just inline it? i admittedly didn't quite follow why we need this version check now.",0,0.9758830666542053
199952165,5322,guozhangwang,2018-07-03T21:15:58Z,"this is a meta comment: i'd suggest having a separate check at the very beginning of `assign()`, after `step zero`, that for each entry value in `topicgroups = taskmanager.builder().topicgroups()`, if each of its `topicsinfo#sourcetopics` are either in `topicsinfo#repartitionsourcetopics` or can be found in `metadata`. if the check fails we immediately falls back into the error case of 1) log an error, and 2) set dummy assignment to all the clients with error code. then in line 419 here we do not need this `do-while` loop, instead we should follow the sub-topology id ordering to assign num.partitions for repartition topics, and if it cannot be decided we will throw an runtime exception since it is not expected any more. in addition we can remove `not_available` as well.",0,0.9941301941871643
199953001,5322,guozhangwang,2018-07-03T21:19:16Z,"+1, we can add an enum inside streamspartitionassignor which can be extended in the future. also for this error case the name `unknown_partition` is a bit confusing, i'd suggest we name it `incomplete_source_topic_metadata`. and upon receiving this error code we should log an error that `some of the source topics ( + source topic lists) are not known yet during rebalance, please make sure they have been pre-created before starting the streams application.`",0,0.9896732568740845
199953116,5322,guozhangwang,2018-07-03T21:19:44Z,"as mentioned in the jira ticket, we should log an error that `some of the source topics ( + source topic lists) are not known yet during rebalance, please make sure they have been pre-created before starting the streams application.`",0,0.9935466647148132
199953424,5322,guozhangwang,2018-07-03T21:20:57Z,nit: add empty line.,0,0.992414653301239
199955030,5322,guozhangwang,2018-07-03T21:27:16Z,"this is another meta comment, not related to this line: in `copartitionedtopicsvalidator` we should also update the logic accordingly, first of the [code block] should never happen, since we would already fail before if the metadata is not complete, and the `not_available` case should not happen either (see my other comment). also note that there is a related bug fix pr for this jira long time ago about when the ensurecopartitioning should be called: [a link] with this general change: [code block] should not happen either since all topic's num.partitions should be determined by then.",0,0.9935212731361389
199955216,5322,guozhangwang,2018-07-03T21:28:03Z,"nit: add empty line between functions, ditto below.",0,0.9939445853233337
199956438,5322,guozhangwang,2018-07-03T21:33:15Z,"again this is another meta comment: the member decoding and handling leader's propagated assignment is in `onassignment`, in which the we decode `assignmentinfo` from `assignment#userdata`. in that function we should check the returned error code in `assignmentinfo`, and if it is not none we should ""gracefully"" shutdown than just throwing a runtime exception: for example, we can set a flag indicating we need to error out, and then in `onpartitionsassigned` callback we can check this flag and then decide to shutdown if necessary.",0,0.9931347370147705
199971943,5322,tedyu,2018-07-03T23:01:43Z,"for onpartitionsassigned, did you mean the method in streamthread ? the method takes collection . does this mean the flag should be added to topicpartition ?",0,0.9947394728660583
199972239,5322,tedyu,2018-07-03T23:04:07Z,"still need to figure out how to follow the sub-topology id ordering. for now, i keep the do-while loop.",0,0.978777289390564
200792196,5322,guozhangwang,2018-07-06T23:32:18Z,"the way `streamthread` class and `streamspartitionassginor` communicates today is bit weird: in order to break mutual dependency and keep the code cleaner, what we did is to pass in mutually needed modules as internal configs via the `streamsconfig`, which `streamspartitionassignor` will call `configure` on. the process works the following: 1. when streamthread creates the consumer, it adds more objects into the properties map to the consumer. 2. consumer client would create the instantiated `streamspartitionassignor`, which will then call `configure` with the passed in properties. the reason is because of the way consumers instantiate their coordinator's `assignor` object today. 2.a) for example, streamthread passed in the `taskmanager` object as `streamsconfig.internalconfig.task_manager_for_partition_assignor`. the streamspartitionassignor would then call its update functions to update the assigned tasks, which stream thread would then try to access in its own class. another example is we pass in the version prob flag as an `atomicboolean` to be set / reset between these two classes as `streamsconfig.internalconfig.version_probing_flag`. so what i meant for a `flag` is to suggest doing the similar thing like the `atomicboolean prob-flag`, in which `streamspartitionassignor` can set in its `onassignment` function. the `onpartitionassigned` function called within `streamthread` can then check this flag. for more details you can reference the current implementation pattern of the version probing flag",-1,0.9418423175811768
200792492,5322,guozhangwang,2018-07-06T23:35:44Z,"one way to break the while loop, is to rely on the [code block] note the `integer` key is indeed the sub-topology id here, and since we sort the sub-topology by their ids, starting with `1`, the first sub-topology 1 should have no internal topics as its source topic. so we can start by this key ordering, to first determine any of the repartition topic's num.partitions as their sink topics of sub-topology 1, and then based on them as for the source topics of sub-topology 2, we can determine sub-topology 2's sink repartition topic's numb.partitions, and so on.",0,0.9908372163772583
201814927,5322,guozhangwang,2018-07-11T19:36:10Z,it is simpler to just have an `encodeversionfour` which does not change anything than `encodeversionthree` but just put the different version. note that within this release cycle we may introduce other format changes as well (so eventually the `encodeversionfour` may be implemented differently anyways).,0,0.9903966188430786
201815805,5322,guozhangwang,2018-07-11T19:39:33Z,"nit: rename to `__assignment.error.code__` and `assignment_error_code`? another comment: thinking about this a bit more, maybe we can subsume the `version_probing_flag` with the `assignment_error_code`, as upon receiving the error code the member should be handling it separately on the error code, sometimes re-join the group with a down-graded encoding version, some time to shutdown, etc. with that we can generalize the handling logic.",0,0.9867357015609741
201816222,5322,guozhangwang,2018-07-11T19:41:19Z,"for trouble shooting only: maybe we can still check that `!partitions.isempty()`, and if yes log an fatal and throw runtime exception? if we had a bug that still causes `partitions.size() == 0`, then the line 83 below would silently skip assigning the maxnumpartitions update, which would be very hard to capture during debugging.",0,0.9769390225410461
201818695,5322,guozhangwang,2018-07-11T19:50:35Z,"i think it is to not call `return` after that since line 272 below will return null and hence return anyways, plus it will log the final debug entry as well. also note that in the only other caller we do [code block] i.e. we need to set `thread.setstatelistener(null);` since otherwise there may be deadlock issues. we need to do the same here.",0,0.9893745183944702
201819967,5322,guozhangwang,2018-07-11T19:55:16Z,cc wdyt?,0,0.99204421043396
201820822,5322,guozhangwang,2018-07-11T19:58:04Z,nit: comment line misaligned,-1,0.5310654640197754
201821078,5322,guozhangwang,2018-07-11T19:59:02Z,"see my other comment: it's better just duplicate the logic of handling version 3 and version 4 information for now, as we may add new info for version 4 soon which would make the handling logic different.",0,0.9924423694610596
201824357,5322,guozhangwang,2018-07-11T20:12:12Z,"same as above, let's add a fatal error and throw a runtime exception like illegalstateexception.",0,0.9885600209236145
201824624,5322,guozhangwang,2018-07-11T20:13:10Z,this seems not used.,0,0.9840855598449707
201825636,5322,guozhangwang,2018-07-11T20:16:53Z,nit: empty line.,0,0.9438178539276123
201825651,5322,guozhangwang,2018-07-11T20:16:55Z,nit: align parameters.,0,0.9941657781600952
201825785,5322,guozhangwang,2018-07-11T20:17:27Z,we can remove the code block line 82-85 above since it will be called here.,0,0.994096040725708
201826312,5322,guozhangwang,2018-07-11T20:19:19Z,"ditto, i'd suggest just duplicating the code since we may add more logic for version 4 anyways.",0,0.9916955828666687
201826496,5322,guozhangwang,2018-07-11T20:19:57Z,nit: latestsupportedversion,0,0.9914081692695618
201826570,5322,guozhangwang,2018-07-11T20:20:13Z,nit: align parameters.,0,0.9941657781600952
201826760,5322,guozhangwang,2018-07-11T20:20:55Z,ditto. let's just add an `encodeversionfour` with duplicated logic except the version.,0,0.9940925240516663
201843313,5322,tedyu,2018-07-11T21:21:47Z,"version probing is a boolean flag. assignment error code is int. if we unify these two, we need to encode version probing. btw version probing doesn't imply assignment error.",0,0.9925585985183716
201850915,5322,tedyu,2018-07-11T21:49:45Z,unfortunately no. the `this` call goes to line 100 where this is no such check.,0,0.5250486731529236
201851272,5322,tedyu,2018-07-11T21:51:16Z,addition to version 4 can be added at the end of `encodeversionfour`,0,0.9960175156593323
201851485,5322,tedyu,2018-07-11T21:52:12Z,i did that first - resulting in duplicate local variable.,0,0.983488142490387
202841909,5322,guozhangwang,2018-07-16T22:15:37Z,"yes, my intention is to use another error code value (seems you've already done it as `version_probing`) to replace the flag, and then after onassignment is called we would check the error code and if it is not `none` react accordingly, it may be simply shutdown and stop-the-world, or other actions like down-grade.",0,0.9933333992958069
202842440,5322,guozhangwang,2018-07-16T22:18:13Z,i see --- we can define latestsupportedversion before the switch not as a `final` int then?,0,0.9932684302330017
202855945,5322,guozhangwang,2018-07-16T23:29:29Z,"if we are adding this function in `kafkastreams` then we do need a kip.. but i was thinking if we can just add this in `streamthread`, which is an internal class and hence doing so does not need a kip. we can, instead, add a `kafkastreamswrapper` (it is similar to `topologywrapper` and `topologytestdriverwrapper` to allow unit test code to access their internal private fields) which can access the threads and globalthread, and then adds this function in this class to manipulate them. also note that streamthread already has a state change listener `final class streamstatelistener implements streamthread.statelistener` so our `statelistenerstub` should not completely replace its logic. instead we can extend that listener to `statelistenerstub` which does the state change tracing in additional to the necessary logic.",0,0.9892898201942444
202856322,5322,guozhangwang,2018-07-16T23:31:58Z,"this condition seems not right: we should not shutdown if the error was `version_probing`, right? i.e we should firstly check if the error was `none`, and if not, switch branch on the actual error code to handle them accordingly.",0,0.9426712393760681
202856380,5322,guozhangwang,2018-07-16T23:32:17Z,"similarly, here we would only create tasks if the error was `none`.",0,0.9919306635856628
202856437,5322,guozhangwang,2018-07-16T23:32:39Z,case 2 is missing.,0,0.9710267782211304
202856560,5322,guozhangwang,2018-07-16T23:33:24Z,ping again.,-1,0.6673350930213928
202857024,5322,guozhangwang,2018-07-16T23:36:20Z,"as we are merging the two scenarios to use the error code, we should let the leader to set the error code in the version probing case as well as setting the `receivedassignmentmetadataversion` in the assignment. and then we only need to do the logic in line 796 above, and do not need to set it in line 827 any more.",0,0.994157075881958
202857302,5322,guozhangwang,2018-07-16T23:38:05Z,we should not use a `topologyexception` here any more since `topologyexception` should be used for dsl statement parsing only. instead we could just throw an illegalstateexception since it should never be expected (i.e. if the metadata is indeed not known we should error out with the error assignment earlier and never reach this line).,0,0.993192732334137
202857594,5322,guozhangwang,2018-07-16T23:39:56Z,adding a parameter `version` for `encodeversionthree` is very confusing to other readers. i'd suggest completely duplicate the code in `encodeversionfour` and remove this parameter in `encodeversionthree`.,0,0.8802827000617981
202857927,5322,guozhangwang,2018-07-16T23:42:01Z,"thanks for adding this integration test! it looks reasonable, but we'd generally adding integration java test under `org.apache.kafka.streams.integration`, not `org.apache.kafka.streams.scala` (the latter is only for the scala api only).",1,0.9904476404190063
202858371,5322,guozhangwang,2018-07-16T23:44:49Z,"and also the title `testshouldcountclicksperregionwithmissingtopic` is confusing, it should be `shouldshutdownwithmissingtopic` right? and note this class is for `streamtotablejoinscalaintegrationtestimplicitserdes`, so not the right class to add this test. i'd suggest adding a new test class under the above mentioned package for this test case, like `assignmenterrorhandlingintegrationtest`, and this test case be `shouldautoshutdownonincompletemetadata`.",0,0.955964207649231
202864203,5322,tedyu,2018-07-17T00:23:59Z,pardon. can you explain in a bit more detail ? i am not sure how leader sets the error code for version probing if not done on line 827.,0,0.9842294454574585
202867018,5322,tedyu,2018-07-17T00:45:35Z,"i took a look at streams/src/test/java/org/apache/kafka/streams/integration/streamtablejoinintegrationtest.java where cluster is not involved. if i move the new test there, a lot of scala code for setting up the testing environment would be repeated. it seems more intuitive if the new integration test is added in this test class in terms of code reuse.",0,0.9831216931343079
202868232,5322,tedyu,2018-07-17T00:55:42Z,please confirm: threads and state fields of kafkastreams can be changed to protected. otherwise the new method in kafkastreamswrapper still cannot access them.,0,0.9949617385864258
202901382,5322,guozhangwang,2018-07-17T05:56:17Z,"yes, they can.",0,0.9872671961784363
202901958,5322,guozhangwang,2018-07-17T06:00:28Z,"currently the version probing works as the following: 1. when leader receives the subscription info encoded with a higher version that it can understand (e.g. the leader is on version 3, while one of the subscription received is encode with version 4), it will send back an empty assignment with the assignment encoded with version 3, and also `latestsupportedversion` set to 3. 2. when the member receives the assignment, it checks if `latestsupportedversion` is smaller than the version it used for encoding the sent subscription (i.e. the above logic). if it is smaller, then it means that leader cannot understand, in this case, version 4. it will then set the flag and then re-subscribe but with a down-graded encoding format of version 3. now with your pr, we can let leader to clearly communicate this error via the error code, and upon receiving the assignment, if the error code is `version_probing`, then the member can immediately know what happens, and hence can simplify the above logic. does that make sense? also cc",0,0.9899306297302246
202902176,5322,guozhangwang,2018-07-17T06:01:51Z,"i understand the code duplication, but still adding a test case that has nothing to do with `streamtotablejoinscalaintegrationtestimplicitserdes` is not recommended. i'd still suggest making a new class and duplicate the setup code a bit.",0,0.9781777858734131
202932846,5322,tedyu,2018-07-17T08:22:31Z,"in the example given above, the gap in subscription info versions between leader and the member is 1. is the expectation that when the gap is > 1, at least one round trip is reduced for version probing compared to the existing implementation ? the version probing error code currently is hard coded and not correlated with the actual gap. i wonder if the optimization can be done in another jira.",0,0.9852978587150574
203204145,5322,mjsax,2018-07-17T22:41:10Z,"iirc, the idea was to be as explicit as possible and list out the versions, in case a future version does not encode `partitionsbyhoststate` any longer. the risk of the change is small though. i am ok with it.",1,0.6700295209884644
203204413,5322,mjsax,2018-07-17T22:42:43Z,nit: code formatting and missing `final`: [code block],0,0.9938403367996216
203204472,5322,mjsax,2018-07-17T22:42:57Z,nit: add `final`,0,0.9956295490264893
203204612,5322,mjsax,2018-07-17T22:43:41Z,nit: use `{}` instead of string concatenation,0,0.9944051504135132
203204975,5322,mjsax,2018-07-17T22:45:43Z,not sure if calling `shutdown()` directly is the best way? shouldn't we just `return` and break the loop in `streamthread#runloop()` ?,0,0.9622982740402222
203205168,5322,mjsax,2018-07-17T22:46:38Z,nit: use `{}` instead of string concatenation,0,0.9944051504135132
203205249,5322,mjsax,2018-07-17T22:47:08Z,nit: add `final`,0,0.9956295490264893
203205508,5322,mjsax,2018-07-17T22:48:23Z,why remove `final` ?,0,0.9886484742164612
203205842,5322,mjsax,2018-07-17T22:49:59Z,"`processversionthreeassignment` -> `processversionfourassignment` if both are identical, it's ok to call `processversionthreeassignment()` from within `processversionfourassignment()` imho, but adding a `processversionfourassignment()` seems to be cleaner to me.",0,0.9814420342445374
203206140,5322,mjsax,2018-07-17T22:51:46Z,`final` ?,0,0.9915042519569397
203206482,5322,mjsax,2018-07-17T22:53:30Z,do we need this new constructor? can the existing one not just be extended with `errorcode`?,0,0.9939244389533997
203206896,5322,mjsax,2018-07-17T22:55:50Z,nit: add `final`,0,0.9956295490264893
203206912,5322,mjsax,2018-07-17T22:55:55Z,nit: add `final`,0,0.9956295490264893
203206951,5322,mjsax,2018-07-17T22:56:07Z,nit: indention,0,0.9862814545631409
203207194,5322,mjsax,2018-07-17T22:57:30Z,why do you remove this test?,0,0.9937477111816406
203207828,5322,guozhangwang,2018-07-17T23:01:17Z,"hmm.. i'm not sure if this is the right fix, but maybe upgrading the test when we bump up version is also out side the scope of this pr itself. i'll let to take a look and decide how can we fix forward the upgrade-test.",0,0.8402400612831116
203208753,5322,mjsax,2018-07-17T23:06:40Z,"if we bump the version, we need to update this to 5 and 4 as already done. we should also make this more generic and test upgrades from 3 -> 4, 3 -> 5 and 4 -> 5. the current code does only go from latest version to future version. however, generalizing the test should be out of scope of this pr and just changing the expected numbers should be fine for this pr.",0,0.9912400841712952
203209970,5322,tedyu,2018-07-17T23:13:46Z,the type of the version probing flag has changed from boolean to integer. there is another subtest for checking the error code.,0,0.9956287145614624
203210372,5322,tedyu,2018-07-17T23:16:16Z,this was suggested by guozhang and i tend to agree with calling shutdown(),0,0.9867152571678162
203216673,5322,mjsax,2018-07-17T23:55:19Z,"i understand that. thus, this test should be updated to `shouldthrowkafkaexceptionifversionprobingflagconfigisnotatomicinteger` -- it tests the data type, ie, the cast operation.",0,0.9924972057342529
203216813,5322,mjsax,2018-07-17T23:56:01Z,what is the reasoning behind this?,0,0.9665223360061646
203248963,5322,guozhangwang,2018-07-18T04:35:43Z,"copying my response from the email thread: [code block] currently i cannot think of a race condition that calling `shutdown` in the callback would introduce than calling shutdown in the main loop, but i'm not 100% sure, so i insisted on triggering a system test.",0,0.9902740120887756
203542445,5322,mjsax,2018-07-18T21:54:19Z,"this should never happen, right? thus, i am wondering if we should throw an `illegalstateexception` instead?",0,0.7721700072288513
203542534,5322,mjsax,2018-07-18T21:54:38Z,nit: add `{ }` to then-block,0,0.9935762286186218
203542781,5322,mjsax,2018-07-18T21:55:50Z,seems this slipped in the last update.,0,0.9838204383850098
203543587,5322,mjsax,2018-07-18T21:58:57Z,"ack. we might still want to add a `return` to make clear it's an early exit. of course, the `if` below evaluate to `false` anyway, however, it makes the code more readable imho.",0,0.7913134694099426
203544388,5322,mjsax,2018-07-18T22:02:10Z,nit: we usually omit `get` prefix for all getter method. please update to `code()` to align with common naming conventions.,0,0.9938880801200867
203544506,5322,mjsax,2018-07-18T22:02:35Z,comment can be omitted,0,0.9825142025947571
203547299,5322,mjsax,2018-07-18T22:15:20Z,"for future version this might work. however, if we upgrade from 2.0 to 2.1 with version bump from 3 -> 4, the old leader is on version 3 and cannot encode the version probing via the error flag. as we are stuck with older version 3 metadata, i am not sure if we gain a lot if we change the logic, as we still need the current code anyway.",0,0.9645432829856873
203547399,5322,mjsax,2018-07-18T22:15:50Z,nit: fix indention,0,0.574457049369812
203548013,5322,mjsax,2018-07-18T22:18:58Z,why do we move this up here? `topics` is only used when an exception is thrown (or did i miss anything)?,0,0.9884573817253113
203548143,5322,mjsax,2018-07-18T22:19:35Z,did this slip?,0,0.9252215623855591
203548277,5322,mjsax,2018-07-18T22:20:13Z,any comments? i would like to keep the number of constructors small if possible.,0,0.9873290061950684
203548421,5322,mjsax,2018-07-18T22:20:52Z,nit: rename to `errorcode` ? we try to avoid abbriviations,0,0.9912583231925964
203548476,5322,mjsax,2018-07-18T22:21:06Z,nit: rename `errorcode()`,0,0.9953722357749939
203548586,5322,mjsax,2018-07-18T22:21:40Z,nit: add empty line,0,0.9917676448822021
203548969,5322,mjsax,2018-07-18T22:23:18Z,add `getversionfourbytelength()` ? or rename method to `getversionthreeandfourbytelength()` ?,0,0.9956541061401367
203549210,5322,mjsax,2018-07-18T22:24:16Z,nit: fix indention,0,0.574457049369812
203549314,5322,mjsax,2018-07-18T22:24:47Z,nit: add empty line,0,0.9917676448822021
203549359,5322,mjsax,2018-07-18T22:25:01Z,seems this slipped,0,0.9222815632820129
203549395,5322,mjsax,2018-07-18T22:25:11Z,seems this slipped,0,0.9222815632820129
203549533,5322,mjsax,2018-07-18T22:25:49Z,seems this slipped,0,0.9222815632820129
203549904,5322,mjsax,2018-07-18T22:27:14Z,should we change the test to expect an exception instead of removing it?,0,0.9910039901733398
203550235,5322,mjsax,2018-07-18T22:28:20Z,"as above: should we check that an exception is thrown? (we had ""infinite loop"" bugs in the past -- those tests seems to be valuable)",0,0.9887181520462036
203550652,5322,mjsax,2018-07-18T22:29:45Z,seems this can be removed?,0,0.9944655299186707
203550712,5322,mjsax,2018-07-18T22:29:59Z,"seems, this can be removed?",0,0.9942631125450134
203555179,5322,mjsax,2018-07-18T22:49:12Z,why is this change required? it seems we forgot to update `assignmentinfo#equals()` and `assignmentinfo#hashcode()`...,0,0.993526816368103
203555598,5322,mjsax,2018-07-18T22:51:27Z,how does this test relate to the change?,0,0.9924355149269104
203555659,5322,mjsax,2018-07-18T22:51:52Z,as above? why do we change this test?,0,0.991999626159668
203556910,5322,tedyu,2018-07-18T22:58:08Z,"right, this code shouldn't be reached.",0,0.988003134727478
203557121,5322,tedyu,2018-07-18T22:59:13Z,there is no then-block - i guess you mean the if-block.,0,0.9878881573677063
203559036,5322,tedyu,2018-07-18T23:09:57Z,i want to mention versionprobingflag just in case some developer who knew the flag comes wondering what happened to the flag :-),0,0.9906502962112427
203559379,5322,mjsax,2018-07-18T23:11:30Z,"terminology is fun... it's and if-then-else statement -- there is no `then` keyword, but still and then-block -- interesting that you call it if-block :)",1,0.9935452938079834
203559593,5322,mjsax,2018-07-18T23:12:51Z,`git blame` is their friend :) -- that's why there is a commit history. allows us to keep the code base clean :),1,0.9959263801574707
203563364,5322,tedyu,2018-07-18T23:34:18Z,right.,0,0.9789980053901672
203564178,5322,tedyu,2018-07-18T23:39:04Z,streamtotablejoinscalaintegrationtestbase is created for reusing cluster setup code between existing test and new integration test.,0,0.9932997226715088
203564273,5322,tedyu,2018-07-18T23:39:37Z,streamtotablejoinscalaintegrationtestimplicitserdes is changed to preserve non-cluster setup test code.,0,0.9940286874771118
203564445,5322,tedyu,2018-07-18T23:40:44Z,i see - yeah i call it if block.,0,0.9923128485679626
203807596,5322,mjsax,2018-07-19T17:21:41Z,"as mentioned in a previous comment, we need to update `hashcode()` and `equals()`.",0,0.9956367611885071
203829239,5322,mjsax,2018-07-19T18:31:54Z,"i understand your other test changes now. however, i am wondering why we add this test to the scala module in the first place? kafka streams is written in java, and we should write all tests in java, too. the scala module is just a thin language wrapper on top, and integration tests in the scala module should only test the scala/java integration, but not core functionality. this test belongs to `stream/src/test/java/org/apache/kafka/stream/integration` thus, my argument is not really about java vs scala, but putting test into the scala wrapper module scatters our test code across two modules and we should not do this.",0,0.9694045186042786
1137856849,13391,jolshan,2023-03-15T23:01:21Z,bug here -- we don't want to clear non-inflight nodes.,0,0.5716421008110046
1137901882,13391,jolshan,2023-03-16T00:00:27Z,i have a fix i will push with the rest of the tests,0,0.981270432472229
1142707455,13391,artemlivshits,2023-03-20T21:44:34Z,"looks like this could be called from multiple threads, do we need to add synchronization?",0,0.9925711750984192
1142722842,13391,artemlivshits,2023-03-20T22:07:29Z,"would it be possible to have a retry (say first request timed out, and then we send another one) and have more than one request?",0,0.9898647665977478
1142729789,13391,artemlivshits,2023-03-20T22:17:58Z,we could use getorelseupdate.,0,0.9954749941825867
1142747856,13391,artemlivshits,2023-03-20T22:48:21Z,"if the request is already in flight, looks like we wouldn't be able to detect and reject a stale request here. is it needed for correctness? if yes, we need to fix that, if not, i'd propose to remove this logic and just properly handle stale epoch when it gets to transaction coordinator.",0,0.9911738038063049
1142753293,13391,artemlivshits,2023-03-20T22:58:00Z,inflightnodes seem to be accessed only by the inter-broker send thread so synchronization is not actually needed.,0,0.9934127926826477
1142758001,13391,artemlivshits,2023-03-20T23:06:56Z,"shouldn't it get cleared automatically once it gets out of scope? if there is a tricky consideration, let's add a comment.",0,0.9926856756210327
1142762452,13391,artemlivshits,2023-03-20T23:15:37Z,"is this client going to be used only for addpartitionstotxnmanager or some other inter-broker communication (in the future) as well? if it the former, we should make name more specific.",0,0.9930155277252197
1142786061,13391,jolshan,2023-03-21T00:08:15Z,"i thought about that, but i was concerned about blocking on a single produce request too long. i though maybe the producer's retry mechanism would be enough to handle this.",0,0.617405116558075
1142787086,13391,jolshan,2023-03-21T00:10:10Z,i think it's ok to have new data when a request is inflight. the issue is that i have an invariant here that we can only have one queued item for a given txn id at a time. this is due to how the information is stored in the map. the only time we can receive two requests from the same txn id is when the producer restarts and the epoch is bumped. that is why i have this logic here.,0,0.9419768452644348
1142787356,13391,jolshan,2023-03-21T00:10:48Z,i guess i was considering more than one send thread :grinning_face_with_sweat: i guess we don't have that now.,1,0.7711186408996582
1142788144,13391,jolshan,2023-03-21T00:12:38Z,we are reusing this for each transactional id and it remains in scope at this time.,0,0.9946720004081726
1142788313,13391,jolshan,2023-03-21T00:13:00Z,we can make it more specific.,0,0.9904161691665649
1144090231,13391,junrao,2023-03-21T23:38:45Z,does the todo still need to be addressed?,0,0.9913950562477112
1144092204,13391,junrao,2023-03-21T23:41:57Z,could we add a new line after?,0,0.9934123158454895
1144106075,13391,junrao,2023-03-22T00:13:25Z,could this be private?,0,0.9816126227378845
1145103445,13391,junrao,2023-03-22T16:26:10Z,"i am wondering why we need to do this in a request thread. for example, transactionmarkerrequestcompletionhandler already appends to the log in a separate thread.",0,0.795555055141449
1145118797,13391,junrao,2023-03-22T16:36:44Z,we already have a transactionmarkerchannelmanager for txn coordinator to send requests to brokers. could we reuse that for sending requests from brokers to txn coordinators? we probably don't want too many separate threads for exchanging requests among brokers.,0,0.9909204244613647
1145376271,13391,jolshan,2023-03-22T20:30:39Z,we are sending from the partition leader to the txn coordinator. can we still use that same thread? i think the usage is different right?,0,0.9928300976753235
1145376651,13391,jolshan,2023-03-22T20:31:03Z,thought this should be done. perhaps he can explain better than me.,0,0.984916627407074
1145453181,13391,junrao,2023-03-22T22:01:40Z,"that's true. however, if you look at transactionmarkerchannelmanager, the main api is `addmarkersforbroker`. so at that level, it's just sending some requests to another broker. in addpartitionstotxnmanager, its main api is `addtxndata`. again, it's just sending some requests to another broker. instead of creating more and more of those specialized broker-to-broker communication channels, it may be better to consolidate them into a single general framework.",0,0.9848373532295227
1145463265,13391,jolshan,2023-03-22T22:15:52Z,"i thought about this, but the trouble is how each request is built slightly differs. some of them pass the node they are sending to when sending adding the request (like this one) and some do the calculation right before (ie, controller channel manager) i can take a look at the transaction channel marker channel manager and see how it handles it. but i think the other benefit for this class is keeping all the add partitions logic together. perhaps there is a way to consolidate this, but also use the same thread/channel?",0,0.9486104846000671
1145487679,13391,junrao,2023-03-22T22:55:39Z,"yes, i was wondering if there is a way to reuse the thread and the channel for broker to broker communication for all low volume requests.",0,0.9928981065750122
1145533272,13391,jolshan,2023-03-22T23:54:53Z,i can look into this. do we also want to handle the callback on that same thread still?,0,0.9933837056159973
1145545834,13391,junrao,2023-03-23T00:21:10Z,"yes, that's what i was wondering. transactionmarkerchannelmanager writes the final commit to the log in the callback of sending the marker to the broker. i am wondering if we could just do the same here.",0,0.987500786781311
1145549423,13391,jolshan,2023-03-23T00:30:05Z,"i think is the best to answer this. he was the one who said we should do this and although i vaguely remember the explanation, he will do a better job explaining.",1,0.6715337634086609
1146789680,13391,YiDing-Duke,2023-03-23T20:24:15Z,"if 1st request timeout, the second one cannot hit this stage unless 1st one is done due to connection muted?",0,0.9921133518218994
1146821982,13391,jolshan,2023-03-23T20:46:16Z,"yi is correct. i also think if we hit timeout, it is the epoch bump case i mentioned before.",0,0.9832144975662231
1146944915,13391,junrao,2023-03-23T22:36:19Z,"chatted with artem offline. his reasoning is for performance. it's better to do any io related operations in the request thread pool to prevent blocking the callback thread. this could be a bit better. if we do this, maybe we should also change transactionmarkerrequestcompletionhandler so that it writes the complete marker in the request thread instead of the callback thread. that could be done in a followup jira.",0,0.9837030172348022
1146951880,13391,jolshan,2023-03-23T22:49:09Z,(answer is above),0,0.9946753978729248
1147152053,13391,artemlivshits,2023-03-24T06:01:39Z,"this should be .offer -- we don't need to block if the request queue is full, and it's ok if we don't have a wakeup request in a full queue -- the queue would would contain a request (due to the fact that it's full) to wake up the poll.",0,0.9939502477645874
1147156380,13391,artemlivshits,2023-03-24T06:10:23Z,"we could probably handle wakeuprequest in this function, so that the wakeup mechanism is encapsulated in requestchannel (i.e. check if we got a wakeup request from the requestqueue and poll the callbackqueue again in that case).",0,0.9929400682449341
1147689005,13391,junrao,2023-03-24T14:50:15Z,could we just reuse the actionqueue instead of introducing a new queue? actionqueue is drained by the request thread whenever it finishes processing the current event.,0,0.9911869168281555
1147787658,13391,jolshan,2023-03-24T16:05:36Z,will we still have the behavior of putting the callback at the front of the queue? it would go to the end of the action queue right?,0,0.9931018352508545
1147789029,13391,jolshan,2023-03-24T16:06:54Z,offer was throwing spotbugs errors since i didn't check the response. i can do that but it will be a little uglier.,0,0.5912725329399109
1147794328,13391,junrao,2023-03-24T16:11:55Z,"it would go to the end of the action queue. however, not every request adds entries to the action queue. so, the action queue is typically smaller than the request queue. also, request threads prioritize the action queue over the request queue.",0,0.9889667630195618
1147804661,13391,jolshan,2023-03-24T16:22:05Z,so it is the case that all the action entries are removed before the next request? for some reason i thought it just cleared one for each request. i can take a look.,0,0.9891378283500671
1147813111,13391,junrao,2023-03-24T16:28:59Z,it clears all entries it sees at the beginning. [code block],0,0.995871365070343
1147857120,13391,jolshan,2023-03-24T17:09:05Z,thanks!,1,0.8631753921508789
1147991721,13391,artemlivshits,2023-03-24T19:43:30Z,"if a request hits a timeout the new request will come in the new connection, so the fact the old connection is muted wouldn't prevent the new request to come. the timeout processing on the client is just a timer, once it expires, it'll kill old connection, create a new one and re-send the batch. we won't bump the epoch on retry -- it'll override duplicate checking logic, so we'd have duplicates if we did, so the exact same batch (same epoch, same sequence) will come again on the new connection.",0,0.991523027420044
1147999817,13391,artemlivshits,2023-03-24T19:53:33Z,i'd expect the synchronization would be added as part of making the class properly multithreaded.,0,0.984550416469574
1148002291,13391,artemlivshits,2023-03-24T19:56:51Z,"should we move it to the proper scope then? (the indentation is hard to follow in the pr view, i assumed it's already in the proper scope)",0,0.9792546629905701
1148025113,13391,artemlivshits,2023-03-24T20:29:51Z,"oh, i see, we have only one request for a trasnactional.id, so we need to complete previous one in order to replace. see my other comments about retries.",0,0.9893285632133484
1148044044,13391,artemlivshits,2023-03-24T20:52:43Z,"we could try to re-purpose the action queue for this, but it currently has different semantics -- the error processing is different, for example (it's executed in the finally clause). what we want here is the semantics that we'd get if we just blocked the thread while we're contacting tc, but without blocking the thread. same error handling, same context, same metrics, etc. the basic implementation of the desired semantics is just a queue, but we could also preserve request context (see todos in kafkarequesthandler.scala) so that this functionality that would work for any requests that need to do non-blocking async calls.",0,0.9824976325035095
1148057123,13391,artemlivshits,2023-03-24T21:08:17Z,"i guess, if the request queue is full then it means that the request threads are all overloaded, so if we block the inter-broker channel thread it probably wouldn't matter much as the broker is already in pain. but on the other hand, it's kind of strange to not implement technically more correct behavior because we've got some spurious warnings.",-1,0.9459430575370789
1148060963,13391,artemlivshits,2023-03-24T21:14:41Z,"we should measure the time it took to process the request to tc and report it (either as ""remote time"" that we already have or as a new metric), otherwise it'll just roll into ""local time"" (time spent by this broker to handle the request).",0,0.9924178123474121
1148081688,13391,jolshan,2023-03-24T21:39:48Z,yeah. i planned to look at the request timing stuff next. thanks for the reminder :),1,0.9939618706703186
1148082243,13391,jolshan,2023-03-24T21:40:36Z,the build will fail with the warnings. but i can add the extra code so the build passes.,0,0.9870339632034302
1148084290,13391,jolshan,2023-03-24T21:42:44Z,"ah. i guess i was thinking of the client restarting. so you are saying in the case where the request times out before we send the request here, we can hit the error?",0,0.9675206542015076
1149586417,13391,jolshan,2023-03-27T17:34:15Z,i think we want to update in both cases -- and we want to distinguish the two.,0,0.9796637296676636
1149838206,13391,artemlivshits,2023-03-27T22:12:27Z,"yes, that's my understanding based on my reading of the code -- once a connection to a broker has at least one timed-out in-flight request, it's disconnected and all in-flight requests get a timeout error (which can be then retried by the producer on a new connection). [a link] it's also not guaranteed that the request that comes later here is the retry (i.e. the assumption that we can just fail the previous request because it must've timed out anyway is not true). should be unlikely with default settings, so we can probably just return some retriable error and document the caveat. alternatively (i would actually prefer that), we could just support multiple requests per transactional.id which would eliminate the need to handle this case here altogether: just add all new requests to the pending ""batch"" and let the tc handle different cases.",0,0.9882780909538269
1149847782,13391,jolshan,2023-03-27T22:28:23Z,i don't think we can add multiple to the batch because of how the callbacks are currently implemented. we would need to know which response goes to which callback. i thought about this a while and one callback is the the simplest way to do it.,0,0.977033257484436
1149873099,13391,artemlivshits,2023-03-27T23:14:12Z,"ok, looks like the protocol is not designed to support multiple requests for one transactional.id. for same-epoch case, though, we'd get the same answer because we'd be asking the same question, so we could just keep multiple callbacks per trasnactional.id and call them all with the response, this way we don't have to guess which message is first and which is the retry.",0,0.9770837426185608
1149903116,13391,jolshan,2023-03-28T00:17:49Z,hmm -- would it be better to just replace the old one? i don't think we'd expect two responses. and we definitely don't want to write twice.,0,0.9405336380004883
1151026334,13391,artemlivshits,2023-03-28T18:44:14Z,we don't know which one is the old one -- the one that's there or the one that just arrived. we won't write twice -- at some point we'll check for duplicates and one of the requests would succeed and the other would get 'duplicate' error (which is effectively success). we had this situation anyway without verifying the transactions: 2 requests will just continue processing and eventually one would succeed and another would get a duplicate. we also have this situation when one request is already in-flight to tc.,0,0.9807673692703247
1151046857,13391,artemlivshits,2023-03-28T19:06:16Z,"(could have syntax errors as i didn't compile it) ``` val nodeandtransactiondata = nodestotransactions.getorelseupdate(node, new transactiondataandcallbacks( new addpartitionstotxntransactioncollection(1), mutable.map.empty)) val currenttransactiondata = nodeandtransactiondata.transactiondata.find(transactiondata.transactionalid))",0,0.9879443645477295
1151269827,13391,YiDing-Duke,2023-03-29T00:07:47Z,"i assume the duplicate and out of order check happens in producer id cache and before this stage. if that's true, in general, the next batches with the same epoch won't hit this stage and should be fenced with out of order retry error to client. there can be a special case where this is the very first batch write from new epoch so the producer id cache cannot block any batches into this stage.",0,0.9925582408905029
1152479391,13391,artemlivshits,2023-03-29T20:59:25Z,"duplicate check + store has to be atomic (cannot really discard a new request as a duplicate until the previous request succeeds, not can let it go through until the previous request fails), so it needs to happen under a lock. the purpose of this stage is to not let a request go into log if the transaction is not there, so it got to be either between the check and the store or before the check and the store, hopefully, it's the latter, because otherwise we'd have a long lock around inter-broker rpc. btw, there should be no out-of-order errors or fenced errors during normal retry processing -- the first try should go through and others would be bounced with ""duplicate"" error which is effectively a success. this way all tries would be effectively successful and the intermittent error would be transparently handled by kafka without bubbling up to the application.",0,0.985552966594696
1152485888,13391,jolshan,2023-03-29T21:07:05Z,"it does not happen before this stage. but artem is right. if we do process the callback twice, i suppose the second one will see it as a duplicate and return fine. i think my concern is that we return a timeout response + the callback response, but i guess this sort of thing can happen normally? i guess my question is whether we still want to return both callbacks with the response to addpartitionstotxn, or if it is just sufficient to ignore the first one.",0,0.9686406254768372
1152509597,13391,jolshan,2023-03-29T21:37:29Z,will do in [a link],0,0.9954219460487366
1152543409,13391,jolshan,2023-03-29T22:21:23Z,actually -- i misread the original comment -- i thought this was about callback time. i'm wondering if we want to report this in a different way after all. it would be a bit confusing to report this as remote time since this is technically still on the broker. i'm also not sure how we would parse the separate metric. is the idea that we would somehow get the time to send and receive the response and subtract it from the local time? i don't even see the local time metric getting incremented at this level. one idea is to take the request time and subtract the time to do the callback. i'd have to see if this is even possible though.,0,0.8090768456459045
1152603124,13391,artemlivshits,2023-03-30T00:03:28Z,"actually, this is a higher level discussion that we should probably have on the kip thread, as it affects public metric semantics. i think it would be useful to have a separate metric, because it'll help with diagnosing extra latency in transactions that we're introducing with this rpc call. especially if we provide a feature flag to turn off this check for perf reasons -- we'd need to have some data to help the admin make a decision.",0,0.9831085801124573
1152615315,13391,artemlivshits,2023-03-30T00:26:37Z,synchronization?,0,0.9934605360031128
1152617531,13391,artemlivshits,2023-03-30T00:32:15Z,"if we'll have a thread pool of network threads, we'd need to synchronize this too. so we probably need to add a comment here.",0,0.9928379654884338
1152624055,13391,artemlivshits,2023-03-30T00:48:02Z,"the kip also mentions a race condition where the transaction may be aborted just after we've verified it, but before we got the reply, it doesn't seem like this pr addresses that, do we plan to do it in a different pr?",0,0.9927817583084106
1153539479,13391,jolshan,2023-03-30T16:56:29Z,thanks for the reminder -- i need to remember the details here.,1,0.8552297949790955
1153540952,13391,jolshan,2023-03-30T16:57:51Z,i don't recall having a pool of network threads. this would just be the one send thread for now i think.,0,0.9830817580223083
1154744670,13391,artemlivshits,2023-03-31T17:49:25Z,"currently we only have one thread and it might be the case forever, but from this code the threading model is not obvious and it would be useful to have a comment that we don't need synchronization for inflightnodes because inflightnodes is only accessed from methods that are called on the sender's thread.",0,0.9921031594276428
1157599255,13391,jolshan,2023-04-04T18:07:21Z,"i've changed the internal details a bit so i no longer have an identifier that the first check succeeded. we append to the log on callback. originally, i was going to update the psm entry to contain the first offset and then we would remove the entry on the end marker. however, now we don't write the offset until the first append. (we can check for the next ones, but not the first append). the later changes with the epochs will make this not necessary since we bump the epoch on the marker write. i'm trying to think how we can handle this in the old clients case on the first append -- if there are any indicators we can check.",0,0.9524781107902527
1157781323,13391,jolshan,2023-04-04T21:20:40Z,"one option here is to check the timestamp of the last time the entry was updated if there is no ""last txn"" information. on the first append, the timestamp should not change on the entry. (i believe it only changes on data appends and txn markers)",0,0.9937556982040405
1158766750,13391,jolshan,2023-04-05T16:40:42Z,i'm going to keep what i have for now -- we can revisit the action queue if we want later.,0,0.9769311547279358
1160343683,13391,artemlivshits,2023-04-07T00:02:30Z,"if we don't want to put too many things in one change, we could implement the race condition checks in a separate change -- even though we didn't fully fix the problem we didn't regress (in fact improved quite a bit). on the other hand, fixing localtime metric should be done in this change, because it worked before this change so if we don't fix it, it would be a regression. another approach (if it makes things simpler in any way) could be to split out the framework to run callbacks on request threads and add metrics there, then rebase this change on top of framework, so this change focuses on the transaction-specific stuff.",0,0.9843144416809082
1160355023,13391,artemlivshits,2023-04-07T00:38:32Z,"update comment to say ""requestchannel and request"".",0,0.9955861568450928
1160356274,13391,artemlivshits,2023-04-07T00:42:51Z,we should set it to null once we're done with the request (in a finally clause). this would avoid issues of a request living longer than needed because it's referenced in a thread local of some request thread.,0,0.9946234226226807
1160357216,13391,artemlivshits,2023-04-07T00:46:09Z,"this change uses only one callback, but as a generic framework, a request could run multiple rpcs during its processing, so we should do `currentrequest.set(request.originalrequest` (and clean it afterwards).",0,0.9939637780189514
1160357426,13391,artemlivshits,2023-04-07T00:46:50Z,maybe use `callback` instead of `request`.,0,0.9914758205413818
1160363167,13391,artemlivshits,2023-04-07T01:04:07Z,"i think the metric could be updated when the response is sent in request.fun(), so it may actually see some value in request.originalrequest.callbackrequestdequetimenanos and no value in callbackrequestcompletetimenanos, in which case the processing time could be negative. also, if multiple callbacks are used during the request processing, we'd lose callback processing time for all but last callback (for this we could add a comment, to add this logic if we have multiple callbacks to handle).",0,0.9896671772003174
1160803600,13391,jolshan,2023-04-07T16:06:04Z,"are you saying network client sends the response + updates the metrics before we reach line 115, so we should put the complete message as part of the response? i'm not sure the best way to put that in the callback. i'll have to think about it.",0,0.9714192152023315
1160807017,13391,jolshan,2023-04-07T16:12:00Z,i wasn't sure if we would have a new request here though. we could be handling this callback after the original request returned right?,0,0.9778226017951965
1160817791,13391,jolshan,2023-04-07T16:30:14Z,we've opted to return a retriable error for the case where the second response is returned first.,0,0.9932331442832947
1160819448,13391,jolshan,2023-04-07T16:32:51Z,let's do the check before append in a followup -- here is the jira -- [a link],0,0.995868444442749
1160830029,13391,jolshan,2023-04-07T16:51:33Z,ah i think i figured it out.,0,0.8632594347000122
1160831069,13391,jolshan,2023-04-07T16:53:25Z,ah i misunderstood your comment. i guess i'm just not sure what setting current request here does for us. why would we use currentrequest instead of original request? unless we wanted to schedule another callback :grinning_face_with_sweat:,1,0.533219039440155
1160849589,13391,artemlivshits,2023-04-07T17:27:55Z,"we might in the future. from the implementation perspective it may seem like we have ""the request"" and ""the callback"", but conceptually we should think in terms of a request that may run a few asynchronous operations and then continue processing, in which case we can have multiple callbacks in the context of the same request. so logically it's like this: -- request starts processing 1. do some processing on a broker request thread 2. do async operation (rpc, or maybe even async storage access in some distant future) 3. continue processing on a broker request thread. 4. do some async operation 5. continue processing on a broker request thread 6. do some async operation 7. finish processing on a broker request thread -- request is done in this case the steps 1, 3, 5, 7 would be accounted as local time and logically we just keep processing the same request, only instead of blocking the thread in steps 2, 4, 6, we wait without blocking the thread.",0,0.9719589948654175
1160872423,13391,jolshan,2023-04-07T18:10:20Z,"i think the issue is that the way that i implemented the metric is that we only have callback start and end. if we wanted to store results of multiple callbacks, we would need to change this. i'm tempted to tackle this sort of thing in a followup change to avoid overcomplicating this one.",0,0.8441202044487
1160875392,13391,artemlivshits,2023-04-07T18:15:07Z,"i think it's still good to keep the request.originalrequest.callbackrequestcompletetimenanos = some(time.nanoseconds()) here as well. looking at the code, request could end in many different ways, some could happen before callback completion, some may happen after callback completion. there are some error cases, like connection disconnects that may not go through the success path.",0,0.9508057236671448
1160879089,13391,artemlivshits,2023-04-07T18:22:06Z,"instead of doing this, i would put the request.callbackrequestcompletetimenanos = some(time.nanoseconds()) back after the callback.fun() call and just update the place where we update metrics to take the current time if callbackrequestcompletetimenanos is empty. then we don't need chase all the code paths that we could go through before updating the metrics.",0,0.9926079511642456
1160883532,13391,artemlivshits,2023-04-07T18:30:54Z,"1. isn't it backwards? the complete time should be larger than deque time. 2. if we do the following logic, then it should work regardless of whether we arrive here before setting callbackrequestcompletetimenanos or after setting callbackrequestcompletetimenanos. [code block]`",0,0.9911509156227112
1160892559,13391,artemlivshits,2023-04-07T18:49:23Z,"yeah, if we need to make larger change to complete the framework, then we should definitely do in a follow-up change, but i think in this case all we need to do is this: [code block] and then we've got ourselves a fully functional framework for supporting arbitrary number of async calls in a request processing :-).",1,0.9707109928131104
1160895598,13391,jolshan,2023-04-07T18:55:52Z,ooops -- good call.,0,0.4978986978530884
1160896272,13391,jolshan,2023-04-07T18:57:08Z,"hmm -- so we should only update if callback is also defined. i'm also not sure about setting it twice, so we should only set after fun() if it is not already set.",0,0.9680384397506714
1160975587,13391,artemlivshits,2023-04-07T21:27:29Z,need to clear as well in the finally clause.,0,0.9909630417823792
1160976550,13391,artemlivshits,2023-04-07T21:30:02Z,"not sure if the 'if' clause is required, prevcallbackstimenanos would be 0 if there was no prev callback.",0,0.9489815831184387
1160980316,13391,jolshan,2023-04-07T21:40:29Z,"i just wanted to avoid doing all this extra code if not needed. in my head, it made more sense to someone reading it.",0,0.9507927894592285
1161050689,13391,artemlivshits,2023-04-08T02:40:25Z,"we don't need to pass the current request, this could be completely encapsulated within wrap. in fact, having a request argument here makes it look like that we could pass some arbitrary request, while here we need exactly the one that is currently processed on the thread.",0,0.9899802803993225
1161050986,13391,artemlivshits,2023-04-08T02:43:44Z,or currentrequest == null,0,0.9926977753639221
1161051019,13391,artemlivshits,2023-04-08T02:44:17Z,ok,0,0.9233372807502747
1161051461,13391,artemlivshits,2023-04-08T02:48:44Z,do we have a test that actually tests that we'd get a failure if we try to produce without adding the partition to transaction first?,0,0.9919877052307129
1161058187,13391,artemlivshits,2023-04-08T04:07:10Z,producerstatemanager.activeproducers.get(producerid).exists(entry => entry.currenttxnfirstoffset.ispresent),0,0.9938923120498657
1161058423,13391,artemlivshits,2023-04-08T04:09:33Z,leaderlogiflocal.exists(leaderlog => leaderlog.hasongoingtransaction(producerid)),0,0.993625283241272
1161846085,13391,jolshan,2023-04-10T15:59:45Z,"my original concern was that if we just used the thread local, we would access it when the inner method is called. i guess i can just save a local variable when wrap is called and pass that value into the inner method.",0,0.9851269125938416
1161847053,13391,jolshan,2023-04-10T16:00:34Z,"depends what you mean here. if you mean a unit test -- yes. if you mean a integration test, no because the correct behavior is built into the producer.",0,0.987745463848114
1161854813,13391,jolshan,2023-04-10T16:06:53Z,actually hmm -- i suppose this test is not present if you mean the exact path of returning the error and not producing to the log. i really did think i added such a test to replica manger test. i can try to add this path.,0,0.9868924021720886
1161874495,13391,jolshan,2023-04-10T16:31:12Z,"this is a java map, so that doesn't work. i can convert to scala, but not sure that is much better.",0,0.748904824256897
1161896585,13391,jolshan,2023-04-10T16:58:16Z,we do have tests from the previous pr that return errors if the partition is not added to the txn. see [a link],0,0.9949878454208374
1161909242,13391,junrao,2023-04-10T17:14:34Z,our long term goal is to replace the scala code with java. could we write this new class and the corresponding test in java?,0,0.9935851693153381
1161915489,13391,junrao,2023-04-10T17:22:40Z,"the above comment still says ""is still under developement"". is the latest version indeed stable? or should we change the comment accordingly?",0,0.9929516911506653
1161918638,13391,junrao,2023-04-10T17:26:46Z,the params of this method is getting a bit large. could we add the javadoc explaining each of the param?,0,0.9908944368362427
1161932999,13391,junrao,2023-04-10T17:45:39Z,coordinatornotavailable error is not listed in produceresponse. should we add it there and verify that it's handled as expected by existing clients?,0,0.9947769641876221
1161943463,13391,junrao,2023-04-10T17:58:16Z,does this need to be volatile?,0,0.9817500114440918
1161946467,13391,jolshan,2023-04-10T18:01:40Z,added a line to the replicamanager test to see that we return early on the error in the callback.,0,0.9948102235794067
1161971721,13391,junrao,2023-04-10T18:33:41Z,do we have a use case where the same callback needs to be handled multiple times by the request thread? how do we prevent that the callback is added an infinite number of time to the callback queue?,0,0.9911729693412781
1161978192,13391,junrao,2023-04-10T18:41:52Z,"so, `originalrequest.callbackrequestcompletetimenanos.isempty` is expected to be true? should we add a warning log if it's false?",0,0.993177056312561
1161979607,13391,junrao,2023-04-10T18:43:46Z,"since we don't expect to see wakeuprequest here, should we add a warning log?",0,0.9914230704307556
1161982117,13391,junrao,2023-04-10T18:46:51Z,this seems to be a more general mechanism than actionqueue. could we move all existing actionqueue usage to callback queue and get rid of actionqueue? this could be done in a separate pr.,0,0.9925232529640198
1161984615,13391,junrao,2023-04-10T18:50:06Z,"incomplete sentence ""check if we have already"".",-1,0.6790072917938232
1161987786,13391,junrao,2023-04-10T18:54:20Z,network_exception is not listed in produceresponse. should we add it there and verify that it's handled as expected by existing clients?,0,0.9946891069412231
1161996676,13391,junrao,2023-04-10T19:05:43Z,addpartitionstotxncollection seems unused?,0,0.9931073784828186
1162000865,13391,junrao,2023-04-10T19:11:11Z,"since this can be skipped, should this be warn instead of error?",0,0.9907893538475037
1162001708,13391,junrao,2023-04-10T19:12:20Z,extra space before returned,0,0.9925479292869568
1162003823,13391,junrao,2023-04-10T19:15:09Z,"hmm, not quite sure that i follow. do you mean that we return invalid_record to be compatible for old clients?",0,0.8192530274391174
1162043968,13391,jolshan,2023-04-10T20:06:24Z,i will update the comment.,0,0.9916371703147888
1162044614,13391,jolshan,2023-04-10T20:07:21Z,it is retriable -- currently if the error is retriable we just retry. it seems like most retriable errors are not enumerated specifically.,0,0.9929525256156921
1162045206,13391,jolshan,2023-04-10T20:08:02Z,^ ditto comment about retriable errors.,0,0.9745113253593445
1162045551,13391,jolshan,2023-04-10T20:08:23Z,"we can make it volatile, but this is only really used in tests.",0,0.9904654026031494
1162046736,13391,jolshan,2023-04-10T20:09:36Z,artem requested this. see comment here. [a link] there is currently not a way to prevent infinite callbacks.,0,0.9856961965560913
1162047387,13391,jolshan,2023-04-10T20:10:12Z,it is not true if we returned a response. we also update the value there.,0,0.9916990995407104
1162047588,13391,jolshan,2023-04-10T20:10:25Z,we can add a warning log.,0,0.9938786625862122
1162049144,13391,jolshan,2023-04-10T20:12:25Z,"yes. sorry for the confusion. in the kip we mention invalid_txn_state for the new clients, but old clients use invalid_record for compatibility. i will update the comment.",-1,0.9895977973937988
1162109668,13391,jolshan,2023-04-10T21:38:30Z,let's do in a separate pr.,0,0.9913396239280701
1163283951,13391,junrao,2023-04-11T20:21:19Z,"hmm, not sure that i follow. in the false case, it seems that we just don't set `callbackrequestcompletetimenanos`? this is a bit weird since the callback is completed.",-1,0.8283951878547668
1163284515,13391,junrao,2023-04-11T20:21:57Z,could we file a jira to track this in a followup?,0,0.9939419627189636
1163287233,13391,junrao,2023-04-11T20:23:51Z,could this be private? ditto for a few other helper methods in this file.,0,0.9919953346252441
1163292661,13391,junrao,2023-04-11T20:28:22Z,"""the error map should remain empty."" what does this mean?",0,0.9915632009506226
1163294534,13391,junrao,2023-04-11T20:29:59Z,get rid of the new line since the following validation is related to this action?,0,0.994856595993042
1163323491,13391,junrao,2023-04-11T20:55:26Z,"basesequence is redefined as val. so, this is unused.",0,0.994712769985199
1163335886,13391,junrao,2023-04-11T21:08:11Z,do we need this? it doesn't seem the request handler thread is involved in the test.,0,0.9900349974632263
1163418845,13391,jolshan,2023-04-11T23:22:00Z,"it means that we didn't complete the request. if we returned an error response, we would populate the map. but if it just replaced the old data, we don't send a response.",0,0.9857672452926636
1163421308,13391,jolshan,2023-04-11T23:26:54Z,"there are two cases according to artem -- one where we send a response via network client and one where we don't (and we have more callbacks) in case a, we set in the network client and that is the end of handling of the request. this is also when the metric is updated. in case b, we don't set it there so we must do it here. i have the check to match the same sort of protocol we see in kafka apis where we check if the value is -1. maybe it's fine to set it twice in case a as we won't update the metrics again, but i did it for consistency.",0,0.9896296858787537
1163421979,13391,jolshan,2023-04-11T23:28:30Z,oops. i see we changed this logic. i will fix the comment.,-1,0.8993442058563232
1163429337,13391,jolshan,2023-04-11T23:44:47Z,"we still call the wrap method which checks if we are on the request handler thread. since we are not it will fail via illegal state exception. we we set the bypass, it just runs the callback.",0,0.9914163947105408
1163446164,13391,junrao,2023-04-12T00:23:43Z,"i am still a bit confused on this. case a - only 1 callback. in this case, callbackrequestcompletetimenanos is never set and is expected to be empty. case b - multiple callbacks. in this case, after the first callback, callbackrequestdequeuetimenanos is set. so, when the 2nd callback is processed, we set callbackrequestcompletetimenanos to empty before executing the callback. when we get here, callbackrequestcompletetimenanos is expected to be empty. so, it seems that in both case a and b, we expect callbackrequestcompletetimenanos to be empty?",-1,0.8735389709472656
1163659843,13391,artemlivshits,2023-04-12T06:02:22Z,"basically, we should search for `apilocalcompletetimenanos` and update the callbackrequestcompletetimenanos in similar places. my understanding is that we can send the reply during request / callback and it may complete (concurrently) before we end the request / callback or after we end request / callback. in which case we want the end time to be the earliest of the two. usually, the way it's done is the start time is set at the start of the request / callback processing and the end time is set after, but if the end time is not set then the metric is reported, then we just report the current time.",0,0.9881877303123474
1163676408,13391,artemlivshits,2023-04-12T06:26:09Z,"right now, this framework just accounts for a single logical request that does a few non-blocking calls and continues serially after each call. we could probably add a check that prohibits adding a second .wrap during request / callback execution.",0,0.9834061861038208
1164335669,13391,jolshan,2023-04-12T15:55:15Z,"in case a, we set it in the network client -- it will not be empty. in case b, it is empty and we set it. then, when executing the next callback, we take this time and subtract it from the start of the new callback. this gives us total time of all.",0,0.9919753670692444
1164392731,13391,junrao,2023-04-12T16:45:31Z,"thanks for the explanation. i understand it now. callbackrequestcompletetimenanos can be non-empty if the response is sent before the callback completes. currently, we update the metric when the sending of the response completes. so, a more accurate place to set callbackrequestcompletetimenanos in requestchannel is when the response send completes. an alternative approach is to delay the updating of the request time metrics until the callback completes. this simplifies the setting of callbackrequestcompletetimenanos since it only needs to be done in kafkarequesthandler and is more accurate since we don't need to cut off callbackrequestcompletetimenanos by response send complete time. both of these could be addressed in a followup jira.",1,0.983942449092865
1164399008,13391,jolshan,2023-04-12T16:51:49Z,"i'm not sure i follow the first part since right now, we need to account for all the callback local times. unless we change to a cumulative callback total time where we periodically add to it, we will need to update either on the send or when the callback completes (if we don't send yet) i'm also not sure about waiting until the callback completes because that is after we send via the network client and that is no longer considered ""local time""",0,0.8399393558502197
1164424805,13391,junrao,2023-04-12T17:17:36Z,"for simplicity, let's just assume there is only one callback for now. currently, the code sets callbackrequestcompletetimenanos when the response is being sent. if the callback has been started, but not completed at that point, the measurement of the callback portion time is not accurate. if we delay the cut off of callbackrequestcompletetimenanos at the time when request time metric is updated (which currently is when the response send completes), we allow for more accurate measurement of the callback portion time. for your second question, yes, it's a bit weird to report the callback time as 'local' after the response is being sent. however, 'local' really reflects the amount of time a request handler thread is tied up for processing a request. from that perspective, it could also make sense. if we cut off the callback portion of the time by response send time, we could leave a portion of the request thread time unaccounted for?",-1,0.5919098258018494
1164431328,13391,jolshan,2023-04-12T17:24:15Z,i asked to just assume one callback earlier but i was told we should just implement this now :grinning_face_with_sweat: (thread here [a link] i'm not sure i follow which scenario is inaccurate?,1,0.6486807465553284
1164445859,13391,junrao,2023-04-12T17:33:50Z,"in the more general case, the callback is not guaranteed to be completed when the response is sent, right? in that case, the code in requestchannel cuts off callbackrequestcompletetimenanos at response send time. when the callback completes, kafkarequesthandler doesn't set callbackrequestcompletetimenanos since it's not empty. this means the measurement of callback time is not accurate, right?",0,0.989575982093811
1164460056,13391,jolshan,2023-04-12T17:48:36Z,"given that we have only one case right now i guess i'm not sure we have a general case -- but in the current case, we complete the callback by sending the response. i guess i saw this protocol working as follows: a) we have one callback and send the response in which local time is correct b) we have multiple callbacks and the first few do not send the response. we updated after calling the callback. then the final one sends the response (case a) we always must return in the final callback because we only use this callback if we've already returned from handle. we must return via the callback in my understanding.",0,0.9771117568016052
1164476174,13391,junrao,2023-04-12T18:04:26Z,"yes, in the current usage where the last callback sends the response as the last thing, it doesn't make much difference. i was thinking that the callbacks in actionqueue are executed after the response is generated. if want to replace actionqueue with the callback queue, we need to handle the more general case.",0,0.9897063970565796
1164479606,13391,jolshan,2023-04-12T18:08:12Z,"yeah -- i guess the previous decisions were made without considering the action queue. i'm wondering if it is better to leave as is and change via a followup or simplify back to ""base case"" (ie, case a which is currently what we do)",0,0.9193086624145508
1164488222,13391,junrao,2023-04-12T18:16:22Z,"yes, we can leave the pr as it is. could we file a jira to revisit action queue? we can make any needed changes there.",0,0.9942139983177185
1164633122,13391,junrao,2023-04-12T20:41:15Z,it's probably used for to log the destination broker on which the request fails. ditto in other logging.,0,0.9923005104064941
1164638992,13391,jolshan,2023-04-12T20:48:13Z,i will switch to the destination node.,0,0.9891126751899719
61458168,1251,gwenshap,2016-04-28T16:23:35Z,nit: oracle's javadoc guide specifically says: [a link],0,0.993389368057251
61458366,1251,gwenshap,2016-04-28T16:25:03Z,"""iff"" means ""if and only if"" and is correct in this context. i don't think it was a typo. if you find ""iff"" unclear, feel free to replace with ""if and only if""",0,0.8631765842437744
61458701,1251,gwenshap,2016-04-28T16:27:09Z,these are new public apis right? ( - correct me if i'm wrong).,0,0.9611352682113647
61459284,1251,gwenshap,2016-04-28T16:30:38Z,"it is a bit hard to tell from the diff, but did you add a new argument as the first in the list? is there a reason? we usually add new arguments at the end.",0,0.9815079569816589
61459399,1251,gwenshap,2016-04-28T16:31:16Z,the nulls are getting a bit hard to read. do we want constants for no_apis and no_metadata?,0,0.6854521632194519
61459449,1251,ijuma,2016-04-28T16:31:33Z,looks like only the consumer and producer packages are considered api: [a link],0,0.992900013923645
61460110,1251,gwenshap,2016-04-28T16:36:22Z,thanks :),1,0.9231597781181335
61460735,1251,gwenshap,2016-04-28T16:40:12Z,"""trace"" maybe? this seems incredibly chatty even for debug.",-1,0.7076594829559326
68186750,1251,ijuma,2016-06-23T07:24:20Z,why was this removed?,0,0.990842342376709
68190038,1251,ijuma,2016-06-23T07:52:43Z,"we probably want a `kafkaconsumer` and `kafkaproducer` test that expects a newer than supported broker. sounds like it needs to be a system test. it probably needs a request to be bumped up too before it works. hmm, actually, we should have system tests for broker versions that don't support `apiversionsrequest` (e.g. 0.9.0.1 and 0.8.2.1). in addition, it would be great if we could detect if something is missing from this list at unit/integration test time. any ideas on how to do that?",0,0.5939950942993164
68190553,1251,ijuma,2016-06-23T07:56:40Z,"i think it would be better for `ready` to be the state where one sends requests. this means that if the api version requests are not needed, we can automatically transition from `connected` to `ready`. thoughts? cc .",0,0.9795820713043213
71025620,1251,SinghAsDev,2016-07-15T19:06:20Z,"it should not be, fixed in next version.",0,0.9847452044487
71026255,1251,SinghAsDev,2016-07-15T19:11:00Z,"added system test against trunk and older broker versions. the interesting tests like testing against unsupported broker versions, will probably have to wait till we have such versions. the list of apis used by client is similar to the practice of specifying used errors for a request. as you said, it will be nice to have this checked dynamically at test time, however nothing comes to my mind with which we can do that. will be happy to accommodate any suggestion on this.",1,0.6373335123062134
71026376,1251,SinghAsDev,2016-07-15T19:11:49Z,"i do not have a strong bias on this, will be happy to make the change if you really think it is a must.",1,0.8036444783210754
74093108,1251,dpkp,2016-08-09T16:25:49Z,"apologies for the late review, but i feel like it would be much clearer if the state transition were: `disconnected -> connecting -> checking_api_versions -> connected` it strikes me that the main reason you have the ready state is to manage `cansendmore`, but i can't actually find where `cansendmore` is called in the api version request flow. networkclient `dosend` skips the `cansendmore` check, i believe, so do we really need that extra layer of complexity? and so would it be possible to check for `this.requiredapiversions == null` directly here and set the next connectionstate to connected if null, or to checking_api_versions if not? then in the api version response handler the state could be updated to connected.",0,0.5476285219192505
74093303,1251,dpkp,2016-08-09T16:26:46Z,why not use a future + callback handler? the inline check in `handlecompletedreceives` is a bit confusing / buried,0,0.7283766269683838
91202952,1251,cmccabe,2016-12-07T00:18:58Z,"hmm. ""java.util.collection"" could be something unsorted like a list. how about making this a map from apikey to apiversion so that we can compare it with the server response more efficiently?",0,0.974553644657135
91203250,1251,cmccabe,2016-12-07T00:21:40Z,"hmm. i was initially confused by what the ""apis"" parameter did. can we call this ""requiredapiversions""? same comment for the other constructor overloads.",0,0.9040896892547607
91203437,1251,cmccabe,2016-12-07T00:23:19Z,"can we have ""if"" statements instead of the ternary operator?",0,0.9926232099533081
92007667,1251,hachikuji,2016-12-12T18:25:33Z,nit: feels like overkill to have constants for `null` which are only used in the constructors.,-1,0.9462197422981262
92007933,1251,hachikuji,2016-12-12T18:26:55Z,might be helpful to add a brief comment here explaining the behavior if `requiredapiversions` is null.,0,0.9932723641395569
92008244,1251,hachikuji,2016-12-12T18:28:25Z,+1. this is a little hard to read.,-1,0.8453013896942139
92009315,1251,hachikuji,2016-12-12T18:33:31Z,"might be helpful to add a short comment explaining the new states and transitions. for example, if the version check fails, do we go to `disconnected`?",0,0.9923434853553772
92036463,1251,hachikuji,2016-12-12T20:48:34Z,"nit: this could be `else if`, right? also, i think we could do an `instanceof` check on the response body, and pass the cast result to `handleapiversionsresponse` instead of going through the `struct` instance.",0,0.9901198148727417
92036719,1251,hachikuji,2016-12-12T20:49:55Z,nit: `else if`.,0,0.9889736771583557
92038835,1251,hachikuji,2016-12-12T21:00:39Z,"i'm in favor of this suggestion, but maybe overloading `connected` would be misleading. perhaps the states could be `disconnected -> connecting -> checking_api_versions -> ready` instead?",0,0.8250970244407654
92042824,1251,hachikuji,2016-12-12T21:21:12Z,"does this need to be concurrent? `networkclient` itself is not thread-safe. also, i wonder if queue is the right data structure. would a `set` make more sense? are there any cases we'd add the same node more than once? now that i'm thinking about it... do we need this collection at all? it seems like it is identical to the set of nodes which are in the `connected` state. maybe we could just get that directly from `clusterconnectionstates`?",0,0.9519177675247192
92043237,1251,hachikuji,2016-12-12T21:23:30Z,nit: this change seems unneeded,0,0.9705615639686584
92043284,1251,hachikuji,2016-12-12T21:23:50Z,nit: could be static.,0,0.9764342308044434
92043619,1251,hachikuji,2016-12-12T21:25:26Z,nit: why not let this be `list `? it's usually preferable to preserve type information as long as possible. same in `kafkaproducer` and the test cases.,0,0.9862885475158691
92044055,1251,hachikuji,2016-12-12T21:27:45Z,this looks like same code as in `kafkaconsumer`. perhaps we should move it to `utils`?,0,0.9926364421844482
92047117,1251,hachikuji,2016-12-12T21:43:40Z,"nit: seems we could use a singleton, maybe `apiversionsrequest.instance` or something like that?",0,0.9871730804443359
92048027,1251,hachikuji,2016-12-12T21:48:13Z,should we try to use `cansendrequest`?,0,0.9939327836036682
92049126,1251,hachikuji,2016-12-12T21:53:42Z,might this be simpler if we just have two methods: `cansendrequest(string node)` and `cansendapiversionrequest(string node)`?,0,0.9919863939285278
92049847,1251,hachikuji,2016-12-12T21:57:36Z,"these tests are a little obscure. i wonder if it would be a little clearer to 1) use only one api instead of a list, and 2) reference the versions directly using `protoutils`?",0,0.824199914932251
92050099,1251,hachikuji,2016-12-12T21:58:38Z,kudos for adding the system test!,1,0.9755075573921204
92050177,1251,hachikuji,2016-12-12T21:59:03Z,nit: why remove the newline?,0,0.9569373726844788
92050279,1251,hachikuji,2016-12-12T21:59:39Z,nit: why remove the newline?,0,0.9569373726844788
92050477,1251,hachikuji,2016-12-12T22:00:40Z,"also, maybe we could call this `consumer_apis` and get rid of the comment, which doesn't add much value.",0,0.9880033731460571
92074335,1251,ijuma,2016-12-13T00:36:53Z,i think the ternary operator is probably ok if the connection state checks were extracted into a variable.,0,0.9742291569709778
92074732,1251,ijuma,2016-12-13T00:40:05Z,`else if` is not required here since the `if` always throws right? or do you just mean as a style thing it's clearer?,0,0.9871664643287659
92079250,1251,ijuma,2016-12-13T01:18:29Z,"yeah, that would be similar to `api_versions_response` in `apiversionsresponse`.",0,0.9922245740890503
92154634,1251,ijuma,2016-12-13T12:01:02Z,it seems a bit inconsistent that `connected` clears the internal list while other methods like `disconnected` don't. maybe we should call `clear()` from `poll`?,0,0.8981797099113464
92154840,1251,ijuma,2016-12-13T12:02:18Z,"we should add `latest_0_10_1` and `latest_0_10_0` too. since they support `apiversionsrequest`, i take it that the behaviour is more graceful?",0,0.994300127029419
92155097,1251,ijuma,2016-12-13T12:04:08Z,nit: maybe there should be no default for `should_fail` since we always pass a value.,0,0.9572719931602478
92155443,1251,ijuma,2016-12-13T12:06:18Z,seems like they can be final.,0,0.9841169714927673
92155793,1251,ijuma,2016-12-13T12:09:05Z,nit: missing space before `:`.,0,0.6336374282836914
92156071,1251,ijuma,2016-12-13T12:11:06Z,it would be good to include more information about the failure in the message.,0,0.9896629452705383
92156138,1251,ijuma,2016-12-13T12:11:28Z,do we want to validate that it failed for the right reason?,0,0.9737058281898499
92156687,1251,ijuma,2016-12-13T12:15:26Z,why are we duplicating all of this logic here? can we not reuse the existing serialization logic?,0,0.9829513430595398
92243074,1251,SinghAsDev,2016-12-13T19:11:41Z,sounds good.,1,0.857205867767334
92243960,1251,SinghAsDev,2016-12-13T19:16:03Z,"i don't think it has to be sorted, though having a consistent order will make it easier to read in logs. also, i failed to see why changing this to a map is going to be more efficient. the checking is happening in `handleapiversionsresponse` and response already has a map of keys to supported versions.",0,0.9709765315055847
92244101,1251,SinghAsDev,2016-12-13T19:16:50Z,"after taking out `connected` state, this is no longer an issue.",0,0.9929797053337097
92259621,1251,SinghAsDev,2016-12-13T20:31:40Z,"we would need some kind of ds to keep track of api versions request that need to be sent during poll. if we were to use `clusterconnectionstates` to do this, we will either have to add a state between `checkingapiversions` and `ready` to indicate that api versions check is already in progress for a connection, or we will have to move trigger for sending api versions from poll to handleconnections. i am more in favor of having it the way it is right now, and have the api version requests be sent during polls. however, i do agree that the ds for this can be a set, and i will make that change.",0,0.965617299079895
92265829,1251,SinghAsDev,2016-12-13T21:05:22Z,"`cansendrequest` also checks if connection state is `ready`, which won't be true here.",0,0.9938701391220093
92266604,1251,SinghAsDev,2016-12-13T21:09:25Z,good point.,1,0.9140551090240479
92270976,1251,SinghAsDev,2016-12-13T21:32:08Z,"if the version check fails, connection is closed. no reason to go in `disconnected` state, as their is no way broker would start supporting the version without having to terminate the connection.",0,0.9797825217247009
92279721,1251,SinghAsDev,2016-12-13T22:16:58Z,"not sure if those changes help, but making those changes anyway. let me know if you meant something else.",0,0.9406763911247253
92285072,1251,SinghAsDev,2016-12-13T22:49:22Z,"not sure, if you wanted me to add checks for exception messages, as it makes these tests a little brittle. i anyway, went ahead and added those checks. let me know if you think they don't add much.",0,0.9327440857887268
92286131,1251,SinghAsDev,2016-12-13T22:55:28Z,ahh.. left over from some debugging.,0,0.9102121591567993
92294978,1251,hachikuji,2016-12-13T23:56:13Z,"yeah, it's personal preference, so feel free to ignore. the `else if` makes the relation between the two cases stand out a bit more.",0,0.9393923282623291
92295136,1251,hachikuji,2016-12-13T23:57:39Z,i think this check and the one above are redundant. maybe we can remove the check for the api key?,0,0.983068585395813
92296138,1251,hachikuji,2016-12-14T00:05:20Z,would be nice to have `node` somewhere in this name. maybe `nodesrequestingapiversions`?,0,0.960843563079834
92296968,1251,hachikuji,2016-12-14T00:13:05Z,or maybe `nodesneedingapiversionsfetch`? might be closer to the usage.,0,0.9925330877304077
92297033,1251,hachikuji,2016-12-14T00:13:38Z,"if the node is in `apiversionsrequests`, then wouldn't the state already be `checking_api_versions`?",0,0.9943141341209412
92299342,1251,hachikuji,2016-12-14T00:33:07Z,nit: the check seems unnecessary.,0,0.5504573583602905
92303136,1251,hachikuji,2016-12-14T01:02:50Z,"i'm wondering if we can simplify this a little bit. once the connection has completed, it seems that both `selector.ischannelready()` and `inflightrequests.cansendmore()` should both be true. so instead of going through this intermediate collection before sending the `apiversionrequest`, perhaps we can just immediately send the request when we transition to `checking_api_versions`? i think that would let us get rid of the `apiversionsrequests` set. does that seem right?",0,0.9624193906784058
92303744,1251,SinghAsDev,2016-12-14T01:08:18Z,"yea that is one option that i was pointing to earlier. it has been so long that i do not remember why i chose this over sending, but one reason that comes to my mind is that handling all sends receives from poll seems like a good idea. however, i am open to change that.",0,0.8922304511070251
92305344,1251,hachikuji,2016-12-14T01:22:43Z,"never mind. i talked with jun and ismael about this and ""connected"" currently does not imply ""ready.""",0,0.9596297144889832
92316606,1251,hachikuji,2016-12-14T03:24:29Z,nit: alignment,0,0.9908159971237183
92316756,1251,hachikuji,2016-12-14T03:27:07Z,nit: doesn't seem like this method adds much.,0,0.8974775671958923
92317190,1251,hachikuji,2016-12-14T03:33:42Z,i don't think we need this one.,0,0.9459941387176514
92318309,1251,hachikuji,2016-12-14T03:47:33Z,"not sure you saw my previous comment, but these two constants seem unneeded.",0,0.9384372234344482
92320200,1251,SinghAsDev,2016-12-14T04:18:28Z,"this was explicitly asked in one of the previous review comments, having bunch of nulls in a method call, makes it hard to read. if this is not a big concern, maybe we can leave it in as it makes code more readable? lmk.",0,0.9805260300636292
92433034,1251,hachikuji,2016-12-14T16:34:34Z,"sure, that's fair.",0,0.9760578274726868
92452791,1251,hachikuji,2016-12-14T18:07:07Z,seems this is unused. do we need it?,0,0.9896065592765808
92456223,1251,hachikuji,2016-12-14T18:23:38Z,"the second argument here is used to indicate when the request is a metadata request initiated by the `networkclient`. this lets us send metadata requests externally without having the `networkclient` intercept them (i think we were the ones who added this feature initially :winking_face: ). i think it would probably make sense to do the same for the `apiversionsrequest`. it seems a little safer and i can imagine using this api from the admin client in the future, for example.",0,0.5869518518447876
92496174,1251,SinghAsDev,2016-12-14T21:45:07Z,"i initially thought to do that, but it is very likely that someone would have raised that as not required in review. however, now that is is raised, happy to add it. if there are no more reviews, i will shortly update the pr here.",1,0.9892948269844055
92498039,1251,hachikuji,2016-12-14T21:53:51Z,could we use a single `isinternalrequest` flag combined with an `instanceof` check to distinguish the two cases?,0,0.9927042722702026
92501345,1251,SinghAsDev,2016-12-14T22:10:43Z,"one can argue against it, as now the same check has to be done at multiple places. if number of such internal requests grow beyond two, then probably it won't make sense to keep a flag for each of them. at that point it would be better to add a method like `boolean isinternalrequestoftype(apikeys apikey)`. makes sense?",0,0.9755066633224487
92503655,1251,hachikuji,2016-12-14T22:23:26Z,"we should probably have the `instanceof` checks anyway prior to casting the response object, so this just removes the need for an extra field. is there any downside?",0,0.9912142753601074
92505757,1251,SinghAsDev,2016-12-14T22:35:00Z,"not sure i am following you here. below is one of the places where `isinternalmetadatarequest` flag is used. [code block] are you suggesting that i change it to something like. [code block] if so, then we are talking about changing `metadataupdater` interface. do we really want to do that? do you see any other type of request being initiated by network client any time soon?",0,0.865705668926239
92510635,1251,hachikuji,2016-12-14T23:03:03Z,"yeah, that's exactly what i was thinking. it seems like a nice improvement to let the `metadataupdater` interface accept an instance of `metadataresponse` directly so that it doesn't have to deal with casting itself.",0,0.5016444325447083
92513323,1251,hachikuji,2016-12-14T23:20:59Z,nit: seems we no longer have much use for `handlemetadataresponse`. maybe we just move its body here?,0,0.9672819972038269
92515767,1251,ijuma,2016-12-14T23:39:14Z,"nit: `oldest` and `latest` are not symmetric. also, it's a bit odd that we use different names for the field names (basically `current` and `minimum`). finally, why do we use `int` instead of `apikeys`?",-1,0.6053206324577332
92515994,1251,ijuma,2016-12-14T23:40:55Z,"if you look at `producerrecord`, we use a slightly different convention for `tostring` (i know we are not consistent everywhere, but i'm trying to improve that).",0,0.9739335775375366
92516990,1251,ijuma,2016-12-14T23:48:30Z,`collections.singletonlist` can be used to make this more concise.,0,0.9934899806976318
92517073,1251,ijuma,2016-12-14T23:49:08Z,"i don't understand this name, why do we call it `used_api_key`?",0,0.9058600068092346
92517275,1251,ijuma,2016-12-14T23:50:41Z,i don't understand why we add +2 to `short.max_value` and then cast to `short` causing it to overflow?,0,0.9317101836204529
92517541,1251,ijuma,2016-12-14T23:52:41Z,don't we have some code that we can reuse for this? why are we manually serialising `apiversionresponse`?,0,0.9879406690597534
92517616,1251,ijuma,2016-12-14T23:53:18Z,we should have a timeout here so that we don't loop forever in case of a bug.,0,0.9823452830314636
92517670,1251,ijuma,2016-12-14T23:53:47Z,"are some of these fields supposed to be `final` (existing code, i know)?",0,0.9880742430686951
92517741,1251,ijuma,2016-12-14T23:54:17Z,nit: maybe this should be `createnetworkclient` and similar for the other method.,0,0.9870226979255676
92517776,1251,ijuma,2016-12-14T23:54:36Z,nit: should probably just be `expectedapiversions`.,0,0.7484639883041382
92517927,1251,ijuma,2016-12-14T23:55:49Z,we should have some shared code for serialising the response and response header instead of duplicating it in multiple places.,0,0.9913734793663025
92517976,1251,ijuma,2016-12-14T23:56:12Z,did you see this comment?,0,0.9929074048995972
92518023,1251,ijuma,2016-12-14T23:56:37Z,nit: extra empty line.,0,0.9813311696052551
92518167,1251,ijuma,2016-12-14T23:57:35Z,"hmm, i thought we'd have `latest_0_10_1` and `latest_0_10_0` instead of `latest_0_10` (which doesn't make sense because we have multiple feature releases in the `0_10` line.",0,0.9359097480773926
92518242,1251,ijuma,2016-12-14T23:58:15Z,should we not check that we get a better error for the case where `apiversions` is available (i.e. `0.10.0.x`)?,0,0.9920607805252075
92528123,1251,hachikuji,2016-12-15T01:32:33Z,"yeah, maybe just remove the constant and use `apikeys.metadata` directly?",0,0.9894012808799744
92866560,1251,ijuma,2016-12-16T19:01:30Z,"on second thought, i'm ok to leave this as it is and we can leave this improvement as future work.",0,0.8507950901985168
92897920,1251,SinghAsDev,2016-12-16T22:35:34Z,"yea, this will require a bit of refactoring. current changes are inline with the way `protoutils` is written. leaving it as it is for now.",0,0.9867416024208069
92897966,1251,SinghAsDev,2016-12-16T22:35:51Z,good point!,1,0.9930058121681213
37427316,151,ijuma,2015-08-19T15:21:47Z,what is the right way to handle this? the random suffix is there because an exception will be thrown in `registermetric` if a broker is removed and then added again. the `selector` doesn't allow the caller to control that in its current form.,0,0.9892939329147339
37427419,151,ijuma,2015-08-19T15:22:27Z,is it ok to use the same config as `socketserver` for this?,0,0.9955564141273499
37427623,151,ijuma,2015-08-19T15:23:51Z,"`config.controllersockettimeoutms` was previously being used for `blockingchannel.readtimeoutms`, is it correct to use it here in this way?",0,0.9941661357879639
37427682,151,ijuma,2015-08-19T15:24:19Z,is it ok to reuse the `socketserver` settings here?,0,0.9955796599388123
37427714,151,ijuma,2015-08-19T15:24:36Z,"`config.controllersockettimeoutms` was previously being used for `blockingchannel.readtimeoutms`, is it correct to use it here in this way?",0,0.9941661357879639
37427818,151,ijuma,2015-08-19T15:25:18Z,is it ok to use the `socketserver` config parameters here?,0,0.9957185387611389
37470292,151,gwenshap,2015-08-19T21:25:21Z,i don't think you need maxbytes here... this was for limiting the message size from clients. we have networkreceive.unlimited if we want to leave this open.,0,0.9896757006645203
37470393,151,gwenshap,2015-08-19T21:26:05Z,can to expend on why would the broker get removed and re-added from here?,0,0.9889894127845764
37472395,151,ijuma,2015-08-19T21:44:00Z,"`controllerchannelmanager.removebroker` is called in `brokerchangelistener.handlechildchange`, the actual line is: `deadbrokerids.foreach(controllercontext.controllerchannelmanager.removebroker(_))`",0,0.9944140911102295
37474431,151,gwenshap,2015-08-19T22:02:49Z,"so, it looks like you have a selector for each controller->broker connection? i'd expect one selector for the controller and open and close connections for brokers. this way the selector string will include the broker id for the controller, but not for the brokers themselves. and we'll probably want to maintain metricsperconnection so we can track those separately. does that make sense?",0,0.980245053768158
37476236,151,gwenshap,2015-08-19T22:23:50Z,"i think these utils are very generic, but also make the code a bit harder to read. it looks like the ""find"" we are waiting for is basically always a reply from a specific broker? in this case, maybe make the generic method private and provide a more specific wrapper?",0,0.9555913209915161
37476467,151,ijuma,2015-08-19T22:26:34Z,"yes, i understand that one selector per controller would be better. i was trying to avoid a complete redesign of `controllerchannelmanager` though. it currently uses one `requestsendthread` per broker with a `blockingqueue` and `blockingchannel`. `controllerchannelmanager` has a public `sendrequest` method that adds to the relevant queue. `requestsendthread` takes from this queue. my understanding is that a given selector should be used from just one thread and hence the resulting code. please let me know if this is not correct. in an ideal world, we would redesign things to use one selector per controller, but it seemed riskier and i thought it would be better to do that in a separate change after the next release (since our main goal at this point is just to use `selector` for the tls/ssl support). what are your thoughts?",0,0.9195539355278015
37476513,151,gwenshap,2015-08-19T22:27:11Z,"yeah, i think it does exactly the same thing we used to do: block until we get a reply or get to the timeout time. iirc, the networkreceive code has some deprecated methods specifically to support the blocking channel timeouts. maybe this can be cleaned up now.",0,0.9814930558204651
37476689,151,gwenshap,2015-08-19T22:29:20Z,blockingchannel used to get the buffer sizes as parameters... shouldn't we keep the same behavior?,0,0.9922075867652893
37476724,151,ijuma,2015-08-19T22:29:48Z,"`blockingchannel` is still used by the old consumer, so i am not sure we can remove anything just yet. i'll double-check though.",0,0.9862804412841797
37476769,151,gwenshap,2015-08-19T22:30:30Z,"i think it is, since it keeps the same behavior.",0,0.9744797348976135
37476900,151,ijuma,2015-08-19T22:32:17Z,"we were passing `blockingchannel.usedefaultbuffersize` (which is `-1`) everywhere and the code in `blockingchannel` does: [code block] so, we were basically not setting anything.",0,0.9880741238594055
37477305,151,gwenshap,2015-08-19T22:36:56Z,"lets see if i got it. we have a communication thread per broker, and a selector per thread. if a broker dies, we close the thread and the selector. if the broker comes back, we can't create a new selector with the same name due to metrics. since the number of possible brokers is limited, can we just store the selector for each broker in a map and reuse / reconnect if the dead broker is revived? this should keep the metrics sane too.",0,0.9713084101676941
37477570,151,gwenshap,2015-08-19T22:39:45Z,"lol, we are cute :) i'd leave it at -1 then.",1,0.9969052672386169
37477835,151,gwenshap,2015-08-19T22:42:36Z,"i'd also document that these are for creating blocking behavior on top of our async network classes, and to use only where blocking makes sense...",0,0.9942476749420166
37478175,151,ijuma,2015-08-19T22:47:28Z,"i can try to add some wrappers and see how it looks. to help me understand, what makes it hard to read? is it because of the long line with many parameters? this could be simplified quite a bit by using implicit value classes and passing the time implicitly as well. example follows: now: [code block] after the proposed change: [code block]",0,0.9844198822975159
37478292,151,ijuma,2015-08-19T22:49:29Z,"yes, that seems doable. i'll try that tomorrow and update the pr.",0,0.9605751037597656
37478390,151,ijuma,2015-08-19T22:50:46Z,good point about documenting the blocking aspect. will do.,1,0.9654232263565063
37478724,151,ijuma,2015-08-19T22:54:31Z,we can't pass -1 to `selector.connect` though as it will fail when it calls `socket.sendbuffersize`. maybe you are suggesting that i update `selector.connect` to behave as `blockingchannel` did when a negative value is passed in (basically not call `set*buffersize`)?,0,0.9910310506820679
37479192,151,gwenshap,2015-08-19T23:00:29Z,yep. basically move the constants and their behavior to the new network classes.,0,0.9864353537559509
37479252,151,ijuma,2015-08-19T23:01:11Z,sounds good.,1,0.857205867767334
37479424,151,gwenshap,2015-08-19T23:03:33Z,"i actually find the very generic ""any predicate"" or ""any find on a collection"" challenging. i'm concerned that future contributors won't quite know what to do with those. i'm thinking that baking the specific ""find"" we actually have into a wrapper, will help. so: polluntilrecievingresponsefromconnection(selector, timeout, connection_id)",-1,0.7900054454803467
37567314,151,gwenshap,2015-08-20T18:53:17Z,nice :),1,0.991594135761261
37606457,151,junrao,2015-08-21T04:49:32Z,"we need to block until the connection is established, right?",0,0.9878749251365662
37606471,151,junrao,2015-08-21T04:50:02Z,"we will need to handle disconnects (like what networkclient does) by checking selector.disconnected(). if a socket is disconnected, there is no need to wait for the timeout. we should just throw an ioexception back. ditto to the selector.poll() below.",0,0.9928024411201477
37606475,151,junrao,2015-08-21T04:50:16Z,"we haven't been using the s notation so far. to be consistent, perhaps it's better to use the string format thing for now and do a global replacement at some point if we feel that's better?",0,0.9902190566062927
37606486,151,junrao,2015-08-21T04:50:28Z,"since there is a selector per broker, we need to add a broker id tag for the metric tag.",0,0.994013249874115
37614464,151,ijuma,2015-08-21T08:12:40Z,"i thought we did not as we will eventually block after the `send`, which happens a few lines below. have i misunderstood how the `selector` should be used in this case?",0,0.9752224683761597
37614569,151,ijuma,2015-08-21T08:14:11Z,"makes sense, will do.",0,0.8586028218269348
37614852,151,ijuma,2015-08-21T08:19:05Z,"i considered that, but we have over 800 instances of `format` in our codebase, so it would be quite a painful global replacement (with potential for introducing bugs). string interpolation is safer and performs better than `.format`, so i thought we could use it for new code where it made sense. we use it in a small number of places already. please let me know if you still think i should change it.",0,0.8780430555343628
37614934,151,ijuma,2015-08-21T08:20:33Z,"will do. i'm not really sure how these tags work to be honest, but i'll see if i can find an existing example. :)",1,0.9957950115203857
37626125,151,ijuma,2015-08-21T11:28:49Z,", i added the `broker-id` tag below. does it still make sense to include `broker.id` in the `metricgrpprefix` above?",0,0.9925292134284973
37651956,151,junrao,2015-08-21T16:34:42Z,"if you look at networkclient, the way that it uses selector is the following. before networkclient can send any request, it has to make sure the connector is connected and the channel is ready. if you don't follow this protocol, things can get weird. for example, in ssl, after we finish the handshake, we will turn off the interest bit for write. if the interest bit for write has already been turned on by a request sent before the handshake completes, the send may never complete. thinking a bit more about this. it seems to implement a blocking channel on the selector, we will need most of the connection state management logic in networkclient. the problem with using networkclient is that it's tied to metadata refresh, which is not needed. we can either add an option to turn off the metadata part in networkclient and use it to implement the blocking channel. alternatively, we can implement a blockingselector on top of selector, but has to copy some of the state management logic from networkclient over. not sure which one is better.",0,0.5647197961807251
37651974,151,junrao,2015-08-21T16:34:54Z,"metricgrpprefix is just a prefix of the metrics group, which is a string. tags give metadata in key/value pairs, which is more informative.",0,0.9913427829742432
37653240,151,ijuma,2015-08-21T16:48:38Z,"ok, i see. i'll check if turning off metadata in `networkclient` can be done without too much complexity.",0,0.98969966173172
38272677,151,ijuma,2015-08-30T15:23:09Z,will add javadoc.,0,0.9944370985031128
38272682,151,ijuma,2015-08-30T15:23:15Z,will add javadoc.,0,0.9944370985031128
38272693,151,ijuma,2015-08-30T15:23:58Z,will add `and version` at the end of the sentence.,0,0.9945420622825623
38272702,151,ijuma,2015-08-30T15:25:30Z,v1 was added during the development of 0.8.3 so we could change this to be like v0 if we think it's important.,0,0.9931554198265076
38272718,151,ijuma,2015-08-30T15:27:19Z,will add `scaladoc` to this class and methods.,0,0.9952753782272339
38279205,151,junrao,2015-08-31T01:03:19Z,"do we need to wait for the next poll() call? disconnect() will cancel the key, after which the key will never be selected again.",0,0.9860183000564575
38279208,151,junrao,2015-08-31T01:03:29Z,it seems that we also need to remove nodeid from clusterconnectionstates?,0,0.9945076107978821
38279209,151,junrao,2015-08-31T01:03:35Z,need to add .,0,0.9931592345237732
38279211,151,junrao,2015-08-31T01:03:42Z,need to add .,0,0.9931592345237732
38279215,151,junrao,2015-08-31T01:03:47Z,need to add .,0,0.9931592345237732
38279216,151,junrao,2015-08-31T01:03:54Z,do we need to pass mode in? could we just get it from configs?,0,0.9934573769569397
38279217,151,junrao,2015-08-31T01:04:00Z,this field should be named live_leaders.,0,0.9949370622634888
38279219,151,junrao,2015-08-31T01:04:04Z,this can just be referencing leader_and_isr_request_partition_state_v0.,0,0.994617760181427
38279226,151,junrao,2015-08-31T01:04:16Z,good catch. it's probably too late to change that though.,1,0.977764368057251
38279229,151,junrao,2015-08-31T01:04:22Z,leaders is better named as liveleaders.,0,0.9313913583755493
38279232,151,junrao,2015-08-31T01:04:33Z,"it's probably better to create two constructors, one for each version. we can then mark the v0 constructor as deprecated and can remove it in the future.",0,0.9894431829452515
38279234,151,junrao,2015-08-31T01:04:38Z,both v0 and v1have host_key_name. perhaps we should check field security_protocol_type_key_name?,0,0.995141863822937
38279239,151,junrao,2015-08-31T01:04:44Z,should we mock the other new method disconnect() too?,0,0.9891863465309143
38279241,151,junrao,2015-08-31T01:04:49Z,response version should be 1.,0,0.9934778213500977
38279242,151,junrao,2015-08-31T01:04:51Z,response version should be 1.,0,0.9934778213500977
38279278,151,junrao,2015-08-31T01:07:21Z,we probably want maxinflightrequests to be 1 so that it's consistent with the current behavior in blockingchannel.,0,0.9901772141456604
38279285,151,junrao,2015-08-31T01:07:47Z,there are a few unused imports.,0,0.988497793674469
38279287,151,junrao,2015-08-31T01:07:55Z,selector should now be networkclient. there are a few other mentions of selector below.,0,0.9957128763198853
38279289,151,junrao,2015-08-31T01:08:00Z,"$sockettimeoutexception should be $sockettimeoutms, right?",0,0.9907935261726379
38279291,151,junrao,2015-08-31T01:08:06Z,we probably want maxinflightrequests to be 1 so that it's consistent with the current behavior in blockingchannel.,0,0.9901772141456604
38279296,151,junrao,2015-08-31T01:08:14Z,do we need to do this? nodes are only used for sending metadatarequest and we are not doing that here.,0,0.9834867715835571
38279300,151,junrao,2015-08-31T01:08:36Z,"we probably want to move the blocking support to the client side. in the future, we likely will be writing the admin tools in java and it potentially will need to make blocking request calls too.",0,0.9908586144447327
38279310,151,junrao,2015-08-31T01:09:04Z,"if the connection didn't fail, is there any reason to back off? it seems that we should be calling networkclient.poll() with the timeout immediately.",0,0.9903731346130371
38279316,151,junrao,2015-08-31T01:09:31Z,"perhaps it's more convenient to include to logic to wait for the connection being ready here. this way, we are guaranteed that every time we send a request, the socket is ready. currently, in controllerchannelmanager, if we can't establish a socket connection, it seems that we can send a request before the channel is ready.",0,0.985988974571228
38292654,151,ijuma,2015-08-31T08:21:53Z,"i copied that documentation from `selector.disconnect`. there is the following code in `selector.poll`: [code block] and there is the following test in `networkclienttest`: [code block] so, that lead me to believe that a poll was needed to update the internal state of the `selector` and `networkclient`. the test above fails without the `poll` line (although it does use a `mockselector`, so the bug could be there). what are your thoughts based on this additional information?",0,0.9871224164962769
38292972,151,ijuma,2015-08-31T08:27:34Z,"i did think about setting the state to disconnected (which has a similar effect), but then i thought that this would be updated automatically via `poll` as per the comment added in the discussion around the javadoc for `kafkaclient.poll`. but maybe the right thing is to do update the state here as you suggest. do you think we should remove the id or set the state to `disconnected`?",0,0.9861196279525757
38296748,151,ijuma,2015-08-31T09:30:40Z,"the 4 places where this is used all pass this parameter explicitly (as `sslfactory.mode.{client,server}`). we could put a key into the configs map, but i think that would make things more opaque with no clear benefit. what do you think?",0,0.9745484590530396
38296826,151,ijuma,2015-08-31T09:32:11Z,"will fix. we also have `alive_brokers` elsewhere, should we be calling that `live_brokers` instead for consistency?",0,0.9933726787567139
38296887,151,ijuma,2015-08-31T09:33:21Z,"ok, will do. i wasn't sure what was our policy when it came to referencing schemas from other apis in the same class. good to know.",1,0.9818474650382996
38296946,151,ijuma,2015-08-31T09:34:04Z,will do.,0,0.9465230703353882
38296965,151,ijuma,2015-08-31T09:34:20Z,will do.,0,0.9465230703353882
38297159,151,ijuma,2015-08-31T09:37:48Z,"in v1, `host_key_name` is in the `end_points` struct though, so it should be fine either way as far as i can see. i'll change it to `security_protocol_type_key_name` as it's clearer though.",0,0.9896520972251892
38297285,151,ijuma,2015-08-31T09:39:41Z,it was already there previously.,0,0.9901244044303894
38297303,151,ijuma,2015-08-31T09:39:56Z,"good catch, will fix.",1,0.9896132349967957
38297314,151,ijuma,2015-08-31T09:40:10Z,"good catch, will fix.",1,0.9896132349967957
38297556,151,ijuma,2015-08-31T09:44:08Z,"i think the behaviour should be consistent anyway as we block for each request. setting this to `1` will enforce it, so i'll change it.",0,0.9881908893585205
38297677,151,ijuma,2015-08-31T09:46:00Z,will fix.,0,0.9901540875434875
38297917,151,ijuma,2015-08-31T09:49:38Z,i'll change this to say `networkclient`/`selector`. i think the other `selector` mentions are fine.,0,0.9795997142791748
38297929,151,ijuma,2015-08-31T09:49:53Z,"good catch, will fix.",1,0.9896132349967957
38297986,151,ijuma,2015-08-31T09:50:55Z,"similar to the other instance of this, i think the behaviour is still correct, but i'll change it to be clearer/safer.",0,0.9732915163040161
38298281,151,ijuma,2015-08-31T09:56:12Z,"we don't strictly need it, but `kafkaclient.leastloadednode` would return `null` if we don't do this. as you say, we don't use that method so it would have no effect right now if we remove it. i did that because i thought it may help avoid surprises in the future, but i don't have a strong opinion on it. do you still think it should be removed?",0,0.9718884229660034
38299301,151,ijuma,2015-08-31T10:12:13Z,i checked this and i think 0 is correct for `leaderandisrresponse`. or am i missing something?,0,0.9881780743598938
38299668,151,ijuma,2015-08-31T10:19:05Z,"i think you meant `controlledshutdownresponse`, i fixed that.",0,0.9893726706504822
38300557,151,ijuma,2015-08-31T10:33:47Z,"is this something we want to do now or when the need arises? i didn't want to add this to the clients jar because i thought it was just useful to help us transition the broker code without bigger changes. it seems like there may be more use cases, but isn't it better to wait until they are concrete before moving the code to the clients jar?",0,0.9840474724769592
38303535,151,ijuma,2015-08-31T11:31:47Z,"actually i can't make this change because `security_protocol_type_key_name` will never exist at this level. i could check for `endpoints_key_name`, but i think the current way is less error-prone (as endpoints could be empty due to a bug perhaps). so i'll leave it as is unless you disagree.",0,0.9852814078330994
38303909,151,ijuma,2015-08-31T11:38:38Z,will fix.,0,0.9901540875434875
38303913,151,ijuma,2015-08-31T11:38:45Z,will fix.,0,0.9901540875434875
38303918,151,ijuma,2015-08-31T11:38:53Z,will fix.,0,0.9901540875434875
38304564,151,ijuma,2015-08-31T11:50:35Z,"perhaps. i'm not sure though. it's easy enough for the caller to call `blockingready` if that is desired, right? i didn't do that in `controllerchannelmanager` because the existing code already handles the exception that would be thrown if the initial connection fails: [code block] the existing code is not the prettiest, but i tried not to make too many changes at this point. i think we should consider redesigning the controller/broker communication to make better use of `networkclient` in the future.",0,0.9555765390396118
38306320,151,ijuma,2015-08-31T12:21:10Z,"i did this, but it's worth being aware of the downsides (and why i had avoided that in the first place): - we now have a number of warnings due to the fact that we call the deprecated constructor - the calling code is more complex as it needs to pass slightly different data to each constructor (we still support both versions from the calling code and previously it just had to pass a version) - a new deprecated inner class `brokerendpoint` had to be introduced for the v0 constructor",0,0.9430927038192749
38313413,151,ijuma,2015-08-31T13:54:32Z,"i'll remove `retrybackoff`. it's how i had it at first, but i was seeing some issues where `poll` was returning immediately which was causing the thread to spin and seemed to be causing more connection timeouts than usual. i now think that this was caused by a bug in the handling of the connection failures (which i fixed before reopening the pr).",0,0.9883381724357605
38332668,151,junrao,2015-08-31T16:58:29Z,"yes, that's how mockselector is implemented. in the real selector, my understanding is that if you disconnect a client, we cancel the key. the cancelled key will never be selected by the selector again. so, you would have to set the connection state in the same disconnect call. if that's the case, we probably need to change the behavior of mockselector.",0,0.9854609370231628
38332742,151,junrao,2015-08-31T16:59:17Z,"this is related to the comment above. if a client calls disconnect, it may not be interested in using this connection any more. so, we probably want to fresh the memory by removing the id from the connection state.",0,0.9929671287536621
38332766,151,junrao,2015-08-31T16:59:27Z,what you have is fine. i didn't realize that mode is implicit and not an explicit property.,1,0.8500856757164001
38332782,151,junrao,2015-08-31T16:59:34Z,what you had is fine.,0,0.6188560128211975
38332818,151,junrao,2015-08-31T16:59:55Z,"it's fine if we set the nodes explicitly. if so, we should do the same for the manualmetadataupdater used in controllerchannelmanager.",0,0.993420422077179
38332943,151,junrao,2015-08-31T17:01:04Z,"yes, the logic in controllerchannelmanager is not pretty. the issue that i see is that if connecttobroker() fails to establish a connection in time, we just disconnect. so, by the time you send a request, there is not guarantee that the connection is ready.",0,0.8522669672966003
38335942,151,junrao,2015-08-31T17:31:06Z,we can keep the blocking logic in scala for now.,0,0.9928846955299377
38336063,151,ijuma,2015-08-31T17:32:10Z,"we do indeed, but at construction time because we use a `networkclient` for each broker connection, i paste the line below: `new manualmetadataupdater(seq(brokernode).asjava)`",0,0.994674563407898
38336694,151,ijuma,2015-08-31T17:37:51Z,"yes, i understand. so, if the connection is not ready, an `illegalstateexception` will be thrown which will cause a disconnect (no-op) followed by another connect and then we will retry again after a 300ms sleep since `issendsuccessful === false`. this behaviour is very similar to what would happen with `blockingchannel` where a closedchannelexception would be thrown if `send` was called and the channel was not connected due to a failure. i can add a `blockingready` call before the `send` if you think that is better though.",0,0.9837818145751953
38337234,151,ijuma,2015-08-31T17:42:47Z,"i see. i'll test the behaviour of the real selector just to be sure. in the likely case that it matches your description, i will do the following: - update `mockselector` - update `networkclienttest` - update `selector.disconnect` and `networkclient.disconnect` documentation - update implementation of `networkclient.disconnect` to update connection states - remove `networkclientblockingops.disconnectandpoll` as `disconnect` will be sufficient have i covered everything?",0,0.9837749004364014
38338561,151,junrao,2015-08-31T17:53:43Z,"yes, relying on illegalstateexception probably works, but it's kind of hacky. illegalstateexception is meant to capture all programming errors, and using it for error handling feels wrong.",-1,0.9747592806816101
38338732,151,junrao,2015-08-31T17:55:07Z,got it. i missed that you can pass in the nodes from the constructor.,0,0.8904483914375305
38338901,151,junrao,2015-08-31T17:56:31Z,that sounds good.,1,0.7971994876861572
38340333,151,ijuma,2015-08-31T18:08:22Z,"ok, i will add a `blockingready` before the send then.",0,0.9952723383903503
38400639,151,ijuma,2015-09-01T09:30:33Z,we have `liveleaders` in `leaderandisrrequest`. do we want to keep this as `alivebrokers` or would it be better to call it `liveborkers`?,0,0.993895947933197
38423086,151,ijuma,2015-09-01T14:16:52Z,i did this here instead of changing `blockingsendandreceive` to make it easier to maintain the previous behaviour of logging once a connection is established.,0,0.9931489825248718
38423154,151,ijuma,2015-09-01T14:17:33Z,"this method already existed in `networkclient`, i just added it to the interface.",0,0.9956690073013306
38423354,151,ijuma,2015-09-01T14:19:08Z,"i named this `close` instead of `disconnect` to match the relevant method in `selector`, but i'd be interested in feedback regarding the naming. also, it's not clear to me when `selector.disconnect` is actually useful.",0,0.9877320528030396
38473289,151,junrao,2015-09-01T21:16:58Z,is that added?,0,0.994509756565094
38473306,151,junrao,2015-09-01T21:17:04Z,this is not really an instance of invalidmetadataexception.,0,0.9676074385643005
38473310,151,junrao,2015-09-01T21:17:09Z,this is not really an instance of invalidmetadataexception.,0,0.9676074385643005
38473361,151,junrao,2015-09-01T21:17:30Z,"even though updatemetadatarequest_v0 has identical structure as leaderandisrrequest_v0, the set of brokers used are slightly different. in updatemetadatarequest_v0, we pass in all live brokers. in leaderandisrrequest_v0, we pass in all live brokers that are the leaders. so, we can keep the names as they are.",0,0.986788272857666
38473426,151,junrao,2015-09-01T21:17:59Z,"in version 0, we should only allow passing in a single brokerendpoint.",0,0.9913391470909119
38473454,151,junrao,2015-09-01T21:18:06Z,"now that we have the broker tag, the group prefix can just be ""controller-channel"" or sth like that.",0,0.9932718873023987
38473470,151,junrao,2015-09-01T21:18:13Z,is the if statement needed since the test is already done in networkclient.blockingready()?,0,0.9951111674308777
38475260,151,ijuma,2015-09-01T21:35:08Z,is it a `retriableexception` or `apiexception` then?,0,0.9917126893997192
38475273,151,ijuma,2015-09-01T21:35:16Z,is it a `retriableexception` or `apiexception` then?,0,0.9917126893997192
38475371,151,ijuma,2015-09-01T21:36:00Z,will fix.,0,0.9901540875434875
38475773,151,ijuma,2015-09-01T21:40:14Z,ok. we don't need to include the controller id in the group prefix or as a tag?,0,0.9936060905456543
38476438,151,ijuma,2015-09-01T21:46:57Z,"it's done this way to only log the ""controller %d connected"" message if the connection is not already ready.",0,0.9948093891143799
38477988,151,junrao,2015-09-01T22:02:59Z,apiexception for both.,0,0.9923375248908997
38478139,151,junrao,2015-09-01T22:04:55Z,we don't need the broker id in group prefix. still need the broker id in the metrics tag.,0,0.9937968254089355
38478285,151,junrao,2015-09-01T22:07:00Z,ok. we can leave it as it is. thanks for the explanation.,1,0.9488376379013062
38478450,151,ijuma,2015-09-01T22:09:06Z,"sorry, my question was about the controller id (i had understood the point about the broker id).",-1,0.9734043478965759
38478876,151,ijuma,2015-09-01T22:14:31Z,"are you sure about this? looking at the scala code, it does: read: `case 0 => for(i <- 0 until numalivebrokers) yield new broker(brokerendpoint.readfrom(buffer),securityprotocol.plaintext)` write: ``case 0 => alivebrokers.foreach(_.getbrokerendpoint(securityprotocol.plaintext).writeto(buffer))`",0,0.9946723580360413
38483970,151,ijuma,2015-09-01T23:18:34Z,"not yet, i was focusing on getting the behaviour right first. i'll add all the missing javadoc/scaladoc in my next commit.",0,0.9700779318809509
38498073,151,junrao,2015-09-02T04:29:17Z,"actually, my comment wasn't right. what you had is right since in v0, we pass in a set of brokerendpoint and v1, we pass in a set of broker.",0,0.9534270763397217
38521906,151,ijuma,2015-09-02T11:30:39Z,"yes, i understand the difference between brokers and leaders. the bit i was asking about is the `live` prefix (in `liveleaders`) versus the `alive` prefix (in `alivebrokers`). it seemed to me that `livebrokers` means the same and the prefix would be consistent. anyway, not a big deal, so fine to keep as is if you prefer.",0,0.6231068968772888
38559331,151,junrao,2015-09-02T17:21:34Z,"yes, i agree that it's better to make the names consistent. so we can use live_brokers and live_leaders here and in protocols as well.",0,0.983327329158783
114734810,2967,ijuma,2017-05-04T09:43:29Z,are the `private` -> `protected` changes still needed?,0,0.9939510822296143
114739200,2967,ijuma,2017-05-04T10:09:24Z,"for consistency, it may make sense for `wrapforoutput` to take a `bytebuffer` too.",0,0.9911187291145325
114740176,2967,ijuma,2017-05-04T10:15:34Z,"we could change `defaultrecord.readfrom` to take a `datainput` (instead of `datainputstream`), change `kafkalz4blockinputstream` to implement `datainput` and then only wrap if the returned value is not already a `datainput`. that would remove a layer of indirection and if it's possible to implement `readfully` more efficiently in `kafkalz4blockinputstream`, then it could be a win. if you have time, it may be worth a try.",0,0.9655771851539612
114742214,2967,ijuma,2017-05-04T10:27:46Z,"it wasn't clear to me why we needed both `thebuffer` and `decompressionbuffer`. it seems that we rely on the fact that `thebuffer` is only populated after the first `readblock` to implement `available` correctly. is that the only difference? if so, would it not be simpler to have a single buffer that is allocated for the first time in `readblock`?",0,0.9817704558372498
114742293,2967,ijuma,2017-05-04T10:28:16Z,`mark()` and `reset()` are synchronized and probably should not be.,0,0.9853109121322632
114742552,2967,ijuma,2017-05-04T10:29:51Z,i think the default should be `current_magic_value`.,0,0.9859262704849243
114742615,2967,ijuma,2017-05-04T10:30:16Z,why did you remove `none` from this list? it seems useful to have the uncompressed baseline.,0,0.9911438226699829
114742753,2967,ijuma,2017-05-04T10:31:07Z,seems like more fields could be final in this class.,0,0.9659472703933716
114743094,2967,ijuma,2017-05-04T10:33:53Z,you should probably use `abstractrecords.sizeinbytesupperbound`.,0,0.9947224855422974
114744092,2967,ijuma,2017-05-04T10:41:09Z,"to make the benchmark less dependent on implementation details, it would be better if it used `memoryrecords.readablerecords(...).batches()`. same for the other benchmark.",0,0.9925128221511841
114744933,2967,ijuma,2017-05-04T10:46:15Z,maybe this should be `recordbatchiterationbenchmark`?,0,0.9878225922584534
114746255,2967,ijuma,2017-05-04T10:55:31Z,"we followed the same approach for snappy and lz4 to deal with the possibility that the libraries are not in the classpath because it's not supported in a given platform. however, we are using kafka classes for the block input stream and block output stream. as such, we can probably reference the constructor directly. we won't invoke the constructor unless lz4 is configured and it's ok to fail in that case. does that make sense?",0,0.9908568263053894
114746515,2967,ijuma,2017-05-04T10:57:30Z,why do we need this?,0,0.9423887133598328
114807909,2967,xvrl,2017-05-04T15:14:02Z,"we don't need them anymore, indeed",0,0.9356087446212769
114808828,2967,xvrl,2017-05-04T15:17:27Z,sure,0,0.9422702193260193
114808856,2967,xvrl,2017-05-04T15:17:33Z,"the benchmark is in the `org.apache.kafka.common.record` package. now that we don't rely on package protected classes anymore, we can move it to `org.apache.kafka.jmh` and remove this.",0,0.9946902990341187
114810971,2967,xvrl,2017-05-04T15:24:57Z,`thebuffer` is also pointed directly to the input buffer when a block is not compressed to avoid copying bytes.,0,0.9931904673576355
114811084,2967,xvrl,2017-05-04T15:25:21Z,"hmm, not sure why they were in the first place",0,0.6193389296531677
114812768,2967,ijuma,2017-05-04T15:31:22Z,"copy and paste, i bet.",0,0.9708737134933472
114812862,2967,ijuma,2017-05-04T15:31:42Z,sounds good.,1,0.857205867767334
114814192,2967,ijuma,2017-05-04T15:36:30Z,"i had noticed that, but didn't think through how that could work if we had a single buffer variable. ok, seems simplest to have two buffers. can we add a comment explaining this?",0,0.9818582534790039
114824952,2967,xvrl,2017-05-04T16:19:55Z,"seems like this is not as straightforward as it seems. memoryrecordsbuilder relies on having access to the underlying bytebuffer held by the bytebufferoutputstream, which would break if the buffer is expanded in bytebufferoutputstream",0,0.9463815689086914
114826480,2967,xvrl,2017-05-04T16:26:38Z,"makes sense, as far as i know lz4 falls back to a pure-java version anyway, so it should be safe regardless (unless there are other platform issues that are unrelated to native code)",0,0.9790385365486145
114826699,2967,xvrl,2017-05-04T16:27:43Z,"i'd prefer to do that in a follow-up pr in trunk, since i'd also like to backport this to 0.10.2.x",0,0.9907062649726868
114826741,2967,xvrl,2017-05-04T16:27:56Z,will do,0,0.9619618058204651
114828336,2967,xvrl,2017-05-04T16:35:40Z,"note however that we store the lz4safedecompressor as a static field, so loading the kafka class would also trigger loading the lz4 classes.",0,0.992713987827301
114873529,2967,xvrl,2017-05-04T20:00:12Z,fixed,0,0.920660674571991
114873560,2967,xvrl,2017-05-04T20:00:19Z,fixed,0,0.920660674571991
114874156,2967,xvrl,2017-05-04T20:03:09Z,"when using `memoryrecords.readablerecords(...)` we don't technically test the compression.none ""compression"" method, but test a different code path, so it's not really comparable if you care about an upper bound on how fast decompression could be.",0,0.9774702787399292
114874228,2967,xvrl,2017-05-04T20:03:31Z,i added it back so we could at least see what it means in practice though,0,0.9897310733795166
114874277,2967,xvrl,2017-05-04T20:03:40Z,fixed,0,0.920660674571991
114874313,2967,xvrl,2017-05-04T20:03:52Z,good to know,1,0.9820453524589539
114874345,2967,xvrl,2017-05-04T20:04:02Z,changed.,0,0.9680466055870056
114876003,2967,xvrl,2017-05-04T20:12:03Z,"i was also thinking, if we avoided readfully altogether, we could avoid the eofexception penalty when reaching the end of the batch on legacy records and get a further 3x improvement for small legacy batches.",0,0.985824465751648
114877226,2967,ijuma,2017-05-04T20:18:00Z,"it's not the same code path, but that's ok. the comparison i'm looking for is a bit like the one in the lz4 github page where it compares memcpy with lz4 decompression ([a link]",0,0.8760679960250854
114879573,2967,ijuma,2017-05-04T20:28:49Z,"hmm, `datainputstream.readfully` only throws an exception if we ask it to read past the end of the inputstream. so supposedly, if we fix the underlying inputstream, it's enough either way. the following pr does that: [a link]",0,0.9782875180244446
115125280,2967,hachikuji,2017-05-06T17:42:08Z,"nit: this looks a little weird. could we just do [code block] also, the name is a bit vague. maybe `record_header_size`?",-1,0.9674069285392761
115125399,2967,hachikuji,2017-05-06T17:47:46Z,this block seems to be the same code as below. perhaps we could move it into a `readfully` function in `utils` (we have a couple of these for working with `filechannel` already)?,0,0.9926868677139282
117260682,2967,ijuma,2017-05-18T14:20:03Z,"good point, can we please add a comment explaining the reason for the inconsistency?",1,0.8881285786628723
117292625,2967,ijuma,2017-05-18T16:19:57Z,"yeah, but `kafkalz4blockinputstream` itself should not be initialised until it's actually used. i made this change, used compressiontype.snappy.wrap* methods while lz4 was not in the classpath and it worked fine. the same exercise did not work for snappy because `snappyinputstream` was not in the classpath. anyway, we can keep it as it is if you prefer as the performance impact is low when compared to other things (8ns instead of 4ns per construction).",0,0.9882749319076538
117300016,2967,xvrl,2017-05-18T16:54:17Z,done,0,0.8682363629341125
117300539,2967,xvrl,2017-05-18T16:56:50Z,"ok, i've change it to construct the lz4 streams directly, and updated the comments accordingly.",0,0.9940415024757385
118957598,2967,ijuma,2017-05-29T15:38:55Z,is it safe to do this on the received buffer? `deeprecordsiterator` doesn't seem to duplicate the buffer before calling `compressiontype.wrapforoutput`.,0,0.9940020442008972
118962982,2967,ijuma,2017-05-29T16:25:02Z,"i'm not totally sure why we were previously using a `readunsigned` method and now we're not. for many of the other cases where we do this, it's easy to verify that the values we care about work either way. the ones that weren't totally clear to me were this and the block checksum cases. can you please elaborate why the change is safe in those two cases?",0,0.9811441898345947
118966334,2967,ijuma,2017-05-29T17:01:00Z,"hmm, so this bug meant that the `blocksize > maxblocksize` check was not working, right? also, did we just get lucky that the `blocksize == 0` check worked?",0,0.9532834887504578
118970809,2967,ijuma,2017-05-29T17:52:18Z,nit: is there a reason why we are modifying the existing block size instead of just setting the bad block size directly?,0,0.5681517124176025
119135013,2967,xvrl,2017-05-30T15:35:05Z,"from reading the code, `byteutils.readunsignedintle` is a misnomer and should probably be just be called `readintle`. unlike `readunsignedint`, which returns a long and applies the proper bit mask, `readunsignedintle` returns an integer and doesn't do anything other than shifting the bytes.",0,0.9515751600265503
119140839,2967,xvrl,2017-05-30T15:55:42Z,"`deeprecordsiterator` technically duplicates the buffer when calling [a link] and never reuses it, but i agree that could easily be missed or introduce odd bugs if that code were to be rewritten. i can add a `duplicate()` here just for safety.",0,0.9894338250160217
119141976,2967,ijuma,2017-05-30T15:59:58Z,sounds good.,1,0.857205867767334
119146762,2967,xvrl,2017-05-30T16:18:08Z,"indeed, the size check wasn't working, but at the end of the day, we would just thrown a different exception in case the block size exceeded the max. regarding the zero size block, we were just lucky that we never set the `lz4_frame_incompressible_mask` flag in `kafkalz4blockoutputstream.writeendmark`. i checked the spec and it didn't seem to specify whether the flag should be set or not in that case, so better be safe.",0,0.9531905651092529
119157414,2967,xvrl,2017-05-30T17:02:15Z,"yes, to make sure it works in both cases when the incompressible flag is set and when it is not.",0,0.9930272698402405
119160775,2967,hachikuji,2017-05-30T17:15:48Z,should we rewind the buffer in case the position wasn't reset after the last use? (also nit: can we just call it `buffer`?),0,0.9760385155677795
119161965,2967,hachikuji,2017-05-30T17:20:29Z,it's a little odd for this to live here given the interface is in `kafkalz4blockinputstream`. i'd suggest either moving it there or pulling the `buffersupplier` interface out of `kafkalz4blockinputstream`.,0,0.7758147120475769
119174351,2967,ijuma,2017-05-30T18:10:08Z,"yeah, my pr removes all of these in favour of existing constants: [a link]",0,0.9924323558807373
119174470,2967,ijuma,2017-05-30T18:10:32Z,you and i had the exact same thought: [a link],0,0.9875594973564148
119174697,2967,ijuma,2017-05-30T18:11:25Z,3 for 3: [a link],0,0.9890024662017822
119174941,2967,ijuma,2017-05-30T18:12:24Z,that's one issue. the other is that if there are two `kafkalz4blockinputstream` instances in the same thread: [a link],0,0.989147961139679
119183125,2967,xvrl,2017-05-30T18:47:29Z,"technically we don't have to, kafkalz4blockinputstream resets position and limit every time anyway when preparing the buffer for consumption. agree that would be a concern if someone were to consume from two separate consumers in the same thread. happy to replace the buffer supplier implementation with the one you pointed to.",0,0.6822497844696045
119185468,2967,hachikuji,2017-05-30T18:57:10Z,"yeah, figured that was the case, but it makes the code a bit brittle to depend on that.",0,0.8241446018218994
107401674,2719,dguy,2017-03-22T12:36:06Z,i wonder if we should set this higher? is there any harm in setting it to `integer.max_value`?,0,0.9658856987953186
107402332,2719,dguy,2017-03-22T12:39:55Z,do you think we should maybe kill some more brokers? or is that going to be too non-deterministic in terms of test failures?,0,0.9676443934440613
107427012,2719,enothereska,2017-03-22T14:26:45Z,we probably can. the main problem i have right now is how to sidestep all the kafka corner cases when it comes to failures while still showing that streams is resilient. stay tuned.,0,0.7188780903816223
107454080,2719,enothereska,2017-03-22T15:57:22Z,ok,0,0.9233372807502747
107481625,2719,enothereska,2017-03-22T17:36:40Z,do these parameters make sense for a config that should not lose data? we are ok to have duplicates. do i need to do anything with `unclean.leader.election`?,0,0.9923890233039856
108192236,2719,dguy,2017-03-27T14:58:35Z,would be better to pass in an implementation of `time` and use `time.sleep(1000l)` here.,0,0.9908168315887451
108193858,2719,dguy,2017-03-27T15:04:12Z,we currently don't do anything about `min.insync.replicas` - should we?,0,0.9895449280738831
108194089,2719,dguy,2017-03-27T15:05:03Z,"nit: ""active tasks {}, standby tasks {}, suspended tasks {}, and suspended standby tasks {}""",0,0.9940882921218872
108194869,2719,dguy,2017-03-27T15:07:41Z,"`new streamsexception(""could not poll."", e)`",0,0.9949278831481934
108195049,2719,dguy,2017-03-27T15:08:16Z,"apart from a `streamsexception` i think the only other exception that `poll` is going to throw is `illegalstateexception` - should we just handle this in `sendrequest` and leave this as it was. even if there are more exceptions, i think it would be better to handle it in `sendrequest` and throw a `streamsexception` from there",0,0.986187219619751
108196783,2719,dguy,2017-03-27T15:15:24Z,i guess you can remove this now?,0,0.9916431903839111
108197021,2719,dguy,2017-03-27T15:16:24Z,you can remove this now as you've set it as the default in `streamsconfig`,0,0.9958529472351074
108197175,2719,dguy,2017-03-27T15:16:59Z,same with this one,0,0.9891930222511292
108202868,2719,enothereska,2017-03-27T15:37:34Z,yes we should. any insights on what you have found useful for that? thanks.,1,0.9556808471679688
108203239,2719,enothereska,2017-03-27T15:38:57Z,"not quite, since in streamsconfig it is the internal streams producer. here it's another producer.",0,0.9755620360374451
108262374,2719,norwood,2017-03-27T19:48:07Z,"something like `min(2, replicationfactor)` should be a good default. i'd also be concerned about this override for `brokers.size() < replicationfactor`. i think i'd prefer we fail here, rather than getting in to a misconfigured state. we have run in to issues where a user brings up a cluster and as kafka is doing its thing also brings up their streams app. so during startup we see 1 broker, then sometime down the line broker 2...n. this was causing us to precreate a bunch of our streams topics incorrectly (when we only saw one broker), and then on restart we would try to verify topics against actual configs and fail.",0,0.6381257176399231
108262836,2719,norwood,2017-03-27T19:50:09Z,i think `validatetopicpartitions` should also validate `replicationfactor`,0,0.9896077513694763
108263977,2719,mjsax,2017-03-27T19:55:21Z,we need a kip if we change any default values...,0,0.9943795800209045
108264259,2719,mjsax,2017-03-27T19:56:42Z,do we really want to do this? i would strongly prefer to throw an exception to the user!,0,0.9351060390472412
108264430,2719,mjsax,2017-03-27T19:57:23Z,i would not change this default value -- it's a hassle of anyone want to run a demo with local single broker setup.,-1,0.811601459980011
108264962,2719,mjsax,2017-03-27T19:59:40Z,ups. we really missed to close suspended tasks. really bad :( great catch eno!,-1,0.9912362098693848
108265404,2719,mjsax,2017-03-27T20:01:29Z,nit: add `final`,0,0.9956295490264893
108265542,2719,mjsax,2017-03-27T20:02:06Z,nit: add `final`,0,0.9956295490264893
108265707,2719,mjsax,2017-03-27T20:02:53Z,nit: add `final`,0,0.9956295490264893
108265721,2719,mjsax,2017-03-27T20:02:56Z,nit: add `final`,0,0.9956295490264893
108268924,2719,norwood,2017-03-27T20:16:25Z,"maybe a more dynamic default here, like with `acks=all=-1`? e.g. set `replicationfactor=-1` => `actualreplicationfactor=min(3, brokers.size())`",0,0.9899189472198486
108276754,2719,enothereska,2017-03-27T20:51:12Z,"the code actually uses min(#brokers, replication_factor), and prints a warning, but it still runs with, say, 1 broker.",0,0.9860424399375916
108276951,2719,enothereska,2017-03-27T20:51:55Z,"this is consistent with how things like schema registry, proactive support etc handle cases when the number of brokers is less than replication factor.",0,0.9920220375061035
108277094,2719,enothereska,2017-03-27T20:52:35Z,"do we? ? i thought we needed a kip to add new config values, not each time we tune them.",0,0.9677814841270447
108277327,2719,enothereska,2017-03-27T20:53:28Z,"the goal here is to do the right thing when there are enough brokers, not to provide magic when there just aren't enough brokers (e.g., in a test environment). currently we do the wrong thing when there are enough brokers.",0,0.9540097713470459
108278624,2719,enothereska,2017-03-27T20:59:15Z,yeah this was fun :),1,0.9943885207176208
108281740,2719,guozhangwang,2017-03-27T21:14:49Z,"i'd suggest throwing an exception here with the motivation similar to above. we have seen similar issues with offset topic num.partitions which we do this ""min(broker.size, required num.broekrs)"" trick and it introduces much more confusions than user-friendly benefits. for unit tests we should just always override these configs.",0,0.9880871772766113
108282040,2719,guozhangwang,2017-03-27T21:16:24Z,let's write a quick kip for this (also including the default replication factor to 3 above)? i think they are mostly fixing a bug but would better making them well known in the community as well.,0,0.9486401677131653
108282772,2719,guozhangwang,2017-03-27T21:20:17Z,"also i feel 1 second maybe too long in production? in practice brokers should be up / running much earlier than streams apps. for cases i still think it's better to fail fast and educate users retry creating their apps after the broker is fully up than trying to wait for, say 5 seconds and hopefully it will succeed.",0,0.923011064529419
108283433,2719,guozhangwang,2017-03-27T21:23:29Z,these two functions are very similar: could we collapse them into one function `performontasks` and pass in a `list ` as an additional parameters?,0,0.9942684173583984
108283588,2719,guozhangwang,2017-03-27T21:24:15Z,ditto above.,0,0.9910715222358704
108283829,2719,guozhangwang,2017-03-27T21:25:22Z,why we want to wrap even a rte as a streamsexception here?,0,0.9838084578514099
108283871,2719,guozhangwang,2017-03-27T21:25:38Z,same here.,0,0.9916109442710876
108288736,2719,mjsax,2017-03-27T21:49:35Z,"i think this dynamic change is quite dangerous -- if i specify replication 3 and cannot get it, i want an exception... thus, i would leave replication factor to 1 for demoing purpose -- if anyone goes to production she can set to whatever value is suitable -- or we make the parameter non-optional. i think it would be a hassle to have default value 3, and overwrite it with 1 in each example we do...",-1,0.9890034794807434
108289042,2719,mjsax,2017-03-27T21:51:10Z,we really need a bug fix release for this! \cc,-1,0.944229006767273
108292755,2719,enothereska,2017-03-27T22:09:39Z,"if i understand you right, you want the default 3, with the option for a user to set it to 1, right? or you want no change at all to what we currently have (default 1, user can set higher). i don't like the current option since it leads to trouble in production. i'm ok with the first option.",0,0.8233407735824585
108292984,2719,enothereska,2017-03-27T22:11:04Z,i think a kip unnecessarily slows things down. why do we need to do a kip to correct an internal flaw? users are already expecting internal topics to be robust. i'd argue we're fixing a bug here.,-1,0.7599794864654541
108293564,2719,norwood,2017-03-27T22:14:25Z,"yeah, my suggestion was to make the dynamism configurable. replication_factor_config= n where n >0 => i know what i want. streams should fail if it can't meet this contract replication_factor_config = -1 => streams is smart and can figure it out for me. this allows *me* to be as anal retentive as i want, but allows the defaults to work for demos/tests/etc.",0,0.9613996744155884
108301670,2719,mjsax,2017-03-27T23:06:09Z,"what should this be than? would we need another parameter ""default_replacation_factor"" and streams can choose between 1 and this value? not sure if this would not be too confusing.",0,0.8481110334396362
108301836,2719,mjsax,2017-03-27T23:07:18Z,i am happy without a kip :) makes live easier for us. it's call. or any other committer.,1,0.9966955184936523
108302114,2719,norwood,2017-03-27T23:09:18Z,"my suggestion above was `min(3, brokers.size())` i dont like this cause it seems like magic, but it also addresses most peoples issues.",-1,0.9675500988960266
108302312,2719,mjsax,2017-03-27T23:10:37Z,"i would prefer to keep the current default 1 and mark the parameter importance as ""high"", indicating that one most likely wants to change the default if going to production. default values must not be ""production ready"" settings imho (cf. `state.dir`). default values should give the best ""out-of-the-box"" experience when getting started with you first ""word count"" -- ie., local single broker setting.",0,0.9894305467605591
108341596,2719,enothereska,2017-03-28T06:20:32Z,"ok, i cannot keep the default to 1. this is what led to several bugs. it's not great to expect users to set this parameter which streams should be maintaining correctly.",-1,0.7587690949440002
108359843,2719,ijuma,2017-03-28T08:19:41Z,", as you know, we have changed the behaviour for the offsets topic so that we default to the safe production setting and fail otherwise. that is based on experience, as said, and seems more relevant than some of the other examples given. the question then is how to make it easy for development. for the offsets topic, we set the value to 1 in the `server.properties` that is used in the quickstarts, etc. that won't work here. there are a few possible solutions that will be helpful for this and many other configs: 1. have a config where users can define whether the environment is prod or dev and change the defaults based on that. 2. provide methods so that a user can get a prod or dev config. for example, `streamsconfigs.production()` or `streamconfigs.development()`. 3. add an enum to the constructor of `streamconfigs` where users can define if the environment is production or development. i think i like `3` best. in any case, we don't need to block this pr on the long-term solution. still, it may be worth figuring out the end state and then a plan on how to get there.",0,0.9413281083106995
108364658,2719,enothereska,2017-03-28T08:44:11Z,cc,0,0.9699252247810364
108368495,2719,ijuma,2017-03-28T09:01:55Z,"we typically do kips for config changes that impact users. kip-106 is one such example. if you can make the case that this is an internal bug fix and has no compatibility impact, then no kip is needed. the replication factor one would seemingly have a compatibility impact.",0,0.9915167093276978
108471613,2719,enothereska,2017-03-28T16:35:58Z,this will now be done in a kip and different pr.,0,0.9934442043304443
108472487,2719,enothereska,2017-03-28T16:39:37Z,"i'm reducing the time, but passing in `time` is a bit of a pain here and other calls also use thread.sleep. would prefer to do a cleanup pass later.",-1,0.8491321802139282
108472921,2719,enothereska,2017-03-28T16:41:17Z,"i didn't get this, what should be `final`?",0,0.9250141978263855
108473345,2719,enothereska,2017-03-28T16:43:10Z,this class should hide all underlying network exceptions and wrap them with stream exception imo. this is consistent with other examples in this class. otherwise the upper layers would need to know all the details of the underlying classes.,0,0.9924305081367493
108473773,2719,enothereska,2017-03-28T16:44:56Z,what exactly? i don't get this.,-1,0.5846701860427856
108479165,2719,enothereska,2017-03-28T17:07:45Z,this will now require a kip. will do in separate pr.,0,0.9954854846000671
108479321,2719,enothereska,2017-03-28T17:08:29Z,this will now require a kip and will be done in separate pr.,0,0.9942988157272339
108479431,2719,enothereska,2017-03-28T17:09:01Z,this will now require a kip and will be done in a separate pr.,0,0.9942333102226257
108481016,2719,mjsax,2017-03-28T17:15:57Z,-> `} catch (final exception e) {`,0,0.9883235692977905
108656204,2719,dguy,2017-03-29T11:52:48Z,can we pass in `time` and use `time.sleep(100l)` here?,0,0.9947572946548462
108656295,2719,dguy,2017-03-29T11:53:14Z,same as above,0,0.9918335676193237
108892220,2719,dguy,2017-03-30T10:31:20Z,i'm thinking it might be better to have a field in `streampartitionassignor` for time. it would default to `time.system` and then have a package private method for overriding it in tests. this way we wouldn't need to make the `time` field on `streamthread` public,0,0.976265013217926
108892245,2719,dguy,2017-03-30T10:31:29Z,see comment above,0,0.9929077625274658
108894798,2719,enothereska,2017-03-30T10:46:16Z,but couldn't that lead to cases when `streamthread` is given one type of time and `streampartitionassignor` another type of time? i'm not sure what that would mean. i think they should use the same time type.,0,0.976576566696167
108895304,2719,dguy,2017-03-30T10:49:18Z,"in tests that could happen. i guess there are other `public final` fields (which i don't agree with), so whatever",0,0.9682172536849976
109059440,2719,guozhangwang,2017-03-30T23:13:34Z,i'd agree with damian to have this time object pass long the hierarchy than passing it from the thread directly to the internal topic manager. i would not worry too much about passing in different objects since both of them are internal topics so the only place we may directly pass the object is in unit tests.,0,0.9556368589401245
109060051,2719,guozhangwang,2017-03-30T23:18:48Z,"for suspended tasks, could the closure process be simpler? for example we have already closed the topology as well as committing the states, etc. ditto below.",0,0.9907003045082092
109073610,2719,mjsax,2017-03-31T01:39:01Z,"nit: i think the error message does not read well: `not enough brokers 2 for replication factor 3` better: `found only 2 brokers, but replication factor is 3. decrease replication factor for internal topics via streamsconfig parameter ""replication.factor"" or add brokers to your cluster.`",0,0.9681732058525085
109073704,2719,mjsax,2017-03-31T01:40:35Z,should we increase backup time if we keep retrying?,0,0.983324408531189
109073754,2719,mjsax,2017-03-31T01:41:19Z,as above?,0,0.9936766028404236
109074329,2719,mjsax,2017-03-31T01:49:23Z,why do we need a `node` now but not before?,0,0.9842190146446228
109074528,2719,mjsax,2017-03-31T01:52:08Z,didn't we change the default values for both already?,0,0.992603600025177
109074584,2719,mjsax,2017-03-31T01:52:51Z,add `final` to `properties props = new properties();` and method parameters. also all variables used farther down.,0,0.9957668781280518
109074646,2719,mjsax,2017-03-31T01:53:37Z,rename `props` to `producerprops` ;),1,0.7068597674369812
109074740,2719,mjsax,2017-03-31T01:54:38Z,not sure what's happening here. but `6` does still not seem to be large. why change it in the first place?,0,0.8335199356079102
109075186,2719,mjsax,2017-03-31T02:01:04Z,"we have replication factor 3 and min.in.sync.replicas 2 -- it might happen that if 2 brokers fail, a topic does not have enough in-sync-replicates anymore?",0,0.9910447597503662
109114808,2719,enothereska,2017-03-31T08:47:50Z,"i could add an extra method in streamtask.java to close the rest, not the topology. however, this only happens at shutdown, not sure it's worth it. so it could be simpler, but with more lines of code.",0,0.8286609053611755
109115463,2719,enothereska,2017-03-31T08:51:36Z,"traditionally we don't do anything clever with backoff times throughout the code. it can get complicated, e.g., by how much to increase in each step.",0,0.9493725299835205
109115631,2719,enothereska,2017-03-31T08:52:28Z,"because now in `makeready` we check the number of brokers in metadata, whereas before we didn't.",0,0.9926143884658813
109117043,2719,enothereska,2017-03-31T09:01:02Z,we decided that changing the internal default values required a kip. for now just changing the test values in this pr.,0,0.9939185380935669
109117552,2719,enothereska,2017-03-31T09:03:53Z,"this is effectively the timeout of the test. with higher replication factor for the internal topics, and with acks to ""all"" i noticed that the test takes slightly longer to run, so upped this value.",0,0.992249608039856
109117773,2719,enothereska,2017-03-31T09:04:50Z,"yeah that's fine. this just means that when there is no failure, keep 2 replicas in sync. when there are 2 failures, the system should still be up and running.",0,0.9537370800971985
109203917,2719,mjsax,2017-03-31T16:54:28Z,"depends on the use case: either add the same value each time, or double up. we this when waiting for locks to get released on rebalance already: [a link]",0,0.9936836957931519
109208623,2719,guozhangwang,2017-03-31T17:19:31Z,makes sense.,0,0.9735017418861389
109279169,2719,enothereska,2017-04-01T06:40:45Z,i'm not ready for this yet. we can revisit backoffs in all the streams code and see how the networking client code has done them. also we should tie these numbers to some sort of config users can set.,0,0.9239352941513062
649771532,10822,erdody,2021-06-11T07:56:17Z,nit: or empty **if** this worker ....,-1,0.542659342288971
649777408,10822,erdody,2021-06-11T08:05:50Z,"nit: this actually collects the state of all tasks, so it's only empty if there are no tasks, right?",0,0.9815549254417419
649778786,10822,erdody,2021-06-11T08:08:00Z,nit: can use a method reference,0,0.9950078725814819
649791058,10822,erdody,2021-06-11T08:26:54Z,"there are a few comments in different places explaining the special equality implementation in restartrequest. have we considered making this a map to make it explicit that we keep the latest per connector, have a more typical equals/hashcode and avoid all the warnings?",0,0.9944158792495728
649792398,10822,erdody,2021-06-11T08:28:48Z,"just out of curiosity, any particular reason why we want to process these in connectorname order? (instead of fifo)",0,0.9883584976196289
649797930,10822,erdody,2021-06-11T08:36:52Z,nit: use a message similar to the one you corrected in line 1030?,0,0.991489052772522
649800302,10822,erdody,2021-06-11T08:40:27Z,"just wondering: could blocking the addition of new entries be a problem, considering that this method can take some time? would it be worth creating a copy of the collection to minimize the synchronized time?",0,0.9831015467643738
649803403,10822,erdody,2021-06-11T08:44:48Z,"nit: quotes around connectorname, like in the line below",0,0.9914700388908386
649806839,10822,erdody,2021-06-11T08:49:53Z,the return value is only used by tests. can we assert based on other methods calls instead?,0,0.9936721324920654
651253521,10822,erdody,2021-06-14T20:26:32Z,nit: move up so you can share with 270?,0,0.9820751547813416
651262244,10822,erdody,2021-06-14T20:40:49Z,nit: `boolean.parseboolean()`,0,0.9943419694900513
651291606,10822,kpatelatwork,2021-06-14T21:30:52Z,done,0,0.8682363629341125
651291754,10822,kpatelatwork,2021-06-14T21:31:09Z,fixed,0,0.920660674571991
651291878,10822,kpatelatwork,2021-06-14T21:31:22Z,fixed,0,0.920660674571991
651292365,10822,kpatelatwork,2021-06-14T21:32:16Z,fixed,0,0.920660674571991
651292417,10822,kpatelatwork,2021-06-14T21:32:22Z,fixed,0,0.920660674571991
651293447,10822,kpatelatwork,2021-06-14T21:34:20Z,"i agree it is used by only tests but it made the tests more clear rather than relying on mock verify. i added a comment to the code to make this clear, please let me know if the new changes looks good.",1,0.888796865940094
651296666,10822,kpatelatwork,2021-06-14T21:40:35Z,we can't make a copy because we are doing pollfirst and its removing it out of set ` while ((request = pendingrestartrequests.pollfirst()) != null) { ` the whole method synchronization was done deliberately to keep the code simple. one more point is that this just triggers the start of connector/tasks and real start happens in another thread so this should be pretty fast.,0,0.9922073483467102
651298044,10822,kpatelatwork,2021-06-14T21:43:12Z,"no particular reason, treeset was a navigableset implementation that came to my mind. but i like your above idea of using a map and simplifying the code, let me work on it.",1,0.740203320980072
651300080,10822,kpatelatwork,2021-06-14T21:46:49Z,"good idea, fixed",1,0.9936415553092957
651323170,10822,kpatelatwork,2021-06-14T22:38:07Z,"fixed, could you please check to see if it looks good now?",0,0.9311693906784058
651323500,10822,kpatelatwork,2021-06-14T22:38:54Z,new implementation with iterator makes this explicit. could you please check to see if it looks good now?,0,0.9675033092498779
651508714,10822,erdody,2021-06-15T07:09:53Z,"the main problem is that you're testing the code you added for tests, not that the actual actions are executed. unless you're also have coverage to verify that there's correspondence between the different results and the actions that need to happen in each case.",0,0.9046190977096558
651509086,10822,erdody,2021-06-15T07:10:23Z,"afaics, since all accesses are synchronized, this doesn't need to be concurrent.",0,0.989937424659729
651852657,10822,kpatelatwork,2021-06-15T14:32:29Z,fixed,0,0.920660674571991
651854001,10822,kpatelatwork,2021-06-15T14:33:51Z,i removed the return and fixed the tests just to power mock verify. anyway i have integration tests so i partially agree that the return values were just me being paranoid in testing.,0,0.97772216796875
652845546,10822,rhauch,2021-06-16T16:16:53Z,can we replace these two methods with the following? [code block],0,0.9960892200469971
652846118,10822,rhauch,2021-06-16T16:17:35Z,nit: [code block],0,0.9919844269752502
652848315,10822,rhauch,2021-06-16T16:20:31Z,"this method name is very similar to the `includetasks()` getter method. wdyt about changing to `istaskincluded(taskstatus status)` instead, to more clearly differentiate that it's not merely a getter? if so, then `includeconnector(...)` could be renamed to `isconnectorincluded(connectorstatus status)`, too.",0,0.9937708973884583
652850147,10822,rhauch,2021-06-16T16:22:43Z,nit: [code block],0,0.9919844269752502
652852357,10822,rhauch,2021-06-16T16:25:39Z,"if the `dorestartconnectorandtasks(..)` method fails, then we won't remove the restart request and the herder will never make progress. should we protect this call a bit more with a try-catch-finally block?",0,0.9902516603469849
652854145,10822,rhauch,2021-06-16T16:28:00Z,"another option might be to dequeue (from the map) the restart requests in a synchronized block, and then perform those restarts outside of the synchronized block. this would at least minimize the work being done within the synchronized block to be just iteration and removal, lessoning the likelihood of blocking new requests. wdyt?",0,0.9907350540161133
652858133,10822,rhauch,2021-06-16T16:33:15Z,"of course, another option is to use a concurrent queue rather than a map, and deduplicate the requests only upon processing. for example, this method could dequeue all of them to a collection, replacing any earlier request with a more recent one, and then restart all of the deduplicated requests (ideally in the same order in which they were received). i'm not sure this is actually simpler. or, did you consider using a concurrentmap to avoid synchronization? that may be the least complicated way to remove the synchronization and yet require very few changes to the existing logic.",0,0.9861798882484436
652858998,10822,rhauch,2021-06-16T16:34:22Z,let's avoid more than 1 adjacent blank line: [code block],0,0.9923513531684875
652860987,10822,rhauch,2021-06-16T16:37:08Z,"i assume the choice of info here was intentional. if not, at what log level do we really want this log message? if so or if we do want this at info level, then maybe we should modify the `restartrequest.tostring()` method to be a little more user friendly (e.g., `restart request for connector %s (...)`). and would it help to mention here that it's being enqueued? maybe: [code block]",0,0.9899489879608154
652872036,10822,rhauch,2021-06-16T16:52:13Z,nice! i didn't recall that `` exists. but we should not have a space between that annotation and the open parenthesis: [code block],1,0.9935708045959473
652875494,10822,rhauch,2021-06-16T16:55:46Z,"won't `string.valueof(boolean)` be used here, and thus we're unboxing the `boolean` instance here? if there is a default value, then will `includetasks` and `onlyfailed` both always be non-null, and if so then couldn't we just use `boolean.tostring()` here?",0,0.9924250841140747
652877090,10822,rhauch,2021-06-16T16:57:28Z,maybe add a comment here: [code block],0,0.9948510527610779
652881239,10822,rhauch,2021-06-16T17:03:05Z,"nit: i wonder if these log messages would be a bit easier to search and filter if they were reworded slightly: [code block] if you agree, then maybe also make similar changes to the corresponding log messages in the `distributedherder`.",0,0.9850450158119202
652883217,10822,rhauch,2021-06-16T17:05:57Z,"should we use a constant for this? i see that it's not really a pattern in the existing code, but maybe we should still do that here.",0,0.9903516173362732
652884464,10822,rhauch,2021-06-16T17:07:48Z,"wdyt about being a bit more tolerant of missing keys? for example, we could use defaults here.",0,0.9853154420852661
652885234,10822,rhauch,2021-06-16T17:08:52Z,let's avoid more than one adjacent blank lines. [code block],0,0.9934017062187195
652886935,10822,rhauch,2021-06-16T17:10:25Z,"""both"" what?",0,0.958314836025238
652887340,10822,rhauch,2021-06-16T17:10:45Z,"again, ""both"" what?",0,0.955252468585968
652888065,10822,rhauch,2021-06-16T17:11:27Z,can we be more explicit in the test method names about what this test does?,0,0.9917603731155396
652888765,10822,rhauch,2021-06-16T17:12:32Z,what does this mean:,0,0.9888119697570801
652890167,10822,rhauch,2021-06-16T17:14:33Z,"iiuc, we are not actually testing that the connector and task instances are distributed across different worker nodes, though it is likely to happen given the light connector load on the connect cluster.",0,0.9879091382026672
652891026,10822,rhauch,2021-06-16T17:15:44Z,"how long does it take for all of the tests in this it to run, say locally? iiuc, we're setting up a new kafka cluster and connect cluster for every test. how difficult would it be to share the same kafka and connect cluster across most of the tests?",0,0.9895943403244019
652921473,10822,kpatelatwork,2021-06-16T17:55:54Z,"could you guide me if there a predictable way to spread the tasks then i can change the test? i found that when i gave numworkers>1 most of the time they were distributed that's how i found an npe bug and had to use in the api. i am using numworkers=1 in other test to have a deterministic number of task restarts, whenever i had numworkers>1 the tasks would get restarted more than what i expect due to rebalance on worker nodes coming up.",0,0.9871048927307129
652923058,10822,kpatelatwork,2021-06-16T17:57:09Z,its on average 7-11sec per test (the ones with 35 sec are due to waiting in noop cases) ![a link] let me see if i can find a way to share and if it reduces the time.,1,0.5147484540939331
653046083,10822,kpatelatwork,2021-06-16T20:53:16Z,"the name was bothering me also :), the method documentation says ""determine whether the connector with the given status is to be restarted."" wdyt about changing it to one of the below? 1. isconnectorrestartable 2. istaskrestartable or 1. shouldrestartconnector 2. shouldrestarttask",1,0.9741758704185486
653053764,10822,kpatelatwork,2021-06-16T21:06:14Z,"good point , i missed this behavior when i moved from navigablemap to a normal hashmap. let me fix it.",1,0.9822388887405396
653088343,10822,kpatelatwork,2021-06-16T22:07:20Z,fixed,0,0.920660674571991
653089179,10822,kpatelatwork,2021-06-16T22:09:03Z,fixed and changed all test names to be explicit,0,0.9934201836585999
653089598,10822,kpatelatwork,2021-06-16T22:09:58Z,"thanks for noticing this, its my bad the ide method extract left the comment and i didn't notice.",-1,0.9334377646446228
653089924,10822,kpatelatwork,2021-06-16T22:10:42Z,fixed,0,0.920660674571991
653115877,10822,rhauch,2021-06-16T23:17:29Z,either work for me.,0,0.9833162426948547
653116810,10822,rhauch,2021-06-16T23:20:07Z,"two things. first, these multi-worker its are not necessarily testing the requests getting forwarded to the leader, but that's really hard to do. second, it might be good to try to send the request to a worker that is not running any instances to be restarted. one way to do that is to run 1 more worker than the total number of `connector` and `task` instances for the connector being restarted. though i'm not sure this adds a lot of value given the others unit tests.",0,0.7635753750801086
653117252,10822,rhauch,2021-06-16T23:21:18Z,"yeah, that's already a good portion of the total time to run the connect unit and integration tests. it'd be great if we could avoid increasing the build times by that much.",0,0.6931612491607666
653117875,10822,kpatelatwork,2021-06-16T23:23:03Z,"good idea, i fixed it",1,0.9937375783920288
653118611,10822,kpatelatwork,2021-06-16T23:25:12Z,"good idea , i fixed it. i added a default constant in kafkaconfigbackingstore class, the only thing i was unsure of if i should use the same default constant in connectorsresource class api or not. they seem to be 2 different world and i didn't wanted to introduce a dependency between the classes as it would expose unwanted details so right now default=false is in 2 places. please let me know if you have a better idea to solve this or if it's ok to have it copied the default value in 2 places.",1,0.9876732230186462
653119839,10822,kpatelatwork,2021-06-16T23:28:46Z,"thanks, i went with shouldxxx and it's committed, the code looks much better now.",1,0.9784387946128845
653174069,10822,kpatelatwork,2021-06-17T02:10:54Z,"this was a good find, i just refactored the code, and this saved 2 min ![a link]",1,0.9968647360801697
653681672,10822,rhauch,2021-06-17T15:32:38Z,nit: would a delimiter here help? [code block],0,0.9930481910705566
653687374,10822,rhauch,2021-06-17T15:39:33Z,"this method is where the worker restarts connector and task instances assigned to it. lines 1153 and 1155, along with the `assignedidstorestart` are really the only evidence that this method does that. can we modify the comments and log messages in this method to make that more evident, and maybe add javadoc?",0,0.9942936301231384
653698313,10822,rhauch,2021-06-17T15:52:11Z,"can you confirm that the methods called in this block of logic handle failures? for example, the `worker.stopandawaitconnector(...)` method waits only up to 5 seconds, and we have no visibility into whether the connector was actually stopped in that time or we timed out. if we timed out, should we restart the connector, or should we abort this method and try again later? if we retry again later, it seems like it's okay to try stopping an already stopped connector, but it'd be good to double check that. same questions about stopping the tasks. we may need to modify the `stopandawait...(...)` methods to add a callback that will allow us to better track what was actually stopped. and where this method is called we may need to handle the case where this restart was not completed and re-enqueue it for restart.",0,0.9857947826385498
653701944,10822,rhauch,2021-06-17T15:56:20Z,"one thing about using a map is that we're always saving the last restart request, rather than the restart request that will (potentially) have the greatest impact. consider two restart requests are submitted at about the same time: 1. restartrequest 1 requests that everything is restarted (onlyfailed=false) for connector foo 2. restartrequest 2 requests that only failed instances are restarted (onlyfailed=true) for connector foo if this method saw restartrequest 2 before restartrequest 1, then everything would be restarted as expected. but if this method saw restartrequest 1 first, then only the failed tasks would be restarted. seems like we should keep the most impactful one: restartrequest 1 in this example. wdyt?",0,0.9864307641983032
653705258,10822,rhauch,2021-06-17T16:00:11Z,"excellent! iiuc, the tests are only using 2 differently-sized clusters (1 node and 4 nodes), which is good because it minimizes the startup time. can you confirm that statement is true? it seems like there are three total methods that take more than 30 seconds -- any reduction in duration on any of those three will have a very direct impact.",1,0.991929292678833
653745712,10822,kpatelatwork,2021-06-17T16:49:20Z,"and i changed the implementation to dequeue from map and perform the restart outside the synchronized block, could you please review to see if it looks ok now?",0,0.9880298972129822
653749526,10822,kpatelatwork,2021-06-17T16:52:53Z,"this is an excellent suggestion, i just added this test based on the above discussion [a link] and now feel more confident that we are testing the distributed behavior of the feature. here is a sample response i copied from the above test output and we can see the call from the test was made on a worker not running the task or connector instance.",1,0.992572009563446
653753526,10822,kpatelatwork,2021-06-17T16:56:42Z,"i agree and i fixed it as part of recent tests changes, ` private static final string connector_name_prefix = ""conn-""; `",0,0.989094078540802
653815012,10822,kkonstantine,2021-06-17T18:02:00Z,"seeing above, seems that this might as well be called `onrestart`. it's only naming but still would be nice to maintain consistency",0,0.960961639881134
653819933,10822,kpatelatwork,2021-06-17T18:09:43Z,"i went with a different sleep duration and that cut the times by 1minute 15 sec ![a link] [a link] i chose 5sec because locally the test that sets up the cluster takes around 5 sec to do it and most test after they setup the cluster finishes in <300ms, request propagation and restart isn't taking long but thats my local machine and i chose to do 15 times the wait in case cloud or other developer machines are slow. could you please review to see if you agree with the fix as another idea is to reduce it to 1 sec?",0,0.8720923066139221
653854373,10822,kpatelatwork,2021-06-17T18:57:12Z,"i agree and implemented it, could you please review the below commit and see if it suffices? [a link]",0,0.9196836352348328
654043932,10822,kpatelatwork,2021-06-17T23:19:44Z,+1 i just fixed them in both classes,0,0.9206548929214478
654060352,10822,kpatelatwork,2021-06-18T00:10:56Z,"i did confirm that both stop and await for task and connector does connector.cancel() and task.cancel() if it timed out. i added try/catch in start connector/tasks [a link] however, i am not sure about re-enqueue as it can lead to infinite tries, and adding retries may complicate things so need some guidance. could you please review to see if it looks a bit better now?",0,0.9322602152824402
654741212,10822,kpatelatwork,2021-06-19T03:30:22Z,the new times after checking that api response didn't return any restarting state is 13 sec and 10 sec out of it is in bringing up kafka cluster. ![a link],-1,0.9571673274040222
654741381,10822,kpatelatwork,2021-06-19T03:32:23Z,added javadoc and cleaned some logs and there are logs in the called methods so didn't added new logs,0,0.9951512813568115
655408049,10822,kpatelatwork,2021-06-21T14:06:30Z,"we can add a retrycount in the restartrequest and start with a default of 5 and decrement it every time we re-enqueue. if the tick() happens every second then we can exhaust the retries pretty fast so we may need to add backoff with a delay before processing the request. adding retry logic to this pr can make the pr complex, i would vote for adding it in a separate pr.",0,0.9917320013046265
655658286,10822,rhauch,2021-06-21T19:45:48Z,"i would agree. we're not sure whether we need this behavior yet, so i'm +1 for keeping it simple in this pr and adding it in the future only if we discover a need for it.",1,0.9146113991737366
655660680,10822,rhauch,2021-06-21T19:49:52Z,let's mention the natural sort order.,0,0.9920552372932434
655678526,10822,rhauch,2021-06-21T20:21:36Z,"the `startconnector(...)` method _should_ handle most of the errors by calling the callback, but there are still a few potential errors that could happen before the worker actually tries starting the connector. do you think this try-catch is needed, though, since the try-catch where this `dorestartconnectorandtasks(...)` is called will catch and log any unexpected change? i guess keeping this will ensure we proceed with starting the tasks, rather than failing quickly.",0,0.9899162650108337
655683692,10822,rhauch,2021-06-21T20:30:35Z,"if we were to change `pendingrestartrequests` to a `concurrentmap`, then we could use the `compute(...)` functionality that actually would work even if we removed the synchronization. i wonder if this is a bit more readable (even though strictly speaking we don't need concurrent access). wdyt? [code block]",0,0.9888672232627869
655688374,10822,rhauch,2021-06-21T20:38:42Z,what do you think about returning `optional ` here (if every worker has at least one instance for the given connector) rather than throwing an exception?,0,0.9883167147636414
655749684,10822,kpatelatwork,2021-06-21T22:40:23Z,"i kinda agree with you but i had seen this code in below two links and it had try/catch around both starttask and startconnector . i added try/catch around starttask so if one tasks fails we can see if others atleasst succeed. the try/catch around startconnector was because i saw the pattern. but i am torn on this, if you think we should remove the try/catch on connector, i am open to removing the try/catch given its already caught at the higher layer, but imho we can keep the starttask try/catch. wdyt? [a link] [a link]",0,0.7644580006599426
655755572,10822,kpatelatwork,2021-06-21T22:55:44Z,turns out a normal hashmap also has compute so i just used it.,0,0.991536021232605
655755798,10822,kpatelatwork,2021-06-21T22:56:17Z,"i added some javadoc, could you please review and see if it looks good?",0,0.5427781343460083
655757673,10822,kpatelatwork,2021-06-21T23:01:30Z,i think it's a good idea but i saw that org.apache.kafka.connect.util.clusters.embeddedconnectcluster#endpointforresource method is using the same pattern and if i change it then i will have to change a lot of classes not related to this pr and ultimately in the test i will have to check for optional.present and do an assert. the situation for not finding a worker is rare and doing empty check and assert in all places will be a lot of copy/paste whereas throwing an exception here is centralizing this rare situation. do you think it's ok to leave it as is?,1,0.8066144585609436
655776106,10822,rhauch,2021-06-21T23:42:01Z,"yeah, i think it's actually fine the way it is: with the try-catrch around `startconnector(...)`, because that helps us catch any problem _at that point_ and allows us to continue starting the tasks. if we were to remove this try-catch around `startconnector(...)`, then any problem would cause us to return immediately from the method.",0,0.857532262802124
655778416,10822,rhauch,2021-06-21T23:48:33Z,"well, the `embeddedconnectcluster` is technically not an official public api for connect, but lots of connector projects use it (as intended), meaning we have to be very clear about backward compatibility. it's probably fine to keep the same pattern.",0,0.9890825748443604
655781412,10822,rhauch,2021-06-21T23:57:06Z,"it might be good to clean up the method name a bit. since it's similar to the existing `endpointforresource(...)`, maybe just add a suffix ... maybe something like `endpointforresourcenotrunningconnector()`?",0,0.9904019236564636
655781662,10822,rhauch,2021-06-21T23:57:46Z,please add descriptions of the other parameters and the return value.,0,0.9949325919151306
655885518,10822,kkonstantine,2021-06-22T05:25:50Z,"i think we can avoid this alignment style. it leaves us with significantly less space to write lambdas, etc. (another indicator is that this style is not applied elsewhere in the file). two tab stops in the line below should be fine, even if the declaration above is where it is now.",0,0.9326999187469482
655887809,10822,kkonstantine,2021-06-22T05:31:37Z,"i don't think we have examples in connect where we refer to an argument in the name of a method. maybe we don't want to change this just yet with the opportunity of the changes introduced by this feature. another observation is that we don't use `get`, `set` and possibly `build`. but since it wouldn't be obvious if it's an action or an object maybe leaving `buildrestartplan` might be fine here. (`restartplan` would be the alternative)",0,0.9866245985031128
655891458,10822,kkonstantine,2021-06-22T05:41:30Z,maybe a good idea to say that this is a plan per connector (and not a global plan). i know the javadoc of the constructor says it already but good to be at the top level too.,1,0.8316798210144043
655892160,10822,kkonstantine,2021-06-22T05:43:08Z,nit: in the constructor we refer to member fields with `this.` during initialization (even if they are not shadowed) [code block],0,0.9942366480827332
655893949,10822,kkonstantine,2021-06-22T05:47:38Z,`shouldrestarttasks` or `shouldrestartanytasks` (same recommendation as above),0,0.9899832010269165
655893977,10822,kkonstantine,2021-06-22T05:47:42Z,since this is not an action but a recommendation i think it'd be better to call `shouldrestartconnector`,0,0.9903618097305298
655894996,10822,kkonstantine,2021-06-22T05:50:00Z,not sure we should say `restart` in the method name. the object is already a `restartplan` type. so that's a bit redundant i think. `connectorstateinfo` ?,0,0.8805221915245056
655896479,10822,kkonstantine,2021-06-22T05:53:29Z,below we have a method name called `restartconnectorandtasks` implying _any_ tasks. so maybe we can skip `any` in the name.,0,0.9896261692047119
655900253,10822,kkonstantine,2021-06-22T06:02:13Z,use of `final` doesn't seem to be consistent in this method. i'd suggest skipping its addition to local variables unless we need it in lambdas.,0,0.9886953234672546
655902961,10822,kkonstantine,2021-06-22T06:07:49Z,any reason not to use primitive types? [code block],0,0.9895548820495605
655904820,10822,kkonstantine,2021-06-22T06:11:50Z,do we have to call it snapshot? is `startsandstops` enough? [code block],0,0.9948810338973999
655905352,10822,kkonstantine,2021-06-22T06:13:02Z,i found the name a bit overloaded and added a suggestion below. you think we could make it a bit simpler?,0,0.9788523316383362
656348082,10822,kpatelatwork,2021-06-22T15:41:56Z,the defaults are used in code like below and using primitive would lead to an extra boxing,0,0.9919853210449219
656356700,10822,kpatelatwork,2021-06-22T15:50:11Z,"excellent suggestion, naming is indeed hard problem and i had the same feeling this is overloaded. i applied your suggestion.",1,0.9932286143302917
656356999,10822,kpatelatwork,2021-06-22T15:50:29Z,fixed,0,0.920660674571991
656357145,10822,kpatelatwork,2021-06-22T15:50:38Z,thanks for catching this,1,0.9224101305007935
656357635,10822,kpatelatwork,2021-06-22T15:51:09Z,thanks for catching this.,1,0.582872211933136
656358121,10822,kpatelatwork,2021-06-22T15:51:45Z,renamed to buildrestartplan as per your suggestion.,0,0.9923761487007141
656358424,10822,kpatelatwork,2021-06-22T15:52:04Z,"good observation, i fixed it.",1,0.9846014976501465
656633158,10822,kpatelatwork,2021-06-22T22:49:51Z,fixed documentation and renamed the method.,0,0.9944690465927124
656633775,10822,kpatelatwork,2021-06-22T22:51:29Z,"good idea, i renamed the method.",1,0.9769460558891296
656652231,10822,kpatelatwork,2021-06-22T23:39:56Z,fixed,0,0.920660674571991
656653569,10822,kpatelatwork,2021-06-22T23:42:54Z,i think we should keep it because in the caller code plan.connectorstateinfo() conveys its the current state but plan.restartconnectorinfo() conveys the intent that its the stateinfo with restart state. i know its not the best name :( cc: if he has any better suggestions for the name.,-1,0.9951743483543396
656654293,10822,kpatelatwork,2021-06-22T23:44:45Z,"and i renamed the methods for shouldxxx suggestion. for removing any in the name, i think we should keep it in the name because plan.shouldrestarttasks() in caller code conveys the intent it would restart all tasks but plan.shouldrestartanytask conveys it would restart at least one task. i know its again not the best name. wdyt if we rename it to shouldrestartatleastonetask, it was too verbose that's why we had picked any?",0,0.9569382667541504
657118416,10822,rhauch,2021-06-23T13:46:50Z,"this is subtly different than a normal `connectorstateinfo`, so keeping the current name may be a bit more clear in the context where this method is used, even if it's less conventional.",0,0.9883430600166321
657148983,10822,kpatelatwork,2021-06-23T14:18:16Z,renamed to shouldrestarttasks,0,0.991607666015625
660274546,10822,kkonstantine,2021-06-29T04:38:50Z,is there any reason we are not adding these new methods in the `taskstatus.listener` interface? in any case we should add javadoc to the base declaration (interface or class methods).,0,0.9942190647125244
660275673,10822,kkonstantine,2021-06-29T04:42:29Z,"nit: the ternary operator can be used (`?:`) as below, unless you're not a fan. [code block]",0,0.9862419366836548
660276986,10822,kkonstantine,2021-06-29T04:46:34Z,"a bit confusing that a second assignment follows if the `if` statement is true. i'd also call the variable `taskstate` (as opposed to `connectorstate` above) ternary can be used here as well: [code block] (as with any suggestion from github, please check it compiles and conforms to the style)",0,0.6675174832344055
660280566,10822,kkonstantine,2021-06-29T04:57:05Z,no problem.,0,0.7675672173500061
660281788,10822,kkonstantine,2021-06-29T05:00:50Z,something like? [code block] breaking this long statement doesn't make it much less long i guess.,0,0.9727731347084045
660283562,10822,kkonstantine,2021-06-29T05:06:17Z,"[code block] ? (seems a bit more common way to say it, but i don't have a strong opinion)",0,0.9211223721504211
660290194,10822,kkonstantine,2021-06-29T05:25:47Z,"i see we've been verbose in similar logic above before, but maybe we can improve on that a bit, at least in new code. here's another suggestion: [code block]",0,0.9789669513702393
660291164,10822,kkonstantine,2021-06-29T05:28:23Z,"following up on the comment above, here's how we could write this and avoid autoboxing/unboxing while using the more readable primitives. [code block]",0,0.9932299852371216
660291287,10822,kkonstantine,2021-06-29T05:28:45Z,similar suggestion as above,0,0.9930245876312256
660291760,10822,kkonstantine,2021-06-29T05:29:56Z,i agree the conversion is on a frequently used path. but maybe it's the code below that can be re-written to avoid both autoboxing and unboxing (when it's not required),0,0.9845404028892517
660293584,10822,kkonstantine,2021-06-29T05:34:43Z,"this misuse might have originated because above, specifically for tasks, `null` is actually a valid value (tombstone/delete), which is not the case here.",0,0.967502772808075
660295568,10822,kkonstantine,2021-06-29T05:40:09Z,since we print the warning inside `recordtorestartrequest` we can probably avoid the early return with: [code block],0,0.9936797618865967
660296712,10822,kkonstantine,2021-06-29T05:43:05Z,"btw, all other log statements are `log.error` elsewhere. should we remain consistent with that, instead of using `log.warn` just here? the issues seem similar above.",0,0.9903958439826965
660301592,10822,kkonstantine,2021-06-29T05:55:31Z,dependents in the implementation of `startandstoplatch` seems to overload the meaning of `null` with a check. but it actually doesn't seem to matter. the call is equivalent to passing an empty list. should we simplify that with something like: [code block] ?,0,0.9892008304595947
660301819,10822,kkonstantine,2021-06-29T05:56:03Z,see comment above on whether `null` matters.,0,0.9925405383110046
660303274,10822,kkonstantine,2021-06-29T05:59:36Z,"does it make sense to skip, given that it's called below? (i hope i'm not missing something)",0,0.8501506447792053
660309326,10822,kkonstantine,2021-06-29T06:13:53Z,nit: similar style as elsewhere in this file [code block],0,0.9934117197990417
660311654,10822,kkonstantine,2021-06-29T06:18:53Z,nit: type inference is nice ... [code block],1,0.9803019165992737
660315005,10822,kkonstantine,2021-06-29T06:25:58Z,i'd call it `plan` here.,0,0.9907165169715881
660315335,10822,kkonstantine,2021-06-29T06:26:38Z,safe to skip the declaration here. [code block],0,0.9945699572563171
660315588,10822,kkonstantine,2021-06-29T06:26:59Z,nit: extra [code block],0,0.9906437993049622
660320316,10822,kkonstantine,2021-06-29T06:36:25Z,same as the connector call above [code block],0,0.9954332709312439
660781818,10822,kpatelatwork,2021-06-29T16:29:13Z,fixed,0,0.920660674571991
660782579,10822,kpatelatwork,2021-06-29T16:30:10Z,i agree and i fixed it like you suggested.,0,0.6998461484909058
660834568,10822,kpatelatwork,2021-06-29T17:42:17Z,"the plan may or may not be present, that's why i was calling it maybeplan",0,0.9827597141265869
660836387,10822,kpatelatwork,2021-06-29T17:45:00Z,"we are logging an error if we are rejecting the request due to an invalid type, but in this particular case as we are defaulting the missing fields, that's why the warn.",0,0.9912387728691101
660864346,10822,kpatelatwork,2021-06-29T18:26:17Z,"i added the missing documentation. i didn't add the onrestart method to listener because it didn't felt it should be a part of the task lifecycle controlled by the worker. earlier the method was called recordrestart but based on a review comment, it was renamed it to onrestart, do you think we should rename it back to recordrestart. the original intent of this method was to just record the state change.",0,0.9917932152748108
660866556,10822,kpatelatwork,2021-06-29T18:29:36Z,fixed as per your suggestions.,0,0.9934552311897278
660867874,10822,kkonstantine,2021-06-29T18:31:31Z,did you compare it with other methods? my understanding is that `ondelete` is the same in that respect and exists on the `listener` as well. but i might have skimmed too quickly through the code,0,0.991817057132721
660868474,10822,kkonstantine,2021-06-29T18:32:28Z,didn't notice. thanks. makes sense then,1,0.9795459508895874
660870565,10822,kkonstantine,2021-06-29T18:35:40Z,"we might be too precise here. as we discussed elsewhere, baking the meaning of the type in every variable name might be too verbose. it's a plan, and the fact that is optional means that there might be one or it might not. that's how i'd read it. the other use of `maybeplan` below is harder to avoid. feel free to keep it consistent here with what you have below. again, my point is not to bake type meaning in the variable names. i feel this keeps things simpler.",0,0.9397332668304443
660925249,10822,kpatelatwork,2021-06-29T20:02:52Z,after your latest explanation it makes sense to rename it to keep it simple. thanks for guiding me. i have renamed it.,1,0.9856825470924377
660953271,10822,kpatelatwork,2021-06-29T20:48:53Z,you are right. do you mind if we do this work in a follow-up pr? the reason i ask is because if we add it to the listener then it becomes part of the interface and this would require me to retrofit the listener event into the old restarttask and restartconnector api for backward compatibility reasons and it can be big change to this already big pr.,0,0.9788646697998047
661028655,10822,kpatelatwork,2021-06-29T23:28:38Z,i moved it to the lisetner interface in [a link] could you please check to see if it looks good.,0,0.9724013805389404
1579221285,15640,cadonna,2024-04-25T10:08:01Z,"why do you use a timer here? the `asynccommit()` does not throw any timeout exception, does it? if you need to pass the timer to the `commitevent` or further up the class hierarchy then you can create the timer in the constructor of `asynccommitevent` or even further up the class hierarchy.",0,0.9926800727844238
1579239807,15640,cadonna,2024-04-25T10:24:10Z,"why should those two fields ever be `null`? they seem necessary for the consumer to function correctly. if my statement is correct, the constructors should ensure that those fields are never `null`.",0,0.9847880601882935
1579264527,15640,cadonna,2024-04-25T10:45:03Z,"i have two questions here: 1. why is this code not in `completableevent`? 2. why do you not keep the timer in a object field? regarding 2, i have the feeling this pr contains code that already exist in the timer. you could have a method on `completableevent` that checks for the expiration without exposing the timer. something like `isexpired()` or `istimedout`.",0,0.9762799143791199
1579269984,15640,cadonna,2024-04-25T10:49:30Z,could you export this lines into a method `processapplicationevents()` or similar. i think it makes the code more readable.,0,0.9892037510871887
1579275627,15640,cadonna,2024-04-25T10:54:36Z,do we need this comment? i am not a big fan of inline comments in general. all the information about the behavior in the comment should be clear from the corresponding unit tests. i do not think we need the references to the legacy consumer. once the legacy consumer is gone we need to remove these references which is work that we can avoid by just not writing those comments.,0,0.9494115114212036
1579283124,15640,cadonna,2024-04-25T11:00:50Z,i think that is clear from the code. we do not need the comment.,0,0.9878283739089966
1579292380,15640,cadonna,2024-04-25T11:09:42Z,"here i have a similar comment as with `asynccommitevent`, i would move the creation of the timer into the constructor of `consumerrebalancelistenercallbackneededevent`.",0,0.9936615228652954
1579314894,15640,cadonna,2024-04-25T11:30:24Z,same questions as above.,0,0.9878294467926025
1579322300,15640,cadonna,2024-04-25T11:36:39Z,"nit: imo, this is more readable, but feel free to leave it if you do not share my taste. [code block]",0,0.7306011915206909
1579324613,15640,cadonna,2024-04-25T11:38:47Z,wouldn't it be safer to not have a default here as a reminder for closing.,0,0.9724494814872742
1579733831,15640,kirktrue,2024-04-25T15:45:14Z,"yeah, i went back and forth on this a few times :winking_face: ultimately i wanted to force the caller to be explicit about its timeout intention, vs. having it implicitly ""hidden"" away in the event hierarchy. also, to create a `timer` in the event constructor, we'd have to pass in a `time` object (`time.timer(long.max_value)`), which seemed a bit obtuse, so :man_shrugging:",0,0.61418217420578
1579735209,15640,kirktrue,2024-04-25T15:46:22Z,"they're only `null` if there was an error in the constructor. the constructor's `finally` block calls `close()`, so we need to handle the case where the consumer wasn't fully constructed before it's closed.",0,0.9906450510025024
1579756071,15640,kirktrue,2024-04-25T16:01:51Z,"i'm happy to reword the comment and clean it up, but the lines that follow that comment are the raison d'tre of this change. it's very subtle and easy to miss, hence the call-out.",1,0.7976628541946411
1579760563,15640,kirktrue,2024-04-25T16:05:28Z,i'll look into how to do this in a way that i don't find too ugly :winking_face:,1,0.7903888821601868
1579864626,15640,kirktrue,2024-04-25T17:22:11Z,"`completableevent` is an interface, but i could see if i can put a static method in there to keep the logic in one place.",0,0.9933737516403198
1579865601,15640,kirktrue,2024-04-25T17:23:08Z,"yeah, i can see your point. tbh, i'm not sure if that's even needed still :thinking_face:",1,0.9864628911018372
1579884608,15640,kirktrue,2024-04-25T17:40:17Z,added a brief comment. ptal.,0,0.9913353323936462
1579884758,15640,kirktrue,2024-04-25T17:40:25Z,done.,0,0.9897913336753845
1579885684,15640,kirktrue,2024-04-25T17:41:16Z,split into a separate method to accommodate the reworded comment.,0,0.99068284034729
1579885847,15640,kirktrue,2024-04-25T17:41:24Z,removed.,0,0.9612457156181335
1579897029,15640,kirktrue,2024-04-25T17:51:50Z,"for point 1, i created a new method named `calculatedeadlinems` that moves this code into one place. for point 2, there is no `timer` in the event because `timer` is not thread safe, and events cross the application/background thread boundary. i did not want to expose the `timer` in the event to avoid its possible usage from the background thread.",0,0.9926735758781433
1579899408,15640,kirktrue,2024-04-25T17:54:02Z,"it turns out `close()` wasn't needed any more, so i just removed it :man_shrugging:",0,0.42937928438186646
1579914824,15640,kirktrue,2024-04-25T18:04:46Z,i was able to refactor the code to eliminate the need for passing in a `timer`.,0,0.9830495119094849
1579915561,15640,kirktrue,2024-04-25T18:05:12Z,i was able to refactor the code and this is now sans `timer` again.,0,0.990695595741272
1580785461,15640,cadonna,2024-04-26T09:53:28Z,nit: could you please move this parameter to the previous line?,0,0.9946039319038391
1580790248,15640,cadonna,2024-04-26T09:57:24Z,i think you do actually not need the timer in this method at all. you could pass a deadline to the event.,0,0.976945161819458
1580879040,15640,cadonna,2024-04-26T11:13:20Z,the timer is not used anywhere else. maybe a deadline for this event would be simpler.,0,0.9902740120887756
1580883395,15640,cadonna,2024-04-26T11:18:18Z,also here the timer is only used in the event. using a deadline would be simpler.,0,0.9924361109733582
1580884538,15640,cadonna,2024-04-26T11:19:34Z,the timer is only used by the event. maybe a deadline is simpler.,0,0.9895557761192322
1580885372,15640,cadonna,2024-04-26T11:20:30Z,the timer is only used in the event.,0,0.9931723475456238
1583451774,15640,kirktrue,2024-04-29T17:28:47Z,"per the above, i added `completableevent.calculatedeadlinems()` to keep the code in a shared location.",0,0.9921417236328125
1583452334,15640,kirktrue,2024-04-29T17:29:14Z,"yep, i made the change to use the deadline directly (vs. a `timer`).",0,0.9914986491203308
1583452722,15640,kirktrue,2024-04-29T17:29:36Z,agreed. using the deadline directly instead of a `timer`.,0,0.9912419319152832
1583452937,15640,kirktrue,2024-04-29T17:29:46Z,changed.,0,0.9680466055870056
1583520696,15640,kirktrue,2024-04-29T18:20:21Z,removed use of `timer` in favor of calculating the deadline from the `time` and `timeout` directly.,0,0.9907588958740234
1583520759,15640,kirktrue,2024-04-29T18:20:26Z,removed use of `timer` in favor of calculating the deadline from the `time` and `timeout` directly.,0,0.9907588958740234
1585003046,15640,lianetm,2024-04-30T15:10:56Z,"couldn't we make that the same add operation removes the event whencomplete? seems tighter that the same operation that adds the event ensures that it's removed (if completes), and then it's simpler here, when we only need to care about maintaining the uncompleted (which seems like the core responsibility of the reaper). also that would mean that we don't rely on calls to reap to remove events that complete in time.",0,0.9919271469116211
1585004533,15640,lianetm,2024-04-30T15:11:39Z,"responsible for events that ""are being processed"" right?",0,0.9602522253990173
1585005659,15640,lianetm,2024-04-30T15:12:14Z,"typo ""we are""",0,0.9821911454200745
1585035057,15640,lianetm,2024-04-30T15:28:16Z,"what about renaming this to be explicit about what we process here? it gets confusing given that at this consumer level we're dealing with app events and background events. `processbackgroundevents` feels pretty clear, and i know there is already another one called liked that, but the other one is more about `awaitfutureprocessingbackgroundevents` , because it actually blocks for a time, only used from the unsubscribe, so maybe rename here and there?",0,0.8714904189109802
1585083395,15640,lianetm,2024-04-30T15:44:39Z,"regarding the func doc, typo and clarification: the app thread enqueues the event in an **application event queue** (that the background thread consumes), right? in the doc we ended up mentioning the background and app thread both adding to the background event queue.",0,0.9846807718276978
1585091606,15640,lianetm,2024-04-30T15:49:20Z,"also, regarding: it does not need to if the consumer unsubscribing does not own any partition, so just for accuracy in the example i would suggest to extend it with ""...needs to be invoked for the partitions the consumer owns""",0,0.9941938519477844
1585152310,15640,lianetm,2024-04-30T16:17:07Z,"not introduced by this pr, but reviewing this processing i don't quite see the value in all [a link] , that are even repeated further down, just for a log, when in practice this are both the happy path that will have [a link] log from the unsubscribe. a one liner with `return consumerutils.getresult(future);` would achieve the same and make the func much simpler. (even if we end up using this from a func other than the unsubscribe, seems an overkill to have all this code for something we don't need now, or know if we we'll need some day)",0,0.80838942527771
1585179214,15640,philipnee,2024-04-30T16:35:22Z,any specific reason for using linkedlist implementation?,0,0.9941008687019348
1585390985,15640,lianetm,2024-04-30T19:17:17Z,"this logic is always needed whenever we `reapincomplete`, and is currently repeated when we call it from the asyncconsumer or here, so what about we move it into the `reapincomplete`, make it receive a list of all events and internally filter the ones that are `completableevent`?",0,0.9935473799705505
1585435927,15640,lianetm,2024-04-30T19:34:00Z,is there a reason for loosing the final on the offsets map?,0,0.9873212575912476
1585466853,15640,lianetm,2024-04-30T20:05:10Z,"the reaper actually calls `completeexceptionally` with a `cancellationexception` instead of calling `completablefuture#cancel(boolean)`. unless i'm missing a subtle semantic diff they should achieve the same, but still, adding a link to `cancel` here would not be accurate i would say.",0,0.9895025491714478
1585531596,15640,philipnee,2024-04-30T21:13:12Z,can we remove this? i think the test works without it.,0,0.9930023550987244
1585537917,15640,philipnee,2024-04-30T21:20:55Z,the test should work without setting the current time to 0. so i think new mocktime(0) should be fine.,0,0.985921323299408
1585558712,15640,philipnee,2024-04-30T21:46:34Z,ditto: we probably don't need the final but it would be good to be consistent.,0,0.9782549738883972
1586499310,15640,kirktrue,2024-05-01T16:46:20Z,"my first attempt at this resulted in a `concurrentmodificationexception`, since we're removing each entry from the very same list we're iterating over :thinking_face:",-1,0.824299693107605
1586524076,15640,kirktrue,2024-05-01T17:11:43Z,"unfortunately, the term ""processed"" is sufficiently ambiguous :disappointed_face: so we're _both_ right :winking_face: here, i'm referring to events that had been passed to the `eventprocessor`'s [a link] method. which, sadly, isn't even correct, because they're being `add()`-ed to the reaper _before_ they're passed to `eventprocessor.process()` :man_facepalming:",-1,0.9757277965545654
1586537358,15640,kirktrue,2024-05-01T17:24:31Z,i reworked the comments/documentation to avoid that altogether. ptal. thanks.,1,0.9823383092880249
1586539952,15640,kirktrue,2024-05-01T17:27:19Z,fixed.,0,0.9905837774276733
1586542049,15640,kirktrue,2024-05-01T17:29:36Z,i renamed `process()` as `processbackgroundevents()`. is that ok?,0,0.9941745400428772
1586557142,15640,kirktrue,2024-05-01T17:43:16Z,"i made the documentation changes you requested and removed the logging to make the logic simpler. when you state that it seems like ""overkill to have all this code for something we don't need now, or know if we we'll need some day,"" i'm a bit confused :thinking_face: because unsubscribing may require invoking `consumerrebalancelistener` callbacks, we need a way to check and run those events that are coming from the background thread, right? i do agree that it's overkill to have this broken out as a separate method since it's only used for the `unsubscribe()` case. iirc, there was some talk of another use case for this, and it does make unit testing it easier.",-1,0.6521586179733276
1586559943,15640,kirktrue,2024-05-01T17:46:08Z,":grinning_squinting_face: yes, i went back and forth on this at least three times during development. i'll look at switching back to the approach you suggest.",0,0.8699532747268677
1586603709,15640,kirktrue,2024-05-01T18:20:32Z,pulled the logic to `reapincomplete()` as suggested.,0,0.9951980710029602
1586607598,15640,kirktrue,2024-05-01T18:23:21Z,added back `final` and changed back to `protected`. not sure how/why i changed those :thinking_face:,1,0.7687248587608337
1586620323,15640,kirktrue,2024-05-01T18:32:47Z,"good catch! i had been using `cancel()`, but noticed that the message in the exception the caller of `future.get()` later received was unhelpful. yes, `cancel()` calls `completeexceptionally(new cancellationexception())`, but i wanted the exception to include a (hopefully) meaningful message. anyhoo... i've updated the documentation to reflect that change.",1,0.9926682114601135
1586622390,15640,kirktrue,2024-05-01T18:34:25Z,"yes, because it has the `drainto()` method. however, this code is now gone, so it's moot :man_shrugging:",0,0.4632112681865692
1586626516,15640,kirktrue,2024-05-01T18:37:25Z,done.,0,0.9897913336753845
1586626597,15640,kirktrue,2024-05-01T18:37:29Z,done.,0,0.9897913336753845
1586632167,15640,kirktrue,2024-05-01T18:40:25Z,"moved the `listoffsetsevent` up to the previous line. missed it on first read, sorry :thumbs_up:",-1,0.9732666015625
1587519244,15640,cadonna,2024-05-02T11:59:47Z,"do you propose to remove completed events in `completableeventreaper#add`? if yes, to avoid the `concurrentmodifictionexception` , you could iterate over `tracked` with an iterator and remove completed events through the iterator: [code block]",0,0.9958880543708801
1587734052,15640,cadonna,2024-05-02T14:26:17Z,is this enough error handling?,0,0.9743967652320862
1587741997,15640,cadonna,2024-05-02T14:31:18Z,is this really unclear from the name `deadlinems`?,0,0.9638779759407043
1587841410,15640,cadonna,2024-05-02T15:30:00Z,"on a second thought, what is the issue with moving [code block] to `add()`? i guess, i am misunderstanding your comments.",0,0.8931008577346802
1588986665,15640,cadonna,2024-05-03T09:49:48Z,you actually do not need a timer here. the event takes the deadline and also the reaper does not use the timer.,0,0.9924672245979309
1589007012,15640,cadonna,2024-05-03T10:07:31Z,"also here, i do not think you need this timer.",0,0.9928257465362549
1589007924,15640,cadonna,2024-05-03T10:08:31Z,same here.,0,0.9916109442710876
1589011280,15640,cadonna,2024-05-03T10:12:05Z,not needed.,0,0.9928713440895081
1589011422,15640,cadonna,2024-05-03T10:12:15Z,not needed.,0,0.9928713440895081
1589016749,15640,cadonna,2024-05-03T10:17:44Z,couldn't you use a simple `collection` with a simple `arraylist` here?,0,0.9923551082611084
1589016846,15640,cadonna,2024-05-03T10:17:50Z,couldn't you use a simple `collection` with a simple `arraylist` here?,0,0.9923551082611084
1589061761,15640,cadonna,2024-05-03T11:05:52Z,tests for the new behavior added to `consumernetworkthread` are missing.,0,0.9848339557647705
1589073577,15640,cadonna,2024-05-03T11:19:32Z,do you not need to add some tests to verify the newly added reaper?,0,0.995254635810852
1599232056,15640,kirktrue,2024-05-14T00:16:37Z,"there's some debate over that, for sure. however, this is the same error processing we've used before this change, so hopefully we can continue that debate separately?",0,0.9686775207519531
1599232355,15640,kirktrue,2024-05-14T00:17:17Z,"we've had some confusion in the past between timeouts and expiration, but i can remove it if you firmly want it removed.",0,0.9900966882705688
1599233659,15640,kirktrue,2024-05-14T00:19:47Z,the use of the `timer` is only for the test method itself. i'd argue the use of the `timer` makes the code a little more obvious than a plain `long` variable as the code switches between expiration timestamps and timeouts.,0,0.9896732568740845
1599235694,15640,kirktrue,2024-05-14T00:24:21Z,"yes. previous versions of `reapexpiredandcompleted()` required a `blockingqueue`. when the logic was changed to use a more general `collection`, i failed to update the test code. i will make the change as suggested.",0,0.992573618888855
1599236609,15640,kirktrue,2024-05-14T00:25:57Z,done.,0,0.9897913336753845
1599236661,15640,kirktrue,2024-05-14T00:26:04Z,done.,0,0.9897913336753845
1599243250,15640,kirktrue,2024-05-14T00:40:27Z,i went ahead and made the change you suggested :thumbs_up:,1,0.9869726300239563
1599243369,15640,kirktrue,2024-05-14T00:40:36Z,removed.,0,0.9612457156181335
1599243426,15640,kirktrue,2024-05-14T00:40:42Z,also removed.,0,0.9819897413253784
1599243498,15640,kirktrue,2024-05-14T00:40:50Z,"removed here, too.",0,0.9608095288276672
1599243592,15640,kirktrue,2024-05-14T00:41:04Z,and from here as well :winking_face:,1,0.9946787357330322
1599244057,15640,kirktrue,2024-05-14T00:42:02Z,"i will add tests for the `consumernetworkthread`, but it will probably take some contortion :thinking_face:",1,0.4714271128177643
1599244816,15640,kirktrue,2024-05-14T00:43:28Z,i will try my best to add tests to `asynckafkaconsumertest`. i'm hoping it's not quite as bad as i'm imagining it will be :frowning_face_with_open_mouth:,-1,0.9770439267158508
1599266953,15640,kirktrue,2024-05-14T01:27:07Z,"keep in mind that `add()` is called _for each event_ in the queue. if we remove completed events in `add()`, we're updating `tracked` each time, too. in the current approach, `tracked` is only updated once inside `reapexpiredandcompleted()`. i think i'm missing the benefit of moving it to `add()` :thinking_face:",0,0.866733729839325
1599698758,15640,cadonna,2024-05-14T09:31:32Z,"usually if it takes some contortion to write unit tests, then there is usually a code smell somewhere. :thinking_face: unit tests do not only test code in execution, but often also help to design components that have loose coupling and high cohesion.",1,0.5036631226539612
1599699017,15640,cadonna,2024-05-14T09:31:43Z,see my comment above. i am sure you will find a good solution!,1,0.9815410375595093
1600781636,15640,kirktrue,2024-05-14T23:38:33Z,"oh, the code definitely has smells! :winking_face: i added a test to `consumernetworkthread`.",1,0.9883346557617188
1600781735,15640,kirktrue,2024-05-14T23:38:45Z,i added a test to `asynckafkaconsumertest`.,0,0.9944619536399841
1601414540,15640,cadonna,2024-05-15T10:56:53Z,why is this not a mock? you do not need to test the actual reaper here. you just need to verify that the reaper is called correctly in the correct situations. please do not use a spy. :folded_hands:,-1,0.9193502068519592
1601422068,15640,cadonna,2024-05-15T11:02:46Z,"the reaper is not only called in `close()`. it is also called in `unsubscribe()` and `poll()`. i do not know how important it is that the reaper is called in `unsubscribe()` or if it is a collateral that we do not need to test. you know best. however, verifying the calls to the reaper in `poll()` seems important to me, doesn't it?",0,0.9855535626411438
1601428828,15640,cadonna,2024-05-15T11:07:52Z,"if you used a mock for the reaper, something like this would be enough to verify the correct use of the reaper in `close()`. [code block]",0,0.9952307343482971
1601430406,15640,cadonna,2024-05-15T11:09:01Z,"also here, why not a mock?",0,0.9835401177406311
1601431832,15640,cadonna,2024-05-15T11:10:14Z,with a mock also this test should get simpler.,0,0.9839257001876831
1601434014,15640,cadonna,2024-05-15T11:12:16Z,"i would write two distinct tests for `runonce()` and `cleanup()`. by using a mock, it should get simpler to separate the tests.",0,0.9892171621322632
1602381867,15640,kirktrue,2024-05-15T23:56:21Z,done,0,0.8682363629341125
1602381940,15640,kirktrue,2024-05-15T23:56:30Z,agreed. ptal.,0,0.5785118937492371
1602382027,15640,kirktrue,2024-05-15T23:56:39Z,"yes, ptal.",0,0.9908079504966736
1603682545,15640,lianetm,2024-05-16T16:22:52Z,the benefit i see is self-cleaning which reduces the scope/responsibilities of `tracked`. we don't really care about events that are created and complete successfully (so nice that they are just temporarily tracked and automatically disappear when they complete). then `reapexpiredandcompleted` it's simply about `reapexpired`,0,0.9414841532707214
1603740393,15640,lianetm,2024-05-16T17:05:16Z,just a suggestion but i would leave it to you as they may be impl details i'm missing ;),0,0.8950087428092957
1603994190,15640,kirktrue,2024-05-16T20:30:44Z,changed to mock.,0,0.7879366874694824
1603994499,15640,kirktrue,2024-05-16T20:31:07Z,"added tests for reaper invocation for `close()`, `poll()`, and `unsubscribe()`.",0,0.9945976734161377
1603994732,15640,kirktrue,2024-05-16T20:31:20Z,done.,0,0.9897913336753845
1604239000,15640,kirktrue,2024-05-17T01:39:30Z,"& please let me know if the following makes sense. i am trying to convince myself of this design as much as anyone else :grinning_face_with_smiling_eyes:... ------- the `consumernetworkthread.run()` method sits in a tight loop that calls `runonce()` on each pass. the ordering of operations inside `runonce()` is as follows: 1. call `processapplicationevents()`, for each event... a. call `completableeventreaper.add()` to add the event to `tracked` list b. call `applicationeventprocessor.process()` to call relevant request manager apis based on the event. many of the calls to the request manager apis will create and return `completablefuture`s 2. call `requestmanager.poll()` for each request manager 3. call `networkclientdelegate.add()` for each `unsentrequest` returned from step 2 4. call `networkclientdelegate.poll()` to process all the requests added in step 3. this will invoke handlers for received network responses, which will call `complete()`/`completeexceptionally()` to be called on any `completablefuture`s created in step 1b 5. call `reapexpiredapplicationevents()` (which calls `completableeventreaper.reap()`) to remove expired events and any `completablefuture`s completed in step 4 the design of `consumernetworkthread` is such that an event's `future` will _only_ `complete()` (success or failure) in step 4. any events eligible to be removed from `tracked` in step 1 would have already been removed in the previous loop's step 5. so it makes the most sense to me to leave the removal in `reap()` vs. `add()`.",1,0.9590122699737549
1608020071,15640,cadonna,2024-05-21T10:02:24Z,why did you remove this test without replacement?,0,0.9915133118629456
1608024280,15640,cadonna,2024-05-21T10:05:39Z,you control the time here. why do you not verify that `reap()` is called with the correct time?,0,0.9891991019248962
1608024737,15640,cadonna,2024-05-21T10:06:00Z,you control the time here. why do you not verify that `reap()` is called with the correct time?,0,0.9891991019248962
1608418633,15640,lianetm,2024-05-21T14:17:52Z,"do we expect the close to throw? if so, we should verify that (at the moment our test will just complete successfully if the close does not throw). if that's the expectation, maybe this simpler snippet would cover it all: [code block]",0,0.9932690262794495
1608453186,15640,lianetm,2024-05-21T14:38:42Z,"this is not a ""maybe"" anymore, so what about `autocommitsyncallconsumed`?",0,0.9910949468612671
1608487528,15640,lianetm,2024-05-21T14:59:16Z,don't we want >= here when identifying expired events? i would expect so (that's the semantic applied in the `timer` class [a link] for instance),0,0.9933494925498962
1608516652,15640,lianetm,2024-05-21T15:18:31Z,"this `processor` passed as argument is in the end always a reference to the `backgroundeventprocessor`, so could we simplify this, remove the arg and directly reference the var? it caught my attention when seeing how this is used, which seems a bit redundant with all calls having to provide the same `processbackgroundevents(backgroundeventprocessor, ...` which feels like an internal that the `processbackgroundevents` could know about.",0,0.9870255589485168
1608534184,15640,kirktrue,2024-05-21T15:30:00Z,good call. done!,1,0.9956315755844116
1608534408,15640,kirktrue,2024-05-21T15:30:11Z,"and done here, too.",0,0.9941781759262085
1608539565,15640,kirktrue,2024-05-21T15:33:44Z,resolving this as there has been further discussion for some time.,0,0.9886217713356018
1608540876,15640,kirktrue,2024-05-21T15:34:43Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9744672775268555
1608541319,15640,kirktrue,2024-05-21T15:35:03Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9744672775268555
1608541494,15640,kirktrue,2024-05-21T15:35:12Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9744672775268555
1608541856,15640,kirktrue,2024-05-21T15:35:25Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9744672775268555
1608542017,15640,kirktrue,2024-05-21T15:35:32Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9744672775268555
1608542270,15640,kirktrue,2024-05-21T15:35:43Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9744672775268555
1608542683,15640,kirktrue,2024-05-21T15:36:00Z,resolving this thread as there have been no further comments for some time. please un-resolve if there is further discussion needed.,0,0.9744672775268555
1608584519,15640,kirktrue,2024-05-21T16:00:40Z,reinstated.,0,0.9771552085876465
1608595900,15640,kirktrue,2024-05-21T16:06:50Z,"this is an interesting point :thinking_face: if a user provides a timeout of 1000 milliseconds, is it expired at 1000 milliseconds or at 1001 milliseconds? regardless, i will change it to `>=` to be consistent.",1,0.969264030456543
1608607062,15640,kirktrue,2024-05-21T16:15:26Z,there is a unit test that passes in a mocked event processor. let me look at refactoring this.,0,0.9917771816253662
1608607604,15640,kirktrue,2024-05-21T16:15:53Z,changed to just `autocommitsync()`. is that ok?,0,0.9942461848258972
1608614638,15640,lianetm,2024-05-21T16:21:36Z,"yes, the flow makes sense to me. also fine with me to keep the reap handling completed and expired.",0,0.9675451517105103
1608730407,15640,kirktrue,2024-05-21T18:01:36Z,done.,0,0.9897913336753845
1608732398,15640,kirktrue,2024-05-21T18:03:30Z,done. that's much better :grinning_face_with_smiling_eyes:,1,0.9956591129302979
1608870767,15640,lianetm,2024-05-21T19:43:33Z,"how did we resolve this? i see the section got completely removed, verification not needed?",0,0.9956367611885071
1608875582,15640,kirktrue,2024-05-21T19:48:33Z,"yes, it turns out that changes made elsewhere have obviated the need for this check.",0,0.990988552570343
1608897877,15640,lianetm,2024-05-21T20:10:37Z,"actually seems to me that we shouldn't have this test here (and maybe this is why removed it before?). as i see it, this unit test is testing something that is not the `consumernetworkthread`'s responsibility (and that's why it ends up being complicated, having to mimic the reaper behaviour and spying). it is testing that events are completed, and that's the reaper.reap responsibility, so seems to me we need to: 1. test that the `consumernetworkthread` calls the reaper with the full list of events -> done already in the [a link] 2. test that the `completableeventreaper.reap(collection events)` completes the events -> done in completableeventreapertest ([a link] and [a link] in the end, as it is, we end up asserting a behaviour we're mocking ourselves in the `doanswer`, so not much value i would say? agree with that we need coverage, but i would say that we have it, on my points 1 and 2, and this should be removed. makes sense?",0,0.9675338864326477
1608934073,15640,kirktrue,2024-05-21T20:48:04Z,"yes, the test was a little suspect in terms of its value-add, so i'd removed it. i was planning to file a jira to move several of the tests (including this one) from `consumernetworkthreadtest` to `applicationeventprocessortest`. then we could fix up some of the funkiness in this test as a separate task.",0,0.937304675579071
1609312616,15640,cadonna,2024-05-22T06:09:52Z,"that is all fine! i was not arguing that we need to keep the test, but if i see a test removed without replacement, i suspect a mistake. which did apparently not happen in this case. next time comment on the pr why you removed the test.",1,0.955449104309082
1609353060,15640,cadonna,2024-05-22T06:28:44Z,"do you still have the change locally, because here it does still not verify the correct time?",0,0.9932643175125122
